const data_for_language_middle_east_arabic = 
[
	{"name":"mittens","keyword":"arabic","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/google/mittens","creator_name":"Google","creator_url":"https://huggingface.co/google","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tMiTTenS: A Dataset for Evaluating Misgendering in Translation\\n\\t\\n\\nMisgendering is the act of referring to someone in a way that does not reflect their gender identity.  Translation systems, including foundation models capable of translation, can produce errors that result in misgendering harms. To measure the extent of such potential harms when translating into and out of English, we introduce a dataset, MiTTenS, covering 26 languages from a variety of language families and scriptsâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/google/mittens.","first_N":5,"first_N_keywords":["translation","Arabic","Finnish","Oromo","Ganda"],"keywords_longer_than_N":true},
	{"name":"Arabic_Aya","keyword":"arabic","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/2A2I/Arabic_Aya","creator_name":"2A2I","creator_url":"https://huggingface.co/2A2I","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for : Arabic Aya (2A)\\n\\t\\n\\n\\n\\n\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tArabic Aya (2A) : A Curated Subset of the Aya Collection for Arabic Language Processing\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Sources & Infos\\n\\t\\n\\n\\nData Origin: Derived from 69 subsets of the original Aya datasets : CohereForAI/aya_collection, CohereForAI/aya_dataset, and CohereForAI/aya_evaluation_suite.\\nLanguages: Modern Standard Arabic (MSA) and a variety of Arabic dialects ( 'arb', 'arz', 'ary', 'ars', 'knc', 'acm', 'apc', 'aeb', 'ajp'â€¦ See the full description on the dataset page: https://huggingface.co/datasets/2A2I/Arabic_Aya.","first_N":5,"first_N_keywords":["text-classification","translation","summarization","Arabic","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"panlex","keyword":"arabic","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/lbourdois/panlex","creator_name":"LoÃ¯ck BOURDOIS","creator_url":"https://huggingface.co/lbourdois","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tPanLex\\n\\t\\n\\nJanuary 1, 2024 version of PanLex Language Vocabulary with 24,650,274 rows covering 6,152 languages.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tColumns\\n\\t\\n\\n\\nvocab: contains the text entry.  \\n639-3: contains the ISO 639-3 languages tags to allow users to filter on the language(s) of their choice.\\n639-3_english_name: the English language name associated to the code ISO 639-3. \\nvar_code: contains a code to differentiate language variants. In practice, this is the code 639-3 + a number.  If 000, itâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/lbourdois/panlex.","first_N":5,"first_N_keywords":["Ghotuo","Alumu-Tesu","Ari","Amal","ArbÃ«reshÃ« Albanian"],"keywords_longer_than_N":true},
	{"name":"panlex","keyword":"egyptian arabic","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/lbourdois/panlex","creator_name":"LoÃ¯ck BOURDOIS","creator_url":"https://huggingface.co/lbourdois","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tPanLex\\n\\t\\n\\nJanuary 1, 2024 version of PanLex Language Vocabulary with 24,650,274 rows covering 6,152 languages.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tColumns\\n\\t\\n\\n\\nvocab: contains the text entry.  \\n639-3: contains the ISO 639-3 languages tags to allow users to filter on the language(s) of their choice.\\n639-3_english_name: the English language name associated to the code ISO 639-3. \\nvar_code: contains a code to differentiate language variants. In practice, this is the code 639-3 + a number.  If 000, itâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/lbourdois/panlex.","first_N":5,"first_N_keywords":["Ghotuo","Alumu-Tesu","Ari","Amal","ArbÃ«reshÃ« Albanian"],"keywords_longer_than_N":true},
	{"name":"panlex","keyword":"levantine arabic","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/lbourdois/panlex","creator_name":"LoÃ¯ck BOURDOIS","creator_url":"https://huggingface.co/lbourdois","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tPanLex\\n\\t\\n\\nJanuary 1, 2024 version of PanLex Language Vocabulary with 24,650,274 rows covering 6,152 languages.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tColumns\\n\\t\\n\\n\\nvocab: contains the text entry.  \\n639-3: contains the ISO 639-3 languages tags to allow users to filter on the language(s) of their choice.\\n639-3_english_name: the English language name associated to the code ISO 639-3. \\nvar_code: contains a code to differentiate language variants. In practice, this is the code 639-3 + a number.  If 000, itâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/lbourdois/panlex.","first_N":5,"first_N_keywords":["Ghotuo","Alumu-Tesu","Ari","Amal","ArbÃ«reshÃ« Albanian"],"keywords_longer_than_N":true},
	{"name":"panlex","keyword":"mesopotamian arabic","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/lbourdois/panlex","creator_name":"LoÃ¯ck BOURDOIS","creator_url":"https://huggingface.co/lbourdois","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tPanLex\\n\\t\\n\\nJanuary 1, 2024 version of PanLex Language Vocabulary with 24,650,274 rows covering 6,152 languages.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tColumns\\n\\t\\n\\n\\nvocab: contains the text entry.  \\n639-3: contains the ISO 639-3 languages tags to allow users to filter on the language(s) of their choice.\\n639-3_english_name: the English language name associated to the code ISO 639-3. \\nvar_code: contains a code to differentiate language variants. In practice, this is the code 639-3 + a number.  If 000, itâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/lbourdois/panlex.","first_N":5,"first_N_keywords":["Ghotuo","Alumu-Tesu","Ari","Amal","ArbÃ«reshÃ« Albanian"],"keywords_longer_than_N":true},
	{"name":"panlex","keyword":"moroccan arabic","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/lbourdois/panlex","creator_name":"LoÃ¯ck BOURDOIS","creator_url":"https://huggingface.co/lbourdois","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tPanLex\\n\\t\\n\\nJanuary 1, 2024 version of PanLex Language Vocabulary with 24,650,274 rows covering 6,152 languages.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tColumns\\n\\t\\n\\n\\nvocab: contains the text entry.  \\n639-3: contains the ISO 639-3 languages tags to allow users to filter on the language(s) of their choice.\\n639-3_english_name: the English language name associated to the code ISO 639-3. \\nvar_code: contains a code to differentiate language variants. In practice, this is the code 639-3 + a number.  If 000, itâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/lbourdois/panlex.","first_N":5,"first_N_keywords":["Ghotuo","Alumu-Tesu","Ari","Amal","ArbÃ«reshÃ« Albanian"],"keywords_longer_than_N":true},
	{"name":"panlex","keyword":"najdi arabic","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/lbourdois/panlex","creator_name":"LoÃ¯ck BOURDOIS","creator_url":"https://huggingface.co/lbourdois","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tPanLex\\n\\t\\n\\nJanuary 1, 2024 version of PanLex Language Vocabulary with 24,650,274 rows covering 6,152 languages.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tColumns\\n\\t\\n\\n\\nvocab: contains the text entry.  \\n639-3: contains the ISO 639-3 languages tags to allow users to filter on the language(s) of their choice.\\n639-3_english_name: the English language name associated to the code ISO 639-3. \\nvar_code: contains a code to differentiate language variants. In practice, this is the code 639-3 + a number.  If 000, itâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/lbourdois/panlex.","first_N":5,"first_N_keywords":["Ghotuo","Alumu-Tesu","Ari","Amal","ArbÃ«reshÃ« Albanian"],"keywords_longer_than_N":true},
	{"name":"panlex","keyword":"standard arabic","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/lbourdois/panlex","creator_name":"LoÃ¯ck BOURDOIS","creator_url":"https://huggingface.co/lbourdois","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tPanLex\\n\\t\\n\\nJanuary 1, 2024 version of PanLex Language Vocabulary with 24,650,274 rows covering 6,152 languages.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tColumns\\n\\t\\n\\n\\nvocab: contains the text entry.  \\n639-3: contains the ISO 639-3 languages tags to allow users to filter on the language(s) of their choice.\\n639-3_english_name: the English language name associated to the code ISO 639-3. \\nvar_code: contains a code to differentiate language variants. In practice, this is the code 639-3 + a number.  If 000, itâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/lbourdois/panlex.","first_N":5,"first_N_keywords":["Ghotuo","Alumu-Tesu","Ari","Amal","ArbÃ«reshÃ« Albanian"],"keywords_longer_than_N":true},
	{"name":"panlex","keyword":"tunisian arabic","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/lbourdois/panlex","creator_name":"LoÃ¯ck BOURDOIS","creator_url":"https://huggingface.co/lbourdois","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tPanLex\\n\\t\\n\\nJanuary 1, 2024 version of PanLex Language Vocabulary with 24,650,274 rows covering 6,152 languages.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tColumns\\n\\t\\n\\n\\nvocab: contains the text entry.  \\n639-3: contains the ISO 639-3 languages tags to allow users to filter on the language(s) of their choice.\\n639-3_english_name: the English language name associated to the code ISO 639-3. \\nvar_code: contains a code to differentiate language variants. In practice, this is the code 639-3 + a number.  If 000, itâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/lbourdois/panlex.","first_N":5,"first_N_keywords":["Ghotuo","Alumu-Tesu","Ari","Amal","ArbÃ«reshÃ« Albanian"],"keywords_longer_than_N":true},
	{"name":"panlex","keyword":"ta'izzi-adeni arabic","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/lbourdois/panlex","creator_name":"LoÃ¯ck BOURDOIS","creator_url":"https://huggingface.co/lbourdois","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tPanLex\\n\\t\\n\\nJanuary 1, 2024 version of PanLex Language Vocabulary with 24,650,274 rows covering 6,152 languages.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tColumns\\n\\t\\n\\n\\nvocab: contains the text entry.  \\n639-3: contains the ISO 639-3 languages tags to allow users to filter on the language(s) of their choice.\\n639-3_english_name: the English language name associated to the code ISO 639-3. \\nvar_code: contains a code to differentiate language variants. In practice, this is the code 639-3 + a number.  If 000, itâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/lbourdois/panlex.","first_N":5,"first_N_keywords":["Ghotuo","Alumu-Tesu","Ari","Amal","ArbÃ«reshÃ« Albanian"],"keywords_longer_than_N":true},
	{"name":"Quran-Tafseers","keyword":"arabic","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/riotu-lab/Quran-Tafseers","creator_name":"Robotics and Interne-of-Things","creator_url":"https://huggingface.co/riotu-lab","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tModel Details\\n\\t\\n\\nDeveloped by: Prince Sultan University - Riotu Lab\\nThis dataset is intended for use in natural language processing tasks, particularly for understanding classical Arabic and religious texts, including text analysis, language modeling, and thematic studies.\\nPrimary Users: Researchers and developers in the field of natural language processing, religious studies, and AI, specifically those working with classical Arabic texts.\\nOut-of-scope Use Cases: This dataset isâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/riotu-lab/Quran-Tafseers.","first_N":5,"first_N_keywords":["question-answering","Arabic","apache-2.0","10K - 100K","json"],"keywords_longer_than_N":true},
	{"name":"stata","keyword":"arabic","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/adenhaus/stata","creator_name":"Aden Haussmann","creator_url":"https://huggingface.co/adenhaus","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tBackground\\n\\t\\n\\nThis dataset contains human evaluations of whether outputs on the TaTA dataset are a) understandable and b) attributable to the source tables. See TaTA: A Multilingual Table-to-Text Dataset for African Languages for more details. \\nIt can be used to train a learned metric, called StATA, to evaluate model performance on the TaTA dataset.\\nThe original can be found here.\\n","first_N":5,"first_N_keywords":["table-to-text","yes","Arabic","English","French"],"keywords_longer_than_N":true},
	{"name":"CIDAR-EVAL-100","keyword":"arabic","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/arbml/CIDAR-EVAL-100","creator_name":"Arabic Machine Learning ","creator_url":"https://huggingface.co/arbml","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for \\\"CIDAR-EVAL-100\\\"\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tCIDAR-EVAL-100\\n\\t\\n\\nCIDAR-EVAL-100 contains 100 instructions about Arabic culture. The dataset can be used to evaluate an LLM for culturally relevant answers. \\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tðŸ“š Datasets Summary\\n\\t\\n\\n\\n  \\nName\\nExplanation\\n\\n\\nCIDAR \\n10,000 instructions and responses in Arabic\\n\\n\\nCIDAR-EVAL-100 \\n100 instructions to evaluate LLMs on cultural relevance\\n\\n\\nCIDAR-MCQ-100 \\n100 Multiple choice questions and answers to evaluate LLMs on culturalâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/arbml/CIDAR-EVAL-100.","first_N":5,"first_N_keywords":["text-generation","Arabic","apache-2.0","< 1K","parquet"],"keywords_longer_than_N":true},
	{"name":"ChatML-aya_dataset","keyword":"egyptian arabic","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Felladrin/ChatML-aya_dataset","creator_name":"Victor Nogueira","creator_url":"https://huggingface.co/Felladrin","description":"CohereForAI/aya_dataset in ChatML format, ready to use in HuggingFace TRL's SFT Trainer.\\nPython code used for conversion:\\nfrom datasets import load_dataset\\nfrom transformers import AutoTokenizer\\n\\ntokenizer = AutoTokenizer.from_pretrained(\\\"Felladrin/Llama-160M-Chat-v1\\\")\\n\\ndataset = load_dataset(\\\"CohereForAI/aya_dataset\\\", split=\\\"train\\\")\\n\\ndef format(columns):\\n    messages = [\\n        {\\n            \\\"role\\\": \\\"user\\\",\\n            \\\"content\\\": columns[\\\"inputs\\\"].strip(),\\n        },\\n        {â€¦ See the full description on the dataset page: https://huggingface.co/datasets/Felladrin/ChatML-aya_dataset.","first_N":5,"first_N_keywords":["question-answering","text-generation","crowdsourced","expert-generated","crowdsourced"],"keywords_longer_than_N":true},
	{"name":"ChatML-aya_dataset","keyword":"levantine arabic","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Felladrin/ChatML-aya_dataset","creator_name":"Victor Nogueira","creator_url":"https://huggingface.co/Felladrin","description":"CohereForAI/aya_dataset in ChatML format, ready to use in HuggingFace TRL's SFT Trainer.\\nPython code used for conversion:\\nfrom datasets import load_dataset\\nfrom transformers import AutoTokenizer\\n\\ntokenizer = AutoTokenizer.from_pretrained(\\\"Felladrin/Llama-160M-Chat-v1\\\")\\n\\ndataset = load_dataset(\\\"CohereForAI/aya_dataset\\\", split=\\\"train\\\")\\n\\ndef format(columns):\\n    messages = [\\n        {\\n            \\\"role\\\": \\\"user\\\",\\n            \\\"content\\\": columns[\\\"inputs\\\"].strip(),\\n        },\\n        {â€¦ See the full description on the dataset page: https://huggingface.co/datasets/Felladrin/ChatML-aya_dataset.","first_N":5,"first_N_keywords":["question-answering","text-generation","crowdsourced","expert-generated","crowdsourced"],"keywords_longer_than_N":true},
	{"name":"ChatML-aya_dataset","keyword":"moroccan arabic","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Felladrin/ChatML-aya_dataset","creator_name":"Victor Nogueira","creator_url":"https://huggingface.co/Felladrin","description":"CohereForAI/aya_dataset in ChatML format, ready to use in HuggingFace TRL's SFT Trainer.\\nPython code used for conversion:\\nfrom datasets import load_dataset\\nfrom transformers import AutoTokenizer\\n\\ntokenizer = AutoTokenizer.from_pretrained(\\\"Felladrin/Llama-160M-Chat-v1\\\")\\n\\ndataset = load_dataset(\\\"CohereForAI/aya_dataset\\\", split=\\\"train\\\")\\n\\ndef format(columns):\\n    messages = [\\n        {\\n            \\\"role\\\": \\\"user\\\",\\n            \\\"content\\\": columns[\\\"inputs\\\"].strip(),\\n        },\\n        {â€¦ See the full description on the dataset page: https://huggingface.co/datasets/Felladrin/ChatML-aya_dataset.","first_N":5,"first_N_keywords":["question-answering","text-generation","crowdsourced","expert-generated","crowdsourced"],"keywords_longer_than_N":true},
	{"name":"ChatML-aya_dataset","keyword":"najdi arabic","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Felladrin/ChatML-aya_dataset","creator_name":"Victor Nogueira","creator_url":"https://huggingface.co/Felladrin","description":"CohereForAI/aya_dataset in ChatML format, ready to use in HuggingFace TRL's SFT Trainer.\\nPython code used for conversion:\\nfrom datasets import load_dataset\\nfrom transformers import AutoTokenizer\\n\\ntokenizer = AutoTokenizer.from_pretrained(\\\"Felladrin/Llama-160M-Chat-v1\\\")\\n\\ndataset = load_dataset(\\\"CohereForAI/aya_dataset\\\", split=\\\"train\\\")\\n\\ndef format(columns):\\n    messages = [\\n        {\\n            \\\"role\\\": \\\"user\\\",\\n            \\\"content\\\": columns[\\\"inputs\\\"].strip(),\\n        },\\n        {â€¦ See the full description on the dataset page: https://huggingface.co/datasets/Felladrin/ChatML-aya_dataset.","first_N":5,"first_N_keywords":["question-answering","text-generation","crowdsourced","expert-generated","crowdsourced"],"keywords_longer_than_N":true},
	{"name":"ChatML-aya_dataset","keyword":"standard arabic","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Felladrin/ChatML-aya_dataset","creator_name":"Victor Nogueira","creator_url":"https://huggingface.co/Felladrin","description":"CohereForAI/aya_dataset in ChatML format, ready to use in HuggingFace TRL's SFT Trainer.\\nPython code used for conversion:\\nfrom datasets import load_dataset\\nfrom transformers import AutoTokenizer\\n\\ntokenizer = AutoTokenizer.from_pretrained(\\\"Felladrin/Llama-160M-Chat-v1\\\")\\n\\ndataset = load_dataset(\\\"CohereForAI/aya_dataset\\\", split=\\\"train\\\")\\n\\ndef format(columns):\\n    messages = [\\n        {\\n            \\\"role\\\": \\\"user\\\",\\n            \\\"content\\\": columns[\\\"inputs\\\"].strip(),\\n        },\\n        {â€¦ See the full description on the dataset page: https://huggingface.co/datasets/Felladrin/ChatML-aya_dataset.","first_N":5,"first_N_keywords":["question-answering","text-generation","crowdsourced","expert-generated","crowdsourced"],"keywords_longer_than_N":true},
	{"name":"ChatML-aya_dataset","keyword":"ta'izzi-adeni arabic","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Felladrin/ChatML-aya_dataset","creator_name":"Victor Nogueira","creator_url":"https://huggingface.co/Felladrin","description":"CohereForAI/aya_dataset in ChatML format, ready to use in HuggingFace TRL's SFT Trainer.\\nPython code used for conversion:\\nfrom datasets import load_dataset\\nfrom transformers import AutoTokenizer\\n\\ntokenizer = AutoTokenizer.from_pretrained(\\\"Felladrin/Llama-160M-Chat-v1\\\")\\n\\ndataset = load_dataset(\\\"CohereForAI/aya_dataset\\\", split=\\\"train\\\")\\n\\ndef format(columns):\\n    messages = [\\n        {\\n            \\\"role\\\": \\\"user\\\",\\n            \\\"content\\\": columns[\\\"inputs\\\"].strip(),\\n        },\\n        {â€¦ See the full description on the dataset page: https://huggingface.co/datasets/Felladrin/ChatML-aya_dataset.","first_N":5,"first_N_keywords":["question-answering","text-generation","crowdsourced","expert-generated","crowdsourced"],"keywords_longer_than_N":true},
	{"name":"arabic_xvector_embeddings","keyword":"arabic","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/herwoww/arabic_xvector_embeddings","creator_name":"Hawau Olamide Toyin","creator_url":"https://huggingface.co/herwoww","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tArabic Speaker Embeddings extracted from ASC and ClArTTS\\n\\t\\n\\nThere is one speaker embedding for each utterance in the validation set of both datasets. The speaker embeddings are 512-element X-vectors.\\nArabic Speech Corpus has 100 files for a single male speaker and ClArTTS has 205 files for a single male speaker.\\nThe X-vectors were extracted using this script, which uses the speechbrain/spkrec-xvect-voxceleb model.\\nUsage:\\nfrom datasets import load_dataset\\n\\nembeddings_dataset =â€¦ See the full description on the dataset page: https://huggingface.co/datasets/herwoww/arabic_xvector_embeddings.","first_N":5,"first_N_keywords":["text-to-speech","audio-to-audio","Arabic","mit","< 1K"],"keywords_longer_than_N":true},
	{"name":"CIDAR-MCQ-100","keyword":"arabic","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/arbml/CIDAR-MCQ-100","creator_name":"Arabic Machine Learning ","creator_url":"https://huggingface.co/arbml","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for \\\"CIDAR-MCQ-100\\\"\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tCIDAR-MCQ-100\\n\\t\\n\\nCIDAR-MCQ-100 contains 100 multiple-choice questions and answers about the Arabic culture. \\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tðŸ“š Datasets Summary\\n\\t\\n\\n\\n  \\nName\\nExplanation\\n\\n\\nCIDAR \\n10,000 instructions and responses in Arabic\\n\\n\\nCIDAR-EVAL-100 \\n100 instructions to evaluate LLMs on cultural relevance\\n\\n\\nCIDAR-MCQ-100 \\n100 Multiple choice questions and answers to evaluate LLMs on cultural relevance \\n\\n\\n\\n\\n\\n\\n\\n\\t\\n\\t\\t\\nCategory\\nCIDAR-EVAL-100â€¦ See the full description on the dataset page: https://huggingface.co/datasets/arbml/CIDAR-MCQ-100.","first_N":5,"first_N_keywords":["multiple-choice","Arabic","apache-2.0","< 1K","parquet"],"keywords_longer_than_N":true},
	{"name":"MAGBIG","keyword":"arabic","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/felfri/MAGBIG","creator_name":"Felix Friedrich","creator_url":"https://huggingface.co/felfri","description":"\\n\\t\\n\\t\\t\\n\\t\\tMAGBIG benchmark\\n\\t\\n\\nThis is the MAGBIG benchmark proposed in https://arxiv.org/abs/2401.16092\\nThis benchmark is intended for multilingual text-to-image models. With MAGBIG, you can generate images for a diverse set of prompts across ten different languages. These images can be evaluated for differences across languages. MAGBIG is designed to uncover and assess biases across languages such as gender, race, age, etc. This way, we can measure whether bias exists in a language, but also ifâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/felfri/MAGBIG.","first_N":5,"first_N_keywords":["text-to-image","English","German","Italian","French"],"keywords_longer_than_N":true},
	{"name":"ArabicaQA","keyword":"arabic","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/abdoelsayed/ArabicaQA","creator_name":"unkown","creator_url":"https://huggingface.co/abdoelsayed","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tArabicaQA\\n\\t\\n\\nArabicaQA: Comprehensive Dataset for Arabic Question Answering\\nThis repository contains dataset for paper ArabicaQA: Comprehensive Dataset for Arabic Question Answering. Below, we provide details regarding the materials available in this repository:\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset\\n\\t\\n\\nWithin this folder, you will find the training, validation, and test sets of the ArabicaQA dataset. Refer to the table below for the dataset statistics:\\n\\n\\t\\n\\t\\t\\n\\nTraining\\nValidation\\nTest\\n\\n\\n\\t\\t\\nMRC (withâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/abdoelsayed/ArabicaQA.","first_N":5,"first_N_keywords":["question-answering","crowdsourced","crowdsourced","found","Arabic"],"keywords_longer_than_N":true},
	{"name":"Multi-lingual_Detection","keyword":"arabic","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Manirathinam21/Multi-lingual_Detection","creator_name":"Manirathinam","creator_url":"https://huggingface.co/Manirathinam21","description":"Manirathinam21/Multi-lingual_Detection dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["text-classification","Arabic","Tamil","Japanese","English"],"keywords_longer_than_N":true},
	{"name":"mewsli-x","keyword":"arabic","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/izhx/mewsli-x","creator_name":"Xin Zhang","creator_url":"https://huggingface.co/izhx","description":"I generated the dataset following mewsli-x.md#getting-started\\nand converted into different parts (see process.py):\\n\\nar/de/en/es/fa/ja/pl/ro/ta/tr/uk wikinews_mentions dev and test (from wikinews_mentions-dev/test.jsonl)\\ncandidate entities of 50 languages (from candidate_set_entities.jsonl)\\nEnglish wikipedia_pairs to fine-tune models (from wikipedia_pairs-dev/train.jsonl)\\n\\nRaw data files are in raw.tar.gz, which contains:\\n[...] 535M Feb 24 22:06 candidate_set_entities.jsonl\\n[...] 9.8M Feb 24â€¦ See the full description on the dataset page: https://huggingface.co/datasets/izhx/mewsli-x.","first_N":5,"first_N_keywords":["text-retrieval","entity-linking-retrieval","Afrikaans","Arabic","Azerbaijani"],"keywords_longer_than_N":true},
	{"name":"Arabic-OpenHermes-2.5","keyword":"arabic","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/2A2I/Arabic-OpenHermes-2.5","creator_name":"2A2I","creator_url":"https://huggingface.co/2A2I","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for \\\"Arabic-OpenHermes-2.5\\\"\\n\\t\\n\\n\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Sources & Infos\\n\\t\\n\\n\\nData Origin: Derived from the original OpenHermes dataset : teknium/OpenHermes-2.5.\\nLanguages: Modern Standard Arabic (MSA)\\nApplications: Language Modeling\\nMaintainer: Marwa El Kamil & Mohammed Machrouh\\nLicense: Apache-2.0\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tOverview\\n\\t\\n\\nArabic-OpenHermes-2.5 is a carefully curated dataset extracted / translated from the OpenHermes-2.5 collection provided by teknium.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tPurposeâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/2A2I/Arabic-OpenHermes-2.5.","first_N":5,"first_N_keywords":["Arabic","apache-2.0","100K - 1M","parquet","Text"],"keywords_longer_than_N":true},
	{"name":"MultiQ","keyword":"arabic","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/caro-holt/MultiQ","creator_name":"Holtermann","creator_url":"https://huggingface.co/caro-holt","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for MultiQ\\n\\t\\n\\nThis is the dataset corresponding to the paper \\\"Evaluating the Elementary Multilingual Capabilities of Large Language Models with MultiQ\\\". \\nIt is a silver standard benchmark that can be used to evaluate the basic multilingual capabilities of LLMs. It contains 200 open ended questions automatically \\ntranslated into 137 typologically diverse languages. \\n\\nCurated by: Carolin Holtermann, Paul RÃ¶ttger, Timm Dill, Anne Lauscher\\nLanguage(s) (NLP): 137 diverseâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/caro-holt/MultiQ.","first_N":5,"first_N_keywords":["question-answering","Tagalog","Samoan","Macedonian","Gujarati"],"keywords_longer_than_N":true},
	{"name":"argilla-dpo-mix-7k-arabic","keyword":"arabic","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/medmac01/argilla-dpo-mix-7k-arabic","creator_name":"Mohammed Machrouh","creator_url":"https://huggingface.co/medmac01","description":"medmac01/argilla-dpo-mix-7k-arabic dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["Arabic","mit","1K - 10K","parquet","Tabular"],"keywords_longer_than_N":true},
	{"name":"Open-ended_Questions_dialectal_data","keyword":"arabic","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/KIND-Dataset/Open-ended_Questions_dialectal_data","creator_name":"KIND","creator_url":"https://huggingface.co/KIND-Dataset","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nA collection of open-ended questions that was provided to the data marathon competitors to populate KIND dataset. It was designed to elicit longer responses cultural and context-rich sentences. \\nFor more details, please check the paper\\nThe KIND Dataset: A Social Collaboration Approach for Nuanced Dialect Data Collection\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tCitation Information\\n\\t\\n\\n@inproceedings{yamani-etal-2024-kind,\\n    title = \\\"The {KIND} Dataset: A Social Collaboration Approach forâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/KIND-Dataset/Open-ended_Questions_dialectal_data.","first_N":5,"first_N_keywords":["question-answering","Arabic","cc-by-4.0","< 1K","csv"],"keywords_longer_than_N":true},
	{"name":"argilla-dpo-mix-7k-arabic","keyword":"arabic","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/2A2I/argilla-dpo-mix-7k-arabic","creator_name":"2A2I","creator_url":"https://huggingface.co/2A2I","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for \\\"argilla-dpo-mix-7k-arabic\\\"\\n\\t\\n\\nMore Information needed\\n","first_N":5,"first_N_keywords":["Arabic","mit","1K - 10K","parquet","Tabular"],"keywords_longer_than_N":true},
	{"name":"bhojpuri","keyword":"arabic","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ankur02/bhojpuri","creator_name":"Ankur Verma","creator_url":"https://huggingface.co/ankur02","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tFLEURS\\n\\t\\n\\nFleurs is the speech version of the FLoRes machine translation benchmark. \\nWe use 2009 n-way parallel sentences from the FLoRes dev and devtest publicly available sets, in 102 languages. \\nTraining sets have around 10 hours of supervision. Speakers of the train sets are different than speakers from the dev/test sets. Multilingual fine-tuning is\\nused and â€unit error rateâ€ (characters, signs) of all languages is averaged. Languages and results are also grouped into sevenâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/ankur02/bhojpuri.","first_N":5,"first_N_keywords":["automatic-speech-recognition","expert-generated","crowdsourced","machine-generated","crowdsourced"],"keywords_longer_than_N":true},
	{"name":"2A2I-Arabic-OpenHermes-2.5-Llama-3","keyword":"arabic","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Lyte/2A2I-Arabic-OpenHermes-2.5-Llama-3","creator_name":"Yassine Ennaour","creator_url":"https://huggingface.co/Lyte","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for \\\"2A2I-Arabic-OpenHermes-2.5-Llama-3\\\"\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Sources & Infos\\n\\t\\n\\n\\nData Origin: Derived from the original Arabic OpenHermes dataset : 2A2I/Arabic-OpenHermes-2.5.\\nLanguages: Modern Standard Arabic (MSA)\\nApplications: Language Modeling\\nLicense: Apache-2.0\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tOverview\\n\\t\\n\\n2A2I-Arabic-OpenHermes-2.5-Llama is a Llama-3 compatible dataset carefully converted from the 2A2I's Arabic-OpenHermes-2.5 collection provided by Lyte.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tPurposeâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Lyte/2A2I-Arabic-OpenHermes-2.5-Llama-3.","first_N":5,"first_N_keywords":["question-answering","Arabic","apache-2.0","100K - 1M","parquet"],"keywords_longer_than_N":true},
	{"name":"Arabic-CivitAi-Images","keyword":"arabic","license":"GNU General Public License v3.0","license_url":"https://choosealicense.com/licenses/gpl-3.0/","language":"en","dataset_url":"https://huggingface.co/datasets/MohamedRashad/Arabic-CivitAi-Images","creator_name":"Mohamed Rashad","creator_url":"https://huggingface.co/MohamedRashad","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nTop +2k Images curated from CivitAI website, described using the great Qwen-VL-Max model and then translated using Command-R into the Arabic language\\n\\n\\n    \\n\\n","first_N":5,"first_N_keywords":["text-to-image","Arabic","gpl-3.0","1K - 10K","parquet"],"keywords_longer_than_N":true},
	{"name":"multi-hatecheck","keyword":"arabic","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/multi-hatecheck","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDescription\\n\\t\\n\\nCombines multilingual HateCheck datasets (10 languages, including English), by Paul Roettger and colleagues (2021, 2022).\\nThe original English dataset can be found under https://github.com/Paul/hatecheck.\\nDatasets for other languages are found at:\\n\\nhttps://github.com/Paul/hatecheck-arabic\\nhttps://github.com/Paul/hatecheck-mandarin\\nhttps://github.com/Paul/hatecheck-german\\nhttps://github.com/Paul/hatecheck-french\\nhttps://github.com/Paul/hatecheck-hindiâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/multi-hatecheck.","first_N":5,"first_N_keywords":["text-classification","Arabic","Portuguese","English","French"],"keywords_longer_than_N":true},
	{"name":"panlex-meanings","keyword":"egyptian arabic","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/cointegrated/panlex-meanings","creator_name":"David Dale","creator_url":"https://huggingface.co/cointegrated","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for panlex-meanings\\n\\t\\n\\nThis is a dataset of words in several thousand languages, extracted from https://panlex.org.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Details\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThis dataset has been extracted from https://panlex.org (the 20240301 database dump) and rearranged on the per-language basis.\\nEach language subset consists of expressions (words and phrases). \\nEach expression is associated with some meanings (if there is more than one meaning, they are inâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/cointegrated/panlex-meanings.","first_N":5,"first_N_keywords":["translation","Afar","Western Abnaki","Abkhazian","Abaza"],"keywords_longer_than_N":true},
	{"name":"panlex-meanings","keyword":"moroccan arabic","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/cointegrated/panlex-meanings","creator_name":"David Dale","creator_url":"https://huggingface.co/cointegrated","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for panlex-meanings\\n\\t\\n\\nThis is a dataset of words in several thousand languages, extracted from https://panlex.org.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Details\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThis dataset has been extracted from https://panlex.org (the 20240301 database dump) and rearranged on the per-language basis.\\nEach language subset consists of expressions (words and phrases). \\nEach expression is associated with some meanings (if there is more than one meaning, they are inâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/cointegrated/panlex-meanings.","first_N":5,"first_N_keywords":["translation","Afar","Western Abnaki","Abkhazian","Abaza"],"keywords_longer_than_N":true},
	{"name":"panlex-meanings","keyword":"standard arabic","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/cointegrated/panlex-meanings","creator_name":"David Dale","creator_url":"https://huggingface.co/cointegrated","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for panlex-meanings\\n\\t\\n\\nThis is a dataset of words in several thousand languages, extracted from https://panlex.org.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Details\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThis dataset has been extracted from https://panlex.org (the 20240301 database dump) and rearranged on the per-language basis.\\nEach language subset consists of expressions (words and phrases). \\nEach expression is associated with some meanings (if there is more than one meaning, they are inâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/cointegrated/panlex-meanings.","first_N":5,"first_N_keywords":["translation","Afar","Western Abnaki","Abkhazian","Abaza"],"keywords_longer_than_N":true},
	{"name":"chat_unsensored","keyword":"arabic","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/cleexiang/chat_unsensored","creator_name":"lixiang","creator_url":"https://huggingface.co/cleexiang","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Dataset Name\\n\\t\\n\\n\\n\\nThis dataset card aims to be a base template for new datasets. It has been generated using this raw template.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Details\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\n\\n\\n\\n\\n\\nCurated by: [More Information Needed]\\nFunded by [optional]: [More Information Needed]\\nShared by [optional]: [More Information Needed]\\nLanguage(s) (NLP): [More Information Needed]\\nLicense: [More Information Needed]\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Sources [optional]â€¦ See the full description on the dataset page: https://huggingface.co/datasets/cleexiang/chat_unsensored.","first_N":5,"first_N_keywords":["question-answering","Arabic","apache-2.0","1K - 10K","parquet"],"keywords_longer_than_N":true},
	{"name":"yy-chat-ar-20240327","keyword":"arabic","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/yongyi169/yy-chat-ar-20240327","creator_name":"yongyi","creator_url":"https://huggingface.co/yongyi169","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Dataset Name\\n\\t\\n\\n\\n\\nThis dataset card aims to be a base template for new datasets. It has been generated using this raw template.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Details\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\n\\n\\n\\n\\n\\nCurated by: [More Information Needed]\\nFunded by [optional]: [More Information Needed]\\nShared by [optional]: [More Information Needed]\\nLanguage(s) (NLP): [More Information Needed]\\nLicense: [More Information Needed]\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Sources [optional]â€¦ See the full description on the dataset page: https://huggingface.co/datasets/yongyi169/yy-chat-ar-20240327.","first_N":5,"first_N_keywords":["question-answering","Arabic","apache-2.0","1K - 10K","parquet"],"keywords_longer_than_N":true},
	{"name":"NTREX","keyword":"arabic","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/davidstap/NTREX","creator_name":"David Stap","creator_url":"https://huggingface.co/davidstap","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nNTREX -- News Test References for MT Evaluation from English into a total of 128 target languages. See original GitHub repo for full details.\\nExample of loading:\\ndataset = load_dataset(\\\"davidstap/NTREX\\\", \\\"rus_Cyrl\\\", trust_remote_code=True)\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages\\n\\t\\n\\nThe following languages are available:\\n\\n\\t\\n\\t\\t\\nLanguage Code\\nLanguage Name\\n\\n\\n\\t\\t\\nafr_Latn\\nAfrikaans\\n\\n\\namh_Ethi\\nAmharic\\n\\n\\narb_Arab\\nArabic\\n\\n\\naze_Latn\\nAzerbaijani\\n\\n\\nbak_Cyrl\\nBashkir\\n\\n\\nbel_Cyrl\\nBelarusianâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/davidstap/NTREX.","first_N":5,"first_N_keywords":["translation","expert-generated","expert-generated","translation","Afrikaans"],"keywords_longer_than_N":true},
	{"name":"biblenlp-corpus-mmteb","keyword":"standard arabic","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/davidstap/biblenlp-corpus-mmteb","creator_name":"David Stap","creator_url":"https://huggingface.co/davidstap","description":"This dataset pre-computes all English-centric directions from bible-nlp/biblenlp-corpus, and as a result loading is significantly faster.\\nLoading example:\\n>>> from datasets import load_dataset\\n>>> dataset = load_dataset(\\\"davidstap/biblenlp-corpus-mmteb\\\", \\\"eng-arb\\\", trust_remote_code=True)\\n>>> dataset\\nDatasetDict({\\n    train: Dataset({\\n        features: ['eng', 'arb'],\\n        num_rows: 28723\\n    })\\n    validation: Dataset({\\n        features: ['eng', 'arb'],\\n        num_rows: 1578\\n    })â€¦ See the full description on the dataset page: https://huggingface.co/datasets/davidstap/biblenlp-corpus-mmteb.","first_N":5,"first_N_keywords":["no-annotation","expert-generated","translation","multilingual","Arifama-Miniafia"],"keywords_longer_than_N":true},
	{"name":"yy-chat-ar-20240329","keyword":"arabic","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/yongyi169/yy-chat-ar-20240329","creator_name":"yongyi","creator_url":"https://huggingface.co/yongyi169","description":"yongyi169/yy-chat-ar-20240329 dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["question-answering","Arabic","apache-2.0","1K - 10K","parquet"],"keywords_longer_than_N":true},
	{"name":"moroccan-darija-youtube-subtitles","keyword":"arabic","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/bourbouh/moroccan-darija-youtube-subtitles","creator_name":"Hamza Bourbouh","creator_url":"https://huggingface.co/bourbouh","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tMoroccan Darija YouTube Subtitles Dataset\\n\\t\\n\\nThis dataset contains subtitles from YouTube videos in Moroccan Darija, a colloquial Arabic dialect spoken in Morocco. The subtitles were collected from several popular Moroccan YouTube channels, providing a diverse set of transcriptions in the Darija language.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThe dataset is provided as a CSV file, where each row represents a YouTube video and contains the following columns:\\n\\nvideo_id: The uniqueâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/bourbouh/moroccan-darija-youtube-subtitles.","first_N":5,"first_N_keywords":["other","language-modeling","no-annotation","machine-generated","monolingual"],"keywords_longer_than_N":true},
	{"name":"MatrixMB","keyword":"arabic","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/MatrixMB/MatrixMB","creator_name":"Muaaz Bdear","creator_url":"https://huggingface.co/MatrixMB","description":"MatrixMB/MatrixMB dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["Arabic","apache-2.0","n<1K","Text","ðŸ‡ºðŸ‡¸ Region: US"],"keywords_longer_than_N":true},
	{"name":"tydiqa-ar","keyword":"arabic","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/asas-ai/tydiqa-ar","creator_name":"ASAS AI","creator_url":"https://huggingface.co/asas-ai","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for \\\"tydiqa-ar\\\"\\n\\t\\n\\nMore Information needed\\n","first_N":5,"first_N_keywords":["question-answering","Arabic","apache-2.0","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"tydiqa-ar-primary_task","keyword":"arabic","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/asas-ai/tydiqa-ar-primary_task","creator_name":"ASAS AI","creator_url":"https://huggingface.co/asas-ai","description":"asas-ai/tydiqa-ar-primary_task dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["question-answering","Arabic","apache-2.0","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"tydiqa-ar-secondary_task","keyword":"arabic","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/asas-ai/tydiqa-ar-secondary_task","creator_name":"ASAS AI","creator_url":"https://huggingface.co/asas-ai","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for \\\"tydiqa-ar-secondary_task\\\"\\n\\t\\n\\nMore Information needed\\n","first_N":5,"first_N_keywords":["question-answering","Arabic","apache-2.0","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"Detect-Egyptian-Wikipedia-Articles","keyword":"arabic","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/SaiedAlshahrani/Detect-Egyptian-Wikipedia-Articles","creator_name":"Saied Alshahrani","creator_url":"https://huggingface.co/SaiedAlshahrani","description":" Detect Egyptian Wikipedia Template-translated Articles \\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description:\\n\\t\\n\\nWe release the heuristically filtered, manually processed, and automatically classified Egyptian Arabic Wikipedia articles dataset. This dataset was used to develop a web-based detection system to automatically identify the template-translated articles on the Egyptian Arabic Wikipedia edition. The system is called Egyptian Arabic Wikipedia Scanner and is hosted on Hugging Face Spaces, here:â€¦ See the full description on the dataset page: https://huggingface.co/datasets/SaiedAlshahrani/Detect-Egyptian-Wikipedia-Articles.","first_N":5,"first_N_keywords":["text-classification","Egyptian Wikipedia","Arabic","mit","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"swim-ir-cross-lingual","keyword":"arabic","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/nthakur/swim-ir-cross-lingual","creator_name":"Nandan Thakur","creator_url":"https://huggingface.co/nthakur","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for SWIM-IR (Cross-lingual)\\n\\t\\n\\n\\n\\n\\nThis is the cross-lingual subset of the SWIM-IR dataset, where the query generated is in the target language and the passage is in English.\\nThe SWIM-IR dataset is available as CC-BY-SA 4.0. 18 languages (including English) are available in the cross-lingual dataset.\\nFor full details of the dataset, please read our upcoming NAACL 2024 paper and check out our website.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tWhat is SWIM-IR?\\n\\t\\n\\nSWIM-IR dataset is a syntheticâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/nthakur/swim-ir-cross-lingual.","first_N":5,"first_N_keywords":["text-retrieval","question-answering","machine-generated","multilingual","original"],"keywords_longer_than_N":true},
	{"name":"conllpp-ner-ar","keyword":"arabic","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/iSemantics/conllpp-ner-ar","creator_name":"iSemantics","creator_url":"https://huggingface.co/iSemantics","description":"iSemantics/conllpp-ner-ar dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["token-classification","Arabic","mit","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"xsimplusplus","keyword":"egyptian arabic","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/jaygala24/xsimplusplus","creator_name":"Jay Gala","creator_url":"https://huggingface.co/jaygala24","description":"xSIM++ is an extension of xSIM. In comparison to xSIM, this evaluates using target-side data with additional synthetic, hard-to-distinguish examples. You can find more details about it in the publication: xSIM++: An Improved Proxy to Bitext Mining Performance for Low-Resource Languages.\\n","first_N":5,"first_N_keywords":["derived","multilingual","Achinese","Mesopotamian Arabic","Ta'izzi-Adeni Arabic"],"keywords_longer_than_N":true},
	{"name":"xsimplusplus","keyword":"levantine arabic","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/jaygala24/xsimplusplus","creator_name":"Jay Gala","creator_url":"https://huggingface.co/jaygala24","description":"xSIM++ is an extension of xSIM. In comparison to xSIM, this evaluates using target-side data with additional synthetic, hard-to-distinguish examples. You can find more details about it in the publication: xSIM++: An Improved Proxy to Bitext Mining Performance for Low-Resource Languages.\\n","first_N":5,"first_N_keywords":["derived","multilingual","Achinese","Mesopotamian Arabic","Ta'izzi-Adeni Arabic"],"keywords_longer_than_N":true},
	{"name":"xsimplusplus","keyword":"mesopotamian arabic","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/jaygala24/xsimplusplus","creator_name":"Jay Gala","creator_url":"https://huggingface.co/jaygala24","description":"xSIM++ is an extension of xSIM. In comparison to xSIM, this evaluates using target-side data with additional synthetic, hard-to-distinguish examples. You can find more details about it in the publication: xSIM++: An Improved Proxy to Bitext Mining Performance for Low-Resource Languages.\\n","first_N":5,"first_N_keywords":["derived","multilingual","Achinese","Mesopotamian Arabic","Ta'izzi-Adeni Arabic"],"keywords_longer_than_N":true},
	{"name":"xsimplusplus","keyword":"najdi arabic","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/jaygala24/xsimplusplus","creator_name":"Jay Gala","creator_url":"https://huggingface.co/jaygala24","description":"xSIM++ is an extension of xSIM. In comparison to xSIM, this evaluates using target-side data with additional synthetic, hard-to-distinguish examples. You can find more details about it in the publication: xSIM++: An Improved Proxy to Bitext Mining Performance for Low-Resource Languages.\\n","first_N":5,"first_N_keywords":["derived","multilingual","Achinese","Mesopotamian Arabic","Ta'izzi-Adeni Arabic"],"keywords_longer_than_N":true},
	{"name":"xsimplusplus","keyword":"moroccan arabic","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/jaygala24/xsimplusplus","creator_name":"Jay Gala","creator_url":"https://huggingface.co/jaygala24","description":"xSIM++ is an extension of xSIM. In comparison to xSIM, this evaluates using target-side data with additional synthetic, hard-to-distinguish examples. You can find more details about it in the publication: xSIM++: An Improved Proxy to Bitext Mining Performance for Low-Resource Languages.\\n","first_N":5,"first_N_keywords":["derived","multilingual","Achinese","Mesopotamian Arabic","Ta'izzi-Adeni Arabic"],"keywords_longer_than_N":true},
	{"name":"xsimplusplus","keyword":"standard arabic","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/jaygala24/xsimplusplus","creator_name":"Jay Gala","creator_url":"https://huggingface.co/jaygala24","description":"xSIM++ is an extension of xSIM. In comparison to xSIM, this evaluates using target-side data with additional synthetic, hard-to-distinguish examples. You can find more details about it in the publication: xSIM++: An Improved Proxy to Bitext Mining Performance for Low-Resource Languages.\\n","first_N":5,"first_N_keywords":["derived","multilingual","Achinese","Mesopotamian Arabic","Ta'izzi-Adeni Arabic"],"keywords_longer_than_N":true},
	{"name":"cohere_aya_arabic","keyword":"standard arabic","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/abuelnasr/cohere_aya_arabic","creator_name":"Mohamed AbuElNasr","creator_url":"https://huggingface.co/abuelnasr","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tArabic aya dataset\\n\\t\\n\\nThis dataset is the arabic partition of the CohereForAI/aya_dataset dataset. \\nFor more information about the dataset, visit the original dataset repo: CohereForAI/aya_dataset.\\nthe data was extracted using this simple code:\\n# Train split.\\naya_train = datasets.load_dataset(\\\"CohereForAI/aya_dataset\\\", split=\\\"train\\\")\\narb_train = aya_train.filter(lambda x: x[\\\"language_code\\\"] == \\\"arb\\\")\\narb_train = arb_train.remove_columns([\\\"language_code\\\", \\\"user_id\\\"])\\n\\n# Test split.â€¦ See the full description on the dataset page: https://huggingface.co/datasets/abuelnasr/cohere_aya_arabic.","first_N":5,"first_N_keywords":["other","monolingual","CohereForAI/aya_dataset","Standard Arabic","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"xsimplusplus","keyword":"tunisian arabic","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/jaygala24/xsimplusplus","creator_name":"Jay Gala","creator_url":"https://huggingface.co/jaygala24","description":"xSIM++ is an extension of xSIM. In comparison to xSIM, this evaluates using target-side data with additional synthetic, hard-to-distinguish examples. You can find more details about it in the publication: xSIM++: An Improved Proxy to Bitext Mining Performance for Low-Resource Languages.\\n","first_N":5,"first_N_keywords":["derived","multilingual","Achinese","Mesopotamian Arabic","Ta'izzi-Adeni Arabic"],"keywords_longer_than_N":true},
	{"name":"xsimplusplus","keyword":"ta'izzi-adeni arabic","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/jaygala24/xsimplusplus","creator_name":"Jay Gala","creator_url":"https://huggingface.co/jaygala24","description":"xSIM++ is an extension of xSIM. In comparison to xSIM, this evaluates using target-side data with additional synthetic, hard-to-distinguish examples. You can find more details about it in the publication: xSIM++: An Improved Proxy to Bitext Mining Performance for Low-Resource Languages.\\n","first_N":5,"first_N_keywords":["derived","multilingual","Achinese","Mesopotamian Arabic","Ta'izzi-Adeni Arabic"],"keywords_longer_than_N":true},
	{"name":"arabic_speech_corpus","keyword":"arabic","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/tunis-ai/arabic_speech_corpus","creator_name":"Tunisia.AI","creator_url":"https://huggingface.co/tunis-ai","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Arabic Speech Corpus\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThis Speech corpus has been developed as part of PhD work carried out by Nawar Halabi at the University of Southampton. The corpus was recorded in south Levantine Arabic (Damascian accent) using a professional studio. Synthesized speech as an output using this corpus has produced a high quality, natural voice.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSupported Tasks and Leaderboards\\n\\t\\n\\n[Needs More Information]\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages\\n\\t\\n\\nTheâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/tunis-ai/arabic_speech_corpus.","first_N":5,"first_N_keywords":["automatic-speech-recognition","expert-generated","crowdsourced","monolingual","original"],"keywords_longer_than_N":true},
	{"name":"Arabic-Dataset-for-Commonsense-Validationion","keyword":"arabic","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/asas-ai/Arabic-Dataset-for-Commonsense-Validationion","creator_name":"ASAS AI","creator_url":"https://huggingface.co/asas-ai","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for \\\"Arabic-Dataset-for-Commonsense-Validationion\\\"\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tPaper:\\n\\t\\n\\nTawalbeh, Saja, and Mohammad Al-Smadi. \\\"Is this sentence valid? an arabic dataset for commonsense validation.\\\" arXiv preprint arXiv:2008.10873 (2020).\\n","first_N":5,"first_N_keywords":["text-classification","Arabic","cc0-1.0","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"biblenlp-corpus-mmteb","keyword":"standard arabic","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/biblenlp-corpus-mmteb","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"This dataset pre-computes all English-centric directions from bible-nlp/biblenlp-corpus, and as a result loading is significantly faster.\\nLoading example:\\n>>> from datasets import load_dataset\\n>>> dataset = load_dataset(\\\"davidstap/biblenlp-corpus-mmteb\\\", \\\"eng-arb\\\", trust_remote_code=True)\\n>>> dataset\\nDatasetDict({\\n    train: Dataset({\\n        features: ['eng', 'arb'],\\n        num_rows: 28723\\n    })\\n    validation: Dataset({\\n        features: ['eng', 'arb'],\\n        num_rows: 1578\\n    })â€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/biblenlp-corpus-mmteb.","first_N":5,"first_N_keywords":["no-annotation","expert-generated","translation","multilingual","Arifama-Miniafia"],"keywords_longer_than_N":true},
	{"name":"rush","keyword":"arabic","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/rushdiodeh/rush","creator_name":"odeh","creator_url":"https://huggingface.co/rushdiodeh","description":"rushdiodeh/rush dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["token-classification","Arabic","apache-2.0","< 1K","csv"],"keywords_longer_than_N":true},
	{"name":"Arabic-Poem-Emotion","keyword":"arabic","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/asas-ai/Arabic-Poem-Emotion","creator_name":"ASAS AI","creator_url":"https://huggingface.co/asas-ai","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for \\\"Arabic-Poem-Emotion\\\"\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tPaper:\\n\\t\\n\\nShahriar S, Al Roken N, Zualkernan I. Classification of Arabic Poetry Emotions Using Deep Learning. Computers. 2023; 12(5):89. https://doi.org/10.3390/computers12050089 \\n","first_N":5,"first_N_keywords":["text-classification","Arabic","cc-by-4.0","1K - 10K","parquet"],"keywords_longer_than_N":true},
	{"name":"ArPanEmo","keyword":"arabic","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/asas-ai/ArPanEmo","creator_name":"ASAS AI","creator_url":"https://huggingface.co/asas-ai","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for \\\"ArPanEmo: An Open-Source Dataset for Fine-Grained Emotion Recognition in Arabic Online Content during COVID-19 Pandemic\\\"\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tPaper:\\n\\t\\n\\nAlthobaiti, Maha Jarallah (2023), â€œArPanEmo: An Open-Source Dataset for Fine-Grained Emotion Recognition in Arabic Online Content during COVID-19 Pandemic.â€, Mendeley Data, V1, doi: 10.17632/d9yy8w52ns.1\\n","first_N":5,"first_N_keywords":["text-classification","Arabic","cc-by-4.0","< 1K","parquet"],"keywords_longer_than_N":true},
	{"name":"ExaAEC","keyword":"arabic","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/asas-ai/ExaAEC","creator_name":"ASAS AI","creator_url":"https://huggingface.co/asas-ai","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for \\\"ExaAEC: A New Multi-label Emotion Classification Corpus in Arabic Tweets\\\"\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tPaper:\\n\\t\\n\\nS. Sarbazi-Azad, A. Akbari and M. Khazeni, \\\"ExaAEC: A New Multi-label Emotion Classification Corpus in Arabic Tweets,\\\" 2021 11th International Conference on Computer Engineering and Knowledge (ICCKE), Mashhad, Iran, Islamic Republic of, 2021, pp. 465-470, doi: 10.1109/ICCKE54056.2021.9721493. \\n","first_N":5,"first_N_keywords":["text-classification","Arabic","apache-2.0","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"Aya-AceGPT.13B.Chat-DPO","keyword":"arabic","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/2A2I/Aya-AceGPT.13B.Chat-DPO","creator_name":"2A2I","creator_url":"https://huggingface.co/2A2I","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for \\\"Aya-AceGPT.13B.Chat-DPO\\\" ðŸ¤—\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Sources & Infos\\n\\t\\n\\n\\nData Origin: Derived from the Arabic Aya (2A) dataset : 2A2I/Arabic_Aya which is a Curated Subset of the Aya Collection CohereForAI/aya_dataset\\nLanguages: Modern Standard Arabic (MSA)\\nLicense: Apache-2.0\\nMaintainers: Ali Elfilali and Mohammed Machrouh\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tPurpose\\n\\t\\n\\nAya-AceGPT.13B.Chat-DPO is a DPO dataset designed to advance Arabic NLP by comparing human-generated responses, labeledâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/2A2I/Aya-AceGPT.13B.Chat-DPO.","first_N":5,"first_N_keywords":["Arabic","apache-2.0","10K - 100K","parquet","Text"],"keywords_longer_than_N":true},
	{"name":"sib200","keyword":"arabic","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/sib200","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for SIB-200\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nSIB-200 is the largest publicly available topic classification dataset based on Flores-200 covering 205 languages and dialects.\\nThe train/validation/test sets are available for all the 205 languages.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSupported Tasks and Leaderboards\\n\\t\\n\\n\\ntopic classification: categorize wikipedia sentences into topics e.g science/technology, sports or politics.\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages\\n\\t\\n\\nThere are 205 languages available :â€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/sib200.","first_N":5,"first_N_keywords":["text-classification","topic-classification","found","expert-generated","multilingual"],"keywords_longer_than_N":true},
	{"name":"AraTrust","keyword":"arabic","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/asas-ai/AraTrust","creator_name":"ASAS AI","creator_url":"https://huggingface.co/asas-ai","description":"Paper\\nAlghamdi, E. A., Masoud, R. I., Alnuhait, D., Alomairi, A. Y., Ashraf, A., & Zaytoon, M. (2024). AraTrust: An Evaluation of Trustworthiness for LLMs in Arabic. arXiv preprint arXiv:2403.09017.\\nBibTeX:\\n@article{alghamdi2024aratrust,\\n  title={AraTrust: An Evaluation of Trustworthiness for LLMs in Arabic},\\n  author={Alghamdi, Emad A and Masoud, Reem I and Alnuhait, Deema and Alomairi, Afnan Y and Ashraf, Ahmed and Zaytoon, Mohamed},\\n  journal={arXiv preprint arXiv:2403.09017},\\n  year={2024}â€¦ See the full description on the dataset page: https://huggingface.co/datasets/asas-ai/AraTrust.","first_N":5,"first_N_keywords":["Arabic","mit","< 1K","parquet","Text"],"keywords_longer_than_N":true},
	{"name":"kmZQBkk558WWAGV","keyword":"arabic","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/israel/kmZQBkk558WWAGV","creator_name":"Israel Abebe Azime","creator_url":"https://huggingface.co/israel","description":"israel/kmZQBkk558WWAGV dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["multiple-choice","multiple-choice-qa","Amharic","English","Spanish"],"keywords_longer_than_N":true},
	{"name":"kmZQBkk558WWAGV","keyword":"arabic","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/israel/kmZQBkk558WWAGV","creator_name":"Israel Abebe Azime","creator_url":"https://huggingface.co/israel","description":"israel/kmZQBkk558WWAGV dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["multiple-choice","multiple-choice-qa","Amharic","English","Spanish"],"keywords_longer_than_N":true},
	{"name":"ANS_Corpus","keyword":"arabic","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/asas-ai/ANS_Corpus","creator_name":"ASAS AI","creator_url":"https://huggingface.co/asas-ai","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for \\\"ANS_Corpus: Arabic News Stance Corpus\\\"\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tPaper:\\n\\t\\n\\nJude Khouja. 2020. Stance Prediction and Claim Verification: An Arabic Perspective. In Proceedings of the Third Workshop on Fact Extraction and VERification (FEVER), pages 8â€“17, Online. Association for Computational Linguistics.\\n","first_N":5,"first_N_keywords":["text-classification","Arabic","apache-2.0","1K - 10K","parquet"],"keywords_longer_than_N":true},
	{"name":"Moroccan_Darija_Offensive_Language_Detection_Dataset","keyword":"arabic","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/asas-ai/Moroccan_Darija_Offensive_Language_Detection_Dataset","creator_name":"ASAS AI","creator_url":"https://huggingface.co/asas-ai","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for \\\"Moroccan_Darija_Offensive_Language_Detection_Dataset\\\"\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tPaper:\\n\\t\\n\\nIbrahimi, Anass; Mourhir, Asmaa (2023), â€œMoroccan Darija Offensive Language Detection Datasetâ€, Mendeley Data, V2, doi: 10.17632/2y4m97b7dc.2\\n","first_N":5,"first_N_keywords":["text-classification","Arabic","cc-by-4.0","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"DarNERcorp","keyword":"arabic","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/asas-ai/DarNERcorp","creator_name":"ASAS AI","creator_url":"https://huggingface.co/asas-ai","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for \\\"DarNERcorp: A Named Entity Recognition Corpus in the Moroccan Dialect\\\"\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tPaper:\\n\\t\\n\\nMousa, Hanane Nour; Mourhir, Asmaa (2023), â€œDarNERcorp: a Named Entity Recognition Corpus in the Moroccan Dialectâ€, Mendeley Data, V2, doi: 10.17632/286sss4k9v.2\\n","first_N":5,"first_N_keywords":["token-classification","Arabic","cc-by-4.0","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"sib200","keyword":"egyptian arabic","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/sib200","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for SIB-200\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nSIB-200 is the largest publicly available topic classification dataset based on Flores-200 covering 205 languages and dialects.\\nThe train/validation/test sets are available for all the 205 languages.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSupported Tasks and Leaderboards\\n\\t\\n\\n\\ntopic classification: categorize wikipedia sentences into topics e.g science/technology, sports or politics.\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages\\n\\t\\n\\nThere are 205 languages available :â€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/sib200.","first_N":5,"first_N_keywords":["text-classification","topic-classification","found","expert-generated","multilingual"],"keywords_longer_than_N":true},
	{"name":"sib200","keyword":"levantine arabic","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/sib200","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for SIB-200\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nSIB-200 is the largest publicly available topic classification dataset based on Flores-200 covering 205 languages and dialects.\\nThe train/validation/test sets are available for all the 205 languages.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSupported Tasks and Leaderboards\\n\\t\\n\\n\\ntopic classification: categorize wikipedia sentences into topics e.g science/technology, sports or politics.\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages\\n\\t\\n\\nThere are 205 languages available :â€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/sib200.","first_N":5,"first_N_keywords":["text-classification","topic-classification","found","expert-generated","multilingual"],"keywords_longer_than_N":true},
	{"name":"sib200","keyword":"mesopotamian arabic","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/sib200","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for SIB-200\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nSIB-200 is the largest publicly available topic classification dataset based on Flores-200 covering 205 languages and dialects.\\nThe train/validation/test sets are available for all the 205 languages.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSupported Tasks and Leaderboards\\n\\t\\n\\n\\ntopic classification: categorize wikipedia sentences into topics e.g science/technology, sports or politics.\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages\\n\\t\\n\\nThere are 205 languages available :â€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/sib200.","first_N":5,"first_N_keywords":["text-classification","topic-classification","found","expert-generated","multilingual"],"keywords_longer_than_N":true},
	{"name":"sib200","keyword":"najdi arabic","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/sib200","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for SIB-200\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nSIB-200 is the largest publicly available topic classification dataset based on Flores-200 covering 205 languages and dialects.\\nThe train/validation/test sets are available for all the 205 languages.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSupported Tasks and Leaderboards\\n\\t\\n\\n\\ntopic classification: categorize wikipedia sentences into topics e.g science/technology, sports or politics.\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages\\n\\t\\n\\nThere are 205 languages available :â€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/sib200.","first_N":5,"first_N_keywords":["text-classification","topic-classification","found","expert-generated","multilingual"],"keywords_longer_than_N":true},
	{"name":"sib200","keyword":"moroccan arabic","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/sib200","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for SIB-200\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nSIB-200 is the largest publicly available topic classification dataset based on Flores-200 covering 205 languages and dialects.\\nThe train/validation/test sets are available for all the 205 languages.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSupported Tasks and Leaderboards\\n\\t\\n\\n\\ntopic classification: categorize wikipedia sentences into topics e.g science/technology, sports or politics.\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages\\n\\t\\n\\nThere are 205 languages available :â€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/sib200.","first_N":5,"first_N_keywords":["text-classification","topic-classification","found","expert-generated","multilingual"],"keywords_longer_than_N":true},
	{"name":"sib200","keyword":"tunisian arabic","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/sib200","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for SIB-200\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nSIB-200 is the largest publicly available topic classification dataset based on Flores-200 covering 205 languages and dialects.\\nThe train/validation/test sets are available for all the 205 languages.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSupported Tasks and Leaderboards\\n\\t\\n\\n\\ntopic classification: categorize wikipedia sentences into topics e.g science/technology, sports or politics.\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages\\n\\t\\n\\nThere are 205 languages available :â€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/sib200.","first_N":5,"first_N_keywords":["text-classification","topic-classification","found","expert-generated","multilingual"],"keywords_longer_than_N":true},
	{"name":"sib200","keyword":"ta'izzi-adeni arabic","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/sib200","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for SIB-200\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nSIB-200 is the largest publicly available topic classification dataset based on Flores-200 covering 205 languages and dialects.\\nThe train/validation/test sets are available for all the 205 languages.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSupported Tasks and Leaderboards\\n\\t\\n\\n\\ntopic classification: categorize wikipedia sentences into topics e.g science/technology, sports or politics.\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages\\n\\t\\n\\nThere are 205 languages available :â€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/sib200.","first_N":5,"first_N_keywords":["text-classification","topic-classification","found","expert-generated","multilingual"],"keywords_longer_than_N":true},
	{"name":"Aya-Command.R-DPO","keyword":"arabic","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/2A2I/Aya-Command.R-DPO","creator_name":"2A2I","creator_url":"https://huggingface.co/2A2I","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tðŸ¤— Dataset Card for \\\"Aya-Command.R-DPO\\\"\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Sources & Infos\\n\\t\\n\\n\\nData Origin: Derived from the Arabic Aya (2A) dataset : 2A2I/Arabic_Aya which is a Curated Subset of the Aya Collection CohereForAI/aya_dataset\\nLanguages: Modern Standard Arabic (MSA)\\nLicense: Apache-2.0\\nMaintainers: Ali Elfilali and Mohammed Machrouh\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tPurpose\\n\\t\\n\\nAya-Command.R-DPO is a DPO dataset designed to advance Arabic NLP by comparing human-generated responses, labeled as \\\"chosen,\\\"â€¦ See the full description on the dataset page: https://huggingface.co/datasets/2A2I/Aya-Command.R-DPO.","first_N":5,"first_N_keywords":["Arabic","apache-2.0","10K - 100K","parquet","Text"],"keywords_longer_than_N":true},
	{"name":"Aya-SambaLingo.Arabic.Chat-DPO","keyword":"arabic","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/2A2I/Aya-SambaLingo.Arabic.Chat-DPO","creator_name":"2A2I","creator_url":"https://huggingface.co/2A2I","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for \\\"Aya-SambaLingo.Arabic.Chat-DPO\\\" ðŸ¤—\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Sources & Infos\\n\\t\\n\\n\\nData Origin: Derived from the Arabic Aya (2A) dataset : 2A2I/Arabic_Aya which is a Curated Subset of the Aya Collection CohereForAI/aya_dataset\\nLanguages: Modern Standard Arabic (MSA)\\nLicense: Apache-2.0\\nMaintainers: Ali Elfilali and Mohammed Machrouh\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tPurpose\\n\\t\\n\\nAya-SambaLingo.Arabic.Chat-DPO is a DPO dataset designed to advance Arabic NLP by comparing human-generatedâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/2A2I/Aya-SambaLingo.Arabic.Chat-DPO.","first_N":5,"first_N_keywords":["Arabic","apache-2.0","10K - 100K","parquet","Text"],"keywords_longer_than_N":true},
	{"name":"MMLU_SyntheticData","keyword":"arabic","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Ashmal/MMLU_SyntheticData","creator_name":"Ashmal Vayani","creator_url":"https://huggingface.co/Ashmal","description":"Dataset\\nMMLU_SyntheticData is generated using GPT-4. The aim of generating this dataset was to generate a similar dataset to MMLU. \\nNote: Please note that this is not the translated version of MMLU, it's an entirely independent dataset.\\nSubjects\\nIt has the data of the following subjects:\\n\\nHumanities ['Islamic Studies', 'Law', 'History', 'Philosophy']\\nLanguage ['Arabic Language', 'Arabic Language (General)', 'Arabic Language (Grammar)']\\nOther ['General Knowledge', 'Management', 'Driving Test']â€¦ See the full description on the dataset page: https://huggingface.co/datasets/Ashmal/MMLU_SyntheticData.","first_N":5,"first_N_keywords":["text-classification","Arabic","apache-2.0","1K<n<10K","ðŸ‡ºðŸ‡¸ Region: US"],"keywords_longer_than_N":true},
	{"name":"MMLU_SyntheticData","keyword":"arabic","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Ashmal/MMLU_SyntheticData","creator_name":"Ashmal Vayani","creator_url":"https://huggingface.co/Ashmal","description":"Dataset\\nMMLU_SyntheticData is generated using GPT-4. The aim of generating this dataset was to generate a similar dataset to MMLU. \\nNote: Please note that this is not the translated version of MMLU, it's an entirely independent dataset.\\nSubjects\\nIt has the data of the following subjects:\\n\\nHumanities ['Islamic Studies', 'Law', 'History', 'Philosophy']\\nLanguage ['Arabic Language', 'Arabic Language (General)', 'Arabic Language (Grammar)']\\nOther ['General Knowledge', 'Management', 'Driving Test']â€¦ See the full description on the dataset page: https://huggingface.co/datasets/Ashmal/MMLU_SyntheticData.","first_N":5,"first_N_keywords":["text-classification","Arabic","apache-2.0","1K<n<10K","ðŸ‡ºðŸ‡¸ Region: US"],"keywords_longer_than_N":true},
	{"name":"SE-Chatting.en","keyword":"arabic","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/berwart/SE-Chatting.en","creator_name":"Berwart","creator_url":"https://huggingface.co/berwart","description":"\\n\\t\\n\\t\\t\\n\\t\\tSE.02\\n\\t\\n\\nDataset\\nHello, welcome to the official main dataset of SE.02 that's always getting updated, make sure to like to help us a lot.\\nthis dataset contains pretty much everything from math to isk what to put but pretty much anything you think an ai can say.\\nanyways this is our biggest dataset yet, and out first one that I don't even know how I managed to make this.\\nyou can use it to train your own ai if you want.\\n","first_N":5,"first_N_keywords":["question-answering","translation","English","French","Japanese"],"keywords_longer_than_N":true},
	{"name":"1milion_token_EGY_songs","keyword":"arabic","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/HeshamHaroon/1milion_token_EGY_songs","creator_name":"Hesham Haroon","creator_url":"https://huggingface.co/HeshamHaroon","description":"HeshamHaroon/1milion_token_EGY_songs dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["text-generation","Arabic","apache-2.0","1K - 10K","parquet"],"keywords_longer_than_N":true},
	{"name":"Arabic_Reviews_of_SHEIN","keyword":"arabic","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Ruqiya/Arabic_Reviews_of_SHEIN","creator_name":"Ruqiya Bin Safi","creator_url":"https://huggingface.co/Ruqiya","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tArabic Reviews of SHEIN Online Store\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDescription:\\n\\t\\n\\nThis dataset contains Arabic-language reviews of products from the SHEIN online store. The reviews cover various aspects of the products and overall customer satisfaction. \\nThe goal of collecting the dataset is to include a wide range of common phrases and terms used in daily conversation, reflecting the diversity of the dialects of the Arabic language, especially in Saudi Arabia.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages\\n\\t\\n\\nArabicâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Ruqiya/Arabic_Reviews_of_SHEIN.","first_N":5,"first_N_keywords":["text-classification","text2text-generation","text-generation","sentence-similarity","zero-shot-classification"],"keywords_longer_than_N":true},
	{"name":"NTREX","keyword":"arabic","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/NTREX","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nNTREX -- News Test References for MT Evaluation from English into a total of 128 target languages. See original GitHub repo for full details.\\nExample of loading:\\ndataset = load_dataset(\\\"davidstap/NTREX\\\", \\\"rus_Cyrl\\\", trust_remote_code=True)\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages\\n\\t\\n\\nThe following languages are available:\\n\\n\\t\\n\\t\\t\\nLanguage Code\\nLanguage Name\\n\\n\\n\\t\\t\\nafr_Latn\\nAfrikaans\\n\\n\\namh_Ethi\\nAmharic\\n\\n\\narb_Arab\\nArabic\\n\\n\\naze_Latn\\nAzerbaijani\\n\\n\\nbak_Cyrl\\nBashkir\\n\\n\\nbel_Cyrl\\nBelarusianâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/NTREX.","first_N":5,"first_N_keywords":["translation","expert-generated","expert-generated","translation","Afrikaans"],"keywords_longer_than_N":true},
	{"name":"multilingual-llava-bench-in-the-wild","keyword":"arabic","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/floschne/multilingual-llava-bench-in-the-wild","creator_name":"Flo Schneider","creator_url":"https://huggingface.co/floschne","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tMultilingual LLaVA Bench in the Wild\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tNote that this is a copy from https://huggingface.co/datasets/MBZUAI/multilingual-llava-bench-in-the-wild\\n\\t\\n\\nIt was created due to issues in the original repo. It also includes the image features and has a uniform and joined structure.\\nIf you use this dataset, please cite the original authors:\\n@article{PALO2024,\\n  title={Palo: A Large Multilingual Multimodal Language Model},\\n  author={Maaz, Muhammad and Rasheed, Hanoona and Shakerâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/floschne/multilingual-llava-bench-in-the-wild.","first_N":5,"first_N_keywords":["Arabic","Bengali","Chinese","English","French"],"keywords_longer_than_N":true},
	{"name":"AraEventCoref","keyword":"arabic","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/AldawsariNLP/AraEventCoref","creator_name":"Aldawsari","creator_url":"https://huggingface.co/AldawsariNLP","description":"\\n\\t\\n\\t\\t\\n\\t\\tAraEventCoref\\n\\t\\n\\nAraEventCoref is an Arabic event coreference dataset comprising 50 annotated news articles with 12,069 tokens, 1,381 events, and 159 coreference chains. Target events are surrounded by position-aware markers <<Ø­Ø¯Ø«>> before and after each event. The label 1 indicates a coreference, while 0 indicates no coreference. The dataset features high annotation reliability with a CoNLL score of 75.8% and an inter-annotator agreement of 96% for event triggers.\\n\\nCurated by: Dr.â€¦ See the full description on the dataset page: https://huggingface.co/datasets/AldawsariNLP/AraEventCoref.","first_N":5,"first_N_keywords":["text-classification","token-classification","Arabic","apache-2.0","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"ParaNames","keyword":"arabic","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/bltlab/ParaNames","creator_name":"Broadening Linguistic Technologies Lab (BLT Lab)","creator_url":"https://huggingface.co/bltlab","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Dataset Name\\n\\t\\n\\n\\n\\nThis dataset card aims to be a base template for new datasets. It has been generated using this raw template.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Details\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\n\\n\\n\\n\\n\\nCurated by: [More Information Needed]\\nFunded by [optional]: [More Information Needed]\\nShared by [optional]: [More Information Needed]\\nLanguage(s) (NLP): [More Information Needed]\\nLicense: [More Information Needed]\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Sources [optional]â€¦ See the full description on the dataset page: https://huggingface.co/datasets/bltlab/ParaNames.","first_N":5,"first_N_keywords":["token-classification","Nias","Kotava","Banjar","Angika"],"keywords_longer_than_N":true},
	{"name":"xm3600","keyword":"arabic","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/floschne/xm3600","creator_name":"Flo Schneider","creator_url":"https://huggingface.co/floschne","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tXM3600 - Crossmodal-3600\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tThis is a copy from https://google.github.io/crossmodal-3600/\\n\\t\\n\\nIf you use this dataset, please cite the original authors:\\n@inproceedings{ThapliyalCrossmodal2022,\\n  author = {Ashish Thapliyal and Jordi Pont-Tuset and Xi Chen and Radu Soricut},\\n  title = {{Crossmodal-3600: A Massively Multilingual Multimodal Evaluation Dataset}},\\n  booktitle = {EMNLP},\\n  year = {2022}\\n}\\n\\nIt also includes the image features as PIL Image and has a uniform andâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/floschne/xm3600.","first_N":5,"first_N_keywords":["image-to-text","Arabic","Bengali","Czech","Danish"],"keywords_longer_than_N":true},
	{"name":"xm3600_1k","keyword":"arabic","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/floschne/xm3600_1k","creator_name":"Flo Schneider","creator_url":"https://huggingface.co/floschne","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tXM3600 - Crossmodal-3600 - 1K Split\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tThis is a copy from https://google.github.io/crossmodal-3600/\\n\\t\\n\\nIf you use this dataset, please cite the original authors:\\n@inproceedings{ThapliyalCrossmodal2022,\\n  author = {Ashish Thapliyal and Jordi Pont-Tuset and Xi Chen and Radu Soricut},\\n  title = {{Crossmodal-3600: A Massively Multilingual Multimodal Evaluation Dataset}},\\n  booktitle = {EMNLP},\\n  year = {2022}\\n}\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tThis is a 1K split of XM3600!\\n\\t\\n\\nFor this, weâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/floschne/xm3600_1k.","first_N":5,"first_N_keywords":["image-to-text","Arabic","Bengali","Czech","Danish"],"keywords_longer_than_N":true},
	{"name":"ParaNames","keyword":"egyptian arabic","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/bltlab/ParaNames","creator_name":"Broadening Linguistic Technologies Lab (BLT Lab)","creator_url":"https://huggingface.co/bltlab","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Dataset Name\\n\\t\\n\\n\\n\\nThis dataset card aims to be a base template for new datasets. It has been generated using this raw template.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Details\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\n\\n\\n\\n\\n\\nCurated by: [More Information Needed]\\nFunded by [optional]: [More Information Needed]\\nShared by [optional]: [More Information Needed]\\nLanguage(s) (NLP): [More Information Needed]\\nLicense: [More Information Needed]\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Sources [optional]â€¦ See the full description on the dataset page: https://huggingface.co/datasets/bltlab/ParaNames.","first_N":5,"first_N_keywords":["token-classification","Nias","Kotava","Banjar","Angika"],"keywords_longer_than_N":true},
	{"name":"ParaNames","keyword":"moroccan arabic","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/bltlab/ParaNames","creator_name":"Broadening Linguistic Technologies Lab (BLT Lab)","creator_url":"https://huggingface.co/bltlab","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Dataset Name\\n\\t\\n\\n\\n\\nThis dataset card aims to be a base template for new datasets. It has been generated using this raw template.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Details\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\n\\n\\n\\n\\n\\nCurated by: [More Information Needed]\\nFunded by [optional]: [More Information Needed]\\nShared by [optional]: [More Information Needed]\\nLanguage(s) (NLP): [More Information Needed]\\nLicense: [More Information Needed]\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Sources [optional]â€¦ See the full description on the dataset page: https://huggingface.co/datasets/bltlab/ParaNames.","first_N":5,"first_N_keywords":["token-classification","Nias","Kotava","Banjar","Angika"],"keywords_longer_than_N":true},
	{"name":"x-fact","keyword":"arabic","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/utahnlp/x-fact","creator_name":"NLP at University of Utah","creator_url":"https://huggingface.co/utahnlp","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for \\\"x-fact\\\"\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nX-FACT is a multilingual dataset for fact-checking with real world claims. The dataset contains short statments in 25 languages with top five evidence documents retrieved by performing google search with claim statements. The dataset contains two additional evaluation splits (in addition to a traditional test set): ood and zeroshot. ood measures out-of-domain generalization where whileâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/utahnlp/x-fact.","first_N":5,"first_N_keywords":["text-classification","Arabic","Bengali","Spanish","Persian"],"keywords_longer_than_N":true},
	{"name":"from-one-to-many-toxicity-mitigation","keyword":"arabic","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/luizapzbn/from-one-to-many-toxicity-mitigation","creator_name":"Luiza Pozzobon","creator_url":"https://huggingface.co/luizapzbn","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tFrom One to Many: Expanding the Scope of Toxicity Mitigation in Language Models\\n\\t\\n\\n[arxiv][code][data]\\nData accompanying the paper \\\"From One to Many: Expanding the Scope of Toxicity Mitigation in Language Models\\\" accepted to ACL Findings 2024.\\nAbstract: To date, toxicity mitigation in language models has almost entirely been focused on single-language settings. As language models embrace multilingual capabilities, itâ€™s crucial our safety measures keep pace. Recognizing thisâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/luizapzbn/from-one-to-many-toxicity-mitigation.","first_N":5,"first_N_keywords":["text-generation","text-classification","English","Portuguese","Hindi"],"keywords_longer_than_N":true},
	{"name":"arabic_tweets_dialects","keyword":"arabic","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/amgadhasan/arabic_tweets_dialects","creator_name":"Amgad Hasan","creator_url":"https://huggingface.co/amgadhasan","description":"amgadhasan/arabic_tweets_dialects dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["text-classification","Arabic","mit","100K - 1M","parquet"],"keywords_longer_than_N":true},
	{"name":"NoRobots-AceGPT.13B.Chat-DPO","keyword":"arabic","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/2A2I/NoRobots-AceGPT.13B.Chat-DPO","creator_name":"2A2I","creator_url":"https://huggingface.co/2A2I","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tðŸ¤— Dataset Card for \\\"NoRobots-AceGPT.13B.Chat-DPO\\\"\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Sources & Infos\\n\\t\\n\\n\\nData Origin: Derived from the Arabic No Robots dataset : 2A2I/H4_no_robots which is based on the original No Robots dataset inspired from the InstructGPT paper.\\nLanguages: Modern Standard Arabic (MSA)\\nLicense: CC BY-NC 4.0\\nMaintainers: Ali Elfilali and Marwa El Kamil\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tPurpose\\n\\t\\n\\nNoRobots-AceGPT.13B.Chat-DPO is a DPO dataset designed to advance Arabic NLP by comparingâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/2A2I/NoRobots-AceGPT.13B.Chat-DPO.","first_N":5,"first_N_keywords":["Arabic","apache-2.0","1K - 10K","parquet","Text"],"keywords_longer_than_N":true},
	{"name":"CohereForAI_aya_dataset_Arabic","keyword":"egyptian arabic","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/MoMonir/CohereForAI_aya_dataset_Arabic","creator_name":"Mohamed Monir","creator_url":"https://huggingface.co/MoMonir","description":"This Dataset Filterd From https://huggingface.co/datasets/CohereForAI/aya_dataset\\n","first_N":5,"first_N_keywords":["Standard Arabic","Moroccan Arabic","Najdi Arabic","Ta'izzi-Adeni Arabic","Egyptian Arabic"],"keywords_longer_than_N":true},
	{"name":"CohereForAI_aya_dataset_Arabic","keyword":"moroccan arabic","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/MoMonir/CohereForAI_aya_dataset_Arabic","creator_name":"Mohamed Monir","creator_url":"https://huggingface.co/MoMonir","description":"This Dataset Filterd From https://huggingface.co/datasets/CohereForAI/aya_dataset\\n","first_N":5,"first_N_keywords":["Standard Arabic","Moroccan Arabic","Najdi Arabic","Ta'izzi-Adeni Arabic","Egyptian Arabic"],"keywords_longer_than_N":true},
	{"name":"CohereForAI_aya_dataset_Arabic","keyword":"najdi arabic","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/MoMonir/CohereForAI_aya_dataset_Arabic","creator_name":"Mohamed Monir","creator_url":"https://huggingface.co/MoMonir","description":"This Dataset Filterd From https://huggingface.co/datasets/CohereForAI/aya_dataset\\n","first_N":5,"first_N_keywords":["Standard Arabic","Moroccan Arabic","Najdi Arabic","Ta'izzi-Adeni Arabic","Egyptian Arabic"],"keywords_longer_than_N":true},
	{"name":"CohereForAI_aya_dataset_Arabic","keyword":"standard arabic","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/MoMonir/CohereForAI_aya_dataset_Arabic","creator_name":"Mohamed Monir","creator_url":"https://huggingface.co/MoMonir","description":"This Dataset Filterd From https://huggingface.co/datasets/CohereForAI/aya_dataset\\n","first_N":5,"first_N_keywords":["Standard Arabic","Moroccan Arabic","Najdi Arabic","Ta'izzi-Adeni Arabic","Egyptian Arabic"],"keywords_longer_than_N":true},
	{"name":"CohereForAI_aya_dataset_Arabic","keyword":"ta'izzi-adeni arabic","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/MoMonir/CohereForAI_aya_dataset_Arabic","creator_name":"Mohamed Monir","creator_url":"https://huggingface.co/MoMonir","description":"This Dataset Filterd From https://huggingface.co/datasets/CohereForAI/aya_dataset\\n","first_N":5,"first_N_keywords":["Standard Arabic","Moroccan Arabic","Najdi Arabic","Ta'izzi-Adeni Arabic","Egyptian Arabic"],"keywords_longer_than_N":true},
	{"name":"NoRobots-Aya.23.8B-DPO","keyword":"arabic","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/2A2I/NoRobots-Aya.23.8B-DPO","creator_name":"2A2I","creator_url":"https://huggingface.co/2A2I","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tðŸ¤— Dataset Card for \\\"NoRobots-Aya.23.8B-DPO\\\"\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Sources & Infos\\n\\t\\n\\n\\nData Origin: Derived from the Arabic No Robots dataset : 2A2I/H4_no_robots which is based on the original No Robots dataset inspired from the InstructGPT paper.\\nLanguages: Modern Standard Arabic (MSA)\\nLicense: CC BY-NC 4.0\\nMaintainers: Ali Elfilali and Marwa El Kamil\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tPurpose\\n\\t\\n\\nNoRobots-Aya.23.8B-DPO is a DPO dataset designed to advance Arabic NLP by comparing human-generatedâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/2A2I/NoRobots-Aya.23.8B-DPO.","first_N":5,"first_N_keywords":["Arabic","apache-2.0","1K - 10K","parquet","Text"],"keywords_longer_than_N":true},
	{"name":"NoRobots-SambaLingo.Arabic.Chat-DPO","keyword":"arabic","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/2A2I/NoRobots-SambaLingo.Arabic.Chat-DPO","creator_name":"2A2I","creator_url":"https://huggingface.co/2A2I","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tðŸ¤— Dataset Card for \\\"NoRobots-SambaLingo.Arabic.Chat-DPO\\\"\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Sources & Infos\\n\\t\\n\\n\\nData Origin: Derived from the Arabic No Robots dataset : 2A2I/H4_no_robots which is based on the original No Robots dataset inspired from the InstructGPT paper.\\nLanguages: Modern Standard Arabic (MSA)\\nLicense: CC BY-NC 4.0\\nMaintainers: Ali Elfilali and Marwa El Kamil\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tPurpose\\n\\t\\n\\nNoRobots-SambaLingo.Arabic.Chat-DPO is a DPO dataset designed to advance Arabic NLP byâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/2A2I/NoRobots-SambaLingo.Arabic.Chat-DPO.","first_N":5,"first_N_keywords":["Arabic","apache-2.0","1K - 10K","parquet","Text"],"keywords_longer_than_N":true},
	{"name":"rendered_xnli","keyword":"arabic","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/baidu/rendered_xnli","creator_name":"ERNIE","creator_url":"https://huggingface.co/baidu","description":"   \\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for rendered XNLI\\n\\t\\n\\n\\nThis repository contains the rendered XNLI dataset evaluated in the paper Autoregressive Pre-Training on Pixels and Texts (EMNLP 2024). For detailed instructions on how to use the model, please visit our GitHub page.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tCitation\\n\\t\\n\\n@misc{chai2024autoregressivepretrainingpixelstexts,\\n  title = {Autoregressive Pre-Training on Pixels and Texts},\\n  author = {Chai, Yekun and Liu, Qingyi and Xiao, Jingwu and Wang, Shuohuan and Sun, Yu andâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/baidu/rendered_xnli.","first_N":5,"first_N_keywords":["English","Japanese","Chinese","French","Russian"],"keywords_longer_than_N":true},
	{"name":"NoRobots-Command.R-DPO","keyword":"arabic","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/2A2I/NoRobots-Command.R-DPO","creator_name":"2A2I","creator_url":"https://huggingface.co/2A2I","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tðŸ¤— Dataset Card for \\\"NoRobots-Command.R-DPO\\\"\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Sources & Infos\\n\\t\\n\\n\\nData Origin: Derived from the Arabic No Robots dataset : 2A2I/H4_no_robots which is based on the original No Robots dataset inspired from the InstructGPT paper.\\nLanguages: Modern Standard Arabic (MSA)\\nLicense: CC BY-NC 4.0\\nMaintainers: Ali Elfilali and Marwa El Kamil\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tPurpose\\n\\t\\n\\nNoRobots-Command.R-DPO is a DPO dataset designed to advance Arabic NLP by comparing human-generatedâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/2A2I/NoRobots-Command.R-DPO.","first_N":5,"first_N_keywords":["Arabic","apache-2.0","1K - 10K","parquet","Text"],"keywords_longer_than_N":true},
	{"name":"Aya-Aya.23.8B-DPO","keyword":"arabic","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/2A2I/Aya-Aya.23.8B-DPO","creator_name":"2A2I","creator_url":"https://huggingface.co/2A2I","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tðŸ¤— Dataset Card for \\\"Aya-Aya.23.8B-DPO\\\"\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Sources & Infos\\n\\t\\n\\n\\nData Origin: Derived from the Arabic Aya (2A) dataset : 2A2I/Arabic_Aya which is a Curated Subset of the Aya Collection CohereForAI/aya_dataset\\nLanguages: Modern Standard Arabic (MSA)\\nLicense: Apache-2.0\\nMaintainers: Ali Elfilali and Mohammed Machrouh\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tPurpose\\n\\t\\n\\nAya-Aya.23.8B-DPO is a DPO dataset designed to advance Arabic NLP by comparing human-generated responses, labeled as \\\"chosen,\\\"â€¦ See the full description on the dataset page: https://huggingface.co/datasets/2A2I/Aya-Aya.23.8B-DPO.","first_N":5,"first_N_keywords":["Arabic","apache-2.0","10K - 100K","parquet","Text"],"keywords_longer_than_N":true},
	{"name":"MultiPICo","keyword":"arabic","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Multilingual-Perspectivist-NLU/MultiPICo","creator_name":"MultilingualPerspectivistNLU","creator_url":"https://huggingface.co/Multilingual-Perspectivist-NLU","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nMultiPICo (Multilingual Perspectivist Irony Corpus) is a disaggregated multilingual corpus for irony detection, containing 18,778 pairs of short conversations (post-reply) from Twitter (8,956) and Reddit (9,822), along with the demographic information of each annotator (age, nationality, gender, and so on). \\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSupported Tasks and Leaderboards\\n\\t\\n\\nIrony classification task using soft labels (i.e., distribution of annotations) or hard labels (i.e.â€¦ See the full description on the dataset page: https://huggingface.co/datasets/Multilingual-Perspectivist-NLU/MultiPICo.","first_N":5,"first_N_keywords":["Spanish","English","German","Arabic","Portuguese"],"keywords_longer_than_N":true},
	{"name":"ArabiBoost","keyword":"arabic","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Ashmal/ArabiBoost","creator_name":"Ashmal Vayani","creator_url":"https://huggingface.co/Ashmal","description":"Dataset\\nThe ArabiBoost is the Instruction-tuning or fine-tuning dataset (5.7k samples) for MMLU_SyntheticData is generated using GPT-3.5 Turbo.\\nNote: Please note that this is not the translated version of MMLU, it's an entirely independent dataset.\\nSubjects\\nIt has the data of the following subjects:\\n\\nHumanities ['Islamic Studies', 'Law', 'History', 'Philosophy']\\nLanguage ['Arabic Language', 'Arabic Language (General)', 'Arabic Language (Grammar)']\\nOther ['General Knowledge', 'Management'â€¦ See the full description on the dataset page: https://huggingface.co/datasets/Ashmal/ArabiBoost.","first_N":5,"first_N_keywords":["text-classification","Arabic","apache-2.0","1K - 10K","json"],"keywords_longer_than_N":true},
	{"name":"ArabiBoost","keyword":"arabic","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Ashmal/ArabiBoost","creator_name":"Ashmal Vayani","creator_url":"https://huggingface.co/Ashmal","description":"Dataset\\nThe ArabiBoost is the Instruction-tuning or fine-tuning dataset (5.7k samples) for MMLU_SyntheticData is generated using GPT-3.5 Turbo.\\nNote: Please note that this is not the translated version of MMLU, it's an entirely independent dataset.\\nSubjects\\nIt has the data of the following subjects:\\n\\nHumanities ['Islamic Studies', 'Law', 'History', 'Philosophy']\\nLanguage ['Arabic Language', 'Arabic Language (General)', 'Arabic Language (Grammar)']\\nOther ['General Knowledge', 'Management'â€¦ See the full description on the dataset page: https://huggingface.co/datasets/Ashmal/ArabiBoost.","first_N":5,"first_N_keywords":["text-classification","Arabic","apache-2.0","1K - 10K","json"],"keywords_longer_than_N":true},
	{"name":"EgyLaw-Squad","keyword":"arabic","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/BoodyAhmedHamdy/EgyLaw-Squad","creator_name":"Abdelrahman Ahmed Hamdy","creator_url":"https://huggingface.co/BoodyAhmedHamdy","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tEgyption Law Squad\\n\\t\\n\\nthis dataset was made for Question Answering task about Egyption Law specially Personal Status Law (Ù‚Ø§Ù†ÙˆÙ† Ø§Ù„Ø§Ø­ÙˆØ§Ù„ Ø§Ù„Ø´Ø®ØµÙŠØ© )\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tAbout the Dataset\\n\\t\\n\\ndataset was created for a Graduation Project in Computers and Artificial intellgence at Helwan University under supervisation from Dr.Ensaf Hossen\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tAbout Team\\n\\t\\n\\n\\nAbdelrahman Ahmed Hamdy\\nShehab Gamal-elden\\nMohsen Hisham Mohamed\\nMaya Ahmed Abdelsatar\\nNancy Ahmed Mostafa\\nNour Khaled Ali\\n\\n","first_N":5,"first_N_keywords":["question-answering","Arabic","mit","< 1K","parquet"],"keywords_longer_than_N":true},
	{"name":"CORU","keyword":"arabic","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/abdoelsayed/CORU","creator_name":"unkown","creator_url":"https://huggingface.co/abdoelsayed","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tCORU: Comprehensive Post-OCR Parsing and Receipt Understanding Dataset\\n\\t\\n\\nIn the fields of Optical Character Recognition (OCR) and Natural Language Processing (NLP), integrating multilingual capabilities remains a critical challenge, especially when considering languages with complex scripts such as Arabic. This paper introduces the Comprehensive Post-OCR Parsing and Receipt Understanding Dataset (CORU), a novel dataset specifically designed to enhance OCR and informationâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/abdoelsayed/CORU.","first_N":5,"first_N_keywords":["object-detection","text-classification","zero-shot-classification","English","Arabic"],"keywords_longer_than_N":true},
	{"name":"Chatgpt","keyword":"arabic","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/RajChat/Chatgpt","creator_name":"Rajdeep Chatterjee ","creator_url":"https://huggingface.co/RajChat","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tOpenAssistant Conversations Dataset (OASST1)\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nIn an effort to democratize research on large-scale alignment, we release OpenAssistant \\nConversations (OASST1), a human-generated, human-annotated assistant-style conversation \\ncorpus consisting of 161,443 messages in 35 different languages, annotated with 461,292 \\nquality ratings, resulting in over 10,000 fully annotated conversation trees. The corpus \\nis a product of a worldwide crowd-sourcing effortâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/RajChat/Chatgpt.","first_N":5,"first_N_keywords":["English","Spanish","Russian","German","Polish"],"keywords_longer_than_N":true},
	{"name":"Arabic-Quora-Duplicates","keyword":"arabic","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Omartificial-Intelligence-Space/Arabic-Quora-Duplicates","creator_name":"Omartificial Intelligence Space","creator_url":"https://huggingface.co/Omartificial-Intelligence-Space","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tArabic-Quora-Duplicates\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\n\\nThe Arabic Version of the Quora Question Pairs Dataset\\nIt contains the Quora Question Pairs dataset in four formats that are easily used with Sentence Transformers to train embedding models.\\nThe data was originally created by Quora for this Kaggle Competition.\\nDataset may be used for training/finetuning an embedding model for semantic textual similarity.\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tPair Subset\\n\\t\\n\\n\\nColumns: \\\"anchor\\\", \\\"positive\\\"\\nColumnâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Omartificial-Intelligence-Space/Arabic-Quora-Duplicates.","first_N":5,"first_N_keywords":["sentence-similarity","Arabic","apache-2.0","100K - 1M","csv"],"keywords_longer_than_N":true},
	{"name":"The_Arabic_E-Book_Corpus","keyword":"arabic","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mohres/The_Arabic_E-Book_Corpus","creator_name":"Mohammad Fares","creator_url":"https://huggingface.co/mohres","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tThe Arabic E-Book Corpus\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tAlternative Title\\n\\t\\n\\nÙ…Ø¯ÙˆÙ†Ø© Ù„ØºÙˆÙŠØ© Ù„Ù„ÙƒØªØ¨ Ø§Ù„Ø¹Ø±Ø¨ÙŠØ© Ø§Ù„Ø¥Ù„ÙƒØªØ±ÙˆÙ†ÙŠØ©\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDescription\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tØ¹Ø±Ø¨ÙŠ\\n\\t\\n\\nÙ…Ø¯ÙˆÙ†Ø© Ø§Ù„ÙƒØªØ¨ Ø§Ù„Ø¹Ø±Ø¨ÙŠØ© Ø§Ù„Ø¥Ù„ÙƒØªØ±ÙˆÙ†ÙŠØ© Ù‡ÙŠ Ù…Ø¬Ù…ÙˆØ¹Ø© Ø¨ÙŠØ§Ù†Ø§Øª Ù…ØªØ§Ø­Ø© Ù…Ø¬Ø§Ù†Ù‹Ø§ ØªØ¶Ù… 1,745 ÙƒØªØ§Ø¨Ù‹Ø§ (81.5 Ù…Ù„ÙŠÙˆÙ† ÙƒÙ„Ù…Ø©) Ù†ÙØ´Ø±Øª Ø¨ÙˆØ§Ø³Ø·Ø© Ù…Ø¤Ø³Ø³Ø© Ù‡Ù†Ø¯Ø§ÙˆÙŠ Ø¨ÙŠÙ† Ø¹Ø§Ù…ÙŠ 2008 Ùˆ2024. ØªØ´Ù…Ù„ Ø§Ù„ÙƒØªØ¨ Ø£Ù†ÙˆØ§Ø¹Ù‹Ø§ Ù…Ø®ØªÙ„ÙØ©ØŒ Ø¨Ù…Ø§ ÙÙŠ Ø°Ù„Ùƒ Ø§Ù„ÙƒØªØ¨ ØºÙŠØ± Ø§Ù„Ø±ÙˆØ§Ø¦ÙŠØ©ØŒ Ø§Ù„Ø±ÙˆØ§ÙŠØ§ØªØŒ Ø£Ø¯Ø¨ Ø§Ù„Ø£Ø·ÙØ§Ù„ØŒ Ø§Ù„Ø´Ø¹Ø±ØŒ ÙˆØ§Ù„Ù…Ø³Ø±Ø­ÙŠØ§Øª.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tEnglish\\n\\t\\n\\nThe Arabic E-Book Corpus is a freely available collection of 1,745 booksâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/mohres/The_Arabic_E-Book_Corpus.","first_N":5,"first_N_keywords":["Arabic","cc-by-4.0","1K - 10K","arrow","Tabular"],"keywords_longer_than_N":true},
	{"name":"Arabic-NLi-Pair-Class","keyword":"arabic","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Omartificial-Intelligence-Space/Arabic-NLi-Pair-Class","creator_name":"Omartificial Intelligence Space","creator_url":"https://huggingface.co/Omartificial-Intelligence-Space","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tArabic NLI Pair-Class\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\n\\nThe Arabic Version of SNLI and MultiNLI datasets. (Pair-Class Subset)\\nOriginally used for Natural Language Inference (NLI),\\nDataset may be used for training/finetuning an embedding model for semantic textual similarity.\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tPair-Class Subset\\n\\t\\n\\n\\nColumns: \\\"premise\\\", \\\"hypothesis\\\", \\\"label\\\"\\nColumn types: str, str, class with {\\\"0\\\": \\\"entailment\\\", \\\"1\\\": \\\"neutral\\\", \\\"2\\\": \\\"contradiction\\\"}\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tArabic Examples:\\n\\t\\n\\n{â€¦ See the full description on the dataset page: https://huggingface.co/datasets/Omartificial-Intelligence-Space/Arabic-NLi-Pair-Class.","first_N":5,"first_N_keywords":["sentence-similarity","Arabic","apache-2.0","100K - 1M","csv"],"keywords_longer_than_N":true},
	{"name":"BLEnD","keyword":"arabic","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/nayeon212/BLEnD","creator_name":"Nayeon Lee","creator_url":"https://huggingface.co/nayeon212","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tBLEnD\\n\\t\\n\\nThis is the official repository of BLEnD: A Benchmark for LLMs on Everyday Knowledge in Diverse Cultures and Languages (Submitted to NeurIPS 2024 Datasets and Benchmarks Track).\\n24/12/05: Updated translation errors\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tAbout\\n\\t\\n\\n\\nLarge language models (LLMs) often lack culture-specific everyday knowledge, especially across diverse regions and non-English languages. Existing benchmarks for evaluating LLMs' cultural sensitivities are usually limited to a singleâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/nayeon212/BLEnD.","first_N":5,"first_N_keywords":["question-answering","English","Chinese","Spanish","Indonesian"],"keywords_longer_than_N":true},
	{"name":"tarwiiga_adgen_dataset","keyword":"arabic","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/maelghrib/tarwiiga_adgen_dataset","creator_name":"Mustafa A. Elghrib","creator_url":"https://huggingface.co/maelghrib","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tTarwiiga AdGen Dataset\\n\\t\\n\\nThis dataset is generated using LLM for the purpose of fine-tunning another LLM for the task of generating Google Ads, and it used is by Tarwiiga AdGen from Tarwiiga\\n","first_N":5,"first_N_keywords":["text-generation","language-modeling","no-annotation","machine-generated","monolingual"],"keywords_longer_than_N":true},
	{"name":"CaLMQA","keyword":"arabic","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/shanearora/CaLMQA","creator_name":"Shane Arora","creator_url":"https://huggingface.co/shanearora","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\n\\n\\nCaLMQA is a long-form question answering (LFQA) dataset spanning 23 high- to low-resource languages. \\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Details\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nCaLMQA is an LFQA dataset with 2K questions from 23 languages, 11 high- to mid-resource and 12 low-resource.\\nQuestions are either culturally specific â€“ uniquely or more likely to be asked by people of a specific\\nculture â€“ or culturally agnostic (not culturally specific). These questions wereâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/shanearora/CaLMQA.","first_N":5,"first_N_keywords":["multilingual","Afar","Arabic","Baluchi","German"],"keywords_longer_than_N":true},
	{"name":"MELA","keyword":"arabic","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Geralt-Targaryen/MELA","creator_name":"Ziyin Zhang","creator_url":"https://huggingface.co/Geralt-Targaryen","description":"See the GitHub repo for details.\\n","first_N":5,"first_N_keywords":["text-classification","English","Chinese","Italian","Russian"],"keywords_longer_than_N":true},
	{"name":"Arabic_Poems","keyword":"arabic","license":"GNU General Public License v2.0","license_url":"https://choosealicense.com/licenses/gpl-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/alwalid54321/Arabic_Poems","creator_name":"Alwalid Ibrahim","creator_url":"https://huggingface.co/alwalid54321","description":"Arabic Poems\\nit's a filtered version for (https://huggingface.co/datasets/arbml/ashaar) with only al-diwan data\\nOverview:\\nThe \\\"Arabic Poems\\\" dataset is a comprehensive collection of Arabic poetry, comprising 8,875 entries. Each entry contains detailed information about individual poems and their respective poets, making it a valuable resource for researchers, developers, and enthusiasts of Arabic literature.\\nColumns:\\nUnnamed: 0: An index column.\\npoem_title: The title of the poem.\\npoem_meter:â€¦ See the full description on the dataset page: https://huggingface.co/datasets/alwalid54321/Arabic_Poems.","first_N":5,"first_N_keywords":["gpl-2.0","1K - 10K","csv","Text","Datasets"],"keywords_longer_than_N":true},
	{"name":"bitext_sib200_miners","keyword":"arabic","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/gentaiscool/bitext_sib200_miners","creator_name":"Genta Indra Winata","creator_url":"https://huggingface.co/gentaiscool","description":"gentaiscool/bitext_sib200_miners dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["multilingual","Achinese","Mesopotamian Arabic","Ta'izzi-Adeni Arabic","Tunisian Arabic"],"keywords_longer_than_N":true},
	{"name":"fleurs_clean","keyword":"arabic","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Helloworld668/fleurs_clean","creator_name":"zhide Tang","creator_url":"https://huggingface.co/Helloworld668","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tFLEURS\\n\\t\\n\\nFleurs is the speech version of the FLoRes machine translation benchmark. \\nWe use 2009 n-way parallel sentences from the FLoRes dev and devtest publicly available sets, in 102 languages. \\nTraining sets have around 10 hours of supervision. Speakers of the train sets are different than speakers from the dev/test sets. Multilingual fine-tuning is\\nused and â€unit error rateâ€ (characters, signs) of all languages is averaged. Languages and results are also grouped into sevenâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Helloworld668/fleurs_clean.","first_N":5,"first_N_keywords":["automatic-speech-recognition","expert-generated","crowdsourced","machine-generated","crowdsourced"],"keywords_longer_than_N":true},
	{"name":"bitext_sib200_miners","keyword":"egyptian arabic","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/gentaiscool/bitext_sib200_miners","creator_name":"Genta Indra Winata","creator_url":"https://huggingface.co/gentaiscool","description":"gentaiscool/bitext_sib200_miners dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["multilingual","Achinese","Mesopotamian Arabic","Ta'izzi-Adeni Arabic","Tunisian Arabic"],"keywords_longer_than_N":true},
	{"name":"bitext_sib200_miners","keyword":"levantine arabic","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/gentaiscool/bitext_sib200_miners","creator_name":"Genta Indra Winata","creator_url":"https://huggingface.co/gentaiscool","description":"gentaiscool/bitext_sib200_miners dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["multilingual","Achinese","Mesopotamian Arabic","Ta'izzi-Adeni Arabic","Tunisian Arabic"],"keywords_longer_than_N":true},
	{"name":"bitext_sib200_miners","keyword":"mesopotamian arabic","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/gentaiscool/bitext_sib200_miners","creator_name":"Genta Indra Winata","creator_url":"https://huggingface.co/gentaiscool","description":"gentaiscool/bitext_sib200_miners dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["multilingual","Achinese","Mesopotamian Arabic","Ta'izzi-Adeni Arabic","Tunisian Arabic"],"keywords_longer_than_N":true},
	{"name":"bitext_sib200_miners","keyword":"moroccan arabic","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/gentaiscool/bitext_sib200_miners","creator_name":"Genta Indra Winata","creator_url":"https://huggingface.co/gentaiscool","description":"gentaiscool/bitext_sib200_miners dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["multilingual","Achinese","Mesopotamian Arabic","Ta'izzi-Adeni Arabic","Tunisian Arabic"],"keywords_longer_than_N":true},
	{"name":"bitext_sib200_miners","keyword":"najdi arabic","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/gentaiscool/bitext_sib200_miners","creator_name":"Genta Indra Winata","creator_url":"https://huggingface.co/gentaiscool","description":"gentaiscool/bitext_sib200_miners dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["multilingual","Achinese","Mesopotamian Arabic","Ta'izzi-Adeni Arabic","Tunisian Arabic"],"keywords_longer_than_N":true},
	{"name":"bitext_sib200_miners","keyword":"tunisian arabic","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/gentaiscool/bitext_sib200_miners","creator_name":"Genta Indra Winata","creator_url":"https://huggingface.co/gentaiscool","description":"gentaiscool/bitext_sib200_miners dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["multilingual","Achinese","Mesopotamian Arabic","Ta'izzi-Adeni Arabic","Tunisian Arabic"],"keywords_longer_than_N":true},
	{"name":"bitext_sib200_miners","keyword":"ta'izzi-adeni arabic","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/gentaiscool/bitext_sib200_miners","creator_name":"Genta Indra Winata","creator_url":"https://huggingface.co/gentaiscool","description":"gentaiscool/bitext_sib200_miners dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["multilingual","Achinese","Mesopotamian Arabic","Ta'izzi-Adeni Arabic","Tunisian Arabic"],"keywords_longer_than_N":true},
	{"name":"xP3x-Kongo","keyword":"arabic","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Svngoku/xP3x-Kongo","creator_name":"NIONGOLO Chrys FÃ©-Marty","creator_url":"https://huggingface.co/Svngoku","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for xP3x Kikongo Focus\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\n\\nxP3x (Crosslingual Public Pool of Prompts eXtended) is a collection of prompts & datasets across 277 languages & 16 NLP tasks. It contains all of xP3 + much more! It is used for training future contenders of mT0 & BLOOMZ at project Aya @C4AI ðŸ§¡\\n\\n\\nCreation: The dataset can be recreated using instructions available here together with the file in this repository named xp3x_create.py. We provide this version to saveâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Svngoku/xP3x-Kongo.","first_N":5,"first_N_keywords":["other","translation","expert-generated","crowdsourced","multilingual"],"keywords_longer_than_N":true},
	{"name":"arabic_functional_text_dimensions","keyword":"arabic","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/zeydferhat/arabic_functional_text_dimensions","creator_name":"ferhat","creator_url":"https://huggingface.co/zeydferhat","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Functional Text Dimensions for Arabic Text Classification.\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThe Arabic Functional Text Dimensions Corpus (AFTD Corpus) is introduced as a curated collection of Arabic documents aimed at evaluating text classification methodologies using the Functional Text Dimensions (FTD) approach. This corpus comprises 3,400 documents covering 17 distinct class categories, designed to enhance text classification in Arabic.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSupportedâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/zeydferhat/arabic_functional_text_dimensions.","first_N":5,"first_N_keywords":["text-classification","Arabic","apache-2.0","1K - 10K","csv"],"keywords_longer_than_N":true},
	{"name":"testing-dataset","keyword":"arabic","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/MouadGhouti/testing-dataset","creator_name":"Mouad Ghouti","creator_url":"https://huggingface.co/MouadGhouti","description":"MouadGhouti/testing-dataset dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["Arabic","English","mit","< 1K","csv"],"keywords_longer_than_N":true},
	{"name":"xP3x-Kongo","keyword":"egyptian arabic","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Svngoku/xP3x-Kongo","creator_name":"NIONGOLO Chrys FÃ©-Marty","creator_url":"https://huggingface.co/Svngoku","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for xP3x Kikongo Focus\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\n\\nxP3x (Crosslingual Public Pool of Prompts eXtended) is a collection of prompts & datasets across 277 languages & 16 NLP tasks. It contains all of xP3 + much more! It is used for training future contenders of mT0 & BLOOMZ at project Aya @C4AI ðŸ§¡\\n\\n\\nCreation: The dataset can be recreated using instructions available here together with the file in this repository named xp3x_create.py. We provide this version to saveâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Svngoku/xP3x-Kongo.","first_N":5,"first_N_keywords":["other","translation","expert-generated","crowdsourced","multilingual"],"keywords_longer_than_N":true},
	{"name":"xP3x-Kongo","keyword":"levantine arabic","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Svngoku/xP3x-Kongo","creator_name":"NIONGOLO Chrys FÃ©-Marty","creator_url":"https://huggingface.co/Svngoku","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for xP3x Kikongo Focus\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\n\\nxP3x (Crosslingual Public Pool of Prompts eXtended) is a collection of prompts & datasets across 277 languages & 16 NLP tasks. It contains all of xP3 + much more! It is used for training future contenders of mT0 & BLOOMZ at project Aya @C4AI ðŸ§¡\\n\\n\\nCreation: The dataset can be recreated using instructions available here together with the file in this repository named xp3x_create.py. We provide this version to saveâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Svngoku/xP3x-Kongo.","first_N":5,"first_N_keywords":["other","translation","expert-generated","crowdsourced","multilingual"],"keywords_longer_than_N":true},
	{"name":"xP3x-Kongo","keyword":"mesopotamian arabic","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Svngoku/xP3x-Kongo","creator_name":"NIONGOLO Chrys FÃ©-Marty","creator_url":"https://huggingface.co/Svngoku","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for xP3x Kikongo Focus\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\n\\nxP3x (Crosslingual Public Pool of Prompts eXtended) is a collection of prompts & datasets across 277 languages & 16 NLP tasks. It contains all of xP3 + much more! It is used for training future contenders of mT0 & BLOOMZ at project Aya @C4AI ðŸ§¡\\n\\n\\nCreation: The dataset can be recreated using instructions available here together with the file in this repository named xp3x_create.py. We provide this version to saveâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Svngoku/xP3x-Kongo.","first_N":5,"first_N_keywords":["other","translation","expert-generated","crowdsourced","multilingual"],"keywords_longer_than_N":true},
	{"name":"xP3x-Kongo","keyword":"moroccan arabic","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Svngoku/xP3x-Kongo","creator_name":"NIONGOLO Chrys FÃ©-Marty","creator_url":"https://huggingface.co/Svngoku","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for xP3x Kikongo Focus\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\n\\nxP3x (Crosslingual Public Pool of Prompts eXtended) is a collection of prompts & datasets across 277 languages & 16 NLP tasks. It contains all of xP3 + much more! It is used for training future contenders of mT0 & BLOOMZ at project Aya @C4AI ðŸ§¡\\n\\n\\nCreation: The dataset can be recreated using instructions available here together with the file in this repository named xp3x_create.py. We provide this version to saveâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Svngoku/xP3x-Kongo.","first_N":5,"first_N_keywords":["other","translation","expert-generated","crowdsourced","multilingual"],"keywords_longer_than_N":true},
	{"name":"xP3x-Kongo","keyword":"najdi arabic","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Svngoku/xP3x-Kongo","creator_name":"NIONGOLO Chrys FÃ©-Marty","creator_url":"https://huggingface.co/Svngoku","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for xP3x Kikongo Focus\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\n\\nxP3x (Crosslingual Public Pool of Prompts eXtended) is a collection of prompts & datasets across 277 languages & 16 NLP tasks. It contains all of xP3 + much more! It is used for training future contenders of mT0 & BLOOMZ at project Aya @C4AI ðŸ§¡\\n\\n\\nCreation: The dataset can be recreated using instructions available here together with the file in this repository named xp3x_create.py. We provide this version to saveâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Svngoku/xP3x-Kongo.","first_N":5,"first_N_keywords":["other","translation","expert-generated","crowdsourced","multilingual"],"keywords_longer_than_N":true},
	{"name":"xP3x-Kongo","keyword":"tunisian arabic","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Svngoku/xP3x-Kongo","creator_name":"NIONGOLO Chrys FÃ©-Marty","creator_url":"https://huggingface.co/Svngoku","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for xP3x Kikongo Focus\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\n\\nxP3x (Crosslingual Public Pool of Prompts eXtended) is a collection of prompts & datasets across 277 languages & 16 NLP tasks. It contains all of xP3 + much more! It is used for training future contenders of mT0 & BLOOMZ at project Aya @C4AI ðŸ§¡\\n\\n\\nCreation: The dataset can be recreated using instructions available here together with the file in this repository named xp3x_create.py. We provide this version to saveâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Svngoku/xP3x-Kongo.","first_N":5,"first_N_keywords":["other","translation","expert-generated","crowdsourced","multilingual"],"keywords_longer_than_N":true},
	{"name":"xP3x-Kongo","keyword":"ta'izzi-adeni arabic","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Svngoku/xP3x-Kongo","creator_name":"NIONGOLO Chrys FÃ©-Marty","creator_url":"https://huggingface.co/Svngoku","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for xP3x Kikongo Focus\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\n\\nxP3x (Crosslingual Public Pool of Prompts eXtended) is a collection of prompts & datasets across 277 languages & 16 NLP tasks. It contains all of xP3 + much more! It is used for training future contenders of mT0 & BLOOMZ at project Aya @C4AI ðŸ§¡\\n\\n\\nCreation: The dataset can be recreated using instructions available here together with the file in this repository named xp3x_create.py. We provide this version to saveâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Svngoku/xP3x-Kongo.","first_N":5,"first_N_keywords":["other","translation","expert-generated","crowdsourced","multilingual"],"keywords_longer_than_N":true},
	{"name":"Khatt-Dataset-Unique-lines-full","keyword":"arabic","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Nada2125/Khatt-Dataset-Unique-lines-full","creator_name":"Abbas","creator_url":"https://huggingface.co/Nada2125","description":"","first_N":5,"first_N_keywords":["image-to-text","Arabic","mit","1K - 10K","text"],"keywords_longer_than_N":true},
	{"name":"Khatt-Dataset-Unique-lines-full","keyword":"arabic","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Nada2125/Khatt-Dataset-Unique-lines-full","creator_name":"Abbas","creator_url":"https://huggingface.co/Nada2125","description":"","first_N":5,"first_N_keywords":["image-to-text","Arabic","mit","1K - 10K","text"],"keywords_longer_than_N":true},
	{"name":"Arabic-books-and-research-dataset","keyword":"arabic","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/riotu-lab/Arabic-books-and-research-dataset","creator_name":"Robotics and Interne-of-Things","creator_url":"https://huggingface.co/riotu-lab","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tArabic reserach and books dataset (ARABD)\\n\\t\\n\\nThis dataset is an extracted cleaned text from more than 60K word files with unique arabic texts never published before.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset diversity\\n\\t\\n\\nthe dataset is diverse from all kind of islamic research: [feqh, hadeeth, tafseer, tahqeeq, ... etc], from new written research to a manuscirpts.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tdataset size\\n\\t\\n\\nthe dataset was more than 11GB but after cleaning (pre-processing) it becase a straight 10GB with less noisyâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/riotu-lab/Arabic-books-and-research-dataset.","first_N":5,"first_N_keywords":["text-generation","Arabic","mit","10K - 100K","csv"],"keywords_longer_than_N":true},
	{"name":"saudi_up","keyword":"arabic","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/yeeaee/saudi_up","creator_name":"yazeed albadawy","creator_url":"https://huggingface.co/yeeaee","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Dataset Name\\n\\t\\n\\n\\n\\nThis dataset card aims to be a base template for new datasets. It has been generated using this raw template.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Details\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\n\\n\\n\\n\\n\\nCurated by: [More Information Needed]\\nFunded by [optional]: [More Information Needed]\\nShared by [optional]: [More Information Needed]\\nLanguage(s) (NLP): [More Information Needed]\\nLicense: [More Information Needed]\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Sources [optional]â€¦ See the full description on the dataset page: https://huggingface.co/datasets/yeeaee/saudi_up.","first_N":5,"first_N_keywords":["text-generation","Arabic","apache-2.0","1M - 10M","parquet"],"keywords_longer_than_N":true},
	{"name":"aracast_text","keyword":"arabic","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/asas-ai/aracast_text","creator_name":"ASAS AI","creator_url":"https://huggingface.co/asas-ai","description":"asas-ai/aracast_text dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["text-generation","Arabic","apache-2.0","10K - 100K","text"],"keywords_longer_than_N":true},
	{"name":"KHATT_v1.0_dataset","keyword":"arabic","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/johnlockejrr/KHATT_v1.0_dataset","creator_name":"John Locke","creator_url":"https://huggingface.co/johnlockejrr","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tKHATT_v1.0 - line level\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nKHATT (KFUPM Handwritten Arabic TexT) database is a database of unconstrained handwritten Arabic Text written by 1000 different writers. This research databaseâ€™s development was undertaken by a research group from KFUPM, Dhahran, S audi Arabia headed by Professor Sabri Mahmoud in collaboration with Professor Fink from TU-Dortmund, Germany and Dr. MÃ¤rgner from TU-Braunschweig, Germany.\\nThe database includes 2000 similar-textâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/johnlockejrr/KHATT_v1.0_dataset.","first_N":5,"first_N_keywords":["image-to-text","Arabic","mit","Image","ðŸ‡ºðŸ‡¸ Region: US"],"keywords_longer_than_N":true},
	{"name":"KHATT_v1.0_dataset","keyword":"arabic","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/johnlockejrr/KHATT_v1.0_dataset","creator_name":"John Locke","creator_url":"https://huggingface.co/johnlockejrr","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tKHATT_v1.0 - line level\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nKHATT (KFUPM Handwritten Arabic TexT) database is a database of unconstrained handwritten Arabic Text written by 1000 different writers. This research databaseâ€™s development was undertaken by a research group from KFUPM, Dhahran, S audi Arabia headed by Professor Sabri Mahmoud in collaboration with Professor Fink from TU-Dortmund, Germany and Dr. MÃ¤rgner from TU-Braunschweig, Germany.\\nThe database includes 2000 similar-textâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/johnlockejrr/KHATT_v1.0_dataset.","first_N":5,"first_N_keywords":["image-to-text","Arabic","mit","Image","ðŸ‡ºðŸ‡¸ Region: US"],"keywords_longer_than_N":true},
	{"name":"arabic-larg","keyword":"arabic","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/yeeaee/arabic-larg","creator_name":"yazeed albadawy","creator_url":"https://huggingface.co/yeeaee","description":"yeeaee/arabic-larg dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["Arabic","apache-2.0","100K - 1M","text","Text"],"keywords_longer_than_N":true},
	{"name":"AyaRedTeaming","keyword":"arabic","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/walledai/AyaRedTeaming","creator_name":"Walled AI","creator_url":"https://huggingface.co/walledai","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Aya Red-teaming\\n\\t\\n\\n\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Details\\n\\t\\n\\nThe Aya Red-teaming dataset is a human-annotated multilingual red-teaming dataset consisting of harmful prompts in 8 languages across 9 different categories of harm with explicit labels for \\\"global\\\" and \\\"local\\\" harm.\\n\\n\\n\\n\\n\\n\\nCurated by: Professional compensated annotators\\nLanguages: Arabic, English, Filipino, French, Hindi, Russian, Serbian and Spanish\\nLicense: Apache 2.0\\nPaper: arxiv link\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tHarmâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/walledai/AyaRedTeaming.","first_N":5,"first_N_keywords":["English","Hindi","French","Spanish","Arabic"],"keywords_longer_than_N":true},
	{"name":"RASAM","keyword":"arabic","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/johnlockejrr/RASAM","creator_name":"John Locke","creator_url":"https://huggingface.co/johnlockejrr","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tRASAM dataset\\n\\t\\n\\nAn Open Dataset for the Recognition and Analysis of Scripts in Arabic Maghrebi\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tHow to cite\\n\\t\\n\\nThe paper has been presented during the ICDAR 2021 conference (ASAR workshop). To cite this work and this dataset, please use the following informations:\\n@InProceedings{2021rasam-dataset,\\nauthor=\\\"Vidal-GorÃ¨ne, Chahan and Lucas, NoÃ«mie and Salah, ClÃ©ment and Decours-Perez, AliÃ©nor and Dupin, Boris\\\",\\neditor=\\\"Barney Smith, Elisa H. and Pal, Umapada\\\",\\ntitle=\\\"RASAMâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/johnlockejrr/RASAM.","first_N":5,"first_N_keywords":["text-classification","text-generation","fill-mask","Arabic","mit"],"keywords_longer_than_N":true},
	{"name":"InstAr-500k","keyword":"arabic","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ClusterlabAi/InstAr-500k","creator_name":"ClusterlabAi","creator_url":"https://huggingface.co/ClusterlabAi","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for \\\"InstAr-500k\\\"\\n\\t\\n\\nThe dataset comprises almost 500,000 Arabic instructions and responses designed for fine-tuning large language models (LLMs) for Arabic NLP tasks. It includes a combination of synthetic and human-crafted data across various domains and instruction types. This extensive dataset aims to improve the performance of LLMs on Arabic-specific tasks\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\n\\n  \\n    Type\\n    Task\\n    Number of Samples\\n    Percentage of Samplesâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/ClusterlabAi/InstAr-500k.","first_N":5,"first_N_keywords":["question-answering","summarization","text-classification","Arabic","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"Multilingual-Benchmark","keyword":"arabic","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/TaiMingLu/Multilingual-Benchmark","creator_name":"TaiMing","creator_url":"https://huggingface.co/TaiMingLu","description":"These are the GSM8K and ARC dataset translated by Google Translate. \\nBibTex\\n@misc{lu2024languagecountslearnunlearn,\\n      title={Every Language Counts: Learn and Unlearn in Multilingual LLMs}, \\n      author={Taiming Lu and Philipp Koehn},\\n      year={2024},\\n      eprint={2406.13748},\\n      archivePrefix={arXiv},\\n      primaryClass={cs.CL},\\n      url={https://arxiv.org/abs/2406.13748}, \\n}\\n\\n","first_N":5,"first_N_keywords":["zero-shot-classification","question-answering","translation","English","German"],"keywords_longer_than_N":true},
	{"name":"arabic-roots","keyword":"arabic","license":"GNU General Public License v3.0","license_url":"https://choosealicense.com/licenses/gpl-3.0/","language":"en","dataset_url":"https://huggingface.co/datasets/MohamedRashad/arabic-roots","creator_name":"Mohamed Rashad","creator_url":"https://huggingface.co/MohamedRashad","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tðŸŒ± Arabic Roots | Ø§Ù„Ø¬Ø°ÙˆØ± Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©\\n\\t\\n\\n\\n  \\n\\n\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThe \\\"arabic-roots\\\" dataset is a comprehensive collection of Arabic root words along with their detailed definitions, sourced from classical Arabic lexicons. It includes 56,606 rows of data, making it a valuable resource for researchers, linguists, and developers working on Arabic language processing and understanding.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Example\\n\\t\\n\\nAn example row in the dataset:\\n{\\n  \\\"root\\\": \\\"Ø¢Ø¡\\\"â€¦ See the full description on the dataset page: https://huggingface.co/datasets/MohamedRashad/arabic-roots.","first_N":5,"first_N_keywords":["Arabic","gpl-3.0","10K - 100K","parquet","Text"],"keywords_longer_than_N":true},
	{"name":"UN-Arabic-English-Filtered","keyword":"arabic","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ymoslem/UN-Arabic-English-Filtered","creator_name":"Yasmin Moslem","creator_url":"https://huggingface.co/ymoslem","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Details\\n\\t\\n\\nMultiUN + UNPC datasets, with rule-based and semantic filtering (train > 0.45 - test/dev > 0.9)\\nas well as (>= 0.1) fasttext language detection.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Structure\\n\\t\\n\\nDatasetDict({\\n    train: Dataset({\\n        features: ['text_en', 'text_ar'],\\n        num_rows: 19279407\\n    })\\n    test: Dataset({\\n        features: ['text_en', 'text_ar'],\\n        num_rows: 8752\\n    })\\n    dev: Dataset({\\n        features: ['text_en', 'text_ar'],\\n        num_rows: 8752â€¦ See the full description on the dataset page: https://huggingface.co/datasets/ymoslem/UN-Arabic-English-Filtered.","first_N":5,"first_N_keywords":["translation","Arabic","English","cc-by-4.0","10M - 100M"],"keywords_longer_than_N":true},
	{"name":"tydi_xor_rc","keyword":"arabic","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/coastalcph/tydi_xor_rc","creator_name":"CoAStaL NLP Group","creator_url":"https://huggingface.co/coastalcph","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for \\\"tydi_xor_rc\\\"\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nTyDi QA is a question answering dataset covering 11 typologically diverse languages. \\nXORQA is an extension of the original TyDi QA dataset to also include unanswerable questions, where context documents are only in English but questions are in 7 languages.\\nXOR-AttriQA contains annotated attribution data for a sample of XORQA.\\nThis dataset is a combined and simplified version of the Reading Comprehension data fromâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/coastalcph/tydi_xor_rc.","first_N":5,"first_N_keywords":["question-answering","extractive-qa","crowdsourced","crowdsourced","multilingual"],"keywords_longer_than_N":true},
	{"name":"multimuc4","keyword":"arabic","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/jgermanmx/multimuc4","creator_name":"Jesus German Ortiz Barajas","creator_url":"https://huggingface.co/jgermanmx","description":"jgermanmx/multimuc4 dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["text-classification","Arabic","English","Persian","Korean"],"keywords_longer_than_N":true},
	{"name":"librivox-tracks","keyword":"arabic","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/xacer/librivox-tracks","creator_name":"xacer","creator_url":"https://huggingface.co/xacer","description":"A dataset of all audio files uploaded to LibriVox before 26th September 2023.\\nForked from https://huggingface.co/datasets/pykeio/librivox-tracks\\nChanges:\\n\\nUsed archive.org metadata API to annotate rows with \\\"duration\\\" column\\n\\n","first_N":5,"first_N_keywords":["text-to-speech","automatic-speech-recognition","feature-extraction","Achinese","Afrikaans"],"keywords_longer_than_N":true},
	{"name":"fact-check-bureau","keyword":"arabic","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/NaughtyConstrictor/fact-check-bureau","creator_name":"Younes","creator_url":"https://huggingface.co/NaughtyConstrictor","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tFact-Check Retrieval Dataset\\n\\t\\n\\nThis dataset is designed to support the development and evaluation of fact-check retrieval pipelines. It is structured to work with FactCheckBureau, a tool for designing and evaluating fact-check retrieval pipelines. The dataset comprises a list of claims, fact-check articles, and precomputed embeddings for English and French fact-checks.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Structure\\n\\t\\n\\nThe dataset consists of the following files and directories:\\n\\narticles.csv:â€¦ See the full description on the dataset page: https://huggingface.co/datasets/NaughtyConstrictor/fact-check-bureau.","first_N":5,"first_N_keywords":["English","French","Portuguese","Spanish","Arabic"],"keywords_longer_than_N":true},
	{"name":"ArabicQA_2.1M","keyword":"arabic","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/riotu-lab/ArabicQA_2.1M","creator_name":"Robotics and Interne-of-Things","creator_url":"https://huggingface.co/riotu-lab","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tArabic Question Answering Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDescription\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Overview\\n\\t\\n\\nOur dataset is an amalgamation of several filtered datasets, the total number of rows for all datasets was 4,731,600 which was reduced to 2,141,146 rows after filtering. The dataset was collected to fine a pretraind model, the model forced a number of contrains on us discussed in the following section.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tFiltering Process\\n\\t\\n\\nThe filtering process for each dataset included oneâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/riotu-lab/ArabicQA_2.1M.","first_N":5,"first_N_keywords":["question-answering","Arabic","apache-2.0","1M - 10M","parquet"],"keywords_longer_than_N":true},
	{"name":"AceGPT-v2-AlignmentData","keyword":"arabic","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/FreedomIntelligence/AceGPT-v2-AlignmentData","creator_name":"FreedomAI","creator_url":"https://huggingface.co/FreedomIntelligence","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tIntroduction\\n\\t\\n\\nTo efficiently achieve native alignment in AceGPT-v2, this dataset was constructed to train a small alignment model to filter the entire pre-train dataset. Therefore, this dataset was built through the following steps:\\n\\nRandomly select 96K samples from ArabicText 2022.\\nUse GPT-4-turbo to rewrite the extracted data according to the provided prompts.\\nOrganize the rewritten data into pairs to create training data for the Alignment LLM.\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSystem Prompt forâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/FreedomIntelligence/AceGPT-v2-AlignmentData.","first_N":5,"first_N_keywords":["Arabic","apache-2.0","10M - 100M","json","Text"],"keywords_longer_than_N":true},
	{"name":"Ar-BeaverTails-Evaluation","keyword":"arabic","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/FreedomIntelligence/Ar-BeaverTails-Evaluation","creator_name":"FreedomAI","creator_url":"https://huggingface.co/FreedomIntelligence","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tIntroduction\\n\\t\\n\\nThis is the Arabic version of BeaverTails-Evaluation.\\nBeaverTails-Evaluation is a dataset designed to assess the safety of large language models. It contains prompts that are likely to provoke the model into generating offensive language. This dataset helps determine whether the model can maintain human values when confronted with offensive questions.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tExample\\n\\t\\n\\nHere is the first sample of this dataset.\\n{\\n  \\\"prompt\\\": \\\"What's the most painful way to skinâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/FreedomIntelligence/Ar-BeaverTails-Evaluation.","first_N":5,"first_N_keywords":["Arabic","English","apache-2.0","< 1K","json"],"keywords_longer_than_N":true},
	{"name":"ARABIC-RAW-TEXT","keyword":"arabic","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/riotu-lab/ARABIC-RAW-TEXT","creator_name":"Robotics and Interne-of-Things","creator_url":"https://huggingface.co/riotu-lab","description":"Dataset: \\n\\nAluka 1.4 GB\\nAraWiki 3.9 GB\\nAya 22.5 GB\\nIslamic Books 21.4 GB\\n\\n","first_N":5,"first_N_keywords":["text-generation","Arabic","apache-2.0","100M - 1B","text"],"keywords_longer_than_N":true},
	{"name":"oasst2_egyptian_arabic_convs","keyword":"arabic","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/kokojake/oasst2_egyptian_arabic_convs","creator_name":"Hossamhasanin","creator_url":"https://huggingface.co/kokojake","description":"kokojake/oasst2_egyptian_arabic_convs dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["text-generation","question-answering","Arabic","apache-2.0","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"XL-HeadTags","keyword":"arabic","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/faisaltareque/XL-HeadTags","creator_name":"Faisal Tareque Shohan","creator_url":"https://huggingface.co/faisaltareque","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for XL-HeadTags Corpus\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Source\\n\\t\\n\\nWe have used M3LS and XL-Sum as source for this dataset.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\n We provide XL-HeadTags, a large-scale news headline and tags generation dataset. The dataset consists of 20 languages across six diverse language families. It contains 415K news headline-article pairs with auxiliary information such as image captions, topic words (read more).\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Structure\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/faisaltareque/XL-HeadTags.","first_N":5,"first_N_keywords":["summarization","text2text-generation","sentence-similarity","English","Portuguese"],"keywords_longer_than_N":true},
	{"name":"parasitic-egg","keyword":"arabic","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Abdelkareem/parasitic-egg","creator_name":"elkahtib","creator_url":"https://huggingface.co/Abdelkareem","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Parasitic Egg Image Classification Dataset\\n\\t\\n\\n\\n\\nThis dataset card aims to be a base template for the Parasitic Egg Image Classification Dataset. It has been generated using this raw template.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Details\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\n\\n\\nThis dataset is designed for the classification of parasitic eggs from microscopic images. Parasitic infections are a major health concern, particularly in developing countries, where parasites are aâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Abdelkareem/parasitic-egg.","first_N":5,"first_N_keywords":["image-classification","image-segmentation","object-detection","Arabic","English"],"keywords_longer_than_N":true},
	{"name":"uae-laws","keyword":"arabic","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/obadabaq/uae-laws","creator_name":"obada baqleh","creator_url":"https://huggingface.co/obadabaq","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for UAE-Laws\\n\\t\\n\\nThis dataset is a collection of information about the laws and regulations in the United Arab Emirates. \\nIt covers different areas of law like: \\n\\neconomy and business \\nfamily and community \\nfinance and banking \\nindustry and technical standardisation \\njustice and juiciary, labour \\nresidency and leberal professions \\nsecurity and safety \\ntax\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Sources\\n\\t\\n\\n\\nUnited Arab Emirates Legislations\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Structure\\n\\t\\n\\nTheâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/obadabaq/uae-laws.","first_N":5,"first_N_keywords":["question-answering","text-generation","English","Arabic","mit"],"keywords_longer_than_N":true},
	{"name":"structured-uae-laws","keyword":"arabic","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/obadabaq/structured-uae-laws","creator_name":"obada baqleh","creator_url":"https://huggingface.co/obadabaq","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for structured-uae-laws\\n\\t\\n\\nThis dataset is a collection of question & answers about the laws and regulations in the United Arab Emirates. \\nIt covers different areas of law like: \\n\\neconomy and business \\nfamily and community \\nfinance and banking \\nindustry and technical standardisation \\njustice and juiciary, labour \\nresidency and leberal professions \\nsecurity and safety \\ntax\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Sources\\n\\t\\n\\n\\nRepository\\nBase Dataset\\nUnited Arab Emirates Legislationsâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/obadabaq/structured-uae-laws.","first_N":5,"first_N_keywords":["question-answering","text-generation","English","Arabic","mit"],"keywords_longer_than_N":true},
	{"name":"hadith_alpaca_ft","keyword":"arabic","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/akbargherbal/hadith_alpaca_ft","creator_name":"Akbar Gherbal","creator_url":"https://huggingface.co/akbargherbal","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tHadith Alpaca Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tOverview\\n\\t\\n\\nThis repository contains the Hadith Alpaca Dataset, comprising 4,592 meticulously processed Hadiths. \\nThe dataset removes the initial chain of transmission in Arabic and extraneous commentary, focusing on the core Hadith text. \\nIt's designed for training and evaluating language models, particularly in understanding and processing Islamic religious texts.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Format\\n\\t\\n\\nThe dataset is structured for ease of use andâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/akbargherbal/hadith_alpaca_ft.","first_N":5,"first_N_keywords":["text-generation","Arabic","English","apache-2.0","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"Arabic_prompts_Mini_175","keyword":"arabic","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/HeshamHaroon/Arabic_prompts_Mini_175","creator_name":"Hesham Haroon","creator_url":"https://huggingface.co/HeshamHaroon","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tArabic Prompts Dataset\\n\\t\\n\\nOverview\\nThe Arabic Prompts Dataset is a comprehensive collection of prompts designed to facilitate research and development in natural language processing (NLP), machine learning, and artificial intelligence, particularly focusing on Arabic language applications. This dataset includes a diverse range of topics and questions across various fields such as literature, science, technology, and culture, making it an invaluable resource for training modelsâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/HeshamHaroon/Arabic_prompts_Mini_175.","first_N":5,"first_N_keywords":["text-generation","Arabic","apache-2.0","< 1K","csv"],"keywords_longer_than_N":true},
	{"name":"Saudilang-Code-Switch-Corpus","keyword":"arabic","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/SDAIANCAI/Saudilang-Code-Switch-Corpus","creator_name":"SDAIA NCAI","creator_url":"https://huggingface.co/SDAIANCAI","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSCC - Saudilang Code-Switch Corpus\\n\\t\\n\\nThe National Center for Artificial Intelligence at the Saudi Data and Artificial Intelligence Authority (SDAIA), published the \\\"SCC\\\" dataset, which stands for \\\"Saudilang Code-Switch Corpusâ€.\\nThis dataset contains a transcription of general conversations taken from a YouTube podcast \\\"Thmanyah\\\" that has been transcribed by the National Center for Artificial Intelligence in SDAIA. The data features three episodes covering different domains:â€¦ See the full description on the dataset page: https://huggingface.co/datasets/SDAIANCAI/Saudilang-Code-Switch-Corpus.","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","Arabic","English","cc-by-sa-4.0"],"keywords_longer_than_N":true},
	{"name":"mmarco-hard-negatives-reranker-score","keyword":"arabic","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/hotchpotch/mmarco-hard-negatives-reranker-score","creator_name":"Yuichi Tateno","creator_url":"https://huggingface.co/hotchpotch","description":"\\nhotchpotch/mmarco-hard-negatives-reranker-score\\n\\nThis repository contains data from mMARCO scored using the reranker BAAI/bge-reranker-v2-m3.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages Covered\\n\\t\\n\\ntarget_languages = [\\n    \\\"english\\\",\\n    \\\"chinese\\\", \\n    \\\"french\\\",\\n    \\\"german\\\",\\n    \\\"indonesian\\\",\\n    \\\"italian\\\",\\n    \\\"portuguese\\\",\\n    \\\"russian\\\",\\n    \\\"spanish\\\",\\n    \\\"arabic\\\",\\n    \\\"dutch\\\",\\n    \\\"hindi\\\",\\n    \\\"japanese\\\",\\n    \\\"vietnamese\\\"\\n]\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tHard Negative Data\\n\\t\\n\\nThe hard negative data is derived fromâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/hotchpotch/mmarco-hard-negatives-reranker-score.","first_N":5,"first_N_keywords":["English","Chinese","French","German","Indonesian"],"keywords_longer_than_N":true},
	{"name":"ArSRED","keyword":"arabic","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/dru-ac/ArSRED","creator_name":"Digital Research Unit - Arab Center For Research and Policy Studies","creator_url":"https://huggingface.co/dru-ac","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tAREEj: Arabic Relation Extraction with Evidence\\n\\t\\n\\nThis dataset was made by adding evidence annotations to the Arabic subset of SREDFM. The dataset is from the Proceedings of The Second Arabic Natural Language Processing Conference paper AREEj: Arabic Relation Extraction with Evidence. If you use the dataset or the model, please reference this work in your paper:\\n@inproceedings{mraikhat-etal-2024-areej,\\n    title = \\\"{AREE}j: {A}rabic Relation Extraction with Evidence\\\",\\n    author =â€¦ See the full description on the dataset page: https://huggingface.co/datasets/dru-ac/ArSRED.","first_N":5,"first_N_keywords":["token-classification","Arabic","cc-by-sa-4.0","100K - 1M","csv"],"keywords_longer_than_N":true},
	{"name":"muri-it-language-split","keyword":"arabic","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/akoksal/muri-it-language-split","creator_name":"Abdullatif Koksal","creator_url":"https://huggingface.co/akoksal","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tMURI-IT: Multilingual Instruction Tuning Dataset for 200 Languages via Multilingual Reverse Instructions\\n\\t\\n\\nMURI-IT is a large-scale multilingual instruction tuning dataset containing 2.2 million instruction-output pairs across 200 languages. It is designed to address the challenges of instruction tuning in low-resource languages with Multilingual Reverse Instructions (MURI), which ensures that the output is human-written, high-quality, and authentic to the cultural and linguisticâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/akoksal/muri-it-language-split.","first_N":5,"first_N_keywords":["text2text-generation","text-generation","question-answering","summarization","Achinese"],"keywords_longer_than_N":true},
	{"name":"Arabic_LLaMA_Math_Dataset","keyword":"arabic","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Jr23xd23/Arabic_LLaMA_Math_Dataset","creator_name":"Jaber","creator_url":"https://huggingface.co/Jr23xd23","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tArabic LLaMA Math Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tExample Entries\\n\\t\\n\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Overview\\n\\t\\n\\n\\nDataset Name: Arabic_LLaMA_Math_Dataset.csv\\nNumber of Records: 12,496\\nNumber of Columns: 3\\nFile Format: CSV\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Structure\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tColumns:\\n\\t\\n\\n\\nInstruction: The problem statement or question (text, in Arabic)\\nInput: Additional input for model fine-tuning (empty in this dataset)\\nSolution: The solution or answer to the problem (text, in Arabic)\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDatasetâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Jr23xd23/Arabic_LLaMA_Math_Dataset.","first_N":5,"first_N_keywords":["question-answering","Arabic","cc0-1.0","10K - 100K","csv"],"keywords_longer_than_N":true},
	{"name":"Arabic_LLaMA_Math_Dataset","keyword":"arabic","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Jr23xd23/Arabic_LLaMA_Math_Dataset","creator_name":"Jaber","creator_url":"https://huggingface.co/Jr23xd23","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tArabic LLaMA Math Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tExample Entries\\n\\t\\n\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Overview\\n\\t\\n\\n\\nDataset Name: Arabic_LLaMA_Math_Dataset.csv\\nNumber of Records: 12,496\\nNumber of Columns: 3\\nFile Format: CSV\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Structure\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tColumns:\\n\\t\\n\\n\\nInstruction: The problem statement or question (text, in Arabic)\\nInput: Additional input for model fine-tuning (empty in this dataset)\\nSolution: The solution or answer to the problem (text, in Arabic)\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDatasetâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Jr23xd23/Arabic_LLaMA_Math_Dataset.","first_N":5,"first_N_keywords":["question-answering","Arabic","cc0-1.0","10K - 100K","csv"],"keywords_longer_than_N":true},
	{"name":"PangeaBench-xm100","keyword":"arabic","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/neulab/PangeaBench-xm100","creator_name":"NeuLab @ LTI/CMU","creator_url":"https://huggingface.co/neulab","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tXM100\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tThis is a copy from https://google.github.io/crossmodal-3600/\\n\\t\\n\\nIf you use this dataset, please cite the original authors:\\n@inproceedings{ThapliyalCrossmodal2022,\\n  author = {Ashish Thapliyal and Jordi Pont-Tuset and Xi Chen and Radu Soricut},\\n  title = {{Crossmodal-3600: A Massively Multilingual Multimodal Evaluation Dataset}},\\n  booktitle = {EMNLP},\\n  year = {2022}\\n}\\n\\n","first_N":5,"first_N_keywords":["image-to-text","Arabic","Bengali","Czech","Danish"],"keywords_longer_than_N":true},
	{"name":"Arabic-finanical-rag-embedding-dataset","keyword":"arabic","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Omartificial-Intelligence-Space/Arabic-finanical-rag-embedding-dataset","creator_name":"Omartificial Intelligence Space","creator_url":"https://huggingface.co/Omartificial-Intelligence-Space","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tArabic Version of The Finanical Rag Embedding Dataset\\n\\t\\n\\n\\nThis dataset is tailored for fine-tuning embedding models in Retrieval-Augmented Generation (RAG) setups. It consists of 7,000 question-context pairs translated into Arabic, sourced from NVIDIA's 2023 SEC Filing Report. \\nThe dataset is designed to improve the performance of embedding models by providing positive samples for financial question-answering tasks in Arabic.\\nThis dataset is the Arabic version of the originalâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Omartificial-Intelligence-Space/Arabic-finanical-rag-embedding-dataset.","first_N":5,"first_N_keywords":["Arabic","apache-2.0","1K - 10K","csv","Text"],"keywords_longer_than_N":true},
	{"name":"Arabic-finanical-rag-embedding-dataset","keyword":"arabic","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Omartificial-Intelligence-Space/Arabic-finanical-rag-embedding-dataset","creator_name":"Omartificial Intelligence Space","creator_url":"https://huggingface.co/Omartificial-Intelligence-Space","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tArabic Version of The Finanical Rag Embedding Dataset\\n\\t\\n\\n\\nThis dataset is tailored for fine-tuning embedding models in Retrieval-Augmented Generation (RAG) setups. It consists of 7,000 question-context pairs translated into Arabic, sourced from NVIDIA's 2023 SEC Filing Report. \\nThe dataset is designed to improve the performance of embedding models by providing positive samples for financial question-answering tasks in Arabic.\\nThis dataset is the Arabic version of the originalâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Omartificial-Intelligence-Space/Arabic-finanical-rag-embedding-dataset.","first_N":5,"first_N_keywords":["Arabic","apache-2.0","1K - 10K","csv","Text"],"keywords_longer_than_N":true},
	{"name":"arabic_mmmu","keyword":"arabic","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/ahmedheakl/arabic_mmmu","creator_name":"Ahmed Heakl","creator_url":"https://huggingface.co/ahmedheakl","description":"Please see paper & code for more information:\\n\\nhttps://github.com/mbzuai-oryx/Camel-Bench\\nhttps://arxiv.org/abs/2410.18976\\n\\n","first_N":5,"first_N_keywords":["Arabic","mit","< 1K","parquet","Image"],"keywords_longer_than_N":true},
	{"name":"arabic_countbench","keyword":"arabic","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/ahmedheakl/arabic_countbench","creator_name":"Ahmed Heakl","creator_url":"https://huggingface.co/ahmedheakl","description":"ahmedheakl/arabic_countbench dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["Arabic","mit","< 1K","parquet","Image"],"keywords_longer_than_N":true},
	{"name":"ApolloMoEDataset","keyword":"arabic","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/FreedomIntelligence/ApolloMoEDataset","creator_name":"FreedomAI","creator_url":"https://huggingface.co/FreedomIntelligence","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDemocratizing Medical LLMs For Much More Languages\\n\\t\\n\\nCovering 12 Major Languages including English, Chinese, French, Hindi, Spanish, Arabic, Russian, Japanese, Korean, German, Italian, Portuguese and 38 Minor Languages So far.\\n\\n   ðŸ“ƒ Paper â€¢ ðŸŒ Demo â€¢ ðŸ¤— ApolloMoEDataset â€¢ ðŸ¤— ApolloMoEBench  â€¢ ðŸ¤— Models  â€¢ðŸŒ Apollo  â€¢ ðŸŒ ApolloMoE\\n\\n\\n\\n\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tðŸŒˆ Update\\n\\t\\n\\n\\n[2024.10.15] ApolloMoE repo is publishedï¼ðŸŽ‰\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages Coverage\\n\\t\\n\\n12 Major Languages and 38 Minor Languagesâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/FreedomIntelligence/ApolloMoEDataset.","first_N":5,"first_N_keywords":["question-answering","Arabic","English","Chinese","Korean"],"keywords_longer_than_N":true},
	{"name":"ApolloMoEBench","keyword":"arabic","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/FreedomIntelligence/ApolloMoEBench","creator_name":"FreedomAI","creator_url":"https://huggingface.co/FreedomIntelligence","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDemocratizing Medical LLMs For Much More Languages\\n\\t\\n\\nCovering 12 Major Languages including English, Chinese, French, Hindi, Spanish, Arabic, Russian, Japanese, Korean, German, Italian, Portuguese and 38 Minor Languages So far.\\n\\n   ðŸ“ƒ Paper â€¢ ðŸŒ Demo â€¢ ðŸ¤— ApolloMoEDataset â€¢ ðŸ¤— ApolloMoEBench  â€¢ ðŸ¤— Models  â€¢ðŸŒ Apollo  â€¢ ðŸŒ ApolloMoE\\n\\n\\n\\n\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tðŸŒˆ Update\\n\\t\\n\\n\\n[2024.10.15] ApolloMoE repo is publishedï¼ðŸŽ‰\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages Coverage\\n\\t\\n\\n12 Major Languages and 38 Minor Languagesâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/FreedomIntelligence/ApolloMoEBench.","first_N":5,"first_N_keywords":["question-answering","Arabic","English","Chinese","Korean"],"keywords_longer_than_N":true},
	{"name":"aya_redteaming_consitutional","keyword":"arabic","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/pbevan11/aya_redteaming_consitutional","creator_name":"Peter J. Bevan","creator_url":"https://huggingface.co/pbevan11","description":"\\n\\t\\n\\t\\t\\n\\t\\tDataset Card for Aya Red-teaming-constiutional\\n\\t\\n\\nThis dataset is an extended version of CohereForAI/aya_redteaming, with added targeted constitutional principles, aiming to allow multilingual constitional AI using the Aya Red team prompts.\\nWe take the Anthropic constitutional principles and manually cut out the existing harms so that we can dynamically insert harms specific to our red team prompts.\\nThere are 16 critiques and 16 revisions for each red-team prompt, each targeting theâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/pbevan11/aya_redteaming_consitutional.","first_N":5,"first_N_keywords":["English","Hindi","French","Spanish","Arabic"],"keywords_longer_than_N":true},
	{"name":"AURA-Sentiment","keyword":"arabic","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/irfan-ahmad/AURA-Sentiment","creator_name":"Irfan Ahmad","creator_url":"https://huggingface.co/irfan-ahmad","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tAURA-Sentiment\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThe AURA Sentiment Dataset is a collection of 29,700 app reviews in Arabic from iOS and Android platforms. Each review is labeled with a sentiment class, enabling researchers and practitioners to develop and evaluate sentiment analysis models tailored to the Arabic language.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tFeatures\\n\\t\\n\\nThe dataset includes the following columns:\\n\\nreview: The text of the app review in Arabic.\\nappName: The name of the applicationâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/irfan-ahmad/AURA-Sentiment.","first_N":5,"first_N_keywords":["Arabic","mit","10K - 100K","parquet","Text"],"keywords_longer_than_N":true},
	{"name":"AURA-Sentiment","keyword":"arabic","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/irfan-ahmad/AURA-Sentiment","creator_name":"Irfan Ahmad","creator_url":"https://huggingface.co/irfan-ahmad","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tAURA-Sentiment\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThe AURA Sentiment Dataset is a collection of 29,700 app reviews in Arabic from iOS and Android platforms. Each review is labeled with a sentiment class, enabling researchers and practitioners to develop and evaluate sentiment analysis models tailored to the Arabic language.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tFeatures\\n\\t\\n\\nThe dataset includes the following columns:\\n\\nreview: The text of the app review in Arabic.\\nappName: The name of the applicationâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/irfan-ahmad/AURA-Sentiment.","first_N":5,"first_N_keywords":["Arabic","mit","10K - 100K","parquet","Text"],"keywords_longer_than_N":true},
	{"name":"DVOICEv1.1-Darija","keyword":"arabic","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/BrunoHays/DVOICEv1.1-Darija","creator_name":"Bruno Hays","creator_url":"https://huggingface.co/BrunoHays","description":"Dialectal Voice is a community project initiated by AIOX Labs to facilitate voice recognition by Intelligent Systems. Today, the need for AI systems capable of recognizing the human voice is increasingly expressed within communities. However, we note that for some languages such as Darija, there are not enough voice technology solutions. To meet this need, we then proposed to establish this program of iterative and interactive construction of a dialectal database open to all in order to helpâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/BrunoHays/DVOICEv1.1-Darija.","first_N":5,"first_N_keywords":["Arabic","cc-by-4.0","1K - 10K","soundfolder","Audio"],"keywords_longer_than_N":true},
	{"name":"MegaWika","keyword":"arabic","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/conceptofmind/MegaWika","creator_name":"Enrico Shippole","creator_url":"https://huggingface.co/conceptofmind","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for MegaWika\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nMegaWika is a multi- and crosslingual text dataset containing 30 million Wikipedia passages with their scraped and cleaned web citations. The passages span\\n50 Wikipedias in 50 languages, and the articles in which the passages were originally embedded are included for convenience. Where a Wikipedia passage is in a\\nnon-English language, an automated English translation is provided. Furthermore, nearly 130 million Englishâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/conceptofmind/MegaWika.","first_N":5,"first_N_keywords":["summarization","question-answering","text-generation","text2text-generation","Afrikaans"],"keywords_longer_than_N":true},
	{"name":"3","keyword":"arabic","license":"Boost Software License 1.0","license_url":"https://choosealicense.com/licenses/bsl-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Mekasiu1018/3","creator_name":"mekasiu","creator_url":"https://huggingface.co/Mekasiu1018","description":"Mekasiu1018/3 dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["token-classification","text-generation","fill-mask","Afrikaans","Arabic"],"keywords_longer_than_N":true},
	{"name":"Context-Aware-English-to-Arabic-Dataset","keyword":"arabic","license":"Artistic License 2.0","license_url":"https://choosealicense.com/licenses/artistic-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Senju2/Context-Aware-English-to-Arabic-Dataset","creator_name":"Afroza Nowshin","creator_url":"https://huggingface.co/Senju2","description":"Senju2/Context-Aware-English-to-Arabic-Dataset dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["Arabic","English","artistic-2.0","1M - 10M","csv"],"keywords_longer_than_N":true},
	{"name":"persian_word_vowels_pronunciations","keyword":"arabic","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/developer-ninja/persian_word_vowels_pronunciations","creator_name":"momo titi","creator_url":"https://huggingface.co/developer-ninja","description":"\\n\\t\\n\\t\\t\\n\\t\\tDataset Card for Dataset Name\\n\\t\\n\\n\\n\\nThis dataset card aims to be a base template for new datasets. It has been generated using this raw template.\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Details\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\n\\n\\n\\n\\n\\nCurated by: [More Information Needed]\\nFunded by [optional]: [More Information Needed]\\nShared by [optional]: [More Information Needed]\\nLanguage(s) (NLP): [More Information Needed]\\nLicense: [More Information Needed]\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Sources [optional]\\n\\t\\n\\n\\n\\n\\nRepository: [Moreâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/developer-ninja/persian_word_vowels_pronunciations.","first_N":5,"first_N_keywords":["Persian","Arabic","apache-2.0","ðŸ‡ºðŸ‡¸ Region: US","language"],"keywords_longer_than_N":true},
	{"name":"EvArEST-dataset-for-Arabic-scene-text-recognition","keyword":"arabic","license":"BSD 3-Clause \"New\" or \"Revised\" License","license_url":"https://choosealicense.com/licenses/bsd-3-clause/","language":"en","dataset_url":"https://huggingface.co/datasets/Melaraby/EvArEST-dataset-for-Arabic-scene-text-recognition","creator_name":"Mostafa","creator_url":"https://huggingface.co/Melaraby","description":"\\n\\t\\n\\t\\t\\n\\t\\tEvArEST\\n\\t\\n\\nEveryday Arabic-English Scene Text dataset, from the paper: Arabic Scene Text Recognition in the Deep Learning Era: Analysis on A Novel Dataset\\nThe dataset includes both the recognition dataset and the synthetic one in a single train and test split.\\n\\n\\t\\n\\t\\t\\n\\t\\tRecognition Dataset\\n\\t\\n\\nThe text recognition dataset comprises of 7232 cropped word images of both Arabic and English languages. The groundtruth for the recognition dataset is provided by a text file with each lineâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Melaraby/EvArEST-dataset-for-Arabic-scene-text-recognition.","first_N":5,"first_N_keywords":["Arabic","bsd-3-clause","100K - 1M","parquet","Image"],"keywords_longer_than_N":true},
	{"name":"quran-cqa","keyword":"arabic","license":"GNU General Public License v3.0","license_url":"https://choosealicense.com/licenses/gpl-3.0/","language":"en","dataset_url":"https://huggingface.co/datasets/sadnblueish/quran-cqa","creator_name":"Muhammad Ali Qureshi","creator_url":"https://huggingface.co/sadnblueish","description":"\\n\\t\\n\\t\\t\\n\\t\\tDataset Card for Dataset Name\\n\\t\\n\\n\\n\\nThis dataset card aims to be a base template for new datasets. It has been generated using this raw template.\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Details\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\n\\n\\n\\n\\n\\nCurated by: [More Information Needed]\\nFunded by [optional]: [More Information Needed]\\nShared by [optional]: [More Information Needed]\\nLanguage(s) (NLP): [More Information Needed]\\nLicense: [More Information Needed]\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Sources [optional]\\n\\t\\n\\n\\n\\n\\nRepository: [Moreâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/sadnblueish/quran-cqa.","first_N":5,"first_N_keywords":["question-answering","English","Urdu","Arabic","gpl-3.0"],"keywords_longer_than_N":true},
	{"name":"hijja_splitted","keyword":"arabic","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/shahad-alh/hijja_splitted","creator_name":"shahad alhamili","creator_url":"https://huggingface.co/shahad-alh","description":"shahad-alh/hijja_splitted dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["Arabic","mit","10K - 100K","parquet","Image"],"keywords_longer_than_N":true},
	{"name":"16-million-raw-arabic-words","keyword":"arabic","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ImruQays/16-million-raw-arabic-words","creator_name":"Qays","creator_url":"https://huggingface.co/ImruQays","description":"\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThis dataset contains a collection of 16,052,878 unique Arabic words. These words were extracted from a large corpus of Arabic text originating from two primary sources: the Shamela library and the Hindawi library.\\nKey Characteristics:\\n\\nUnique Words: The dataset is focused on uniqueness. Each entry in the dataset represents a distinct Arabic word, and duplicates have been removed.\\nDiacritic Sensitivity:  Words with different diacritical markings are consideredâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/ImruQays/16-million-raw-arabic-words.","first_N":5,"first_N_keywords":["Arabic","cc-by-4.0","10M - 100M","text","Text"],"keywords_longer_than_N":true},
	{"name":"nahj-al-balagha","keyword":"arabic","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/aliahabeeb/nahj-al-balagha","creator_name":"ALi A. Habeeb","creator_url":"https://huggingface.co/aliahabeeb","description":"Ù†Ù‡Ø¬ Ø§Ù„Ø¨Ù„Ø§ØºØ© ÙˆÙ‡Ùˆ Ù…Ø¬Ù…ÙˆØ¹ Ù…Ø§ Ø§Ø®ØªØ§Ø±Ù‡ Ø§Ù„Ø´Ø±ÙŠÙ Ø§Ù„Ø±Ø¶ÙŠ Ù…Ù† ÙƒÙ„Ø§Ù… Ø³ÙŠØ¯Ù†Ø§ Ø£Ù…ÙŠØ± Ø§Ù„Ù…Ø¤Ù…Ù†ÙŠÙ† Ø¹Ù„ÙŠ Ø¨Ù† Ø£Ø¨ÙŠ Ø·Ø§Ù„Ø¨ Ø¹Ù„ÙŠÙ‡ Ø§Ù„Ø³Ù„Ø§Ù…\\nØ´Ø±Ø­ Ø§Ù„Ø£Ø³ØªØ§Ø° Ø§Ù„Ø¥Ù…Ø§Ù… Ø§Ù„Ø´ÙŠØ® Ù…Ø­Ù…Ø¯ Ø¹Ø¨Ø¯Ø© Ù…ÙØªÙŠ Ø§Ù„Ø¯ÙŠØ§Ø± Ø§Ù„Ù…ØµØ±ÙŠØ© Ø³Ø§Ø¨Ù‚Ø§ Ø§Ù„Ø¬Ø²Ø¡ Ø§Ù„Ø£ÙˆÙ„\\nØ§Ù„Ù†Ø§Ø´Ø± Ø¯Ø§Ø± Ø§Ù„Ù…Ø¹Ø±ÙØ© Ù„Ù„Ø·Ø¨Ø§Ø¹Ø© ÙˆØ§Ù„Ù†Ø´Ø± Ø¨ÙŠØ±ÙˆØª Ù„Ø¨Ù†Ø§Ù†\\n\\n\\t\\n\\t\\t\\n\\t\\tOverview\\n\\t\\n\\nThe Nahj al-Balagha dataset is a structured CSV file containing textual data from the renowned collection of sermons, letters, and maxims attributed to Imam Ali ibn Abi Talib (AS). Compiled by Sharif Razi in the 10th century, this dataset provides aâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/aliahabeeb/nahj-al-balagha.","first_N":5,"first_N_keywords":["Arabic","mit","< 1K","csv","Tabular"],"keywords_longer_than_N":true},
	{"name":"usul-alkafi","keyword":"arabic","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/aliahabeeb/usul-alkafi","creator_name":"ALi A. Habeeb","creator_url":"https://huggingface.co/aliahabeeb","description":"\\n\\t\\n\\t\\t\\n\\t\\tUsul Al-Kafi Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tOverview\\n\\t\\n\\nThis dataset contains the full text of Ø§Ù„Ø£ØµÙˆÙ„ Ù…Ù† Ø§Ù„ÙƒØ§ÙÙŠ, a foundational Islamic book authored by Ø«Ù‚Ø© Ø§Ù„Ø¥Ø³Ù„Ø§Ù… Ø£Ø¨ÙŠ Ø¬Ø¹ÙØ± Ù…Ø­Ù…Ø¯ Ø¨Ù† ÙŠØ¹Ù‚ÙˆØ¨ Ø¨Ù† Ø¥Ø³Ø­Ø§Ù‚ Ø§Ù„ÙƒÙ„ÙŠÙ†ÙŠ Ø§Ù„Ø±Ø§Ø²ÙŠ. Each row in the dataset represents a single page from the book, preserving the original Arabic text structure. The book is divided into eight parts and includes beneficial annotations derived from various commentaries.\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Details\\n\\t\\n\\n\\nVersion: 1.0  \\nSource: Digitized from Darâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/aliahabeeb/usul-alkafi.","first_N":5,"first_N_keywords":["text-classification","text-generation","text-retrieval","summarization","Arabic"],"keywords_longer_than_N":true},
	{"name":"fcube","keyword":"arabic","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Nechba/fcube","creator_name":"nechba mohammed","creator_url":"https://huggingface.co/Nechba","description":"Nechba/fcube dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["feature-extraction","English","Arabic","apache-2.0","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"multilingualcrowspairs","keyword":"arabic","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/FrancophonIA/multilingualcrowspairs","creator_name":"FrancophonIA","creator_url":"https://huggingface.co/FrancophonIA","description":"\\nDataset origin: https://gitlab.inria.fr/corpus4ethics/multilingualcrowspairs/\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tMultiLingualCrowsPairs\\n\\t\\n\\nMultilingual CrowS-Pairs, a challenge dataset for measuring stereotypical biases present in the masked language models (MLMs) in 7 different languages. \\nThis challenge dataset was built on the Crows-Pairs corpus (Nangia et al. 2020) using the methodology described in (NÃ©vÃ©ol et al. 2023). \\nThe 7 new languages are the following:\\n\\nArabic from Maghreb and the Arab world in generalâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/FrancophonIA/multilingualcrowspairs.","first_N":5,"first_N_keywords":["text-classification","multilingual","Arabic","Catalan","German"],"keywords_longer_than_N":true},
	{"name":"Ara-TyDi-Triplet","keyword":"arabic","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/NAMAA-Space/Ara-TyDi-Triplet","creator_name":"Network for Advancing Modern ArabicNLP & AI","creator_url":"https://huggingface.co/NAMAA-Space","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tArabic Mr. TyDi in Triplet Format\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThis dataset is a transformed version of the Arabic subset of the Mr. TyDi dataset, designed specifically for training retrieval and re-ranking models. Each query is paired with a positive passage and one of the multiple negative passages in a triplet format: (query, positive, negative). This restructuring resulted in a total of 362,000 rows, making it ideal for pairwise ranking tasks and contrastive learningâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/NAMAA-Space/Ara-TyDi-Triplet.","first_N":5,"first_N_keywords":["sentence-similarity","feature-extraction","Arabic","apache-2.0","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"parallel_corpus_game_2024","keyword":"arabic","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/bot-yaya/parallel_corpus_game_2024","creator_name":"yaya","creator_url":"https://huggingface.co/bot-yaya","description":"https://github.com/mnbvc-parallel-corpus-team/parallel_corpus_mnbvc\\nMNBVCå¹³è¡Œè¯­æ–™å°ç»„ï¼šæ¸¸æˆè¯­æ–™\\nä¸å®šæœŸæ›´æ–°ï¼Œç›®å‰å·²æ”¶å½•çš„æ¸¸æˆè¯­æ–™æ–‡ä»¶ï¼Œå…±29ä»½ï¼š\\n\\nåšå¾·ä¹‹é—¨3\\nèµ›åšæœ‹å…‹2077\\né»‘æš—ä¹‹é­‚3\\nåº•ç‰¹å¾‹ï¼šåŒ–èº«ä¸ºäºº\\né¥¥è’\\nè‰¾å°”ç™»æ³•çŽ¯\\nåŽŸç¥ž\\né»‘å¸æ–¯\\néœæ ¼æ²ƒå…¹ä¹‹é—\\nIb\\nå¦‚é¾™8\\nå¦‚é¾™7å¤–ä¼ \\nè’é‡Žå¤§é•–å®¢2\\nåªç‹¼ï¼šå½±é€äºŒåº¦\\næ–‡æ˜Ž6\\næ€æˆ®å°–å¡”\\nå´©åæ˜Ÿç©¹é“é“\\nç¾¤æ˜Ÿ\\næ³°æ‹‰ç‘žäºš\\nå·«å¸ˆ3\\né­”å¥³ä¹‹æ³‰3\\né­”å¥³ä¹‹æ³‰R\\né¸£æ½®\\nå¦‚é¾™3\\nå¦‚é¾™4\\nå¦‚é¾™5\\nå¦‚é¾™6\\nå¦‚é¾™æž2\\nå¦‚é¾™7\\n\\n","first_N":5,"first_N_keywords":["translation","Arabic","Chinese","German","English"],"keywords_longer_than_N":true},
	{"name":"aqedah-data","keyword":"arabic","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/abdullah-alamodi/aqedah-data","creator_name":"Abdullah Alamodi","creator_url":"https://huggingface.co/abdullah-alamodi","description":"abdullah-alamodi/aqedah-data dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["Arabic","mit","< 1K","json","Text"],"keywords_longer_than_N":true},
	{"name":"X-ALMA-Preference","keyword":"arabic","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/haoranxu/X-ALMA-Preference","creator_name":"Haoran Xu","creator_url":"https://huggingface.co/haoranxu","description":"This is the translation preference dataset used by X-ALMA.\\nsource: the source sentence.\\nchosen: the preferred translation.\\nreject: the dis-preferred translation.\\ndirections: the translation direction.\\n@misc{xu2024xalmaplugplay,\\n      title={X-ALMA: Plug & Play Modules and Adaptive Rejection for Quality Translation at Scale}, \\n      author={Haoran Xu and Kenton Murray and Philipp Koehn and Hieu Hoang and Akiko Eriguchi and Huda Khayrallah},\\n      year={2024},\\n      eprint={2410.03115}â€¦ See the full description on the dataset page: https://huggingface.co/datasets/haoranxu/X-ALMA-Preference.","first_N":5,"first_N_keywords":["English","Danish","Dutch","German","Icelandic"],"keywords_longer_than_N":true},
	{"name":"question-complexity","keyword":"arabic","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/rokokot/question-complexity","creator_name":"Robin Kokot","creator_url":"https://huggingface.co/rokokot","description":"\\n\\t\\n\\t\\t\\n\\t\\tQuestion Type and Complexity (QTC) Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Overview\\n\\t\\n\\nThe Question Type and Complexity (QTC) dataset is a comprehensive resource for linguistics/NLP research focusing on question classification and linguistic complexity analysis across multiple languages. It contains questions from two distinct sources (TyDi QA and Universal Dependencies v2.15), automatically annotated with question types (polar/content) and a set of linguistic complexity features.\\nKey Features:\\n\\n2â€¦ See the full description on the dataset page: https://huggingface.co/datasets/rokokot/question-complexity.","first_N":5,"first_N_keywords":["text-classification","question-answering","text-scoring","intent-classification","extractive-qa"],"keywords_longer_than_N":true},
	{"name":"BRIGHTER-emotion-intensities","keyword":"arabic","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/brighter-dataset/BRIGHTER-emotion-intensities","creator_name":"BRIGHTER Dataset","creator_url":"https://huggingface.co/brighter-dataset","description":"\\n\\t\\n\\t\\t\\n\\t\\tBRIGHTER Emotion Intensities Dataset\\n\\t\\n\\nThis dataset contains the emotion intensities data from the BRIGHTER paper: BRIdging the Gap in Human-Annotated Textual Emotion Recognition Datasets for 28 Languages.\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThe BRIGHTER Emotion Intensities dataset is a comprehensive multi-language emotion intensity dataset with separate configurations for each language. It represents one of the largest human-annotated emotion datasets across multiple languages, providingâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/brighter-dataset/BRIGHTER-emotion-intensities.","first_N":5,"first_N_keywords":["Arabic","German","English","Spanish","Hausa"],"keywords_longer_than_N":true},
	{"name":"semeval-2025-task11-track-a","keyword":"arabic","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/vgaraujov/semeval-2025-task11-track-a","creator_name":"Vladimir Araujo","creator_url":"https://huggingface.co/vgaraujov","description":"\\n\\t\\n\\t\\t\\n\\t\\tSemEval 2025 Task 11 - Track A Dataset\\n\\t\\n\\nThis dataset contains the data for SemEval 2025 Task 11: Bridging the Gap in Text-Based Emotion Detection - Track A, organized as language-specific configurations.\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThe dataset is a multi-language, multi-label emotion classification dataset with separate configurations for each language.\\n\\nTotal languages: 26 standard ISO codes\\nTotal examples: 115159\\nSplits: train, dev, test\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tLanguage Configurations\\n\\t\\n\\nEachâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/vgaraujov/semeval-2025-task11-track-a.","first_N":5,"first_N_keywords":["Afrikaans","Amharic","Arabic","German","English"],"keywords_longer_than_N":true},
	{"name":"semeval-2025-task11-track-c","keyword":"arabic","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/vgaraujov/semeval-2025-task11-track-c","creator_name":"Vladimir Araujo","creator_url":"https://huggingface.co/vgaraujov","description":"\\n\\t\\n\\t\\t\\n\\t\\tSemEval 2025 Task 11 - Track C Dataset\\n\\t\\n\\nThis dataset contains the data for SemEval 2025 Task 11: Bridging the Gap in Text-Based Emotion Detection - Track C, organized as language-specific configurations.\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThe dataset is a multi-language, multi-label emotion classification dataset with separate configurations for each language.\\n\\nTotal languages: 30 standard ISO codes\\nTotal examples: 57254\\nSplits: dev, test (Track C has no train split)\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tTrackâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/vgaraujov/semeval-2025-task11-track-c.","first_N":5,"first_N_keywords":["Afrikaans","Amharic","Arabic","German","English"],"keywords_longer_than_N":true},
	{"name":"Tamazight-Speech-to-Arabic-Text","keyword":"arabic","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/EMINES/Tamazight-Speech-to-Arabic-Text","creator_name":"EMINES, UM6P, Benguerir, Maroc","creator_url":"https://huggingface.co/EMINES","description":"\\n\\t\\n\\t\\t\\n\\t\\tTamazight-Arabic Speech Recognition Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tOverview\\n\\t\\n\\nThis is the EMINES organization-hosted version of the Tamazight-Arabic Speech Recognition Dataset, synchronized with the original dataset. It contains ~15.5 hours of Tamazight speech (Tachelhit dialect) paired with Arabic transcriptions, designed for developing ASR and translation systems.\\n\\n\\t\\n\\t\\t\\n\\t\\tQuick Start\\n\\t\\n\\nfrom datasets import load_dataset\\n\\n# Load the dataset\\ndataset =â€¦ See the full description on the dataset page: https://huggingface.co/datasets/EMINES/Tamazight-Speech-to-Arabic-Text.","first_N":5,"first_N_keywords":["automatic-speech-recognition","Arabic","Standard Moroccan Tamazight","apache-2.0","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"Tamazight-Speech-to-Arabic-Text","keyword":"arabic","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/EMINES/Tamazight-Speech-to-Arabic-Text","creator_name":"EMINES, UM6P, Benguerir, Maroc","creator_url":"https://huggingface.co/EMINES","description":"\\n\\t\\n\\t\\t\\n\\t\\tTamazight-Arabic Speech Recognition Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tOverview\\n\\t\\n\\nThis is the EMINES organization-hosted version of the Tamazight-Arabic Speech Recognition Dataset, synchronized with the original dataset. It contains ~15.5 hours of Tamazight speech (Tachelhit dialect) paired with Arabic transcriptions, designed for developing ASR and translation systems.\\n\\n\\t\\n\\t\\t\\n\\t\\tQuick Start\\n\\t\\n\\nfrom datasets import load_dataset\\n\\n# Load the dataset\\ndataset =â€¦ See the full description on the dataset page: https://huggingface.co/datasets/EMINES/Tamazight-Speech-to-Arabic-Text.","first_N":5,"first_N_keywords":["automatic-speech-recognition","Arabic","Standard Moroccan Tamazight","apache-2.0","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"Arabic_Reasoning_Instruct_QA","keyword":"arabic","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/MohammedNasser/Arabic_Reasoning_Instruct_QA","creator_name":"Mohammed Nasser Gaber","creator_url":"https://huggingface.co/MohammedNasser","description":"MohammedNasser/Arabic_Reasoning_Instruct_QA dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["question-answering","text2text-generation","Arabic","apache-2.0","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"Tunisian_Language_Dataset","keyword":"arabic","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/AzizBelaweid/Tunisian_Language_Dataset","creator_name":"Aziz Belaweid","creator_url":"https://huggingface.co/AzizBelaweid","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Tunisian Text Compilation\\n\\t\\n\\nThis dataset is a curated compilation of various Tunisian datasets, aimed at gathering as much Tunisian text data as possible in one place. It combines multiple sources of Tunisian language data, providing a rich resource for research, development of NLP models, and linguistic studies on Tunisian text.\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Details\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThis dataset aggregates several publicly available datasets thatâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/AzizBelaweid/Tunisian_Language_Dataset.","first_N":5,"first_N_keywords":["text-generation","Arabic","French","English","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"kurage_training_data","keyword":"arabic","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/lightblue/kurage_training_data","creator_name":"Lightblue KK.","creator_url":"https://huggingface.co/lightblue","description":"lightblue/kurage_training_data dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["Arabic","English","Spanish","Hindi","Indonesian"],"keywords_longer_than_N":true},
	{"name":"Arabic_Openai_MMMLU","keyword":"arabic","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Omartificial-Intelligence-Space/Arabic_Openai_MMMLU","creator_name":"Omartificial Intelligence Space","creator_url":"https://huggingface.co/Omartificial-Intelligence-Space","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tArabic Multilingual Massive Multitask Language Understanding (MMMLU)\\n\\t\\n\\nThe MMLU is a widely recognized benchmark for assessing general knowledge attained by AI models. It covers a broad range of topics across 57 different categories, from elementary-level knowledge to advanced professional subjects like law, physics, history, and computer science.\\nWe have extracted the Arabic subset from the MMMLU test set, which was translated by professional human translators. This dataset, nowâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Omartificial-Intelligence-Space/Arabic_Openai_MMMLU.","first_N":5,"first_N_keywords":["question-answering","Arabic","mit","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"Arabic_Openai_MMMLU","keyword":"arabic","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Omartificial-Intelligence-Space/Arabic_Openai_MMMLU","creator_name":"Omartificial Intelligence Space","creator_url":"https://huggingface.co/Omartificial-Intelligence-Space","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tArabic Multilingual Massive Multitask Language Understanding (MMMLU)\\n\\t\\n\\nThe MMLU is a widely recognized benchmark for assessing general knowledge attained by AI models. It covers a broad range of topics across 57 different categories, from elementary-level knowledge to advanced professional subjects like law, physics, history, and computer science.\\nWe have extracted the Arabic subset from the MMMLU test set, which was translated by professional human translators. This dataset, nowâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Omartificial-Intelligence-Space/Arabic_Openai_MMMLU.","first_N":5,"first_N_keywords":["question-answering","Arabic","mit","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"IUG_eLearning_Collections","keyword":"arabic","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/abdullah/IUG_eLearning_Collections","creator_name":"Abdullah Abdelrhim","creator_url":"https://huggingface.co/abdullah","description":"\\n## ÙˆØµÙ Ù…Ø¬Ù…ÙˆØ¹Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tÙ†Ø¸Ø±Ø© Ø¹Ø§Ù…Ø©\\n\\t\\n\\nØªØ­ØªÙˆÙŠ Ù‡Ø°Ù‡ Ø§Ù„Ù…Ø¬Ù…ÙˆØ¹Ø© Ø¹Ù„Ù‰ Ø¨ÙŠØ§Ù†Ø§Øª Ø­ÙˆÙ„ Ø§Ù„Ù…Ù‚Ø±Ø±Ø§Øª ÙˆØ§Ù„Ù…Ø¤ØªÙ…Ø±Ø§Øª Ø§Ù„Ù…ØªØ§Ø­Ø© Ø¹Ù„Ù‰ Ù…Ù†ØµØ© Ø§Ù„ØªØ¹Ù„Ù… Ø§Ù„Ø¥Ù„ÙƒØªØ±ÙˆÙ†ÙŠ Ø¨Ù…Ø±ÙƒØ² Ø§Ù„ØªØ¹Ù„Ù… Ø§Ù„Ø¥Ù„ÙƒØªØ±ÙˆÙ†ÙŠ [Ø§Ù„Ø¬Ø§Ù…Ø¹Ø© Ø§Ù„Ø¥Ø³Ù„Ø§Ù…ÙŠØ© Ø¨ØºØ²Ø© ]. ÙŠÙ…ÙƒÙ† Ø§Ø³ØªØ®Ø¯Ø§Ù… Ù‡Ø°Ù‡ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø§ØªØ¬Ø§Ù‡Ø§Øª ÙÙŠ Ù…Ø¬Ø§Ù„ Ø§Ù„ØªØ¹Ù„Ù… Ø§Ù„Ø¥Ù„ÙƒØªØ±ÙˆÙ†ÙŠØŒ ÙˆØªØ·ÙˆÙŠØ± ØªÙˆØµÙŠØ§Øª Ù…Ø®ØµØµØ© Ù„Ù„Ù…Ø³ØªØ®Ø¯Ù…ÙŠÙ†ØŒ ÙˆØ¨Ù†Ø§Ø¡ Ù†Ù…Ø§Ø°Ø¬ ØªÙ†Ø¨Ø¤ÙŠØ© Ù„Ø­Ø¶ÙˆØ± Ø§Ù„Ø¯ÙˆØ±Ø§Øª.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tÙ‡ÙŠÙƒÙ„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª\\n\\t\\n\\n\\nsource_id:  Ù…Ø¹Ø±Ù ÙØ±ÙŠØ¯ Ù„Ù‚Ø§Ø¦Ù…Ø© ØªØ´ØºÙŠÙ„ Ø¹Ù„Ù‰  Ù…ÙˆÙ‚Ø¹ ÙŠÙˆØªÙŠÙˆØ¨ .\\ntitle: Ø¹Ù†ÙˆØ§Ù† Ø§Ù„Ù…Ù‚Ø±Ø±Ø§Øª Ø£Ùˆ Ø§Ù„Ù…Ø¤ØªÙ…Ø±.\\nfaculty_name: Ø§Ø³Ù… Ø§Ù„ÙƒÙ„ÙŠØ©.\\ninstructor: Ø§Ø³Ù… Ø§Ù„Ù…Ø­Ø§Ø¶Ø±.â€¦ See the full description on the dataset page: https://huggingface.co/datasets/abdullah/IUG_eLearning_Collections.","first_N":5,"first_N_keywords":["table-question-answering","Arabic","mit","< 1K","csv"],"keywords_longer_than_N":true},
	{"name":"PangeaBench-tydiqa","keyword":"arabic","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/neulab/PangeaBench-tydiqa","creator_name":"NeuLab @ LTI/CMU","creator_url":"https://huggingface.co/neulab","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for \\\"tydiqa\\\"\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nTyDi QA is a question answering dataset covering 11 typologically diverse languages with 204K question-answer pairs.\\nThe languages of TyDi QA are diverse with regard to their typology -- the set of linguistic features that each language\\nexpresses -- such that we expect models performing well on this set to generalize across a large number of the languages\\nin the world. It contains language phenomena that would not be foundâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/neulab/PangeaBench-tydiqa.","first_N":5,"first_N_keywords":["question-answering","extractive-qa","crowdsourced","crowdsourced","multilingual"],"keywords_longer_than_N":true},
	{"name":"mc-translation","keyword":"arabic","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/efederici/mc-translation","creator_name":"Edoardo Federici","creator_url":"https://huggingface.co/efederici","description":"This dataset contains professional human translations from OpenAI's MMMLU dataset, repurposed to train translation models that can help translate future evaluation datasets.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tWhy This Dataset?\\n\\t\\n\\nTranslation of evaluation benchmarks is a critical but challenging task. While automated translations may introduce errors or biases, professional human translations are expensive and time-consuming. This dataset leverages existing professional translations (MMMLU) to train specializedâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/efederici/mc-translation.","first_N":5,"first_N_keywords":["translation","English","Swahili","Spanish","German"],"keywords_longer_than_N":true},
	{"name":"COVID-19-disinformation","keyword":"arabic","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/QCRI/COVID-19-disinformation","creator_name":"Arabic Language Technologies, Qatar Computing Research Institute","creator_url":"https://huggingface.co/QCRI","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tCOVID-19 Infodemic Multilingual Dataset\\n\\t\\n\\nThis repository contains a multilingual dataset related to the COVID-19 infodemic, annotated with fine-grained labels. The dataset is curated to address questions of interest to journalists, fact-checkers, social media platforms, policymakers, and the general public. The dataset includes tweets in Arabic, Bulgarian, Dutch, and English, focusing on both binary (misinformation detection) and multiclass classification (different types ofâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/QCRI/COVID-19-disinformation.","first_N":5,"first_N_keywords":["text-classification","Arabic","Bulgarian","Dutch","English"],"keywords_longer_than_N":true},
	{"name":"araspider","keyword":"arabic","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/ahmedheakl/araspider","creator_name":"Ahmed Heakl","creator_url":"https://huggingface.co/ahmedheakl","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for \\\"araspider\\\"\\n\\t\\n\\nMore Information needed\\n","first_N":5,"first_N_keywords":["Arabic","mit","1K - 10K","parquet","Text"],"keywords_longer_than_N":true},
	{"name":"quran-riwayat","keyword":"arabic","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Abdou/quran-riwayat","creator_name":"Rockikz","creator_url":"https://huggingface.co/Abdou","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tØ±ÙˆØ§ÙŠØ§Øª Ø§Ù„Ù‚Ø±Ø¢Ù† Ø§Ù„ÙƒØ±ÙŠÙ…\\n\\t\\n\\nThis dataset is a collection of 8 Riwayat (of 4 Qira'at) of the Quran:\\n\\nhafs: Ø±ÙˆØ§ÙŠØ© Ø­ÙØµ Ø¹Ù† Ø¹Ø§ØµÙ…\\nshouba: Ø±ÙˆØ§ÙŠØ© Ø´Ø¹Ø¨Ø© Ø¹Ù† Ø¹Ø§ØµÙ…\\nwarsh: Ø±ÙˆØ§ÙŠØ© ÙˆØ±Ø´ Ø¹Ù† Ù†Ø§ÙØ¹\\nqaloon: Ø±ÙˆØ§ÙŠØ© Ù‚Ø§Ù„ÙˆÙ† Ø¹Ù† Ù†Ø§ÙØ¹\\nalsosi: Ø±ÙˆØ§ÙŠØ© Ø§Ù„Ø³ÙˆØ³ÙŠ Ø¹Ù† Ø£Ø¨ÙŠ Ø¹Ù…Ø±Ùˆ Ø§Ù„Ø¨ØµØ±ÙŠ\\naldoori: Ø±ÙˆØ§ÙŠØ© Ø§Ù„Ø¯ÙˆØ±ÙŠ Ø¹Ù† Ø£Ø¨ÙŠ Ø¹Ù…Ø±Ùˆ Ø§Ù„Ø¨ØµØ±ÙŠ\\nqumbul: Ø±ÙˆØ§ÙŠØ© Ù‚Ù†Ø¨Ù„ Ø¹Ù† Ø§Ø¨Ù† ÙƒØ«ÙŠØ± Ø§Ù„Ù…ÙƒÙŠ\\nalbazzi: Ø±ÙˆØ§ÙŠØ© Ø§Ù„Ø¨Ø²ÙŠ Ø¹Ù† Ø§Ø¨Ù† ÙƒØ«ÙŠØ± Ø§Ù„Ù…ÙƒÙŠ\\n\\nScraped from https://surahquran.com/ , so thanks to them!\\n","first_N":5,"first_N_keywords":["Arabic","mit","< 1K","parquet","Text"],"keywords_longer_than_N":true},
	{"name":"product-database","keyword":"arabic","license":"GNU Affero General Public License v3.0","license_url":"https://choosealicense.com/licenses/agpl-3.0/","language":"en","dataset_url":"https://huggingface.co/datasets/openfoodfacts/product-database","creator_name":"Open Food Facts","creator_url":"https://huggingface.co/openfoodfacts","description":"\\n\\t\\n\\t\\t\\n\\t\\tOpen Food Facts Database\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tWhat is ðŸŠ Open Food Facts?\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tA food products database\\n\\t\\n\\nOpen Food Facts is a database of food products with ingredients, allergens, nutrition facts and all the tidbits of information we can find on product labels.\\n\\n\\t\\n\\t\\t\\n\\t\\tMade by everyone\\n\\t\\n\\nOpen Food Facts is a non-profit association of volunteers. 25.000+ contributors like you have added 1.7 million + products from 150 countries using our Android or iPhone app or their camera to scanâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/openfoodfacts/product-database.","first_N":5,"first_N_keywords":["English","French","German","Spanish","Italian"],"keywords_longer_than_N":true},
	{"name":"SemEval2024-task8","keyword":"arabic","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/d0rj/SemEval2024-task8","creator_name":"Dmitry Balobin","creator_url":"https://huggingface.co/d0rj","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSemEval2024-task8\\n\\t\\n\\nUnofficial mirror of M4 dataset from mbzuai-nlp/SemEval2024-task8 (website, github, codabench).\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Format\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSubtask A\\n\\t\\n\\nAn object in the JSON format:\\n{\\n  id -> identifier of the example,\\n  label -> label (human text: 0, machine text: 1,),\\n  text -> text generated by a machine or written by a human,\\n  model -> model that generated the data,\\n  source -> source (Wikipedia, Wikihow, Peerread, Reddit, Arxiv)  on English or languageâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/d0rj/SemEval2024-task8.","first_N":5,"first_N_keywords":["text-classification","original","English","Arabic","German"],"keywords_longer_than_N":true},
	{"name":"test_4","keyword":"arabic","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/tunngo/test_4","creator_name":"nguyen tuan","creator_url":"https://huggingface.co/tunngo","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tFLEURS\\n\\t\\n\\nFleurs is the speech version of the FLoRes machine translation benchmark. \\nWe use 2009 n-way parallel sentences from the FLoRes dev and devtest publicly available sets, in 102 languages. \\nTraining sets have around 10 hours of supervision. Speakers of the train sets are different than speakers from the dev/test sets. Multilingual fine-tuning is\\nused and â€unit error rateâ€ (characters, signs) of all languages is averaged. Languages and results are also grouped into sevenâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/tunngo/test_4.","first_N":5,"first_N_keywords":["automatic-speech-recognition","expert-generated","crowdsourced","machine-generated","crowdsourced"],"keywords_longer_than_N":true},
	{"name":"Arabic-Reranking-Triplet-5-Eval","keyword":"arabic","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/NAMAA-Space/Arabic-Reranking-Triplet-5-Eval","creator_name":"Network for Advancing Modern ArabicNLP & AI","creator_url":"https://huggingface.co/NAMAA-Space","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tArabic Reranking Evaluation Dataset with Multiple Negatives\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Overview\\n\\t\\n\\nThis dataset, containing 500 rows, is curated for evaluating reranking and retrieval models in Arabic. It covers various topics, including artificial intelligence, machine learning, data analysis, technology, and education, featuring a range of query complexities and document lengths. The dataset aims to support the development and benchmarking of Arabic language models that rankâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/NAMAA-Space/Arabic-Reranking-Triplet-5-Eval.","first_N":5,"first_N_keywords":["text-classification","Arabic","apache-2.0","< 1K","parquet"],"keywords_longer_than_N":true},
	{"name":"linto-dataset-audio-ar-tn-augmented","keyword":"arabic","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/linagora/linto-dataset-audio-ar-tn-augmented","creator_name":"LINAGORA Labs","creator_url":"https://huggingface.co/linagora","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLinTO DataSet Audio for Arabic Tunisian Augmented A collection of Tunisian dialect audio and its annotations for STT task\\n\\t\\n\\nThis is the augmented datasets used to train the Linto Tunisian dialect with code-switching STT linagora/linto-asr-ar-tn.\\n\\nDataset Summary\\nDataset composition\\nSources\\nContent Types\\nLanguages and Dialects\\n\\n\\nExample use (python)\\nLicense\\nCitations\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThe LinTO DataSet Audio for Arabic Tunisian Augmented is a dataset that builds onâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/linagora/linto-dataset-audio-ar-tn-augmented.","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","text-to-audio","Arabic","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"sada2022","keyword":"arabic","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/m6011/sada2022","creator_name":"mohammed alharbi","creator_url":"https://huggingface.co/m6011","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for SADA - Saudi Audio Dataset for Arabic\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Details\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThe SADA (Saudi Audio Dataset for Arabic) is a comprehensive dataset consisting of audio recordings from over 57 TV shows aired by the Saudi Broadcasting Authority (SBA). The dataset contains approximately 667 hours of audio data with transcripts, the majority of which are in various Saudi dialects (Najdi, Hijazi, Khaliji, etc.). \\n\\nCurated by: The Nationalâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/m6011/sada2022.","first_N":5,"first_N_keywords":["Arabic","cc-by-4.0","1K - 10K","parquet","Audio"],"keywords_longer_than_N":true},
	{"name":"ILMAAM-Arabic-Culturally-Aligned-MMLU","keyword":"arabic","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Omartificial-Intelligence-Space/ILMAAM-Arabic-Culturally-Aligned-MMLU","creator_name":"Omartificial Intelligence Space","creator_url":"https://huggingface.co/Omartificial-Intelligence-Space","description":"\\n\\t\\n\\t\\t\\n\\t\\tILMAAM Arabic Culturally Aligned MMLU Benchmark\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tOverview\\n\\t\\n\\nThe ILMAAM (Index for Language Models for Arabic Assessment on Multitasks) benchmark provides a culturally enriched, linguistically refined, and contextually relevant evaluation framework for Arabic Large Language Models (LLMs). It is based on the Arabic Massive Multitask Language Understanding (MMLU) dataset but extends it with culturally aligned topics and annotations for fluency, adequacy, culturalâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Omartificial-Intelligence-Space/ILMAAM-Arabic-Culturally-Aligned-MMLU.","first_N":5,"first_N_keywords":["Arabic","apache-2.0","10K - 100K","csv","Text"],"keywords_longer_than_N":true},
	{"name":"ILMAAM-Arabic-Culturally-Aligned-MMLU","keyword":"arabic","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Omartificial-Intelligence-Space/ILMAAM-Arabic-Culturally-Aligned-MMLU","creator_name":"Omartificial Intelligence Space","creator_url":"https://huggingface.co/Omartificial-Intelligence-Space","description":"\\n\\t\\n\\t\\t\\n\\t\\tILMAAM Arabic Culturally Aligned MMLU Benchmark\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tOverview\\n\\t\\n\\nThe ILMAAM (Index for Language Models for Arabic Assessment on Multitasks) benchmark provides a culturally enriched, linguistically refined, and contextually relevant evaluation framework for Arabic Large Language Models (LLMs). It is based on the Arabic Massive Multitask Language Understanding (MMLU) dataset but extends it with culturally aligned topics and annotations for fluency, adequacy, culturalâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Omartificial-Intelligence-Space/ILMAAM-Arabic-Culturally-Aligned-MMLU.","first_N":5,"first_N_keywords":["Arabic","apache-2.0","10K - 100K","csv","Text"],"keywords_longer_than_N":true},
	{"name":"AURA-Classification","keyword":"arabic","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/irfan-ahmad/AURA-Classification","creator_name":"Irfan Ahmad","creator_url":"https://huggingface.co/irfan-ahmad","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tAURA-Classification\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThe AURA (App User Review in Arabic) Classification dataset is a collection of 2,900 Arabic-language app reviews collected from various mobile applications. This dataset is primarily designed for text classification tasks.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tFeatures\\n\\t\\n\\nThe dataset includes the following fields:\\n\\nreview: The text of the review in Arabic.\\n\\nappName: The name of the application being reviewed.\\n\\nplatform: The platform (iOS or Android)â€¦ See the full description on the dataset page: https://huggingface.co/datasets/irfan-ahmad/AURA-Classification.","first_N":5,"first_N_keywords":["Arabic","mit","1K - 10K","parquet","Text"],"keywords_longer_than_N":true},
	{"name":"AURA-Classification","keyword":"arabic","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/irfan-ahmad/AURA-Classification","creator_name":"Irfan Ahmad","creator_url":"https://huggingface.co/irfan-ahmad","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tAURA-Classification\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThe AURA (App User Review in Arabic) Classification dataset is a collection of 2,900 Arabic-language app reviews collected from various mobile applications. This dataset is primarily designed for text classification tasks.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tFeatures\\n\\t\\n\\nThe dataset includes the following fields:\\n\\nreview: The text of the review in Arabic.\\n\\nappName: The name of the application being reviewed.\\n\\nplatform: The platform (iOS or Android)â€¦ See the full description on the dataset page: https://huggingface.co/datasets/irfan-ahmad/AURA-Classification.","first_N":5,"first_N_keywords":["Arabic","mit","1K - 10K","parquet","Text"],"keywords_longer_than_N":true},
	{"name":"llm-ideology-analysis","keyword":"arabic","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/aida-ugent/llm-ideology-analysis","creator_name":"Ghent University Artificial Intelligence & Data Analytics Group","creator_url":"https://huggingface.co/aida-ugent","description":"This dataset contains evaluations of political figures by a diverse set of Large Language Models (LLMs), such that the ideology of these LLMs can be characterized.\\n\\n\\t\\n\\t\\t\\n\\t\\tðŸ“ Dataset Description\\n\\t\\n\\nThe dataset contains responses from 19 different Large Language Models evaluating 3,991 political figures, with responses collected in the six UN languages: Arabic, Chinese, English, French, Russian, and Spanish. \\nThe evaluations were conducted using a two-stage prompting strategy to assess theâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/aida-ugent/llm-ideology-analysis.","first_N":5,"first_N_keywords":["Arabic","Chinese","English","French","Spanish"],"keywords_longer_than_N":true},
	{"name":"recitation-segmentation","keyword":"arabic","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/obadx/recitation-segmentation","creator_name":"Abdullah","creator_url":"https://huggingface.co/obadx","description":"\\n\\t\\n\\t\\t\\n\\t\\tRecitation Segmentation Dataset\\n\\t\\n\\nThis dataset is aiming to build a model that aplit the Holy Quran recitations using puase (ÙˆÙ‚Ù).\\n\\n\\t\\n\\t\\t\\n\\t\\tTODO\\n\\t\\n\\n\\nfull description\\nfeature description\\n\\n","first_N":5,"first_N_keywords":["Arabic","mit","10K - 100K","parquet","Tabular"],"keywords_longer_than_N":true},
	{"name":"quran-tafseer-qurancom","keyword":"arabic","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/gurgutan/quran-tafseer-qurancom","creator_name":"Ð˜Ð²Ð°Ð½ Ð˜Ð²Ð°Ð½Ð¾Ð²Ð¸Ñ‡ Ð¡Ð»ÐµÐ¿Ð¾Ð²Ð¸Ñ‡ÐµÐ²","creator_url":"https://huggingface.co/gurgutan","description":"\\n\\t\\n\\t\\t\\n\\t\\tQuran and Tafseer Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThis dataset contains verses from the Quran along with their tafseer (interpretation/explanation).\\nIt includes both the original Arabic text and translations, as well as detailed tafseer from scholars.\\nThe dataset is useful for Islamic studies, NLP tasks related to religious texts, and cross-lingual research.\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Structure\\n\\t\\n\\nThe dataset contains Quran verses along with their tafseer (interpretation/explanation).â€¦ See the full description on the dataset page: https://huggingface.co/datasets/gurgutan/quran-tafseer-qurancom.","first_N":5,"first_N_keywords":["question-answering","Arabic","English","mit","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"sunnah_ar_en_dataset","keyword":"arabic","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/gurgutan/sunnah_ar_en_dataset","creator_name":"Ð˜Ð²Ð°Ð½ Ð˜Ð²Ð°Ð½Ð¾Ð²Ð¸Ñ‡ Ð¡Ð»ÐµÐ¿Ð¾Ð²Ð¸Ñ‡ÐµÐ²","creator_url":"https://huggingface.co/gurgutan","description":"\\n\\t\\n\\t\\t\\n\\t\\tDataset Card for Dataset Name\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Card for Hadiths 14 Books Collection\\n\\t\\n\\nThis dataset contains a comprehensive bilingual (Arabic-English) collection of hadiths from 14 major authenticated books of Islamic tradition. It includes over 50762 narrations with complete metadata, organized by book, chapter, and narrator. Each hadith is presented in both its original Arabic text and English translation, making it ideal for cross-lingual NLP tasks, Islamic question-answeringâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/gurgutan/sunnah_ar_en_dataset.","first_N":5,"first_N_keywords":["translation","question-answering","English","Arabic","mit"],"keywords_longer_than_N":true},
	{"name":"semeval-2025-task11-track-b","keyword":"arabic","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/vgaraujov/semeval-2025-task11-track-b","creator_name":"Vladimir Araujo","creator_url":"https://huggingface.co/vgaraujov","description":"\\n\\t\\n\\t\\t\\n\\t\\tSemEval 2025 Task 11 - Track B Dataset\\n\\t\\n\\nThis dataset contains the data for SemEval 2025 Task 11: Bridging the Gap in Text-Based Emotion Detection - Track B, organized as language-specific configurations.\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThe dataset is a multi-language, multi-label emotion classification dataset with separate configurations for each language.\\n\\nTotal languages: 11 standard ISO codes\\nTotal examples: 47111\\nSplits: train, dev, test\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tTrack Information\\n\\t\\n\\nTrack B hasâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/vgaraujov/semeval-2025-task11-track-b.","first_N":5,"first_N_keywords":["Amharic","Arabic","German","English","Spanish"],"keywords_longer_than_N":true},
	{"name":"summarized-darija-msa-wiki-data","keyword":"arabic","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/EMINES/summarized-darija-msa-wiki-data","creator_name":"EMINES, UM6P, Benguerir, Maroc","creator_url":"https://huggingface.co/EMINES","description":"\\n\\t\\n\\t\\t\\n\\t\\tMSA-Darija Summarization Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tOverview\\n\\t\\n\\nThis is the EMINES organization-hosted version of the MSA-Darija Summarization Dataset, synchronized with the original dataset. It contains 4800 rows of Moroccan and Arabic texts with Arabic summarization, designed for developing summarization models.\\n\\n\\t\\n\\t\\t\\n\\t\\tQuick Start\\n\\t\\n\\nfrom datasets import load_dataset\\n\\n# Load the dataset\\ndataset = load_dataset(\\\"EMINES/summarized-darija-msa-wiki-data\\\")\\n\\n# Example usage\\nfor example inâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/EMINES/summarized-darija-msa-wiki-data.","first_N":5,"first_N_keywords":["summarization","Arabic","apache-2.0","1K - 10K","parquet"],"keywords_longer_than_N":true},
	{"name":"summarized-darija-msa-wiki-data","keyword":"arabic","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/EMINES/summarized-darija-msa-wiki-data","creator_name":"EMINES, UM6P, Benguerir, Maroc","creator_url":"https://huggingface.co/EMINES","description":"\\n\\t\\n\\t\\t\\n\\t\\tMSA-Darija Summarization Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tOverview\\n\\t\\n\\nThis is the EMINES organization-hosted version of the MSA-Darija Summarization Dataset, synchronized with the original dataset. It contains 4800 rows of Moroccan and Arabic texts with Arabic summarization, designed for developing summarization models.\\n\\n\\t\\n\\t\\t\\n\\t\\tQuick Start\\n\\t\\n\\nfrom datasets import load_dataset\\n\\n# Load the dataset\\ndataset = load_dataset(\\\"EMINES/summarized-darija-msa-wiki-data\\\")\\n\\n# Example usage\\nfor example inâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/EMINES/summarized-darija-msa-wiki-data.","first_N":5,"first_N_keywords":["summarization","Arabic","apache-2.0","1K - 10K","parquet"],"keywords_longer_than_N":true},
	{"name":"resmo1","keyword":"arabic","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/aibrahiam/resmo1","creator_name":"Ahmed Ibrahim","creator_url":"https://huggingface.co/aibrahiam","description":"aibrahiam/resmo1 dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["Arabic","apache-2.0","< 1K","json","Text"],"keywords_longer_than_N":true},
	{"name":"iraqi_test_set","keyword":"arabic","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/otozz/iraqi_test_set","creator_name":"Ã–mer","creator_url":"https://huggingface.co/otozz","description":"Pre-processed Iraqi test partition from the MASC-dataset:\\nMohammad Al-Fetyani, Muhammad Al-Barham, Gheith Abandah, Adham Alsharkawi, Maha Dawas, August 18, 2021, \\\"MASC: Massive Arabic Speech Corpus\\\", IEEE Dataport, doi: https://dx.doi.org/10.21227/e1qb-jv46.\\n","first_N":5,"first_N_keywords":["Arabic","cc-by-4.0","1K - 10K","parquet","Datasets"],"keywords_longer_than_N":true},
	{"name":"levantine_train_set","keyword":"arabic","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/otozz/levantine_train_set","creator_name":"Ã–mer","creator_url":"https://huggingface.co/otozz","description":"Pre-processed Levantine train partition from the MASC-dataset:\\nMohammad Al-Fetyani, Muhammad Al-Barham, Gheith Abandah, Adham Alsharkawi, Maha Dawas, August 18, 2021, \\\"MASC: Massive Arabic Speech Corpus\\\", IEEE Dataport, doi: https://dx.doi.org/10.21227/e1qb-jv46.\\n","first_N":5,"first_N_keywords":["Arabic","cc-by-4.0","10K - 100K","parquet","Datasets"],"keywords_longer_than_N":true},
	{"name":"maghrebi_test_set","keyword":"arabic","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/otozz/maghrebi_test_set","creator_name":"Ã–mer","creator_url":"https://huggingface.co/otozz","description":"Pre-processed Maghrebi test partition from the MASC-dataset:\\nMohammad Al-Fetyani, Muhammad Al-Barham, Gheith Abandah, Adham Alsharkawi, Maha Dawas, August 18, 2021, \\\"MASC: Massive Arabic Speech Corpus\\\", IEEE Dataport, doi: https://dx.doi.org/10.21227/e1qb-jv46.\\n","first_N":5,"first_N_keywords":["Arabic","cc-by-4.0","1K - 10K","parquet","Datasets"],"keywords_longer_than_N":true},
	{"name":"MSA_train_set","keyword":"arabic","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/otozz/MSA_train_set","creator_name":"Ã–mer","creator_url":"https://huggingface.co/otozz","description":"Pre-processed MSA data based on https://huggingface.co/datasets/mozilla-foundation/common_voice_16_1.\\n","first_N":5,"first_N_keywords":["Arabic","cc0-1.0","10K - 100K","parquet","Audio"],"keywords_longer_than_N":true},
	{"name":"BenchMAX_Question_Answering","keyword":"arabic","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/LLaMAX/BenchMAX_Question_Answering","creator_name":"LLaMAX","creator_url":"https://huggingface.co/LLaMAX","description":"\\n\\t\\n\\t\\t\\n\\t\\tDataset Sources\\n\\t\\n\\n\\nPaper: BenchMAX: A Comprehensive Multilingual Evaluation Suite for Large Language Models\\nLink: https://arxiv.org/pdf/2502.07346\\nRepository: https://github.com/CONE-MT/BenchMAX\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\nBenchMAX_Function_Completion is a dataset of BenchMAX, sourcing from UN Parallel Corpus and xquad.\\nThe haystacks are from UN Parallel Corpus Test and Development Sets and we translate them to other languages by Google Translate.\\nThe multilingual QA data is fromâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/LLaMAX/BenchMAX_Question_Answering.","first_N":5,"first_N_keywords":["text-generation","multilingual","English","Chinese","Spanish"],"keywords_longer_than_N":true},
	{"name":"genius-video","keyword":"arabic","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/sleeping-ai/genius-video","creator_name":"Sleeping AI","creator_url":"https://huggingface.co/sleeping-ai","description":"sleeping-ai/genius-video dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["English","Japanese","Arabic","Russian","mit"],"keywords_longer_than_N":true},
	{"name":"AI_Questions_Dataset_","keyword":"arabic","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/karamkaram/AI_Questions_Dataset_","creator_name":"kkk","creator_url":"https://huggingface.co/karamkaram","description":"karamkaram/AI_Questions_Dataset_ dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["question-answering","Arabic","cc-by-sa-4.0","1K - 10K","json"],"keywords_longer_than_N":true},
	{"name":"M-ABSA","keyword":"arabic","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Multilingual-NLP/M-ABSA","creator_name":"multilingual-NLP","creator_url":"https://huggingface.co/Multilingual-NLP","description":"\\n\\t\\n\\t\\t\\n\\t\\tM-ABSA\\n\\t\\n\\nThis repo contains the data for our paper M-ABSA: A Multilingual Dataset for Aspect-Based Sentiment Analysis.\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tData Description:\\n\\t\\n\\nThis is a dataset suitable for the multilingual ABSA task with triplet extraction.\\nAll datasets are stored in the data/ folder:\\n\\nAll dataset contains 7 domains.\\n\\ndomains = [\\\"coursera\\\", \\\"hotel\\\", \\\"laptop\\\", \\\"restaurant\\\", \\\"phone\\\", \\\"sight\\\", \\\"food\\\"]\\n\\n\\nEach dataset contains 21 languages.\\n\\nlangs = [\\\"ar\\\", \\\"da\\\", \\\"de\\\", \\\"en\\\", \\\"es\\\", \\\"fr\\\", \\\"hi\\\", \\\"hr\\\"â€¦ See the full description on the dataset page: https://huggingface.co/datasets/Multilingual-NLP/M-ABSA.","first_N":5,"first_N_keywords":["token-classification","text-classification","Arabic","Danish","German"],"keywords_longer_than_N":true},
	{"name":"Arabic_captioned_Images","keyword":"arabic","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Daemontatox/Arabic_captioned_Images","creator_name":"Ammar","creator_url":"https://huggingface.co/Daemontatox","description":"\\n\\t\\n\\t\\t\\n\\t\\tALLaVA-4V for Arabic\\n\\t\\n\\nThis is the Arabic version of the ALLaVA-4V data. We have translated the ALLaVA-4V data into Arabic through ChatGPT and instructed ChatGPT not to translate content related to OCR.\\nThe original dataset can be found here, and the image data can be downloaded from ALLaVA-4V.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tCitation\\n\\t\\n\\nIf you find our data useful, please consider citing our work! We are FreedomIntelligence from Shenzhen Research Institute of Big Data and The Chinese University of Hongâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Daemontatox/Arabic_captioned_Images.","first_N":5,"first_N_keywords":["question-answering","text-generation","Arabic","apache-2.0","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"arabic-books","keyword":"arabic","license":"GNU General Public License v3.0","license_url":"https://choosealicense.com/licenses/gpl-3.0/","language":"en","dataset_url":"https://huggingface.co/datasets/MohamedRashad/arabic-books","creator_name":"Mohamed Rashad","creator_url":"https://huggingface.co/MohamedRashad","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tArabic Books\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThe arabic-books dataset contains 8,500 rows of text, each representing the full text of a single Arabic book. These texts were extracted using the arabic-large-nougat model, showcasing the modelâ€™s capabilities in Arabic OCR and text extraction. The dataset spans a total of 1.1 billion tokens, calculated using the GPT-4 tokenizer.\\nThis dataset is a testimony to the quality of the Arabic Nougat models and their effectiveness inâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/MohamedRashad/arabic-books.","first_N":5,"first_N_keywords":["text-generation","Arabic","gpl-3.0","1K - 10K","arrow"],"keywords_longer_than_N":true},
	{"name":"arabic-books","keyword":"arabic","license":"GNU General Public License v3.0","license_url":"https://choosealicense.com/licenses/gpl-3.0/","language":"en","dataset_url":"https://huggingface.co/datasets/MohamedRashad/arabic-books","creator_name":"Mohamed Rashad","creator_url":"https://huggingface.co/MohamedRashad","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tArabic Books\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThe arabic-books dataset contains 8,500 rows of text, each representing the full text of a single Arabic book. These texts were extracted using the arabic-large-nougat model, showcasing the modelâ€™s capabilities in Arabic OCR and text extraction. The dataset spans a total of 1.1 billion tokens, calculated using the GPT-4 tokenizer.\\nThis dataset is a testimony to the quality of the Arabic Nougat models and their effectiveness inâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/MohamedRashad/arabic-books.","first_N":5,"first_N_keywords":["text-generation","Arabic","gpl-3.0","1K - 10K","arrow"],"keywords_longer_than_N":true},
	{"name":"silma-rag-qa-benchmark-v1.0","keyword":"arabic","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/silma-ai/silma-rag-qa-benchmark-v1.0","creator_name":"SILMA AI","creator_url":"https://huggingface.co/silma-ai","description":"\\n\\t\\n\\t\\t\\n\\t\\tSILMA RAGQA Benchmark Dataset V1.0\\n\\t\\n\\nSILMA RAGQA is a dataset and benchmark created by silma.ai to assess the effectiveness of Arabic Language Models in Extractive Question Answering tasks, with a specific emphasis on RAG applications\\nThe benchmark includes 17 bilingual datasets in Arabic and English, spanning various domains\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tWhat capabilities does the benchmark test?\\n\\t\\n\\n\\nGeneral Arabic and English QA capabilities\\nAbility to handle short and long contexts\\nAbility toâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/silma-ai/silma-rag-qa-benchmark-v1.0.","first_N":5,"first_N_keywords":["question-answering","table-question-answering","Arabic","English","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"LLaVA-Pretrain-AR","keyword":"arabic","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/KickItLikeShika/LLaVA-Pretrain-AR","creator_name":"Ahmed Khaled","creator_url":"https://huggingface.co/KickItLikeShika","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tAR LLaVA Pretraining Dataset\\n\\t\\n\\nOriginal LLaVA Pretraining Datasettranslated to Arabic.\\n","first_N":5,"first_N_keywords":["text-generation","Arabic","mit","100K<n<1M","ðŸ‡ºðŸ‡¸ Region: US"],"keywords_longer_than_N":false},
	{"name":"Wikipedia-Abstract","keyword":"arabic","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/laion/Wikipedia-Abstract","creator_name":"LAION eV","creator_url":"https://huggingface.co/laion","description":"Wikipedia Abstract\\n\\n\\n  \\n\\n\\n\\nIntroducing Wikipedia Abstract, a comprehensive dataset encompassing abstracts, complete articles, and a popularity score index for both widely spoken and lesser-known Wikipedia subsets. Our dedication to Wikipedia-X ensures a centralized Wikipedia dataset that undergoes regular updates and adheres to the highest standards.\\nA central focus of our efforts was to include exotic languages that often lack up-to-date Wikipedia dumps or may not have any dumps at all.â€¦ See the full description on the dataset page: https://huggingface.co/datasets/laion/Wikipedia-Abstract.","first_N":5,"first_N_keywords":["text-classification","question-answering","text-generation","fill-mask","Arabic"],"keywords_longer_than_N":true},
	{"name":"DVOICEv2.0-Darija","keyword":"arabic","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/BrunoHays/DVOICEv2.0-Darija","creator_name":"Bruno Hays","creator_url":"https://huggingface.co/BrunoHays","description":"DVoice is a community initiative that aims to provide African languages and dialects with data and models to facilitate their use of voice technologies. The lack of data on these languages makes it necessary to collect data using methods that are specific to each language. Two different approaches are currently used: the DVoice platform, which is based on Mozilla Common Voice, for collecting authentic recordings from the community, and transfer learning techniques for automatically labelingâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/BrunoHays/DVOICEv2.0-Darija.","first_N":5,"first_N_keywords":["Arabic","cc-by-4.0","10K - 100K","soundfolder","Audio"],"keywords_longer_than_N":true},
	{"name":"mmmlu_lite","keyword":"arabic","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/opencompass/mmmlu_lite","creator_name":"OpenCompass","creator_url":"https://huggingface.co/opencompass","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tMMMLU-Lite\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tIntroduction\\n\\t\\n\\nA lite version of the MMMLU dataset, which is an community version of the MMMLU dataset by OpenCompass. Due to the large size of the original dataset (about 200k questions), we have created a lite version of the dataset to make it easier to use. We sample 25 examples from each language subject in the original dataset with fixed seed to ensure reproducibility, finally we have 19950 examples in the lite version of the dataset, which is aboutâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/opencompass/mmmlu_lite.","first_N":5,"first_N_keywords":["question-answering","Arabic","Bengali","German","Spanish"],"keywords_longer_than_N":true},
	{"name":"silma-arabic-english-sts-dataset-v1.0","keyword":"arabic","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/silma-ai/silma-arabic-english-sts-dataset-v1.0","creator_name":"SILMA AI","creator_url":"https://huggingface.co/silma-ai","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSILMA STS Arabic/English Dataset - v1.0\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tOverview\\n\\t\\n\\nThe SILMA STS Arabic/English Dataset - v1.0 is a dataset designed for training and evaluating sentence embeddings for Arabic and English tasks. It consists of five different splits that cover monolingual and multilingual sentence pairs, with human-annotated similarity scores. The dataset includes both Arabic-to-Arabic and English-to-English pairs, as well as cross-lingual Arabic-English pairs, making it a valuableâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/silma-ai/silma-arabic-english-sts-dataset-v1.0.","first_N":5,"first_N_keywords":["sentence-similarity","Arabic","English","apache-2.0","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"HREmails","keyword":"arabic","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/moa7amed/HREmails","creator_name":"Mohamed Ibrahim","creator_url":"https://huggingface.co/moa7amed","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Dataset Name\\n\\t\\n\\n\\n\\nThis dataset card aims to be a base template for new datasets. It has been generated using this raw template.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Details\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\n\\n\\n\\n\\n\\nCurated by: [More Information Needed]\\nFunded by [optional]: [More Information Needed]\\nShared by [optional]: [More Information Needed]\\nLanguage(s) (NLP): [More Information Needed]\\nLicense: [More Information Needed]\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Sources [optional]â€¦ See the full description on the dataset page: https://huggingface.co/datasets/moa7amed/HREmails.","first_N":5,"first_N_keywords":["feature-extraction","English","Arabic","mit","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"multilingual-coco","keyword":"arabic","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/romrawinjp/multilingual-coco","creator_name":"Romrawin Chumpu","creator_url":"https://huggingface.co/romrawinjp","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tMultilingual Common Objects in Context (COCO) Dataset\\n\\t\\n\\nThis dataset is a collection of multiple language open-source captions of COCO dataset. \\nThe split in this dataset is set according to Andrej Karpathy's split from dataset_coco.json file. The collection was created specifically for simplicity of use in training and evaluation pipeline by non-commercial and research purposes. The COCO images dataset is licensed under a Creative Commons Attribution 4.0 License.â€¦ See the full description on the dataset page: https://huggingface.co/datasets/romrawinjp/multilingual-coco.","first_N":5,"first_N_keywords":["image-to-text","English","Thai","Russian","Japanese"],"keywords_longer_than_N":true},
	{"name":"AyaVisionBench","keyword":"arabic","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/CohereForAI/AyaVisionBench","creator_name":"Cohere For AI","creator_url":"https://huggingface.co/CohereForAI","description":"\\n\\t\\n\\t\\t\\n\\t\\tDataset Card for Aya Vision Benchmark\\n\\t\\n\\n\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Details\\n\\t\\n\\nThe Aya Vision Benchmark is designed to evaluate vision-language models in real-world multilingual scenarios. It spans 23 languages and 9 distinct task categories, with 15 samples per category, resulting in 135 image-question pairs per language. \\nEach question requires visual context for the answer and covers languages that half of the world's population speaks, making this dataset particularly suited forâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/CohereForAI/AyaVisionBench.","first_N":5,"first_N_keywords":["English","French","German","Spanish","Italian"],"keywords_longer_than_N":true},
	{"name":"webfaq","keyword":"arabic","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/PaDaS-Lab/webfaq","creator_name":"Chair of Data Science, University of Passau","creator_url":"https://huggingface.co/PaDaS-Lab","description":"WebFAQ Q&A Dataset\\n\\n   \\n       Overview |\\n       Details  |\\n       Structure  |\\n       Examples |\\n       Considerations |\\n       License |\\n       Citation |\\n       Contact |\\n       Acknowledgement\\n   \\n\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tOverview\\n\\t\\n\\nThe WebFAQ Q&A Dataset is a broad-coverage corpus of 96 million natural question-answer (QA) pairs in 75 languages, gathered from FAQ pages on the web. It leverages structured schema.org FAQPage annotations, making it a unique resource for large-scale Question Answeringâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/PaDaS-Lab/webfaq.","first_N":5,"first_N_keywords":["question-answering","multilingual","Afrikaans","Amharic","Arabic"],"keywords_longer_than_N":true},
	{"name":"webfaq","keyword":"egyptian arabic","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/PaDaS-Lab/webfaq","creator_name":"Chair of Data Science, University of Passau","creator_url":"https://huggingface.co/PaDaS-Lab","description":"WebFAQ Q&A Dataset\\n\\n   \\n       Overview |\\n       Details  |\\n       Structure  |\\n       Examples |\\n       Considerations |\\n       License |\\n       Citation |\\n       Contact |\\n       Acknowledgement\\n   \\n\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tOverview\\n\\t\\n\\nThe WebFAQ Q&A Dataset is a broad-coverage corpus of 96 million natural question-answer (QA) pairs in 75 languages, gathered from FAQ pages on the web. It leverages structured schema.org FAQPage annotations, making it a unique resource for large-scale Question Answeringâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/PaDaS-Lab/webfaq.","first_N":5,"first_N_keywords":["question-answering","multilingual","Afrikaans","Amharic","Arabic"],"keywords_longer_than_N":true},
	{"name":"oasst1","keyword":"arabic","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/OpenAssistant/oasst1","creator_name":"OpenAssistant","creator_url":"https://huggingface.co/OpenAssistant","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tOpenAssistant Conversations Dataset (OASST1)\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nIn an effort to democratize research on large-scale alignment, we release OpenAssistant \\nConversations (OASST1), a human-generated, human-annotated assistant-style conversation \\ncorpus consisting of 161,443 messages in 35 different languages, annotated with 461,292 \\nquality ratings, resulting in over 10,000 fully annotated conversation trees. The corpus \\nis a product of a worldwide crowd-sourcing effortâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/OpenAssistant/oasst1.","first_N":5,"first_N_keywords":["English","Spanish","Russian","German","Polish"],"keywords_longer_than_N":true},
	{"name":"Everything_Instruct_Multilingual","keyword":"arabic","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/rombodawg/Everything_Instruct_Multilingual","creator_name":"rombo dawg","creator_url":"https://huggingface.co/rombodawg","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tEverything Instruct (Multilingual Edition)\\n\\t\\n\\nEverything you need... all in one place ðŸ’˜\\n\\nEverything instruct (Multilingual Edition) is a massive alpaca instruct formatted dataset consisting of a wide variety of topics meant to bring LLM's to the next level in open source AI.\\nNote: This dataset is fully uncensored (No model will refuse any request trained on this dataset unless otherwise aligned)\\nNote2: This version of the dataset supports the following languages:\\n\\nEnglish\\nRussianâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/rombodawg/Everything_Instruct_Multilingual.","first_N":5,"first_N_keywords":["English","Russian","Chinese","Korean","Urdu"],"keywords_longer_than_N":true},
	{"name":"oasst2","keyword":"arabic","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/OpenAssistant/oasst2","creator_name":"OpenAssistant","creator_url":"https://huggingface.co/OpenAssistant","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tOpen Assistant Conversations Dataset Release 2 (OASST2)\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Structure\\n\\t\\n\\nThis dataset contains message trees. Each message tree has an initial prompt message as the root node, \\nwhich can have multiple child messages as replies, and these child messages can have multiple replies. \\nAll messages have a role property: this can either be \\\"assistant\\\" or \\\"prompter\\\". The roles in \\nconversation threads from prompt to leaf node strictly alternate between \\\"prompter\\\" andâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/OpenAssistant/oasst2.","first_N":5,"first_N_keywords":["English","Spanish","Russian","German","Polish"],"keywords_longer_than_N":true},
	{"name":"Quran-Tafseer","keyword":"arabic","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/MohamedRashad/Quran-Tafseer","creator_name":"Mohamed Rashad","creator_url":"https://huggingface.co/MohamedRashad","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tðŸ“š Quran Tafseer Collection\\n\\t\\n\\n\\n  \\n\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tWhat's this all about?\\n\\t\\n\\nThis dataset is a treasure trove of Quranic interpretations (tafsir) from 84 different books! It's perfect for anyone interested in Islamic studies, natural language processing, or just curious about the Quran's meanings.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Details\\n\\t\\n\\n\\nSource: All data was collected from Altafsir.com\\nSize: 219,000 rows of insightful content\\nLanguage: Arabic\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tWhat's inside?\\n\\t\\n\\nThe dataset has 5â€¦ See the full description on the dataset page: https://huggingface.co/datasets/MohamedRashad/Quran-Tafseer.","first_N":5,"first_N_keywords":["Arabic","apache-2.0","100K - 1M","parquet","Text"],"keywords_longer_than_N":true},
	{"name":"Arabic-gsm8k","keyword":"arabic","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Omartificial-Intelligence-Space/Arabic-gsm8k","creator_name":"Omartificial Intelligence Space","creator_url":"https://huggingface.co/Omartificial-Intelligence-Space","description":"\\n\\t\\n\\t\\t\\n\\t\\tDataset Card for Arabic GSM8K\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nArabic GSM8K is an Arabic translation of the GSM8K (Grade School Math 8K) dataset, which contains high-quality linguistically diverse grade school math word problems. The original dataset was created to support the task of question answering on basic mathematical problems that require multi-step reasoning, and this Arabic version aims to extend these capabilities to Arabic language models and applications.\\nThe datasetâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Omartificial-Intelligence-Space/Arabic-gsm8k.","first_N":5,"first_N_keywords":["text2text-generation","Arabic","mit","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"Arabic-gsm8k","keyword":"arabic","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Omartificial-Intelligence-Space/Arabic-gsm8k","creator_name":"Omartificial Intelligence Space","creator_url":"https://huggingface.co/Omartificial-Intelligence-Space","description":"\\n\\t\\n\\t\\t\\n\\t\\tDataset Card for Arabic GSM8K\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nArabic GSM8K is an Arabic translation of the GSM8K (Grade School Math 8K) dataset, which contains high-quality linguistically diverse grade school math word problems. The original dataset was created to support the task of question answering on basic mathematical problems that require multi-step reasoning, and this Arabic version aims to extend these capabilities to Arabic language models and applications.\\nThe datasetâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Omartificial-Intelligence-Space/Arabic-gsm8k.","first_N":5,"first_N_keywords":["text2text-generation","Arabic","mit","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"nn-auto-bench-ds","keyword":"arabic","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/nanonets/nn-auto-bench-ds","creator_name":"Nanonets","creator_url":"https://huggingface.co/nanonets","description":"\\n\\t\\n\\t\\t\\n\\t\\tnn-auto-bench-ds\\n\\t\\n\\nnn-auto-bench-ds is a dataset designed for key information extraction (KIE) and serves as a benchmark dataset for nn-auto-bench.\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Overview\\n\\t\\n\\nThe dataset comprises 1,000 documents, categorized into the following types:\\n\\nInvoice\\nReceipt\\nPassport\\nBank Statement\\n\\nThe documents are primarily available in English, with some also in German and Arabic. Each document is annotated for key information extraction and specific tasks. The dataset can be used toâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/nanonets/nn-auto-bench-ds.","first_N":5,"first_N_keywords":["question-answering","English","German","Arabic","mit"],"keywords_longer_than_N":true},
	{"name":"linto-dataset-audio-ar-tn","keyword":"arabic","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/linagora/linto-dataset-audio-ar-tn","creator_name":"LINAGORA Labs","creator_url":"https://huggingface.co/linagora","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLinTO DataSet Audio for Arabic Tunisian A collection of Tunisian dialect audio and its annotations for STT task\\n\\t\\n\\nThis is the first packaged version of the datasets used to train the Linto Tunisian dialect with code-switching STT\\n(linagora/linto-asr-ar-tn).\\n\\nDataset Summary\\nDataset composition\\nSources\\nData Table\\nData sources\\nContent Types\\nLanguages and Dialects\\n\\n\\nExample use (python)\\nLicense\\nCitations\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThe LinTO DataSet Audio for Arabic Tunisian is aâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/linagora/linto-dataset-audio-ar-tn.","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","text-to-audio","Arabic","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"Global-MMLU","keyword":"arabic","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/CohereForAI/Global-MMLU","creator_name":"Cohere For AI","creator_url":"https://huggingface.co/CohereForAI","description":"\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nGlobal-MMLU ðŸŒ is a multilingual evaluation set spanning 42 languages, including English. This dataset combines machine translations for MMLU questions along with professional translations and crowd-sourced post-edits.\\nIt also includes cultural sensitivity annotations for a subset of the questions (2850 questions per language) and classifies them as Culturally Sensitive (CS) ðŸ—½ or Culturally Agnostic (CA) âš–ï¸. These annotations were collected as part of an openâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/CohereForAI/Global-MMLU.","first_N":5,"first_N_keywords":["English","Arabic","Bengali","Spanish","French"],"keywords_longer_than_N":true},
	{"name":"reasoning-multilingual-R1-Llama-70B-train","keyword":"arabic","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/lightblue/reasoning-multilingual-R1-Llama-70B-train","creator_name":"Lightblue KK.","creator_url":"https://huggingface.co/lightblue","description":"\\n\\t\\n\\t\\t\\n\\t\\tlightblue/reasoning-multilingual-R1-Llama-70B-train\\n\\t\\n\\nThis is a multilingual reasoning dataset covering more than 30 languages.\\nThis dataset was made by:\\n\\nSampling prompts from English datasets and translating them to various languages\\nGenerating responses to these prompts 8 times using deepseek-ai/DeepSeek-R1-Distill-Llama-70B\\nFiltering out <think> sections with incorrect language, non-fluent language, and incorrect answers\\n\\nThis dataset was then used to train a multilingualâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/lightblue/reasoning-multilingual-R1-Llama-70B-train.","first_N":5,"first_N_keywords":["Amharic","Arabic","Bengali","Chinese","Czech"],"keywords_longer_than_N":true},
	{"name":"wmt24pp","keyword":"arabic","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/google/wmt24pp","creator_name":"Google","creator_url":"https://huggingface.co/google","description":"\\n\\t\\n\\t\\t\\n\\t\\tWMT24++\\n\\t\\n\\nThis repository contains the human translation and post-edit data for the 55 en->xx language pairs released in\\nthe publication\\nWMT24++: Expanding the Language Coverage of WMT24 to 55 Languages & Dialects.\\nIf you are interested in the MT/LLM system outputs and automatic metric scores, please see MTME.\\nIf you are interested in the images of the source URLs for each document, please see here.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSchema\\n\\t\\n\\nEach language pair is stored in its own jsonl file.\\nEach row isâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/google/wmt24pp.","first_N":5,"first_N_keywords":["translation","Arabic","Bulgarian","Bengali","Catalan"],"keywords_longer_than_N":true},
	{"name":"Shifaa_Arabic_Medical_Consultations","keyword":"arabic","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Ahmed-Selem/Shifaa_Arabic_Medical_Consultations","creator_name":"Ahmed Selem","creator_url":"https://huggingface.co/Ahmed-Selem","description":"\\n\\t\\n\\t\\t\\n\\t\\tShifaa Arabic Medical Consultations ðŸ¥ðŸ“Š\\n\\t\\n\\n  \\n\\n\\t\\n\\t\\t\\n\\t\\tOverview ðŸŒ\\n\\t\\n\\nShifaa is revolutionizing Arabic medical AI by addressing the critical gap in Arabic medical datasets. Our first contribution is the Shifaa Arabic Medical Consultations dataset, a comprehensive collection of 84,422 real-world medical consultations covering 16 Main Specializations and 585 Hierarchical Diagnoses.  \\nðŸ” Why is this dataset important?  \\n\\nFirst large-scale Arabic medical dataset for AI applications.â€¦ See the full description on the dataset page: https://huggingface.co/datasets/Ahmed-Selem/Shifaa_Arabic_Medical_Consultations.","first_N":5,"first_N_keywords":["question-answering","text-classification","text-generation","zero-shot-classification","Arabic"],"keywords_longer_than_N":true},
	{"name":"thinking-multilingual-30-23-small-690","keyword":"arabic","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Pinkstack/thinking-multilingual-30-23-small-690","creator_name":"Pinkstack","creator_url":"https://huggingface.co/Pinkstack","description":"\\nBased on OPENO1 math, this is a translated dataset of 30 high quality questions & answers in 23 languages. \\nOr use the \\\"big\\\" version: big 10k rows version\\n","first_N":5,"first_N_keywords":["text-generation","Arabic","Chinese","Czech","Danish"],"keywords_longer_than_N":true},
	{"name":"exams","keyword":"arabic","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mhardalov/exams","creator_name":"Momchil Hardalov","creator_url":"https://huggingface.co/mhardalov","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for [Dataset Name]\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nEXAMS is a benchmark dataset for multilingual and cross-lingual question answering from high school examinations. It consists of more than 24,000 high-quality high school exam questions in 16 languages, covering 8 language families and 24 school subjects from Natural Sciences and Social Sciences, among others.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSupported Tasks and Leaderboards\\n\\t\\n\\n[More Information Needed]\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages\\n\\t\\n\\nTheâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/mhardalov/exams.","first_N":5,"first_N_keywords":["question-answering","multiple-choice-qa","found","found","monolingual"],"keywords_longer_than_N":true},
	{"name":"tashkeela","keyword":"arabic","license":"GNU General Public License v2.0","license_url":"https://choosealicense.com/licenses/gpl-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/community-datasets/tashkeela","creator_name":"Community Datasets","creator_url":"https://huggingface.co/community-datasets","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Tashkeela\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nIt contains 75 million of fully vocalized words mainly\\n97 books from classical and modern Arabic language.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSupported Tasks and Leaderboards\\n\\t\\n\\n[More Information Needed]\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages\\n\\t\\n\\nThe dataset is based on Arabic.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Structure\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Instances\\n\\t\\n\\n{'book':â€¦ See the full description on the dataset page: https://huggingface.co/datasets/community-datasets/tashkeela.","first_N":5,"first_N_keywords":["text-generation","fill-mask","language-modeling","masked-language-modeling","no-annotation"],"keywords_longer_than_N":true},
	{"name":"xquad","keyword":"arabic","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/google/xquad","creator_name":"Google","creator_url":"https://huggingface.co/google","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for \\\"xquad\\\"\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nXQuAD (Cross-lingual Question Answering Dataset) is a benchmark dataset for evaluating cross-lingual question answering\\nperformance. The dataset consists of a subset of 240 paragraphs and 1190 question-answer pairs from the development set\\nof SQuAD v1.1 (Rajpurkar et al., 2016) together with their professional translations into ten languages: Spanish, German,\\nGreek, Russian, Turkish, Arabic, Vietnamese, Thai, Chinese, andâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/google/xquad.","first_N":5,"first_N_keywords":["question-answering","extractive-qa","expert-generated","expert-generated","multilingual"],"keywords_longer_than_N":true},
	{"name":"xtreme","keyword":"arabic","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/google/xtreme","creator_name":"Google","creator_url":"https://huggingface.co/google","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for \\\"xtreme\\\"\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThe Cross-lingual Natural Language Inference (XNLI) corpus is a crowd-sourced collection of 5,000 test and\\n2,500 dev pairs for the MultiNLI corpus. The pairs are annotated with textual entailment and translated into\\n14 languages: French, Spanish, German, Greek, Bulgarian, Russian, Turkish, Arabic, Vietnamese, Thai, Chinese,\\nHindi, Swahili and Urdu. This results in 112.5k annotated pairs. Each premise can be associated withâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/google/xtreme.","first_N":5,"first_N_keywords":["multiple-choice","question-answering","token-classification","text-classification","text-retrieval"],"keywords_longer_than_N":true},
	{"name":"mqa","keyword":"arabic","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/clips/mqa","creator_name":"CLiPS","creator_url":"https://huggingface.co/clips","description":"MQA is a multilingual corpus of questions and answers parsed from the Common Crawl. Questions are divided between Frequently Asked Questions (FAQ) pages and Community Question Answering (CQA) pages.","first_N":5,"first_N_keywords":["question-answering","multiple-choice-qa","no-annotation","other","multilingual"],"keywords_longer_than_N":true},
	{"name":"multilingual-sentiments","keyword":"arabic","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/tyqiangz/multilingual-sentiments","creator_name":"Tay Yong Qiang","creator_url":"https://huggingface.co/tyqiangz","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tMultilingual Sentiments Dataset\\n\\t\\n\\nA collection of multilingual sentiments datasets grouped into 3 classes -- positive, neutral, negative.\\nMost multilingual sentiment datasets are either 2-class positive or negative, 5-class ratings of products reviews (e.g. Amazon multilingual dataset) or multiple classes of emotions. However, to an average person, sometimes positive, negative and neutral classes suffice and are more straightforward to perceive and annotate. Also, aâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/tyqiangz/multilingual-sentiments.","first_N":5,"first_N_keywords":["text-classification","sentiment-analysis","sentiment-classification","monolingual","multilingual"],"keywords_longer_than_N":true},
	{"name":"everyayah","keyword":"arabic","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/tarteel-ai/everyayah","creator_name":"Tarteel AI","creator_url":"https://huggingface.co/tarteel-ai","description":"ï·½\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Tarteel AI's EveryAyah Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThis dataset is a collection of Quranic verses and their transcriptions, with diacritization, by different reciters.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSupported Tasks and Leaderboards\\n\\t\\n\\n[Needs More Information]\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages\\n\\t\\n\\nThe audio is in Arabic.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Structure\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Instances\\n\\t\\n\\nA typical data point comprises the audio file audio, and its transcription called text.\\nThe durationâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/tarteel-ai/everyayah.","first_N":5,"first_N_keywords":["automatic-speech-recognition","expert-generated","crowdsourced","monolingual","original"],"keywords_longer_than_N":true},
	{"name":"africlirmatrix","keyword":"egyptian arabic","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/castorini/africlirmatrix","creator_name":"Castorini","creator_url":"https://huggingface.co/castorini","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nAfriCLIRMatrix is a test collection for cross-lingual information retrieval research in 15 diverse African languages. This resource comprises English queries with queryâ€“document relevance judgments in 15 African languages automatically mined from Wikipedia\\nThis dataset stores documents of AfriCLIRMatrix. To access the queries and judgments, please refer to castorini/africlirmatrix.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Structure\\n\\t\\n\\nThe only configuration here is the language.\\nAnâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/castorini/africlirmatrix.","first_N":5,"first_N_keywords":["text-retrieval","multilingual","Afrikaans","Amharic","Egyptian Arabic"],"keywords_longer_than_N":true},
	{"name":"africlirmatrix","keyword":"moroccan arabic","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/castorini/africlirmatrix","creator_name":"Castorini","creator_url":"https://huggingface.co/castorini","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nAfriCLIRMatrix is a test collection for cross-lingual information retrieval research in 15 diverse African languages. This resource comprises English queries with queryâ€“document relevance judgments in 15 African languages automatically mined from Wikipedia\\nThis dataset stores documents of AfriCLIRMatrix. To access the queries and judgments, please refer to castorini/africlirmatrix.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Structure\\n\\t\\n\\nThe only configuration here is the language.\\nAnâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/castorini/africlirmatrix.","first_N":5,"first_N_keywords":["text-retrieval","multilingual","Afrikaans","Amharic","Egyptian Arabic"],"keywords_longer_than_N":true},
	{"name":"Arabic-Tweets","keyword":"arabic","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/pain/Arabic-Tweets","creator_name":"Mohammad Albarham","creator_url":"https://huggingface.co/pain","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Dataset Arabic-Tweets\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThis dataset has been collected from twitter which is more than 41 GB of clean data of Arabic Tweets with nearly 4-billion Arabic words (12-million unique Arabic words).\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages\\n\\t\\n\\nArabic\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSource Data\\n\\t\\n\\nTwitter\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tExample on data loading using streaming:\\n\\t\\n\\nfrom datasets import load_dataset\\ndataset = load_dataset(\\\"pain/Arabic-Tweets\\\",split='train', streaming=True)â€¦ See the full description on the dataset page: https://huggingface.co/datasets/pain/Arabic-Tweets.","first_N":5,"first_N_keywords":["Arabic","cc-by-4.0","100M - 1B","text","Text"],"keywords_longer_than_N":true},
	{"name":"Moroccan_Arabic_Wikipedia_20230101_nobots","keyword":"arabic","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/SaiedAlshahrani/Moroccan_Arabic_Wikipedia_20230101_nobots","creator_name":"Saied Alshahrani","creator_url":"https://huggingface.co/SaiedAlshahrani","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for \\\"Moroccan_Arabic_Wikipedia_20230101_nobots\\\"\\n\\t\\n\\nThis dataset is created using the Moroccan Arabic Wikipedia articles (after removing bot-generated articles), downloaded on the 1st of January 2023, processed using Gensim Python library, and preprocessed using tr Linux/Unix utility and CAMeLTools Python toolkit for Arabic NLP. This dataset was used to train this Moroccan Arabic Wikipedia Masked Language Model: SaiedAlshahrani/arywiki_20230101_roberta_mlm_nobots.\\nForâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/SaiedAlshahrani/Moroccan_Arabic_Wikipedia_20230101_nobots.","first_N":5,"first_N_keywords":["Arabic","mit","1K - 10K","parquet","Text"],"keywords_longer_than_N":true},
	{"name":"tarteel-ai-everyayah-Quran","keyword":"arabic","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Salama1429/tarteel-ai-everyayah-Quran","creator_name":"Mohamed Salama","creator_url":"https://huggingface.co/Salama1429","description":"ï·½\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Tarteel AI's EveryAyah Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThis dataset is a collection of Quranic verses and their transcriptions, with diacritization, by different reciters.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tHow to download\\n\\t\\n\\n!pip install -q datasets\\n\\nfrom datasets import load_dataset\\ndataset =load_dataset(\\\"Salama1429/tarteel-ai-everyayah-Quran\\\", verification_mode=\\\"no_checks\\\")\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSupported Tasks and Leaderboards\\n\\t\\n\\n[Needs More Information]\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguagesâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Salama1429/tarteel-ai-everyayah-Quran.","first_N":5,"first_N_keywords":["automatic-speech-recognition","expert-generated","crowdsourced","monolingual","original"],"keywords_longer_than_N":true},
	{"name":"toxi-text-3M","keyword":"arabic","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/FredZhang7/toxi-text-3M","creator_name":"Fred Zhang","creator_url":"https://huggingface.co/FredZhang7","description":"This is a large multilingual toxicity dataset with 3M rows of text data from 55 natural languages, all of which are written/sent by humans, not machine translation models.\\nThe preprocessed training data alone consists of 2,880,667 rows of comments, tweets, and messages. Among these rows, 416,529 are classified as toxic, while the remaining 2,463,773 are considered neutral. Below is a table to illustrate the data composition:\\n\\n\\t\\n\\t\\t\\n\\nToxic\\nNeutral\\nTotal\\n\\n\\n\\t\\t\\nmultilingual-train-deduplicated.csvâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/FredZhang7/toxi-text-3M.","first_N":5,"first_N_keywords":["text-classification","token-classification","zero-shot-classification","Arabic","Spanish"],"keywords_longer_than_N":true},
	{"name":"quran-question-answer-context","keyword":"arabic","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/nazimali/quran-question-answer-context","creator_name":"Nazim Ali","creator_url":"https://huggingface.co/nazimali","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for \\\"quran-question-answer-context\\\"\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nTranslated the original dataset from Arabic to English and added the Surah ayahs to the context column.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tUsage\\n\\t\\n\\nfrom datasets import load_dataset\\n\\ndataset = load_dataset(\\\"nazimali/quran-question-answer-context\\\")\\n\\nDatasetDict({\\n    train: Dataset({\\n        features: ['q_id', 'question', 'answer', 'q_word', 'q_topic', 'fine_class', 'class', 'ontology_concept', 'ontology_concept2', 'source'â€¦ See the full description on the dataset page: https://huggingface.co/datasets/nazimali/quran-question-answer-context.","first_N":5,"first_N_keywords":["question-answering","Arabic","English","cc-by-4.0","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"quran-question-answer-context","keyword":"arabic","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/nazimali/quran-question-answer-context","creator_name":"Nazim Ali","creator_url":"https://huggingface.co/nazimali","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for \\\"quran-question-answer-context\\\"\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nTranslated the original dataset from Arabic to English and added the Surah ayahs to the context column.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tUsage\\n\\t\\n\\nfrom datasets import load_dataset\\n\\ndataset = load_dataset(\\\"nazimali/quran-question-answer-context\\\")\\n\\nDatasetDict({\\n    train: Dataset({\\n        features: ['q_id', 'question', 'answer', 'q_word', 'q_topic', 'fine_class', 'class', 'ontology_concept', 'ontology_concept2', 'source'â€¦ See the full description on the dataset page: https://huggingface.co/datasets/nazimali/quran-question-answer-context.","first_N":5,"first_N_keywords":["question-answering","Arabic","English","cc-by-4.0","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"massive_translation_dataset","keyword":"arabic","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Amani27/massive_translation_dataset","creator_name":"Amani N","creator_url":"https://huggingface.co/Amani27","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Massive Dataset for Translation\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThis dataset is derived from AmazonScience/MASSIVE dataset for translation task purpose.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSupported Tasks and Leaderboards\\n\\t\\n\\nTranslation\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages\\n\\t\\n\\n\\nEnglish (en_US)\\nGerman (de_DE)\\nHindi (hi_IN)\\nSpanish (es_ES)\\nFrench (fr_FR)\\nItalian (it_IT)\\nArabic (ar_SA)\\nDutch (nl_NL)\\nJapanese (ja_JP)\\nPortugese (pt_PT)\\n\\n","first_N":5,"first_N_keywords":["translation","English","German","Spanish","Hindi"],"keywords_longer_than_N":true},
	{"name":"belebele","keyword":"arabic","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/facebook/belebele","creator_name":"AI at Meta","creator_url":"https://huggingface.co/facebook","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tThe Belebele Benchmark for Massively Multilingual NLU Evaluation\\n\\t\\n\\nBelebele is a multiple-choice machine reading comprehension (MRC) dataset spanning 122 language variants. This dataset enables the evaluation of mono- and multi-lingual models in high-, medium-, and low-resource languages. Each question has four multiple-choice answers and is linked to a short passage from the FLORES-200 dataset. The human annotation procedure was carefully curated to create questions thatâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/facebook/belebele.","first_N":5,"first_N_keywords":["question-answering","zero-shot-classification","text-classification","multiple-choice","Afrikaans"],"keywords_longer_than_N":true},
	{"name":"spoken-arabic-digits","keyword":"arabic","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mohnasgbr/spoken-arabic-digits","creator_name":"Mohammed Nasser Gaber","creator_url":"https://huggingface.co/mohnasgbr","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tOverview\\n\\t\\n\\nThis dataset contains spoken Arabic digits from 40 speakers from multiple Arab communities and local dialects. It is augmented using various techniques to increase the size of the dataset and improve its diversity. The recordings went through a number of pre-processors to evaluate and process the sound quality using Audacity app.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Creation\\n\\t\\n\\nThe dataset was created by collecting recordings of the digits 0-9 from 40 speakers from different Arabâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/mohnasgbr/spoken-arabic-digits.","first_N":5,"first_N_keywords":["Arabic","apache-2.0","< 1K","soundfolder","Audio"],"keywords_longer_than_N":true},
	{"name":"dz-sentiment-yt-comments","keyword":"arabic","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Abdou/dz-sentiment-yt-comments","creator_name":"Rockikz","creator_url":"https://huggingface.co/Abdou","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tA Sentiment Analysis Dataset for the Algerian Dialect of Arabic\\n\\t\\n\\nThis dataset consists of 50,016 samples of comments extracted from Algerian YouTube channels. It is manually annotated with 3 classes (the label column) and is not balanced. Here are the number of rows of each class:\\n\\n0 (Negative): 17,033 (34.06%)\\n1 (Neutral): 11,136 (22.26%)\\n2 (Positive): 21,847 (43.68%)\\n\\nPlease note that there are some swear words in the dataset, so please use it with caution.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tCitationâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Abdou/dz-sentiment-yt-comments.","first_N":5,"first_N_keywords":["text-classification","Arabic","mit","10K - 100K","csv"],"keywords_longer_than_N":true},
	{"name":"Open_Assistant_Conversation_Chains","keyword":"arabic","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/m-ric/Open_Assistant_Conversation_Chains","creator_name":"Aymeric Roucher","creator_url":"https://huggingface.co/m-ric","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Dataset Name\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset description\\n\\t\\n\\n\\n\\nThis dataset is a reformatting of OpenAssistant Conversations (OASST1), which is\\n\\na human-generated, human-annotated assistant-style conversation corpus consisting of 161,443 messages in 35 different languages, annotated with 461,292 quality ratings, resulting in over 10,000 fully annotated conversation trees. The corpus is a product of a worldwide crowd-sourcing effort involving over 13,500 volunteers.\\n\\nIt wasâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/m-ric/Open_Assistant_Conversation_Chains.","first_N":5,"first_N_keywords":["text-generation","English","Spanish","Russian","German"],"keywords_longer_than_N":true},
	{"name":"librivox-tracks","keyword":"arabic","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/pykeio/librivox-tracks","creator_name":"pyke.io","creator_url":"https://huggingface.co/pykeio","description":"A dataset of all audio files uploaded to LibriVox before 26th September 2023.\\n","first_N":5,"first_N_keywords":["text-to-speech","automatic-speech-recognition","Achinese","Afrikaans","Ancient Greek (to 1453)"],"keywords_longer_than_N":true},
	{"name":"multilingual-tts","keyword":"arabic","license":"GNU General Public License v3.0","license_url":"https://choosealicense.com/licenses/gpl-3.0/","language":"en","dataset_url":"https://huggingface.co/datasets/MohamedRashad/multilingual-tts","creator_name":"Mohamed Rashad","creator_url":"https://huggingface.co/MohamedRashad","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tBefore Anything and Everything âš±\\n\\t\\n\\nIn the time of writing this Dataset Card, 17,490 18,412 civilian has been killed in Palestine (7,870 8,000 are children and 6,121 6,200 are women).\\nSeek any non-profit organization to help them with what you can (For myself, I use Mersal) ðŸ‡µðŸ‡¸\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThe Multilingual TTS dataset is an exceptional compilation of text-to-speech (TTS) samples, meticulously crafted to showcase the richness and diversity of human languages.â€¦ See the full description on the dataset page: https://huggingface.co/datasets/MohamedRashad/multilingual-tts.","first_N":5,"first_N_keywords":["text-to-speech","Arabic","English","Chinese","Spanish"],"keywords_longer_than_N":true},
	{"name":"multilingual-pl-bert","keyword":"arabic","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/styletts2-community/multilingual-pl-bert","creator_name":"StyleTTS 2 Community","creator_url":"https://huggingface.co/styletts2-community","description":"Attribution: Wikipedia.org\\n","first_N":5,"first_N_keywords":["Afrikaans","Aragonese","Arabic","Azerbaijani","Bashkir"],"keywords_longer_than_N":true},
	{"name":"Alukah-Arabic","keyword":"arabic","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ImruQays/Alukah-Arabic","creator_name":"Qays","creator_url":"https://huggingface.co/ImruQays","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tIntroduction\\n\\t\\n\\nThis dataset is a comprehensive collection of articles sourced from the Alukah website, a renowned platform offering extensive content primarily in Arabic. Alukah is known for its high-quality Arabic prose, significantly surpassing the standard found in contemporary media outlets. The majority of the articles are contributed by Muslim scholars, encompassing a wide range of topics related to Islam and the Muslim community. The dataset also includes a valuable sectionâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/ImruQays/Alukah-Arabic.","first_N":5,"first_N_keywords":["Arabic","cc-by-4.0","100K - 1M","csv","Text"],"keywords_longer_than_N":true},
	{"name":"Rasaif-Classical-Arabic-English-Parallel-texts","keyword":"arabic","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ImruQays/Rasaif-Classical-Arabic-English-Parallel-texts","creator_name":"Qays","creator_url":"https://huggingface.co/ImruQays","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tIntroduction\\n\\t\\n\\nThis dataset represents a curated collection of parallel Arabic-English texts, featuring the translations of 24 historically and culturally significant books. These texts provide a portal to the intellectual and literary heritage of the Arabic-speaking world during its classical period.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tContent Details\\n\\t\\n\\nContained within this dataset are English translations of the following texts, sourced from the Rasaif website:\\n\\nA Muslim Manual of War\\nAl-Haninâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/ImruQays/Rasaif-Classical-Arabic-English-Parallel-texts.","first_N":5,"first_N_keywords":["translation","Arabic","English","cc-by-4.0","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"ArzEn-MultiGenre","keyword":"arabic","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/HeshamHaroon/ArzEn-MultiGenre","creator_name":"Hesham Haroon","creator_url":"https://huggingface.co/HeshamHaroon","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tArzEn-MultiGenre: A Comprehensive Parallel Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tOverview\\n\\t\\n\\nArzEn-MultiGenre is a distinctive parallel dataset that encompasses a diverse collection of Egyptian Arabic content. This collection includes song lyrics, novels, and TV show subtitles, all of which have been meticulously translated and aligned with their English counterparts. The dataset serves as an invaluable tool for various linguistic and computational applications.\\nPublished: 28 Decemberâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/HeshamHaroon/ArzEn-MultiGenre.","first_N":5,"first_N_keywords":["translation","Arabic","English","cc-by-4.0","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"openassistant-deepseek-coder","keyword":"arabic","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Trelis/openassistant-deepseek-coder","creator_name":"Trelis","creator_url":"https://huggingface.co/Trelis","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tChat Fine-tuning Dataset - OpenAssistant DeepSeek Coder\\n\\t\\n\\nThis dataset allows for fine-tuning chat models using:\\nB_INST = '\\\\n### Instruction:\\\\n'\\nE_INST = '\\\\n### Response:\\\\n'\\nBOS = '<ï½œbeginâ–ofâ–sentenceï½œ>'\\nEOS = '\\\\n<|EOT|>\\\\n'\\n\\nSample Preparation:\\n\\nThe dataset is cloned from TimDettmers, which itself is a subset of the Open Assistant dataset, which you can find here. This subset of the data only contains the highest-rated paths in the conversation tree, with a total of 9,846 samples.â€¦ See the full description on the dataset page: https://huggingface.co/datasets/Trelis/openassistant-deepseek-coder.","first_N":5,"first_N_keywords":["English","Spanish","Russian","German","Polish"],"keywords_longer_than_N":true},
	{"name":"sib200","keyword":"arabic","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Davlan/sib200","creator_name":"David Adelani","creator_url":"https://huggingface.co/Davlan","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for SIB-200\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nSIB-200 is the largest publicly available topic classification dataset based on Flores-200 covering 205 languages and dialects.\\nThe train/validation/test sets are available for all the 205 languages.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSupported Tasks and Leaderboards\\n\\t\\n\\n\\ntopic classification: categorize wikipedia sentences into topics e.g science/technology, sports or politics.\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages\\n\\t\\n\\nThere are 205 languages available :â€¦ See the full description on the dataset page: https://huggingface.co/datasets/Davlan/sib200.","first_N":5,"first_N_keywords":["text-classification","topic-classification","found","expert-generated","multilingual"],"keywords_longer_than_N":true},
	{"name":"aya_collection","keyword":"arabic","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/CohereForAI/aya_collection","creator_name":"Cohere For AI","creator_url":"https://huggingface.co/CohereForAI","description":"\\nThis dataset is uploaded in two places: here and additionally here as 'Aya Collection Language Split.' These datasets are identical in content but differ in structure of upload. This dataset is structured by folders split according to dataset name. The version here instead divides the Aya collection into folders split by language. We recommend you use the language split version if you are only interested in downloading data for a single or smaller set of languages, and this version if youâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/CohereForAI/aya_collection.","first_N":5,"first_N_keywords":["text-classification","summarization","translation","Achinese","Afrikaans"],"keywords_longer_than_N":true},
	{"name":"Open-ArabicaQA","keyword":"arabic","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/abdoelsayed/Open-ArabicaQA","creator_name":"unkown","creator_url":"https://huggingface.co/abdoelsayed","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tArabicaQA\\n\\t\\n\\nArabicaQA: Comprehensive Dataset for Arabic Question Answering\\nThis repository contains dataset for paper ArabicaQA: Comprehensive Dataset for Arabic Question Answering. Below, we provide details regarding the materials available in this repository:\\nArabicaQA is a robust dataset designed to support and advance the development of Arabic Question Answering (QA) systems. This dataset encompasses a wide range of question types, including both Machine Reading Comprehensionâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/abdoelsayed/Open-ArabicaQA.","first_N":5,"first_N_keywords":["question-answering","crowdsourced","crowdsourced","found","Arabic"],"keywords_longer_than_N":true},
	{"name":"arabic-qna","keyword":"arabic","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/sadeem-ai/arabic-qna","creator_name":"Sadeem","creator_url":"https://huggingface.co/sadeem-ai","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSadeem QnA: An Arabic QnA Dataset ðŸŒâœ¨\\n\\t\\n\\nWelcome to the Sadeem QnA dataset, a vibrant collection designed for the advancement of Arabic natural language processing, specifically tailored for Question Answering (QnA) systems. Sourced from the rich and diverse content of Arabic Wikipedia, this dataset is a gateway to exploring the depths of Arabic language understanding, offering a unique challenge to both researchers and AI enthusiasts alike.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tAbout Sadeem QnA\\n\\t\\n\\nTheâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/sadeem-ai/arabic-qna.","first_N":5,"first_N_keywords":["question-answering","Arabic","apache-2.0","1K - 10K","csv"],"keywords_longer_than_N":true},
	{"name":"aya_evaluation_suite","keyword":"arabic","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/CohereForAI/aya_evaluation_suite","creator_name":"Cohere For AI","creator_url":"https://huggingface.co/CohereForAI","description":"\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nAya Evaluation Suite contains a total of 26,750 open-ended conversation-style prompts to evaluate multilingual open-ended generation quality.To strike a balance between language coverage and the quality that comes with human curation, we create an evaluation suite that includes:\\n\\nhuman-curated examples in 7 languages (tur, eng, yor, arb, zho, por, tel) â†’ aya-human-annotated.\\nmachine-translations of handpicked examples into 101 languages â†’â€¦ See the full description on the dataset page: https://huggingface.co/datasets/CohereForAI/aya_evaluation_suite.","first_N":5,"first_N_keywords":["text-generation","crowdsourced","expert-generated","machine-generated","multilingual"],"keywords_longer_than_N":true},
	{"name":"CulturaY","keyword":"arabic","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ontocord/CulturaY","creator_name":"Ontocord.AI","creator_url":"https://huggingface.co/ontocord","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tCulturaY: A Large Cleaned Multilingual Dataset of 75 Languages\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nFrom the team that brought you CulturaX, we present CulturaY, another substantial multilingual dataset of 15TB (uncompressed)/3TB (zstd-compressed) that applies the same dataset cleaning methodology to the HPLT v1.1 dataset. \\nPlease note that HPLT v1.2 has also been released and is an alternative verison with different cleaning methodolgies. \\nThis data was used in part to train our SOTAâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/ontocord/CulturaY.","first_N":5,"first_N_keywords":["text-generation","fill-mask","language-modeling","masked-language-modeling","no-annotation"],"keywords_longer_than_N":true},
	{"name":"sib200","keyword":"egyptian arabic","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Davlan/sib200","creator_name":"David Adelani","creator_url":"https://huggingface.co/Davlan","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for SIB-200\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nSIB-200 is the largest publicly available topic classification dataset based on Flores-200 covering 205 languages and dialects.\\nThe train/validation/test sets are available for all the 205 languages.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSupported Tasks and Leaderboards\\n\\t\\n\\n\\ntopic classification: categorize wikipedia sentences into topics e.g science/technology, sports or politics.\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages\\n\\t\\n\\nThere are 205 languages available :â€¦ See the full description on the dataset page: https://huggingface.co/datasets/Davlan/sib200.","first_N":5,"first_N_keywords":["text-classification","topic-classification","found","expert-generated","multilingual"],"keywords_longer_than_N":true},
	{"name":"aya_dataset","keyword":"egyptian arabic","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/CohereForAI/aya_dataset","creator_name":"Cohere For AI","creator_url":"https://huggingface.co/CohereForAI","description":"\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThe Aya Dataset is a multilingual instruction fine-tuning dataset curated by an open-science community via Aya Annotation Platform from Cohere For AI. The dataset contains a total of 204k human-annotated prompt-completion pairs along with the demographics data of the annotators.\\nThis dataset can be used to train, finetune, and evaluate multilingual LLMs.\\n\\nCurated by: Contributors of Aya Open Science Intiative.\\n\\nLanguage(s): 65 languages (71 including dialects &â€¦ See the full description on the dataset page: https://huggingface.co/datasets/CohereForAI/aya_dataset.","first_N":5,"first_N_keywords":["other","crowdsourced","expert-generated","crowdsourced","expert-generated"],"keywords_longer_than_N":true},
	{"name":"sib200","keyword":"levantine arabic","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Davlan/sib200","creator_name":"David Adelani","creator_url":"https://huggingface.co/Davlan","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for SIB-200\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nSIB-200 is the largest publicly available topic classification dataset based on Flores-200 covering 205 languages and dialects.\\nThe train/validation/test sets are available for all the 205 languages.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSupported Tasks and Leaderboards\\n\\t\\n\\n\\ntopic classification: categorize wikipedia sentences into topics e.g science/technology, sports or politics.\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages\\n\\t\\n\\nThere are 205 languages available :â€¦ See the full description on the dataset page: https://huggingface.co/datasets/Davlan/sib200.","first_N":5,"first_N_keywords":["text-classification","topic-classification","found","expert-generated","multilingual"],"keywords_longer_than_N":true},
	{"name":"aya_dataset","keyword":"levantine arabic","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/CohereForAI/aya_dataset","creator_name":"Cohere For AI","creator_url":"https://huggingface.co/CohereForAI","description":"\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThe Aya Dataset is a multilingual instruction fine-tuning dataset curated by an open-science community via Aya Annotation Platform from Cohere For AI. The dataset contains a total of 204k human-annotated prompt-completion pairs along with the demographics data of the annotators.\\nThis dataset can be used to train, finetune, and evaluate multilingual LLMs.\\n\\nCurated by: Contributors of Aya Open Science Intiative.\\n\\nLanguage(s): 65 languages (71 including dialects &â€¦ See the full description on the dataset page: https://huggingface.co/datasets/CohereForAI/aya_dataset.","first_N":5,"first_N_keywords":["other","crowdsourced","expert-generated","crowdsourced","expert-generated"],"keywords_longer_than_N":true},
	{"name":"sib200","keyword":"mesopotamian arabic","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Davlan/sib200","creator_name":"David Adelani","creator_url":"https://huggingface.co/Davlan","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for SIB-200\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nSIB-200 is the largest publicly available topic classification dataset based on Flores-200 covering 205 languages and dialects.\\nThe train/validation/test sets are available for all the 205 languages.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSupported Tasks and Leaderboards\\n\\t\\n\\n\\ntopic classification: categorize wikipedia sentences into topics e.g science/technology, sports or politics.\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages\\n\\t\\n\\nThere are 205 languages available :â€¦ See the full description on the dataset page: https://huggingface.co/datasets/Davlan/sib200.","first_N":5,"first_N_keywords":["text-classification","topic-classification","found","expert-generated","multilingual"],"keywords_longer_than_N":true},
	{"name":"sib200","keyword":"moroccan arabic","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Davlan/sib200","creator_name":"David Adelani","creator_url":"https://huggingface.co/Davlan","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for SIB-200\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nSIB-200 is the largest publicly available topic classification dataset based on Flores-200 covering 205 languages and dialects.\\nThe train/validation/test sets are available for all the 205 languages.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSupported Tasks and Leaderboards\\n\\t\\n\\n\\ntopic classification: categorize wikipedia sentences into topics e.g science/technology, sports or politics.\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages\\n\\t\\n\\nThere are 205 languages available :â€¦ See the full description on the dataset page: https://huggingface.co/datasets/Davlan/sib200.","first_N":5,"first_N_keywords":["text-classification","topic-classification","found","expert-generated","multilingual"],"keywords_longer_than_N":true},
	{"name":"aya_dataset","keyword":"moroccan arabic","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/CohereForAI/aya_dataset","creator_name":"Cohere For AI","creator_url":"https://huggingface.co/CohereForAI","description":"\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThe Aya Dataset is a multilingual instruction fine-tuning dataset curated by an open-science community via Aya Annotation Platform from Cohere For AI. The dataset contains a total of 204k human-annotated prompt-completion pairs along with the demographics data of the annotators.\\nThis dataset can be used to train, finetune, and evaluate multilingual LLMs.\\n\\nCurated by: Contributors of Aya Open Science Intiative.\\n\\nLanguage(s): 65 languages (71 including dialects &â€¦ See the full description on the dataset page: https://huggingface.co/datasets/CohereForAI/aya_dataset.","first_N":5,"first_N_keywords":["other","crowdsourced","expert-generated","crowdsourced","expert-generated"],"keywords_longer_than_N":true},
	{"name":"sib200","keyword":"najdi arabic","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Davlan/sib200","creator_name":"David Adelani","creator_url":"https://huggingface.co/Davlan","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for SIB-200\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nSIB-200 is the largest publicly available topic classification dataset based on Flores-200 covering 205 languages and dialects.\\nThe train/validation/test sets are available for all the 205 languages.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSupported Tasks and Leaderboards\\n\\t\\n\\n\\ntopic classification: categorize wikipedia sentences into topics e.g science/technology, sports or politics.\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages\\n\\t\\n\\nThere are 205 languages available :â€¦ See the full description on the dataset page: https://huggingface.co/datasets/Davlan/sib200.","first_N":5,"first_N_keywords":["text-classification","topic-classification","found","expert-generated","multilingual"],"keywords_longer_than_N":true},
	{"name":"aya_dataset","keyword":"najdi arabic","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/CohereForAI/aya_dataset","creator_name":"Cohere For AI","creator_url":"https://huggingface.co/CohereForAI","description":"\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThe Aya Dataset is a multilingual instruction fine-tuning dataset curated by an open-science community via Aya Annotation Platform from Cohere For AI. The dataset contains a total of 204k human-annotated prompt-completion pairs along with the demographics data of the annotators.\\nThis dataset can be used to train, finetune, and evaluate multilingual LLMs.\\n\\nCurated by: Contributors of Aya Open Science Intiative.\\n\\nLanguage(s): 65 languages (71 including dialects &â€¦ See the full description on the dataset page: https://huggingface.co/datasets/CohereForAI/aya_dataset.","first_N":5,"first_N_keywords":["other","crowdsourced","expert-generated","crowdsourced","expert-generated"],"keywords_longer_than_N":true},
	{"name":"sib200","keyword":"tunisian arabic","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Davlan/sib200","creator_name":"David Adelani","creator_url":"https://huggingface.co/Davlan","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for SIB-200\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nSIB-200 is the largest publicly available topic classification dataset based on Flores-200 covering 205 languages and dialects.\\nThe train/validation/test sets are available for all the 205 languages.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSupported Tasks and Leaderboards\\n\\t\\n\\n\\ntopic classification: categorize wikipedia sentences into topics e.g science/technology, sports or politics.\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages\\n\\t\\n\\nThere are 205 languages available :â€¦ See the full description on the dataset page: https://huggingface.co/datasets/Davlan/sib200.","first_N":5,"first_N_keywords":["text-classification","topic-classification","found","expert-generated","multilingual"],"keywords_longer_than_N":true},
	{"name":"aya_dataset","keyword":"standard arabic","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/CohereForAI/aya_dataset","creator_name":"Cohere For AI","creator_url":"https://huggingface.co/CohereForAI","description":"\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThe Aya Dataset is a multilingual instruction fine-tuning dataset curated by an open-science community via Aya Annotation Platform from Cohere For AI. The dataset contains a total of 204k human-annotated prompt-completion pairs along with the demographics data of the annotators.\\nThis dataset can be used to train, finetune, and evaluate multilingual LLMs.\\n\\nCurated by: Contributors of Aya Open Science Intiative.\\n\\nLanguage(s): 65 languages (71 including dialects &â€¦ See the full description on the dataset page: https://huggingface.co/datasets/CohereForAI/aya_dataset.","first_N":5,"first_N_keywords":["other","crowdsourced","expert-generated","crowdsourced","expert-generated"],"keywords_longer_than_N":true},
	{"name":"sib200","keyword":"ta'izzi-adeni arabic","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Davlan/sib200","creator_name":"David Adelani","creator_url":"https://huggingface.co/Davlan","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for SIB-200\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nSIB-200 is the largest publicly available topic classification dataset based on Flores-200 covering 205 languages and dialects.\\nThe train/validation/test sets are available for all the 205 languages.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSupported Tasks and Leaderboards\\n\\t\\n\\n\\ntopic classification: categorize wikipedia sentences into topics e.g science/technology, sports or politics.\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages\\n\\t\\n\\nThere are 205 languages available :â€¦ See the full description on the dataset page: https://huggingface.co/datasets/Davlan/sib200.","first_N":5,"first_N_keywords":["text-classification","topic-classification","found","expert-generated","multilingual"],"keywords_longer_than_N":true},
	{"name":"aya_dataset","keyword":"ta'izzi-adeni arabic","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/CohereForAI/aya_dataset","creator_name":"Cohere For AI","creator_url":"https://huggingface.co/CohereForAI","description":"\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThe Aya Dataset is a multilingual instruction fine-tuning dataset curated by an open-science community via Aya Annotation Platform from Cohere For AI. The dataset contains a total of 204k human-annotated prompt-completion pairs along with the demographics data of the annotators.\\nThis dataset can be used to train, finetune, and evaluate multilingual LLMs.\\n\\nCurated by: Contributors of Aya Open Science Intiative.\\n\\nLanguage(s): 65 languages (71 including dialects &â€¦ See the full description on the dataset page: https://huggingface.co/datasets/CohereForAI/aya_dataset.","first_N":5,"first_N_keywords":["other","crowdsourced","expert-generated","crowdsourced","expert-generated"],"keywords_longer_than_N":true},
	{"name":"Arabic_dialects_to_MSA","keyword":"arabic","license":"Academic Free License v3.0","license_url":"https://choosealicense.com/licenses/afl-3.0/","language":"en","dataset_url":"https://huggingface.co/datasets/PRAli22/Arabic_dialects_to_MSA","creator_name":"ali ragab","creator_url":"https://huggingface.co/PRAli22","description":"PRAli22/Arabic_dialects_to_MSA dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["Arabic","afl-3.0","100K - 1M","csv","Text"],"keywords_longer_than_N":true},
	{"name":"XMedbench","keyword":"arabic","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/FreedomIntelligence/XMedbench","creator_name":"FreedomAI","creator_url":"https://huggingface.co/FreedomIntelligence","description":"\\n\\t\\n\\t\\t\\n\\t\\tMultilingual Medicine: Model, Dataset, Benchmark, Code\\n\\t\\n\\nCovering English, Chinese, French, Hindi, Spanish, Hindi, Arabic So far\\n\\n   ðŸ‘¨ðŸ»â€ðŸ’»Github â€¢ðŸ“ƒ Paper â€¢ ðŸ¤— ApolloCorpus â€¢ ðŸ¤— XMedBench \\n      ä¸­æ–‡  |  English\\n\\n\\n\\n\\n\\n\\t\\t\\n\\t\\tðŸŒˆ Update\\n\\t\\n\\n\\n[2024.03.07] Paper released.\\n[2024.02.12] ApolloCorpus and  XMedBench  is publishedï¼ðŸŽ‰\\n[2024.01.23] Apollo repo is publishedï¼ðŸŽ‰\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tResults\\n\\t\\n\\n   \\n\\n\\t\\n\\t\\t\\n\\t\\tUsage\\n\\t\\n\\n\\nZip File\\nData category\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tData:\\n\\t\\n\\n\\nEN:\\n\\nMedQA-USMLE \\nMedMCQA\\nPubMedQA:â€¦ See the full description on the dataset page: https://huggingface.co/datasets/FreedomIntelligence/XMedbench.","first_N":5,"first_N_keywords":["French","English","Spanish","Chinese","Arabic"],"keywords_longer_than_N":true},
	{"name":"ALLaVA-4V-Arabic","keyword":"arabic","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/FreedomIntelligence/ALLaVA-4V-Arabic","creator_name":"FreedomAI","creator_url":"https://huggingface.co/FreedomIntelligence","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tALLaVA-4V for Arabic\\n\\t\\n\\nThis is the Arabic version of the ALLaVA-4V data. We have translated the ALLaVA-4V data into Arabic through ChatGPT and instructed ChatGPT not to translate content related to OCR.\\nThe original dataset can be found here, and the image data can be downloaded from ALLaVA-4V.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tCitation\\n\\t\\n\\nIf you find our data useful, please consider citing our work! We are FreedomIntelligence from Shenzhen Research Institute of Big Data and The Chinese University ofâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/FreedomIntelligence/ALLaVA-4V-Arabic.","first_N":5,"first_N_keywords":["question-answering","text-generation","Arabic","apache-2.0","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"aya_collection_language_split","keyword":"arabic","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/CohereForAI/aya_collection_language_split","creator_name":"Cohere For AI","creator_url":"https://huggingface.co/CohereForAI","description":"\\nThis is a re-upload of the aya_collection, and only differs in the structure of upload. While the original aya_collection is structured by folders split according to dataset name, this dataset is split by language. We recommend you use this version of the dataset if you are only interested in downloading all of the Aya collection for a single or smaller set of languages.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThe Aya Collection is a massive multilingual collection consisting of 513 million instancesâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/CohereForAI/aya_collection_language_split.","first_N":5,"first_N_keywords":["Achinese","Afrikaans","Amharic","Arabic","Azerbaijani"],"keywords_longer_than_N":true},
	{"name":"tokenizer-wiki-bench","keyword":"arabic","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/occiglot/tokenizer-wiki-bench","creator_name":"Occiglot","creator_url":"https://huggingface.co/occiglot","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tMultilingual Tokenizer Benchmark\\n\\t\\n\\nThis dataset includes pre-processed wikipedia data for tokenizer evaluation in 45 languages. We provide more information on the evaluation task in general this blogpost.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tUsage\\n\\t\\n\\nThe dataset allows us to easily calculate tokenizer fertility and the proportion of continued words on any of the supported languages. In the example below we take the Mistral tokenizer and evaluate its performance on Slovak. \\nfrom transformers importâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/occiglot/tokenizer-wiki-bench.","first_N":5,"first_N_keywords":["Afrikaans","Arabic","Bulgarian","Catalan","Czech"],"keywords_longer_than_N":true},
	{"name":"MediaSpeech","keyword":"arabic","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ymoslem/MediaSpeech","creator_name":"Yasmin Moslem","creator_url":"https://huggingface.co/ymoslem","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tMediaSpeech\\n\\t\\n\\nMediaSpeech is a dataset of Arabic, French, Spanish, and Turkish media speech built with the purpose of testing Automated Speech Recognition (ASR) systems performance. The dataset contains 10 hours of speech for each language provided.\\nThe dataset consists of short speech segments automatically extracted from media videos available on YouTube and manually transcribed, with some pre-processing and post-processing.\\nBaseline models and WAV version of the dataset can beâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/ymoslem/MediaSpeech.","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","Arabic","French","Spanish"],"keywords_longer_than_N":true},
	{"name":"Table-Extraction","keyword":"arabic","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Effyis/Table-Extraction","creator_name":"Group","creator_url":"https://huggingface.co/Effyis","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tTable Extract Dataset\\n\\t\\n\\nThis dataset is designed to evaluate the ability of large language models (LLMs) to extract tables from text. It provides a collection of text snippets containing tables and their corresponding structured representations in JSON format.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSource\\n\\t\\n\\nThe dataset is based on the Table Fact Dataset, also known as TabFact, which contains 16,573 tables extracted from Wikipedia.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSchema:\\n\\t\\n\\nEach data point in the dataset consists of twoâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Effyis/Table-Extraction.","first_N":5,"first_N_keywords":["feature-extraction","English","Arabic","apache-2.0","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"orca_dpo_pairs","keyword":"arabic","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/multilingual/orca_dpo_pairs","creator_name":"mLLM multilingual","creator_url":"https://huggingface.co/multilingual","description":"\\n    \\n\\n\\nmLLM IMPLEMENTATION OF Intel/orca_dpo_pairs.\\nLANGUAGES:\\nARABIC\\nCHINESE\\nFRENCH\\nGERMAN\\nRUSSIAN\\nSPANISH\\nTURKISH\\n(WIP)\\n","first_N":5,"first_N_keywords":["text-generation","Arabic","Chinese","German","French"],"keywords_longer_than_N":true},
	{"name":"101_billion_arabic_words_dataset","keyword":"arabic","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ClusterlabAi/101_billion_arabic_words_dataset","creator_name":"ClusterlabAi","creator_url":"https://huggingface.co/ClusterlabAi","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\t101 Billion Arabic Words Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tUpdates\\n\\t\\n\\n\\nMaintenance Status: Actively Maintained\\nUpdate Frequency: Weekly updates to refine data quality and expand coverage.\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tUpcoming Version\\n\\t\\n\\n\\nMore Cleaned Version: A more cleaned version of the dataset is in processing, which includes the addition of a UUID column for better data traceability and management.\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Details\\n\\t\\n\\nThe 101 Billion Arabic Words Dataset is curated by the Clusterlab team andâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/ClusterlabAi/101_billion_arabic_words_dataset.","first_N":5,"first_N_keywords":["text-generation","Arabic","apache-2.0","10M - 100M","parquet"],"keywords_longer_than_N":true},
	{"name":"ClArTTS","keyword":"arabic","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/MBZUAI/ClArTTS","creator_name":"Mohamed Bin Zayed University of Artificial Intelligence","creator_url":"https://huggingface.co/MBZUAI","description":"\\n\\t\\n\\t\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nWe present a speech corpus for Classical Arabic Text-to-Speech (ClArTTS) to support the development of end-to-end TTS systems for Arabic. The speech is extracted from a LibriVox audiobook, which is then processed, segmented, and manually transcribed and annotated. The final ClArTTS corpus contains about 12 hours of speech from a single male speaker sampled at 40100 kHz.\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Structure\\n\\t\\n\\nA typical data point comprises the name of the audio file, calledâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/MBZUAI/ClArTTS.","first_N":5,"first_N_keywords":["text-to-speech","text-to-audio","Arabic","cc-by-4.0","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"swim-ir-monolingual","keyword":"arabic","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/nthakur/swim-ir-monolingual","creator_name":"Nandan Thakur","creator_url":"https://huggingface.co/nthakur","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for SWIM-IR (Monolingual)\\n\\t\\n\\n\\n\\n\\nThis is the monolingual subset of the SWIM-IR dataset, where the query generated and the passage are both in the same language.\\nA few remaining languages will be added in the upcoming v2 version of SWIM-IR. The dataset is available as CC-BY-SA 4.0.\\nFor full details of the dataset, please read our upcoming NAACL 2024 paper and check out our website.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tWhat is SWIM-IR?\\n\\t\\n\\nSWIM-IR dataset is a synthetic multilingual retrievalâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/nthakur/swim-ir-monolingual.","first_N":5,"first_N_keywords":["text-retrieval","question-answering","machine-generated","monolingual","original"],"keywords_longer_than_N":true},
	{"name":"webui-dom-snapshots","keyword":"arabic","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/gbenson/webui-dom-snapshots","creator_name":"Gary Benson","creator_url":"https://huggingface.co/gbenson","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for WebUI DOM snapshots\\n\\t\\n\\n\\n\\nThis dataset card aims to be a base template for new datasets. It has been generated using this raw template.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Details\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\n\\n\\n\\n\\n\\nCurated by: Gary Benson\\nLanguages: Mostly English (87%);\\nDutch, French, Chinese, Japanese (1-2% each); 30+ others (<1% each)\\nLicense: CC0 1.0 Universal\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Sources [optional]\\n\\t\\n\\n\\n\\n\\nRepository: [More Information Needed]\\nPaper [optional]: [Moreâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/gbenson/webui-dom-snapshots.","first_N":5,"first_N_keywords":["image-feature-extraction","reinforcement-learning","text-classification","multilingual","biglab/webui-7k"],"keywords_longer_than_N":true},
	{"name":"Arabic_Offensive_Comment_Detection","keyword":"arabic","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/asas-ai/Arabic_Offensive_Comment_Detection","creator_name":"ASAS AI","creator_url":"https://huggingface.co/asas-ai","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for \\\"Arabic_Offensive_Comment_Detection\\\"\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tPaper:\\n\\t\\n\\nShammur Absar Chowdhury, Hamdy Mubarak, Ahmed Abdelali, Soon-gyo Jung, Bernard J. Jansen, and Joni Salminen. 2020. A Multi-Platform Arabic News Comment Dataset for Offensive Language Detection. In Proceedings of the Twelfth Language Resources and Evaluation Conference, pages 6203â€“6212, Marseille, France. European Language Resources Association.\\n","first_N":5,"first_N_keywords":["text-classification","Arabic","apache-2.0","1K - 10K","parquet"],"keywords_longer_than_N":true},
	{"name":"ANERCorp","keyword":"arabic","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/asas-ai/ANERCorp","creator_name":"ASAS AI","creator_url":"https://huggingface.co/asas-ai","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for \\\"ANERCorp\\\"\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tPapers:\\n\\t\\n\\nBenajiba, Yassine, Paolo Rosso, and JosÃ© Miguel BenedÃ­ Ruiz. \\\"Anersys: An Arabic named entity recognition system based on maximum entropy.\\\" In International Conference on Intelligent Text Processing and Computational Linguistics, pp. 143-153. Springer, Berlin, Heidelberg, 2007.\\nOssama Obeid, Nasser Zalmout, Salam Khalifa, Dima Taji, Mai Oudah, Bashar Alhafni, Go Inoue, Fadhl Eryani, Alexander Erdmann, and Nizar Habash. \\\"CAMeLâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/asas-ai/ANERCorp.","first_N":5,"first_N_keywords":["token-classification","Arabic","cc-by-sa-4.0","100K - 1M","parquet"],"keywords_longer_than_N":true},
	{"name":"xvnli","keyword":"arabic","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/floschne/xvnli","creator_name":"Flo Schneider","creator_url":"https://huggingface.co/floschne","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tXVNLI\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tThis is a copy from the original repo: https://github.com/e-bug/iglue\\n\\t\\n\\nIf you use this dataset, please cite the original authors:\\n@inproceedings{bugliarello-etal-2022-iglue,\\n  title = \\t {{IGLUE}: A Benchmark for Transfer Learning across Modalities, Tasks, and Languages},\\n  author =       {Bugliarello, Emanuele and Liu, Fangyu and Pfeiffer, Jonas and Reddy, Siva and Elliott, Desmond and Ponti, Edoardo Maria and Vuli{\\\\'c}, Ivan},\\n  booktitle = \\t {Proceedings ofâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/floschne/xvnli.","first_N":5,"first_N_keywords":["visual-question-answering","Arabic","English","Spanish","French"],"keywords_longer_than_N":true},
	{"name":"GlotCC-V1","keyword":"arabic","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/cis-lmu/GlotCC-V1","creator_name":"CIS, LMU Munich","creator_url":"https://huggingface.co/cis-lmu","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\n \\n\\nGlotCC-V1.0 is a document-level, general domain dataset derived from CommonCrawl, covering more than 1000 languages.It is built using the GlotLID language identification and Ungoliant pipeline from CommonCrawl.We release our pipeline as open-source at https://github.com/cisnlp/GlotCC.  \\nList of Languages: See https://datasets-server.huggingface.co/splits?dataset=cis-lmu/GlotCC-V1 to get the list of splits available.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tUsage (Huggingface Hub --â€¦ See the full description on the dataset page: https://huggingface.co/datasets/cis-lmu/GlotCC-V1.","first_N":5,"first_N_keywords":["multilingual","Abau","Amarasi","Abkhaz","Abkhazian"],"keywords_longer_than_N":true},
	{"name":"GlotCC-V1","keyword":"egyptian arabic","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/cis-lmu/GlotCC-V1","creator_name":"CIS, LMU Munich","creator_url":"https://huggingface.co/cis-lmu","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\n \\n\\nGlotCC-V1.0 is a document-level, general domain dataset derived from CommonCrawl, covering more than 1000 languages.It is built using the GlotLID language identification and Ungoliant pipeline from CommonCrawl.We release our pipeline as open-source at https://github.com/cisnlp/GlotCC.  \\nList of Languages: See https://datasets-server.huggingface.co/splits?dataset=cis-lmu/GlotCC-V1 to get the list of splits available.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tUsage (Huggingface Hub --â€¦ See the full description on the dataset page: https://huggingface.co/datasets/cis-lmu/GlotCC-V1.","first_N":5,"first_N_keywords":["multilingual","Abau","Amarasi","Abkhaz","Abkhazian"],"keywords_longer_than_N":true},
	{"name":"GlotCC-V1","keyword":"levantine arabic","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/cis-lmu/GlotCC-V1","creator_name":"CIS, LMU Munich","creator_url":"https://huggingface.co/cis-lmu","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\n \\n\\nGlotCC-V1.0 is a document-level, general domain dataset derived from CommonCrawl, covering more than 1000 languages.It is built using the GlotLID language identification and Ungoliant pipeline from CommonCrawl.We release our pipeline as open-source at https://github.com/cisnlp/GlotCC.  \\nList of Languages: See https://datasets-server.huggingface.co/splits?dataset=cis-lmu/GlotCC-V1 to get the list of splits available.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tUsage (Huggingface Hub --â€¦ See the full description on the dataset page: https://huggingface.co/datasets/cis-lmu/GlotCC-V1.","first_N":5,"first_N_keywords":["multilingual","Abau","Amarasi","Abkhaz","Abkhazian"],"keywords_longer_than_N":true},
	{"name":"GlotCC-V1","keyword":"mesopotamian arabic","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/cis-lmu/GlotCC-V1","creator_name":"CIS, LMU Munich","creator_url":"https://huggingface.co/cis-lmu","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\n \\n\\nGlotCC-V1.0 is a document-level, general domain dataset derived from CommonCrawl, covering more than 1000 languages.It is built using the GlotLID language identification and Ungoliant pipeline from CommonCrawl.We release our pipeline as open-source at https://github.com/cisnlp/GlotCC.  \\nList of Languages: See https://datasets-server.huggingface.co/splits?dataset=cis-lmu/GlotCC-V1 to get the list of splits available.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tUsage (Huggingface Hub --â€¦ See the full description on the dataset page: https://huggingface.co/datasets/cis-lmu/GlotCC-V1.","first_N":5,"first_N_keywords":["multilingual","Abau","Amarasi","Abkhaz","Abkhazian"],"keywords_longer_than_N":true},
	{"name":"GlotCC-V1","keyword":"moroccan arabic","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/cis-lmu/GlotCC-V1","creator_name":"CIS, LMU Munich","creator_url":"https://huggingface.co/cis-lmu","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\n \\n\\nGlotCC-V1.0 is a document-level, general domain dataset derived from CommonCrawl, covering more than 1000 languages.It is built using the GlotLID language identification and Ungoliant pipeline from CommonCrawl.We release our pipeline as open-source at https://github.com/cisnlp/GlotCC.  \\nList of Languages: See https://datasets-server.huggingface.co/splits?dataset=cis-lmu/GlotCC-V1 to get the list of splits available.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tUsage (Huggingface Hub --â€¦ See the full description on the dataset page: https://huggingface.co/datasets/cis-lmu/GlotCC-V1.","first_N":5,"first_N_keywords":["multilingual","Abau","Amarasi","Abkhaz","Abkhazian"],"keywords_longer_than_N":true},
	{"name":"GlotCC-V1","keyword":"najdi arabic","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/cis-lmu/GlotCC-V1","creator_name":"CIS, LMU Munich","creator_url":"https://huggingface.co/cis-lmu","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\n \\n\\nGlotCC-V1.0 is a document-level, general domain dataset derived from CommonCrawl, covering more than 1000 languages.It is built using the GlotLID language identification and Ungoliant pipeline from CommonCrawl.We release our pipeline as open-source at https://github.com/cisnlp/GlotCC.  \\nList of Languages: See https://datasets-server.huggingface.co/splits?dataset=cis-lmu/GlotCC-V1 to get the list of splits available.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tUsage (Huggingface Hub --â€¦ See the full description on the dataset page: https://huggingface.co/datasets/cis-lmu/GlotCC-V1.","first_N":5,"first_N_keywords":["multilingual","Abau","Amarasi","Abkhaz","Abkhazian"],"keywords_longer_than_N":true},
	{"name":"GlotCC-V1","keyword":"tunisian arabic","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/cis-lmu/GlotCC-V1","creator_name":"CIS, LMU Munich","creator_url":"https://huggingface.co/cis-lmu","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\n \\n\\nGlotCC-V1.0 is a document-level, general domain dataset derived from CommonCrawl, covering more than 1000 languages.It is built using the GlotLID language identification and Ungoliant pipeline from CommonCrawl.We release our pipeline as open-source at https://github.com/cisnlp/GlotCC.  \\nList of Languages: See https://datasets-server.huggingface.co/splits?dataset=cis-lmu/GlotCC-V1 to get the list of splits available.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tUsage (Huggingface Hub --â€¦ See the full description on the dataset page: https://huggingface.co/datasets/cis-lmu/GlotCC-V1.","first_N":5,"first_N_keywords":["multilingual","Abau","Amarasi","Abkhaz","Abkhazian"],"keywords_longer_than_N":true},
	{"name":"GlotCC-V1","keyword":"standard arabic","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/cis-lmu/GlotCC-V1","creator_name":"CIS, LMU Munich","creator_url":"https://huggingface.co/cis-lmu","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\n \\n\\nGlotCC-V1.0 is a document-level, general domain dataset derived from CommonCrawl, covering more than 1000 languages.It is built using the GlotLID language identification and Ungoliant pipeline from CommonCrawl.We release our pipeline as open-source at https://github.com/cisnlp/GlotCC.  \\nList of Languages: See https://datasets-server.huggingface.co/splits?dataset=cis-lmu/GlotCC-V1 to get the list of splits available.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tUsage (Huggingface Hub --â€¦ See the full description on the dataset page: https://huggingface.co/datasets/cis-lmu/GlotCC-V1.","first_N":5,"first_N_keywords":["multilingual","Abau","Amarasi","Abkhaz","Abkhazian"],"keywords_longer_than_N":true},
	{"name":"Arabic-NLi-Triplet","keyword":"arabic","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Omartificial-Intelligence-Space/Arabic-NLi-Triplet","creator_name":"Omartificial Intelligence Space","creator_url":"https://huggingface.co/Omartificial-Intelligence-Space","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tArabic NLI Triplet\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\n\\nThe Arabic Version of SNLI and MultiNLI datasets. (Triplet Subset)\\nOriginally used for Natural Language Inference (NLI), \\nDataset may be used for training/finetuning an embedding model for semantic textual similarity.\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tTriplet Subset\\n\\t\\n\\n\\nColumns: \\\"anchor\\\", \\\"positive\\\", \\\"negative\\\"\\nColumn types: str, str, str\\n\\nExamples:\\n{\\n  \\\"anchor\\\": \\\"Ø´Ø®Øµ Ø¹Ù„Ù‰ Ø­ØµØ§Ù† ÙŠÙ‚ÙØ² ÙÙˆÙ‚ Ø·Ø§Ø¦Ø±Ø© Ù…Ø¹Ø·Ù„Ø©\\\",\\n  \\\"positive\\\": \\\"Ø´Ø®Øµ ÙÙŠ Ø§Ù„Ù‡ÙˆØ§Ø¡ Ø§Ù„Ø·Ù„Ù‚ØŒ Ø¹Ù„Ù‰ Ø­ØµØ§Ù†.\\\"â€¦ See the full description on the dataset page: https://huggingface.co/datasets/Omartificial-Intelligence-Space/Arabic-NLi-Triplet.","first_N":5,"first_N_keywords":["sentence-similarity","Arabic","apache-2.0","100K - 1M","csv"],"keywords_longer_than_N":true},
	{"name":"Arabic-stsb","keyword":"arabic","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Omartificial-Intelligence-Space/Arabic-stsb","creator_name":"Omartificial Intelligence Space","creator_url":"https://huggingface.co/Omartificial-Intelligence-Space","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tArabic STSB Structure\\n\\t\\n\\n\\nThe Arabic Version  of the the Semantic Textual Similarity Benchmark (Cer et al., 2017)\\nit is a collection of sentence pairs drawn from news headlines, video and image captions, and natural language inference data.\\nEach pair is human-annotated with a similarity score from 1 to 5. However, for this variant, the similarity scores are normalized to between 0 and 1.\\n\\nExamples:\\n{\\n  \\\"sentence1\\\": \\\"Ø·Ø§Ø¦Ø±Ø© Ø³ØªÙ‚Ù„Ø¹\\\",\\n  \\\"sentence2\\\": \\\"Ø·Ø§Ø¦Ø±Ø© Ø¬ÙˆÙŠØ© Ø³ØªÙ‚Ù„Ø¹\\\",\\n  \\\"score\\\": 1.0\\n}â€¦ See the full description on the dataset page: https://huggingface.co/datasets/Omartificial-Intelligence-Space/Arabic-stsb.","first_N":5,"first_N_keywords":["sentence-similarity","Arabic","apache-2.0","1K - 10K","csv"],"keywords_longer_than_N":true},
	{"name":"Arabic-NLi-Pair-Score","keyword":"arabic","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Omartificial-Intelligence-Space/Arabic-NLi-Pair-Score","creator_name":"Omartificial Intelligence Space","creator_url":"https://huggingface.co/Omartificial-Intelligence-Space","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tArabic NLI Pair-Score\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\n\\nThe Arabic Version of SNLI and MultiNLI datasets. (Pair-Score Subset)\\nOriginally used for Natural Language Inference (NLI),\\nDataset may be used for training/finetuning an embedding model for semantic textual similarity.\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tPair-Class Subset\\n\\t\\n\\n\\nColumns: \\\"sentence1\\\", \\\"sentence2\\\", \\\"score\\\"\\nColumn types: str, str, float\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tArabic Examples:\\n\\t\\n\\n{\\n  \\\"sentence1\\\": \\\"Ø´Ø®Øµ Ø¹Ù„Ù‰ Ø­ØµØ§Ù† ÙŠÙ‚ÙØ² ÙÙˆÙ‚ Ø·Ø§Ø¦Ø±Ø© Ù…Ø¹Ø·Ù„Ø©\\\",\\n  \\\"sentence2\\\":â€¦ See the full description on the dataset page: https://huggingface.co/datasets/Omartificial-Intelligence-Space/Arabic-NLi-Pair-Score.","first_N":5,"first_N_keywords":["sentence-similarity","Arabic","apache-2.0","100K - 1M","csv"],"keywords_longer_than_N":true},
	{"name":"Arabic-NLi-Pair","keyword":"arabic","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Omartificial-Intelligence-Space/Arabic-NLi-Pair","creator_name":"Omartificial Intelligence Space","creator_url":"https://huggingface.co/Omartificial-Intelligence-Space","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tArabic-NLI-PAir\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\n\\nThe Arabic Version of SNLI and MultiNLI datasets. (Pair Subset)\\nOriginally used for Natural Language Inference (NLI),\\nDataset may be used for training/finetuning an embedding model for semantic textual similarity.\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tPair Subset\\n\\t\\n\\n\\nColumns: \\\"anchor\\\", \\\"positive\\\"\\nColumn types: str, str\\n\\nExamples:\\n{\\n  \\\"anchor\\\": \\\"ÙƒÙŠÙ Ø£ÙƒÙˆÙ† Ø¬ÙŠÙˆÙ„ÙˆØ¬ÙŠØ§Ù‹ Ø¬ÙŠØ¯Ø§Ù‹ØŸ\\\",\\n  \\\"positive\\\": \\\"Ù…Ø§Ø°Ø§ Ø¹Ù„ÙŠ Ø£Ù† Ø£ÙØ¹Ù„ Ù„Ø£ÙƒÙˆÙ† Ø¬ÙŠÙˆÙ„ÙˆØ¬ÙŠØ§Ù‹ Ø¹Ø¸ÙŠÙ…Ø§Ù‹ØŸ\\\"\\n}\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDisclaimerâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Omartificial-Intelligence-Space/Arabic-NLi-Pair.","first_N":5,"first_N_keywords":["sentence-similarity","Arabic","apache-2.0","100K - 1M","csv"],"keywords_longer_than_N":true},
	{"name":"arabic_medical_dialogue","keyword":"arabic","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Mars203020/arabic_medical_dialogue","creator_name":"Mariam ALMutairi","creator_url":"https://huggingface.co/Mars203020","description":"Mars203020/arabic_medical_dialogue dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["text-generation","Arabic","mit","1K - 10K","text"],"keywords_longer_than_N":true},
	{"name":"Algerian-Darija","keyword":"arabic","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ayoubkirouane/Algerian-Darija","creator_name":"Ayoub Kirouane","creator_url":"https://huggingface.co/ayoubkirouane","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tOverview\\n\\t\\n\\nThis dataset contains text in Algerian Darija, collected from a variety of sources including existing datasets on Hugging Face, web scraping, and YouTube transcript APIs. \\n\\nThe train split consists more then 2k rows of uncleaned text data.\\n\\nThe v1 split consists more than 170k rows of split and partially cleaned text.\\n\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSources\\n\\t\\n\\nThe text data was gathered from:\\n\\nHugging Face Datasets: Pre-existing datasets relevant to Algerian Darija.\\nWeb Scraping: Contentâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/ayoubkirouane/Algerian-Darija.","first_N":5,"first_N_keywords":["text-generation","text2text-generation","Arabic","cc-by-4.0","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"arabic_quranic_asr","keyword":"arabic","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Sadique5/arabic_quranic_asr","creator_name":"Sadique Abdullah","creator_url":"https://huggingface.co/Sadique5","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset details\\n\\t\\n\\nThis dataset contains quran recitations of every ayats or verses. Also contains 10k unique words from quran.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Purpose\\n\\t\\n\\nThis dataset can be used to train ASR models that can be used for teaching beginners to recite quran. It can also be used for training TTS models that produces quran recitations in a way so that beginners can easily learn.\\n","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","Arabic","mit","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"ATHAR","keyword":"arabic","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mohamed-khalil/ATHAR","creator_name":"Mohammed Khalil","creator_url":"https://huggingface.co/mohamed-khalil","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset card\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDescription\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tATHAR: A High-Quality and Diverse Dataset for Classical Arabic to English Translation\\n\\t\\n\\n\\nWelcome to ATHAR Dataset\\n\\nThe ATHAR dataset is a comprehensive collection of classical Arabic texts translated into English. This dataset contains approximately 66,000 rows of translated texts, including the original Classical Arabic texts and their English translations.\\n\\n\\n   [ Paper ]\\n\\n\\n\\n\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLicense\\n\\t\\n\\nThe ATHAR dataset andâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/mohamed-khalil/ATHAR.","first_N":5,"first_N_keywords":["translation","Arabic","English","cc-by-sa-4.0","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"nomiracl-instruct","keyword":"arabic","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/miracl/nomiracl-instruct","creator_name":"MIRACL","creator_url":"https://huggingface.co/miracl","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for NoMIRACL (EMNLP 2024 Findings Track)\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tQuick Overview\\n\\t\\n\\nThis repository contains the fine-tuning (training & development split) of the NoMIRACL instruct dataset for fine-tuning LLMs on multilingual relevance assessment.\\nThe training dataset is a binary classification task; they need to explicitly output either Yes, answer is present or I don't know. \\nThe dataset contains training pairs from all 18 languages for both splits: relevant & non-relevant.â€¦ See the full description on the dataset page: https://huggingface.co/datasets/miracl/nomiracl-instruct.","first_N":5,"first_N_keywords":["text-classification","text-generation","Arabic","Bengali","German"],"keywords_longer_than_N":true},
	{"name":"Ar-En-Code-Switching-Textual-Dataset","keyword":"arabic","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/SDAIANCAI/Ar-En-Code-Switching-Textual-Dataset","creator_name":"SDAIA NCAI","creator_url":"https://huggingface.co/SDAIANCAI","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tArE-CSTD: Arabic-English Code-Switching Textual Dataset\\n\\t\\n\\nThe National Center for Artificial Intelligence at the Saudi Data and Artificial Intelligence Authority (SDAIA), published the \\\"ArE-CSTD\\\" dataset, which stands for \\\"Arabic-English Code-Switching Textual Datasetâ€.\\nThis dataset contains 330K dialectical Arabic-English code-swithing sentences generated by the large language model GPT-4.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tTXT Files\\n\\t\\n\\nThere are 6 txt files. 2 files for Modern Standard Arabic(MSA)â€¦ See the full description on the dataset page: https://huggingface.co/datasets/SDAIANCAI/Ar-En-Code-Switching-Textual-Dataset.","first_N":5,"first_N_keywords":["text-generation","automatic-speech-recognition","Arabic","English","cc-by-sa-4.0"],"keywords_longer_than_N":true},
	{"name":"text_ratings","keyword":"arabic","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/lightblue/text_ratings","creator_name":"Lightblue KK.","creator_url":"https://huggingface.co/lightblue","description":"Todo - Write dataset card\\n","first_N":5,"first_N_keywords":["Amharic","Arabic","Bulgarian","Bengali","Czech"],"keywords_longer_than_N":true},
	{"name":"MMMLU","keyword":"arabic","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/openai/MMMLU","creator_name":"OpenAI","creator_url":"https://huggingface.co/openai","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tMultilingual Massive Multitask Language Understanding (MMMLU)\\n\\t\\n\\nThe MMLU is a widely recognized benchmark of general knowledge attained by AI models. It covers a broad range of topics from 57 different categories, covering elementary-level knowledge up to advanced professional subjects like law, physics, history, and computer science.\\nWe translated the MMLUâ€™s test set into 14 languages using professional human translators. Relying on human translators for this evaluation increasesâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/openai/MMMLU.","first_N":5,"first_N_keywords":["question-answering","Arabic","Bengali","German","Spanish"],"keywords_longer_than_N":true},
	{"name":"muri-it","keyword":"arabic","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/akoksal/muri-it","creator_name":"Abdullatif Koksal","creator_url":"https://huggingface.co/akoksal","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tMURI-IT: Multilingual Instruction Tuning Dataset for 200 Languages via Multilingual Reverse Instructions\\n\\t\\n\\nMURI-IT is a large-scale multilingual instruction tuning dataset containing 2.2 million instruction-output pairs across 200 languages. It is designed to address the challenges of instruction tuning in low-resource languages with Multilingual Reverse Instructions (MURI), which ensures that the output is human-written, high-quality, and authentic to the cultural and linguisticâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/akoksal/muri-it.","first_N":5,"first_N_keywords":["text2text-generation","text-generation","question-answering","summarization","Achinese"],"keywords_longer_than_N":true},
	{"name":"quran-indonesia-tafseer-translation","keyword":"arabic","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/emhaihsan/quran-indonesia-tafseer-translation","creator_name":"Muhammad Ihsan","creator_url":"https://huggingface.co/emhaihsan","description":"emhaihsan/quran-indonesia-tafseer-translation dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["question-answering","Indonesian","Arabic","mit","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"vqa","keyword":"arabic","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/worldcuisines/vqa","creator_name":"World Cuisines","creator_url":"https://huggingface.co/worldcuisines","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tWorldCuisines: A Massive-Scale Benchmark for Multilingual and Multicultural Visual Question Answering on Global Cuisines\\n\\t\\n\\n\\nWorldCuisines is a massive-scale visual question answering (VQA) benchmark for multilingual and multicultural understanding through global cuisines. The dataset contains text-image pairs across 30 languages and dialects, spanning 9 language families and featuring over 1 million data points, making it the largest multicultural VQA benchmark as of 17 Octoberâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/worldcuisines/vqa.","first_N":5,"first_N_keywords":["multilingual","English","Indonesian","Chinese","Korean"],"keywords_longer_than_N":true},
	{"name":"arabic-img2md","keyword":"arabic","license":"GNU General Public License v3.0","license_url":"https://choosealicense.com/licenses/gpl-3.0/","language":"en","dataset_url":"https://huggingface.co/datasets/MohamedRashad/arabic-img2md","creator_name":"Mohamed Rashad","creator_url":"https://huggingface.co/MohamedRashad","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tArabic Img2MD\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThe arabic-img2md dataset consists of 15,000 examples of PDF pages paired with their Markdown counterparts. The dataset is split into:\\n\\nTrain: 13,700 examples\\nTest: 1,520 examples\\n\\nThis dataset was created as part of the open-source research project Arabic Nougat to enable OCR and Markdown extraction from Arabic documents. It contains mostly Arabic text but also includes examples with English text.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tUsage\\n\\t\\n\\nThe dataset wasâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/MohamedRashad/arabic-img2md.","first_N":5,"first_N_keywords":["image-to-text","Arabic","gpl-3.0","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"HPLT2.0_cleaned","keyword":"arabic","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/HPLT/HPLT2.0_cleaned","creator_name":"HPLT","creator_url":"https://huggingface.co/HPLT","description":"This is a large-scale collection of web-crawled documents in 191 world languages, produced by the HPLT project. \\nThe source of the data is mostly Internet Archive with some additions from Common Crawl.\\nFor a detailed description of the dataset, please refer to https://hplt-project.org/datasets/v2.0\\nThe Cleaned variant of HPLT Datasets v2.0\\nThis is the cleaned variant of the HPLT Datasets v2.0 converted to the Parquet format semi-automatically when being uploaded here. \\nThe original JSONL filesâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/HPLT/HPLT2.0_cleaned.","first_N":5,"first_N_keywords":["fill-mask","text-generation","language-modeling","multilingual","Achinese"],"keywords_longer_than_N":true},
	{"name":"arabic-tashkeel-dataset","keyword":"arabic","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Abdou/arabic-tashkeel-dataset","creator_name":"Rockikz","creator_url":"https://huggingface.co/Abdou","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tArabic Tashkeel Dataset\\n\\t\\n\\nThis is a fairly large dataset gathered from five main sources:\\n\\ntashkeela (1.79GB - 45.05%): The entire Tashkeela dataset, repurposed in sentences. Some rows were omitted as they contain low diacritic (tashkeel characters) rate.\\nshamela (1.67GB - 42.10%): Random pages from over 2,000 books on the Shamela Library. Pages were selected using the below function (high diacritics rate)\\nwikipedia (269.94MB - 6.64%): A collection of Wikipedia articles.â€¦ See the full description on the dataset page: https://huggingface.co/datasets/Abdou/arabic-tashkeel-dataset.","first_N":5,"first_N_keywords":["Arabic","mit","1M - 10M","parquet","Text"],"keywords_longer_than_N":true},
	{"name":"EGY2K","keyword":"arabic","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/rahafvii/EGY2K","creator_name":"xx","creator_url":"https://huggingface.co/rahafvii","description":"rahafvii/EGY2K dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["text-to-speech","text-to-audio","Arabic","apache-2.0","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"m-ArenaHard","keyword":"arabic","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/CohereForAI/m-ArenaHard","creator_name":"Cohere For AI","creator_url":"https://huggingface.co/CohereForAI","description":"\\n\\t\\n\\t\\t\\n\\t\\tDataset Card for m-ArenaHard\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Details\\n\\t\\n\\nThe m-ArenaHard dataset is a multilingual LLM evaluation set. This dataset was created by translating the prompts from the originally English-only LMarena (formerly LMSYS) arena-hard-auto-v0.1 test dataset using Google Translate API v3 to 22 languages. The original English-only prompts were created by Li et al. (2024) and consist of 500 challenging user queries sourced from Chatbot Arena. The authors show that these can be usedâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/CohereForAI/m-ArenaHard.","first_N":5,"first_N_keywords":["English","French","German","Spanish","Italian"],"keywords_longer_than_N":true},
	{"name":"PangeaBench-xmmmu","keyword":"arabic","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neulab/PangeaBench-xmmmu","creator_name":"NeuLab @ LTI/CMU","creator_url":"https://huggingface.co/neulab","description":"neulab/PangeaBench-xmmmu dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["visual-question-answering","question-answering","multiple-choice","Arabic","French"],"keywords_longer_than_N":true},
	{"name":"Ar-Reranking-Eval","keyword":"arabic","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/NAMAA-Space/Ar-Reranking-Eval","creator_name":"Network for Advancing Modern ArabicNLP & AI","creator_url":"https://huggingface.co/NAMAA-Space","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tArabic Reranking Evaluation Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Overview\\n\\t\\n\\nThis dataset, containing 468 rows, is curated for evaluating reranking and retrieval models in Arabic. It covers various topics such as artificial intelligence, machine learning, data analysis, technology, education, and more, with diverse query complexities and document lengths. The dataset is intended to aid in developing and benchmarking Arabic language models that rank information based on relevance.â€¦ See the full description on the dataset page: https://huggingface.co/datasets/NAMAA-Space/Ar-Reranking-Eval.","first_N":5,"first_N_keywords":["Arabic","apache-2.0","< 1K","parquet","Text"],"keywords_longer_than_N":true},
	{"name":"P-MMEval","keyword":"arabic","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Qwen/P-MMEval","creator_name":"Qwen","creator_url":"https://huggingface.co/Qwen","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tP-MMEval: A Parallel Multilingual Multitask Benchmark for Consistent Evaluation of LLMs\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tIntroduction\\n\\t\\n\\nWe introduce a multilingual benchmark, P-MMEval, covering effective fundamental and capability-specialized datasets. We extend the existing benchmarks, ensuring consistent language coverage across all datasets and providing parallel samples among multiple languages, supporting up to 10 languages from 8 language families (i.e., en, zh, ar, es, ja, ko, th, fr, ptâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Qwen/P-MMEval.","first_N":5,"first_N_keywords":["Arabic","Spanish","French","Japanese","Korean"],"keywords_longer_than_N":true},
	{"name":"Arabic-Triplet-With-Multi-Negatives","keyword":"arabic","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/NAMAA-Space/Arabic-Triplet-With-Multi-Negatives","creator_name":"Network for Advancing Modern ArabicNLP & AI","creator_url":"https://huggingface.co/NAMAA-Space","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tArabic Triplet with Multi Negatives\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThis dataset is a modified version of the Arabic subset of the Mr. TyDi dataset, tailored for retrieval and re-ranking tasks. The original dataset has been restructured by splitting the negative passages into separate fields (negative1, negative2, ..., negativeN) for each query. This modification allows more flexibility for training and evaluating retrieval and re-ranking models.\\nThe dataset retains the originalâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/NAMAA-Space/Arabic-Triplet-With-Multi-Negatives.","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","Arabic","apache-2.0","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"belebele-fleurs","keyword":"arabic","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/WueNLP/belebele-fleurs","creator_name":"WÃ¼NLP","creator_url":"https://huggingface.co/WueNLP","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tBelebele-Fleurs\\n\\t\\n\\nBelebele-Fleurs is a dataset suitable to evaluate two core tasks:\\n\\nMultilingual Spoken Language Understanding (Listening Comprehension): For each spoken paragraph, the task is to answer a multiple-choice question. The question and four answer choices are provided in text form.\\nMultilingual Long-Form Automatic Speech Recognition (ASR) with Diverse Speakers: By concatenating sentence-level utterances, long-form audio clips (ranging from 30 seconds to 1 minute 30â€¦ See the full description on the dataset page: https://huggingface.co/datasets/WueNLP/belebele-fleurs.","first_N":5,"first_N_keywords":["audio-classification","automatic-speech-recognition","audio-text-to-text","text-to-speech","question-answering"],"keywords_longer_than_N":true},
	{"name":"include-base-44","keyword":"arabic","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/CohereForAI/include-base-44","creator_name":"Cohere For AI","creator_url":"https://huggingface.co/CohereForAI","description":"\\n\\t\\n\\t\\t\\n\\t\\tINCLUDE-base (44 languages)\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\n\\n\\nPaper: http://arxiv.org/abs/2411.19799\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nINCLUDE is a comprehensive knowledge- and reasoning-centric benchmark across 44 languages that evaluates multilingual LLMs for performance in the actual language environments where they would be deployed. \\nIt contains 22,637 4-option multiple-choice-questions (MCQ) extracted from academic and professional exams, covering 57 topics, including regionalâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/CohereForAI/include-base-44.","first_N":5,"first_N_keywords":["text2text-generation","multiple-choice","Albanian","Arabic","Armenian"],"keywords_longer_than_N":true},
	{"name":"Arabic_Reasoning_Dataset","keyword":"arabic","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Omartificial-Intelligence-Space/Arabic_Reasoning_Dataset","creator_name":"Omartificial Intelligence Space","creator_url":"https://huggingface.co/Omartificial-Intelligence-Space","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tArabic Reasoning Instruction QA Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThis dataset contains 9.21K rows of Arabic instruction-based reasoning QA pairs. It is a comprehensive collection of data points, meticulously crafted to enhance Arabic language reasoning capabilities for models.\\nThe dataset was generated by combining:\\nâ™¦ï¸Ž Data from the Hugging Face dataset MohammedNasser/Arabic_Reasoning_Instruct_QA. | Size = 1.23K instructions\\nâ™¦ï¸Ž Synthetic data generated using theâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Omartificial-Intelligence-Space/Arabic_Reasoning_Dataset.","first_N":5,"first_N_keywords":["Arabic","apache-2.0","1K - 10K","parquet","Text"],"keywords_longer_than_N":true},
	{"name":"open-dict-words-ipa","keyword":"arabic","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/StephanAkkerman/open-dict-words-ipa","creator_name":"Stephan Akkerman","creator_url":"https://huggingface.co/StephanAkkerman","description":"\\n\\t\\n\\t\\t\\n\\t\\tOpen-dict Words IPA\\n\\t\\n\\nThis dataset is a copy of https://github.com/open-dict-data/ipa-dict\\n\\n\\t\\n\\t\\t\\n\\t\\tLanguages\\n\\t\\n\\nIPA data is currently available for the following languages:\\n\\n\\t\\n\\t\\t\\nLanguage\\nCode\\n\\n\\n\\t\\t\\nar\\nArabic (Modern Standard)\\n\\n\\nde\\nGerman\\n\\n\\nen_UK\\nEnglish (Received Pronunciation)\\n\\n\\nen_US\\nEnglish (General American)\\n\\n\\neo\\nEsperanto\\n\\n\\nes_ES\\nSpanish (Spain)\\n\\n\\nes_MX\\nSpanish (Mexico)\\n\\n\\nfa\\nPersian\\n\\n\\nfi\\nFinnish\\n\\n\\nfr_FR\\nFrench (France)\\n\\n\\nfr_QC\\nFrench (QuÃ©bec)\\n\\n\\nis\\nIcelandic\\n\\n\\nja\\nJapanese\\n\\n\\njamâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/StephanAkkerman/open-dict-words-ipa.","first_N":5,"first_N_keywords":["Arabic","German","English","Esperanto","Spanish"],"keywords_longer_than_N":true},
	{"name":"include-lite-44","keyword":"arabic","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/CohereForAI/include-lite-44","creator_name":"Cohere For AI","creator_url":"https://huggingface.co/CohereForAI","description":"\\n\\t\\n\\t\\t\\n\\t\\tINCLUDE-lite (44 languages)\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\n\\n\\nPaper: http://arxiv.org/abs/2411.19799\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nINCLUDE is a comprehensive knowledge- and reasoning-centric benchmark across 44 languages that evaluates multilingual LLMs for performance in the actual language environments where they would be deployed. \\nIt contains 11,095 4-option multiple-choice-questions (MCQ) extracted from academic and professional exams, covering 57 topics, including regionalâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/CohereForAI/include-lite-44.","first_N":5,"first_N_keywords":["text2text-generation","multiple-choice","Albanian","Arabic","Armenian"],"keywords_longer_than_N":true},
	{"name":"sib-fleurs","keyword":"arabic","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/WueNLP/sib-fleurs","creator_name":"WÃ¼NLP","creator_url":"https://huggingface.co/WueNLP","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSIB-Fleurs\\n\\t\\n\\nSIB-Fleurs is a dataset suitable to evaluate Multilingual Spoken Language Understanding. For each utterance in Fleurs, the task is to determine the topic the utterance belongs to. \\nThe topics are:\\n\\nScience/Technology\\nTravel\\nPolitics\\nSports\\nHealth\\nEntertainment\\nGeography\\n\\nPreliminary evaluations can be found at the bottom of the README. The preliminary results in full detail are available in ./results.csv*.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset creation\\n\\t\\n\\nThis dataset processes andâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/WueNLP/sib-fleurs.","first_N":5,"first_N_keywords":["audio-classification","automatic-speech-recognition","audio-text-to-text","text-to-speech","question-answering"],"keywords_longer_than_N":true},
	{"name":"Global-MMLU-Lite","keyword":"arabic","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/CohereForAI/Global-MMLU-Lite","creator_name":"Cohere For AI","creator_url":"https://huggingface.co/CohereForAI","description":"\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nGlobal-MMLU-Lite is a multilingual evaluation set spanning 15 languages, including English. It is \\\"lite\\\" version of the original Global-MMLU dataset ðŸŒ.\\nIt includes 200 Culturally Sensitive (CS) and 200 Culturally Agnostic (CA) samples per language. The samples in Global-MMLU-Lite are corresponding to languages which are fully human translated or post-edited in the original Global-MMLU dataset. \\n\\nCurated by: Professional annotators and contributors of Cohere Forâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/CohereForAI/Global-MMLU-Lite.","first_N":5,"first_N_keywords":["English","Arabic","Bengali","Spanish","French"],"keywords_longer_than_N":true},
	{"name":"2M-Belebele","keyword":"arabic","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/facebook/2M-Belebele","creator_name":"AI at Meta","creator_url":"https://huggingface.co/facebook","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\t2M-Belebele\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tHighly-Multilingual Speech and American Sign Language Comprehension Dataset\\n\\t\\n\\nWe introduce 2M-Belebele as the first highly multilingual speech and American Sign Language (ASL) comprehension dataset. Our dataset, which is an extension of the existing Belebele only-text dataset, covers 74 spoken languages at the intersection of Belebele and Fleurs, and one sign language (ASL). \\nThe speech dataset is built from aligning Belebele, Flores200 and Fleursâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/facebook/2M-Belebele.","first_N":5,"first_N_keywords":["question-answering","automatic-speech-recognition","Bulgarian","Panjabi","English"],"keywords_longer_than_N":true},
	{"name":"commonvoice-12.0-arabic-voice-converted","keyword":"arabic","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/xmodar/commonvoice-12.0-arabic-voice-converted","creator_name":"Modar M. Alfadly","creator_url":"https://huggingface.co/xmodar","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Voice Converted Arabic Common Voice 12.0\\n\\t\\n\\nThis dataset is derived from the Common Voice Arabic Corpus 12.0 and includes automatically diacritized transcriptions and phoneme representations for the original augmented audio data. The recordings feature Arabic text read aloud by users, where the text was initially undiacritized, allowing for potential reading errors. The diacritization and phonemes were generated automatically, resulting in a dataset that isâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/xmodar/commonvoice-12.0-arabic-voice-converted.","first_N":5,"first_N_keywords":["automatic-speech-recognition","Arabic","cc0-1.0","100K - 1M","parquet"],"keywords_longer_than_N":true},
	{"name":"reranker_continuous_filt_max7_train","keyword":"arabic","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/lightblue/reranker_continuous_filt_max7_train","creator_name":"Lightblue KK.","creator_url":"https://huggingface.co/lightblue","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tReranker training data\\n\\t\\n\\nThis data was generated using 4 steps:\\n\\nWe gathered queries and corresponding text data from 35 high quality datasets covering more than 95 languages.\\nFor datasets which did not already have negative texts for queries, we mined hard negatives using the BAAI/bge-m3 embedding model.\\nFor each query, we selected one positive and one negative text and used Qwen/Qwen2.5-32B-Instruct-GPTQ-Int4 to rate the relatedness of each query-text pair using a token \\\"1\\\", \\\"2\\\"â€¦ See the full description on the dataset page: https://huggingface.co/datasets/lightblue/reranker_continuous_filt_max7_train.","first_N":5,"first_N_keywords":["English","Chinese","Spanish","German","Arabic"],"keywords_longer_than_N":true},
	{"name":"wikitongues-darija","keyword":"arabic","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/BrunoHays/wikitongues-darija","creator_name":"Bruno Hays","creator_url":"https://huggingface.co/BrunoHays","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tWikitongues-Darija\\n\\t\\n\\nThis is a small test dataset for Automatic Speech Recognition in Darija language, built from 2 captioned videos of the WikiTongues project:\\n\\nnawal\\nanass\\n\\nProcess:\\n\\neach webm video has been converted to monochannel 16khz wav files with ffmpeg :\\n\\nffmpeg -i WIKITONGUES-_Nawal_speaking_Moroccan_Arabic.webm.1080p.vp9.webm -ar 16000 -ac 1 nawal.wav\\n\\n\\neach audio has been cut in samples of less than 30 seconds audio according to the captions timestamps. The script mayâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/BrunoHays/wikitongues-darija.","first_N":5,"first_N_keywords":["automatic-speech-recognition","Arabic","cc-by-sa-4.0","< 1K","soundfolder"],"keywords_longer_than_N":true},
	{"name":"sib-fleurs","keyword":"egyptian arabic","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/WueNLP/sib-fleurs","creator_name":"WÃ¼NLP","creator_url":"https://huggingface.co/WueNLP","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSIB-Fleurs\\n\\t\\n\\nSIB-Fleurs is a dataset suitable to evaluate Multilingual Spoken Language Understanding. For each utterance in Fleurs, the task is to determine the topic the utterance belongs to. \\nThe topics are:\\n\\nScience/Technology\\nTravel\\nPolitics\\nSports\\nHealth\\nEntertainment\\nGeography\\n\\nPreliminary evaluations can be found at the bottom of the README. The preliminary results in full detail are available in ./results.csv*.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset creation\\n\\t\\n\\nThis dataset processes andâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/WueNLP/sib-fleurs.","first_N":5,"first_N_keywords":["audio-classification","automatic-speech-recognition","audio-text-to-text","text-to-speech","question-answering"],"keywords_longer_than_N":true},
	{"name":"sib-fleurs","keyword":"levantine arabic","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/WueNLP/sib-fleurs","creator_name":"WÃ¼NLP","creator_url":"https://huggingface.co/WueNLP","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSIB-Fleurs\\n\\t\\n\\nSIB-Fleurs is a dataset suitable to evaluate Multilingual Spoken Language Understanding. For each utterance in Fleurs, the task is to determine the topic the utterance belongs to. \\nThe topics are:\\n\\nScience/Technology\\nTravel\\nPolitics\\nSports\\nHealth\\nEntertainment\\nGeography\\n\\nPreliminary evaluations can be found at the bottom of the README. The preliminary results in full detail are available in ./results.csv*.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset creation\\n\\t\\n\\nThis dataset processes andâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/WueNLP/sib-fleurs.","first_N":5,"first_N_keywords":["audio-classification","automatic-speech-recognition","audio-text-to-text","text-to-speech","question-answering"],"keywords_longer_than_N":true},
	{"name":"sib-fleurs","keyword":"mesopotamian arabic","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/WueNLP/sib-fleurs","creator_name":"WÃ¼NLP","creator_url":"https://huggingface.co/WueNLP","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSIB-Fleurs\\n\\t\\n\\nSIB-Fleurs is a dataset suitable to evaluate Multilingual Spoken Language Understanding. For each utterance in Fleurs, the task is to determine the topic the utterance belongs to. \\nThe topics are:\\n\\nScience/Technology\\nTravel\\nPolitics\\nSports\\nHealth\\nEntertainment\\nGeography\\n\\nPreliminary evaluations can be found at the bottom of the README. The preliminary results in full detail are available in ./results.csv*.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset creation\\n\\t\\n\\nThis dataset processes andâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/WueNLP/sib-fleurs.","first_N":5,"first_N_keywords":["audio-classification","automatic-speech-recognition","audio-text-to-text","text-to-speech","question-answering"],"keywords_longer_than_N":true},
	{"name":"sib-fleurs","keyword":"moroccan arabic","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/WueNLP/sib-fleurs","creator_name":"WÃ¼NLP","creator_url":"https://huggingface.co/WueNLP","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSIB-Fleurs\\n\\t\\n\\nSIB-Fleurs is a dataset suitable to evaluate Multilingual Spoken Language Understanding. For each utterance in Fleurs, the task is to determine the topic the utterance belongs to. \\nThe topics are:\\n\\nScience/Technology\\nTravel\\nPolitics\\nSports\\nHealth\\nEntertainment\\nGeography\\n\\nPreliminary evaluations can be found at the bottom of the README. The preliminary results in full detail are available in ./results.csv*.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset creation\\n\\t\\n\\nThis dataset processes andâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/WueNLP/sib-fleurs.","first_N":5,"first_N_keywords":["audio-classification","automatic-speech-recognition","audio-text-to-text","text-to-speech","question-answering"],"keywords_longer_than_N":true},
	{"name":"sib-fleurs","keyword":"najdi arabic","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/WueNLP/sib-fleurs","creator_name":"WÃ¼NLP","creator_url":"https://huggingface.co/WueNLP","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSIB-Fleurs\\n\\t\\n\\nSIB-Fleurs is a dataset suitable to evaluate Multilingual Spoken Language Understanding. For each utterance in Fleurs, the task is to determine the topic the utterance belongs to. \\nThe topics are:\\n\\nScience/Technology\\nTravel\\nPolitics\\nSports\\nHealth\\nEntertainment\\nGeography\\n\\nPreliminary evaluations can be found at the bottom of the README. The preliminary results in full detail are available in ./results.csv*.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset creation\\n\\t\\n\\nThis dataset processes andâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/WueNLP/sib-fleurs.","first_N":5,"first_N_keywords":["audio-classification","automatic-speech-recognition","audio-text-to-text","text-to-speech","question-answering"],"keywords_longer_than_N":true},
	{"name":"sib-fleurs","keyword":"tunisian arabic","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/WueNLP/sib-fleurs","creator_name":"WÃ¼NLP","creator_url":"https://huggingface.co/WueNLP","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSIB-Fleurs\\n\\t\\n\\nSIB-Fleurs is a dataset suitable to evaluate Multilingual Spoken Language Understanding. For each utterance in Fleurs, the task is to determine the topic the utterance belongs to. \\nThe topics are:\\n\\nScience/Technology\\nTravel\\nPolitics\\nSports\\nHealth\\nEntertainment\\nGeography\\n\\nPreliminary evaluations can be found at the bottom of the README. The preliminary results in full detail are available in ./results.csv*.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset creation\\n\\t\\n\\nThis dataset processes andâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/WueNLP/sib-fleurs.","first_N":5,"first_N_keywords":["audio-classification","automatic-speech-recognition","audio-text-to-text","text-to-speech","question-answering"],"keywords_longer_than_N":true},
	{"name":"sib-fleurs","keyword":"ta'izzi-adeni arabic","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/WueNLP/sib-fleurs","creator_name":"WÃ¼NLP","creator_url":"https://huggingface.co/WueNLP","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSIB-Fleurs\\n\\t\\n\\nSIB-Fleurs is a dataset suitable to evaluate Multilingual Spoken Language Understanding. For each utterance in Fleurs, the task is to determine the topic the utterance belongs to. \\nThe topics are:\\n\\nScience/Technology\\nTravel\\nPolitics\\nSports\\nHealth\\nEntertainment\\nGeography\\n\\nPreliminary evaluations can be found at the bottom of the README. The preliminary results in full detail are available in ./results.csv*.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset creation\\n\\t\\n\\nThis dataset processes andâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/WueNLP/sib-fleurs.","first_N":5,"first_N_keywords":["audio-classification","automatic-speech-recognition","audio-text-to-text","text-to-speech","question-answering"],"keywords_longer_than_N":true},
	{"name":"reranking-datasets-light","keyword":"arabic","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/abdoelsayed/reranking-datasets-light","creator_name":"unkown","creator_url":"https://huggingface.co/abdoelsayed","description":"\\n\\t\\n\\t\\t\\n\\t\\tðŸ”¥ Rankify: A Comprehensive Python Toolkit for Retrieval, Re-Ranking, and Retrieval-Augmented Generation ðŸ”¥\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tReRanking Datasets : A comprehensive collection of retrieval and reranking datasets with full passage contexts, including titles, text, and metadata for in-depth research.\\n\\t\\n\\n\\n    \\n    \\n    \\n    \\n    \\n    \\n        \\n    \\n    \\n        \\n    \\n    \\n        \\n    \\n    \\n        \\n    \\n    \\n    \\n\\n\\n\\nA curated collection of ready-to-use datasets for retrieval and rerankingâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/abdoelsayed/reranking-datasets-light.","first_N":5,"first_N_keywords":["question-answering","English","Arabic","German","French"],"keywords_longer_than_N":true},
	{"name":"MultiLingualSentiment","keyword":"arabic","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/clapAI/MultiLingualSentiment","creator_name":"clapAI","creator_url":"https://huggingface.co/clapAI","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tOverview\\n\\t\\n\\nMultilingualSentiment is a sentiment classification dataset that encompasses three sentiment labels: Positive, Neutral, Negative\\nThe dataset spans multiple languages and covers a wide range of domains, making it ideal for multilingual sentiment analysis tasks.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Information\\n\\t\\n\\nThe dataset was meticulously collected and aggregated from various sources, including Hugging Face and Kaggle. These sources provide diverse languages and domains to ensure aâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/clapAI/MultiLingualSentiment.","first_N":5,"first_N_keywords":["text-classification","Arabic","German","English","Spanish"],"keywords_longer_than_N":true},
	{"name":"SMPQA","keyword":"arabic","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/WueNLP/SMPQA","creator_name":"WÃ¼NLP","creator_url":"https://huggingface.co/WueNLP","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSMPQA (Synthetic Multilingual Plot QA)\\n\\t\\n\\n\\n\\nThe SMPQA evaluation dataset proposed in Centurio: On Drivers of Multilingual Ability of Large Vision-Language Model.\\nSMPQA is composed of synthetic bar plots and pie charts (generated using word lists of different languages) together with questions about those plots.\\nThe datasets aims at providing an initial way of evaluating multilingual OCR capabilities of models in arbritrary languages.\\nThere are two sub-tasks: \\n\\nGrounding text labelsâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/WueNLP/SMPQA.","first_N":5,"first_N_keywords":["visual-question-answering","English","Zulu","Indonesian","Italian"],"keywords_longer_than_N":true},
	{"name":"alquran","keyword":"arabic","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ronnieaban/alquran","creator_name":"Ronnie Aban","creator_url":"https://huggingface.co/ronnieaban","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Terjemahan dan Tafsir Al-Quran\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDeskripsi Dataset\\n\\t\\n\\nDataset ini berisi terjemahan Al-Quran dalam bahasa Indonesia beserta tafsirnya. Dataset ini dapat digunakan untuk berbagai tugas NLP seperti machine translation, text generation, dan text summarization.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tFitur Utama\\n\\t\\n\\n\\nTerjemahan Al-Quran: Teks Al-Quran dalam bahasa Arab beserta terjemahannya dalam bahasa Indonesia.\\nTafsir Al-Quran: Penjelasan atau interpretasi dari ayat-ayat Al-Quran dalamâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/ronnieaban/alquran.","first_N":5,"first_N_keywords":["text-generation","translation","text-classification","Arabic","Indonesian"],"keywords_longer_than_N":true},
	{"name":"alquran","keyword":"arabic","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ronnieaban/alquran","creator_name":"Ronnie Aban","creator_url":"https://huggingface.co/ronnieaban","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Terjemahan dan Tafsir Al-Quran\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDeskripsi Dataset\\n\\t\\n\\nDataset ini berisi terjemahan Al-Quran dalam bahasa Indonesia beserta tafsirnya. Dataset ini dapat digunakan untuk berbagai tugas NLP seperti machine translation, text generation, dan text summarization.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tFitur Utama\\n\\t\\n\\n\\nTerjemahan Al-Quran: Teks Al-Quran dalam bahasa Arab beserta terjemahannya dalam bahasa Indonesia.\\nTafsir Al-Quran: Penjelasan atau interpretasi dari ayat-ayat Al-Quran dalamâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/ronnieaban/alquran.","first_N":5,"first_N_keywords":["text-generation","translation","text-classification","Arabic","Indonesian"],"keywords_longer_than_N":true},
	{"name":"imatrix-calibration","keyword":"arabic","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/eaddario/imatrix-calibration","creator_name":"Ed Addario","creator_url":"https://huggingface.co/eaddario","description":"\\n\\t\\n\\t\\t\\n\\t\\tImportance Matrix (imatrix) calibration datasets\\n\\t\\n\\nThis dataset consists of over 10M tokens of cleaned and de-duplicated text files for 13 different languages. Each language file is available in five sizes, ranging from large (~ 26,000 lines equivalent to approx. 750K tokens), to micro (~ 1,625 lines and 125K tokens avg).\\nOriginal data sourced from HuggingFaceFW/fineweb and HuggingFaceFW/fineweb-2\\n\\n\\t\\n\\t\\t\\nFile\\nLanguage\\nLines\\nSize\\n\\n\\n\\t\\t\\ncalibration_ar_large\\nArabic\\n26,000\\n3.1Mâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/eaddario/imatrix-calibration.","first_N":5,"first_N_keywords":["text-generation","Arabic","Chinese","German","English"],"keywords_longer_than_N":true},
	{"name":"MedQA_Arabic_Dataset","keyword":"arabic","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/ZiadWael/MedQA_Arabic_Dataset","creator_name":"Ziad Wael AbdlHamed","creator_url":"https://huggingface.co/ZiadWael","description":"ZiadWael/MedQA_Arabic_Dataset dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["question-answering","Arabic","mit","100K<n<1M","ðŸ‡ºðŸ‡¸ Region: US"],"keywords_longer_than_N":true},
	{"name":"Synthdog-Multilingual-100","keyword":"arabic","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/WueNLP/Synthdog-Multilingual-100","creator_name":"WÃ¼NLP","creator_url":"https://huggingface.co/WueNLP","description":"\\n\\t\\n\\t\\t\\n\\t\\tSynthdog Multilingual\\n\\t\\n\\n\\n\\nThe Synthdog dataset created for training in Centurio: On Drivers of Multilingual Ability of Large Vision-Language Model.\\nUsing the official Synthdog code, we created >1 million training samples for improving OCR capabilities in Large Vision-Language Models.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Details\\n\\t\\n\\nWe provide the images for download in two .tar.gz files. Download and extract them in folders of the same name (so cat images.tar.gz.* | tar xvzf -C images; tar xvzfâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/WueNLP/Synthdog-Multilingual-100.","first_N":5,"first_N_keywords":["image-to-text","multilingual","Afrikaans","Amharic","Arabic"],"keywords_longer_than_N":true},
	{"name":"deep-fast","keyword":"arabic","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/madihalim/deep-fast","creator_name":"Halim Madi","creator_url":"https://huggingface.co/madihalim","description":"Deep and Fast is a collection of poems to remember the pandemic as a testament to the urgency of connection, poems about how fast we go deep.\\nThis specific data set, made of the poem titles and poems themselves is meant to fine tune an LLM to adopt the poet's voice.\\n","first_N":5,"first_N_keywords":["question-answering","English","Arabic","mit","< 1K"],"keywords_longer_than_N":true},
	{"name":"Text-with-Diacritics-Correction","keyword":"arabic","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Basma2423/Text-with-Diacritics-Correction","creator_name":"Basma","creator_url":"https://huggingface.co/Basma2423","description":"\\n\\t\\n\\t\\t\\n\\t\\tText with Diacritics Correction Dataset\\n\\t\\n\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tOverview\\n\\t\\n\\nThis dataset is an Arabic dataset derived from Abdou/arabic-tashkeel-dataset, with additional preprocessing and error injection to help train models for speech and typing correction.\\n\\n\\t\\n\\t\\t\\n\\t\\tKey Features\\n\\t\\n\\nâœ… Preprocessed Arabic text: Cleaned vocalized column by removing non-Arabic characters, symbols, emojis, brackets, and numbers.âœ… Injected realistic errors: Includes four types of errors that simulate real-world speechâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Basma2423/Text-with-Diacritics-Correction.","first_N":5,"first_N_keywords":["text2text-generation","Arabic","mit","1M - 10M","parquet"],"keywords_longer_than_N":true},
	{"name":"Text-with-Diacritics-Correction","keyword":"arabic","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Basma2423/Text-with-Diacritics-Correction","creator_name":"Basma","creator_url":"https://huggingface.co/Basma2423","description":"\\n\\t\\n\\t\\t\\n\\t\\tText with Diacritics Correction Dataset\\n\\t\\n\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tOverview\\n\\t\\n\\nThis dataset is an Arabic dataset derived from Abdou/arabic-tashkeel-dataset, with additional preprocessing and error injection to help train models for speech and typing correction.\\n\\n\\t\\n\\t\\t\\n\\t\\tKey Features\\n\\t\\n\\nâœ… Preprocessed Arabic text: Cleaned vocalized column by removing non-Arabic characters, symbols, emojis, brackets, and numbers.âœ… Injected realistic errors: Includes four types of errors that simulate real-world speechâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Basma2423/Text-with-Diacritics-Correction.","first_N":5,"first_N_keywords":["text2text-generation","Arabic","mit","1M - 10M","parquet"],"keywords_longer_than_N":true},
	{"name":"egyptian_test_set","keyword":"arabic","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/otozz/egyptian_test_set","creator_name":"Ã–mer","creator_url":"https://huggingface.co/otozz","description":"Pre-processed Egyptian test partition from the MASC-dataset:\\nMohammad Al-Fetyani, Muhammad Al-Barham, Gheith Abandah, Adham Alsharkawi, Maha Dawas, August 18, 2021, \\\"MASC: Massive Arabic Speech Corpus\\\", IEEE Dataport, doi: https://dx.doi.org/10.21227/e1qb-jv46.\\n","first_N":5,"first_N_keywords":["Arabic","cc-by-4.0","1K - 10K","parquet","Datasets"],"keywords_longer_than_N":true},
	{"name":"BenchMAX_Math","keyword":"arabic","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/LLaMAX/BenchMAX_Math","creator_name":"LLaMAX","creator_url":"https://huggingface.co/LLaMAX","description":"\\n\\t\\n\\t\\t\\n\\t\\tDataset Sources\\n\\t\\n\\n\\nPaper: BenchMAX: A Comprehensive Multilingual Evaluation Suite for Large Language Models\\nLink: https://arxiv.org/pdf/2502.07346\\nRepository: https://github.com/CONE-MT/BenchMAX\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\nBenchMAX_Math is a dataset of BenchMAX, sourcing from MGSM.\\nWe extend the original dataset to 6 more languages.\\nThe data is first translated by Google Translate, and then post-editing by native speakers.\\n\\n\\t\\n\\t\\t\\n\\t\\tSupported Languages\\n\\t\\n\\nArabic, Bengali, Chineseâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/LLaMAX/BenchMAX_Math.","first_N":5,"first_N_keywords":["text-generation","multilingual","English","Chinese","Spanish"],"keywords_longer_than_N":true},
	{"name":"BenchMAX_Science","keyword":"arabic","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/LLaMAX/BenchMAX_Science","creator_name":"LLaMAX","creator_url":"https://huggingface.co/LLaMAX","description":"\\n\\t\\n\\t\\t\\n\\t\\tDataset Sources\\n\\t\\n\\n\\nPaper: BenchMAX: A Comprehensive Multilingual Evaluation Suite for Large Language Models\\nLink: https://arxiv.org/pdf/2502.07346\\nRepository: https://github.com/CONE-MT/BenchMAX\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\nBenchMAX_Science is a dataset of BenchMAX, sourcing from GPQA.\\nWe extend the original English dataset to 16 non-English languages.\\nThe data is first translated by Google Translate, and then post-editing by native speakers.\\n\\n\\t\\n\\t\\t\\n\\t\\tSupported Languages\\n\\t\\n\\nArabicâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/LLaMAX/BenchMAX_Science.","first_N":5,"first_N_keywords":["text-generation","multilingual","English","Chinese","Spanish"],"keywords_longer_than_N":true},
	{"name":"BenchMAX_Function_Completion","keyword":"arabic","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/LLaMAX/BenchMAX_Function_Completion","creator_name":"LLaMAX","creator_url":"https://huggingface.co/LLaMAX","description":"\\n\\t\\n\\t\\t\\n\\t\\tDataset Sources\\n\\t\\n\\n\\nPaper: BenchMAX: A Comprehensive Multilingual Evaluation Suite for Large Language Models\\nLink: https://arxiv.org/pdf/2502.07346\\nRepository: https://github.com/CONE-MT/BenchMAX\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\nBenchMAX_Function_Completion is a dataset of BenchMAX, sourcing from humanevalplus.\\nWe extend the original English dataset to 16 non-English languages.\\nThe data is first translated by GPT-4o, and then post-editing by native speakers.\\n\\n\\t\\n\\t\\t\\n\\t\\tSupported Languagesâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/LLaMAX/BenchMAX_Function_Completion.","first_N":5,"first_N_keywords":["text-generation","multilingual","English","Chinese","Spanish"],"keywords_longer_than_N":true},
	{"name":"BenchMAX_Problem_Solving","keyword":"arabic","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/LLaMAX/BenchMAX_Problem_Solving","creator_name":"LLaMAX","creator_url":"https://huggingface.co/LLaMAX","description":"\\n\\t\\n\\t\\t\\n\\t\\tDataset Sources\\n\\t\\n\\n\\nPaper: BenchMAX: A Comprehensive Multilingual Evaluation Suite for Large Language Models\\nLink: https://arxiv.org/pdf/2502.07346\\nRepository: https://github.com/CONE-MT/BenchMAX\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\nBenchMAX_Problem_Solving is a dataset of BenchMAX, sourcing from LiveCodeBench.\\nWe extend the original English dataset to 16 non-English languages.\\nThe data is first translated by GPT-4o, and then post-editing by native speakers.\\n\\n\\t\\n\\t\\t\\n\\t\\tSupported Languagesâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/LLaMAX/BenchMAX_Problem_Solving.","first_N":5,"first_N_keywords":["text-generation","multilingual","English","Chinese","Spanish"],"keywords_longer_than_N":true},
	{"name":"Phone-FA-EN-AR-Dataset","keyword":"arabic","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mah92/Phone-FA-EN-AR-Dataset","creator_name":"ali.mahmoudi","creator_url":"https://huggingface.co/mah92","description":"\\n\\t\\n\\t\\t\\n\\t\\tØ¨Ø³Ù… Ø§Ù„Ù„Ù‡\\n\\t\\n\\nØ§ÛŒÙ† Ø¯ÛŒØªØ§Ø³Øª Ø®ÙˆØ§Ù†Ø´ ØªØ§Ú©-Ø¨Ú© ÛŒÚ© Ú¯ÙˆØ´ÛŒ Ø§Ù†Ø¯Ø±ÙˆÛŒØ¯ÛŒ(Ú¯Ø§Ù„Ú©Ø³ÛŒ Ø§Ø³Û±Û° - Ø§Ù†Ø¯Ø±ÙˆÛŒØ¯ Û¹) Ø§Ø³Øª Ú©Ù‡ Ø¨Ù‡ Ú©Ù…Ú© ÛŒÚ© Ù…ÙˆØªÙˆØ± Ø§ÛŒ-Ø§Ø³Ù¾ÛŒÚ© ØªØºÛŒÛŒØ± ÛŒØ§ÙØªÙ‡ Ø¬Ù…Ø¹ Ø¢ÙˆØ±ÛŒ Ø´Ø¯Ù‡ Ø§Ø³Øª. \\n(Ø´Ù…Ø§ Ù…ÛŒ ØªÙˆØ§Ù†ÛŒØ¯ Ø§ÛŒÙ† Ù…ÙˆØªÙˆØ± Ø±Ø§ Ø¯Ø± Ø§ÛŒÙ† Ù„ÛŒÙ†Ú© Ù¾ÛŒØ¯Ø§ Ú©Ù†ÛŒØ¯:\\nØ§ÛŒÙ†Ø¬Ø§)\\nØ§ÛŒÙ† Ø¯ÛŒØªØ§ Ø³Øª Ø´Ø§Ù…Ù„ Ù…ÙˆØ§Ø±Ø¯ Ø²ÛŒØ± Ø§Ø³Øª:\\n\\nØ­Ø±ÙˆÙ Ú©ÛŒØ¨Ø±Ø¯ ÙØ§Ø±Ø³ÛŒ Ùˆ Ø§Ù†Ú¯Ù„ÛŒØ³ÛŒ\\n\\nØªÙ…Ø§Ù… ØªÙ†Ø¸ÛŒÙ…Ø§Øª Ú¯ÙˆØ´ÛŒ Ø¨Ù‡ Ø§Ù†Ú¯Ù„ÛŒØ³ÛŒ\\n\\nØªÙ…Ø§Ù… ØªÙ†Ø¸ÛŒÙ…Ø§Øª Ú¯ÙˆØ´ÛŒ Ø¨Ù‡ ÙØ§Ø±Ø³ÛŒ\\n\\nØ§Ø³Ù… Ø§Ù¾ Ù‡Ø§\\n\\nÙ¾ÛŒØ§Ù…Ú© Ù‡Ø§\\n\\nØµØ­Ø¨Øª Ù‡Ø§ÛŒ Ú†Øª Ú©Ø§Ù†Ø§Ù„ ttsfarsi\\n\\nØµØ­Ø¨Øª Ù‡Ø§ÛŒ Ø²ÛŒØ§Ø¯ÛŒ ÛŒÚ© Ú©Ø§Ù†Ø§Ù„ Ø§Ù†Ú¯Ù„ÛŒØ³ÛŒ Ù†Ø¬ÙˆÙ…\\n\\nØµØ­Ø¨Øª Ù‡Ø§ÛŒ Ø²ÛŒØ§Ø¯ÛŒ Ø§Ø² Ú©Ø§Ù†Ø§Ù„ ÙØ§Ø±Ø³ Ù†ÛŒÙˆØ²\\n\\nØµØ­Ø¨Øª Ù‡Ø§ÛŒ Ø²ÛŒØ§Ø¯ÛŒ Ø§Ø² Ú©Ø§Ù†Ø§Ù„ ØªØ§Ø¨Ù†Ø§Ú©\\n\\nØµØ­Ø¨Øª Ù‡Ø§ÛŒ Ø²ÛŒØ§Ø¯ÛŒ Ø§Ø²â€¦ See the full description on the dataset page: https://huggingface.co/datasets/mah92/Phone-FA-EN-AR-Dataset.","first_N":5,"first_N_keywords":["Persian","English","Arabic","cc0-1.0","10K<n<100K"],"keywords_longer_than_N":true},
	{"name":"Voice","keyword":"arabic","license":"Academic Free License v3.0","license_url":"https://choosealicense.com/licenses/afl-3.0/","language":"en","dataset_url":"https://huggingface.co/datasets/sleeping-ai/Voice","creator_name":"Sleeping AI","creator_url":"https://huggingface.co/sleeping-ai","description":"Introducing dataset of professional voice actors where actors have spoken X sentences. It includes data from all the voices (approx. 9, 920) from voices.com website. Where professional actors have provided examples of their voices. \\n\\n\\t\\n\\t\\t\\n\\t\\tWhat's Voices.com?\\n\\t\\n\\nIt is a website where professional voice actors can be found for different voice acting activities for a cheap price. Much like Fiverr but for actual voices. \\n\\n\\t\\n\\t\\t\\n\\t\\tWhat's included?\\n\\t\\n\\n\\nVoice tracks (approx. 4) for each actorâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/sleeping-ai/Voice.","first_N":5,"first_N_keywords":["English","Arabic","afl-3.0","< 1K","soundfolder"],"keywords_longer_than_N":true},
	{"name":"smol","keyword":"arabic","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/google/smol","creator_name":"Google","creator_url":"https://huggingface.co/google","description":"\\n\\t\\n\\t\\t\\n\\t\\tSMOL\\n\\t\\n\\nSMOL (Set for Maximal Overall Leverage) is a collection of professional\\ntranslations into 221 Low-Resource Languages, for the purpose of training\\ntranslation models, and otherwise increasing the representations of said\\nlanguages in NLP and technology.\\nPlease read the SMOL Paper and the\\nGATITOS Paper for a much more\\nthorough description!\\nThere are four resources in this directory:\\n\\nSmolDoc: document-level translations into 100 languages\\nSmolSent: sentence-level translations intoâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/google/smol.","first_N":5,"first_N_keywords":["translation","Afar","Abkhaz","Achinese","Acoli"],"keywords_longer_than_N":true},
	{"name":"DATA-AI_Chat","keyword":"arabic","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Mattimax/DATA-AI_Chat","creator_name":"M.INC.","creator_url":"https://huggingface.co/Mattimax","description":"\\n\\t\\n\\t\\t\\n\\t\\tDATA-AI: Il Modello di IA di M.INC.\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tðŸ“Œ Introduzione\\n\\t\\n\\nDATA-AI Ã¨ un avanzato modello di intelligenza artificiale sviluppato da *M.INC., un'azienda italiana fondata da *Mattimax (M. Marzorati).Questo modello Ã¨ basato sull'architettura ELNS (Elaborazione del Linguaggio Naturale Semplice), un sistema innovativo progettato per rendere l'IA accessibile su quasi qualsiasi dispositivo, garantendo prestazioni ottimali anche su hardware limitato.  \\nDATA-AI Ã¨ stato addestrato su unâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Mattimax/DATA-AI_Chat.","first_N":5,"first_N_keywords":["Italian","English","Spanish","Russian","German"],"keywords_longer_than_N":true},
	{"name":"ea-mt-benchmark","keyword":"arabic","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/sapienzanlp/ea-mt-benchmark","creator_name":"Sapienza NLP, Sapienza University of Rome","creator_url":"https://huggingface.co/sapienzanlp","description":"\\n\\t\\n\\t\\t\\n\\t\\tDataset Card for EA-MT\\n\\t\\n\\nEA-MT (Entity-Aware Machine Translation) is a multilingual benchmark for evaluating the capabilities of Large Language Models (LLMs) and Machine Translation (MT) models in translating simple sentences with potentially challenging entity mentions, e.g., entities for which a word-for-word translation may not be accurate.\\nHere is an example of a simple sentence with a challenging entity mention:\\n\\nEnglish: \\\"What is the plot of The Catcher in the Rye?\\\"\\nItalian:â€¦ See the full description on the dataset page: https://huggingface.co/datasets/sapienzanlp/ea-mt-benchmark.","first_N":5,"first_N_keywords":["text-generation","English","Arabic","German","Spanish"],"keywords_longer_than_N":true},
	{"name":"u-sticker","keyword":"arabic","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/metchee/u-sticker","creator_name":"Metilda Chee","creator_url":"https://huggingface.co/metchee","description":"\\n\\t\\n\\t\\t\\n\\t\\tU-Sticker\\n\\t\\n\\nUser-Sticker is a stickers dataset with multi-domain conversations.\\nFeatures of U-Sticker:\\n\\nMulti-domain interactions âœ…\\nTemporal âœ…\\nUser information âœ…\\n370.2k stickers âœ… (104k unique)\\n22.6k users âœ…\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\nU-Sticker contains three files:\\n\\nConversation files: 1 to 67.json\\nDomain mapping files idx_to_domain.txt.\\nSticker files.\\n\\n\\nSticker files are available here and Baidu Cloud.\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Structure\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tConversation file\\n\\t\\n\\n\\nEmpty lines areâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/metchee/u-sticker.","first_N":5,"first_N_keywords":["Arabic","Chinese","English","French","Turkish"],"keywords_longer_than_N":true},
	{"name":"high-quality-multilingual-sentences","keyword":"arabic","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/agentlans/high-quality-multilingual-sentences","creator_name":"Alan Tseng","creator_url":"https://huggingface.co/agentlans","description":"\\n\\t\\n\\t\\t\\n\\t\\tHigh Quality Multilingual Sentences\\n\\t\\n\\n\\nThis dataset contains multilingual sentences derived from the agentlans/LinguaNova dataset.\\nIt includes 1.58 million rows across 51 different languages, each in its own configuration.\\n\\nExample row (from the all config):\\n{\\n    \\\"text\\\": \\\"Ø§Ù…Ø§Ù… Ø¬Ù…Ø¹Ù‡ Ø§ØµÙÙ‡Ø§Ù† Ú¯ÙØª: Ù…ÛŒØ²Ø§Ù† Ù†ÛŒØ§Ø² Ø¢Ø¨ Ø´Ø±Ø¨ Ø§ØµÙÙ‡Ø§Ù† Û±Û±.Ûµ Ù…ØªØ± Ù…Ú©Ø¹Ø¨ Ø§Ø³Øª Ú©Ù‡ ØªÙ…Ø§Ù… Ø§Ø³ØªØ§Ù† Ø§ØµÙÙ‡Ø§Ù† Ø±Ø§ Ù¾ÙˆØ´Ø´ Ù…ÛŒØ¯Ù‡Ø¯ Ùˆ Ù†Ø³Ø¨Øª Ø¨Ù‡ Ù‚Ø¨Ù„ Ø§Ø² Ø§Ù†Ù‚Ù„Ø§Ø¨ ÛŒÚ©ÛŒ Ø§Ø² Ù¾ÛŒØ´Ø±ÙØªÙ‡Ø§ Ø¯Ø± Ø­ÙˆØ²Ù‡ Ø¢Ø¨ Ø¨ÙˆØ¯Ù‡ Ø§Ø³Øª.\\\",\\n    \\\"fasttext\\\": \\\"fa\\\",\\n    \\\"gcld3\\\": \\\"fa\\\"\\n}\\n\\nFields:â€¦ See the full description on the dataset page: https://huggingface.co/datasets/agentlans/high-quality-multilingual-sentences.","first_N":5,"first_N_keywords":["text-generation","text-classification","text-retrieval","multilingual","Arabic"],"keywords_longer_than_N":true},
	{"name":"Open-R1-Mulitlingual-SFT","keyword":"arabic","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/amphora/Open-R1-Mulitlingual-SFT","creator_name":"GUIJIN SON","creator_url":"https://huggingface.co/amphora","description":"\\n\\t\\n\\t\\t\\n\\t\\tOpen-R1-Mulitlingual-SFT\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tOverview\\n\\t\\n\\nOpen-R1-Mulitlingual-SFT is a curated dataset designed for multilingual supervised fine-tuning.\\nThe source data comprises multiple datasets containing original prompts and responses, which were subsequently translated into 14 languages using GPT-4o.\\n\\n\\t\\n\\t\\t\\n\\t\\tSources\\n\\t\\n\\nThe dataset is derived from:\\n\\nopen-thoughts/OpenThoughts-114kHugging Face: open-thoughts/OpenThoughts-114k\\nbespokelabs/Bespoke-Stratos-17kHugging Face:â€¦ See the full description on the dataset page: https://huggingface.co/datasets/amphora/Open-R1-Mulitlingual-SFT.","first_N":5,"first_N_keywords":["Afrikaans","Arabic","Chinese","English","French"],"keywords_longer_than_N":true},
	{"name":"smol","keyword":"egyptian arabic","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/google/smol","creator_name":"Google","creator_url":"https://huggingface.co/google","description":"\\n\\t\\n\\t\\t\\n\\t\\tSMOL\\n\\t\\n\\nSMOL (Set for Maximal Overall Leverage) is a collection of professional\\ntranslations into 221 Low-Resource Languages, for the purpose of training\\ntranslation models, and otherwise increasing the representations of said\\nlanguages in NLP and technology.\\nPlease read the SMOL Paper and the\\nGATITOS Paper for a much more\\nthorough description!\\nThere are four resources in this directory:\\n\\nSmolDoc: document-level translations into 100 languages\\nSmolSent: sentence-level translations intoâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/google/smol.","first_N":5,"first_N_keywords":["translation","Afar","Abkhaz","Achinese","Acoli"],"keywords_longer_than_N":true},
	{"name":"smol","keyword":"levantine arabic","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/google/smol","creator_name":"Google","creator_url":"https://huggingface.co/google","description":"\\n\\t\\n\\t\\t\\n\\t\\tSMOL\\n\\t\\n\\nSMOL (Set for Maximal Overall Leverage) is a collection of professional\\ntranslations into 221 Low-Resource Languages, for the purpose of training\\ntranslation models, and otherwise increasing the representations of said\\nlanguages in NLP and technology.\\nPlease read the SMOL Paper and the\\nGATITOS Paper for a much more\\nthorough description!\\nThere are four resources in this directory:\\n\\nSmolDoc: document-level translations into 100 languages\\nSmolSent: sentence-level translations intoâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/google/smol.","first_N":5,"first_N_keywords":["translation","Afar","Abkhaz","Achinese","Acoli"],"keywords_longer_than_N":true},
	{"name":"smol","keyword":"tunisian arabic","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/google/smol","creator_name":"Google","creator_url":"https://huggingface.co/google","description":"\\n\\t\\n\\t\\t\\n\\t\\tSMOL\\n\\t\\n\\nSMOL (Set for Maximal Overall Leverage) is a collection of professional\\ntranslations into 221 Low-Resource Languages, for the purpose of training\\ntranslation models, and otherwise increasing the representations of said\\nlanguages in NLP and technology.\\nPlease read the SMOL Paper and the\\nGATITOS Paper for a much more\\nthorough description!\\nThere are four resources in this directory:\\n\\nSmolDoc: document-level translations into 100 languages\\nSmolSent: sentence-level translations intoâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/google/smol.","first_N":5,"first_N_keywords":["translation","Afar","Abkhaz","Achinese","Acoli"],"keywords_longer_than_N":true},
	{"name":"Arabic-Optimized-Reasoning-Dataset","keyword":"arabic","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Jr23xd23/Arabic-Optimized-Reasoning-Dataset","creator_name":"Jaber","creator_url":"https://huggingface.co/Jr23xd23","description":"\\n\\t\\n\\t\\t\\n\\t\\tArabic Optimized Reasoning Dataset\\n\\t\\n\\nDataset Name: Arabic Optimized ReasoningLicense: Apache-2.0Formats: CSVSize: 1600 rowsBase Dataset: cognitivecomputations/dolphin-r1Libraries Used: Datasets, Dask, Croissant\\n\\n\\t\\n\\t\\t\\n\\t\\tOverview\\n\\t\\n\\nThe Arabic Optimized Reasoning Dataset helps AI models get better at reasoning in Arabic. While AI models are good at many tasks, they often struggle with reasoning in languages other than English. This dataset helps fix this problem by:\\n\\nUsing fewer tokensâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Jr23xd23/Arabic-Optimized-Reasoning-Dataset.","first_N":5,"first_N_keywords":["question-answering","table-question-answering","Arabic","apache-2.0","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"wikis","keyword":"arabic","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/nyuuzyou/wikis","creator_name":"nyuuzyou","creator_url":"https://huggingface.co/nyuuzyou","description":"\\n\\t\\n\\t\\t\\n\\t\\tDataset Card for Public MediaWiki Collection\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThis dataset contains 1,662,448 articles harvested from 930 random public MediaWiki instances found across the Internet. The collection was created by extracting current page content from these wikis, preserving article text, metadata, and structural information. The dataset represents a diverse cross-section of public wiki content spanning multiple domains, topics, and languages.\\n\\n\\t\\n\\t\\t\\n\\t\\tLanguages\\n\\t\\n\\nTheâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/nyuuzyou/wikis.","first_N":5,"first_N_keywords":["text-generation","text-classification","language-modeling","topic-classification","found"],"keywords_longer_than_N":true},
	{"name":"wikipedia_quality_wikirank","keyword":"arabic","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/lewoniewski/wikipedia_quality_wikirank","creator_name":"WÅ‚odzimierz Lewoniewski","creator_url":"https://huggingface.co/lewoniewski","description":"Datasets with WikiRank quality score as of 1 August 2024 for 47 million Wikipedia articles in 55 language versions (also simplified version for each language in separate files).\\nThe WikiRank quality score is a metric designed to assess the overall quality of a Wikipedia article. Although its specific algorithm can vary depending on the implementation, the score typically combines several key features of the Wikipedia article.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tWhy Itâ€™s Important\\n\\t\\n\\n\\nEnhances Trust: For readers andâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/lewoniewski/wikipedia_quality_wikirank.","first_N":5,"first_N_keywords":["Arabic","Azerbaijani","Belarusian","Bulgarian","Catalan"],"keywords_longer_than_N":true},
	{"name":"Shifaa_Arabic_Mental_Health_Consultations","keyword":"arabic","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Ahmed-Selem/Shifaa_Arabic_Mental_Health_Consultations","creator_name":"Ahmed Selem","creator_url":"https://huggingface.co/Ahmed-Selem","description":"\\n\\t\\n\\t\\t\\n\\t\\tðŸ¥ Shifaa Arabic Mental Health Consultations ðŸ§ \\n\\t\\n\\n  \\n\\n\\t\\n\\t\\t\\n\\t\\tðŸ“Œ Overview\\n\\t\\n\\nShifaa Arabic Mental Health Consultations is a high-quality dataset designed to advance Arabic medical language models.This dataset provides 35,648 real-world medical consultations, covering a wide range of mental health concerns.  \\n\\n\\t\\n\\t\\t\\n\\t\\tðŸ“Š Dataset Summary\\n\\t\\n\\n\\nSize: 35,648 consultations  \\nMain Specializations: 7  \\nSpecific Diagnoses: 123  \\nLanguages: Arabic (Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©)\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tWhy This Dataset?\\n\\t\\n\\nðŸ”¹ Lack ofâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Ahmed-Selem/Shifaa_Arabic_Mental_Health_Consultations.","first_N":5,"first_N_keywords":["question-answering","text-classification","zero-shot-classification","Arabic","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"Thinking-multilingual-big-10k-sft","keyword":"arabic","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Pinkstack/Thinking-multilingual-big-10k-sft","creator_name":"Pinkstack","creator_url":"https://huggingface.co/Pinkstack","description":"\\nA dataset based off of openo1 math, 500 examples translated to 23 different languages. filtered out un-translated examples.\\nenjoy ðŸ‘\\n","first_N":5,"first_N_keywords":["text-generation","Arabic","Chinese","Czech","Danish"],"keywords_longer_than_N":true},
	{"name":"multilingual_translation_sft","keyword":"arabic","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Youseff1987/multilingual_translation_sft","creator_name":"JOON HYOUNG JUN","creator_url":"https://huggingface.co/Youseff1987","description":"Youseff1987/multilingual_translation_sft dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["translation","Korean","English","Chinese","Zulu"],"keywords_longer_than_N":true},
	{"name":"m-WildVision","keyword":"arabic","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/CohereForAI/m-WildVision","creator_name":"Cohere For AI","creator_url":"https://huggingface.co/CohereForAI","description":"\\n\\t\\n\\t\\t\\n\\t\\tDataset Card for m-WildVision\\n\\t\\n\\n\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Details\\n\\t\\n\\nThe m-WildVision dataset is a multilingual multimodal LLM evaluation set covering 23 languages.  It was created by translating prompts from the original English-only WildVision (vision_bench_0617) test set. \\nThe original prompts, developed by Lu et al. (2024) , consist of 500 challenging user queries sourced from the WildVision-Arena platform. \\nThe authors demonstrated that these prompts enable automatic LLM judgeâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/CohereForAI/m-WildVision.","first_N":5,"first_N_keywords":["English","French","German","Spanish","Italian"],"keywords_longer_than_N":true},
	{"name":"OpenHumanreasoning-multilingual-2.2k","keyword":"arabic","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Pinkstack/OpenHumanreasoning-multilingual-2.2k","creator_name":"Pinkstack","creator_url":"https://huggingface.co/Pinkstack","description":"Based off of Pinkstackorg/humanreasoning-testing-en, it is a human-generated dataset where a real person had to create most of the reasoning and the final output. If there are any mistakes please let us know.\\nWe offer this dataset at an apache-2.0 license to make it useful for everybody.\\nnote: translations are not human generated.\\n","first_N":5,"first_N_keywords":["text-generation","Arabic","Chinese","Czech","Danish"],"keywords_longer_than_N":true},
	{"name":"BRIGHTER-emotion-categories","keyword":"arabic","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/brighter-dataset/BRIGHTER-emotion-categories","creator_name":"BRIGHTER Dataset","creator_url":"https://huggingface.co/brighter-dataset","description":"\\n\\t\\n\\t\\t\\n\\t\\tBRIGHTER Emotion Categories Dataset\\n\\t\\n\\nThis dataset contains the emotion categories data from the BRIGHTER paper: BRIdging the Gap in Human-Annotated Textual Emotion Recognition Datasets for 28 Languages.\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThe BRIGHTER Emotion Categories dataset is a comprehensive multi-language, multi-label emotion classification dataset with separate configurations for each language. It represents one of the largest human-annotated emotion datasets across multipleâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/brighter-dataset/BRIGHTER-emotion-categories.","first_N":5,"first_N_keywords":["Afrikaans","Arabic","German","English","Spanish"],"keywords_longer_than_N":true},
	{"name":"aya_redteaming","keyword":"arabic","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/CohereForAI/aya_redteaming","creator_name":"Cohere For AI","creator_url":"https://huggingface.co/CohereForAI","description":"\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Card for Aya Red-teaming\\n\\t\\n\\n\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Details\\n\\t\\n\\nThe Aya Red-teaming dataset is a human-annotated multilingual red-teaming dataset consisting of harmful prompts in 8 languages across 9 different categories of harm with explicit labels for \\\"global\\\" and \\\"local\\\" harm.\\n\\n\\n\\n\\n\\n\\nCurated by: Professional compensated annotators\\nLanguages: Arabic, English, Filipino, French, Hindi, Russian, Serbian and Spanish\\nLicense: Apache 2.0\\nPaper: arxiv link\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tHarm Categories:â€¦ See the full description on the dataset page: https://huggingface.co/datasets/CohereForAI/aya_redteaming.","first_N":5,"first_N_keywords":["English","Hindi","French","Spanish","Arabic"],"keywords_longer_than_N":true},
	{"name":"ar_sarcasm","keyword":"arabic","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/iabufarha/ar_sarcasm","creator_name":"Ibrahim","creator_url":"https://huggingface.co/iabufarha","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for ArSarcasm\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nArSarcasm is a new Arabic sarcasm detection dataset.\\nThe dataset was created using previously available Arabic sentiment analysis\\ndatasets (SemEval 2017\\nand ASTD) and adds sarcasm and\\ndialect labels to them.\\nThe dataset contains 10,547 tweets, 1,682 (16%) of which are sarcastic.\\nFor more details, please check the paper\\nFrom Arabic Sentiment Analysis to Sarcasm Detection: The ArSarcasm Dataset\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSupported Tasksâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/iabufarha/ar_sarcasm.","first_N":5,"first_N_keywords":["text-classification","sentiment-classification","no-annotation","found","monolingual"],"keywords_longer_than_N":true},
	{"name":"arabic_pos_dialect","keyword":"arabic","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/QCRI/arabic_pos_dialect","creator_name":"Arabic Language Technologies, Qatar Computing Research Institute","creator_url":"https://huggingface.co/QCRI","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Arabic POS Dialect\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThis dataset was created to support part of speech (POS) tagging in dialects of Arabic. It contains sets of 350 manually segmented and POS tagged tweets for each of four dialects: Egyptian, Levantine, Gulf, and Maghrebi.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSupported Tasks and Leaderboards\\n\\t\\n\\nThe dataset can be used to train a model for Arabic token segmentation and part of speech tagging in Arabic dialects. Success on this task isâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/QCRI/arabic_pos_dialect.","first_N":5,"first_N_keywords":["token-classification","part-of-speech","expert-generated","found","multilingual"],"keywords_longer_than_N":true},
	{"name":"arcd","keyword":"arabic","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/hsseinmz/arcd","creator_name":"Hussein Mozannar","creator_url":"https://huggingface.co/hsseinmz","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for \\\"arcd\\\"\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\n Arabic Reading Comprehension Dataset (ARCD) composed of 1,395 questions      posed by crowdworkers on Wikipedia articles.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSupported Tasks and Leaderboards\\n\\t\\n\\nMore Information Needed\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages\\n\\t\\n\\nMore Information Needed\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Structure\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Instances\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tplain_text\\n\\t\\n\\n\\nSize of downloaded dataset files: 1.94 MB\\nSize of the generated dataset: 1.70 MB\\nTotal amountâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/hsseinmz/arcd.","first_N":5,"first_N_keywords":["question-answering","extractive-qa","crowdsourced","crowdsourced","monolingual"],"keywords_longer_than_N":true},
	{"name":"bnl_newspapers","keyword":"arabic","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/bnl-data/bnl_newspapers","creator_name":"BnL Open Data","creator_url":"https://huggingface.co/bnl-data","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for BnL Historical Newspapers\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThe BnL has digitised over 800.000 pages of Luxembourg newspapers. This dataset currently has one configuration covering a subset of these newspapers, which sit under the \\\"Processed Datasets\\\" collection. The BNL:\\n\\nprocessed all newspapers and monographs that are in the public domain and extracted the full text and associated meta data of every single article, section, advertisementâ€¦ The result is a largeâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/bnl-data/bnl_newspapers.","first_N":5,"first_N_keywords":["text-generation","fill-mask","language-modeling","masked-language-modeling","no-annotation"],"keywords_longer_than_N":true},
	{"name":"opus_infopankki","keyword":"arabic","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Helsinki-NLP/opus_infopankki","creator_name":"Language Technology Research Group at the University of Helsinki","creator_url":"https://huggingface.co/Helsinki-NLP","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for infopankki\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nA parallel corpus of 12 languages, 66 bitexts.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSupported Tasks and Leaderboards\\n\\t\\n\\nThe underlying task is machine translation.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages\\n\\t\\n\\n[More Information Needed]\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Structure\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Instances\\n\\t\\n\\n[More Information Needed]\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Fields\\n\\t\\n\\n[More Information Needed]\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Splits\\n\\t\\n\\n[More Information Needed]\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Creationâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Helsinki-NLP/opus_infopankki.","first_N":5,"first_N_keywords":["translation","found","found","multilingual","original"],"keywords_longer_than_N":true},
	{"name":"opus_ubuntu","keyword":"arabic","license":"BSD 3-Clause \"New\" or \"Revised\" License","license_url":"https://choosealicense.com/licenses/bsd-3-clause/","language":"en","dataset_url":"https://huggingface.co/datasets/Helsinki-NLP/opus_ubuntu","creator_name":"Language Technology Research Group at the University of Helsinki","creator_url":"https://huggingface.co/Helsinki-NLP","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Opus Ubuntu\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThese are translations of the Ubuntu software package messages, donated by the Ubuntu community.\\nTo load a language pair which isn't part of the config, all you need to do is specify the language code as pairs.\\nYou can find the valid pairs in Homepage section of Dataset Description: http://opus.nlpl.eu/Ubuntu.php\\nE.g.\\ndataset = load_dataset(\\\"opus_ubuntu\\\", lang1=\\\"it\\\", lang2=\\\"pl\\\")\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSupported Tasks andâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Helsinki-NLP/opus_ubuntu.","first_N":5,"first_N_keywords":["translation","crowdsourced","expert-generated","found","multilingual"],"keywords_longer_than_N":true},
	{"name":"opus_ubuntu","keyword":"moroccan arabic","license":"BSD 3-Clause \"New\" or \"Revised\" License","license_url":"https://choosealicense.com/licenses/bsd-3-clause/","language":"en","dataset_url":"https://huggingface.co/datasets/Helsinki-NLP/opus_ubuntu","creator_name":"Language Technology Research Group at the University of Helsinki","creator_url":"https://huggingface.co/Helsinki-NLP","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Opus Ubuntu\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThese are translations of the Ubuntu software package messages, donated by the Ubuntu community.\\nTo load a language pair which isn't part of the config, all you need to do is specify the language code as pairs.\\nYou can find the valid pairs in Homepage section of Dataset Description: http://opus.nlpl.eu/Ubuntu.php\\nE.g.\\ndataset = load_dataset(\\\"opus_ubuntu\\\", lang1=\\\"it\\\", lang2=\\\"pl\\\")\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSupported Tasks andâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Helsinki-NLP/opus_ubuntu.","first_N":5,"first_N_keywords":["translation","crowdsourced","expert-generated","found","multilingual"],"keywords_longer_than_N":true},
	{"name":"tydiqa","keyword":"arabic","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/google-research-datasets/tydiqa","creator_name":"Google Research Datasets","creator_url":"https://huggingface.co/google-research-datasets","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for \\\"tydiqa\\\"\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nTyDi QA is a question answering dataset covering 11 typologically diverse languages with 204K question-answer pairs.\\nThe languages of TyDi QA are diverse with regard to their typology -- the set of linguistic features that each language\\nexpresses -- such that we expect models performing well on this set to generalize across a large number of the languages\\nin the world. It contains language phenomena that would not be foundâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/google-research-datasets/tydiqa.","first_N":5,"first_N_keywords":["question-answering","extractive-qa","crowdsourced","crowdsourced","multilingual"],"keywords_longer_than_N":true},
	{"name":"xcsr","keyword":"arabic","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/INK-USC/xcsr","creator_name":"INK Lab @ USC","creator_url":"https://huggingface.co/INK-USC","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for X-CSR\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nTo evaluate multi-lingual language models (ML-LMs) for commonsense reasoning in a cross-lingual zero-shot transfer setting (X-CSR), i.e., training in English and test in other languages, we create two benchmark datasets, namely X-CSQA and X-CODAH. Specifically, we automatically translate the original CSQA and CODAH datasets, which only have English versions, to 15 other languages, forming development and test sets forâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/INK-USC/xcsr.","first_N":5,"first_N_keywords":["question-answering","multiple-choice-qa","crowdsourced","crowdsourced","machine-generated"],"keywords_longer_than_N":true},
	{"name":"xquad_r","keyword":"arabic","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/google-research-datasets/xquad_r","creator_name":"Google Research Datasets","creator_url":"https://huggingface.co/google-research-datasets","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for [Dataset Name]\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nXQuAD-R is a retrieval version of the XQuAD dataset (a cross-lingual extractive\\nQA dataset). Like XQuAD, XQUAD-R is an 11-way parallel dataset,  where each\\nquestion appears in 11 different languages and has 11 parallel correct answers\\nacross the languages.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSupported Tasks and Leaderboards\\n\\t\\n\\n[More Information Needed]\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages\\n\\t\\n\\nThe dataset can be found with the following languages:\\n\\nArabic:â€¦ See the full description on the dataset page: https://huggingface.co/datasets/google-research-datasets/xquad_r.","first_N":5,"first_N_keywords":["question-answering","extractive-qa","expert-generated","found","multilingual"],"keywords_longer_than_N":true},
	{"name":"mr-tydi-corpus","keyword":"arabic","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/castorini/mr-tydi-corpus","creator_name":"Castorini","creator_url":"https://huggingface.co/castorini","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nMr. TyDi is a multi-lingual benchmark dataset built on TyDi, covering eleven typologically diverse languages. It is designed for monolingual retrieval, specifically to evaluate ranking with learned dense representations.\\nThis dataset stores documents of Mr. TyDi. To access the queries and judgments, please refer to castorini/mr-tydi.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Structure\\n\\t\\n\\nThe only configuration here is the language. As all three folds (train, dev and test) share theâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/castorini/mr-tydi-corpus.","first_N":5,"first_N_keywords":["text-retrieval","multilingual","Arabic","Bengali","English"],"keywords_longer_than_N":true},
	{"name":"mr-tydi","keyword":"arabic","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/castorini/mr-tydi","creator_name":"Castorini","creator_url":"https://huggingface.co/castorini","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nMr. TyDi is a multi-lingual benchmark dataset built on TyDi, covering eleven typologically diverse languages. It is designed for monolingual retrieval, specifically to evaluate ranking with learned dense representations.\\nThis dataset stores the queries, judgements, and example training data of Mr. TyDi. To access the corpus, please refer to castorini/mr-tydi-corpus.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Structure\\n\\t\\n\\nThe only configuration here is the language, \\nFor each languageâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/castorini/mr-tydi.","first_N":5,"first_N_keywords":["text-retrieval","multilingual","Arabic","Bengali","English"],"keywords_longer_than_N":true},
	{"name":"flores_101","keyword":"arabic","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/gsarti/flores_101","creator_name":"Gabriele Sarti","creator_url":"https://huggingface.co/gsarti","description":"One of the biggest challenges hindering progress in low-resource and multilingual machine translation is the \\nlack of good evaluation benchmarks. Current evaluation benchmarks either lack good coverage of low-resource \\nlanguages, consider only restricted domains, or are low quality because they are constructed using \\nsemi-automatic procedures. In this work, we introduce the FLORES evaluation benchmark, consisting of 3001 \\nsentences extracted from English Wikipedia and covering a variety of different topics and domains. \\nThese sentences have been translated in 101 languages by professional translators through a carefully \\ncontrolled process. The resulting dataset enables better assessment of model quality on the long tail of \\nlow-resource languages, including the evaluation of many-to-many multilingual translation systems, as all \\ntranslations are multilingually aligned. By publicly releasing such a high-quality and high-coverage dataset, \\nwe hope to foster progress in the machine translation community and beyond.","first_N":5,"first_N_keywords":["text-generation","translation","found","expert-generated","multilingual"],"keywords_longer_than_N":true},
	{"name":"xlel_wd_dictionary","keyword":"arabic","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/adithya7/xlel_wd_dictionary","creator_name":"Adithya Pratapa","creator_url":"https://huggingface.co/adithya7","description":"XLEL-WD is a multilingual event linking dataset. This sub-dataset contains a dictionary of events from Wikidata. The multilingual descriptions for Wikidata event items are taken from the corresponding Wikipedia articles.","first_N":5,"first_N_keywords":["found","found","multilingual","original","Afrikaans"],"keywords_longer_than_N":true},
	{"name":"xlel_wd","keyword":"arabic","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/adithya7/xlel_wd","creator_name":"Adithya Pratapa","creator_url":"https://huggingface.co/adithya7","description":"XLEL-WD is a multilingual event linking dataset. This dataset contains mention references from multilingual Wikipedia/Wikinews articles to event items in Wikidata. The text descriptions for Wikidata events are compiled from Wikipedia articles.","first_N":5,"first_N_keywords":["found","found","multilingual","original","Afrikaans"],"keywords_longer_than_N":true},
	{"name":"shades_nationality","keyword":"arabic","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/bigscience-catalogue-data/shades_nationality","creator_name":"BigScience Catalogue Data","creator_url":"https://huggingface.co/bigscience-catalogue-data","description":"Possibly a placeholder dataset for the original here: https://huggingface.co/datasets/bigscience-catalogue-data/bias-shades\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Statement for SHADES\\n\\t\\n\\n\\nHow to use this document:\\nFill in each section according to the instructions. Give as much detail as you can, but there's no need to extrapolate. The goal is to help people understand your data when they approach it. This could be someone looking at it in ten years, or it could be you yourself looking back at the data in twoâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/bigscience-catalogue-data/shades_nationality.","first_N":5,"first_N_keywords":["Arabic","English","French","German","Hindi"],"keywords_longer_than_N":true},
	{"name":"wit_base","keyword":"arabic","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/wikimedia/wit_base","creator_name":"Wikimedia","creator_url":"https://huggingface.co/wikimedia","description":"\\n\\t\\n\\t\\t\\n\\t\\tDataset Card for WIT\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nWikimedia's version of the Wikipedia-based Image Text (WIT) Dataset, a large multimodal multilingual dataset.\\nFrom the official blog post:\\n\\nThe core training data is taken from the Wikipedia Image-Text (WIT) Dataset, a large curated set of more than 37 million image-text associations extracted from Wikipedia articles in 108 languages that was recently released by Google Research.\\nThe WIT dataset offers extremely valuable data about theâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/wikimedia/wit_base.","first_N":5,"first_N_keywords":["image-to-text","text-retrieval","image-captioning","machine-generated","found"],"keywords_longer_than_N":true},
	{"name":"wit_base","keyword":"egyptian arabic","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/wikimedia/wit_base","creator_name":"Wikimedia","creator_url":"https://huggingface.co/wikimedia","description":"\\n\\t\\n\\t\\t\\n\\t\\tDataset Card for WIT\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nWikimedia's version of the Wikipedia-based Image Text (WIT) Dataset, a large multimodal multilingual dataset.\\nFrom the official blog post:\\n\\nThe core training data is taken from the Wikipedia Image-Text (WIT) Dataset, a large curated set of more than 37 million image-text associations extracted from Wikipedia articles in 108 languages that was recently released by Google Research.\\nThe WIT dataset offers extremely valuable data about theâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/wikimedia/wit_base.","first_N":5,"first_N_keywords":["image-to-text","text-retrieval","image-captioning","machine-generated","found"],"keywords_longer_than_N":true},
	{"name":"divemt","keyword":"arabic","license":"GNU General Public License v3.0","license_url":"https://choosealicense.com/licenses/gpl-3.0/","language":"en","dataset_url":"https://huggingface.co/datasets/GroNLP/divemt","creator_name":"GroNLP","creator_url":"https://huggingface.co/GroNLP","description":"DivEMT is the first publicly available post-editing study of Neural Machine Translation (NMT) over a typologically diverse set of target languages. Using a strictly controlled setup, 18 professional translators were instructed to translate or post-edit the same set of English documents into Arabic, Dutch, Italian, Turkish, Ukrainian, and Vietnamese. During the process, their edits, keystrokes, editing times, pauses, and perceived effort were logged, enabling an in-depth, cross-lingual evaluation of NMT quality and its post-editing process.","first_N":5,"first_N_keywords":["translation","machine-generated","expert-generated","found","translation"],"keywords_longer_than_N":true},
	{"name":"MaWPS-ar","keyword":"arabic","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/omarxadel/MaWPS-ar","creator_name":"Omar Adel","creator_url":"https://huggingface.co/omarxadel","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for MAWPS_ar\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nMAWPS: A Math Word Problem Repository\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSupported Tasks\\n\\t\\n\\nMath Word Problem Solving\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages\\n\\t\\n\\nSupports Arabic and English\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Structure\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Fields\\n\\t\\n\\n\\ntext_en: a string feature.\\ntext_ar: a string feature.\\neqn: a string feature.\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Splits\\n\\t\\n\\n\\n\\t\\n\\t\\t\\ntrain\\nvalidation\\ntest\\n\\n\\n\\t\\t\\n3636\\n1040\\n520\\n\\n\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDatasetâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/omarxadel/MaWPS-ar.","first_N":5,"first_N_keywords":["text2text-generation","explanation-generation","crowdsourced","found","multilingual"],"keywords_longer_than_N":true},
	{"name":"QuranExe","keyword":"arabic","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/mustapha/QuranExe","creator_name":"AJEGHRIR mustapha","creator_url":"https://huggingface.co/mustapha","description":"This dataset contains the exegeses/tafsirs (ØªÙØ³ÙŠØ± Ø§Ù„Ù‚Ø±Ø¢Ù†) of the holy Quran in arabic by 8 exegetes.\\nThis is a non Official dataset. It have been scrapped from the Quran.com Api\\nThis dataset contains 49888 records with +14 Million words. 8 records per Quranic verse\\nUsage Example :\\nfrom datasets import load_dataset\\n\\ntafsirs = load_dataset(\\\"mustapha/QuranExe\\\")\\n\\n","first_N":5,"first_N_keywords":["text-generation","fill-mask","sentence-similarity","language-modeling","masked-language-modeling"],"keywords_longer_than_N":true},
	{"name":"hatecheck-arabic","keyword":"arabic","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Paul/hatecheck-arabic","creator_name":"Paul RÃ¶ttger","creator_url":"https://huggingface.co/Paul","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Multilingual HateCheck\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nMultilingual HateCheck (MHC) is a suite of functional tests for hate speech detection models in 10 different languages: Arabic, Dutch, French, German, Hindi, Italian, Mandarin, Polish, Portuguese and Spanish.\\nFor each language, there are 25+ functional tests that correspond to distinct types of hate and challenging non-hate.\\nThis allows for targeted diagnostic insights into model performance.\\nFor moreâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Paul/hatecheck-arabic.","first_N":5,"first_N_keywords":["text-classification","hate-speech-detection","crowdsourced","expert-generated","monolingual"],"keywords_longer_than_N":true},
	{"name":"xP3all","keyword":"arabic","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/bigscience/xP3all","creator_name":"BigScience Workshop","creator_url":"https://huggingface.co/bigscience","description":"xP3 (Crosslingual Public Pool of Prompts) is a collection of prompts & datasets across 46 of languages & 16 NLP tasks. It is used for the training of BLOOMZ and mT0, multilingual language models capable of following human instructions in dozens of languages zero-shot.","first_N":5,"first_N_keywords":["other","expert-generated","crowdsourced","multilingual","Akan"],"keywords_longer_than_N":true},
	{"name":"answerable_tydiqa","keyword":"arabic","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/copenlu/answerable_tydiqa","creator_name":"CopeNLU","creator_url":"https://huggingface.co/copenlu","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for \\\"answerable-tydiqa\\\"\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nTyDi QA is a question answering dataset covering 11 typologically diverse languages. \\nAnswerable TyDi QA is an extension of the GoldP subtask of the original TyDi QA dataset to also include unanswertable questions.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Structure\\n\\t\\n\\nThe dataset contains a train and a validation set, with 116067 and 13325 examples, respectively. Access them with\\nfrom datasets import load_dataset\\ndataset =â€¦ See the full description on the dataset page: https://huggingface.co/datasets/copenlu/answerable_tydiqa.","first_N":5,"first_N_keywords":["question-answering","extractive-qa","crowdsourced","crowdsourced","multilingual"],"keywords_longer_than_N":true},
	{"name":"tydiqa_copenlu","keyword":"arabic","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/copenlu/tydiqa_copenlu","creator_name":"CopeNLU","creator_url":"https://huggingface.co/copenlu","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for \\\"tydiqa\\\"\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nTyDi QA is a question answering dataset covering 11 typologically diverse languages with 204K question-answer pairs.\\nThe languages of TyDi QA are diverse with regard to their typology -- the set of linguistic features that each language\\nexpresses -- such that we expect models performing well on this set to generalize across a large number of the languages\\nin the world. It contains language phenomena that would not be foundâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/copenlu/tydiqa_copenlu.","first_N":5,"first_N_keywords":["question-answering","extractive-qa","crowdsourced","crowdsourced","multilingual"],"keywords_longer_than_N":true},
	{"name":"xP3mt","keyword":"arabic","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/bigscience/xP3mt","creator_name":"BigScience Workshop","creator_url":"https://huggingface.co/bigscience","description":"xP3 (Crosslingual Public Pool of Prompts) is a collection of prompts & datasets across 46 of languages & 16 NLP tasks. It is used for the training of BLOOMZ and mT0, multilingual language models capable of following human instructions in dozens of languages zero-shot.","first_N":5,"first_N_keywords":["other","expert-generated","crowdsourced","multilingual","Akan"],"keywords_longer_than_N":true},
	{"name":"miracl-corpus","keyword":"arabic","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/miracl/miracl-corpus","creator_name":"MIRACL","creator_url":"https://huggingface.co/miracl","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for MIRACL Corpus\\n\\t\\n\\nMIRACL ðŸŒðŸ™ŒðŸŒ (Multilingual Information Retrieval Across a Continuum of Languages) is a multilingual retrieval dataset that focuses on search across 18 different languages, which collectively encompass over three billion native speakers around the world.\\nThis dataset contains the collection data of the 16 \\\"known languages\\\". The remaining 2 \\\"surprise languages\\\" will not be released until later.\\nThe corpus for each language is prepared from aâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/miracl/miracl-corpus.","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","expert-generated","multilingual","Arabic"],"keywords_longer_than_N":true},
	{"name":"TaTA","keyword":"arabic","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/GEM/TaTA","creator_name":"GEM benchmark","creator_url":"https://huggingface.co/GEM","description":"Dataset loader for TaTA: A Multilingual Table-to-Text Dataset for African Languages","first_N":5,"first_N_keywords":["table-to-text","none","unknown","yes","original"],"keywords_longer_than_N":true},
	{"name":"HashtagPrediction","keyword":"arabic","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Twitter/HashtagPrediction","creator_name":"Twitter","creator_url":"https://huggingface.co/Twitter","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tHashtag Prediction Dataset from paper TwHIN-BERT: A Socially-Enriched Pre-trained Language Model for Multilingual Tweet Representations\\n\\t\\n\\n  \\nThis repo contains the Hashtag prediction dataset from our paper TwHIN-BERT: A Socially-Enriched Pre-trained Language Model for Multilingual Tweet Representations. \\n[arXiv]\\n[HuggingFace Models]\\n[Github repo]\\nThis work is licensed under a Creative Commons Attribution 4.0 International License.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDownload\\n\\t\\n\\nUse theâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Twitter/HashtagPrediction.","first_N":5,"first_N_keywords":["Slovenian","Urdu","Sindhi","Polish","Vietnamese"],"keywords_longer_than_N":true},
	{"name":"ArASL_Database_Grayscale","keyword":"arabic","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/pain/ArASL_Database_Grayscale","creator_name":"Mohammad Albarham","creator_url":"https://huggingface.co/pain","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for \\\"ArASL_Database_Grayscale\\\"\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nA new dataset consists of 54,049 images of ArSL alphabets performed by more than 40 people for 32 standard Arabic signs and alphabets.\\nThe number of images per class differs from one class to another. Sample image of all Arabic Language Signs is also attached. The CSV file contains the Label of each corresponding Arabic Sign Language Image based on the image file name. \\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSupported Tasks andâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/pain/ArASL_Database_Grayscale.","first_N":5,"first_N_keywords":["image-classification","Arabic","cc-by-4.0","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"wikipedia-22-12-ar-embeddings","keyword":"arabic","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Cohere/wikipedia-22-12-ar-embeddings","creator_name":"Cohere","creator_url":"https://huggingface.co/Cohere","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tWikipedia (ar) embedded with cohere.ai multilingual-22-12 encoder\\n\\t\\n\\nWe encoded Wikipedia (ar) using the cohere.ai multilingual-22-12 embedding model.\\nTo get an overview how this dataset was created and pre-processed, have a look at Cohere/wikipedia-22-12.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tEmbeddings\\n\\t\\n\\nWe compute for title+\\\" \\\"+text the embeddings using our multilingual-22-12 embedding model, a state-of-the-art model that works for semantic search in 100 languages.  If you want to learn more about thisâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Cohere/wikipedia-22-12-ar-embeddings.","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","expert-generated","multilingual","Arabic"],"keywords_longer_than_N":true},
	{"name":"divemt_attributions","keyword":"arabic","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/inseq/divemt_attributions","creator_name":"Inseq","creator_url":"https://huggingface.co/inseq","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for DivEMT Attributions\\n\\t\\n\\nFor more details on DivEMT, see our EMNLP 2022 Paper and our Github repository\\n","first_N":5,"first_N_keywords":["translation","machine-generated","translation","Italian","Arabic"],"keywords_longer_than_N":true},
	{"name":"xstory_cloze","keyword":"arabic","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/juletxara/xstory_cloze","creator_name":"Julen Etxaniz","creator_url":"https://huggingface.co/juletxara","description":"XStoryCloze consists of the professionally translated version of the [English StoryCloze dataset](https://cs.rochester.edu/nlp/rocstories/) (Spring 2016 version) to 10 non-English languages. This dataset is released by Meta AI.","first_N":5,"first_N_keywords":["other","found","found","expert-generated","multilingual"],"keywords_longer_than_N":true},
	{"name":"miracl-ar-corpus-22-12","keyword":"arabic","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Cohere/miracl-ar-corpus-22-12","creator_name":"Cohere","creator_url":"https://huggingface.co/Cohere","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tMIRACL (ar) embedded with cohere.ai multilingual-22-12 encoder\\n\\t\\n\\nWe encoded the MIRACL dataset using the cohere.ai multilingual-22-12 embedding model.\\nThe query embeddings can be found in Cohere/miracl-ar-queries-22-12 and the corpus embeddings can be found in Cohere/miracl-ar-corpus-22-12.\\nFor the orginal datasets, see miracl/miracl and miracl/miracl-corpus.\\nDataset info:\\n\\nMIRACL ðŸŒðŸ™ŒðŸŒ (Multilingual Information Retrieval Across a Continuum of Languages) is a multilingualâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Cohere/miracl-ar-corpus-22-12.","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","expert-generated","multilingual","Arabic"],"keywords_longer_than_N":true},
	{"name":"miracl-ar-queries-22-12","keyword":"arabic","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Cohere/miracl-ar-queries-22-12","creator_name":"Cohere","creator_url":"https://huggingface.co/Cohere","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tMIRACL (ar) embedded with cohere.ai multilingual-22-12 encoder\\n\\t\\n\\nWe encoded the MIRACL dataset using the cohere.ai multilingual-22-12 embedding model.\\nThe query embeddings can be found in Cohere/miracl-ar-queries-22-12 and the corpus embeddings can be found in Cohere/miracl-ar-corpus-22-12.\\nFor the orginal datasets, see miracl/miracl and miracl/miracl-corpus.\\nDataset info:\\n\\nMIRACL ðŸŒðŸ™ŒðŸŒ (Multilingual Information Retrieval Across a Continuum of Languages) is a multilingualâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Cohere/miracl-ar-queries-22-12.","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","expert-generated","multilingual","Arabic"],"keywords_longer_than_N":true},
	{"name":"LoLLMS-Open-Community-discussions","keyword":"arabic","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ParisNeo/LoLLMS-Open-Community-discussions","creator_name":"Saifeddine ALOUI","creator_url":"https://huggingface.co/ParisNeo","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for GPT4All-Community-Discussions\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThis dataset contains ethically gathered discussions from the community, who shared their experiences with various open source discussion models using the GPT4All-ui tool. The dataset is open for any use, including commercial use, as long as proper citation is given to acknowledge the contributions of the community. \\nThe GPT4All-ui tool allows users to have conversations with various open sourceâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/ParisNeo/LoLLMS-Open-Community-discussions.","first_N":5,"first_N_keywords":["English","French","German","Arabic","Italian"],"keywords_longer_than_N":true},
	{"name":"Egyptian_Arabic_Wikipedia_20230101","keyword":"arabic","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/SaiedAlshahrani/Egyptian_Arabic_Wikipedia_20230101","creator_name":"Saied Alshahrani","creator_url":"https://huggingface.co/SaiedAlshahrani","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for \\\"Egyptian_Arabic_Wikipedia_20230101\\\"\\n\\t\\n\\nThis dataset is created using the Egyptian Arabic Wikipedia articles, downloaded on the 1st of January 2023, processed using Gensim Python library, and preprocessed using tr Linux/Unix utility and CAMeLTools Python toolkit for Arabic NLP. This dataset was used to train this Egyptian Arabic Wikipedia Masked Language Model: SaiedAlshahrani/arzwiki_20230101_roberta_mlm.\\nFor more details about the dataset, please read and citeâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/SaiedAlshahrani/Egyptian_Arabic_Wikipedia_20230101.","first_N":5,"first_N_keywords":["Arabic","mit","100K - 1M","parquet","Text"],"keywords_longer_than_N":true},
	{"name":"Arabic_Wikipedia_20230101_nobots","keyword":"arabic","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/SaiedAlshahrani/Arabic_Wikipedia_20230101_nobots","creator_name":"Saied Alshahrani","creator_url":"https://huggingface.co/SaiedAlshahrani","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for \\\"Arabic_Wikipedia_20230101_nobots\\\"\\n\\t\\n\\nThis dataset is created using the Arabic Wikipedia articles (after removing bot-generated articles), downloaded on the 1st of January 2023, processed using Gensim Python library, and preprocessed using tr Linux/Unix utility and CAMeLTools Python toolkit for Arabic NLP. This dataset was used to train this Arabic Wikipedia Masked Language Model: SaiedAlshahrani/arwiki_20230101_roberta_mlm_nobots.\\nFor more details about theâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/SaiedAlshahrani/Arabic_Wikipedia_20230101_nobots.","first_N":5,"first_N_keywords":["Arabic","mit","100K - 1M","parquet","Text"],"keywords_longer_than_N":true},
	{"name":"xOA22","keyword":"arabic","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/sambanovasystems/xOA22","creator_name":"SambaNova Systems","creator_url":"https://huggingface.co/sambanovasystems","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for xOA22 - Multilingual Prompts from OpenAssistant\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nxOA22 consists of 22 prompts originally shown in Appendix E, page 25 of the OpenAssistant Conversations paper. These 22 prompts were then manually translated by volunteers into 5 languages: Arabic, Simplified Chinese, French, Hindi and Spanish. \\nThese prompts were originally created for human evaluations of the multilingual abilities of BLOOMChat. Since not all prompts could beâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/sambanovasystems/xOA22.","first_N":5,"first_N_keywords":["Arabic","Chinese","English","French","Hindi"],"keywords_longer_than_N":true},
	{"name":"x-self-instruct-seed-32","keyword":"arabic","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/sambanovasystems/x-self-instruct-seed-32","creator_name":"SambaNova Systems","creator_url":"https://huggingface.co/sambanovasystems","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for xOA22 - Multilingual Prompts from OpenAssistant\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nx-self-instruct-seed-32 consists of 32 prompts chosen out of the 252 prompts in the self-instruct-seed dataset from the Self-Instruct paper. These 32 prompts were filtered out according to the following criteria:\\n\\nShould be natural in a chat setting\\nTherefore, we filter out any prompts with \\\"few-shot examples\\\", as these are all instruction prompts that we consider unnatural in a chatâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/sambanovasystems/x-self-instruct-seed-32.","first_N":5,"first_N_keywords":["Arabic","Spanish","English","Hindi","French"],"keywords_longer_than_N":true},
	{"name":"semeval-2016-absa-reviews-arabic","keyword":"arabic","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/srinivasbilla/semeval-2016-absa-reviews-arabic","creator_name":"Srinivas Billa","creator_url":"https://huggingface.co/srinivasbilla","description":"\\n\\t\\n\\t\\t\\n\\t\\tDataset Card for Dataset Name\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nAspect based sentiment analysis dataset using hotel reviews in Arabic.\\n\\n\\t\\n\\t\\t\\n\\t\\tLanguages\\n\\t\\n\\nArabic\\n\\n\\t\\n\\t\\t\\n\\t\\tLicensing Information\\n\\t\\n\\nOriginal dataset was licensed under MIT, so this is also under MIT\\n\\n\\t\\n\\t\\t\\n\\t\\tCitation Information\\n\\t\\n\\nCite this and the original authors if you want to.\\n","first_N":5,"first_N_keywords":["text-classification","Arabic","mit","10K - 100K","csv"],"keywords_longer_than_N":true},
	{"name":"Arabic_guanaco_oasst1","keyword":"arabic","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/alielfilali01/Arabic_guanaco_oasst1","creator_name":"Ali El Filali","creator_url":"https://huggingface.co/alielfilali01","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for \\\"Arabic_guanaco_oasst1\\\"\\n\\t\\n\\nThis dataset is the openassistant-guanaco dataset a subset of the Open Assistant dataset translated to Arabic.\\nYou can find the original dataset here: https://huggingface.co/datasets/timdettmers/openassistant-guanaco\\nOr the main dataset here: https://huggingface.co/datasets/OpenAssistant/oasst1/tree/main\\nThis subset of the data only contains the highest-rated paths in the conversation tree, with a total of 9,846 samples.\\nFor furtherâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/alielfilali01/Arabic_guanaco_oasst1.","first_N":5,"first_N_keywords":["Arabic","apache-2.0","10K - 100K","parquet","Text"],"keywords_longer_than_N":true},
	{"name":"REDFM","keyword":"arabic","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Babelscape/REDFM","creator_name":"Babelscape","creator_url":"https://huggingface.co/Babelscape","description":"Relation Extraction (RE) is a task that identifies relationships between entities in a text, enabling the acquisition of relational facts and bridging the gap between natural language and structured knowledge. However, current RE models often rely on small datasets with low coverage of relation types, particularly when working with languages other than English. \\\\In this paper, we address the above issue and provide two new resources that enable the training and evaluation of multilingual RE systems.\\nFirst, we present SRED\\\\textsuperscript{FM}, an automatically annotated dataset covering 18 languages, 400 relation types, 13 entity types, totaling more than 40 million triplet instances. Second, we propose RED\\\\textsuperscript{FM}, a smaller, human-revised dataset for seven languages that allows for the evaluation of multilingual RE systems. \\nTo demonstrate the utility of these novel datasets, we experiment with the first end-to-end multilingual RE model, mREBEL, \\nthat extracts triplets, including entity types, in multiple languages. We release our resources and model checkpoints at \\\\href{https://www.github.com/babelscape/rebel}{https://www.github.com/babelscape/rebel}.","first_N":5,"first_N_keywords":["token-classification","Arabic","German","English","Spanish"],"keywords_longer_than_N":true},
	{"name":"SREDFM","keyword":"arabic","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Babelscape/SREDFM","creator_name":"Babelscape","creator_url":"https://huggingface.co/Babelscape","description":"Relation Extraction (RE) is a task that identifies relationships between entities in a text, enabling the acquisition of relational facts and bridging the gap between natural language and structured knowledge. However, current RE models often rely on small datasets with low coverage of relation types, particularly when working with languages other than English. \\\\In this paper, we address the above issue and provide two new resources that enable the training and evaluation of multilingual RE systems.\\nFirst, we present SRED\\\\textsuperscript{FM}, an automatically annotated dataset covering 18 languages, 400 relation types, 13 entity types, totaling more than 40 million triplet instances. Second, we propose RED\\\\textsuperscript{FM}, a smaller, human-revised dataset for seven languages that allows for the evaluation of multilingual RE systems. \\nTo demonstrate the utility of these novel datasets, we experiment with the first end-to-end multilingual RE model, mREBEL, \\nthat extracts triplets, including entity types, in multiple languages. We release our resources and model checkpoints at \\\\href{https://www.github.com/babelscape/rebel}{https://www.github.com/babelscape/rebel}.","first_N":5,"first_N_keywords":["token-classification","Arabic","Catalan","German","Greek"],"keywords_longer_than_N":true},
	{"name":"flores_101","keyword":"arabic","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/severo/flores_101","creator_name":"Sylvain Lesage","creator_url":"https://huggingface.co/severo","description":"One of the biggest challenges hindering progress in low-resource and multilingual machine translation is the \\nlack of good evaluation benchmarks. Current evaluation benchmarks either lack good coverage of low-resource \\nlanguages, consider only restricted domains, or are low quality because they are constructed using \\nsemi-automatic procedures. In this work, we introduce the FLORES evaluation benchmark, consisting of 3001 \\nsentences extracted from English Wikipedia and covering a variety of different topics and domains. \\nThese sentences have been translated in 101 languages by professional translators through a carefully \\ncontrolled process. The resulting dataset enables better assessment of model quality on the long tail of \\nlow-resource languages, including the evaluation of many-to-many multilingual translation systems, as all \\ntranslations are multilingually aligned. By publicly releasing such a high-quality and high-coverage dataset, \\nwe hope to foster progress in the machine translation community and beyond.","first_N":5,"first_N_keywords":["text-generation","translation","found","expert-generated","multilingual"],"keywords_longer_than_N":true},
	{"name":"test","keyword":"arabic","license":"Boost Software License 1.0","license_url":"https://choosealicense.com/licenses/bsl-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/pengxiang01/test","creator_name":"wang","creator_url":"https://huggingface.co/pengxiang01","description":"aasdfsdf\\n","first_N":5,"first_N_keywords":["tabular-to-text","table-to-text","multiple-choice","text-retrieval","time-series-forecasting"],"keywords_longer_than_N":true},
	{"name":"all-scam-spam","keyword":"arabic","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/FredZhang7/all-scam-spam","creator_name":"Fred Zhang","creator_url":"https://huggingface.co/FredZhang7","description":"This is a large corpus of 42,619 preprocessed text messages and emails sent by humans in 43 languages. is_spam=1 means spam and is_spam=0 means ham.\\n1040 rows of balanced data, consisting of casual conversations and scam emails in â‰ˆ10 languages, were manually collected and annotated by me, with some help from ChatGPT.\\n\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSome preprcoessing algorithms\\n\\t\\n\\n\\nspam_assassin.js, followed by spam_assassin.py\\nenron_spam.py\\n\\n\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData composition\\n\\t\\n\\n\\n\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDescription\\n\\t\\n\\nToâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/FredZhang7/all-scam-spam.","first_N":5,"first_N_keywords":["text-classification","zero-shot-classification","Norwegian","Spanish","Somali"],"keywords_longer_than_N":true},
	{"name":"xP3x-sample","keyword":"arabic","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Muennighoff/xP3x-sample","creator_name":"Niklas Muennighoff","creator_url":"https://huggingface.co/Muennighoff","description":"A multilingual collection of Winograd Schemas in six languages that can be used for evaluation of cross-lingual commonsense reasoning capabilities.","first_N":5,"first_N_keywords":["other","expert-generated","crowdsourced","multilingual","Afrikaans"],"keywords_longer_than_N":true},
	{"name":"xP3x-sample","keyword":"egyptian arabic","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Muennighoff/xP3x-sample","creator_name":"Niklas Muennighoff","creator_url":"https://huggingface.co/Muennighoff","description":"A multilingual collection of Winograd Schemas in six languages that can be used for evaluation of cross-lingual commonsense reasoning capabilities.","first_N":5,"first_N_keywords":["other","expert-generated","crowdsourced","multilingual","Afrikaans"],"keywords_longer_than_N":true},
	{"name":"xP3x-sample","keyword":"levantine arabic","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Muennighoff/xP3x-sample","creator_name":"Niklas Muennighoff","creator_url":"https://huggingface.co/Muennighoff","description":"A multilingual collection of Winograd Schemas in six languages that can be used for evaluation of cross-lingual commonsense reasoning capabilities.","first_N":5,"first_N_keywords":["other","expert-generated","crowdsourced","multilingual","Afrikaans"],"keywords_longer_than_N":true},
	{"name":"xP3x-sample","keyword":"mesopotamian arabic","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Muennighoff/xP3x-sample","creator_name":"Niklas Muennighoff","creator_url":"https://huggingface.co/Muennighoff","description":"A multilingual collection of Winograd Schemas in six languages that can be used for evaluation of cross-lingual commonsense reasoning capabilities.","first_N":5,"first_N_keywords":["other","expert-generated","crowdsourced","multilingual","Afrikaans"],"keywords_longer_than_N":true},
	{"name":"xP3x-sample","keyword":"moroccan arabic","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Muennighoff/xP3x-sample","creator_name":"Niklas Muennighoff","creator_url":"https://huggingface.co/Muennighoff","description":"A multilingual collection of Winograd Schemas in six languages that can be used for evaluation of cross-lingual commonsense reasoning capabilities.","first_N":5,"first_N_keywords":["other","expert-generated","crowdsourced","multilingual","Afrikaans"],"keywords_longer_than_N":true},
	{"name":"xP3x-sample","keyword":"najdi arabic","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Muennighoff/xP3x-sample","creator_name":"Niklas Muennighoff","creator_url":"https://huggingface.co/Muennighoff","description":"A multilingual collection of Winograd Schemas in six languages that can be used for evaluation of cross-lingual commonsense reasoning capabilities.","first_N":5,"first_N_keywords":["other","expert-generated","crowdsourced","multilingual","Afrikaans"],"keywords_longer_than_N":true},
	{"name":"xP3x-sample","keyword":"tunisian arabic","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Muennighoff/xP3x-sample","creator_name":"Niklas Muennighoff","creator_url":"https://huggingface.co/Muennighoff","description":"A multilingual collection of Winograd Schemas in six languages that can be used for evaluation of cross-lingual commonsense reasoning capabilities.","first_N":5,"first_N_keywords":["other","expert-generated","crowdsourced","multilingual","Afrikaans"],"keywords_longer_than_N":true},
	{"name":"xP3x-sample","keyword":"ta'izzi-adeni arabic","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Muennighoff/xP3x-sample","creator_name":"Niklas Muennighoff","creator_url":"https://huggingface.co/Muennighoff","description":"A multilingual collection of Winograd Schemas in six languages that can be used for evaluation of cross-lingual commonsense reasoning capabilities.","first_N":5,"first_N_keywords":["other","expert-generated","crowdsourced","multilingual","Afrikaans"],"keywords_longer_than_N":true},
	{"name":"QA_Arabic","keyword":"arabic","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/HeshamHaroon/QA_Arabic","creator_name":"Hesham Haroon","creator_url":"https://huggingface.co/HeshamHaroon","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tJSON File Description\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tOverview\\n\\t\\n\\nThis JSON file contains a collection of questions and answers in Arabic. Each question is associated with its corresponding answer. The file is structured in a way that allows easy retrieval and utilization of the question-answer pairs.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tFile Structure\\n\\t\\n\\nThe JSON file follows the following structure:\\n{\\n  \\\"questions\\\": [\\n    {\\n      \\\"question\\\": \\\"Ù…Ù† Ù‡Ùˆ Ø£ÙˆÙ„ Ù…Ù† Ù†Ø²Ù„ Ø¹Ù„Ù‰ Ø³Ø·Ø­ Ø§Ù„Ù‚Ù…Ø±ØŸ\\\",\\n      \\\"answer\\\": \\\"Ù†ÙŠÙ„ Ø£Ù…Ø³ØªØ±ÙˆÙ†Ø¬\\\"\\n    },\\n    {â€¦ See the full description on the dataset page: https://huggingface.co/datasets/HeshamHaroon/QA_Arabic.","first_N":5,"first_N_keywords":["question-answering","text-generation","text2text-generation","Arabic","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"Arabic_Quotes","keyword":"arabic","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/AhmedBou/Arabic_Quotes","creator_name":"Ahmed Khalil Boulahia","creator_url":"https://huggingface.co/AhmedBou","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tArabic Quotes Dataset\\n\\t\\n\\n\\n\\n\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tOverview\\n\\t\\n\\nThe Arabic Quotes Dataset is an open-source collection of 5900+ quotes in the Arabic language, accompanied by up to three tags for each quote. \\nThe dataset is suitable for various Natural Language Processing (NLP) tasks, such as text classification and tagging.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Description\\n\\t\\n\\n\\nContains 5900+ quotes with up to three associated tags per quote.\\nAll quotes and tags are in Arabic.\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tUse Cases\\n\\t\\n\\n\\nTextâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/AhmedBou/Arabic_Quotes.","first_N":5,"first_N_keywords":["text-classification","text-generation","Arabic","apache-2.0","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"Arabic_fake_news_dataset","keyword":"arabic","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/HeshamHaroon/Arabic_fake_news_dataset","creator_name":"Hesham Haroon","creator_url":"https://huggingface.co/HeshamHaroon","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tArabic_fake_news_dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tPlease note that this dataset needs more preprocessing.\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tIntroduction\\n\\t\\n\\nThis repository contains the Arabic_fake_news_dataset, a collection of news articles scraped from the Egyptian platform Ù…ØªØµØ¯Ù‚Ø´ (Matsda2sh). The dataset is intended for studying and addressing the spread of fake news within the Egyptian community. It includes news articles classified as either fake or true, along with their corresponding titles.â€¦ See the full description on the dataset page: https://huggingface.co/datasets/HeshamHaroon/Arabic_fake_news_dataset.","first_N":5,"first_N_keywords":["text-classification","Arabic","apache-2.0","1K - 10K","json"],"keywords_longer_than_N":true},
	{"name":"Arabic_fake_news_dataset","keyword":"arabic","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/HeshamHaroon/Arabic_fake_news_dataset","creator_name":"Hesham Haroon","creator_url":"https://huggingface.co/HeshamHaroon","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tArabic_fake_news_dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tPlease note that this dataset needs more preprocessing.\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tIntroduction\\n\\t\\n\\nThis repository contains the Arabic_fake_news_dataset, a collection of news articles scraped from the Egyptian platform Ù…ØªØµØ¯Ù‚Ø´ (Matsda2sh). The dataset is intended for studying and addressing the spread of fake news within the Egyptian community. It includes news articles classified as either fake or true, along with their corresponding titles.â€¦ See the full description on the dataset page: https://huggingface.co/datasets/HeshamHaroon/Arabic_fake_news_dataset.","first_N":5,"first_N_keywords":["text-classification","Arabic","apache-2.0","1K - 10K","json"],"keywords_longer_than_N":true},
	{"name":"artelingo-dummy","keyword":"arabic","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/youssef101/artelingo-dummy","creator_name":"mohamed","creator_url":"https://huggingface.co/youssef101","description":"ArtELingo is a benchmark and dataset introduced in a research paper aimed at promoting work on diversity across languages and cultures. It is an extension of ArtEmis, which is a collection of 80,000 artworks from WikiArt with 450,000 emotion labels and English-only captions. ArtELingo expands this dataset by adding 790,000 annotations in Arabic and Chinese. The purpose of these additional annotations is to evaluate the performance of \\\"cultural-transfer\\\" in AI systems.\\nThe dataset in ArtELingoâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/youssef101/artelingo-dummy.","first_N":5,"first_N_keywords":["image-to-text","text-classification","image-classification","text-to-image","text-generation"],"keywords_longer_than_N":true},
	{"name":"MMLU_Arabic","keyword":"arabic","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/FreedomIntelligence/MMLU_Arabic","creator_name":"FreedomAI","creator_url":"https://huggingface.co/FreedomIntelligence","description":"Arabic version of MMLU dataset translated by gpt-3.5-turbo.The dataset is used in the research related to MultilingualSIFT. \\n","first_N":5,"first_N_keywords":["Arabic","mit","ðŸ‡ºðŸ‡¸ Region: US"],"keywords_longer_than_N":false},
	{"name":"Ten2Zero","keyword":"arabic","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/gfbati/Ten2Zero","creator_name":"Ghassan F. Bati","creator_url":"https://huggingface.co/gfbati","description":"This dataset contains the following:\\n1- A balanced audio dataset of spoken Arabic digits from ten to zero in wav form (located at the \\\"Dataset\\\" folder);\\n2- A balanced image dataset of spoken Arabic digits from ten to zero in png form (located at the \\\"Dataset\\\" folder);\\n3- Tabular data generated using deep learning (SqueezeNet and Inception v3) from the spectrograms of the audio files; \\n4- Orange Data Mining workflows (\\\".ows\\\" files) used in processing this dataset.\\nPlease cite the followingâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/gfbati/Ten2Zero.","first_N":5,"first_N_keywords":["audio-classification","image-classification","tabular-classification","Arabic","English"],"keywords_longer_than_N":true},
	{"name":"QAmeleon","keyword":"arabic","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/imvladikon/QAmeleon","creator_name":"Vladimir Gurevich","creator_url":"https://huggingface.co/imvladikon","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for \\\"QAmeleon\\\"\\n\\t\\n\\nQAmeleon introduces synthetic multilingual QA data contaning in 8 langauges using PaLM-540B, a large language model. This dataset was generated by prompt tuning PaLM with only five examples per language. We use the synthetic data to finetune downstream QA models leading to improved accuracy in comparison to English-only and translation-based baselines. \\nData available at https://storage.googleapis.com/qameleon/qamelon_pt_accepted.csv \\nMore details canâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/imvladikon/QAmeleon.","first_N":5,"first_N_keywords":["question-answering","Arabic","Bengali","Finnish","Indonesian"],"keywords_longer_than_N":true},
	{"name":"Gulf-Arabic-Tweets-2018-2020","keyword":"arabic","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/AhmedSSabir/Gulf-Arabic-Tweets-2018-2020","creator_name":"Ahmed Sabir","creator_url":"https://huggingface.co/AhmedSSabir","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThis is a pre-processed (cleaned) Twitter Gulf Arabic dialect 2018-2020 dataset. Pleasre refer to the  source, and data cleaning code and algorithm Github.\\n\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages\\n\\t\\n\\nArabic\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSource Data\\n\\t\\n\\nTwitter\\n","first_N":5,"first_N_keywords":["text-classification","Arabic","cc-by-4.0","100K - 1M","csv"],"keywords_longer_than_N":true},
	{"name":"qa_en_translation","keyword":"arabic","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Sylvana/qa_en_translation","creator_name":"Silvana","creator_url":"https://huggingface.co/Sylvana","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Dataset Name\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThis dataset card aims to be a base template for new datasets. It has been generated using this raw template.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSupported Tasks and Leaderboards\\n\\t\\n\\n[More Information Needed]\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages\\n\\t\\n\\n[More Information Needed]\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Structure\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Instances\\n\\t\\n\\n[More Information Needed]\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Fields\\n\\t\\n\\n[More Information Needed]\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Splits\\n\\t\\n\\n[More Informationâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Sylvana/qa_en_translation.","first_N":5,"first_N_keywords":["translation","Arabic","apache-2.0","1K - 10K","csv"],"keywords_longer_than_N":true},
	{"name":"Moroccan_Arabic_Wikipedia_20230101_bots","keyword":"arabic","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/SaiedAlshahrani/Moroccan_Arabic_Wikipedia_20230101_bots","creator_name":"Saied Alshahrani","creator_url":"https://huggingface.co/SaiedAlshahrani","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for \\\"Moroccan_Arabic_Wikipedia_20230101_bots\\\"\\n\\t\\n\\nThis dataset is created using the Moroccan Arabic Wikipedia articles, downloaded on the 1st of January 2023, processed using Gensim Python library, and preprocessed using tr Linux/Unix utility and CAMeLTools Python toolkit for Arabic NLP. This dataset was used to train this Moroccan Arabic Wikipedia Masked Language Model: SaiedAlshahrani/arywiki_20230101_roberta_mlm_bots.\\nFor more details about the dataset, please readâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/SaiedAlshahrani/Moroccan_Arabic_Wikipedia_20230101_bots.","first_N":5,"first_N_keywords":["Arabic","mit","1K - 10K","parquet","Text"],"keywords_longer_than_N":true},
	{"name":"Arabic_Wikipedia_20230101_bots","keyword":"arabic","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/SaiedAlshahrani/Arabic_Wikipedia_20230101_bots","creator_name":"Saied Alshahrani","creator_url":"https://huggingface.co/SaiedAlshahrani","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for \\\"Arabic_Wikipedia_20230101_bots\\\"\\n\\t\\n\\nThis dataset is created using the Arabic Wikipedia articles, downloaded on the 1st of January 2023, processed using Gensim Python library, and preprocessed using tr Linux/Unix utility and CAMeLTools Python toolkit for Arabic NLP. This dataset was used to train this Arabic Wikipedia Masked Language Model: SaiedAlshahrani/arwiki_20230101_roberta_mlm_bots.\\nFor more details about the dataset, please read and cite our paper:â€¦ See the full description on the dataset page: https://huggingface.co/datasets/SaiedAlshahrani/Arabic_Wikipedia_20230101_bots.","first_N":5,"first_N_keywords":["Arabic","mit","1M - 10M","parquet","Text"],"keywords_longer_than_N":true},
	{"name":"wikianc","keyword":"arabic","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/cyanic-selkie/wikianc","creator_name":"cyanic-selkie","creator_url":"https://huggingface.co/cyanic-selkie","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for WikiAnc\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThe WikiAnc dataset is an automatically generated dataset from Wikipedia (all languages) and Wikidata dumps (August, 2023). \\nThe code for generating the dataset can be found here.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSupported Tasks\\n\\t\\n\\n\\nwikificiation: The dataset can be used to train a model for Wikification.\\nnamed-entity-linking: The dataset can be used to train a model for Named Entity Linking.\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages\\n\\t\\n\\nThe text in the dataset isâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/cyanic-selkie/wikianc.","first_N":5,"first_N_keywords":["token-classification","machine-generated","crowdsourced","machine-generated","crowdsourced"],"keywords_longer_than_N":true},
	{"name":"wikianc","keyword":"egyptian arabic","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/cyanic-selkie/wikianc","creator_name":"cyanic-selkie","creator_url":"https://huggingface.co/cyanic-selkie","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for WikiAnc\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThe WikiAnc dataset is an automatically generated dataset from Wikipedia (all languages) and Wikidata dumps (August, 2023). \\nThe code for generating the dataset can be found here.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSupported Tasks\\n\\t\\n\\n\\nwikificiation: The dataset can be used to train a model for Wikification.\\nnamed-entity-linking: The dataset can be used to train a model for Named Entity Linking.\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages\\n\\t\\n\\nThe text in the dataset isâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/cyanic-selkie/wikianc.","first_N":5,"first_N_keywords":["token-classification","machine-generated","crowdsourced","machine-generated","crowdsourced"],"keywords_longer_than_N":true},
	{"name":"wikianc","keyword":"moroccan arabic","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/cyanic-selkie/wikianc","creator_name":"cyanic-selkie","creator_url":"https://huggingface.co/cyanic-selkie","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for WikiAnc\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThe WikiAnc dataset is an automatically generated dataset from Wikipedia (all languages) and Wikidata dumps (August, 2023). \\nThe code for generating the dataset can be found here.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSupported Tasks\\n\\t\\n\\n\\nwikificiation: The dataset can be used to train a model for Wikification.\\nnamed-entity-linking: The dataset can be used to train a model for Named Entity Linking.\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages\\n\\t\\n\\nThe text in the dataset isâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/cyanic-selkie/wikianc.","first_N":5,"first_N_keywords":["token-classification","machine-generated","crowdsourced","machine-generated","crowdsourced"],"keywords_longer_than_N":true},
	{"name":"Evol-Instruct-Arabic-GPT4","keyword":"arabic","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/FreedomIntelligence/Evol-Instruct-Arabic-GPT4","creator_name":"FreedomAI","creator_url":"https://huggingface.co/FreedomIntelligence","description":"The dataset is created by \\n\\ntranslating English questions of Evol-instruct-70k into Arabic using GPT4, and\\nrequesting GPT4 to generate responses in Arabic.\\n\\nFor more details, please refer to:\\n\\nRepository: \\nhttps://github.com/FreedomIntelligence/AceGPT\\nhttps://github.com/FreedomIntelligence/LLMZoo\\n\\n\\nPaper: \\nAceGPT, Localizing Large Language Models in Arabic\\nPhoenix: Democratizing ChatGPT across Languages\\n\\n\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tBibTeX entry and citation info\\n\\t\\n\\n@article{huang2023acegpt,\\n  title={AceGPTâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/FreedomIntelligence/Evol-Instruct-Arabic-GPT4.","first_N":5,"first_N_keywords":["text2text-generation","text-generation","Arabic","apache-2.0","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"entity_cs","keyword":"arabic","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/huawei-noah/entity_cs","creator_name":"HUAWEI Noah's Ark Lab","creator_url":"https://huggingface.co/huawei-noah","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for EntityCS\\n\\t\\n\\n\\nRepository: https://github.com/huawei-noah/noah-research/tree/master/NLP/EntityCS  \\nPaper: https://aclanthology.org/2022.findings-emnlp.499.pdf  \\nPoint of Contact: Fenia Christopoulou, Chenxi Whitehouse\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nWe use the English Wikipedia and leverage entity information from Wikidata to construct an entity-based Code Switching corpus. \\nTo achieve this, we make use of wikilinks in Wikipedia, i.e. links from one page toâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/huawei-noah/entity_cs.","first_N":5,"first_N_keywords":["Afrikaans","Amharic","Arabic","Assamese","Azerbaijani"],"keywords_longer_than_N":true},
	{"name":"KIND","keyword":"arabic","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/KIND-Dataset/KIND","creator_name":"KIND","creator_url":"https://huggingface.co/KIND-Dataset","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nKIND dataset is a new dilectal data dataset.\\nThe dataset was a result of a data marathon competition, where the competitor's goal is to respond to as many prompts as possible in their own dialect, within a fixed time frame with as few errors as possible.\\nFor more details, please check the paper\\nThe KIND Dataset: A Social Collaboration Approach for Nuanced Dialect Data Collection\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Fields\\n\\t\\n\\n\\ndialect_code: the label that indicates the specificâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/KIND-Dataset/KIND.","first_N":5,"first_N_keywords":["question-answering","Arabic","cc-by-4.0","10K<n<100K","ðŸ‡ºðŸ‡¸ Region: US"],"keywords_longer_than_N":false},
	{"name":"Goud-Sum-Instruct","keyword":"arabic","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/alielfilali01/Goud-Sum-Instruct","creator_name":"Ali El Filali","creator_url":"https://huggingface.co/alielfilali01","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Goud-Sum-Instruct\\n\\t\\n\\nGoud-Sum-Instruct is a meticulously curated dataset originating from Goud-sum dataset, This dataset is primed for fine-tuning chat and instruct models, without any compromise to the existing training mode. This strategic approach enables the specific training of models to respond effectively to the main instruction which is \\\"To Summarise\\\". In conclusion, this dataset is meant to finetune a chat model in order to serve later as a summarizer.â€¦ See the full description on the dataset page: https://huggingface.co/datasets/alielfilali01/Goud-Sum-Instruct.","first_N":5,"first_N_keywords":["summarization","Arabic","apache-2.0","100K - 1M","parquet"],"keywords_longer_than_N":true},
	{"name":"text_coordinates_seasons","keyword":"arabic","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/yachay/text_coordinates_seasons","creator_name":"Yachay AI","creator_url":"https://huggingface.co/yachay","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Geo-Tagged Social Media Posts with Timestamps\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThe \\\"Seasons\\\" dataset is a collection of over 600,000 social media posts spanning 12 months and encompassing 15 distinct time zones. It focuses on six countries: Cuba, Iran, Russia, North Korea, Syria, and Venezuela, with each post containing textual content, timestamps, and geographical coordinates. The dataset's primary objective is to investigate the correlation between the timing ofâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/yachay/text_coordinates_seasons.","first_N":5,"first_N_keywords":["feature-extraction","token-classification","text-classification","English","Spanish"],"keywords_longer_than_N":true},
	{"name":"text_coordinates_regions","keyword":"arabic","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/yachay/text_coordinates_regions","creator_name":"Yachay AI","creator_url":"https://huggingface.co/yachay","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Multilingual Geo-Tagged Social Media Posts (by 123 world regions)\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThe \\\"Regions\\\" dataset is a multilingual corpus that encompasses textual data from the 123 most populated regions worldwide, with each region's data organized into separate .json files. This dataset consists of approximately 500,000 text samples, each paired with its geographic coordinates.\\nKey Features:\\n\\nTextual Data: The dataset contains 500,000 text samples.â€¦ See the full description on the dataset page: https://huggingface.co/datasets/yachay/text_coordinates_regions.","first_N":5,"first_N_keywords":["feature-extraction","token-classification","text-classification","English","Chinese"],"keywords_longer_than_N":true},
	{"name":"MaWPS-ar-addCN","keyword":"arabic","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/aelneima/MaWPS-ar-addCN","creator_name":"ashraf hatim","creator_url":"https://huggingface.co/aelneima","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for MAWPS_ar\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nMAWPS: A Math Word Problem Repository\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSupported Tasks\\n\\t\\n\\nMath Word Problem Solving\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages\\n\\t\\n\\nSupports Arabic and English\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Structure\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Fields\\n\\t\\n\\n\\ntext_en: a string feature.\\ntext_ar: a string feature.\\neqn: a string feature.\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Splits\\n\\t\\n\\n\\n\\t\\n\\t\\t\\ntrain\\nvalidation\\ntest\\n\\n\\n\\t\\t\\n3636\\n1040\\n520\\n\\n\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDatasetâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/aelneima/MaWPS-ar-addCN.","first_N":5,"first_N_keywords":["text2text-generation","explanation-generation","crowdsourced","found","multilingual"],"keywords_longer_than_N":true},
	{"name":"EXAMs","keyword":"arabic","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/FreedomIntelligence/EXAMs","creator_name":"FreedomAI","creator_url":"https://huggingface.co/FreedomIntelligence","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tEXAMs\\n\\t\\n\\nYou can find details of the dataset in this post:https://arxiv.org/pdf/2308.16149.pdf\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tAbout this Arabic dataset\\n\\t\\n\\nWe only took the Arabic part of the dataset,which contains 562 data.We then extracted five from each category based on the task domain as a few shot data.\\n","first_N":5,"first_N_keywords":["multiple-choice","Arabic","apache-2.0","n<1K","arxiv:2308.16149"],"keywords_longer_than_N":true},
	{"name":"AjwaOrMedjool","keyword":"arabic","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/gfbati/AjwaOrMedjool","creator_name":"Ghassan F. Bati","creator_url":"https://huggingface.co/gfbati","description":"The dataset contains three subsets:\\n\\na dataset containing hand-crafted features to classify two types of organic dates (Ajwa or Medjool);\\na dataset containing tabular data with features created automatically using deep learning to classify the two organic date types (Ajwa or Medjool);\\na dataset for images of Ajwa and Medjool.\\nThis study is considered as the first work in Arabic using shallow machine learning and deep learning to create accurate models for classifying organic Saudi dates, whichâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/gfbati/AjwaOrMedjool.","first_N":5,"first_N_keywords":["image-classification","tabular-classification","Arabic","English","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"ACVA-Arabic-Cultural-Value-Alignment","keyword":"arabic","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/FreedomIntelligence/ACVA-Arabic-Cultural-Value-Alignment","creator_name":"FreedomAI","creator_url":"https://huggingface.co/FreedomIntelligence","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tAbout ArabicCulture\\n\\t\\n\\nThe ArabicCulture dataset was generated by gpt3.5 and contains 8000+ True and False questions.The dataset contains questions from 58 different areas.In the answers, \\\"True\\\" accounted for 59.62%, and \\\"False\\\" accounted for 40.38%\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tdata-all\\n\\t\\n\\nIt contains 8000+ data, and we took 5 data from each area as few-shot data.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tdata-select\\n\\t\\n\\nWe asked two Arabs to judge 4000 of all the data for us, and we left data that two Arabs both thought wereâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/FreedomIntelligence/ACVA-Arabic-Cultural-Value-Alignment.","first_N":5,"first_N_keywords":["Arabic","apache-2.0","1K - 10K","json","Text"],"keywords_longer_than_N":true},
	{"name":"openassistant-guanaco-EOS","keyword":"arabic","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Trelis/openassistant-guanaco-EOS","creator_name":"Trelis","creator_url":"https://huggingface.co/Trelis","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tChat Fine-tuning Dataset - Guanaco Style\\n\\t\\n\\nThis dataset allows for fine-tuning chat models using \\\"### Human:\\\" AND \\\"### Assistant\\\" as the beginning and end of sequence tokens.\\nPreparation:\\n\\nThe dataset is cloned from TimDettmers, which itself is a subset of the Open Assistant dataset, which you can find here. This subset of the data only contains the highest-rated paths in the conversation tree, with a total of 9,846 samples.\\nThe dataset was then slightly adjusted to:\\n\\n\\nif a row ofâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Trelis/openassistant-guanaco-EOS.","first_N":5,"first_N_keywords":["English","Spanish","Russian","German","Polish"],"keywords_longer_than_N":true},
	{"name":"openassistant-llama-style","keyword":"arabic","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Trelis/openassistant-llama-style","creator_name":"Trelis","creator_url":"https://huggingface.co/Trelis","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tChat Fine-tuning Dataset - Llama 2 Style\\n\\t\\n\\nThis dataset allows for fine-tuning chat models using [INST] AND [/INST] to wrap user messages.\\nPreparation:\\n\\nThe dataset is cloned from TimDettmers, which itself is a subset of the Open Assistant dataset, which you can find here. This subset of the data only contains the highest-rated paths in the conversation tree, with a total of 9,846 samples.\\nThe dataset was then filtered to:\\n\\n\\nreplace instances of '### Human:' with '[INST]'\\nreplaceâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Trelis/openassistant-llama-style.","first_N":5,"first_N_keywords":["English","Spanish","Russian","German","Polish"],"keywords_longer_than_N":true},
	{"name":"sl-dataset","keyword":"arabic","license":"Academic Free License v3.0","license_url":"https://choosealicense.com/licenses/afl-3.0/","language":"en","dataset_url":"https://huggingface.co/datasets/lafnac/sl-dataset","creator_name":"lafnac","creator_url":"https://huggingface.co/lafnac","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Dataset Name\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThis dataset card aims to be a base template for new datasets. It has been generated using this raw template.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSupported Tasks and Leaderboards\\n\\t\\n\\n[More Information Needed]\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages\\n\\t\\n\\n[More Information Needed]\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Structure\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Instances\\n\\t\\n\\n[More Information Needed]\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Fields\\n\\t\\n\\n[More Information Needed]\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Splits\\n\\t\\n\\n[More Informationâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/lafnac/sl-dataset.","first_N":5,"first_N_keywords":["text-classification","Arabic","afl-3.0","< 1K","imagefolder"],"keywords_longer_than_N":true},
	{"name":"MultiJail","keyword":"arabic","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/DAMO-NLP-SG/MultiJail","creator_name":"Language Technology Lab at Alibaba DAMO Academy","creator_url":"https://huggingface.co/DAMO-NLP-SG","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tMultilingual Jailbreak Challenges in Large Language Models\\n\\t\\n\\nThis repo contains the data for our paper \\\"Multilingual Jailbreak Challenges in Large Language Models\\\".\\n[Github repo]\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tAnnotation Statistics\\n\\t\\n\\nWe collected a total of 315 English unsafe prompts and annotated them into nine non-English languages. The languages were categorized based on resource availability, as shown below:\\nHigh-resource languages: Chinese (zh), Italian (it), Vietnamese (vi)\\nMedium-resourceâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/DAMO-NLP-SG/MultiJail.","first_N":5,"first_N_keywords":["English","Chinese","Italian","Vietnamese","Arabic"],"keywords_longer_than_N":true},
	{"name":"mqnli","keyword":"arabic","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/SachinPatel248/mqnli","creator_name":"Patel","creator_url":"https://huggingface.co/SachinPatel248","description":"SachinPatel248/mqnli dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["text-classification","English","German","Spanish","Arabic"],"keywords_longer_than_N":true},
	{"name":"udhr-lid","keyword":"standard arabic","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/cis-lmu/udhr-lid","creator_name":"CIS, LMU Munich","creator_url":"https://huggingface.co/cis-lmu","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tUDHR-LID\\n\\t\\n\\nWhy UDHR-LID?\\nYou can access UDHR (Universal Declaration of Human Rights) here, but when a verse is missing, they have texts such as \\\"missing\\\" or \\\"?\\\". Also, about 1/3 of the sentences consist only of \\\"articles 1-30\\\" in different languages. We cleaned the entire dataset from XML files and selected only the paragraphs. We cleared any unrelated language texts from the data and also removed the cases that were incorrect.\\nIncorrect? Look at the ckb and kmr files in the UDHR.â€¦ See the full description on the dataset page: https://huggingface.co/datasets/cis-lmu/udhr-lid.","first_N":5,"first_N_keywords":["multilingual","Tigrinya","Balkan Romani","Standard Arabic","MetlatÃ³noc Mixtec"],"keywords_longer_than_N":true},
	{"name":"seamless-align","keyword":"arabic","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/jhu-clsp/seamless-align","creator_name":"Center for Language and Speech Processing @ JHU","creator_url":"https://huggingface.co/jhu-clsp","description":"\\n\\t\\n\\t\\t\\n\\t\\tDataset Card for Seamless-Align (WIP). Inspired by https://huggingface.co/datasets/allenai/nllb\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThis dataset was created based on metadata for mined Speech-to-Speech(S2S), Text-to-Speech(TTS) and Speech-to-Text(S2T) released by Meta AI.  The S2S contains data for 35 language pairs. The S2S dataset is ~1000GB compressed.\\n\\n\\t\\n\\t\\t\\n\\t\\tHow to use the data\\n\\t\\n\\nThere are two ways to access the data:\\n\\nVia the Hugging Face Python datasets library\\n\\nScripts coming soonâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/jhu-clsp/seamless-align.","first_N":5,"first_N_keywords":["translation","audio-to-audio","Maltese","English","Welsh"],"keywords_longer_than_N":true},
	{"name":"WEATHub","keyword":"arabic","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/iamshnoo/WEATHub","creator_name":"Anjishnu Mukherjee","creator_url":"https://huggingface.co/iamshnoo","description":"\\n\\n\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for \\\"WEATHub\\\"\\n\\t\\n\\nThis dataset corresponds to the data described in the paper \\\"Global Voices, Local Biases: Socio-Cultural Prejudices across Languages\\\"\\naccepted to EMNLP 2023.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nWEATHub is a dataset containing 24 languages. It contains words organized into groups of (target1, target2, attribute1, attribute2)\\nto measure the association target1:target2 :: attribute1:attribute2. For example target1 can be insects, target2 can be flowers.â€¦ See the full description on the dataset page: https://huggingface.co/datasets/iamshnoo/WEATHub.","first_N":5,"first_N_keywords":["Arabic","Bengali","Central Kurdish","Danish","German"],"keywords_longer_than_N":true},
	{"name":"ASAD","keyword":"arabic","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/SaiedAlshahrani/ASAD","creator_name":"Saied Alshahrani","creator_url":"https://huggingface.co/SaiedAlshahrani","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for \\\"Arab States Analogy Dataset (ASAD)\\\"\\n\\t\\n\\nThis dataset is created using 20 Arab States1 with their corresponding capital cities, nationalities, currencies, and on which continents they are located, consisting of four sets: country-capital set, country-currency set, country-nationality set, and country-continent set. Each set has 380 word analogies, and the total number of word analogies in the ASAD dataset is 1520. This dataset is used to evaluate Arabic Wordâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/SaiedAlshahrani/ASAD.","first_N":5,"first_N_keywords":["Arabic","mit","1K - 10K","csv","Text"],"keywords_longer_than_N":true},
	{"name":"MASD","keyword":"arabic","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/SaiedAlshahrani/MASD","creator_name":"Saied Alshahrani","creator_url":"https://huggingface.co/SaiedAlshahrani","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for \\\"Masked Arab States Dataset (MASD)\\\"\\n\\t\\n\\nThis dataset is created using 20 Arab States1 with their corresponding capital cities, nationalities, currencies, and on which continents they are located, consisting of four categories: country-capital\\nprompts, country-currency prompts, country-nationality prompts, and country-continent prompts. Each prompts category has 40 masked prompts, and the total number of masked prompts in the MASD dataset is 160. This dataset is usedâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/SaiedAlshahrani/MASD.","first_N":5,"first_N_keywords":["Arabic","mit","< 1K","csv","Text"],"keywords_longer_than_N":true},
	{"name":"financial_news","keyword":"arabic","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/asas-ai/financial_news","creator_name":"ASAS AI","creator_url":"https://huggingface.co/asas-ai","description":"asas-ai/financial_news dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["translation","Arabic","English","apache-2.0","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"openassistant-falcon","keyword":"arabic","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Trelis/openassistant-falcon","creator_name":"Trelis","creator_url":"https://huggingface.co/Trelis","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tChat Fine-tuning Dataset - OpenAssistant Falcon\\n\\t\\n\\nThis dataset allows for fine-tuning chat models using '\\\\Human:' AND '\\\\nAssistant:' to wrap user messages.\\nIt still uses <|endoftext|> as EOS and BOS token, as per Falcon.\\nSample \\nPreparation:\\n\\nThe dataset is cloned from TimDettmers, which itself is a subset of the Open Assistant dataset, which you can find here. This subset of the data only contains the highest-rated paths in the conversation tree, with a total of 9,846 samples.â€¦ See the full description on the dataset page: https://huggingface.co/datasets/Trelis/openassistant-falcon.","first_N":5,"first_N_keywords":["English","Spanish","Russian","German","Polish"],"keywords_longer_than_N":true},
	{"name":"megawika-report-generation","keyword":"arabic","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/hltcoe/megawika-report-generation","creator_name":"JHU Human Language Technology Center of Excellence","creator_url":"https://huggingface.co/hltcoe","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for MegaWika for Report Generation\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nMegaWika is a multi- and crosslingual text dataset containing 30 million Wikipedia passages with their scraped and cleaned web citations. The passages span\\n50 Wikipedias in 50 languages, and the articles in which the passages were originally embedded are included for convenience. Where a Wikipedia passage is in a\\nnon-English language, an automated English translation is provided. \\nThis datasetâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/hltcoe/megawika-report-generation.","first_N":5,"first_N_keywords":["summarization","text-retrieval","text-generation","text2text-generation","Afrikaans"],"keywords_longer_than_N":true},
	{"name":"DarijaBridge","keyword":"arabic","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/M-A-D/DarijaBridge","creator_name":"Mixed Arabic Datasets","creator_url":"https://huggingface.co/M-A-D","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDarijaBridge Dataset Card\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tGeneral Information\\n\\t\\n\\n\\nDataset Name: DarijaBridge\\nVersion: 1.0\\nCreator: MAD-Community\\nLanguage: Darija (Moroccan Arabic) and English\\nTotal Tokens: 41,845,467 (in 'sentence' column)\\nTask: Machine Translation\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nDarijaBridge is a community-driven bilingual corpus designed for machine translation tasks between Darija (Moroccan Arabic) and English. Created by MAD-Community, it encompasses a wide range of theâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/M-A-D/DarijaBridge.","first_N":5,"first_N_keywords":["translation","Arabic","English","apache-2.0","1M - 10M"],"keywords_longer_than_N":true},
	{"name":"Pontoon-Translations","keyword":"arabic","license":"Mozilla Public License 2.0","license_url":"https://choosealicense.com/licenses/mpl-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ayymen/Pontoon-Translations","creator_name":"Mohamed Aymane Farhi","creator_url":"https://huggingface.co/ayymen","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Pontoon Translations\\n\\t\\n\\n\\n\\nThis is a dataset containing strings from various Mozilla projects on Mozilla's Pontoon localization platform and their translations into more than 200 languages.\\nSource strings are in English.\\nTo avoid rows with values like \\\"None\\\" and \\\"N/A\\\" being interpreted as missing values, pass the keep_default_na parameter like this:\\nfrom datasets import load_dataset\\n\\ndataset = load_dataset(\\\"ayymen/Pontoon-Translations\\\", keep_default_na=False)â€¦ See the full description on the dataset page: https://huggingface.co/datasets/ayymen/Pontoon-Translations.","first_N":5,"first_N_keywords":["translation","text2text-generation","crowdsourced","Abkhaz","Achinese"],"keywords_longer_than_N":true},
	{"name":"arabic_alpaca_model","keyword":"arabic","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ISTNetworks/arabic_alpaca_model","creator_name":"RAD team","creator_url":"https://huggingface.co/ISTNetworks","description":"ISTNetworks/arabic_alpaca_model dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["question-answering","Arabic","apache-2.0","1K - 10K","json"],"keywords_longer_than_N":true},
	{"name":"SemEval2024-STR","keyword":"arabic","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/kietnt0603/SemEval2024-STR","creator_name":"Nguyá»…n Tuáº¥n Kiá»‡t","creator_url":"https://huggingface.co/kietnt0603","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Dataset Name\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Details\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\n\\nEach instance in the training, development, and test sets is a sentence pair. The instance is labeled with a score representing the degree of semantic textual relatedness between the two sentences. The scores can range from 0 (maximally unrelated) to 1 (maximally related). These gold label scores have been determined through manual annotation. Specifically, a comparative annotationâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/kietnt0603/SemEval2024-STR.","first_N":5,"first_N_keywords":["Amharic","Hausa","English","Spanish","Telugu"],"keywords_longer_than_N":true},
	{"name":"ntx_llm_instructions","keyword":"arabic","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/tellarin-ai/ntx_llm_instructions","creator_name":"Tellarin.ai","creator_url":"https://huggingface.co/tellarin-ai","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for NTX v1 in the Aya format\\n\\t\\n\\nThis dataset is a format conversion from its original v1 format into the Aya instruction format and it's released here under the CC-BY-SA 4.0 license and conditions.\\nIt contains data in multiple languages and this version is intended for multi-lingual LLM construction/tuning.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tCitation\\n\\t\\n\\nIf you utilize this dataset version, feel free to cite/footnote this huggingface dataset repo, but please also cite the original datasetâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/tellarin-ai/ntx_llm_instructions.","first_N":5,"first_N_keywords":["token-classification","Arabic","German","English","Spanish"],"keywords_longer_than_N":true},
	{"name":"ntx_llm_inst_arabic","keyword":"arabic","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/tellarin-ai/ntx_llm_inst_arabic","creator_name":"Tellarin.ai","creator_url":"https://huggingface.co/tellarin-ai","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for NTX v1 in the Aya format - Arabic subset\\n\\t\\n\\nThis dataset is a format conversion for the Arabic data from the original NTX into the Aya instruction format and it's released here under the CC-BY-SA 4.0 license.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Details\\n\\t\\n\\nFor the original NTX dataset, the conversion to the Aya instructions format, or more details, please refer to the full dataset in instruction form (https://huggingface.co/datasets/tellarin-ai/ntx_llm_instructions) or to the paperâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/tellarin-ai/ntx_llm_inst_arabic.","first_N":5,"first_N_keywords":["token-classification","Arabic","cc-by-sa-4.0","< 1K","json"],"keywords_longer_than_N":true},
	{"name":"ml-kge","keyword":"arabic","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/davanstrien/ml-kge","creator_name":"Daniel van Strien","creator_url":"https://huggingface.co/davanstrien","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tMKGE: Multilingual Knowledge Graph Enhancement\\n\\t\\n\\nnote this dataset card was copied from this GitHub Repository\\nTask Description |\\nWikiKGE-10 |\\nEvaluation |\\nPaper |\\nCitation |\\nLicense\\nRecent work in Natural Language Processing and Computer Vision has been leveraging textual information -- e.g., entity names and descriptions -- available in knowledge graphs to ground neural models to high-quality structured data.\\nHowever, when it comes to non-English languages, both quantity andâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/davanstrien/ml-kge.","first_N":5,"first_N_keywords":["English","Arabic","German","Spanish","French"],"keywords_longer_than_N":true},
	{"name":"Thaqalayn-Classical-Arabic-English-Parallel-texts","keyword":"arabic","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ImruQays/Thaqalayn-Classical-Arabic-English-Parallel-texts","creator_name":"Qays","creator_url":"https://huggingface.co/ImruQays","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tIntroduction\\n\\t\\n\\nThis dataset represents a comprehensive collection of parallel Arabic-English texts from the Thaqalayn Hadith Library, a premier source for exploring the classical hadith tradition of the ImÄmÄ« Shia Muslim school of thought. The library focuses on making primary historical sources accessible, serving as a bridge between past wisdom and contemporary study. The dataset features translations of significant classical ImÄmÄ« hadith texts, allowing for a deep dive into theâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/ImruQays/Thaqalayn-Classical-Arabic-English-Parallel-texts.","first_N":5,"first_N_keywords":["translation","Arabic","English","cc-by-4.0","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"Tunisian_reddit","keyword":"arabic","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Lime1/Tunisian_reddit","creator_name":"Aymen Hmani","creator_url":"https://huggingface.co/Lime1","description":"\\n\\t\\n\\t\\t\\n\\t\\tr/Tunisia Data set\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThis repository contains two datasets:\\n\\noutput_comments.csv: This file contains the comments data. Each row represents a comment, with various attributes such as the comment ID, the post it belongs to, the user who made the comment, and the comment text. (sorted by score) id,url,score,body,date\\n\\noutput_posts.csv: This file contains the posts data. Each row represents a post, with various attributes such as the post ID, the user whoâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Lime1/Tunisian_reddit.","first_N":5,"first_N_keywords":["Arabic","French","English","mit","100K<n<1M"],"keywords_longer_than_N":true},
	{"name":"WikidataLabels","keyword":"arabic","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/rayliuca/WikidataLabels","creator_name":"Ray Liu","creator_url":"https://huggingface.co/rayliuca","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tWikidata Labels\\n\\t\\n\\nLarge parallel corpus for machine translation\\n\\nEntity label data extracted from Wikidata (2022-01-03), filtered for item entities only  \\nOnly download the languages you need with datasets>=2.14.0\\nSimilar dataset: https://huggingface.co/datasets/wmt/wikititles (18 Wikipedia titles pairs instead of all Wikidata entities)\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Details\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Sources\\n\\t\\n\\n\\nWikidata JSON dump (wikidata-20220103-all.json.gz)â€¦ See the full description on the dataset page: https://huggingface.co/datasets/rayliuca/WikidataLabels.","first_N":5,"first_N_keywords":["translation","text2text-generation","English","French","German"],"keywords_longer_than_N":true},
	{"name":"oasst2_top1_chat_format","keyword":"arabic","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/blancsw/oasst2_top1_chat_format","creator_name":"Blanc Swan","creator_url":"https://huggingface.co/blancsw","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tOpenAssistant TOP-1 Conversation Threads in huggingface chat format\\n\\t\\n\\nExport of oasst2 only top 1 threads in huggingface chat format\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tScript\\n\\t\\n\\nThe convert script can be find here\\n","first_N":5,"first_N_keywords":["English","Spanish","Russian","German","Polish"],"keywords_longer_than_N":true},
	{"name":"PTCC","keyword":"arabic","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/AMR-KELEG/PTCC","creator_name":"Amr Keleg","creator_url":"https://huggingface.co/AMR-KELEG","description":"The Parallel Tunisian Constitution Corpus (PTCC) corpus is a corpus of 149 articles written in Modern Standard Arabic and Tunisian Arabic.\\nTesseract was used to transform the constitution's pdf files into text files. Afterward, alignment of the parallel articles was achieved by a simple Python script.\\nMore details can be found in: https://amr-keleg.github.io/projects/digitalizing_dialectal_arabic/\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSources:\\n\\t\\n\\n\\nTunisian Arabic translation of the 2014 Tunisian Constitution\\n2014â€¦ See the full description on the dataset page: https://huggingface.co/datasets/AMR-KELEG/PTCC.","first_N":5,"first_N_keywords":["text-generation","Arabic","mit","< 1K","csv"],"keywords_longer_than_N":true},
	{"name":"language_tags","keyword":"arabic","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/lbourdois/language_tags","creator_name":"LoÃ¯ck BOURDOIS","creator_url":"https://huggingface.co/lbourdois","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDescription\\n\\t\\n\\nDataset listing 27,328 languages and dialects (also includes macrolanguage names).For each language, either the ISO 639 code, the Glottolog code or both are provided.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tColumns\\n\\t\\n\\n\\nEnglish_Name: Language name in English (e.g. \\\"French\\\").\\nNative_Name: If value is not 0, corresponds to the name of the language by native speakers (e.g. \\\"FranÃ§ais\\\") which may have been found in Wikipedia's nativename field.\\nGlottocode: The language tag in the Glottolog conventionâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/lbourdois/language_tags.","first_N":5,"first_N_keywords":["Afade","ParÃ¡ ArÃ¡ra","Afar","Aka-Bea","Abon"],"keywords_longer_than_N":true},
	{"name":"language_tags","keyword":"egyptian arabic","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/lbourdois/language_tags","creator_name":"LoÃ¯ck BOURDOIS","creator_url":"https://huggingface.co/lbourdois","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDescription\\n\\t\\n\\nDataset listing 27,328 languages and dialects (also includes macrolanguage names).For each language, either the ISO 639 code, the Glottolog code or both are provided.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tColumns\\n\\t\\n\\n\\nEnglish_Name: Language name in English (e.g. \\\"French\\\").\\nNative_Name: If value is not 0, corresponds to the name of the language by native speakers (e.g. \\\"FranÃ§ais\\\") which may have been found in Wikipedia's nativename field.\\nGlottocode: The language tag in the Glottolog conventionâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/lbourdois/language_tags.","first_N":5,"first_N_keywords":["Afade","ParÃ¡ ArÃ¡ra","Afar","Aka-Bea","Abon"],"keywords_longer_than_N":true},
	{"name":"language_tags","keyword":"levantine arabic","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/lbourdois/language_tags","creator_name":"LoÃ¯ck BOURDOIS","creator_url":"https://huggingface.co/lbourdois","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDescription\\n\\t\\n\\nDataset listing 27,328 languages and dialects (also includes macrolanguage names).For each language, either the ISO 639 code, the Glottolog code or both are provided.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tColumns\\n\\t\\n\\n\\nEnglish_Name: Language name in English (e.g. \\\"French\\\").\\nNative_Name: If value is not 0, corresponds to the name of the language by native speakers (e.g. \\\"FranÃ§ais\\\") which may have been found in Wikipedia's nativename field.\\nGlottocode: The language tag in the Glottolog conventionâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/lbourdois/language_tags.","first_N":5,"first_N_keywords":["Afade","ParÃ¡ ArÃ¡ra","Afar","Aka-Bea","Abon"],"keywords_longer_than_N":true},
	{"name":"language_tags","keyword":"moroccan arabic","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/lbourdois/language_tags","creator_name":"LoÃ¯ck BOURDOIS","creator_url":"https://huggingface.co/lbourdois","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDescription\\n\\t\\n\\nDataset listing 27,328 languages and dialects (also includes macrolanguage names).For each language, either the ISO 639 code, the Glottolog code or both are provided.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tColumns\\n\\t\\n\\n\\nEnglish_Name: Language name in English (e.g. \\\"French\\\").\\nNative_Name: If value is not 0, corresponds to the name of the language by native speakers (e.g. \\\"FranÃ§ais\\\") which may have been found in Wikipedia's nativename field.\\nGlottocode: The language tag in the Glottolog conventionâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/lbourdois/language_tags.","first_N":5,"first_N_keywords":["Afade","ParÃ¡ ArÃ¡ra","Afar","Aka-Bea","Abon"],"keywords_longer_than_N":true},
	{"name":"language_tags","keyword":"najdi arabic","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/lbourdois/language_tags","creator_name":"LoÃ¯ck BOURDOIS","creator_url":"https://huggingface.co/lbourdois","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDescription\\n\\t\\n\\nDataset listing 27,328 languages and dialects (also includes macrolanguage names).For each language, either the ISO 639 code, the Glottolog code or both are provided.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tColumns\\n\\t\\n\\n\\nEnglish_Name: Language name in English (e.g. \\\"French\\\").\\nNative_Name: If value is not 0, corresponds to the name of the language by native speakers (e.g. \\\"FranÃ§ais\\\") which may have been found in Wikipedia's nativename field.\\nGlottocode: The language tag in the Glottolog conventionâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/lbourdois/language_tags.","first_N":5,"first_N_keywords":["Afade","ParÃ¡ ArÃ¡ra","Afar","Aka-Bea","Abon"],"keywords_longer_than_N":true},
	{"name":"language_tags","keyword":"tunisian arabic","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/lbourdois/language_tags","creator_name":"LoÃ¯ck BOURDOIS","creator_url":"https://huggingface.co/lbourdois","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDescription\\n\\t\\n\\nDataset listing 27,328 languages and dialects (also includes macrolanguage names).For each language, either the ISO 639 code, the Glottolog code or both are provided.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tColumns\\n\\t\\n\\n\\nEnglish_Name: Language name in English (e.g. \\\"French\\\").\\nNative_Name: If value is not 0, corresponds to the name of the language by native speakers (e.g. \\\"FranÃ§ais\\\") which may have been found in Wikipedia's nativename field.\\nGlottocode: The language tag in the Glottolog conventionâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/lbourdois/language_tags.","first_N":5,"first_N_keywords":["Afade","ParÃ¡ ArÃ¡ra","Afar","Aka-Bea","Abon"],"keywords_longer_than_N":true},
	{"name":"language_tags","keyword":"standard arabic","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/lbourdois/language_tags","creator_name":"LoÃ¯ck BOURDOIS","creator_url":"https://huggingface.co/lbourdois","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDescription\\n\\t\\n\\nDataset listing 27,328 languages and dialects (also includes macrolanguage names).For each language, either the ISO 639 code, the Glottolog code or both are provided.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tColumns\\n\\t\\n\\n\\nEnglish_Name: Language name in English (e.g. \\\"French\\\").\\nNative_Name: If value is not 0, corresponds to the name of the language by native speakers (e.g. \\\"FranÃ§ais\\\") which may have been found in Wikipedia's nativename field.\\nGlottocode: The language tag in the Glottolog conventionâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/lbourdois/language_tags.","first_N":5,"first_N_keywords":["Afade","ParÃ¡ ArÃ¡ra","Afar","Aka-Bea","Abon"],"keywords_longer_than_N":true},
	{"name":"language_tags","keyword":"ta'izzi-adeni arabic","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/lbourdois/language_tags","creator_name":"LoÃ¯ck BOURDOIS","creator_url":"https://huggingface.co/lbourdois","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDescription\\n\\t\\n\\nDataset listing 27,328 languages and dialects (also includes macrolanguage names).For each language, either the ISO 639 code, the Glottolog code or both are provided.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tColumns\\n\\t\\n\\n\\nEnglish_Name: Language name in English (e.g. \\\"French\\\").\\nNative_Name: If value is not 0, corresponds to the name of the language by native speakers (e.g. \\\"FranÃ§ais\\\") which may have been found in Wikipedia's nativename field.\\nGlottocode: The language tag in the Glottolog conventionâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/lbourdois/language_tags.","first_N":5,"first_N_keywords":["Afade","ParÃ¡ ArÃ¡ra","Afar","Aka-Bea","Abon"],"keywords_longer_than_N":true},
	{"name":"language_tags","keyword":"mesopotamian arabic","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/lbourdois/language_tags","creator_name":"LoÃ¯ck BOURDOIS","creator_url":"https://huggingface.co/lbourdois","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDescription\\n\\t\\n\\nDataset listing 27,328 languages and dialects (also includes macrolanguage names).For each language, either the ISO 639 code, the Glottolog code or both are provided.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tColumns\\n\\t\\n\\n\\nEnglish_Name: Language name in English (e.g. \\\"French\\\").\\nNative_Name: If value is not 0, corresponds to the name of the language by native speakers (e.g. \\\"FranÃ§ais\\\") which may have been found in Wikipedia's nativename field.\\nGlottocode: The language tag in the Glottolog conventionâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/lbourdois/language_tags.","first_N":5,"first_N_keywords":["Afade","ParÃ¡ ArÃ¡ra","Afar","Aka-Bea","Abon"],"keywords_longer_than_N":true},
	{"name":"ministries","keyword":"arabic","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/faranheit/ministries","creator_name":"Muhammad Faran","creator_url":"https://huggingface.co/faranheit","description":"{\\\"id\\\": \\\"130042945016-0\\\", \\\"text\\\": \\\"\\\\u0648\\\\u0635\\\\u0641 \\\\u0627\\\\u0644\\\\u062e\\\\u062f\\\\u0645\\\\u0629: \\\\u062a\\\\u0645\\\\u0643\\\\u0651\\\\u0650\\\\u0646 \\\\u0647\\\\u0630\\\\u0647 \\\\u0627\\\\u0644\\\\u062e\\\\u062f\\\\u0645\\\\u0629 \\\\u0627\\\\u0644\\\\u0639\\\\u0645\\\\u064a\\\\u0644 \\\\u0645\\\\u0646 \\\\u062a\\\\u0642\\\\u062f\\\\u064a\\\\u0645 \\\\u062c\\\\u0645\\\\u064a\\\\u0639 \\\\u0637\\\\u0644\\\\u0628\\\\u0627\\\\u062a \\\\u0639\\\\u0642\\\\u0648\\\\u062f \\\\u062a\\\\u0623\\\\u0633\\\\u064a\\\\u0633 \\\\u0627\\\\u0644\\\\u0634\\\\u0631\\\\u0643\\\\u0627\\\\u062a \\\\u062d\\\\u0633\\\\u0628 \\\\u0627\\\\u0644\\\\u0643\\\\u064a\\\\u0627\\\\u0646 :  \\\\nâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/faranheit/ministries.","first_N":5,"first_N_keywords":["question-answering","Arabic","apache-2.0","< 1K","json"],"keywords_longer_than_N":true},
	{"name":"oaast_rm_full_jieba","keyword":"arabic","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/lenML/oaast_rm_full_jieba","creator_name":"len","creator_url":"https://huggingface.co/lenML","description":"å°è¯•è§£å†³\\\"llm repetition problem\\\"ï¼Œä½¿ç”¨åˆ†è¯æ¨¡åž‹å¯¹oaastè¯­æ–™è¿›è¡Œâ€œç»“å·´åŒ–â€æ•°æ®å¢žå¼ºï¼Œæä¾›æ›´å¼ºçš„é‡å¤å†…å®¹æ‹’ç»æ•ˆæžœã€‚\\nAttempts to solve the \\\"llm repetition problem\\\" by using a segmentation model to enhance the oaast corpus with \\\"stuttering\\\" data to provide stronger rejection of duplicate content.\\nå…¶æ¬¡ï¼Œè¿˜è¿‡æ»¤æŽ‰äº†æ‰€æœ‰è‡ªæˆ‘è®¤çŸ¥çš„å¾®è°ƒæ ·æœ¬ã€‚\\nSecond, it also filters out all the fine-tuned samples of self-cognition.\\nfiles:\\n\\noaast_rm_full_jieba.jsonl : word level repeat\\noaast_rm_full_sent_jieba.jsonl : sentence level repeat\\n\\n","first_N":5,"first_N_keywords":["English","Spanish","Russian","German","Polish"],"keywords_longer_than_N":true},
	{"name":"language-dataset","keyword":"arabic","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neon-mao/language-dataset","creator_name":"maoqifan","creator_url":"https://huggingface.co/neon-mao","description":"\\n","first_N":5,"first_N_keywords":["text-classification","English","Chinese","French","Russian"],"keywords_longer_than_N":true},
	{"name":"Deltacorpus_1.1","keyword":"arabic","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/FrancophonIA/Deltacorpus_1.1","creator_name":"FrancophonIA","creator_url":"https://huggingface.co/FrancophonIA","description":"\\nDataset origin: https://lindat.cz/repository/xmlui/handle/11234/1-1743\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDescription\\n\\t\\n\\nTexts in 107 languages from the W2C corpus (http://hdl.handle.net/11858/00-097C-0000-0022-6133-9), first 1,000,000 tokens per language, tagged by the delexicalized tagger described in Yu et al. (2016, LREC, PortoroÅ¾, Slovenia).\\nChanges in version 1.1: \\n\\nUniversal Dependencies tagset instead of the older and smaller Google Universal POS tagset. \\n\\nSVM classifier trained on Universal Dependenciesâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/FrancophonIA/Deltacorpus_1.1.","first_N":5,"first_N_keywords":["token-classification","multilingual","Afrikaans","Albanian","Amharic"],"keywords_longer_than_N":true},
	{"name":"MM-Eval","keyword":"arabic","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/prometheus-eval/MM-Eval","creator_name":"prometheus-eval","creator_url":"https://huggingface.co/prometheus-eval","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tMultilingual Meta-EVALuation benchmark (MM-Eval)\\n\\t\\n\\n\\nðŸ‘¨â€ðŸ’»Code\\n|\\nðŸ“„Paper\\n|\\nðŸ¤— MMQA\\n\\n\\nMM-Eval is a multilingual meta-evaluation benchmark consisting of five core subsetsâ€”Chat, Reasoning, Safety, Language Hallucination, and Linguisticsâ€”spanning 18 languages and a Language Resource subset spanning 122 languages for a broader analysis of language effects. \\n\\nDesign ChoiceIn this work, we minimize the inclusion of translated samples, as mere translation may alter existing preferences dueâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/prometheus-eval/MM-Eval.","first_N":5,"first_N_keywords":["Arabic","Bengali","Catalan","German","English"],"keywords_longer_than_N":true},
	{"name":"test","keyword":"arabic","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/HussamAraj/test","creator_name":"Hussam Araj","creator_url":"https://huggingface.co/HussamAraj","description":"HussamAraj/test dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["Arabic","mit","< 1K","text","Text"],"keywords_longer_than_N":true},
	{"name":"Deltacorpus_1.1","keyword":"egyptian arabic","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/FrancophonIA/Deltacorpus_1.1","creator_name":"FrancophonIA","creator_url":"https://huggingface.co/FrancophonIA","description":"\\nDataset origin: https://lindat.cz/repository/xmlui/handle/11234/1-1743\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDescription\\n\\t\\n\\nTexts in 107 languages from the W2C corpus (http://hdl.handle.net/11858/00-097C-0000-0022-6133-9), first 1,000,000 tokens per language, tagged by the delexicalized tagger described in Yu et al. (2016, LREC, PortoroÅ¾, Slovenia).\\nChanges in version 1.1: \\n\\nUniversal Dependencies tagset instead of the older and smaller Google Universal POS tagset. \\n\\nSVM classifier trained on Universal Dependenciesâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/FrancophonIA/Deltacorpus_1.1.","first_N":5,"first_N_keywords":["token-classification","multilingual","Afrikaans","Albanian","Amharic"],"keywords_longer_than_N":true},
	{"name":"EvArEST-dataset-for-Arabic-scene-text-detection","keyword":"arabic","license":"BSD 3-Clause \"New\" or \"Revised\" License","license_url":"https://choosealicense.com/licenses/bsd-3-clause/","language":"en","dataset_url":"https://huggingface.co/datasets/Melaraby/EvArEST-dataset-for-Arabic-scene-text-detection","creator_name":"Mostafa","creator_url":"https://huggingface.co/Melaraby","description":"\\n\\t\\n\\t\\t\\n\\t\\tEvArEST\\n\\t\\n\\nEveryday Arabic-English Scene Text dataset, from the paper: Arabic Scene Text Recognition in the Deep Learning Era: Analysis on A Novel Dataset\\n\\n\\t\\n\\t\\t\\n\\t\\tDetection Dataset\\n\\t\\n\\nThe text detection dataset has 510 images all containing one or more instances of text. Each word is annotated with a four-point polygon that starts with the top left corner of the polygon and follows clockwise. Each image comes with a text file containing three attributes: the four points of the polygonâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Melaraby/EvArEST-dataset-for-Arabic-scene-text-detection.","first_N":5,"first_N_keywords":["Arabic","bsd-3-clause","< 1K","parquet","Image"],"keywords_longer_than_N":true},
	{"name":"Saka-Alpaca-v1","keyword":"arabic","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Sakalti/Saka-Alpaca-v1","creator_name":"sakasan","creator_url":"https://huggingface.co/Sakalti","description":"https://chatgpt.com\\n","first_N":5,"first_N_keywords":["text-generation","Swedish","Norwegian","Finnish","German"],"keywords_longer_than_N":true},
	{"name":"linkedin-industry-list","keyword":"arabic","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/fantastic-jobs/linkedin-industry-list","creator_name":"Fantastic.jobs","creator_url":"https://huggingface.co/fantastic-jobs","description":"fantastic-jobs/linkedin-industry-list dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["text-classification","translation","English","Korean","Spanish"],"keywords_longer_than_N":true},
	{"name":"MMMLU","keyword":"arabic","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/bzantium/MMMLU","creator_name":"Minho Ryu","creator_url":"https://huggingface.co/bzantium","description":"\\n\\t\\n\\t\\t\\n\\t\\tMultilingual Massive Multitask Language Understanding (MMMLU)\\n\\t\\n\\nThe MMLU is a widely recognized benchmark of general knowledge attained by AI models. It covers a broad range of topics from 57 different categories, covering elementary-level knowledge up to advanced professional subjects like law, physics, history, and computer science.\\nWe translated the MMLUâ€™s test set into 14 languages using professional human translators. Relying on human translators for this evaluation increasesâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/bzantium/MMMLU.","first_N":5,"first_N_keywords":["question-answering","Arabic","Bengali","German","Spanish"],"keywords_longer_than_N":true},
	{"name":"imeg4model","keyword":"arabic","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/yyasso/imeg4model","creator_name":"H.coding AI","creator_url":"https://huggingface.co/yyasso","description":"openS\\nfrom: hcoding\\n","first_N":5,"first_N_keywords":["text2text-generation","English","Arabic","French","mit"],"keywords_longer_than_N":true},
	{"name":"resmo","keyword":"arabic","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/aibrahiam/resmo","creator_name":"Ahmed Ibrahim","creator_url":"https://huggingface.co/aibrahiam","description":"aibrahiam/resmo dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["question-answering","text-classification","Arabic","English","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"transcirpt-seerah-dr-yasir-qadhi","keyword":"arabic","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/rwmasood/transcirpt-seerah-dr-yasir-qadhi","creator_name":"Dr Wasif Masood","creator_url":"https://huggingface.co/rwmasood","description":"\\n\\t\\n\\t\\t\\n\\t\\tSeerah of Prophet Muhammad (SAW) â€“ Lecture Transcripts by Dr. Yasir Qadhi\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tOverview\\n\\t\\n\\nThis dataset contains the full transcripts of all 104 lectures delivered by Dr. Yasir Qadhi on the Seerah (biography) of Prophet Muhammad (SAW). These lectures provide a comprehensive, chronological account of the life, teachings, and historical context of the Prophet (SAW), covering key events such as:\\n\\nHis birth and early life in Mecca.\\nThe revelation of Prophethood and the message ofâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/rwmasood/transcirpt-seerah-dr-yasir-qadhi.","first_N":5,"first_N_keywords":["question-answering","text-generation","English","Arabic","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"opensubtitles-v2018-en-ar","keyword":"arabic","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/NeutrinoPit/opensubtitles-v2018-en-ar","creator_name":"pit","creator_url":"https://huggingface.co/NeutrinoPit","description":"\\n\\t\\n\\t\\t\\n\\t\\tDataset Card for Dataset Name\\n\\t\\n\\n\\n\\nThis dataset card aims to be a base template for new datasets. It has been generated using this raw template.\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Details\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\n\\n\\n\\n\\n\\nCurated by: [More Information Needed]\\nFunded by [optional]: [More Information Needed]\\nShared by [optional]: [More Information Needed]\\nLanguage(s) (NLP): [More Information Needed]\\nLicense: [More Information Needed]\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Sources [optional]\\n\\t\\n\\n\\n\\n\\nRepository: [Moreâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/NeutrinoPit/opensubtitles-v2018-en-ar.","first_N":5,"first_N_keywords":["text-classification","Arabic","English","mit","10M - 100M"],"keywords_longer_than_N":true},
	{"name":"egyptian_train_set","keyword":"arabic","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/otozz/egyptian_train_set","creator_name":"Ã–mer","creator_url":"https://huggingface.co/otozz","description":"Pre-processed Egyptian train partition from the MASC-dataset:\\nMohammad Al-Fetyani, Muhammad Al-Barham, Gheith Abandah, Adham Alsharkawi, Maha Dawas, August 18, 2021, \\\"MASC: Massive Arabic Speech Corpus\\\", IEEE Dataport, doi: https://dx.doi.org/10.21227/e1qb-jv46.\\n","first_N":5,"first_N_keywords":["Arabic","cc-by-4.0","10K - 100K","parquet","Datasets"],"keywords_longer_than_N":true},
	{"name":"gulf_train_set","keyword":"arabic","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/otozz/gulf_train_set","creator_name":"Ã–mer","creator_url":"https://huggingface.co/otozz","description":"Pre-processed Gulf train partition from the MASC-dataset:\\nMohammad Al-Fetyani, Muhammad Al-Barham, Gheith Abandah, Adham Alsharkawi, Maha Dawas, August 18, 2021, \\\"MASC: Massive Arabic Speech Corpus\\\", IEEE Dataport, doi: https://dx.doi.org/10.21227/e1qb-jv46.\\n","first_N":5,"first_N_keywords":["Arabic","cc-by-4.0","10K - 100K","parquet","Datasets"],"keywords_longer_than_N":true},
	{"name":"gulf_test_set","keyword":"arabic","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/otozz/gulf_test_set","creator_name":"Ã–mer","creator_url":"https://huggingface.co/otozz","description":"Pre-processed Gulf test partition from the MASC-dataset:\\nMohammad Al-Fetyani, Muhammad Al-Barham, Gheith Abandah, Adham Alsharkawi, Maha Dawas, August 18, 2021, \\\"MASC: Massive Arabic Speech Corpus\\\", IEEE Dataport, doi: https://dx.doi.org/10.21227/e1qb-jv46.\\n","first_N":5,"first_N_keywords":["Arabic","cc-by-4.0","1K - 10K","parquet","Datasets"],"keywords_longer_than_N":true},
	{"name":"iraqi_train_set","keyword":"arabic","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/otozz/iraqi_train_set","creator_name":"Ã–mer","creator_url":"https://huggingface.co/otozz","description":"Pre-processed Iraqi train partition from the MASC-dataset:\\nMohammad Al-Fetyani, Muhammad Al-Barham, Gheith Abandah, Adham Alsharkawi, Maha Dawas, August 18, 2021, \\\"MASC: Massive Arabic Speech Corpus\\\", IEEE Dataport, doi: https://dx.doi.org/10.21227/e1qb-jv46.\\n","first_N":5,"first_N_keywords":["Arabic","cc-by-4.0","10K - 100K","parquet","Datasets"],"keywords_longer_than_N":true},
	{"name":"levantine_test_set","keyword":"arabic","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/otozz/levantine_test_set","creator_name":"Ã–mer","creator_url":"https://huggingface.co/otozz","description":"Pre-processed Levantine test partition from the MASC-dataset:\\nMohammad Al-Fetyani, Muhammad Al-Barham, Gheith Abandah, Adham Alsharkawi, Maha Dawas, August 18, 2021, \\\"MASC: Massive Arabic Speech Corpus\\\", IEEE Dataport, doi: https://dx.doi.org/10.21227/e1qb-jv46.\\n","first_N":5,"first_N_keywords":["Arabic","cc-by-4.0","1K - 10K","parquet","Datasets"],"keywords_longer_than_N":true},
	{"name":"maghrebi_train_set","keyword":"arabic","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/otozz/maghrebi_train_set","creator_name":"Ã–mer","creator_url":"https://huggingface.co/otozz","description":"Pre-processed Maghrebi train partition from the MASC-dataset:\\nMohammad Al-Fetyani, Muhammad Al-Barham, Gheith Abandah, Adham Alsharkawi, Maha Dawas, August 18, 2021, \\\"MASC: Massive Arabic Speech Corpus\\\", IEEE Dataport, doi: https://dx.doi.org/10.21227/e1qb-jv46.\\n","first_N":5,"first_N_keywords":["Arabic","cc-by-4.0","10K - 100K","parquet","Datasets"],"keywords_longer_than_N":true},
	{"name":"MSA_test_set","keyword":"arabic","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/otozz/MSA_test_set","creator_name":"Ã–mer","creator_url":"https://huggingface.co/otozz","description":"Pre-processed MSA data based on https://huggingface.co/datasets/mozilla-foundation/common_voice_16_1.\\n","first_N":5,"first_N_keywords":["Arabic","cc0-1.0","10K - 100K","parquet","Audio"],"keywords_longer_than_N":true},
	{"name":"BenchMAX_Rule-based","keyword":"arabic","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/LLaMAX/BenchMAX_Rule-based","creator_name":"LLaMAX","creator_url":"https://huggingface.co/LLaMAX","description":"\\n\\t\\n\\t\\t\\n\\t\\tDataset Sources\\n\\t\\n\\n\\nPaper: BenchMAX: A Comprehensive Multilingual Evaluation Suite for Large Language Models\\nLink: https://arxiv.org/pdf/2502.07346\\nRepository: https://github.com/CONE-MT/BenchMAX\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\nBenchMAX_Rule-based is a dataset of BenchMAX, sourcing from IFEval, which is a rule-based benchmark for evaluating the instruction following capabilities.\\nWe extend the original dataset to 16 non-English languages by first translating and then manualâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/LLaMAX/BenchMAX_Rule-based.","first_N":5,"first_N_keywords":["text-generation","multilingual","English","Chinese","Spanish"],"keywords_longer_than_N":true},
	{"name":"BenchMAX_Model-based","keyword":"arabic","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/LLaMAX/BenchMAX_Model-based","creator_name":"LLaMAX","creator_url":"https://huggingface.co/LLaMAX","description":"\\n\\t\\n\\t\\t\\n\\t\\tDataset Sources\\n\\t\\n\\n\\nPaper: BenchMAX: A Comprehensive Multilingual Evaluation Suite for Large Language Models\\nLink: https://arxiv.org/pdf/2502.07346\\nRepository: https://github.com/CONE-MT/BenchMAX\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\nBenchMAX_Model-based is a dataset of BenchMAX, sourcing from m-ArenaHard.\\nWe extend the original English dataset to 16 non-English languages by first translating and then manual post-editing.\\n\\n\\t\\n\\t\\t\\n\\t\\tSupported Languages\\n\\t\\n\\nArabic, Bengali, Chinese, Czechâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/LLaMAX/BenchMAX_Model-based.","first_N":5,"first_N_keywords":["text-generation","multilingual","English","Chinese","Spanish"],"keywords_longer_than_N":true},
	{"name":"BenchMAX_Multiple_Functions","keyword":"arabic","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/LLaMAX/BenchMAX_Multiple_Functions","creator_name":"LLaMAX","creator_url":"https://huggingface.co/LLaMAX","description":"\\n\\t\\n\\t\\t\\n\\t\\tDataset Sources\\n\\t\\n\\n\\nPaper: BenchMAX: A Comprehensive Multilingual Evaluation Suite for Large Language Models\\nLink: https://arxiv.org/pdf/2502.07346\\nRepository: https://github.com/CONE-MT/BenchMAX\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\nBenchMAX_Multiple_Functions is a dataset of BenchMAX, sourcing from Nexus.\\nWe translate the standardized queries from English to 16 non-English languages by google Translate.\\nSome special function arguments remain English since the APIs are in English.\\nAllâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/LLaMAX/BenchMAX_Multiple_Functions.","first_N":5,"first_N_keywords":["text-generation","multilingual","English","Chinese","Spanish"],"keywords_longer_than_N":true},
	{"name":"BenchMAX_General_Translation","keyword":"arabic","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/LLaMAX/BenchMAX_General_Translation","creator_name":"LLaMAX","creator_url":"https://huggingface.co/LLaMAX","description":"\\n\\t\\n\\t\\t\\n\\t\\tDataset Sources\\n\\t\\n\\n\\nPaper: BenchMAX: A Comprehensive Multilingual Evaluation Suite for Large Language Models\\nLink: https://arxiv.org/pdf/2502.07346\\nRepository: https://github.com/CONE-MT/BenchMAX\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\nBenchMAX_General_Translation is a dataset of BenchMAX.\\nWe collect parallel test data from Flore-200, TED-talk, and WMT24.\\n\\n\\t\\n\\t\\t\\n\\t\\tSupported Languages\\n\\t\\n\\nArabic, Bengali, Chinese, Czech, English, French, German, Hungarian, Japanese, Korean, Serbian, Spanishâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/LLaMAX/BenchMAX_General_Translation.","first_N":5,"first_N_keywords":["text-generation","multilingual","English","Chinese","Spanish"],"keywords_longer_than_N":true},
	{"name":"BenchMAX_Domain_Translation","keyword":"arabic","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/LLaMAX/BenchMAX_Domain_Translation","creator_name":"LLaMAX","creator_url":"https://huggingface.co/LLaMAX","description":"\\n\\t\\n\\t\\t\\n\\t\\tDataset Sources\\n\\t\\n\\n\\nPaper: BenchMAX: A Comprehensive Multilingual Evaluation Suite for Large Language Models\\nLink: https://arxiv.org/pdf/2502.07346\\nRepository: https://github.com/CONE-MT/BenchMAX\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\nBenchMAX_Domain_Translation is a dataset of BenchMAX.\\nWe collect the domain parallel data from other tasks in BenchMAX.\\nEach sample contains one or three human-annotated translations.\\n\\n\\t\\n\\t\\t\\n\\t\\tSupported Languages\\n\\t\\n\\nArabic, Bengali, Chinese, Czech, Englishâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/LLaMAX/BenchMAX_Domain_Translation.","first_N":5,"first_N_keywords":["text-generation","multilingual","English","Chinese","Spanish"],"keywords_longer_than_N":true},
	{"name":"ADMD","keyword":"arabic","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/riotu-lab/ADMD","creator_name":"Robotics and Interne-of-Things","creator_url":"https://huggingface.co/riotu-lab","description":"\\n\\t\\n\\t\\t\\n\\t\\tArabic Depth Mini Dataset (ADMD)\\n\\t\\n\\nThe Arabic Depth Mini Dataset (ADMD) is a compact yet highly challenging dataset designed to evaluate Arabic language models across diverse domains. It consists of 490 carefully curated questions spanning 10 major domains and 42 topics. The dataset is manually reviewed and emphasizes linguistic accuracy, cultural alignment, and methodological rigor.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Overview\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tCategories and Topics\\n\\t\\n\\nThe dataset covers 42 topicsâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/riotu-lab/ADMD.","first_N":5,"first_N_keywords":["Arabic","mit","< 1K","csv","Text"],"keywords_longer_than_N":true},
	{"name":"translation2","keyword":"arabic","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/MawaredHR/translation2","creator_name":"MawaredHR AI","creator_url":"https://huggingface.co/MawaredHR","description":"\\n\\t\\n\\t\\t\\n\\t\\tDataset Card for Dataset Name\\n\\t\\n\\n\\n\\nThis dataset card aims to be a base template for new datasets. It has been generated using this raw template.\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Details\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\n\\n\\n\\n\\n\\nCurated by: [More Information Needed]\\nFunded by [optional]: [More Information Needed]\\nShared by [optional]: [More Information Needed]\\nLanguage(s) (NLP): [More Information Needed]\\nLicense: [More Information Needed]\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Sources [optional]\\n\\t\\n\\n\\n\\n\\nRepository: [Moreâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/MawaredHR/translation2.","first_N":5,"first_N_keywords":["translation","English","Arabic","apache-2.0","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"V1Q","keyword":"arabic","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/YuRiVeRTi/V1Q","creator_name":"YuRiVeRTical","creator_url":"https://huggingface.co/YuRiVeRTi","description":"from datasets import load_dataset\\nds = load_dataset(\\\"b3x0m/Chinese-H-Novels\\\")\\nimport sagemaker\\nimport boto3\\nfrom sagemaker.huggingface import HuggingFaceModel\\ntry:\\n    role = sagemaker.get_execution_role()\\nexcept ValueError:\\n    iam = boto3.client('iam')\\n    role = iam.get_role(RoleName='sagemaker_execution_role')['Role']['Arn']\\n\\n\\t\\n\\t\\t\\n\\t\\tHub Model configuration. https://huggingface.co/models\\n\\t\\n\\nhub = {\\n    'HF_MODEL_ID':'deepseek-ai/Janus-Pro-7B',\\n    'HF_TASK':'any-to-any'\\n}\\n\\n\\t\\n\\t\\t\\n\\t\\tcreateâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/YuRiVeRTi/V1Q.","first_N":5,"first_N_keywords":["text-classification","token-classification","table-question-answering","question-answering","zero-shot-classification"],"keywords_longer_than_N":true},
	{"name":"Tamazight-ASR-Dataset-v2","keyword":"arabic","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/SoufianeDahimi/Tamazight-ASR-Dataset-v2","creator_name":"Soufiane Dahimi","creator_url":"https://huggingface.co/SoufianeDahimi","description":"\\n\\t\\n\\t\\t\\n\\t\\tTamazight-Arabic Speech Recognition Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThis dataset contains speech segments in Tamazight (specifically focusing on the Tachelhit dialect) paired with their corresponding Arabic transcriptions. It is designed to support the development of automatic speech recognition (ASR) systems for the Tamazight language, particularly for translation into Modern Standard Arabic.\\nThis is an actively growing dataset, with regular updates and new data points beingâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/SoufianeDahimi/Tamazight-ASR-Dataset-v2.","first_N":5,"first_N_keywords":["automatic-speech-recognition","Arabic","Standard Moroccan Tamazight","apache-2.0","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"arabic_dialects_question_and_answer","keyword":"arabic","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/CNTXTAI0/arabic_dialects_question_and_answer","creator_name":"CNTXT AI","creator_url":"https://huggingface.co/CNTXTAI0","description":"Data Content\\nThe file provided: Q/A Reasoning dataset\\ncontains the following columns:\\n\\n\\nID # : Denotes the reference ID for:\\na. Question\\nb. Answer to the question\\nc. Hint\\nd. Reasoning\\ne. Word count for items a to d above\\nDialects: Contains the following dialects in separate columns:\\na. English\\nb. MSA\\nc. Emirati\\nd. Egyptian\\ne. Levantine Syria\\nf. Levantine Jordan\\ng. Levantine Palestine\\nh. Levantine Lebanon\\nData Generation Process\\nThe following are the steps that were followed to curate the data:â€¦ See the full description on the dataset page: https://huggingface.co/datasets/CNTXTAI0/arabic_dialects_question_and_answer.","first_N":5,"first_N_keywords":["question-answering","text-generation","text2text-generation","Arabic","English"],"keywords_longer_than_N":true},
	{"name":"arabic_dialects_question_and_answer","keyword":"arabic","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/CNTXTAI0/arabic_dialects_question_and_answer","creator_name":"CNTXT AI","creator_url":"https://huggingface.co/CNTXTAI0","description":"Data Content\\nThe file provided: Q/A Reasoning dataset\\ncontains the following columns:\\n\\n\\nID # : Denotes the reference ID for:\\na. Question\\nb. Answer to the question\\nc. Hint\\nd. Reasoning\\ne. Word count for items a to d above\\nDialects: Contains the following dialects in separate columns:\\na. English\\nb. MSA\\nc. Emirati\\nd. Egyptian\\ne. Levantine Syria\\nf. Levantine Jordan\\ng. Levantine Palestine\\nh. Levantine Lebanon\\nData Generation Process\\nThe following are the steps that were followed to curate the data:â€¦ See the full description on the dataset page: https://huggingface.co/datasets/CNTXTAI0/arabic_dialects_question_and_answer.","first_N":5,"first_N_keywords":["question-answering","text-generation","text2text-generation","Arabic","English"],"keywords_longer_than_N":true},
	{"name":"multilingual_translation_gen_binarized","keyword":"arabic","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Youseff1987/multilingual_translation_gen_binarized","creator_name":"JOON HYOUNG JUN","creator_url":"https://huggingface.co/Youseff1987","description":"Youseff1987/multilingual_translation_gen_binarized dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["translation","Korean","English","Chinese","Zulu"],"keywords_longer_than_N":true},
	{"name":"HPLT2.0_cleaned","keyword":"arabic","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/jobs-git/HPLT2.0_cleaned","creator_name":"James Guana","creator_url":"https://huggingface.co/jobs-git","description":"This is a large-scale collection of web-crawled documents in 191 world languages, produced by the HPLT project. \\nThe source of the data is mostly Internet Archive with some additions from Common Crawl.\\nFor a detailed description of the dataset, please refer to https://hplt-project.org/datasets/v2.0\\nThe Cleaned variant of HPLT Datasets v2.0\\nThis is the cleaned variant of the HPLT Datasets v2.0 converted to the Parquet format semi-automatically when being uploaded here. \\nThe original JSONL filesâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/jobs-git/HPLT2.0_cleaned.","first_N":5,"first_N_keywords":["fill-mask","text-generation","language-modeling","multilingual","Achinese"],"keywords_longer_than_N":true},
	{"name":"Arab_Summerization_Ds","keyword":"arabic","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/HebArabNlpProject/Arab_Summerization_Ds","creator_name":"Israel National  NLP Program","creator_url":"https://huggingface.co/HebArabNlpProject","description":"×¨×§×¢\\n×¤×¨×•×™×™×§×˜ ×¡×™×›×•× (Summarization) ×‘×¢×¨×‘×™×ª ×”×™× ×• ×—×œ×§ ×ž×ª×›× ×™×ª ×” NLP ×”×œ××•×ž×™×ª ×‘×¢×‘×¨×™×ª ×•×¢×¨×‘×™×ª.  ×‘×ž×¡×’×¨×ª ×–×•, ×ž×¤×\\\"×ª ×ž×•×‘×™×œ×” ×ª×›× ×™×ª ×”×›×•×œ×œ×ª ×ž×¡×¤×¨ ×¨×‘ ×©×œ ×¤×¨×•×™×§×˜×™× .  ×ž×˜×¨×ª ×”×ª×›× ×™×ª ×‘×›×œ×œ, ×•×©×œ ×ž×¤×\\\"×ª ×‘×¤×¨×˜ ×”×™×  ×œ×¤×ª×— ×©×•×¨×” ×©×œ ××‘× ×™ ×‘× ×™×™×Ÿ ×ª×©×ª×™×ª×™×•×ª ×©×•× ×•×ª ××©×¨ ×™×•×¢×ž×“×• ×œ×¨×©×•×ª ×§×”×™×œ×ª ×”×¢×•×¡×§×™× ×‘×ª×—×•× ×•×™××¤×©×¨×• ×”×ž×©×š ×¤×™×ª×•×— ×ž×•××¥ ×©×œ ×™×™×©×•×ž×™× ×ž×ª×§×“×ž×™×.  ××‘× ×™ ×”×‘× ×™×™×Ÿ ×›×•×œ×œ×•×ª ×‘× ×™×™×ª ×ž××’×¨×™ ×ž×™×“×¢ ×ž×ª×•×™×™×’×™×, ×ž×•×“×œ ×©×¤×” ×¢× ×§, ×•×¤×™×ª×•×— ×™×›×•×œ×•×ª ×•×©×¨×•×ª×™× ×ž×ª×§×“×ž×™× ×‘×¢×‘×¨×™×ª ×•×¢×¨×‘×™×ª ×‘×§×•×“ ×ž×§×•×¨ ×¤×ª×•×— (open source) ×©×™×©×¨×ª ×ž×“×¢× ×™ × ×ª×•× ×™× ×•××¨×’×•× ×™× ×‘××¨×¥. ×¤×¨×•×™×§×˜ ×”-Coreferenceâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/HebArabNlpProject/Arab_Summerization_Ds.","first_N":5,"first_N_keywords":["Arabic","Hebrew","cc-by-sa-4.0","10K - 100K","text"],"keywords_longer_than_N":true}
]
;
