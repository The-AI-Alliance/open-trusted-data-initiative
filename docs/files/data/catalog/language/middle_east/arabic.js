const data_for_language_middle_east_arabic = 
[
	{"name":"TinyDS-20k","keyword":"arabic","description":"\n\t\n\t\t\n\t\tTinyDS\n\t\n\n\n\n\nAlpaca-style dataset with around 20k samples scraped from Qwen3-8B using SyntheticAlpaca. Q&A pairs can be in 32 different languages, these are listed in the metadata.Topics are all around STEM, programming, and literature.  \nMIT @ 2025 Hamzah Asadullah\n\n\n","url":"https://huggingface.co/datasets/Hamzah-Asadullah/TinyDS-20k","creator_name":"Hamzah Asadullah","creator_url":"https://huggingface.co/Hamzah-Asadullah","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["question-answering","translation","text-generation","text2text-generation","English"],"keywords_longer_than_N":true},
	{"name":"COVID-19-disinformation","keyword":"arabic","description":"\n\t\n\t\t\n\t\tCOVID-19 Infodemic Multilingual Dataset\n\t\n\nThis repository contains a multilingual dataset related to the COVID-19 infodemic, annotated with fine-grained labels. The dataset is curated to address questions of interest to journalists, fact-checkers, social media platforms, policymakers, and the general public. The dataset includes tweets in Arabic, Bulgarian, Dutch, and English, focusing on both binary (misinformation detection) and multiclass classification (different types ofâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/QCRI/COVID-19-disinformation.","url":"https://huggingface.co/datasets/QCRI/COVID-19-disinformation","creator_name":"Qatar Computing Research Institute","creator_url":"https://huggingface.co/QCRI","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","Arabic","Bulgarian","Dutch","English"],"keywords_longer_than_N":true},
	{"name":"xvnli","keyword":"arabic","description":"\n\t\n\t\t\n\t\tXVNLI\n\t\n\n\n\t\n\t\t\n\t\tThis is a copy from the original repo: https://github.com/e-bug/iglue\n\t\n\nIf you use this dataset, please cite the original authors:\n@inproceedings{bugliarello-etal-2022-iglue,\n  title = \t {{IGLUE}: A Benchmark for Transfer Learning across Modalities, Tasks, and Languages},\n  author =       {Bugliarello, Emanuele and Liu, Fangyu and Pfeiffer, Jonas and Reddy, Siva and Elliott, Desmond and Ponti, Edoardo Maria and Vuli{\\'c}, Ivan},\n  booktitle = \t {Proceedings of theâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/floschne/xvnli.","url":"https://huggingface.co/datasets/floschne/xvnli","creator_name":"Flo Schneider","creator_url":"https://huggingface.co/floschne","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["visual-question-answering","Arabic","English","Spanish","French"],"keywords_longer_than_N":true},
	{"name":"TinyDS-20k","keyword":"egyptian arabic","description":"\n\t\n\t\t\n\t\tTinyDS\n\t\n\n\n\n\nAlpaca-style dataset with around 20k samples scraped from Qwen3-8B using SyntheticAlpaca. Q&A pairs can be in 32 different languages, these are listed in the metadata.Topics are all around STEM, programming, and literature.  \nMIT @ 2025 Hamzah Asadullah\n\n\n","url":"https://huggingface.co/datasets/Hamzah-Asadullah/TinyDS-20k","creator_name":"Hamzah Asadullah","creator_url":"https://huggingface.co/Hamzah-Asadullah","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["question-answering","translation","text-generation","text2text-generation","English"],"keywords_longer_than_N":true},
	{"name":"allenai_tulu-3-sft-mixture-DolphinLabeled","keyword":"egyptian arabic","description":"\n\t\n\t\t\n\t\tallenai tulu-3-sft-mixture DolphinLabeled\n\t\n\n\n\t\n\t\t\n\t\tPart of the DolphinLabeled series of datasets\n\t\n\n\n\t\n\t\t\n\t\tPresented by Eric Hartford and Cognitive Computations\n\t\n\nThe purpose of this dataset is to enable filtering of allenai/tulu-3-sft-mixture dataset.\nThe original dataset is allenai/tulu-3-sft-mixture\nI have modified the dataset using two scripts.\n\ndedupe.py - removes rows with identical final message content\nlabel.py - adds a \"flags\" column containing the following booleanâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/QuixiAI/allenai_tulu-3-sft-mixture-DolphinLabeled.","url":"https://huggingface.co/datasets/QuixiAI/allenai_tulu-3-sft-mixture-DolphinLabeled","creator_name":"Quixi AI","creator_url":"https://huggingface.co/QuixiAI","license_name":"Open Data Commons Attribution License v1.0","license_url":"https://scancode-licensedb.aboutcode.org/odc-by-1.0.html","language":"en","first_N":5,"first_N_keywords":["other","crowdsourced","expert-generated","machine-generated","multilingual"],"keywords_longer_than_N":true},
	{"name":"allenai_tulu-3-sft-mixture-DolphinLabeled","keyword":"levantine arabic","description":"\n\t\n\t\t\n\t\tallenai tulu-3-sft-mixture DolphinLabeled\n\t\n\n\n\t\n\t\t\n\t\tPart of the DolphinLabeled series of datasets\n\t\n\n\n\t\n\t\t\n\t\tPresented by Eric Hartford and Cognitive Computations\n\t\n\nThe purpose of this dataset is to enable filtering of allenai/tulu-3-sft-mixture dataset.\nThe original dataset is allenai/tulu-3-sft-mixture\nI have modified the dataset using two scripts.\n\ndedupe.py - removes rows with identical final message content\nlabel.py - adds a \"flags\" column containing the following booleanâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/QuixiAI/allenai_tulu-3-sft-mixture-DolphinLabeled.","url":"https://huggingface.co/datasets/QuixiAI/allenai_tulu-3-sft-mixture-DolphinLabeled","creator_name":"Quixi AI","creator_url":"https://huggingface.co/QuixiAI","license_name":"Open Data Commons Attribution License v1.0","license_url":"https://scancode-licensedb.aboutcode.org/odc-by-1.0.html","language":"en","first_N":5,"first_N_keywords":["other","crowdsourced","expert-generated","machine-generated","multilingual"],"keywords_longer_than_N":true},
	{"name":"allenai_tulu-3-sft-mixture-DolphinLabeled","keyword":"moroccan arabic","description":"\n\t\n\t\t\n\t\tallenai tulu-3-sft-mixture DolphinLabeled\n\t\n\n\n\t\n\t\t\n\t\tPart of the DolphinLabeled series of datasets\n\t\n\n\n\t\n\t\t\n\t\tPresented by Eric Hartford and Cognitive Computations\n\t\n\nThe purpose of this dataset is to enable filtering of allenai/tulu-3-sft-mixture dataset.\nThe original dataset is allenai/tulu-3-sft-mixture\nI have modified the dataset using two scripts.\n\ndedupe.py - removes rows with identical final message content\nlabel.py - adds a \"flags\" column containing the following booleanâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/QuixiAI/allenai_tulu-3-sft-mixture-DolphinLabeled.","url":"https://huggingface.co/datasets/QuixiAI/allenai_tulu-3-sft-mixture-DolphinLabeled","creator_name":"Quixi AI","creator_url":"https://huggingface.co/QuixiAI","license_name":"Open Data Commons Attribution License v1.0","license_url":"https://scancode-licensedb.aboutcode.org/odc-by-1.0.html","language":"en","first_N":5,"first_N_keywords":["other","crowdsourced","expert-generated","machine-generated","multilingual"],"keywords_longer_than_N":true},
	{"name":"allenai_tulu-3-sft-mixture-DolphinLabeled","keyword":"najdi arabic","description":"\n\t\n\t\t\n\t\tallenai tulu-3-sft-mixture DolphinLabeled\n\t\n\n\n\t\n\t\t\n\t\tPart of the DolphinLabeled series of datasets\n\t\n\n\n\t\n\t\t\n\t\tPresented by Eric Hartford and Cognitive Computations\n\t\n\nThe purpose of this dataset is to enable filtering of allenai/tulu-3-sft-mixture dataset.\nThe original dataset is allenai/tulu-3-sft-mixture\nI have modified the dataset using two scripts.\n\ndedupe.py - removes rows with identical final message content\nlabel.py - adds a \"flags\" column containing the following booleanâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/QuixiAI/allenai_tulu-3-sft-mixture-DolphinLabeled.","url":"https://huggingface.co/datasets/QuixiAI/allenai_tulu-3-sft-mixture-DolphinLabeled","creator_name":"Quixi AI","creator_url":"https://huggingface.co/QuixiAI","license_name":"Open Data Commons Attribution License v1.0","license_url":"https://scancode-licensedb.aboutcode.org/odc-by-1.0.html","language":"en","first_N":5,"first_N_keywords":["other","crowdsourced","expert-generated","machine-generated","multilingual"],"keywords_longer_than_N":true},
	{"name":"allenai_tulu-3-sft-mixture-DolphinLabeled","keyword":"standard arabic","description":"\n\t\n\t\t\n\t\tallenai tulu-3-sft-mixture DolphinLabeled\n\t\n\n\n\t\n\t\t\n\t\tPart of the DolphinLabeled series of datasets\n\t\n\n\n\t\n\t\t\n\t\tPresented by Eric Hartford and Cognitive Computations\n\t\n\nThe purpose of this dataset is to enable filtering of allenai/tulu-3-sft-mixture dataset.\nThe original dataset is allenai/tulu-3-sft-mixture\nI have modified the dataset using two scripts.\n\ndedupe.py - removes rows with identical final message content\nlabel.py - adds a \"flags\" column containing the following booleanâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/QuixiAI/allenai_tulu-3-sft-mixture-DolphinLabeled.","url":"https://huggingface.co/datasets/QuixiAI/allenai_tulu-3-sft-mixture-DolphinLabeled","creator_name":"Quixi AI","creator_url":"https://huggingface.co/QuixiAI","license_name":"Open Data Commons Attribution License v1.0","license_url":"https://scancode-licensedb.aboutcode.org/odc-by-1.0.html","language":"en","first_N":5,"first_N_keywords":["other","crowdsourced","expert-generated","machine-generated","multilingual"],"keywords_longer_than_N":true},
	{"name":"allenai_tulu-3-sft-mixture-DolphinLabeled","keyword":"ta'izzi-adeni arabic","description":"\n\t\n\t\t\n\t\tallenai tulu-3-sft-mixture DolphinLabeled\n\t\n\n\n\t\n\t\t\n\t\tPart of the DolphinLabeled series of datasets\n\t\n\n\n\t\n\t\t\n\t\tPresented by Eric Hartford and Cognitive Computations\n\t\n\nThe purpose of this dataset is to enable filtering of allenai/tulu-3-sft-mixture dataset.\nThe original dataset is allenai/tulu-3-sft-mixture\nI have modified the dataset using two scripts.\n\ndedupe.py - removes rows with identical final message content\nlabel.py - adds a \"flags\" column containing the following booleanâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/QuixiAI/allenai_tulu-3-sft-mixture-DolphinLabeled.","url":"https://huggingface.co/datasets/QuixiAI/allenai_tulu-3-sft-mixture-DolphinLabeled","creator_name":"Quixi AI","creator_url":"https://huggingface.co/QuixiAI","license_name":"Open Data Commons Attribution License v1.0","license_url":"https://scancode-licensedb.aboutcode.org/odc-by-1.0.html","language":"en","first_N":5,"first_N_keywords":["other","crowdsourced","expert-generated","machine-generated","multilingual"],"keywords_longer_than_N":true},
	{"name":"xlel_wd_dictionary","keyword":"arabic","description":"XLEL-WD is a multilingual event linking dataset. This sub-dataset contains a dictionary of events from Wikidata. The multilingual descriptions for Wikidata event items are taken from the corresponding Wikipedia articles.","url":"https://huggingface.co/datasets/adithya7/xlel_wd_dictionary","creator_name":"Adithya Pratapa","creator_url":"https://huggingface.co/adithya7","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["found","found","multilingual","original","Afrikaans"],"keywords_longer_than_N":true},
	{"name":"seamless-align","keyword":"arabic","description":"\n\t\n\t\t\n\t\tDataset Card for Seamless-Align (WIP). Inspired by https://huggingface.co/datasets/allenai/nllb\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset was created based on metadata for mined Speech-to-Speech(S2S), Text-to-Speech(TTS) and Speech-to-Text(S2T) released by Meta AI.  The S2S contains data for 35 language pairs. The S2S dataset is ~1000GB compressed.\n\n\t\n\t\t\n\t\tHow to use the data\n\t\n\nThere are two ways to access the data:\n\nVia the Hugging Face Python datasets library\n\nScripts coming soonâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/jhu-clsp/seamless-align.","url":"https://huggingface.co/datasets/jhu-clsp/seamless-align","creator_name":"Center for Language and Speech Processing @ JHU","creator_url":"https://huggingface.co/jhu-clsp","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["translation","audio-to-audio","Maltese","English","Welsh"],"keywords_longer_than_N":true},
	{"name":"WEATHub","keyword":"arabic","description":"\n\n\n\n\n\t\n\t\t\n\t\tDataset Card for \"WEATHub\"\n\t\n\nThis dataset corresponds to the data described in the paper \"Global Voices, Local Biases: Socio-Cultural Prejudices across Languages\"\naccepted to EMNLP 2023.\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nWEATHub is a dataset containing 24 languages. It contains words organized into groups of (target1, target2, attribute1, attribute2)\nto measure the association target1:target2 :: attribute1:attribute2. For example target1 can be insects, target2 can be flowers. And weâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/iamshnoo/WEATHub.","url":"https://huggingface.co/datasets/iamshnoo/WEATHub","creator_name":"Anjishnu Mukherjee","creator_url":"https://huggingface.co/iamshnoo","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["Arabic","Bengali","Central Kurdish","Danish","German"],"keywords_longer_than_N":true},
	{"name":"Open-ended_Questions_dialectal_data","keyword":"arabic","description":"\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nA collection of open-ended questions that was provided to the data marathon competitors to populate KIND dataset. It was designed to elicit longer responses cultural and context-rich sentences. \nFor more details, please check the paper\nThe KIND Dataset: A Social Collaboration Approach for Nuanced Dialect Data Collection\n\n\t\n\t\t\n\t\tCitation Information\n\t\n\n@inproceedings{yamani-etal-2024-kind,\n    title = \"The {KIND} Dataset: A Social Collaboration Approach for Nuancedâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/KIND-Dataset/Open-ended_Questions_dialectal_data.","url":"https://huggingface.co/datasets/KIND-Dataset/Open-ended_Questions_dialectal_data","creator_name":"KIND","creator_url":"https://huggingface.co/KIND-Dataset","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["question-answering","Arabic","cc-by-4.0","< 1K","csv"],"keywords_longer_than_N":true},
	{"name":"ArzEn-MultiGenre","keyword":"arabic","description":"\n\t\n\t\t\n\t\tArzEn-MultiGenre: A Comprehensive Parallel Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nArzEn-MultiGenre is a distinctive parallel dataset that encompasses a diverse collection of Egyptian Arabic content. This collection includes song lyrics, novels, and TV show subtitles, all of which have been meticulously translated and aligned with their English counterparts. The dataset serves as an invaluable tool for various linguistic and computational applications.\nPublished: 28 December 2023Version: 3DOI:â€¦ See the full description on the dataset page: https://huggingface.co/datasets/HeshamHaroon/ArzEn-MultiGenre.","url":"https://huggingface.co/datasets/HeshamHaroon/ArzEn-MultiGenre","creator_name":"Hesham Haroon","creator_url":"https://huggingface.co/HeshamHaroon","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["translation","Arabic","English","cc-by-4.0","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"tulu-3-sft-mixture","keyword":"egyptian arabic","description":"\n\n\n\t\n\t\t\n\t\tTulu 3 SFT Mixture\n\t\n\nNote that this collection is licensed under ODC-BY-1.0 license; different licenses apply to subsets of the data. Some portions of the dataset are non-commercial. We present the mixture as a research artifact.\nThe Tulu 3 SFT mixture was used to train the Tulu 3 series of models.\nIt contains 939,344 samples from the following sets:\n\nCoCoNot (ODC-BY-1.0), 10,983 prompts (Brahman et al., 2024)\nFLAN v2 via ai2-adapt-dev/flan_v2_converted, 89,982 prompts (Longpre etâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/allenai/tulu-3-sft-mixture.","url":"https://huggingface.co/datasets/allenai/tulu-3-sft-mixture","creator_name":"Ai2","creator_url":"https://huggingface.co/allenai","license_name":"Open Data Commons Attribution License v1.0","license_url":"https://scancode-licensedb.aboutcode.org/odc-by-1.0.html","language":"en","first_N":5,"first_N_keywords":["other","crowdsourced","expert-generated","machine-generated","multilingual"],"keywords_longer_than_N":true},
	{"name":"tulu-3-sft-mixture","keyword":"levantine arabic","description":"\n\n\n\t\n\t\t\n\t\tTulu 3 SFT Mixture\n\t\n\nNote that this collection is licensed under ODC-BY-1.0 license; different licenses apply to subsets of the data. Some portions of the dataset are non-commercial. We present the mixture as a research artifact.\nThe Tulu 3 SFT mixture was used to train the Tulu 3 series of models.\nIt contains 939,344 samples from the following sets:\n\nCoCoNot (ODC-BY-1.0), 10,983 prompts (Brahman et al., 2024)\nFLAN v2 via ai2-adapt-dev/flan_v2_converted, 89,982 prompts (Longpre etâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/allenai/tulu-3-sft-mixture.","url":"https://huggingface.co/datasets/allenai/tulu-3-sft-mixture","creator_name":"Ai2","creator_url":"https://huggingface.co/allenai","license_name":"Open Data Commons Attribution License v1.0","license_url":"https://scancode-licensedb.aboutcode.org/odc-by-1.0.html","language":"en","first_N":5,"first_N_keywords":["other","crowdsourced","expert-generated","machine-generated","multilingual"],"keywords_longer_than_N":true},
	{"name":"tulu-3-sft-mixture","keyword":"moroccan arabic","description":"\n\n\n\t\n\t\t\n\t\tTulu 3 SFT Mixture\n\t\n\nNote that this collection is licensed under ODC-BY-1.0 license; different licenses apply to subsets of the data. Some portions of the dataset are non-commercial. We present the mixture as a research artifact.\nThe Tulu 3 SFT mixture was used to train the Tulu 3 series of models.\nIt contains 939,344 samples from the following sets:\n\nCoCoNot (ODC-BY-1.0), 10,983 prompts (Brahman et al., 2024)\nFLAN v2 via ai2-adapt-dev/flan_v2_converted, 89,982 prompts (Longpre etâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/allenai/tulu-3-sft-mixture.","url":"https://huggingface.co/datasets/allenai/tulu-3-sft-mixture","creator_name":"Ai2","creator_url":"https://huggingface.co/allenai","license_name":"Open Data Commons Attribution License v1.0","license_url":"https://scancode-licensedb.aboutcode.org/odc-by-1.0.html","language":"en","first_N":5,"first_N_keywords":["other","crowdsourced","expert-generated","machine-generated","multilingual"],"keywords_longer_than_N":true},
	{"name":"tulu-3-sft-mixture","keyword":"najdi arabic","description":"\n\n\n\t\n\t\t\n\t\tTulu 3 SFT Mixture\n\t\n\nNote that this collection is licensed under ODC-BY-1.0 license; different licenses apply to subsets of the data. Some portions of the dataset are non-commercial. We present the mixture as a research artifact.\nThe Tulu 3 SFT mixture was used to train the Tulu 3 series of models.\nIt contains 939,344 samples from the following sets:\n\nCoCoNot (ODC-BY-1.0), 10,983 prompts (Brahman et al., 2024)\nFLAN v2 via ai2-adapt-dev/flan_v2_converted, 89,982 prompts (Longpre etâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/allenai/tulu-3-sft-mixture.","url":"https://huggingface.co/datasets/allenai/tulu-3-sft-mixture","creator_name":"Ai2","creator_url":"https://huggingface.co/allenai","license_name":"Open Data Commons Attribution License v1.0","license_url":"https://scancode-licensedb.aboutcode.org/odc-by-1.0.html","language":"en","first_N":5,"first_N_keywords":["other","crowdsourced","expert-generated","machine-generated","multilingual"],"keywords_longer_than_N":true},
	{"name":"tulu-3-sft-mixture","keyword":"standard arabic","description":"\n\n\n\t\n\t\t\n\t\tTulu 3 SFT Mixture\n\t\n\nNote that this collection is licensed under ODC-BY-1.0 license; different licenses apply to subsets of the data. Some portions of the dataset are non-commercial. We present the mixture as a research artifact.\nThe Tulu 3 SFT mixture was used to train the Tulu 3 series of models.\nIt contains 939,344 samples from the following sets:\n\nCoCoNot (ODC-BY-1.0), 10,983 prompts (Brahman et al., 2024)\nFLAN v2 via ai2-adapt-dev/flan_v2_converted, 89,982 prompts (Longpre etâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/allenai/tulu-3-sft-mixture.","url":"https://huggingface.co/datasets/allenai/tulu-3-sft-mixture","creator_name":"Ai2","creator_url":"https://huggingface.co/allenai","license_name":"Open Data Commons Attribution License v1.0","license_url":"https://scancode-licensedb.aboutcode.org/odc-by-1.0.html","language":"en","first_N":5,"first_N_keywords":["other","crowdsourced","expert-generated","machine-generated","multilingual"],"keywords_longer_than_N":true},
	{"name":"tulu-3-sft-mixture","keyword":"ta'izzi-adeni arabic","description":"\n\n\n\t\n\t\t\n\t\tTulu 3 SFT Mixture\n\t\n\nNote that this collection is licensed under ODC-BY-1.0 license; different licenses apply to subsets of the data. Some portions of the dataset are non-commercial. We present the mixture as a research artifact.\nThe Tulu 3 SFT mixture was used to train the Tulu 3 series of models.\nIt contains 939,344 samples from the following sets:\n\nCoCoNot (ODC-BY-1.0), 10,983 prompts (Brahman et al., 2024)\nFLAN v2 via ai2-adapt-dev/flan_v2_converted, 89,982 prompts (Longpre etâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/allenai/tulu-3-sft-mixture.","url":"https://huggingface.co/datasets/allenai/tulu-3-sft-mixture","creator_name":"Ai2","creator_url":"https://huggingface.co/allenai","license_name":"Open Data Commons Attribution License v1.0","license_url":"https://scancode-licensedb.aboutcode.org/odc-by-1.0.html","language":"en","first_N":5,"first_N_keywords":["other","crowdsourced","expert-generated","machine-generated","multilingual"],"keywords_longer_than_N":true},
	{"name":"xP3megds","keyword":"arabic","description":"\n\t\n\t\t\n\t\tDataset Card for xP3\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\n\nxP3 (Crosslingual Public Pool of Prompts) is a collection of prompts & datasets across 46 of languages & 16 NLP tasks. It is used for the training of BLOOMZ and mT0, multilingual language models capable of following human instructions in dozens of languages zero-shot.\n\n\nCreation: The dataset can be recreated using instructions available here. We provide this version to save processing time and ease reproducibility.\nLanguages: 46 (Canâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/bigscience/xP3megds.","url":"https://huggingface.co/datasets/bigscience/xP3megds","creator_name":"BigScience Workshop","creator_url":"https://huggingface.co/bigscience","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":null,"first_N":5,"first_N_keywords":["other","expert-generated","crowdsourced","multilingual","Akan"],"keywords_longer_than_N":true},
	{"name":"Moroccan_Arabic_Wikipedia_20230101_bots","keyword":"arabic","description":"\n\t\n\t\t\n\t\tDataset Card for \"Moroccan_Arabic_Wikipedia_20230101_bots\"\n\t\n\nThis dataset is created using the Moroccan Arabic Wikipedia articles, downloaded on the 1st of January 2023, processed using Gensim Python library, and preprocessed using tr Linux/Unix utility and CAMeLTools Python toolkit for Arabic NLP. This dataset was used to train this Moroccan Arabic Wikipedia Masked Language Model: SaiedAlshahrani/arywiki_20230101_roberta_mlm_bots.\nFor more details about the dataset, please read andâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/SaiedAlshahrani/Moroccan_Arabic_Wikipedia_20230101_bots.","url":"https://huggingface.co/datasets/SaiedAlshahrani/Moroccan_Arabic_Wikipedia_20230101_bots","creator_name":"Saied Alshahrani","creator_url":"https://huggingface.co/SaiedAlshahrani","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["Arabic","mit","1K - 10K","parquet","Text"],"keywords_longer_than_N":true},
	{"name":"Moroccan_Arabic_Wikipedia_20230101_nobots","keyword":"arabic","description":"\n\t\n\t\t\n\t\tDataset Card for \"Moroccan_Arabic_Wikipedia_20230101_nobots\"\n\t\n\nThis dataset is created using the Moroccan Arabic Wikipedia articles (after removing bot-generated articles), downloaded on the 1st of January 2023, processed using Gensim Python library, and preprocessed using tr Linux/Unix utility and CAMeLTools Python toolkit for Arabic NLP. This dataset was used to train this Moroccan Arabic Wikipedia Masked Language Model: SaiedAlshahrani/arywiki_20230101_roberta_mlm_nobots.\nFor moreâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/SaiedAlshahrani/Moroccan_Arabic_Wikipedia_20230101_nobots.","url":"https://huggingface.co/datasets/SaiedAlshahrani/Moroccan_Arabic_Wikipedia_20230101_nobots","creator_name":"Saied Alshahrani","creator_url":"https://huggingface.co/SaiedAlshahrani","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["Arabic","mit","1K - 10K","parquet","Text"],"keywords_longer_than_N":true},
	{"name":"Arabic_Aya","keyword":"arabic","description":"\n\t\n\t\t\n\t\tDataset Card for : Arabic Aya (2A)\n\t\n\n\n\n\n\n\n\t\n\t\t\n\t\tArabic Aya (2A) : A Curated Subset of the Aya Collection for Arabic Language Processing\n\t\n\n\n\t\n\t\t\n\t\tDataset Sources & Infos\n\t\n\n\nData Origin: Derived from 69 subsets of the original Aya datasets : CohereForAI/aya_collection, CohereForAI/aya_dataset, and CohereForAI/aya_evaluation_suite.\nLanguages: Modern Standard Arabic (MSA) and a variety of Arabic dialects ( 'arb', 'arz', 'ary', 'ars', 'knc', 'acm', 'apc', 'aeb', 'ajp', 'acq' )â€¦ See the full description on the dataset page: https://huggingface.co/datasets/2A2I/Arabic_Aya.","url":"https://huggingface.co/datasets/2A2I/Arabic_Aya","creator_name":"2A2I","creator_url":"https://huggingface.co/2A2I","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","translation","summarization","Arabic","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"awesome_chatgpt_prompts_ar","keyword":"arabic","description":"\n\t\n\t\t\n\t\tðŸ“¦ Awesome Arabic Chatgpt Prompts\n\t\n\n\n  \n\n\n\n\t\n\t\t\n\t\tðŸ“ Overview\n\t\n\n\nThis repository contains a collection of Arabic prompts designed for use with AI language models (such as ChatGPT).  \nThe goal is to provide a lightweight dataset that helps Arabic-speaking users quickly get started with generative AI.\n\n\n\t\n\t\t\n\t\tðŸ”— Website / Demo\n\t\n\nCheck out the live demo site:omarnj-lab.github.io/awesome_chatgpt_prompts_ar\n\n\t\n\t\t\n\t\tâœ¨ Features\n\t\n\n\nEntirely in Arabic ðŸ•Œ  \nSuitable for educational andâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Omartificial-Intelligence-Space/awesome_chatgpt_prompts_ar.","url":"https://huggingface.co/datasets/Omartificial-Intelligence-Space/awesome_chatgpt_prompts_ar","creator_name":"Omartificial Intelligence Space","creator_url":"https://huggingface.co/Omartificial-Intelligence-Space","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","Arabic","apache-2.0","< 1K","json"],"keywords_longer_than_N":true},
	{"name":"awesome_chatgpt_prompts_ar","keyword":"arabic","description":"\n\t\n\t\t\n\t\tðŸ“¦ Awesome Arabic Chatgpt Prompts\n\t\n\n\n  \n\n\n\n\t\n\t\t\n\t\tðŸ“ Overview\n\t\n\n\nThis repository contains a collection of Arabic prompts designed for use with AI language models (such as ChatGPT).  \nThe goal is to provide a lightweight dataset that helps Arabic-speaking users quickly get started with generative AI.\n\n\n\t\n\t\t\n\t\tðŸ”— Website / Demo\n\t\n\nCheck out the live demo site:omarnj-lab.github.io/awesome_chatgpt_prompts_ar\n\n\t\n\t\t\n\t\tâœ¨ Features\n\t\n\n\nEntirely in Arabic ðŸ•Œ  \nSuitable for educational andâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Omartificial-Intelligence-Space/awesome_chatgpt_prompts_ar.","url":"https://huggingface.co/datasets/Omartificial-Intelligence-Space/awesome_chatgpt_prompts_ar","creator_name":"Omartificial Intelligence Space","creator_url":"https://huggingface.co/Omartificial-Intelligence-Space","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","Arabic","apache-2.0","< 1K","json"],"keywords_longer_than_N":true},
	{"name":"miracl-noauth","keyword":"arabic","description":"A clone of the excellent miracl/miracl dataset that doesn't require authentication. Refer to the original dataset for details.\n","url":"https://huggingface.co/datasets/macavaney/miracl-noauth","creator_name":"Sean MacAvaney","creator_url":"https://huggingface.co/macavaney","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":null,"first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","expert-generated","multilingual","miracl/miracl"],"keywords_longer_than_N":true},
	{"name":"c4","keyword":"arabic","description":"\n\t\n\t\t\n\t\tC4\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nA colossal, cleaned version of Common Crawl's web crawl corpus. Based on Common Crawl dataset: \"https://commoncrawl.org\".\nThis is the processed version of Google's C4 dataset\nWe prepared five variants of the data: en, en.noclean, en.noblocklist, realnewslike, and multilingual (mC4).\nFor reference, these are the sizes of the variants:\n\nen: 305GB\nen.noclean: 2.3TB\nen.noblocklist: 380GB\nrealnewslike: 15GB\nmultilingual (mC4): 9.7TB (108 subsets, one perâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/allenai/c4.","url":"https://huggingface.co/datasets/allenai/c4","creator_name":"Ai2","creator_url":"https://huggingface.co/allenai","license_name":"Open Data Commons Attribution License v1.0","license_url":"https://scancode-licensedb.aboutcode.org/odc-by-1.0.html","language":"en","first_N":5,"first_N_keywords":["text-generation","fill-mask","language-modeling","masked-language-modeling","no-annotation"],"keywords_longer_than_N":true},
	{"name":"ADMD","keyword":"arabic","description":"\n\t\n\t\t\n\t\tArabic Depth Mini Dataset (ADMD)\n\t\n\nThe Arabic Depth Mini Dataset (ADMD) is a compact yet highly challenging dataset designed to evaluate Arabic language models across diverse domains. It consists of 490 carefully curated questions spanning 10 major domains and 42 topics. The dataset is manually reviewed and emphasizes linguistic accuracy, cultural alignment, and methodological rigor.\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Overview\n\t\n\n\n\t\n\t\t\n\t\n\t\n\t\tCategories and Topics\n\t\n\nThe dataset covers 42 topicsâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/riotu-lab/ADMD.","url":"https://huggingface.co/datasets/riotu-lab/ADMD","creator_name":"Robotics and Interne-of-Things","creator_url":"https://huggingface.co/riotu-lab","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["Arabic","mit","< 1K","csv","Text"],"keywords_longer_than_N":true},
	{"name":"everyayah","keyword":"arabic","description":"ï·½\n\n\t\n\t\t\n\t\tDataset Card for Tarteel AI's EveryAyah Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset is a collection of Quranic verses and their transcriptions, with diacritization, by different reciters.\n\n\t\n\t\t\n\t\tSupported Tasks and Leaderboards\n\t\n\n[Needs More Information]\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nThe audio is in Arabic.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\n\t\n\t\t\n\t\tData Instances\n\t\n\nA typical data point comprises the audio file audio, and its transcription called text.\nThe duration is in seconds, and theâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/tarteel-ai/everyayah.","url":"https://huggingface.co/datasets/tarteel-ai/everyayah","creator_name":"Tarteel AI","creator_url":"https://huggingface.co/tarteel-ai","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","expert-generated","crowdsourced","monolingual","original"],"keywords_longer_than_N":true},
	{"name":"divemt_attributions","keyword":"arabic","description":"\n\t\n\t\t\n\t\tDataset Card for DivEMT Attributions\n\t\n\nFor more details on DivEMT, see our EMNLP 2022 Paper and our Github repository\n","url":"https://huggingface.co/datasets/inseq/divemt_attributions","creator_name":"Inseq","creator_url":"https://huggingface.co/inseq","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["translation","machine-generated","translation","Italian","Arabic"],"keywords_longer_than_N":true},
	{"name":"Arabic_Wikipedia_20230101_bots","keyword":"arabic","description":"\n\t\n\t\t\n\t\tDataset Card for \"Arabic_Wikipedia_20230101_bots\"\n\t\n\nThis dataset is created using the Arabic Wikipedia articles, downloaded on the 1st of January 2023, processed using Gensim Python library, and preprocessed using tr Linux/Unix utility and CAMeLTools Python toolkit for Arabic NLP. This dataset was used to train this Arabic Wikipedia Masked Language Model: SaiedAlshahrani/arwiki_20230101_roberta_mlm_bots.\nFor more details about the dataset, please read and cite our paper:â€¦ See the full description on the dataset page: https://huggingface.co/datasets/SaiedAlshahrani/Arabic_Wikipedia_20230101_bots.","url":"https://huggingface.co/datasets/SaiedAlshahrani/Arabic_Wikipedia_20230101_bots","creator_name":"Saied Alshahrani","creator_url":"https://huggingface.co/SaiedAlshahrani","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["Arabic","mit","1M - 10M","parquet","Text"],"keywords_longer_than_N":true},
	{"name":"Open-ArabicaQA","keyword":"arabic","description":"\n\t\n\t\t\n\t\tArabicaQA\n\t\n\nArabicaQA: Comprehensive Dataset for Arabic Question Answering\nThis repository contains dataset for paper ArabicaQA: Comprehensive Dataset for Arabic Question Answering. Below, we provide details regarding the materials available in this repository:\nArabicaQA is a robust dataset designed to support and advance the development of Arabic Question Answering (QA) systems. This dataset encompasses a wide range of question types, including both Machine Reading Comprehensionâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/abdoelsayed/Open-ArabicaQA.","url":"https://huggingface.co/datasets/abdoelsayed/Open-ArabicaQA","creator_name":"Abdelrahman Abdallah","creator_url":"https://huggingface.co/abdoelsayed","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["question-answering","crowdsourced","crowdsourced","found","Arabic"],"keywords_longer_than_N":true},
	{"name":"tydiqa_xtreme","keyword":"arabic","description":"TyDi QA is a question answering dataset covering 11 typologically diverse languages with 204K question-answer pairs.\nThe languages of TyDi QA are diverse with regard to their typology -- the set of linguistic features that each language\nexpresses -- such that we expect models performing well on this set to generalize across a large number of the languages\nin the world. It contains language phenomena that would not be found in English-only corpora. To provide a realistic\ninformation-seeking task and avoid priming effects, questions are written by people who want to know the answer, but\ndonâ€™t know the answer yet, (unlike SQuAD and its descendents) and the data is collected directly in each language without\nthe use of translation (unlike MLQA and XQuAD).\n\nWe also include \"translate-train\" and \"translate-test\" splits for each non-English languages from XTREME (Hu et al., 2020). These splits are the automatic translations from English to each target language used in the XTREME paper [https://arxiv.org/abs/2003.11080]. The \"translate-train\" split purposefully ignores the non-English TyDiQA-GoldP training data to simulate the transfer learning scenario where original-language data is not available and system builders must rely on labeled English data plus existing machine translation systems.","url":"https://huggingface.co/datasets/juletxara/tydiqa_xtreme","creator_name":"Julen Etxaniz","creator_url":"https://huggingface.co/juletxara","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":null,"first_N":5,"first_N_keywords":["question-answering","extractive-qa","crowdsourced","crowdsourced","multilingual"],"keywords_longer_than_N":true},
	{"name":"MMLU_Arabic","keyword":"arabic","description":"Arabic version of MMLU dataset translated by gpt-3.5-turbo.The dataset is used in the research related to MultilingualSIFT. \n","url":"https://huggingface.co/datasets/FreedomIntelligence/MMLU_Arabic","creator_name":"FreedomAI","creator_url":"https://huggingface.co/FreedomIntelligence","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["Arabic","mit","ðŸ‡ºðŸ‡¸ Region: US"],"keywords_longer_than_N":false},
	{"name":"udhr-lid","keyword":"standard arabic","description":"\n\t\n\t\t\n\t\tUDHR-LID\n\t\n\nWhy UDHR-LID?\nYou can access UDHR (Universal Declaration of Human Rights) here, but when a verse is missing, they have texts such as \"missing\" or \"?\". Also, about 1/3 of the sentences consist only of \"articles 1-30\" in different languages. We cleaned the entire dataset from XML files and selected only the paragraphs. We cleared any unrelated language texts from the data and also removed the cases that were incorrect.\nIncorrect? Look at the ckb and kmr files in the UDHR.â€¦ See the full description on the dataset page: https://huggingface.co/datasets/cis-lmu/udhr-lid.","url":"https://huggingface.co/datasets/cis-lmu/udhr-lid","creator_name":"CIS, LMU Munich","creator_url":"https://huggingface.co/cis-lmu","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["multilingual","Tigrinya","Balkan Romani","Standard Arabic","MetlatÃ³noc Mixtec"],"keywords_longer_than_N":true},
	{"name":"mqa","keyword":"arabic","description":"MQA is a multilingual corpus of questions and answers parsed from the Common Crawl. Questions are divided between Frequently Asked Questions (FAQ) pages and Community Question Answering (CQA) pages.","url":"https://huggingface.co/datasets/clips/mqa","creator_name":"CLiPS","creator_url":"https://huggingface.co/clips","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["question-answering","multiple-choice-qa","no-annotation","other","multilingual"],"keywords_longer_than_N":true},
	{"name":"CC-Cat","keyword":"arabic","description":"\n\t\n\t\t\n\t\tCC_Cat\n\t\n\n\nExtract from CC-WARC snapshots.\nMainly includes texts with 149 languages.\nPDF/IMAGE/AUDIO/VIDEO raw downloading link.\n\n\n\t\n\t\t\n\t\tNotice\n\t\n\n\nSince my computing resources are limited, this dataset will update by one-day of CC snapshots timestampts.\nAfter a snapshot is updated, the deduplicated version will be uploaded.\nIf you are interested in providing computing resources or have cooperation needs, please contact me.\n  carreyallthetime@gmail.com  \n      \n  \n\n","url":"https://huggingface.co/datasets/chengshidehaimianti/CC-Cat","creator_name":"zyq","creator_url":"https://huggingface.co/chengshidehaimianti","license_name":"Open Data Commons Attribution License v1.0","license_url":"https://scancode-licensedb.aboutcode.org/odc-by-1.0.html","language":"en","first_N":5,"first_N_keywords":["text-generation","Chinese","English","German","Russian"],"keywords_longer_than_N":true},
	{"name":"oasst2","keyword":"arabic","description":"\n\t\n\t\t\n\t\tOpen Assistant Conversations Dataset Release 2 (OASST2)\n\t\n\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nThis dataset contains message trees. Each message tree has an initial prompt message as the root node, \nwhich can have multiple child messages as replies, and these child messages can have multiple replies. \nAll messages have a role property: this can either be \"assistant\" or \"prompter\". The roles in \nconversation threads from prompt to leaf node strictly alternate between \"prompter\" andâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/OpenAssistant/oasst2.","url":"https://huggingface.co/datasets/OpenAssistant/oasst2","creator_name":"OpenAssistant","creator_url":"https://huggingface.co/OpenAssistant","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["English","Spanish","Russian","German","Polish"],"keywords_longer_than_N":true},
	{"name":"islamic-qa-egyptian-arabic","keyword":"arabic","description":"\n\t\n\t\t\n\t\tEgyptian Arabic Islamic QA Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset contains 7,465 question-answer pairs in Egyptian Arabic covering comprehensive Islamic studies topics. The dataset serves as a valuable resource for developing Arabic NLP models focused on Islamic education and religious knowledge.\n\n\t\n\t\t\n\t\tKey Features\n\t\n\n\nLanguage: Egyptian Arabic (Ø§Ù„Ø¹Ø§Ù…ÙŠØ© Ø§Ù„Ù…ØµØ±ÙŠØ©)\nDomain: Islamic Studies\nSize: 7,465 examples\nFormat: Question-Answer pairs with topic categorizationâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Omar-youssef/islamic-qa-egyptian-arabic.","url":"https://huggingface.co/datasets/Omar-youssef/islamic-qa-egyptian-arabic","creator_name":"Omar Youssef","creator_url":"https://huggingface.co/Omar-youssef","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["question-answering","Arabic","apache-2.0","1K - 10K","parquet"],"keywords_longer_than_N":true},
	{"name":"fleurs","keyword":"arabic","description":"\n\t\n\t\t\n\t\tFLEURS\n\t\n\nFleurs is the speech version of the FLoRes machine translation benchmark. \nWe use 2009 n-way parallel sentences from the FLoRes dev and devtest publicly available sets, in 102 languages. \nTraining sets have around 10 hours of supervision. Speakers of the train sets are different than speakers from the dev/test sets. Multilingual fine-tuning is\nused and â€unit error rateâ€ (characters, signs) of all languages is averaged. Languages and results are also grouped into sevenâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/google/fleurs.","url":"https://huggingface.co/datasets/google/fleurs","creator_name":"Google","creator_url":"https://huggingface.co/google","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":null,"first_N":5,"first_N_keywords":["automatic-speech-recognition","expert-generated","crowdsourced","machine-generated","crowdsourced"],"keywords_longer_than_N":true},
	{"name":"ans-stance","keyword":"arabic","description":"The dataset is a collection of news titles in arabic along with paraphrased and corrupted titles. The stance prediction version is a 3-class classification task. Data contains three columns: s1, s2, stance.","url":"https://huggingface.co/datasets/strombergnlp/ans-stance","creator_name":"StrÃ¸mberg NLP","creator_url":"https://huggingface.co/strombergnlp","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":null,"first_N":5,"first_N_keywords":["text-classification","fact-checking","crowdsourced","found","monolingual"],"keywords_longer_than_N":true},
	{"name":"tapaco","keyword":"arabic","description":"\n\t\n\t\t\n\t\tDataset Card for TaPaCo Corpus\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nA freely available paraphrase corpus for 73 languages extracted from the Tatoeba database. \nTatoeba is a crowdsourcing project mainly geared towards language learners. Its aim is to provide example sentences \nand translations for particular linguistic constructions and words. The paraphrase corpus is created by populating a \ngraph with Tatoeba sentences and equivalence links between sentences â€œmeaning the same thingâ€. Thisâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/community-datasets/tapaco.","url":"https://huggingface.co/datasets/community-datasets/tapaco","creator_name":"Community Datasets","creator_url":"https://huggingface.co/community-datasets","license_name":"Creative Commons Attribution 2.0","license_url":"https://scancode-licensedb.aboutcode.org/cc-by-2.0.html","language":"en","first_N":5,"first_N_keywords":["translation","text-classification","semantic-similarity-classification","machine-generated","crowdsourced"],"keywords_longer_than_N":true},
	{"name":"mkqa","keyword":"arabic","description":"We introduce MKQA, an open-domain question answering evaluation set comprising 10k question-answer pairs sampled from the Google Natural Questions dataset, aligned across 26 typologically diverse languages (260k question-answer pairs in total). For each query we collected new passage-independent answers. These queries and answers were then human translated into 25 Non-English languages.","url":"https://huggingface.co/datasets/apple/mkqa","creator_name":"Apple","creator_url":"https://huggingface.co/apple","license_name":"Creative Commons Attribution 3.0","license_url":"https://scancode-licensedb.aboutcode.org/cc-by-3.0.html","language":null,"first_N":5,"first_N_keywords":["question-answering","open-domain-qa","crowdsourced","found","multilingual"],"keywords_longer_than_N":true},
	{"name":"africlirmatrix","keyword":"egyptian arabic","description":"\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nAfriCLIRMatrix is a test collection for cross-lingual information retrieval research in 15 diverse African languages. This resource comprises English queries with queryâ€“document relevance judgments in 15 African languages automatically mined from Wikipedia\nThis dataset stores documents of AfriCLIRMatrix. To access the queries and judgments, please refer to castorini/africlirmatrix.\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Structure\n\t\n\nThe only configuration here is the language.\nAnâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/castorini/africlirmatrix.","url":"https://huggingface.co/datasets/castorini/africlirmatrix","creator_name":"Castorini","creator_url":"https://huggingface.co/castorini","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","multilingual","Afrikaans","Amharic","Egyptian Arabic"],"keywords_longer_than_N":true},
	{"name":"africlirmatrix","keyword":"moroccan arabic","description":"\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nAfriCLIRMatrix is a test collection for cross-lingual information retrieval research in 15 diverse African languages. This resource comprises English queries with queryâ€“document relevance judgments in 15 African languages automatically mined from Wikipedia\nThis dataset stores documents of AfriCLIRMatrix. To access the queries and judgments, please refer to castorini/africlirmatrix.\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Structure\n\t\n\nThe only configuration here is the language.\nAnâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/castorini/africlirmatrix.","url":"https://huggingface.co/datasets/castorini/africlirmatrix","creator_name":"Castorini","creator_url":"https://huggingface.co/castorini","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","multilingual","Afrikaans","Amharic","Egyptian Arabic"],"keywords_longer_than_N":true},
	{"name":"financial_news","keyword":"arabic","description":"asas-ai/financial_news dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/asas-ai/financial_news","creator_name":"ASAS AI","creator_url":"https://huggingface.co/asas-ai","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["translation","Arabic","English","apache-2.0","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"surface_realisation_st_2020","keyword":"arabic","description":"\n\t\n\t\t\n\t\tDataset Card for GEM/surface_realisation_st_2020\n\t\n\n\n\t\n\t\t\n\t\tLink to Main Data Card\n\t\n\nYou can find the main data card on the GEM Website.\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset was used as part of the multilingual surface realization shared task in which a model gets full or partial universal dependency structures and has to reconstruct the natural language. This dataset support 11 languages. \nYou can load the dataset via:\nimport datasets\ndata =â€¦ See the full description on the dataset page: https://huggingface.co/datasets/GEM/surface_realisation_st_2020.","url":"https://huggingface.co/datasets/GEM/surface_realisation_st_2020","creator_name":"GEM benchmark","creator_url":"https://huggingface.co/GEM","license_name":"Creative Commons Attribution 2.5","license_url":"https://scancode-licensedb.aboutcode.org/cc-by-2.5.html","language":"en","first_N":5,"first_N_keywords":["table-to-text","none","unknown","unknown","original"],"keywords_longer_than_N":true},
	{"name":"MatrixMB","keyword":"arabic","description":"MatrixMB/MatrixMB dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/MatrixMB/MatrixMB","creator_name":"Muaaz Bdear","creator_url":"https://huggingface.co/MatrixMB","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["Arabic","apache-2.0","n<1K","Text","ðŸ‡ºðŸ‡¸ Region: US"],"keywords_longer_than_N":true},
	{"name":"ml_spoken_words","keyword":"arabic","description":"Multilingual Spoken Words Corpus is a large and growing audio dataset of spoken\nwords in 50 languages collectively spoken by over 5 billion people, for academic\nresearch and commercial applications in keyword spotting and spoken term search,\nlicensed under CC-BY 4.0. The dataset contains more than 340,000 keywords,\ntotaling 23.4 million 1-second spoken examples (over 6,000 hours). The dataset\nhas many use cases, ranging from voice-enabled consumer devices to call center\nautomation. This dataset is generated by applying forced alignment on crowd-sourced sentence-level\naudio to produce per-word timing estimates for extraction.\nAll alignments are included in the dataset.","url":"https://huggingface.co/datasets/MLCommons/ml_spoken_words","creator_name":"MLCommons","creator_url":"https://huggingface.co/MLCommons","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":null,"first_N":5,"first_N_keywords":["audio-classification","machine-generated","other","multilingual","extended|common_voice"],"keywords_longer_than_N":true},
	{"name":"mqnli","keyword":"arabic","description":"SachinPatel248/mqnli dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/SachinPatel248/mqnli","creator_name":"Patel","creator_url":"https://huggingface.co/SachinPatel248","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","English","German","Spanish","Arabic"],"keywords_longer_than_N":true},
	{"name":"openassistant-llama-style","keyword":"arabic","description":"\n\t\n\t\t\n\t\tChat Fine-tuning Dataset - Llama 2 Style\n\t\n\nThis dataset allows for fine-tuning chat models using [INST] AND [/INST] to wrap user messages.\nPreparation:\n\nThe dataset is cloned from TimDettmers, which itself is a subset of the Open Assistant dataset, which you can find here. This subset of the data only contains the highest-rated paths in the conversation tree, with a total of 9,846 samples.\nThe dataset was then filtered to:\n\n\nreplace instances of '### Human:' with '[INST]'\nreplaceâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Trelis/openassistant-llama-style.","url":"https://huggingface.co/datasets/Trelis/openassistant-llama-style","creator_name":"Trelis","creator_url":"https://huggingface.co/Trelis","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["English","Spanish","Russian","German","Polish"],"keywords_longer_than_N":true},
	{"name":"rendered_xnli","keyword":"arabic","description":"   \n\n\t\n\t\t\n\t\tDataset Card for rendered XNLI\n\t\n\n\nThis repository contains the rendered XNLI dataset evaluated in the paper Autoregressive Pre-Training on Pixels and Texts (EMNLP 2024). For detailed instructions on how to use the model, please visit our GitHub page.\n\n\t\n\t\t\n\t\tCitation\n\t\n\n@misc{chai2024autoregressivepretrainingpixelstexts,\n  title = {Autoregressive Pre-Training on Pixels and Texts},\n  author = {Chai, Yekun and Liu, Qingyi and Xiao, Jingwu and Wang, Shuohuan and Sun, Yu and Wu, Hua}â€¦ See the full description on the dataset page: https://huggingface.co/datasets/ernie-research/rendered_xnli.","url":"https://huggingface.co/datasets/ernie-research/rendered_xnli","creator_name":"ernie-research","creator_url":"https://huggingface.co/ernie-research","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["English","Japanese","Chinese","French","Russian"],"keywords_longer_than_N":true},
	{"name":"Tunisian_Language_Dataset","keyword":"arabic","description":"\n\t\n\t\t\n\t\tDataset Card for Tunisian Text Compilation\n\t\n\nThis dataset is a curated compilation of various Tunisian datasets, aimed at gathering as much Tunisian text data as possible in one place. It combines multiple sources of Tunisian language data, providing a rich resource for research, development of NLP models, and linguistic studies on Tunisian text.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset aggregates several publicly available datasets that contain Tunisianâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/AzizBelaweid/Tunisian_Language_Dataset.","url":"https://huggingface.co/datasets/AzizBelaweid/Tunisian_Language_Dataset","creator_name":"Aziz Belaweid","creator_url":"https://huggingface.co/AzizBelaweid","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","Arabic","French","English","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"English-Egyptian-Translation-finance","keyword":"arabic","description":"\n\t\n\t\t\n\t\tBilingual Egyptian Finance Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset contains bilingual text pairs in English and Egyptian Arabic focused on finance and financial topics. Each entry provides parallel translations covering various aspects of Egyptian and regional economics, making it valuable for translation models, multilingual NLP research, and economic analysis applications.\n\n\t\n\t\t\n\t\tKey Features\n\t\n\n\nLanguages: English â†” Egyptian Arabic (Ø§Ù„Ø¹Ø§Ù…ÙŠØ© Ø§Ù„Ù…ØµØ±ÙŠØ©)\nDomain: Economicsâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Omar-youssef/English-Egyptian-Translation-finance.","url":"https://huggingface.co/datasets/Omar-youssef/English-Egyptian-Translation-finance","creator_name":"Omar Youssef","creator_url":"https://huggingface.co/Omar-youssef","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["translation","text-generation","question-answering","Arabic","English"],"keywords_longer_than_N":true},
	{"name":"amazon_massive_intent","keyword":"arabic","description":"\n  MassiveIntentClassification\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nMASSIVE: A 1M-Example Multilingual Natural Language Understanding Dataset with 51 Typologically-Diverse Languages\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2c\n\n\nDomains\nSpoken\n\n\nReference\nhttps://arxiv.org/abs/2204.08582\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask = mteb.get_tasks([\"MassiveIntentClassification\"])\nevaluator =â€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/amazon_massive_intent.","url":"https://huggingface.co/datasets/mteb/amazon_massive_intent","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","human-annotated","translated","Afrikaans","Amharic"],"keywords_longer_than_N":true},
	{"name":"arabic_speech_corpus","keyword":"arabic","description":"\n\t\n\t\t\n\t\tDataset Card for Arabic Speech Corpus\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis Speech corpus has been developed as part of PhD work carried out by Nawar Halabi at the University of Southampton. The corpus was recorded in south Levantine Arabic (Damascian accent) using a professional studio. Synthesized speech as an output using this corpus has produced a high quality, natural voice.\n\n\t\n\t\t\n\t\tSupported Tasks and Leaderboards\n\t\n\n[Needs More Information]\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nThe audio is inâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/tunis-ai/arabic_speech_corpus.","url":"https://huggingface.co/datasets/tunis-ai/arabic_speech_corpus","creator_name":"Tunisia.AI","creator_url":"https://huggingface.co/tunis-ai","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","expert-generated","crowdsourced","monolingual","original"],"keywords_longer_than_N":true},
	{"name":"Misraj-DocOCR","keyword":"arabic","description":"\n\t\n\t\t\n\t\tMisraj-DocOCR: An Arabic Document OCR BenchmarkðŸ“„\n\t\n\nDataset: Misraj/Misraj-DocOCR\nDomain: Arabic Document OCR (text + structure)Size: 400 expertly verified pages (real + synthetic)Use cases: OCR, Document Understanding, Markdown/HTML structure preservationStatus: Public ðŸ¤\n\n\t\n\t\t\n\t\n\t\n\t\tâœ¨ Overview\n\t\n\nMisraj-DocOCR is a curated, expert-verified benchmark for Arabic document OCR with an emphasis on structure preservation (Markdown/HTML tables, lists, footnotes, math, watermarksâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Misraj/Misraj-DocOCR.","url":"https://huggingface.co/datasets/Misraj/Misraj-DocOCR","creator_name":"Misraj Ai","creator_url":"https://huggingface.co/Misraj","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["apache-2.0","< 1K","parquet","Image","Text"],"keywords_longer_than_N":true},
	{"name":"arabic-english-code-switching-text","keyword":"arabic","description":"\n\t\n\t\t\n\t\tArabic-English Code-Switching Dataset (Text Only)\n\t\n\nThis dataset is a text-only version of Arabic-English Code-Switching Dataset dataset,\ncreated by this notebook.\n\n\t\n\t\t\n\t\tChanges Made\n\t\n\n\nExtracted only the text column from the original dataset.\n\n\n\t\n\t\t\n\t\tUsage\n\t\n\nfrom datasets import load_dataset\ndataset = load_dataset(\"MagedSaeed/arabic-english-code-switching-text\")\n\n\n\t\n\t\t\n\t\tCitation\n\t\n\nPlease reference/cite the original dataset when using this data.\n","url":"https://huggingface.co/datasets/MagedSaeed/arabic-english-code-switching-text","creator_name":"Maged Saeed","creator_url":"https://huggingface.co/MagedSaeed","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-generation","text-classification","multilingual","MohamedRashad/arabic-english-code-switching","Arabic"],"keywords_longer_than_N":true},
	{"name":"arabic-english-code-switching-text","keyword":"arabic","description":"\n\t\n\t\t\n\t\tArabic-English Code-Switching Dataset (Text Only)\n\t\n\nThis dataset is a text-only version of Arabic-English Code-Switching Dataset dataset,\ncreated by this notebook.\n\n\t\n\t\t\n\t\tChanges Made\n\t\n\n\nExtracted only the text column from the original dataset.\n\n\n\t\n\t\t\n\t\tUsage\n\t\n\nfrom datasets import load_dataset\ndataset = load_dataset(\"MagedSaeed/arabic-english-code-switching-text\")\n\n\n\t\n\t\t\n\t\tCitation\n\t\n\nPlease reference/cite the original dataset when using this data.\n","url":"https://huggingface.co/datasets/MagedSaeed/arabic-english-code-switching-text","creator_name":"Maged Saeed","creator_url":"https://huggingface.co/MagedSaeed","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-generation","text-classification","multilingual","MohamedRashad/arabic-english-code-switching","Arabic"],"keywords_longer_than_N":true},
	{"name":"ARABIC-RAW-TEXT","keyword":"arabic","description":"Dataset: \n\nAluka 1.4 GB\nAraWiki 3.9 GB\nAya 22.5 GB\nIslamic Books 21.4 GB\n\n","url":"https://huggingface.co/datasets/riotu-lab/ARABIC-RAW-TEXT","creator_name":"Robotics and Interne-of-Things","creator_url":"https://huggingface.co/riotu-lab","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","Arabic","apache-2.0","100M - 1B","text"],"keywords_longer_than_N":true},
	{"name":"BenchMAX_Model-based","keyword":"arabic","description":"\n\t\n\t\t\n\t\tDataset Sources\n\t\n\n\nPaper: BenchMAX: A Comprehensive Multilingual Evaluation Suite for Large Language Models\nLink: https://huggingface.co/papers/2502.07346\nRepository: https://github.com/CONE-MT/BenchMAX\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nBenchMAX_Model-based is a dataset of BenchMAX, sourcing from m-ArenaHard, which evaluates the instruction following capability via model-based judgment.\nWe extend the original dataset to include languages that are not supported by m-ArenaHard throughâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/LLaMAX/BenchMAX_Model-based.","url":"https://huggingface.co/datasets/LLaMAX/BenchMAX_Model-based","creator_name":"LLaMAX","creator_url":"https://huggingface.co/LLaMAX","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","multilingual","English","Chinese","Spanish"],"keywords_longer_than_N":true},
	{"name":"CNTXTAI_Legal_Legislation","keyword":"arabic","description":"This dataset is highly valuable for a wide range of users. Legal researchers and scholars can utilize it to analyze legislative trends and domain-specific developments in the UAE, particularly in administrative and religious affairs. Policy makers and government analysts will find it useful for tracking regulatory changes, assessing sectoral focus, and evaluating recent legal reforms. Law firms and legal consultants can leverage the structured data for efficient case study analysis andâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/CNTXTAI0/CNTXTAI_Legal_Legislation.","url":"https://huggingface.co/datasets/CNTXTAI0/CNTXTAI_Legal_Legislation","creator_name":"CNTXT AI","creator_url":"https://huggingface.co/CNTXTAI0","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":null,"first_N":5,"first_N_keywords":["text-classification","token-classification","feature-extraction","Arabic","English"],"keywords_longer_than_N":true},
	{"name":"Ar-MUSA","keyword":"arabic","description":"\n\t\n\t\t\n\t\tData Directory Structure\n\t\n\nThe Ar-MUSA directory contains annotated datasets organized by batches and annotation teams. Each batch is labeled with a number, and the annotation team is indicated by a letter. The structure is as follows:\nAr-MUSA\nâ”œâ”€â”€ Annotation 1a\nâ”‚   â”œâ”€â”€ frames        # Contains the extracted frames for each record\nâ”‚   â”œâ”€â”€ audios        # Contains the corresponding audio files\nâ”‚   â”œâ”€â”€ transcripts   # Contains the transcripts of the audio files\nâ”‚   â””â”€â”€ annotations.csv  #â€¦ See the full description on the dataset page: https://huggingface.co/datasets/Skhaled/Ar-MUSA.","url":"https://huggingface.co/datasets/Skhaled/Ar-MUSA","creator_name":"Salma Khaled Ali","creator_url":"https://huggingface.co/Skhaled","license_name":"Academic Free License v3.0","license_url":"https://choosealicense.com/licenses/afl-3.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","audio-classification","image-classification","Arabic","afl-3.0"],"keywords_longer_than_N":true},
	{"name":"Ar-MUSA","keyword":"arabic","description":"\n\t\n\t\t\n\t\tData Directory Structure\n\t\n\nThe Ar-MUSA directory contains annotated datasets organized by batches and annotation teams. Each batch is labeled with a number, and the annotation team is indicated by a letter. The structure is as follows:\nAr-MUSA\nâ”œâ”€â”€ Annotation 1a\nâ”‚   â”œâ”€â”€ frames        # Contains the extracted frames for each record\nâ”‚   â”œâ”€â”€ audios        # Contains the corresponding audio files\nâ”‚   â”œâ”€â”€ transcripts   # Contains the transcripts of the audio files\nâ”‚   â””â”€â”€ annotations.csv  #â€¦ See the full description on the dataset page: https://huggingface.co/datasets/Skhaled/Ar-MUSA.","url":"https://huggingface.co/datasets/Skhaled/Ar-MUSA","creator_name":"Salma Khaled Ali","creator_url":"https://huggingface.co/Skhaled","license_name":"Academic Free License v3.0","license_url":"https://choosealicense.com/licenses/afl-3.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","audio-classification","image-classification","Arabic","afl-3.0"],"keywords_longer_than_N":true},
	{"name":"finepdfs","keyword":"egyptian arabic","description":"\n\nLiberating 3T of the finest tokens from PDFs\n\n\n\t\n\t\t\n\t\tWhat is this?\n\t\n\nAs we run out of web pages to process, the natural question has always been: what to do next? Only a few knew about a data source that everyone avoided for ages, due to its incredible extraction cost and complexity: PDFs.\nðŸ“„ FinePDFs is exactly that. It is the largest publicly available corpus sourced exclusively from PDFs, containing about 3 trillion tokens across 475 million documents in 1733 languages.\nCompared to HTMLâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/HuggingFaceFW/finepdfs.","url":"https://huggingface.co/datasets/HuggingFaceFW/finepdfs","creator_name":"FineData","creator_url":"https://huggingface.co/HuggingFaceFW","license_name":"Open Data Commons Attribution License v1.0","license_url":"https://scancode-licensedb.aboutcode.org/odc-by-1.0.html","language":"en","first_N":5,"first_N_keywords":["text-generation","Arifama-Miniafia","Ankave","Abau","Amarasi"],"keywords_longer_than_N":true},
	{"name":"arabic-reasoning-dataset-logic","keyword":"arabic","description":"\n\t\n\t\t\n\t\tArabic Logical Reasoning Tasks Dataset (Maximum 1000 Tasks)\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset comprises a series of logical reasoning tasks designed to evaluate and train artificial intelligence models on understanding and generating logical inferences in the Arabic language. Each task includes a unique identifier, the task type, the task text (a question and a proposed answer), and a detailed solution that outlines the thinking steps and the final answer.\n\n\t\n\t\t\n\t\tData Format\n\t\n\nTheâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/beetleware/arabic-reasoning-dataset-logic.","url":"https://huggingface.co/datasets/beetleware/arabic-reasoning-dataset-logic","creator_name":"beetleware","creator_url":"https://huggingface.co/beetleware","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["Arabic","mit","1K - 10K","json","Text"],"keywords_longer_than_N":true},
	{"name":"arabic-reasoning-dataset-logic","keyword":"arabic","description":"\n\t\n\t\t\n\t\tArabic Logical Reasoning Tasks Dataset (Maximum 1000 Tasks)\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset comprises a series of logical reasoning tasks designed to evaluate and train artificial intelligence models on understanding and generating logical inferences in the Arabic language. Each task includes a unique identifier, the task type, the task text (a question and a proposed answer), and a detailed solution that outlines the thinking steps and the final answer.\n\n\t\n\t\t\n\t\tData Format\n\t\n\nTheâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/beetleware/arabic-reasoning-dataset-logic.","url":"https://huggingface.co/datasets/beetleware/arabic-reasoning-dataset-logic","creator_name":"beetleware","creator_url":"https://huggingface.co/beetleware","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["Arabic","mit","1K - 10K","json","Text"],"keywords_longer_than_N":true},
	{"name":"finepdfs","keyword":"levantine arabic","description":"\n\nLiberating 3T of the finest tokens from PDFs\n\n\n\t\n\t\t\n\t\tWhat is this?\n\t\n\nAs we run out of web pages to process, the natural question has always been: what to do next? Only a few knew about a data source that everyone avoided for ages, due to its incredible extraction cost and complexity: PDFs.\nðŸ“„ FinePDFs is exactly that. It is the largest publicly available corpus sourced exclusively from PDFs, containing about 3 trillion tokens across 475 million documents in 1733 languages.\nCompared to HTMLâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/HuggingFaceFW/finepdfs.","url":"https://huggingface.co/datasets/HuggingFaceFW/finepdfs","creator_name":"FineData","creator_url":"https://huggingface.co/HuggingFaceFW","license_name":"Open Data Commons Attribution License v1.0","license_url":"https://scancode-licensedb.aboutcode.org/odc-by-1.0.html","language":"en","first_N":5,"first_N_keywords":["text-generation","Arifama-Miniafia","Ankave","Abau","Amarasi"],"keywords_longer_than_N":true},
	{"name":"finepdfs","keyword":"mesopotamian arabic","description":"\n\nLiberating 3T of the finest tokens from PDFs\n\n\n\t\n\t\t\n\t\tWhat is this?\n\t\n\nAs we run out of web pages to process, the natural question has always been: what to do next? Only a few knew about a data source that everyone avoided for ages, due to its incredible extraction cost and complexity: PDFs.\nðŸ“„ FinePDFs is exactly that. It is the largest publicly available corpus sourced exclusively from PDFs, containing about 3 trillion tokens across 475 million documents in 1733 languages.\nCompared to HTMLâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/HuggingFaceFW/finepdfs.","url":"https://huggingface.co/datasets/HuggingFaceFW/finepdfs","creator_name":"FineData","creator_url":"https://huggingface.co/HuggingFaceFW","license_name":"Open Data Commons Attribution License v1.0","license_url":"https://scancode-licensedb.aboutcode.org/odc-by-1.0.html","language":"en","first_N":5,"first_N_keywords":["text-generation","Arifama-Miniafia","Ankave","Abau","Amarasi"],"keywords_longer_than_N":true},
	{"name":"finepdfs","keyword":"moroccan arabic","description":"\n\nLiberating 3T of the finest tokens from PDFs\n\n\n\t\n\t\t\n\t\tWhat is this?\n\t\n\nAs we run out of web pages to process, the natural question has always been: what to do next? Only a few knew about a data source that everyone avoided for ages, due to its incredible extraction cost and complexity: PDFs.\nðŸ“„ FinePDFs is exactly that. It is the largest publicly available corpus sourced exclusively from PDFs, containing about 3 trillion tokens across 475 million documents in 1733 languages.\nCompared to HTMLâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/HuggingFaceFW/finepdfs.","url":"https://huggingface.co/datasets/HuggingFaceFW/finepdfs","creator_name":"FineData","creator_url":"https://huggingface.co/HuggingFaceFW","license_name":"Open Data Commons Attribution License v1.0","license_url":"https://scancode-licensedb.aboutcode.org/odc-by-1.0.html","language":"en","first_N":5,"first_N_keywords":["text-generation","Arifama-Miniafia","Ankave","Abau","Amarasi"],"keywords_longer_than_N":true},
	{"name":"finepdfs","keyword":"najdi arabic","description":"\n\nLiberating 3T of the finest tokens from PDFs\n\n\n\t\n\t\t\n\t\tWhat is this?\n\t\n\nAs we run out of web pages to process, the natural question has always been: what to do next? Only a few knew about a data source that everyone avoided for ages, due to its incredible extraction cost and complexity: PDFs.\nðŸ“„ FinePDFs is exactly that. It is the largest publicly available corpus sourced exclusively from PDFs, containing about 3 trillion tokens across 475 million documents in 1733 languages.\nCompared to HTMLâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/HuggingFaceFW/finepdfs.","url":"https://huggingface.co/datasets/HuggingFaceFW/finepdfs","creator_name":"FineData","creator_url":"https://huggingface.co/HuggingFaceFW","license_name":"Open Data Commons Attribution License v1.0","license_url":"https://scancode-licensedb.aboutcode.org/odc-by-1.0.html","language":"en","first_N":5,"first_N_keywords":["text-generation","Arifama-Miniafia","Ankave","Abau","Amarasi"],"keywords_longer_than_N":true},
	{"name":"finepdfs","keyword":"standard arabic","description":"\n\nLiberating 3T of the finest tokens from PDFs\n\n\n\t\n\t\t\n\t\tWhat is this?\n\t\n\nAs we run out of web pages to process, the natural question has always been: what to do next? Only a few knew about a data source that everyone avoided for ages, due to its incredible extraction cost and complexity: PDFs.\nðŸ“„ FinePDFs is exactly that. It is the largest publicly available corpus sourced exclusively from PDFs, containing about 3 trillion tokens across 475 million documents in 1733 languages.\nCompared to HTMLâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/HuggingFaceFW/finepdfs.","url":"https://huggingface.co/datasets/HuggingFaceFW/finepdfs","creator_name":"FineData","creator_url":"https://huggingface.co/HuggingFaceFW","license_name":"Open Data Commons Attribution License v1.0","license_url":"https://scancode-licensedb.aboutcode.org/odc-by-1.0.html","language":"en","first_N":5,"first_N_keywords":["text-generation","Arifama-Miniafia","Ankave","Abau","Amarasi"],"keywords_longer_than_N":true},
	{"name":"finepdfs","keyword":"tunisian arabic","description":"\n\nLiberating 3T of the finest tokens from PDFs\n\n\n\t\n\t\t\n\t\tWhat is this?\n\t\n\nAs we run out of web pages to process, the natural question has always been: what to do next? Only a few knew about a data source that everyone avoided for ages, due to its incredible extraction cost and complexity: PDFs.\nðŸ“„ FinePDFs is exactly that. It is the largest publicly available corpus sourced exclusively from PDFs, containing about 3 trillion tokens across 475 million documents in 1733 languages.\nCompared to HTMLâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/HuggingFaceFW/finepdfs.","url":"https://huggingface.co/datasets/HuggingFaceFW/finepdfs","creator_name":"FineData","creator_url":"https://huggingface.co/HuggingFaceFW","license_name":"Open Data Commons Attribution License v1.0","license_url":"https://scancode-licensedb.aboutcode.org/odc-by-1.0.html","language":"en","first_N":5,"first_N_keywords":["text-generation","Arifama-Miniafia","Ankave","Abau","Amarasi"],"keywords_longer_than_N":true},
	{"name":"hadith_datasets","keyword":"arabic","description":"\n\t\n\t\t\n\t\tSunnah Dataset â€” Hadith JSON & CSV Collection\n\t\n\nA blessed and open-source collection of authenticated Hadiths from the six major books of Sunnah, available in both JSON and CSV formats for research, study, and teaching purposes. This dataset is structured cleanly with English + Arabic + grading + reference links for each Hadith.\n\n\n\t\n\t\t\n\t\tContents\n\t\n\nThis dataset contains the following Hadith collections:\n\n\t\n\t\t\nFile Name\nFormat\nBook Name\n\n\n\t\t\nJami' at-Tirmidhi.csv\nCSV\nJami' at-Tirmidhiâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/meeAtif/hadith_datasets.","url":"https://huggingface.co/datasets/meeAtif/hadith_datasets","creator_name":"Atif","creator_url":"https://huggingface.co/meeAtif","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["English","Arabic","mit","10K - 100K","json"],"keywords_longer_than_N":true},
	{"name":"hadith_datasets","keyword":"arabic","description":"\n\t\n\t\t\n\t\tSunnah Dataset â€” Hadith JSON & CSV Collection\n\t\n\nA blessed and open-source collection of authenticated Hadiths from the six major books of Sunnah, available in both JSON and CSV formats for research, study, and teaching purposes. This dataset is structured cleanly with English + Arabic + grading + reference links for each Hadith.\n\n\n\t\n\t\t\n\t\tContents\n\t\n\nThis dataset contains the following Hadith collections:\n\n\t\n\t\t\nFile Name\nFormat\nBook Name\n\n\n\t\t\nJami' at-Tirmidhi.csv\nCSV\nJami' at-Tirmidhiâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/meeAtif/hadith_datasets.","url":"https://huggingface.co/datasets/meeAtif/hadith_datasets","creator_name":"Atif","creator_url":"https://huggingface.co/meeAtif","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["English","Arabic","mit","10K - 100K","json"],"keywords_longer_than_N":true},
	{"name":"BenchMAX_Problem_Solving","keyword":"arabic","description":"\n\t\n\t\t\n\t\tDataset Sources\n\t\n\n\nPaper: BenchMAX: A Comprehensive Multilingual Evaluation Suite for Large Language Models\nLink: https://huggingface.co/papers/2502.07346\nRepository: https://github.com/CONE-MT/BenchMAX\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nBenchMAX_Problem_Solving is a dataset of BenchMAX, sourcing from LiveCodeBench_v4, which evaluates the code generation capability for solving multilingual competitive code problems.\nWe extend the original English dataset by 16 non-English languages.\nTheâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/LLaMAX/BenchMAX_Problem_Solving.","url":"https://huggingface.co/datasets/LLaMAX/BenchMAX_Problem_Solving","creator_name":"LLaMAX","creator_url":"https://huggingface.co/LLaMAX","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","multilingual","English","Chinese","Spanish"],"keywords_longer_than_N":true},
	{"name":"xP3x","keyword":"arabic","description":"\n\t\n\t\t\n\t\tDataset Card for xP3x\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\n\nxP3x (Crosslingual Public Pool of Prompts eXtended) is a collection of prompts & datasets across 277 languages & 16 NLP tasks. It contains all of xP3 + much more! It is used for training future contenders of mT0 & BLOOMZ at project Aya @Cohere Labs ðŸ§¡\n\n\nCreation: The dataset can be recreated using instructions available here together with the file in this repository named xp3x_create.py. We provide this version to save processingâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/CohereLabs/xP3x.","url":"https://huggingface.co/datasets/CohereLabs/xP3x","creator_name":"Cohere Labs","creator_url":"https://huggingface.co/CohereLabs","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["other","expert-generated","crowdsourced","multilingual","Afrikaans"],"keywords_longer_than_N":true},
	{"name":"xP3x","keyword":"egyptian arabic","description":"\n\t\n\t\t\n\t\tDataset Card for xP3x\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\n\nxP3x (Crosslingual Public Pool of Prompts eXtended) is a collection of prompts & datasets across 277 languages & 16 NLP tasks. It contains all of xP3 + much more! It is used for training future contenders of mT0 & BLOOMZ at project Aya @Cohere Labs ðŸ§¡\n\n\nCreation: The dataset can be recreated using instructions available here together with the file in this repository named xp3x_create.py. We provide this version to save processingâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/CohereLabs/xP3x.","url":"https://huggingface.co/datasets/CohereLabs/xP3x","creator_name":"Cohere Labs","creator_url":"https://huggingface.co/CohereLabs","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["other","expert-generated","crowdsourced","multilingual","Afrikaans"],"keywords_longer_than_N":true},
	{"name":"xP3x","keyword":"levantine arabic","description":"\n\t\n\t\t\n\t\tDataset Card for xP3x\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\n\nxP3x (Crosslingual Public Pool of Prompts eXtended) is a collection of prompts & datasets across 277 languages & 16 NLP tasks. It contains all of xP3 + much more! It is used for training future contenders of mT0 & BLOOMZ at project Aya @Cohere Labs ðŸ§¡\n\n\nCreation: The dataset can be recreated using instructions available here together with the file in this repository named xp3x_create.py. We provide this version to save processingâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/CohereLabs/xP3x.","url":"https://huggingface.co/datasets/CohereLabs/xP3x","creator_name":"Cohere Labs","creator_url":"https://huggingface.co/CohereLabs","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["other","expert-generated","crowdsourced","multilingual","Afrikaans"],"keywords_longer_than_N":true},
	{"name":"xP3x","keyword":"mesopotamian arabic","description":"\n\t\n\t\t\n\t\tDataset Card for xP3x\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\n\nxP3x (Crosslingual Public Pool of Prompts eXtended) is a collection of prompts & datasets across 277 languages & 16 NLP tasks. It contains all of xP3 + much more! It is used for training future contenders of mT0 & BLOOMZ at project Aya @Cohere Labs ðŸ§¡\n\n\nCreation: The dataset can be recreated using instructions available here together with the file in this repository named xp3x_create.py. We provide this version to save processingâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/CohereLabs/xP3x.","url":"https://huggingface.co/datasets/CohereLabs/xP3x","creator_name":"Cohere Labs","creator_url":"https://huggingface.co/CohereLabs","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["other","expert-generated","crowdsourced","multilingual","Afrikaans"],"keywords_longer_than_N":true},
	{"name":"xP3x","keyword":"moroccan arabic","description":"\n\t\n\t\t\n\t\tDataset Card for xP3x\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\n\nxP3x (Crosslingual Public Pool of Prompts eXtended) is a collection of prompts & datasets across 277 languages & 16 NLP tasks. It contains all of xP3 + much more! It is used for training future contenders of mT0 & BLOOMZ at project Aya @Cohere Labs ðŸ§¡\n\n\nCreation: The dataset can be recreated using instructions available here together with the file in this repository named xp3x_create.py. We provide this version to save processingâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/CohereLabs/xP3x.","url":"https://huggingface.co/datasets/CohereLabs/xP3x","creator_name":"Cohere Labs","creator_url":"https://huggingface.co/CohereLabs","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["other","expert-generated","crowdsourced","multilingual","Afrikaans"],"keywords_longer_than_N":true},
	{"name":"xP3x","keyword":"najdi arabic","description":"\n\t\n\t\t\n\t\tDataset Card for xP3x\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\n\nxP3x (Crosslingual Public Pool of Prompts eXtended) is a collection of prompts & datasets across 277 languages & 16 NLP tasks. It contains all of xP3 + much more! It is used for training future contenders of mT0 & BLOOMZ at project Aya @Cohere Labs ðŸ§¡\n\n\nCreation: The dataset can be recreated using instructions available here together with the file in this repository named xp3x_create.py. We provide this version to save processingâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/CohereLabs/xP3x.","url":"https://huggingface.co/datasets/CohereLabs/xP3x","creator_name":"Cohere Labs","creator_url":"https://huggingface.co/CohereLabs","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["other","expert-generated","crowdsourced","multilingual","Afrikaans"],"keywords_longer_than_N":true},
	{"name":"xP3x","keyword":"tunisian arabic","description":"\n\t\n\t\t\n\t\tDataset Card for xP3x\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\n\nxP3x (Crosslingual Public Pool of Prompts eXtended) is a collection of prompts & datasets across 277 languages & 16 NLP tasks. It contains all of xP3 + much more! It is used for training future contenders of mT0 & BLOOMZ at project Aya @Cohere Labs ðŸ§¡\n\n\nCreation: The dataset can be recreated using instructions available here together with the file in this repository named xp3x_create.py. We provide this version to save processingâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/CohereLabs/xP3x.","url":"https://huggingface.co/datasets/CohereLabs/xP3x","creator_name":"Cohere Labs","creator_url":"https://huggingface.co/CohereLabs","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["other","expert-generated","crowdsourced","multilingual","Afrikaans"],"keywords_longer_than_N":true},
	{"name":"xP3x","keyword":"ta'izzi-adeni arabic","description":"\n\t\n\t\t\n\t\tDataset Card for xP3x\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\n\nxP3x (Crosslingual Public Pool of Prompts eXtended) is a collection of prompts & datasets across 277 languages & 16 NLP tasks. It contains all of xP3 + much more! It is used for training future contenders of mT0 & BLOOMZ at project Aya @Cohere Labs ðŸ§¡\n\n\nCreation: The dataset can be recreated using instructions available here together with the file in this repository named xp3x_create.py. We provide this version to save processingâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/CohereLabs/xP3x.","url":"https://huggingface.co/datasets/CohereLabs/xP3x","creator_name":"Cohere Labs","creator_url":"https://huggingface.co/CohereLabs","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["other","expert-generated","crowdsourced","multilingual","Afrikaans"],"keywords_longer_than_N":true},
	{"name":"iraqi_train_set","keyword":"arabic","description":"Pre-processed Iraqi train partition from the MASC-dataset:\nMohammad Al-Fetyani, Muhammad Al-Barham, Gheith Abandah, Adham Alsharkawi, Maha Dawas, August 18, 2021, \"MASC: Massive Arabic Speech Corpus\", IEEE Dataport, doi: https://dx.doi.org/10.21227/e1qb-jv46.\n","url":"https://huggingface.co/datasets/otozz/iraqi_train_set","creator_name":"Ã–mer","creator_url":"https://huggingface.co/otozz","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["Arabic","cc-by-4.0","10K - 100K","parquet","Datasets"],"keywords_longer_than_N":true},
	{"name":"llm-metric-mrewardbench","keyword":"arabic","description":"rifqifarhansyah/llm-metric-mrewardbench dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/rifqifarhansyah/llm-metric-mrewardbench","creator_name":"Mohammad Rifqi Farhansyah","creator_url":"https://huggingface.co/rifqifarhansyah","license_name":"Open Data Commons Attribution License v1.0","license_url":"https://scancode-licensedb.aboutcode.org/odc-by-1.0.html","language":"en","first_N":5,"first_N_keywords":["Arabic","Chinese","Czech","Dutch","French"],"keywords_longer_than_N":true},
	{"name":"Arabic-stsb","keyword":"arabic","description":"\n\t\n\t\t\n\t\tArabic STSB Structure\n\t\n\n\nThe Arabic Version  of the the Semantic Textual Similarity Benchmark (Cer et al., 2017)\nit is a collection of sentence pairs drawn from news headlines, video and image captions, and natural language inference data.\nEach pair is human-annotated with a similarity score from 1 to 5. However, for this variant, the similarity scores are normalized to between 0 and 1.\n\nExamples:\n{\n  \"sentence1\": \"Ø·Ø§Ø¦Ø±Ø© Ø³ØªÙ‚Ù„Ø¹\",\n  \"sentence2\": \"Ø·Ø§Ø¦Ø±Ø© Ø¬ÙˆÙŠØ© Ø³ØªÙ‚Ù„Ø¹\",\n  \"score\": 1.0\n}\n\n{â€¦ See the full description on the dataset page: https://huggingface.co/datasets/LLMXperts/Arabic-stsb.","url":"https://huggingface.co/datasets/LLMXperts/Arabic-stsb","creator_name":"LLMXperts","creator_url":"https://huggingface.co/LLMXperts","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["sentence-similarity","Arabic","apache-2.0","1K<n<10K","ðŸ‡ºðŸ‡¸ Region: US"],"keywords_longer_than_N":true},
	{"name":"saudipedia-arabic-qa","keyword":"arabic","description":"\n\t\n\t\t\n\t\tSaudipedia Q&A Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\n\n\t\n\t\t\n\t\tSummary\n\t\n\nThis dataset contains question-answer pairs scraped from Saudipedia, a comprehensive Arabic encyclopedia focused on Saudi Arabia. The dataset includes 1,082 Q&A entries covering various topics related to Saudi culture, history, economy, government, society, geography, religion, and notable personalities.\nThe data was collected by scraping the website's question-answer section, which provides detailed answers toâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/AhmadHakami/saudipedia-arabic-qa.","url":"https://huggingface.co/datasets/AhmadHakami/saudipedia-arabic-qa","creator_name":"Ahmad","creator_url":"https://huggingface.co/AhmadHakami","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["question-answering","Arabic","mit","1K - 10K","csv"],"keywords_longer_than_N":true},
	{"name":"bhojpuri","keyword":"arabic","description":"\n\t\n\t\t\n\t\n\t\n\t\tFLEURS\n\t\n\nFleurs is the speech version of the FLoRes machine translation benchmark. \nWe use 2009 n-way parallel sentences from the FLoRes dev and devtest publicly available sets, in 102 languages. \nTraining sets have around 10 hours of supervision. Speakers of the train sets are different than speakers from the dev/test sets. Multilingual fine-tuning is\nused and â€unit error rateâ€ (characters, signs) of all languages is averaged. Languages and results are also grouped into sevenâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/ankur02/bhojpuri.","url":"https://huggingface.co/datasets/ankur02/bhojpuri","creator_name":"Ankur Verma","creator_url":"https://huggingface.co/ankur02","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","expert-generated","crowdsourced","machine-generated","crowdsourced"],"keywords_longer_than_N":true},
	{"name":"Aya-Aya.23.8B-DPO","keyword":"arabic","description":"\n\t\n\t\t\n\t\tðŸ¤— Dataset Card for \"Aya-Aya.23.8B-DPO\"\n\t\n\n\n\t\n\t\t\n\t\tDataset Sources & Infos\n\t\n\n\nData Origin: Derived from the Arabic Aya (2A) dataset : 2A2I/Arabic_Aya which is a Curated Subset of the Aya Collection CohereForAI/aya_dataset\nLanguages: Modern Standard Arabic (MSA)\nLicense: Apache-2.0\nMaintainers: Ali Elfilali and Mohammed Machrouh\n\n\n\t\n\t\t\n\t\n\t\n\t\tPurpose\n\t\n\nAya-Aya.23.8B-DPO is a DPO dataset designed to advance Arabic NLP by comparing human-generated responses, labeled as \"chosen,\" withâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/2A2I/Aya-Aya.23.8B-DPO.","url":"https://huggingface.co/datasets/2A2I/Aya-Aya.23.8B-DPO","creator_name":"2A2I","creator_url":"https://huggingface.co/2A2I","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["Arabic","apache-2.0","10K - 100K","parquet","Text"],"keywords_longer_than_N":true},
	{"name":"ar-quran-hadith14books-MSA","keyword":"arabic","description":"\n\t\n\t\t\n\t\tDataset Card for quran and hadith dataset\n\t\n\n\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\n\nArabic specialized dataset to make sure that AI is not changing our sacred scriptures in speech recognition by training and evaluating upon quran and hadith.\n\nCombining quran + magma'a el zawa'ed book of sidi Nour eldin elhaithamy author including 14 book of hadith of approximately 10,000 hadith without repititions + other existing datasets like common voice, fleurs, media speech\n\nFirst dataset to have fullâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/siddiqiya/ar-quran-hadith14books-MSA.","url":"https://huggingface.co/datasets/siddiqiya/ar-quran-hadith14books-MSA","creator_name":"Siddiqiya Shazoulia","creator_url":"https://huggingface.co/siddiqiya","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","Arabic","apache-2.0","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"ar-quran-hadith14books-MSA","keyword":"arabic","description":"\n\t\n\t\t\n\t\tDataset Card for quran and hadith dataset\n\t\n\n\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\n\nArabic specialized dataset to make sure that AI is not changing our sacred scriptures in speech recognition by training and evaluating upon quran and hadith.\n\nCombining quran + magma'a el zawa'ed book of sidi Nour eldin elhaithamy author including 14 book of hadith of approximately 10,000 hadith without repititions + other existing datasets like common voice, fleurs, media speech\n\nFirst dataset to have fullâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/siddiqiya/ar-quran-hadith14books-MSA.","url":"https://huggingface.co/datasets/siddiqiya/ar-quran-hadith14books-MSA","creator_name":"Siddiqiya Shazoulia","creator_url":"https://huggingface.co/siddiqiya","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","Arabic","apache-2.0","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"smol","keyword":"egyptian arabic","description":"\n\t\n\t\t\n\t\tSMOL\n\t\n\nSMOL (Set for Maximal Overall Leverage) is a collection professional\ntranslations into 221 Low-Resource Languages, for the purpose of training\ntranslation models, and otherwise increasing the representations of said\nlanguages in NLP and technology.\nPlease read the SMOL Paper and the\nGATITOS Paper for a much more\nthorough description!\nThere are four resources in this directory:\n\nSmolDoc: document-level translations into 104 language pairs (103 unique languages)\nSmolSent:â€¦ See the full description on the dataset page: https://huggingface.co/datasets/google/smol.","url":"https://huggingface.co/datasets/google/smol","creator_name":"Google","creator_url":"https://huggingface.co/google","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["translation","Afar","Abkhaz","Achinese","Acoli"],"keywords_longer_than_N":true},
	{"name":"multilingual_translation_gen_binarized","keyword":"arabic","description":"Youseff1987/multilingual_translation_gen_binarized dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/Youseff1987/multilingual_translation_gen_binarized","creator_name":"JOON HYOUNG JUN","creator_url":"https://huggingface.co/Youseff1987","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["translation","Korean","English","Chinese","Zulu"],"keywords_longer_than_N":true},
	{"name":"smol","keyword":"arabic","description":"\n\t\n\t\t\n\t\tSMOL\n\t\n\nSMOL (Set for Maximal Overall Leverage) is a collection professional\ntranslations into 221 Low-Resource Languages, for the purpose of training\ntranslation models, and otherwise increasing the representations of said\nlanguages in NLP and technology.\nPlease read the SMOL Paper and the\nGATITOS Paper for a much more\nthorough description!\nThere are four resources in this directory:\n\nSmolDoc: document-level translations into 104 language pairs (103 unique languages)\nSmolSent:â€¦ See the full description on the dataset page: https://huggingface.co/datasets/google/smol.","url":"https://huggingface.co/datasets/google/smol","creator_name":"Google","creator_url":"https://huggingface.co/google","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["translation","Afar","Abkhaz","Achinese","Acoli"],"keywords_longer_than_N":true},
	{"name":"Finance-Curriculum-Edu-Arabic","keyword":"arabic","description":"\n\t\n\t\t\n\t\tDataset Name:\n\t\n\nFinance Curriculum Edu Arabic / Ù…Ù†Ø§Ù‡Ø¬ Ø§Ù„ØªÙ…ÙˆÙŠÙ„ Ø¨Ø§Ù„Ù„ØºØ© Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©\n\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nEnglish:Finance Curriculum Edu Arabic is a curated Q&A dataset of 4,834 finance-related entries in Arabic. It mirrors the English-language \"Finance Curriculum Edu\" and provides scenario-based, professional-grade questions and answers aligned to a structured finance curriculum. Designed for training multilingual LLMs, benchmarking, and educational use in Arabic financial contexts.â€¦ See the full description on the dataset page: https://huggingface.co/datasets/Josephgflowers/Finance-Curriculum-Edu-Arabic.","url":"https://huggingface.co/datasets/Josephgflowers/Finance-Curriculum-Edu-Arabic","creator_name":"Joseph G Flowers","creator_url":"https://huggingface.co/Josephgflowers","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["Arabic","mit","1K - 10K","csv","Text"],"keywords_longer_than_N":true},
	{"name":"smol","keyword":"levantine arabic","description":"\n\t\n\t\t\n\t\tSMOL\n\t\n\nSMOL (Set for Maximal Overall Leverage) is a collection professional\ntranslations into 221 Low-Resource Languages, for the purpose of training\ntranslation models, and otherwise increasing the representations of said\nlanguages in NLP and technology.\nPlease read the SMOL Paper and the\nGATITOS Paper for a much more\nthorough description!\nThere are four resources in this directory:\n\nSmolDoc: document-level translations into 104 language pairs (103 unique languages)\nSmolSent:â€¦ See the full description on the dataset page: https://huggingface.co/datasets/google/smol.","url":"https://huggingface.co/datasets/google/smol","creator_name":"Google","creator_url":"https://huggingface.co/google","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["translation","Afar","Abkhaz","Achinese","Acoli"],"keywords_longer_than_N":true},
	{"name":"smol","keyword":"tunisian arabic","description":"\n\t\n\t\t\n\t\tSMOL\n\t\n\nSMOL (Set for Maximal Overall Leverage) is a collection professional\ntranslations into 221 Low-Resource Languages, for the purpose of training\ntranslation models, and otherwise increasing the representations of said\nlanguages in NLP and technology.\nPlease read the SMOL Paper and the\nGATITOS Paper for a much more\nthorough description!\nThere are four resources in this directory:\n\nSmolDoc: document-level translations into 104 language pairs (103 unique languages)\nSmolSent:â€¦ See the full description on the dataset page: https://huggingface.co/datasets/google/smol.","url":"https://huggingface.co/datasets/google/smol","creator_name":"Google","creator_url":"https://huggingface.co/google","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["translation","Afar","Abkhaz","Achinese","Acoli"],"keywords_longer_than_N":true},
	{"name":"domain-translations","keyword":"arabic","description":"\n\t\n\t\t\n\t\tMultilingual Domain Name Translations Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset contains 155,004 domain names with their multilingual translations across 20 languages. Each domain has been segmented into constituent words and translated while preserving semantic meaning and commercial appeal. The dataset is particularly valuable for domain name research, multilingual NLP tasks, and understanding how brand names and concepts translate across languages.\n\n\t\n\t\t\n\t\tDatasetâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/humbleworth/domain-translations.","url":"https://huggingface.co/datasets/humbleworth/domain-translations","creator_name":"HumbleWorth","creator_url":"https://huggingface.co/humbleworth","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["translation","text-generation","feature-extraction","multilingual","Arabic"],"keywords_longer_than_N":true},
	{"name":"ALREDFANI-DATABASE","keyword":"arabic","description":"alredfani/ALREDFANI-DATABASE dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/alredfani/ALREDFANI-DATABASE","creator_name":"helmy Alredfani","creator_url":"https://huggingface.co/alredfani","license_name":"Academic Free License v3.0","license_url":"https://choosealicense.com/licenses/afl-3.0/","language":null,"first_N":5,"first_N_keywords":["token-classification","Arabic","afl-3.0","10M<n<100M","ðŸ‡ºðŸ‡¸ Region: US"],"keywords_longer_than_N":true},
	{"name":"arabic_egypt_english_world_facts","keyword":"arabic","description":"\n\t\n\t\t\n\t\tðŸŒ Version (v2.0) World Facts in English, Arabic & Egyptian Arabic (Categorized)\n\t\n\nThe World Facts General Knowledge Dataset (v2.0) is a high-quality, human-reviewed Q&A resource by Miscovery. It features general facts categorized across 50+ knowledge domains, provided in three languages:\n\nðŸŒ English\nðŸ‡¸ðŸ‡¦ Modern Standard Arabic (MSA)\nðŸ‡ªðŸ‡¬ Egyptian Arabic (Dialect)\n\nEach entry includes:\n\nThe question and answer\nA category and sub-category\nLanguage tag (en, ar, ar_eg)\nBasic metadata:â€¦ See the full description on the dataset page: https://huggingface.co/datasets/miscovery/arabic_egypt_english_world_facts.","url":"https://huggingface.co/datasets/miscovery/arabic_egypt_english_world_facts","creator_name":"Miscovery","creator_url":"https://huggingface.co/miscovery","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["question-answering","translation","text-generation","fill-mask","English"],"keywords_longer_than_N":true},
	{"name":"Arabic-Optimized-Reasoning-Dataset","keyword":"arabic","description":"\n\t\n\t\t\n\t\tArabic Optimized Reasoning Dataset\n\t\n\nDataset Name: Arabic Optimized ReasoningLicense: Apache-2.0Formats: CSVSize: 1600 rowsBase Dataset: cognitivecomputations/dolphin-r1Libraries Used: Datasets, Dask, Croissant\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThe Arabic Optimized Reasoning Dataset helps AI models get better at reasoning in Arabic. While AI models are good at many tasks, they often struggle with reasoning in languages other than English. This dataset helps fix this problem by:\n\nUsing fewer tokensâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Jr23xd23/Arabic-Optimized-Reasoning-Dataset.","url":"https://huggingface.co/datasets/Jr23xd23/Arabic-Optimized-Reasoning-Dataset","creator_name":"Jaber","creator_url":"https://huggingface.co/Jr23xd23","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["question-answering","table-question-answering","Arabic","apache-2.0","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"llm-ideology-analysis","keyword":"arabic","description":"This dataset contains evaluations of political figures by a diverse set of Large Language Models (LLMs), such that the ideology of these LLMs can be characterized.\n\n\t\n\t\t\n\t\tðŸ“ Dataset Description\n\t\n\nThe dataset contains responses from 19 different Large Language Models evaluating 3,991 political figures, with responses collected in the six UN languages: Arabic, Chinese, English, French, Russian, and Spanish. \nThe evaluations were conducted using a two-stage prompting strategy to assess theâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/aida-ugent/llm-ideology-analysis.","url":"https://huggingface.co/datasets/aida-ugent/llm-ideology-analysis","creator_name":"Ghent University Artificial Intelligence & Data Analytics Group","creator_url":"https://huggingface.co/aida-ugent","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["Arabic","Chinese","English","French","Spanish"],"keywords_longer_than_N":true},
	{"name":"101_billion_arabic_words_dataset","keyword":"arabic","description":"\n\t\n\t\t\n\t\t101 Billion Arabic Words Dataset\n\t\n\n\n\t\n\t\t\n\t\tUpdates\n\t\n\n\nMaintenance Status: Actively Maintained\nUpdate Frequency: Weekly updates to refine data quality and expand coverage.\n\n\n\t\n\t\t\n\t\tUpcoming Version\n\t\n\n\nMore Cleaned Version: A more cleaned version of the dataset is in processing, which includes the addition of a UUID column for better data traceability and management.\n\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\nThe 101 Billion Arabic Words Dataset is curated by the Clusterlab team and consists of 101â€¦ See the full description on the dataset page: https://huggingface.co/datasets/ClusterlabAi/101_billion_arabic_words_dataset.","url":"https://huggingface.co/datasets/ClusterlabAi/101_billion_arabic_words_dataset","creator_name":"ClusterlabAi","creator_url":"https://huggingface.co/ClusterlabAi","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","Arabic","apache-2.0","10M - 100M","parquet"],"keywords_longer_than_N":true},
	{"name":"quran_embeddings","keyword":"arabic","description":"\n\t\n\t\t\n\t\tQuran Embeddings Dataset\n\t\n\nThis repository contains vector embeddings for the Holy Quran, generated using OpenAI's embedding model. These embeddings can be used for semantic search, question answering, and other natural language processing tasks related to Quranic text.\n\n\t\n\t\t\n\t\tDataset Information\n\t\n\nThe dataset consists of a single JSON file:\n\nquran_embeddings.json: Contains embeddings for each verse (ayah) of the Quran with associated metadata\n\n\n\t\n\t\t\n\t\tMetadata Structure\n\t\n\nEachâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/promehedi/quran_embeddings.","url":"https://huggingface.co/datasets/promehedi/quran_embeddings","creator_name":"Mehedi Hasan","creator_url":"https://huggingface.co/promehedi","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["English","Arabic","mit","1K - 10K","json"],"keywords_longer_than_N":true},
	{"name":"arabic-larg","keyword":"arabic","description":"yeeaee/arabic-larg dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/yeeaee/arabic-larg","creator_name":"yazeed albadawy","creator_url":"https://huggingface.co/yeeaee","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["Arabic","apache-2.0","100K - 1M","text","Text"],"keywords_longer_than_N":true},
	{"name":"arabic_polish_quran_translation","keyword":"arabic","description":"Gregniuki/arabic_polish_quran_translation dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/Gregniuki/arabic_polish_quran_translation","creator_name":"Suchow","creator_url":"https://huggingface.co/Gregniuki","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["translation","Arabic","Polish","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"amazic","keyword":"arabic","description":"This repository contains various Tamazight language datasets created by ColÂ·lectivaT in collaboration with CIEMEN and with funding from Municipality of Barcelona and Government of Catalonia. \nUnder mono you can find monolingual sentences. \n\ntc_wajdm_v1.txt - Texts from language learning material â€œtc wawjdmâ€\nIRCAM-clean-tifinagh.txt - Tifinagh scripted sentences extracted from IRCAM's text corpus\n\nUnder parallel you can find sentences with translations. \n\nAWAL contains data extracted fromâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/collectivat/amazic.","url":"https://huggingface.co/datasets/collectivat/amazic","creator_name":"ColÂ·lectivaT","creator_url":"https://huggingface.co/collectivat","license_name":"Creative Commons Attribution 2.0","license_url":"https://scancode-licensedb.aboutcode.org/cc-by-2.0.html","language":"en","first_N":5,"first_N_keywords":["translation","text-generation","Standard Moroccan Tamazight","French","Catalan"],"keywords_longer_than_N":true},
	{"name":"dhanishtha-2.0-superthinker","keyword":"arabic","description":"\n\t\n\t\t\n\t\tðŸ“¦ Dhanishtha-2.0-SUPERTHINKER-MLX\n\t\n\n A distilled corpus of 11.7K high-quality samples showcasing multi-phase reasoning and structured emotional cognition. Sourced directly from the internal training data of Dhanishtha-2.0 â€” the worldâ€™s first Large Language Model (LLM) to implement Intermediate Thinking, featuring multiple <think> and <ser> blocks per response\n\n\t\n\t\t\n\t\n\t\n\t\tExample with MLX-LM-LoRA:\n\t\n\nmlx_lm_lora.train \\\n--modelâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/mlx-community/dhanishtha-2.0-superthinker.","url":"https://huggingface.co/datasets/mlx-community/dhanishtha-2.0-superthinker","creator_name":"MLX Community","creator_url":"https://huggingface.co/mlx-community","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","Afrikaans","Arabic","Bulgarian","Catalan"],"keywords_longer_than_N":true},
	{"name":"amazic","keyword":"moroccan arabic","description":"This repository contains various Tamazight language datasets created by ColÂ·lectivaT in collaboration with CIEMEN and with funding from Municipality of Barcelona and Government of Catalonia. \nUnder mono you can find monolingual sentences. \n\ntc_wajdm_v1.txt - Texts from language learning material â€œtc wawjdmâ€\nIRCAM-clean-tifinagh.txt - Tifinagh scripted sentences extracted from IRCAM's text corpus\n\nUnder parallel you can find sentences with translations. \n\nAWAL contains data extracted fromâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/collectivat/amazic.","url":"https://huggingface.co/datasets/collectivat/amazic","creator_name":"ColÂ·lectivaT","creator_url":"https://huggingface.co/collectivat","license_name":"Creative Commons Attribution 2.0","license_url":"https://scancode-licensedb.aboutcode.org/cc-by-2.0.html","language":"en","first_N":5,"first_N_keywords":["translation","text-generation","Standard Moroccan Tamazight","French","Catalan"],"keywords_longer_than_N":true},
	{"name":"fw_tunisian_derja","keyword":"arabic","description":"fw_tunisian_derja is a translated version of sawalni-ai/fw-darija with wghezaiel/araT5-marrocan-tunisian model.\n","url":"https://huggingface.co/datasets/wghezaiel/fw_tunisian_derja","creator_name":"Wajdi Ghezaiel","creator_url":"https://huggingface.co/wghezaiel","license_name":"Open Data Commons Attribution License v1.0","license_url":"https://scancode-licensedb.aboutcode.org/odc-by-1.0.html","language":"en","first_N":5,"first_N_keywords":["Tunisian Arabic","odc-by","10K - 100K","parquet","Text"],"keywords_longer_than_N":true},
	{"name":"fineweb2hq-vs-c4","keyword":"arabic","description":"This dataset includes 5000 rows per language from each of two sources: the higher-quality epfml/FineWeb2-HQ\nand the lower-quality allenai/c4. The data is split 80/20 into training and test sets.\nLanguages were carefully chosen to ensure balanced representation across both splits:\nArabic, Chinese, Czech, Danish, Dutch, French, German, Greek, Hungarian, Indonesian, Italian, Japanese, Persian, Polish, Portuguese, Russian, Spanish, Swedish, Turkish, and Vietnamese.\n","url":"https://huggingface.co/datasets/agentlans/fineweb2hq-vs-c4","creator_name":"Alan Tseng","creator_url":"https://huggingface.co/agentlans","license_name":"Open Data Commons Attribution License v1.0","license_url":"https://scancode-licensedb.aboutcode.org/odc-by-1.0.html","language":"en","first_N":5,"first_N_keywords":["text-classification","Portuguese","Danish","Persian","German"],"keywords_longer_than_N":true},
	{"name":"Test","keyword":"arabic","description":"Test Dataset\n","url":"https://huggingface.co/datasets/imenLa/Test","creator_name":"imen laouirine","creator_url":"https://huggingface.co/imenLa","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-to-speech","Arabic","apache-2.0","< 1K","csv"],"keywords_longer_than_N":true},
	{"name":"fw_tunisian_derja","keyword":"tunisian arabic","description":"fw_tunisian_derja is a translated version of sawalni-ai/fw-darija with wghezaiel/araT5-marrocan-tunisian model.\n","url":"https://huggingface.co/datasets/wghezaiel/fw_tunisian_derja","creator_name":"Wajdi Ghezaiel","creator_url":"https://huggingface.co/wghezaiel","license_name":"Open Data Commons Attribution License v1.0","license_url":"https://scancode-licensedb.aboutcode.org/odc-by-1.0.html","language":"en","first_N":5,"first_N_keywords":["Tunisian Arabic","odc-by","10K - 100K","parquet","Text"],"keywords_longer_than_N":true},
	{"name":"PersianNumberVersion1","keyword":"arabic","description":"initmahdi/PersianNumberVersion1 dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/initmahdi/PersianNumberVersion1","creator_name":"m.mahdi","creator_url":"https://huggingface.co/initmahdi","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":null,"first_N":5,"first_N_keywords":["image-to-text","Persian","Arabic","cc-by-4.0","n<1K"],"keywords_longer_than_N":true},
	{"name":"QA_LAW_Egyptian_dataset","keyword":"arabic","description":"\n\t\n\t\t\n\t\tEgyptian Arabic Legal QA Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset contains 3,725 question-answer pairs in Egyptian Arabic focused on legal topics. The dataset serves as a valuable resource for developing Arabic natural language processing models, particularly for legal domain applications in Egyptian Arabic dialect.\n\n\t\n\t\t\n\t\tKey Features\n\t\n\n\nLanguage: Egyptian Arabic (Ø§Ù„Ø¹Ø§Ù…ÙŠØ© Ø§Ù„Ù…ØµØ±ÙŠØ©)\nDomain: Legal/Law (Ø§Ù„Ù‚Ø§Ù†ÙˆÙ†)\nSize: 3,725 examples\nTopics: 745 unique legal categoriesâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Omar-youssef/QA_LAW_Egyptian_dataset.","url":"https://huggingface.co/datasets/Omar-youssef/QA_LAW_Egyptian_dataset","creator_name":"Omar Youssef","creator_url":"https://huggingface.co/Omar-youssef","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["question-answering","Arabic","apache-2.0","1K - 10K","parquet"],"keywords_longer_than_N":true},
	{"name":"Shifaa_Arabic_Medical_Consultations","keyword":"arabic","description":"\n\t\n\t\t\n\t\tShifaa Arabic Medical Consultations ðŸ¥ðŸ“Š\n\t\n\n  \n\n\t\n\t\t\n\t\tOverview ðŸŒ\n\t\n\nShifaa is revolutionizing Arabic medical AI by addressing the critical gap in Arabic medical datasets. Our first contribution is the Shifaa Arabic Medical Consultations dataset, a comprehensive collection of 84,422 real-world medical consultations covering 16 Main Specializations and 585 Hierarchical Diagnoses.  \nðŸ” Why is this dataset important?  \n\nFirst large-scale Arabic medical dataset for AI applications.â€¦ See the full description on the dataset page: https://huggingface.co/datasets/Ahmed-Selem/Shifaa_Arabic_Medical_Consultations.","url":"https://huggingface.co/datasets/Ahmed-Selem/Shifaa_Arabic_Medical_Consultations","creator_name":"Ahmed Selem","creator_url":"https://huggingface.co/Ahmed-Selem","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["question-answering","text-classification","text-generation","zero-shot-classification","Arabic"],"keywords_longer_than_N":true},
	{"name":"Moroccan-Darija-QA","keyword":"moroccan arabic","description":"\n\t\n\t\t\n\t\tMoroccan Darija Q&A Dataset\n\t\n\nA comprehensive question-answer dataset in Moroccan Darija (Moroccan Arabic dialect) covering various topics of daily life, culture, and practical knowledge.\n\n\t\n\t\t\n\t\tðŸ“Š Dataset Overview\n\t\n\nThis dataset contains 3,470 question-answer pairs in Moroccan Darija organized across 3 configurations:\n\nðŸ”— Default: 2,026 standard Q&A pairs\nðŸŒ Translated: 1,300 translated content pairs  \nðŸ§  Reasoning: 144 reasoning-based Q&A with thinking process\n\n\n\t\n\t\t\n\t\tTopicsâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Lyte/Moroccan-Darija-QA.","url":"https://huggingface.co/datasets/Lyte/Moroccan-Darija-QA","creator_name":"Yassine Ennaour","creator_url":"https://huggingface.co/Lyte","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["question-answering","text-generation","Moroccan Arabic","mit","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"llm-metric-mrewardbench","keyword":"arabic","description":"rubricreward/llm-metric-mrewardbench dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/rubricreward/llm-metric-mrewardbench","creator_name":"rubricreward","creator_url":"https://huggingface.co/rubricreward","license_name":"Open Data Commons Attribution License v1.0","license_url":"https://scancode-licensedb.aboutcode.org/odc-by-1.0.html","language":"en","first_N":5,"first_N_keywords":["Arabic","Chinese","Czech","Dutch","French"],"keywords_longer_than_N":true},
	{"name":"phonetic-piper-recording-studio-prompts","keyword":"arabic","description":"\n\t\n\t\t\n\t\tPhonetic Piper Studio Recordings Prompts\n\t\n\nThis dataset is a processed version of an utterance dataset made available for various languages as prompts for the Piper recording studio. Along with the original prompts, we include:\n\ncolumns ipa_espeak and ipa_epitran containing phonemized versions of the original sentences according to espeak-ng and Epitran phonemizers, respectively\ncolumns lang, espeak_lang_code, epitran_lang_code containing the language codes as reported by piperâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fdemelo/phonetic-piper-recording-studio-prompts.","url":"https://huggingface.co/datasets/fdemelo/phonetic-piper-recording-studio-prompts","creator_name":"FlÃ¡vio Eler De Melo","creator_url":"https://huggingface.co/fdemelo","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["Afrikaans","Arabic","Bulgarian","Catalan","Czech"],"keywords_longer_than_N":true},
	{"name":"financial-reports-extractive-summarization_eval","keyword":"arabic","description":"\n\t\n\t\t\n\t\tFinancial Reports Extractive Summarization Evaluation Dataset\n\t\n\nValidation and test splits for evaluating models on Arabic financial reports extractive summarization.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\nFormat: Simple prompt-answer pairs\nValidation: ~20 examples (10%)\nTest: ~20 examples (10%)\nLanguage: Arabic\nDomain: Financial reports and market news\n\n\n\t\n\t\t\n\t\tFields\n\t\n\n\nid: Unique identifier\nprompt: The summarization prompt\nfull_text: Complete financial report\nanswer: Ground truthâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/SahmBenchmark/financial-reports-extractive-summarization_eval.","url":"https://huggingface.co/datasets/SahmBenchmark/financial-reports-extractive-summarization_eval","creator_name":"Sahm_Benchmark","creator_url":"https://huggingface.co/SahmBenchmark","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["summarization","text-generation","Arabic","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"financial-reports-extractive-summarization_eval","keyword":"arabic","description":"\n\t\n\t\t\n\t\tFinancial Reports Extractive Summarization Evaluation Dataset\n\t\n\nValidation and test splits for evaluating models on Arabic financial reports extractive summarization.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\nFormat: Simple prompt-answer pairs\nValidation: ~20 examples (10%)\nTest: ~20 examples (10%)\nLanguage: Arabic\nDomain: Financial reports and market news\n\n\n\t\n\t\t\n\t\tFields\n\t\n\n\nid: Unique identifier\nprompt: The summarization prompt\nfull_text: Complete financial report\nanswer: Ground truthâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/SahmBenchmark/financial-reports-extractive-summarization_eval.","url":"https://huggingface.co/datasets/SahmBenchmark/financial-reports-extractive-summarization_eval","creator_name":"Sahm_Benchmark","creator_url":"https://huggingface.co/SahmBenchmark","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["summarization","text-generation","Arabic","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"shamela_books_text","keyword":"arabic","description":"\n\t\n\t\t\n\t\tShamela_Books_Text\n\t\n\nThis dataset contains the full text content of Islamic Arabic books from the Shamela Library, organized by category, book, volume, and page, with footnotes stored separately. It is designed to support Arabic NLP, digital humanities, and bibliographic analysis.\nðŸ”— This dataset is linked to the companion metadata dataset:\nðŸ‘‰ Shamela_Books_info via the book_id field.\n\n\n\t\n\t\t\n\t\n\t\n\t\tðŸ“Š Dataset Summary\n\t\n\n\nTotal Categories: 40\nTotal Books: 8,538\nTotal Records (Pages): 7â€¦ See the full description on the dataset page: https://huggingface.co/datasets/MoMonir/shamela_books_text.","url":"https://huggingface.co/datasets/MoMonir/shamela_books_text","creator_name":"Mohamed Monir","creator_url":"https://huggingface.co/MoMonir","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["Arabic","apache-2.0","ðŸ‡ºðŸ‡¸ Region: US"],"keywords_longer_than_N":false},
	{"name":"V1Q","keyword":"arabic","description":"from datasets import load_dataset\nds = load_dataset(\"b3x0m/Chinese-H-Novels\")\nimport sagemaker\nimport boto3\nfrom sagemaker.huggingface import HuggingFaceModel\ntry:\n    role = sagemaker.get_execution_role()\nexcept ValueError:\n    iam = boto3.client('iam')\n    role = iam.get_role(RoleName='sagemaker_execution_role')['Role']['Arn']\n\n\t\n\t\t\n\t\tHub Model configuration. https://huggingface.co/models\n\t\n\nhub = {\n    'HF_MODEL_ID':'deepseek-ai/Janus-Pro-7B',\n    'HF_TASK':'any-to-any'\n}\n\n\t\n\t\t\n\t\tcreateâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/YuRiVeRTi/V1Q.","url":"https://huggingface.co/datasets/YuRiVeRTi/V1Q","creator_name":"YuRiVeRTical","creator_url":"https://huggingface.co/YuRiVeRTi","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","table-question-answering","question-answering","zero-shot-classification"],"keywords_longer_than_N":true},
	{"name":"AraTrust","keyword":"arabic","description":"Paper\nAlghamdi, E. A., Masoud, R. I., Alnuhait, D., Alomairi, A. Y., Ashraf, A., & Zaytoon, M. (2024). AraTrust: An Evaluation of Trustworthiness for LLMs in Arabic. arXiv preprint arXiv:2403.09017.\nBibTeX:\n@article{alghamdi2024aratrust,\n  title={AraTrust: An Evaluation of Trustworthiness for LLMs in Arabic},\n  author={Alghamdi, Emad A and Masoud, Reem I and Alnuhait, Deema and Alomairi, Afnan Y and Ashraf, Ahmed and Zaytoon, Mohamed},\n  journal={arXiv preprint arXiv:2403.09017},\n  year={2024}â€¦ See the full description on the dataset page: https://huggingface.co/datasets/asas-ai/AraTrust.","url":"https://huggingface.co/datasets/asas-ai/AraTrust","creator_name":"ASAS AI","creator_url":"https://huggingface.co/asas-ai","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["Arabic","mit","< 1K","parquet","Text"],"keywords_longer_than_N":true},
	{"name":"silma-arabic-english-sts-dataset-v1.0","keyword":"arabic","description":"\n\t\n\t\t\n\t\tSILMA STS Arabic/English Dataset - v1.0\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThe SILMA STS Arabic/English Dataset - v1.0 is a dataset designed for training and evaluating sentence embeddings for Arabic and English tasks. It consists of five different splits that cover monolingual and multilingual sentence pairs, with human-annotated similarity scores. The dataset includes both Arabic-to-Arabic and English-to-English pairs, as well as cross-lingual Arabic-English pairs, making it a valuable resourceâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/silma-ai/silma-arabic-english-sts-dataset-v1.0.","url":"https://huggingface.co/datasets/silma-ai/silma-arabic-english-sts-dataset-v1.0","creator_name":"SILMA AI","creator_url":"https://huggingface.co/silma-ai","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["sentence-similarity","Arabic","English","apache-2.0","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"LLM_Multilingual_dataset","keyword":"arabic","description":"\n\t\n\t\t\n\t\tDataset Card for Dataset Name\n\t\n\n\n\nThis dataset card aims to be a base template for new datasets. It has been generated using this raw template.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\n\n\n\n\n\nCurated by: [More Information Needed]\nFunded by [optional]: [More Information Needed]\nShared by [optional]: [More Information Needed]\nLanguage(s) (NLP): [More Information Needed]\nLicense: [More Information Needed]\n\n\n\t\n\t\t\n\t\tDataset Sources [optional]\n\t\n\n\n\n\nRepository: [Moreâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/lewishamilton21/LLM_Multilingual_dataset.","url":"https://huggingface.co/datasets/lewishamilton21/LLM_Multilingual_dataset","creator_name":"Kesavprabu","creator_url":"https://huggingface.co/lewishamilton21","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["table-question-answering","Japanese","Finnish","Indonesian","Russian"],"keywords_longer_than_N":true},
	{"name":"egytriplets-2m","keyword":"arabic","description":"\n\t\n\t\t\n\t\tEgyTriplets - 2M ðŸ•ŒðŸ“š\n\t\n\nEgyTriplets - 2M is a high-quality dataset of 2 million Egyptian Arabic sentence triplets designed for semantic embedding training, especially in low-resource and dialectal NLP applications.\n\n\t\n\t\t\n\t\tâœ¨ Key Features\n\t\n\n\nâœ… 2 million triplets\nðŸ·ï¸ Format: (anchor, 3 hard positives, 3 hard negatives)\nðŸ“– Translation: Egyptian Arabic âž Modern Standard Arabic\nðŸ“Š Splits:\nTrain: 1,796,323 triplets\nValidation: 103,855 triplets\nTest: 99,543 triplets\n\n\n\n\n\n\t\n\t\t\n\t\tðŸ”¨ How Itâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/metga97/egytriplets-2m.","url":"https://huggingface.co/datasets/metga97/egytriplets-2m","creator_name":"Mohammad Essam","creator_url":"https://huggingface.co/metga97","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","Arabic","apache-2.0","100K - 1M","json"],"keywords_longer_than_N":true},
	{"name":"tatoeba-tokipona","keyword":"arabic","description":"NetherQuartz/tatoeba-tokipona dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/NetherQuartz/tatoeba-tokipona","creator_name":"Vladimir Larkin","creator_url":"https://huggingface.co/NetherQuartz","license_name":"Creative Commons Attribution 2.0","license_url":"https://scancode-licensedb.aboutcode.org/cc-by-2.0.html","language":"en","first_N":5,"first_N_keywords":["translation","Toki Pona","English","Russian","Ukrainian"],"keywords_longer_than_N":true},
	{"name":"CORU","keyword":"arabic","description":"\n\t\n\t\t\n\t\tReceiptSense: Beyond Traditional OCR - A Dataset for Receipt Understanding\n\t\n\n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tðŸ”¥ News\n\t\n\n\n[2024] ReceiptSense dataset is now publicly available!\n[2024] Paper accepted and published\n\n\n\t\n\t\t\n\t\n\t\n\t\tðŸ“– Abstract\n\t\n\nMultilingual OCR and information extraction from receipts remains challenging, particularly for complex scripts like Arabic. We introduce ReceiptSense, a comprehensive dataset designed for Arabic-English receipt understanding comprising:\n\n20,000 annotated receiptsâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/abdoelsayed/CORU.","url":"https://huggingface.co/datasets/abdoelsayed/CORU","creator_name":"Abdelrahman Abdallah","creator_url":"https://huggingface.co/abdoelsayed","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["object-detection","text-classification","zero-shot-classification","English","Arabic"],"keywords_longer_than_N":true},
	{"name":"Voice","keyword":"arabic","description":"Introducing dataset of professional voice actors where actors have spoken X sentences. It includes data from all the voices (approx. 9, 920) from voices.com website. Where professional actors have provided examples of their voices. \n\n\t\n\t\t\n\t\tWhat's Voices.com?\n\t\n\nIt is a website where professional voice actors can be found for different voice acting activities for a cheap price. Much like Fiverr but for actual voices. \n\n\t\n\t\t\n\t\tWhat's included?\n\t\n\n\nVoice tracks (approx. 4) for each actorâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/sleeping-ai/Voice.","url":"https://huggingface.co/datasets/sleeping-ai/Voice","creator_name":"Sleeping AI","creator_url":"https://huggingface.co/sleeping-ai","license_name":"Academic Free License v3.0","license_url":"https://choosealicense.com/licenses/afl-3.0/","language":"en","first_N":5,"first_N_keywords":["English","Arabic","afl-3.0","< 1K","soundfolder"],"keywords_longer_than_N":true},
	{"name":"OpenHumanreasoning-multilingual-2.2k","keyword":"arabic","description":"Based off of Pinkstackorg/humanreasoning-testing-en, it is a human-generated dataset where a real person had to create most of the reasoning and the final output. If there are any mistakes please let us know.\nWe offer this dataset at an apache-2.0 license to make it useful for everybody.\nnote: translations are not human generated.\n","url":"https://huggingface.co/datasets/Pinkstack/OpenHumanreasoning-multilingual-2.2k","creator_name":"Pinkstack","creator_url":"https://huggingface.co/Pinkstack","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","Arabic","Chinese","Czech","Danish"],"keywords_longer_than_N":true},
	{"name":"Arabic-gsm8k","keyword":"arabic","description":"\n\t\n\t\t\n\t\tDataset Card for Arabic GSM8K\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nArabic GSM8K is an Arabic translation of the GSM8K (Grade School Math 8K) dataset, which contains high-quality linguistically diverse grade school math word problems. The original dataset was created to support the task of question answering on basic mathematical problems that require multi-step reasoning, and this Arabic version aims to extend these capabilities to Arabic language models and applications.\nThe datasetâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Omartificial-Intelligence-Space/Arabic-gsm8k.","url":"https://huggingface.co/datasets/Omartificial-Intelligence-Space/Arabic-gsm8k","creator_name":"Omartificial Intelligence Space","creator_url":"https://huggingface.co/Omartificial-Intelligence-Space","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["Arabic","mit","10K - 100K","parquet","Text"],"keywords_longer_than_N":true},
	{"name":"Arabic-gsm8k","keyword":"arabic","description":"\n\t\n\t\t\n\t\tDataset Card for Arabic GSM8K\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nArabic GSM8K is an Arabic translation of the GSM8K (Grade School Math 8K) dataset, which contains high-quality linguistically diverse grade school math word problems. The original dataset was created to support the task of question answering on basic mathematical problems that require multi-step reasoning, and this Arabic version aims to extend these capabilities to Arabic language models and applications.\nThe datasetâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Omartificial-Intelligence-Space/Arabic-gsm8k.","url":"https://huggingface.co/datasets/Omartificial-Intelligence-Space/Arabic-gsm8k","creator_name":"Omartificial Intelligence Space","creator_url":"https://huggingface.co/Omartificial-Intelligence-Space","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["Arabic","mit","10K - 100K","parquet","Text"],"keywords_longer_than_N":true},
	{"name":"rush","keyword":"arabic","description":"rushdiodeh/rush dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/rushdiodeh/rush","creator_name":"odeh","creator_url":"https://huggingface.co/rushdiodeh","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["token-classification","Arabic","apache-2.0","< 1K","csv"],"keywords_longer_than_N":true},
	{"name":"wmt24pp","keyword":"arabic","description":"\n\t\n\t\t\n\t\tWMT24++\n\t\n\nThis repository contains the human translation and post-edit data for the 55 en->xx language pairs released in\nthe publication\nWMT24++: Expanding the Language Coverage of WMT24 to 55 Languages & Dialects.\nIf you are interested in the MT/LLM system outputs and automatic metric scores, please see MTME.\nIf you are interested in the images of the source URLs for each document, please see here.\n\n\t\n\t\t\n\t\n\t\n\t\tSchema\n\t\n\nEach language pair is stored in its own jsonl file.\nEach row isâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/google/wmt24pp.","url":"https://huggingface.co/datasets/google/wmt24pp","creator_name":"Google","creator_url":"https://huggingface.co/google","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["translation","Arabic","Bulgarian","Bengali","Catalan"],"keywords_longer_than_N":true},
	{"name":"FiqhQA","keyword":"arabic","description":"\n\t\n\t\t\n\t\tDataset Card for Dataset Name\n\t\n\n\n\nPaper: Sacred or Synthetic? Evaluating LLM Reliability and Abstention for Religious Questions\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\n\n\nWe introduce a novel benchmark FiqhQA focused on the LLM generated Islamic rulings explicitly categorized by\nthe four major Sunni schools of thought, in both Arabic and English.\n\nCurated by: [Farah Atif, Nursultan Askarbekuly, Kareem Darwish and Monojit Choudhury]\n\nLanguage(s) (NLP): [ARABICâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/MBZUAI/FiqhQA.","url":"https://huggingface.co/datasets/MBZUAI/FiqhQA","creator_name":"Mohamed Bin Zayed University of Artificial Intelligence","creator_url":"https://huggingface.co/MBZUAI","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["question-answering","English","Arabic","mit","< 1K"],"keywords_longer_than_N":true},
	{"name":"CNTXTAI_Legal_Court_Cases","keyword":"arabic","description":"This dataset captures detailed structured information from 50 UAE court cases across 18 fields. It includes metadata about court types, jurisdictions, legal categories, case titles, and key dates. Designed to support legal domain research, the dataset is particularly rich in contextual and categorical features that can assist in case classification, jurisdiction mapping, and legal trend analysis.\nThis is a valuable dataset for the legal domain, especially for researchers, legal technologistsâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/CNTXTAI0/CNTXTAI_Legal_Court_Cases.","url":"https://huggingface.co/datasets/CNTXTAI0/CNTXTAI_Legal_Court_Cases","creator_name":"CNTXT AI","creator_url":"https://huggingface.co/CNTXTAI0","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":null,"first_N":5,"first_N_keywords":["text-classification","token-classification","Arabic","English","mit"],"keywords_longer_than_N":true},
	{"name":"x-fact","keyword":"arabic","description":"\n\t\n\t\t\n\t\tDataset Card for \"x-fact\"\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nX-FACT is a multilingual dataset for fact-checking with real world claims. The dataset contains short statments in 25 languages with top five evidence documents retrieved by performing google search with claim statements. The dataset contains two additional evaluation splits (in addition to a traditional test set): ood and zeroshot. ood measures out-of-domain generalization where while the languageâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/utahnlp/x-fact.","url":"https://huggingface.co/datasets/utahnlp/x-fact","creator_name":"NLP at University of Utah","creator_url":"https://huggingface.co/utahnlp","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","Arabic","Bengali","Spanish","Persian"],"keywords_longer_than_N":true},
	{"name":"OGC_Military","keyword":"arabic","description":"\n\t\n\t\t\n\t\tOGC - Organized, Grouped, Cleaned\n\t\n\n\n\t\n\t\t\n\t\tMilitary Vision DSE\n\t\n\n\nIntended for image/text to vector (DSE)\n\n\n\t\n\t\t\n\t\tDataset Composition\n\t\n\nMade with https://github.com/RacineAIOS/OGC_pdf-to-parquet\nThis dataset was created by scraping PDF documents from online sources and generating relevant synthetic queries.\nWe used Google's Gemini 2.0 Flash Lite model in our custom pipeline to produce the queries, allowing us to create a diverse set of questions based on the document content.â€¦ See the full description on the dataset page: https://huggingface.co/datasets/racineai/OGC_Military.","url":"https://huggingface.co/datasets/racineai/OGC_Military","creator_name":"racine.ai","creator_url":"https://huggingface.co/racineai","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["visual-document-retrieval","text-retrieval","English","French","Arabic"],"keywords_longer_than_N":true},
	{"name":"IUG_eLearning_Collections","keyword":"arabic","description":"\n## ÙˆØµÙ Ù…Ø¬Ù…ÙˆØ¹Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª\n\n\n\t\n\t\t\n\t\tÙ†Ø¸Ø±Ø© Ø¹Ø§Ù…Ø©\n\t\n\nØªØ­ØªÙˆÙŠ Ù‡Ø°Ù‡ Ø§Ù„Ù…Ø¬Ù…ÙˆØ¹Ø© Ø¹Ù„Ù‰ Ø¨ÙŠØ§Ù†Ø§Øª Ø­ÙˆÙ„ Ø§Ù„Ù…Ù‚Ø±Ø±Ø§Øª ÙˆØ§Ù„Ù…Ø¤ØªÙ…Ø±Ø§Øª Ø§Ù„Ù…ØªØ§Ø­Ø© Ø¹Ù„Ù‰ Ù…Ù†ØµØ© Ø§Ù„ØªØ¹Ù„Ù… Ø§Ù„Ø¥Ù„ÙƒØªØ±ÙˆÙ†ÙŠ Ø¨Ù…Ø±ÙƒØ² Ø§Ù„ØªØ¹Ù„Ù… Ø§Ù„Ø¥Ù„ÙƒØªØ±ÙˆÙ†ÙŠ [Ø§Ù„Ø¬Ø§Ù…Ø¹Ø© Ø§Ù„Ø¥Ø³Ù„Ø§Ù…ÙŠØ© Ø¨ØºØ²Ø© ]. ÙŠÙ…ÙƒÙ† Ø§Ø³ØªØ®Ø¯Ø§Ù… Ù‡Ø°Ù‡ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø§ØªØ¬Ø§Ù‡Ø§Øª ÙÙŠ Ù…Ø¬Ø§Ù„ Ø§Ù„ØªØ¹Ù„Ù… Ø§Ù„Ø¥Ù„ÙƒØªØ±ÙˆÙ†ÙŠØŒ ÙˆØªØ·ÙˆÙŠØ± ØªÙˆØµÙŠØ§Øª Ù…Ø®ØµØµØ© Ù„Ù„Ù…Ø³ØªØ®Ø¯Ù…ÙŠÙ†ØŒ ÙˆØ¨Ù†Ø§Ø¡ Ù†Ù…Ø§Ø°Ø¬ ØªÙ†Ø¨Ø¤ÙŠØ© Ù„Ø­Ø¶ÙˆØ± Ø§Ù„Ø¯ÙˆØ±Ø§Øª.\n\n\t\n\t\t\n\t\tÙ‡ÙŠÙƒÙ„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª\n\t\n\n\nsource_id:  Ù…Ø¹Ø±Ù ÙØ±ÙŠØ¯ Ù„Ù‚Ø§Ø¦Ù…Ø© ØªØ´ØºÙŠÙ„ Ø¹Ù„Ù‰  Ù…ÙˆÙ‚Ø¹ ÙŠÙˆØªÙŠÙˆØ¨ .\ntitle: Ø¹Ù†ÙˆØ§Ù† Ø§Ù„Ù…Ù‚Ø±Ø±Ø§Øª Ø£Ùˆ Ø§Ù„Ù…Ø¤ØªÙ…Ø±.\nfaculty_name: Ø§Ø³Ù… Ø§Ù„ÙƒÙ„ÙŠØ©.\ninstructor: Ø§Ø³Ù… Ø§Ù„Ù…Ø­Ø§Ø¶Ø±.â€¦ See the full description on the dataset page: https://huggingface.co/datasets/abdullah/IUG_eLearning_Collections.","url":"https://huggingface.co/datasets/abdullah/IUG_eLearning_Collections","creator_name":"Abdullah Abdelrhim","creator_url":"https://huggingface.co/abdullah","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["table-question-answering","Arabic","mit","< 1K","csv"],"keywords_longer_than_N":true},
	{"name":"librivox-tracks","keyword":"arabic","description":"A dataset of all audio files uploaded to LibriVox before 26th September 2023.\nForked from https://huggingface.co/datasets/pykeio/librivox-tracks\nChanges:\n\nUsed archive.org metadata API to annotate rows with \"duration\" column\n\n","url":"https://huggingface.co/datasets/xacer/librivox-tracks","creator_name":"xacer","creator_url":"https://huggingface.co/xacer","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-to-speech","automatic-speech-recognition","feature-extraction","Achinese","Afrikaans"],"keywords_longer_than_N":true},
	{"name":"multilingual-reward-bench","keyword":"arabic","description":"\n\t\n\t\t\n\t\tMultilingual Reward Bench (v1.0)\n\t\n\nReward models (RMs) have driven the development of state-of-the-art LLMs today, with unprecedented impact across the globe. However, their performance in multilingual settings still remains understudied. \nIn order to probe reward model behavior on multilingual data, we present M-RewardBench, a benchmark for 23 typologically diverse languages. \nM-RewardBench contains prompt-chosen-rejected preference triples obtained by curating and translating chatâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/CohereLabsCommunity/multilingual-reward-bench.","url":"https://huggingface.co/datasets/CohereLabsCommunity/multilingual-reward-bench","creator_name":"Cohere Labs Community","creator_url":"https://huggingface.co/CohereLabsCommunity","license_name":"Open Data Commons Attribution License v1.0","license_url":"https://scancode-licensedb.aboutcode.org/odc-by-1.0.html","language":"en","first_N":5,"first_N_keywords":["Arabic","Chinese","Czech","Dutch","French"],"keywords_longer_than_N":true},
	{"name":"include-lite-44","keyword":"arabic","description":"\n\t\n\t\t\n\t\tINCLUDE-lite (44 languages)\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\n\n\nPaper: http://arxiv.org/abs/2411.19799\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nINCLUDE is a comprehensive knowledge- and reasoning-centric benchmark across 44 languages that evaluates multilingual LLMs for performance in the actual language environments where they would be deployed. \nIt contains 11,095 4-option multiple-choice-questions (MCQ) extracted from academic and professional exams, covering 57 topics, including regionalâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/CohereLabs/include-lite-44.","url":"https://huggingface.co/datasets/CohereLabs/include-lite-44","creator_name":"Cohere Labs","creator_url":"https://huggingface.co/CohereLabs","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["multiple-choice","Albanian","Arabic","Armenian","Azerbaijani"],"keywords_longer_than_N":true},
	{"name":"ArabicQA_2.1M","keyword":"arabic","description":"\n\t\n\t\t\n\t\tArabic Question Answering Dataset\n\t\n\n\n\t\n\t\t\n\t\tDescription\n\t\n\n\n\t\n\t\t\n\t\tDataset Overview\n\t\n\nOur dataset is an amalgamation of several filtered datasets, the total number of rows for all datasets was 4,731,600 which was reduced to 2,141,146 rows after filtering. The dataset was collected to fine a pretraind model, the model forced a number of contrains on us discussed in the following section.\n\n\t\n\t\t\n\t\tFiltering Process\n\t\n\nThe filtering process for each dataset included one or more of theâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/riotu-lab/ArabicQA_2.1M.","url":"https://huggingface.co/datasets/riotu-lab/ArabicQA_2.1M","creator_name":"Robotics and Interne-of-Things","creator_url":"https://huggingface.co/riotu-lab","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["question-answering","Arabic","apache-2.0","1M - 10M","parquet"],"keywords_longer_than_N":true},
	{"name":"egyptian_test_set","keyword":"arabic","description":"Pre-processed Egyptian test partition from the MASC-dataset:\nMohammad Al-Fetyani, Muhammad Al-Barham, Gheith Abandah, Adham Alsharkawi, Maha Dawas, August 18, 2021, \"MASC: Massive Arabic Speech Corpus\", IEEE Dataport, doi: https://dx.doi.org/10.21227/e1qb-jv46.\n","url":"https://huggingface.co/datasets/otozz/egyptian_test_set","creator_name":"Ã–mer","creator_url":"https://huggingface.co/otozz","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["Arabic","cc-by-4.0","1K - 10K","parquet","Datasets"],"keywords_longer_than_N":true},
	{"name":"common_voice_21_0","keyword":"arabic","description":"\n\t\n\t\t\n\t\tDataset Card for Common Voice Corpus 21.0\n\t\n\n\n\nThis dataset is an unofficial version of the Mozilla Common Voice Corpus 21. It was downloaded and converted from the project's website https://commonvoice.mozilla.org/.\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nAbkhaz, Albanian, Amharic, Arabic, Armenian, Assamese, Asturian, Azerbaijani, Basaa, Bashkir, Basque, Belarusian, Bengali, Breton, Bulgarian, Cantonese, Catalan, Central Kurdish, Chinese (China), Chinese (Hong Kong), Chinese (Taiwan), Chuvash, Czechâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fsicoli/common_voice_21_0.","url":"https://huggingface.co/datasets/fsicoli/common_voice_21_0","creator_name":"Fabio Sicoli","creator_url":"https://huggingface.co/fsicoli","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":null,"first_N":5,"first_N_keywords":["automatic-speech-recognition","Abkhaz","Afrikaans","Amharic","Arabic"],"keywords_longer_than_N":true},
	{"name":"egyptian-arabic-sharegpt","keyword":"arabic","description":"\n\t\n\t\t\n\t\tEgyptian Arabic Conversations in ShareGPT Format\n\t\n\nThis dataset contains conversational examples in Egyptian Arabic dialect, formatted in the ShareGPT format \nwith 'from'/'value' fields that is compatible with Llama 3.1 fine-tuning using Unsloth.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nEach example contains:\n\nconversations: A list of messages with from and value fields\nsource: Origin of the data ('egyptian_arabic')\nscore: Quality score for the conversation (1.0)\n\n\n\t\n\t\t\n\t\tExample\n\t\n\n{â€¦ See the full description on the dataset page: https://huggingface.co/datasets/Rabe3/egyptian-arabic-sharegpt.","url":"https://huggingface.co/datasets/Rabe3/egyptian-arabic-sharegpt","creator_name":"mohamed ahmed rabiee","creator_url":"https://huggingface.co/Rabe3","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["Arabic","cc-by-4.0","10K - 100K","json","Text"],"keywords_longer_than_N":true},
	{"name":"egyptian-arabic-sharegpt","keyword":"arabic","description":"\n\t\n\t\t\n\t\tEgyptian Arabic Conversations in ShareGPT Format\n\t\n\nThis dataset contains conversational examples in Egyptian Arabic dialect, formatted in the ShareGPT format \nwith 'from'/'value' fields that is compatible with Llama 3.1 fine-tuning using Unsloth.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nEach example contains:\n\nconversations: A list of messages with from and value fields\nsource: Origin of the data ('egyptian_arabic')\nscore: Quality score for the conversation (1.0)\n\n\n\t\n\t\t\n\t\tExample\n\t\n\n{â€¦ See the full description on the dataset page: https://huggingface.co/datasets/Rabe3/egyptian-arabic-sharegpt.","url":"https://huggingface.co/datasets/Rabe3/egyptian-arabic-sharegpt","creator_name":"mohamed ahmed rabiee","creator_url":"https://huggingface.co/Rabe3","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["Arabic","cc-by-4.0","10K - 100K","json","Text"],"keywords_longer_than_N":true},
	{"name":"AURA-Sentiment","keyword":"arabic","description":"\n\t\n\t\t\n\t\tAURA-Sentiment\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe AURA Sentiment Dataset is a collection of 29,700 app reviews in Arabic from iOS and Android platforms. Each review is labeled with a sentiment class, enabling researchers and practitioners to develop and evaluate sentiment analysis models tailored to the Arabic language.\n\n\t\n\t\t\n\t\tFeatures\n\t\n\nThe dataset includes the following columns:\n\nreview: The text of the app review in Arabic.\nappName: The name of the application reviewed.â€¦ See the full description on the dataset page: https://huggingface.co/datasets/irfan-ahmad/AURA-Sentiment.","url":"https://huggingface.co/datasets/irfan-ahmad/AURA-Sentiment","creator_name":"Irfan Ahmad","creator_url":"https://huggingface.co/irfan-ahmad","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["Arabic","mit","10K - 100K","parquet","Text"],"keywords_longer_than_N":true},
	{"name":"AURA-Sentiment","keyword":"arabic","description":"\n\t\n\t\t\n\t\tAURA-Sentiment\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe AURA Sentiment Dataset is a collection of 29,700 app reviews in Arabic from iOS and Android platforms. Each review is labeled with a sentiment class, enabling researchers and practitioners to develop and evaluate sentiment analysis models tailored to the Arabic language.\n\n\t\n\t\t\n\t\tFeatures\n\t\n\nThe dataset includes the following columns:\n\nreview: The text of the app review in Arabic.\nappName: The name of the application reviewed.â€¦ See the full description on the dataset page: https://huggingface.co/datasets/irfan-ahmad/AURA-Sentiment.","url":"https://huggingface.co/datasets/irfan-ahmad/AURA-Sentiment","creator_name":"Irfan Ahmad","creator_url":"https://huggingface.co/irfan-ahmad","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["Arabic","mit","10K - 100K","parquet","Text"],"keywords_longer_than_N":true},
	{"name":"DeepAIM-AIM-G1","keyword":"arabic","description":"\n\t\n\t\t\n\t\tDeepAIM-AIMG1-2M\n\t\n\nDeepAIM-AIMG1-2M is a custom dataset built for training the DeepAIM artificial intelligence model (version: AIM-G1).This dataset is carefully structured to simulate realistic multi-turn conversations, emotions, and reasoning for building deep-response AI agents.\n\n\n\t\n\t\t\n\t\tðŸ§  Dataset Overview\n\t\n\n\nModel Target: AIM-G1 â€“ 2M parameters\nLanguage: English\nFocus Areas:\nDeep context understanding\nEmotion-aware responses\nDynamic response chains\nScolding / correction logicâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/QuickdigiLLC/DeepAIM-AIM-G1.","url":"https://huggingface.co/datasets/QuickdigiLLC/DeepAIM-AIM-G1","creator_name":"QuickDigi","creator_url":"https://huggingface.co/QuickdigiLLC","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-generation","question-answering","sentence-similarity","Arabic","English"],"keywords_longer_than_N":true},
	{"name":"BenchMAX_General_Translation","keyword":"arabic","description":"\n\t\n\t\t\n\t\tDataset Sources\n\t\n\n\nPaper: BenchMAX: A Comprehensive Multilingual Evaluation Suite for Large Language Models\nLink: https://huggingface.co/papers/2502.07346\nRepository: https://github.com/CONE-MT/BenchMAX\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nBenchMAX_General_Translation is a dataset of BenchMAX, which evaluates the translation capability on the general domain.\nWe collect parallel test data from Flore-200, TED-talk, and WMT24.\n\n\t\n\t\t\n\t\n\t\n\t\tUsage\n\t\n\nRun the following commands to generateâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/LLaMAX/BenchMAX_General_Translation.","url":"https://huggingface.co/datasets/LLaMAX/BenchMAX_General_Translation","creator_name":"LLaMAX","creator_url":"https://huggingface.co/LLaMAX","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["translation","multilingual","English","Chinese","Spanish"],"keywords_longer_than_N":true},
	{"name":"BenchMAX_Math","keyword":"arabic","description":"\n\t\n\t\t\n\t\tDataset Sources\n\t\n\n\nPaper: BenchMAX: A Comprehensive Multilingual Evaluation Suite for Large Language Models\nLink: https://huggingface.co/papers/2502.07346\nRepository: https://github.com/CONE-MT/BenchMAX\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nBenchMAX_Math is a dataset of BenchMAX, sourcing from MGSM, which evaluates the math reasoning capability in multilingual scenarios.\nWe extend the original MGSM dataset by six additional languages, i.e. Arabic, Czech, Hungarian, Korean, Serbian, andâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/LLaMAX/BenchMAX_Math.","url":"https://huggingface.co/datasets/LLaMAX/BenchMAX_Math","creator_name":"LLaMAX","creator_url":"https://huggingface.co/LLaMAX","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","multilingual","English","Chinese","Spanish"],"keywords_longer_than_N":true},
	{"name":"from-one-to-many-toxicity-mitigation","keyword":"arabic","description":"\n\t\n\t\t\n\t\n\t\n\t\tFrom One to Many: Expanding the Scope of Toxicity Mitigation in Language Models\n\t\n\n[arxiv][code][data]\nData accompanying the paper \"From One to Many: Expanding the Scope of Toxicity Mitigation in Language Models\" accepted to ACL Findings 2024.\nAbstract: To date, toxicity mitigation in language models has almost entirely been focused on single-language settings. As language models embrace multilingual capabilities, itâ€™s crucial our safety measures keep pace. Recognizing thisâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/luizapzbn/from-one-to-many-toxicity-mitigation.","url":"https://huggingface.co/datasets/luizapzbn/from-one-to-many-toxicity-mitigation","creator_name":"Luiza Pozzobon","creator_url":"https://huggingface.co/luizapzbn","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","text-classification","English","Portuguese","Hindi"],"keywords_longer_than_N":true},
	{"name":"arabic_functional_text_dimensions","keyword":"arabic","description":"\n\t\n\t\t\n\t\tDataset Card for Functional Text Dimensions for Arabic Text Classification.\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThe Arabic Functional Text Dimensions Corpus (AFTD Corpus) is introduced as a curated collection of Arabic documents aimed at evaluating text classification methodologies using the Functional Text Dimensions (FTD) approach. This corpus comprises 3,400 documents covering 17 distinct class categories, designed to enhance text classification in Arabic.\n\n\t\n\t\t\n\t\tSupported Tasks andâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/zeydferhat/arabic_functional_text_dimensions.","url":"https://huggingface.co/datasets/zeydferhat/arabic_functional_text_dimensions","creator_name":"ferhat","creator_url":"https://huggingface.co/zeydferhat","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","Arabic","apache-2.0","1K - 10K","csv"],"keywords_longer_than_N":true},
	{"name":"Multilingual-Benchmark","keyword":"arabic","description":"These are the GSM8K and ARC dataset translated by Google Translate. \nBibTex\n@misc{lu2024languagecountslearnunlearn,\n      title={Every Language Counts: Learn and Unlearn in Multilingual LLMs}, \n      author={Taiming Lu and Philipp Koehn},\n      year={2024},\n      eprint={2406.13748},\n      archivePrefix={arXiv},\n      primaryClass={cs.CL},\n      url={https://arxiv.org/abs/2406.13748}, \n}\n\n","url":"https://huggingface.co/datasets/TaiMingLu/Multilingual-Benchmark","creator_name":"TaiMing","creator_url":"https://huggingface.co/TaiMingLu","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["zero-shot-classification","question-answering","translation","English","German"],"keywords_longer_than_N":true},
	{"name":"h_a_z_i_m","keyword":"arabic","description":"hazim16/h_a_z_i_m dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/hazim16/h_a_z_i_m","creator_name":"Hassan","creator_url":"https://huggingface.co/hazim16","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["English","Arabic","mit","< 1K","Document"],"keywords_longer_than_N":true},
	{"name":"nahj-al-balagha","keyword":"arabic","description":"Ù†Ù‡Ø¬ Ø§Ù„Ø¨Ù„Ø§ØºØ© ÙˆÙ‡Ùˆ Ù…Ø¬Ù…ÙˆØ¹ Ù…Ø§ Ø§Ø®ØªØ§Ø±Ù‡ Ø§Ù„Ø´Ø±ÙŠÙ Ø§Ù„Ø±Ø¶ÙŠ Ù…Ù† ÙƒÙ„Ø§Ù… Ø³ÙŠØ¯Ù†Ø§ Ø£Ù…ÙŠØ± Ø§Ù„Ù…Ø¤Ù…Ù†ÙŠÙ† Ø¹Ù„ÙŠ Ø¨Ù† Ø£Ø¨ÙŠ Ø·Ø§Ù„Ø¨ Ø¹Ù„ÙŠÙ‡ Ø§Ù„Ø³Ù„Ø§Ù…\nØ´Ø±Ø­ Ø§Ù„Ø£Ø³ØªØ§Ø° Ø§Ù„Ø¥Ù…Ø§Ù… Ø§Ù„Ø´ÙŠØ® Ù…Ø­Ù…Ø¯ Ø¹Ø¨Ø¯Ø© Ù…ÙØªÙŠ Ø§Ù„Ø¯ÙŠØ§Ø± Ø§Ù„Ù…ØµØ±ÙŠØ© Ø³Ø§Ø¨Ù‚Ø§ Ø§Ù„Ø¬Ø²Ø¡ Ø§Ù„Ø£ÙˆÙ„\nØ§Ù„Ù†Ø§Ø´Ø± Ø¯Ø§Ø± Ø§Ù„Ù…Ø¹Ø±ÙØ© Ù„Ù„Ø·Ø¨Ø§Ø¹Ø© ÙˆØ§Ù„Ù†Ø´Ø± Ø¨ÙŠØ±ÙˆØª Ù„Ø¨Ù†Ø§Ù†\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThe Nahj al-Balagha dataset is a structured CSV file containing textual data from the renowned collection of sermons, letters, and maxims attributed to Imam Ali ibn Abi Talib (AS). Compiled by Sharif Razi in the 10th century, this dataset provides aâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/aliahabeeb/nahj-al-balagha.","url":"https://huggingface.co/datasets/aliahabeeb/nahj-al-balagha","creator_name":"ALi A. Habeeb","creator_url":"https://huggingface.co/aliahabeeb","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["Arabic","mit","< 1K","csv","Tabular"],"keywords_longer_than_N":true},
	{"name":"Ar-News","keyword":"arabic","description":"ArlonCarion/Ar-News dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/ArlonCarion/Ar-News","creator_name":"Arlon News","creator_url":"https://huggingface.co/ArlonCarion","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":null,"first_N":5,"first_N_keywords":["text-classification","Indonesian","Afar","Avestan","Afrikaans"],"keywords_longer_than_N":true},
	{"name":"u-sticker","keyword":"arabic","description":"\n\t\n\t\t\n\t\tU-Sticker\n\t\n\nUser-Sticker is a stickers dataset with multi-domain conversations.\nFeatures of U-Sticker:\n\nMulti-domain interactions âœ…\nTemporal âœ…\nUser information âœ…\n370.2k stickers âœ… (104k unique)\n22.6k users âœ…\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nU-Sticker contains three files:\n\nConversation files: 1 to 67.json\nDomain mapping files idx_to_domain.txt.\nSticker files.\n\n\nSticker files are available here and Baidu Cloud.\n\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\n\t\n\t\t\n\t\tConversation file\n\t\n\n\nEmpty lines areâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/metchee/u-sticker.","url":"https://huggingface.co/datasets/metchee/u-sticker","creator_name":"Metilda Chee","creator_url":"https://huggingface.co/metchee","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["Arabic","Chinese","English","French","Turkish"],"keywords_longer_than_N":true},
	{"name":"FineWeb2-MSA","keyword":"arabic","description":"\n\t\n\t\t\n\t\tFineWeb2 MSA Arabic\n\t\n\n\nThis is the MSA Arabic Portion of The FineWeb2 Dataset.\nThis dataset contains a rich collection of text in MSA Arabic (ISO 639-3: arz), a widely spoken dialect within the Afro-Asiatic language family. \nWith over 439 million words and 1.4 million documents, it serves as a valuable resource for NLP development and linguistic research focused on Egyptian Arabic.\n\n\t\n\t\n\t\n\t\tPurpose of This Repository\n\t\n\nThis repository provides easy access to the Arabic portion - MSAâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Omartificial-Intelligence-Space/FineWeb2-MSA.","url":"https://huggingface.co/datasets/Omartificial-Intelligence-Space/FineWeb2-MSA","creator_name":"Omartificial Intelligence Space","creator_url":"https://huggingface.co/Omartificial-Intelligence-Space","license_name":"Open Data Commons Attribution License v1.0","license_url":"https://scancode-licensedb.aboutcode.org/odc-by-1.0.html","language":"en","first_N":5,"first_N_keywords":["Arabic","odc-by","100M - 1B","text","Text"],"keywords_longer_than_N":true},
	{"name":"montok","keyword":"standard arabic","description":"\n\t\n\t\t\n\t\tMonTok: A Suite of Monolingual Tokenizers\n\t\n\nThis is a set of monolingual tokenizers for 98 languages. For each language, there are Unigram, BPE, and SuperBPE tokenizers, ranging in vocabulary size from around 6k to over 200k.\n\n\t\n\t\t\n\t\tTraining Details\n\t\n\n\n\t\n\t\t\n\t\tTraining Data\n\t\n\nAll tokenizers are trained on samples of the data used to the train the Goldfish language models. \nThe tokenizers were either trained on scaled or unscaled data. This refers to whether the models are trained onâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/catherinearnett/montok.","url":"https://huggingface.co/datasets/catherinearnett/montok","creator_name":"Catherine Arnett","creator_url":"https://huggingface.co/catherinearnett","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["Afrikaans","Tosk Albanian","Amharic","Standard Arabic","Assamese"],"keywords_longer_than_N":true},
	{"name":"CohereForAI_aya_dataset_Arabic","keyword":"egyptian arabic","description":"This Dataset Filterd From https://huggingface.co/datasets/CohereForAI/aya_dataset\n","url":"https://huggingface.co/datasets/MoMonir/CohereForAI_aya_dataset_Arabic","creator_name":"Mohamed Monir","creator_url":"https://huggingface.co/MoMonir","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["Standard Arabic","Moroccan Arabic","Najdi Arabic","Ta'izzi-Adeni Arabic","Egyptian Arabic"],"keywords_longer_than_N":true},
	{"name":"CohereForAI_aya_dataset_Arabic","keyword":"moroccan arabic","description":"This Dataset Filterd From https://huggingface.co/datasets/CohereForAI/aya_dataset\n","url":"https://huggingface.co/datasets/MoMonir/CohereForAI_aya_dataset_Arabic","creator_name":"Mohamed Monir","creator_url":"https://huggingface.co/MoMonir","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["Standard Arabic","Moroccan Arabic","Najdi Arabic","Ta'izzi-Adeni Arabic","Egyptian Arabic"],"keywords_longer_than_N":true},
	{"name":"CohereForAI_aya_dataset_Arabic","keyword":"najdi arabic","description":"This Dataset Filterd From https://huggingface.co/datasets/CohereForAI/aya_dataset\n","url":"https://huggingface.co/datasets/MoMonir/CohereForAI_aya_dataset_Arabic","creator_name":"Mohamed Monir","creator_url":"https://huggingface.co/MoMonir","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["Standard Arabic","Moroccan Arabic","Najdi Arabic","Ta'izzi-Adeni Arabic","Egyptian Arabic"],"keywords_longer_than_N":true},
	{"name":"CohereForAI_aya_dataset_Arabic","keyword":"standard arabic","description":"This Dataset Filterd From https://huggingface.co/datasets/CohereForAI/aya_dataset\n","url":"https://huggingface.co/datasets/MoMonir/CohereForAI_aya_dataset_Arabic","creator_name":"Mohamed Monir","creator_url":"https://huggingface.co/MoMonir","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["Standard Arabic","Moroccan Arabic","Najdi Arabic","Ta'izzi-Adeni Arabic","Egyptian Arabic"],"keywords_longer_than_N":true},
	{"name":"CohereForAI_aya_dataset_Arabic","keyword":"ta'izzi-adeni arabic","description":"This Dataset Filterd From https://huggingface.co/datasets/CohereForAI/aya_dataset\n","url":"https://huggingface.co/datasets/MoMonir/CohereForAI_aya_dataset_Arabic","creator_name":"Mohamed Monir","creator_url":"https://huggingface.co/MoMonir","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["Standard Arabic","Moroccan Arabic","Najdi Arabic","Ta'izzi-Adeni Arabic","Egyptian Arabic"],"keywords_longer_than_N":true},
	{"name":"arabic_english_dataset_for_lang_translations_tasks","keyword":"arabic","description":"amrosama/arabic_english_dataset_for_lang_translations_tasks dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/amrosama/arabic_english_dataset_for_lang_translations_tasks","creator_name":"amr osama","creator_url":"https://huggingface.co/amrosama","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":null,"first_N":5,"first_N_keywords":["apache-2.0","ðŸ‡ºðŸ‡¸ Region: US","translation","arabic"],"keywords_longer_than_N":false},
	{"name":"NoRobots-SambaLingo.Arabic.Chat-DPO","keyword":"arabic","description":"\n\t\n\t\t\n\t\tðŸ¤— Dataset Card for \"NoRobots-SambaLingo.Arabic.Chat-DPO\"\n\t\n\n\n\t\n\t\t\n\t\tDataset Sources & Infos\n\t\n\n\nData Origin: Derived from the Arabic No Robots dataset : 2A2I/H4_no_robots which is based on the original No Robots dataset inspired from the InstructGPT paper.\nLanguages: Modern Standard Arabic (MSA)\nLicense: CC BY-NC 4.0\nMaintainers: Ali Elfilali and Marwa El Kamil\n\n\n\t\n\t\n\t\n\t\tPurpose\n\t\n\nNoRobots-SambaLingo.Arabic.Chat-DPO is a DPO dataset designed to advance Arabic NLP by comparingâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/2A2I/NoRobots-SambaLingo.Arabic.Chat-DPO.","url":"https://huggingface.co/datasets/2A2I/NoRobots-SambaLingo.Arabic.Chat-DPO","creator_name":"2A2I","creator_url":"https://huggingface.co/2A2I","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["Arabic","apache-2.0","1K - 10K","parquet","Text"],"keywords_longer_than_N":true},
	{"name":"testing-dataset","keyword":"arabic","description":"MouadGhouti/testing-dataset dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/MouadGhouti/testing-dataset","creator_name":"Mouad Ghouti","creator_url":"https://huggingface.co/MouadGhouti","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["Arabic","English","mit","< 1K","csv"],"keywords_longer_than_N":true},
	{"name":"Shamela_Books_info","keyword":"arabic","description":"\n\t\n\t\t\n\t\tShamela Books information\n\t\n\nThis dataset contains structured metadata for 8,492 books sourced from the Shamela Library, with enhancements for clarity, consistency, and usability. It is intended to support NLP, bibliographic research, and digital humanities efforts involving Arabic texts.For full books text dataset please check shamela_books_text\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Features\n\t\n\nThe dataset includes the following cleaned and standardized features:\n\nUnification of Author Names: Authorâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/MoMonir/Shamela_Books_info.","url":"https://huggingface.co/datasets/MoMonir/Shamela_Books_info","creator_name":"Mohamed Monir","creator_url":"https://huggingface.co/MoMonir","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["Arabic","apache-2.0","1K - 10K","csv","Tabular"],"keywords_longer_than_N":true},
	{"name":"ANS_Corpus","keyword":"arabic","description":"\n\t\n\t\t\n\t\tDataset Card for \"ANS_Corpus: Arabic News Stance Corpus\"\n\t\n\n\n\t\n\t\t\n\t\tPaper:\n\t\n\nJude Khouja. 2020. Stance Prediction and Claim Verification: An Arabic Perspective. In Proceedings of the Third Workshop on Fact Extraction and VERification (FEVER), pages 8â€“17, Online. Association for Computational Linguistics.\n","url":"https://huggingface.co/datasets/asas-ai/ANS_Corpus","creator_name":"ASAS AI","creator_url":"https://huggingface.co/asas-ai","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","Arabic","apache-2.0","1K - 10K","parquet"],"keywords_longer_than_N":true},
	{"name":"english-egyptian-arabic_sentence-pairs_mt560","keyword":"egyptian arabic","description":"\n\t\n\t\t\n\t\tEnglish-Egyptian Arabic Parallel Dataset\n\t\n\nThis dataset contains parallel sentences in English and Egyptian Arabic (Egypt).\n\n\t\n\t\t\n\t\tDataset Information\n\t\n\n\nLanguage Pair: English â†” Egyptian Arabic\nLanguage Code: arz\nCountry: Egypt\nOriginal Source: OPUS MT560 Dataset\n\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nThe dataset contains parallel sentences that can be used for:\n\nMachine translation training\nCross-lingual NLP tasks\nLanguage model fine-tuning\n\n\n\t\n\t\t\n\t\tCitation\n\t\n\nIf you use this datasetâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/michsethowusu/english-egyptian-arabic_sentence-pairs_mt560.","url":"https://huggingface.co/datasets/michsethowusu/english-egyptian-arabic_sentence-pairs_mt560","creator_name":"Mich-Seth Owusu","creator_url":"https://huggingface.co/michsethowusu","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["translation","original","English","Egyptian Arabic","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"librivox-tracks","keyword":"arabic","description":"A dataset of all audio files uploaded to LibriVox before 26th September 2023.\n","url":"https://huggingface.co/datasets/pykeio/librivox-tracks","creator_name":"pyke.io","creator_url":"https://huggingface.co/pykeio","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-to-speech","automatic-speech-recognition","Achinese","Afrikaans","Ancient Greek (to 1453)"],"keywords_longer_than_N":true},
	{"name":"summarized-darija-msa-wiki-data","keyword":"arabic","description":"\n\t\n\t\t\n\t\tMSA-Darija Summarization Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis is the EMINES organization-hosted version of the MSA-Darija Summarization Dataset, synchronized with the original dataset. It contains 4800 rows of Moroccan and Arabic texts with Arabic summarization, designed for developing summarization models.\n\n\t\n\t\t\n\t\tQuick Start\n\t\n\nfrom datasets import load_dataset\n\n# Load the dataset\ndataset = load_dataset(\"EMINES/summarized-darija-msa-wiki-data\")\n\n# Example usage\nfor example inâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/EMINES/summarized-darija-msa-wiki-data.","url":"https://huggingface.co/datasets/EMINES/summarized-darija-msa-wiki-data","creator_name":"EMINES, UM6P, Benguerir, Maroc","creator_url":"https://huggingface.co/EMINES","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["summarization","Arabic","apache-2.0","1K - 10K","parquet"],"keywords_longer_than_N":true},
	{"name":"summarized-darija-msa-wiki-data","keyword":"arabic","description":"\n\t\n\t\t\n\t\tMSA-Darija Summarization Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis is the EMINES organization-hosted version of the MSA-Darija Summarization Dataset, synchronized with the original dataset. It contains 4800 rows of Moroccan and Arabic texts with Arabic summarization, designed for developing summarization models.\n\n\t\n\t\t\n\t\tQuick Start\n\t\n\nfrom datasets import load_dataset\n\n# Load the dataset\ndataset = load_dataset(\"EMINES/summarized-darija-msa-wiki-data\")\n\n# Example usage\nfor example inâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/EMINES/summarized-darija-msa-wiki-data.","url":"https://huggingface.co/datasets/EMINES/summarized-darija-msa-wiki-data","creator_name":"EMINES, UM6P, Benguerir, Maroc","creator_url":"https://huggingface.co/EMINES","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["summarization","Arabic","apache-2.0","1K - 10K","parquet"],"keywords_longer_than_N":true},
	{"name":"fiNERweb","keyword":"arabic","description":"fiNERweb is a multilingual named entity recognition dataset containing annotated text in multiple languages.\nEach example contains the original text, tokenized text, BIO tags, and character/token spans for entities.","url":"https://huggingface.co/datasets/whoisjones/fiNERweb","creator_name":"Jonas Golde","creator_url":"https://huggingface.co/whoisjones","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":null,"first_N":5,"first_N_keywords":["token-classification","named-entity-recognition","Vietnamese","Tamil","Oriya"],"keywords_longer_than_N":true},
	{"name":"multilingual-text","keyword":"arabic","description":"\n\t\n\t\t\n\t\tMultilingual Text Dataset\n\t\n\nThis dataset contains a curated selection of rows from multiple input datasets, where each row includes a text chunk of approximately 2000 tokens (as measured by Llama 3.1 tokenizer) verified to be written in the correct language. Only rows with properly classified language chunks are retained, ensuring high-quality multilingual data for analysis or model training.\n\n\t\n\t\t\n\t\tPreprocessing Steps\n\t\n\n\nNormalized whitespace, punctuation, Unicode characters, andâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/agentlans/multilingual-text.","url":"https://huggingface.co/datasets/agentlans/multilingual-text","creator_name":"Alan Tseng","creator_url":"https://huggingface.co/agentlans","license_name":"Open Data Commons Attribution License v1.0","license_url":"https://scancode-licensedb.aboutcode.org/odc-by-1.0.html","language":"en","first_N":5,"first_N_keywords":["text-generation","text-classification","Amharic","Arabic","Bengali"],"keywords_longer_than_N":true},
	{"name":"UN-Arabic-English-Filtered","keyword":"arabic","description":"\n\t\n\t\t\n\t\tDataset Details\n\t\n\nMultiUN + UNPC datasets, with rule-based and semantic filtering (train > 0.45 - test/dev > 0.9)\nas well as (>= 0.1) fasttext language detection.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nDatasetDict({\n    train: Dataset({\n        features: ['text_en', 'text_ar'],\n        num_rows: 19279407\n    })\n    test: Dataset({\n        features: ['text_en', 'text_ar'],\n        num_rows: 8752\n    })\n    dev: Dataset({\n        features: ['text_en', 'text_ar'],\n        num_rows: 8752\n    })\n})â€¦ See the full description on the dataset page: https://huggingface.co/datasets/ymoslem/UN-Arabic-English-Filtered.","url":"https://huggingface.co/datasets/ymoslem/UN-Arabic-English-Filtered","creator_name":"Yasmin Moslem","creator_url":"https://huggingface.co/ymoslem","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["translation","Arabic","English","cc-by-4.0","10M - 100M"],"keywords_longer_than_N":true},
	{"name":"Chatgpt","keyword":"arabic","description":"\n\t\n\t\t\n\t\tOpenAssistant Conversations Dataset (OASST1)\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nIn an effort to democratize research on large-scale alignment, we release OpenAssistant \nConversations (OASST1), a human-generated, human-annotated assistant-style conversation \ncorpus consisting of 161,443 messages in 35 different languages, annotated with 461,292 \nquality ratings, resulting in over 10,000 fully annotated conversation trees. The corpus \nis a product of a worldwide crowd-sourcing effortâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/RajChat/Chatgpt.","url":"https://huggingface.co/datasets/RajChat/Chatgpt","creator_name":"Rajdeep Chatterjee ","creator_url":"https://huggingface.co/RajChat","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["English","Spanish","Russian","German","Polish"],"keywords_longer_than_N":true},
	{"name":"prophet-mosque-library-compressed","keyword":"arabic","description":"\n\t\n\t\t\n\t\tProphet's Mosque Library - Compressed\n\t\n\n\n\t\n\t\t\n\t\tðŸ“– Overview\n\t\n\nProphetâ€™s Mosque Library is one of the primary resources for Islamic books. It hosts more than 48,000 PDF books across over 70 categories.\nIn this dataset, we processed the original PDF files using Google Document AI APIs and extracted their contents into two additional formats: TXT and DOCX.\n\n\t\n\t\t\n\t\tðŸ“Š Dataset Contents\n\t\n\nThis dataset is identical to ieasybooks-org/prophet-mosque-library, with one key difference: theâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/ieasybooks-org/prophet-mosque-library-compressed.","url":"https://huggingface.co/datasets/ieasybooks-org/prophet-mosque-library-compressed","creator_name":"Ø§Ù„ÙƒØªØ¨ Ø§Ù„Ù…ÙÙŠØ³Ù‘Ø±Ø©","creator_url":"https://huggingface.co/ieasybooks-org","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["image-to-text","Arabic","mit","10K - 100K","csv"],"keywords_longer_than_N":true},
	{"name":"common_voice_22_0","keyword":"arabic","description":"\n\t\n\t\t\n\t\tDataset Card for Common Voice Corpus 22.0\n\t\n\n\n\nThis dataset is an unofficial version of the Mozilla Common Voice Corpus 22. It was downloaded and converted from the project's website https://commonvoice.mozilla.org/.\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nAbkhaz, Albanian, Amharic, Arabic, Armenian, Assamese, Asturian, Azerbaijani, Basaa, Bashkir, Basque, Belarusian, Bengali, Breton, Bulgarian, Cantonese, Catalan, Central Kurdish, Chinese (China), Chinese (Hong Kong), Chinese (Taiwan), Chuvash, Czechâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fsicoli/common_voice_22_0.","url":"https://huggingface.co/datasets/fsicoli/common_voice_22_0","creator_name":"Fabio Sicoli","creator_url":"https://huggingface.co/fsicoli","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":null,"first_N":5,"first_N_keywords":["automatic-speech-recognition","Abkhaz","Afrikaans","Amharic","Arabic"],"keywords_longer_than_N":true},
	{"name":"InstAr-500k","keyword":"arabic","description":"\n\t\n\t\t\n\t\tDataset Card for \"InstAr-500k\"\n\t\n\nThe dataset comprises almost 500,000 Arabic instructions and responses designed for fine-tuning large language models (LLMs) for Arabic NLP tasks. It includes a combination of synthetic and human-crafted data across various domains and instruction types. This extensive dataset aims to improve the performance of LLMs on Arabic-specific tasks\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\n\n  \n    Type\n    Task\n    Number of Samples\n    Percentage of Samplesâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/ClusterlabAi/InstAr-500k.","url":"https://huggingface.co/datasets/ClusterlabAi/InstAr-500k","creator_name":"ClusterlabAi","creator_url":"https://huggingface.co/ClusterlabAi","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["question-answering","summarization","text-classification","Arabic","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"bordirlines","keyword":"arabic","description":"\n\t\n\t\t\n\t\tBordIRLines Dataset\n\t\n\nThis is the dataset associated with the paper \"BordIRlines: A Dataset for Evaluating Cross-lingual Retrieval-Augmented Generation\" (link).\nCode: https://github.com/manestay/bordIRlines\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThe BordIRLines Dataset is an information retrieval (IR) dataset constructed from various language corpora. It contains queries and corresponding ranked docs along with their relevance scores. The dataset includes multiple languages, including Englishâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/borderlines/bordirlines.","url":"https://huggingface.co/datasets/borderlines/bordirlines","creator_name":"cross-lingual LLMs and RAG","creator_url":"https://huggingface.co/borderlines","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":null,"first_N":5,"first_N_keywords":["question-answering","human","machine-generated","found","multilingual"],"keywords_longer_than_N":true},
	{"name":"afri-aya","keyword":"arabic","description":"\n\t\n\t\t\n\t\tAfri-Aya ðŸŒ\n\t\n\nGiving Sight to African LLMs\nAfri-Aya is a community-curated multilingual image dataset covering 13 major African languages with AI-powered categorization, created as part of Expedition Aya - a six-week global open-build challenge hosted by Cohere Labs.\n\n\t\n\t\t\n\t\tProject Background\n\t\n\nThis dataset was developed by the Cohere Labs Regional Africa community during Expedition Aya, aiming to include more African low-resource languages and their cultures in Vision Languageâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/CohereLabsCommunity/afri-aya.","url":"https://huggingface.co/datasets/CohereLabsCommunity/afri-aya","creator_name":"Cohere Labs Community","creator_url":"https://huggingface.co/CohereLabsCommunity","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["image-to-text","visual-question-answering","text-generation","English","Ganda"],"keywords_longer_than_N":true},
	{"name":"text_ratings","keyword":"arabic","description":"Todo - Write dataset card\n","url":"https://huggingface.co/datasets/lightblue/text_ratings","creator_name":"Lightblue KK.","creator_url":"https://huggingface.co/lightblue","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["Amharic","Arabic","Bulgarian","Bengali","Czech"],"keywords_longer_than_N":true},
	{"name":"EgyptianHellaSwag","keyword":"egyptian arabic","description":"\n\t\n\t\t\n\t\tDataset Card for EgyptianHellaSwag\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nEgyptianHellaSwag is a challenging multiple-choice benchmark designed to\nevaluate machine reading comprehension and commonsense reasoning in Egyptian\nArabic (Masri). It is a translated version of the HellaSwag train, validation,\nand test sets which presents scenarios where models must choose the most\nplausible continuation of a passage from four options.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\n\nTask Category: Multiple-choice questionâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/MBZUAI-Paris/EgyptianHellaSwag.","url":"https://huggingface.co/datasets/MBZUAI-Paris/EgyptianHellaSwag","creator_name":"MBZUAI-IFM Paris Lab","creator_url":"https://huggingface.co/MBZUAI-Paris","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["question-answering","multiple-choice-qa","machine-translated","machine-translated","translation"],"keywords_longer_than_N":true},
	{"name":"xm3600","keyword":"arabic","description":"\n\t\n\t\t\n\t\n\t\n\t\tXM3600 - Crossmodal-3600\n\t\n\n\n\t\n\t\t\n\t\n\t\n\t\tThis is a copy from https://google.github.io/crossmodal-3600/\n\t\n\nIf you use this dataset, please cite the original authors:\n@inproceedings{ThapliyalCrossmodal2022,\n  author = {Ashish Thapliyal and Jordi Pont-Tuset and Xi Chen and Radu Soricut},\n  title = {{Crossmodal-3600: A Massively Multilingual Multimodal Evaluation Dataset}},\n  booktitle = {EMNLP},\n  year = {2022}\n}\n\nIt also includes the image features as PIL Image and has a uniform andâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/floschne/xm3600.","url":"https://huggingface.co/datasets/floschne/xm3600","creator_name":"Flo Schneider","creator_url":"https://huggingface.co/floschne","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["image-to-text","Arabic","Bengali","Czech","Danish"],"keywords_longer_than_N":true},
	{"name":"ExaAEC","keyword":"arabic","description":"\n\t\n\t\t\n\t\tDataset Card for \"ExaAEC: A New Multi-label Emotion Classification Corpus in Arabic Tweets\"\n\t\n\n\n\t\n\t\t\n\t\tPaper:\n\t\n\nS. Sarbazi-Azad, A. Akbari and M. Khazeni, \"ExaAEC: A New Multi-label Emotion Classification Corpus in Arabic Tweets,\" 2021 11th International Conference on Computer Engineering and Knowledge (ICCKE), Mashhad, Iran, Islamic Republic of, 2021, pp. 465-470, doi: 10.1109/ICCKE54056.2021.9721493. \n","url":"https://huggingface.co/datasets/asas-ai/ExaAEC","creator_name":"ASAS AI","creator_url":"https://huggingface.co/asas-ai","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","Arabic","apache-2.0","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"rightnow-arabic-llm-corpus","keyword":"arabic","description":"\n\n\t\n\t\t\n\t\tRightNow Arabic LLM Corpus\n\t\n\nThe largest and highest-quality Arabic language model training dataset, featuring 743,288 meticulously cleaned articles with 244 million words of professional Arabic text.\n\n\t\n\t\t\n\t\tAbout RightNow AI\n\t\n\nThis dataset was collected by the RightNow AI team, creators of the #1 GPU-powered AI code editor. Visit us at https://rightnowai.co/\n\n\t\n\t\t\n\t\tDataset Statistics\n\t\n\n\n\t\n\t\t\nMetric\nValue\n\n\n\t\t\nTotal Articles\n743,288\n\n\nTotal Words\n244,000,000+\n\n\nDataset Size\n8.7â€¦ See the full description on the dataset page: https://huggingface.co/datasets/Jr23xd23/rightnow-arabic-llm-corpus.","url":"https://huggingface.co/datasets/Jr23xd23/rightnow-arabic-llm-corpus","creator_name":"Jaber","creator_url":"https://huggingface.co/Jr23xd23","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","text-classification","token-classification","question-answering","summarization"],"keywords_longer_than_N":true},
	{"name":"rightnow-arabic-llm-corpus","keyword":"arabic","description":"\n\n\t\n\t\t\n\t\tRightNow Arabic LLM Corpus\n\t\n\nThe largest and highest-quality Arabic language model training dataset, featuring 743,288 meticulously cleaned articles with 244 million words of professional Arabic text.\n\n\t\n\t\t\n\t\tAbout RightNow AI\n\t\n\nThis dataset was collected by the RightNow AI team, creators of the #1 GPU-powered AI code editor. Visit us at https://rightnowai.co/\n\n\t\n\t\t\n\t\tDataset Statistics\n\t\n\n\n\t\n\t\t\nMetric\nValue\n\n\n\t\t\nTotal Articles\n743,288\n\n\nTotal Words\n244,000,000+\n\n\nDataset Size\n8.7â€¦ See the full description on the dataset page: https://huggingface.co/datasets/Jr23xd23/rightnow-arabic-llm-corpus.","url":"https://huggingface.co/datasets/Jr23xd23/rightnow-arabic-llm-corpus","creator_name":"Jaber","creator_url":"https://huggingface.co/Jr23xd23","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","text-classification","token-classification","question-answering","summarization"],"keywords_longer_than_N":true},
	{"name":"recitation-segmentation-augmented","keyword":"arabic","description":"\n\t\n\t\t\n\t\tAutomatic Pronunciation Error Detection and Correction of the Holy Quran's Learners Using Deep Learning\n\t\n\nPaper | Project Page | Code\n\n\t\n\t\t\n\t\tIntroduction\n\t\n\nThis dataset is developed as part of the research presented in the paper \"Automatic Pronunciation Error Detection and Correction of the Holy Quran's Learners Using Deep Learning\". The work introduces a 98% automated pipeline to produce high-quality Quranic datasets, comprising over 850 hours of audio (~300K annotated utterances).â€¦ See the full description on the dataset page: https://huggingface.co/datasets/obadx/recitation-segmentation-augmented.","url":"https://huggingface.co/datasets/obadx/recitation-segmentation-augmented","creator_name":"Abdullah","creator_url":"https://huggingface.co/obadx","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","Arabic","mit","10K - 100K","Tabular"],"keywords_longer_than_N":true},
	{"name":"recitation-segmentation-augmented","keyword":"arabic","description":"\n\t\n\t\t\n\t\tAutomatic Pronunciation Error Detection and Correction of the Holy Quran's Learners Using Deep Learning\n\t\n\nPaper | Project Page | Code\n\n\t\n\t\t\n\t\tIntroduction\n\t\n\nThis dataset is developed as part of the research presented in the paper \"Automatic Pronunciation Error Detection and Correction of the Holy Quran's Learners Using Deep Learning\". The work introduces a 98% automated pipeline to produce high-quality Quranic datasets, comprising over 850 hours of audio (~300K annotated utterances).â€¦ See the full description on the dataset page: https://huggingface.co/datasets/obadx/recitation-segmentation-augmented.","url":"https://huggingface.co/datasets/obadx/recitation-segmentation-augmented","creator_name":"Abdullah","creator_url":"https://huggingface.co/obadx","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","Arabic","mit","10K - 100K","Tabular"],"keywords_longer_than_N":true},
	{"name":"xm3600_1k","keyword":"arabic","description":"\n\t\n\t\t\n\t\n\t\n\t\tXM3600 - Crossmodal-3600 - 1K Split\n\t\n\n\n\t\n\t\t\n\t\n\t\n\t\tThis is a copy from https://google.github.io/crossmodal-3600/\n\t\n\nIf you use this dataset, please cite the original authors:\n@inproceedings{ThapliyalCrossmodal2022,\n  author = {Ashish Thapliyal and Jordi Pont-Tuset and Xi Chen and Radu Soricut},\n  title = {{Crossmodal-3600: A Massively Multilingual Multimodal Evaluation Dataset}},\n  booktitle = {EMNLP},\n  year = {2022}\n}\n\n\n\t\n\t\t\n\t\n\t\n\t\tThis is a 1K split of XM3600!\n\t\n\nFor this, weâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/floschne/xm3600_1k.","url":"https://huggingface.co/datasets/floschne/xm3600_1k","creator_name":"Flo Schneider","creator_url":"https://huggingface.co/floschne","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["image-to-text","Arabic","Bengali","Czech","Danish"],"keywords_longer_than_N":true},
	{"name":"Saka-Alpaca-v1","keyword":"arabic","description":"https://chatgpt.com\n","url":"https://huggingface.co/datasets/Sakalti/Saka-Alpaca-v1","creator_name":"sakasan","creator_url":"https://huggingface.co/Sakalti","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","Swedish","Norwegian","Finnish","German"],"keywords_longer_than_N":true},
	{"name":"quran_recitations_phonemes","keyword":"arabic","description":"\n\t\n\t\t\n\t\tPhoneme-labelled Quran Datatset\n\t\n\nThis dataset contains recitations from 45 professional Quran reciters, sourced from EveryAyah and QUL.\nThe audio has been automatically phoneme-labelled using a custom phonemizer that encodes Tajweed rules.\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Structure\n\t\n\n\naudio: 16 kHz resampled mono audio\n\nduration: length of the audio in seconds\n\nverse: reference in {surah_num}_{ayah_num} format\n\nreciter: name of the Qari\n\ntext: diacritised text in Uthmani script\n\nphonemes:â€¦ See the full description on the dataset page: https://huggingface.co/datasets/hetchyy/quran_recitations_phonemes.","url":"https://huggingface.co/datasets/hetchyy/quran_recitations_phonemes","creator_name":"Ahmed Ibrahim","creator_url":"https://huggingface.co/hetchyy","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","Arabic","cc-by-4.0","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"BenchMAX_Rule-based","keyword":"arabic","description":"\n\t\n\t\t\n\t\tDataset Sources\n\t\n\n\nPaper: BenchMAX: A Comprehensive Multilingual Evaluation Suite for Large Language Models\nLink: https://huggingface.co/papers/2502.07346\nRepository: https://github.com/CONE-MT/BenchMAX\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nBenchMAX_Rule-based is a dataset of BenchMAX, sourcing from IFEval, which is a rule-based benchmark for evaluating the instruction following capabilities in multilingual scenarios.\nWe extend the original dataset to 16 non-English languages by firstâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/LLaMAX/BenchMAX_Rule-based.","url":"https://huggingface.co/datasets/LLaMAX/BenchMAX_Rule-based","creator_name":"LLaMAX","creator_url":"https://huggingface.co/LLaMAX","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","multilingual","English","Chinese","Spanish"],"keywords_longer_than_N":true},
	{"name":"UPRPRC_docfiles_from_UN","keyword":"arabic","description":"This datasets contains all the raw DOC file crawl from United Nations Digital Library, produced by https://github.com/mnbvc-parallel-corpus-team/UPRPRC/blob/v2_record_spider/scripts/v4_list2doc.py, using the index in https://huggingface.co/datasets/bot-yaya/documents.un.org_search_result.\nIf you are writing spider script to download all these files, you can do increment download based on this dataset.\nOur UPRPRC project: https://github.com/mnbvc-parallel-corpus-team/UPRPRC\nAttention: Recordâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/bot-yaya/UPRPRC_docfiles_from_UN.","url":"https://huggingface.co/datasets/bot-yaya/UPRPRC_docfiles_from_UN","creator_name":"yaya","creator_url":"https://huggingface.co/bot-yaya","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["translation","Arabic","Spanish","Chinese","English"],"keywords_longer_than_N":true},
	{"name":"Arabic-NLi-Pair-Class","keyword":"arabic","description":"\n\t\n\t\t\n\t\tArabic NLI Pair-Class\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\n\nThe Arabic Version of SNLI and MultiNLI datasets. (Pair-Class Subset)\nOriginally used for Natural Language Inference (NLI),\nDataset may be used for training/finetuning an embedding model for semantic textual similarity.\n\n\n\t\n\t\t\n\t\tPair-Class Subset\n\t\n\n\nColumns: \"premise\", \"hypothesis\", \"label\"\nColumn types: str, str, class with {\"0\": \"entailment\", \"1\": \"neutral\", \"2\": \"contradiction\"}\n\n\n\t\n\t\t\n\t\tArabic Examples:\n\t\n\n{\n  \"premise\": \"Ø´Ø®Øµâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Omartificial-Intelligence-Space/Arabic-NLi-Pair-Class.","url":"https://huggingface.co/datasets/Omartificial-Intelligence-Space/Arabic-NLi-Pair-Class","creator_name":"Omartificial Intelligence Space","creator_url":"https://huggingface.co/Omartificial-Intelligence-Space","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["sentence-similarity","Arabic","apache-2.0","100K - 1M","csv"],"keywords_longer_than_N":true},
	{"name":"mmarco-hard-negatives-reranker-score","keyword":"arabic","description":"\nhotchpotch/mmarco-hard-negatives-reranker-score\n\nThis repository contains data from mMARCO scored using the reranker BAAI/bge-reranker-v2-m3.\n\n\t\n\t\t\n\t\tLanguages Covered\n\t\n\ntarget_languages = [\n    \"english\",\n    \"chinese\", \n    \"french\",\n    \"german\",\n    \"indonesian\",\n    \"italian\",\n    \"portuguese\",\n    \"russian\",\n    \"spanish\",\n    \"arabic\",\n    \"dutch\",\n    \"hindi\",\n    \"japanese\",\n    \"vietnamese\"\n]\n\n\n\t\n\t\t\n\t\tHard Negative Data\n\t\n\nThe hard negative data is derived fromâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/hotchpotch/mmarco-hard-negatives-reranker-score.","url":"https://huggingface.co/datasets/hotchpotch/mmarco-hard-negatives-reranker-score","creator_name":"Yuichi Tateno","creator_url":"https://huggingface.co/hotchpotch","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["English","Chinese","French","German","Indonesian"],"keywords_longer_than_N":true},
	{"name":"Ar-BeaverTails-Evaluation","keyword":"arabic","description":"\n\t\n\t\t\n\t\tIntroduction\n\t\n\nThis is the Arabic version of BeaverTails-Evaluation.\nBeaverTails-Evaluation is a dataset designed to assess the safety of large language models. It contains prompts that are likely to provoke the model into generating offensive language. This dataset helps determine whether the model can maintain human values when confronted with offensive questions.\n\n\t\n\t\t\n\t\tExample\n\t\n\nHere is the first sample of this dataset.\n{\n  \"prompt\": \"What's the most painful way to skin a catâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/FreedomIntelligence/Ar-BeaverTails-Evaluation.","url":"https://huggingface.co/datasets/FreedomIntelligence/Ar-BeaverTails-Evaluation","creator_name":"FreedomAI","creator_url":"https://huggingface.co/FreedomIntelligence","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["Arabic","English","apache-2.0","< 1K","json"],"keywords_longer_than_N":true},
	{"name":"aya_collection_language_split","keyword":"arabic","description":"\nThis is a re-upload of the aya_collection, and only differs in the structure of upload. While the original aya_collection is structured by folders split according to dataset name, this dataset is split by language. We recommend you use this version of the dataset if you are only interested in downloading all of the Aya collection for a single or smaller set of languages.\n\n\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThe Aya Collection is a massive multilingual collection consisting of 513 million instances ofâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/CohereLabs/aya_collection_language_split.","url":"https://huggingface.co/datasets/CohereLabs/aya_collection_language_split","creator_name":"Cohere Labs","creator_url":"https://huggingface.co/CohereLabs","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["Achinese","Afrikaans","Amharic","Arabic","Azerbaijani"],"keywords_longer_than_N":true},
	{"name":"Tamazight-ASR-Dataset-v2","keyword":"arabic","description":"\n\t\n\t\t\n\t\tTamazight-Arabic Speech Recognition Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset contains speech segments in Tamazight (specifically focusing on the Tachelhit dialect) paired with their corresponding Arabic transcriptions. It is designed to support the development of automatic speech recognition (ASR) systems for the Tamazight language, particularly for translation into Modern Standard Arabic.\nThis is an actively growing dataset, with regular updates and new data points beingâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/SoufianeDahimi/Tamazight-ASR-Dataset-v2.","url":"https://huggingface.co/datasets/SoufianeDahimi/Tamazight-ASR-Dataset-v2","creator_name":"Soufiane Dahimi","creator_url":"https://huggingface.co/SoufianeDahimi","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","Arabic","Standard Moroccan Tamazight","apache-2.0","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"imatrix-calibration","keyword":"arabic","description":"\n\t\n\t\t\n\t\tImportance Matrix Calibration Datasets\n\t\n\nThis repository contains calibration datasets used to generate importance matrices (imatrix), which in turn help minimise errors introduced during quantization.\n\n\t\n\t\t\n\t\tMath calibration datasets\n\t\n\nThis dataset consists of over 10M tokens of cleaned math prompts and is available in six sizes, ranging from huge (~ 430,000 lines equivalent to approx. 10M tokens), to micro (~ 13,700 lines and 1.7M tokens avg).\nOriginal data sourced fromâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/eaddario/imatrix-calibration.","url":"https://huggingface.co/datasets/eaddario/imatrix-calibration","creator_name":"Ed Addario","creator_url":"https://huggingface.co/eaddario","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-generation","Arabic","Chinese","German","English"],"keywords_longer_than_N":true},
	{"name":"Multi-lingual_Detection","keyword":"arabic","description":"Manirathinam21/Multi-lingual_Detection dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/Manirathinam21/Multi-lingual_Detection","creator_name":"Manirathinam","creator_url":"https://huggingface.co/Manirathinam21","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","Arabic","Tamil","Japanese","English"],"keywords_longer_than_N":true},
	{"name":"levantine_test_set","keyword":"arabic","description":"Pre-processed Levantine test partition from the MASC-dataset:\nMohammad Al-Fetyani, Muhammad Al-Barham, Gheith Abandah, Adham Alsharkawi, Maha Dawas, August 18, 2021, \"MASC: Massive Arabic Speech Corpus\", IEEE Dataport, doi: https://dx.doi.org/10.21227/e1qb-jv46.\n","url":"https://huggingface.co/datasets/otozz/levantine_test_set","creator_name":"Ã–mer","creator_url":"https://huggingface.co/otozz","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["Arabic","cc-by-4.0","1K - 10K","parquet","Datasets"],"keywords_longer_than_N":true},
	{"name":"epfml-FineWeb2-HQ-sample","keyword":"arabic","description":"\n\t\n\t\t\n\t\tepfml/FineWeb2-HQ\n\t\n\nA curated subset of the epfml/FineWeb2-HQ dataset featuring high-quality multilingual text.\n\n\t\n\t\t\n\t\tDetails\n\t\n\n\nFirst 25â€‰000 rows per config (language and script pair)\nDuplicates removed\nTexts truncated to 512 LLaMA 3.1 tokens\nScores transformed with log10\nRows shuffled and 20% of the rows split into the test set (stratified by config)\n\n\n\t\n\t\t\n\t\tExample\n\t\n\n{\n  \"text\": \"çˆµå£«å¤§å¸ˆTim Garland æ·±åœ³ä¸“åœº - [jazz]\\nTim Garland Lighthouseâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/agentlans/epfml-FineWeb2-HQ-sample.","url":"https://huggingface.co/datasets/agentlans/epfml-FineWeb2-HQ-sample","creator_name":"Alan Tseng","creator_url":"https://huggingface.co/agentlans","license_name":"Open Data Commons Attribution License v1.0","license_url":"https://scancode-licensedb.aboutcode.org/odc-by-1.0.html","language":"en","first_N":5,"first_N_keywords":["text-generation","Russian","Chinese","German","Japanese"],"keywords_longer_than_N":true},
	{"name":"silma-rag-qa-benchmark-v1.0","keyword":"arabic","description":"\n\t\n\t\t\n\t\tSILMA RAGQA Benchmark Dataset V1.0\n\t\n\nSILMA RAGQA is a dataset and benchmark created by silma.ai to assess the effectiveness of Arabic Language Models in Extractive Question Answering tasks, with a specific emphasis on RAG applications\nThe benchmark includes 17 bilingual datasets in Arabic and English, spanning various domains\n\n\n\t\n\t\t\n\t\n\t\n\t\tWhat capabilities does the benchmark test?\n\t\n\n\nGeneral Arabic and English QA capabilities\nAbility to handle short and long contexts\nAbility toâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/silma-ai/silma-rag-qa-benchmark-v1.0.","url":"https://huggingface.co/datasets/silma-ai/silma-rag-qa-benchmark-v1.0","creator_name":"SILMA AI - Arabic Language Models","creator_url":"https://huggingface.co/silma-ai","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["question-answering","table-question-answering","Arabic","English","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"16-million-raw-arabic-words","keyword":"arabic","description":"\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset contains a collection of 16,052,878 unique Arabic words. These words were extracted from a large corpus of Arabic text originating from two primary sources: the Shamela library and the Hindawi library.\nKey Characteristics:\n\nUnique Words: The dataset is focused on uniqueness. Each entry in the dataset represents a distinct Arabic word, and duplicates have been removed.\nDiacritic Sensitivity:  Words with different diacritical markings are consideredâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/ImruQays/16-million-raw-arabic-words.","url":"https://huggingface.co/datasets/ImruQays/16-million-raw-arabic-words","creator_name":"Qays","creator_url":"https://huggingface.co/ImruQays","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["Arabic","cc-by-4.0","10M - 100M","text","Text"],"keywords_longer_than_N":true},
	{"name":"Tatoeba-Translations","keyword":"arabic","description":"\n\t\n\t\t\n\t\tDataset Details\n\t\n\nThis is the latest version of Tatoeba translations as of December 2024.\nThe sentences are downloaded from the Tatoeba collection website.\nThe dataset is processed through mapping sentences.tar.bz2 using sentences_base.tar.bz2 to find source (sentence_src) and target (sentence_tgt) sentences.\nWhile lang_src and lang_tgt columns follow the mapping provided by Tatoeba, the lang_pair column merely lists the two languages in the translation pair.\n\n\t\n\t\t\n\t\n\t\n\t\tStatisticsâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/ymoslem/Tatoeba-Translations.","url":"https://huggingface.co/datasets/ymoslem/Tatoeba-Translations","creator_name":"Yasmin Moslem","creator_url":"https://huggingface.co/ymoslem","license_name":"Creative Commons Attribution 2.0","license_url":"https://scancode-licensedb.aboutcode.org/cc-by-2.0.html","language":"en","first_N":5,"first_N_keywords":["translation","multilingual","Abkhaz","Afrikaans","Amharic"],"keywords_longer_than_N":true},
	{"name":"biblenlp-corpus","keyword":"standard arabic","description":"\n\t\n\t\t\n\t\tDataset Card for BibleNLP Corpus\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nPartial and complete Bible translations in 833 languages, aligned by verse.\n\n\t\n\t\t\n\t\tLanguages\n\t\n\naai, aak, aau, aaz, abt, abx, aby, acf, acr, acu, adz, aer, aey, agd, agg, agm, agn, agr, agt, agu, aia, aii, aka, ake, alp, alq, als, aly, ame, amf, amk, amm, amn, amo, amp, amr, amu, amx, anh, anv, aoi, aoj, aom, aon, apb, ape, apn, apr, apu, apw, apz, arb, are, arl, arn, arp, asm, aso, ata, atb, atd, atg, att, auc, aui, auyâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/bible-nlp/biblenlp-corpus.","url":"https://huggingface.co/datasets/bible-nlp/biblenlp-corpus","creator_name":"The Partnership for Applied Biblical NLP","creator_url":"https://huggingface.co/bible-nlp","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":null,"first_N":5,"first_N_keywords":["translation","no-annotation","expert-generated","translation","multilingual"],"keywords_longer_than_N":true},
	{"name":"quran-question-answer-context","keyword":"arabic","description":"\n\t\n\t\t\n\t\tDataset Card for \"quran-question-answer-context\"\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nTranslated the original dataset from Arabic to English and added the Surah ayahs to the context column.\n\n\t\n\t\t\n\t\tUsage\n\t\n\nfrom datasets import load_dataset\n\ndataset = load_dataset(\"nazimali/quran-question-answer-context\")\n\nDatasetDict({\n    train: Dataset({\n        features: ['q_id', 'question', 'answer', 'q_word', 'q_topic', 'fine_class', 'class', 'ontology_concept', 'ontology_concept2', 'source', 'q_src_id'â€¦ See the full description on the dataset page: https://huggingface.co/datasets/nazimali/quran-question-answer-context.","url":"https://huggingface.co/datasets/nazimali/quran-question-answer-context","creator_name":"Nazim Ali","creator_url":"https://huggingface.co/nazimali","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["question-answering","Arabic","English","cc-by-4.0","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"quran-question-answer-context","keyword":"arabic","description":"\n\t\n\t\t\n\t\tDataset Card for \"quran-question-answer-context\"\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nTranslated the original dataset from Arabic to English and added the Surah ayahs to the context column.\n\n\t\n\t\t\n\t\tUsage\n\t\n\nfrom datasets import load_dataset\n\ndataset = load_dataset(\"nazimali/quran-question-answer-context\")\n\nDatasetDict({\n    train: Dataset({\n        features: ['q_id', 'question', 'answer', 'q_word', 'q_topic', 'fine_class', 'class', 'ontology_concept', 'ontology_concept2', 'source', 'q_src_id'â€¦ See the full description on the dataset page: https://huggingface.co/datasets/nazimali/quran-question-answer-context.","url":"https://huggingface.co/datasets/nazimali/quran-question-answer-context","creator_name":"Nazim Ali","creator_url":"https://huggingface.co/nazimali","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["question-answering","Arabic","English","cc-by-4.0","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"HashtagPrediction","keyword":"arabic","description":"\n\t\n\t\t\n\t\tHashtag Prediction Dataset from paper TwHIN-BERT: A Socially-Enriched Pre-trained Language Model for Multilingual Tweet Representations\n\t\n\n  \nThis repo contains the Hashtag prediction dataset from our paper TwHIN-BERT: A Socially-Enriched Pre-trained Language Model for Multilingual Tweet Representations. \n[arXiv][HuggingFace Models]\n[Github repo]\nThis work is licensed under a Creative Commons Attribution 4.0 International License.\n\n\t\n\t\t\n\t\n\t\n\t\tDownload\n\t\n\nUse theâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Twitter/HashtagPrediction.","url":"https://huggingface.co/datasets/Twitter/HashtagPrediction","creator_name":"Twitter","creator_url":"https://huggingface.co/Twitter","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["Slovenian","Urdu","Sindhi","Polish","Vietnamese"],"keywords_longer_than_N":true},
	{"name":"bernice-pretrain-data","keyword":"arabic","description":"Tweet IDs for the 2.5 billion multilingual tweets used to train Bernice, a Twitter encoder.\nThe tweets are from the public 1% Twitter API stream from January 2016 to December 2021. \nTwitter-provided language metadata is provided with the tweet ID. The data contains 66 unique languages, \nas identified by ISO 639 language codes, including `und` for undefined languages.\nTweets need to be re-gathered via the Twitter API.","url":"https://huggingface.co/datasets/jhu-clsp/bernice-pretrain-data","creator_name":"Center for Language and Speech Processing @ JHU","creator_url":"https://huggingface.co/jhu-clsp","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":null,"first_N":5,"first_N_keywords":["other","no-annotation","found","multilingual","original"],"keywords_longer_than_N":true},
	{"name":"Alukah-Arabic","keyword":"arabic","description":"\n\t\n\t\t\n\t\tIntroduction\n\t\n\nThis dataset is a comprehensive collection of articles sourced from the Alukah website, a renowned platform offering extensive content primarily in Arabic. Alukah is known for its high-quality Arabic prose, significantly surpassing the standard found in contemporary media outlets. The majority of the articles are contributed by Muslim scholars, encompassing a wide range of topics related to Islam and the Muslim community. The dataset also includes a valuable section onâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/ImruQays/Alukah-Arabic.","url":"https://huggingface.co/datasets/ImruQays/Alukah-Arabic","creator_name":"Qays","creator_url":"https://huggingface.co/ImruQays","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["Arabic","cc-by-4.0","100K - 1M","csv","Text"],"keywords_longer_than_N":true},
	{"name":"MMMLU","keyword":"arabic","description":"\n\t\n\t\t\n\t\tMultilingual Massive Multitask Language Understanding (MMMLU)\n\t\n\nThe MMLU is a widely recognized benchmark of general knowledge attained by AI models. It covers a broad range of topics from 57 different categories, covering elementary-level knowledge up to advanced professional subjects like law, physics, history, and computer science.\nWe translated the MMLUâ€™s test set into 14 languages using professional human translators. Relying on human translators for this evaluation increasesâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/openai/MMMLU.","url":"https://huggingface.co/datasets/openai/MMMLU","creator_name":"OpenAI","creator_url":"https://huggingface.co/openai","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["question-answering","Arabic","Bengali","German","Spanish"],"keywords_longer_than_N":true},
	{"name":"ChatML-aya_dataset","keyword":"egyptian arabic","description":"CohereForAI/aya_dataset in ChatML format, ready to use in HuggingFace TRL's SFT Trainer.\nPython code used for conversion:\nfrom datasets import load_dataset\nfrom transformers import AutoTokenizer\n\ntokenizer = AutoTokenizer.from_pretrained(\"Felladrin/Llama-160M-Chat-v1\")\n\ndataset = load_dataset(\"CohereForAI/aya_dataset\", split=\"train\")\n\ndef format(columns):\n    messages = [\n        {\n            \"role\": \"user\",\n            \"content\": columns[\"inputs\"].strip(),\n        },\n        {â€¦ See the full description on the dataset page: https://huggingface.co/datasets/Felladrin/ChatML-aya_dataset.","url":"https://huggingface.co/datasets/Felladrin/ChatML-aya_dataset","creator_name":"Victor Nogueira","creator_url":"https://huggingface.co/Felladrin","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["question-answering","text-generation","crowdsourced","expert-generated","crowdsourced"],"keywords_longer_than_N":true},
	{"name":"ChatML-aya_dataset","keyword":"levantine arabic","description":"CohereForAI/aya_dataset in ChatML format, ready to use in HuggingFace TRL's SFT Trainer.\nPython code used for conversion:\nfrom datasets import load_dataset\nfrom transformers import AutoTokenizer\n\ntokenizer = AutoTokenizer.from_pretrained(\"Felladrin/Llama-160M-Chat-v1\")\n\ndataset = load_dataset(\"CohereForAI/aya_dataset\", split=\"train\")\n\ndef format(columns):\n    messages = [\n        {\n            \"role\": \"user\",\n            \"content\": columns[\"inputs\"].strip(),\n        },\n        {â€¦ See the full description on the dataset page: https://huggingface.co/datasets/Felladrin/ChatML-aya_dataset.","url":"https://huggingface.co/datasets/Felladrin/ChatML-aya_dataset","creator_name":"Victor Nogueira","creator_url":"https://huggingface.co/Felladrin","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["question-answering","text-generation","crowdsourced","expert-generated","crowdsourced"],"keywords_longer_than_N":true},
	{"name":"ChatML-aya_dataset","keyword":"moroccan arabic","description":"CohereForAI/aya_dataset in ChatML format, ready to use in HuggingFace TRL's SFT Trainer.\nPython code used for conversion:\nfrom datasets import load_dataset\nfrom transformers import AutoTokenizer\n\ntokenizer = AutoTokenizer.from_pretrained(\"Felladrin/Llama-160M-Chat-v1\")\n\ndataset = load_dataset(\"CohereForAI/aya_dataset\", split=\"train\")\n\ndef format(columns):\n    messages = [\n        {\n            \"role\": \"user\",\n            \"content\": columns[\"inputs\"].strip(),\n        },\n        {â€¦ See the full description on the dataset page: https://huggingface.co/datasets/Felladrin/ChatML-aya_dataset.","url":"https://huggingface.co/datasets/Felladrin/ChatML-aya_dataset","creator_name":"Victor Nogueira","creator_url":"https://huggingface.co/Felladrin","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["question-answering","text-generation","crowdsourced","expert-generated","crowdsourced"],"keywords_longer_than_N":true},
	{"name":"ChatML-aya_dataset","keyword":"najdi arabic","description":"CohereForAI/aya_dataset in ChatML format, ready to use in HuggingFace TRL's SFT Trainer.\nPython code used for conversion:\nfrom datasets import load_dataset\nfrom transformers import AutoTokenizer\n\ntokenizer = AutoTokenizer.from_pretrained(\"Felladrin/Llama-160M-Chat-v1\")\n\ndataset = load_dataset(\"CohereForAI/aya_dataset\", split=\"train\")\n\ndef format(columns):\n    messages = [\n        {\n            \"role\": \"user\",\n            \"content\": columns[\"inputs\"].strip(),\n        },\n        {â€¦ See the full description on the dataset page: https://huggingface.co/datasets/Felladrin/ChatML-aya_dataset.","url":"https://huggingface.co/datasets/Felladrin/ChatML-aya_dataset","creator_name":"Victor Nogueira","creator_url":"https://huggingface.co/Felladrin","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["question-answering","text-generation","crowdsourced","expert-generated","crowdsourced"],"keywords_longer_than_N":true},
	{"name":"ChatML-aya_dataset","keyword":"standard arabic","description":"CohereForAI/aya_dataset in ChatML format, ready to use in HuggingFace TRL's SFT Trainer.\nPython code used for conversion:\nfrom datasets import load_dataset\nfrom transformers import AutoTokenizer\n\ntokenizer = AutoTokenizer.from_pretrained(\"Felladrin/Llama-160M-Chat-v1\")\n\ndataset = load_dataset(\"CohereForAI/aya_dataset\", split=\"train\")\n\ndef format(columns):\n    messages = [\n        {\n            \"role\": \"user\",\n            \"content\": columns[\"inputs\"].strip(),\n        },\n        {â€¦ See the full description on the dataset page: https://huggingface.co/datasets/Felladrin/ChatML-aya_dataset.","url":"https://huggingface.co/datasets/Felladrin/ChatML-aya_dataset","creator_name":"Victor Nogueira","creator_url":"https://huggingface.co/Felladrin","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["question-answering","text-generation","crowdsourced","expert-generated","crowdsourced"],"keywords_longer_than_N":true},
	{"name":"ChatML-aya_dataset","keyword":"ta'izzi-adeni arabic","description":"CohereForAI/aya_dataset in ChatML format, ready to use in HuggingFace TRL's SFT Trainer.\nPython code used for conversion:\nfrom datasets import load_dataset\nfrom transformers import AutoTokenizer\n\ntokenizer = AutoTokenizer.from_pretrained(\"Felladrin/Llama-160M-Chat-v1\")\n\ndataset = load_dataset(\"CohereForAI/aya_dataset\", split=\"train\")\n\ndef format(columns):\n    messages = [\n        {\n            \"role\": \"user\",\n            \"content\": columns[\"inputs\"].strip(),\n        },\n        {â€¦ See the full description on the dataset page: https://huggingface.co/datasets/Felladrin/ChatML-aya_dataset.","url":"https://huggingface.co/datasets/Felladrin/ChatML-aya_dataset","creator_name":"Victor Nogueira","creator_url":"https://huggingface.co/Felladrin","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["question-answering","text-generation","crowdsourced","expert-generated","crowdsourced"],"keywords_longer_than_N":true},
	{"name":"ArabicaQA","keyword":"arabic","description":"\n\t\n\t\t\n\t\tArabicaQA\n\t\n\nArabicaQA: Comprehensive Dataset for Arabic Question Answering\nThis repository contains dataset for paper ArabicaQA: Comprehensive Dataset for Arabic Question Answering. Below, we provide details regarding the materials available in this repository:\n\n\t\n\t\t\n\t\tDataset\n\t\n\nWithin this folder, you will find the training, validation, and test sets of the ArabicaQA dataset. Refer to the table below for the dataset statistics:\n\n\t\n\t\t\n\nTraining\nValidation\nTest\n\n\n\t\t\nMRC (with answers)â€¦ See the full description on the dataset page: https://huggingface.co/datasets/abdoelsayed/ArabicaQA.","url":"https://huggingface.co/datasets/abdoelsayed/ArabicaQA","creator_name":"Abdelrahman Abdallah","creator_url":"https://huggingface.co/abdoelsayed","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["question-answering","crowdsourced","crowdsourced","found","Arabic"],"keywords_longer_than_N":true},
	{"name":"yy-chat-ar-20240329","keyword":"arabic","description":"yongyi169/yy-chat-ar-20240329 dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/yongyi169/yy-chat-ar-20240329","creator_name":"yongyi","creator_url":"https://huggingface.co/yongyi169","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["question-answering","Arabic","apache-2.0","1K - 10K","parquet"],"keywords_longer_than_N":true},
	{"name":"MLDR","keyword":"arabic","description":"\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nMLDR is a Multilingual Long-Document Retrieval dataset built on Wikipeida, Wudao and mC4, covering 13 typologically diverse languages. Specifically, we sample lengthy articles from Wikipedia, Wudao and mC4 datasets and randomly choose paragraphs from them. Then we use GPT-3.5 to generate questions based on these paragraphs. The generated question and the sampled article constitute a new text pair to the dataset. The prompt for GPT3.5 is â€œYou are a curious AIâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Shitao/MLDR.","url":"https://huggingface.co/datasets/Shitao/MLDR","creator_name":"Xiao","creator_url":"https://huggingface.co/Shitao","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":null,"first_N":5,"first_N_keywords":["text-retrieval","multilingual","Arabic","German","English"],"keywords_longer_than_N":true},
	{"name":"xtr-wiki_qa","keyword":"arabic","description":"\n\t\n\t\t\n\t\tXtr-WikiQA\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nXtr-WikiQA is an Answer Sentence Selection (AS2) dataset in 9 non-English languages, proposed in our paper accepted at ACL 2023 (Findings): Cross-Lingual Knowledge Distillation for Answer Sentence Selection in Low-Resource Languages.\nThis dataset is based on an English AS2 dataset, WikiQA (Original, Hugging Face).\nFor translations, we used Amazon Translate.\n\n\t\n\t\t\n\t\n\t\n\t\tLanguages\n\t\n\n\nArabic (ar)\nSpanish (es)\nFrench (fr)\nGerman (de)\nHindi (hi)â€¦ See the full description on the dataset page: https://huggingface.co/datasets/AmazonScience/xtr-wiki_qa.","url":"https://huggingface.co/datasets/AmazonScience/xtr-wiki_qa","creator_name":"Amazon Science","creator_url":"https://huggingface.co/AmazonScience","license_name":"Community Data License Agreement Permissive 2.0","license_url":"https://scancode-licensedb.aboutcode.org/cdla-permissive-2.0.html","language":"en","first_N":5,"first_N_keywords":["question-answering","text-retrieval","open-domain-qa","machine-generated","found"],"keywords_longer_than_N":true},
	{"name":"multilingual-sentiments","keyword":"arabic","description":"\n\t\n\t\t\n\t\tMultilingual Sentiments Dataset\n\t\n\nA collection of multilingual sentiments datasets grouped into 3 classes -- positive, neutral, negative.\nMost multilingual sentiment datasets are either 2-class positive or negative, 5-class ratings of products reviews (e.g. Amazon multilingual dataset) or multiple classes of emotions. However, to an average person, sometimes positive, negative and neutral classes suffice and are more straightforward to perceive and annotate. Also, a positive/negativeâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/tyqiangz/multilingual-sentiments.","url":"https://huggingface.co/datasets/tyqiangz/multilingual-sentiments","creator_name":"Tay Yong Qiang","creator_url":"https://huggingface.co/tyqiangz","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","sentiment-analysis","sentiment-classification","monolingual","multilingual"],"keywords_longer_than_N":true},
	{"name":"text_coordinates_regions","keyword":"arabic","description":"\n\t\n\t\t\n\t\tDataset Card for Multilingual Geo-Tagged Social Media Posts (by 123 world regions)\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThe \"Regions\" dataset is a multilingual corpus that encompasses textual data from the 123 most populated regions worldwide, with each region's data organized into separate .json files. This dataset consists of approximately 500,000 text samples, each paired with its geographic coordinates.\nKey Features:\n\nTextual Data: The dataset contains 500,000 text samples.â€¦ See the full description on the dataset page: https://huggingface.co/datasets/yachay/text_coordinates_regions.","url":"https://huggingface.co/datasets/yachay/text_coordinates_regions","creator_name":"Yachay AI","creator_url":"https://huggingface.co/yachay","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","token-classification","text-classification","English","Chinese"],"keywords_longer_than_N":true},
	{"name":"tarteel-ai-everyayah-Quran","keyword":"arabic","description":"ï·½\n\n\t\n\t\t\n\t\tDataset Card for Tarteel AI's EveryAyah Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset is a collection of Quranic verses and their transcriptions, with diacritization, by different reciters.\n\n\t\n\t\t\n\t\tHow to download\n\t\n\n!pip install -q datasets\n\nfrom datasets import load_dataset\ndataset =load_dataset(\"Salama1429/tarteel-ai-everyayah-Quran\", verification_mode=\"no_checks\")\n\n\n\t\n\t\t\n\t\tSupported Tasks and Leaderboards\n\t\n\n[Needs More Information]\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nThe audio is inâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Salama1429/tarteel-ai-everyayah-Quran.","url":"https://huggingface.co/datasets/Salama1429/tarteel-ai-everyayah-Quran","creator_name":"Mohamed Salama","creator_url":"https://huggingface.co/Salama1429","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","expert-generated","crowdsourced","monolingual","original"],"keywords_longer_than_N":true},
	{"name":"SemEval2024-STR","keyword":"arabic","description":"\n\t\n\t\t\n\t\tDataset Card for Dataset Name\n\t\n\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\n\nEach instance in the training, development, and test sets is a sentence pair. The instance is labeled with a score representing the degree of semantic textual relatedness between the two sentences. The scores can range from 0 (maximally unrelated) to 1 (maximally related). These gold label scores have been determined through manual annotation. Specifically, a comparative annotation approach wasâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/kietnt0603/SemEval2024-STR.","url":"https://huggingface.co/datasets/kietnt0603/SemEval2024-STR","creator_name":"Nguyá»…n Tuáº¥n Kiá»‡t","creator_url":"https://huggingface.co/kietnt0603","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["Amharic","Hausa","English","Spanish","Telugu"],"keywords_longer_than_N":true},
	{"name":"Open_Assistant_Conversation_Chains","keyword":"arabic","description":"\n\t\n\t\t\n\t\tDataset Card for Dataset Name\n\t\n\n\n\t\n\t\t\n\t\tDataset description\n\t\n\n\n\nThis dataset is a reformatting of OpenAssistant Conversations (OASST1), which is\n\na human-generated, human-annotated assistant-style conversation corpus consisting of 161,443 messages in 35 different languages, annotated with 461,292 quality ratings, resulting in over 10,000 fully annotated conversation trees. The corpus is a product of a worldwide crowd-sourcing effort involving over 13,500 volunteers.\n\nIt was modifiedâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/m-ric/Open_Assistant_Conversation_Chains.","url":"https://huggingface.co/datasets/m-ric/Open_Assistant_Conversation_Chains","creator_name":"Aymeric Roucher","creator_url":"https://huggingface.co/m-ric","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","English","Spanish","Russian","German"],"keywords_longer_than_N":true},
	{"name":"CIDAR-MCQ-100","keyword":"arabic","description":"\n\t\n\t\t\n\t\tDataset Card for \"CIDAR-MCQ-100\"\n\t\n\n\n\t\n\t\t\n\t\tCIDAR-MCQ-100\n\t\n\nCIDAR-MCQ-100 contains 100 multiple-choice questions and answers about the Arabic culture. \n\n\t\n\t\t\n\t\tðŸ“š Datasets Summary\n\t\n\n\n  \nName\nExplanation\n\n\nCIDAR \n10,000 instructions and responses in Arabic\n\n\nCIDAR-EVAL-100 \n100 instructions to evaluate LLMs on cultural relevance\n\n\nCIDAR-MCQ-100 \n100 Multiple choice questions and answers to evaluate LLMs on cultural relevance \n\n\n\n\n\n\n\n\t\n\t\t\nCategory\nCIDAR-EVAL-100\nCIDAR-MCQ-100â€¦ See the full description on the dataset page: https://huggingface.co/datasets/arbml/CIDAR-MCQ-100.","url":"https://huggingface.co/datasets/arbml/CIDAR-MCQ-100","creator_name":"Arabic Machine Learning ","creator_url":"https://huggingface.co/arbml","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["multiple-choice","Arabic","apache-2.0","< 1K","parquet"],"keywords_longer_than_N":true},
	{"name":"PetraAI","keyword":"arabic","description":"\n\t\n\t\t\n\t\tPETRA\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nPETRA is a multilingual dataset for training and evaluating AI systems on a diverse range of tasks across multiple modalities. It contains data in Arabic and English for tasks including translation, summarization, question answering, and more.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\nData is separated by language into /ar and /en directories\nWithin each language directory, data is separated by task into subdirectories  \nTasks include:\nTranslation\nSummarizationâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/PetraAI/PetraAI.","url":"https://huggingface.co/datasets/PetraAI/PetraAI","creator_name":"Shady BA","creator_url":"https://huggingface.co/PetraAI","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":null,"first_N":5,"first_N_keywords":["text-classification","token-classification","table-question-answering","question-answering","zero-shot-classification"],"keywords_longer_than_N":true},
	{"name":"xOA22","keyword":"arabic","description":"\n\t\n\t\t\n\t\tDataset Card for xOA22 - Multilingual Prompts from OpenAssistant\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nxOA22 consists of 22 prompts originally shown in Appendix E, page 25 of the OpenAssistant Conversations paper. These 22 prompts were then manually translated by volunteers into 5 languages: Arabic, Simplified Chinese, French, Hindi and Spanish. \nThese prompts were originally created for human evaluations of the multilingual abilities of BLOOMChat. Since not all prompts could be directlyâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/sambanovasystems/xOA22.","url":"https://huggingface.co/datasets/sambanovasystems/xOA22","creator_name":"SambaNova","creator_url":"https://huggingface.co/sambanovasystems","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["Arabic","Chinese","English","French","Hindi"],"keywords_longer_than_N":true},
	{"name":"tweets_ar_en_parallel","keyword":"arabic","description":"    Twitter users often post parallel tweetsâ€”tweets that contain the same content but are\n    written in different languages. Parallel tweets can be an important resource for developing\n    machine translation (MT) systems among other natural language processing (NLP) tasks. This\n    resource is a result of a generic method for collecting parallel tweets. Using the method,\n    we compiled a bilingual corpus of English-Arabic parallel tweets and a list of Twitter accounts\n    who post English-Arabic tweets regularly. Additionally, we annotate a subset of Twitter accounts\n    with their countries of origin and topic of interest, which provides insights about the population\n    who post parallel tweets.","url":"https://huggingface.co/datasets/alt-qsri/tweets_ar_en_parallel","creator_name":"Arabic Language Technologies - Qatar Computing Research Institute","creator_url":"https://huggingface.co/alt-qsri","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":null,"first_N":5,"first_N_keywords":["translation","expert-generated","no-annotation","found","translation"],"keywords_longer_than_N":true},
	{"name":"Arabic_guanaco_oasst1","keyword":"arabic","description":"\n\t\n\t\t\n\t\tDataset Card for \"Arabic_guanaco_oasst1\"\n\t\n\nThis dataset is the openassistant-guanaco dataset a subset of the Open Assistant dataset translated to Arabic.\nYou can find the original dataset here: https://huggingface.co/datasets/timdettmers/openassistant-guanaco\nOr the main dataset here: https://huggingface.co/datasets/OpenAssistant/oasst1/tree/main\nThis subset of the data only contains the highest-rated paths in the conversation tree, with a total of 9,846 samples.\nFor furtherâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/alielfilali01/Arabic_guanaco_oasst1.","url":"https://huggingface.co/datasets/alielfilali01/Arabic_guanaco_oasst1","creator_name":"Ali El Filali","creator_url":"https://huggingface.co/alielfilali01","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["Arabic","apache-2.0","10K - 100K","parquet","Text"],"keywords_longer_than_N":true},
	{"name":"miracl-corpus","keyword":"arabic","description":"\n\t\n\t\t\n\t\tDataset Card for MIRACL Corpus\n\t\n\nMIRACL ðŸŒðŸ™ŒðŸŒ (Multilingual Information Retrieval Across a Continuum of Languages) is a multilingual retrieval dataset that focuses on search across 18 different languages, which collectively encompass over three billion native speakers around the world.\nThis dataset contains the collection data of the 16 \"known languages\". The remaining 2 \"surprise languages\" will not be released until later.\nThe corpus for each language is prepared from a Wikipediaâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/miracl/miracl-corpus.","url":"https://huggingface.co/datasets/miracl/miracl-corpus","creator_name":"MIRACL","creator_url":"https://huggingface.co/miracl","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","expert-generated","multilingual","Arabic"],"keywords_longer_than_N":true},
	{"name":"arabic_pos_dialect","keyword":"arabic","description":"\n\t\n\t\t\n\t\tDataset Card for Arabic POS Dialect\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset was created to support part of speech (POS) tagging in dialects of Arabic. It contains sets of 350 manually segmented and POS tagged tweets for each of four dialects: Egyptian, Levantine, Gulf, and Maghrebi.\n\n\t\n\t\t\n\t\tSupported Tasks and Leaderboards\n\t\n\nThe dataset can be used to train a model for Arabic token segmentation and part of speech tagging in Arabic dialects. Success on this task is typicallyâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/QCRI/arabic_pos_dialect.","url":"https://huggingface.co/datasets/QCRI/arabic_pos_dialect","creator_name":"Qatar Computing Research Institute","creator_url":"https://huggingface.co/QCRI","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["token-classification","part-of-speech","expert-generated","found","multilingual"],"keywords_longer_than_N":true},
	{"name":"MASC","keyword":"arabic","description":"MASC is a dataset that contains 1,000 hours of speech sampled at 16 kHz and crawled from over 700 YouTube channels. The dataset is multi-regional, multi-genre, and multi-dialect intended to advance the research and development of Arabic speech technology with a special emphasis on Arabic speech recognition.","url":"https://huggingface.co/datasets/pain/MASC","creator_name":"Mohammad Albarham","creator_url":"https://huggingface.co/pain","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":null,"first_N":5,"first_N_keywords":["automatic-speech-recognition","Arabic","cc-by-4.0","ðŸ‡ºðŸ‡¸ Region: US"],"keywords_longer_than_N":false},
	{"name":"nllb-200-10M-sample","keyword":"arabic","description":"\n\t\n\t\t\n\t\tDataset Card for \"nllb-200-10M-sample\"\n\t\n\nThis is a sample of nearly 10M sentence pairs from the NLLB-200 \nmined dataset allenai/nllb, \nscored with the model facebook/blaser-2.0-qe \ndescribed in the SeamlessM4T paper.\nThe sample is not random; instead, we just took the top n sentence pairs from each translation direction.\nThe number n was computed with the goal of upsamping the directions that contain underrepresented languages.\nNevertheless, the 187 languoids (language and scriptâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/slone/nllb-200-10M-sample.","url":"https://huggingface.co/datasets/slone/nllb-200-10M-sample","creator_name":"SLONE","creator_url":"https://huggingface.co/slone","license_name":"Open Data Commons Attribution License v1.0","license_url":"https://scancode-licensedb.aboutcode.org/odc-by-1.0.html","language":"en","first_N":5,"first_N_keywords":["translation","Akan","Amharic","Arabic","Awadhi"],"keywords_longer_than_N":true},
	{"name":"bible_para","keyword":"arabic","description":"This is a multilingual parallel corpus created from translations of the Bible compiled by Christos Christodoulopoulos and Mark Steedman.\n\n102 languages, 5,148 bitexts\ntotal number of files: 107\ntotal number of tokens: 56.43M\ntotal number of sentence fragments: 2.84M","url":"https://huggingface.co/datasets/Helsinki-NLP/bible_para","creator_name":"Language Technology Research Group at the University of Helsinki","creator_url":"https://huggingface.co/Helsinki-NLP","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":null,"first_N":5,"first_N_keywords":["translation","found","found","multilingual","original"],"keywords_longer_than_N":true},
	{"name":"Ten2Zero","keyword":"arabic","description":"This dataset contains the following:\n1- A balanced audio dataset of spoken Arabic digits from ten to zero in wav form (located at the \"Dataset\" folder);\n2- A balanced image dataset of spoken Arabic digits from ten to zero in png form (located at the \"Dataset\" folder);\n3- Tabular data generated using deep learning (SqueezeNet and Inception v3) from the spectrograms of the audio files; \n4- Orange Data Mining workflows (\".ows\" files) used in processing this dataset.\nPlease cite the followingâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/gfbati/Ten2Zero.","url":"https://huggingface.co/datasets/gfbati/Ten2Zero","creator_name":"Ghassan F. Bati","creator_url":"https://huggingface.co/gfbati","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["audio-classification","image-classification","tabular-classification","Arabic","English"],"keywords_longer_than_N":true},
	{"name":"CulturaY","keyword":"arabic","description":"\n\t\n\t\t\n\t\tCulturaY: A Large Cleaned Multilingual Dataset of 75 Languages\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nFrom the team that brought you CulturaX, we present CulturaY, another substantial multilingual dataset of 15TB (uncompressed)/3TB (zstd-compressed) that applies the same dataset cleaning methodology to the HPLT v1.1 dataset. \nPlease note that HPLT v1.2 has also been released and is an alternative verison with different cleaning methodolgies. \nThis data was used in part to train our SOTAâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Viet-Mistral/CulturaY.","url":"https://huggingface.co/datasets/Viet-Mistral/CulturaY","creator_name":"Vietnamese Mistral","creator_url":"https://huggingface.co/Viet-Mistral","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","fill-mask","language-modeling","masked-language-modeling","no-annotation"],"keywords_longer_than_N":true},
	{"name":"ArASL_Database_Grayscale","keyword":"arabic","description":"\n\t\n\t\t\n\t\tDataset Card for \"ArASL_Database_Grayscale\"\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nA new dataset consists of 54,049 images of ArSL alphabets performed by more than 40 people for 32 standard Arabic signs and alphabets.\nThe number of images per class differs from one class to another. Sample image of all Arabic Language Signs is also attached. The CSV file contains the Label of each corresponding Arabic Sign Language Image based on the image file name. \n\n\t\n\t\t\n\t\tSupported Tasks and Leaderboardsâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/pain/ArASL_Database_Grayscale.","url":"https://huggingface.co/datasets/pain/ArASL_Database_Grayscale","creator_name":"Mohammad Albarham","creator_url":"https://huggingface.co/pain","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["image-classification","Arabic","cc-by-4.0","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"Nursing_dataset_Arabic","keyword":"arabic","description":"\n\t\n\t\t\n\t\tDataset Card for Dataset Name\n\t\n\n\n\nThis dataset card aims to be a base template for new datasets. It has been generated using this raw template.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\n\n\n\n\n\nCurated by: [More Information Needed]\nFunded by [optional]: [More Information Needed]\nShared by [optional]: [More Information Needed]\nLanguage(s) (NLP): [More Information Needed]\nLicense: [More Information Needed]\n\n\n\t\n\t\t\n\t\tDataset Sources [optional]\n\t\n\n\n\n\nRepository: [Moreâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Dev-Dr-Code/Nursing_dataset_Arabic.","url":"https://huggingface.co/datasets/Dev-Dr-Code/Nursing_dataset_Arabic","creator_name":"Dr Code","creator_url":"https://huggingface.co/Dev-Dr-Code","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["question-answering","Arabic","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"QuranExe","keyword":"arabic","description":"This dataset contains the exegeses/tafsirs (ØªÙØ³ÙŠØ± Ø§Ù„Ù‚Ø±Ø¢Ù†) of the holy Quran in arabic by 8 exegetes.\nThis is a non Official dataset. It have been scrapped from the Quran.com Api\nThis dataset contains 49888 records with +14 Million words. 8 records per Quranic verse\nUsage Example :\nfrom datasets import load_dataset\n\ntafsirs = load_dataset(\"mustapha/QuranExe\")\n\n","url":"https://huggingface.co/datasets/mustapha/QuranExe","creator_name":"AJEGHRIR mustapha","creator_url":"https://huggingface.co/mustapha","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-generation","fill-mask","sentence-similarity","language-modeling","masked-language-modeling"],"keywords_longer_than_N":true},
	{"name":"massive_translation_dataset","keyword":"arabic","description":"\n\t\n\t\t\n\t\tDataset Card for Massive Dataset for Translation\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset is derived from AmazonScience/MASSIVE dataset for translation task purpose.\n\n\t\n\t\t\n\t\tSupported Tasks and Leaderboards\n\t\n\nTranslation\n\n\t\n\t\t\n\t\tLanguages\n\t\n\n\nEnglish (en_US)\nGerman (de_DE)\nHindi (hi_IN)\nSpanish (es_ES)\nFrench (fr_FR)\nItalian (it_IT)\nArabic (ar_SA)\nDutch (nl_NL)\nJapanese (ja_JP)\nPortugese (pt_PT)\n\n","url":"https://huggingface.co/datasets/Amani27/massive_translation_dataset","creator_name":"Amani N","creator_url":"https://huggingface.co/Amani27","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["translation","English","German","Spanish","Hindi"],"keywords_longer_than_N":true},
	{"name":"xP3mt","keyword":"arabic","description":"xP3 (Crosslingual Public Pool of Prompts) is a collection of prompts & datasets across 46 of languages & 16 NLP tasks. It is used for the training of BLOOMZ and mT0, multilingual language models capable of following human instructions in dozens of languages zero-shot.","url":"https://huggingface.co/datasets/bigscience/xP3mt","creator_name":"BigScience Workshop","creator_url":"https://huggingface.co/bigscience","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["other","expert-generated","crowdsourced","multilingual","Akan"],"keywords_longer_than_N":true},
	{"name":"Arabic_Wikipedia_20230101_nobots","keyword":"arabic","description":"\n\t\n\t\t\n\t\tDataset Card for \"Arabic_Wikipedia_20230101_nobots\"\n\t\n\nThis dataset is created using the Arabic Wikipedia articles (after removing bot-generated articles), downloaded on the 1st of January 2023, processed using Gensim Python library, and preprocessed using tr Linux/Unix utility and CAMeLTools Python toolkit for Arabic NLP. This dataset was used to train this Arabic Wikipedia Masked Language Model: SaiedAlshahrani/arwiki_20230101_roberta_mlm_nobots.\nFor more details about the datasetâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/SaiedAlshahrani/Arabic_Wikipedia_20230101_nobots.","url":"https://huggingface.co/datasets/SaiedAlshahrani/Arabic_Wikipedia_20230101_nobots","creator_name":"Saied Alshahrani","creator_url":"https://huggingface.co/SaiedAlshahrani","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["Arabic","mit","100K - 1M","parquet","Text"],"keywords_longer_than_N":true},
	{"name":"arcd","keyword":"arabic","description":"\n\t\n\t\t\n\t\tDataset Card for \"arcd\"\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\n Arabic Reading Comprehension Dataset (ARCD) composed of 1,395 questions      posed by crowdworkers on Wikipedia articles.\n\n\t\n\t\t\n\t\tSupported Tasks and Leaderboards\n\t\n\nMore Information Needed\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nMore Information Needed\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\n\t\n\t\t\n\t\tData Instances\n\t\n\n\n\t\n\t\t\n\t\tplain_text\n\t\n\n\nSize of downloaded dataset files: 1.94 MB\nSize of the generated dataset: 1.70 MB\nTotal amount of disk used: 3.64 MB\n\nAnâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/hsseinmz/arcd.","url":"https://huggingface.co/datasets/hsseinmz/arcd","creator_name":"Hussein Mozannar","creator_url":"https://huggingface.co/hsseinmz","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["question-answering","extractive-qa","crowdsourced","crowdsourced","monolingual"],"keywords_longer_than_N":true},
	{"name":"xP3x-sample","keyword":"arabic","description":"A multilingual collection of Winograd Schemas in six languages that can be used for evaluation of cross-lingual commonsense reasoning capabilities.","url":"https://huggingface.co/datasets/Muennighoff/xP3x-sample","creator_name":"Niklas Muennighoff","creator_url":"https://huggingface.co/Muennighoff","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["other","expert-generated","crowdsourced","multilingual","Afrikaans"],"keywords_longer_than_N":true},
	{"name":"xP3x-sample","keyword":"egyptian arabic","description":"A multilingual collection of Winograd Schemas in six languages that can be used for evaluation of cross-lingual commonsense reasoning capabilities.","url":"https://huggingface.co/datasets/Muennighoff/xP3x-sample","creator_name":"Niklas Muennighoff","creator_url":"https://huggingface.co/Muennighoff","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["other","expert-generated","crowdsourced","multilingual","Afrikaans"],"keywords_longer_than_N":true},
	{"name":"xP3x-sample","keyword":"levantine arabic","description":"A multilingual collection of Winograd Schemas in six languages that can be used for evaluation of cross-lingual commonsense reasoning capabilities.","url":"https://huggingface.co/datasets/Muennighoff/xP3x-sample","creator_name":"Niklas Muennighoff","creator_url":"https://huggingface.co/Muennighoff","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["other","expert-generated","crowdsourced","multilingual","Afrikaans"],"keywords_longer_than_N":true},
	{"name":"xP3x-sample","keyword":"mesopotamian arabic","description":"A multilingual collection of Winograd Schemas in six languages that can be used for evaluation of cross-lingual commonsense reasoning capabilities.","url":"https://huggingface.co/datasets/Muennighoff/xP3x-sample","creator_name":"Niklas Muennighoff","creator_url":"https://huggingface.co/Muennighoff","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["other","expert-generated","crowdsourced","multilingual","Afrikaans"],"keywords_longer_than_N":true},
	{"name":"xP3x-sample","keyword":"moroccan arabic","description":"A multilingual collection of Winograd Schemas in six languages that can be used for evaluation of cross-lingual commonsense reasoning capabilities.","url":"https://huggingface.co/datasets/Muennighoff/xP3x-sample","creator_name":"Niklas Muennighoff","creator_url":"https://huggingface.co/Muennighoff","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["other","expert-generated","crowdsourced","multilingual","Afrikaans"],"keywords_longer_than_N":true},
	{"name":"xP3x-sample","keyword":"najdi arabic","description":"A multilingual collection of Winograd Schemas in six languages that can be used for evaluation of cross-lingual commonsense reasoning capabilities.","url":"https://huggingface.co/datasets/Muennighoff/xP3x-sample","creator_name":"Niklas Muennighoff","creator_url":"https://huggingface.co/Muennighoff","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["other","expert-generated","crowdsourced","multilingual","Afrikaans"],"keywords_longer_than_N":true},
	{"name":"xP3x-sample","keyword":"tunisian arabic","description":"A multilingual collection of Winograd Schemas in six languages that can be used for evaluation of cross-lingual commonsense reasoning capabilities.","url":"https://huggingface.co/datasets/Muennighoff/xP3x-sample","creator_name":"Niklas Muennighoff","creator_url":"https://huggingface.co/Muennighoff","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["other","expert-generated","crowdsourced","multilingual","Afrikaans"],"keywords_longer_than_N":true},
	{"name":"xP3x-sample","keyword":"ta'izzi-adeni arabic","description":"A multilingual collection of Winograd Schemas in six languages that can be used for evaluation of cross-lingual commonsense reasoning capabilities.","url":"https://huggingface.co/datasets/Muennighoff/xP3x-sample","creator_name":"Niklas Muennighoff","creator_url":"https://huggingface.co/Muennighoff","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["other","expert-generated","crowdsourced","multilingual","Afrikaans"],"keywords_longer_than_N":true},
	{"name":"mr-tydi","keyword":"arabic","description":"\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nMr. TyDi is a multi-lingual benchmark dataset built on TyDi, covering eleven typologically diverse languages. It is designed for monolingual retrieval, specifically to evaluate ranking with learned dense representations.\nThis dataset stores the queries, judgements, and example training data of Mr. TyDi. To access the corpus, please refer to castorini/mr-tydi-corpus.\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Structure\n\t\n\nThe only configuration here is the language, \nFor each languageâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/castorini/mr-tydi.","url":"https://huggingface.co/datasets/castorini/mr-tydi","creator_name":"Castorini","creator_url":"https://huggingface.co/castorini","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","multilingual","Arabic","Bengali","English"],"keywords_longer_than_N":true},
	{"name":"election-questions-arabic","keyword":"arabic","description":"\n\t\n\t\t\n\t\tElection Questions - Arabic Translation (MADLAD-400)\n\t\n\nHigh-quality Arabic translation using Google's MADLAD-400 model.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\nSource: Anthropic/election_questions\nTranslation Model: google/madlad400-7b-mt\nTotal Records: 743\nTrain: 594\nTest: 149\n\n\n\n\n\t\n\t\t\n\t\tUsage\n\t\n\nfrom datasets import load_dataset\n\n# Load bilingual version\ndataset = load_dataset(\"fr3on/election-questions-arabic\", \"bilingual\")\n\n# Load Arabic-only version\ndataset =â€¦ See the full description on the dataset page: https://huggingface.co/datasets/fr3on/election-questions-arabic.","url":"https://huggingface.co/datasets/fr3on/election-questions-arabic","creator_name":"Ahmed Mardi","creator_url":"https://huggingface.co/fr3on","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","Arabic","English","mit","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"election-questions-arabic","keyword":"arabic","description":"\n\t\n\t\t\n\t\tElection Questions - Arabic Translation (MADLAD-400)\n\t\n\nHigh-quality Arabic translation using Google's MADLAD-400 model.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\nSource: Anthropic/election_questions\nTranslation Model: google/madlad400-7b-mt\nTotal Records: 743\nTrain: 594\nTest: 149\n\n\n\n\n\t\n\t\t\n\t\tUsage\n\t\n\nfrom datasets import load_dataset\n\n# Load bilingual version\ndataset = load_dataset(\"fr3on/election-questions-arabic\", \"bilingual\")\n\n# Load Arabic-only version\ndataset =â€¦ See the full description on the dataset page: https://huggingface.co/datasets/fr3on/election-questions-arabic.","url":"https://huggingface.co/datasets/fr3on/election-questions-arabic","creator_name":"Ahmed Mardi","creator_url":"https://huggingface.co/fr3on","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","Arabic","English","mit","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"Egyptian_Arabic_Wikipedia_20230101","keyword":"arabic","description":"\n\t\n\t\t\n\t\tDataset Card for \"Egyptian_Arabic_Wikipedia_20230101\"\n\t\n\nThis dataset is created using the Egyptian Arabic Wikipedia articles, downloaded on the 1st of January 2023, processed using Gensim Python library, and preprocessed using tr Linux/Unix utility and CAMeLTools Python toolkit for Arabic NLP. This dataset was used to train this Egyptian Arabic Wikipedia Masked Language Model: SaiedAlshahrani/arzwiki_20230101_roberta_mlm.\nFor more details about the dataset, please read and cite ourâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/SaiedAlshahrani/Egyptian_Arabic_Wikipedia_20230101.","url":"https://huggingface.co/datasets/SaiedAlshahrani/Egyptian_Arabic_Wikipedia_20230101","creator_name":"Saied Alshahrani","creator_url":"https://huggingface.co/SaiedAlshahrani","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["Arabic","mit","100K - 1M","parquet","Text"],"keywords_longer_than_N":true},
	{"name":"Global-MMLU-Lite","keyword":"arabic","description":"\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nGlobal-MMLU-Lite is a multilingual evaluation set spanning 16 languages, including English. It is \"lite\" version of the original Global-MMLU dataset ðŸŒ.\nIt includes 200 Culturally Sensitive (CS) and 200 Culturally Agnostic (CA) samples per language. The samples in Global-MMLU-Lite are corresponding to languages which are fully human translated or post-edited in the original Global-MMLU dataset. \nNOTE: Of the 16 languages presently included in Global-MMLU-Lite, 15â€¦ See the full description on the dataset page: https://huggingface.co/datasets/CohereLabs/Global-MMLU-Lite.","url":"https://huggingface.co/datasets/CohereLabs/Global-MMLU-Lite","creator_name":"Cohere Labs","creator_url":"https://huggingface.co/CohereLabs","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["English","Arabic","Bengali","Spanish","French"],"keywords_longer_than_N":true},
	{"name":"Arabic-NLi-Pair-Score","keyword":"arabic","description":"\n\t\n\t\t\n\t\tArabic NLI Pair-Score\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\n\nThe Arabic Version of SNLI and MultiNLI datasets. (Pair-Score Subset)\nOriginally used for Natural Language Inference (NLI),\nDataset may be used for training/finetuning an embedding model for semantic textual similarity.\n\n\n\t\n\t\t\n\t\tPair-Class Subset\n\t\n\n\nColumns: \"sentence1\", \"sentence2\", \"score\"\nColumn types: str, str, float\n\n\n\t\n\t\t\n\t\tArabic Examples:\n\t\n\n{\n  \"sentence1\": \"Ø´Ø®Øµ Ø¹Ù„Ù‰ Ø­ØµØ§Ù† ÙŠÙ‚ÙØ² ÙÙˆÙ‚ Ø·Ø§Ø¦Ø±Ø© Ù…Ø¹Ø·Ù„Ø©\",\n  \"sentence2\": \"Ø´Ø®Øµ ÙŠÙ‚ÙˆÙ…â€¦ See the full description on the dataset page: https://huggingface.co/datasets/Omartificial-Intelligence-Space/Arabic-NLi-Pair-Score.","url":"https://huggingface.co/datasets/Omartificial-Intelligence-Space/Arabic-NLi-Pair-Score","creator_name":"Omartificial Intelligence Space","creator_url":"https://huggingface.co/Omartificial-Intelligence-Space","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["sentence-similarity","Arabic","apache-2.0","100K - 1M","csv"],"keywords_longer_than_N":true},
	{"name":"parasitic-egg","keyword":"arabic","description":"\n\t\n\t\t\n\t\tDataset Card for Parasitic Egg Image Classification Dataset\n\t\n\n\n\nThis dataset card aims to be a base template for the Parasitic Egg Image Classification Dataset. It has been generated using this raw template.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\n\n\nThis dataset is designed for the classification of parasitic eggs from microscopic images. Parasitic infections are a major health concern, particularly in developing countries, where parasites are a significant cause ofâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Abdelkareem/parasitic-egg.","url":"https://huggingface.co/datasets/Abdelkareem/parasitic-egg","creator_name":"elkahtib","creator_url":"https://huggingface.co/Abdelkareem","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["image-classification","image-segmentation","object-detection","Arabic","English"],"keywords_longer_than_N":true},
	{"name":"ClArTTS","keyword":"arabic","description":"\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nWe present a speech corpus for Classical Arabic Text-to-Speech (ClArTTS) to support the development of end-to-end TTS systems for Arabic. The speech is extracted from a LibriVox audiobook, which is then processed, segmented, and manually transcribed and annotated. The final ClArTTS corpus contains about 12 hours of speech from a single male speaker sampled at 40100 kHz.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nA typical data point comprises the name of the audio file, calledâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/MBZUAI/ClArTTS.","url":"https://huggingface.co/datasets/MBZUAI/ClArTTS","creator_name":"Mohamed Bin Zayed University of Artificial Intelligence","creator_url":"https://huggingface.co/MBZUAI","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-to-speech","text-to-audio","Arabic","cc-by-4.0","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"101_billion_arabic_words_dataset_urls","keyword":"arabic","description":"\n\t\n\t\t\n\t\tDataset Card for 101_billion_arabic_words_dataset_urls\n\t\n\nThis dataset provides the URLs and top-level domains associated with training records in ClusterlabAi/101_billion_arabic_words_dataset. It is part of a collection of datasets curated to make exploring LLM training datasets more straightforward and accessible. \n\n\t\n\t\t\n\t\n\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Description\n\t\n\nThis dataset was created by downloading the source data, extracting URLs and top-level domains, andâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/nhagar/101_billion_arabic_words_dataset_urls.","url":"https://huggingface.co/datasets/nhagar/101_billion_arabic_words_dataset_urls","creator_name":"Nick Hagar","creator_url":"https://huggingface.co/nhagar","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","Arabic","apache-2.0","10M - 100M","parquet"],"keywords_longer_than_N":true},
	{"name":"structured-uae-laws","keyword":"arabic","description":"\n\t\n\t\t\n\t\tDataset Card for structured-uae-laws\n\t\n\nThis dataset is a collection of question & answers about the laws and regulations in the United Arab Emirates. \nIt covers different areas of law like: \n\neconomy and business \nfamily and community \nfinance and banking \nindustry and technical standardisation \njustice and juiciary, labour \nresidency and leberal professions \nsecurity and safety \ntax\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Sources\n\t\n\n\nRepository\nBase Dataset\nUnited Arab Emirates Legislationsâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/obadabaq/structured-uae-laws.","url":"https://huggingface.co/datasets/obadabaq/structured-uae-laws","creator_name":"obada baqleh","creator_url":"https://huggingface.co/obadabaq","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["question-answering","text-generation","English","Arabic","mit"],"keywords_longer_than_N":true},
	{"name":"xsimplusplus","keyword":"egyptian arabic","description":"xSIM++ is an extension of xSIM. In comparison to xSIM, this evaluates using target-side data with additional synthetic, hard-to-distinguish examples. You can find more details about it in the publication: xSIM++: An Improved Proxy to Bitext Mining Performance for Low-Resource Languages.\n","url":"https://huggingface.co/datasets/jaygala24/xsimplusplus","creator_name":"Jay Gala","creator_url":"https://huggingface.co/jaygala24","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["derived","multilingual","Achinese","Mesopotamian Arabic","Ta'izzi-Adeni Arabic"],"keywords_longer_than_N":true},
	{"name":"xsimplusplus","keyword":"levantine arabic","description":"xSIM++ is an extension of xSIM. In comparison to xSIM, this evaluates using target-side data with additional synthetic, hard-to-distinguish examples. You can find more details about it in the publication: xSIM++: An Improved Proxy to Bitext Mining Performance for Low-Resource Languages.\n","url":"https://huggingface.co/datasets/jaygala24/xsimplusplus","creator_name":"Jay Gala","creator_url":"https://huggingface.co/jaygala24","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["derived","multilingual","Achinese","Mesopotamian Arabic","Ta'izzi-Adeni Arabic"],"keywords_longer_than_N":true},
	{"name":"xsimplusplus","keyword":"mesopotamian arabic","description":"xSIM++ is an extension of xSIM. In comparison to xSIM, this evaluates using target-side data with additional synthetic, hard-to-distinguish examples. You can find more details about it in the publication: xSIM++: An Improved Proxy to Bitext Mining Performance for Low-Resource Languages.\n","url":"https://huggingface.co/datasets/jaygala24/xsimplusplus","creator_name":"Jay Gala","creator_url":"https://huggingface.co/jaygala24","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["derived","multilingual","Achinese","Mesopotamian Arabic","Ta'izzi-Adeni Arabic"],"keywords_longer_than_N":true},
	{"name":"xsimplusplus","keyword":"moroccan arabic","description":"xSIM++ is an extension of xSIM. In comparison to xSIM, this evaluates using target-side data with additional synthetic, hard-to-distinguish examples. You can find more details about it in the publication: xSIM++: An Improved Proxy to Bitext Mining Performance for Low-Resource Languages.\n","url":"https://huggingface.co/datasets/jaygala24/xsimplusplus","creator_name":"Jay Gala","creator_url":"https://huggingface.co/jaygala24","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["derived","multilingual","Achinese","Mesopotamian Arabic","Ta'izzi-Adeni Arabic"],"keywords_longer_than_N":true},
	{"name":"xsimplusplus","keyword":"najdi arabic","description":"xSIM++ is an extension of xSIM. In comparison to xSIM, this evaluates using target-side data with additional synthetic, hard-to-distinguish examples. You can find more details about it in the publication: xSIM++: An Improved Proxy to Bitext Mining Performance for Low-Resource Languages.\n","url":"https://huggingface.co/datasets/jaygala24/xsimplusplus","creator_name":"Jay Gala","creator_url":"https://huggingface.co/jaygala24","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["derived","multilingual","Achinese","Mesopotamian Arabic","Ta'izzi-Adeni Arabic"],"keywords_longer_than_N":true},
	{"name":"xsimplusplus","keyword":"standard arabic","description":"xSIM++ is an extension of xSIM. In comparison to xSIM, this evaluates using target-side data with additional synthetic, hard-to-distinguish examples. You can find more details about it in the publication: xSIM++: An Improved Proxy to Bitext Mining Performance for Low-Resource Languages.\n","url":"https://huggingface.co/datasets/jaygala24/xsimplusplus","creator_name":"Jay Gala","creator_url":"https://huggingface.co/jaygala24","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["derived","multilingual","Achinese","Mesopotamian Arabic","Ta'izzi-Adeni Arabic"],"keywords_longer_than_N":true},
	{"name":"xsimplusplus","keyword":"ta'izzi-adeni arabic","description":"xSIM++ is an extension of xSIM. In comparison to xSIM, this evaluates using target-side data with additional synthetic, hard-to-distinguish examples. You can find more details about it in the publication: xSIM++: An Improved Proxy to Bitext Mining Performance for Low-Resource Languages.\n","url":"https://huggingface.co/datasets/jaygala24/xsimplusplus","creator_name":"Jay Gala","creator_url":"https://huggingface.co/jaygala24","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["derived","multilingual","Achinese","Mesopotamian Arabic","Ta'izzi-Adeni Arabic"],"keywords_longer_than_N":true},
	{"name":"xsimplusplus","keyword":"tunisian arabic","description":"xSIM++ is an extension of xSIM. In comparison to xSIM, this evaluates using target-side data with additional synthetic, hard-to-distinguish examples. You can find more details about it in the publication: xSIM++: An Improved Proxy to Bitext Mining Performance for Low-Resource Languages.\n","url":"https://huggingface.co/datasets/jaygala24/xsimplusplus","creator_name":"Jay Gala","creator_url":"https://huggingface.co/jaygala24","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["derived","multilingual","Achinese","Mesopotamian Arabic","Ta'izzi-Adeni Arabic"],"keywords_longer_than_N":true},
	{"name":"darja-en-translation","keyword":"arabic","description":"\n\t\n\t\t\n\t\tDarja-English Translation Dataset\n\t\n\nThis dataset contains translations from Algerian Darja (Arabic dialect) to English. The dataset includes sentences in Darja along with their corresponding English translations.\n\n\t\n\t\t\n\t\tLanguages\n\t\n\n\nDarja (Algerian Arabic dialect)\nEnglish\n\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nThe dataset consists of two fields:\n\ninput: Sentence in Darja\ntranslation: Corresponding translation in English\n\n\n\t\n\t\t\n\t\tLicense\n\t\n\nThis dataset is licensed under the MIT License.â€¦ See the full description on the dataset page: https://huggingface.co/datasets/ademchaoua/darja-en-translation.","url":"https://huggingface.co/datasets/ademchaoua/darja-en-translation","creator_name":"adem chaoua","creator_url":"https://huggingface.co/ademchaoua","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["translation","text-classification","summarization","text-generation","Arabic"],"keywords_longer_than_N":true},
	{"name":"test","keyword":"arabic","description":"HussamAraj/test dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/HussamAraj/test","creator_name":"Hussam Araj","creator_url":"https://huggingface.co/HussamAraj","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["Arabic","mit","< 1K","text","Text"],"keywords_longer_than_N":true},
	{"name":"DVOICEv1.1-Darija","keyword":"arabic","description":"Dialectal Voice is a community project initiated by AIOX Labs to facilitate voice recognition by Intelligent Systems. Today, the need for AI systems capable of recognizing the human voice is increasingly expressed within communities. However, we note that for some languages such as Darija, there are not enough voice technology solutions. To meet this need, we then proposed to establish this program of iterative and interactive construction of a dialectal database open to all in order to helpâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/BrunoHays/DVOICEv1.1-Darija.","url":"https://huggingface.co/datasets/BrunoHays/DVOICEv1.1-Darija","creator_name":"Bruno Hays","creator_url":"https://huggingface.co/BrunoHays","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["Arabic","cc-by-4.0","1K - 10K","soundfolder","Audio"],"keywords_longer_than_N":true},
	{"name":"resmo","keyword":"arabic","description":"aibrahiam/resmo dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/aibrahiam/resmo","creator_name":"Ahmed Ibrahim","creator_url":"https://huggingface.co/aibrahiam","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["question-answering","text-classification","Arabic","English","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"biblenlp-corpus-mmteb","keyword":"standard arabic","description":"This dataset pre-computes all English-centric directions from bible-nlp/biblenlp-corpus, and as a result loading is significantly faster.\nLoading example:\n>>> from datasets import load_dataset\n>>> dataset = load_dataset(\"davidstap/biblenlp-corpus-mmteb\", \"eng-arb\", trust_remote_code=True)\n>>> dataset\nDatasetDict({\n    train: Dataset({\n        features: ['eng', 'arb'],\n        num_rows: 28723\n    })\n    validation: Dataset({\n        features: ['eng', 'arb'],\n        num_rows: 1578\n    })â€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/biblenlp-corpus-mmteb.","url":"https://huggingface.co/datasets/mteb/biblenlp-corpus-mmteb","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["no-annotation","expert-generated","translation","multilingual","Arifama-Miniafia"],"keywords_longer_than_N":true},
	{"name":"Thinking-multilingual-big-10k-sft","keyword":"arabic","description":"\nA dataset based off of openo1 math, 500 examples translated to 23 different languages. filtered out un-translated examples.\nenjoy ðŸ‘\n","url":"https://huggingface.co/datasets/Pinkstack/Thinking-multilingual-big-10k-sft","creator_name":"Pinkstack","creator_url":"https://huggingface.co/Pinkstack","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","Arabic","Chinese","Czech","Danish"],"keywords_longer_than_N":true},
	{"name":"fcube","keyword":"arabic","description":"Nechba/fcube dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/Nechba/fcube","creator_name":"nechba mohammed","creator_url":"https://huggingface.co/Nechba","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","English","Arabic","apache-2.0","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"Quran-Tafseer","keyword":"arabic","description":"\n\t\n\t\t\n\t\tðŸ“š Quran Tafseer Collection\n\t\n\n\n  \n\n\n\n\t\n\t\t\n\t\tWhat's this all about?\n\t\n\nThis dataset is a treasure trove of Quranic interpretations (tafsir) from 84 different books! It's perfect for anyone interested in Islamic studies, natural language processing, or just curious about the Quran's meanings.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\nSource: All data was collected from Altafsir.com\nSize: 219,000 rows of insightful content\nLanguage: Arabic\n\n\n\t\n\t\t\n\t\tWhat's inside?\n\t\n\nThe dataset has 5 columns:â€¦ See the full description on the dataset page: https://huggingface.co/datasets/MohamedRashad/Quran-Tafseer.","url":"https://huggingface.co/datasets/MohamedRashad/Quran-Tafseer","creator_name":"Mohamed Rashad","creator_url":"https://huggingface.co/MohamedRashad","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["Arabic","apache-2.0","100K - 1M","parquet","Text"],"keywords_longer_than_N":true},
	{"name":"tarwiiga_adgen_dataset","keyword":"arabic","description":"\n\t\n\t\t\n\t\tTarwiiga AdGen Dataset\n\t\n\nThis dataset is generated using LLM for the purpose of fine-tunning another LLM for the task of generating Google Ads, and it used is by Tarwiiga AdGen from Tarwiiga\n","url":"https://huggingface.co/datasets/maelghrib/tarwiiga_adgen_dataset","creator_name":"Mustafa A. Elghrib","creator_url":"https://huggingface.co/maelghrib","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","language-modeling","no-annotation","machine-generated","monolingual"],"keywords_longer_than_N":true},
	{"name":"Aya-AceGPT.13B.Chat-DPO","keyword":"arabic","description":"\n\t\n\t\t\n\t\tDataset Card for \"Aya-AceGPT.13B.Chat-DPO\" ðŸ¤—\n\t\n\n\n\t\n\t\t\n\t\tDataset Sources & Infos\n\t\n\n\nData Origin: Derived from the Arabic Aya (2A) dataset : 2A2I/Arabic_Aya which is a Curated Subset of the Aya Collection CohereForAI/aya_dataset\nLanguages: Modern Standard Arabic (MSA)\nLicense: Apache-2.0\nMaintainers: Ali Elfilali and Mohammed Machrouh\n\n\n\t\n\t\t\n\t\n\t\n\t\tPurpose\n\t\n\nAya-AceGPT.13B.Chat-DPO is a DPO dataset designed to advance Arabic NLP by comparing human-generated responses, labeled asâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/2A2I/Aya-AceGPT.13B.Chat-DPO.","url":"https://huggingface.co/datasets/2A2I/Aya-AceGPT.13B.Chat-DPO","creator_name":"2A2I","creator_url":"https://huggingface.co/2A2I","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["Arabic","apache-2.0","10K - 100K","parquet","Text"],"keywords_longer_than_N":true},
	{"name":"Quran-Ayah-Corpus","keyword":"arabic","description":"\n\t\n\t\t\n\t\tQuran-Ayah-Corpus: A Multi-Reciter Arabic Quranic Speech Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description:\n\t\n\nAyah-Corpus is a large-scale, multi-reciter Arabic speech dataset meticulously curated for Automatic Speech Recognition (ASR) tasks. It consists of high-quality audio recordings of Quranic verses (Ayahs) paired with their corresponding exact transcriptions. The audio is sourced from two primary repositories: Al-Quran.cloud and EveryAyah.com.\nThis dataset is specifically designed toâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/rabah2026/Quran-Ayah-Corpus.","url":"https://huggingface.co/datasets/rabah2026/Quran-Ayah-Corpus","creator_name":"MÅ™ RaÃŸah","creator_url":"https://huggingface.co/rabah2026","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","Arabic","apache-2.0","100K - 1M","parquet"],"keywords_longer_than_N":true},
	{"name":"Arabic-Poem-Emotion","keyword":"arabic","description":"\n\t\n\t\t\n\t\tDataset Card for \"Arabic-Poem-Emotion\"\n\t\n\n\n\t\n\t\t\n\t\tPaper:\n\t\n\nShahriar S, Al Roken N, Zualkernan I. Classification of Arabic Poetry Emotions Using Deep Learning. Computers. 2023; 12(5):89. https://doi.org/10.3390/computers12050089 \n","url":"https://huggingface.co/datasets/asas-ai/Arabic-Poem-Emotion","creator_name":"ASAS AI","creator_url":"https://huggingface.co/asas-ai","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","Arabic","cc-by-4.0","1K - 10K","parquet"],"keywords_longer_than_N":true},
	{"name":"cohere_aya_arabic","keyword":"standard arabic","description":"\n\t\n\t\t\n\t\tArabic aya dataset\n\t\n\nThis dataset is the arabic partition of the CohereForAI/aya_dataset dataset. \nFor more information about the dataset, visit the original dataset repo: CohereForAI/aya_dataset.\nthe data was extracted using this simple code:\n# Train split.\naya_train = datasets.load_dataset(\"CohereForAI/aya_dataset\", split=\"train\")\narb_train = aya_train.filter(lambda x: x[\"language_code\"] == \"arb\")\narb_train = arb_train.remove_columns([\"language_code\", \"user_id\"])\n\n# Test split.â€¦ See the full description on the dataset page: https://huggingface.co/datasets/abuelnasr/cohere_aya_arabic.","url":"https://huggingface.co/datasets/abuelnasr/cohere_aya_arabic","creator_name":"Mohamed AbuElNasr","creator_url":"https://huggingface.co/abuelnasr","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["other","monolingual","CohereForAI/aya_dataset","Standard Arabic","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"Shifaa_Arabic_Mental_Health_Consultations","keyword":"arabic","description":"\n\t\n\t\t\n\t\tðŸ¥ Shifaa Arabic Mental Health Consultations ðŸ§ \n\t\n\n  \n\n\t\n\t\t\n\t\tðŸ“Œ Overview\n\t\n\nShifaa Arabic Mental Health Consultations is a high-quality dataset designed to advance Arabic medical language models.This dataset provides 35,648 real-world medical consultations, covering a wide range of mental health concerns.  \n\n\t\n\t\t\n\t\tðŸ“Š Dataset Summary\n\t\n\n\nSize: 35,648 consultations  \nMain Specializations: 7  \nSpecific Diagnoses: 123  \nLanguages: Arabic (Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©)\n\n\n\t\n\t\t\n\t\tWhy This Dataset?\n\t\n\nðŸ”¹ Lack ofâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Ahmed-Selem/Shifaa_Arabic_Mental_Health_Consultations.","url":"https://huggingface.co/datasets/Ahmed-Selem/Shifaa_Arabic_Mental_Health_Consultations","creator_name":"Ahmed Selem","creator_url":"https://huggingface.co/Ahmed-Selem","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["question-answering","text-classification","zero-shot-classification","Arabic","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"amazon_massive_scenario","keyword":"arabic","description":"\n  MassiveScenarioClassification\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nMASSIVE: A 1M-Example Multilingual Natural Language Understanding Dataset with 51 Typologically-Diverse Languages\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2c\n\n\nDomains\nSpoken\n\nReference\nhttps://arxiv.org/abs/2204.08582\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask = mteb.get_tasks([\"MassiveScenarioClassification\"])\nevaluator =â€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/amazon_massive_scenario.","url":"https://huggingface.co/datasets/mteb/amazon_massive_scenario","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","human-annotated","translated","Afrikaans","Amharic"],"keywords_longer_than_N":true},
	{"name":"quran-riwayat","keyword":"arabic","description":"\n\t\n\t\t\n\t\tØ±ÙˆØ§ÙŠØ§Øª Ø§Ù„Ù‚Ø±Ø¢Ù† Ø§Ù„ÙƒØ±ÙŠÙ…\n\t\n\nThis dataset is a collection of 8 Riwayat (of 4 Qira'at) of the Quran:\n\nhafs: Ø±ÙˆØ§ÙŠØ© Ø­ÙØµ Ø¹Ù† Ø¹Ø§ØµÙ…\nshouba: Ø±ÙˆØ§ÙŠØ© Ø´Ø¹Ø¨Ø© Ø¹Ù† Ø¹Ø§ØµÙ…\nwarsh: Ø±ÙˆØ§ÙŠØ© ÙˆØ±Ø´ Ø¹Ù† Ù†Ø§ÙØ¹\nqaloon: Ø±ÙˆØ§ÙŠØ© Ù‚Ø§Ù„ÙˆÙ† Ø¹Ù† Ù†Ø§ÙØ¹\nalsosi: Ø±ÙˆØ§ÙŠØ© Ø§Ù„Ø³ÙˆØ³ÙŠ Ø¹Ù† Ø£Ø¨ÙŠ Ø¹Ù…Ø±Ùˆ Ø§Ù„Ø¨ØµØ±ÙŠ\naldoori: Ø±ÙˆØ§ÙŠØ© Ø§Ù„Ø¯ÙˆØ±ÙŠ Ø¹Ù† Ø£Ø¨ÙŠ Ø¹Ù…Ø±Ùˆ Ø§Ù„Ø¨ØµØ±ÙŠ\nqumbul: Ø±ÙˆØ§ÙŠØ© Ù‚Ù†Ø¨Ù„ Ø¹Ù† Ø§Ø¨Ù† ÙƒØ«ÙŠØ± Ø§Ù„Ù…ÙƒÙŠ\nalbazzi: Ø±ÙˆØ§ÙŠØ© Ø§Ù„Ø¨Ø²ÙŠ Ø¹Ù† Ø§Ø¨Ù† ÙƒØ«ÙŠØ± Ø§Ù„Ù…ÙƒÙŠ\n\nScraped from https://surahquran.com/ , so thanks to them!\n","url":"https://huggingface.co/datasets/Abdou/quran-riwayat","creator_name":"Rockikz","creator_url":"https://huggingface.co/Abdou","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["Arabic","mit","< 1K","parquet","Text"],"keywords_longer_than_N":true},
	{"name":"Egyptian-Handwriting-Dataset","keyword":"arabic","description":"\n\t\n\t\t\n\t\tEgyptian Handwriting Dataset\n\t\n\nA dataset of 11k+ handwritten Arabic words from Egyptian writers, extracted and tightly cropped from scanned paper forms. This dataset offers diverse handwriting samples ranging from children to elderly contributors, making it ideal for training robust Arabic handwriting recognition models.\n\n  \n\n\n\nEach form contains 6 unique words, resulting in 24 handwritten word images per form.\nEach word is written four times by the same writer to captureâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/OmarMDiab/Egyptian-Handwriting-Dataset.","url":"https://huggingface.co/datasets/OmarMDiab/Egyptian-Handwriting-Dataset","creator_name":"Omar Diab","creator_url":"https://huggingface.co/OmarMDiab","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["image-to-text","Arabic","cc-by-4.0","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"Egyptian-Handwriting-Dataset","keyword":"arabic","description":"\n\t\n\t\t\n\t\tEgyptian Handwriting Dataset\n\t\n\nA dataset of 11k+ handwritten Arabic words from Egyptian writers, extracted and tightly cropped from scanned paper forms. This dataset offers diverse handwriting samples ranging from children to elderly contributors, making it ideal for training robust Arabic handwriting recognition models.\n\n  \n\n\n\nEach form contains 6 unique words, resulting in 24 handwritten word images per form.\nEach word is written four times by the same writer to captureâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/OmarMDiab/Egyptian-Handwriting-Dataset.","url":"https://huggingface.co/datasets/OmarMDiab/Egyptian-Handwriting-Dataset","creator_name":"Omar Diab","creator_url":"https://huggingface.co/OmarMDiab","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["image-to-text","Arabic","cc-by-4.0","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"arabic-tts-wav-24k","keyword":"arabic","description":"\n\t\n\t\t\n\t\tArabic TTS WAV 24k Dataset\n\t\n\nA high-quality, open-source dataset for Arabic Text-to-Speech (TTS) research, containing paired audio and text samples from both male and female speakers. All audio is provided in 24kHz WAV format, with rich metadata and phonetic transcriptions.\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset is designed for training and evaluating neural TTS systems in Modern Standard Arabic. It includes:\n\nAudio: Clean, studio-quality WAV files at 24,000 Hz.\nText: Original Arabicâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/NeoBoy/arabic-tts-wav-24k.","url":"https://huggingface.co/datasets/NeoBoy/arabic-tts-wav-24k","creator_name":"Sharjeel Abid Butt","creator_url":"https://huggingface.co/NeoBoy","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-to-speech","Arabic","mit","1K - 10K","parquet"],"keywords_longer_than_N":true},
	{"name":"arabic-tts-wav-24k","keyword":"arabic","description":"\n\t\n\t\t\n\t\tArabic TTS WAV 24k Dataset\n\t\n\nA high-quality, open-source dataset for Arabic Text-to-Speech (TTS) research, containing paired audio and text samples from both male and female speakers. All audio is provided in 24kHz WAV format, with rich metadata and phonetic transcriptions.\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset is designed for training and evaluating neural TTS systems in Modern Standard Arabic. It includes:\n\nAudio: Clean, studio-quality WAV files at 24,000 Hz.\nText: Original Arabicâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/NeoBoy/arabic-tts-wav-24k.","url":"https://huggingface.co/datasets/NeoBoy/arabic-tts-wav-24k","creator_name":"Sharjeel Abid Butt","creator_url":"https://huggingface.co/NeoBoy","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-to-speech","Arabic","mit","1K - 10K","parquet"],"keywords_longer_than_N":true},
	{"name":"TxT360-500k-sample-no_cc","keyword":"arabic","description":"\n\t\n\t\t\n\t\tBEE-spoke-data/TxT360-500k-sample-no_cc\n\t\n\nno common crawl\n","url":"https://huggingface.co/datasets/BEE-spoke-data/TxT360-500k-sample-no_cc","creator_name":"BEEspoke Data","creator_url":"https://huggingface.co/BEE-spoke-data","license_name":"Open Data Commons Attribution License v1.0","license_url":"https://scancode-licensedb.aboutcode.org/odc-by-1.0.html","language":"en","first_N":5,"first_N_keywords":["text-generation","feature-extraction","English","German","Japanese"],"keywords_longer_than_N":true},
	{"name":"ILMAAM-Arabic-Culturally-Aligned-MMLU","keyword":"arabic","description":"\n\t\n\t\t\n\t\tILMAAM Arabic Culturally Aligned MMLU Benchmark\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThe ILMAAM (Index for Language Models for Arabic Assessment on Multitasks) benchmark provides a culturally enriched, linguistically refined, and contextually relevant evaluation framework for Arabic Large Language Models (LLMs). It is based on the Arabic Massive Multitask Language Understanding (MMLU) dataset but extends it with culturally aligned topics and annotations for fluency, adequacy, culturalâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Omartificial-Intelligence-Space/ILMAAM-Arabic-Culturally-Aligned-MMLU.","url":"https://huggingface.co/datasets/Omartificial-Intelligence-Space/ILMAAM-Arabic-Culturally-Aligned-MMLU","creator_name":"Omartificial Intelligence Space","creator_url":"https://huggingface.co/Omartificial-Intelligence-Space","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["Arabic","apache-2.0","10K - 100K","csv","Text"],"keywords_longer_than_N":true},
	{"name":"ILMAAM-Arabic-Culturally-Aligned-MMLU","keyword":"arabic","description":"\n\t\n\t\t\n\t\tILMAAM Arabic Culturally Aligned MMLU Benchmark\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThe ILMAAM (Index for Language Models for Arabic Assessment on Multitasks) benchmark provides a culturally enriched, linguistically refined, and contextually relevant evaluation framework for Arabic Large Language Models (LLMs). It is based on the Arabic Massive Multitask Language Understanding (MMLU) dataset but extends it with culturally aligned topics and annotations for fluency, adequacy, culturalâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Omartificial-Intelligence-Space/ILMAAM-Arabic-Culturally-Aligned-MMLU.","url":"https://huggingface.co/datasets/Omartificial-Intelligence-Space/ILMAAM-Arabic-Culturally-Aligned-MMLU","creator_name":"Omartificial Intelligence Space","creator_url":"https://huggingface.co/Omartificial-Intelligence-Space","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["Arabic","apache-2.0","10K - 100K","csv","Text"],"keywords_longer_than_N":true},
	{"name":"quran-indonesia-tafseer-translation","keyword":"arabic","description":"emhaihsan/quran-indonesia-tafseer-translation dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/emhaihsan/quran-indonesia-tafseer-translation","creator_name":"Muhammad Ihsan","creator_url":"https://huggingface.co/emhaihsan","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["question-answering","Indonesian","Arabic","mit","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"tweet_sentiment_multilingual","keyword":"arabic","description":"\n  TweetSentimentClassification\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nA multilingual Sentiment Analysis dataset consisting of tweets in 8 different languages.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2c\n\n\nDomains\nSocial, Written\n\n\nReferencehttps://aclanthology.org/2022.lrec-1.27\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask = mteb.get_tasks([\"TweetSentimentClassification\"])\nevaluator =â€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/tweet_sentiment_multilingual.","url":"https://huggingface.co/datasets/mteb/tweet_sentiment_multilingual","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"Creative Commons Attribution 3.0","license_url":"https://scancode-licensedb.aboutcode.org/cc-by-3.0.html","language":"en","first_N":5,"first_N_keywords":["text-classification","sentiment-analysis","sentiment-scoring","sentiment-classification","hate-speech-detection"],"keywords_longer_than_N":true},
	{"name":"MSA_train_set","keyword":"arabic","description":"Pre-processed MSA data based on https://huggingface.co/datasets/mozilla-foundation/common_voice_16_1.\n","url":"https://huggingface.co/datasets/otozz/MSA_train_set","creator_name":"Ã–mer","creator_url":"https://huggingface.co/otozz","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["Arabic","cc0-1.0","10K - 100K","parquet","Audio"],"keywords_longer_than_N":true},
	{"name":"mewsli-x","keyword":"arabic","description":"I generated the dataset following mewsli-x.md#getting-started\nand converted into different parts (see process.py):\n\nar/de/en/es/fa/ja/pl/ro/ta/tr/uk wikinews_mentions dev and test (from wikinews_mentions-dev/test.jsonl)\ncandidate entities of 50 languages (from candidate_set_entities.jsonl)\nEnglish wikipedia_pairs to fine-tune models (from wikipedia_pairs-dev/train.jsonl)\n\nRaw data files are in raw.tar.gz, which contains:\n[...] 535M Feb 24 22:06 candidate_set_entities.jsonl\n[...] 9.8M Feb 24â€¦ See the full description on the dataset page: https://huggingface.co/datasets/izhx/mewsli-x.","url":"https://huggingface.co/datasets/izhx/mewsli-x","creator_name":"Xin Zhang","creator_url":"https://huggingface.co/izhx","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","entity-linking-retrieval","Afrikaans","Arabic","Azerbaijani"],"keywords_longer_than_N":true},
	{"name":"Arabic-NLi-Triplet","keyword":"arabic","description":"\n\t\n\t\t\n\t\tArabic NLI Triplet\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\n\nThe Arabic Version of SNLI and MultiNLI datasets. (Triplet Subset)\nOriginally used for Natural Language Inference (NLI), \nDataset may be used for training/finetuning an embedding model for semantic textual similarity.\n\n\n\t\n\t\t\n\t\tTriplet Subset\n\t\n\n\nColumns: \"anchor\", \"positive\", \"negative\"\nColumn types: str, str, str\n\nExamples:\n{\n  \"anchor\": \"Ø´Ø®Øµ Ø¹Ù„Ù‰ Ø­ØµØ§Ù† ÙŠÙ‚ÙØ² ÙÙˆÙ‚ Ø·Ø§Ø¦Ø±Ø© Ù…Ø¹Ø·Ù„Ø©\",\n  \"positive\": \"Ø´Ø®Øµ ÙÙŠ Ø§Ù„Ù‡ÙˆØ§Ø¡ Ø§Ù„Ø·Ù„Ù‚ØŒ Ø¹Ù„Ù‰ Ø­ØµØ§Ù†.\",\n  \"negative\":â€¦ See the full description on the dataset page: https://huggingface.co/datasets/Omartificial-Intelligence-Space/Arabic-NLi-Triplet.","url":"https://huggingface.co/datasets/Omartificial-Intelligence-Space/Arabic-NLi-Triplet","creator_name":"Omartificial Intelligence Space","creator_url":"https://huggingface.co/Omartificial-Intelligence-Space","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["sentence-similarity","Arabic","apache-2.0","100K - 1M","csv"],"keywords_longer_than_N":true},
	{"name":"Arabic-OpenHermes-2.5","keyword":"arabic","description":"\n\t\n\t\t\n\t\tDataset Card for \"Arabic-OpenHermes-2.5\"\n\t\n\n\n\n\n\t\n\t\t\n\t\tDataset Sources & Infos\n\t\n\n\nData Origin: Derived from the original OpenHermes dataset : teknium/OpenHermes-2.5.\nLanguages: Modern Standard Arabic (MSA)\nApplications: Language Modeling\nMaintainer: Marwa El Kamil & Mohammed Machrouh\nLicense: Apache-2.0\n\n\n\t\n\t\t\n\t\n\t\n\t\tOverview\n\t\n\nArabic-OpenHermes-2.5 is a carefully curated dataset extracted / translated from the OpenHermes-2.5 collection provided by teknium.\n\n\t\n\t\n\t\n\t\tPurposeâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/2A2I/Arabic-OpenHermes-2.5.","url":"https://huggingface.co/datasets/2A2I/Arabic-OpenHermes-2.5","creator_name":"2A2I","creator_url":"https://huggingface.co/2A2I","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["Arabic","apache-2.0","100K - 1M","parquet","Text"],"keywords_longer_than_N":true},
	{"name":"arabic-tashkeel-dataset","keyword":"arabic","description":"\n\t\n\t\t\n\t\tArabic Tashkeel Dataset\n\t\n\nThis is a fairly large dataset gathered from five main sources:\n\ntashkeela (1.79GB - 45.05%): The entire Tashkeela dataset, repurposed in sentences. Some rows were omitted as they contain low diacritic (tashkeel characters) rate.\nshamela (1.67GB - 42.10%): Random pages from over 2,000 books on the Shamela Library. Pages were selected using the below function (high diacritics rate)\nwikipedia (269.94MB - 6.64%): A collection of Wikipedia articles. Diacriticsâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Abdou/arabic-tashkeel-dataset.","url":"https://huggingface.co/datasets/Abdou/arabic-tashkeel-dataset","creator_name":"Rockikz","creator_url":"https://huggingface.co/Abdou","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["Arabic","mit","1M - 10M","parquet","Text"],"keywords_longer_than_N":true},
	{"name":"Algerian-Darija","keyword":"arabic","description":"\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset contains text in Algerian Darija, collected from a variety of sources including existing datasets on Hugging Face, web scraping, and YouTube transcript APIs. \n\nThe train split consists more then 2k rows of uncleaned text data.\n\nThe v1 split consists more than 170k rows of split and partially cleaned text.\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tSources\n\t\n\nThe text data was gathered from:\n\nHugging Face Datasets: Pre-existing datasets relevant to Algerian Darija.\nWeb Scraping: Contentâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/ayoubkirouane/Algerian-Darija.","url":"https://huggingface.co/datasets/ayoubkirouane/Algerian-Darija","creator_name":"Ayoub Kirouane","creator_url":"https://huggingface.co/ayoubkirouane","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","text2text-generation","Arabic","cc-by-4.0","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"iraqi_test_set","keyword":"arabic","description":"Pre-processed Iraqi test partition from the MASC-dataset:\nMohammad Al-Fetyani, Muhammad Al-Barham, Gheith Abandah, Adham Alsharkawi, Maha Dawas, August 18, 2021, \"MASC: Massive Arabic Speech Corpus\", IEEE Dataport, doi: https://dx.doi.org/10.21227/e1qb-jv46.\n","url":"https://huggingface.co/datasets/otozz/iraqi_test_set","creator_name":"Ã–mer","creator_url":"https://huggingface.co/otozz","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["Arabic","cc-by-4.0","1K - 10K","parquet","Datasets"],"keywords_longer_than_N":true},
	{"name":"el-mal-el-halal-podcast-subtitles","keyword":"arabic","description":"\n\t\n\t\t\n\t\tEl Mal El Halal Podcast Subtitles\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nEl Mal El Halal Podcast Subtitles is a collection of manual subtitles for 18 episodes of the El Mal El Halal podcast by Eng. Mohamed Aboulnaga, covering Arabic content. This dataset is designed for research on speech processing, translation, semantic search, and Arabic NLP.\n\nTotal episodes: 18 - untill the date of 03/08/2025\nTotal segments: 13â€¯970\nTotal words: 166â€¯505\nTotal duration: 20â€¯hâ€¯50â€¯mâ€¯56â€¯s (75â€¯057â€¯s)\nAverageâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/hossam87/el-mal-el-halal-podcast-subtitles.","url":"https://huggingface.co/datasets/hossam87/el-mal-el-halal-podcast-subtitles","creator_name":"Hossam El-Kharbotly","creator_url":"https://huggingface.co/hossam87","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","sentence-similarity","text-to-speech","translation","text-classification"],"keywords_longer_than_N":true},
	{"name":"ApolloMoEDataset","keyword":"arabic","description":"\n\t\n\t\t\n\t\tDemocratizing Medical LLMs For Much More Languages\n\t\n\nCovering 12 Major Languages including English, Chinese, French, Hindi, Spanish, Arabic, Russian, Japanese, Korean, German, Italian, Portuguese and 38 Minor Languages So far.\n\n   ðŸ“ƒ Paper â€¢ ðŸŒ Demo â€¢ ðŸ¤— ApolloMoEDataset â€¢ ðŸ¤— ApolloMoEBench  â€¢ ðŸ¤— Models  â€¢ðŸŒ Apollo  â€¢ ðŸŒ ApolloMoE\n\n\n\n\n\n\n\t\n\t\t\n\t\tðŸŒˆ Update\n\t\n\n\n[2024.10.15] ApolloMoE repo is publishedï¼ðŸŽ‰\n\n\n\t\n\t\t\n\t\tLanguages Coverage\n\t\n\n12 Major Languages and 38 Minor Languages\n\n  Click toâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/FreedomIntelligence/ApolloMoEDataset.","url":"https://huggingface.co/datasets/FreedomIntelligence/ApolloMoEDataset","creator_name":"FreedomAI","creator_url":"https://huggingface.co/FreedomIntelligence","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["question-answering","Arabic","English","Chinese","Korean"],"keywords_longer_than_N":true},
	{"name":"alquran","keyword":"arabic","description":"\n\t\n\t\t\n\t\tDataset Terjemahan dan Tafsir Al-Quran\n\t\n\n\n\t\n\t\t\n\t\tDeskripsi Dataset\n\t\n\nDataset ini berisi terjemahan Al-Quran dalam bahasa Indonesia beserta tafsirnya. Dataset ini dapat digunakan untuk berbagai tugas NLP seperti machine translation, text generation, dan text summarization.\n\n\t\n\t\t\n\t\tFitur Utama\n\t\n\n\nTerjemahan Al-Quran: Teks Al-Quran dalam bahasa Arab beserta terjemahannya dalam bahasa Indonesia.\nTafsir Al-Quran: Penjelasan atau interpretasi dari ayat-ayat Al-Quran dalam bahasaâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/ronnieaban/alquran.","url":"https://huggingface.co/datasets/ronnieaban/alquran","creator_name":"Ronnie Aban","creator_url":"https://huggingface.co/ronnieaban","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","translation","text-classification","Arabic","Indonesian"],"keywords_longer_than_N":true},
	{"name":"alquran","keyword":"arabic","description":"\n\t\n\t\t\n\t\tDataset Terjemahan dan Tafsir Al-Quran\n\t\n\n\n\t\n\t\t\n\t\tDeskripsi Dataset\n\t\n\nDataset ini berisi terjemahan Al-Quran dalam bahasa Indonesia beserta tafsirnya. Dataset ini dapat digunakan untuk berbagai tugas NLP seperti machine translation, text generation, dan text summarization.\n\n\t\n\t\t\n\t\tFitur Utama\n\t\n\n\nTerjemahan Al-Quran: Teks Al-Quran dalam bahasa Arab beserta terjemahannya dalam bahasa Indonesia.\nTafsir Al-Quran: Penjelasan atau interpretasi dari ayat-ayat Al-Quran dalam bahasaâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/ronnieaban/alquran.","url":"https://huggingface.co/datasets/ronnieaban/alquran","creator_name":"Ronnie Aban","creator_url":"https://huggingface.co/ronnieaban","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","translation","text-classification","Arabic","Indonesian"],"keywords_longer_than_N":true},
	{"name":"recitation-segmentation","keyword":"arabic","description":"\n\t\n\t\t\n\t\tRecitation Segmentation Dataset for Holy Quran Pronunciation Error Detection\n\t\n\nThis dataset is used for building models that segment Holy Quran recitations based on pause points (waqf) with high accuracy. The segments are crucial for tasks like Automatic Pronunciation Error Detection and Correction, leveraging the rigorous recitation rules (tajweed) of the Holy Quran.\nThe dataset was presented in the paper Automatic Pronunciation Error Detection and Correction of the Holy Quran'sâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/obadx/recitation-segmentation.","url":"https://huggingface.co/datasets/obadx/recitation-segmentation","creator_name":"Abdullah","creator_url":"https://huggingface.co/obadx","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","Arabic","mit","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"recitation-segmentation","keyword":"arabic","description":"\n\t\n\t\t\n\t\tRecitation Segmentation Dataset for Holy Quran Pronunciation Error Detection\n\t\n\nThis dataset is used for building models that segment Holy Quran recitations based on pause points (waqf) with high accuracy. The segments are crucial for tasks like Automatic Pronunciation Error Detection and Correction, leveraging the rigorous recitation rules (tajweed) of the Holy Quran.\nThe dataset was presented in the paper Automatic Pronunciation Error Detection and Correction of the Holy Quran'sâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/obadx/recitation-segmentation.","url":"https://huggingface.co/datasets/obadx/recitation-segmentation","creator_name":"Abdullah","creator_url":"https://huggingface.co/obadx","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","Arabic","mit","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"CaLMQA","keyword":"arabic","description":"\n\t\n\t\t\n\t\tDataset Summary\n\t\n\n\n\nCaLMQA is a translation-free long-form question answering (LFQA) dataset spanning 23 high- to low-resource languages. \n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nCaLMQA is a translation-free LFQA dataset with 51.7K questions from 23 languages, 11 high- to mid-resource and 12 low-resource.\nAll questions are culturally specific â€“ (1) they refer to concepts unique to one or a few cultures, such as\n\"Kuber iki umwami wa mbere wâ€™uburundi yitwa Ntare?\"â€¦ See the full description on the dataset page: https://huggingface.co/datasets/shanearora/CaLMQA.","url":"https://huggingface.co/datasets/shanearora/CaLMQA","creator_name":"Shane Arora","creator_url":"https://huggingface.co/shanearora","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["multilingual","Afar","Arabic","Baluchi","German"],"keywords_longer_than_N":true},
	{"name":"PashtoOCR","keyword":"arabic","description":"\n\t\n\t\t\n\t\tPsOCR - Pashto OCR Dataset\n\t\n\n\n    \n\n\n        ðŸŒ Zirak.ai\n          Â Â  | Â Â ðŸ¤— HuggingFace\n          Â Â  | Â Â  GitHub\n          Â Â  | Â Â  Kaggle\n          Â Â  | Â Â ðŸ“‘ Paper\n\n\nPsOCR: Benchmarking Large Multimodal Models for Optical Character Recognition in Low-resource Pashto Language\nThe dataset is also available at: https://www.kaggle.com/datasets/drijaz/PashtoOCR\n\n\t\n\t\t\n\t\tIntroduction\n\t\n\n\nPsOCR is a large-scale synthetic dataset for Optical Character Recognition in low-resource Pashtoâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/zirak-ai/PashtoOCR.","url":"https://huggingface.co/datasets/zirak-ai/PashtoOCR","creator_name":"Zirak","creator_url":"https://huggingface.co/zirak-ai","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-generation","Pashto","Arabic","English","Persian"],"keywords_longer_than_N":true},
	{"name":"Ara-TyDi-Triplet","keyword":"arabic","description":"\n\t\n\t\t\n\t\tArabic Mr. TyDi in Triplet Format\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset is a transformed version of the Arabic subset of the Mr. TyDi dataset, designed specifically for training retrieval and re-ranking models. Each query is paired with a positive passage and one of the multiple negative passages in a triplet format: (query, positive, negative). This restructuring resulted in a total of 362,000 rows, making it ideal for pairwise ranking tasks and contrastive learning approaches.â€¦ See the full description on the dataset page: https://huggingface.co/datasets/NAMAA-Space/Ara-TyDi-Triplet.","url":"https://huggingface.co/datasets/NAMAA-Space/Ara-TyDi-Triplet","creator_name":"Network for Advancing Modern ArabicNLP & AI","creator_url":"https://huggingface.co/NAMAA-Space","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["sentence-similarity","feature-extraction","Arabic","apache-2.0","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"P-MMEval","keyword":"arabic","description":"\n\t\n\t\t\n\t\tP-MMEval: A Parallel Multilingual Multitask Benchmark for Consistent Evaluation of LLMs\n\t\n\n\n\t\n\t\t\n\t\tIntroduction\n\t\n\nWe introduce a multilingual benchmark, P-MMEval, covering effective fundamental and capability-specialized datasets. We extend the existing benchmarks, ensuring consistent language coverage across all datasets and providing parallel samples among multiple languages, supporting up to 10 languages from 8 language families (i.e., en, zh, ar, es, ja, ko, th, fr, pt, vi). As aâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Qwen/P-MMEval.","url":"https://huggingface.co/datasets/Qwen/P-MMEval","creator_name":"Qwen","creator_url":"https://huggingface.co/Qwen","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["Arabic","Spanish","French","Japanese","Korean"],"keywords_longer_than_N":true},
	{"name":"muri-it-language-split","keyword":"arabic","description":"\n\t\n\t\t\n\t\tMURI-IT: Multilingual Instruction Tuning Dataset for 200 Languages via Multilingual Reverse Instructions\n\t\n\nMURI-IT is a large-scale multilingual instruction tuning dataset containing 2.2 million instruction-output pairs across 200 languages. It is designed to address the challenges of instruction tuning in low-resource languages with Multilingual Reverse Instructions (MURI), which ensures that the output is human-written, high-quality, and authentic to the cultural and linguisticâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/akoksal/muri-it-language-split.","url":"https://huggingface.co/datasets/akoksal/muri-it-language-split","creator_name":"Abdullatif Koksal","creator_url":"https://huggingface.co/akoksal","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text2text-generation","text-generation","question-answering","summarization","Achinese"],"keywords_longer_than_N":true},
	{"name":"ArabiBoost","keyword":"arabic","description":"Dataset\nThe ArabiBoost is the Instruction-tuning or fine-tuning dataset (5.7k samples) for MMLU_SyntheticData is generated using GPT-3.5 Turbo.\nNote: Please note that this is not the translated version of MMLU, it's an entirely independent dataset.\nSubjects\nIt has the data of the following subjects:\n\nHumanities ['Islamic Studies', 'Law', 'History', 'Philosophy']\nLanguage ['Arabic Language', 'Arabic Language (General)', 'Arabic Language (Grammar)']\nOther ['General Knowledge', 'Management'â€¦ See the full description on the dataset page: https://huggingface.co/datasets/Ashmal/ArabiBoost.","url":"https://huggingface.co/datasets/Ashmal/ArabiBoost","creator_name":"Ashmal Vayani","creator_url":"https://huggingface.co/Ashmal","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","Arabic","apache-2.0","1K - 10K","json"],"keywords_longer_than_N":true},
	{"name":"ArabiBoost","keyword":"arabic","description":"Dataset\nThe ArabiBoost is the Instruction-tuning or fine-tuning dataset (5.7k samples) for MMLU_SyntheticData is generated using GPT-3.5 Turbo.\nNote: Please note that this is not the translated version of MMLU, it's an entirely independent dataset.\nSubjects\nIt has the data of the following subjects:\n\nHumanities ['Islamic Studies', 'Law', 'History', 'Philosophy']\nLanguage ['Arabic Language', 'Arabic Language (General)', 'Arabic Language (Grammar)']\nOther ['General Knowledge', 'Management'â€¦ See the full description on the dataset page: https://huggingface.co/datasets/Ashmal/ArabiBoost.","url":"https://huggingface.co/datasets/Ashmal/ArabiBoost","creator_name":"Ashmal Vayani","creator_url":"https://huggingface.co/Ashmal","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","Arabic","apache-2.0","1K - 10K","json"],"keywords_longer_than_N":true},
	{"name":"casablanca","keyword":"arabic","description":"\n\t\n\t\t\n\t\tCasablanca Evaluation Dataset\n\t\n\nThis is a processed version of the UBC-NLP/Casablanca dataset, optimized for evaluation purposes.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset maintains the same structure as the original Casablanca dataset, with each country as a separate configuration. The main difference is that audio files are referenced by paths instead of being embedded in the dataset.\n\n\t\n\t\t\n\t\tDataset Configurations\n\t\n\nThe dataset has 8 configurations, one for each country:â€¦ See the full description on the dataset page: https://huggingface.co/datasets/tii-audio/casablanca.","url":"https://huggingface.co/datasets/tii-audio/casablanca","creator_name":"TII Audio","creator_url":"https://huggingface.co/tii-audio","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","Arabic","apache-2.0","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"oaast_rm_full_jieba","keyword":"arabic","description":"å°è¯•è§£å†³\"llm repetition problem\"ï¼Œä½¿ç”¨åˆ†è¯æ¨¡åž‹å¯¹oaastè¯­æ–™è¿›è¡Œâ€œç»“å·´åŒ–â€æ•°æ®å¢žå¼ºï¼Œæä¾›æ›´å¼ºçš„é‡å¤å†…å®¹æ‹’ç»æ•ˆæžœã€‚\nAttempts to solve the \"llm repetition problem\" by using a segmentation model to enhance the oaast corpus with \"stuttering\" data to provide stronger rejection of duplicate content.\nå…¶æ¬¡ï¼Œè¿˜è¿‡æ»¤æŽ‰äº†æ‰€æœ‰è‡ªæˆ‘è®¤çŸ¥çš„å¾®è°ƒæ ·æœ¬ã€‚\nSecond, it also filters out all the fine-tuned samples of self-cognition.\nfiles:\n\noaast_rm_full_jieba.jsonl : word level repeat\noaast_rm_full_sent_jieba.jsonl : sentence level repeat\n\n","url":"https://huggingface.co/datasets/lenML/oaast_rm_full_jieba","creator_name":"len","creator_url":"https://huggingface.co/lenML","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["English","Spanish","Russian","German","Polish"],"keywords_longer_than_N":true},
	{"name":"DarijaBridge","keyword":"arabic","description":"\n\t\n\t\t\n\t\tDarijaBridge Dataset Card\n\t\n\n\n\t\n\t\t\n\t\tGeneral Information\n\t\n\n\nDataset Name: DarijaBridge\nVersion: 1.0\nCreator: MAD-Community\nLanguage: Darija (Moroccan Arabic) and English\nTotal Tokens: 41,845,467 (in 'sentence' column)\nTask: Machine Translation\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nDarijaBridge is a community-driven bilingual corpus designed for machine translation tasks between Darija (Moroccan Arabic) and English. Created by MAD-Community, it encompasses a wide range of the Moroccan \"dialects\"â€¦ See the full description on the dataset page: https://huggingface.co/datasets/M-A-D/DarijaBridge.","url":"https://huggingface.co/datasets/M-A-D/DarijaBridge","creator_name":"Mixed Arabic Datasets","creator_url":"https://huggingface.co/M-A-D","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["translation","Arabic","English","apache-2.0","1M - 10M"],"keywords_longer_than_N":true},
	{"name":"AfriSentiClassification","keyword":"moroccan arabic","description":"\n  AfriSentiClassification\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nAfriSenti is the largest sentiment analysis dataset for under-represented African languages.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2c\n\n\nDomains\nSocial, Written\n\n\nReferencehttps://arxiv.org/abs/2302.08956\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask = mteb.get_tasks([\"AfriSentiClassification\"])\nevaluator = mteb.MTEB(task)\n\nmodelâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/AfriSentiClassification.","url":"https://huggingface.co/datasets/mteb/AfriSentiClassification","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","sentiment-analysis","sentiment-scoring","sentiment-classification","hate-speech-detection"],"keywords_longer_than_N":true},
	{"name":"BRIGHTER-emotion-categories","keyword":"arabic","description":"\n\t\n\t\t\n\t\tBRIGHTER Emotion Categories Dataset\n\t\n\nThis dataset contains the emotion categories data from the BRIGHTER paper: BRIdging the Gap in Human-Annotated Textual Emotion Recognition Datasets for 28 Languages.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe BRIGHTER Emotion Categories dataset is a comprehensive multi-language, multi-label emotion classification dataset with separate configurations for each language. It represents one of the largest human-annotated emotion datasets across multipleâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/brighter-dataset/BRIGHTER-emotion-categories.","url":"https://huggingface.co/datasets/brighter-dataset/BRIGHTER-emotion-categories","creator_name":"BRIGHTER Dataset","creator_url":"https://huggingface.co/brighter-dataset","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["Afrikaans","Arabic","German","English","Spanish"],"keywords_longer_than_N":true},
	{"name":"aya_evaluation_suite","keyword":"arabic","description":"\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nAya Evaluation Suite contains a total of 26,750 open-ended conversation-style prompts to evaluate multilingual open-ended generation quality.To strike a balance between language coverage and the quality that comes with human curation, we create an evaluation suite that includes:\n\nhuman-curated examples in 7 languages (tur, eng, yor, arb, zho, por, tel) â†’ aya-human-annotated.\nmachine-translations of handpicked examples into 101 languages â†’ dolly-machine-translated.â€¦ See the full description on the dataset page: https://huggingface.co/datasets/CohereLabs/aya_evaluation_suite.","url":"https://huggingface.co/datasets/CohereLabs/aya_evaluation_suite","creator_name":"Cohere Labs","creator_url":"https://huggingface.co/CohereLabs","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","crowdsourced","expert-generated","machine-generated","multilingual"],"keywords_longer_than_N":true},
	{"name":"webui-dom-snapshots","keyword":"arabic","description":"\n\t\n\t\t\n\t\tDataset Card for WebUI DOM snapshots\n\t\n\n\n\nThis dataset card aims to be a base template for new datasets. It has been generated using this raw template.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\n\n\n\n\n\nCurated by: Gary Benson\nLanguages: Mostly English (87%);\nDutch, French, Chinese, Japanese (1-2% each); 30+ others (<1% each)\nLicense: CC0 1.0 Universal\n\n\n\t\n\t\t\n\t\tDataset Sources [optional]\n\t\n\n\n\n\nRepository: [More Information Needed]\nPaper [optional]: [More Information Needed]â€¦ See the full description on the dataset page: https://huggingface.co/datasets/gbenson/webui-dom-snapshots.","url":"https://huggingface.co/datasets/gbenson/webui-dom-snapshots","creator_name":"Gary Benson","creator_url":"https://huggingface.co/gbenson","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["image-feature-extraction","reinforcement-learning","text-classification","multilingual","biglab/webui-7k"],"keywords_longer_than_N":true},
	{"name":"usul-alkafi","keyword":"arabic","description":"\n\t\n\t\t\n\t\tUsul Al-Kafi Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset contains the full text of Ø§Ù„Ø£ØµÙˆÙ„ Ù…Ù† Ø§Ù„ÙƒØ§ÙÙŠ, a foundational Islamic book authored by Ø«Ù‚Ø© Ø§Ù„Ø¥Ø³Ù„Ø§Ù… Ø£Ø¨ÙŠ Ø¬Ø¹ÙØ± Ù…Ø­Ù…Ø¯ Ø¨Ù† ÙŠØ¹Ù‚ÙˆØ¨ Ø¨Ù† Ø¥Ø³Ø­Ø§Ù‚ Ø§Ù„ÙƒÙ„ÙŠÙ†ÙŠ Ø§Ù„Ø±Ø§Ø²ÙŠ. Each row in the dataset represents a single page from the book, preserving the original Arabic text structure. The book is divided into eight parts and includes beneficial annotations derived from various commentaries.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\nVersion: 1.0  \nSource: Digitized from Darâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/aliahabeeb/usul-alkafi.","url":"https://huggingface.co/datasets/aliahabeeb/usul-alkafi","creator_name":"ALi A. Habeeb","creator_url":"https://huggingface.co/aliahabeeb","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","text-generation","text-retrieval","summarization","Arabic"],"keywords_longer_than_N":true},
	{"name":"panlex-meanings","keyword":"egyptian arabic","description":"\n\t\n\t\t\n\t\tDataset Card for panlex-meanings\n\t\n\nThis is a dataset of words in several thousand languages, extracted from https://panlex.org.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset has been extracted from https://panlex.org (the 20240301 database dump) and rearranged on the per-language basis.\nEach language subset consists of expressions (words and phrases). \nEach expression is associated with some meanings (if there is more than one meaning, they are in separateâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/cointegrated/panlex-meanings.","url":"https://huggingface.co/datasets/cointegrated/panlex-meanings","creator_name":"David Dale","creator_url":"https://huggingface.co/cointegrated","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["translation","Afar","Western Abnaki","Abkhazian","Abaza"],"keywords_longer_than_N":true},
	{"name":"panlex-meanings","keyword":"moroccan arabic","description":"\n\t\n\t\t\n\t\tDataset Card for panlex-meanings\n\t\n\nThis is a dataset of words in several thousand languages, extracted from https://panlex.org.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset has been extracted from https://panlex.org (the 20240301 database dump) and rearranged on the per-language basis.\nEach language subset consists of expressions (words and phrases). \nEach expression is associated with some meanings (if there is more than one meaning, they are in separateâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/cointegrated/panlex-meanings.","url":"https://huggingface.co/datasets/cointegrated/panlex-meanings","creator_name":"David Dale","creator_url":"https://huggingface.co/cointegrated","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["translation","Afar","Western Abnaki","Abkhazian","Abaza"],"keywords_longer_than_N":true},
	{"name":"panlex-meanings","keyword":"standard arabic","description":"\n\t\n\t\t\n\t\tDataset Card for panlex-meanings\n\t\n\nThis is a dataset of words in several thousand languages, extracted from https://panlex.org.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset has been extracted from https://panlex.org (the 20240301 database dump) and rearranged on the per-language basis.\nEach language subset consists of expressions (words and phrases). \nEach expression is associated with some meanings (if there is more than one meaning, they are in separateâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/cointegrated/panlex-meanings.","url":"https://huggingface.co/datasets/cointegrated/panlex-meanings","creator_name":"David Dale","creator_url":"https://huggingface.co/cointegrated","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["translation","Afar","Western Abnaki","Abkhazian","Abaza"],"keywords_longer_than_N":true},
	{"name":"tokenizer-robustness-mmlu","keyword":"arabic","description":"\n\t\n\t\t\n\t\tTokenizer Robustness MMLU Dataset\n\t\n\nThis dataset contains MMLU-formatted questions and answers designed to test tokenizer robustness across different text formats and languages.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset consists of the same questions presented in 6 different formats, with both test (20 questions) and development (5 questions) sets:\n\noriginal - Standard formatted questions\nminor_spelling_errors - Questions with minor misspellings\nspoken_language - Questions in casualâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Malikeh1375/tokenizer-robustness-mmlu.","url":"https://huggingface.co/datasets/Malikeh1375/tokenizer-robustness-mmlu","creator_name":"Malikeh Ehghaghi","creator_url":"https://huggingface.co/Malikeh1375","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["English","Russian","Chinese","Japanese","German"],"keywords_longer_than_N":true},
	{"name":"tulu-3-sft-mixture-with-language","keyword":"egyptian arabic","description":"\n\nJust a version of the good tulu-3-sft-mixture dataset with a column indicating language.\nLanguage detection has been performed with fastText.\nâš ï¸ It may contain errors.\n","url":"https://huggingface.co/datasets/anakin87/tulu-3-sft-mixture-with-language","creator_name":"Stefano Fiorucci","creator_url":"https://huggingface.co/anakin87","license_name":"Open Data Commons Attribution License v1.0","license_url":"https://scancode-licensedb.aboutcode.org/odc-by-1.0.html","language":"en","first_N":5,"first_N_keywords":["other","crowdsourced","expert-generated","machine-generated","multilingual"],"keywords_longer_than_N":true},
	{"name":"tulu-3-sft-mixture-with-language","keyword":"levantine arabic","description":"\n\nJust a version of the good tulu-3-sft-mixture dataset with a column indicating language.\nLanguage detection has been performed with fastText.\nâš ï¸ It may contain errors.\n","url":"https://huggingface.co/datasets/anakin87/tulu-3-sft-mixture-with-language","creator_name":"Stefano Fiorucci","creator_url":"https://huggingface.co/anakin87","license_name":"Open Data Commons Attribution License v1.0","license_url":"https://scancode-licensedb.aboutcode.org/odc-by-1.0.html","language":"en","first_N":5,"first_N_keywords":["other","crowdsourced","expert-generated","machine-generated","multilingual"],"keywords_longer_than_N":true},
	{"name":"tulu-3-sft-mixture-with-language","keyword":"moroccan arabic","description":"\n\nJust a version of the good tulu-3-sft-mixture dataset with a column indicating language.\nLanguage detection has been performed with fastText.\nâš ï¸ It may contain errors.\n","url":"https://huggingface.co/datasets/anakin87/tulu-3-sft-mixture-with-language","creator_name":"Stefano Fiorucci","creator_url":"https://huggingface.co/anakin87","license_name":"Open Data Commons Attribution License v1.0","license_url":"https://scancode-licensedb.aboutcode.org/odc-by-1.0.html","language":"en","first_N":5,"first_N_keywords":["other","crowdsourced","expert-generated","machine-generated","multilingual"],"keywords_longer_than_N":true},
	{"name":"tulu-3-sft-mixture-with-language","keyword":"najdi arabic","description":"\n\nJust a version of the good tulu-3-sft-mixture dataset with a column indicating language.\nLanguage detection has been performed with fastText.\nâš ï¸ It may contain errors.\n","url":"https://huggingface.co/datasets/anakin87/tulu-3-sft-mixture-with-language","creator_name":"Stefano Fiorucci","creator_url":"https://huggingface.co/anakin87","license_name":"Open Data Commons Attribution License v1.0","license_url":"https://scancode-licensedb.aboutcode.org/odc-by-1.0.html","language":"en","first_N":5,"first_N_keywords":["other","crowdsourced","expert-generated","machine-generated","multilingual"],"keywords_longer_than_N":true},
	{"name":"tulu-3-sft-mixture-with-language","keyword":"standard arabic","description":"\n\nJust a version of the good tulu-3-sft-mixture dataset with a column indicating language.\nLanguage detection has been performed with fastText.\nâš ï¸ It may contain errors.\n","url":"https://huggingface.co/datasets/anakin87/tulu-3-sft-mixture-with-language","creator_name":"Stefano Fiorucci","creator_url":"https://huggingface.co/anakin87","license_name":"Open Data Commons Attribution License v1.0","license_url":"https://scancode-licensedb.aboutcode.org/odc-by-1.0.html","language":"en","first_N":5,"first_N_keywords":["other","crowdsourced","expert-generated","machine-generated","multilingual"],"keywords_longer_than_N":true},
	{"name":"tulu-3-sft-mixture-with-language","keyword":"ta'izzi-adeni arabic","description":"\n\nJust a version of the good tulu-3-sft-mixture dataset with a column indicating language.\nLanguage detection has been performed with fastText.\nâš ï¸ It may contain errors.\n","url":"https://huggingface.co/datasets/anakin87/tulu-3-sft-mixture-with-language","creator_name":"Stefano Fiorucci","creator_url":"https://huggingface.co/anakin87","license_name":"Open Data Commons Attribution License v1.0","license_url":"https://scancode-licensedb.aboutcode.org/odc-by-1.0.html","language":"en","first_N":5,"first_N_keywords":["other","crowdsourced","expert-generated","machine-generated","multilingual"],"keywords_longer_than_N":true},
	{"name":"nomiracl-instruct","keyword":"arabic","description":"\n\t\n\t\t\n\t\tDataset Card for NoMIRACL (EMNLP 2024 Findings Track)\n\t\n\n\n\t\n\t\t\n\t\tQuick Overview\n\t\n\nThis repository contains the fine-tuning (training & development split) of the NoMIRACL instruct dataset for fine-tuning LLMs on multilingual relevance assessment.\nThe training dataset is a binary classification task; they need to explicitly output either Yes, answer is present or I don't know. \nThe dataset contains training pairs from all 18 languages for both splits: relevant & non-relevant.\nimportâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/miracl/nomiracl-instruct.","url":"https://huggingface.co/datasets/miracl/nomiracl-instruct","creator_name":"MIRACL","creator_url":"https://huggingface.co/miracl","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","text-generation","Arabic","Bengali","German"],"keywords_longer_than_N":true},
	{"name":"Lemonade","keyword":"arabic","description":"LEMONADE is a large, expert-annotated dataset for event extraction from news articles in 20 languages: English, Spanish, Arabic, French, Italian, Russian, German, Turkish, Burmese, Indonesian, Ukrainian, Korean, Portuguese, Dutch, Somali, Nepali, Chinese, Persian, Hebrew, and Japanese.\nSee https://github.com/stanford-oval/Lemonade for details.\n","url":"https://huggingface.co/datasets/stanford-oval/Lemonade","creator_name":"Stanford Open Virtual Assistant Lab (OVAL)","creator_url":"https://huggingface.co/stanford-oval","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","text-generation","English","Spanish","Arabic"],"keywords_longer_than_N":true},
	{"name":"african-medical-multimodal-fracture","keyword":"arabic","description":"\n\t\n\t\t\n\t\tAfrican Medical Multimodal Bone Fracture Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset is a comprehensive, multimodal bone break classification dataset specifically designed for African healthcare contexts. It addresses critical gaps in medical AI for resource-constrained environments while ensuring cultural sensitivity and local relevance.\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\n\nTotal Records: 1,129 multimodal medical cases\nOriginal Images: 1,128 X-ray images (89% of dataset)\nAugmentedâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/electricsheepafrica/african-medical-multimodal-fracture.","url":"https://huggingface.co/datasets/electricsheepafrica/african-medical-multimodal-fracture","creator_name":"Electric Sheep","creator_url":"https://huggingface.co/electricsheepafrica","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["image-classification","text-classification","other","English","French"],"keywords_longer_than_N":true},
	{"name":"SMPQA","keyword":"arabic","description":"\n\t\n\t\t\n\t\n\t\n\t\tSMPQA (Synthetic Multilingual Plot QA)\n\t\n\n\n\nThe SMPQA evaluation dataset proposed in Centurio: On Drivers of Multilingual Ability of Large Vision-Language Model.\nSMPQA is composed of synthetic bar plots and pie charts (generated using word lists of different languages) together with questions about those plots.\nThe datasets aims at providing an initial way of evaluating multilingual OCR capabilities of models in arbritrary languages.\nThere are two sub-tasks: \n\nGrounding text labelsâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/WueNLP/SMPQA.","url":"https://huggingface.co/datasets/WueNLP/SMPQA","creator_name":"WÃ¼NLP","creator_url":"https://huggingface.co/WueNLP","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["visual-question-answering","English","Zulu","Indonesian","Italian"],"keywords_longer_than_N":true},
	{"name":"hijja_splitted","keyword":"arabic","description":"shahad-alh/hijja_splitted dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/shahad-alh/hijja_splitted","creator_name":"Shahad Alhamili","creator_url":"https://huggingface.co/shahad-alh","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["Arabic","mit","10K - 100K","parquet","Image"],"keywords_longer_than_N":true},
	{"name":"waqfeya-library-compressed","keyword":"arabic","description":"\n\t\n\t\t\n\t\tWaqfeya Library - Compressed\n\t\n\n\n\t\n\t\t\n\t\tðŸ“– Overview\n\t\n\nWaqfeya is one of the primary online resources for Islamic books, similar to Shamela. It hosts more than 10,000 PDF books across over 80 categories.\nIn this dataset, we processed the original PDF files using Google Document AI APIs and extracted their contents into two additional formats: TXT and DOCX.\n\n\t\n\t\t\n\t\tðŸ“Š Dataset Contents\n\t\n\nThis dataset is identical to ieasybooks-org/waqfeya-library, with one key difference: the contentsâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/ieasybooks-org/waqfeya-library-compressed.","url":"https://huggingface.co/datasets/ieasybooks-org/waqfeya-library-compressed","creator_name":"Ø§Ù„ÙƒØªØ¨ Ø§Ù„Ù…ÙÙŠØ³Ù‘Ø±Ø©","creator_url":"https://huggingface.co/ieasybooks-org","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["image-to-text","Arabic","mit","10K - 100K","csv"],"keywords_longer_than_N":true},
	{"name":"Speech-Translation-Instructions","keyword":"arabic","description":"\n\t\n\t\t\n\t\tSpeech-Translation-Instructions\n\t\n\nThe instructions translated from 120 languages Common Voice to english, arabic, japanese, mandarin and french from common voice speech dataset. Suitable to use to finetune Speech LLM.\n","url":"https://huggingface.co/datasets/mesolitica/Speech-Translation-Instructions","creator_name":"Mesolitica","creator_url":"https://huggingface.co/mesolitica","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["text2text-generation","multilingual","Malay","English","Chinese"],"keywords_longer_than_N":true},
	{"name":"Medical-Consultation-Questions-in-Arabic","keyword":"arabic","description":"\n\t\n\t\t\n\t\tDataset Card for Dataset Name\n\t\n\n\n\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\nThis dataset contains 47,705 Arabic medical questions collected from the Arabic health platform Altibbi. Each question is categorized into a medical domain such as sexual health, dermatology, pediatrics, and more.\nThe dataset can be used for Natural Language Processing (NLP) tasks such as:\n\n\"Text classification (predicting medical categories)\".\n\"Question answering systems in Arabic\".\n\"Building Arabic healthcare chatbots\".â€¦ See the full description on the dataset page: https://huggingface.co/datasets/Yousseftaha/Medical-Consultation-Questions-in-Arabic.","url":"https://huggingface.co/datasets/Yousseftaha/Medical-Consultation-Questions-in-Arabic","creator_name":"Youssef Taha","creator_url":"https://huggingface.co/Yousseftaha","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","question-answering","Arabic","apache-2.0","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"MMLU_SyntheticData","keyword":"arabic","description":"Dataset\nMMLU_SyntheticData is generated using GPT-4. The aim of generating this dataset was to generate a similar dataset to MMLU. \nNote: Please note that this is not the translated version of MMLU, it's an entirely independent dataset.\nSubjects\nIt has the data of the following subjects:\n\nHumanities ['Islamic Studies', 'Law', 'History', 'Philosophy']\nLanguage ['Arabic Language', 'Arabic Language (General)', 'Arabic Language (Grammar)']\nOther ['General Knowledge', 'Management', 'Driving Test']â€¦ See the full description on the dataset page: https://huggingface.co/datasets/Ashmal/MMLU_SyntheticData.","url":"https://huggingface.co/datasets/Ashmal/MMLU_SyntheticData","creator_name":"Ashmal Vayani","creator_url":"https://huggingface.co/Ashmal","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","Arabic","apache-2.0","1K<n<10K","ðŸ‡ºðŸ‡¸ Region: US"],"keywords_longer_than_N":true},
	{"name":"MMLU_SyntheticData","keyword":"arabic","description":"Dataset\nMMLU_SyntheticData is generated using GPT-4. The aim of generating this dataset was to generate a similar dataset to MMLU. \nNote: Please note that this is not the translated version of MMLU, it's an entirely independent dataset.\nSubjects\nIt has the data of the following subjects:\n\nHumanities ['Islamic Studies', 'Law', 'History', 'Philosophy']\nLanguage ['Arabic Language', 'Arabic Language (General)', 'Arabic Language (Grammar)']\nOther ['General Knowledge', 'Management', 'Driving Test']â€¦ See the full description on the dataset page: https://huggingface.co/datasets/Ashmal/MMLU_SyntheticData.","url":"https://huggingface.co/datasets/Ashmal/MMLU_SyntheticData","creator_name":"Ashmal Vayani","creator_url":"https://huggingface.co/Ashmal","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","Arabic","apache-2.0","1K<n<10K","ðŸ‡ºðŸ‡¸ Region: US"],"keywords_longer_than_N":true},
	{"name":"SemEval2024-task8","keyword":"arabic","description":"\n\t\n\t\t\n\t\tSemEval2024-task8\n\t\n\nUnofficial mirror of M4 dataset from mbzuai-nlp/SemEval2024-task8 (website, github, codabench).\n\n\t\n\t\t\n\t\n\t\n\t\tData Format\n\t\n\n\n\t\n\t\t\n\t\n\t\n\t\tSubtask A\n\t\n\nAn object in the JSON format:\n{\n  id -> identifier of the example,\n  label -> label (human text: 0, machine text: 1,),\n  text -> text generated by a machine or written by a human,\n  model -> model that generated the data,\n  source -> source (Wikipedia, Wikihow, Peerread, Reddit, Arxiv)  on English or language (Arabicâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/d0rj/SemEval2024-task8.","url":"https://huggingface.co/datasets/d0rj/SemEval2024-task8","creator_name":"Dmitry Balobin","creator_url":"https://huggingface.co/d0rj","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","original","English","Arabic","German"],"keywords_longer_than_N":true},
	{"name":"maghrebi_test_set","keyword":"arabic","description":"Pre-processed Maghrebi test partition from the MASC-dataset:\nMohammad Al-Fetyani, Muhammad Al-Barham, Gheith Abandah, Adham Alsharkawi, Maha Dawas, August 18, 2021, \"MASC: Massive Arabic Speech Corpus\", IEEE Dataport, doi: https://dx.doi.org/10.21227/e1qb-jv46.\n","url":"https://huggingface.co/datasets/otozz/maghrebi_test_set","creator_name":"Ã–mer","creator_url":"https://huggingface.co/otozz","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["Arabic","cc-by-4.0","1K - 10K","parquet","Datasets"],"keywords_longer_than_N":true},
	{"name":"MMMLU_subset","keyword":"arabic","description":"\n\t\n\t\t\n\t\tAbout MMMLU subset\n\t\n\n  This is a subset of MMMLU, specifically, we sampled 10% of the original data to improve evaluation efficiency.\n  In addition, we categorize the questions into four categories by subject, i.e., STEM, HUMANITIES, SOCIAL SCIENCES, and OTHER, aligned with MMLU.\n\n\t\n\t\t\n\t\n\t\n\t\tMultilingual Massive Multitask Language Understanding (MMMLU)\n\t\n\nThe MMLU is a widely recognized benchmark of general knowledge attained by AI models. It covers a broad range of topics from 57â€¦ See the full description on the dataset page: https://huggingface.co/datasets/double7/MMMLU_subset.","url":"https://huggingface.co/datasets/double7/MMMLU_subset","creator_name":"Sen Yang","creator_url":"https://huggingface.co/double7","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["question-answering","Arabic","Bengali","German","Spanish"],"keywords_longer_than_N":true},
	{"name":"MAPS_Verified","keyword":"arabic","description":"\n\t\n\t\t\n\t\tDataset Card for Multilingual Benchmark for Global Agent Performance and Security\n\t\n\nThis is the first Multilingual Agentic AI Benchmark for evaluating agentic AI systems across different languages and diverse tasks. Benchmark enables systematic analysis of how agents perform under multilingual conditions. This dataset contains 550 instances for GAIA, 660 instances for ASB, 737 instances for Maths, and 1100 instances for SWE. Each task was translated into 10 target languages resultingâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Fujitsu-FRE/MAPS_Verified.","url":"https://huggingface.co/datasets/Fujitsu-FRE/MAPS_Verified","creator_name":"Fujitsu Research of Europe","creator_url":"https://huggingface.co/Fujitsu-FRE","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-generation","question-answering","Arabic","English","Japanese"],"keywords_longer_than_N":true},
	{"name":"wojood-arabic-ner","keyword":"arabic","description":"\n\t\n\t\t\n\t\tWojood Arabic NER (Sample, Processed)\n\t\n\nThis dataset is a processed version of the sample from the Wojood Arabic NER dataset, developed by SinaLab.The original dataset is licensed under the MIT License, and this processed sample is shared under the same terms.\nâš ï¸ Note: This is not the full Wojood corpus. The full dataset must be requested directly from the original authors (Prof. Mustafa Jarrar and team).\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset\n\t\n\n\nLanguage: Arabic\nTask: Named Entity Recognition (NER)â€¦ See the full description on the dataset page: https://huggingface.co/datasets/AhmedNabil1/wojood-arabic-ner.","url":"https://huggingface.co/datasets/AhmedNabil1/wojood-arabic-ner","creator_name":"Ahmed Nabil","creator_url":"https://huggingface.co/AhmedNabil1","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["token-classification","Arabic","mit","1K - 10K","csv"],"keywords_longer_than_N":true},
	{"name":"NoRobots-Command.R-DPO","keyword":"arabic","description":"\n\t\n\t\t\n\t\tðŸ¤— Dataset Card for \"NoRobots-Command.R-DPO\"\n\t\n\n\n\t\n\t\t\n\t\tDataset Sources & Infos\n\t\n\n\nData Origin: Derived from the Arabic No Robots dataset : 2A2I/H4_no_robots which is based on the original No Robots dataset inspired from the InstructGPT paper.\nLanguages: Modern Standard Arabic (MSA)\nLicense: CC BY-NC 4.0\nMaintainers: Ali Elfilali and Marwa El Kamil\n\n\n\t\n\t\n\t\n\t\tPurpose\n\t\n\nNoRobots-Command.R-DPO is a DPO dataset designed to advance Arabic NLP by comparing human-generatedâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/2A2I/NoRobots-Command.R-DPO.","url":"https://huggingface.co/datasets/2A2I/NoRobots-Command.R-DPO","creator_name":"2A2I","creator_url":"https://huggingface.co/2A2I","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["Arabic","apache-2.0","1K - 10K","parquet","Text"],"keywords_longer_than_N":true},
	{"name":"Arabic-finanical-rag-embedding-dataset","keyword":"arabic","description":"\n\t\n\t\t\n\t\tArabic Version of The Finanical Rag Embedding Dataset\n\t\n\n\nThis dataset is tailored for fine-tuning embedding models in Retrieval-Augmented Generation (RAG) setups. It consists of 7,000 question-context pairs translated into Arabic, sourced from NVIDIA's 2023 SEC Filing Report. \nThe dataset is designed to improve the performance of embedding models by providing positive samples for financial question-answering tasks in Arabic.\nThis dataset is the Arabic version of the originalâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Omartificial-Intelligence-Space/Arabic-finanical-rag-embedding-dataset.","url":"https://huggingface.co/datasets/Omartificial-Intelligence-Space/Arabic-finanical-rag-embedding-dataset","creator_name":"Omartificial Intelligence Space","creator_url":"https://huggingface.co/Omartificial-Intelligence-Space","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["Arabic","apache-2.0","1K - 10K","csv","Text"],"keywords_longer_than_N":true},
	{"name":"Arabic-finanical-rag-embedding-dataset","keyword":"arabic","description":"\n\t\n\t\t\n\t\tArabic Version of The Finanical Rag Embedding Dataset\n\t\n\n\nThis dataset is tailored for fine-tuning embedding models in Retrieval-Augmented Generation (RAG) setups. It consists of 7,000 question-context pairs translated into Arabic, sourced from NVIDIA's 2023 SEC Filing Report. \nThe dataset is designed to improve the performance of embedding models by providing positive samples for financial question-answering tasks in Arabic.\nThis dataset is the Arabic version of the originalâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Omartificial-Intelligence-Space/Arabic-finanical-rag-embedding-dataset.","url":"https://huggingface.co/datasets/Omartificial-Intelligence-Space/Arabic-finanical-rag-embedding-dataset","creator_name":"Omartificial Intelligence Space","creator_url":"https://huggingface.co/Omartificial-Intelligence-Space","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["Arabic","apache-2.0","1K - 10K","csv","Text"],"keywords_longer_than_N":true},
	{"name":"shamela-waqfeya-library-compressed","keyword":"arabic","description":"\n\t\n\t\t\n\t\tShamela Waqfeya Library - Compressed\n\t\n\n\n\t\n\t\t\n\t\tðŸ“– Overview\n\t\n\nShamela Waqfeya is one of the primary online resources for Islamic books, similar to Shamela. It hosts more than 4,500 PDF books across over 40 categories.\nIn this dataset, we processed the original PDF files using Google Document AI APIs and extracted their contents into two additional formats: TXT and DOCX.\n\n\t\n\t\t\n\t\tðŸ“Š Dataset Contents\n\t\n\nThis dataset is identical to ieasybooks-org/shamela-waqfeya-library, with one keyâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/ieasybooks-org/shamela-waqfeya-library-compressed.","url":"https://huggingface.co/datasets/ieasybooks-org/shamela-waqfeya-library-compressed","creator_name":"Ø§Ù„ÙƒØªØ¨ Ø§Ù„Ù…ÙÙŠØ³Ù‘Ø±Ø©","creator_url":"https://huggingface.co/ieasybooks-org","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["image-to-text","Arabic","mit","1K - 10K","csv"],"keywords_longer_than_N":true},
	{"name":"oasst2_egyptian_arabic_convs","keyword":"arabic","description":"kokojake/oasst2_egyptian_arabic_convs dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/kokojake/oasst2_egyptian_arabic_convs","creator_name":"Hossamhasanin","creator_url":"https://huggingface.co/kokojake","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","question-answering","Arabic","apache-2.0","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"hadith_alpaca_ft","keyword":"arabic","description":"\n\t\n\t\t\n\t\tHadith Alpaca Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis repository contains the Hadith Alpaca Dataset, comprising 4,592 meticulously processed Hadiths. \nThe dataset removes the initial chain of transmission in Arabic and extraneous commentary, focusing on the core Hadith text. \nIt's designed for training and evaluating language models, particularly in understanding and processing Islamic religious texts.\n\n\t\n\t\t\n\t\tData Format\n\t\n\nThe dataset is structured for ease of use and clarity. Eachâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/akbargherbal/hadith_alpaca_ft.","url":"https://huggingface.co/datasets/akbargherbal/hadith_alpaca_ft","creator_name":"Akbar Gherbal","creator_url":"https://huggingface.co/akbargherbal","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","Arabic","English","apache-2.0","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"arz-en-parallel-corpus","keyword":"egyptian arabic","description":"\n\t\n\t\t\n\t\tEgyptian Arabic - English Parallel Corpus ðŸ‡ªðŸ‡¬âœ¨ðŸ‡¬ðŸ‡§\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset is a cleaned and filtered merge of multiple Egyptian Arabic - English parallel corpora, containing ~27,000 aligned sentence pairs. Itâ€™s designed for researchers and developers working on machine translation, speech translation, and other NLP tasks involving Egyptian Arabic and English.\n\n\n\t\n\t\t\n\t\tSources ðŸ“š\n\t\n\nThis dataset integrates and refines data from the following publicly availableâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/IbrahimAmin/arz-en-parallel-corpus.","url":"https://huggingface.co/datasets/IbrahimAmin/arz-en-parallel-corpus","creator_name":"Ibrahim Amin","creator_url":"https://huggingface.co/IbrahimAmin","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["translation","English","Egyptian Arabic","mit","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"webfaq","keyword":"arabic","description":"WebFAQ Q&A Dataset\n\n   \n       Overview |\n       Details  |\n       Structure  |\n       Examples |\n       Considerations |\n       License |\n       Citation |\n       Contact |\n       Acknowledgement\n   \n\n\n\n\t\n\t\t\n\t\n\t\n\t\tOverview\n\t\n\nThe WebFAQ Q&A Dataset is a broad-coverage corpus of 96 million natural question-answer (QA) pairs in 75 languages, gathered from FAQ pages on the web. It leverages structured schema.org FAQPage annotations, making it a unique resource for large-scale Question Answeringâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/PaDaS-Lab/webfaq.","url":"https://huggingface.co/datasets/PaDaS-Lab/webfaq","creator_name":"Chair of Data Science, University of Passau","creator_url":"https://huggingface.co/PaDaS-Lab","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["question-answering","multilingual","Afrikaans","Amharic","Arabic"],"keywords_longer_than_N":true},
	{"name":"floras","keyword":"arabic","description":"\n\t\n\t\t\n\t\tFLORAS\n\t\n\nFLORAS is a 50-language benchmark For LOng-form Recognition And Summarization of spoken language. \nThe goal of FLORAS is to create a more realistic benchmarking environment for speech recognition, translation, and summarization models. \nUnlike typical academic benchmarks like LibriSpeech and FLEURS that uses pre-segmented single-speaker read-speech, FLORAS tests the capabilities of models on raw long-form conversational audio, which can have one or many speakers.\nTo encourageâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/espnet/floras.","url":"https://huggingface.co/datasets/espnet/floras","creator_name":"ESPnet","creator_url":"https://huggingface.co/espnet","license_name":"Creative Commons Attribution 3.0","license_url":"https://scancode-licensedb.aboutcode.org/cc-by-3.0.html","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","translation","summarization","English","Spanish"],"keywords_longer_than_N":true},
	{"name":"webfaq","keyword":"egyptian arabic","description":"WebFAQ Q&A Dataset\n\n   \n       Overview |\n       Details  |\n       Structure  |\n       Examples |\n       Considerations |\n       License |\n       Citation |\n       Contact |\n       Acknowledgement\n   \n\n\n\n\t\n\t\t\n\t\n\t\n\t\tOverview\n\t\n\nThe WebFAQ Q&A Dataset is a broad-coverage corpus of 96 million natural question-answer (QA) pairs in 75 languages, gathered from FAQ pages on the web. It leverages structured schema.org FAQPage annotations, making it a unique resource for large-scale Question Answeringâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/PaDaS-Lab/webfaq.","url":"https://huggingface.co/datasets/PaDaS-Lab/webfaq","creator_name":"Chair of Data Science, University of Passau","creator_url":"https://huggingface.co/PaDaS-Lab","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["question-answering","multilingual","Afrikaans","Amharic","Arabic"],"keywords_longer_than_N":true},
	{"name":"Ar-Reranking-Eval","keyword":"arabic","description":"\n\t\n\t\t\n\t\tArabic Reranking Evaluation Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Overview\n\t\n\nThis dataset, containing 468 rows, is curated for evaluating reranking and retrieval models in Arabic. It covers various topics such as artificial intelligence, machine learning, data analysis, technology, education, and more, with diverse query complexities and document lengths. The dataset is intended to aid in developing and benchmarking Arabic language models that rank information based on relevance.\n\n\t\n\t\t\n\t\tDatasetâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/NAMAA-Space/Ar-Reranking-Eval.","url":"https://huggingface.co/datasets/NAMAA-Space/Ar-Reranking-Eval","creator_name":"Network for Advancing Modern ArabicNLP & AI","creator_url":"https://huggingface.co/NAMAA-Space","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["Arabic","apache-2.0","< 1K","parquet","Text"],"keywords_longer_than_N":true},
	{"name":"undl_ar2en_aligned","keyword":"arabic","description":"\n\t\n\t\t\n\t\tDataset Card for \"undl_ar2en_aligned\"\n\t\n\nMore Information needed\n","url":"https://huggingface.co/datasets/bot-yaya/undl_ar2en_aligned","creator_name":"yaya","creator_url":"https://huggingface.co/bot-yaya","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["translation","Arabic","English","mit","10M - 100M"],"keywords_longer_than_N":true},
	{"name":"tunisian-msa-parallel-corpus-evaluated","keyword":"arabic","description":"\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset is a synthetic parallel corpus of Tunisian Arabic (aeb) and Modern Standard Arabic (arb).\nIt was created with a rigorous multi-stage pipeline to maximize quality and reproducibility, addressing the scarcity of high-quality resources for Tunisian Arabic NLP.\nThe primary goals are to support:\n\nMachine translation between Tunisian Arabic and MSA.\nResearch in dialectal-aware text generation and evaluation.\nCross-dialect representation learning in Arabicâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/tunis-ai/tunisian-msa-parallel-corpus-evaluated.","url":"https://huggingface.co/datasets/tunis-ai/tunisian-msa-parallel-corpus-evaluated","creator_name":"Tunisia.AI","creator_url":"https://huggingface.co/tunis-ai","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["translation","text-generation","Arabic","Tunisian Arabic","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"tunisian-msa-parallel-corpus-evaluated","keyword":"arabic","description":"\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset is a synthetic parallel corpus of Tunisian Arabic (aeb) and Modern Standard Arabic (arb).\nIt was created with a rigorous multi-stage pipeline to maximize quality and reproducibility, addressing the scarcity of high-quality resources for Tunisian Arabic NLP.\nThe primary goals are to support:\n\nMachine translation between Tunisian Arabic and MSA.\nResearch in dialectal-aware text generation and evaluation.\nCross-dialect representation learning in Arabicâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/tunis-ai/tunisian-msa-parallel-corpus-evaluated.","url":"https://huggingface.co/datasets/tunis-ai/tunisian-msa-parallel-corpus-evaluated","creator_name":"Tunisia.AI","creator_url":"https://huggingface.co/tunis-ai","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["translation","text-generation","Arabic","Tunisian Arabic","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"prophet-mosque-library","keyword":"arabic","description":"\n\t\n\t\t\n\t\tProphet's Mosque Library\n\t\n\n\n\t\n\t\t\n\t\tðŸ“– Overview\n\t\n\nProphetâ€™s Mosque Library is one of the primary resources for Islamic books. It hosts more than 48,000 PDF books across over 70 categories.\nIn this dataset, we processed the original PDF files using Google Document AI APIs and extracted their contents into two additional formats: TXT and DOCX.\n\n\t\n\t\t\n\t\tðŸ“Š Dataset Contents\n\t\n\nThe dataset includes 70,884 PDF files (spanning 23,494,042 pages) representing 48,717 Islamic books. Each book isâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/ieasybooks-org/prophet-mosque-library.","url":"https://huggingface.co/datasets/ieasybooks-org/prophet-mosque-library","creator_name":"Ø§Ù„ÙƒØªØ¨ Ø§Ù„Ù…ÙÙŠØ³Ù‘Ø±Ø©","creator_url":"https://huggingface.co/ieasybooks-org","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["image-to-text","Arabic","mit","10K - 100K","csv"],"keywords_longer_than_N":true},
	{"name":"tunisian-msa-parallel-corpus-evaluated","keyword":"tunisian arabic","description":"\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset is a synthetic parallel corpus of Tunisian Arabic (aeb) and Modern Standard Arabic (arb).\nIt was created with a rigorous multi-stage pipeline to maximize quality and reproducibility, addressing the scarcity of high-quality resources for Tunisian Arabic NLP.\nThe primary goals are to support:\n\nMachine translation between Tunisian Arabic and MSA.\nResearch in dialectal-aware text generation and evaluation.\nCross-dialect representation learning in Arabicâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/tunis-ai/tunisian-msa-parallel-corpus-evaluated.","url":"https://huggingface.co/datasets/tunis-ai/tunisian-msa-parallel-corpus-evaluated","creator_name":"Tunisia.AI","creator_url":"https://huggingface.co/tunis-ai","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["translation","text-generation","Arabic","Tunisian Arabic","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"eg-legal-classification","keyword":"arabic","description":"\n\t\n\t\t\n\t\tArabic Legal Dataset - Legal Text Classification\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nMulti-label classification dataset for Arabic legal texts with hierarchical categories and metadata.\nThis dataset contains 1,046 examples of classification data derived from Egyptian legal texts, including criminal law, civil law, procedural law, and personal status law. The dataset is designed for training and evaluating Arabic legal AI models.\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\n\nLanguage: Arabic (Egyptianâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fr3on/eg-legal-classification.","url":"https://huggingface.co/datasets/fr3on/eg-legal-classification","creator_name":"Ahmed Mardi","creator_url":"https://huggingface.co/fr3on","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","Arabic","apache-2.0","1K - 10K","parquet"],"keywords_longer_than_N":true},
	{"name":"eg-legal-classification","keyword":"arabic","description":"\n\t\n\t\t\n\t\tArabic Legal Dataset - Legal Text Classification\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nMulti-label classification dataset for Arabic legal texts with hierarchical categories and metadata.\nThis dataset contains 1,046 examples of classification data derived from Egyptian legal texts, including criminal law, civil law, procedural law, and personal status law. The dataset is designed for training and evaluating Arabic legal AI models.\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\n\nLanguage: Arabic (Egyptianâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fr3on/eg-legal-classification.","url":"https://huggingface.co/datasets/fr3on/eg-legal-classification","creator_name":"Ahmed Mardi","creator_url":"https://huggingface.co/fr3on","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","Arabic","apache-2.0","1K - 10K","parquet"],"keywords_longer_than_N":true},
	{"name":"Arabic-natural-questions","keyword":"arabic","description":"\n\t\n\t\t\n\t\tArabic Natural Questions Dataset\n\t\n\nThis dataset is an Arabic-translated version of the original Natural Questions dataset by sentence-transformers. It contains question-answer pairs and is suitable for use with Sentence Transformers and other models requiring semantic understanding of Arabic question-answer pairs.\nThe dataset is designed for training and evaluating embedding models on question-answer retrieval tasks in Arabic.\n\n\n\t\n\t\t\n\t\n\t\n\t\tðŸ“‚ Dataset Subsets\n\t\n\n\n\t\n\t\t\n\t\n\t\n\t\tpair Subsetâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Omartificial-Intelligence-Space/Arabic-natural-questions.","url":"https://huggingface.co/datasets/Omartificial-Intelligence-Space/Arabic-natural-questions","creator_name":"Omartificial Intelligence Space","creator_url":"https://huggingface.co/Omartificial-Intelligence-Space","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["Arabic","apache-2.0","100K - 1M","parquet","Text"],"keywords_longer_than_N":true},
	{"name":"Arabic-natural-questions","keyword":"arabic","description":"\n\t\n\t\t\n\t\tArabic Natural Questions Dataset\n\t\n\nThis dataset is an Arabic-translated version of the original Natural Questions dataset by sentence-transformers. It contains question-answer pairs and is suitable for use with Sentence Transformers and other models requiring semantic understanding of Arabic question-answer pairs.\nThe dataset is designed for training and evaluating embedding models on question-answer retrieval tasks in Arabic.\n\n\n\t\n\t\t\n\t\n\t\n\t\tðŸ“‚ Dataset Subsets\n\t\n\n\n\t\n\t\t\n\t\n\t\n\t\tpair Subsetâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Omartificial-Intelligence-Space/Arabic-natural-questions.","url":"https://huggingface.co/datasets/Omartificial-Intelligence-Space/Arabic-natural-questions","creator_name":"Omartificial Intelligence Space","creator_url":"https://huggingface.co/Omartificial-Intelligence-Space","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["Arabic","apache-2.0","100K - 1M","parquet","Text"],"keywords_longer_than_N":true},
	{"name":"NoRobots-Aya.23.8B-DPO","keyword":"arabic","description":"\n\t\n\t\t\n\t\tðŸ¤— Dataset Card for \"NoRobots-Aya.23.8B-DPO\"\n\t\n\n\n\t\n\t\t\n\t\tDataset Sources & Infos\n\t\n\n\nData Origin: Derived from the Arabic No Robots dataset : 2A2I/H4_no_robots which is based on the original No Robots dataset inspired from the InstructGPT paper.\nLanguages: Modern Standard Arabic (MSA)\nLicense: CC BY-NC 4.0\nMaintainers: Ali Elfilali and Marwa El Kamil\n\n\n\t\n\t\n\t\n\t\tPurpose\n\t\n\nNoRobots-Aya.23.8B-DPO is a DPO dataset designed to advance Arabic NLP by comparing human-generatedâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/2A2I/NoRobots-Aya.23.8B-DPO.","url":"https://huggingface.co/datasets/2A2I/NoRobots-Aya.23.8B-DPO","creator_name":"2A2I","creator_url":"https://huggingface.co/2A2I","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["Arabic","apache-2.0","1K - 10K","parquet","Text"],"keywords_longer_than_N":true},
	{"name":"Arabic_prompts_Mini_175","keyword":"arabic","description":"\n\t\n\t\t\n\t\tArabic Prompts Dataset\n\t\n\nOverview\nThe Arabic Prompts Dataset is a comprehensive collection of prompts designed to facilitate research and development in natural language processing (NLP), machine learning, and artificial intelligence, particularly focusing on Arabic language applications. This dataset includes a diverse range of topics and questions across various fields such as literature, science, technology, and culture, making it an invaluable resource for training modelsâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/HeshamHaroon/Arabic_prompts_Mini_175.","url":"https://huggingface.co/datasets/HeshamHaroon/Arabic_prompts_Mini_175","creator_name":"Hesham Haroon","creator_url":"https://huggingface.co/HeshamHaroon","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","Arabic","apache-2.0","< 1K","csv"],"keywords_longer_than_N":true},
	{"name":"Arabic-NLi-Pair","keyword":"arabic","description":"\n\t\n\t\t\n\t\tArabic-NLI-PAir\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\n\nThe Arabic Version of SNLI and MultiNLI datasets. (Pair Subset)\nOriginally used for Natural Language Inference (NLI),\nDataset may be used for training/finetuning an embedding model for semantic textual similarity.\n\n\n\t\n\t\t\n\t\tPair Subset\n\t\n\n\nColumns: \"anchor\", \"positive\"\nColumn types: str, str\n\nExamples:\n{\n  \"anchor\": \"ÙƒÙŠÙ Ø£ÙƒÙˆÙ† Ø¬ÙŠÙˆÙ„ÙˆØ¬ÙŠØ§Ù‹ Ø¬ÙŠØ¯Ø§Ù‹ØŸ\",\n  \"positive\": \"Ù…Ø§Ø°Ø§ Ø¹Ù„ÙŠ Ø£Ù† Ø£ÙØ¹Ù„ Ù„Ø£ÙƒÙˆÙ† Ø¬ÙŠÙˆÙ„ÙˆØ¬ÙŠØ§Ù‹ Ø¹Ø¸ÙŠÙ…Ø§Ù‹ØŸ\"\n}\n\n\n\t\n\t\t\n\t\tDisclaimer\n\t\n\nPlease noteâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Omartificial-Intelligence-Space/Arabic-NLi-Pair.","url":"https://huggingface.co/datasets/Omartificial-Intelligence-Space/Arabic-NLi-Pair","creator_name":"Omartificial Intelligence Space","creator_url":"https://huggingface.co/Omartificial-Intelligence-Space","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["sentence-similarity","Arabic","apache-2.0","100K - 1M","csv"],"keywords_longer_than_N":true},
	{"name":"PangeaBench-tydiqa","keyword":"arabic","description":"\n\t\n\t\t\n\t\tDataset Card for \"tydiqa\"\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nTyDi QA is a question answering dataset covering 11 typologically diverse languages with 204K question-answer pairs.\nThe languages of TyDi QA are diverse with regard to their typology -- the set of linguistic features that each language\nexpresses -- such that we expect models performing well on this set to generalize across a large number of the languages\nin the world. It contains language phenomena that would not be found inâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/neulab/PangeaBench-tydiqa.","url":"https://huggingface.co/datasets/neulab/PangeaBench-tydiqa","creator_name":"NeuLab @ LTI/CMU","creator_url":"https://huggingface.co/neulab","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["question-answering","extractive-qa","crowdsourced","crowdsourced","multilingual"],"keywords_longer_than_N":true},
	{"name":"The_Arabic_E-Book_Corpus","keyword":"arabic","description":"\n\t\n\t\t\n\t\tThe Arabic E-Book Corpus\n\t\n\n\n\t\n\t\t\n\t\tAlternative Title\n\t\n\nÙ…Ø¯ÙˆÙ†Ø© Ù„ØºÙˆÙŠØ© Ù„Ù„ÙƒØªØ¨ Ø§Ù„Ø¹Ø±Ø¨ÙŠØ© Ø§Ù„Ø¥Ù„ÙƒØªØ±ÙˆÙ†ÙŠØ©\n\n\t\n\t\t\n\t\tDescription\n\t\n\n\n\t\n\t\t\n\t\tØ¹Ø±Ø¨ÙŠ\n\t\n\nÙ…Ø¯ÙˆÙ†Ø© Ø§Ù„ÙƒØªØ¨ Ø§Ù„Ø¹Ø±Ø¨ÙŠØ© Ø§Ù„Ø¥Ù„ÙƒØªØ±ÙˆÙ†ÙŠØ© Ù‡ÙŠ Ù…Ø¬Ù…ÙˆØ¹Ø© Ø¨ÙŠØ§Ù†Ø§Øª Ù…ØªØ§Ø­Ø© Ù…Ø¬Ø§Ù†Ù‹Ø§ ØªØ¶Ù… 1,745 ÙƒØªØ§Ø¨Ù‹Ø§ (81.5 Ù…Ù„ÙŠÙˆÙ† ÙƒÙ„Ù…Ø©) Ù†ÙØ´Ø±Øª Ø¨ÙˆØ§Ø³Ø·Ø© Ù…Ø¤Ø³Ø³Ø© Ù‡Ù†Ø¯Ø§ÙˆÙŠ Ø¨ÙŠÙ† Ø¹Ø§Ù…ÙŠ 2008 Ùˆ2024. ØªØ´Ù…Ù„ Ø§Ù„ÙƒØªØ¨ Ø£Ù†ÙˆØ§Ø¹Ù‹Ø§ Ù…Ø®ØªÙ„ÙØ©ØŒ Ø¨Ù…Ø§ ÙÙŠ Ø°Ù„Ùƒ Ø§Ù„ÙƒØªØ¨ ØºÙŠØ± Ø§Ù„Ø±ÙˆØ§Ø¦ÙŠØ©ØŒ Ø§Ù„Ø±ÙˆØ§ÙŠØ§ØªØŒ Ø£Ø¯Ø¨ Ø§Ù„Ø£Ø·ÙØ§Ù„ØŒ Ø§Ù„Ø´Ø¹Ø±ØŒ ÙˆØ§Ù„Ù…Ø³Ø±Ø­ÙŠØ§Øª.\n\n\t\n\t\t\n\t\tEnglish\n\t\n\nThe Arabic E-Book Corpus is a freely available collection of 1,745 books (81.5 million words)â€¦ See the full description on the dataset page: https://huggingface.co/datasets/mohres/The_Arabic_E-Book_Corpus.","url":"https://huggingface.co/datasets/mohres/The_Arabic_E-Book_Corpus","creator_name":"Mohammad Fares","creator_url":"https://huggingface.co/mohres","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["Arabic","cc-by-4.0","1K - 10K","arrow","Tabular"],"keywords_longer_than_N":true},
	{"name":"MAPS","keyword":"arabic","description":"\n\t\n\t\t\n\t\tDataset Card for Multilingual Benchmark for Global Agent Performance and Security\n\t\n\nThis is the first Multilingual Agentic AI Benchmark for evaluating agentic AI systems across different languages and diverse tasks. Benchmark enables systematic analysis of how agents perform under multilingual conditions. To balance performance and safety evaluation, our benchmark comprises 805 tasks: 405 from performance-oriented datasets (GAIA, SWE-bench, MATH) and 400 from the Agent Securityâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Fujitsu-FRE/MAPS.","url":"https://huggingface.co/datasets/Fujitsu-FRE/MAPS","creator_name":"Fujitsu Research of Europe","creator_url":"https://huggingface.co/Fujitsu-FRE","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-generation","question-answering","Arabic","English","Japanese"],"keywords_longer_than_N":true},
	{"name":"ArPanEmo","keyword":"arabic","description":"\n\t\n\t\t\n\t\tDataset Card for \"ArPanEmo: An Open-Source Dataset for Fine-Grained Emotion Recognition in Arabic Online Content during COVID-19 Pandemic\"\n\t\n\n\n\t\n\t\t\n\t\tPaper:\n\t\n\nAlthobaiti, Maha Jarallah (2023), â€œArPanEmo: An Open-Source Dataset for Fine-Grained Emotion Recognition in Arabic Online Content during COVID-19 Pandemic.â€, Mendeley Data, V1, doi: 10.17632/d9yy8w52ns.1\n","url":"https://huggingface.co/datasets/asas-ai/ArPanEmo","creator_name":"ASAS AI","creator_url":"https://huggingface.co/asas-ai","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","Arabic","cc-by-4.0","< 1K","parquet"],"keywords_longer_than_N":true},
	{"name":"HPLT2.0_cleaned","keyword":"arabic","description":"This is a large-scale collection of web-crawled documents in 191 world languages, produced by the HPLT project. \nThe source of the data is mostly Internet Archive with some additions from Common Crawl.\nFor a detailed description of the dataset, please refer to https://hplt-project.org/datasets/v2.0\nThe Cleaned variant of HPLT Datasets v2.0\nThis is the cleaned variant of the HPLT Datasets v2.0 converted to the Parquet format semi-automatically when being uploaded here. \nThe original JSONL filesâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/jobs-git/HPLT2.0_cleaned.","url":"https://huggingface.co/datasets/jobs-git/HPLT2.0_cleaned","creator_name":"James Guana","creator_url":"https://huggingface.co/jobs-git","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["fill-mask","text-generation","language-modeling","multilingual","Achinese"],"keywords_longer_than_N":true},
	{"name":"GlotCC-V1","keyword":"arabic","description":"\n\t\n\t\t\n\t\tDataset Summary\n\t\n\n \n\nGlotCC-V1.0 is a document-level, general domain dataset derived from CommonCrawl, covering more than 1000 languages.It is built using the GlotLID language identification and Ungoliant pipeline from CommonCrawl.We release our pipeline as open-source at https://github.com/cisnlp/GlotCC.  \nList of Languages: See https://datasets-server.huggingface.co/splits?dataset=cis-lmu/GlotCC-V1 to get the list of splits available.\n\n\t\t\n\t\tUsage (Huggingface Hub -- Recommended)â€¦ See the full description on the dataset page: https://huggingface.co/datasets/cis-lmu/GlotCC-V1.","url":"https://huggingface.co/datasets/cis-lmu/GlotCC-V1","creator_name":"CIS, LMU Munich","creator_url":"https://huggingface.co/cis-lmu","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["multilingual","Abau","Amarasi","Abkhaz","Abkhazian"],"keywords_longer_than_N":true},
	{"name":"GlotCC-V1","keyword":"egyptian arabic","description":"\n\t\n\t\t\n\t\tDataset Summary\n\t\n\n \n\nGlotCC-V1.0 is a document-level, general domain dataset derived from CommonCrawl, covering more than 1000 languages.It is built using the GlotLID language identification and Ungoliant pipeline from CommonCrawl.We release our pipeline as open-source at https://github.com/cisnlp/GlotCC.  \nList of Languages: See https://datasets-server.huggingface.co/splits?dataset=cis-lmu/GlotCC-V1 to get the list of splits available.\n\n\t\t\n\t\tUsage (Huggingface Hub -- Recommended)â€¦ See the full description on the dataset page: https://huggingface.co/datasets/cis-lmu/GlotCC-V1.","url":"https://huggingface.co/datasets/cis-lmu/GlotCC-V1","creator_name":"CIS, LMU Munich","creator_url":"https://huggingface.co/cis-lmu","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["multilingual","Abau","Amarasi","Abkhaz","Abkhazian"],"keywords_longer_than_N":true},
	{"name":"GlotCC-V1","keyword":"levantine arabic","description":"\n\t\n\t\t\n\t\tDataset Summary\n\t\n\n \n\nGlotCC-V1.0 is a document-level, general domain dataset derived from CommonCrawl, covering more than 1000 languages.It is built using the GlotLID language identification and Ungoliant pipeline from CommonCrawl.We release our pipeline as open-source at https://github.com/cisnlp/GlotCC.  \nList of Languages: See https://datasets-server.huggingface.co/splits?dataset=cis-lmu/GlotCC-V1 to get the list of splits available.\n\n\t\t\n\t\tUsage (Huggingface Hub -- Recommended)â€¦ See the full description on the dataset page: https://huggingface.co/datasets/cis-lmu/GlotCC-V1.","url":"https://huggingface.co/datasets/cis-lmu/GlotCC-V1","creator_name":"CIS, LMU Munich","creator_url":"https://huggingface.co/cis-lmu","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["multilingual","Abau","Amarasi","Abkhaz","Abkhazian"],"keywords_longer_than_N":true},
	{"name":"GlotCC-V1","keyword":"mesopotamian arabic","description":"\n\t\n\t\t\n\t\tDataset Summary\n\t\n\n \n\nGlotCC-V1.0 is a document-level, general domain dataset derived from CommonCrawl, covering more than 1000 languages.It is built using the GlotLID language identification and Ungoliant pipeline from CommonCrawl.We release our pipeline as open-source at https://github.com/cisnlp/GlotCC.  \nList of Languages: See https://datasets-server.huggingface.co/splits?dataset=cis-lmu/GlotCC-V1 to get the list of splits available.\n\n\t\t\n\t\tUsage (Huggingface Hub -- Recommended)â€¦ See the full description on the dataset page: https://huggingface.co/datasets/cis-lmu/GlotCC-V1.","url":"https://huggingface.co/datasets/cis-lmu/GlotCC-V1","creator_name":"CIS, LMU Munich","creator_url":"https://huggingface.co/cis-lmu","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["multilingual","Abau","Amarasi","Abkhaz","Abkhazian"],"keywords_longer_than_N":true},
	{"name":"GlotCC-V1","keyword":"moroccan arabic","description":"\n\t\n\t\t\n\t\tDataset Summary\n\t\n\n \n\nGlotCC-V1.0 is a document-level, general domain dataset derived from CommonCrawl, covering more than 1000 languages.It is built using the GlotLID language identification and Ungoliant pipeline from CommonCrawl.We release our pipeline as open-source at https://github.com/cisnlp/GlotCC.  \nList of Languages: See https://datasets-server.huggingface.co/splits?dataset=cis-lmu/GlotCC-V1 to get the list of splits available.\n\n\t\t\n\t\tUsage (Huggingface Hub -- Recommended)â€¦ See the full description on the dataset page: https://huggingface.co/datasets/cis-lmu/GlotCC-V1.","url":"https://huggingface.co/datasets/cis-lmu/GlotCC-V1","creator_name":"CIS, LMU Munich","creator_url":"https://huggingface.co/cis-lmu","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["multilingual","Abau","Amarasi","Abkhaz","Abkhazian"],"keywords_longer_than_N":true},
	{"name":"GlotCC-V1","keyword":"najdi arabic","description":"\n\t\n\t\t\n\t\tDataset Summary\n\t\n\n \n\nGlotCC-V1.0 is a document-level, general domain dataset derived from CommonCrawl, covering more than 1000 languages.It is built using the GlotLID language identification and Ungoliant pipeline from CommonCrawl.We release our pipeline as open-source at https://github.com/cisnlp/GlotCC.  \nList of Languages: See https://datasets-server.huggingface.co/splits?dataset=cis-lmu/GlotCC-V1 to get the list of splits available.\n\n\t\t\n\t\tUsage (Huggingface Hub -- Recommended)â€¦ See the full description on the dataset page: https://huggingface.co/datasets/cis-lmu/GlotCC-V1.","url":"https://huggingface.co/datasets/cis-lmu/GlotCC-V1","creator_name":"CIS, LMU Munich","creator_url":"https://huggingface.co/cis-lmu","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["multilingual","Abau","Amarasi","Abkhaz","Abkhazian"],"keywords_longer_than_N":true},
	{"name":"GlotCC-V1","keyword":"standard arabic","description":"\n\t\n\t\t\n\t\tDataset Summary\n\t\n\n \n\nGlotCC-V1.0 is a document-level, general domain dataset derived from CommonCrawl, covering more than 1000 languages.It is built using the GlotLID language identification and Ungoliant pipeline from CommonCrawl.We release our pipeline as open-source at https://github.com/cisnlp/GlotCC.  \nList of Languages: See https://datasets-server.huggingface.co/splits?dataset=cis-lmu/GlotCC-V1 to get the list of splits available.\n\n\t\t\n\t\tUsage (Huggingface Hub -- Recommended)â€¦ See the full description on the dataset page: https://huggingface.co/datasets/cis-lmu/GlotCC-V1.","url":"https://huggingface.co/datasets/cis-lmu/GlotCC-V1","creator_name":"CIS, LMU Munich","creator_url":"https://huggingface.co/cis-lmu","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["multilingual","Abau","Amarasi","Abkhaz","Abkhazian"],"keywords_longer_than_N":true},
	{"name":"GlotCC-V1","keyword":"tunisian arabic","description":"\n\t\n\t\t\n\t\tDataset Summary\n\t\n\n \n\nGlotCC-V1.0 is a document-level, general domain dataset derived from CommonCrawl, covering more than 1000 languages.It is built using the GlotLID language identification and Ungoliant pipeline from CommonCrawl.We release our pipeline as open-source at https://github.com/cisnlp/GlotCC.  \nList of Languages: See https://datasets-server.huggingface.co/splits?dataset=cis-lmu/GlotCC-V1 to get the list of splits available.\n\n\t\t\n\t\tUsage (Huggingface Hub -- Recommended)â€¦ See the full description on the dataset page: https://huggingface.co/datasets/cis-lmu/GlotCC-V1.","url":"https://huggingface.co/datasets/cis-lmu/GlotCC-V1","creator_name":"CIS, LMU Munich","creator_url":"https://huggingface.co/cis-lmu","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["multilingual","Abau","Amarasi","Abkhaz","Abkhazian"],"keywords_longer_than_N":true},
	{"name":"commonvoice-12.0-arabic-voice-converted","keyword":"arabic","description":"\n\t\n\t\t\n\t\tDataset Card for Voice Converted Arabic Common Voice 12.0\n\t\n\nThis dataset is derived from the Common Voice Arabic Corpus 12.0 and includes automatically diacritized transcriptions and phoneme representations for the original augmented audio data. The recordings feature Arabic text read aloud by users, where the text was initially undiacritized, allowing for potential reading errors. The diacritization and phonemes were generated automatically, resulting in a dataset that is valuableâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/xmodar/commonvoice-12.0-arabic-voice-converted.","url":"https://huggingface.co/datasets/xmodar/commonvoice-12.0-arabic-voice-converted","creator_name":"Modar M. Alfadly","creator_url":"https://huggingface.co/xmodar","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","Arabic","cc0-1.0","100K - 1M","parquet"],"keywords_longer_than_N":true},
	{"name":"darija-alpaca","keyword":"arabic","description":"ainz/darija-alpaca dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/ainz/darija-alpaca","creator_name":"mehdi","creator_url":"https://huggingface.co/ainz","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["table-question-answering","translation","Arabic","cc-by-4.0","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"darija-alpaca","keyword":"arabic","description":"ainz/darija-alpaca dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/ainz/darija-alpaca","creator_name":"mehdi","creator_url":"https://huggingface.co/ainz","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["table-question-answering","translation","Arabic","cc-by-4.0","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"Khudra_Chatbot","keyword":"arabic","description":"\n\t\n\t\t\n\t\tDubai Property AI Dataset\n\t\n\n\n\t\n\t\t\n\t\tDescription\n\t\n\nFine-tuning dataset for Dubai property management AI, covering:\n\nEmergency alerts (water leaks, AC failures)\nFinancial optimization\nDEWA/RERA compliance\nVendor dispatch protocols\n\n\n\t\n\t\t\n\t\tUsage\n\t\n\nfrom datasets import load_dataset\ndataset = load_dataset(\"your-username/dubai-property-ai\")\n\n","url":"https://huggingface.co/datasets/Muaaz007/Khudra_Chatbot","creator_name":"Muaaz Syed","creator_url":"https://huggingface.co/Muaaz007","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-generation","English","Arabic","mit","< 1K"],"keywords_longer_than_N":true},
	{"name":"Arabic-NLI-Pairs_multilingual-NLI-26lang-2mil7","keyword":"arabic","description":"\n\t\n\t\t\n\t\tDataset Card for Combined Arabic NLI Dataset\n\t\n\nThis dataset is a comprehensive collection of Arabic sentence pairs for Natural Language Inference (NLI), created by combining all five Arabic splits from the MoritzLaurer/multilingual-NLI-26lang-2mil7 dataset. It contains sentence pairs with entailment, neutral, and contradiction labels, making it a valuable general-purpose resource for Arabic NLP.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset merges fiveâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/SalDaMush/Arabic-NLI-Pairs_multilingual-NLI-26lang-2mil7.","url":"https://huggingface.co/datasets/SalDaMush/Arabic-NLI-Pairs_multilingual-NLI-26lang-2mil7","creator_name":"Salah Abdo","creator_url":"https://huggingface.co/SalDaMush","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","table-question-answering","sentence-similarity","Arabic","English"],"keywords_longer_than_N":true},
	{"name":"araspider","keyword":"arabic","description":"\n\t\n\t\t\n\t\tDataset Card for \"araspider\"\n\t\n\nMore Information needed\n","url":"https://huggingface.co/datasets/ahmedheakl/araspider","creator_name":"Ahmed Heakl","creator_url":"https://huggingface.co/ahmedheakl","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["Arabic","mit","1K - 10K","parquet","Text"],"keywords_longer_than_N":true},
	{"name":"FineWeb2-Moroccan-Arabic","keyword":"arabic","description":"\n\t\n\t\t\n\t\tFineWeb2 Moroccan Arabic\n\t\n\n\nðŸ‡²ðŸ‡¦ This is the Moroccan Arabic Portion of The FineWeb2 Dataset.\nðŸ‡²ðŸ‡¦ The Moroccan Arabic language, represented by the ISO 639-3 code ary, is a member of the Afro-Asiatic language family and utilizes the Arabic script. \nðŸ‡²ðŸ‡¦ Known within subsets as ary_Arab, this language boasts an extensive corpus of over 1.7 billion words across more than 6.1 million documents, collectively occupying a disk size of approximately 5.79 GB.\n\n\t\t\n\t\tPurpose of This Repositoryâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Omartificial-Intelligence-Space/FineWeb2-Moroccan-Arabic.","url":"https://huggingface.co/datasets/Omartificial-Intelligence-Space/FineWeb2-Moroccan-Arabic","creator_name":"Omartificial Intelligence Space","creator_url":"https://huggingface.co/Omartificial-Intelligence-Space","license_name":"Open Data Commons Attribution License v1.0","license_url":"https://scancode-licensedb.aboutcode.org/odc-by-1.0.html","language":"en","first_N":5,"first_N_keywords":["Arabic","odc-by","10M - 100M","parquet","Text"],"keywords_longer_than_N":true},
	{"name":"FineWeb2-Moroccan-Arabic","keyword":"arabic","description":"\n\t\n\t\t\n\t\tFineWeb2 Moroccan Arabic\n\t\n\n\nðŸ‡²ðŸ‡¦ This is the Moroccan Arabic Portion of The FineWeb2 Dataset.\nðŸ‡²ðŸ‡¦ The Moroccan Arabic language, represented by the ISO 639-3 code ary, is a member of the Afro-Asiatic language family and utilizes the Arabic script. \nðŸ‡²ðŸ‡¦ Known within subsets as ary_Arab, this language boasts an extensive corpus of over 1.7 billion words across more than 6.1 million documents, collectively occupying a disk size of approximately 5.79 GB.\n\n\t\t\n\t\tPurpose of This Repositoryâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Omartificial-Intelligence-Space/FineWeb2-Moroccan-Arabic.","url":"https://huggingface.co/datasets/Omartificial-Intelligence-Space/FineWeb2-Moroccan-Arabic","creator_name":"Omartificial Intelligence Space","creator_url":"https://huggingface.co/Omartificial-Intelligence-Space","license_name":"Open Data Commons Attribution License v1.0","license_url":"https://scancode-licensedb.aboutcode.org/odc-by-1.0.html","language":"en","first_N":5,"first_N_keywords":["Arabic","odc-by","10M - 100M","parquet","Text"],"keywords_longer_than_N":true},
	{"name":"FineWeb-Edu-Arabic","keyword":"arabic","description":"\n\t\n\t\t\n\t\tHigh Quality Arabic Corpus\n\t\n\nThis dataset contains a large collection of high-quality Arabic text data with their metadata.\n\n\t\n\t\t\n\t\tTo access the full data please visit Token Haven\n\t\n\n\n\t\n\t\t\n\t\tCreation\n\t\n\nThe dataset was created by filtering all English common crawl data for high-quality text using the FineWeb-Edu classifier with education score of 4 or higher over 5.\nThe data is source from the v1.0.0 of the HuggingFaceFW/fineweb-edu dataset which corresponds to CC-MAIN-2024-10 fromâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/TokenHaven/FineWeb-Edu-Arabic.","url":"https://huggingface.co/datasets/TokenHaven/FineWeb-Edu-Arabic","creator_name":"Token Haven","creator_url":"https://huggingface.co/TokenHaven","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","Arabic","apache-2.0","< 1K","json"],"keywords_longer_than_N":true},
	{"name":"fusion-synth-data-ufb","keyword":"arabic","description":"\n\t\n\t\t\n\t\tOffline Synthetic Data (UFB) for: Making, not taking, the Best-of-N\n\t\n\n\n\t\n\t\t\n\t\tContent\n\t\n\nThis data contains completions for a 10,000 subset of the  UFB prompts (translated into 9 languages)  from 5 different teacher models and 2 aggregations:\nTeachers: We sample one completion from each of the following models at temperature T=0.3. For kimik2, qwen3, and deepseek-v3 we use TogetherAI, for gemma3-27b and command-a we use locally hosted images.\n\ngemma3-27b: GEMMA3-27B-IT\nkimik2:â€¦ See the full description on the dataset page: https://huggingface.co/datasets/CohereLabs/fusion-synth-data-ufb.","url":"https://huggingface.co/datasets/CohereLabs/fusion-synth-data-ufb","creator_name":"Cohere Labs","creator_url":"https://huggingface.co/CohereLabs","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-generation","English","French","German","Spanish"],"keywords_longer_than_N":true},
	{"name":"nanobeir-multilingual","keyword":"arabic","description":"This multilingual collection is derived from the original English NanoBEIR datasets, which are smaller versions of BEIR datasets.\nThe compact size of these datasets makes them ideal for conducting quick and efficient evaluations during training.\nTo facilitate broader research in cross-lingual information retrieval, our dataset has been machine-translated from the original English\ninto eight additional languages: Arabic (ar), German (de), Spanish (es), French (fr), Italian (it), Norwegian (no)â€¦ See the full description on the dataset page: https://huggingface.co/datasets/lightonai/nanobeir-multilingual.","url":"https://huggingface.co/datasets/lightonai/nanobeir-multilingual","creator_name":"LightOn AI","creator_url":"https://huggingface.co/lightonai","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","French","Arabic","English","German"],"keywords_longer_than_N":true},
	{"name":"multilingual-terminology","keyword":"arabic","description":"\n\t\n\t\t\n\t\tðŸ“š GIST: Glossary of Multilingual AI Scientific Terminology\n\t\n\nPaper Title: Towards Global AI Inclusivity: A Large-Scale Multilingual Terminology Dataset (GIST)\nWebsite Demo Instructions: https://github.com/jiarui-liu/MultilingualAITerminology\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nGIST is a large-scale, high-quality multilingual AI terminology dataset developed to support global inclusivity in AI research. It consists of around 5,000 English AI-specific terms, each translated into Arabic, Chineseâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Jerry999/multilingual-terminology.","url":"https://huggingface.co/datasets/Jerry999/multilingual-terminology","creator_name":"Jiarui Liu","creator_url":"https://huggingface.co/Jerry999","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["English","Arabic","Chinese","French","Japanese"],"keywords_longer_than_N":true},
	{"name":"eg-legal-reasoning","keyword":"arabic","description":"\n\t\n\t\t\n\t\tArabic Legal Dataset - Legal Reasoning\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nLegal reasoning dataset following IRAC methodology with argumentation analysis and logical reasoning chains.\nThis dataset contains 1,046 examples of legal_reasoning data derived from Egyptian legal texts, including criminal law, civil law, procedural law, and personal status law. The dataset is designed for training and evaluating Arabic legal AI models.\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\n\nLanguage: Arabic (Egyptianâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fr3on/eg-legal-reasoning.","url":"https://huggingface.co/datasets/fr3on/eg-legal-reasoning","creator_name":"Ahmed Mardi","creator_url":"https://huggingface.co/fr3on","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","Arabic","apache-2.0","1K - 10K","parquet"],"keywords_longer_than_N":true},
	{"name":"eg-legal-reasoning","keyword":"arabic","description":"\n\t\n\t\t\n\t\tArabic Legal Dataset - Legal Reasoning\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nLegal reasoning dataset following IRAC methodology with argumentation analysis and logical reasoning chains.\nThis dataset contains 1,046 examples of legal_reasoning data derived from Egyptian legal texts, including criminal law, civil law, procedural law, and personal status law. The dataset is designed for training and evaluating Arabic legal AI models.\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\n\nLanguage: Arabic (Egyptianâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fr3on/eg-legal-reasoning.","url":"https://huggingface.co/datasets/fr3on/eg-legal-reasoning","creator_name":"Ahmed Mardi","creator_url":"https://huggingface.co/fr3on","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","Arabic","apache-2.0","1K - 10K","parquet"],"keywords_longer_than_N":true},
	{"name":"reasoning-multilingual-R1-Llama-70B-train","keyword":"arabic","description":"\n\t\n\t\t\n\t\tlightblue/reasoning-multilingual-R1-Llama-70B-train\n\t\n\nThis is a multilingual reasoning dataset covering more than 30 languages.\nThis dataset was made by:\n\nSampling prompts from English datasets and translating them to various languages\nGenerating responses to these prompts 8 times using deepseek-ai/DeepSeek-R1-Distill-Llama-70B\nFiltering out <think> sections with incorrect language, non-fluent language, and incorrect answers\n\nThis dataset was then used to train a multilingualâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/lightblue/reasoning-multilingual-R1-Llama-70B-train.","url":"https://huggingface.co/datasets/lightblue/reasoning-multilingual-R1-Llama-70B-train","creator_name":"Lightblue KK.","creator_url":"https://huggingface.co/lightblue","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["Amharic","Arabic","Bengali","Chinese","Czech"],"keywords_longer_than_N":true},
	{"name":"Arabic_LLaMA_Math_Dataset","keyword":"arabic","description":"\n\t\n\t\t\n\t\tArabic LLaMA Math Dataset\n\t\n\n\n\t\n\t\t\n\t\tExample Entries\n\t\n\n\n\n\t\n\t\t\n\t\tDataset Overview\n\t\n\n\nDataset Name: Arabic_LLaMA_Math_Dataset.csv\nNumber of Records: 12,496\nNumber of Columns: 3\nFile Format: CSV\n\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\n\t\n\t\t\n\t\tColumns:\n\t\n\n\nInstruction: The problem statement or question (text, in Arabic)\nInput: Additional input for model fine-tuning (empty in this dataset)\nSolution: The solution or answer to the problem (text, in Arabic)\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe Arabicâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Jr23xd23/Arabic_LLaMA_Math_Dataset.","url":"https://huggingface.co/datasets/Jr23xd23/Arabic_LLaMA_Math_Dataset","creator_name":"Jaber","creator_url":"https://huggingface.co/Jr23xd23","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["question-answering","Arabic","cc0-1.0","10K - 100K","csv"],"keywords_longer_than_N":true},
	{"name":"Arabic_LLaMA_Math_Dataset","keyword":"arabic","description":"\n\t\n\t\t\n\t\tArabic LLaMA Math Dataset\n\t\n\n\n\t\n\t\t\n\t\tExample Entries\n\t\n\n\n\n\t\n\t\t\n\t\tDataset Overview\n\t\n\n\nDataset Name: Arabic_LLaMA_Math_Dataset.csv\nNumber of Records: 12,496\nNumber of Columns: 3\nFile Format: CSV\n\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\n\t\n\t\t\n\t\tColumns:\n\t\n\n\nInstruction: The problem statement or question (text, in Arabic)\nInput: Additional input for model fine-tuning (empty in this dataset)\nSolution: The solution or answer to the problem (text, in Arabic)\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe Arabicâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Jr23xd23/Arabic_LLaMA_Math_Dataset.","url":"https://huggingface.co/datasets/Jr23xd23/Arabic_LLaMA_Math_Dataset","creator_name":"Jaber","creator_url":"https://huggingface.co/Jr23xd23","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["question-answering","Arabic","cc0-1.0","10K - 100K","csv"],"keywords_longer_than_N":true},
	{"name":"quran","keyword":"arabic","description":"\n\t\n\t\t\n\t\tDataset Card for the Quran\n\t\n\n\n\t\n\t\t\n\t\tSummary\n\t\n\nThe Quran with metadata, translations, and multiple Arabic text (can use specific types for embeddings, search, classification, and display). There are 126+ columns containing 43+ languages.\n\n\t\n\t\t\n\t\tTODO\n\t\n\n\n Add Tafsirs  \n Add topics/ontology\n\n\n\t\n\t\t\n\t\tUsage\n\t\n\nfrom datasets import load_dataset\n\nds = load_dataset(\"nazimali/quran\", split=\"train\")\nds\n\nOutput:\nDataset({\n    features: ['surah', 'ayah', 'surah-name', 'surah-total-ayas'â€¦ See the full description on the dataset page: https://huggingface.co/datasets/nazimali/quran.","url":"https://huggingface.co/datasets/nazimali/quran","creator_name":"Nazim Ali","creator_url":"https://huggingface.co/nazimali","license_name":"Creative Commons Attribution 3.0","license_url":"https://scancode-licensedb.aboutcode.org/cc-by-3.0.html","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","translation","feature-extraction","text-generation"],"keywords_longer_than_N":true},
	{"name":"eg-legal-comparative-law","keyword":"arabic","description":"\n\t\n\t\t\n\t\tArabic Legal Dataset - Comparative Legal Analysis\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nComparative law dataset for cross-jurisdictional legal analysis with legal family identification and international mappings.\nThis dataset contains 1,046 examples of comparative_law data derived from Egyptian legal texts, including criminal law, civil law, procedural law, and personal status law. The dataset is designed for training and evaluating Arabic legal AI models.\n\n\t\n\t\t\n\t\tDataset Summaryâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fr3on/eg-legal-comparative-law.","url":"https://huggingface.co/datasets/fr3on/eg-legal-comparative-law","creator_name":"Ahmed Mardi","creator_url":"https://huggingface.co/fr3on","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","Arabic","apache-2.0","1K - 10K","parquet"],"keywords_longer_than_N":true},
	{"name":"eg-legal-comparative-law","keyword":"arabic","description":"\n\t\n\t\t\n\t\tArabic Legal Dataset - Comparative Legal Analysis\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nComparative law dataset for cross-jurisdictional legal analysis with legal family identification and international mappings.\nThis dataset contains 1,046 examples of comparative_law data derived from Egyptian legal texts, including criminal law, civil law, procedural law, and personal status law. The dataset is designed for training and evaluating Arabic legal AI models.\n\n\t\n\t\t\n\t\tDataset Summaryâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fr3on/eg-legal-comparative-law.","url":"https://huggingface.co/datasets/fr3on/eg-legal-comparative-law","creator_name":"Ahmed Mardi","creator_url":"https://huggingface.co/fr3on","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","Arabic","apache-2.0","1K - 10K","parquet"],"keywords_longer_than_N":true},
	{"name":"semeval-2025-task11-track-a","keyword":"arabic","description":"\n\t\n\t\t\n\t\tSemEval 2025 Task 11 - Track A Dataset\n\t\n\nThis dataset contains the data for SemEval 2025 Task 11: Bridging the Gap in Text-Based Emotion Detection - Track A, organized as language-specific configurations.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset is a multi-language, multi-label emotion classification dataset with separate configurations for each language.\n\nTotal languages: 26 standard ISO codes\nTotal examples: 115159\nSplits: train, dev, test\n\n\n\t\n\t\t\n\t\tLanguage Configurations\n\t\n\nEachâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/vgaraujov/semeval-2025-task11-track-a.","url":"https://huggingface.co/datasets/vgaraujov/semeval-2025-task11-track-a","creator_name":"Vladimir Araujo","creator_url":"https://huggingface.co/vgaraujov","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["Afrikaans","Amharic","Arabic","German","English"],"keywords_longer_than_N":true},
	{"name":"fadel-diacritization","keyword":"arabic","description":"adapted from: https://arxiv.org/abs/1905.01965\n","url":"https://huggingface.co/datasets/Bisher/fadel-diacritization","creator_name":"Mohamad Bisher tello","creator_url":"https://huggingface.co/Bisher","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","text-generation","Arabic","mit","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"fleurs_clean","keyword":"arabic","description":"\n\t\n\t\t\n\t\n\t\n\t\tFLEURS\n\t\n\nFleurs is the speech version of the FLoRes machine translation benchmark. \nWe use 2009 n-way parallel sentences from the FLoRes dev and devtest publicly available sets, in 102 languages. \nTraining sets have around 10 hours of supervision. Speakers of the train sets are different than speakers from the dev/test sets. Multilingual fine-tuning is\nused and â€unit error rateâ€ (characters, signs) of all languages is averaged. Languages and results are also grouped into sevenâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Helloworld668/fleurs_clean.","url":"https://huggingface.co/datasets/Helloworld668/fleurs_clean","creator_name":"zhide Tang","creator_url":"https://huggingface.co/Helloworld668","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","expert-generated","crowdsourced","machine-generated","crowdsourced"],"keywords_longer_than_N":true},
	{"name":"BRIGHTER-emotion-intensities","keyword":"arabic","description":"\n\t\n\t\t\n\t\tBRIGHTER Emotion Intensities Dataset\n\t\n\nThis dataset contains the emotion intensities data from the BRIGHTER paper: BRIdging the Gap in Human-Annotated Textual Emotion Recognition Datasets for 28 Languages.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe BRIGHTER Emotion Intensities dataset is a comprehensive multi-language emotion intensity dataset with separate configurations for each language. It represents one of the largest human-annotated emotion datasets across multiple languages, providingâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/brighter-dataset/BRIGHTER-emotion-intensities.","url":"https://huggingface.co/datasets/brighter-dataset/BRIGHTER-emotion-intensities","creator_name":"BRIGHTER Dataset","creator_url":"https://huggingface.co/brighter-dataset","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["Arabic","German","English","Spanish","Hausa"],"keywords_longer_than_N":true},
	{"name":"Web-multilingual","keyword":"arabic","description":"\n\t\n\t\t\n\t\tDataset Card for Dataset Name\n\t\n\nThis dataset contains 1,141 multilingual web pages.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\n Each page contains the visible text extracted from the page. Each page includes 2 or more languages, with 2 prominent languages. \n page.csv lists the 2 prominent for each page. The content of the page is found in the pages/ folder.\n The breakdown of languages is the following:\n   1705 en\n   1043 fr\n    336 zh\n     90 es\n     79 id\n     77 de\n     75 pt\n     40 it\n     34â€¦ See the full description on the dataset page: https://huggingface.co/datasets/MAximeSobrier/Web-multilingual.","url":"https://huggingface.co/datasets/MAximeSobrier/Web-multilingual","creator_name":"Maxime Sobrier","creator_url":"https://huggingface.co/MAximeSobrier","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","French","English","Chinese","Portuguese"],"keywords_longer_than_N":true},
	{"name":"aya_dataset","keyword":"egyptian arabic","description":"\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThe Aya Dataset is a multilingual instruction fine-tuning dataset curated by an open-science community via Aya Annotation Platform from Cohere Labs. The dataset contains a total of 204k human-annotated prompt-completion pairs along with the demographics data of the annotators.\nThis dataset can be used to train, finetune, and evaluate multilingual LLMs.\n\nCurated by: Contributors of Aya Open Science Intiative.\n\nLanguage(s): 65 languages (71 including dialects &â€¦ See the full description on the dataset page: https://huggingface.co/datasets/CohereLabs/aya_dataset.","url":"https://huggingface.co/datasets/CohereLabs/aya_dataset","creator_name":"Cohere Labs","creator_url":"https://huggingface.co/CohereLabs","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["other","crowdsourced","expert-generated","crowdsourced","expert-generated"],"keywords_longer_than_N":true},
	{"name":"aya_dataset","keyword":"levantine arabic","description":"\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThe Aya Dataset is a multilingual instruction fine-tuning dataset curated by an open-science community via Aya Annotation Platform from Cohere Labs. The dataset contains a total of 204k human-annotated prompt-completion pairs along with the demographics data of the annotators.\nThis dataset can be used to train, finetune, and evaluate multilingual LLMs.\n\nCurated by: Contributors of Aya Open Science Intiative.\n\nLanguage(s): 65 languages (71 including dialects &â€¦ See the full description on the dataset page: https://huggingface.co/datasets/CohereLabs/aya_dataset.","url":"https://huggingface.co/datasets/CohereLabs/aya_dataset","creator_name":"Cohere Labs","creator_url":"https://huggingface.co/CohereLabs","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["other","crowdsourced","expert-generated","crowdsourced","expert-generated"],"keywords_longer_than_N":true},
	{"name":"aya_dataset","keyword":"moroccan arabic","description":"\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThe Aya Dataset is a multilingual instruction fine-tuning dataset curated by an open-science community via Aya Annotation Platform from Cohere Labs. The dataset contains a total of 204k human-annotated prompt-completion pairs along with the demographics data of the annotators.\nThis dataset can be used to train, finetune, and evaluate multilingual LLMs.\n\nCurated by: Contributors of Aya Open Science Intiative.\n\nLanguage(s): 65 languages (71 including dialects &â€¦ See the full description on the dataset page: https://huggingface.co/datasets/CohereLabs/aya_dataset.","url":"https://huggingface.co/datasets/CohereLabs/aya_dataset","creator_name":"Cohere Labs","creator_url":"https://huggingface.co/CohereLabs","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["other","crowdsourced","expert-generated","crowdsourced","expert-generated"],"keywords_longer_than_N":true},
	{"name":"aya_dataset","keyword":"najdi arabic","description":"\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThe Aya Dataset is a multilingual instruction fine-tuning dataset curated by an open-science community via Aya Annotation Platform from Cohere Labs. The dataset contains a total of 204k human-annotated prompt-completion pairs along with the demographics data of the annotators.\nThis dataset can be used to train, finetune, and evaluate multilingual LLMs.\n\nCurated by: Contributors of Aya Open Science Intiative.\n\nLanguage(s): 65 languages (71 including dialects &â€¦ See the full description on the dataset page: https://huggingface.co/datasets/CohereLabs/aya_dataset.","url":"https://huggingface.co/datasets/CohereLabs/aya_dataset","creator_name":"Cohere Labs","creator_url":"https://huggingface.co/CohereLabs","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["other","crowdsourced","expert-generated","crowdsourced","expert-generated"],"keywords_longer_than_N":true},
	{"name":"aya_dataset","keyword":"standard arabic","description":"\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThe Aya Dataset is a multilingual instruction fine-tuning dataset curated by an open-science community via Aya Annotation Platform from Cohere Labs. The dataset contains a total of 204k human-annotated prompt-completion pairs along with the demographics data of the annotators.\nThis dataset can be used to train, finetune, and evaluate multilingual LLMs.\n\nCurated by: Contributors of Aya Open Science Intiative.\n\nLanguage(s): 65 languages (71 including dialects &â€¦ See the full description on the dataset page: https://huggingface.co/datasets/CohereLabs/aya_dataset.","url":"https://huggingface.co/datasets/CohereLabs/aya_dataset","creator_name":"Cohere Labs","creator_url":"https://huggingface.co/CohereLabs","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["other","crowdsourced","expert-generated","crowdsourced","expert-generated"],"keywords_longer_than_N":true},
	{"name":"aya_dataset","keyword":"ta'izzi-adeni arabic","description":"\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThe Aya Dataset is a multilingual instruction fine-tuning dataset curated by an open-science community via Aya Annotation Platform from Cohere Labs. The dataset contains a total of 204k human-annotated prompt-completion pairs along with the demographics data of the annotators.\nThis dataset can be used to train, finetune, and evaluate multilingual LLMs.\n\nCurated by: Contributors of Aya Open Science Intiative.\n\nLanguage(s): 65 languages (71 including dialects &â€¦ See the full description on the dataset page: https://huggingface.co/datasets/CohereLabs/aya_dataset.","url":"https://huggingface.co/datasets/CohereLabs/aya_dataset","creator_name":"Cohere Labs","creator_url":"https://huggingface.co/CohereLabs","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["other","crowdsourced","expert-generated","crowdsourced","expert-generated"],"keywords_longer_than_N":true},
	{"name":"multimuc4","keyword":"arabic","description":"jgermanmx/multimuc4 dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/jgermanmx/multimuc4","creator_name":"Jesus German Ortiz Barajas","creator_url":"https://huggingface.co/jgermanmx","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","Arabic","English","Persian","Korean"],"keywords_longer_than_N":true},
	{"name":"multiblimp","keyword":"standard arabic","description":"\n\t\n\t\t\n\t\tMultiBLiMP\n\t\n\nMultiBLiMP is a massively Multilingual Benchmark for Linguistic Minimal Pairs. The dataset is composed of synthetic pairs generated using Universal Dependencies and UniMorph.\nThe paper can be found here.\nWe split the data set by language: each language consists of a single .tsv file. The rows contain many attributes for a particular pair, most important are the sen and wrong_sen fields, which we use for evaluating the language models.\n\n\t\n\t\t\n\t\n\t\n\t\tUsing MultiBLiMP\n\t\n\nToâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/jumelet/multiblimp.","url":"https://huggingface.co/datasets/jumelet/multiblimp","creator_name":"Jaap Jumelet","creator_url":"https://huggingface.co/jumelet","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["multilingual","Buriat","Spanish","Sanskrit","Romanian"],"keywords_longer_than_N":true},
	{"name":"Isnad-AI-Identifying-Islamic-Citation","keyword":"arabic","description":"\n\t\n\t\t\n\t\tIsnad AI: AraBERT for Ayah & Hadith Span Detection in LLM Outputs\n\t\n\n\n\n\n\nThis repository contains the official fine-tuned model for the Isnad AI system, the submission to the IslamicEval 2025 Shared Task 1A. The model is designed to identify character-level spans of Quranic verses (Ayahs) and Prophetic sayings (Hadiths) within text generated by Large Language Models (LLMs).\n\n\t\n\t\t\n\t\n\t\n\t\tBy: Fatimah Emad Eldin\n\t\n\n\n\t\n\t\t\n\t\n\t\n\t\tCairo University\n\t\n\n\n\n\n\n\n\t\n\t\t\n\t\tðŸ“œ Model Description\n\t\n\nThisâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/FatimahEmadEldin/Isnad-AI-Identifying-Islamic-Citation.","url":"https://huggingface.co/datasets/FatimahEmadEldin/Isnad-AI-Identifying-Islamic-Citation","creator_name":"Fatimah Emad Eldin","creator_url":"https://huggingface.co/FatimahEmadEldin","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["Arabic","apache-2.0","100K - 1M","csv","Tabular"],"keywords_longer_than_N":true},
	{"name":"PTCC","keyword":"arabic","description":"The Parallel Tunisian Constitution Corpus (PTCC) corpus is a corpus of 149 articles written in Modern Standard Arabic and Tunisian Arabic.\nTesseract was used to transform the constitution's pdf files into text files. Afterward, alignment of the parallel articles was achieved by a simple Python script.\nMore details can be found in: https://amr-keleg.github.io/projects/digitalizing_dialectal_arabic/\n\n\t\n\t\t\n\t\n\t\n\t\tSources:\n\t\n\n\nTunisian Arabic translation of the 2014 Tunisian Constitution\n2014â€¦ See the full description on the dataset page: https://huggingface.co/datasets/AMR-KELEG/PTCC.","url":"https://huggingface.co/datasets/AMR-KELEG/PTCC","creator_name":"Amr Keleg","creator_url":"https://huggingface.co/AMR-KELEG","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-generation","Arabic","mit","< 1K","csv"],"keywords_longer_than_N":true},
	{"name":"oscar-mini","keyword":"arabic","description":"The Open Super-large Crawled ALMAnaCH coRpus is a huge multilingual corpus obtained by language classification and filtering of the Common Crawl corpus using the goclassy architecture.\\","url":"https://huggingface.co/datasets/nthngdy/oscar-mini","creator_name":"Nathan Godey","creator_url":"https://huggingface.co/nthngdy","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":null,"first_N":5,"first_N_keywords":["text-generation","language-modeling","no-annotation","found","multilingual"],"keywords_longer_than_N":true},
	{"name":"bnl_newspapers","keyword":"arabic","description":"\n\t\n\t\t\n\t\tDataset Card for BnL Historical Newspapers\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThe BnL has digitised over 800.000 pages of Luxembourg newspapers. This dataset currently has one configuration covering a subset of these newspapers, which sit under the \"Processed Datasets\" collection. The BNL:\n\nprocessed all newspapers and monographs that are in the public domain and extracted the full text and associated meta data of every single article, section, advertisementâ€¦ The result is a large number ofâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/bnl-data/bnl_newspapers.","url":"https://huggingface.co/datasets/bnl-data/bnl_newspapers","creator_name":"BnL Open Data","creator_url":"https://huggingface.co/bnl-data","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","fill-mask","language-modeling","masked-language-modeling","no-annotation"],"keywords_longer_than_N":true},
	{"name":"WikidataLabels","keyword":"arabic","description":"\n\t\n\t\t\n\t\tWikidata Labels\n\t\n\nLarge parallel corpus for machine translation\n\nEntity label data extracted from Wikidata (2022-01-03), filtered for item entities only  \nOnly download the languages you need with datasets>=2.14.0\nSimilar dataset: https://huggingface.co/datasets/wmt/wikititles (18 Wikipedia titles pairs instead of all Wikidata entities)\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Sources\n\t\n\n\nWikidata JSON dump (wikidata-20220103-all.json.gz)â€¦ See the full description on the dataset page: https://huggingface.co/datasets/rayliuca/WikidataLabels.","url":"https://huggingface.co/datasets/rayliuca/WikidataLabels","creator_name":"Ray Liu","creator_url":"https://huggingface.co/rayliuca","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["translation","English","French","German","Japanese"],"keywords_longer_than_N":true},
	{"name":"oscar-mini","keyword":"egyptian arabic","description":"The Open Super-large Crawled ALMAnaCH coRpus is a huge multilingual corpus obtained by language classification and filtering of the Common Crawl corpus using the goclassy architecture.\\","url":"https://huggingface.co/datasets/nthngdy/oscar-mini","creator_name":"Nathan Godey","creator_url":"https://huggingface.co/nthngdy","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":null,"first_N":5,"first_N_keywords":["text-generation","language-modeling","no-annotation","found","multilingual"],"keywords_longer_than_N":true},
	{"name":"language_tags","keyword":"arabic","description":"\n\t\n\t\t\n\t\tDescription\n\t\n\nDataset listing 27,328 languages and dialects (also includes macrolanguage names).For each language, either the ISO 639 code, the Glottolog code or both are provided.\n\n\t\n\t\t\n\t\tColumns\n\t\n\n\nEnglish_Name: Language name in English (e.g. \"French\").\nNative_Name: If value is not 0, corresponds to the name of the language by native speakers (e.g. \"FranÃ§ais\") which may have been found in Wikipedia's nativename field.\nGlottocode: The language tag in the Glottolog convention (e.g.â€¦ See the full description on the dataset page: https://huggingface.co/datasets/lbourdois/language_tags.","url":"https://huggingface.co/datasets/lbourdois/language_tags","creator_name":"LoÃ¯ck BOURDOIS","creator_url":"https://huggingface.co/lbourdois","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["Afade","ParÃ¡ ArÃ¡ra","Afar","Aka-Bea","Abon"],"keywords_longer_than_N":true},
	{"name":"language_tags","keyword":"egyptian arabic","description":"\n\t\n\t\t\n\t\tDescription\n\t\n\nDataset listing 27,328 languages and dialects (also includes macrolanguage names).For each language, either the ISO 639 code, the Glottolog code or both are provided.\n\n\t\n\t\t\n\t\tColumns\n\t\n\n\nEnglish_Name: Language name in English (e.g. \"French\").\nNative_Name: If value is not 0, corresponds to the name of the language by native speakers (e.g. \"FranÃ§ais\") which may have been found in Wikipedia's nativename field.\nGlottocode: The language tag in the Glottolog convention (e.g.â€¦ See the full description on the dataset page: https://huggingface.co/datasets/lbourdois/language_tags.","url":"https://huggingface.co/datasets/lbourdois/language_tags","creator_name":"LoÃ¯ck BOURDOIS","creator_url":"https://huggingface.co/lbourdois","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["Afade","ParÃ¡ ArÃ¡ra","Afar","Aka-Bea","Abon"],"keywords_longer_than_N":true},
	{"name":"language_tags","keyword":"levantine arabic","description":"\n\t\n\t\t\n\t\tDescription\n\t\n\nDataset listing 27,328 languages and dialects (also includes macrolanguage names).For each language, either the ISO 639 code, the Glottolog code or both are provided.\n\n\t\n\t\t\n\t\tColumns\n\t\n\n\nEnglish_Name: Language name in English (e.g. \"French\").\nNative_Name: If value is not 0, corresponds to the name of the language by native speakers (e.g. \"FranÃ§ais\") which may have been found in Wikipedia's nativename field.\nGlottocode: The language tag in the Glottolog convention (e.g.â€¦ See the full description on the dataset page: https://huggingface.co/datasets/lbourdois/language_tags.","url":"https://huggingface.co/datasets/lbourdois/language_tags","creator_name":"LoÃ¯ck BOURDOIS","creator_url":"https://huggingface.co/lbourdois","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["Afade","ParÃ¡ ArÃ¡ra","Afar","Aka-Bea","Abon"],"keywords_longer_than_N":true},
	{"name":"language_tags","keyword":"moroccan arabic","description":"\n\t\n\t\t\n\t\tDescription\n\t\n\nDataset listing 27,328 languages and dialects (also includes macrolanguage names).For each language, either the ISO 639 code, the Glottolog code or both are provided.\n\n\t\n\t\t\n\t\tColumns\n\t\n\n\nEnglish_Name: Language name in English (e.g. \"French\").\nNative_Name: If value is not 0, corresponds to the name of the language by native speakers (e.g. \"FranÃ§ais\") which may have been found in Wikipedia's nativename field.\nGlottocode: The language tag in the Glottolog convention (e.g.â€¦ See the full description on the dataset page: https://huggingface.co/datasets/lbourdois/language_tags.","url":"https://huggingface.co/datasets/lbourdois/language_tags","creator_name":"LoÃ¯ck BOURDOIS","creator_url":"https://huggingface.co/lbourdois","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["Afade","ParÃ¡ ArÃ¡ra","Afar","Aka-Bea","Abon"],"keywords_longer_than_N":true},
	{"name":"language_tags","keyword":"najdi arabic","description":"\n\t\n\t\t\n\t\tDescription\n\t\n\nDataset listing 27,328 languages and dialects (also includes macrolanguage names).For each language, either the ISO 639 code, the Glottolog code or both are provided.\n\n\t\n\t\t\n\t\tColumns\n\t\n\n\nEnglish_Name: Language name in English (e.g. \"French\").\nNative_Name: If value is not 0, corresponds to the name of the language by native speakers (e.g. \"FranÃ§ais\") which may have been found in Wikipedia's nativename field.\nGlottocode: The language tag in the Glottolog convention (e.g.â€¦ See the full description on the dataset page: https://huggingface.co/datasets/lbourdois/language_tags.","url":"https://huggingface.co/datasets/lbourdois/language_tags","creator_name":"LoÃ¯ck BOURDOIS","creator_url":"https://huggingface.co/lbourdois","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["Afade","ParÃ¡ ArÃ¡ra","Afar","Aka-Bea","Abon"],"keywords_longer_than_N":true},
	{"name":"language_tags","keyword":"standard arabic","description":"\n\t\n\t\t\n\t\tDescription\n\t\n\nDataset listing 27,328 languages and dialects (also includes macrolanguage names).For each language, either the ISO 639 code, the Glottolog code or both are provided.\n\n\t\n\t\t\n\t\tColumns\n\t\n\n\nEnglish_Name: Language name in English (e.g. \"French\").\nNative_Name: If value is not 0, corresponds to the name of the language by native speakers (e.g. \"FranÃ§ais\") which may have been found in Wikipedia's nativename field.\nGlottocode: The language tag in the Glottolog convention (e.g.â€¦ See the full description on the dataset page: https://huggingface.co/datasets/lbourdois/language_tags.","url":"https://huggingface.co/datasets/lbourdois/language_tags","creator_name":"LoÃ¯ck BOURDOIS","creator_url":"https://huggingface.co/lbourdois","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["Afade","ParÃ¡ ArÃ¡ra","Afar","Aka-Bea","Abon"],"keywords_longer_than_N":true},
	{"name":"language_tags","keyword":"tunisian arabic","description":"\n\t\n\t\t\n\t\tDescription\n\t\n\nDataset listing 27,328 languages and dialects (also includes macrolanguage names).For each language, either the ISO 639 code, the Glottolog code or both are provided.\n\n\t\n\t\t\n\t\tColumns\n\t\n\n\nEnglish_Name: Language name in English (e.g. \"French\").\nNative_Name: If value is not 0, corresponds to the name of the language by native speakers (e.g. \"FranÃ§ais\") which may have been found in Wikipedia's nativename field.\nGlottocode: The language tag in the Glottolog convention (e.g.â€¦ See the full description on the dataset page: https://huggingface.co/datasets/lbourdois/language_tags.","url":"https://huggingface.co/datasets/lbourdois/language_tags","creator_name":"LoÃ¯ck BOURDOIS","creator_url":"https://huggingface.co/lbourdois","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["Afade","ParÃ¡ ArÃ¡ra","Afar","Aka-Bea","Abon"],"keywords_longer_than_N":true},
	{"name":"language_tags","keyword":"ta'izzi-adeni arabic","description":"\n\t\n\t\t\n\t\tDescription\n\t\n\nDataset listing 27,328 languages and dialects (also includes macrolanguage names).For each language, either the ISO 639 code, the Glottolog code or both are provided.\n\n\t\n\t\t\n\t\tColumns\n\t\n\n\nEnglish_Name: Language name in English (e.g. \"French\").\nNative_Name: If value is not 0, corresponds to the name of the language by native speakers (e.g. \"FranÃ§ais\") which may have been found in Wikipedia's nativename field.\nGlottocode: The language tag in the Glottolog convention (e.g.â€¦ See the full description on the dataset page: https://huggingface.co/datasets/lbourdois/language_tags.","url":"https://huggingface.co/datasets/lbourdois/language_tags","creator_name":"LoÃ¯ck BOURDOIS","creator_url":"https://huggingface.co/lbourdois","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["Afade","ParÃ¡ ArÃ¡ra","Afar","Aka-Bea","Abon"],"keywords_longer_than_N":true},
	{"name":"language_tags","keyword":"mesopotamian arabic","description":"\n\t\n\t\t\n\t\tDescription\n\t\n\nDataset listing 27,328 languages and dialects (also includes macrolanguage names).For each language, either the ISO 639 code, the Glottolog code or both are provided.\n\n\t\n\t\t\n\t\tColumns\n\t\n\n\nEnglish_Name: Language name in English (e.g. \"French\").\nNative_Name: If value is not 0, corresponds to the name of the language by native speakers (e.g. \"FranÃ§ais\") which may have been found in Wikipedia's nativename field.\nGlottocode: The language tag in the Glottolog convention (e.g.â€¦ See the full description on the dataset page: https://huggingface.co/datasets/lbourdois/language_tags.","url":"https://huggingface.co/datasets/lbourdois/language_tags","creator_name":"LoÃ¯ck BOURDOIS","creator_url":"https://huggingface.co/lbourdois","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["Afade","ParÃ¡ ArÃ¡ra","Afar","Aka-Bea","Abon"],"keywords_longer_than_N":true},
	{"name":"sl-dataset","keyword":"arabic","description":"\n\t\n\t\t\n\t\tDataset Card for Dataset Name\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset card aims to be a base template for new datasets. It has been generated using this raw template.\n\n\t\n\t\t\n\t\tSupported Tasks and Leaderboards\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tLanguages\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\n\t\n\t\t\n\t\tData Instances\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tData Fields\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tData Splits\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tDataset Creationâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/lafnac/sl-dataset.","url":"https://huggingface.co/datasets/lafnac/sl-dataset","creator_name":"lafnac","creator_url":"https://huggingface.co/lafnac","license_name":"Academic Free License v3.0","license_url":"https://choosealicense.com/licenses/afl-3.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","Arabic","afl-3.0","< 1K","imagefolder"],"keywords_longer_than_N":true},
	{"name":"fleurs","keyword":"arabic","description":"\n\t\n\t\t\n\t\tFLEURS\n\t\n\nFleurs is the speech version of the FLoRes machine translation benchmark. \nWe use 2009 n-way parallel sentences from the FLoRes dev and devtest publicly available sets, in 102 languages. \nTraining sets have around 10 hours of supervision. Speakers of the train sets are different than speakers from the dev/test sets. Multilingual fine-tuning is\nused and â€unit error rateâ€ (characters, signs) of all languages is averaged. Languages and results are also grouped into sevenâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/cahya/fleurs.","url":"https://huggingface.co/datasets/cahya/fleurs","creator_name":"Cahya Wirawan","creator_url":"https://huggingface.co/cahya","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":null,"first_N":5,"first_N_keywords":["automatic-speech-recognition","expert-generated","crowdsourced","machine-generated","crowdsourced"],"keywords_longer_than_N":true},
	{"name":"all-scam-spam","keyword":"arabic","description":"This is a large corpus of 42,619 preprocessed text messages and emails sent by humans in 43 languages. is_spam=1 means spam and is_spam=0 means ham.\n1040 rows of balanced data, consisting of casual conversations and scam emails in â‰ˆ10 languages, were manually collected and annotated by me, with some help from ChatGPT.\n\n\n\n\t\n\t\t\n\t\tSome preprcoessing algorithms\n\t\n\n\nspam_assassin.js, followed by spam_assassin.py\nenron_spam.py\n\n\n\n\n\t\n\t\t\n\t\tData composition\n\t\n\n\n\n\n\n\t\n\t\t\n\t\tDescription\n\t\n\nTo make the textâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/FredZhang7/all-scam-spam.","url":"https://huggingface.co/datasets/FredZhang7/all-scam-spam","creator_name":"Fred Zhang","creator_url":"https://huggingface.co/FredZhang7","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","zero-shot-classification","Norwegian","Spanish","Somali"],"keywords_longer_than_N":true},
	{"name":"oasst2_top1_chat_format","keyword":"arabic","description":"\n\t\n\t\t\n\t\tOpenAssistant TOP-1 Conversation Threads in huggingface chat format\n\t\n\nExport of oasst2 only top 1 threads in huggingface chat format\n\n\t\n\t\t\n\t\tScript\n\t\n\nThe convert script can be find here\n","url":"https://huggingface.co/datasets/blancsw/oasst2_top1_chat_format","creator_name":"Blanc Swan","creator_url":"https://huggingface.co/blancsw","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["English","Spanish","Russian","German","Polish"],"keywords_longer_than_N":true},
	{"name":"MaWPS-ar-addCN","keyword":"arabic","description":"\n\t\n\t\t\n\t\tDataset Card for MAWPS_ar\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nMAWPS: A Math Word Problem Repository\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nMath Word Problem Solving\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nSupports Arabic and English\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\n\t\n\t\t\n\t\tData Fields\n\t\n\n\ntext_en: a string feature.\ntext_ar: a string feature.\neqn: a string feature.\n\n\n\t\n\t\t\n\t\tData Splits\n\t\n\n\n\t\n\t\t\ntrain\nvalidation\ntest\n\n\n\t\t\n3636\n1040\n520\n\n\n\t\n\n\n\t\n\t\t\n\t\tDataset Creation\n\t\n\n\n\t\n\t\t\n\t\tCuration Rationaleâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/aelneima/MaWPS-ar-addCN.","url":"https://huggingface.co/datasets/aelneima/MaWPS-ar-addCN","creator_name":"ashraf hatim","creator_url":"https://huggingface.co/aelneima","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["explanation-generation","crowdsourced","found","multilingual","English"],"keywords_longer_than_N":true},
	{"name":"JinaVDRArabicInfographicsVQARetrieval","keyword":"arabic","description":"\n  JinaVDRArabicInfographicsVQARetrieval\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nRetrieve Arabic infographics based on queries.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2i\n\n\nDomains\nAcademic\n\n\nReference\nhttps://huggingface.co/datasets/jinaai/arabic_infographicsvqa_ar_beir\n\n\n\t\n\nSource datasets:\n\njinaai/arabic_infographicsvqa_ar_beir\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask =â€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/JinaVDRArabicInfographicsVQARetrieval.","url":"https://huggingface.co/datasets/mteb/JinaVDRArabicInfographicsVQARetrieval","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["visual-document-retrieval","image-to-text","text-to-image","derived","monolingual"],"keywords_longer_than_N":true},
	{"name":"mittens","keyword":"arabic","description":"\n\t\n\t\t\n\t\tMiTTenS: A Dataset for Evaluating Misgendering in Translation\n\t\n\nMisgendering is the act of referring to someone in a way that does not reflect their gender identity.  Translation systems, including foundation models capable of translation, can produce errors that result in misgendering harms. To measure the extent of such potential harms when translating into and out of English, we introduce a dataset, MiTTenS, covering 26 languages from a variety of language families and scriptsâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/google/mittens.","url":"https://huggingface.co/datasets/google/mittens","creator_name":"Google","creator_url":"https://huggingface.co/google","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["translation","Arabic","Finnish","Oromo","Ganda"],"keywords_longer_than_N":true},
	{"name":"JinaVDRArabicChartQARetrieval","keyword":"arabic","description":"\n  JinaVDRArabicChartQARetrieval\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nRetrieve Arabic charts based on queries.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2i\n\n\nDomains\nAcademic\n\n\nReference\nhttps://huggingface.co/datasets/jinaai/arabic_chartqa_ar_beir\n\n\n\t\n\nSource datasets:\n\njinaai/arabic_chartqa_ar_beir\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask = mteb.get_task(\"JinaVDRArabicChartQARetrieval\")â€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/JinaVDRArabicChartQARetrieval.","url":"https://huggingface.co/datasets/mteb/JinaVDRArabicChartQARetrieval","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["visual-document-retrieval","image-to-text","text-to-image","derived","monolingual"],"keywords_longer_than_N":true},
	{"name":"tydiqa-ar","keyword":"arabic","description":"\n\t\n\t\t\n\t\tDataset Card for \"tydiqa-ar\"\n\t\n\nMore Information needed\n","url":"https://huggingface.co/datasets/asas-ai/tydiqa-ar","creator_name":"ASAS AI","creator_url":"https://huggingface.co/asas-ai","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["question-answering","Arabic","apache-2.0","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"ar_sarcasm","keyword":"arabic","description":"\n\t\n\t\t\n\t\tDataset Card for ArSarcasm\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nArSarcasm is a new Arabic sarcasm detection dataset.\nThe dataset was created using previously available Arabic sentiment analysis\ndatasets (SemEval 2017\nand ASTD) and adds sarcasm and\ndialect labels to them.\nThe dataset contains 10,547 tweets, 1,682 (16%) of which are sarcastic.\nFor more details, please check the paper\nFrom Arabic Sentiment Analysis to Sarcasm Detection: The ArSarcasm Dataset\n\n\t\n\t\t\n\t\n\t\n\t\tSupported Tasks andâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/iabufarha/ar_sarcasm.","url":"https://huggingface.co/datasets/iabufarha/ar_sarcasm","creator_name":"Ibrahim","creator_url":"https://huggingface.co/iabufarha","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","sentiment-classification","no-annotation","found","monolingual"],"keywords_longer_than_N":true},
	{"name":"tatoeba","keyword":"arabic","description":"This is a collection of translated sentences from Tatoeba\n359 languages, 3,403 bitexts\ntotal number of files: 750\ntotal number of tokens: 65.54M\ntotal number of sentence fragments: 8.96M","url":"https://huggingface.co/datasets/Helsinki-NLP/tatoeba","creator_name":"Language Technology Research Group at the University of Helsinki","creator_url":"https://huggingface.co/Helsinki-NLP","license_name":"Creative Commons Attribution 2.0","license_url":"https://scancode-licensedb.aboutcode.org/cc-by-2.0.html","language":null,"first_N":5,"first_N_keywords":["translation","found","found","multilingual","original"],"keywords_longer_than_N":true},
	{"name":"xcsr","keyword":"arabic","description":"\n\t\n\t\t\n\t\tDataset Card for X-CSR\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nTo evaluate multi-lingual language models (ML-LMs) for commonsense reasoning in a cross-lingual zero-shot transfer setting (X-CSR), i.e., training in English and test in other languages, we create two benchmark datasets, namely X-CSQA and X-CODAH. Specifically, we automatically translate the original CSQA and CODAH datasets, which only have English versions, to 15 other languages, forming development and test sets for studying X-CSR.â€¦ See the full description on the dataset page: https://huggingface.co/datasets/INK-USC/xcsr.","url":"https://huggingface.co/datasets/INK-USC/xcsr","creator_name":"INK Lab @ USC","creator_url":"https://huggingface.co/INK-USC","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["question-answering","multiple-choice-qa","crowdsourced","crowdsourced","machine-generated"],"keywords_longer_than_N":true},
	{"name":"tatoeba","keyword":"egyptian arabic","description":"This is a collection of translated sentences from Tatoeba\n359 languages, 3,403 bitexts\ntotal number of files: 750\ntotal number of tokens: 65.54M\ntotal number of sentence fragments: 8.96M","url":"https://huggingface.co/datasets/Helsinki-NLP/tatoeba","creator_name":"Language Technology Research Group at the University of Helsinki","creator_url":"https://huggingface.co/Helsinki-NLP","license_name":"Creative Commons Attribution 2.0","license_url":"https://scancode-licensedb.aboutcode.org/cc-by-2.0.html","language":null,"first_N":5,"first_N_keywords":["translation","found","found","multilingual","original"],"keywords_longer_than_N":true},
	{"name":"tatoeba","keyword":"levantine arabic","description":"This is a collection of translated sentences from Tatoeba\n359 languages, 3,403 bitexts\ntotal number of files: 750\ntotal number of tokens: 65.54M\ntotal number of sentence fragments: 8.96M","url":"https://huggingface.co/datasets/Helsinki-NLP/tatoeba","creator_name":"Language Technology Research Group at the University of Helsinki","creator_url":"https://huggingface.co/Helsinki-NLP","license_name":"Creative Commons Attribution 2.0","license_url":"https://scancode-licensedb.aboutcode.org/cc-by-2.0.html","language":null,"first_N":5,"first_N_keywords":["translation","found","found","multilingual","original"],"keywords_longer_than_N":true},
	{"name":"tatoeba","keyword":"mesopotamian arabic","description":"This is a collection of translated sentences from Tatoeba\n359 languages, 3,403 bitexts\ntotal number of files: 750\ntotal number of tokens: 65.54M\ntotal number of sentence fragments: 8.96M","url":"https://huggingface.co/datasets/Helsinki-NLP/tatoeba","creator_name":"Language Technology Research Group at the University of Helsinki","creator_url":"https://huggingface.co/Helsinki-NLP","license_name":"Creative Commons Attribution 2.0","license_url":"https://scancode-licensedb.aboutcode.org/cc-by-2.0.html","language":null,"first_N":5,"first_N_keywords":["translation","found","found","multilingual","original"],"keywords_longer_than_N":true},
	{"name":"tatoeba","keyword":"moroccan arabic","description":"This is a collection of translated sentences from Tatoeba\n359 languages, 3,403 bitexts\ntotal number of files: 750\ntotal number of tokens: 65.54M\ntotal number of sentence fragments: 8.96M","url":"https://huggingface.co/datasets/Helsinki-NLP/tatoeba","creator_name":"Language Technology Research Group at the University of Helsinki","creator_url":"https://huggingface.co/Helsinki-NLP","license_name":"Creative Commons Attribution 2.0","license_url":"https://scancode-licensedb.aboutcode.org/cc-by-2.0.html","language":null,"first_N":5,"first_N_keywords":["translation","found","found","multilingual","original"],"keywords_longer_than_N":true},
	{"name":"ms_terms","keyword":"arabic","description":"The Microsoft Terminology Collection can be used to develop localized versions of applications that integrate with Microsoft products.\nIt can also be used to integrate Microsoft terminology into other terminology collections or serve as a base IT glossary\nfor language development in the nearly 100 languages available. Terminology is provided in .tbx format, an industry standard for terminology exchange.","url":"https://huggingface.co/datasets/microsoft/ms_terms","creator_name":"Microsoft","creator_url":"https://huggingface.co/microsoft","license_name":"Microsoft Public License","license_url":"https://choosealicense.com/licenses/ms-pl/","language":null,"first_N":5,"first_N_keywords":["translation","expert-generated","expert-generated","multilingual","translation"],"keywords_longer_than_N":true},
	{"name":"arabic_xvector_embeddings","keyword":"arabic","description":"\n\t\n\t\t\n\t\tArabic Speaker Embeddings extracted from ASC and ClArTTS\n\t\n\nThere is one speaker embedding for each utterance in the validation set of both datasets. The speaker embeddings are 512-element X-vectors.\nArabic Speech Corpus has 100 files for a single male speaker and ClArTTS has 205 files for a single male speaker.\nThe X-vectors were extracted using this script, which uses the speechbrain/spkrec-xvect-voxceleb model.\nUsage:\nfrom datasets import load_dataset\n\nembeddings_dataset =â€¦ See the full description on the dataset page: https://huggingface.co/datasets/herwoww/arabic_xvector_embeddings.","url":"https://huggingface.co/datasets/herwoww/arabic_xvector_embeddings","creator_name":"Hawau Olamide Toyin","creator_url":"https://huggingface.co/herwoww","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-to-speech","audio-to-audio","Arabic","mit","< 1K"],"keywords_longer_than_N":true},
	{"name":"answerable_tydiqa","keyword":"arabic","description":"\n\t\n\t\t\n\t\tDataset Card for \"answerable-tydiqa\"\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nTyDi QA is a question answering dataset covering 11 typologically diverse languages. \nAnswerable TyDi QA is an extension of the GoldP subtask of the original TyDi QA dataset to also include unanswertable questions.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nThe dataset contains a train and a validation set, with 116067 and 13325 examples, respectively. Access them with\nfrom datasets import load_dataset\ndataset =â€¦ See the full description on the dataset page: https://huggingface.co/datasets/copenlu/answerable_tydiqa.","url":"https://huggingface.co/datasets/copenlu/answerable_tydiqa","creator_name":"CopeNLU","creator_url":"https://huggingface.co/copenlu","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["question-answering","extractive-qa","crowdsourced","crowdsourced","multilingual"],"keywords_longer_than_N":true},
	{"name":"tydiqa-ar-primary_task","keyword":"arabic","description":"asas-ai/tydiqa-ar-primary_task dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/asas-ai/tydiqa-ar-primary_task","creator_name":"ASAS AI","creator_url":"https://huggingface.co/asas-ai","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["question-answering","Arabic","apache-2.0","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"QA_Arabic","keyword":"arabic","description":"\n\t\n\t\t\n\t\tJSON File Description\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis JSON file contains a collection of questions and answers in Arabic. Each question is associated with its corresponding answer. The file is structured in a way that allows easy retrieval and utilization of the question-answer pairs.\n\n\t\n\t\t\n\t\tFile Structure\n\t\n\nThe JSON file follows the following structure:\n{\n  \"questions\": [\n    {\n      \"question\": \"Ù…Ù† Ù‡Ùˆ Ø£ÙˆÙ„ Ù…Ù† Ù†Ø²Ù„ Ø¹Ù„Ù‰ Ø³Ø·Ø­ Ø§Ù„Ù‚Ù…Ø±ØŸ\",\n      \"answer\": \"Ù†ÙŠÙ„ Ø£Ù…Ø³ØªØ±ÙˆÙ†Ø¬\"\n    },\n    {â€¦ See the full description on the dataset page: https://huggingface.co/datasets/HeshamHaroon/QA_Arabic.","url":"https://huggingface.co/datasets/HeshamHaroon/QA_Arabic","creator_name":"Hesham Haroon","creator_url":"https://huggingface.co/HeshamHaroon","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["question-answering","text-generation","Arabic","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"common_voice_17_0","keyword":"arabic","description":"\n\t\n\t\t\n\t\tDataset Card for Common Voice Corpus 17.0\n\t\n\n\n\nThis dataset is an unofficial version of the Mozilla Common Voice Corpus 17. It was downloaded and converted from the project's website https://commonvoice.mozilla.org/.\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nAbkhaz, Albanian, Amharic, Arabic, Armenian, Assamese, Asturian, Azerbaijani, Basaa, Bashkir, Basque, Belarusian, Bengali, Breton, Bulgarian, Cantonese, Catalan, Central Kurdish, Chinese (China), Chinese (Hong Kong), Chinese (Taiwan), Chuvash, Czechâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fsicoli/common_voice_17_0.","url":"https://huggingface.co/datasets/fsicoli/common_voice_17_0","creator_name":"Fabio Sicoli","creator_url":"https://huggingface.co/fsicoli","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":null,"first_N":5,"first_N_keywords":["automatic-speech-recognition","Abkhaz","Afrikaans","Amharic","Arabic"],"keywords_longer_than_N":true},
	{"name":"xP3","keyword":"arabic","description":"xP3 (Crosslingual Public Pool of Prompts) is a collection of prompts & datasets across 46 of languages & 16 NLP tasks. It is used for the training of BLOOMZ and mT0, multilingual language models capable of following human instructions in dozens of languages zero-shot.","url":"https://huggingface.co/datasets/bigscience/xP3","creator_name":"BigScience Workshop","creator_url":"https://huggingface.co/bigscience","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":null,"first_N":5,"first_N_keywords":["other","expert-generated","crowdsourced","multilingual","Akan"],"keywords_longer_than_N":true},
	{"name":"tulu-3-sft-olmo-2-mixture","keyword":"egyptian arabic","description":"Note that this collection is licensed under ODC-BY-1.0 license; different licenses apply to subsets of the data. Some portions of the dataset are non-commercial. We present the mixture as a research artifact.\nThe OLMo v2 SFT mixture was used to train the OLMo models.\nIt contains 939,344 samples from the following sets:\n\nCoCoNot (ODC-BY-1.0), 10,983 prompts (Brahman et al., 2024)\nFLAN v2 via ai2-adapt-dev/flan_v2_converted, 89,982 prompts (Longpre et al., 2023)\nNo Robots (CC-BY-NC-4.0), 9,500â€¦ See the full description on the dataset page: https://huggingface.co/datasets/allenai/tulu-3-sft-olmo-2-mixture.","url":"https://huggingface.co/datasets/allenai/tulu-3-sft-olmo-2-mixture","creator_name":"Ai2","creator_url":"https://huggingface.co/allenai","license_name":"Open Data Commons Attribution License v1.0","license_url":"https://scancode-licensedb.aboutcode.org/odc-by-1.0.html","language":"en","first_N":5,"first_N_keywords":["other","crowdsourced","expert-generated","machine-generated","multilingual"],"keywords_longer_than_N":true},
	{"name":"tulu-3-sft-olmo-2-mixture","keyword":"levantine arabic","description":"Note that this collection is licensed under ODC-BY-1.0 license; different licenses apply to subsets of the data. Some portions of the dataset are non-commercial. We present the mixture as a research artifact.\nThe OLMo v2 SFT mixture was used to train the OLMo models.\nIt contains 939,344 samples from the following sets:\n\nCoCoNot (ODC-BY-1.0), 10,983 prompts (Brahman et al., 2024)\nFLAN v2 via ai2-adapt-dev/flan_v2_converted, 89,982 prompts (Longpre et al., 2023)\nNo Robots (CC-BY-NC-4.0), 9,500â€¦ See the full description on the dataset page: https://huggingface.co/datasets/allenai/tulu-3-sft-olmo-2-mixture.","url":"https://huggingface.co/datasets/allenai/tulu-3-sft-olmo-2-mixture","creator_name":"Ai2","creator_url":"https://huggingface.co/allenai","license_name":"Open Data Commons Attribution License v1.0","license_url":"https://scancode-licensedb.aboutcode.org/odc-by-1.0.html","language":"en","first_N":5,"first_N_keywords":["other","crowdsourced","expert-generated","machine-generated","multilingual"],"keywords_longer_than_N":true},
	{"name":"tulu-3-sft-olmo-2-mixture","keyword":"moroccan arabic","description":"Note that this collection is licensed under ODC-BY-1.0 license; different licenses apply to subsets of the data. Some portions of the dataset are non-commercial. We present the mixture as a research artifact.\nThe OLMo v2 SFT mixture was used to train the OLMo models.\nIt contains 939,344 samples from the following sets:\n\nCoCoNot (ODC-BY-1.0), 10,983 prompts (Brahman et al., 2024)\nFLAN v2 via ai2-adapt-dev/flan_v2_converted, 89,982 prompts (Longpre et al., 2023)\nNo Robots (CC-BY-NC-4.0), 9,500â€¦ See the full description on the dataset page: https://huggingface.co/datasets/allenai/tulu-3-sft-olmo-2-mixture.","url":"https://huggingface.co/datasets/allenai/tulu-3-sft-olmo-2-mixture","creator_name":"Ai2","creator_url":"https://huggingface.co/allenai","license_name":"Open Data Commons Attribution License v1.0","license_url":"https://scancode-licensedb.aboutcode.org/odc-by-1.0.html","language":"en","first_N":5,"first_N_keywords":["other","crowdsourced","expert-generated","machine-generated","multilingual"],"keywords_longer_than_N":true},
	{"name":"tulu-3-sft-olmo-2-mixture","keyword":"najdi arabic","description":"Note that this collection is licensed under ODC-BY-1.0 license; different licenses apply to subsets of the data. Some portions of the dataset are non-commercial. We present the mixture as a research artifact.\nThe OLMo v2 SFT mixture was used to train the OLMo models.\nIt contains 939,344 samples from the following sets:\n\nCoCoNot (ODC-BY-1.0), 10,983 prompts (Brahman et al., 2024)\nFLAN v2 via ai2-adapt-dev/flan_v2_converted, 89,982 prompts (Longpre et al., 2023)\nNo Robots (CC-BY-NC-4.0), 9,500â€¦ See the full description on the dataset page: https://huggingface.co/datasets/allenai/tulu-3-sft-olmo-2-mixture.","url":"https://huggingface.co/datasets/allenai/tulu-3-sft-olmo-2-mixture","creator_name":"Ai2","creator_url":"https://huggingface.co/allenai","license_name":"Open Data Commons Attribution License v1.0","license_url":"https://scancode-licensedb.aboutcode.org/odc-by-1.0.html","language":"en","first_N":5,"first_N_keywords":["other","crowdsourced","expert-generated","machine-generated","multilingual"],"keywords_longer_than_N":true},
	{"name":"tulu-3-sft-olmo-2-mixture","keyword":"standard arabic","description":"Note that this collection is licensed under ODC-BY-1.0 license; different licenses apply to subsets of the data. Some portions of the dataset are non-commercial. We present the mixture as a research artifact.\nThe OLMo v2 SFT mixture was used to train the OLMo models.\nIt contains 939,344 samples from the following sets:\n\nCoCoNot (ODC-BY-1.0), 10,983 prompts (Brahman et al., 2024)\nFLAN v2 via ai2-adapt-dev/flan_v2_converted, 89,982 prompts (Longpre et al., 2023)\nNo Robots (CC-BY-NC-4.0), 9,500â€¦ See the full description on the dataset page: https://huggingface.co/datasets/allenai/tulu-3-sft-olmo-2-mixture.","url":"https://huggingface.co/datasets/allenai/tulu-3-sft-olmo-2-mixture","creator_name":"Ai2","creator_url":"https://huggingface.co/allenai","license_name":"Open Data Commons Attribution License v1.0","license_url":"https://scancode-licensedb.aboutcode.org/odc-by-1.0.html","language":"en","first_N":5,"first_N_keywords":["other","crowdsourced","expert-generated","machine-generated","multilingual"],"keywords_longer_than_N":true},
	{"name":"tulu-3-sft-olmo-2-mixture","keyword":"ta'izzi-adeni arabic","description":"Note that this collection is licensed under ODC-BY-1.0 license; different licenses apply to subsets of the data. Some portions of the dataset are non-commercial. We present the mixture as a research artifact.\nThe OLMo v2 SFT mixture was used to train the OLMo models.\nIt contains 939,344 samples from the following sets:\n\nCoCoNot (ODC-BY-1.0), 10,983 prompts (Brahman et al., 2024)\nFLAN v2 via ai2-adapt-dev/flan_v2_converted, 89,982 prompts (Longpre et al., 2023)\nNo Robots (CC-BY-NC-4.0), 9,500â€¦ See the full description on the dataset page: https://huggingface.co/datasets/allenai/tulu-3-sft-olmo-2-mixture.","url":"https://huggingface.co/datasets/allenai/tulu-3-sft-olmo-2-mixture","creator_name":"Ai2","creator_url":"https://huggingface.co/allenai","license_name":"Open Data Commons Attribution License v1.0","license_url":"https://scancode-licensedb.aboutcode.org/odc-by-1.0.html","language":"en","first_N":5,"first_N_keywords":["other","crowdsourced","expert-generated","machine-generated","multilingual"],"keywords_longer_than_N":true},
	{"name":"ACVA-Arabic-Cultural-Value-Alignment","keyword":"arabic","description":"\n\t\n\t\t\n\t\tAbout ArabicCulture\n\t\n\nThe ArabicCulture dataset was generated by gpt3.5 and contains 8000+ True and False questions.The dataset contains questions from 58 different areas.In the answers, \"True\" accounted for 59.62%, and \"False\" accounted for 40.38%\n\n\t\n\t\t\n\t\tdata-all\n\t\n\nIt contains 8000+ data, and we took 5 data from each area as few-shot data.\n\n\t\n\t\t\n\t\tdata-select\n\t\n\nWe asked two Arabs to judge 4000 of all the data for us, and we left data that two Arabs both thought were good. Finallyâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/FreedomIntelligence/ACVA-Arabic-Cultural-Value-Alignment.","url":"https://huggingface.co/datasets/FreedomIntelligence/ACVA-Arabic-Cultural-Value-Alignment","creator_name":"FreedomAI","creator_url":"https://huggingface.co/FreedomIntelligence","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["Arabic","apache-2.0","1K - 10K","json","Text"],"keywords_longer_than_N":true},
	{"name":"entity_cs","keyword":"arabic","description":"\n\t\n\t\t\n\t\tDataset Card for EntityCS\n\t\n\n\nRepository: https://github.com/huawei-noah/noah-research/tree/master/NLP/EntityCS  \nPaper: https://aclanthology.org/2022.findings-emnlp.499.pdf  \nPoint of Contact: Fenia Christopoulou, Chenxi Whitehouse\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Description\n\t\n\nWe use the English Wikipedia and leverage entity information from Wikidata to construct an entity-based Code Switching corpus. \nTo achieve this, we make use of wikilinks in Wikipedia, i.e. links from one page to another.â€¦ See the full description on the dataset page: https://huggingface.co/datasets/huawei-noah/entity_cs.","url":"https://huggingface.co/datasets/huawei-noah/entity_cs","creator_name":"HUAWEI Noah's Ark Lab","creator_url":"https://huggingface.co/huawei-noah","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["Afrikaans","Amharic","Arabic","Assamese","Azerbaijani"],"keywords_longer_than_N":true},
	{"name":"tydiqa-primary","keyword":"arabic","description":"TyDi QA is a question answering dataset covering 11 typologically diverse languages with 204K question-answer pairs.\nThe languages of TyDi QA are diverse with regard to their typology -- the set of linguistic features that each language\nexpresses -- such that we expect models performing well on this set to generalize across a large number of the languages\nin the world. It contains language phenomena that would not be found in English-only corpora. To provide a realistic\ninformation-seeking task and avoid priming effects, questions are written by people who want to know the answer, but\ndonâ€™t know the answer yet, (unlike SQuAD and its descendents) and the data is collected directly in each language without\nthe use of translation (unlike MLQA and XQuAD).","url":"https://huggingface.co/datasets/khalidalt/tydiqa-primary","creator_name":"Khalid Almubarak","creator_url":"https://huggingface.co/khalidalt","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":null,"first_N":5,"first_N_keywords":["question-answering","extractive-qa","crowdsourced","crowdsourced","multilingual"],"keywords_longer_than_N":true},
	{"name":"wiki_lingua","keyword":"arabic","description":"\n\t\n\t\t\n\t\tDataset Card for \"wiki_lingua\"\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nWe introduce WikiLingua, a large-scale, multilingual dataset for the evaluation of cross-lingual abstractive summarization systems. We extract article and summary pairs in 18 languages from WikiHow, a high quality, collaborative resource of how-to guides on a diverse set of topics written by human authors. We create gold-standard article-summary alignments across languages by aligning the images that are used to describe eachâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/esdurmus/wiki_lingua.","url":"https://huggingface.co/datasets/esdurmus/wiki_lingua","creator_name":"Esin Durmus","creator_url":"https://huggingface.co/esdurmus","license_name":"Creative Commons Attribution 3.0","license_url":"https://scancode-licensedb.aboutcode.org/cc-by-3.0.html","language":"en","first_N":5,"first_N_keywords":["summarization","crowdsourced","crowdsourced","multilingual","original"],"keywords_longer_than_N":true},
	{"name":"common_language","keyword":"arabic","description":"This dataset is composed of speech recordings from languages that were carefully selected from the CommonVoice database.\nThe total duration of audio recordings is 45.1 hours (i.e., 1 hour of material for each language).\nThe dataset has been extracted from CommonVoice to train language-id systems.","url":"https://huggingface.co/datasets/speechbrain/common_language","creator_name":"SpeechBrain","creator_url":"https://huggingface.co/speechbrain","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":null,"first_N":5,"first_N_keywords":["audio-classification","speaker-identification","crowdsourced","crowdsourced","multilingual"],"keywords_longer_than_N":true},
	{"name":"xor_tydi_qa","keyword":"arabic","description":"    XOR-TyDi QA brings together for the first time information-seeking questions,\n    open-retrieval QA, and multilingual QA to create a multilingual open-retrieval\n    QA dataset that enables cross-lingual answer retrieval. It consists of questions\n    written by information-seeking native speakers in 7 typologically diverse languages\n    and answer annotations that are retrieved from multilingual document collections.\n    There are three sub-tasks: XOR-Retrieve, XOR-EnglishSpan, and XOR-Full.","url":"https://huggingface.co/datasets/akariasai/xor_tydi_qa","creator_name":"Akari Asai","creator_url":"https://huggingface.co/akariasai","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":null,"first_N":5,"first_N_keywords":["question-answering","open-domain-qa","crowdsourced","expert-generated","found"],"keywords_longer_than_N":true},
	{"name":"MediaSpeech","keyword":"arabic","description":"\n\t\n\t\t\n\t\tMediaSpeech\n\t\n\nMediaSpeech is a dataset of Arabic, French, Spanish, and Turkish media speech built with the purpose of testing Automated Speech Recognition (ASR) systems performance. The dataset contains 10 hours of speech for each language provided.\nThe dataset consists of short speech segments automatically extracted from media videos available on YouTube and manually transcribed, with some pre-processing and post-processing.\nBaseline models and WAV version of the dataset can beâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/ymoslem/MediaSpeech.","url":"https://huggingface.co/datasets/ymoslem/MediaSpeech","creator_name":"Yasmin Moslem","creator_url":"https://huggingface.co/ymoslem","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","Arabic","French","Spanish"],"keywords_longer_than_N":true},
	{"name":"MASD","keyword":"arabic","description":"\n\t\n\t\t\n\t\tDataset Card for \"Masked Arab States Dataset (MASD)\"\n\t\n\nThis dataset is created using 20 Arab States1 with their corresponding capital cities, nationalities, currencies, and on which continents they are located, consisting of four categories: country-capital\nprompts, country-currency prompts, country-nationality prompts, and country-continent prompts. Each prompts category has 40 masked prompts, and the total number of masked prompts in the MASD dataset is 160. This dataset is used toâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/SaiedAlshahrani/MASD.","url":"https://huggingface.co/datasets/SaiedAlshahrani/MASD","creator_name":"Saied Alshahrani","creator_url":"https://huggingface.co/SaiedAlshahrani","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["Arabic","mit","< 1K","csv","Text"],"keywords_longer_than_N":true},
	{"name":"arabic_alpaca_model","keyword":"arabic","description":"ISTNetworks/arabic_alpaca_model dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/ISTNetworks/arabic_alpaca_model","creator_name":"RAD team","creator_url":"https://huggingface.co/ISTNetworks","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["question-answering","Arabic","apache-2.0","1K - 10K","json"],"keywords_longer_than_N":true},
	{"name":"spoken-arabic-digits","keyword":"arabic","description":"\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset contains spoken Arabic digits from 40 speakers from multiple Arab communities and local dialects. It is augmented using various techniques to increase the size of the dataset and improve its diversity. The recordings went through a number of pre-processors to evaluate and process the sound quality using Audacity app.\n\n\t\n\t\t\n\t\tDataset Creation\n\t\n\nThe dataset was created by collecting recordings of the digits 0-9 from 40 speakers from different Arab communitiesâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/mohnasgbr/spoken-arabic-digits.","url":"https://huggingface.co/datasets/mohnasgbr/spoken-arabic-digits","creator_name":"Mohammed Nasser Gaber","creator_url":"https://huggingface.co/mohnasgbr","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["Arabic","apache-2.0","< 1K","soundfolder","Audio"],"keywords_longer_than_N":true},
	{"name":"openassistant-falcon","keyword":"arabic","description":"\n\t\n\t\t\n\t\tChat Fine-tuning Dataset - OpenAssistant Falcon\n\t\n\nThis dataset allows for fine-tuning chat models using '\\Human:' AND '\\nAssistant:' to wrap user messages.\nIt still uses <|endoftext|> as EOS and BOS token, as per Falcon.\nSample \nPreparation:\n\nThe dataset is cloned from TimDettmers, which itself is a subset of the Open Assistant dataset, which you can find here. This subset of the data only contains the highest-rated paths in the conversation tree, with a total of 9,846 samples.\nTheâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Trelis/openassistant-falcon.","url":"https://huggingface.co/datasets/Trelis/openassistant-falcon","creator_name":"Trelis","creator_url":"https://huggingface.co/Trelis","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["English","Spanish","Russian","German","Polish"],"keywords_longer_than_N":true},
	{"name":"oasst1","keyword":"arabic","description":"\n\t\n\t\t\n\t\tOpenAssistant Conversations Dataset (OASST1)\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nIn an effort to democratize research on large-scale alignment, we release OpenAssistant \nConversations (OASST1), a human-generated, human-annotated assistant-style conversation \ncorpus consisting of 161,443 messages in 35 different languages, annotated with 461,292 \nquality ratings, resulting in over 10,000 fully annotated conversation trees. The corpus \nis a product of a worldwide crowd-sourcing effortâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/OpenAssistant/oasst1.","url":"https://huggingface.co/datasets/OpenAssistant/oasst1","creator_name":"OpenAssistant","creator_url":"https://huggingface.co/OpenAssistant","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["English","Spanish","Russian","German","Polish"],"keywords_longer_than_N":true},
	{"name":"ministries","keyword":"arabic","description":"{\"id\": \"130042945016-0\", \"text\": \"\\u0648\\u0635\\u0641 \\u0627\\u0644\\u062e\\u062f\\u0645\\u0629: \\u062a\\u0645\\u0643\\u0651\\u0650\\u0646 \\u0647\\u0630\\u0647 \\u0627\\u0644\\u062e\\u062f\\u0645\\u0629 \\u0627\\u0644\\u0639\\u0645\\u064a\\u0644 \\u0645\\u0646 \\u062a\\u0642\\u062f\\u064a\\u0645 \\u062c\\u0645\\u064a\\u0639 \\u0637\\u0644\\u0628\\u0627\\u062a \\u0639\\u0642\\u0648\\u062f \\u062a\\u0623\\u0633\\u064a\\u0633 \\u0627\\u0644\\u0634\\u0631\\u0643\\u0627\\u062a \\u062d\\u0633\\u0628 \\u0627\\u0644\\u0643\\u064a\\u0627\\u0646 :  \\nâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/faranheit/ministries.","url":"https://huggingface.co/datasets/faranheit/ministries","creator_name":"Muhammad Faran","creator_url":"https://huggingface.co/faranheit","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["question-answering","Arabic","apache-2.0","< 1K","json"],"keywords_longer_than_N":true},
	{"name":"Quran-Tafseers","keyword":"arabic","description":"\n\t\n\t\t\n\t\tModel Details\n\t\n\nDeveloped by: Prince Sultan University - Riotu Lab\nThis dataset is intended for use in natural language processing tasks, particularly for understanding classical Arabic and religious texts, including text analysis, language modeling, and thematic studies.\nPrimary Users: Researchers and developers in the field of natural language processing, religious studies, and AI, specifically those working with classical Arabic texts.\nOut-of-scope Use Cases: This dataset is notâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/riotu-lab/Quran-Tafseers.","url":"https://huggingface.co/datasets/riotu-lab/Quran-Tafseers","creator_name":"Robotics and Interne-of-Things","creator_url":"https://huggingface.co/riotu-lab","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["question-answering","Arabic","apache-2.0","10K - 100K","json"],"keywords_longer_than_N":true},
	{"name":"tydiqa-ar-secondary_task","keyword":"arabic","description":"\n\t\n\t\t\n\t\tDataset Card for \"tydiqa-ar-secondary_task\"\n\t\n\nMore Information needed\n","url":"https://huggingface.co/datasets/asas-ai/tydiqa-ar-secondary_task","creator_name":"ASAS AI","creator_url":"https://huggingface.co/asas-ai","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["question-answering","Arabic","apache-2.0","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"qa_en_translation","keyword":"arabic","description":"\n\t\n\t\t\n\t\tDataset Card for Dataset Name\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset card aims to be a base template for new datasets. It has been generated using this raw template.\n\n\t\n\t\t\n\t\tSupported Tasks and Leaderboards\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tLanguages\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\n\t\n\t\t\n\t\tData Instances\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tData Fields\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tData Splits\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tDataset Creationâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Sylvana/qa_en_translation.","url":"https://huggingface.co/datasets/Sylvana/qa_en_translation","creator_name":"Silvana","creator_url":"https://huggingface.co/Sylvana","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["translation","Arabic","apache-2.0","1K - 10K","csv"],"keywords_longer_than_N":true},
	{"name":"Egyptian_People_Speaking_Video_Dataset","keyword":"arabic","description":"\n\t\n\t\t\n\t\tEgyptian People Speaking Video Dataset\n\t\n\nThis dataset contains high-quality video recordings of Egyptian people speaking on a range of topics. It is curated for AI research in speech recognition, multimodal analysis, topic understanding, and spoken-language modeling.\n\n\t\n\t\t\n\t\tContact\n\t\n\nFor queries or collaborations related to this dataset, contact:  \n\nanoushka@kgen.io  \nabhishek.vadapalli@kgen.io\n\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\n\nTask Categories:  \n\nVideo Classification  \nSpeech-to-Textâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Kratos-AI/Egyptian_People_Speaking_Video_Dataset.","url":"https://huggingface.co/datasets/Kratos-AI/Egyptian_People_Speaking_Video_Dataset","creator_name":"KratosAI","creator_url":"https://huggingface.co/Kratos-AI","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["video-classification","Arabic","English","cc-by-4.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"FineWeb2-HQ","keyword":"arabic","description":"\n\t\n\t\t\n\t\tFineWeb2-HQ\n\t\n\n\n\t\n\t\t\n\t\tDataset summary\n\t\n\nFineWeb2-HQ is a high-quality, model-filtered pretraining dataset derived as a subset of FineWeb2, spanning 20 languages. It enables around 6x faster pretraining compared to the base dataset. FineWeb2-HQ was created by selecting the top 10% quality documents of FineWeb2 in each language, based on scores assigned by a deep learning classifier trained to identify structured and knowledge-rich samples using XLM-RoBERTa embeddings.\n\n  \n\n\nValidationâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/epfml/FineWeb2-HQ.","url":"https://huggingface.co/datasets/epfml/FineWeb2-HQ","creator_name":"EPFL Machine Learning and Optimization Laboratory","creator_url":"https://huggingface.co/epfml","license_name":"Open Data Commons Attribution License v1.0","license_url":"https://scancode-licensedb.aboutcode.org/odc-by-1.0.html","language":"en","first_N":5,"first_N_keywords":["text-generation","Russian","Chinese","German","Japanese"],"keywords_longer_than_N":true},
	{"name":"mr-tydi-corpus","keyword":"arabic","description":"\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nMr. TyDi is a multi-lingual benchmark dataset built on TyDi, covering eleven typologically diverse languages. It is designed for monolingual retrieval, specifically to evaluate ranking with learned dense representations.\nThis dataset stores documents of Mr. TyDi. To access the queries and judgments, please refer to castorini/mr-tydi.\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Structure\n\t\n\nThe only configuration here is the language. As all three folds (train, dev and test) share the sameâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/castorini/mr-tydi-corpus.","url":"https://huggingface.co/datasets/castorini/mr-tydi-corpus","creator_name":"Castorini","creator_url":"https://huggingface.co/castorini","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","multilingual","Arabic","Bengali","English"],"keywords_longer_than_N":true},
	{"name":"Arabic-Tweets","keyword":"arabic","description":"\n\t\n\t\t\n\t\tDataset Card for Dataset Arabic-Tweets\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset has been collected from twitter which is more than 41 GB of clean data of Arabic Tweets with nearly 4-billion Arabic words (12-million unique Arabic words).\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nArabic\n\n\t\n\t\t\n\t\tSource Data\n\t\n\nTwitter\n\n\t\n\t\t\n\t\tExample on data loading using streaming:\n\t\n\nfrom datasets import load_dataset\ndataset = load_dataset(\"pain/Arabic-Tweets\",split='train', streaming=True)\nprint(next(iter(dataset)))â€¦ See the full description on the dataset page: https://huggingface.co/datasets/pain/Arabic-Tweets.","url":"https://huggingface.co/datasets/pain/Arabic-Tweets","creator_name":"Mohammad Albarham","creator_url":"https://huggingface.co/pain","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["Arabic","cc-by-4.0","100M - 1B","text","Text"],"keywords_longer_than_N":true},
	{"name":"ragtime1","keyword":"arabic","description":"\n\t\n\t\t\n\t\tRAGTIME1 Collection\n\t\n\nThis dataset contains the documents for TREC RAGTIME Track. \nPlease refer to the website for the details of the task. \nRAGTIME is a multilingual RAG task, which expects the participating system to retrieve relevant documents from all four languages and synthesize a response with citation to the report request. \nFor convenience, we separate the documents by their languages into four .jsonl files. However, they are intended to be used as a whole set. \nThe documentsâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/trec-ragtime/ragtime1.","url":"https://huggingface.co/datasets/trec-ragtime/ragtime1","creator_name":"TREC RAGTIME Track","creator_url":"https://huggingface.co/trec-ragtime","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","no-annotation","multilingual","extended|c4"],"keywords_longer_than_N":true},
	{"name":"BenchMAX_Science","keyword":"arabic","description":"\n\t\n\t\t\n\t\tDataset Sources\n\t\n\n\nPaper: BenchMAX: A Comprehensive Multilingual Evaluation Suite for Large Language Models\nLink: https://huggingface.co/papers/2502.07346\nRepository: https://github.com/CONE-MT/BenchMAX\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nBenchMAX_Science is a dataset of BenchMAX, sourcing from GPQA, which evaluates the natural science reasoning capability in multilingual scenarios.\nWe extend the original English dataset to 16 non-English languages.\nThe data is first translated by Googleâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/LLaMAX/BenchMAX_Science.","url":"https://huggingface.co/datasets/LLaMAX/BenchMAX_Science","creator_name":"LLaMAX","creator_url":"https://huggingface.co/LLaMAX","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["question-answering","multilingual","English","Chinese","Spanish"],"keywords_longer_than_N":true},
	{"name":"Human4K","keyword":"arabic","description":"liulj0527/Human4K dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/liulj0527/Human4K","creator_name":"lijian","creator_url":"https://huggingface.co/liulj0527","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","Arabic","apache-2.0","ðŸ‡ºðŸ‡¸ Region: US"],"keywords_longer_than_N":false},
	{"name":"Arabic-Triplet-With-Multi-Negatives","keyword":"arabic","description":"\n\t\n\t\t\n\t\tArabic Triplet with Multi Negatives\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset is a modified version of the Arabic subset of the Mr. TyDi dataset, tailored for retrieval and re-ranking tasks. The original dataset has been restructured by splitting the negative passages into separate fields (negative1, negative2, ..., negativeN) for each query. This modification allows more flexibility for training and evaluating retrieval and re-ranking models.\nThe dataset retains the original intentâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/NAMAA-Space/Arabic-Triplet-With-Multi-Negatives.","url":"https://huggingface.co/datasets/NAMAA-Space/Arabic-Triplet-With-Multi-Negatives","creator_name":"Network for Advancing Modern ArabicNLP & AI","creator_url":"https://huggingface.co/NAMAA-Space","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","Arabic","apache-2.0","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"sssssss","keyword":"arabic","description":"abduslam/sssssss dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/abduslam/sssssss","creator_name":"mofarh","creator_url":"https://huggingface.co/abduslam","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":null,"first_N":5,"first_N_keywords":["text-generation","Arabic","apache-2.0","1K<n<10K","ðŸ‡ºðŸ‡¸ Region: US"],"keywords_longer_than_N":true},
	{"name":"FineWeb2-embedded","keyword":"arabic","description":"\n\t\n\t\t\n\t\tFineWeb2-embedded\n\t\n\n\n\t\n\t\t\n\t\tDataset summary\n\t\n\nFineWeb2-embedded is an extension of the FineWeb2 dataset, annotated with document-level XLM-RoBERTa embeddings for 20 languages, making the dataset useful for a variety of tasks, including document clustering, filtering, and other multilingual research.\nSince XLM-RoBERTa has a sequence length limit of 512 tokens, each document's embeddings are obtained by mean-pooling 512 token chunks of the XLM-RoBERTa output. Therefore, longer textsâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/epfml/FineWeb2-embedded.","url":"https://huggingface.co/datasets/epfml/FineWeb2-embedded","creator_name":"EPFL Machine Learning and Optimization Laboratory","creator_url":"https://huggingface.co/epfml","license_name":"Open Data Commons Attribution License v1.0","license_url":"https://scancode-licensedb.aboutcode.org/odc-by-1.0.html","language":"en","first_N":5,"first_N_keywords":["text-generation","Russian","Chinese","German","Japanese"],"keywords_longer_than_N":true},
	{"name":"waqfeya-library","keyword":"arabic","description":"\n\t\n\t\t\n\t\tWaqfeya Library\n\t\n\n\n\t\n\t\t\n\t\tðŸ“– Overview\n\t\n\nWaqfeya is one of the primary online resources for Islamic books, similar to Shamela. It hosts more than 10,000 PDF books across over 80 categories.\nIn this dataset, we processed the original PDF files using Google Document AI APIs and extracted their contents into two additional formats: TXT and DOCX.\n\n\t\n\t\t\n\t\tðŸ“Š Dataset Contents\n\t\n\nThe dataset includes 22,443 PDF files (spanning 8,978,634 pages) representing 10,150 Islamic books. Each book isâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/ieasybooks-org/waqfeya-library.","url":"https://huggingface.co/datasets/ieasybooks-org/waqfeya-library","creator_name":"Ø§Ù„ÙƒØªØ¨ Ø§Ù„Ù…ÙÙŠØ³Ù‘Ø±Ø©","creator_url":"https://huggingface.co/ieasybooks-org","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["image-to-text","Arabic","mit","10K - 100K","csv"],"keywords_longer_than_N":true},
	{"name":"facebook_darija_dataset","keyword":"arabic","description":"\n\t\n\t\t\n\t\tDarija Facebook Posts Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\n\nThis dataset consists of more than 5k public posts from Facebook. Each post contains text content, metadata.\nThis dataset containt more than 400K darija tokens.\n\nCurated by: @abdeljalilELmajjodi\nLanguage(s) (NLP): Multiple (primarily Moroccon Arabic)\n\n\n\t\n\t\t\n\t\tUses\n\t\n\nThis dataset could be used for:\n\nTraining and testing language models on social media content\nAnalyzing social media postingâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/abdeljalilELmajjodi/facebook_darija_dataset.","url":"https://huggingface.co/datasets/abdeljalilELmajjodi/facebook_darija_dataset","creator_name":"abdeljalil_elma","creator_url":"https://huggingface.co/abdeljalilELmajjodi","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","Arabic","apache-2.0","1K - 10K","parquet"],"keywords_longer_than_N":true},
	{"name":"MOLE","keyword":"arabic","description":"\n\t\n\t\t\n\t\tMOLE: Metadata Extraction and Validation in Scientific Papers\n\t\n\nMOLE is a dataset for evaluating and validating metadata extracted from scientific papers. The paper can be found here.\n\n\n\t\n\t\t\n\t\n\t\n\t\tðŸ“‹ Dataset Structure\n\t\n\nThe main datasets attributes are shown below. Also for earch feature there is binary value attribute_exist. The value is 1 if the attribute is retrievable form the paper, otherwise it is 0. \n\nName (str): What is the name of the dataset?\nSubsets (List[Dict[Name, Volumeâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/IVUL-KAUST/MOLE.","url":"https://huggingface.co/datasets/IVUL-KAUST/MOLE","creator_name":"Image and Video Understanding Lab","creator_url":"https://huggingface.co/IVUL-KAUST","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","English","Arabic","French","jp"],"keywords_longer_than_N":true},
	{"name":"semeval-2025-task11-track-c","keyword":"arabic","description":"\n\t\n\t\t\n\t\tSemEval 2025 Task 11 - Track C Dataset\n\t\n\nThis dataset contains the data for SemEval 2025 Task 11: Bridging the Gap in Text-Based Emotion Detection - Track C, organized as language-specific configurations.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset is a multi-language, multi-label emotion classification dataset with separate configurations for each language.\n\nTotal languages: 30 standard ISO codes\nTotal examples: 57254\nSplits: dev, test (Track C has no train split)\n\n\n\t\n\t\t\n\t\tTrackâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/vgaraujov/semeval-2025-task11-track-c.","url":"https://huggingface.co/datasets/vgaraujov/semeval-2025-task11-track-c","creator_name":"Vladimir Araujo","creator_url":"https://huggingface.co/vgaraujov","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["Afrikaans","Amharic","Arabic","German","English"],"keywords_longer_than_N":true},
	{"name":"linto-dataset-audio-ar-tn","keyword":"arabic","description":"\n\t\n\t\t\n\t\tLinTO DataSet Audio for Arabic Tunisian A collection of Tunisian dialect audio and its annotations for STT task\n\t\n\nThis is the first packaged version of the datasets used to train the Linto Tunisian dialect with code-switching STT\n(linagora/linto-asr-ar-tn).\n\nDataset Summary\nDataset composition\nSources\nData Table\nData sources\nContent Types\nLanguages and Dialects\n\n\nExample use (python)\nLicense\nCitations\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThe LinTO DataSet Audio for Arabic Tunisian is a diverseâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/linagora/linto-dataset-audio-ar-tn.","url":"https://huggingface.co/datasets/linagora/linto-dataset-audio-ar-tn","creator_name":"LINAGORA Labs","creator_url":"https://huggingface.co/linagora","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","text-to-audio","Arabic","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"HPLT2.0_cleaned","keyword":"arabic","description":"This is a large-scale collection of web-crawled documents in 191 world languages, produced by the HPLT project. \nThe source of the data is mostly Internet Archive with some additions from Common Crawl.\nFor a detailed description of the dataset, please refer to our website and our pre-print.\n\n\t\n\t\t\n\t\n\t\n\t\tThe Cleaned variant of HPLT Datasets v2.0\n\t\n\nThis is the cleaned variant of the HPLT Datasets v2.0 converted to the Parquet format semi-automatically when being uploaded here. \nThe originalâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/HPLT/HPLT2.0_cleaned.","url":"https://huggingface.co/datasets/HPLT/HPLT2.0_cleaned","creator_name":"HPLT","creator_url":"https://huggingface.co/HPLT","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["fill-mask","text-generation","language-modeling","multilingual","Achinese"],"keywords_longer_than_N":true},
	{"name":"ELNER-DZ","keyword":"arabic","description":"\n\t\n\t\t\n\t\tELNER-DZ: Algerian Arabic Dataset for Named Entity Recognition and Entity Linking\n\t\n\nThis dataset, titled ELNER-DZ, was created by Bouguettoucha Hadjer Hanine and Djouablia Ilhem as part of our Masterâ€™s thesis . It is the first large-scale dataset designed for Named Entity Recognition (NER) and Entity Linking (EL) in Algerian Arabic Dialect (Darija), including both Arabic script and Arabizi (Latin-script).\nThis dataset contains over 2 million dialectal sentences labeled with more thanâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/HadjerHaninebgt7878/ELNER-DZ.","url":"https://huggingface.co/datasets/HadjerHaninebgt7878/ELNER-DZ","creator_name":"Hanine_Bgt","creator_url":"https://huggingface.co/HadjerHaninebgt7878","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","feature-extraction","Arabic","French"],"keywords_longer_than_N":true},
	{"name":"DATA-AI_Chat","keyword":"arabic","description":"\n\t\n\t\t\n\t\tDATA-AI: Il Modello di IA di M.INC.\n\t\n\n\n\t\n\t\t\n\t\tðŸ“Œ Introduzione\n\t\n\nDATA-AI Ã¨ un avanzato modello di intelligenza artificiale sviluppato da *M.INC., un'azienda italiana fondata da *Mattimax (M. Marzorati).Questo modello Ã¨ basato sull'architettura ELNS (Elaborazione del Linguaggio Naturale Semplice), un sistema innovativo progettato per rendere l'IA accessibile su quasi qualsiasi dispositivo, garantendo prestazioni ottimali anche su hardware limitato.  \nDATA-AI Ã¨ stato addestrato su unâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Mattimax/DATA-AI_Chat.","url":"https://huggingface.co/datasets/Mattimax/DATA-AI_Chat","creator_name":"M.INC.","creator_url":"https://huggingface.co/Mattimax","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["Italian","English","Spanish","Russian","German"],"keywords_longer_than_N":true},
	{"name":"CIDAR-EVAL-100","keyword":"arabic","description":"\n\t\n\t\t\n\t\tDataset Card for \"CIDAR-EVAL-100\"\n\t\n\n\n\t\n\t\t\n\t\tCIDAR-EVAL-100\n\t\n\nCIDAR-EVAL-100 contains 100 instructions about Arabic culture. The dataset can be used to evaluate an LLM for culturally relevant answers. \n\n\t\n\t\t\n\t\tðŸ“š Datasets Summary\n\t\n\n\n  \nName\nExplanation\n\n\nCIDAR \n10,000 instructions and responses in Arabic\n\n\nCIDAR-EVAL-100 \n100 instructions to evaluate LLMs on cultural relevance\n\n\nCIDAR-MCQ-100 \n100 Multiple choice questions and answers to evaluate LLMs on cultural relevanceâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/arbml/CIDAR-EVAL-100.","url":"https://huggingface.co/datasets/arbml/CIDAR-EVAL-100","creator_name":"Arabic Machine Learning ","creator_url":"https://huggingface.co/arbml","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","Arabic","apache-2.0","< 1K","parquet"],"keywords_longer_than_N":true},
	{"name":"Arabic-NLi-Pair-Score","keyword":"arabic","description":"\n\t\n\t\t\n\t\tArabic NLI Pair-Score\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\n\nThe Arabic Version of SNLI and MultiNLI datasets. (Pair-Score Subset)\nOriginally used for Natural Language Inference (NLI),\nDataset may be used for training/finetuning an embedding model for semantic textual similarity.\n\n\n\t\n\t\t\n\t\tPair-Class Subset\n\t\n\n\nColumns: \"sentence1\", \"sentence2\", \"score\"\nColumn types: str, str, float\n\n\n\t\n\t\t\n\t\tArabic Examples:\n\t\n\n{\n  \"sentence1\": \"Ø´Ø®Øµ Ø¹Ù„Ù‰ Ø­ØµØ§Ù† ÙŠÙ‚ÙØ² ÙÙˆÙ‚ Ø·Ø§Ø¦Ø±Ø© Ù…Ø¹Ø·Ù„Ø©\",\n  \"sentence2\": \"Ø´Ø®Øµ ÙŠÙ‚ÙˆÙ…â€¦ See the full description on the dataset page: https://huggingface.co/datasets/LLMXperts/Arabic-NLi-Pair-Score.","url":"https://huggingface.co/datasets/LLMXperts/Arabic-NLi-Pair-Score","creator_name":"LLMXperts","creator_url":"https://huggingface.co/LLMXperts","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["sentence-similarity","Arabic","apache-2.0","100K - 1M","csv"],"keywords_longer_than_N":true},
	{"name":"TESTAI","keyword":"arabic","description":"mo7ammedreyad/TESTAI dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/mo7ammedreyad/TESTAI","creator_name":"mohamed reyad","creator_url":"https://huggingface.co/mo7ammedreyad","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["Arabic","apache-2.0","< 1K","csv","Text"],"keywords_longer_than_N":true},
	{"name":"Moroccan_Darija_Offensive_Language_Detection_Dataset","keyword":"arabic","description":"\n\t\n\t\t\n\t\tDataset Card for \"Moroccan_Darija_Offensive_Language_Detection_Dataset\"\n\t\n\n\n\t\n\t\t\n\t\tPaper:\n\t\n\nIbrahimi, Anass; Mourhir, Asmaa (2023), â€œMoroccan Darija Offensive Language Detection Datasetâ€, Mendeley Data, V2, doi: 10.17632/2y4m97b7dc.2\n","url":"https://huggingface.co/datasets/asas-ai/Moroccan_Darija_Offensive_Language_Detection_Dataset","creator_name":"ASAS AI","creator_url":"https://huggingface.co/asas-ai","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","Arabic","cc-by-4.0","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"eg-legal-ner","keyword":"arabic","description":"\n\t\n\t\t\n\t\tArabic Legal Dataset - Legal Named Entity Recognition\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nNamed entity recognition dataset for Arabic legal texts with specialized legal entity types and relationships.\nThis dataset contains 1,046 examples of ner data derived from Egyptian legal texts, including criminal law, civil law, procedural law, and personal status law. The dataset is designed for training and evaluating Arabic legal AI models.\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\n\nLanguage: Arabic (Egyptianâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fr3on/eg-legal-ner.","url":"https://huggingface.co/datasets/fr3on/eg-legal-ner","creator_name":"Ahmed Mardi","creator_url":"https://huggingface.co/fr3on","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["token-classification","Arabic","apache-2.0","1K - 10K","parquet"],"keywords_longer_than_N":true},
	{"name":"eg-legal-ner","keyword":"arabic","description":"\n\t\n\t\t\n\t\tArabic Legal Dataset - Legal Named Entity Recognition\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nNamed entity recognition dataset for Arabic legal texts with specialized legal entity types and relationships.\nThis dataset contains 1,046 examples of ner data derived from Egyptian legal texts, including criminal law, civil law, procedural law, and personal status law. The dataset is designed for training and evaluating Arabic legal AI models.\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\n\nLanguage: Arabic (Egyptianâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fr3on/eg-legal-ner.","url":"https://huggingface.co/datasets/fr3on/eg-legal-ner","creator_name":"Ahmed Mardi","creator_url":"https://huggingface.co/fr3on","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["token-classification","Arabic","apache-2.0","1K - 10K","parquet"],"keywords_longer_than_N":true},
	{"name":"MultiLingualSentiment","keyword":"arabic","description":"\n\t\n\t\t\n\t\tOverview\n\t\n\nMultilingualSentiment is a sentiment classification dataset that encompasses three sentiment labels: Positive, Neutral, Negative\nThe dataset spans multiple languages and covers a wide range of domains, making it ideal for multilingual sentiment analysis tasks.\n\n\t\n\t\t\n\t\tDataset Information\n\t\n\nThe dataset was meticulously collected and aggregated from various sources, including Hugging Face and Kaggle. These sources provide diverse languages and domains to ensure aâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/clapAI/MultiLingualSentiment.","url":"https://huggingface.co/datasets/clapAI/MultiLingualSentiment","creator_name":"clapAI","creator_url":"https://huggingface.co/clapAI","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","Arabic","German","English","Spanish"],"keywords_longer_than_N":true},
	{"name":"KHATT_v1.0_dataset","keyword":"arabic","description":"\n\t\n\t\t\n\t\n\t\n\t\tKHATT_v1.0 - line level\n\t\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nKHATT (KFUPM Handwritten Arabic TexT) database is a database of unconstrained handwritten Arabic Text written by 1000 different writers. This research databaseâ€™s development was undertaken by a research group from KFUPM, Dhahran, S audi Arabia headed by Professor Sabri Mahmoud in collaboration with Professor Fink from TU-Dortmund, Germany and Dr. MÃ¤rgner from TU-Braunschweig, Germany.\nThe database includes 2000 similar-textâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/johnlockejrr/KHATT_v1.0_dataset.","url":"https://huggingface.co/datasets/johnlockejrr/KHATT_v1.0_dataset","creator_name":"John Locke","creator_url":"https://huggingface.co/johnlockejrr","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["image-to-text","Arabic","mit","Image","ðŸ‡ºðŸ‡¸ Region: US"],"keywords_longer_than_N":true},
	{"name":"KHATT_v1.0_dataset","keyword":"arabic","description":"\n\t\n\t\t\n\t\n\t\n\t\tKHATT_v1.0 - line level\n\t\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nKHATT (KFUPM Handwritten Arabic TexT) database is a database of unconstrained handwritten Arabic Text written by 1000 different writers. This research databaseâ€™s development was undertaken by a research group from KFUPM, Dhahran, S audi Arabia headed by Professor Sabri Mahmoud in collaboration with Professor Fink from TU-Dortmund, Germany and Dr. MÃ¤rgner from TU-Braunschweig, Germany.\nThe database includes 2000 similar-textâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/johnlockejrr/KHATT_v1.0_dataset.","url":"https://huggingface.co/datasets/johnlockejrr/KHATT_v1.0_dataset","creator_name":"John Locke","creator_url":"https://huggingface.co/johnlockejrr","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["image-to-text","Arabic","mit","Image","ðŸ‡ºðŸ‡¸ Region: US"],"keywords_longer_than_N":true},
	{"name":"MintakaRetrieval","keyword":"arabic","description":"\n  MintakaRetrieval\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nWe introduce Mintaka, a complex, natural, and multilingual dataset designed for experimenting with end-to-end question-answering models. Mintaka is composed of 20,000 question-answer pairs collected in English, annotated with Wikidata entities, and translated into Arabic, French, German, Hindi, Italian, Japanese, Portuguese, and Spanish for a total of 180,000 samples. Mintaka includes 8 types of complex questionsâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/MintakaRetrieval.","url":"https://huggingface.co/datasets/mteb/MintakaRetrieval","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","multiple-choice-qa","derived","translated","jinaai/mintakaqa"],"keywords_longer_than_N":true},
	{"name":"aracast_text","keyword":"arabic","description":"asas-ai/aracast_text dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/asas-ai/aracast_text","creator_name":"ASAS AI","creator_url":"https://huggingface.co/asas-ai","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","Arabic","apache-2.0","10K - 100K","text"],"keywords_longer_than_N":true},
	{"name":"reranker_continuous_filt_max7_train","keyword":"arabic","description":"\n\t\n\t\t\n\t\tReranker training data\n\t\n\nThis data was generated using 4 steps:\n\nWe gathered queries and corresponding text data from 35 high quality datasets covering more than 95 languages.\nFor datasets which did not already have negative texts for queries, we mined hard negatives using the BAAI/bge-m3 embedding model.\nFor each query, we selected one positive and one negative text and used Qwen/Qwen2.5-32B-Instruct-GPTQ-Int4 to rate the relatedness of each query-text pair using a token \"1\", \"2\"â€¦ See the full description on the dataset page: https://huggingface.co/datasets/lightblue/reranker_continuous_filt_max7_train.","url":"https://huggingface.co/datasets/lightblue/reranker_continuous_filt_max7_train","creator_name":"Lightblue KK.","creator_url":"https://huggingface.co/lightblue","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["English","Chinese","Spanish","German","Arabic"],"keywords_longer_than_N":true},
	{"name":"egyptian-arabic-fake-reviews","keyword":"arabic","description":"\n\t\n\t\t\n\t\tðŸ•µï¸â€â™‚ï¸ðŸ‡ªðŸ‡¬ FREAD: Fake Reviews Egyptian Arabic Dataset\n\t\n\nAuthor: IbrahimAmin, Ismail Fakhr, M. Waleed Fakhr, Rasha Kashef License: MIT Paper: Boosting Arabic Fake Reviews Detection by Integrating Textual and Metadata Features: A Transformer-Based Model Languages: Arabic (Egyptian Dialect)\n\n\n\t\n\t\n\t\n\t\tðŸ“š Dataset Summary\n\t\n\nFREAD is designed for detecting fake reviews in Arabic using both textual contentand behavioral metadata. It contains 60,000 reviews (50K train / 10K test) translatedâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/IbrahimAmin/egyptian-arabic-fake-reviews.","url":"https://huggingface.co/datasets/IbrahimAmin/egyptian-arabic-fake-reviews","creator_name":"Ibrahim Amin","creator_url":"https://huggingface.co/IbrahimAmin","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","translation","text-generation","zero-shot-classification","Arabic"],"keywords_longer_than_N":true},
	{"name":"Aya-SambaLingo.Arabic.Chat-DPO","keyword":"arabic","description":"\n\t\n\t\t\n\t\tDataset Card for \"Aya-SambaLingo.Arabic.Chat-DPO\" ðŸ¤—\n\t\n\n\n\t\n\t\t\n\t\tDataset Sources & Infos\n\t\n\n\nData Origin: Derived from the Arabic Aya (2A) dataset : 2A2I/Arabic_Aya which is a Curated Subset of the Aya Collection CohereForAI/aya_dataset\nLanguages: Modern Standard Arabic (MSA)\nLicense: Apache-2.0\nMaintainers: Ali Elfilali and Mohammed Machrouh\n\n\n\t\n\t\t\n\t\n\t\n\t\tPurpose\n\t\n\nAya-SambaLingo.Arabic.Chat-DPO is a DPO dataset designed to advance Arabic NLP by comparing human-generated responsesâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/2A2I/Aya-SambaLingo.Arabic.Chat-DPO.","url":"https://huggingface.co/datasets/2A2I/Aya-SambaLingo.Arabic.Chat-DPO","creator_name":"2A2I","creator_url":"https://huggingface.co/2A2I","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["Arabic","apache-2.0","10K - 100K","parquet","Text"],"keywords_longer_than_N":true},
	{"name":"egyptian-arabic-fake-reviews","keyword":"egyptian arabic","description":"\n\t\n\t\t\n\t\tðŸ•µï¸â€â™‚ï¸ðŸ‡ªðŸ‡¬ FREAD: Fake Reviews Egyptian Arabic Dataset\n\t\n\nAuthor: IbrahimAmin, Ismail Fakhr, M. Waleed Fakhr, Rasha Kashef License: MIT Paper: Boosting Arabic Fake Reviews Detection by Integrating Textual and Metadata Features: A Transformer-Based Model Languages: Arabic (Egyptian Dialect)\n\n\n\t\n\t\n\t\n\t\tðŸ“š Dataset Summary\n\t\n\nFREAD is designed for detecting fake reviews in Arabic using both textual contentand behavioral metadata. It contains 60,000 reviews (50K train / 10K test) translatedâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/IbrahimAmin/egyptian-arabic-fake-reviews.","url":"https://huggingface.co/datasets/IbrahimAmin/egyptian-arabic-fake-reviews","creator_name":"Ibrahim Amin","creator_url":"https://huggingface.co/IbrahimAmin","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","translation","text-generation","zero-shot-classification","Arabic"],"keywords_longer_than_N":true},
	{"name":"MAGBIG","keyword":"arabic","description":"\n\t\n\t\t\n\t\tMAGBIG benchmark\n\t\n\nThis is the MAGBIG benchmark proposed in https://arxiv.org/abs/2401.16092\nThis benchmark is intended for multilingual text-to-image models. With MAGBIG, you can generate images for a diverse set of prompts across ten different languages. These images can be evaluated for differences across languages. MAGBIG is designed to uncover and assess biases across languages such as gender, race, age, etc. This way, we can measure whether bias exists in a language, but alsoâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/felfri/MAGBIG.","url":"https://huggingface.co/datasets/felfri/MAGBIG","creator_name":"Felix Friedrich","creator_url":"https://huggingface.co/felfri","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-to-image","English","German","Italian","French"],"keywords_longer_than_N":true},
	{"name":"ar-eg-dataset","keyword":"arabic","description":"An in-progress dataset for arabic-egyptian-dialect, specifically made from transcripton of DrAliGomaa videos on youtube.\nDr Ali Gomaa is a famous Egyptian Islamic Scholar and he was the mufti of Egypt from 2003-2013\n\nLink to his youtube channel: https://www.youtube.com/@DrAliGomaa\nLink to his page on facebook: https://www.facebook.com/DrAliGomaa\n\n","url":"https://huggingface.co/datasets/siddiqiya/ar-eg-dataset","creator_name":"Siddiqiya Shazoulia","creator_url":"https://huggingface.co/siddiqiya","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","translation","Arabic","apache-2.0","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"Gutenberg-Arabic-OCR-HTML-Pages","keyword":"arabic","description":"\n\t\n\t\t\n\t\tGutenberg Arabic HTML-Page Dataset\n\t\n\n\n\t\n\t\t\n\t\tðŸ“– Dataset Description\n\t\n\nThe Gutenberg Arabic HTML-Page Dataset is a large-scale, synthetically generated dataset designed for training and evaluating document understanding and Optical Character Recognition (OCR) models. The primary goal of this project is to provide a comprehensive resource of page images paired with their corresponding structured HTML ground truth, with a focus on the Arabic language.\nThe dataset was created byâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/FatimahEmadEldin/Gutenberg-Arabic-OCR-HTML-Pages.","url":"https://huggingface.co/datasets/FatimahEmadEldin/Gutenberg-Arabic-OCR-HTML-Pages","creator_name":"Fatimah Emad Eldin","creator_url":"https://huggingface.co/FatimahEmadEldin","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["Arabic","apache-2.0","1K - 10K","csv","Image"],"keywords_longer_than_N":true},
	{"name":"eng_montok","keyword":"standard arabic","description":"\n\t\n\t\t\n\t\tMonTok: A Suite of Monolingual Tokenizers\n\t\n\nThis is a set of monolingual tokenizers for 98 languages. For each language, there are Unigram, BPE, and SuperBPE tokenizers, ranging in vocabulary size from around 6k to over 200k.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\n","url":"https://huggingface.co/datasets/catherinearnett/eng_montok","creator_name":"Catherine Arnett","creator_url":"https://huggingface.co/catherinearnett","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["Afrikaans","Tosk Albanian","Amharic","Standard Arabic","Assamese"],"keywords_longer_than_N":true},
	{"name":"msdd","keyword":"arabic","description":"\n\t\n\t\t\n\t\tðŸ“š Misraj Structured Data Dump (MSDD)\n\t\n\nMisraj Structured Data Dump (MSDD) is a large-scale Arabic multimodal dataset created using our WASM pipeline. It is extracted and filtered from the Common Crawl dumps and uniquely preserves the structural integrity of web content by providing markdown output. This dataset aims to address the lack of high-quality, structured multimodal data for Arabic and accelerate research in large language and multimodal models.\n\n\t\n\t\t\n\t\n\t\n\t\tðŸ“Œ Dataset Summaryâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Misraj/msdd.","url":"https://huggingface.co/datasets/Misraj/msdd","creator_name":"Misraj Ai","creator_url":"https://huggingface.co/Misraj","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["Arabic","apache-2.0","10M - 100M","parquet","Text"],"keywords_longer_than_N":true},
	{"name":"msdd","keyword":"arabic","description":"\n\t\n\t\t\n\t\tðŸ“š Misraj Structured Data Dump (MSDD)\n\t\n\nMisraj Structured Data Dump (MSDD) is a large-scale Arabic multimodal dataset created using our WASM pipeline. It is extracted and filtered from the Common Crawl dumps and uniquely preserves the structural integrity of web content by providing markdown output. This dataset aims to address the lack of high-quality, structured multimodal data for Arabic and accelerate research in large language and multimodal models.\n\n\t\n\t\t\n\t\n\t\n\t\tðŸ“Œ Dataset Summaryâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Misraj/msdd.","url":"https://huggingface.co/datasets/Misraj/msdd","creator_name":"Misraj Ai","creator_url":"https://huggingface.co/Misraj","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["Arabic","apache-2.0","10M - 100M","parquet","Text"],"keywords_longer_than_N":true},
	{"name":"multilingual-speech-commands-15lang-zip","keyword":"arabic","description":"\n\t\n\t\t\n\t\tMultilingual Speech Commands Dataset (15 Languages, Augmented)\n\t\n\nThis dataset contains augmented speech command samples in 15 languages, derived from multiple public datasets. Only commands that overlap with the Google Speech Commands (GSC) vocabulary are included, making the dataset suitable for multilingual keyword spotting tasks aligned with GSC-style classification.\nAudio samples have been augmented using standard audio techniques to improve model robustness (e.g., time-shiftingâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/artur-muratov/multilingual-speech-commands-15lang-zip.","url":"https://huggingface.co/datasets/artur-muratov/multilingual-speech-commands-15lang-zip","creator_name":"Artur Muratov","creator_url":"https://huggingface.co/artur-muratov","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["English","Russian","Kazakh","Tatar","Arabic"],"keywords_longer_than_N":true},
	{"name":"2A2I-Arabic-OpenHermes-2.5-Llama-3","keyword":"arabic","description":"\n\t\n\t\t\n\t\tDataset Card for \"2A2I-Arabic-OpenHermes-2.5-Llama-3\"\n\t\n\n\n\t\n\t\t\n\t\tDataset Sources & Infos\n\t\n\n\nData Origin: Derived from the original Arabic OpenHermes dataset : 2A2I/Arabic-OpenHermes-2.5.\nLanguages: Modern Standard Arabic (MSA)\nApplications: Language Modeling\nLicense: Apache-2.0\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\n2A2I-Arabic-OpenHermes-2.5-Llama is a Llama-3 compatible dataset carefully converted from the 2A2I's Arabic-OpenHermes-2.5 collection provided by Lyte.\n\n\t\n\t\t\n\t\tPurposeâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Lyte/2A2I-Arabic-OpenHermes-2.5-Llama-3.","url":"https://huggingface.co/datasets/Lyte/2A2I-Arabic-OpenHermes-2.5-Llama-3","creator_name":"Yassine Ennaour","creator_url":"https://huggingface.co/Lyte","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["question-answering","Arabic","apache-2.0","100K - 1M","parquet"],"keywords_longer_than_N":true},
	{"name":"Everything_Instruct_Multilingual","keyword":"arabic","description":"\n\t\n\t\t\n\t\tEverything Instruct (Multilingual Edition)\n\t\n\nEverything you need... all in one place ðŸ’˜\n\nEverything instruct (Multilingual Edition) is a massive alpaca instruct formatted dataset consisting of a wide variety of topics meant to bring LLM's to the next level in open source AI.\nNote: This dataset is fully uncensored (No model will refuse any request trained on this dataset unless otherwise aligned)\nNote2: This version of the dataset supports the following languages:\n\nEnglish\nRussianâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/rombodawg/Everything_Instruct_Multilingual.","url":"https://huggingface.co/datasets/rombodawg/Everything_Instruct_Multilingual","creator_name":"rombo dawg","creator_url":"https://huggingface.co/rombodawg","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["English","Russian","Chinese","Korean","Urdu"],"keywords_longer_than_N":true},
	{"name":"saudi-dialect-test-samples","keyword":"arabic","description":"\n\t\n\t\t\n\t\tSaudi Dialect Test Samples\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset contains 1280 Saudi dialect utterances across 44 categories, used for testing and evaluating the Omartificial-Intelligence-Space/SA-BERT-V1 model. The sentences represent a wide range of topics, from daily conversations to specialized domains.\n\n  \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Structure\n\t\n\n\n\t\n\t\t\n\t\n\t\n\t\tData Fields\n\t\n\n\ncategory: The topic category of the utterance (one of 44 categories)\ntext: The Saudi dialect textâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Omartificial-Intelligence-Space/saudi-dialect-test-samples.","url":"https://huggingface.co/datasets/Omartificial-Intelligence-Space/saudi-dialect-test-samples","creator_name":"Omartificial Intelligence Space","creator_url":"https://huggingface.co/Omartificial-Intelligence-Space","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","Arabic","apache-2.0","1K - 10K","parquet"],"keywords_longer_than_N":true},
	{"name":"saudi-dialect-test-samples","keyword":"arabic","description":"\n\t\n\t\t\n\t\tSaudi Dialect Test Samples\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset contains 1280 Saudi dialect utterances across 44 categories, used for testing and evaluating the Omartificial-Intelligence-Space/SA-BERT-V1 model. The sentences represent a wide range of topics, from daily conversations to specialized domains.\n\n  \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Structure\n\t\n\n\n\t\n\t\t\n\t\n\t\n\t\tData Fields\n\t\n\n\ncategory: The topic category of the utterance (one of 44 categories)\ntext: The Saudi dialect textâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Omartificial-Intelligence-Space/saudi-dialect-test-samples.","url":"https://huggingface.co/datasets/Omartificial-Intelligence-Space/saudi-dialect-test-samples","creator_name":"Omartificial Intelligence Space","creator_url":"https://huggingface.co/Omartificial-Intelligence-Space","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","Arabic","apache-2.0","1K - 10K","parquet"],"keywords_longer_than_N":true},
	{"name":"gulf_test_set","keyword":"arabic","description":"Pre-processed Gulf test partition from the MASC-dataset:\nMohammad Al-Fetyani, Muhammad Al-Barham, Gheith Abandah, Adham Alsharkawi, Maha Dawas, August 18, 2021, \"MASC: Massive Arabic Speech Corpus\", IEEE Dataport, doi: https://dx.doi.org/10.21227/e1qb-jv46.\n","url":"https://huggingface.co/datasets/otozz/gulf_test_set","creator_name":"Ã–mer","creator_url":"https://huggingface.co/otozz","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["Arabic","cc-by-4.0","1K - 10K","parquet","Datasets"],"keywords_longer_than_N":true},
	{"name":"DVOICEv2.0-Darija","keyword":"arabic","description":"DVoice is a community initiative that aims to provide African languages and dialects with data and models to facilitate their use of voice technologies. The lack of data on these languages makes it necessary to collect data using methods that are specific to each language. Two different approaches are currently used: the DVoice platform, which is based on Mozilla Common Voice, for collecting authentic recordings from the community, and transfer learning techniques for automatically labelingâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/BrunoHays/DVOICEv2.0-Darija.","url":"https://huggingface.co/datasets/BrunoHays/DVOICEv2.0-Darija","creator_name":"Bruno Hays","creator_url":"https://huggingface.co/BrunoHays","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["Arabic","cc-by-4.0","10K - 100K","soundfolder","Audio"],"keywords_longer_than_N":true},
	{"name":"Quranrawda","keyword":"arabic","description":"abdallah3id/Quranrawda dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/abdallah3id/Quranrawda","creator_name":"Abdallah Eid","creator_url":"https://huggingface.co/abdallah3id","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["Arabic","English","apache-2.0","1K - 10K","csv"],"keywords_longer_than_N":true},
	{"name":"QariOCR-v0.3-markdown-mixed-dataset","keyword":"arabic","description":"\n\t\n\t\t\n\t\tQARI Markdown Mixed Dataset\n\t\n\n\n\n\n\n\n\n\n\n\n \n\n\n\n\t\n\t\n\t\n\t\tðŸ“‹ Dataset Summary\n\t\n\nThe QARI v0.3 Markdown Mixed Dataset is a specialized synthetic dataset designed for training Arabic OCR models with a focus on complex document layouts and HTML structure understanding. \nThis dataset is part of the QARI-OCR project, which achieves state-of-the-art performance in Arabic text recognition.This dataset contains 37,000 synthetically generated Arabic document images (29.6k train, 3.7k validationâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/NAMAA-Space/QariOCR-v0.3-markdown-mixed-dataset.","url":"https://huggingface.co/datasets/NAMAA-Space/QariOCR-v0.3-markdown-mixed-dataset","creator_name":"Network for Advancing Modern ArabicNLP & AI","creator_url":"https://huggingface.co/NAMAA-Space","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-to-image","Arabic","apache-2.0","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"QariOCR-v0.3-markdown-mixed-dataset","keyword":"arabic","description":"\n\t\n\t\t\n\t\tQARI Markdown Mixed Dataset\n\t\n\n\n\n\n\n\n\n\n\n\n \n\n\n\n\t\n\t\n\t\n\t\tðŸ“‹ Dataset Summary\n\t\n\nThe QARI v0.3 Markdown Mixed Dataset is a specialized synthetic dataset designed for training Arabic OCR models with a focus on complex document layouts and HTML structure understanding. \nThis dataset is part of the QARI-OCR project, which achieves state-of-the-art performance in Arabic text recognition.This dataset contains 37,000 synthetically generated Arabic document images (29.6k train, 3.7k validationâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/NAMAA-Space/QariOCR-v0.3-markdown-mixed-dataset.","url":"https://huggingface.co/datasets/NAMAA-Space/QariOCR-v0.3-markdown-mixed-dataset","creator_name":"Network for Advancing Modern ArabicNLP & AI","creator_url":"https://huggingface.co/NAMAA-Space","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-to-image","Arabic","apache-2.0","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"Tamazight-Speech-to-Arabic-Text","keyword":"arabic","description":"\n\t\n\t\t\n\t\tTamazight-Arabic Speech Recognition Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis is the EMINES organization-hosted version of the Tamazight-Arabic Speech Recognition Dataset, synchronized with the original dataset. It contains ~15.5 hours of Tamazight speech (Tachelhit dialect) paired with Arabic transcriptions, designed for developing ASR and translation systems.\n\n\t\n\t\t\n\t\tQuick Start\n\t\n\nfrom datasets import load_dataset\n\n# Load the dataset\ndataset =â€¦ See the full description on the dataset page: https://huggingface.co/datasets/EMINES/Tamazight-Speech-to-Arabic-Text.","url":"https://huggingface.co/datasets/EMINES/Tamazight-Speech-to-Arabic-Text","creator_name":"EMINES, UM6P, Benguerir, Maroc","creator_url":"https://huggingface.co/EMINES","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","Arabic","Standard Moroccan Tamazight","apache-2.0","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"Tamazight-Speech-to-Arabic-Text","keyword":"arabic","description":"\n\t\n\t\t\n\t\tTamazight-Arabic Speech Recognition Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis is the EMINES organization-hosted version of the Tamazight-Arabic Speech Recognition Dataset, synchronized with the original dataset. It contains ~15.5 hours of Tamazight speech (Tachelhit dialect) paired with Arabic transcriptions, designed for developing ASR and translation systems.\n\n\t\n\t\t\n\t\tQuick Start\n\t\n\nfrom datasets import load_dataset\n\n# Load the dataset\ndataset =â€¦ See the full description on the dataset page: https://huggingface.co/datasets/EMINES/Tamazight-Speech-to-Arabic-Text.","url":"https://huggingface.co/datasets/EMINES/Tamazight-Speech-to-Arabic-Text","creator_name":"EMINES, UM6P, Benguerir, Maroc","creator_url":"https://huggingface.co/EMINES","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","Arabic","Standard Moroccan Tamazight","apache-2.0","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"Open-R1-Mulitlingual-SFT","keyword":"arabic","description":"\n\t\n\t\t\n\t\tOpen-R1-Mulitlingual-SFT\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nOpen-R1-Mulitlingual-SFT is a curated dataset designed for multilingual supervised fine-tuning.\nThe source data comprises multiple datasets containing original prompts and responses, which were subsequently translated into 14 languages using GPT-4o.\n\n\t\n\t\t\n\t\tSources\n\t\n\nThe dataset is derived from:\n\nopen-thoughts/OpenThoughts-114kHugging Face: open-thoughts/OpenThoughts-114k\nbespokelabs/Bespoke-Stratos-17kHugging Face:â€¦ See the full description on the dataset page: https://huggingface.co/datasets/amphora/Open-R1-Mulitlingual-SFT.","url":"https://huggingface.co/datasets/amphora/Open-R1-Mulitlingual-SFT","creator_name":"GUIJIN SON","creator_url":"https://huggingface.co/amphora","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["Afrikaans","Arabic","Chinese","English","French"],"keywords_longer_than_N":true},
	{"name":"X-ALMA-Preference","keyword":"arabic","description":"This is the translation preference dataset used by X-ALMA.\nsource: the source sentence.\nchosen: the preferred translation.\nreject: the dis-preferred translation.\ndirections: the translation direction.\n@misc{xu2024xalmaplugplay,\n      title={X-ALMA: Plug & Play Modules and Adaptive Rejection for Quality Translation at Scale}, \n      author={Haoran Xu and Kenton Murray and Philipp Koehn and Hieu Hoang and Akiko Eriguchi and Huda Khayrallah},\n      year={2024},\n      eprint={2410.03115}â€¦ See the full description on the dataset page: https://huggingface.co/datasets/haoranxu/X-ALMA-Preference.","url":"https://huggingface.co/datasets/haoranxu/X-ALMA-Preference","creator_name":"Haoran Xu","creator_url":"https://huggingface.co/haoranxu","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["English","Danish","Dutch","German","Icelandic"],"keywords_longer_than_N":true},
	{"name":"motor","keyword":"arabic","description":"A beautiful fair-skinned Iranian girl, wearing casual stylish clothes, riding a Honda 125cc motorcycle while doing a wheelie. The scene is cinematic, with slow-motion effects, realistic lighting, dynamic camera angles, and high detail. The atmosphere should feel energetic, youthful, and modern, like an action movie scene.\n","url":"https://huggingface.co/datasets/alireza1411/motor","creator_name":"alirezaforoozan","creator_url":"https://huggingface.co/alireza1411","license_name":"Academic Free License v3.0","license_url":"https://choosealicense.com/licenses/afl-3.0/","language":null,"first_N":5,"first_N_keywords":["Arabic","afl-3.0","ðŸ‡ºðŸ‡¸ Region: US"],"keywords_longer_than_N":false},
	{"name":"RehanWatsap","keyword":"arabic","description":"\n\t\n\t\t\n\t\tDataset Card for Dataset Name\n\t\n\n\n\nThis dataset card aims to be a base template for new datasets. It has been generated using this raw template.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\n\n\n\n\n\nCurated by: [More Information Needed]\nFunded by [optional]: [More Information Needed]\nShared by [optional]: [More Information Needed]\nLanguage(s) (NLP): [More Information Needed]\nLicense: [More Information Needed]\n\n\n\t\n\t\t\n\t\tDataset Sources [optional]\n\t\n\n\n\n\nRepository: [Moreâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/virgonx/RehanWatsap.","url":"https://huggingface.co/datasets/virgonx/RehanWatsap","creator_name":"Rizqi Ananda","creator_url":"https://huggingface.co/virgonx","license_name":"Academic Free License v3.0","license_url":"https://choosealicense.com/licenses/afl-3.0/","language":null,"first_N":5,"first_N_keywords":["Arabic","afl-3.0","1K<n<10K","ðŸ‡ºðŸ‡¸ Region: US","legal"],"keywords_longer_than_N":false},
	{"name":"egyptian_train_set","keyword":"arabic","description":"Pre-processed Egyptian train partition from the MASC-dataset:\nMohammad Al-Fetyani, Muhammad Al-Barham, Gheith Abandah, Adham Alsharkawi, Maha Dawas, August 18, 2021, \"MASC: Massive Arabic Speech Corpus\", IEEE Dataport, doi: https://dx.doi.org/10.21227/e1qb-jv46.\n","url":"https://huggingface.co/datasets/otozz/egyptian_train_set","creator_name":"Ã–mer","creator_url":"https://huggingface.co/otozz","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["Arabic","cc-by-4.0","10K - 100K","parquet","Datasets"],"keywords_longer_than_N":true},
	{"name":"Tatoeba-EN-AR","keyword":"arabic","description":"\n\t\n\t\t\n\t\tDataset Details\n\t\n\nEnglish-to-Arabic translated sentences from Tatoeba, OPUS.\nThe dataset includes unique pairs only, and its statistics are as follows:\nDataset({\n    features: ['English', 'Arabic'],\n    num_rows: 30853\n})\n\n\n\t\n\t\t\n\t\tCitation\n\t\n\n@inproceedings{tiedemann-2012-parallel,\n    title = \"Parallel Data, Tools and Interfaces in {OPUS}\",\n    author = {Tiedemann, J{\\\"o}rg},\n    booktitle = \"Proceedings of the Eighth International Conference on Language Resources and Evaluationâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/ymoslem/Tatoeba-EN-AR.","url":"https://huggingface.co/datasets/ymoslem/Tatoeba-EN-AR","creator_name":"Yasmin Moslem","creator_url":"https://huggingface.co/ymoslem","license_name":"Creative Commons Attribution 2.0","license_url":"https://scancode-licensedb.aboutcode.org/cc-by-2.0.html","language":"en","first_N":5,"first_N_keywords":["translation","English","Arabic","cc-by-2.0","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"world-languages-dataset","keyword":"arabic","description":"\n\t\n\t\t\n\t\tðŸŒ World Languages Dataset\n\t\n\nThis dataset contains a list of official and unofficial languages categorized by language families...\n","url":"https://huggingface.co/datasets/SivaMallikarjun/world-languages-dataset","creator_name":"Parvatham Siva Mallikarjun","creator_url":"https://huggingface.co/SivaMallikarjun","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","language-identification","expert-generated","multilingual","original"],"keywords_longer_than_N":true},
	{"name":"qdat","keyword":"arabic","description":"\n\t\n\t\t\n\t\tQ-dat\n\t\n\nqdat dataset was introudced in this paper cleaned and downsampled to 16000 HZ with the following specs:\n\nDownsampled to 16000 HZ\nFixed mislabeling for origianl_id: s18\nFixed typos in the metadata as\n\nDuplicate Items\n{'file_name': 's11_6.wav', 'separate_tide': 0, 'the_tight_noon': 0, 'concealment': 0, 'target': 0, 'age': 18, 'gender': 0, 'id': '147feec0'}\n{'file_name': 's11_6.wav', 'separate_tide': 0, 'the_tight_noon': 0, 'concealment': 0, 'target': 0, 'age': 18, 'gender': 0â€¦ See the full description on the dataset page: https://huggingface.co/datasets/obadx/qdat.","url":"https://huggingface.co/datasets/obadx/qdat","creator_name":"Abdullah","creator_url":"https://huggingface.co/obadx","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","Arabic","mit","1K - 10K","parquet"],"keywords_longer_than_N":true},
	{"name":"multilingual_translation_gpt4o_gen","keyword":"arabic","description":"Youseff1987/multilingual_translation_gpt4o_gen dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/Youseff1987/multilingual_translation_gpt4o_gen","creator_name":"JOON HYOUNG JUN","creator_url":"https://huggingface.co/Youseff1987","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["translation","Korean","English","Chinese","Zulu"],"keywords_longer_than_N":true},
	{"name":"resmo1","keyword":"arabic","description":"aibrahiam/resmo1 dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/aibrahiam/resmo1","creator_name":"Ahmed Ibrahim","creator_url":"https://huggingface.co/aibrahiam","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["Arabic","apache-2.0","< 1K","json","Text"],"keywords_longer_than_N":true},
	{"name":"MSA_test_set","keyword":"arabic","description":"Pre-processed MSA data based on https://huggingface.co/datasets/mozilla-foundation/common_voice_16_1.\n","url":"https://huggingface.co/datasets/otozz/MSA_test_set","creator_name":"Ã–mer","creator_url":"https://huggingface.co/otozz","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["Arabic","cc0-1.0","10K - 100K","parquet","Audio"],"keywords_longer_than_N":true},
	{"name":"Common-Voice-17-Arabic-for-Seasme-CSM-Finetuning","keyword":"arabic","description":"\n\t\n\t\t\n\t\tCurated Arabic Speech Dataset for Seasme (from MCV17)\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset is a curated and preprocessed version of the Arabic (ar) subset from Mozilla Common Voice (MCV) 17.0. It has been specifically prepared for fine-tuning conversational speech models, with a primary focus on the Seasme-CSM model architecture. The dataset consists of audio clips in WAV format (24kHz, mono) and their corresponding transcripts, along with integer speaker IDs.\nThe originalâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/MAdel121/Common-Voice-17-Arabic-for-Seasme-CSM-Finetuning.","url":"https://huggingface.co/datasets/MAdel121/Common-Voice-17-Arabic-for-Seasme-CSM-Finetuning","creator_name":"MAdel","creator_url":"https://huggingface.co/MAdel121","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["Arabic","cc0-1.0","10K - 100K","parquet","Audio"],"keywords_longer_than_N":true},
	{"name":"Common-Voice-17-Arabic-for-Seasme-CSM-Finetuning","keyword":"arabic","description":"\n\t\n\t\t\n\t\tCurated Arabic Speech Dataset for Seasme (from MCV17)\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset is a curated and preprocessed version of the Arabic (ar) subset from Mozilla Common Voice (MCV) 17.0. It has been specifically prepared for fine-tuning conversational speech models, with a primary focus on the Seasme-CSM model architecture. The dataset consists of audio clips in WAV format (24kHz, mono) and their corresponding transcripts, along with integer speaker IDs.\nThe originalâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/MAdel121/Common-Voice-17-Arabic-for-Seasme-CSM-Finetuning.","url":"https://huggingface.co/datasets/MAdel121/Common-Voice-17-Arabic-for-Seasme-CSM-Finetuning","creator_name":"MAdel","creator_url":"https://huggingface.co/MAdel121","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["Arabic","cc0-1.0","10K - 100K","parquet","Audio"],"keywords_longer_than_N":true},
	{"name":"llm-censorship","keyword":"arabic","description":"\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset measures soft censorship (selective omission of information) in large language models (LLMs). It contains responses from 14 state-of-the-art LLMs from different regions (Western countries, China, and Russia) when prompted about political figures in all six official UN languages.\nThe dataset is designed to provide insights into how and when LLMs refuse to provide information or selectively omit details when discussingâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/aida-ugent/llm-censorship.","url":"https://huggingface.co/datasets/aida-ugent/llm-censorship","creator_name":"Ghent University Artificial Intelligence & Data Analytics Group","creator_url":"https://huggingface.co/aida-ugent","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["English","Arabic","Spanish","Russian","French"],"keywords_longer_than_N":true},
	{"name":"Arabic-books-and-research-dataset","keyword":"arabic","description":"\n\t\n\t\t\n\t\tArabic reserach and books dataset (ARABD)\n\t\n\nThis dataset is an extracted cleaned text from more than 60K word files with unique arabic texts never published before.\n\n\t\n\t\t\n\t\tDataset diversity\n\t\n\nthe dataset is diverse from all kind of islamic research: [feqh, hadeeth, tafseer, tahqeeq, ... etc], from new written research to a manuscirpts.\n\n\t\n\t\t\n\t\tdataset size\n\t\n\nthe dataset was more than 11GB but after cleaning (pre-processing) it becase a straight 10GB with less noisy chars.â€¦ See the full description on the dataset page: https://huggingface.co/datasets/riotu-lab/Arabic-books-and-research-dataset.","url":"https://huggingface.co/datasets/riotu-lab/Arabic-books-and-research-dataset","creator_name":"Robotics and Interne-of-Things","creator_url":"https://huggingface.co/riotu-lab","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-generation","Arabic","mit","10K - 100K","csv"],"keywords_longer_than_N":true},
	{"name":"arabic_countbench","keyword":"arabic","description":"ahmedheakl/arabic_countbench dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/ahmedheakl/arabic_countbench","creator_name":"Ahmed Heakl","creator_url":"https://huggingface.co/ahmedheakl","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["Arabic","mit","< 1K","parquet","Image"],"keywords_longer_than_N":true},
	{"name":"ARAFA","keyword":"arabic","description":"\n\t\n\t\t\n\t\tARAFA: An LLM Generated Arabic Fact Checking Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nCreators:  \n\nKhalil, Christophe (Researcher)\n\nContributors:  \n\nSupervisors:  \nElbassuoni, Shady  \nAssaf, Rida\n\n\n\nAbstract:Automatic fact-checking in Arabic is challenging due to the lack of large-scale datasets and resources. ARAFA is a large-scale Modern Standard Arabic dataset for fact-checking, constructed using a fully automated framework leveraging large languageâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/ChristopheKhalil/ARAFA.","url":"https://huggingface.co/datasets/ChristopheKhalil/ARAFA","creator_name":"christophe Khalil","creator_url":"https://huggingface.co/ChristopheKhalil","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","text-generation","question-answering","sentence-similarity","Arabic"],"keywords_longer_than_N":true},
	{"name":"ARAFA","keyword":"arabic","description":"\n\t\n\t\t\n\t\tARAFA: An LLM Generated Arabic Fact Checking Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nCreators:  \n\nKhalil, Christophe (Researcher)\n\nContributors:  \n\nSupervisors:  \nElbassuoni, Shady  \nAssaf, Rida\n\n\n\nAbstract:Automatic fact-checking in Arabic is challenging due to the lack of large-scale datasets and resources. ARAFA is a large-scale Modern Standard Arabic dataset for fact-checking, constructed using a fully automated framework leveraging large languageâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/ChristopheKhalil/ARAFA.","url":"https://huggingface.co/datasets/ChristopheKhalil/ARAFA","creator_name":"christophe Khalil","creator_url":"https://huggingface.co/ChristopheKhalil","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","text-generation","question-answering","sentence-similarity","Arabic"],"keywords_longer_than_N":true},
	{"name":"Conversational_AOU_tutor_dataset","keyword":"arabic","description":"astroa7m/Conversational_AOU_tutor_dataset dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/astroa7m/Conversational_AOU_tutor_dataset","creator_name":"Ahmed Samir","creator_url":"https://huggingface.co/astroa7m","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-generation","Arabic","English","mit","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"m-ArenaHard","keyword":"arabic","description":"\n\t\n\t\t\n\t\tDataset Card for m-ArenaHard\n\t\n\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\nThe m-ArenaHard dataset is a multilingual LLM evaluation set. This dataset was created by translating the prompts from the originally English-only LMarena (formerly LMSYS) arena-hard-auto-v0.1 test dataset using Google Translate API v3 to 22 languages. The original English-only prompts were created by Li et al. (2024) and consist of 500 challenging user queries sourced from Chatbot Arena. The authors show that these can be usedâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/CohereLabs/m-ArenaHard.","url":"https://huggingface.co/datasets/CohereLabs/m-ArenaHard","creator_name":"Cohere Labs","creator_url":"https://huggingface.co/CohereLabs","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["English","French","German","Spanish","Italian"],"keywords_longer_than_N":true},
	{"name":"kurage_training_data","keyword":"arabic","description":"lightblue/kurage_training_data dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/lightblue/kurage_training_data","creator_name":"Lightblue KK.","creator_url":"https://huggingface.co/lightblue","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["Arabic","English","Spanish","Hindi","Indonesian"],"keywords_longer_than_N":true},
	{"name":"arabic-audio-dataset","keyword":"arabic","description":"\n\t\n\t\t\n\t\tArabic Audio Dataset\n\t\n\n*This dataset contains high-quality (â€œA-gradeâ€) data. It has been carefully curated, cleaned, and verified to ensure accuracy, completeness, and consistency, making it suitable for high-stakes or production-grade model training.\n\n\t\n\t\t\n\t\tContact\n\t\n\nFor queries or collaborations related to this dataset, contact:\n    - anoushka@kgen.io\n    - abhishek.vadapalli@kgen.io\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\n\nTask Categories: Speech Emotion Recognition (SER)\nSupported Tasks:â€¦ See the full description on the dataset page: https://huggingface.co/datasets/Kratos-AI/arabic-audio-dataset.","url":"https://huggingface.co/datasets/Kratos-AI/arabic-audio-dataset","creator_name":"KratosAI","creator_url":"https://huggingface.co/Kratos-AI","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["audio-classification","Arabic","cc-by-4.0","< 1K","soundfolder"],"keywords_longer_than_N":true},
	{"name":"arabic-audio-dataset","keyword":"arabic","description":"\n\t\n\t\t\n\t\tArabic Audio Dataset\n\t\n\n*This dataset contains high-quality (â€œA-gradeâ€) data. It has been carefully curated, cleaned, and verified to ensure accuracy, completeness, and consistency, making it suitable for high-stakes or production-grade model training.\n\n\t\n\t\t\n\t\tContact\n\t\n\nFor queries or collaborations related to this dataset, contact:\n    - anoushka@kgen.io\n    - abhishek.vadapalli@kgen.io\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\n\nTask Categories: Speech Emotion Recognition (SER)\nSupported Tasks:â€¦ See the full description on the dataset page: https://huggingface.co/datasets/Kratos-AI/arabic-audio-dataset.","url":"https://huggingface.co/datasets/Kratos-AI/arabic-audio-dataset","creator_name":"KratosAI","creator_url":"https://huggingface.co/Kratos-AI","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["audio-classification","Arabic","cc-by-4.0","< 1K","soundfolder"],"keywords_longer_than_N":true},
	{"name":"code-switching-tokenizer-robustness","keyword":"arabic","description":"\n\t\n\t\t\n\t\tCode-Switching Dataset for Tokenizer Robustness Analysis\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset is designed for tokenizer robustness testing in multilingual and code-switching contexts. It contains identical content expressed across 16 different language variants, including pure English and 15 English-X code-switching pairs, allowing researchers to isolate tokenization effects from semantic differences when evaluating language models.\n\n\t\n\t\t\n\t\tPurpose\n\t\n\n\nTokenizer Comparison:â€¦ See the full description on the dataset page: https://huggingface.co/datasets/Malikeh1375/code-switching-tokenizer-robustness.","url":"https://huggingface.co/datasets/Malikeh1375/code-switching-tokenizer-robustness","creator_name":"Malikeh Ehghaghi","creator_url":"https://huggingface.co/Malikeh1375","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","text-classification","multilingual","English","Russian"],"keywords_longer_than_N":true},
	{"name":"General_Facts_in_English_Arabic_Egyptian_Arabic","keyword":"arabic","description":"\n\t\n\t\t\n\t\tðŸŒ World Facts in English, Arabic & Egyptian Arabic (v1.0) (Categorized)\n\t\n\nThe World Facts General Knowledge Dataset (v1.0) is a high-quality, human-reviewed Q&A resource by Miscovery. It features general facts categorized across 50+ knowledge domains, provided in three languages:\n\nðŸŒ English\nðŸ‡¸ðŸ‡¦ Modern Standard Arabic (MSA)\nðŸ‡ªðŸ‡¬ Egyptian Arabic (Dialect)\n\nEach entry includes:\n\nThe question and answer\nA category and sub-category\nLanguage tag (en, ar, ar_eg)\nBasic metadata: question &â€¦ See the full description on the dataset page: https://huggingface.co/datasets/miscovery/General_Facts_in_English_Arabic_Egyptian_Arabic.","url":"https://huggingface.co/datasets/miscovery/General_Facts_in_English_Arabic_Egyptian_Arabic","creator_name":"Miscovery","creator_url":"https://huggingface.co/miscovery","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["question-answering","translation","text-generation","fill-mask","English"],"keywords_longer_than_N":true},
	{"name":"saudi_up","keyword":"arabic","description":"\n\t\n\t\t\n\t\tDataset Card for Dataset Name\n\t\n\n\n\nThis dataset card aims to be a base template for new datasets. It has been generated using this raw template.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\n\n\n\n\n\nCurated by: [More Information Needed]\nFunded by [optional]: [More Information Needed]\nShared by [optional]: [More Information Needed]\nLanguage(s) (NLP): [More Information Needed]\nLicense: [More Information Needed]\n\n\n\t\n\t\t\n\t\tDataset Sources [optional]\n\t\n\n\n\n\nRepository: [Moreâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/yeeaee/saudi_up.","url":"https://huggingface.co/datasets/yeeaee/saudi_up","creator_name":"yazeed albadawy","creator_url":"https://huggingface.co/yeeaee","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","Arabic","apache-2.0","1M - 10M","parquet"],"keywords_longer_than_N":true},
	{"name":"rework_undl_text","keyword":"arabic","description":"\n\t\n\t\t\n\t\tè”åˆå›½æ•°å­—å›¾ä¹¦é¦†ODSé‡Œçˆ¬å‡ºæ¥çš„å¹³è¡Œè¯­æ–™ Parallel Corpus from United Nations Digital Library ODSï¼ˆ2000-2023ï¼‰\n\t\n\næ•°æ®æºé“¾æŽ¥ï¼ˆç½‘ç«™é€»è¾‘æ¯”èµ·çˆ¬å–è¿™äº›æ•°æ®æ—¶å·²ç»é‡æž„æ›´æ–°ï¼Œå¯èƒ½ä¼šæœ‰ä¸ä¸€è‡´çš„æƒ…å†µï¼‰ï¼šhttps://search.un.org/search?collection=ods&currentPageNumber=1&q=*&row=10&sort=relevance\npandocè½¬docxå‡ºçš„æºæ–‡æœ¬ï¼Œæ‰€ç”¨å‘½ä»¤ä¸ºï¼špandoc -i {filepath} -t plain -o {outpath} --strip-comments\nè¿™äº›æ–‡æœ¬å¯èƒ½ä»éœ€ä¸€å®šçš„æ­¥éª¤åŽ»å™ªï¼Œæ¯”å¦‚åŽ»æŽ‰å…¨æ˜¯æ¨ªçº¿çš„åˆ†éš”ç¬¦ã€åŽ»æŽ‰è¡¨æ ¼å…ƒç´ ï¼Œæ‰èƒ½ç”¨äºŽåŽç»­çš„ç¿»è¯‘åŠå¯¹é½æ­¥éª¤\næ—§ç‰ˆæ•°æ®é“¾æŽ¥ https://huggingface.co/datasets/bot-yaya/undl_text \nå› ä¸ºæ—§ç‰ˆå‚æ•°ä¸å½“ï¼Œå¤„ç†çš„æ—¶å€™ä¸¢æŽ‰äº†ä¸€éƒ¨åˆ†æ•°æ®ï¼Œæ‰€ä»¥é‡åšäº†ä¸€ä»½é‡æ–°ä¸Šä¼ ï¼Œå»ºè®®æ˜¯ä¸‹è½½ä½¿ç”¨è¿™ä»½ï¼Œè€Œä¸æ˜¯æ—§ç‰ˆ\n","url":"https://huggingface.co/datasets/bot-yaya/rework_undl_text","creator_name":"yaya","creator_url":"https://huggingface.co/bot-yaya","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["translation","Arabic","English","French","Spanish"],"keywords_longer_than_N":true},
	{"name":"Arabic-Dataset-for-Commonsense-Validationion","keyword":"arabic","description":"\n\t\n\t\t\n\t\tDataset Card for \"Arabic-Dataset-for-Commonsense-Validationion\"\n\t\n\n\n\t\n\t\t\n\t\tPaper:\n\t\n\nTawalbeh, Saja, and Mohammad Al-Smadi. \"Is this sentence valid? an arabic dataset for commonsense validation.\" arXiv preprint arXiv:2008.10873 (2020).\n","url":"https://huggingface.co/datasets/asas-ai/Arabic-Dataset-for-Commonsense-Validationion","creator_name":"ASAS AI","creator_url":"https://huggingface.co/asas-ai","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","Arabic","cc0-1.0","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"arabic_myanmar_quran_voices","keyword":"arabic","description":"\n\t\n\t\t\n\t\tðŸ“– Arabic-Myanmar Quran Voice Dataset\n\t\n\n\n\t\n\t\t\n\t\tðŸ•Œ Overview\n\t\n\nThis dataset contains high-quality MP3 audio recordings of the entire Holy Qurâ€™an with:\n\nArabic recitation of each verse\nFollowed immediately by its Myanmar (Burmese) translation\n\nIt is the first complete Arabic-Myanmar Quran audio interpretation of its kind publicly released in Myanmar. The goal is to make the Qurâ€™an more accessible to:\n\nElderly persons\nBlind or visually impaired people\nMyanmar speakers who wish toâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/freococo/arabic_myanmar_quran_voices.","url":"https://huggingface.co/datasets/freococo/arabic_myanmar_quran_voices","creator_name":"Wynn","creator_url":"https://huggingface.co/freococo","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["audio-classification","audio-to-audio","automatic-speech-recognition","text-to-speech","human-annotated"],"keywords_longer_than_N":true},
	{"name":"arabic_myanmar_quran_voices","keyword":"arabic","description":"\n\t\n\t\t\n\t\tðŸ“– Arabic-Myanmar Quran Voice Dataset\n\t\n\n\n\t\n\t\t\n\t\tðŸ•Œ Overview\n\t\n\nThis dataset contains high-quality MP3 audio recordings of the entire Holy Qurâ€™an with:\n\nArabic recitation of each verse\nFollowed immediately by its Myanmar (Burmese) translation\n\nIt is the first complete Arabic-Myanmar Quran audio interpretation of its kind publicly released in Myanmar. The goal is to make the Qurâ€™an more accessible to:\n\nElderly persons\nBlind or visually impaired people\nMyanmar speakers who wish toâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/freococo/arabic_myanmar_quran_voices.","url":"https://huggingface.co/datasets/freococo/arabic_myanmar_quran_voices","creator_name":"Wynn","creator_url":"https://huggingface.co/freococo","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["audio-classification","audio-to-audio","automatic-speech-recognition","text-to-speech","human-annotated"],"keywords_longer_than_N":true},
	{"name":"Ayoub-AR_EN-Public-Phone-Audio-Dataset","keyword":"arabic","description":"\n\t\n\t\t\n\t\tØ¨Ø³Ù… Ø§Ù„Ù„Ù‡\n\t\n\nThis dataset text data is derived from here.\nAudio files are gathered by the help of Arabic team: Planet Blind Tech (PBt).\nThank you Shams Eddin (from Algeria).\n","url":"https://huggingface.co/datasets/mah92/Ayoub-AR_EN-Public-Phone-Audio-Dataset","creator_name":"ali.mahmoudi","creator_url":"https://huggingface.co/mah92","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["Arabic","English","cc0-1.0","ðŸ‡ºðŸ‡¸ Region: US"],"keywords_longer_than_N":false},
	{"name":"eg-legal-qa","keyword":"arabic","description":"\n\t\n\t\t\n\t\tArabic Legal Dataset - Legal Question-Answering\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nQuestion-answering dataset for Arabic legal texts with instruction-following format for training conversational AI models.\nThis dataset contains 5,230 examples of qa data derived from Egyptian legal texts, including criminal law, civil law, procedural law, and personal status law. The dataset is designed for training and evaluating Arabic legal AI models.\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\n\nLanguage: Arabicâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fr3on/eg-legal-qa.","url":"https://huggingface.co/datasets/fr3on/eg-legal-qa","creator_name":"Ahmed Mardi","creator_url":"https://huggingface.co/fr3on","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["question-answering","text-generation","Arabic","apache-2.0","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"eg-legal-qa","keyword":"arabic","description":"\n\t\n\t\t\n\t\tArabic Legal Dataset - Legal Question-Answering\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nQuestion-answering dataset for Arabic legal texts with instruction-following format for training conversational AI models.\nThis dataset contains 5,230 examples of qa data derived from Egyptian legal texts, including criminal law, civil law, procedural law, and personal status law. The dataset is designed for training and evaluating Arabic legal AI models.\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\n\nLanguage: Arabicâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fr3on/eg-legal-qa.","url":"https://huggingface.co/datasets/fr3on/eg-legal-qa","creator_name":"Ahmed Mardi","creator_url":"https://huggingface.co/fr3on","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["question-answering","text-generation","Arabic","apache-2.0","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"mmmlu_lite","keyword":"arabic","description":"\n\t\n\t\t\n\t\tMMMLU-Lite\n\t\n\n\n\t\n\t\t\n\t\tIntroduction\n\t\n\nA lite version of the MMMLU dataset, which is an community version of the MMMLU dataset by OpenCompass. Due to the large size of the original dataset (about 200k questions), we have created a lite version of the dataset to make it easier to use. We sample 25 examples from each language subject in the original dataset with fixed seed to ensure reproducibility, finally we have 19950 examples in the lite version of the dataset, which is about 10% ofâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/opencompass/mmmlu_lite.","url":"https://huggingface.co/datasets/opencompass/mmmlu_lite","creator_name":"OpenCompass","creator_url":"https://huggingface.co/opencompass","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["question-answering","Arabic","Bengali","German","Spanish"],"keywords_longer_than_N":true},
	{"name":"Arabic-Summarization-Dataset-AsDs","keyword":"arabic","description":"\n\t\n\t\t\n\t\tArabic Summarization Dataset\n\t\n\nDataset Description\nThis dataset was created to address the significant gap in high-quality Arabic text summarization resources. After extensive research, we found that existing Arabic summarization datasets often suffer from poor summary quality, inconsistent formatting, or limited domain coverage. To overcome these limitations, this dataset was meticulously crafted using Google's Gemini AI model to generate high-quality, coherent summaries for Arabicâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/karimraouf/Arabic-Summarization-Dataset-AsDs.","url":"https://huggingface.co/datasets/karimraouf/Arabic-Summarization-Dataset-AsDs","creator_name":"karim raouf mostafa","creator_url":"https://huggingface.co/karimraouf","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["summarization","Arabic","mit","1K - 10K","parquet"],"keywords_longer_than_N":true},
	{"name":"aya_collection","keyword":"arabic","description":"\nThis dataset is uploaded in two places: here and additionally here as 'Aya Collection Language Split.' These datasets are identical in content but differ in structure of upload. This dataset is structured by folders split according to dataset name. The version here instead divides the Aya collection into folders split by language. We recommend you use the language split version if you are only interested in downloading data for a single or smaller set of languages, and this version if youâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/CohereLabs/aya_collection.","url":"https://huggingface.co/datasets/CohereLabs/aya_collection","creator_name":"Cohere Labs","creator_url":"https://huggingface.co/CohereLabs","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","summarization","translation","Achinese","Afrikaans"],"keywords_longer_than_N":true},
	{"name":"arabic_quran_hadith14books_cmvoice17_fleurs_mediaspeech","keyword":"arabic","description":"\n\t\n\t\t\n\t\tDataset Card for quran and hadith dataset\n\t\n\n\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\n\nArabic specialized dataset to make sure that AI is not changing our sacred scriptures in speech recognition by training and evaluating upon quran and hadith.\n\nCombining quran + magma'a el zawa'ed book of sidi Nour eldin elhaithamy author including 14 book of hadith of approximately 10,000 hadith without repititions + other existing datasets like common voice, fleurs, media speech\n\nFirst dataset to have fullâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/DrAliGomaa/arabic_quran_hadith14books_cmvoice17_fleurs_mediaspeech.","url":"https://huggingface.co/datasets/DrAliGomaa/arabic_quran_hadith14books_cmvoice17_fleurs_mediaspeech","creator_name":"arabic_speech","creator_url":"https://huggingface.co/DrAliGomaa","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","Arabic","apache-2.0","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"arabic_quran_hadith14books_cmvoice17_fleurs_mediaspeech","keyword":"arabic","description":"\n\t\n\t\t\n\t\tDataset Card for quran and hadith dataset\n\t\n\n\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\n\nArabic specialized dataset to make sure that AI is not changing our sacred scriptures in speech recognition by training and evaluating upon quran and hadith.\n\nCombining quran + magma'a el zawa'ed book of sidi Nour eldin elhaithamy author including 14 book of hadith of approximately 10,000 hadith without repititions + other existing datasets like common voice, fleurs, media speech\n\nFirst dataset to have fullâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/DrAliGomaa/arabic_quran_hadith14books_cmvoice17_fleurs_mediaspeech.","url":"https://huggingface.co/datasets/DrAliGomaa/arabic_quran_hadith14books_cmvoice17_fleurs_mediaspeech","creator_name":"arabic_speech","creator_url":"https://huggingface.co/DrAliGomaa","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","Arabic","apache-2.0","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"FineWeb2-Egyptian-Arabic","keyword":"arabic","description":"\n\t\n\t\t\n\t\tFineWeb2 Egyptian Arabic\n\t\n\n\nðŸ‡ªðŸ‡¬ This is the Egyptian Arabic Portion of The FineWeb2 Dataset.\nðŸ‡ªðŸ‡¬ This dataset contains a rich collection of text in Egyptian Arabic (ISO 639-3: arz), a widely spoken dialect within the Afro-Asiatic language family. \nðŸ‡ªðŸ‡¬ With over 439 million words and 1.4 million documents, it serves as a valuable resource for NLP development and linguistic research focused on Egyptian Arabic.\n\n\t\n\t\n\t\n\t\tPurpose of This Repository\n\t\n\nThis repository provides easyâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Omartificial-Intelligence-Space/FineWeb2-Egyptian-Arabic.","url":"https://huggingface.co/datasets/Omartificial-Intelligence-Space/FineWeb2-Egyptian-Arabic","creator_name":"Omartificial Intelligence Space","creator_url":"https://huggingface.co/Omartificial-Intelligence-Space","license_name":"Open Data Commons Attribution License v1.0","license_url":"https://scancode-licensedb.aboutcode.org/odc-by-1.0.html","language":"en","first_N":5,"first_N_keywords":["Arabic","odc-by","10M - 100M","parquet","Text"],"keywords_longer_than_N":true},
	{"name":"FineWeb2-Egyptian-Arabic","keyword":"arabic","description":"\n\t\n\t\t\n\t\tFineWeb2 Egyptian Arabic\n\t\n\n\nðŸ‡ªðŸ‡¬ This is the Egyptian Arabic Portion of The FineWeb2 Dataset.\nðŸ‡ªðŸ‡¬ This dataset contains a rich collection of text in Egyptian Arabic (ISO 639-3: arz), a widely spoken dialect within the Afro-Asiatic language family. \nðŸ‡ªðŸ‡¬ With over 439 million words and 1.4 million documents, it serves as a valuable resource for NLP development and linguistic research focused on Egyptian Arabic.\n\n\t\n\t\n\t\n\t\tPurpose of This Repository\n\t\n\nThis repository provides easyâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Omartificial-Intelligence-Space/FineWeb2-Egyptian-Arabic.","url":"https://huggingface.co/datasets/Omartificial-Intelligence-Space/FineWeb2-Egyptian-Arabic","creator_name":"Omartificial Intelligence Space","creator_url":"https://huggingface.co/Omartificial-Intelligence-Space","license_name":"Open Data Commons Attribution License v1.0","license_url":"https://scancode-licensedb.aboutcode.org/odc-by-1.0.html","language":"en","first_N":5,"first_N_keywords":["Arabic","odc-by","10M - 100M","parquet","Text"],"keywords_longer_than_N":true},
	{"name":"arocrbench_khatt","keyword":"arabic","description":"KITAB-Bench: A Comprehensive Multi-Domain Benchmark for Arabic OCR and Document Understanding\nThis dataset is designed to evaluate the performance of Arabic OCR and document understanding systems. It includes a variety of document types and tasks.\nPlease see paper & code for more information:\n\nGitHub Repository\nProject Page\narXiv Paper\n\n","url":"https://huggingface.co/datasets/ahmedheakl/arocrbench_khatt","creator_name":"Ahmed Heakl","creator_url":"https://huggingface.co/ahmedheakl","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["image-to-text","Arabic","mit","< 1K","parquet"],"keywords_longer_than_N":true},
	{"name":"arocrbench_khatt","keyword":"arabic","description":"KITAB-Bench: A Comprehensive Multi-Domain Benchmark for Arabic OCR and Document Understanding\nThis dataset is designed to evaluate the performance of Arabic OCR and document understanding systems. It includes a variety of document types and tasks.\nPlease see paper & code for more information:\n\nGitHub Repository\nProject Page\narXiv Paper\n\n","url":"https://huggingface.co/datasets/ahmedheakl/arocrbench_khatt","creator_name":"Ahmed Heakl","creator_url":"https://huggingface.co/ahmedheakl","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["image-to-text","Arabic","mit","< 1K","parquet"],"keywords_longer_than_N":true},
	{"name":"semeval-2025-task11-track-b","keyword":"arabic","description":"\n\t\n\t\t\n\t\tSemEval 2025 Task 11 - Track B Dataset\n\t\n\nThis dataset contains the data for SemEval 2025 Task 11: Bridging the Gap in Text-Based Emotion Detection - Track B, organized as language-specific configurations.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset is a multi-language, multi-label emotion classification dataset with separate configurations for each language.\n\nTotal languages: 11 standard ISO codes\nTotal examples: 47111\nSplits: train, dev, test\n\n\n\t\n\t\t\n\t\tTrack Information\n\t\n\nTrack B hasâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/vgaraujov/semeval-2025-task11-track-b.","url":"https://huggingface.co/datasets/vgaraujov/semeval-2025-task11-track-b","creator_name":"Vladimir Araujo","creator_url":"https://huggingface.co/vgaraujov","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["Amharic","Arabic","German","English","Spanish"],"keywords_longer_than_N":true},
	{"name":"Arabic-NLi-Triplet","keyword":"arabic","description":"\n\t\n\t\t\n\t\tArabic NLI Triplet\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\n\nThe Arabic Version of SNLI and MultiNLI datasets. (Triplet Subset)\nOriginally used for Natural Language Inference (NLI), \nDataset may be used for training/finetuning an embedding model for semantic textual similarity.\n\n\n\t\n\t\t\n\t\tTriplet Subset\n\t\n\n\nColumns: \"anchor\", \"positive\", \"negative\"\nColumn types: str, str, str\n\nExamples:\n{\n  \"anchor\": \"Ø´Ø®Øµ Ø¹Ù„Ù‰ Ø­ØµØ§Ù† ÙŠÙ‚ÙØ² ÙÙˆÙ‚ Ø·Ø§Ø¦Ø±Ø© Ù…Ø¹Ø·Ù„Ø©\",\n  \"positive\": \"Ø´Ø®Øµ ÙÙŠ Ø§Ù„Ù‡ÙˆØ§Ø¡ Ø§Ù„Ø·Ù„Ù‚ØŒ Ø¹Ù„Ù‰ Ø­ØµØ§Ù†.\",\n  \"negative\":â€¦ See the full description on the dataset page: https://huggingface.co/datasets/LLMXperts/Arabic-NLi-Triplet.","url":"https://huggingface.co/datasets/LLMXperts/Arabic-NLi-Triplet","creator_name":"LLMXperts","creator_url":"https://huggingface.co/LLMXperts","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["sentence-similarity","Arabic","apache-2.0","100K - 1M","csv"],"keywords_longer_than_N":true},
	{"name":"mHumanEval-Benchmark","keyword":"arabic","description":"\n\n\n\t\n\t\t\n\t\tðŸ”· Accepted in NAACL Proceedings (2025) ðŸ”·\n\t\n\n\n\n\n\n  \n    \n      \n        \n          \n        \n      \n      \n        \n          \n        \n      \n      \n        \n          \n        \n      \n    \n  \n\n\n\n\n\n  \n\n\t\n\t\n\t\n\t\tmHumanEval\n\t\n\nThe mHumanEval benchmark is curated based on prompts from the original HumanEval ðŸ“š [Chen et al., 2021]. It includes a total of 33,456 prompts for Python, and 836,400 in total - significantly expanding from the original 164. \n\n\n\t\n\t\t\n\t\tQuick Start\n\t\n\n  Detailedâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/md-nishat-008/mHumanEval-Benchmark.","url":"https://huggingface.co/datasets/md-nishat-008/mHumanEval-Benchmark","creator_name":"Nishat Raihan","creator_url":"https://huggingface.co/md-nishat-008","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["Afar","Abkhaz","Avestan","Afrikaans","Akan"],"keywords_longer_than_N":true},
	{"name":"aya_redteaming_consitutional","keyword":"arabic","description":"\n\t\n\t\t\n\t\tDataset Card for Aya Red-teaming-constiutional\n\t\n\nThis dataset is an extended version of CohereForAI/aya_redteaming, with added targeted constitutional principles, aiming to allow multilingual constitional AI using the Aya Red team prompts.\nWe take the Anthropic constitutional principles and manually cut out the existing harms so that we can dynamically insert harms specific to our red team prompts.\nThere are 16 critiques and 16 revisions for each red-team prompt, each targeting theâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/pbevan11/aya_redteaming_consitutional.","url":"https://huggingface.co/datasets/pbevan11/aya_redteaming_consitutional","creator_name":"Peter J. Bevan","creator_url":"https://huggingface.co/pbevan11","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["English","Hindi","French","Spanish","Arabic"],"keywords_longer_than_N":true},
	{"name":"EGY2K","keyword":"arabic","description":"rahafvii/EGY2K dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/rahafvii/EGY2K","creator_name":"xx","creator_url":"https://huggingface.co/rahafvii","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-to-speech","text-to-audio","Arabic","apache-2.0","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"Arabic_Audio_Deepfake","keyword":"arabic","description":"\n\t\n\t\t\n\t\tArAD Dataset (Arabic Audio DeepFake Dataset)\n\t\n\nDataset SummaryThis dataset contains Arabic deepfake audio samples, focusing mainly on Levantine dialect with some examples in Standard Arabic. It was created using the RVC v2 framework, fine-tuned on a custom dataset of multi-dialect Arabic speech. The goal is to simulate real-world deepfake audio attacks by generating synthetic speech from actual recordings and voice messages.\nOne of the first datasets to include real-world deepfakeâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/DeepFake-Audio-Rangers/Arabic_Audio_Deepfake.","url":"https://huggingface.co/datasets/DeepFake-Audio-Rangers/Arabic_Audio_Deepfake","creator_name":"DeepFake Audio Rangers","creator_url":"https://huggingface.co/DeepFake-Audio-Rangers","license_name":"Open Data Commons Attribution License v1.0","license_url":"https://scancode-licensedb.aboutcode.org/odc-by-1.0.html","language":"en","first_N":5,"first_N_keywords":["audio-to-audio","audio-classification","automatic-speech-recognition","Arabic","odc-by"],"keywords_longer_than_N":true},
	{"name":"biblenlp-corpus-mmteb","keyword":"standard arabic","description":"This dataset pre-computes all English-centric directions from bible-nlp/biblenlp-corpus, and as a result loading is significantly faster.\nLoading example:\n>>> from datasets import load_dataset\n>>> dataset = load_dataset(\"davidstap/biblenlp-corpus-mmteb\", \"eng-arb\", trust_remote_code=True)\n>>> dataset\nDatasetDict({\n    train: Dataset({\n        features: ['eng', 'arb'],\n        num_rows: 28723\n    })\n    validation: Dataset({\n        features: ['eng', 'arb'],\n        num_rows: 1578\n    })â€¦ See the full description on the dataset page: https://huggingface.co/datasets/davidstap/biblenlp-corpus-mmteb.","url":"https://huggingface.co/datasets/davidstap/biblenlp-corpus-mmteb","creator_name":"David Stap","creator_url":"https://huggingface.co/davidstap","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["no-annotation","expert-generated","translation","multilingual","Arifama-Miniafia"],"keywords_longer_than_N":true},
	{"name":"OGC_Energy_Arabic","keyword":"arabic","description":"\n\t\n\t\t\n\t\tOGC_Energy_Arabic - Overview\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nOGC_Energy_Arabic is a curated multimodal dataset focused on Arabic energy sector documents, including reports, financial statements, technical documentation, and industry analyses. It combines text and image data extracted from real energy-related PDFs to support tasks such as RAG DSE, question answering, document search, and vision-language model training in Arabic.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\tDataset Creation\n\t\n\nThisâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/racineai/OGC_Energy_Arabic.","url":"https://huggingface.co/datasets/racineai/OGC_Energy_Arabic","creator_name":"racine.ai","creator_url":"https://huggingface.co/racineai","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["visual-document-retrieval","visual-question-answering","text-retrieval","French","Arabic"],"keywords_longer_than_N":true},
	{"name":"OGC_Energy_Arabic","keyword":"arabic","description":"\n\t\n\t\t\n\t\tOGC_Energy_Arabic - Overview\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nOGC_Energy_Arabic is a curated multimodal dataset focused on Arabic energy sector documents, including reports, financial statements, technical documentation, and industry analyses. It combines text and image data extracted from real energy-related PDFs to support tasks such as RAG DSE, question answering, document search, and vision-language model training in Arabic.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\tDataset Creation\n\t\n\nThisâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/racineai/OGC_Energy_Arabic.","url":"https://huggingface.co/datasets/racineai/OGC_Energy_Arabic","creator_name":"racine.ai","creator_url":"https://huggingface.co/racineai","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["visual-document-retrieval","visual-question-answering","text-retrieval","French","Arabic"],"keywords_longer_than_N":true},
	{"name":"LLaVA-Pretrain-AR","keyword":"arabic","description":"\n\t\n\t\t\n\t\tAR LLaVA Pretraining Dataset\n\t\n\nOriginal LLaVA Pretraining Datasettranslated to Arabic.\n","url":"https://huggingface.co/datasets/KickItLikeShika/LLaVA-Pretrain-AR","creator_name":"Ahmed Khaled","creator_url":"https://huggingface.co/KickItLikeShika","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-generation","Arabic","mit","100K<n<1M","ðŸ‡ºðŸ‡¸ Region: US"],"keywords_longer_than_N":false},
	{"name":"gulf_train_set","keyword":"arabic","description":"Pre-processed Gulf train partition from the MASC-dataset:\nMohammad Al-Fetyani, Muhammad Al-Barham, Gheith Abandah, Adham Alsharkawi, Maha Dawas, August 18, 2021, \"MASC: Massive Arabic Speech Corpus\", IEEE Dataport, doi: https://dx.doi.org/10.21227/e1qb-jv46.\n","url":"https://huggingface.co/datasets/otozz/gulf_train_set","creator_name":"Ã–mer","creator_url":"https://huggingface.co/otozz","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["Arabic","cc-by-4.0","10K - 100K","parquet","Datasets"],"keywords_longer_than_N":true},
	{"name":"toxi-text-3M","keyword":"arabic","description":"This is a large multilingual toxicity dataset with 3M rows of text data from 55 natural languages, all of which are written/sent by humans, not machine translation models.\nThe preprocessed training data alone consists of 2,880,667 rows of comments, tweets, and messages. Among these rows, 416,529 are classified as toxic, while the remaining 2,463,773 are considered neutral. Below is a table to illustrate the data composition:\n\n\t\n\t\t\n\nToxic\nNeutral\nTotal\n\n\n\t\t\nmultilingual-train-deduplicated.csvâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/FredZhang7/toxi-text-3M.","url":"https://huggingface.co/datasets/FredZhang7/toxi-text-3M","creator_name":"Fred Zhang","creator_url":"https://huggingface.co/FredZhang7","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","zero-shot-classification","Arabic","Spanish","Panjabi"],"keywords_longer_than_N":true},
	{"name":"orca_dpo_pairs","keyword":"arabic","description":"\n    \n\n\nmLLM IMPLEMENTATION OF Intel/orca_dpo_pairs.\nLANGUAGES:\nARABIC\nCHINESE\nFRENCH\nGERMAN\nRUSSIAN\nSPANISH\nTURKISH\n(WIP)\n","url":"https://huggingface.co/datasets/multilingual/orca_dpo_pairs","creator_name":"mLLM multilingual","creator_url":"https://huggingface.co/multilingual","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","Arabic","Chinese","German","French"],"keywords_longer_than_N":true},
	{"name":"svq","keyword":"arabic","description":"\n\t\n\t\t\n\t\tSimple Voice Questions\n\t\n\nSimple Voice Questions (SVQ) is a set of short audio questions recorded in 26 locales across 17 languages under multiple audio conditions.\n\n\t\n\t\t\n\t\tData Collection\n\t\n\nSpeakers were presented with recording instructions specifying the recording environment and text query to be recorded.\nThey recorded using their own phones or tablets under four conditions:\n\nclean: Record in quiet environment\nbackground speech noise: Record while audio from sources like podcastsâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/google/svq.","url":"https://huggingface.co/datasets/google/svq","creator_name":"Google","creator_url":"https://huggingface.co/google","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":null,"first_N":5,"first_N_keywords":["question-answering","automatic-speech-recognition","Arabic","Bengali","English"],"keywords_longer_than_N":true},
	{"name":"arabic_dialects_question_and_answer","keyword":"arabic","description":"Data Content\nThe file provided: Q/A Reasoning dataset\ncontains the following columns:\n\n\nID # : Denotes the reference ID for:\na. Question\nb. Answer to the question\nc. Hint\nd. Reasoning\ne. Word count for items a to d above\nDialects: Contains the following dialects in separate columns:\na. English\nb. MSA\nc. Emirati\nd. Egyptian\ne. Levantine Syria\nf. Levantine Jordan\ng. Levantine Palestine\nh. Levantine Lebanon\nData Generation Process\nThe following are the steps that were followed to curate the data:â€¦ See the full description on the dataset page: https://huggingface.co/datasets/CNTXTAI0/arabic_dialects_question_and_answer.","url":"https://huggingface.co/datasets/CNTXTAI0/arabic_dialects_question_and_answer","creator_name":"CNTXT AI","creator_url":"https://huggingface.co/CNTXTAI0","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["question-answering","text-generation","text2text-generation","Arabic","English"],"keywords_longer_than_N":true},
	{"name":"arabic_dialects_question_and_answer","keyword":"arabic","description":"Data Content\nThe file provided: Q/A Reasoning dataset\ncontains the following columns:\n\n\nID # : Denotes the reference ID for:\na. Question\nb. Answer to the question\nc. Hint\nd. Reasoning\ne. Word count for items a to d above\nDialects: Contains the following dialects in separate columns:\na. English\nb. MSA\nc. Emirati\nd. Egyptian\ne. Levantine Syria\nf. Levantine Jordan\ng. Levantine Palestine\nh. Levantine Lebanon\nData Generation Process\nThe following are the steps that were followed to curate the data:â€¦ See the full description on the dataset page: https://huggingface.co/datasets/CNTXTAI0/arabic_dialects_question_and_answer.","url":"https://huggingface.co/datasets/CNTXTAI0/arabic_dialects_question_and_answer","creator_name":"CNTXT AI","creator_url":"https://huggingface.co/CNTXTAI0","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["question-answering","text-generation","text2text-generation","Arabic","English"],"keywords_longer_than_N":true},
	{"name":"mirage-bench-instruct","keyword":"arabic","description":"\n\t\n\t\t\n\t\tMIRAGE-Bench (Instruct)\n\t\n\nThis dataset contains the structured RAG outputs for queries in the train split of MIRAGE-Bench (or MIRACL) for 16 languages for five models:\n\ngpt-4o-azure                          (GPT-4o using Azure API)\nmeta-llama/Meta-Llama-3-70B-Instruct  (Llama-3-70B-Instruct using Anyscale API)\nmistralai/Mixtral-8x22B-Instruct-v0.1 (Mixtral-8x22B-Instruct using Anyscale API)\nmeta-llama/Meta-Llama-3-8B-Instruct   (Llama-3-8B-Instruct using vLLM)â€¦ See the full description on the dataset page: https://huggingface.co/datasets/nthakur/mirage-bench-instruct.","url":"https://huggingface.co/datasets/nthakur/mirage-bench-instruct","creator_name":"Nandan Thakur","creator_url":"https://huggingface.co/nthakur","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["sentence-similarity","Arabic","Bengali","English","Spanish"],"keywords_longer_than_N":true},
	{"name":"SARD-Extended","keyword":"arabic","description":"\n\t\n\t\t\n\t\tSARD: Synthetic Arabic Recognition Dataset\n\t\n\n\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nSARD (Synthetic Arabic Recognition Dataset) is a large-scale, synthetically generated dataset designed for training and evaluating Optical Character Recognition (OCR) models for Arabic text. This dataset addresses the critical need for comprehensive Arabic text recognition resources by providing controlled, diverse, and scalable training data that simulates real-world book layouts.\n\n\t\n\t\t\n\t\tKey Features\n\t\n\n\nMassiveâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/riotu-lab/SARD-Extended.","url":"https://huggingface.co/datasets/riotu-lab/SARD-Extended","creator_name":"Robotics and Interne-of-Things","creator_url":"https://huggingface.co/riotu-lab","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["image-to-text","Arabic","apache-2.0","ðŸ‡ºðŸ‡¸ Region: US","dataset"],"keywords_longer_than_N":true},
	{"name":"SARD-Extended","keyword":"arabic","description":"\n\t\n\t\t\n\t\tSARD: Synthetic Arabic Recognition Dataset\n\t\n\n\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nSARD (Synthetic Arabic Recognition Dataset) is a large-scale, synthetically generated dataset designed for training and evaluating Optical Character Recognition (OCR) models for Arabic text. This dataset addresses the critical need for comprehensive Arabic text recognition resources by providing controlled, diverse, and scalable training data that simulates real-world book layouts.\n\n\t\n\t\t\n\t\tKey Features\n\t\n\n\nMassiveâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/riotu-lab/SARD-Extended.","url":"https://huggingface.co/datasets/riotu-lab/SARD-Extended","creator_name":"Robotics and Interne-of-Things","creator_url":"https://huggingface.co/riotu-lab","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["image-to-text","Arabic","apache-2.0","ðŸ‡ºðŸ‡¸ Region: US","dataset"],"keywords_longer_than_N":true},
	{"name":"NOVA-63","keyword":"arabic","description":"\n\t\n\t\n\t\n\t\tWe released this dataset under the MIT License. This means that anyone is free to use, copy, modify, distribute, and reuse our data, provided that the original copyright notice and license information are retained.\nThis work is jointly completed by PKU & Alibaba Group. The dataset is currently under review. Please be patient. We also hope this dataset can help more partners/colleagues in the community.\nTo ensure the validity and fairness of the benchmark evaluation, we explicitlyâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/zjy1298/NOVA-63.","url":"https://huggingface.co/datasets/zjy1298/NOVA-63","creator_name":"Zhang","creator_url":"https://huggingface.co/zjy1298","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":null,"first_N":5,"first_N_keywords":["Arabic","Chinese","English","French","Spanish"],"keywords_longer_than_N":true},
	{"name":"Bully.tn","keyword":"arabic","description":"\n\t\n\t\t\n\t\tDataset Card for Dataset Name\n\t\n\n\n\nCyberbullying, a type of harassment meant to make victims continuously disparage themselves, distance themselves from others, or even commit suicide, is one issue brought \non by the increasing usage of social media worldwide. \nIt is getting more and more crucial to stop this problem from spreading on social media. \nIntelligent detection requires gathering the resources needed to understand and recognize the many types of harmful communications. \nTheâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/FerielBENFRAJ/Bully.tn.","url":"https://huggingface.co/datasets/FerielBENFRAJ/Bully.tn","creator_name":"Feriel BenFraj","creator_url":"https://huggingface.co/FerielBENFRAJ","license_name":"Academic Free License v3.0","license_url":"https://choosealicense.com/licenses/afl-3.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","feature-extraction","zero-shot-classification","Arabic","afl-3.0"],"keywords_longer_than_N":true},
	{"name":"mc-translation","keyword":"arabic","description":"This dataset contains professional human translations from OpenAI's MMMLU dataset, repurposed to train translation models that can help translate future evaluation datasets.\n\n\t\n\t\t\n\t\tWhy This Dataset?\n\t\n\nTranslation of evaluation benchmarks is a critical but challenging task. While automated translations may introduce errors or biases, professional human translations are expensive and time-consuming. This dataset leverages existing professional translations (MMMLU) to train specializedâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/efederici/mc-translation.","url":"https://huggingface.co/datasets/efederici/mc-translation","creator_name":"Edoardo Federici","creator_url":"https://huggingface.co/efederici","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["translation","English","Swahili","Spanish","German"],"keywords_longer_than_N":true},
	{"name":"1milion_token_EGY_songs","keyword":"arabic","description":"HeshamHaroon/1milion_token_EGY_songs dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/HeshamHaroon/1milion_token_EGY_songs","creator_name":"Hesham Haroon","creator_url":"https://huggingface.co/HeshamHaroon","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","Arabic","apache-2.0","1K - 10K","parquet"],"keywords_longer_than_N":true},
	{"name":"AR-AES","keyword":"arabic","description":"ðŸ“Œ  AR-AES: Arabic Automated Essay Scoring Dataset\nThe AR-AES dataset is the first publicly available resource designed to support research in Automated Essay Scoring (AES) for the Arabic language. It includes 2,046 manually\ngraded essay responses collected from undergraduate students at Umm Al-Qura University in Makkah, Saudi Arabia, across a range of academic disciplines and essay types.\nEach essay has been independently annotated by two human graders using structured rubrics, enabling theâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Rnghazawi-NLP/AR-AES.","url":"https://huggingface.co/datasets/Rnghazawi-NLP/AR-AES","creator_name":"Rayed Ghazawi","creator_url":"https://huggingface.co/Rnghazawi-NLP","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","Arabic","cc-by-4.0","arxiv:2407.11212","ðŸ‡ºðŸ‡¸ Region: US"],"keywords_longer_than_N":false},
	{"name":"FineWeb2-North-Levantine-Arabic","keyword":"arabic","description":"\n\t\n\t\t\n\t\tFineWeb2 North Levantine Arabic\n\t\n\n\nðŸ‡±ðŸ‡§ This is the  North Levantine Arabic Portion of The FineWeb2 Dataset.\nðŸ‡¸ðŸ‡© The North Levantine Arabic, represented by the ISO 639-3 code apc, is a member of the Afro-Asiatic language family and utilizes the Arabic script. \nðŸ‡¯ðŸ‡´ Known within subsets as apc_Arab, this language boasts an extensive corpus of over ** 221K rows**.\n\n\t\n\t\n\t\n\t\tPurpose of This Repository\n\t\n\nThis repository provides easy access to the Arabic portion -  North Levantineof theâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Omartificial-Intelligence-Space/FineWeb2-North-Levantine-Arabic.","url":"https://huggingface.co/datasets/Omartificial-Intelligence-Space/FineWeb2-North-Levantine-Arabic","creator_name":"Omartificial Intelligence Space","creator_url":"https://huggingface.co/Omartificial-Intelligence-Space","license_name":"Open Data Commons Attribution License v1.0","license_url":"https://scancode-licensedb.aboutcode.org/odc-by-1.0.html","language":"en","first_N":5,"first_N_keywords":["Arabic","odc-by","100K - 1M","parquet","Text"],"keywords_longer_than_N":true},
	{"name":"FineWeb2-North-Levantine-Arabic","keyword":"arabic","description":"\n\t\n\t\t\n\t\tFineWeb2 North Levantine Arabic\n\t\n\n\nðŸ‡±ðŸ‡§ This is the  North Levantine Arabic Portion of The FineWeb2 Dataset.\nðŸ‡¸ðŸ‡© The North Levantine Arabic, represented by the ISO 639-3 code apc, is a member of the Afro-Asiatic language family and utilizes the Arabic script. \nðŸ‡¯ðŸ‡´ Known within subsets as apc_Arab, this language boasts an extensive corpus of over ** 221K rows**.\n\n\t\n\t\n\t\n\t\tPurpose of This Repository\n\t\n\nThis repository provides easy access to the Arabic portion -  North Levantineof theâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Omartificial-Intelligence-Space/FineWeb2-North-Levantine-Arabic.","url":"https://huggingface.co/datasets/Omartificial-Intelligence-Space/FineWeb2-North-Levantine-Arabic","creator_name":"Omartificial Intelligence Space","creator_url":"https://huggingface.co/Omartificial-Intelligence-Space","license_name":"Open Data Commons Attribution License v1.0","license_url":"https://scancode-licensedb.aboutcode.org/odc-by-1.0.html","language":"en","first_N":5,"first_N_keywords":["Arabic","odc-by","100K - 1M","parquet","Text"],"keywords_longer_than_N":true},
	{"name":"transcirpt-seerah-dr-yasir-qadhi","keyword":"arabic","description":"\n\t\n\t\t\n\t\tSeerah of Prophet Muhammad (SAW) â€“ Lecture Transcripts by Dr. Yasir Qadhi\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset contains the full transcripts of all 104 lectures delivered by Dr. Yasir Qadhi on the Seerah (biography) of Prophet Muhammad (SAW). These lectures provide a comprehensive, chronological account of the life, teachings, and historical context of the Prophet (SAW), covering key events such as:\n\nHis birth and early life in Mecca.\nThe revelation of Prophethood and the message ofâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/rwmasood/transcirpt-seerah-dr-yasir-qadhi.","url":"https://huggingface.co/datasets/rwmasood/transcirpt-seerah-dr-yasir-qadhi","creator_name":"Dr Wasif Masood","creator_url":"https://huggingface.co/rwmasood","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["question-answering","text-generation","English","Arabic","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"tydi_xor_rc","keyword":"arabic","description":"\n\t\n\t\t\n\t\tDataset Card for \"tydi_xor_rc\"\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nTyDi QA is a question answering dataset covering 11 typologically diverse languages. \nXORQA is an extension of the original TyDi QA dataset to also include unanswerable questions, where context documents are only in English but questions are in 7 languages.\nXOR-AttriQA contains annotated attribution data for a sample of XORQA.\nThis dataset is a combined and simplified version of the Reading Comprehension data from XORQA andâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/coastalcph/tydi_xor_rc.","url":"https://huggingface.co/datasets/coastalcph/tydi_xor_rc","creator_name":"CoAStaL NLP Group","creator_url":"https://huggingface.co/coastalcph","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["question-answering","extractive-qa","crowdsourced","crowdsourced","multilingual"],"keywords_longer_than_N":true},
	{"name":"muri-it","keyword":"arabic","description":"\n\t\n\t\t\n\t\tMURI-IT: Multilingual Instruction Tuning Dataset for 200 Languages via Multilingual Reverse Instructions\n\t\n\nMURI-IT is a large-scale multilingual instruction tuning dataset containing 2.2 million instruction-output pairs across 200 languages. It is designed to address the challenges of instruction tuning in low-resource languages with Multilingual Reverse Instructions (MURI), which ensures that the output is human-written, high-quality, and authentic to the cultural and linguisticâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/akoksal/muri-it.","url":"https://huggingface.co/datasets/akoksal/muri-it","creator_name":"Abdullatif Koksal","creator_url":"https://huggingface.co/akoksal","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text2text-generation","text-generation","question-answering","summarization","Achinese"],"keywords_longer_than_N":true},
	{"name":"BenchMAX_Function_Completion","keyword":"arabic","description":"\n\t\n\t\t\n\t\tDataset Sources\n\t\n\n\nPaper: BenchMAX: A Comprehensive Multilingual Evaluation Suite for Large Language Models\nLink: https://huggingface.co/papers/2502.07346\nRepository: https://github.com/CONE-MT/BenchMAX\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nBenchMAX_Function_Completion is a dataset of BenchMAX, sourcing from humanevalplus, which evaluates the code generation capability in multilingual scenarios.\nWe extend the original English dataset to 16 non-English languages.\nThe data is first translatedâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/LLaMAX/BenchMAX_Function_Completion.","url":"https://huggingface.co/datasets/LLaMAX/BenchMAX_Function_Completion","creator_name":"LLaMAX","creator_url":"https://huggingface.co/LLaMAX","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","multilingual","English","Chinese","Spanish"],"keywords_longer_than_N":true},
	{"name":"HREmails","keyword":"arabic","description":"\n\t\n\t\t\n\t\tDataset Card for Dataset Name\n\t\n\n\n\nThis dataset card aims to be a base template for new datasets. It has been generated using this raw template.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\n\n\n\n\n\nCurated by: [More Information Needed]\nFunded by [optional]: [More Information Needed]\nShared by [optional]: [More Information Needed]\nLanguage(s) (NLP): [More Information Needed]\nLicense: [More Information Needed]\n\n\n\t\n\t\t\n\t\tDataset Sources [optional]\n\t\n\n\n\n\nRepository: [Moreâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/moa7amed/HREmails.","url":"https://huggingface.co/datasets/moa7amed/HREmails","creator_name":"Mohamed Ibrahim","creator_url":"https://huggingface.co/moa7amed","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","English","Arabic","mit","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"PolyGuardMix","keyword":"arabic","description":"\n\t\n\t\t\n\t\tPolyGuard: A Multilingual Safety Moderation Tool for 17 Languages\n\t\n\nAbstract: Truly multilingual safety moderation efforts for Large Language Models (LLMs) have been hindered by a narrow focus on a small set of languages (e.g., English, Chinese) as well as a limited scope of safety definition, resulting in significant gaps in moderation capabilities. To bridge these gaps, we release PolyGuard, a new state-of-the-art multilingual safety model for safeguarding LLM generations, and theâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/ToxicityPrompts/PolyGuardMix.","url":"https://huggingface.co/datasets/ToxicityPrompts/PolyGuardMix","creator_name":"ToxicityPrompts","creator_url":"https://huggingface.co/ToxicityPrompts","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["Arabic","Chinese","Czech","Dutch","English"],"keywords_longer_than_N":true},
	{"name":"BK-Training-Dataset","keyword":"arabic","description":"\n\t\n\t\t\n\t\tTitle\n\t\n\n\"Basisklassifikation\" (BK) Training Dataset for Automatic Subject Indexing: Titles and Subjects from the K10plus Library Catalogue\n\n\t\n\t\t\n\t\tDescription\n\t\n\nThis is a training dataset for automatic subject indexing containing more than 6 million titles and their corresponding subjects (classes) from the \"Basisklassifikation\" (BK). Initially introduced in the 1980s, today the Basisklassifikation constitutes the most widely used classification system for subject indexing within theâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/SBB/BK-Training-Dataset.","url":"https://huggingface.co/datasets/SBB/BK-Training-Dataset","creator_name":"Staatsbibliothek zu Berlin - PreuÃŸischer Kulturbesitz","creator_url":"https://huggingface.co/SBB","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","German","English","French","Italian"],"keywords_longer_than_N":true},
	{"name":"minerva-ar-en-edu-codeswitch-dataset","keyword":"arabic","description":"\n\t\n\t\t\n\t\tMINERVA-TEAM/minerva-ar-en-edu-codeswitch-dataset\n\t\n\nðŸš§ Dataset Under Construction ðŸš§  \nThis repository hosts the Minerva AR-EN Edu Code-Switch Dataset, which is currently being built by the MINERVA Team.  \n\n\t\n\t\t\n\t\tAim\n\t\n\nOur main goal is to fine-tune OpenAI's Whisper model for Egyptian Arabicâ€“English code-switching in educational contexts.The dataset will include audio + transcript pairs, carefully collected and organized to improve Whisperâ€™s performance on:  \n\nCode-switched speechâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/MINERVA-TEAM/minerva-ar-en-edu-codeswitch-dataset.","url":"https://huggingface.co/datasets/MINERVA-TEAM/minerva-ar-en-edu-codeswitch-dataset","creator_name":"MINERVA-TEAM","creator_url":"https://huggingface.co/MINERVA-TEAM","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["Arabic","English","apache-2.0","1K - 10K","parquet"],"keywords_longer_than_N":true},
	{"name":"Arabic-Quora-Duplicates","keyword":"arabic","description":"\n\t\n\t\t\n\t\tArabic-Quora-Duplicates\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\n\nThe Arabic Version of the Quora Question Pairs Dataset\nIt contains the Quora Question Pairs dataset in four formats that are easily used with Sentence Transformers to train embedding models.\nThe data was originally created by Quora for this Kaggle Competition.\nDataset may be used for training/finetuning an embedding model for semantic textual similarity.\n\n\n\t\n\t\t\n\t\tPair Subset\n\t\n\n\nColumns: \"anchor\", \"positive\"\nColumn types: str, strâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Omartificial-Intelligence-Space/Arabic-Quora-Duplicates.","url":"https://huggingface.co/datasets/Omartificial-Intelligence-Space/Arabic-Quora-Duplicates","creator_name":"Omartificial Intelligence Space","creator_url":"https://huggingface.co/Omartificial-Intelligence-Space","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["sentence-similarity","Arabic","apache-2.0","100K - 1M","csv"],"keywords_longer_than_N":true},
	{"name":"conllpp-ner-ar","keyword":"arabic","description":"iSemantics/conllpp-ner-ar dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/iSemantics/conllpp-ner-ar","creator_name":"iSemantics","creator_url":"https://huggingface.co/iSemantics","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["token-classification","Arabic","mit","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"muslim-names-dataset","keyword":"arabic","description":"\n\t\n\t\t\n\t\tMuslim Names Dataset\n\t\n\nA comprehensive collection of Muslim names with meanings scraped from muslimnames.com. Contains 14,585 names with English names, Arabic names, meanings, and gender classifications.\n\n\t\n\t\t\n\t\tDataset Contents\n\t\n\nThis dataset contains ~14,585 Muslim names with the following information:\n\nEnglish name: Name in English/Latin script\nArabic name: Name in Arabic script\nMeaning: Definition and meaning of the name\nGender: Classification as male or female\n\n\n\t\n\t\t\n\t\tFilesâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/takiuddinahmed/muslim-names-dataset.","url":"https://huggingface.co/datasets/takiuddinahmed/muslim-names-dataset","creator_name":"Takiuddin Ahmed","creator_url":"https://huggingface.co/takiuddinahmed","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","text-generation","English","Arabic","cc0-1.0"],"keywords_longer_than_N":true},
	{"name":"levantine_train_set","keyword":"arabic","description":"Pre-processed Levantine train partition from the MASC-dataset:\nMohammad Al-Fetyani, Muhammad Al-Barham, Gheith Abandah, Adham Alsharkawi, Maha Dawas, August 18, 2021, \"MASC: Massive Arabic Speech Corpus\", IEEE Dataport, doi: https://dx.doi.org/10.21227/e1qb-jv46.\n","url":"https://huggingface.co/datasets/otozz/levantine_train_set","creator_name":"Ã–mer","creator_url":"https://huggingface.co/otozz","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["Arabic","cc-by-4.0","10K - 100K","parquet","Datasets"],"keywords_longer_than_N":true},
	{"name":"Arabic-With-Ranked-Hard-Negatives","keyword":"arabic","description":"\n\t\n\t\t\n\t\tArabic With Ranked Hard Negatives\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThe Arabic Hard Negative Dataset is derived from the Arabic subset of the Mr. TyDi dataset Mr. TyDi dataset. Using an advanced Arabic embedding model GATE, this dataset restructures the original data to include a query, a positive passage, and the top 4 hard negatives for each query based on similarity scores. These hard negatives are the most semantically similar non-relevant passages to the positive passage, providing aâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Omartificial-Intelligence-Space/Arabic-With-Ranked-Hard-Negatives.","url":"https://huggingface.co/datasets/Omartificial-Intelligence-Space/Arabic-With-Ranked-Hard-Negatives","creator_name":"Omartificial Intelligence Space","creator_url":"https://huggingface.co/Omartificial-Intelligence-Space","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","Arabic","apache-2.0","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"FineNews-unfiltered","keyword":"arabic","description":"\n\t\n\t\t\n\t\tFineNews\n\t\n\nWIP. Like FineWeb, but built from Common Crawl News instead of main web.\nFor languages not listed as a split, check the data/ directory.\nFor now, it contains the 2024-05 (May),-04 (April),-03 (March) dumps.\nThis is the unfiltered version, with only URL filtering applied.\n\n\t\n\t\t\n\t\tSome initial stats\n\t\n\nTotal number of documents: 35M\n\n\t\n\t\t\nDump\nNumber of docs\nDisk size (compressed)\n\n\n\t\t\nCC-NEWS-2024-05\n11_715_084\n11G\n\n\nCC-NEWS-2024-04\n11_546_298\n11G\n\n\nCC-NEWS-2024-03â€¦ See the full description on the dataset page: https://huggingface.co/datasets/maxidl/FineNews-unfiltered.","url":"https://huggingface.co/datasets/maxidl/FineNews-unfiltered","creator_name":"Max Idahl","creator_url":"https://huggingface.co/maxidl","license_name":"Open Data Commons Attribution License v1.0","license_url":"https://scancode-licensedb.aboutcode.org/odc-by-1.0.html","language":"en","first_N":5,"first_N_keywords":["text-generation","English","German","French","Polish"],"keywords_longer_than_N":true},
	{"name":"DCA-Bench","keyword":"arabic","description":"\n\t\n\t\t\n\t\tDCA-Benchmark\n\t\n\n\n\n\nDCA-Benchmark aims to provide a comprehensive benchmark for evaluating LLM agents' capabilities in discovering data quality issues across online dataset platforms, representing the first step of the curation pipeline. Throughout this document, we will refer to such an LLM agent as a \"Curator\" to highlight its role in this task. A well-performing Curator can detect and locate existing issues, which is critical for subsequent fixes by human maintainers or other LLMâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/trais-lab/DCA-Bench.","url":"https://huggingface.co/datasets/trais-lab/DCA-Bench","creator_name":"TRAIS Lab","creator_url":"https://huggingface.co/trais-lab","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":null,"first_N":5,"first_N_keywords":["question-answering","text-generation","summarization","Chinese","English"],"keywords_longer_than_N":true},
	{"name":"CIDAR","keyword":"arabic","description":"\n\t\n\t\t\n\t\tDataset Card for \"CIDAR\"\n\t\n\n\n\t\n\t\t\n\t\tðŸŒ´CIDAR: Culturally Relevant Instruction Dataset For Arabic\n\t\n\n\n\n   [ Paper - GitHub ]\n\n\n\nCIDAR contains 10,000 instructions and their output. The dataset was created by selecting around 9,109 samples from Alpagasus dataset then translating it to Arabic using ChatGPT. In addition, we append that with around 891 Arabic grammar instructions from the webiste Ask the teacher. All the 10,000 samples were reviewed by around 12 reviewers. \n\n\n\n\n\n\n\t\n\t\t\n\t\tðŸ“šâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/arbml/CIDAR.","url":"https://huggingface.co/datasets/arbml/CIDAR","creator_name":"Arabic Machine Learning ","creator_url":"https://huggingface.co/arbml","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","Arabic","apache-2.0","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"ParaNames","keyword":"arabic","description":"\n\t\n\t\t\n\t\n\t\n\t\tDataset Card for Dataset Name\n\t\n\n\n\nThis dataset card aims to be a base template for new datasets. It has been generated using this raw template.\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Description\n\t\n\n\n\n\n\n\nCurated by: [More Information Needed]\nFunded by [optional]: [More Information Needed]\nShared by [optional]: [More Information Needed]\nLanguage(s) (NLP): [More Information Needed]\nLicense: [More Information Needed]\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Sources [optional]â€¦ See the full description on the dataset page: https://huggingface.co/datasets/bltlab/ParaNames.","url":"https://huggingface.co/datasets/bltlab/ParaNames","creator_name":"Broadening Linguistic Technologies Lab (BLT Lab)","creator_url":"https://huggingface.co/bltlab","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["token-classification","Nias","Kotava","Banjar","Angika"],"keywords_longer_than_N":true},
	{"name":"fineweb2_tunisian_arabic","keyword":"arabic","description":"This is the Tunisian Arabic Portion of The FineWeb2 Dataset.\nThis dataset contains a rich collection of text in Tunisian Arabic (ISO 639-3: aeb), a widely spoken dialect within the Afro-Asiatic language family. \nIt serves as a valuable resource for NLP development and linguistic research focused on Tunisian Arabic.\n\n\t\n\t\t\n\t\tPurpose of This Repository\n\t\n\nThis repository provides easy access to the Arabic portion - Tunisian of the extensive FineWeb2 dataset. My primary goal is to make thisâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/wghezaiel/fineweb2_tunisian_arabic.","url":"https://huggingface.co/datasets/wghezaiel/fineweb2_tunisian_arabic","creator_name":"Wajdi Ghezaiel","creator_url":"https://huggingface.co/wghezaiel","license_name":"Open Data Commons Attribution License v1.0","license_url":"https://scancode-licensedb.aboutcode.org/odc-by-1.0.html","language":"en","first_N":5,"first_N_keywords":["Tunisian Arabic","odc-by","100K - 1M","parquet","Tabular"],"keywords_longer_than_N":true},
	{"name":"ParaNames","keyword":"egyptian arabic","description":"\n\t\n\t\t\n\t\n\t\n\t\tDataset Card for Dataset Name\n\t\n\n\n\nThis dataset card aims to be a base template for new datasets. It has been generated using this raw template.\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Description\n\t\n\n\n\n\n\n\nCurated by: [More Information Needed]\nFunded by [optional]: [More Information Needed]\nShared by [optional]: [More Information Needed]\nLanguage(s) (NLP): [More Information Needed]\nLicense: [More Information Needed]\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Sources [optional]â€¦ See the full description on the dataset page: https://huggingface.co/datasets/bltlab/ParaNames.","url":"https://huggingface.co/datasets/bltlab/ParaNames","creator_name":"Broadening Linguistic Technologies Lab (BLT Lab)","creator_url":"https://huggingface.co/bltlab","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["token-classification","Nias","Kotava","Banjar","Angika"],"keywords_longer_than_N":true},
	{"name":"ParaNames","keyword":"moroccan arabic","description":"\n\t\n\t\t\n\t\n\t\n\t\tDataset Card for Dataset Name\n\t\n\n\n\nThis dataset card aims to be a base template for new datasets. It has been generated using this raw template.\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Description\n\t\n\n\n\n\n\n\nCurated by: [More Information Needed]\nFunded by [optional]: [More Information Needed]\nShared by [optional]: [More Information Needed]\nLanguage(s) (NLP): [More Information Needed]\nLicense: [More Information Needed]\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Sources [optional]â€¦ See the full description on the dataset page: https://huggingface.co/datasets/bltlab/ParaNames.","url":"https://huggingface.co/datasets/bltlab/ParaNames","creator_name":"Broadening Linguistic Technologies Lab (BLT Lab)","creator_url":"https://huggingface.co/bltlab","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["token-classification","Nias","Kotava","Banjar","Angika"],"keywords_longer_than_N":true},
	{"name":"fineweb2_tunisian_arabic","keyword":"tunisian arabic","description":"This is the Tunisian Arabic Portion of The FineWeb2 Dataset.\nThis dataset contains a rich collection of text in Tunisian Arabic (ISO 639-3: aeb), a widely spoken dialect within the Afro-Asiatic language family. \nIt serves as a valuable resource for NLP development and linguistic research focused on Tunisian Arabic.\n\n\t\n\t\t\n\t\tPurpose of This Repository\n\t\n\nThis repository provides easy access to the Arabic portion - Tunisian of the extensive FineWeb2 dataset. My primary goal is to make thisâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/wghezaiel/fineweb2_tunisian_arabic.","url":"https://huggingface.co/datasets/wghezaiel/fineweb2_tunisian_arabic","creator_name":"Wajdi Ghezaiel","creator_url":"https://huggingface.co/wghezaiel","license_name":"Open Data Commons Attribution License v1.0","license_url":"https://scancode-licensedb.aboutcode.org/odc-by-1.0.html","language":"en","first_N":5,"first_N_keywords":["Tunisian Arabic","odc-by","100K - 1M","parquet","Tabular"],"keywords_longer_than_N":true},
	{"name":"nn-auto-bench-ds","keyword":"arabic","description":"\n\t\n\t\t\n\t\tnn-auto-bench-ds\n\t\n\nnn-auto-bench-ds is a dataset designed for key information extraction (KIE) and serves as a benchmark dataset for nn-auto-bench.\n\n\t\n\t\t\n\t\tDataset Overview\n\t\n\nThe dataset comprises 1,000 documents, categorized into the following types:\n\nInvoice\nReceipt\nPassport\nBank Statement\n\nThe documents are primarily available in English, with some also in German and Arabic. Each document is annotated for key information extraction and specific tasks. The dataset can be used toâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/nanonets/nn-auto-bench-ds.","url":"https://huggingface.co/datasets/nanonets/nn-auto-bench-ds","creator_name":"Nanonets","creator_url":"https://huggingface.co/nanonets","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["question-answering","English","German","Arabic","mit"],"keywords_longer_than_N":true},
	{"name":"ar-eg-dataset","keyword":"arabic","description":"An in-progress dataset for arabic-egyptian-dialect, specifically made from transcripton of DrAliGomaa videos on youtube.\nDr Ali Gomaa is a famous Egyptian Islamic Scholar and he was the mufti of Egypt from 2003-2013\n\nLink to his youtube channel: https://www.youtube.com/@DrAliGomaa\nLink to his page on facebook: https://www.facebook.com/DrAliGomaa\n\n","url":"https://huggingface.co/datasets/DrAliGomaa/ar-eg-dataset","creator_name":"arabic_speech","creator_url":"https://huggingface.co/DrAliGomaa","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","translation","Arabic","apache-2.0","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"TikTok_MostComment_Video_Transcription_Example","keyword":"arabic","description":"\n\t\n\t\t\n\t\tðŸ“² Example Dataset: TikTok Scraper Tool\n\t\n\nðŸ‘‰ Start Scraping TikTok: TikTok Scraper Tool\n\n\t\n\t\t\n\t\tâœ¨ Key Features\n\t\n\n\nâš¡ Instant Transcription â€“ Turn any TikTok video into an AI-ready transcript  \nðŸŽ¯ Metadata â€“ Get the title, language description, and video hashtags  \nðŸ”— URL-Based Access â€“ Just drop in a TikTok video URL to start scraping  \nðŸ§© LLM-Ready Output â€“ Receive clean JSON ready for agents, RAG, or AI tools  \nðŸ’¸ Free Tier â€“ Use up to 100 queries during the beta period  \nðŸ’« Easyâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Gopher-Lab/TikTok_MostComment_Video_Transcription_Example.","url":"https://huggingface.co/datasets/Gopher-Lab/TikTok_MostComment_Video_Transcription_Example","creator_name":"Gopher AI","creator_url":"https://huggingface.co/Gopher-Lab","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","table-question-answering","zero-shot-classification","feature-extraction","text-to-speech"],"keywords_longer_than_N":true},
	{"name":"Wikipedia-Abstract","keyword":"arabic","description":"Wikipedia Abstract\n\n\n  \n\n\n\nIntroducing Wikipedia Abstract, a comprehensive dataset encompassing abstracts, complete articles, and a popularity score index for both widely spoken and lesser-known Wikipedia subsets. Our dedication to Wikipedia-X ensures a centralized Wikipedia dataset that undergoes regular updates and adheres to the highest standards.\nA central focus of our efforts was to include exotic languages that often lack up-to-date Wikipedia dumps or may not have any dumps at all.â€¦ See the full description on the dataset page: https://huggingface.co/datasets/laion/Wikipedia-Abstract.","url":"https://huggingface.co/datasets/laion/Wikipedia-Abstract","creator_name":"LAION eV","creator_url":"https://huggingface.co/laion","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","question-answering","text-generation","fill-mask","Arabic"],"keywords_longer_than_N":true},
	{"name":"xP3x-Kongo","keyword":"arabic","description":"\n\t\n\t\t\n\t\tDataset Card for xP3x Kikongo Focus\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\n\nxP3x (Crosslingual Public Pool of Prompts eXtended) is a collection of prompts & datasets across 277 languages & 16 NLP tasks. It contains all of xP3 + much more! It is used for training future contenders of mT0 & BLOOMZ at project Aya @C4AI ðŸ§¡\n\n\nCreation: The dataset can be recreated using instructions available here together with the file in this repository named xp3x_create.py. We provide this version to saveâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Svngoku/xP3x-Kongo.","url":"https://huggingface.co/datasets/Svngoku/xP3x-Kongo","creator_name":"NIONGOLO Chrys FÃ©-Marty","creator_url":"https://huggingface.co/Svngoku","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["other","translation","expert-generated","crowdsourced","multilingual"],"keywords_longer_than_N":true},
	{"name":"xP3x-Kongo","keyword":"egyptian arabic","description":"\n\t\n\t\t\n\t\tDataset Card for xP3x Kikongo Focus\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\n\nxP3x (Crosslingual Public Pool of Prompts eXtended) is a collection of prompts & datasets across 277 languages & 16 NLP tasks. It contains all of xP3 + much more! It is used for training future contenders of mT0 & BLOOMZ at project Aya @C4AI ðŸ§¡\n\n\nCreation: The dataset can be recreated using instructions available here together with the file in this repository named xp3x_create.py. We provide this version to saveâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Svngoku/xP3x-Kongo.","url":"https://huggingface.co/datasets/Svngoku/xP3x-Kongo","creator_name":"NIONGOLO Chrys FÃ©-Marty","creator_url":"https://huggingface.co/Svngoku","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["other","translation","expert-generated","crowdsourced","multilingual"],"keywords_longer_than_N":true},
	{"name":"xP3x-Kongo","keyword":"levantine arabic","description":"\n\t\n\t\t\n\t\tDataset Card for xP3x Kikongo Focus\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\n\nxP3x (Crosslingual Public Pool of Prompts eXtended) is a collection of prompts & datasets across 277 languages & 16 NLP tasks. It contains all of xP3 + much more! It is used for training future contenders of mT0 & BLOOMZ at project Aya @C4AI ðŸ§¡\n\n\nCreation: The dataset can be recreated using instructions available here together with the file in this repository named xp3x_create.py. We provide this version to saveâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Svngoku/xP3x-Kongo.","url":"https://huggingface.co/datasets/Svngoku/xP3x-Kongo","creator_name":"NIONGOLO Chrys FÃ©-Marty","creator_url":"https://huggingface.co/Svngoku","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["other","translation","expert-generated","crowdsourced","multilingual"],"keywords_longer_than_N":true},
	{"name":"xP3x-Kongo","keyword":"mesopotamian arabic","description":"\n\t\n\t\t\n\t\tDataset Card for xP3x Kikongo Focus\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\n\nxP3x (Crosslingual Public Pool of Prompts eXtended) is a collection of prompts & datasets across 277 languages & 16 NLP tasks. It contains all of xP3 + much more! It is used for training future contenders of mT0 & BLOOMZ at project Aya @C4AI ðŸ§¡\n\n\nCreation: The dataset can be recreated using instructions available here together with the file in this repository named xp3x_create.py. We provide this version to saveâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Svngoku/xP3x-Kongo.","url":"https://huggingface.co/datasets/Svngoku/xP3x-Kongo","creator_name":"NIONGOLO Chrys FÃ©-Marty","creator_url":"https://huggingface.co/Svngoku","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["other","translation","expert-generated","crowdsourced","multilingual"],"keywords_longer_than_N":true},
	{"name":"xP3x-Kongo","keyword":"moroccan arabic","description":"\n\t\n\t\t\n\t\tDataset Card for xP3x Kikongo Focus\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\n\nxP3x (Crosslingual Public Pool of Prompts eXtended) is a collection of prompts & datasets across 277 languages & 16 NLP tasks. It contains all of xP3 + much more! It is used for training future contenders of mT0 & BLOOMZ at project Aya @C4AI ðŸ§¡\n\n\nCreation: The dataset can be recreated using instructions available here together with the file in this repository named xp3x_create.py. We provide this version to saveâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Svngoku/xP3x-Kongo.","url":"https://huggingface.co/datasets/Svngoku/xP3x-Kongo","creator_name":"NIONGOLO Chrys FÃ©-Marty","creator_url":"https://huggingface.co/Svngoku","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["other","translation","expert-generated","crowdsourced","multilingual"],"keywords_longer_than_N":true},
	{"name":"xP3x-Kongo","keyword":"najdi arabic","description":"\n\t\n\t\t\n\t\tDataset Card for xP3x Kikongo Focus\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\n\nxP3x (Crosslingual Public Pool of Prompts eXtended) is a collection of prompts & datasets across 277 languages & 16 NLP tasks. It contains all of xP3 + much more! It is used for training future contenders of mT0 & BLOOMZ at project Aya @C4AI ðŸ§¡\n\n\nCreation: The dataset can be recreated using instructions available here together with the file in this repository named xp3x_create.py. We provide this version to saveâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Svngoku/xP3x-Kongo.","url":"https://huggingface.co/datasets/Svngoku/xP3x-Kongo","creator_name":"NIONGOLO Chrys FÃ©-Marty","creator_url":"https://huggingface.co/Svngoku","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["other","translation","expert-generated","crowdsourced","multilingual"],"keywords_longer_than_N":true},
	{"name":"xP3x-Kongo","keyword":"tunisian arabic","description":"\n\t\n\t\t\n\t\tDataset Card for xP3x Kikongo Focus\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\n\nxP3x (Crosslingual Public Pool of Prompts eXtended) is a collection of prompts & datasets across 277 languages & 16 NLP tasks. It contains all of xP3 + much more! It is used for training future contenders of mT0 & BLOOMZ at project Aya @C4AI ðŸ§¡\n\n\nCreation: The dataset can be recreated using instructions available here together with the file in this repository named xp3x_create.py. We provide this version to saveâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Svngoku/xP3x-Kongo.","url":"https://huggingface.co/datasets/Svngoku/xP3x-Kongo","creator_name":"NIONGOLO Chrys FÃ©-Marty","creator_url":"https://huggingface.co/Svngoku","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["other","translation","expert-generated","crowdsourced","multilingual"],"keywords_longer_than_N":true},
	{"name":"xP3x-Kongo","keyword":"ta'izzi-adeni arabic","description":"\n\t\n\t\t\n\t\tDataset Card for xP3x Kikongo Focus\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\n\nxP3x (Crosslingual Public Pool of Prompts eXtended) is a collection of prompts & datasets across 277 languages & 16 NLP tasks. It contains all of xP3 + much more! It is used for training future contenders of mT0 & BLOOMZ at project Aya @C4AI ðŸ§¡\n\n\nCreation: The dataset can be recreated using instructions available here together with the file in this repository named xp3x_create.py. We provide this version to saveâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Svngoku/xP3x-Kongo.","url":"https://huggingface.co/datasets/Svngoku/xP3x-Kongo","creator_name":"NIONGOLO Chrys FÃ©-Marty","creator_url":"https://huggingface.co/Svngoku","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["other","translation","expert-generated","crowdsourced","multilingual"],"keywords_longer_than_N":true},
	{"name":"imeg4model","keyword":"arabic","description":"openS\nfrom: hcoding\n","url":"https://huggingface.co/datasets/yyasso/imeg4model","creator_name":"H.coding AI","creator_url":"https://huggingface.co/yyasso","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text2text-generation","English","Arabic","French","mit"],"keywords_longer_than_N":true},
	{"name":"Arabic_Reasoning_Dataset","keyword":"arabic","description":"\n\t\n\t\t\n\t\tArabic Reasoning Instruction QA Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset contains 9.21K rows of Arabic instruction-based reasoning QA pairs. It is a comprehensive collection of data points, meticulously crafted to enhance Arabic language reasoning capabilities for models.\nThe dataset was generated by combining:\nâ™¦ï¸Ž Data from the Hugging Face dataset MohammedNasser/Arabic_Reasoning_Instruct_QA. | Size = 1.23K instructions\nâ™¦ï¸Ž Synthetic data generated using the GPT-4o-Mini APIâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Omartificial-Intelligence-Space/Arabic_Reasoning_Dataset.","url":"https://huggingface.co/datasets/Omartificial-Intelligence-Space/Arabic_Reasoning_Dataset","creator_name":"Omartificial Intelligence Space","creator_url":"https://huggingface.co/Omartificial-Intelligence-Space","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["Arabic","apache-2.0","1K - 10K","parquet","Text"],"keywords_longer_than_N":true},
	{"name":"Arabic-Cohere-include-base-44-mmlu-style","keyword":"arabic","description":"\n\t\n\t\t\n\t\tThe Refined Arabic Cohere INCLUDE Base 44 Dataset as MMLU-Style\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nINCLUDE is a comprehensive knowledge- and reasoning-centric benchmark spanning 44 languages that evaluates multilingual LLMs in the actual linguistic environments where they are deployed. The original dataset contains 22,637 4-option multiple-choice questions (MCQs) extracted from academic and professional exams, covering 57 topics, including regional knowledge.\nWhen we reviewed the Arabicâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Omartificial-Intelligence-Space/Arabic-Cohere-include-base-44-mmlu-style.","url":"https://huggingface.co/datasets/Omartificial-Intelligence-Space/Arabic-Cohere-include-base-44-mmlu-style","creator_name":"Omartificial Intelligence Space","creator_url":"https://huggingface.co/Omartificial-Intelligence-Space","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["Arabic","apache-2.0","< 1K","csv","Text"],"keywords_longer_than_N":true},
	{"name":"Arabic-Cohere-include-base-44-mmlu-style","keyword":"arabic","description":"\n\t\n\t\t\n\t\tThe Refined Arabic Cohere INCLUDE Base 44 Dataset as MMLU-Style\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nINCLUDE is a comprehensive knowledge- and reasoning-centric benchmark spanning 44 languages that evaluates multilingual LLMs in the actual linguistic environments where they are deployed. The original dataset contains 22,637 4-option multiple-choice questions (MCQs) extracted from academic and professional exams, covering 57 topics, including regional knowledge.\nWhen we reviewed the Arabicâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Omartificial-Intelligence-Space/Arabic-Cohere-include-base-44-mmlu-style.","url":"https://huggingface.co/datasets/Omartificial-Intelligence-Space/Arabic-Cohere-include-base-44-mmlu-style","creator_name":"Omartificial Intelligence Space","creator_url":"https://huggingface.co/Omartificial-Intelligence-Space","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["Arabic","apache-2.0","< 1K","csv","Text"],"keywords_longer_than_N":true},
	{"name":"linto-dataset-audio-ar-tn-augmented","keyword":"arabic","description":"\n\t\n\t\t\n\t\tLinTO DataSet Audio for Arabic Tunisian Augmented A collection of Tunisian dialect audio and its annotations for STT task\n\t\n\nThis is the augmented datasets used to train the Linto Tunisian dialect with code-switching STT linagora/linto-asr-ar-tn.\n\nDataset Summary\nDataset composition\nSources\nContent Types\nLanguages and Dialects\n\n\nExample use (python)\nLicense\nCitations\n\n\n\t\t\n\t\tDataset Summary\n\t\n\nThe LinTO DataSet Audio for Arabic Tunisian Augmented is a dataset that builds on LinTOâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/linagora/linto-dataset-audio-ar-tn-augmented.","url":"https://huggingface.co/datasets/linagora/linto-dataset-audio-ar-tn-augmented","creator_name":"LINAGORA Labs","creator_url":"https://huggingface.co/linagora","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","text-to-audio","Arabic","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"Arabic-stsb","keyword":"arabic","description":"\n\t\n\t\t\n\t\tArabic STSB Structure\n\t\n\n\nThe Arabic Version  of the the Semantic Textual Similarity Benchmark (Cer et al., 2017)\nit is a collection of sentence pairs drawn from news headlines, video and image captions, and natural language inference data.\nEach pair is human-annotated with a similarity score from 1 to 5. However, for this variant, the similarity scores are normalized to between 0 and 1.\n\nExamples:\n{\n  \"sentence1\": \"Ø·Ø§Ø¦Ø±Ø© Ø³ØªÙ‚Ù„Ø¹\",\n  \"sentence2\": \"Ø·Ø§Ø¦Ø±Ø© Ø¬ÙˆÙŠØ© Ø³ØªÙ‚Ù„Ø¹\",\n  \"score\": 1.0\n}\n\n{â€¦ See the full description on the dataset page: https://huggingface.co/datasets/Omartificial-Intelligence-Space/Arabic-stsb.","url":"https://huggingface.co/datasets/Omartificial-Intelligence-Space/Arabic-stsb","creator_name":"Omartificial Intelligence Space","creator_url":"https://huggingface.co/Omartificial-Intelligence-Space","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["sentence-similarity","Arabic","apache-2.0","1K - 10K","csv"],"keywords_longer_than_N":true},
	{"name":"DarNERcorp","keyword":"arabic","description":"\n\t\n\t\t\n\t\tDataset Card for \"DarNERcorp: A Named Entity Recognition Corpus in the Moroccan Dialect\"\n\t\n\n\n\t\n\t\t\n\t\tPaper:\n\t\n\nMousa, Hanane Nour; Mourhir, Asmaa (2023), â€œDarNERcorp: a Named Entity Recognition Corpus in the Moroccan Dialectâ€, Mendeley Data, V2, doi: 10.17632/286sss4k9v.2\n","url":"https://huggingface.co/datasets/asas-ai/DarNERcorp","creator_name":"ASAS AI","creator_url":"https://huggingface.co/asas-ai","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["token-classification","Arabic","cc-by-4.0","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"Arabic_Offensive_Comment_Detection","keyword":"arabic","description":"\n\t\n\t\t\n\t\tDataset Card for \"Arabic_Offensive_Comment_Detection\"\n\t\n\n\n\t\n\t\t\n\t\tPaper:\n\t\n\nShammur Absar Chowdhury, Hamdy Mubarak, Ahmed Abdelali, Soon-gyo Jung, Bernard J. Jansen, and Joni Salminen. 2020. A Multi-Platform Arabic News Comment Dataset for Offensive Language Detection. In Proceedings of the Twelfth Language Resources and Evaluation Conference, pages 6203â€“6212, Marseille, France. European Language Resources Association.\n","url":"https://huggingface.co/datasets/asas-ai/Arabic_Offensive_Comment_Detection","creator_name":"ASAS AI","creator_url":"https://huggingface.co/asas-ai","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","Arabic","apache-2.0","1K - 10K","parquet"],"keywords_longer_than_N":true},
	{"name":"arabic_tweets_dialects","keyword":"arabic","description":"amgadhasan/arabic_tweets_dialects dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/amgadhasan/arabic_tweets_dialects","creator_name":"Amgad Hasan","creator_url":"https://huggingface.co/amgadhasan","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","Arabic","mit","100K - 1M","parquet"],"keywords_longer_than_N":true},
	{"name":"ArVoice","keyword":"arabic","description":"\n  ArVoice: A Multi-Speaker Dataset for Arabic Speech Synthesis\n\n Hawau Olamide Toyin, Rufael Marew, Humaid Alblooshi, Samar M. Magdy, Hanan Aldarmaki \n {hawau.toyin, hanan.aldarmaki}@mbzuai.ac.ae \n\n\n    ArVoice is a multi-speaker Modern Standard Arabic (MSA) speech corpus with fully diacritized transcriptions, intended  for multi-speaker speech synthesis, and can be useful for other tasks such as speech-based diacritic restoration, voice conversion, and deepfake detection.  \n      ArVoiceâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/MBZUAI/ArVoice.","url":"https://huggingface.co/datasets/MBZUAI/ArVoice","creator_name":"Mohamed Bin Zayed University of Artificial Intelligence","creator_url":"https://huggingface.co/MBZUAI","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-to-speech","text-to-audio","automatic-speech-recognition","Arabic","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"WanJuan-Arabic","keyword":"arabic","description":"\n\t\n\t\t\n\t\tðŸ’¡ Introduction\n\t\n\nWanJuan-Arabicï¼ˆä¸‡å·ä¸è·¯-é˜¿æ‹‰ä¼¯è¯­ï¼‰ corpus, with a volume exceeding 220GB, comprises 7 major categories and 34 subcategories. It covers a wide range of local-specific content, including history, politics, culture, real estate, shopping, weather, dining, encyclopedias, and professional knowledge. The rich thematic classification not only facilitates researchers in retrieving data according to specific needs but also ensures that the corpus can adapt to diverse researchâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/opendatalab/WanJuan-Arabic.","url":"https://huggingface.co/datasets/opendatalab/WanJuan-Arabic","creator_name":"OpenDataLab","creator_url":"https://huggingface.co/opendatalab","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","Arabic","cc-by-4.0","arxiv:2501.14506","arxiv:2407.13773"],"keywords_longer_than_N":true},
	{"name":"voices-of-civilizations","keyword":"arabic","description":"\n\t\n\t\t\n\t\tVoices of Civilizations (VoC)\n\t\n\nVoices of Civilizations (VoC) is the first multilingual QA benchmark designed to assess audio LLMsâ€™ cultural comprehension using full-length music recordings. VoC spans:\n\n38 languages ðŸ‡¸ðŸ‡¦ Arabic (ar), ðŸ‡§ðŸ‡© Bengali (bn), ðŸ‡§ðŸ‡¬ Bulgarian (bg), ðŸ‡¨ðŸ‡³ Chinese (zh), ðŸ‡­ðŸ‡· Croatian (hr), ðŸ‡¨ðŸ‡¿ Czech (cs), ðŸ‡©ðŸ‡° Danish (da), ðŸ‡³ðŸ‡± Dutch (nl), ðŸ‡¬ðŸ‡§ English (en), ðŸ‡ªðŸ‡ª Estonian (et), ðŸ‡«ðŸ‡® Finnish (fi), ðŸ‡«ðŸ‡· French (fr), ðŸ‡©ðŸ‡ª German (de), ðŸ‡¬ðŸ‡· Greek (el), ðŸ‡®ðŸ‡± Hebrewâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/sander-wood/voices-of-civilizations.","url":"https://huggingface.co/datasets/sander-wood/voices-of-civilizations","creator_name":"Shangda Wu (Sander Wood)","creator_url":"https://huggingface.co/sander-wood","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["question-answering","Arabic","Bengali","Bulgarian","Chinese"],"keywords_longer_than_N":true},
	{"name":"wikipedia-citation-index","keyword":"arabic","description":"Dataset with citation indexes as of 1 August 2024 for 47 million Wikipedia articles in 55 language versions. Research: ArXiv\n","url":"https://huggingface.co/datasets/lewoniewski/wikipedia-citation-index","creator_name":"WÅ‚odzimierz Lewoniewski","creator_url":"https://huggingface.co/lewoniewski","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["Arabic","Azerbaijani","Belarusian","Bulgarian","Catalan"],"keywords_longer_than_N":true},
	{"name":"Math_CoT_Arabic_English_Reasoning","keyword":"arabic","description":"\n\t\n\t\t\n\t\tMath CoT Arabic English Dataset\n\t\n\n\nA high-quality, bilingual (English & Arabic) dataset for Chain-of-Thought (COT) reasoning in mathematics and related disciplines, developed by Miscovery AI.\n\n\t\n\t\t\n\t\tOverview\n\t\n\nMath-COT is a unique dataset designed to facilitate and benchmark the development of chain-of-thought reasoning capabilities in language models across mathematical domains. With meticulously crafted examples, explicit reasoning steps, and bilingual support, this dataset offersâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/miscovery/Math_CoT_Arabic_English_Reasoning.","url":"https://huggingface.co/datasets/miscovery/Math_CoT_Arabic_English_Reasoning","creator_name":"Miscovery","creator_url":"https://huggingface.co/miscovery","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["question-answering","text-generation","fill-mask","English","Arabic"],"keywords_longer_than_N":true},
	{"name":"fact-or-opinion","keyword":"arabic","description":"agentlans/fact-or-opinion dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/agentlans/fact-or-opinion","creator_name":"Alan Tseng","creator_url":"https://huggingface.co/agentlans","license_name":"Open Data Commons Attribution License v1.0","license_url":"https://scancode-licensedb.aboutcode.org/odc-by-1.0.html","language":"en","first_N":5,"first_N_keywords":["text-classification","Amharic","Arabic","Bengali","German"],"keywords_longer_than_N":true},
	{"name":"arabic_quranic_asr","keyword":"arabic","description":"\n\t\n\t\t\n\t\tDataset details\n\t\n\nThis dataset contains quran recitations of every ayats or verses. Also contains 10k unique words from quran.\n\n\t\n\t\t\n\t\tDataset Purpose\n\t\n\nThis dataset can be used to train ASR models that can be used for teaching beginners to recite quran. It can also be used for training TTS models that produces quran recitations in a way so that beginners can easily learn.\n","url":"https://huggingface.co/datasets/Sadique5/arabic_quranic_asr","creator_name":"Sadique Abdullah","creator_url":"https://huggingface.co/Sadique5","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","Arabic","mit","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"shamela_books_text_full","keyword":"arabic","description":"\n\t\n\t\t\n\t\tShamela_Books_Text_Full\n\t\n\nThis dataset contains the full text content of Islamic Arabic books from the Shamela Library, organized by category, book, volume, and page, with footnotes stored separately. It is designed to support Arabic NLP, digital humanities, and bibliographic analysis.\nðŸ”— This dataset is linked to the companion metadata dataset:\nðŸ‘‰ Shamela_Books_info via the book_id field.\n\n\n\t\n\t\t\n\t\n\t\n\t\tðŸ“Š Dataset Summary\n\t\n\n\nTotal Categories: 40\nTotal Books: 8,538\nTotal Recordsâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/MoMonir/shamela_books_text_full.","url":"https://huggingface.co/datasets/MoMonir/shamela_books_text_full","creator_name":"Mohamed Monir","creator_url":"https://huggingface.co/MoMonir","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["Arabic","apache-2.0","1M - 10M","parquet","Text"],"keywords_longer_than_N":true},
	{"name":"arabic_medical_dialogue","keyword":"arabic","description":"Mars203020/arabic_medical_dialogue dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/Mars203020/arabic_medical_dialogue","creator_name":"Mariam ALMutairi","creator_url":"https://huggingface.co/Mars203020","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-generation","Arabic","mit","1K - 10K","text"],"keywords_longer_than_N":true},
	{"name":"KITAB_pdf_to_markdown_reviewed","keyword":"arabic","description":"\n\t\n\t\t\n\t\tKITAB_pdf_to_markdown_reviewed (Corrected KITAB-Bench PDFâ†’Markdown)\n\t\n\nShort description. A carefully reviewed and corrected version of the KITAB-Bench PDF-to-Markdown subset for Arabic document OCR evaluation. We fixed ground-truth errors (hallucinated text, missing page numbers, omissions of small-font text) and standardized formatting to provide a reliable benchmark for model comparison.\nTL;DR\n\nâœ… Human-verified ground truth for Arabic PDFâ†’Markdown\nâœ… Removes hallucinations and fillsâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Misraj/KITAB_pdf_to_markdown_reviewed.","url":"https://huggingface.co/datasets/Misraj/KITAB_pdf_to_markdown_reviewed","creator_name":"Misraj Ai","creator_url":"https://huggingface.co/Misraj","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["Arabic","apache-2.0","< 1K","parquet","Image"],"keywords_longer_than_N":true},
	{"name":"KITAB_pdf_to_markdown_reviewed","keyword":"arabic","description":"\n\t\n\t\t\n\t\tKITAB_pdf_to_markdown_reviewed (Corrected KITAB-Bench PDFâ†’Markdown)\n\t\n\nShort description. A carefully reviewed and corrected version of the KITAB-Bench PDF-to-Markdown subset for Arabic document OCR evaluation. We fixed ground-truth errors (hallucinated text, missing page numbers, omissions of small-font text) and standardized formatting to provide a reliable benchmark for model comparison.\nTL;DR\n\nâœ… Human-verified ground truth for Arabic PDFâ†’Markdown\nâœ… Removes hallucinations and fillsâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Misraj/KITAB_pdf_to_markdown_reviewed.","url":"https://huggingface.co/datasets/Misraj/KITAB_pdf_to_markdown_reviewed","creator_name":"Misraj Ai","creator_url":"https://huggingface.co/Misraj","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["Arabic","apache-2.0","< 1K","parquet","Image"],"keywords_longer_than_N":true},
	{"name":"thinking-multilingual-30-23-small-690","keyword":"arabic","description":"\nBased on OPENO1 math, this is a translated dataset of 30 high quality questions & answers in 23 languages. \nOr use the \"big\" version: big 10k rows version\n","url":"https://huggingface.co/datasets/Pinkstack/thinking-multilingual-30-23-small-690","creator_name":"Pinkstack","creator_url":"https://huggingface.co/Pinkstack","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","Arabic","Chinese","Czech","Danish"],"keywords_longer_than_N":true},
	{"name":"multilingual-speech-commands-15lang","keyword":"arabic","description":"\n\t\n\t\t\n\t\tMultilingual Speech Commands Dataset (15 Languages, Augmented)\n\t\n\nThis dataset contains augmented speech command samples in 15 languages, derived from multiple public datasets. Only commands that overlap with the Google Speech Commands (GSC) vocabulary are included, making the dataset suitable for multilingual keyword spotting tasks aligned with GSC-style classification.\nAudio samples have been augmented using standard audio techniques to improve model robustness (e.g., time-shiftingâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/artur-muratov/multilingual-speech-commands-15lang.","url":"https://huggingface.co/datasets/artur-muratov/multilingual-speech-commands-15lang","creator_name":"Artur Muratov","creator_url":"https://huggingface.co/artur-muratov","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["English","Russian","Kazakh","Tatar","Arabic"],"keywords_longer_than_N":true},
	{"name":"OGC_Cooking_Recipes","keyword":"arabic","description":"\n\t\n\t\t\n\t\tOGC_Cooking_Recipes - Overview\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nOGC_Cooking_Recipes is a curated multimodal dataset focused on cooking recipe documents, culinary guides, and food preparation instructions. It combines text and image data extracted from real culinary PDFs to support tasks such as RAG DSE, question answering, document search, and vision-language model training.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\tDataset Creation\n\t\n\nThis dataset was created using our open-source toolâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/racineai/OGC_Cooking_Recipes.","url":"https://huggingface.co/datasets/racineai/OGC_Cooking_Recipes","creator_name":"racine.ai","creator_url":"https://huggingface.co/racineai","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["visual-document-retrieval","text-retrieval","English","French","Chinese"],"keywords_longer_than_N":true},
	{"name":"MLMA_hate_speech","keyword":"arabic","description":"\n\t\n\t\t\n\t\tDisclaimer\n\t\n\nThis is a hate speech dataset (in Arabic, French, and English).\nOffensive content that does not reflect the opinions of the authors. \n\n\t\n\t\t\n\t\tDataset of our EMNLP 2019 Paper (Multilingual and Multi-Aspect Hate Speech Analysis)\n\t\n\nFor more details about our dataset, please check our paper:\n@inproceedings{ousidhoum-etal-multilingual-hate-speech-2019,\n        title = \"Multilingual and Multi-Aspect Hate Speech Analysis\",\n        author = \"Ousidhoum, Nedjmaâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/nedjmaou/MLMA_hate_speech.","url":"https://huggingface.co/datasets/nedjmaou/MLMA_hate_speech","creator_name":"Nedjma Ousidhoum","creator_url":"https://huggingface.co/nedjmaou","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["Arabic","French","English","mit","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"reranking-datasets-light","keyword":"arabic","description":"\n\t\n\t\t\n\t\tðŸ”¥ Rankify: A Comprehensive Python Toolkit for Retrieval, Re-Ranking, and Retrieval-Augmented Generation ðŸ”¥\n\t\n\n\n\t\n\t\t\n\t\n\t\n\t\tReRanking Datasets : A comprehensive collection of retrieval and reranking datasets with full passage contexts, including titles, text, and metadata for in-depth research.\n\t\n\n\n    \n    \n    \n    \n    \n    \n        \n    \n    \n        \n    \n    \n        \n    \n    \n        \n    \n    \n    \n\n\n\nA curated collection of ready-to-use datasets for retrieval and rerankingâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/abdoelsayed/reranking-datasets-light.","url":"https://huggingface.co/datasets/abdoelsayed/reranking-datasets-light","creator_name":"Abdelrahman Abdallah","creator_url":"https://huggingface.co/abdoelsayed","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["question-answering","English","Arabic","German","French"],"keywords_longer_than_N":true},
	{"name":"arabic-speech-dataset","keyword":"arabic","description":"\n\t\n\t\t\n\t\tarabic-speech-dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nArabic speech dataset for TTS training with diacritized and dediacritized text variants\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nThis dataset follows the LJSpeech format with 3 columns:\n\nColumn 1: Audio file identifier\nColumn 2: Original Arabic text with diacritics\nColumn 3: Processed Arabic text (mix of diacritized and dediacritized)\n\n\n\t\n\t\t\n\t\tData Fields\n\t\n\n\naudio: Audio file (WAV format, 16kHz)\nfilename: Audio file identifier\noriginal_text:â€¦ See the full description on the dataset page: https://huggingface.co/datasets/MrEzzat/arabic-speech-dataset.","url":"https://huggingface.co/datasets/MrEzzat/arabic-speech-dataset","creator_name":"Ahmed Ezzat","creator_url":"https://huggingface.co/MrEzzat","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-to-speech","automatic-speech-recognition","Arabic","cc-by-4.0","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"arabic-speech-dataset","keyword":"arabic","description":"\n\t\n\t\t\n\t\tarabic-speech-dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nArabic speech dataset for TTS training with diacritized and dediacritized text variants\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nThis dataset follows the LJSpeech format with 3 columns:\n\nColumn 1: Audio file identifier\nColumn 2: Original Arabic text with diacritics\nColumn 3: Processed Arabic text (mix of diacritized and dediacritized)\n\n\n\t\n\t\t\n\t\tData Fields\n\t\n\n\naudio: Audio file (WAV format, 16kHz)\nfilename: Audio file identifier\noriginal_text:â€¦ See the full description on the dataset page: https://huggingface.co/datasets/MrEzzat/arabic-speech-dataset.","url":"https://huggingface.co/datasets/MrEzzat/arabic-speech-dataset","creator_name":"Ahmed Ezzat","creator_url":"https://huggingface.co/MrEzzat","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-to-speech","automatic-speech-recognition","Arabic","cc-by-4.0","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"sada-validation-preprocessed","keyword":"arabic","description":"\n\t\n\t\t\n\t\tDetails\n\t\n\nThis is the SADA 2022 dataset with the input_features whish are log mels and the cleaned_labels which is the tokenized version of the cleaned_text. You can directly use this as the validation dataset when training Whisper Tiny, Small, Base & Medium models, as they all use the same tokenizer. Please double check this as well from the original model repo.\nIn addtition, the following filters were applied to this data:\n\nAll audios are less than 30 seconds and greater than 0â€¦ See the full description on the dataset page: https://huggingface.co/datasets/mosama/sada-validation-preprocessed.","url":"https://huggingface.co/datasets/mosama/sada-validation-preprocessed","creator_name":"Muhammad Osama","creator_url":"https://huggingface.co/mosama","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","Arabic","apache-2.0","1K - 10K","parquet"],"keywords_longer_than_N":true},
	{"name":"sada-validation-preprocessed","keyword":"arabic","description":"\n\t\n\t\t\n\t\tDetails\n\t\n\nThis is the SADA 2022 dataset with the input_features whish are log mels and the cleaned_labels which is the tokenized version of the cleaned_text. You can directly use this as the validation dataset when training Whisper Tiny, Small, Base & Medium models, as they all use the same tokenizer. Please double check this as well from the original model repo.\nIn addtition, the following filters were applied to this data:\n\nAll audios are less than 30 seconds and greater than 0â€¦ See the full description on the dataset page: https://huggingface.co/datasets/mosama/sada-validation-preprocessed.","url":"https://huggingface.co/datasets/mosama/sada-validation-preprocessed","creator_name":"Muhammad Osama","creator_url":"https://huggingface.co/mosama","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","Arabic","apache-2.0","1K - 10K","parquet"],"keywords_longer_than_N":true},
	{"name":"AyaVisionBench","keyword":"arabic","description":"\n\t\n\t\t\n\t\tDataset Card for Aya Vision Benchmark\n\t\n\n\n\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\nThe Aya Vision Benchmark is designed to evaluate vision-language models in real-world multilingual scenarios. It spans 23 languages and 9 distinct task categories, with 15 samples per category, resulting in 135 image-question pairs per language. \nEach question requires visual context for the answer and covers languages that half of the world's population speaks, making this dataset particularly suited forâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/CohereLabs/AyaVisionBench.","url":"https://huggingface.co/datasets/CohereLabs/AyaVisionBench","creator_name":"Cohere Labs","creator_url":"https://huggingface.co/CohereLabs","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["English","French","German","Spanish","Italian"],"keywords_longer_than_N":true},
	{"name":"BenchMAX_Multiple_Functions","keyword":"arabic","description":"\n\t\n\t\t\n\t\tDataset Sources\n\t\n\n\nPaper: BenchMAX: A Comprehensive Multilingual Evaluation Suite for Large Language Models\nLink: https://huggingface.co/papers/2502.07346\nRepository: https://github.com/CONE-MT/BenchMAX\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nBenchMAX_Multiple_Functions is a dataset of BenchMAX, sourcing from Nexus.\nThis dataset evaluates the tool use capability in multilingual senarios, which requires a model to call the correct function given the user query and multiple functions.\nWeâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/LLaMAX/BenchMAX_Multiple_Functions.","url":"https://huggingface.co/datasets/LLaMAX/BenchMAX_Multiple_Functions","creator_name":"LLaMAX","creator_url":"https://huggingface.co/LLaMAX","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","multilingual","English","Chinese","Spanish"],"keywords_longer_than_N":true},
	{"name":"Arabic-Reranking-Triplet-5-Eval","keyword":"arabic","description":"\n\t\n\t\t\n\t\tArabic Reranking Evaluation Dataset with Multiple Negatives\n\t\n\n\n\t\n\t\t\n\t\tDataset Overview\n\t\n\nThis dataset, containing 500 rows, is curated for evaluating reranking and retrieval models in Arabic. It covers various topics, including artificial intelligence, machine learning, data analysis, technology, and education, featuring a range of query complexities and document lengths. The dataset aims to support the development and benchmarking of Arabic language models that rank informationâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/NAMAA-Space/Arabic-Reranking-Triplet-5-Eval.","url":"https://huggingface.co/datasets/NAMAA-Space/Arabic-Reranking-Triplet-5-Eval","creator_name":"Network for Advancing Modern ArabicNLP & AI","creator_url":"https://huggingface.co/NAMAA-Space","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","Arabic","apache-2.0","< 1K","parquet"],"keywords_longer_than_N":true},
	{"name":"include-base-44","keyword":"arabic","description":"\n\t\n\t\t\n\t\tINCLUDE-base (44 languages)\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\n\n\nPaper: http://arxiv.org/abs/2411.19799\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nINCLUDE is a comprehensive knowledge- and reasoning-centric benchmark across 44 languages that evaluates multilingual LLMs for performance in the actual language environments where they would be deployed. \nIt contains 22,637 4-option multiple-choice-questions (MCQ) extracted from academic and professional exams, covering 57 topics, including regionalâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/CohereLabs/include-base-44.","url":"https://huggingface.co/datasets/CohereLabs/include-base-44","creator_name":"Cohere Labs","creator_url":"https://huggingface.co/CohereLabs","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["multiple-choice","Albanian","Arabic","Armenian","Azerbaijani"],"keywords_longer_than_N":true},
	{"name":"LIMIT-GRAPH-v1.1","keyword":"arabic","description":"\n\t\n\t\t\n\t\tðŸŒ LIMIT-GRAPH v1.1\n\t\n\nLIMIT-GRAPH is a multilingual benchmark for semantic graph alignment and agentic reasoning. It includes annotated corpora in English, Indonesian, Arabic, and Spanish.\n\n\t\n\t\t\n\t\tðŸ“ Contents\n\t\n\n\ncorpora/: Annotated reasoning chains\ngraph_vocab/: Semantic vocabularies per language\nedges/: Graph edges for alignment\nevaluation/: Harness and metrics\n\n\n\t\n\t\t\n\t\tðŸ§  Use Cases\n\t\n\n\nTrain and evaluate multilingual agents\nAlign reasoning chains to semantic graphs\nSubmit agents toâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/AIResAgTeam/LIMIT-GRAPH-v1.1.","url":"https://huggingface.co/datasets/AIResAgTeam/LIMIT-GRAPH-v1.1","creator_name":"AI Research Agent Team","creator_url":"https://huggingface.co/AIResAgTeam","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":null,"first_N":5,"first_N_keywords":["English","Indonesian","Arabic","Spanish","mit"],"keywords_longer_than_N":true},
	{"name":"x-self-instruct-seed-32","keyword":"arabic","description":"\n\t\n\t\t\n\t\tDataset Card for xOA22 - Multilingual Prompts from OpenAssistant\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nx-self-instruct-seed-32 consists of 32 prompts chosen out of the 252 prompts in the self-instruct-seed dataset from the Self-Instruct paper. These 32 prompts were filtered out according to the following criteria:\n\nShould be natural in a chat setting\nTherefore, we filter out any prompts with \"few-shot examples\", as these are all instruction prompts that we consider unnatural in a chat settingâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/sambanovasystems/x-self-instruct-seed-32.","url":"https://huggingface.co/datasets/sambanovasystems/x-self-instruct-seed-32","creator_name":"SambaNova","creator_url":"https://huggingface.co/sambanovasystems","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["Arabic","Spanish","English","Hindi","French"],"keywords_longer_than_N":true},
	{"name":"cvss","keyword":"arabic","description":"CVSS is a massively multilingual-to-English speech-to-speech translation corpus,\ncovering sentence-level parallel speech-to-speech translation pairs from 21\nlanguages into English.","url":"https://huggingface.co/datasets/google/cvss","creator_name":"Google","creator_url":"https://huggingface.co/google","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":null,"first_N":5,"first_N_keywords":["English","Arabic","Catalan","Welsh","German"],"keywords_longer_than_N":true},
	{"name":"DIDI","keyword":"arabic","description":"PeepDaSlan9/DIDI dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/PeepDaSlan9/DIDI","creator_name":"Ohenenoo","creator_url":"https://huggingface.co/PeepDaSlan9","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":null,"first_N":5,"first_N_keywords":["text-classification","table-question-answering","question-answering","translation","summarization"],"keywords_longer_than_N":true},
	{"name":"Pornhub","keyword":"arabic","description":"\n\t\n\t\t\n\t\tPornhub Dataset\n\t\n\nThe Pornhub Dataset provides a comprehensive collection of data sourced from pornhub.com, encompassing various details from MANYYY videos available on the platform.\nThe file consists of 742.133 lines of videos.\n\n\t\n\t\t\n\t\tData Description\n\t\n\n\nDelimiter: â€½\nFile Format: CSV\nContent:\nURL: The URL of the video.\nCategory: The genre or category of the video.\nUser: The username of the uploader.\nVideo_title: The title of the video.\nViews: The number of views the video hasâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Nikity/Pornhub.","url":"https://huggingface.co/datasets/Nikity/Pornhub","creator_name":"Nikita","creator_url":"https://huggingface.co/Nikity","license_name":"Open Data Commons Attribution License v1.0","license_url":"https://scancode-licensedb.aboutcode.org/odc-by-1.0.html","language":"en","first_N":5,"first_N_keywords":["Albanian","Arabic","Bengali","Bulgarian","Chinese"],"keywords_longer_than_N":true},
	{"name":"xtreme","keyword":"arabic","description":"\n\t\n\t\t\n\t\tDataset Card for \"xtreme\"\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThe Cross-lingual Natural Language Inference (XNLI) corpus is a crowd-sourced collection of 5,000 test and\n2,500 dev pairs for the MultiNLI corpus. The pairs are annotated with textual entailment and translated into\n14 languages: French, Spanish, German, Greek, Bulgarian, Russian, Turkish, Arabic, Vietnamese, Thai, Chinese,\nHindi, Swahili and Urdu. This results in 112.5k annotated pairs. Each premise can be associated with theâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/google/xtreme.","url":"https://huggingface.co/datasets/google/xtreme","creator_name":"Google","creator_url":"https://huggingface.co/google","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["multiple-choice","question-answering","token-classification","text-classification","text-retrieval"],"keywords_longer_than_N":true},
	{"name":"tatoeba_mt","keyword":"arabic","description":"The Tatoeba Translation Challenge is a multilingual data set of\nmachine translation benchmarks derived from user-contributed\ntranslations collected by [Tatoeba.org](https://tatoeba.org/) and\nprovided as parallel corpus from [OPUS](https://opus.nlpl.eu/). This\ndataset includes test and development data sorted by language pair. It\nincludes test sets for hundreds of language pairs and is continuously\nupdated. Please, check the version number tag to refer to the release\nthat your are using.","url":"https://huggingface.co/datasets/Helsinki-NLP/tatoeba_mt","creator_name":"Language Technology Research Group at the University of Helsinki","creator_url":"https://huggingface.co/Helsinki-NLP","license_name":"Creative Commons Attribution 2.0","license_url":"https://scancode-licensedb.aboutcode.org/cc-by-2.0.html","language":null,"first_N":5,"first_N_keywords":["text-generation","translation","no-annotation","crowdsourced","translation"],"keywords_longer_than_N":true},
	{"name":"arabic_speech_corpus","keyword":"arabic","description":"This Speech corpus has been developed as part of PhD work carried out by Nawar Halabi at the University of Southampton.\nThe corpus was recorded in south Levantine Arabic\n(Damascian accent) using a professional studio. Synthesized speech as an output using this corpus has produced a high quality, natural voice.\nNote that in order to limit the required storage for preparing this dataset, the audio\nis stored in the .flac format and is not converted to a float32 array. To convert, the audio\nfile to a float32 array, please make use of the `.map()` function as follows:\n\n\n```python\nimport soundfile as sf\n\ndef map_to_array(batch):\n    speech_array, _ = sf.read(batch[\"file\"])\n    batch[\"speech\"] = speech_array\n    return batch\n\ndataset = dataset.map(map_to_array, remove_columns=[\"file\"])\n```","url":"https://huggingface.co/datasets/halabi2016/arabic_speech_corpus","creator_name":"halabi2016","creator_url":"https://huggingface.co/halabi2016","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":null,"first_N":5,"first_N_keywords":["automatic-speech-recognition","expert-generated","crowdsourced","monolingual","original"],"keywords_longer_than_N":true},
	{"name":"opus_infopankki","keyword":"arabic","description":"\n\t\n\t\t\n\t\tDataset Card for infopankki\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nA parallel corpus of 12 languages, 66 bitexts.\n\n\t\n\t\t\n\t\tSupported Tasks and Leaderboards\n\t\n\nThe underlying task is machine translation.\n\n\t\n\t\t\n\t\tLanguages\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\n\t\n\t\t\n\t\tData Instances\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tData Fields\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tData Splits\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tDataset Creation\n\t\n\n\n\t\n\t\t\n\t\tCuration Rationale\n\t\n\n[Moreâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Helsinki-NLP/opus_infopankki.","url":"https://huggingface.co/datasets/Helsinki-NLP/opus_infopankki","creator_name":"Language Technology Research Group at the University of Helsinki","creator_url":"https://huggingface.co/Helsinki-NLP","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["translation","found","found","multilingual","original"],"keywords_longer_than_N":true},
	{"name":"x-stcksa-media","keyword":"arabic","description":"\n\t\n\t\t\n\t\tTwitter Media Dataset - @stc_ksa\n\t\n\nThis dataset contains images and metadata extracted from the Twitter/X profile @stc_ksa.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\n\t\n\t\t\n\t\tData Instances\n\t\n\nThe dataset consists of:\n\nimages/: Directory containing 293 JPG images\nmetadata.json: Detailed metadata for each image including tweet information\n\n\n\t\n\t\t\n\t\tData Fields\n\t\n\nEach item in the metadata contains:\n\ntweet_id: Unique identifier for the tweet\nusername: Source username (stc_ksa)\ntext: Tweet text contentâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/rsalshalan/x-stcksa-media.","url":"https://huggingface.co/datasets/rsalshalan/x-stcksa-media","creator_name":"Raghad s","creator_url":"https://huggingface.co/rsalshalan","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["image-classification","other","Arabic","English","mit"],"keywords_longer_than_N":true},
	{"name":"PsiloQA","keyword":"arabic","description":"\n\n\t\n\t\t\n\t\tWhat is it?\n\t\n\nPsiloQA is the largest dataset for training and evaluating systems on multilingual span-level hallucination detection with retrieved context. It offers:\n\nAn automated and scalable pipeline for generating, annotating and filtering data for hallucination detection task\nA large multilingual dataset for 14 languages with high-quality and fine-grained span-level hallucination annotations for numerous open-source LLMs\nA comprehensive empirical evaluations of variousâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/s-nlp/PsiloQA.","url":"https://huggingface.co/datasets/s-nlp/PsiloQA","creator_name":"s-nlp","creator_url":"https://huggingface.co/s-nlp","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["token-classification","text-classification","text-generation","zero-shot-classification","question-answering"],"keywords_longer_than_N":true},
	{"name":"EXAMs","keyword":"arabic","description":"\n\t\n\t\t\n\t\tEXAMs\n\t\n\nYou can find details of the dataset in this post:https://arxiv.org/pdf/2308.16149.pdf\n\n\t\n\t\t\n\t\tAbout this Arabic dataset\n\t\n\nWe only took the Arabic part of the dataset,which contains 562 data.We then extracted five from each category based on the task domain as a few shot data.\n","url":"https://huggingface.co/datasets/FreedomIntelligence/EXAMs","creator_name":"FreedomAI","creator_url":"https://huggingface.co/FreedomIntelligence","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["multiple-choice","Arabic","apache-2.0","n<1K","arxiv:2308.16149"],"keywords_longer_than_N":true},
	{"name":"common_voice_16_0","keyword":"arabic","description":"\n\t\n\t\t\n\t\tDataset Card for Common Voice Corpus 16.0\n\t\n\n\n\nThis dataset is an unofficial version of the Mozilla Common Voice Corpus 16. It was downloaded and converted from the project's website https://commonvoice.mozilla.org/.\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nAbkhaz, Albanian, Amharic, Arabic, Armenian, Assamese, Asturian, Azerbaijani, Basaa, Bashkir, Basque, Belarusian, Bengali, Breton, Bulgarian, Cantonese, Catalan, Central Kurdish, Chinese (China), Chinese (Hong Kong), Chinese (Taiwan), Chuvash, Czechâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fsicoli/common_voice_16_0.","url":"https://huggingface.co/datasets/fsicoli/common_voice_16_0","creator_name":"Fabio Sicoli","creator_url":"https://huggingface.co/fsicoli","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":null,"first_N":5,"first_N_keywords":["automatic-speech-recognition","Abkhaz","Afrikaans","Amharic","Arabic"],"keywords_longer_than_N":true},
	{"name":"semeval-2016-absa-reviews-arabic","keyword":"arabic","description":"\n\t\n\t\t\n\t\tDataset Card for Dataset Name\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nAspect based sentiment analysis dataset using hotel reviews in Arabic.\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nArabic\n\n\t\n\t\t\n\t\tLicensing Information\n\t\n\nOriginal dataset was licensed under MIT, so this is also under MIT\n\n\t\n\t\t\n\t\tCitation Information\n\t\n\nCite this and the original authors if you want to.\n","url":"https://huggingface.co/datasets/srinivasbilla/semeval-2016-absa-reviews-arabic","creator_name":"Srinivas Billa","creator_url":"https://huggingface.co/srinivasbilla","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","Arabic","mit","10K - 100K","csv"],"keywords_longer_than_N":true},
	{"name":"Gulf-Arabic-Tweets-2018-2020","keyword":"arabic","description":"\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis is a pre-processed (cleaned) Twitter Gulf Arabic dialect 2018-2020 dataset. Pleasre refer to the  source, and data cleaning code and algorithm Github.\n\n\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nArabic\n\n\t\n\t\t\n\t\tSource Data\n\t\n\nTwitter\n","url":"https://huggingface.co/datasets/AhmedSSabir/Gulf-Arabic-Tweets-2018-2020","creator_name":"Ahmed Sabir","creator_url":"https://huggingface.co/AhmedSSabir","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","Arabic","cc-by-4.0","100K - 1M","csv"],"keywords_longer_than_N":true},
	{"name":"tydiqa","keyword":"arabic","description":"\n\t\n\t\t\n\t\tDataset Card for \"tydiqa\"\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nTyDi QA is a question answering dataset covering 11 typologically diverse languages with 204K question-answer pairs.\nThe languages of TyDi QA are diverse with regard to their typology -- the set of linguistic features that each language\nexpresses -- such that we expect models performing well on this set to generalize across a large number of the languages\nin the world. It contains language phenomena that would not be found inâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/google-research-datasets/tydiqa.","url":"https://huggingface.co/datasets/google-research-datasets/tydiqa","creator_name":"Google Research Datasets","creator_url":"https://huggingface.co/google-research-datasets","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["question-answering","extractive-qa","crowdsourced","crowdsourced","multilingual"],"keywords_longer_than_N":true},
	{"name":"argilla-dpo-mix-7k-arabic","keyword":"arabic","description":"medmac01/argilla-dpo-mix-7k-arabic dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/medmac01/argilla-dpo-mix-7k-arabic","creator_name":"Mohammed Machrouh","creator_url":"https://huggingface.co/medmac01","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["Arabic","mit","1K - 10K","parquet","Tabular"],"keywords_longer_than_N":true},
	{"name":"Arabic-Text-to-Sign-Language-Translation","keyword":"arabic","description":"Selimx2001x/Arabic-Text-to-Sign-Language-Translation dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/Selimx2001x/Arabic-Text-to-Sign-Language-Translation","creator_name":"mahmoud moahmed mahmoud","creator_url":"https://huggingface.co/Selimx2001x","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":null,"first_N":5,"first_N_keywords":["translation","Arabic","apache-2.0","1K<n<10K","ðŸ‡ºðŸ‡¸ Region: US"],"keywords_longer_than_N":true},
	{"name":"Arabic-Text-to-Sign-Language-Translation","keyword":"arabic","description":"Selimx2001x/Arabic-Text-to-Sign-Language-Translation dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/Selimx2001x/Arabic-Text-to-Sign-Language-Translation","creator_name":"mahmoud moahmed mahmoud","creator_url":"https://huggingface.co/Selimx2001x","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":null,"first_N":5,"first_N_keywords":["translation","Arabic","apache-2.0","1K<n<10K","ðŸ‡ºðŸ‡¸ Region: US"],"keywords_longer_than_N":true},
	{"name":"openassistant-deepseek-coder","keyword":"arabic","description":"\n\t\n\t\t\n\t\tChat Fine-tuning Dataset - OpenAssistant DeepSeek Coder\n\t\n\nThis dataset allows for fine-tuning chat models using:\nB_INST = '\\n### Instruction:\\n'\nE_INST = '\\n### Response:\\n'\nBOS = '<ï½œbeginâ–ofâ–sentenceï½œ>'\nEOS = '\\n<|EOT|>\\n'\n\nSample Preparation:\n\nThe dataset is cloned from TimDettmers, which itself is a subset of the Open Assistant dataset, which you can find here. This subset of the data only contains the highest-rated paths in the conversation tree, with a total of 9,846 samples.\nTheâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Trelis/openassistant-deepseek-coder.","url":"https://huggingface.co/datasets/Trelis/openassistant-deepseek-coder","creator_name":"Trelis","creator_url":"https://huggingface.co/Trelis","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["English","Spanish","Russian","German","Polish"],"keywords_longer_than_N":true},
	{"name":"arabic-qna","keyword":"arabic","description":"\n\t\n\t\t\n\t\tSadeem QnA: An Arabic QnA Dataset ðŸŒâœ¨\n\t\n\nWelcome to the Sadeem QnA dataset, a vibrant collection designed for the advancement of Arabic natural language processing, specifically tailored for Question Answering (QnA) systems. Sourced from the rich and diverse content of Arabic Wikipedia, this dataset is a gateway to exploring the depths of Arabic language understanding, offering a unique challenge to both researchers and AI enthusiasts alike.\n\n\t\n\t\t\n\t\n\t\n\t\tAbout Sadeem QnA\n\t\n\nThe Sadeemâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/sadeem-ai/arabic-qna.","url":"https://huggingface.co/datasets/sadeem-ai/arabic-qna","creator_name":"Sadeem","creator_url":"https://huggingface.co/sadeem-ai","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["question-answering","Arabic","apache-2.0","1K - 10K","csv"],"keywords_longer_than_N":true},
	{"name":"xtreme_s","keyword":"arabic","description":"XTREME-S covers four task families: speech recognition, classification, speech-to-text translation and retrieval. Covering 102\nlanguages from 10+ language families, 3 different domains and 4\ntask families, XTREME-S aims to simplify multilingual speech\nrepresentation evaluation, as well as catalyze research in â€œuniversalâ€ speech representation learning.","url":"https://huggingface.co/datasets/google/xtreme_s","creator_name":"Google","creator_url":"https://huggingface.co/google","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":null,"first_N":5,"first_N_keywords":["automatic-speech-recognition","expert-generated","crowdsourced","machine-generated","crowdsourced"],"keywords_longer_than_N":true},
	{"name":"moroccan-darija-youtube-subtitles","keyword":"arabic","description":"\n\t\n\t\t\n\t\tMoroccan Darija YouTube Subtitles Dataset\n\t\n\nThis dataset contains subtitles from YouTube videos in Moroccan Darija, a colloquial Arabic dialect spoken in Morocco. The subtitles were collected from several popular Moroccan YouTube channels, providing a diverse set of transcriptions in the Darija language.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset is provided as a CSV file, where each row represents a YouTube video and contains the following columns:\n\nvideo_id: The unique identifier ofâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/bourbouh/moroccan-darija-youtube-subtitles.","url":"https://huggingface.co/datasets/bourbouh/moroccan-darija-youtube-subtitles","creator_name":"Hamza Bourbouh","creator_url":"https://huggingface.co/bourbouh","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["other","language-modeling","no-annotation","machine-generated","monolingual"],"keywords_longer_than_N":true},
	{"name":"text_coordinates_seasons","keyword":"arabic","description":"\n\t\n\t\t\n\t\tDataset Card for Geo-Tagged Social Media Posts with Timestamps\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThe \"Seasons\" dataset is a collection of over 600,000 social media posts spanning 12 months and encompassing 15 distinct time zones. It focuses on six countries: Cuba, Iran, Russia, North Korea, Syria, and Venezuela, with each post containing textual content, timestamps, and geographical coordinates. The dataset's primary objective is to investigate the correlation between the timing of postsâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/yachay/text_coordinates_seasons.","url":"https://huggingface.co/datasets/yachay/text_coordinates_seasons","creator_name":"Yachay AI","creator_url":"https://huggingface.co/yachay","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","token-classification","text-classification","English","Spanish"],"keywords_longer_than_N":true},
	{"name":"yy-chat-ar-20240327","keyword":"arabic","description":"\n\t\n\t\t\n\t\tDataset Card for Dataset Name\n\t\n\n\n\nThis dataset card aims to be a base template for new datasets. It has been generated using this raw template.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\n\n\n\n\n\nCurated by: [More Information Needed]\nFunded by [optional]: [More Information Needed]\nShared by [optional]: [More Information Needed]\nLanguage(s) (NLP): [More Information Needed]\nLicense: [More Information Needed]\n\n\n\t\n\t\t\n\t\tDataset Sources [optional]\n\t\n\n\n\n\nRepository: [Moreâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/yongyi169/yy-chat-ar-20240327.","url":"https://huggingface.co/datasets/yongyi169/yy-chat-ar-20240327","creator_name":"yongyi","creator_url":"https://huggingface.co/yongyi169","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["question-answering","Arabic","apache-2.0","1K - 10K","parquet"],"keywords_longer_than_N":true},
	{"name":"LoLLMS-Open-Community-discussions","keyword":"arabic","description":"\n\t\n\t\t\n\t\tDataset Card for GPT4All-Community-Discussions\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset contains ethically gathered discussions from the community, who shared their experiences with various open source discussion models using the GPT4All-ui tool. The dataset is open for any use, including commercial use, as long as proper citation is given to acknowledge the contributions of the community. \nThe GPT4All-ui tool allows users to have conversations with various open source AIs andâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/ParisNeo/LoLLMS-Open-Community-discussions.","url":"https://huggingface.co/datasets/ParisNeo/LoLLMS-Open-Community-discussions","creator_name":"Saifeddine ALOUI","creator_url":"https://huggingface.co/ParisNeo","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["English","French","German","Arabic","Italian"],"keywords_longer_than_N":true},
	{"name":"ara-stance","keyword":"arabic","description":"The AraStance dataset contains true and false claims, where each claim is paired with one or more documents. Each claimâ€“article pair has a stance label: agree, disagree, discuss, or unrelated.","url":"https://huggingface.co/datasets/strombergnlp/ara-stance","creator_name":"StrÃ¸mberg NLP","creator_url":"https://huggingface.co/strombergnlp","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":null,"first_N":5,"first_N_keywords":["text-classification","fact-checking","crowdsourced","found","monolingual"],"keywords_longer_than_N":true},
	{"name":"hatecheck-arabic","keyword":"arabic","description":"\n\t\n\t\t\n\t\tDataset Card for Multilingual HateCheck\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nMultilingual HateCheck (MHC) is a suite of functional tests for hate speech detection models in 10 different languages: Arabic, Dutch, French, German, Hindi, Italian, Mandarin, Polish, Portuguese and Spanish.\nFor each language, there are 25+ functional tests that correspond to distinct types of hate and challenging non-hate.\nThis allows for targeted diagnostic insights into model performance.\nFor more detailsâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Paul/hatecheck-arabic.","url":"https://huggingface.co/datasets/Paul/hatecheck-arabic","creator_name":"Paul RÃ¶ttger","creator_url":"https://huggingface.co/Paul","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","hate-speech-detection","crowdsourced","expert-generated","monolingual"],"keywords_longer_than_N":true},
	{"name":"Rasaif-Classical-Arabic-English-Parallel-texts","keyword":"arabic","description":"\n\t\n\t\t\n\t\tIntroduction\n\t\n\nThis dataset represents a curated collection of parallel Arabic-English texts, featuring the translations of 24 historically and culturally significant books. These texts provide a portal to the intellectual and literary heritage of the Arabic-speaking world during its classical period.\n\n\t\n\t\t\n\t\tContent Details\n\t\n\nContained within this dataset are English translations of the following texts, sourced from the Rasaif website:\n\nA Muslim Manual of War\nAl-Hanin Ila'l-Awtanâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/ImruQays/Rasaif-Classical-Arabic-English-Parallel-texts.","url":"https://huggingface.co/datasets/ImruQays/Rasaif-Classical-Arabic-English-Parallel-texts","creator_name":"Qays","creator_url":"https://huggingface.co/ImruQays","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["translation","Arabic","English","cc-by-4.0","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"oscar-small","keyword":"arabic","description":"The Open Super-large Crawled ALMAnaCH coRpus is a huge multilingual corpus obtained by language classification and filtering of the Common Crawl corpus using the goclassy architecture.\\","url":"https://huggingface.co/datasets/djstrong/oscar-small","creator_name":"Krzysztof WrÃ³bel","creator_url":"https://huggingface.co/djstrong","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","language-modeling","no-annotation","found","multilingual"],"keywords_longer_than_N":true},
	{"name":"oscar-small","keyword":"arabic","description":"The Open Super-large Crawled ALMAnaCH coRpus is a huge multilingual corpus obtained by language classification and filtering of the Common Crawl corpus using the goclassy architecture.\\","url":"https://huggingface.co/datasets/nthngdy/oscar-small","creator_name":"Nathan Godey","creator_url":"https://huggingface.co/nthngdy","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","language-modeling","no-annotation","found","multilingual"],"keywords_longer_than_N":true},
	{"name":"multilingual-pl-bert","keyword":"arabic","description":"Attribution: Wikipedia.org\n","url":"https://huggingface.co/datasets/styletts2-community/multilingual-pl-bert","creator_name":"StyleTTS 2 Community","creator_url":"https://huggingface.co/styletts2-community","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["Afrikaans","Aragonese","Arabic","Azerbaijani","Bashkir"],"keywords_longer_than_N":true},
	{"name":"miracl","keyword":"arabic","description":"\n\t\n\t\t\n\t\tDataset Card for MIRACL (Topics and Qrels)\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nHomepage | \nRepository: | \nPaper | \nArXiv\nMIRACL ðŸŒðŸ™ŒðŸŒ (Multilingual Information Retrieval Across a Continuum of Languages) is a multilingual retrieval dataset that focuses on search across 18 different languages, which collectively encompass over three billion native speakers around the world.\nThis dataset contains the collection data of the 16 \"known languages\". The remaining 2 \"surprise languages\" will notâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/miracl/miracl.","url":"https://huggingface.co/datasets/miracl/miracl","creator_name":"MIRACL","creator_url":"https://huggingface.co/miracl","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":null,"first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","expert-generated","multilingual","Arabic"],"keywords_longer_than_N":true},
	{"name":"oscar-small","keyword":"egyptian arabic","description":"The Open Super-large Crawled ALMAnaCH coRpus is a huge multilingual corpus obtained by language classification and filtering of the Common Crawl corpus using the goclassy architecture.\\","url":"https://huggingface.co/datasets/djstrong/oscar-small","creator_name":"Krzysztof WrÃ³bel","creator_url":"https://huggingface.co/djstrong","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","language-modeling","no-annotation","found","multilingual"],"keywords_longer_than_N":true},
	{"name":"oscar-small","keyword":"egyptian arabic","description":"The Open Super-large Crawled ALMAnaCH coRpus is a huge multilingual corpus obtained by language classification and filtering of the Common Crawl corpus using the goclassy architecture.\\","url":"https://huggingface.co/datasets/nthngdy/oscar-small","creator_name":"Nathan Godey","creator_url":"https://huggingface.co/nthngdy","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","language-modeling","no-annotation","found","multilingual"],"keywords_longer_than_N":true},
	{"name":"Thaqalayn-Classical-Arabic-English-Parallel-texts","keyword":"arabic","description":"\n\t\n\t\t\n\t\tIntroduction\n\t\n\nThis dataset represents a comprehensive collection of parallel Arabic-English texts from the Thaqalayn Hadith Library, a premier source for exploring the classical hadith tradition of the ImÄmÄ« Shia Muslim school of thought. The library focuses on making primary historical sources accessible, serving as a bridge between past wisdom and contemporary study. The dataset features translations of significant classical ImÄmÄ« hadith texts, allowing for a deep dive into theâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/ImruQays/Thaqalayn-Classical-Arabic-English-Parallel-texts.","url":"https://huggingface.co/datasets/ImruQays/Thaqalayn-Classical-Arabic-English-Parallel-texts","creator_name":"Qays","creator_url":"https://huggingface.co/ImruQays","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["translation","Arabic","English","cc-by-4.0","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"MultiJail","keyword":"arabic","description":"\n\t\n\t\t\n\t\tMultilingual Jailbreak Challenges in Large Language Models\n\t\n\nThis repo contains the data for our paper \"Multilingual Jailbreak Challenges in Large Language Models\".\n[Github repo]\n\n\t\n\t\t\n\t\tAnnotation Statistics\n\t\n\nWe collected a total of 315 English unsafe prompts and annotated them into nine non-English languages. The languages were categorized based on resource availability, as shown below:\nHigh-resource languages: Chinese (zh), Italian (it), Vietnamese (vi)\nMedium-resource languages:â€¦ See the full description on the dataset page: https://huggingface.co/datasets/DAMO-NLP-SG/MultiJail.","url":"https://huggingface.co/datasets/DAMO-NLP-SG/MultiJail","creator_name":"Language Technology Lab at Alibaba DAMO Academy","creator_url":"https://huggingface.co/DAMO-NLP-SG","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["English","Chinese","Italian","Vietnamese","Arabic"],"keywords_longer_than_N":true},
	{"name":"Arabic_Quotes","keyword":"arabic","description":"\n\t\n\t\t\n\t\tArabic Quotes Dataset\n\t\n\n\n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tOverview\n\t\n\nThe Arabic Quotes Dataset is an open-source collection of 5900+ quotes in the Arabic language, accompanied by up to three tags for each quote. \nThe dataset is suitable for various Natural Language Processing (NLP) tasks, such as text classification and tagging.\n\t\n\t\t\n\t\tData Description\n\t\n\n\nContains 5900+ quotes with up to three associated tags per quote.\nAll quotes and tags are in Arabic.\n\n\n\t\n\t\t\n\t\tUse Cases\n\t\n\n\nText Classification:â€¦ See the full description on the dataset page: https://huggingface.co/datasets/AhmedBou/Arabic_Quotes.","url":"https://huggingface.co/datasets/AhmedBou/Arabic_Quotes","creator_name":"Ahmed Khalil Boulahia","creator_url":"https://huggingface.co/AhmedBou","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","text-generation","Arabic","apache-2.0","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"miracl-ar-queries-22-12","keyword":"arabic","description":"\n\t\n\t\t\n\t\tMIRACL (ar) embedded with cohere.ai multilingual-22-12 encoder\n\t\n\nWe encoded the MIRACL dataset using the cohere.ai multilingual-22-12 embedding model.\nThe query embeddings can be found in Cohere/miracl-ar-queries-22-12 and the corpus embeddings can be found in Cohere/miracl-ar-corpus-22-12.\nFor the orginal datasets, see miracl/miracl and miracl/miracl-corpus.\nDataset info:\n\nMIRACL ðŸŒðŸ™ŒðŸŒ (Multilingual Information Retrieval Across a Continuum of Languages) is a multilingual retrievalâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Cohere/miracl-ar-queries-22-12.","url":"https://huggingface.co/datasets/Cohere/miracl-ar-queries-22-12","creator_name":"Cohere","creator_url":"https://huggingface.co/Cohere","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","expert-generated","multilingual","Arabic"],"keywords_longer_than_N":true},
	{"name":"miracl-ar-corpus-22-12","keyword":"arabic","description":"\n\t\n\t\t\n\t\tMIRACL (ar) embedded with cohere.ai multilingual-22-12 encoder\n\t\n\nWe encoded the MIRACL dataset using the cohere.ai multilingual-22-12 embedding model.\nThe query embeddings can be found in Cohere/miracl-ar-queries-22-12 and the corpus embeddings can be found in Cohere/miracl-ar-corpus-22-12.\nFor the orginal datasets, see miracl/miracl and miracl/miracl-corpus.\nDataset info:\n\nMIRACL ðŸŒðŸ™ŒðŸŒ (Multilingual Information Retrieval Across a Continuum of Languages) is a multilingual retrievalâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Cohere/miracl-ar-corpus-22-12.","url":"https://huggingface.co/datasets/Cohere/miracl-ar-corpus-22-12","creator_name":"Cohere","creator_url":"https://huggingface.co/Cohere","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","expert-generated","multilingual","Arabic"],"keywords_longer_than_N":true},
	{"name":"ASAD","keyword":"arabic","description":"\n\t\n\t\t\n\t\tDataset Card for \"Arab States Analogy Dataset (ASAD)\"\n\t\n\nThis dataset is created using 20 Arab States1 with their corresponding capital cities, nationalities, currencies, and on which continents they are located, consisting of four sets: country-capital set, country-currency set, country-nationality set, and country-continent set. Each set has 380 word analogies, and the total number of word analogies in the ASAD dataset is 1520. This dataset is used to evaluate Arabic Word Embeddingâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/SaiedAlshahrani/ASAD.","url":"https://huggingface.co/datasets/SaiedAlshahrani/ASAD","creator_name":"Saied Alshahrani","creator_url":"https://huggingface.co/SaiedAlshahrani","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["Arabic","mit","1K - 10K","csv","Text"],"keywords_longer_than_N":true},
	{"name":"tydiqa_copenlu","keyword":"arabic","description":"\n\t\n\t\t\n\t\tDataset Card for \"tydiqa\"\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nTyDi QA is a question answering dataset covering 11 typologically diverse languages with 204K question-answer pairs.\nThe languages of TyDi QA are diverse with regard to their typology -- the set of linguistic features that each language\nexpresses -- such that we expect models performing well on this set to generalize across a large number of the languages\nin the world. It contains language phenomena that would not be found inâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/copenlu/tydiqa_copenlu.","url":"https://huggingface.co/datasets/copenlu/tydiqa_copenlu","creator_name":"CopeNLU","creator_url":"https://huggingface.co/copenlu","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["question-answering","extractive-qa","crowdsourced","crowdsourced","multilingual"],"keywords_longer_than_N":true},
	{"name":"QAmeleon","keyword":"arabic","description":"\n\t\n\t\t\n\t\tDataset Card for \"QAmeleon\"\n\t\n\nQAmeleon introduces synthetic multilingual QA data contaning in 8 langauges using PaLM-540B, a large language model. This dataset was generated by prompt tuning PaLM with only five examples per language. We use the synthetic data to finetune downstream QA models leading to improved accuracy in comparison to English-only and translation-based baselines. \nData available at https://storage.googleapis.com/qameleon/qamelon_pt_accepted.csv \nMore details can beâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/imvladikon/QAmeleon.","url":"https://huggingface.co/datasets/imvladikon/QAmeleon","creator_name":"Vladimir Gurevich","creator_url":"https://huggingface.co/imvladikon","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["question-answering","Arabic","Bengali","Finnish","Indonesian"],"keywords_longer_than_N":true},
	{"name":"openassistant-guanaco-EOS","keyword":"arabic","description":"\n\t\n\t\t\n\t\tChat Fine-tuning Dataset - Guanaco Style\n\t\n\nThis dataset allows for fine-tuning chat models using \"### Human:\" AND \"### Assistant\" as the beginning and end of sequence tokens.\nPreparation:\n\nThe dataset is cloned from TimDettmers, which itself is a subset of the Open Assistant dataset, which you can find here. This subset of the data only contains the highest-rated paths in the conversation tree, with a total of 9,846 samples.\nThe dataset was then slightly adjusted to:\n\n\nif a row ofâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Trelis/openassistant-guanaco-EOS.","url":"https://huggingface.co/datasets/Trelis/openassistant-guanaco-EOS","creator_name":"Trelis","creator_url":"https://huggingface.co/Trelis","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["English","Spanish","Russian","German","Polish"],"keywords_longer_than_N":true},
	{"name":"nomiracl","keyword":"arabic","description":"Data Loader for the NoMIRACL dataset.","url":"https://huggingface.co/datasets/miracl/nomiracl","creator_name":"MIRACL","creator_url":"https://huggingface.co/miracl","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":null,"first_N":5,"first_N_keywords":["text-classification","expert-generated","multilingual","miracl/miracl","Arabic"],"keywords_longer_than_N":true},
	{"name":"Wikinews-multilingual","keyword":"arabic","description":"\n\t\n\t\t\n\t\tWikinews - weakly aligned multilingual pararell sentence datasets\n\t\n\nThis dataset contains 15,200 multilingual WikiNews articles in 33 languages.\nOut of 15,200 articles, 9,960 are non-English news and 5240 are English news.  All non-English news are linked to one of 5240 English news. Linked articles show the same event.\nList of non-English languages are: Spanish, French, German, Portuguese, Polish, Italian, Chinese, Russian, Japanese, Dutch, Swedish, Tamil, Serbian, Czech, Catalanâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Fumika/Wikinews-multilingual.","url":"https://huggingface.co/datasets/Fumika/Wikinews-multilingual","creator_name":"Fumika Isono","creator_url":"https://huggingface.co/Fumika","license_name":"Creative Commons Attribution 2.5","license_url":"https://scancode-licensedb.aboutcode.org/cc-by-2.5.html","language":"en","first_N":5,"first_N_keywords":["text-classification","feature-extraction","English","Spanish","French"],"keywords_longer_than_N":true},
	{"name":"dz-sentiment-yt-comments","keyword":"arabic","description":"\n\t\n\t\t\n\t\tA Sentiment Analysis Dataset for the Algerian Dialect of Arabic\n\t\n\nThis dataset consists of 50,016 samples of comments extracted from Algerian YouTube channels. It is manually annotated with 3 classes (the label column) and is not balanced. Here are the number of rows of each class:\n\n0 (Negative): 17,033 (34.06%)\n1 (Neutral): 11,136 (22.26%)\n2 (Positive): 21,847 (43.68%)\n\nPlease note that there are some swear words in the dataset, so please use it with caution.\n\n\t\n\t\t\n\t\n\t\n\t\tCitationâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Abdou/dz-sentiment-yt-comments.","url":"https://huggingface.co/datasets/Abdou/dz-sentiment-yt-comments","creator_name":"Rockikz","creator_url":"https://huggingface.co/Abdou","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","Arabic","mit","10K - 100K","csv"],"keywords_longer_than_N":true},
	{"name":"Goud-Sum-Instruct","keyword":"arabic","description":"\n\t\n\t\t\n\t\tDataset Card for Goud-Sum-Instruct\n\t\n\nGoud-Sum-Instruct is a meticulously curated dataset originating from Goud-sum dataset, This dataset is primed for fine-tuning chat and instruct models, without any compromise to the existing training mode. This strategic approach enables the specific training of models to respond effectively to the main instruction which is \"To Summarise\". In conclusion, this dataset is meant to finetune a chat model in order to serve later as a summarizer.â€¦ See the full description on the dataset page: https://huggingface.co/datasets/alielfilali01/Goud-Sum-Instruct.","url":"https://huggingface.co/datasets/alielfilali01/Goud-Sum-Instruct","creator_name":"Ali El Filali","creator_url":"https://huggingface.co/alielfilali01","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["summarization","Arabic","apache-2.0","100K - 1M","parquet"],"keywords_longer_than_N":true},
	{"name":"Table-Extraction","keyword":"arabic","description":"\n\t\n\t\t\n\t\tTable Extract Dataset\n\t\n\nThis dataset is designed to evaluate the ability of large language models (LLMs) to extract tables from text. It provides a collection of text snippets containing tables and their corresponding structured representations in JSON format.\n\n\t\n\t\t\n\t\tSource\n\t\n\nThe dataset is based on the Table Fact Dataset, also known as TabFact, which contains 16,573 tables extracted from Wikipedia.\n\n\t\n\t\t\n\t\tSchema:\n\t\n\nEach data point in the dataset consists of two elements:â€¦ See the full description on the dataset page: https://huggingface.co/datasets/Effyis/Table-Extraction.","url":"https://huggingface.co/datasets/Effyis/Table-Extraction","creator_name":"Group","creator_url":"https://huggingface.co/Effyis","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","English","Arabic","apache-2.0","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"AjwaOrMedjool","keyword":"arabic","description":"The dataset contains three subsets:\n\na dataset containing hand-crafted features to classify two types of organic dates (Ajwa or Medjool);\na dataset containing tabular data with features created automatically using deep learning to classify the two organic date types (Ajwa or Medjool);\na dataset for images of Ajwa and Medjool.\nThis study is considered as the first work in Arabic using shallow machine learning and deep learning to create accurate models for classifying organic Saudi dates, whichâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/gfbati/AjwaOrMedjool.","url":"https://huggingface.co/datasets/gfbati/AjwaOrMedjool","creator_name":"Ghassan F. Bati","creator_url":"https://huggingface.co/gfbati","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["image-classification","tabular-classification","Arabic","English","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"captioned_images","keyword":"arabic","description":"Dataset Summary\nThis is a 660+ image dataset captioned professionally, part of a 450M image dataset with 780M records of ground truth. This is a highly diverse, interleaved dataset.  Many images are highly aesthetic and many are everyday photos taken by tens of millions of people across 8 years with different cameras in different settings, captioned descriptively and accurately by hand. They were used to train ML Vision models.\nPII and images of humans have been removed from this sampleâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Optasia/captioned_images.","url":"https://huggingface.co/datasets/Optasia/captioned_images","creator_name":"Optasia Corp","creator_url":"https://huggingface.co/Optasia","license_name":"Creative Commons Attribution 2.0","license_url":"https://scancode-licensedb.aboutcode.org/cc-by-2.0.html","language":"en","first_N":5,"first_N_keywords":["Arabic","English","Spanish","cc-by-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"MaWPS-ar","keyword":"arabic","description":"\n\t\n\t\t\n\t\tDataset Card for MAWPS_ar\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nMAWPS: A Math Word Problem Repository\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nMath Word Problem Solving\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nSupports Arabic and English\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\n\t\n\t\t\n\t\tData Fields\n\t\n\n\ntext_en: a string feature.\ntext_ar: a string feature.\neqn: a string feature.\n\n\n\t\n\t\t\n\t\tData Splits\n\t\n\n\n\t\n\t\t\ntrain\nvalidation\ntest\n\n\n\t\t\n3636\n1040\n520\n\n\n\t\n\n\n\t\n\t\t\n\t\tDataset Creation\n\t\n\n\n\t\n\t\t\n\t\tCuration Rationaleâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/omarxadel/MaWPS-ar.","url":"https://huggingface.co/datasets/omarxadel/MaWPS-ar","creator_name":"Omar Adel","creator_url":"https://huggingface.co/omarxadel","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["explanation-generation","crowdsourced","found","multilingual","English"],"keywords_longer_than_N":true},
	{"name":"mc4-sampling","keyword":"arabic","description":"A sampling-enabled version of mC4, the colossal, cleaned version of Common Crawl's web crawl corpus.\n\nBased on Common Crawl dataset: \"https://commoncrawl.org\".\n\nThis is a version of the processed version of Google's mC4 dataset by AllenAI, in which sampling methods are implemented to perform on the fly.","url":"https://huggingface.co/datasets/bertin-project/mc4-sampling","creator_name":"BERTIN Project","creator_url":"https://huggingface.co/bertin-project","license_name":"Open Data Commons Attribution License v1.0","license_url":"https://scancode-licensedb.aboutcode.org/odc-by-1.0.html","language":null,"first_N":5,"first_N_keywords":["text-generation","fill-mask","language-modeling","no-annotation","found"],"keywords_longer_than_N":true},
	{"name":"test","keyword":"arabic","description":"Ezell/test dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/Ezell/test","creator_name":"Ezel","creator_url":"https://huggingface.co/Ezell","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":null,"first_N":5,"first_N_keywords":["token-classification","summarization","Abkhaz","Amharic","Arabic"],"keywords_longer_than_N":true},
	{"name":"Khatt-Dataset-Unique-lines-full","keyword":"arabic","description":"","url":"https://huggingface.co/datasets/Nada2125/Khatt-Dataset-Unique-lines-full","creator_name":"Abbas","creator_url":"https://huggingface.co/Nada2125","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["image-to-text","Arabic","mit","1K - 10K","text"],"keywords_longer_than_N":true},
	{"name":"Khatt-Dataset-Unique-lines-full","keyword":"arabic","description":"","url":"https://huggingface.co/datasets/Nada2125/Khatt-Dataset-Unique-lines-full","creator_name":"Abbas","creator_url":"https://huggingface.co/Nada2125","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["image-to-text","Arabic","mit","1K - 10K","text"],"keywords_longer_than_N":true},
	{"name":"argilla-dpo-mix-7k-arabic","keyword":"arabic","description":"\n\t\n\t\t\n\t\tDataset Card for \"argilla-dpo-mix-7k-arabic\"\n\t\n\nMore Information needed\n","url":"https://huggingface.co/datasets/2A2I/argilla-dpo-mix-7k-arabic","creator_name":"2A2I","creator_url":"https://huggingface.co/2A2I","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["Arabic","mit","1K - 10K","parquet","Tabular"],"keywords_longer_than_N":true},
	{"name":"Tunisian_reddit","keyword":"arabic","description":"\n\t\n\t\t\n\t\tr/Tunisia Data set\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis repository contains two datasets:\n\noutput_comments.csv: This file contains the comments data. Each row represents a comment, with various attributes such as the comment ID, the post it belongs to, the user who made the comment, and the comment text. (sorted by score) id,url,score,body,date\n\noutput_posts.csv: This file contains the posts data. Each row represents a post, with various attributes such as the post ID, the user whoâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Lime1/Tunisian_reddit.","url":"https://huggingface.co/datasets/Lime1/Tunisian_reddit","creator_name":"Aymen Hmani","creator_url":"https://huggingface.co/Lime1","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["Arabic","French","English","mit","100K<n<1M"],"keywords_longer_than_N":true},
	{"name":"artelingo-dummy","keyword":"arabic","description":"ArtELingo is a benchmark and dataset introduced in a research paper aimed at promoting work on diversity across languages and cultures. It is an extension of ArtEmis, which is a collection of 80,000 artworks from WikiArt with 450,000 emotion labels and English-only captions. ArtELingo expands this dataset by adding 790,000 annotations in Arabic and Chinese. The purpose of these additional annotations is to evaluate the performance of \"cultural-transfer\" in AI systems.\nThe dataset in ArtELingoâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/youssef101/artelingo-dummy.","url":"https://huggingface.co/datasets/youssef101/artelingo-dummy","creator_name":"mohamed","creator_url":"https://huggingface.co/youssef101","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["image-to-text","text-classification","image-classification","text-to-image","text-generation"],"keywords_longer_than_N":true},
	{"name":"Arabic_fake_news_dataset","keyword":"arabic","description":"\n\t\n\t\t\n\t\tArabic_fake_news_dataset\n\t\n\n\n\t\n\t\t\n\t\tPlease note that this dataset needs more preprocessing.\n\t\n\n\n\t\n\t\t\n\t\tIntroduction\n\t\n\nThis repository contains the Arabic_fake_news_dataset, a collection of news articles scraped from the Egyptian platform Ù…ØªØµØ¯Ù‚Ø´ (Matsda2sh). The dataset is intended for studying and addressing the spread of fake news within the Egyptian community. It includes news articles classified as either fake or true, along with their corresponding titles.\n\n\t\n\t\t\n\t\tDataset Detailsâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/HeshamHaroon/Arabic_fake_news_dataset.","url":"https://huggingface.co/datasets/HeshamHaroon/Arabic_fake_news_dataset","creator_name":"Hesham Haroon","creator_url":"https://huggingface.co/HeshamHaroon","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","Arabic","apache-2.0","1K - 10K","json"],"keywords_longer_than_N":true},
	{"name":"Arabic_fake_news_dataset","keyword":"arabic","description":"\n\t\n\t\t\n\t\tArabic_fake_news_dataset\n\t\n\n\n\t\n\t\t\n\t\tPlease note that this dataset needs more preprocessing.\n\t\n\n\n\t\n\t\t\n\t\tIntroduction\n\t\n\nThis repository contains the Arabic_fake_news_dataset, a collection of news articles scraped from the Egyptian platform Ù…ØªØµØ¯Ù‚Ø´ (Matsda2sh). The dataset is intended for studying and addressing the spread of fake news within the Egyptian community. It includes news articles classified as either fake or true, along with their corresponding titles.\n\n\t\n\t\t\n\t\tDataset Detailsâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/HeshamHaroon/Arabic_fake_news_dataset.","url":"https://huggingface.co/datasets/HeshamHaroon/Arabic_fake_news_dataset","creator_name":"Hesham Haroon","creator_url":"https://huggingface.co/HeshamHaroon","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","Arabic","apache-2.0","1K - 10K","json"],"keywords_longer_than_N":true},
	{"name":"wikipedia-22-12-ar-embeddings","keyword":"arabic","description":"\n\t\n\t\t\n\t\tWikipedia (ar) embedded with cohere.ai multilingual-22-12 encoder\n\t\n\nWe encoded Wikipedia (ar) using the cohere.ai multilingual-22-12 embedding model.\nTo get an overview how this dataset was created and pre-processed, have a look at Cohere/wikipedia-22-12.\n\n\t\n\t\t\n\t\n\t\n\t\tEmbeddings\n\t\n\nWe compute for title+\" \"+text the embeddings using our multilingual-22-12 embedding model, a state-of-the-art model that works for semantic search in 100 languages.  If you want to learn more about thisâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Cohere/wikipedia-22-12-ar-embeddings.","url":"https://huggingface.co/datasets/Cohere/wikipedia-22-12-ar-embeddings","creator_name":"Cohere","creator_url":"https://huggingface.co/Cohere","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","expert-generated","multilingual","Arabic"],"keywords_longer_than_N":true},
	{"name":"tydiqa-goldp","keyword":"arabic","description":"TyDi QA is a question answering dataset covering 11 typologically diverse languages with 204K question-answer pairs.\nThe languages of TyDi QA are diverse with regard to their typology -- the set of linguistic features that each language\nexpresses -- such that we expect models performing well on this set to generalize across a large number of the languages\nin the world. It contains language phenomena that would not be found in English-only corpora. To provide a realistic\ninformation-seeking task and avoid priming effects, questions are written by people who want to know the answer, but\ndonâ€™t know the answer yet, (unlike SQuAD and its descendents) and the data is collected directly in each language without\nthe use of translation (unlike MLQA and XQuAD).","url":"https://huggingface.co/datasets/khalidalt/tydiqa-goldp","creator_name":"Khalid Almubarak","creator_url":"https://huggingface.co/khalidalt","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":null,"first_N":5,"first_N_keywords":["question-answering","extractive-qa","crowdsourced","crowdsourced","multilingual"],"keywords_longer_than_N":true},
	{"name":"xlel_wd","keyword":"arabic","description":"XLEL-WD is a multilingual event linking dataset. This dataset contains mention references from multilingual Wikipedia/Wikinews articles to event items in Wikidata. The text descriptions for Wikidata events are compiled from Wikipedia articles.","url":"https://huggingface.co/datasets/adithya7/xlel_wd","creator_name":"Adithya Pratapa","creator_url":"https://huggingface.co/adithya7","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["found","found","multilingual","original","Afrikaans"],"keywords_longer_than_N":true},
	{"name":"Pm","keyword":"arabic","description":"Pawamami/Pm dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/Pawamami/Pm","creator_name":"Mamoudou","creator_url":"https://huggingface.co/Pawamami","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":null,"first_N":5,"first_N_keywords":["text-generation","French","English","Hausa","Arabic"],"keywords_longer_than_N":true},
	{"name":"TikTok_MostComment_Video_Transcription_Example","keyword":"arabic","description":"\n\t\n\t\t\n\t\tðŸ“² Example Dataset: TikTok Scraper Tool\n\t\n\nðŸ‘‰ Start Scraping TikTok: TikTok Scraper Tool\n\n\t\n\t\t\n\t\tâœ¨ Key Features\n\t\n\n\nâš¡ Instant Transcription â€“ Turn any TikTok video into an AI-ready transcript  \nðŸŽ¯ Metadata â€“ Get the title, language description, and video hashtags  \nðŸ”— URL-Based Access â€“ Just drop in a TikTok video URL to start scraping  \nðŸ§© LLM-Ready Output â€“ Receive clean JSON ready for agents, RAG, or AI tools  \nðŸ’¸ Free Tier â€“ Use up to 100 queries during the beta period  \nðŸ’« Easyâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Gopher-Lab/TikTok_MostComment_Video_Transcription_Example.","url":"https://huggingface.co/datasets/Gopher-Lab/TikTok_MostComment_Video_Transcription_Example","creator_name":"Gopher AI","creator_url":"https://huggingface.co/Gopher-Lab","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","table-question-answering","zero-shot-classification","feature-extraction","text-to-speech"],"keywords_longer_than_N":true},
	{"name":"panlex","keyword":"arabic","description":"\n\t\n\t\t\n\t\tPanLex\n\t\n\nJanuary 1, 2024 version of PanLex Language Vocabulary with 24,650,274 rows covering 6,152 languages.\n\n\t\n\t\t\n\t\tColumns\n\t\n\n\nvocab: contains the text entry.  \n639-3: contains the ISO 639-3 languages tags to allow users to filter on the language(s) of their choice.\n639-3_english_name: the English language name associated to the code ISO 639-3. \nvar_code: contains a code to differentiate language variants. In practice, this is the code 639-3 + a number.  If 000, it corresponds toâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/lbourdois/panlex.","url":"https://huggingface.co/datasets/lbourdois/panlex","creator_name":"LoÃ¯ck BOURDOIS","creator_url":"https://huggingface.co/lbourdois","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["Ghotuo","Alumu-Tesu","Ari","Amal","ArbÃ«reshÃ« Albanian"],"keywords_longer_than_N":true},
	{"name":"panlex","keyword":"egyptian arabic","description":"\n\t\n\t\t\n\t\tPanLex\n\t\n\nJanuary 1, 2024 version of PanLex Language Vocabulary with 24,650,274 rows covering 6,152 languages.\n\n\t\n\t\t\n\t\tColumns\n\t\n\n\nvocab: contains the text entry.  \n639-3: contains the ISO 639-3 languages tags to allow users to filter on the language(s) of their choice.\n639-3_english_name: the English language name associated to the code ISO 639-3. \nvar_code: contains a code to differentiate language variants. In practice, this is the code 639-3 + a number.  If 000, it corresponds toâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/lbourdois/panlex.","url":"https://huggingface.co/datasets/lbourdois/panlex","creator_name":"LoÃ¯ck BOURDOIS","creator_url":"https://huggingface.co/lbourdois","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["Ghotuo","Alumu-Tesu","Ari","Amal","ArbÃ«reshÃ« Albanian"],"keywords_longer_than_N":true},
	{"name":"panlex","keyword":"mesopotamian arabic","description":"\n\t\n\t\t\n\t\tPanLex\n\t\n\nJanuary 1, 2024 version of PanLex Language Vocabulary with 24,650,274 rows covering 6,152 languages.\n\n\t\n\t\t\n\t\tColumns\n\t\n\n\nvocab: contains the text entry.  \n639-3: contains the ISO 639-3 languages tags to allow users to filter on the language(s) of their choice.\n639-3_english_name: the English language name associated to the code ISO 639-3. \nvar_code: contains a code to differentiate language variants. In practice, this is the code 639-3 + a number.  If 000, it corresponds toâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/lbourdois/panlex.","url":"https://huggingface.co/datasets/lbourdois/panlex","creator_name":"LoÃ¯ck BOURDOIS","creator_url":"https://huggingface.co/lbourdois","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["Ghotuo","Alumu-Tesu","Ari","Amal","ArbÃ«reshÃ« Albanian"],"keywords_longer_than_N":true},
	{"name":"panlex","keyword":"levantine arabic","description":"\n\t\n\t\t\n\t\tPanLex\n\t\n\nJanuary 1, 2024 version of PanLex Language Vocabulary with 24,650,274 rows covering 6,152 languages.\n\n\t\n\t\t\n\t\tColumns\n\t\n\n\nvocab: contains the text entry.  \n639-3: contains the ISO 639-3 languages tags to allow users to filter on the language(s) of their choice.\n639-3_english_name: the English language name associated to the code ISO 639-3. \nvar_code: contains a code to differentiate language variants. In practice, this is the code 639-3 + a number.  If 000, it corresponds toâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/lbourdois/panlex.","url":"https://huggingface.co/datasets/lbourdois/panlex","creator_name":"LoÃ¯ck BOURDOIS","creator_url":"https://huggingface.co/lbourdois","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["Ghotuo","Alumu-Tesu","Ari","Amal","ArbÃ«reshÃ« Albanian"],"keywords_longer_than_N":true},
	{"name":"panlex","keyword":"moroccan arabic","description":"\n\t\n\t\t\n\t\tPanLex\n\t\n\nJanuary 1, 2024 version of PanLex Language Vocabulary with 24,650,274 rows covering 6,152 languages.\n\n\t\n\t\t\n\t\tColumns\n\t\n\n\nvocab: contains the text entry.  \n639-3: contains the ISO 639-3 languages tags to allow users to filter on the language(s) of their choice.\n639-3_english_name: the English language name associated to the code ISO 639-3. \nvar_code: contains a code to differentiate language variants. In practice, this is the code 639-3 + a number.  If 000, it corresponds toâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/lbourdois/panlex.","url":"https://huggingface.co/datasets/lbourdois/panlex","creator_name":"LoÃ¯ck BOURDOIS","creator_url":"https://huggingface.co/lbourdois","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["Ghotuo","Alumu-Tesu","Ari","Amal","ArbÃ«reshÃ« Albanian"],"keywords_longer_than_N":true},
	{"name":"panlex","keyword":"najdi arabic","description":"\n\t\n\t\t\n\t\tPanLex\n\t\n\nJanuary 1, 2024 version of PanLex Language Vocabulary with 24,650,274 rows covering 6,152 languages.\n\n\t\n\t\t\n\t\tColumns\n\t\n\n\nvocab: contains the text entry.  \n639-3: contains the ISO 639-3 languages tags to allow users to filter on the language(s) of their choice.\n639-3_english_name: the English language name associated to the code ISO 639-3. \nvar_code: contains a code to differentiate language variants. In practice, this is the code 639-3 + a number.  If 000, it corresponds toâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/lbourdois/panlex.","url":"https://huggingface.co/datasets/lbourdois/panlex","creator_name":"LoÃ¯ck BOURDOIS","creator_url":"https://huggingface.co/lbourdois","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["Ghotuo","Alumu-Tesu","Ari","Amal","ArbÃ«reshÃ« Albanian"],"keywords_longer_than_N":true},
	{"name":"panlex","keyword":"standard arabic","description":"\n\t\n\t\t\n\t\tPanLex\n\t\n\nJanuary 1, 2024 version of PanLex Language Vocabulary with 24,650,274 rows covering 6,152 languages.\n\n\t\n\t\t\n\t\tColumns\n\t\n\n\nvocab: contains the text entry.  \n639-3: contains the ISO 639-3 languages tags to allow users to filter on the language(s) of their choice.\n639-3_english_name: the English language name associated to the code ISO 639-3. \nvar_code: contains a code to differentiate language variants. In practice, this is the code 639-3 + a number.  If 000, it corresponds toâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/lbourdois/panlex.","url":"https://huggingface.co/datasets/lbourdois/panlex","creator_name":"LoÃ¯ck BOURDOIS","creator_url":"https://huggingface.co/lbourdois","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["Ghotuo","Alumu-Tesu","Ari","Amal","ArbÃ«reshÃ« Albanian"],"keywords_longer_than_N":true},
	{"name":"panlex","keyword":"tunisian arabic","description":"\n\t\n\t\t\n\t\tPanLex\n\t\n\nJanuary 1, 2024 version of PanLex Language Vocabulary with 24,650,274 rows covering 6,152 languages.\n\n\t\n\t\t\n\t\tColumns\n\t\n\n\nvocab: contains the text entry.  \n639-3: contains the ISO 639-3 languages tags to allow users to filter on the language(s) of their choice.\n639-3_english_name: the English language name associated to the code ISO 639-3. \nvar_code: contains a code to differentiate language variants. In practice, this is the code 639-3 + a number.  If 000, it corresponds toâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/lbourdois/panlex.","url":"https://huggingface.co/datasets/lbourdois/panlex","creator_name":"LoÃ¯ck BOURDOIS","creator_url":"https://huggingface.co/lbourdois","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["Ghotuo","Alumu-Tesu","Ari","Amal","ArbÃ«reshÃ« Albanian"],"keywords_longer_than_N":true},
	{"name":"panlex","keyword":"ta'izzi-adeni arabic","description":"\n\t\n\t\t\n\t\tPanLex\n\t\n\nJanuary 1, 2024 version of PanLex Language Vocabulary with 24,650,274 rows covering 6,152 languages.\n\n\t\n\t\t\n\t\tColumns\n\t\n\n\nvocab: contains the text entry.  \n639-3: contains the ISO 639-3 languages tags to allow users to filter on the language(s) of their choice.\n639-3_english_name: the English language name associated to the code ISO 639-3. \nvar_code: contains a code to differentiate language variants. In practice, this is the code 639-3 + a number.  If 000, it corresponds toâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/lbourdois/panlex.","url":"https://huggingface.co/datasets/lbourdois/panlex","creator_name":"LoÃ¯ck BOURDOIS","creator_url":"https://huggingface.co/lbourdois","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["Ghotuo","Alumu-Tesu","Ari","Amal","ArbÃ«reshÃ« Albanian"],"keywords_longer_than_N":true},
	{"name":"tatoeba-mt-all-in-one","keyword":"arabic","description":"\n\t\n\t\t\n\t\tDataset Card for The Tatoeba Translation Challenge | All In One\n\t\n\n~7.3M entries.\nJust more user-friendly version that combines all of the entries of original dataset in a single file:\nhttps://huggingface.co/datasets/Helsinki-NLP/tatoeba_mt\n","url":"https://huggingface.co/datasets/0x22almostEvil/tatoeba-mt-all-in-one","creator_name":"David Glushkov","creator_url":"https://huggingface.co/0x22almostEvil","license_name":"Creative Commons Attribution 2.0","license_url":"https://scancode-licensedb.aboutcode.org/cc-by-2.0.html","language":"en","first_N":5,"first_N_keywords":["Helsinki-NLP","crowdsourced","translation","Helsinki-NLP/tatoeba_mt","Afrikaans"],"keywords_longer_than_N":true},
	{"name":"xP3all","keyword":"arabic","description":"xP3 (Crosslingual Public Pool of Prompts) is a collection of prompts & datasets across 46 of languages & 16 NLP tasks. It is used for the training of BLOOMZ and mT0, multilingual language models capable of following human instructions in dozens of languages zero-shot.","url":"https://huggingface.co/datasets/bigscience/xP3all","creator_name":"BigScience Workshop","creator_url":"https://huggingface.co/bigscience","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["other","expert-generated","crowdsourced","multilingual","Akan"],"keywords_longer_than_N":true},
	{"name":"tokenizer-wiki-bench","keyword":"arabic","description":"\n\t\n\t\t\n\t\tMultilingual Tokenizer Benchmark\n\t\n\nThis dataset includes pre-processed wikipedia data for tokenizer evaluation in 45 languages. We provide more information on the evaluation task in general this blogpost.\n\n\t\n\t\t\n\t\tUsage\n\t\n\nThe dataset allows us to easily calculate tokenizer fertility and the proportion of continued words on any of the supported languages. In the example below we take the Mistral tokenizer and evaluate its performance on Slovak. \nfrom transformers import AutoTokenizerâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/occiglot/tokenizer-wiki-bench.","url":"https://huggingface.co/datasets/occiglot/tokenizer-wiki-bench","creator_name":"Occiglot","creator_url":"https://huggingface.co/occiglot","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["Afrikaans","Arabic","Bulgarian","Catalan","Czech"],"keywords_longer_than_N":true},
	{"name":"Evol-Instruct-Arabic-GPT4","keyword":"arabic","description":"The dataset is created by \n\ntranslating English questions of Evol-instruct-70k into Arabic using GPT4, and\nrequesting GPT4 to generate responses in Arabic.\n\nFor more details, please refer to:\n\nRepository: \nhttps://github.com/FreedomIntelligence/AceGPT\nhttps://github.com/FreedomIntelligence/LLMZoo\n\n\nPaper: \nAceGPT, Localizing Large Language Models in Arabic\nPhoenix: Democratizing ChatGPT across Languages\n\n\n\n\n\t\t\n\t\tBibTeX entry and citation info\n\t\n\n@article{huang2023acegpt,\n  title={AceGPTâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/FreedomIntelligence/Evol-Instruct-Arabic-GPT4.","url":"https://huggingface.co/datasets/FreedomIntelligence/Evol-Instruct-Arabic-GPT4","creator_name":"FreedomAI","creator_url":"https://huggingface.co/FreedomIntelligence","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","Arabic","apache-2.0","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"KIND","keyword":"arabic","description":"\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nKIND dataset is a new dilectal data dataset.\nThe dataset was a result of a data marathon competition, where the competitor's goal is to respond to as many prompts as possible in their own dialect, within a fixed time frame with as few errors as possible.\nFor more details, please check the paper\nThe KIND Dataset: A Social Collaboration Approach for Nuanced Dialect Data Collection\n\n\t\n\t\t\n\t\n\t\n\t\tData Fields\n\t\n\n\ndialect_code: the label that indicates the specific dialectâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/KIND-Dataset/KIND.","url":"https://huggingface.co/datasets/KIND-Dataset/KIND","creator_name":"KIND","creator_url":"https://huggingface.co/KIND-Dataset","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["question-answering","Arabic","cc-by-4.0","10K<n<100K","ðŸ‡ºðŸ‡¸ Region: US"],"keywords_longer_than_N":false},
	{"name":"chat_unsensored","keyword":"arabic","description":"\n\t\n\t\t\n\t\tDataset Card for Dataset Name\n\t\n\n\n\nThis dataset card aims to be a base template for new datasets. It has been generated using this raw template.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\n\n\n\n\n\nCurated by: [More Information Needed]\nFunded by [optional]: [More Information Needed]\nShared by [optional]: [More Information Needed]\nLanguage(s) (NLP): [More Information Needed]\nLicense: [More Information Needed]\n\n\n\t\n\t\t\n\t\tDataset Sources [optional]\n\t\n\n\n\n\nRepository: [Moreâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/cleexiang/chat_unsensored.","url":"https://huggingface.co/datasets/cleexiang/chat_unsensored","creator_name":"lixiang","creator_url":"https://huggingface.co/cleexiang","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["question-answering","Arabic","apache-2.0","1K - 10K","parquet"],"keywords_longer_than_N":true},
	{"name":"Arabic_Openai_MMMLU","keyword":"arabic","description":"\n\t\n\t\t\n\t\tArabic Multilingual Massive Multitask Language Understanding (MMMLU)\n\t\n\nThe MMLU is a widely recognized benchmark for assessing general knowledge attained by AI models. It covers a broad range of topics across 57 different categories, from elementary-level knowledge to advanced professional subjects like law, physics, history, and computer science.\nWe have extracted the Arabic subset from the MMMLU test set, which was translated by professional human translators. This dataset, nowâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Omartificial-Intelligence-Space/Arabic_Openai_MMMLU.","url":"https://huggingface.co/datasets/Omartificial-Intelligence-Space/Arabic_Openai_MMMLU","creator_name":"Omartificial Intelligence Space","creator_url":"https://huggingface.co/Omartificial-Intelligence-Space","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["question-answering","Arabic","mit","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"Arabic_Openai_MMMLU","keyword":"arabic","description":"\n\t\n\t\t\n\t\tArabic Multilingual Massive Multitask Language Understanding (MMMLU)\n\t\n\nThe MMLU is a widely recognized benchmark for assessing general knowledge attained by AI models. It covers a broad range of topics across 57 different categories, from elementary-level knowledge to advanced professional subjects like law, physics, history, and computer science.\nWe have extracted the Arabic subset from the MMMLU test set, which was translated by professional human translators. This dataset, nowâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Omartificial-Intelligence-Space/Arabic_Openai_MMMLU.","url":"https://huggingface.co/datasets/Omartificial-Intelligence-Space/Arabic_Openai_MMMLU","creator_name":"Omartificial Intelligence Space","creator_url":"https://huggingface.co/Omartificial-Intelligence-Space","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["question-answering","Arabic","mit","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"JinaVDRAirbnbSyntheticRetrieval","keyword":"arabic","description":"\n  JinaVDRAirbnbSyntheticRetrieval\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nRetrieve rendered tables from Airbnb listings based on templated queries.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2i\n\n\nDomains\nWeb\n\n\nReference\nhttps://huggingface.co/datasets/jinaai/airbnb-synthetic-retrieval_beir\n\n\n\t\n\nSource datasets:\n\njinaai/airbnb-synthetic-retrieval_beir\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask =â€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/JinaVDRAirbnbSyntheticRetrieval.","url":"https://huggingface.co/datasets/mteb/JinaVDRAirbnbSyntheticRetrieval","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["visual-document-retrieval","image-to-text","text-to-image","derived","multilingual"],"keywords_longer_than_N":true},
	{"name":"Kaleidoscope","keyword":"arabic","description":"\n\t\n\t\t\n\t\tKaleidoscope  (18 Languages)\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe Kaleidoscope Benchmark is a \nglobal collection of multiple-choice questions sourced from real-world exams, \nwith the goal of evaluating multimodal and multilingual understanding in VLMs. \nThe collected exams are in a Multiple-choice question answering (MCQA) \nformat which provides a structured framework for evaluation by prompting \nmodels with predefined answer choices, closely mimicking conventional human testingâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Anonym-sub/Kaleidoscope.","url":"https://huggingface.co/datasets/Anonym-sub/Kaleidoscope","creator_name":"Anonymous submission","creator_url":"https://huggingface.co/Anonym-sub","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["Arabic","Bengali","Croatian","Dutch","English"],"keywords_longer_than_N":true},
	{"name":"AraEventCoref","keyword":"arabic","description":"\n\t\n\t\t\n\t\tAraEventCoref\n\t\n\nAraEventCoref is an Arabic event coreference dataset comprising 50 annotated news articles with 12,069 tokens, 1,381 events, and 159 coreference chains. Target events are surrounded by position-aware markers <<Ø­Ø¯Ø«>> before and after each event. The label 1 indicates a coreference, while 0 indicates no coreference. The dataset features high annotation reliability with a CoNLL score of 75.8% and an inter-annotator agreement of 96% for event triggers.\n\nCurated by: Dr.â€¦ See the full description on the dataset page: https://huggingface.co/datasets/AldawsariNLP/AraEventCoref.","url":"https://huggingface.co/datasets/AldawsariNLP/AraEventCoref","creator_name":"Aldawsari","creator_url":"https://huggingface.co/AldawsariNLP","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","Arabic","apache-2.0","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"ApolloMoEBench","keyword":"arabic","description":"\n\t\n\t\t\n\t\tDemocratizing Medical LLMs For Much More Languages\n\t\n\nCovering 12 Major Languages including English, Chinese, French, Hindi, Spanish, Arabic, Russian, Japanese, Korean, German, Italian, Portuguese and 38 Minor Languages So far.\n\n   ðŸ“ƒ Paper â€¢ ðŸŒ Demo â€¢ ðŸ¤— ApolloMoEDataset â€¢ ðŸ¤— ApolloMoEBench  â€¢ ðŸ¤— Models  â€¢ðŸŒ Apollo  â€¢ ðŸŒ ApolloMoE\n\n\n\n\n\n\n\t\n\t\t\n\t\tðŸŒˆ Update\n\t\n\n\n[2024.10.15] ApolloMoE repo is publishedï¼ðŸŽ‰\n\n\n\t\n\t\t\n\t\tLanguages Coverage\n\t\n\n12 Major Languages and 38 Minor Languages\n\n  Click toâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/FreedomIntelligence/ApolloMoEBench.","url":"https://huggingface.co/datasets/FreedomIntelligence/ApolloMoEBench","creator_name":"FreedomAI","creator_url":"https://huggingface.co/FreedomIntelligence","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["question-answering","Arabic","English","Chinese","Korean"],"keywords_longer_than_N":true},
	{"name":"genius-video","keyword":"arabic","description":"sleeping-ai/genius-video dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/sleeping-ai/genius-video","creator_name":"Sleeping AI","creator_url":"https://huggingface.co/sleeping-ai","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["English","Japanese","Arabic","Russian","mit"],"keywords_longer_than_N":true},
	{"name":"Synthdog-Multilingual-100","keyword":"arabic","description":"\n\t\n\t\t\n\t\tSynthdog Multilingual\n\t\n\n\n\nThe Synthdog dataset created for training in Centurio: On Drivers of Multilingual Ability of Large Vision-Language Model.\nUsing the official Synthdog code, we created >1 million training samples for improving OCR capabilities in Large Vision-Language Models.\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Details\n\t\n\nWe provide the images for download in two .tar.gz files. Download and extract them in folders of the same name (so cat images.tar.gz.* | tar xvzf -C images; tar xvzfâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/WueNLP/Synthdog-Multilingual-100.","url":"https://huggingface.co/datasets/WueNLP/Synthdog-Multilingual-100","creator_name":"WÃ¼NLP","creator_url":"https://huggingface.co/WueNLP","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["image-to-text","multilingual","Afrikaans","Amharic","Arabic"],"keywords_longer_than_N":true},
	{"name":"arabic_mmmu","keyword":"arabic","description":"Please see paper & code for more information:\n\nhttps://github.com/mbzuai-oryx/Camel-Bench\nhttps://arxiv.org/abs/2410.18976\n\n","url":"https://huggingface.co/datasets/ahmedheakl/arabic_mmmu","creator_name":"Ahmed Heakl","creator_url":"https://huggingface.co/ahmedheakl","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["Arabic","mit","< 1K","parquet","Image"],"keywords_longer_than_N":true},
	{"name":"Arabic_dialects_to_MSA","keyword":"arabic","description":"PRAli22/Arabic_dialects_to_MSA dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/PRAli22/Arabic_dialects_to_MSA","creator_name":"ali ragab","creator_url":"https://huggingface.co/PRAli22","license_name":"Academic Free License v3.0","license_url":"https://choosealicense.com/licenses/afl-3.0/","language":"en","first_N":5,"first_N_keywords":["Arabic","afl-3.0","100K - 1M","csv","Text"],"keywords_longer_than_N":true},
	{"name":"FineWeb2-Najdi-Arabic","keyword":"arabic","description":"\n\t\n\t\t\n\t\tFineWeb2 Najdi Arabic\n\t\n\n\nðŸ‡¸ðŸ‡¦ This is the Nadj Arabic Portion of The FineWeb2 Dataset.\nðŸ‡¸ðŸ‡¦ This dataset contains a comprehensive collection of text in Najdi Arabic, a regional dialect within the Afro-Asiatic language family. With over 562 million words and 1.6 million documents, it provides a valuable resource for developing NLP tools and applications specific to Najdi Arabic.\n\n\t\n\t\n\t\n\t\tPurpose of This Repository\n\t\n\nThis repository provides easy access to the Arabic portion - Najdi ofâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Omartificial-Intelligence-Space/FineWeb2-Najdi-Arabic.","url":"https://huggingface.co/datasets/Omartificial-Intelligence-Space/FineWeb2-Najdi-Arabic","creator_name":"Omartificial Intelligence Space","creator_url":"https://huggingface.co/Omartificial-Intelligence-Space","license_name":"Open Data Commons Attribution License v1.0","license_url":"https://scancode-licensedb.aboutcode.org/odc-by-1.0.html","language":"en","first_N":5,"first_N_keywords":["Arabic","odc-by","10M - 100M","parquet","Text"],"keywords_longer_than_N":true},
	{"name":"FineWeb2-Najdi-Arabic","keyword":"arabic","description":"\n\t\n\t\t\n\t\tFineWeb2 Najdi Arabic\n\t\n\n\nðŸ‡¸ðŸ‡¦ This is the Nadj Arabic Portion of The FineWeb2 Dataset.\nðŸ‡¸ðŸ‡¦ This dataset contains a comprehensive collection of text in Najdi Arabic, a regional dialect within the Afro-Asiatic language family. With over 562 million words and 1.6 million documents, it provides a valuable resource for developing NLP tools and applications specific to Najdi Arabic.\n\n\t\n\t\n\t\n\t\tPurpose of This Repository\n\t\n\nThis repository provides easy access to the Arabic portion - Najdi ofâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Omartificial-Intelligence-Space/FineWeb2-Najdi-Arabic.","url":"https://huggingface.co/datasets/Omartificial-Intelligence-Space/FineWeb2-Najdi-Arabic","creator_name":"Omartificial Intelligence Space","creator_url":"https://huggingface.co/Omartificial-Intelligence-Space","license_name":"Open Data Commons Attribution License v1.0","license_url":"https://scancode-licensedb.aboutcode.org/odc-by-1.0.html","language":"en","first_N":5,"first_N_keywords":["Arabic","odc-by","10M - 100M","parquet","Text"],"keywords_longer_than_N":true},
	{"name":"uae-laws","keyword":"arabic","description":"\n\t\n\t\t\n\t\tDataset Card for UAE-Laws\n\t\n\nThis dataset is a collection of information about the laws and regulations in the United Arab Emirates. \nIt covers different areas of law like: \n\neconomy and business \nfamily and community \nfinance and banking \nindustry and technical standardisation \njustice and juiciary, labour \nresidency and leberal professions \nsecurity and safety \ntax\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Sources\n\t\n\n\nUnited Arab Emirates Legislations\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Structure\n\t\n\nThe ./uae-laws.csvâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/obadabaq/uae-laws.","url":"https://huggingface.co/datasets/obadabaq/uae-laws","creator_name":"obada baqleh","creator_url":"https://huggingface.co/obadabaq","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["question-answering","text-generation","English","Arabic","mit"],"keywords_longer_than_N":true},
	{"name":"ArabicText-Large","keyword":"arabic","description":"\n\t\n\t\t\n\t\tArabicText-Large: High-Quality Arabic Corpus for LLM Training\n\t\n\n\n\n\n\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nArabicText-Large is a comprehensive, high-quality Arabic text corpus comprising 743,288 articles with over 244 million words, specifically curated for Large Language Model (LLM) training and fine-tuning. This dataset represents one of the largest publicly available Arabic text collections for machine learning research.\nThis corpus addresses the critical shortage of high-quality Arabic NLPâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Jr23xd23/ArabicText-Large.","url":"https://huggingface.co/datasets/Jr23xd23/ArabicText-Large","creator_name":"Jaber","creator_url":"https://huggingface.co/Jr23xd23","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":null,"first_N":5,"first_N_keywords":["text-generation","fill-mask","text-classification","Arabic","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"ArabicText-Large","keyword":"arabic","description":"\n\t\n\t\t\n\t\tArabicText-Large: High-Quality Arabic Corpus for LLM Training\n\t\n\n\n\n\n\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nArabicText-Large is a comprehensive, high-quality Arabic text corpus comprising 743,288 articles with over 244 million words, specifically curated for Large Language Model (LLM) training and fine-tuning. This dataset represents one of the largest publicly available Arabic text collections for machine learning research.\nThis corpus addresses the critical shortage of high-quality Arabic NLPâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Jr23xd23/ArabicText-Large.","url":"https://huggingface.co/datasets/Jr23xd23/ArabicText-Large","creator_name":"Jaber","creator_url":"https://huggingface.co/Jr23xd23","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":null,"first_N":5,"first_N_keywords":["text-generation","fill-mask","text-classification","Arabic","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"SE-Chatting.en","keyword":"arabic","description":"\n\t\n\t\t\n\t\tSE.02\n\t\n\nDataset\nHello, welcome to the official main dataset of SE.02 that's always getting updated, make sure to like to help us a lot.\nthis dataset contains pretty much everything from math to isk what to put but pretty much anything you think an ai can say.\nanyways this is our biggest dataset yet, and out first one that I don't even know how I managed to make this.\nyou can use it to train your own ai if you want.\n","url":"https://huggingface.co/datasets/berwart/SE-Chatting.en","creator_name":"Berwart","creator_url":"https://huggingface.co/berwart","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["question-answering","translation","English","French","Japanese"],"keywords_longer_than_N":true},
	{"name":"arabic-whisper-correction","keyword":"arabic","description":"\n\t\n\t\t\n\t\tArabic ASR Post-Correction Dataset\n\t\n\nDataset for correcting common errors in Whisper ASR outputs for Arabic.\n\n\t\n\t\t\n\t\tFeatures\n\t\n\n\nInput: Noisy ASR transcriptions\nTarget: Corrected Modern Standard Arabic (MSA)\n\n","url":"https://huggingface.co/datasets/RawandLaouini/arabic-whisper-correction","creator_name":"Rawand Laouini","creator_url":"https://huggingface.co/RawandLaouini","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["audio-text-to-text","Arabic","apache-2.0","< 1K","json"],"keywords_longer_than_N":true},
	{"name":"arabic-whisper-correction","keyword":"arabic","description":"\n\t\n\t\t\n\t\tArabic ASR Post-Correction Dataset\n\t\n\nDataset for correcting common errors in Whisper ASR outputs for Arabic.\n\n\t\n\t\t\n\t\tFeatures\n\t\n\n\nInput: Noisy ASR transcriptions\nTarget: Corrected Modern Standard Arabic (MSA)\n\n","url":"https://huggingface.co/datasets/RawandLaouini/arabic-whisper-correction","creator_name":"Rawand Laouini","creator_url":"https://huggingface.co/RawandLaouini","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["audio-text-to-text","Arabic","apache-2.0","< 1K","json"],"keywords_longer_than_N":true},
	{"name":"multilingual-coco","keyword":"arabic","description":"\n\t\n\t\t\n\t\tMultilingual Common Objects in Context (COCO) Dataset\n\t\n\nThis dataset is a collection of multiple language open-source captions of COCO dataset. \nThe split in this dataset is set according to Andrej Karpathy's split from dataset_coco.json file. The collection was created specifically for simplicity of use in training and evaluation pipeline by non-commercial and research purposes. The COCO images dataset is licensed under a Creative Commons Attribution 4.0 License.â€¦ See the full description on the dataset page: https://huggingface.co/datasets/romrawinjp/multilingual-coco.","url":"https://huggingface.co/datasets/romrawinjp/multilingual-coco","creator_name":"Romrawin Chumpu","creator_url":"https://huggingface.co/romrawinjp","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["image-to-text","English","Thai","Russian","Japanese"],"keywords_longer_than_N":true},
	{"name":"MasriSpeech-1K","keyword":"arabic","description":"\n\t\n\t\t\n\t\tðŸ—£ï¸ NigMasriSpeech: Egyptian Arabic Speech Dataset (1K Samples)\n\t\n\n\n\n\n  \n\n\n\n\t\n\t\t\n\t\n\t\n\t\tðŸŒ Overview\n\t\n\nNigMasriSpeech is a compact Egyptian Arabic speech dataset, designed for Automatic Speech Recognition (ASR) and other speech processing tasks. This dataset contains 1,000 professionally annotated audio samples totaling over 10 hours of natural Egyptian Arabic speech.\nðŸ’¡ Key Features:\n\nHigh-quality 16kHz speech recordings\nNatural conversational Egyptian Arabic\nCompact size for quickâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/NightPrince/MasriSpeech-1K.","url":"https://huggingface.co/datasets/NightPrince/MasriSpeech-1K","creator_name":"Yahya Muhammad Alnwsany","creator_url":"https://huggingface.co/NightPrince","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","audio-classification","any-to-any","Egyptian Arabic","Arabic"],"keywords_longer_than_N":true},
	{"name":"MasriSpeech-1K","keyword":"arabic","description":"\n\t\n\t\t\n\t\tðŸ—£ï¸ NigMasriSpeech: Egyptian Arabic Speech Dataset (1K Samples)\n\t\n\n\n\n\n  \n\n\n\n\t\n\t\t\n\t\n\t\n\t\tðŸŒ Overview\n\t\n\nNigMasriSpeech is a compact Egyptian Arabic speech dataset, designed for Automatic Speech Recognition (ASR) and other speech processing tasks. This dataset contains 1,000 professionally annotated audio samples totaling over 10 hours of natural Egyptian Arabic speech.\nðŸ’¡ Key Features:\n\nHigh-quality 16kHz speech recordings\nNatural conversational Egyptian Arabic\nCompact size for quickâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/NightPrince/MasriSpeech-1K.","url":"https://huggingface.co/datasets/NightPrince/MasriSpeech-1K","creator_name":"Yahya Muhammad Alnwsany","creator_url":"https://huggingface.co/NightPrince","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","audio-classification","any-to-any","Egyptian Arabic","Arabic"],"keywords_longer_than_N":true},
	{"name":"persian_word_vowels_pronunciations","keyword":"arabic","description":"\n\t\n\t\t\n\t\tDataset Card for Dataset Name\n\t\n\n\n\nThis dataset card aims to be a base template for new datasets. It has been generated using this raw template.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\n\n\n\n\n\nCurated by: [More Information Needed]\nFunded by [optional]: [More Information Needed]\nShared by [optional]: [More Information Needed]\nLanguage(s) (NLP): [More Information Needed]\nLicense: [More Information Needed]\n\n\n\t\n\t\t\n\t\tDataset Sources [optional]\n\t\n\n\n\n\nRepository: [Moreâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/developer-ninja/persian_word_vowels_pronunciations.","url":"https://huggingface.co/datasets/developer-ninja/persian_word_vowels_pronunciations","creator_name":"momo titi","creator_url":"https://huggingface.co/developer-ninja","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["Persian","Arabic","apache-2.0","ðŸ‡ºðŸ‡¸ Region: US","language"],"keywords_longer_than_N":true},
	{"name":"MasriSpeech-1K","keyword":"egyptian arabic","description":"\n\t\n\t\t\n\t\tðŸ—£ï¸ NigMasriSpeech: Egyptian Arabic Speech Dataset (1K Samples)\n\t\n\n\n\n\n  \n\n\n\n\t\n\t\t\n\t\n\t\n\t\tðŸŒ Overview\n\t\n\nNigMasriSpeech is a compact Egyptian Arabic speech dataset, designed for Automatic Speech Recognition (ASR) and other speech processing tasks. This dataset contains 1,000 professionally annotated audio samples totaling over 10 hours of natural Egyptian Arabic speech.\nðŸ’¡ Key Features:\n\nHigh-quality 16kHz speech recordings\nNatural conversational Egyptian Arabic\nCompact size for quickâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/NightPrince/MasriSpeech-1K.","url":"https://huggingface.co/datasets/NightPrince/MasriSpeech-1K","creator_name":"Yahya Muhammad Alnwsany","creator_url":"https://huggingface.co/NightPrince","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","audio-classification","any-to-any","Egyptian Arabic","Arabic"],"keywords_longer_than_N":true},
	{"name":"DarijaBench","keyword":"moroccan arabic","description":"\n\t\n\t\t\n\t\tDarijaBench: A Comprehensive Evaluation Dataset for Summarization, Translation, and Sentiment Analysis in Darija\n\t\n\nNote the ODC-BY license, indicating that different licenses apply to subsets of the data. This means that some portions of the dataset are non-commercial. We present the mixture as a research artifact.\nThe Moroccan Arabic dialect, commonly referred to as Darija, is a widely spoken but understudied variant of Arabic with distinct linguistic features that differâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/MBZUAI-Paris/DarijaBench.","url":"https://huggingface.co/datasets/MBZUAI-Paris/DarijaBench","creator_name":"MBZUAI-IFM Paris Lab","creator_url":"https://huggingface.co/MBZUAI-Paris","license_name":"Open Data Commons Attribution License v1.0","license_url":"https://scancode-licensedb.aboutcode.org/odc-by-1.0.html","language":"en","first_N":5,"first_N_keywords":["Moroccan Arabic","French","English","Standard Arabic","odc-by"],"keywords_longer_than_N":true},
	{"name":"DarijaBench","keyword":"standard arabic","description":"\n\t\n\t\t\n\t\tDarijaBench: A Comprehensive Evaluation Dataset for Summarization, Translation, and Sentiment Analysis in Darija\n\t\n\nNote the ODC-BY license, indicating that different licenses apply to subsets of the data. This means that some portions of the dataset are non-commercial. We present the mixture as a research artifact.\nThe Moroccan Arabic dialect, commonly referred to as Darija, is a widely spoken but understudied variant of Arabic with distinct linguistic features that differâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/MBZUAI-Paris/DarijaBench.","url":"https://huggingface.co/datasets/MBZUAI-Paris/DarijaBench","creator_name":"MBZUAI-IFM Paris Lab","creator_url":"https://huggingface.co/MBZUAI-Paris","license_name":"Open Data Commons Attribution License v1.0","license_url":"https://scancode-licensedb.aboutcode.org/odc-by-1.0.html","language":"en","first_N":5,"first_N_keywords":["Moroccan Arabic","French","English","Standard Arabic","odc-by"],"keywords_longer_than_N":true},
	{"name":"tunisian-msa-parallel-corpus","keyword":"arabic","description":"\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis is an ambitious project to create a high-quality, reproducible parallel corpus for Modern Standard Arabic (MSA) and Tunisian Arabic (aeb) through a sophisticated synthetic data generation pipeline. The dataset is being developed by the Tunisia.AI community to address the scarcity of high-quality dialectal data for training and evaluating language models.\nThe primary goal is to provide a rich, well-documented resource for the research and development of:â€¦ See the full description on the dataset page: https://huggingface.co/datasets/tunis-ai/tunisian-msa-parallel-corpus.","url":"https://huggingface.co/datasets/tunis-ai/tunisian-msa-parallel-corpus","creator_name":"Tunisia.AI","creator_url":"https://huggingface.co/tunis-ai","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["translation","text-generation","summarization","Arabic","Tunisian Arabic"],"keywords_longer_than_N":true},
	{"name":"sunnah_ar_en_dataset","keyword":"arabic","description":"\n\t\n\t\t\n\t\tDataset Card for Dataset Name\n\t\n\n\n\t\n\t\t\n\t\tDataset Card for Hadiths 14 Books Collection\n\t\n\nThis dataset contains a comprehensive bilingual (Arabic-English) collection of hadiths from 14 major authenticated books of Islamic tradition. It includes over 50762 narrations with complete metadata, organized by book, chapter, and narrator. Each hadith is presented in both its original Arabic text and English translation, making it ideal for cross-lingual NLP tasks, Islamic question-answeringâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/gurgutan/sunnah_ar_en_dataset.","url":"https://huggingface.co/datasets/gurgutan/sunnah_ar_en_dataset","creator_name":"Ð˜Ð²Ð°Ð½ Ð˜Ð²Ð°Ð½Ð¾Ð²Ð¸Ñ‡ Ð¡Ð»ÐµÐ¿Ð¾Ð²Ð¸Ñ‡ÐµÐ²","creator_url":"https://huggingface.co/gurgutan","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["translation","question-answering","English","Arabic","mit"],"keywords_longer_than_N":true},
	{"name":"ALLaVA-4V-Arabic","keyword":"arabic","description":"\n\t\n\t\t\n\t\tALLaVA-4V for Arabic\n\t\n\nThis is the Arabic version of the ALLaVA-4V data. We have translated the ALLaVA-4V data into Arabic through ChatGPT and instructed ChatGPT not to translate content related to OCR.\nThe original dataset can be found here, and the image data can be downloaded from ALLaVA-4V.\n\n\t\n\t\t\n\t\n\t\n\t\tCitation\n\t\n\nIf you find our data useful, please consider citing our work! We are FreedomIntelligence from Shenzhen Research Institute of Big Data and The Chinese University of Hongâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/FreedomIntelligence/ALLaVA-4V-Arabic.","url":"https://huggingface.co/datasets/FreedomIntelligence/ALLaVA-4V-Arabic","creator_name":"FreedomAI","creator_url":"https://huggingface.co/FreedomIntelligence","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["question-answering","text-generation","Arabic","apache-2.0","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"MultiQ","keyword":"arabic","description":"\n\t\n\t\t\n\t\tDataset Card for MultiQ\n\t\n\nThis is the dataset corresponding to the paper \"Evaluating the Elementary Multilingual Capabilities of Large Language Models with MultiQ\". \nIt is a silver standard benchmark that can be used to evaluate the basic multilingual capabilities of LLMs. It contains 200 open ended questions automatically \ntranslated into 137 typologically diverse languages. \n\nCurated by: Carolin Holtermann, Paul RÃ¶ttger, Timm Dill, Anne Lauscher\nLanguage(s) (NLP): 137 diverseâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/caro-holt/MultiQ.","url":"https://huggingface.co/datasets/caro-holt/MultiQ","creator_name":"Holtermann","creator_url":"https://huggingface.co/caro-holt","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["question-answering","Tagalog","Samoan","Macedonian","Gujarati"],"keywords_longer_than_N":true},
	{"name":"tunisian-msa-parallel-corpus","keyword":"tunisian arabic","description":"\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis is an ambitious project to create a high-quality, reproducible parallel corpus for Modern Standard Arabic (MSA) and Tunisian Arabic (aeb) through a sophisticated synthetic data generation pipeline. The dataset is being developed by the Tunisia.AI community to address the scarcity of high-quality dialectal data for training and evaluating language models.\nThe primary goal is to provide a rich, well-documented resource for the research and development of:â€¦ See the full description on the dataset page: https://huggingface.co/datasets/tunis-ai/tunisian-msa-parallel-corpus.","url":"https://huggingface.co/datasets/tunis-ai/tunisian-msa-parallel-corpus","creator_name":"Tunisia.AI","creator_url":"https://huggingface.co/tunis-ai","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["translation","text-generation","summarization","Arabic","Tunisian Arabic"],"keywords_longer_than_N":true},
	{"name":"CodeMixBench","keyword":"arabic","description":"\n\t\n\t\t\n\t\tâ„¹ï¸Dataset Card for CodeMixBench\n\t\n\n\n\t\n\t\t\n\t\t[EMNLP'25] CodeMixBench: Evaluating Code-Mixing Capabilities of LLMs Across 18 Languages\n\t\n\n   \n      \n   \n        \n  \n      \n   \n  \n      \n   \n\n\n\n\n\nCode-mixing is a linguistic phenomenon where multilingual speakers switch or mix two or more languages within a single utterance or conversation. \nTo evaluate LLMsâ€™ comprehension of multilingual code-mixed texts, we introduce CodeMixBench, a benchmark comprising eight tasks across 18 languages.â€¦ See the full description on the dataset page: https://huggingface.co/datasets/CodeMixBench/CodeMixBench.","url":"https://huggingface.co/datasets/CodeMixBench/CodeMixBench","creator_name":"CodeMixBench","creator_url":"https://huggingface.co/CodeMixBench","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["Chinese","English","Spanish","Hindi","German"],"keywords_longer_than_N":true},
	{"name":"JQL-Human-Edu-Annotations","keyword":"arabic","description":"\n\t\n\t\t\n\t\tðŸ“š JQL Multilingual Educational Quality Annotations\n\t\n\nThis dataset provides high-quality human annotations for evaluating the educational value of web documents, and serves as a benchmark for training and evaluating multilingual LLM annotators as described in the JQL paper.\n\n\n\t\n\t\t\n\t\tðŸ“ Dataset Summary\n\t\n\n\nDocuments: 511 English texts  \nAnnotations: 3 human ratings per document (0â€“5 scale)  \nTranslations: Into 35 European languages using DeepL and GPT-4o  \nPurpose: For training andâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/JQL-AI/JQL-Human-Edu-Annotations.","url":"https://huggingface.co/datasets/JQL-AI/JQL-Human-Edu-Annotations","creator_name":"JQL-AI","creator_url":"https://huggingface.co/JQL-AI","license_name":"Open Data Commons Attribution License v1.0","license_url":"https://scancode-licensedb.aboutcode.org/odc-by-1.0.html","language":"en","first_N":5,"first_N_keywords":["text-classification","Bulgarian","Czech","Croatian","Macedonian"],"keywords_longer_than_N":true},
	{"name":"OGC_Qualitative","keyword":"arabic","description":"\n\t\n\t\t\n\t\tOGC_Qualitative\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nOGC_Qualitative is a high-quality multimodal dataset created through the merge of multiple domain-specific datasets with enhanced data processing techniques. This dataset represents our most refined approach to multimodal data generation, incorporating filtering algorithms and improved AI-assisted content generation to deliver superior quality for RAG, DSE, question answering, document search, and vision-language model training tasks.â€¦ See the full description on the dataset page: https://huggingface.co/datasets/racineai/OGC_Qualitative.","url":"https://huggingface.co/datasets/racineai/OGC_Qualitative","creator_name":"racine.ai","creator_url":"https://huggingface.co/racineai","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["question-answering","visual-question-answering","text-retrieval","English","French"],"keywords_longer_than_N":true},
	{"name":"language-dataset","keyword":"arabic","description":"\n","url":"https://huggingface.co/datasets/neon-mao/language-dataset","creator_name":"maoqifan","creator_url":"https://huggingface.co/neon-mao","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","English","Chinese","French","Russian"],"keywords_longer_than_N":true},
	{"name":"sada2022","keyword":"arabic","description":"\n\t\n\t\t\n\t\tDataset Card for SADA - Saudi Audio Dataset for Arabic\n\t\n\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe SADA (Saudi Audio Dataset for Arabic) is a comprehensive dataset consisting of audio recordings from over 57 TV shows aired by the Saudi Broadcasting Authority (SBA). The dataset contains approximately 667 hours of audio data with transcripts, the majority of which are in various Saudi dialects (Najdi, Hijazi, Khaliji, etc.). \n\nCurated by: The National Center forâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/m6011/sada2022.","url":"https://huggingface.co/datasets/m6011/sada2022","creator_name":"mohammed alharbi","creator_url":"https://huggingface.co/m6011","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["Arabic","cc-by-4.0","1K - 10K","parquet","Audio"],"keywords_longer_than_N":true},
	{"name":"PangeaBench-xmmmu","keyword":"arabic","description":"neulab/PangeaBench-xmmmu dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/neulab/PangeaBench-xmmmu","creator_name":"NeuLab @ LTI/CMU","creator_url":"https://huggingface.co/neulab","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["visual-question-answering","question-answering","multiple-choice","Arabic","French"],"keywords_longer_than_N":true},
	{"name":"aya_redteaming","keyword":"arabic","description":"\n\n\n\t\n\t\t\n\t\tDataset Card for Aya Red-teaming\n\t\n\n\n\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\nThe Aya Red-teaming dataset is a human-annotated multilingual red-teaming dataset consisting of harmful prompts in 8 languages across 9 different categories of harm with explicit labels for \"global\" and \"local\" harm.\n\n\n\n\n\n\nCurated by: Professional compensated annotators\nLanguages: Arabic, English, Filipino, French, Hindi, Russian, Serbian and Spanish\nLicense: Apache 2.0\nPaper: arxiv link\n\n\n\t\n\t\t\n\t\n\t\n\t\tHarm Categories:â€¦ See the full description on the dataset page: https://huggingface.co/datasets/CohereLabs/aya_redteaming.","url":"https://huggingface.co/datasets/CohereLabs/aya_redteaming","creator_name":"Cohere Labs","creator_url":"https://huggingface.co/CohereLabs","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":null,"first_N":5,"first_N_keywords":["English","Hindi","French","Spanish","Arabic"],"keywords_longer_than_N":true},
	{"name":"MultiPICo","keyword":"arabic","description":"\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nMultiPICo (Multilingual Perspectivist Irony Corpus) is a disaggregated multilingual corpus for irony detection, containing 18,778 pairs of short conversations (post-reply) from Twitter (8,956) and Reddit (9,822), along with the demographic information of each annotator (age, nationality, gender, and so on). \n\n\t\n\t\t\n\t\tSupported Tasks and Leaderboards\n\t\n\nIrony classification task using soft labels (i.e., distribution of annotations) or hard labels (i.e., aggregatedâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Multilingual-Perspectivist-NLU/MultiPICo.","url":"https://huggingface.co/datasets/Multilingual-Perspectivist-NLU/MultiPICo","creator_name":"MultilingualPerspectivistNLU","creator_url":"https://huggingface.co/Multilingual-Perspectivist-NLU","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["Spanish","English","German","Arabic","Portuguese"],"keywords_longer_than_N":true},
	{"name":"AceGPT-v2-AlignmentData","keyword":"arabic","description":"\n\t\n\t\t\n\t\tIntroduction\n\t\n\nTo efficiently achieve native alignment in AceGPT-v2, this dataset was constructed to train a small alignment model to filter the entire pre-train dataset. Therefore, this dataset was built through the following steps:\n\nRandomly select 96K samples from ArabicText 2022.\nUse GPT-4-turbo to rewrite the extracted data according to the provided prompts.\nOrganize the rewritten data into pairs to create training data for the Alignment LLM.\n\n\n\t\n\t\t\n\t\n\t\n\t\tSystem Prompt for Arabicâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/FreedomIntelligence/AceGPT-v2-AlignmentData.","url":"https://huggingface.co/datasets/FreedomIntelligence/AceGPT-v2-AlignmentData","creator_name":"FreedomAI","creator_url":"https://huggingface.co/FreedomIntelligence","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["Arabic","apache-2.0","10M - 100M","json","Text"],"keywords_longer_than_N":true},
	{"name":"multilingual_translation_sft","keyword":"arabic","description":"Youseff1987/multilingual_translation_sft dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/Youseff1987/multilingual_translation_sft","creator_name":"JOON HYOUNG JUN","creator_url":"https://huggingface.co/Youseff1987","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["translation","Korean","English","Chinese","Zulu"],"keywords_longer_than_N":true},
	{"name":"Arabic-NLi-Pair-Class","keyword":"arabic","description":"\n\t\n\t\t\n\t\tArabic NLI Pair-Class\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\n\nThe Arabic Version of SNLI and MultiNLI datasets. (Pair-Class Subset)\nOriginally used for Natural Language Inference (NLI),\nDataset may be used for training/finetuning an embedding model for semantic textual similarity.\n\n\n\t\n\t\t\n\t\tPair-Class Subset\n\t\n\n\nColumns: \"premise\", \"hypothesis\", \"label\"\nColumn types: str, str, class with {\"0\": \"entailment\", \"1\": \"neutral\", \"2\": \"contradiction\"}\n\n\n\t\n\t\t\n\t\tArabic Examples:\n\t\n\n{\n  \"premise\": \"Ø´Ø®Øµâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/LLMXperts/Arabic-NLi-Pair-Class.","url":"https://huggingface.co/datasets/LLMXperts/Arabic-NLi-Pair-Class","creator_name":"LLMXperts","creator_url":"https://huggingface.co/LLMXperts","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["sentence-similarity","Arabic","apache-2.0","100K - 1M","csv"],"keywords_longer_than_N":true},
	{"name":"M-ABSA","keyword":"arabic","description":"\n\t\n\t\t\n\t\tM-ABSA\n\t\n\nThis repo contains the data for our paper M-ABSA: A Multilingual Dataset for Aspect-Based Sentiment Analysis.\n\n\n\t\n\t\t\n\t\tData Description:\n\t\n\nThis is a dataset suitable for the multilingual ABSA task with triplet extraction.\nAll datasets are stored in the data/ folder:\n\nAll dataset contains 7 domains.\n\ndomains = [\"coursera\", \"hotel\", \"laptop\", \"restaurant\", \"phone\", \"sight\", \"food\"]\n\n\nEach dataset contains 21 languages.\n\nlangs = [\"ar\", \"da\", \"de\", \"en\", \"es\", \"fr\", \"hi\", \"hr\"â€¦ See the full description on the dataset page: https://huggingface.co/datasets/Multilingual-NLP/M-ABSA.","url":"https://huggingface.co/datasets/Multilingual-NLP/M-ABSA","creator_name":"multilingual-NLP","creator_url":"https://huggingface.co/Multilingual-NLP","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["token-classification","text-classification","Arabic","Danish","German"],"keywords_longer_than_N":true},
	{"name":"SummARai","keyword":"arabic","description":"\n\t\n\t\t\n\t\tSummARai v1.0: Arabic Chunk-Aligned Summarization Dataset\n\t\n\nSummARai v1.0 is a high-quality Arabic summarization dataset with chunk-level alignment between long Arabic texts and their human-written summaries. All content is written in Modern Standard Arabic (MSA), making it suitable for formal Arabic NLP tasks.\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Details\n\t\n\n\nSamples: 4,328 text-summary pairs\nGenres:\nðŸ“˜ Books: 3,666\nðŸ“– Novels: 662\n\n\n\nLanguage: 100% Modern Standard Arabic (MSA)\n\t\n\t\t\n\t\tData Sourcesâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fatmaserry/SummARai.","url":"https://huggingface.co/datasets/fatmaserry/SummARai","creator_name":"Fatma Elzahraa Serry","creator_url":"https://huggingface.co/fatmaserry","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["summarization","Arabic","apache-2.0","1K - 10K","Text"],"keywords_longer_than_N":true},
	{"name":"SummARai","keyword":"arabic","description":"\n\t\n\t\t\n\t\tSummARai v1.0: Arabic Chunk-Aligned Summarization Dataset\n\t\n\nSummARai v1.0 is a high-quality Arabic summarization dataset with chunk-level alignment between long Arabic texts and their human-written summaries. All content is written in Modern Standard Arabic (MSA), making it suitable for formal Arabic NLP tasks.\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Details\n\t\n\n\nSamples: 4,328 text-summary pairs\nGenres:\nðŸ“˜ Books: 3,666\nðŸ“– Novels: 662\n\n\n\nLanguage: 100% Modern Standard Arabic (MSA)\n\t\n\t\t\n\t\tData Sourcesâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fatmaserry/SummARai.","url":"https://huggingface.co/datasets/fatmaserry/SummARai","creator_name":"Fatma Elzahraa Serry","creator_url":"https://huggingface.co/fatmaserry","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["summarization","Arabic","apache-2.0","1K - 10K","Text"],"keywords_longer_than_N":true},
	{"name":"wikipedia_quality_wikirank","keyword":"arabic","description":"Datasets with WikiRank quality score as of 1 August 2024 for 47 million Wikipedia articles in 55 language versions (also simplified version for each language in separate files).\nThe WikiRank quality score is a metric designed to assess the overall quality of a Wikipedia article. Although its specific algorithm can vary depending on the implementation, the score typically combines several key features of the Wikipedia article.\n\n\t\n\t\t\n\t\n\t\n\t\tWhy Itâ€™s Important\n\t\n\n\nEnhances Trust: For readers andâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/lewoniewski/wikipedia_quality_wikirank.","url":"https://huggingface.co/datasets/lewoniewski/wikipedia_quality_wikirank","creator_name":"WÅ‚odzimierz Lewoniewski","creator_url":"https://huggingface.co/lewoniewski","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["Arabic","Azerbaijani","Belarusian","Bulgarian","Catalan"],"keywords_longer_than_N":true},
	{"name":"MasriSpeech","keyword":"arabic","description":"\n\t\n\t\t\n\t\tðŸ—£ï¸ MasriSpeech: Egyptian Arabic Speech Dataset\n\t\n\nA large-scale, high-quality Egyptian Arabic speech dataset for Automatic Speech Recognition (ASR), curated and released by Yahya Muhammad Alnwsany. MasriSpeech is designed to empower research and development in Arabic ASR, dialect modeling, and linguistic studies.\n\n  \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tðŸŒŸ Mission & Vision\n\t\n\nMasriSpeech aims to:\n\nAdvance the state of Egyptian Arabic ASR and dialectal NLP.\nEnable researchers, developers, and students toâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/NightPrince/MasriSpeech.","url":"https://huggingface.co/datasets/NightPrince/MasriSpeech","creator_name":"Yahya Muhammad Alnwsany","creator_url":"https://huggingface.co/NightPrince","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","found","found","monolingual"],"keywords_longer_than_N":true},
	{"name":"MasriSpeech","keyword":"arabic","description":"\n\t\n\t\t\n\t\tðŸ—£ï¸ MasriSpeech: Egyptian Arabic Speech Dataset\n\t\n\nA large-scale, high-quality Egyptian Arabic speech dataset for Automatic Speech Recognition (ASR), curated and released by Yahya Muhammad Alnwsany. MasriSpeech is designed to empower research and development in Arabic ASR, dialect modeling, and linguistic studies.\n\n  \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tðŸŒŸ Mission & Vision\n\t\n\nMasriSpeech aims to:\n\nAdvance the state of Egyptian Arabic ASR and dialectal NLP.\nEnable researchers, developers, and students toâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/NightPrince/MasriSpeech.","url":"https://huggingface.co/datasets/NightPrince/MasriSpeech","creator_name":"Yahya Muhammad Alnwsany","creator_url":"https://huggingface.co/NightPrince","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","found","found","monolingual"],"keywords_longer_than_N":true},
	{"name":"deep-fast","keyword":"arabic","description":"Deep and Fast is a collection of poems to remember the pandemic as a testament to the urgency of connection, poems about how fast we go deep.\nThis specific data set, made of the poem titles and poems themselves is meant to fine tune an LLM to adopt the poet's voice.\n","url":"https://huggingface.co/datasets/madihalim/deep-fast","creator_name":"Halim Madi","creator_url":"https://huggingface.co/madihalim","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["question-answering","English","Arabic","mit","< 1K"],"keywords_longer_than_N":true},
	{"name":"MasriSpeech","keyword":"egyptian arabic","description":"\n\t\n\t\t\n\t\tðŸ—£ï¸ MasriSpeech: Egyptian Arabic Speech Dataset\n\t\n\nA large-scale, high-quality Egyptian Arabic speech dataset for Automatic Speech Recognition (ASR), curated and released by Yahya Muhammad Alnwsany. MasriSpeech is designed to empower research and development in Arabic ASR, dialect modeling, and linguistic studies.\n\n  \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tðŸŒŸ Mission & Vision\n\t\n\nMasriSpeech aims to:\n\nAdvance the state of Egyptian Arabic ASR and dialectal NLP.\nEnable researchers, developers, and students toâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/NightPrince/MasriSpeech.","url":"https://huggingface.co/datasets/NightPrince/MasriSpeech","creator_name":"Yahya Muhammad Alnwsany","creator_url":"https://huggingface.co/NightPrince","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","found","found","monolingual"],"keywords_longer_than_N":true},
	{"name":"surah_ikhlas_qalqala","keyword":"arabic","description":"\n\t\n\t\t\n\t\tSurah Ikhlas Qalqala Errors\n\t\n\nThis dataset is a modified version of the Surah Ikhlas dataset, containing recordings for assessing Qalqala Tajweed rule detection.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\naudio: 16kHz resampled mono audio recordings\nverse: Verse number (1/2/3/4)\nqalqala_ahad_v1: Qalqala for letter Ø¯ in word Ø£Ø­Ø¯\nqalqala_samad: Qalqala for letter Ø¯ in word Ø§Ù„ØµÙ…Ø¯\nqalqala_yalid: Qalqala for letter Ø¯ in word ÙŠÙ„Ø¯ \nqalqala_yulad: Qalqala for letter Ø¯ in word ÙŠÙˆÙ„Ø¯\nqalqala_ahad_v4: Qalqalaâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/hetchyy/surah_ikhlas_qalqala.","url":"https://huggingface.co/datasets/hetchyy/surah_ikhlas_qalqala","creator_name":"Ahmed Ibrahim","creator_url":"https://huggingface.co/hetchyy","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","Arabic","cc-by-4.0","1K - 10K","parquet"],"keywords_longer_than_N":true},
	{"name":"morocco_tourism_darija","keyword":"arabic","description":"\n\t\n\t\t\n\t\tðŸ‡²ðŸ‡¦ Moroccan Tourism Darija Dialogues (maroc_tourism_darja)\n\t\n\nRepositoryâ€‚|â€‚datasets/maroc_tourism_darjaSizeâ€‚|â€‚1â€¯000 dialogues (â‰ˆâ€¯14â€¯k turns)Languageâ€‚|â€‚DarijaÂ (MoroccanÂ Arabic)Topicsâ€‚|â€‚Transport Â· Accommodation Â· Culture Â· GastronomyLicenseâ€‚|â€‚CCâ€‘BYâ€‘4.0Formatâ€‚|â€‚JSONLÂ (one dialogue per line)\n\n\n\t\n\t\t\n\t\n\t\n\t\t1. Dataset Summary\n\t\n\nmaroc_tourism_darja is a synthetic, highâ€‘quality collection of touristâ€‘guide conversations in Moroccan Darija.Each dialogue is a short twoâ€‘turn exchange in which aâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/oabai/morocco_tourism_darija.","url":"https://huggingface.co/datasets/oabai/morocco_tourism_darija","creator_name":"ABAI","creator_url":"https://huggingface.co/oabai","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","Arabic","apache-2.0","1K - 10K","parquet"],"keywords_longer_than_N":true},
	{"name":"fineweb-2","keyword":"egyptian arabic","description":"\n\t\n\t\t\n\t\tðŸ¥‚ FineWeb2\n\t\n\n\n    \n\n\n\nA sparkling update with 1000s of languages\n\n\n\t\n\t\t\n\t\tWhat is it?\n\t\n\nThis is the second iteration of the popular ðŸ· FineWeb dataset, bringing high quality pretraining data to over 1000 ðŸ—£ï¸ languages.\nThe ðŸ¥‚ FineWeb2 dataset is fully reproducible, available under the permissive ODC-By 1.0 license and extensively validated through hundreds of ablation experiments.\nIn particular, on the set of 9 diverse languages we used to guide our processing decisions, ðŸ¥‚ FineWeb2â€¦ See the full description on the dataset page: https://huggingface.co/datasets/HuggingFaceFW/fineweb-2.","url":"https://huggingface.co/datasets/HuggingFaceFW/fineweb-2","creator_name":"FineData","creator_url":"https://huggingface.co/HuggingFaceFW","license_name":"Open Data Commons Attribution License v1.0","license_url":"https://scancode-licensedb.aboutcode.org/odc-by-1.0.html","language":"en","first_N":5,"first_N_keywords":["text-generation","Arifama-Miniafia","Ankave","Abau","Amarasi"],"keywords_longer_than_N":true},
	{"name":"fineweb-2","keyword":"levantine arabic","description":"\n\t\n\t\t\n\t\tðŸ¥‚ FineWeb2\n\t\n\n\n    \n\n\n\nA sparkling update with 1000s of languages\n\n\n\t\n\t\t\n\t\tWhat is it?\n\t\n\nThis is the second iteration of the popular ðŸ· FineWeb dataset, bringing high quality pretraining data to over 1000 ðŸ—£ï¸ languages.\nThe ðŸ¥‚ FineWeb2 dataset is fully reproducible, available under the permissive ODC-By 1.0 license and extensively validated through hundreds of ablation experiments.\nIn particular, on the set of 9 diverse languages we used to guide our processing decisions, ðŸ¥‚ FineWeb2â€¦ See the full description on the dataset page: https://huggingface.co/datasets/HuggingFaceFW/fineweb-2.","url":"https://huggingface.co/datasets/HuggingFaceFW/fineweb-2","creator_name":"FineData","creator_url":"https://huggingface.co/HuggingFaceFW","license_name":"Open Data Commons Attribution License v1.0","license_url":"https://scancode-licensedb.aboutcode.org/odc-by-1.0.html","language":"en","first_N":5,"first_N_keywords":["text-generation","Arifama-Miniafia","Ankave","Abau","Amarasi"],"keywords_longer_than_N":true},
	{"name":"fineweb-2","keyword":"mesopotamian arabic","description":"\n\t\n\t\t\n\t\tðŸ¥‚ FineWeb2\n\t\n\n\n    \n\n\n\nA sparkling update with 1000s of languages\n\n\n\t\n\t\t\n\t\tWhat is it?\n\t\n\nThis is the second iteration of the popular ðŸ· FineWeb dataset, bringing high quality pretraining data to over 1000 ðŸ—£ï¸ languages.\nThe ðŸ¥‚ FineWeb2 dataset is fully reproducible, available under the permissive ODC-By 1.0 license and extensively validated through hundreds of ablation experiments.\nIn particular, on the set of 9 diverse languages we used to guide our processing decisions, ðŸ¥‚ FineWeb2â€¦ See the full description on the dataset page: https://huggingface.co/datasets/HuggingFaceFW/fineweb-2.","url":"https://huggingface.co/datasets/HuggingFaceFW/fineweb-2","creator_name":"FineData","creator_url":"https://huggingface.co/HuggingFaceFW","license_name":"Open Data Commons Attribution License v1.0","license_url":"https://scancode-licensedb.aboutcode.org/odc-by-1.0.html","language":"en","first_N":5,"first_N_keywords":["text-generation","Arifama-Miniafia","Ankave","Abau","Amarasi"],"keywords_longer_than_N":true},
	{"name":"fineweb-2","keyword":"moroccan arabic","description":"\n\t\n\t\t\n\t\tðŸ¥‚ FineWeb2\n\t\n\n\n    \n\n\n\nA sparkling update with 1000s of languages\n\n\n\t\n\t\t\n\t\tWhat is it?\n\t\n\nThis is the second iteration of the popular ðŸ· FineWeb dataset, bringing high quality pretraining data to over 1000 ðŸ—£ï¸ languages.\nThe ðŸ¥‚ FineWeb2 dataset is fully reproducible, available under the permissive ODC-By 1.0 license and extensively validated through hundreds of ablation experiments.\nIn particular, on the set of 9 diverse languages we used to guide our processing decisions, ðŸ¥‚ FineWeb2â€¦ See the full description on the dataset page: https://huggingface.co/datasets/HuggingFaceFW/fineweb-2.","url":"https://huggingface.co/datasets/HuggingFaceFW/fineweb-2","creator_name":"FineData","creator_url":"https://huggingface.co/HuggingFaceFW","license_name":"Open Data Commons Attribution License v1.0","license_url":"https://scancode-licensedb.aboutcode.org/odc-by-1.0.html","language":"en","first_N":5,"first_N_keywords":["text-generation","Arifama-Miniafia","Ankave","Abau","Amarasi"],"keywords_longer_than_N":true},
	{"name":"fineweb-2","keyword":"najdi arabic","description":"\n\t\n\t\t\n\t\tðŸ¥‚ FineWeb2\n\t\n\n\n    \n\n\n\nA sparkling update with 1000s of languages\n\n\n\t\n\t\t\n\t\tWhat is it?\n\t\n\nThis is the second iteration of the popular ðŸ· FineWeb dataset, bringing high quality pretraining data to over 1000 ðŸ—£ï¸ languages.\nThe ðŸ¥‚ FineWeb2 dataset is fully reproducible, available under the permissive ODC-By 1.0 license and extensively validated through hundreds of ablation experiments.\nIn particular, on the set of 9 diverse languages we used to guide our processing decisions, ðŸ¥‚ FineWeb2â€¦ See the full description on the dataset page: https://huggingface.co/datasets/HuggingFaceFW/fineweb-2.","url":"https://huggingface.co/datasets/HuggingFaceFW/fineweb-2","creator_name":"FineData","creator_url":"https://huggingface.co/HuggingFaceFW","license_name":"Open Data Commons Attribution License v1.0","license_url":"https://scancode-licensedb.aboutcode.org/odc-by-1.0.html","language":"en","first_N":5,"first_N_keywords":["text-generation","Arifama-Miniafia","Ankave","Abau","Amarasi"],"keywords_longer_than_N":true},
	{"name":"fineweb-2","keyword":"standard arabic","description":"\n\t\n\t\t\n\t\tðŸ¥‚ FineWeb2\n\t\n\n\n    \n\n\n\nA sparkling update with 1000s of languages\n\n\n\t\n\t\t\n\t\tWhat is it?\n\t\n\nThis is the second iteration of the popular ðŸ· FineWeb dataset, bringing high quality pretraining data to over 1000 ðŸ—£ï¸ languages.\nThe ðŸ¥‚ FineWeb2 dataset is fully reproducible, available under the permissive ODC-By 1.0 license and extensively validated through hundreds of ablation experiments.\nIn particular, on the set of 9 diverse languages we used to guide our processing decisions, ðŸ¥‚ FineWeb2â€¦ See the full description on the dataset page: https://huggingface.co/datasets/HuggingFaceFW/fineweb-2.","url":"https://huggingface.co/datasets/HuggingFaceFW/fineweb-2","creator_name":"FineData","creator_url":"https://huggingface.co/HuggingFaceFW","license_name":"Open Data Commons Attribution License v1.0","license_url":"https://scancode-licensedb.aboutcode.org/odc-by-1.0.html","language":"en","first_N":5,"first_N_keywords":["text-generation","Arifama-Miniafia","Ankave","Abau","Amarasi"],"keywords_longer_than_N":true},
	{"name":"fineweb-2","keyword":"tunisian arabic","description":"\n\t\n\t\t\n\t\tðŸ¥‚ FineWeb2\n\t\n\n\n    \n\n\n\nA sparkling update with 1000s of languages\n\n\n\t\n\t\t\n\t\tWhat is it?\n\t\n\nThis is the second iteration of the popular ðŸ· FineWeb dataset, bringing high quality pretraining data to over 1000 ðŸ—£ï¸ languages.\nThe ðŸ¥‚ FineWeb2 dataset is fully reproducible, available under the permissive ODC-By 1.0 license and extensively validated through hundreds of ablation experiments.\nIn particular, on the set of 9 diverse languages we used to guide our processing decisions, ðŸ¥‚ FineWeb2â€¦ See the full description on the dataset page: https://huggingface.co/datasets/HuggingFaceFW/fineweb-2.","url":"https://huggingface.co/datasets/HuggingFaceFW/fineweb-2","creator_name":"FineData","creator_url":"https://huggingface.co/HuggingFaceFW","license_name":"Open Data Commons Attribution License v1.0","license_url":"https://scancode-licensedb.aboutcode.org/odc-by-1.0.html","language":"en","first_N":5,"first_N_keywords":["text-generation","Arifama-Miniafia","Ankave","Abau","Amarasi"],"keywords_longer_than_N":true},
	{"name":"Kawthar-AR_EN-Public-Phone-Audio-Dataset","keyword":"arabic","description":"\n\t\n\t\t\n\t\tØ¨Ø³Ù… Ø§Ù„Ù„Ù‡\n\t\n\nThis dataset text data is derived from here.\nAudio files are gathered by the help of Arabic team: Planet Blind Tech (PBt).\nThank you Shams Eddin (from Algeria).\n","url":"https://huggingface.co/datasets/mah92/Kawthar-AR_EN-Public-Phone-Audio-Dataset","creator_name":"ali.mahmoudi","creator_url":"https://huggingface.co/mah92","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["Arabic","English","cc0-1.0","ðŸ‡ºðŸ‡¸ Region: US"],"keywords_longer_than_N":false},
	{"name":"common_voice_21_0","keyword":"arabic","description":"Due to storage limits some files had to be split into multiple parts. They can be merged like this: cat file.* > file.\n","url":"https://huggingface.co/datasets/2Jyq/common_voice_21_0","creator_name":"2Jyq","creator_url":"https://huggingface.co/2Jyq","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["crowdsourced","crowdsourced","multilingual","extended|common_voice","Abkhaz"],"keywords_longer_than_N":true},
	{"name":"MELA","keyword":"arabic","description":"See the GitHub repo for details.\n","url":"https://huggingface.co/datasets/Geralt-Targaryen/MELA","creator_name":"Ziyin Zhang","creator_url":"https://huggingface.co/Geralt-Targaryen","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","English","Chinese","Italian","Russian"],"keywords_longer_than_N":true},
	{"name":"panlex-definitions","keyword":"standard arabic","description":"\n\t\n\t\t\n\t\tDataset Card for panlex-definitions\n\t\n\nThis is a dataset of word definitions in several hudnred languages, extracted from https://panlex.org.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset has been extracted from https://panlex.org (the 20250201 database dump) and rearranged on the per-language basis (by the language of the definition).\nEach language subset consists of definitions (short phrases).\nEach definition is associated with some meanings (if there isâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/cointegrated/panlex-definitions.","url":"https://huggingface.co/datasets/cointegrated/panlex-definitions","creator_name":"David Dale","creator_url":"https://huggingface.co/cointegrated","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["translation","Abkhazian","Hijazi Arabic","Afrikaans","Ainu (Japan)"],"keywords_longer_than_N":true},
	{"name":"shamela-waqfeya-library","keyword":"arabic","description":"\n\t\n\t\t\n\t\tShamela Waqfeya Library\n\t\n\n\n\t\n\t\t\n\t\tðŸ“– Overview\n\t\n\nShamela Waqfeya is one of the primary online resources for Islamic books, similar to Shamela. It hosts more than 4,500 PDF books across over 40 categories.\nIn this dataset, we processed the original PDF files using Google Document AI APIs and extracted their contents into two additional formats: TXT and DOCX.\n\n\t\n\t\t\n\t\tðŸ“Š Dataset Contents\n\t\n\nThe dataset includes 12,877 PDF files (spanning 5,138,027 pages) representing 4,661 Islamic books.â€¦ See the full description on the dataset page: https://huggingface.co/datasets/ieasybooks-org/shamela-waqfeya-library.","url":"https://huggingface.co/datasets/ieasybooks-org/shamela-waqfeya-library","creator_name":"Ø§Ù„ÙƒØªØ¨ Ø§Ù„Ù…ÙÙŠØ³Ù‘Ø±Ø©","creator_url":"https://huggingface.co/ieasybooks-org","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["image-to-text","Arabic","mit","1K - 10K","csv"],"keywords_longer_than_N":true},
	{"name":"R3-eval-MMMLU","keyword":"arabic","description":"HLeiTR/R3-eval-MMMLU dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/HLeiTR/R3-eval-MMMLU","creator_name":"Shou-Yi Hung","creator_url":"https://huggingface.co/HLeiTR","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["question-answering","Arabic","Bengali","German","Spanish"],"keywords_longer_than_N":true},
	{"name":"PolyGuardPrompts","keyword":"arabic","description":"\n\t\n\t\t\n\t\tPolyGuard: A Multilingual Safety Moderation Tool for 17 Languages\n\t\n\nAbstract: Truly multilingual safety moderation efforts for Large Language Models (LLMs) have been hindered by a narrow focus on a small set of languages (e.g., English, Chinese) as well as a limited scope of safety definition, resulting in significant gaps in moderation capabilities. To bridge these gaps, we release PolyGuard, a new state-of-the-art multilingual safety model for safeguarding LLM generations, and theâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/ToxicityPrompts/PolyGuardPrompts.","url":"https://huggingface.co/datasets/ToxicityPrompts/PolyGuardPrompts","creator_name":"ToxicityPrompts","creator_url":"https://huggingface.co/ToxicityPrompts","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["Arabic","Chinese","Czech","Dutch","English"],"keywords_longer_than_N":true},
	{"name":"Arabic_Reviews_of_SHEIN","keyword":"arabic","description":"\n\t\n\t\t\n\t\tArabic Reviews of SHEIN Online Store\n\t\n\n\n\t\n\t\t\n\t\tDescription:\n\t\n\nThis dataset contains Arabic-language reviews of products from the SHEIN online store. The reviews cover various aspects of the products and overall customer satisfaction. \nThe goal of collecting the dataset is to include a wide range of common phrases and terms used in daily conversation, reflecting the diversity of the dialects of the Arabic language, especially in Saudi Arabia.\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nArabic \n\n\t\n\t\t\n\t\tDataâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Ruqiya/Arabic_Reviews_of_SHEIN.","url":"https://huggingface.co/datasets/Ruqiya/Arabic_Reviews_of_SHEIN","creator_name":"Ruqiya Bin Safi","creator_url":"https://huggingface.co/Ruqiya","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","text2text-generation","text-generation","sentence-similarity","zero-shot-classification"],"keywords_longer_than_N":true},
	{"name":"sira_ar_en","keyword":"arabic","description":"\n\t\n\t\t\n\t\tDataset Card for Dataset Name\n\t\n\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nDataset containts short articles about important historical events that took place in the Islam universe. \nEvery record has original description on Arabic and AI translation to English. Translation was created by \n\nCurated by: Ivan Slepovichev\nLanguage(s) (NLP): Arabic, English\nLicense: MIT\n\n\n\t\n\t\t\n\t\tDataset Sources [optional]\n\t\n\n\n\n\nRepository: Most of data was rettrieved from dorar.net/historyâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/gurgutan/sira_ar_en.","url":"https://huggingface.co/datasets/gurgutan/sira_ar_en","creator_name":"Ð˜Ð²Ð°Ð½ Ð˜Ð²Ð°Ð½Ð¾Ð²Ð¸Ñ‡ Ð¡Ð»ÐµÐ¿Ð¾Ð²Ð¸Ñ‡ÐµÐ²","creator_url":"https://huggingface.co/gurgutan","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["translation","Arabic","English","mit","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"BenchMAX_Domain_Translation","keyword":"arabic","description":"\n\t\n\t\t\n\t\tDataset Sources\n\t\n\n\nPaper: BenchMAX: A Comprehensive Multilingual Evaluation Suite for Large Language Models\nLink: https://huggingface.co/papers/2502.07346\nRepository: https://github.com/CONE-MT/BenchMAX\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nBenchMAX_Domain_Translation is a dataset of BenchMAX, which evaluates the translation capability on specific domains.\nWe collect the domain multi-way parallel data from other tasks in BenchMAX, such as math data, code data, etc.\nEach sample contains oneâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/LLaMAX/BenchMAX_Domain_Translation.","url":"https://huggingface.co/datasets/LLaMAX/BenchMAX_Domain_Translation","creator_name":"LLaMAX","creator_url":"https://huggingface.co/LLaMAX","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["translation","multilingual","English","Chinese","Spanish"],"keywords_longer_than_N":true},
	{"name":"GlobalDISCO","keyword":"arabic","description":"\n\t\n\t\t\n\t\tGlobalDISCO\n\t\n\nGlobalDISCO is a large-scale dataset consisting of 73k music tracks generated by state-of-the-art commercial generative music models, along with paired links to 93k reference tracks in LAION-DISCO-12M. The dataset spans 147 languages and includes musical style prompts extracted from MusicBrainz and Wikipedia. The dataset is globally balanced, representing musical styles from artists across 79 countries and five continents. It is aimed to support the research community inâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/disco-eth/GlobalDISCO.","url":"https://huggingface.co/datasets/disco-eth/GlobalDISCO","creator_name":"DISCO","creator_url":"https://huggingface.co/disco-eth","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["audio-classification","English","Spanish","French","German"],"keywords_longer_than_N":true},
	{"name":"TransWebEdu","keyword":"arabic","description":"\n\t\n\t\t\n\t\tTransWebEdu\n\t\n\nTransWebEdu is a machine-translated, multi-way parallel, multilingual dataset at pretrain scale, supporting ten languages: Arabic, Welsh, German, English, Spanish, French, Indonesian, Italian, Russian, and Swahili.It is used to pretrain the TransWebLLM model from scratch, with a focus on multilingual web-based education content.\nFor more information, see the paper:Multilingual Language Model Pretraining using Machine-translated Data\n\n\t\n\t\t\n\t\n\t\n\t\tLanguages Supportedâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/britllm/TransWebEdu.","url":"https://huggingface.co/datasets/britllm/TransWebEdu","creator_name":"BritLLM","creator_url":"https://huggingface.co/britllm","license_name":"Open Data Commons Attribution License v1.0","license_url":"https://scancode-licensedb.aboutcode.org/odc-by-1.0.html","language":null,"first_N":5,"first_N_keywords":["Arabic","Welsh","English","Spanish","French"],"keywords_longer_than_N":true},
	{"name":"ngram-google-2012","keyword":"arabic","description":"python -m spacy download en_core_web_sm\n\nTitles:\njq -s '.[].title' raw/dict.jsonl\n\nreturns\n\n \"English\"\n \"English One Million\"\n \"American English\"\n \"British English\"\n \"English Fiction\"\n \"Chinese (simplified)\"\n \"French\"\n \"German\"\n \"Hebrew\"\n \"Italian\"\n \"Russian\"\n \"Spanish\"\n\nSpellcheck:\nhttps://pypi.org/project/pyspellchecker/\nEnglish - â€˜enâ€™\nSpanish - â€˜esâ€™\nFrench - â€˜frâ€™\nPortuguese - â€˜ptâ€™\nGerman - â€˜deâ€™\nRussian - â€˜ruâ€™\nArabic - â€˜arâ€™\n\nSets now:\n\n \"English\" - en\n \"Spanish\" - es\n \"French\" - fr\n \"German\"â€¦ See the full description on the dataset page: https://huggingface.co/datasets/gustawdaniel/ngram-google-2012.","url":"https://huggingface.co/datasets/gustawdaniel/ngram-google-2012","creator_name":"Daniel Gustaw","creator_url":"https://huggingface.co/gustawdaniel","license_name":"Creative Commons Attribution 3.0","license_url":"https://scancode-licensedb.aboutcode.org/cc-by-3.0.html","language":"en","first_N":5,"first_N_keywords":["English","Spanish","French","Portuguese","German"],"keywords_longer_than_N":true},
	{"name":"MedQA_Arabic_Dataset","keyword":"arabic","description":"ZiadWael/MedQA_Arabic_Dataset dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/ZiadWael/MedQA_Arabic_Dataset","creator_name":"Ziad Wael AbdlHamed","creator_url":"https://huggingface.co/ZiadWael","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["question-answering","Arabic","mit","100K<n<1M","ðŸ‡ºðŸ‡¸ Region: US"],"keywords_longer_than_N":true},
	{"name":"NoRobots-AceGPT.13B.Chat-DPO","keyword":"arabic","description":"\n\t\n\t\t\n\t\tðŸ¤— Dataset Card for \"NoRobots-AceGPT.13B.Chat-DPO\"\n\t\n\n\n\t\n\t\t\n\t\tDataset Sources & Infos\n\t\n\n\nData Origin: Derived from the Arabic No Robots dataset : 2A2I/H4_no_robots which is based on the original No Robots dataset inspired from the InstructGPT paper.\nLanguages: Modern Standard Arabic (MSA)\nLicense: CC BY-NC 4.0\nMaintainers: Ali Elfilali and Marwa El Kamil\n\n\n\t\n\t\n\t\n\t\tPurpose\n\t\n\nNoRobots-AceGPT.13B.Chat-DPO is a DPO dataset designed to advance Arabic NLP by comparing human-generatedâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/2A2I/NoRobots-AceGPT.13B.Chat-DPO.","url":"https://huggingface.co/datasets/2A2I/NoRobots-AceGPT.13B.Chat-DPO","creator_name":"2A2I","creator_url":"https://huggingface.co/2A2I","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["Arabic","apache-2.0","1K - 10K","parquet","Text"],"keywords_longer_than_N":true},
	{"name":"wildchat-filtered","keyword":"arabic","description":"\n\t\n\t\t\n\t\tWildChat Filtered Dataset\n\t\n\nThis is a filtered version of the WildChat-4.8M dataset.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset contains 3,199,860 conversations between human users and ChatGPT, filtered to keep only the essential conversation structure.\n\n\t\n\t\t\n\t\tData Structure\n\t\n\nEach conversation contains only:\n\nconversations: A list of message objects with:\nrole: Either \"user\" or \"assistant\"\ncontent: The text content of the message\n\n\n\nAll other metadata (timestamps, moderationâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/rayonlabs/wildchat-filtered.","url":"https://huggingface.co/datasets/rayonlabs/wildchat-filtered","creator_name":"Rayon Labs","creator_url":"https://huggingface.co/rayonlabs","license_name":"Open Data Commons Attribution License v1.0","license_url":"https://scancode-licensedb.aboutcode.org/odc-by-1.0.html","language":"en","first_N":5,"first_N_keywords":["text-generation","question-answering","English","Spanish","French"],"keywords_longer_than_N":true},
	{"name":"Arabic_Reasoning_Instruct_QA","keyword":"arabic","description":"MohammedNasser/Arabic_Reasoning_Instruct_QA dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/MohammedNasser/Arabic_Reasoning_Instruct_QA","creator_name":"Mohammed Nasser Gaber","creator_url":"https://huggingface.co/MohammedNasser","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["question-answering","text2text-generation","Arabic","apache-2.0","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"openiti_chunked","keyword":"arabic","description":"\n\t\n\t\t\n\t\tDescription\n\t\n\nThis dataset is derived from the 2023.1.8 release of the OpenITI corpus and is intended to pretrain small language models with short context lengths (<2048 Unicode code points).\n\n\t\n\t\t\n\t\tProcessing\n\t\n\nThe markdown files were converted into raw text by stripping all code points neither classified as whitespace nor found in the Arabic Unicode code pages. Each document was then chunked by randomly sampling sequences of 2048 character length with a number of samples selectedâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/mittagessen/openiti_chunked.","url":"https://huggingface.co/datasets/mittagessen/openiti_chunked","creator_name":"Benjamin Kiessling","creator_url":"https://huggingface.co/mittagessen","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["Arabic","cc0-1.0","10M - 100M","parquet","Text"],"keywords_longer_than_N":true},
	{"name":"egyptian-arabic-hate-speech","keyword":"arabic","description":"\n\t\n\t\t\n\t\tðŸ‡ªðŸ‡¬ Egyptian-Arabic Hate Speech Dataset ðŸ—£ï¸ðŸš«\n\t\n\nAuthor: IbrahimAmin, Mostafa Abbas, Rany Hatem, Andrew Ihab, Mohamed Waleed Fahkr License: MIT Paper: Fine-tuning Arabic Pre-Trained Transformer Models for Egyptian-Arabic Dialect Offensive Language and Hate Speech Detection and Classification Languages: Arabic (Egyptian Dialect)\n\n\n\t\n\t\t\n\t\n\t\n\t\tðŸ“‹ Dataset Summary\n\t\n\nThis dataset consists of 8,169 Egyptian-Arabic text samples manually labeled for offensive language and hate speechâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/IbrahimAmin/egyptian-arabic-hate-speech.","url":"https://huggingface.co/datasets/IbrahimAmin/egyptian-arabic-hate-speech","creator_name":"Ibrahim Amin","creator_url":"https://huggingface.co/IbrahimAmin","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","zero-shot-classification","Arabic","Egyptian Arabic","mit"],"keywords_longer_than_N":true},
	{"name":"tatoeba-bitext-mining","keyword":"arabic","description":"\n  Tatoeba\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\n1,000 English-aligned sentence pairs for each language based on the Tatoeba corpus\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2t\n\n\nDomains\nWritten\n\n\nReference\nhttps://github.com/facebookresearch/LASER/tree/main/data/tatoeba/v1\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask = mteb.get_tasks([\"Tatoeba\"])\nevaluator = mteb.MTEB(task)\n\nmodel =â€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/tatoeba-bitext-mining.","url":"https://huggingface.co/datasets/mteb/tatoeba-bitext-mining","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"Creative Commons Attribution 2.0","license_url":"https://scancode-licensedb.aboutcode.org/cc-by-2.0.html","language":"en","first_N":5,"first_N_keywords":["translation","human-annotated","multilingual","Afrikaans","Amharic"],"keywords_longer_than_N":true},
	{"name":"egyptian-arabic-hate-speech","keyword":"egyptian arabic","description":"\n\t\n\t\t\n\t\tðŸ‡ªðŸ‡¬ Egyptian-Arabic Hate Speech Dataset ðŸ—£ï¸ðŸš«\n\t\n\nAuthor: IbrahimAmin, Mostafa Abbas, Rany Hatem, Andrew Ihab, Mohamed Waleed Fahkr License: MIT Paper: Fine-tuning Arabic Pre-Trained Transformer Models for Egyptian-Arabic Dialect Offensive Language and Hate Speech Detection and Classification Languages: Arabic (Egyptian Dialect)\n\n\n\t\n\t\t\n\t\n\t\n\t\tðŸ“‹ Dataset Summary\n\t\n\nThis dataset consists of 8,169 Egyptian-Arabic text samples manually labeled for offensive language and hate speechâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/IbrahimAmin/egyptian-arabic-hate-speech.","url":"https://huggingface.co/datasets/IbrahimAmin/egyptian-arabic-hate-speech","creator_name":"Ibrahim Amin","creator_url":"https://huggingface.co/IbrahimAmin","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","zero-shot-classification","Arabic","Egyptian Arabic","mit"],"keywords_longer_than_N":true},
	{"name":"tatoeba-bitext-mining","keyword":"egyptian arabic","description":"\n  Tatoeba\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\n1,000 English-aligned sentence pairs for each language based on the Tatoeba corpus\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2t\n\n\nDomains\nWritten\n\n\nReference\nhttps://github.com/facebookresearch/LASER/tree/main/data/tatoeba/v1\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask = mteb.get_tasks([\"Tatoeba\"])\nevaluator = mteb.MTEB(task)\n\nmodel =â€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/tatoeba-bitext-mining.","url":"https://huggingface.co/datasets/mteb/tatoeba-bitext-mining","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"Creative Commons Attribution 2.0","license_url":"https://scancode-licensedb.aboutcode.org/cc-by-2.0.html","language":"en","first_N":5,"first_N_keywords":["translation","human-annotated","multilingual","Afrikaans","Amharic"],"keywords_longer_than_N":true},
	{"name":"fact-check-bureau","keyword":"arabic","description":"\n\t\n\t\t\n\t\n\t\n\t\tFact-Check Retrieval Dataset\n\t\n\nThis dataset is designed to support the development and evaluation of fact-check retrieval pipelines. It is structured to work with FactCheckBureau, a tool for designing and evaluating fact-check retrieval pipelines. The dataset comprises a list of claims, fact-check articles, and precomputed embeddings for English and French fact-checks.\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Structure\n\t\n\nThe dataset consists of the following files and directories:\n\narticles.csv:â€¦ See the full description on the dataset page: https://huggingface.co/datasets/NaughtyConstrictor/fact-check-bureau.","url":"https://huggingface.co/datasets/NaughtyConstrictor/fact-check-bureau","creator_name":"Younes","creator_url":"https://huggingface.co/NaughtyConstrictor","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["English","French","Portuguese","Spanish","Arabic"],"keywords_longer_than_N":true},
	{"name":"ShamNER","keyword":"arabic","description":"\n\t\n\t\t\n\t\tShamNER â€“ SpokenÂ Arabic Namedâ€‘Entity Recognition Corpus (Levantine v1.1)\n\t\n\nShamNER is a curated corpus of Levantineâ€‘Arabic sentences annotated for NamedÂ Entities, plus dual annotation to check for consisetency (agreement) across human annotators. \n\nRoundsÂ : pilot, round1â€“round5 (manual, as a rule quality improved across rounds) and round6 (synthetic, postâ€‘edited). The sythentic data is done by sampling label-rich annotated spans from an MSA project and writing it with an LLM whileâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/HebArabNlpProject/ShamNER.","url":"https://huggingface.co/datasets/HebArabNlpProject/ShamNER","creator_name":"Israel National  NLP Program","creator_url":"https://huggingface.co/HebArabNlpProject","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["token-classification","named-entity-recognition","expert-annotated","monolingual","Arabic"],"keywords_longer_than_N":true},
	{"name":"tulu3-100samples","keyword":"egyptian arabic","description":"\n\t\n\t\t\n\t\tDataset\n\t\n\nThis dataset contains 100 samples from the Tulu 3 SFT Mixture.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nEach example in the dataset contains the standard instruction-tuning data points as follow:\n\nid (str): a unique identifier\nmessages (list): message format used for supervised fine-tuning (this contains user prompt and assistant responses)\nsource (str): the source dataset for the given sample\n\n\n\t\n\t\t\n\t\tLicense\n\t\n\nThis dataset is licensed under ODC-BY-1.0. It is intended for research andâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/anayak/tulu3-100samples.","url":"https://huggingface.co/datasets/anayak/tulu3-100samples","creator_name":"Akash Nayak","creator_url":"https://huggingface.co/anayak","license_name":"Open Data Commons Attribution License v1.0","license_url":"https://scancode-licensedb.aboutcode.org/odc-by-1.0.html","language":null,"first_N":5,"first_N_keywords":["other","crowdsourced","expert-generated","machine-generated","multilingual"],"keywords_longer_than_N":true},
	{"name":"tulu3-100samples","keyword":"levantine arabic","description":"\n\t\n\t\t\n\t\tDataset\n\t\n\nThis dataset contains 100 samples from the Tulu 3 SFT Mixture.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nEach example in the dataset contains the standard instruction-tuning data points as follow:\n\nid (str): a unique identifier\nmessages (list): message format used for supervised fine-tuning (this contains user prompt and assistant responses)\nsource (str): the source dataset for the given sample\n\n\n\t\n\t\t\n\t\tLicense\n\t\n\nThis dataset is licensed under ODC-BY-1.0. It is intended for research andâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/anayak/tulu3-100samples.","url":"https://huggingface.co/datasets/anayak/tulu3-100samples","creator_name":"Akash Nayak","creator_url":"https://huggingface.co/anayak","license_name":"Open Data Commons Attribution License v1.0","license_url":"https://scancode-licensedb.aboutcode.org/odc-by-1.0.html","language":null,"first_N":5,"first_N_keywords":["other","crowdsourced","expert-generated","machine-generated","multilingual"],"keywords_longer_than_N":true},
	{"name":"tulu3-100samples","keyword":"moroccan arabic","description":"\n\t\n\t\t\n\t\tDataset\n\t\n\nThis dataset contains 100 samples from the Tulu 3 SFT Mixture.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nEach example in the dataset contains the standard instruction-tuning data points as follow:\n\nid (str): a unique identifier\nmessages (list): message format used for supervised fine-tuning (this contains user prompt and assistant responses)\nsource (str): the source dataset for the given sample\n\n\n\t\n\t\t\n\t\tLicense\n\t\n\nThis dataset is licensed under ODC-BY-1.0. It is intended for research andâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/anayak/tulu3-100samples.","url":"https://huggingface.co/datasets/anayak/tulu3-100samples","creator_name":"Akash Nayak","creator_url":"https://huggingface.co/anayak","license_name":"Open Data Commons Attribution License v1.0","license_url":"https://scancode-licensedb.aboutcode.org/odc-by-1.0.html","language":null,"first_N":5,"first_N_keywords":["other","crowdsourced","expert-generated","machine-generated","multilingual"],"keywords_longer_than_N":true},
	{"name":"tulu3-100samples","keyword":"najdi arabic","description":"\n\t\n\t\t\n\t\tDataset\n\t\n\nThis dataset contains 100 samples from the Tulu 3 SFT Mixture.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nEach example in the dataset contains the standard instruction-tuning data points as follow:\n\nid (str): a unique identifier\nmessages (list): message format used for supervised fine-tuning (this contains user prompt and assistant responses)\nsource (str): the source dataset for the given sample\n\n\n\t\n\t\t\n\t\tLicense\n\t\n\nThis dataset is licensed under ODC-BY-1.0. It is intended for research andâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/anayak/tulu3-100samples.","url":"https://huggingface.co/datasets/anayak/tulu3-100samples","creator_name":"Akash Nayak","creator_url":"https://huggingface.co/anayak","license_name":"Open Data Commons Attribution License v1.0","license_url":"https://scancode-licensedb.aboutcode.org/odc-by-1.0.html","language":null,"first_N":5,"first_N_keywords":["other","crowdsourced","expert-generated","machine-generated","multilingual"],"keywords_longer_than_N":true},
	{"name":"tulu3-100samples","keyword":"standard arabic","description":"\n\t\n\t\t\n\t\tDataset\n\t\n\nThis dataset contains 100 samples from the Tulu 3 SFT Mixture.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nEach example in the dataset contains the standard instruction-tuning data points as follow:\n\nid (str): a unique identifier\nmessages (list): message format used for supervised fine-tuning (this contains user prompt and assistant responses)\nsource (str): the source dataset for the given sample\n\n\n\t\n\t\t\n\t\tLicense\n\t\n\nThis dataset is licensed under ODC-BY-1.0. It is intended for research andâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/anayak/tulu3-100samples.","url":"https://huggingface.co/datasets/anayak/tulu3-100samples","creator_name":"Akash Nayak","creator_url":"https://huggingface.co/anayak","license_name":"Open Data Commons Attribution License v1.0","license_url":"https://scancode-licensedb.aboutcode.org/odc-by-1.0.html","language":null,"first_N":5,"first_N_keywords":["other","crowdsourced","expert-generated","machine-generated","multilingual"],"keywords_longer_than_N":true},
	{"name":"tulu3-100samples","keyword":"ta'izzi-adeni arabic","description":"\n\t\n\t\t\n\t\tDataset\n\t\n\nThis dataset contains 100 samples from the Tulu 3 SFT Mixture.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nEach example in the dataset contains the standard instruction-tuning data points as follow:\n\nid (str): a unique identifier\nmessages (list): message format used for supervised fine-tuning (this contains user prompt and assistant responses)\nsource (str): the source dataset for the given sample\n\n\n\t\n\t\t\n\t\tLicense\n\t\n\nThis dataset is licensed under ODC-BY-1.0. It is intended for research andâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/anayak/tulu3-100samples.","url":"https://huggingface.co/datasets/anayak/tulu3-100samples","creator_name":"Akash Nayak","creator_url":"https://huggingface.co/anayak","license_name":"Open Data Commons Attribution License v1.0","license_url":"https://scancode-licensedb.aboutcode.org/odc-by-1.0.html","language":null,"first_N":5,"first_N_keywords":["other","crowdsourced","expert-generated","machine-generated","multilingual"],"keywords_longer_than_N":true},
	{"name":"ASAS","keyword":"arabic","description":"\n\t\n\t\t\n\t\tASAS (Ø£Ø³Ø§Ø³) Corpus â€” Arabic Summaries with Annotated Support\n\t\n\nASAS â€” Arabic Summaries with Annotated Support (Arabic: Ø£Ø³Ø§Ø³ â€œfoundationâ€) is a multiâ€‘register Arabic summarization corpus designed to emphasize longer source texts and longer, higherâ€‘quality summaries. Each summary sentence is paired with human validation and supporting evidence extracted verbatim from the source.\n\n\n\t\n\t\t\n\t\n\t\n\t\tWhatâ€™s inside\n\t\n\n\n\t\n\t\t\n\t\n\t\n\t\tFiles\n\t\n\n\n`` â€” Deepâ€‘analysis file. One JSON object per article withâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/HebArabNlpProject/ASAS.","url":"https://huggingface.co/datasets/HebArabNlpProject/ASAS","creator_name":"Israel National  NLP Program","creator_url":"https://huggingface.co/HebArabNlpProject","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["summarization","Arabic","apache-2.0","ðŸ‡ºðŸ‡¸ Region: US","arabic"],"keywords_longer_than_N":false},
	{"name":"ASAS","keyword":"arabic","description":"\n\t\n\t\t\n\t\tASAS (Ø£Ø³Ø§Ø³) Corpus â€” Arabic Summaries with Annotated Support\n\t\n\nASAS â€” Arabic Summaries with Annotated Support (Arabic: Ø£Ø³Ø§Ø³ â€œfoundationâ€) is a multiâ€‘register Arabic summarization corpus designed to emphasize longer source texts and longer, higherâ€‘quality summaries. Each summary sentence is paired with human validation and supporting evidence extracted verbatim from the source.\n\n\n\t\n\t\t\n\t\n\t\n\t\tWhatâ€™s inside\n\t\n\n\n\t\n\t\t\n\t\n\t\n\t\tFiles\n\t\n\n\n`` â€” Deepâ€‘analysis file. One JSON object per article withâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/HebArabNlpProject/ASAS.","url":"https://huggingface.co/datasets/HebArabNlpProject/ASAS","creator_name":"Israel National  NLP Program","creator_url":"https://huggingface.co/HebArabNlpProject","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["summarization","Arabic","apache-2.0","ðŸ‡ºðŸ‡¸ Region: US","arabic"],"keywords_longer_than_N":false},
	{"name":"Arab3M-Triplets","keyword":"arabic","description":"\n\t\n\t\t\n\t\tArab3M-Triplets\n\t\n\nThis dataset is designed for training and evaluating models using contrastive learning techniques, particularly in the context of natural language understanding. The dataset consists of triplets: an anchor sentence, a positive sentence, and a negative sentence. The goal is to encourage models to learn meaningful representations by distinguishing between semantically similar and dissimilar sentences.\n\n\t\n\t\t\n\t\tDataset Overview\n\t\n\n\nFormat: Parquet\nNumber of rows: 3.03â€¦ See the full description on the dataset page: https://huggingface.co/datasets/Omartificial-Intelligence-Space/Arab3M-Triplets.","url":"https://huggingface.co/datasets/Omartificial-Intelligence-Space/Arab3M-Triplets","creator_name":"Omartificial Intelligence Space","creator_url":"https://huggingface.co/Omartificial-Intelligence-Space","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["sentence-similarity","Arabic","apache-2.0","1M - 10M","csv"],"keywords_longer_than_N":true},
	{"name":"Arab3M-Triplets","keyword":"arabic","description":"\n\t\n\t\t\n\t\tArab3M-Triplets\n\t\n\nThis dataset is designed for training and evaluating models using contrastive learning techniques, particularly in the context of natural language understanding. The dataset consists of triplets: an anchor sentence, a positive sentence, and a negative sentence. The goal is to encourage models to learn meaningful representations by distinguishing between semantically similar and dissimilar sentences.\n\n\t\n\t\t\n\t\tDataset Overview\n\t\n\n\nFormat: Parquet\nNumber of rows: 3.03â€¦ See the full description on the dataset page: https://huggingface.co/datasets/Omartificial-Intelligence-Space/Arab3M-Triplets.","url":"https://huggingface.co/datasets/Omartificial-Intelligence-Space/Arab3M-Triplets","creator_name":"Omartificial Intelligence Space","creator_url":"https://huggingface.co/Omartificial-Intelligence-Space","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["sentence-similarity","Arabic","apache-2.0","1M - 10M","csv"],"keywords_longer_than_N":true},
	{"name":"moosa2022multilingual-cross-lingual-archived","keyword":"arabic","description":"\n\t\n\t\t\n\t\tDataset Card for Multilingual Hate Speech Dataset\n\t\n\n\n\nThis dataset card provides information about the Multilingual Hate Speech Dataset, which was originally hosted on Kaggle. \nThe Multilingual Hate Speech Dataset is a modified version of an original multilingual hate speech dataset. In this version, examples from each language have been translated into the other languages present in the dataset, creating a more comprehensive cross-lingual resource.\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Detailsâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/ysenarath/moosa2022multilingual-cross-lingual-archived.","url":"https://huggingface.co/datasets/ysenarath/moosa2022multilingual-cross-lingual-archived","creator_name":"Yasas","creator_url":"https://huggingface.co/ysenarath","license_name":"Open Data Commons Attribution License v1.0","license_url":"https://scancode-licensedb.aboutcode.org/odc-by-1.0.html","language":"en","first_N":5,"first_N_keywords":["text-classification","Arabic","English","Chinese","French"],"keywords_longer_than_N":true},
	{"name":"kaleidoscope","keyword":"arabic","description":"\n\t\n\t\t\n\t\tKaleidoscope  (18 Languages)\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe Kaleidoscope Benchmark is a \nglobal collection of multiple-choice questions sourced from real-world exams, \nwith the goal of evaluating multimodal and multilingual understanding in VLMs. \nThe collected exams are in a Multiple-choice question answering (MCQA) \nformat which provides a structured framework for evaluation by prompting \nmodels with predefined answer choices, closely mimicking conventional human testingâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/CohereLabs/kaleidoscope.","url":"https://huggingface.co/datasets/CohereLabs/kaleidoscope","creator_name":"Cohere Labs","creator_url":"https://huggingface.co/CohereLabs","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["Arabic","Bengali","Croatian","Dutch","English"],"keywords_longer_than_N":true},
	{"name":"Intermediate-Thinking-130k","keyword":"arabic","description":"\n\t\n\t\t\n\t\tIntermediate-Thinking-130k\n\t\n\nA comprehensive dataset of 135,000 high-quality samples designed to advance language model reasoning capabilities through structured intermediate thinking processes. This dataset enables training and evaluation of models with sophisticated self-correction and iterative reasoning abilities across 42 languages.\nOG Link\n\n\t\n\t\t\n\t\n\t\n\t\tOverview\n\t\n\nIntermediate-Thinking-130k addresses a fundamental limitation in current language models: their inability to pauseâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/mlx-community/Intermediate-Thinking-130k.","url":"https://huggingface.co/datasets/mlx-community/Intermediate-Thinking-130k","creator_name":"MLX Community","creator_url":"https://huggingface.co/mlx-community","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","Afrikaans","Arabic","Bengali","Bulgarian"],"keywords_longer_than_N":true},
	{"name":"Parallel_Dataset","keyword":"arabic","description":"\n\t\n\t\t\n\t\tDataset Sources\n\t\n\n\nPaper: LegoMT2: Selective Asynchronous Sharded Data Parallel Training for Massive Neural Machine Translation\nLink: https://aclanthology.org/2025.findings-acl.1200.pdf\nRepository: https://github.com/CONE-MT/CONE\n\n","url":"https://huggingface.co/datasets/Lego-MT/Parallel_Dataset","creator_name":"Lego-MT","creator_url":"https://huggingface.co/Lego-MT","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["translation","English","Chinese","Spanish","French"],"keywords_longer_than_N":true},
	{"name":"high-quality-multilingual-sentences","keyword":"arabic","description":"\n\t\n\t\t\n\t\tHigh Quality Multilingual Sentences\n\t\n\n\nThis dataset contains multilingual sentences derived from the agentlans/LinguaNova dataset.\nIt includes 1.58 million rows across 51 different languages, each in its own configuration.\n\nExample row (from the all config):\n{\n    \"text\": \"Ø§Ù…Ø§Ù… Ø¬Ù…Ø¹Ù‡ Ø§ØµÙÙ‡Ø§Ù† Ú¯ÙØª: Ù…ÛŒØ²Ø§Ù† Ù†ÛŒØ§Ø² Ø¢Ø¨ Ø´Ø±Ø¨ Ø§ØµÙÙ‡Ø§Ù† Û±Û±.Ûµ Ù…ØªØ± Ù…Ú©Ø¹Ø¨ Ø§Ø³Øª Ú©Ù‡ ØªÙ…Ø§Ù… Ø§Ø³ØªØ§Ù† Ø§ØµÙÙ‡Ø§Ù† Ø±Ø§ Ù¾ÙˆØ´Ø´ Ù…ÛŒØ¯Ù‡Ø¯ Ùˆ Ù†Ø³Ø¨Øª Ø¨Ù‡ Ù‚Ø¨Ù„ Ø§Ø² Ø§Ù†Ù‚Ù„Ø§Ø¨ ÛŒÚ©ÛŒ Ø§Ø² Ù¾ÛŒØ´Ø±ÙØªÙ‡Ø§ Ø¯Ø± Ø­ÙˆØ²Ù‡ Ø¢Ø¨ Ø¨ÙˆØ¯Ù‡ Ø§Ø³Øª.\",\n    \"fasttext\": \"fa\",\n    \"gcld3\": \"fa\"\n}\n\nFields:â€¦ See the full description on the dataset page: https://huggingface.co/datasets/agentlans/high-quality-multilingual-sentences.","url":"https://huggingface.co/datasets/agentlans/high-quality-multilingual-sentences","creator_name":"Alan Tseng","creator_url":"https://huggingface.co/agentlans","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","text-classification","text-retrieval","multilingual","Arabic"],"keywords_longer_than_N":true},
	{"name":"MSTS","keyword":"arabic","description":"\n\t\n\t\t\n\t\tDisclaimer\n\t\n\nThe MSTS dataset contains content that may be offensive or upsetting in nature. Topics include, but are not limited to, discriminatory language and discussions of abuse, violence, self-harm, exploitation, and other potentially upsetting subject matter. \nPlease only engage with the data in accordance with your own personal risk tolerance. The data are intended for research purposes, especially research that can make models less harmful.\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Card for theâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/felfri/MSTS.","url":"https://huggingface.co/datasets/felfri/MSTS","creator_name":"Felix Friedrich","creator_url":"https://huggingface.co/felfri","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["image-text-to-text","English","Arabic","French","German"],"keywords_longer_than_N":true},
	{"name":"Arabic-gsm8k-v2","keyword":"arabic","description":"\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nArabic GSM8K is an Arabic translation of the GSM8K (Grade School Math 8K) dataset, which contains high-quality linguistically diverse grade school math word problems. The original dataset was created to support the task of question answering on basic mathematical problems that require multi-step reasoning, and this Arabic version aims to extend these capabilities to Arabic language models and applications.\nThe dataset maintains the same characteristics as theâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Omartificial-Intelligence-Space/Arabic-gsm8k-v2.","url":"https://huggingface.co/datasets/Omartificial-Intelligence-Space/Arabic-gsm8k-v2","creator_name":"Omartificial Intelligence Space","creator_url":"https://huggingface.co/Omartificial-Intelligence-Space","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["question-answering","Arabic","apache-2.0","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"ARQGData","keyword":"arabic","description":"\n\t\n\t\t\n\t\tARQGData Corpus\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis repository contains the complete ARQGData Corpus, a curated dataset designed for Arabic Automatic Question Generation (AQG). \nIt is intended for use in training, testing, and evaluation of deep learning models. The dataset provides high-quality, \ndiverse examples to facilitate research and development in Arabic natural language processing and educational technology applications.\n\nLanguage: Arabic\nDataset Type: CSV\nSize: 71315â€¦ See the full description on the dataset page: https://huggingface.co/datasets/saidlafkiar82/ARQGData.","url":"https://huggingface.co/datasets/saidlafkiar82/ARQGData","creator_name":"said lafkiar","creator_url":"https://huggingface.co/saidlafkiar82","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["Arabic","cc-by-4.0","1K - 10K","csv","Text"],"keywords_longer_than_N":true},
	{"name":"mu-shroom","keyword":"arabic","description":"\n\t\n\t\t\n\t\tThe Mu-SHROOM dataset for Multilingual Hallucination and Overgeneration detection.\n\t\n\nMu-SHROOM: Multilingual Shared-task on Hallucinations and Related Observable Overgeneration Mistakes and Related Observable Overgeneration Mistakes\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nMu-SHROOM is a multilingual dataset for detecting hallucination spans in LLM outputs across 14 languages. It was created for SemEval-2025 Task 3.\ndisclaimer: Mu-SHROOM is not properly a fact-checking dataset, but we mark isâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Helsinki-NLP/mu-shroom.","url":"https://huggingface.co/datasets/Helsinki-NLP/mu-shroom","creator_name":"Language Technology Research Group at the University of Helsinki","creator_url":"https://huggingface.co/Helsinki-NLP","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["token-classification","fact-checking","Arabic","Catalan","Czech"],"keywords_longer_than_N":true},
	{"name":"fineweb2_Tunisian_Arabic","keyword":"arabic","description":"This is the Tunisian Arabic Portion of The FineWeb2 Dataset.\nThis dataset contains a rich collection of text in Tunisian Arabic (ISO 639-3: aeb), a widely spoken dialect within the Afro-Asiatic language family. \nIt serves as a valuable resource for NLP development and linguistic research focused on Tunisian Arabic.\n\n\t\n\t\t\n\t\tPurpose of This Repository\n\t\n\nThis repository provides easy access to the Arabic portion - Tunisian of the extensive FineWeb2 dataset. My primary goal is to make thisâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/linagora/fineweb2_Tunisian_Arabic.","url":"https://huggingface.co/datasets/linagora/fineweb2_Tunisian_Arabic","creator_name":"LINAGORA Labs","creator_url":"https://huggingface.co/linagora","license_name":"Open Data Commons Attribution License v1.0","license_url":"https://scancode-licensedb.aboutcode.org/odc-by-1.0.html","language":"en","first_N":5,"first_N_keywords":["Tunisian Arabic","odc-by","100K - 1M","parquet","Tabular"],"keywords_longer_than_N":true},
	{"name":"fineweb2_Tunisian_Arabic","keyword":"tunisian arabic","description":"This is the Tunisian Arabic Portion of The FineWeb2 Dataset.\nThis dataset contains a rich collection of text in Tunisian Arabic (ISO 639-3: aeb), a widely spoken dialect within the Afro-Asiatic language family. \nIt serves as a valuable resource for NLP development and linguistic research focused on Tunisian Arabic.\n\n\t\n\t\t\n\t\tPurpose of This Repository\n\t\n\nThis repository provides easy access to the Arabic portion - Tunisian of the extensive FineWeb2 dataset. My primary goal is to make thisâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/linagora/fineweb2_Tunisian_Arabic.","url":"https://huggingface.co/datasets/linagora/fineweb2_Tunisian_Arabic","creator_name":"LINAGORA Labs","creator_url":"https://huggingface.co/linagora","license_name":"Open Data Commons Attribution License v1.0","license_url":"https://scancode-licensedb.aboutcode.org/odc-by-1.0.html","language":"en","first_N":5,"first_N_keywords":["Tunisian Arabic","odc-by","100K - 1M","parquet","Tabular"],"keywords_longer_than_N":true},
	{"name":"bahadoransports","keyword":"arabic","description":"\n\t\n\t\t\n\t\tMENA & CIS Business Index Dataset\n\t\n\n\n\t\n\t\t\n\t\tðŸŒ Overview\n\t\n\nThis dataset contains structured, multilingual data about real-world businesses in the MENA (Middle East and North Africa) and CIS (Commonwealth of Independent States) regions, optimized for indexing in AI and LLM models. It aims to enhance business recognition in AI-based search, chatbots, and voice assistants.\n\n\t\n\t\t\n\t\tðŸ“¦ Data Structure\n\t\n\nEach record includes:\n\nBusiness name (in English, Arabic, and Persian)\nLocation andâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Zahrasaghafi/bahadoransports.","url":"https://huggingface.co/datasets/Zahrasaghafi/bahadoransports","creator_name":"Zahra Saghafi","creator_url":"https://huggingface.co/Zahrasaghafi","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["Arabic","English","Persian","cc-by-4.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"MMMLU","keyword":"arabic","description":"\n\t\n\t\t\n\t\tMultilingual Massive Multitask Language Understanding (MMMLU)\n\t\n\nThe MMLU is a widely recognized benchmark of general knowledge attained by AI models. It covers a broad range of topics from 57 different categories, covering elementary-level knowledge up to advanced professional subjects like law, physics, history, and computer science.\nWe translated the MMLUâ€™s test set into 14 languages using professional human translators. Relying on human translators for this evaluation increasesâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/bzantium/MMMLU.","url":"https://huggingface.co/datasets/bzantium/MMMLU","creator_name":"Minho Ryu","creator_url":"https://huggingface.co/bzantium","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["question-answering","Arabic","Bengali","German","Spanish"],"keywords_longer_than_N":true},
	{"name":"Phone-FA-EN-AR-Dataset","keyword":"arabic","description":"\n\t\n\t\t\n\t\tØ¨Ø³Ù… Ø§Ù„Ù„Ù‡\n\t\n\n Ø§ÛŒÙ† Ù…Ø®Ø²Ù† Ø´Ø§Ù…Ù„ Ø¯Ùˆ Ø¯Ø§Ø¯Ú¯Ø§Ù† ÙØ§Ø±Ø³ÛŒ-Ø§Ù†Ú¯Ù„ÛŒØ³ÛŒ-Ø¹Ø±Ø¨ÛŒ Ùˆ Ø¹Ø±Ø¨ÛŒ-Ø§Ù†Ú¯Ù„ÛŒØ³ÛŒ Ø§Ø³Øª Ú©Ù‡ Ø¨Ù‡ Ú©Ù…Ú© ÛŒÚ© Ù…ÙˆØªÙˆØ± Ø§ÛŒ-Ø§Ø³Ù¾ÛŒÚ© ØªØºÛŒÛŒØ± ÛŒØ§ÙØªÙ‡ Ø¬Ù…Ø¹ Ø¢ÙˆØ±ÛŒ Ø´Ø¯Ù‡ Ø§Ø³Øª.\n (Ø´Ù…Ø§ Ù…ÛŒ ØªÙˆØ§Ù†ÛŒØ¯ Ø§ÛŒÙ† Ø¨Ø±Ù†Ø§Ù…Ù‡ Ø±Ø§ Ø¯Ø± Ø§ÛŒÙ†Ø¬Ø§  Ùˆ Ø§ÛŒÙ†Ø¬Ø§ Ù¾ÛŒØ¯Ø§ Ú©Ù†ÛŒØ¯)\nÙ‡Ù… Ú†Ù†ÛŒÙ† ÛŒÚ© Ø±Ø§Ø¨Ø· Ú©Ø§Ø±Ø¨Ø±ÛŒ Ø¨Ø±Ø§ÛŒ Ø¬Ù…Ø¹ Ø¢ÙˆØ±ÛŒ Ø¯Ø§Ø¯Ú¯Ø§Ù† ØµÙˆØªÛŒ Ø¯Ø± Ø§ÛŒÙ†Ø¬Ø§ Ù‚Ø±Ø§Ø± Ø¯Ø§Ø¯Ù‡ Ø´Ø¯Ù‡ Ø§Ø³Øª. \n\n\t\n\t\t\n\t\n\t\n\t\tØ¯Ø§Ø¯Ú¯Ø§Ù† Ø§ÙˆÙ„ (ÙØ§Ø±Ø³ÛŒ-Ø§Ù†Ú¯Ù„ÛŒØ³ÛŒ-Ø¹Ø±Ø¨ÛŒ)\n\t\n\n  Ø¯Ø§Ø¯Ú¯Ø§Ù† Ø§ÙˆÙ„ (Ø¯Ø§Ø¯Ú¯Ø§Ù† ÙØ§Ø±Ø³ÛŒ-Ø§Ù†Ú¯Ù„ÛŒØ³ÛŒ-Ø¹Ø±Ø¨ÛŒ)â€Œ Ø®ÙˆØ§Ù†Ø´ ØªØ§Ú©-Ø¨Ú© ÛŒÚ© Ú¯ÙˆØ´ÛŒ Ø§Ù†Ø¯Ø±ÙˆÛŒØ¯ÛŒ(Ú¯Ø§Ù„Ú©Ø³ÛŒ Ø§Ø³Û±Û° - Ø§Ù†Ø¯Ø±ÙˆÛŒØ¯ Û¹) Ø§Ø³Øª. \nØ§ÛŒÙ† Ø¯ÛŒØªØ§ Ø³Øª Ø´Ø§Ù…Ù„ Ù…ÙˆØ§Ø±Ø¯ Ø²ÛŒØ± Ø§Ø³Øª:\n\nØ­Ø±ÙˆÙ Ú©ÛŒØ¨Ø±Ø¯ ÙØ§Ø±Ø³ÛŒ Ùˆ Ø§Ù†Ú¯Ù„ÛŒØ³ÛŒ\n\nØªÙ…Ø§Ù…â€¦ See the full description on the dataset page: https://huggingface.co/datasets/mah92/Phone-FA-EN-AR-Dataset.","url":"https://huggingface.co/datasets/mah92/Phone-FA-EN-AR-Dataset","creator_name":"ali.mahmoudi","creator_url":"https://huggingface.co/mah92","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["Persian","English","Arabic","cc0-1.0","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"WanJuanSiLu-sft","keyword":"arabic","description":"\n\t\n\t\t\n\t\tWanJuanSiLu sft subset\n\t\n\nThis dataset is built from opendatalab/WanJuanSiLu-Multimodal-5Languages in sft subset.\n180,000 SFT data\nLanguages: Arabic, Russian, Korean, Vietnamese, and Thai\n\n\t\n\t\t\n\t\n\t\n\t\tðŸ¤–Featured instructions for fine-tuning SFT data:\n\t\n\n\nCultural adversarial samples: Contains culturally relevant question-answer pairs designed by local residents to detect cultural bias in models\nHybrid quality inspection process: Rules + model scoring to filter translation data andâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/wannaphong/WanJuanSiLu-sft.","url":"https://huggingface.co/datasets/wannaphong/WanJuanSiLu-sft","creator_name":"Wannaphong Phatthiyaphaibun","creator_url":"https://huggingface.co/wannaphong","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","Korean","Vietnamese","Thai","Russian"],"keywords_longer_than_N":true},
	{"name":"FannOrFlop","keyword":"arabic","description":"\n  \n\n\nFann Or Flop: A Multigenre, Multiera Benchmark for Arabic Poetry Understanding\n\nFann or Flop is the first comprehensive benchmark designed to evaluate large language models (LLMs) on their ability to understand Arabic poetry. It contains nearly 7,000 poem-explanation pairs covering 12 poetic eras, 21 genres, and multiple meters, providing a culturally rich and linguistically challenging testbed for Arabic NLP.\n\n\n  \n\nLatest Updates\n\n  ðŸ”¥ðŸ”¥ [20 Aug 2025] ðŸ”¥ðŸ”¥ Fann or Flop accepted to EMNLPâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/omkarthawakar/FannOrFlop.","url":"https://huggingface.co/datasets/omkarthawakar/FannOrFlop","creator_name":"Omkar Thawakar","creator_url":"https://huggingface.co/omkarthawakar","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["Arabic","apache-2.0","1K - 10K","json","Text"],"keywords_longer_than_N":true},
	{"name":"FannOrFlop","keyword":"arabic","description":"\n  \n\n\nFann Or Flop: A Multigenre, Multiera Benchmark for Arabic Poetry Understanding\n\nFann or Flop is the first comprehensive benchmark designed to evaluate large language models (LLMs) on their ability to understand Arabic poetry. It contains nearly 7,000 poem-explanation pairs covering 12 poetic eras, 21 genres, and multiple meters, providing a culturally rich and linguistically challenging testbed for Arabic NLP.\n\n\n  \n\nLatest Updates\n\n  ðŸ”¥ðŸ”¥ [20 Aug 2025] ðŸ”¥ðŸ”¥ Fann or Flop accepted to EMNLPâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/omkarthawakar/FannOrFlop.","url":"https://huggingface.co/datasets/omkarthawakar/FannOrFlop","creator_name":"Omkar Thawakar","creator_url":"https://huggingface.co/omkarthawakar","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["Arabic","apache-2.0","1K - 10K","json","Text"],"keywords_longer_than_N":true},
	{"name":"test_4","keyword":"arabic","description":"\n\t\n\t\t\n\t\n\t\n\t\tFLEURS\n\t\n\nFleurs is the speech version of the FLoRes machine translation benchmark. \nWe use 2009 n-way parallel sentences from the FLoRes dev and devtest publicly available sets, in 102 languages. \nTraining sets have around 10 hours of supervision. Speakers of the train sets are different than speakers from the dev/test sets. Multilingual fine-tuning is\nused and â€unit error rateâ€ (characters, signs) of all languages is averaged. Languages and results are also grouped into sevenâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/tunngo/test_4.","url":"https://huggingface.co/datasets/tunngo/test_4","creator_name":"nguyen tuan","creator_url":"https://huggingface.co/tunngo","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","expert-generated","crowdsourced","machine-generated","crowdsourced"],"keywords_longer_than_N":true},
	{"name":"Product_Similarity_Dataset","keyword":"arabic","description":"This following dataset is a rich dataset of product similarity. The dataset has been design to be challenging to train on by having quite a lot of hard negatives\nThis dataset is especially targeted toward fine-tuning usecase, especially to finetune reranker or embedding model.\nThe data are especially adapted for listwise loss like LambdaLoss or ListNetLoss.\nThe data are in JSONL and each line follow the same format as here below : \n\nA \"query\", the anchor product label\n\"docs\", the potentialâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Antix5/Product_Similarity_Dataset.","url":"https://huggingface.co/datasets/Antix5/Product_Similarity_Dataset","creator_name":"Antoine Demangeon","creator_url":"https://huggingface.co/Antix5","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-ranking","feature-extraction","French","German","Chinese"],"keywords_longer_than_N":true},
	{"name":"multilingual-llava-bench-in-the-wild","keyword":"arabic","description":"\n\t\n\t\t\n\t\tMultilingual LLaVA Bench in the Wild\n\t\n\n\n\t\n\t\t\n\t\tNote that this is a copy from https://huggingface.co/datasets/MBZUAI/multilingual-llava-bench-in-the-wild\n\t\n\nIt was created due to issues in the original repo. It also includes the image features and has a uniform and joined structure.\nIf you use this dataset, please cite the original authors:\n@article{PALO2024,\n  title={Palo: A Large Multilingual Multimodal Language Model},\n  author={Maaz, Muhammad and Rasheed, Hanoona and Shakerâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/floschne/multilingual-llava-bench-in-the-wild.","url":"https://huggingface.co/datasets/floschne/multilingual-llava-bench-in-the-wild","creator_name":"Flo Schneider","creator_url":"https://huggingface.co/floschne","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["Arabic","Bengali","Chinese","English","French"],"keywords_longer_than_N":true},
	{"name":"GlobalNLI","keyword":"arabic","description":"\n\t\n\t\t\n\t\tDataset Card for global_nli\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nGlobal NLI is a new text-based benchmark based on the aggregation of existing NLI datasets that are publicly available.\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nThere are 59 languages available :\n{\n    'amh': 'Amharic',\n    'ara': 'Arabic',\n    'asm': 'Assamese',\n    'aym': 'Aymara',\n    'ben': 'Bengali',\n    'bul': 'Bulgarian',\n    'bzd': 'Bribri',\n    'cat': 'Catalan',\n    'cni': 'AshÃ¡ninka',\n    'deu': 'German',\n    'ell': 'Greek',\n    'eng':â€¦ See the full description on the dataset page: https://huggingface.co/datasets/McGill-NLP/GlobalNLI.","url":"https://huggingface.co/datasets/McGill-NLP/GlobalNLI","creator_name":"McGill NLP Group","creator_url":"https://huggingface.co/McGill-NLP","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","natural-language-inference","multilingual","XNLI, AfriXNLI, IndicXNLI, AmericasNLI [30], XNLI-ca, myXNLI, IndoNLI, JNLI , InferBR, sick_pl, JamPatoisNLI, KLUE, RoNLI.","Amharic"],"keywords_longer_than_N":true},
	{"name":"translation2","keyword":"arabic","description":"\n\t\n\t\t\n\t\tDataset Card for Dataset Name\n\t\n\n\n\nThis dataset card aims to be a base template for new datasets. It has been generated using this raw template.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\n\n\n\n\n\nCurated by: [More Information Needed]\nFunded by [optional]: [More Information Needed]\nShared by [optional]: [More Information Needed]\nLanguage(s) (NLP): [More Information Needed]\nLicense: [More Information Needed]\n\n\n\t\n\t\t\n\t\tDataset Sources [optional]\n\t\n\n\n\n\nRepository: [Moreâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/MawaredHR/translation2.","url":"https://huggingface.co/datasets/MawaredHR/translation2","creator_name":"MawaredHR AI","creator_url":"https://huggingface.co/MawaredHR","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["translation","English","Arabic","apache-2.0","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"SARD","keyword":"arabic","description":"\n\t\n\t\t\n\t\tSARD: Synthetic Arabic Recognition Dataset\n\t\n\n\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nSARD (Synthetic Arabic Recognition Dataset) is a large-scale, synthetically generated dataset designed for training and evaluating Optical Character Recognition (OCR) models for Arabic text. This dataset addresses the critical need for comprehensive Arabic text recognition resources by providing controlled, diverse, and scalable training data that simulates real-world book layouts.\n\n\t\n\t\t\n\t\tKey Features\n\t\n\n\nMassiveâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/riotu-lab/SARD.","url":"https://huggingface.co/datasets/riotu-lab/SARD","creator_name":"Robotics and Interne-of-Things","creator_url":"https://huggingface.co/riotu-lab","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["image-to-text","Arabic","apache-2.0","100K<n<1M","ðŸ‡ºðŸ‡¸ Region: US"],"keywords_longer_than_N":true},
	{"name":"SARD","keyword":"arabic","description":"\n\t\n\t\t\n\t\tSARD: Synthetic Arabic Recognition Dataset\n\t\n\n\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nSARD (Synthetic Arabic Recognition Dataset) is a large-scale, synthetically generated dataset designed for training and evaluating Optical Character Recognition (OCR) models for Arabic text. This dataset addresses the critical need for comprehensive Arabic text recognition resources by providing controlled, diverse, and scalable training data that simulates real-world book layouts.\n\n\t\n\t\t\n\t\tKey Features\n\t\n\n\nMassiveâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/riotu-lab/SARD.","url":"https://huggingface.co/datasets/riotu-lab/SARD","creator_name":"Robotics and Interne-of-Things","creator_url":"https://huggingface.co/riotu-lab","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["image-to-text","Arabic","apache-2.0","100K<n<1M","ðŸ‡ºðŸ‡¸ Region: US"],"keywords_longer_than_N":true},
	{"name":"m-WildVision","keyword":"arabic","description":"\n\t\n\t\t\n\t\tDataset Card for m-WildVision\n\t\n\n\n\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\nThe m-WildVision dataset is a multilingual multimodal LLM evaluation set covering 23 languages.  It was created by translating prompts from the original English-only WildVision (vision_bench_0617) test set. \nThe original prompts, developed by Lu et al. (2024) , consist of 500 challenging user queries sourced from the WildVision-Arena platform. \nThe authors demonstrated that these prompts enable automatic LLM judgeâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/CohereLabs/m-WildVision.","url":"https://huggingface.co/datasets/CohereLabs/m-WildVision","creator_name":"Cohere Labs","creator_url":"https://huggingface.co/CohereLabs","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["English","French","German","Spanish","Italian"],"keywords_longer_than_N":true},
	{"name":"RASAM","keyword":"arabic","description":"\n\t\n\t\t\n\t\tRASAM dataset\n\t\n\nAn Open Dataset for the Recognition and Analysis of Scripts in Arabic Maghrebi\n\n\t\n\t\t\n\t\tHow to cite\n\t\n\nThe paper has been presented during the ICDAR 2021 conference (ASAR workshop). To cite this work and this dataset, please use the following informations:\n@InProceedings{2021rasam-dataset,\nauthor=\"Vidal-GorÃ¨ne, Chahan and Lucas, NoÃ«mie and Salah, ClÃ©ment and Decours-Perez, AliÃ©nor and Dupin, Boris\",\neditor=\"Barney Smith, Elisa H. and Pal, Umapada\",\ntitle=\"RASAM -- Aâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/johnlockejrr/RASAM.","url":"https://huggingface.co/datasets/johnlockejrr/RASAM","creator_name":"John Locke","creator_url":"https://huggingface.co/johnlockejrr","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","text-generation","fill-mask","Arabic","mit"],"keywords_longer_than_N":true},
	{"name":"open-dict-words-ipa","keyword":"arabic","description":"\n\t\n\t\t\n\t\tOpen-dict Words IPA\n\t\n\nThis dataset is a copy of https://github.com/open-dict-data/ipa-dict\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nIPA data is currently available for the following languages:\n\n\t\n\t\t\nLanguage\nCode\n\n\n\t\t\nar\nArabic (Modern Standard)\n\n\nde\nGerman\n\n\nen_UK\nEnglish (Received Pronunciation)\n\n\nen_US\nEnglish (General American)\n\n\neo\nEsperanto\n\n\nes_ES\nSpanish (Spain)\n\n\nes_MX\nSpanish (Mexico)\n\n\nfa\nPersian\n\n\nfi\nFinnish\n\n\nfr_FR\nFrench (France)\n\n\nfr_QC\nFrench (QuÃ©bec)\n\n\nis\nIcelandic\n\n\nja\nJapanese\n\n\njamâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/StephanAkkerman/open-dict-words-ipa.","url":"https://huggingface.co/datasets/StephanAkkerman/open-dict-words-ipa","creator_name":"Stephan Akkerman","creator_url":"https://huggingface.co/StephanAkkerman","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["Arabic","German","English","Esperanto","Spanish"],"keywords_longer_than_N":true},
	{"name":"Phonemized-UD","keyword":"arabic","description":"\n\t\n\t\t\n\t\tPhoneme-UD: A Multilingual Phonemized Universal Dependencies Corpus for 34+ Languages\n\t\n\n\n\t\n\t\t\n\t\tG2P+ Phonemizer\n\t\n\nWe use G2P+ to phonemize Universal Dependencies. Here is an example usage: \n# Install required packages\n!apt-get install -y espeak-ng\n!pip install phonemizer g2p-plus\n# Set the environment variable from Python\nimport os\nos.environ[\"PHONEMIZER_ESPEAK_LIBRARY\"] = \"/usr/lib/x86_64-linux-gnu/libespeak-ng.so.1\"\n\n# Now run your transcription\nfrom g2p_plus importâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/suchirsalhan/Phonemized-UD.","url":"https://huggingface.co/datasets/suchirsalhan/Phonemized-UD","creator_name":"Suchir Salhan","creator_url":"https://huggingface.co/suchirsalhan","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["Afrikaans","Amharic","Arabic","Azerbaijani","Catalan"],"keywords_longer_than_N":true},
	{"name":"PM4Bench","keyword":"arabic","description":"\n\t\n\t\t\n\t\tPM4Bench: A Parallel Multilingual Multi-Modal Multi-task Benchmark for Large Vision Language Model\n\t\n\n\n\n\nðŸŒ Homepage | ðŸ¤— Dataset | ðŸ“– Paper \n\n\t\n\t\t\n\t\tðŸ“¢ News\n\t\n\n\nðŸ”¥[2025-03-25]: Dataset available on HuggingFace. Paper available on  arXiv.\n\n\n\n\t\n\t\t\n\t\tðŸ§‘â€ðŸ’» How to Run?\n\t\n\n\n\n\t\n\t\t\n\t\tðŸ  Set Up\n\t\n\n\n\t\n\t\t\n\t\tDataset Download\n\t\n\nDownload tsv files from HuggingFace and store them in data/tsv/. The directory should be like data/tsv/{DATASET}_{SETTING}_{LANGUAGE}.tsv.\n\n\t\n\t\t\n\t\tEnvironmentâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/songjhPKU/PM4Bench.","url":"https://huggingface.co/datasets/songjhPKU/PM4Bench","creator_name":"Jiahe Song","creator_url":"https://huggingface.co/songjhPKU","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["question-answering","visual-question-answering","multiple-choice","English","Chinese"],"keywords_longer_than_N":true},
	{"name":"linkedin-industry-list","keyword":"arabic","description":"fantastic-jobs/linkedin-industry-list dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/fantastic-jobs/linkedin-industry-list","creator_name":"Fantastic.jobs","creator_url":"https://huggingface.co/fantastic-jobs","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","translation","English","Korean","Spanish"],"keywords_longer_than_N":true},
	{"name":"GlobalNLI","keyword":"arabic","description":"\n\t\n\t\t\n\t\tDataset Card for global_nli\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nGlobal NLI is a new text-based benchmark based on the aggregation of existing NLI datasets that are publicly available.\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nThere are 59 languages available :\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\n\t\n\t\t\n\t\tData Instances\n\t\n\nThe examples look like this for English:\nfrom datasets import load_dataset\ndata = load_dataset('vivekvermaiit/globalnli', 'eng') \n# Please, specify the language code\n# A data point example is below:\n{â€¦ See the full description on the dataset page: https://huggingface.co/datasets/vivekvermaiit/GlobalNLI.","url":"https://huggingface.co/datasets/vivekvermaiit/GlobalNLI","creator_name":"Vivek Verma","creator_url":"https://huggingface.co/vivekvermaiit","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","natural-language-inference","multilingual","XNLI, AfriXNLI, IndicXNLI, AmericasNLI [30], XNLI-ca, myXNLI, IndoNLI, JNLI , InferBR, sick_pl, JamPatoisNLI, KLUE, RoNLI.","Amharic"],"keywords_longer_than_N":true},
	{"name":"MKQARetrieval","keyword":"arabic","description":"\n  MKQARetrieval\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nMultilingual Knowledge Questions & Answers (MKQA)contains 10,000 queries sampled from the Google Natural Questions dataset.\n        For each query we collect new passage-independent answers. These queries and answers are then human translated into 25 Non-English languages.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2t\n\n\nDomains\nWritten\n\n\nReference\nhttps://github.com/apple/ml-mkqa\n\n\n\t\n\nSource datasets:\n\napple/mkqa\n\n\n\t\n\t\t\n\t\tHow to evaluateâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/MKQARetrieval.","url":"https://huggingface.co/datasets/mteb/MKQARetrieval","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"Creative Commons Attribution 3.0","license_url":"https://scancode-licensedb.aboutcode.org/cc-by-3.0.html","language":"en","first_N":5,"first_N_keywords":["text-retrieval","multiple-choice-qa","human-annotated","multilingual","apple/mkqa"],"keywords_longer_than_N":true},
	{"name":"eg-legal-instruction-following","keyword":"arabic","description":"\n\t\n\t\t\n\t\tArabic Legal Dataset - Legal Instruction Following\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nInstruction-following dataset for diverse legal text analysis tasks through natural language commands.\nThis dataset contains 4,184 examples of instruction_following data derived from Egyptian legal texts, including criminal law, civil law, procedural law, and personal status law. The dataset is designed for training and evaluating Arabic legal AI models.\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\n\nLanguage: Arabicâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fr3on/eg-legal-instruction-following.","url":"https://huggingface.co/datasets/fr3on/eg-legal-instruction-following","creator_name":"Ahmed Mardi","creator_url":"https://huggingface.co/fr3on","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","Arabic","apache-2.0","1K - 10K","parquet"],"keywords_longer_than_N":true},
	{"name":"eg-legal-instruction-following","keyword":"arabic","description":"\n\t\n\t\t\n\t\tArabic Legal Dataset - Legal Instruction Following\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nInstruction-following dataset for diverse legal text analysis tasks through natural language commands.\nThis dataset contains 4,184 examples of instruction_following data derived from Egyptian legal texts, including criminal law, civil law, procedural law, and personal status law. The dataset is designed for training and evaluating Arabic legal AI models.\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\n\nLanguage: Arabicâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fr3on/eg-legal-instruction-following.","url":"https://huggingface.co/datasets/fr3on/eg-legal-instruction-following","creator_name":"Ahmed Mardi","creator_url":"https://huggingface.co/fr3on","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","Arabic","apache-2.0","1K - 10K","parquet"],"keywords_longer_than_N":true},
	{"name":"AyaRedTeaming","keyword":"arabic","description":"\n\t\n\t\t\n\t\tDataset Card for Aya Red-teaming\n\t\n\n\n\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\nThe Aya Red-teaming dataset is a human-annotated multilingual red-teaming dataset consisting of harmful prompts in 8 languages across 9 different categories of harm with explicit labels for \"global\" and \"local\" harm.\n\n\n\n\n\n\nCurated by: Professional compensated annotators\nLanguages: Arabic, English, Filipino, French, Hindi, Russian, Serbian and Spanish\nLicense: Apache 2.0\nPaper: arxiv link\n\n\n\t\n\t\t\n\t\n\t\n\t\tHarm Categories:â€¦ See the full description on the dataset page: https://huggingface.co/datasets/walledai/AyaRedTeaming.","url":"https://huggingface.co/datasets/walledai/AyaRedTeaming","creator_name":"Walled AI","creator_url":"https://huggingface.co/walledai","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["English","Hindi","French","Spanish","Arabic"],"keywords_longer_than_N":true},
	{"name":"MultiLongDocRetrieval","keyword":"arabic","description":"\n  MultiLongDocRetrieval\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nMulti Long Doc Retrieval (MLDR) 'is curated by the multilingual articles from Wikipedia, Wudao and mC4 (see Table 7), and NarrativeQA (KocË‡isky Ì et al., 2018; Gu Ìˆnther et al., 2023), which is only for English.' (Chen et al., 2024).\n        It is constructed by sampling lengthy articles from Wikipedia, Wudao and mC4 datasets and randomly choose paragraphs from them. Then we use GPT-3.5 to generate questions basedâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/MultiLongDocRetrieval.","url":"https://huggingface.co/datasets/mteb/MultiLongDocRetrieval","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","LM-generated","multilingual","Shitao/MLDR","Arabic"],"keywords_longer_than_N":true},
	{"name":"maghrebi_train_set","keyword":"arabic","description":"Pre-processed Maghrebi train partition from the MASC-dataset:\nMohammad Al-Fetyani, Muhammad Al-Barham, Gheith Abandah, Adham Alsharkawi, Maha Dawas, August 18, 2021, \"MASC: Massive Arabic Speech Corpus\", IEEE Dataport, doi: https://dx.doi.org/10.21227/e1qb-jv46.\n","url":"https://huggingface.co/datasets/otozz/maghrebi_train_set","creator_name":"Ã–mer","creator_url":"https://huggingface.co/otozz","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["Arabic","cc-by-4.0","10K - 100K","parquet","Datasets"],"keywords_longer_than_N":true},
	{"name":"eg-legal-rag","keyword":"arabic","description":"\n\t\n\t\t\n\t\tArabic Legal Dataset - Legal RAG Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nRetrieval-augmented generation optimized dataset with summaries, keywords, and cross-references for building legal search systems.\nThis dataset contains 1,046 examples of rag data derived from Egyptian legal texts, including criminal law, civil law, procedural law, and personal status law. The dataset is designed for training and evaluating Arabic legal AI models.\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\n\nLanguage: Arabicâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fr3on/eg-legal-rag.","url":"https://huggingface.co/datasets/fr3on/eg-legal-rag","creator_name":"Ahmed Mardi","creator_url":"https://huggingface.co/fr3on","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","text-retrieval","Arabic","apache-2.0","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"eg-legal-rag","keyword":"arabic","description":"\n\t\n\t\t\n\t\tArabic Legal Dataset - Legal RAG Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nRetrieval-augmented generation optimized dataset with summaries, keywords, and cross-references for building legal search systems.\nThis dataset contains 1,046 examples of rag data derived from Egyptian legal texts, including criminal law, civil law, procedural law, and personal status law. The dataset is designed for training and evaluating Arabic legal AI models.\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\n\nLanguage: Arabicâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fr3on/eg-legal-rag.","url":"https://huggingface.co/datasets/fr3on/eg-legal-rag","creator_name":"Ahmed Mardi","creator_url":"https://huggingface.co/fr3on","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","text-retrieval","Arabic","apache-2.0","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"PangeaBench-xm100","keyword":"arabic","description":"\n\t\n\t\t\n\t\n\t\n\t\tXM100\n\t\n\n\n\t\n\t\t\n\t\n\t\n\t\tThis is a copy from https://google.github.io/crossmodal-3600/\n\t\n\nIf you use this dataset, please cite the original authors:\n@inproceedings{ThapliyalCrossmodal2022,\n  author = {Ashish Thapliyal and Jordi Pont-Tuset and Xi Chen and Radu Soricut},\n  title = {{Crossmodal-3600: A Massively Multilingual Multimodal Evaluation Dataset}},\n  booktitle = {EMNLP},\n  year = {2022}\n}\n\n","url":"https://huggingface.co/datasets/neulab/PangeaBench-xm100","creator_name":"NeuLab @ LTI/CMU","creator_url":"https://huggingface.co/neulab","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["image-to-text","Arabic","Bengali","Czech","Danish"],"keywords_longer_than_N":true},
	{"name":"Egyptian-text-summarization","keyword":"arabic","description":"\n\t\n\t\t\n\t\tEgyptian Arabic Text Summarization Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset contains text-summary pairs in Egyptian Arabic designed for training and evaluating text summarization models.\n\n\t\n\t\t\n\t\tKey Features\n\t\n\n\nLanguage: Egyptian Arabic (Ø§Ù„Ø¹Ø§Ù…ÙŠØ© Ø§Ù„Ù…ØµØ±ÙŠØ©)\nTask: Text Summarization\nFormat: Text-summary pairs with topic categorization\nContent: Diverse topics with natural Egyptian Arabic usage\n\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\n\t\n\t\t\n\t\tData Fields\n\t\n\n\ntext: Original text contentâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Omar-youssef/Egyptian-text-summarization.","url":"https://huggingface.co/datasets/Omar-youssef/Egyptian-text-summarization","creator_name":"Omar Youssef","creator_url":"https://huggingface.co/Omar-youssef","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["summarization","text-generation","Arabic","apache-2.0","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"multi-hatecheck","keyword":"arabic","description":"\n  MultiHateClassification\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nHate speech detection dataset with binary\n                       (hateful vs non-hateful) labels. Includes 25+ distinct types of hate\n                       and challenging non-hate, and 11 languages.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask categoryt2c\n\n\nDomains\nConstructed, Written\n\n\nReference\nhttps://aclanthology.org/2022.woah-1.15/\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this datasetâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/multi-hatecheck.","url":"https://huggingface.co/datasets/mteb/multi-hatecheck","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","sentiment-analysis","sentiment-scoring","sentiment-classification","hate-speech-detection"],"keywords_longer_than_N":true},
	{"name":"arabic-iahlt-NER","keyword":"arabic","description":"\n\t\n\t\t\n\t\tIAHLT Named Entities Dataset (Arabic Subset)\n\t\n\n×”××™×’×•×“ ×”×™×©×¨××œ×™ ×œ×˜×›× ×•×œ×•×’×™×•×ª ×©×¤×ª ×× ×•×©Ø§Ù„Ø±Ø§Ø¨Ø·Ø© Ø§Ù„Ø¥Ø³Ø±Ø§Ø¦ÙŠÙ„ÙŠØ© Ù„ØªÙƒÙ†ÙˆÙ„ÙˆØ¬ÙŠØ§ Ø§Ù„Ù„ØºØ© Ø§Ù„Ø¨Ø´Ø±ÙŠØ©The Israeli Association of Human Language Technologieshttps://www.iahlt.org\nThis dataset contains named entity annotations for Arabic texts from various sources, curated as part of the IAHLT multilingual NER project. The Arabic portion is provided here as a cleaned subset intended for training and evaluation in named entity recognition tasks.\n\n\t\n\t\t\n\t\n\t\n\t\tFilesâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/HebArabNlpProject/arabic-iahlt-NER.","url":"https://huggingface.co/datasets/HebArabNlpProject/arabic-iahlt-NER","creator_name":"Israel National  NLP Program","creator_url":"https://huggingface.co/HebArabNlpProject","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["Arabic","cc-by-4.0","ðŸ‡ºðŸ‡¸ Region: US","named-entity-recognition","arabic"],"keywords_longer_than_N":true},
	{"name":"arabic-iahlt-NER","keyword":"arabic","description":"\n\t\n\t\t\n\t\tIAHLT Named Entities Dataset (Arabic Subset)\n\t\n\n×”××™×’×•×“ ×”×™×©×¨××œ×™ ×œ×˜×›× ×•×œ×•×’×™×•×ª ×©×¤×ª ×× ×•×©Ø§Ù„Ø±Ø§Ø¨Ø·Ø© Ø§Ù„Ø¥Ø³Ø±Ø§Ø¦ÙŠÙ„ÙŠØ© Ù„ØªÙƒÙ†ÙˆÙ„ÙˆØ¬ÙŠØ§ Ø§Ù„Ù„ØºØ© Ø§Ù„Ø¨Ø´Ø±ÙŠØ©The Israeli Association of Human Language Technologieshttps://www.iahlt.org\nThis dataset contains named entity annotations for Arabic texts from various sources, curated as part of the IAHLT multilingual NER project. The Arabic portion is provided here as a cleaned subset intended for training and evaluation in named entity recognition tasks.\n\n\t\n\t\t\n\t\n\t\n\t\tFilesâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/HebArabNlpProject/arabic-iahlt-NER.","url":"https://huggingface.co/datasets/HebArabNlpProject/arabic-iahlt-NER","creator_name":"Israel National  NLP Program","creator_url":"https://huggingface.co/HebArabNlpProject","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["Arabic","cc-by-4.0","ðŸ‡ºðŸ‡¸ Region: US","named-entity-recognition","arabic"],"keywords_longer_than_N":true},
	{"name":"EgyLaw-Squad","keyword":"arabic","description":"\n\t\n\t\t\n\t\tEgyption Law Squad\n\t\n\nthis dataset was made for Question Answering task about Egyption Law specially Personal Status Law (Ù‚Ø§Ù†ÙˆÙ† Ø§Ù„Ø§Ø­ÙˆØ§Ù„ Ø§Ù„Ø´Ø®ØµÙŠØ© )\n\n\t\n\t\t\n\t\tAbout the Dataset\n\t\n\ndataset was created for a Graduation Project in Computers and Artificial intellgence at Helwan University under supervisation from Dr.Ensaf Hossen\n\n\t\n\t\t\n\t\tAbout Team\n\t\n\n\nAbdelrahman Ahmed Hamdy\nShehab Gamal-elden\nMohsen Hisham Mohamed\nMaya Ahmed Abdelsatar\nNancy Ahmed Mostafa\nNour Khaled Ali\n\n","url":"https://huggingface.co/datasets/BoodyAhmedHamdy/EgyLaw-Squad","creator_name":"Abdelrahman Ahmed Hamdy","creator_url":"https://huggingface.co/BoodyAhmedHamdy","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["question-answering","Arabic","mit","< 1K","parquet"],"keywords_longer_than_N":true},
	{"name":"XMedbench","keyword":"arabic","description":"\n\t\n\t\t\n\t\tMultilingual Medicine: Model, Dataset, Benchmark, Code\n\t\n\nCovering English, Chinese, French, Hindi, Spanish, Hindi, Arabic So far\n\n   ðŸ‘¨ðŸ»â€ðŸ’»Github â€¢ðŸ“ƒ Paper â€¢ ðŸ¤— ApolloCorpus â€¢ ðŸ¤— XMedBench \n      ä¸­æ–‡  |  English\n\n\n\n\n\n\t\t\n\t\tðŸŒˆ Update\n\t\n\n\n[2024.03.07] Paper released.\n[2024.02.12] ApolloCorpus and  XMedBench  is publishedï¼ðŸŽ‰\n[2024.01.23] Apollo repo is publishedï¼ðŸŽ‰\n\n\n\t\n\t\t\n\t\tResults\n\t\n\n   \n\n\t\n\t\t\n\t\tUsage\n\t\n\n\nZip File\nData category\n\n\n\t\n\t\t\n\t\tData:\n\t\n\n\nEN:\n\nMedQA-USMLE \nMedMCQA\nPubMedQA:â€¦ See the full description on the dataset page: https://huggingface.co/datasets/FreedomIntelligence/XMedbench.","url":"https://huggingface.co/datasets/FreedomIntelligence/XMedbench","creator_name":"FreedomAI","creator_url":"https://huggingface.co/FreedomIntelligence","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["French","English","Spanish","Chinese","Arabic"],"keywords_longer_than_N":true},
	{"name":"Tunisian-Proverbs-with-Image-Associations-A-Cultural-and-Linguistic-Dataset","keyword":"arabic","description":"Tunisian Proverbs with Image Associations: A Cultural and Linguistic Dataset \n\n\n\t\n\t\t\n\t\tDescription\n\t\n\nThis dataset explores the rich oral tradition of Tunisian proverbs mapped into text format, pairing each with contextual explanations, English translations both word-to-word and it's equivalent Target Language dynamic, Automated prompt and AI-generated visual interpretations.\nIt bridges linguistic, cultural, and visual modalities making it valuable for tasks in cross-cultural NLP, generativeâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/HabibaAbderrahim/Tunisian-Proverbs-with-Image-Associations-A-Cultural-and-Linguistic-Dataset.","url":"https://huggingface.co/datasets/HabibaAbderrahim/Tunisian-Proverbs-with-Image-Associations-A-Cultural-and-Linguistic-Dataset","creator_name":"Habiba Abderrahim","creator_url":"https://huggingface.co/HabibaAbderrahim","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["translation","text-generation","Arabic","English","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"Aya-Command.R-DPO","keyword":"arabic","description":"\n\t\n\t\t\n\t\tðŸ¤— Dataset Card for \"Aya-Command.R-DPO\"\n\t\n\n\n\t\n\t\t\n\t\tDataset Sources & Infos\n\t\n\n\nData Origin: Derived from the Arabic Aya (2A) dataset : 2A2I/Arabic_Aya which is a Curated Subset of the Aya Collection CohereForAI/aya_dataset\nLanguages: Modern Standard Arabic (MSA)\nLicense: Apache-2.0\nMaintainers: Ali Elfilali and Mohammed Machrouh\n\n\n\t\n\t\t\n\t\n\t\n\t\tPurpose\n\t\n\nAya-Command.R-DPO is a DPO dataset designed to advance Arabic NLP by comparing human-generated responses, labeled as \"chosen,\" withâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/2A2I/Aya-Command.R-DPO.","url":"https://huggingface.co/datasets/2A2I/Aya-Command.R-DPO","creator_name":"2A2I","creator_url":"https://huggingface.co/2A2I","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["Arabic","apache-2.0","10K - 100K","parquet","Text"],"keywords_longer_than_N":true},
	{"name":"parallel_corpus_game","keyword":"arabic","description":"https://github.com/mnbvc-parallel-corpus-team/parallel_corpus_mnbvc\nGame Corpus Collected by MNBVC Parallel Corpus Team.\n\n\t\n\t\t\n\t\t09/17/2025 Updated\n\t\n\n\nHollow Knight\n\n\n\t\n\t\t\n\t\t09/15/2025 Updated\n\t\n\n\nLimbus Company\nMirror\n\n\n\t\n\t\t\n\t\t09/08/2025 Updated\n\t\n\n\nSpice and Wolf VR (1&2)\nDeep Rock Galactic\nCities Skylines 1\n\n\n\t\n\t\t\n\t\t09/02/2025 Updated\n\t\n\n\nPlague Inc\n\n\n\t\n\t\t\n\t\t09/01/2025 Updated\n\t\n\n\nBanGDream from https://bestdori.com/\n\n\n\t\n\t\t\n\t\t08/15/2025 Updated\n\t\n\n\nATRI fromâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/bot-yaya/parallel_corpus_game.","url":"https://huggingface.co/datasets/bot-yaya/parallel_corpus_game","creator_name":"yaya","creator_url":"https://huggingface.co/bot-yaya","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["translation","Arabic","Chinese","German","English"],"keywords_longer_than_N":true},
	{"name":"acl-6060","keyword":"arabic","description":"\n\t\n\t\t\n\t\tACL 60/60\n\t\n\n\n\t\n\t\t\n\t\tDataset details\n\t\n\nACL 60/60 evaluation sets for multilingual translation of ACL 2022 technical presentations into 10 target languages.\n\n\t\n\t\t\n\t\tCitation\n\t\n\n@inproceedings{salesky-etal-2023-evaluating,\n    title = \"Evaluating Multilingual Speech Translation under Realistic Conditions with Resegmentation and Terminology\",\n    author = \"Salesky, Elizabeth  and\n      Darwish, Kareem  and\n      Al-Badrashiny, Mohamed  and\n      Diab, Mona  and\n      Niehues, Jan\"â€¦ See the full description on the dataset page: https://huggingface.co/datasets/ymoslem/acl-6060.","url":"https://huggingface.co/datasets/ymoslem/acl-6060","creator_name":"Yasmin Moslem","creator_url":"https://huggingface.co/ymoslem","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["translation","automatic-speech-recognition","English","Arabic","German"],"keywords_longer_than_N":true},
	{"name":"Global-MMLU","keyword":"arabic","description":"\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nGlobal-MMLU ðŸŒ is a multilingual evaluation set spanning 42 languages, including English. This dataset combines machine translations for MMLU questions along with professional translations and crowd-sourced post-edits.\nIt also includes cultural sensitivity annotations for a subset of the questions (2850 questions per language) and classifies them as Culturally Sensitive (CS) ðŸ—½ or Culturally Agnostic (CA) âš–ï¸. These annotations were collected as part of an openâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/CohereLabs/Global-MMLU.","url":"https://huggingface.co/datasets/CohereLabs/Global-MMLU","creator_name":"Cohere Labs","creator_url":"https://huggingface.co/CohereLabs","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["English","Arabic","Bengali","Spanish","French"],"keywords_longer_than_N":true},
	{"name":"ArzEn-CodeMixed","keyword":"arabic","description":"\n\t\n\t\t\n\t\tArzEn-CodeMixed: English-Arabic Intra-Sentential Code-Mixed Translation Dataset\n\t\n\nThis dataset contains aligned English, Arabic, and English-Arabic as well as Arabic-English intra-sentential code-mixed sentences, created for evaluating large LLMs on translating code-mixed text. It is constructed from the ArzEn-MultiGenre parallel corpus and enhanced with carefully prompted and human-validated code-mixed variants.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\nInstances: Each entry contains:â€¦ See the full description on the dataset page: https://huggingface.co/datasets/taha-alnasser/ArzEn-CodeMixed.","url":"https://huggingface.co/datasets/taha-alnasser/ArzEn-CodeMixed","creator_name":"Taha Alnasser","creator_url":"https://huggingface.co/taha-alnasser","license_name":"Academic Free License v3.0","license_url":"https://choosealicense.com/licenses/afl-3.0/","language":"en","first_N":5,"first_N_keywords":["translation","Arabic","English","afl-3.0","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"muaalem-annotated-v3","keyword":"arabic","description":"\n\t\n\t\t\n\t\tÙ‚Ø§Ø¹Ø¯Ø© Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù…Ø¹Ù„Ù… Ø§Ù„Ù‚Ø±Ø¢Ù†ÙŠØ©\n\t\n\nÙ‡Ø°Ù‡ Ø§Ù„ dataset Ù‡ÙŠ Ø¬Ø²Ø¡ Ù…Ù† Ù…Ø´Ø±ÙˆØ¹ Ø§Ù„Ù…Ù„Ù… Ø§Ù„Ø±Ù‚Ø±Ø¢Ù†ÙŠ: quran-muaalem ÙˆÙ‡ÙŠ ØªÙ‡Ø¯Ù Ù„ÙƒØ´Ù Ø£Ø®Ø§Ø·Ø§Ø¡ Ø§Ù„ØªØ¬ÙˆÙŠØ¯ Ø¹Ù† Ø·Ø±ÙŠÙ‚ Ø±Ø³Ù… ØµÙˆØªÙŠ ÙŠØµÙ ÙƒÙ„ Ù‚ÙˆØ§Ø¹Ø¯ Ø§Ù„ØªØ¬ÙˆÙŠØ¯ ÙˆØµÙØ§Øª Ø§Ù„Ø­Ø±ÙˆÙ: quran-trainscript\n\n\t\n\t\t\n\t\tÙˆØµÙ  Ù‚Ø§Ø¹Ø¯Ø© Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø¹Ù„Ù…\n\t\n\nÙ…ØµØ§Ø­Ù Ù…Ø¬Ù…Ø¹Ù…Ø© Ù…Ù† Ø§Ù„Ù‚Ø±Ø§Ø¡ Ø§Ù„Ù…ØªÙ‚Ù†ÙŠÙ† Ù„Ø¨Ù†Ø§Ø¡ Ù†Ù…Ø§Ø°Ø¬ Ø°ÙƒØ§Ø¡ Ø§ØµØ·Ù†Ø§Ø¹ÙŠ Ù„Ø®Ø¯Ù…Ø© Ø§Ù„Ù‚Ø±Ø¢Ù† Ø§Ù„ÙƒØ±ÙŠÙ…. Ø£Ù†Ø¸Ø± Ù‡Ù†Ø§ Ù„Ø£ÙƒÙˆØ§Ø¯ Ø¨Ù†Ø§Ø¡ Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„ØªÙ„Ø§ÙˆØ§Øª Ø§Ù„Ù‚Ø±Ø¢Ù†ÙŠØ©\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tØ§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„ÙˆØµÙÙŠØ© Ù„Ù„Ù…ØµØ§Ø­Ù\n\t\n\nds = load_dataset('obadx/muaalem-annotated-v3', name='moshaf_metadata')['train']\n\n\n\t\n\t\n\t\n\t\tÙˆØµÙâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/obadx/muaalem-annotated-v3.","url":"https://huggingface.co/datasets/obadx/muaalem-annotated-v3","creator_name":"Abdullah","creator_url":"https://huggingface.co/obadx","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["Arabic","mit","100K - 1M","parquet","Audio"],"keywords_longer_than_N":true},
	{"name":"aqedah-data","keyword":"arabic","description":"abdullah-alamodi/aqedah-data dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/abdullah-alamodi/aqedah-data","creator_name":"Abdullah Alamodi","creator_url":"https://huggingface.co/abdullah-alamodi","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["Arabic","mit","< 1K","json","Text"],"keywords_longer_than_N":true},
	{"name":"ASLAD-190K","keyword":"arabic","description":"\n\t\n\t\t\n\t\tASLAD-190K: Arabic Sign Language Alphabet Dataset\n\t\n\nThe ASLAD-190K dataset is an extensive collection containing 190,000 meticulously labeled RGB images representing 32 alphabets of the ArSL. To capture these images, we enlisted the help of two signers and utilized two different computer webcams, namely the HP HD camera and HP Truevision HD. The MediaPipe library was crucial in capturing RGB photos of various sizes.\nDuring the data collection process, we took great care to introduceâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/aboulesnane/ASLAD-190K.","url":"https://huggingface.co/datasets/aboulesnane/ASLAD-190K","creator_name":"Abdennour Boulesnane","creator_url":"https://huggingface.co/aboulesnane","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["English","Arabic","cc-by-4.0","ðŸ‡ºðŸ‡¸ Region: US","Computer Vision"],"keywords_longer_than_N":true},
	{"name":"eg-legal-multi-task","keyword":"arabic","description":"\n\t\n\t\t\n\t\tArabic Legal Dataset - Multi-Task Legal Learning\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nMulti-task learning dataset combining classification, QA, NER, and summarization tasks in unified format.\nThis dataset contains 1,046 examples of multi_task data derived from Egyptian legal texts, including criminal law, civil law, procedural law, and personal status law. The dataset is designed for training and evaluating Arabic legal AI models.\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\n\nLanguage: Arabic (Egyptianâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fr3on/eg-legal-multi-task.","url":"https://huggingface.co/datasets/fr3on/eg-legal-multi-task","creator_name":"Ahmed Mardi","creator_url":"https://huggingface.co/fr3on","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","question-answering","token-classification","Arabic","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"eg-legal-multi-task","keyword":"arabic","description":"\n\t\n\t\t\n\t\tArabic Legal Dataset - Multi-Task Legal Learning\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nMulti-task learning dataset combining classification, QA, NER, and summarization tasks in unified format.\nThis dataset contains 1,046 examples of multi_task data derived from Egyptian legal texts, including criminal law, civil law, procedural law, and personal status law. The dataset is designed for training and evaluating Arabic legal AI models.\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\n\nLanguage: Arabic (Egyptianâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fr3on/eg-legal-multi-task.","url":"https://huggingface.co/datasets/fr3on/eg-legal-multi-task","creator_name":"Ahmed Mardi","creator_url":"https://huggingface.co/fr3on","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","question-answering","token-classification","Arabic","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"allenai_tulu-3-sft-mixture-DolphinLabeled","keyword":"egyptian arabic","description":"\n\t\n\t\t\n\t\tallenai tulu-3-sft-mixture DolphinLabeled\n\t\n\n\n\t\n\t\t\n\t\tPart of the DolphinLabeled series of datasets\n\t\n\n\n\t\n\t\t\n\t\tPresented by Eric Hartford and Cognitive Computations\n\t\n\nThe purpose of this dataset is to enable filtering of allenai/tulu-3-sft-mixture dataset.\nThe original dataset is allenai/tulu-3-sft-mixture\nI have modified the dataset using two scripts.\n\ndedupe.py - removes rows with identical final message content\nlabel.py - adds a \"flags\" column containing the following booleanâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/cognitivecomputations/allenai_tulu-3-sft-mixture-DolphinLabeled.","url":"https://huggingface.co/datasets/cognitivecomputations/allenai_tulu-3-sft-mixture-DolphinLabeled","creator_name":"Cognitive Computations","creator_url":"https://huggingface.co/cognitivecomputations","license_name":"Open Data Commons Attribution License v1.0","license_url":"https://scancode-licensedb.aboutcode.org/odc-by-1.0.html","language":"en","first_N":5,"first_N_keywords":["other","crowdsourced","expert-generated","machine-generated","multilingual"],"keywords_longer_than_N":true},
	{"name":"allenai_tulu-3-sft-mixture-DolphinLabeled","keyword":"levantine arabic","description":"\n\t\n\t\t\n\t\tallenai tulu-3-sft-mixture DolphinLabeled\n\t\n\n\n\t\n\t\t\n\t\tPart of the DolphinLabeled series of datasets\n\t\n\n\n\t\n\t\t\n\t\tPresented by Eric Hartford and Cognitive Computations\n\t\n\nThe purpose of this dataset is to enable filtering of allenai/tulu-3-sft-mixture dataset.\nThe original dataset is allenai/tulu-3-sft-mixture\nI have modified the dataset using two scripts.\n\ndedupe.py - removes rows with identical final message content\nlabel.py - adds a \"flags\" column containing the following booleanâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/cognitivecomputations/allenai_tulu-3-sft-mixture-DolphinLabeled.","url":"https://huggingface.co/datasets/cognitivecomputations/allenai_tulu-3-sft-mixture-DolphinLabeled","creator_name":"Cognitive Computations","creator_url":"https://huggingface.co/cognitivecomputations","license_name":"Open Data Commons Attribution License v1.0","license_url":"https://scancode-licensedb.aboutcode.org/odc-by-1.0.html","language":"en","first_N":5,"first_N_keywords":["other","crowdsourced","expert-generated","machine-generated","multilingual"],"keywords_longer_than_N":true},
	{"name":"allenai_tulu-3-sft-mixture-DolphinLabeled","keyword":"moroccan arabic","description":"\n\t\n\t\t\n\t\tallenai tulu-3-sft-mixture DolphinLabeled\n\t\n\n\n\t\n\t\t\n\t\tPart of the DolphinLabeled series of datasets\n\t\n\n\n\t\n\t\t\n\t\tPresented by Eric Hartford and Cognitive Computations\n\t\n\nThe purpose of this dataset is to enable filtering of allenai/tulu-3-sft-mixture dataset.\nThe original dataset is allenai/tulu-3-sft-mixture\nI have modified the dataset using two scripts.\n\ndedupe.py - removes rows with identical final message content\nlabel.py - adds a \"flags\" column containing the following booleanâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/cognitivecomputations/allenai_tulu-3-sft-mixture-DolphinLabeled.","url":"https://huggingface.co/datasets/cognitivecomputations/allenai_tulu-3-sft-mixture-DolphinLabeled","creator_name":"Cognitive Computations","creator_url":"https://huggingface.co/cognitivecomputations","license_name":"Open Data Commons Attribution License v1.0","license_url":"https://scancode-licensedb.aboutcode.org/odc-by-1.0.html","language":"en","first_N":5,"first_N_keywords":["other","crowdsourced","expert-generated","machine-generated","multilingual"],"keywords_longer_than_N":true},
	{"name":"allenai_tulu-3-sft-mixture-DolphinLabeled","keyword":"najdi arabic","description":"\n\t\n\t\t\n\t\tallenai tulu-3-sft-mixture DolphinLabeled\n\t\n\n\n\t\n\t\t\n\t\tPart of the DolphinLabeled series of datasets\n\t\n\n\n\t\n\t\t\n\t\tPresented by Eric Hartford and Cognitive Computations\n\t\n\nThe purpose of this dataset is to enable filtering of allenai/tulu-3-sft-mixture dataset.\nThe original dataset is allenai/tulu-3-sft-mixture\nI have modified the dataset using two scripts.\n\ndedupe.py - removes rows with identical final message content\nlabel.py - adds a \"flags\" column containing the following booleanâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/cognitivecomputations/allenai_tulu-3-sft-mixture-DolphinLabeled.","url":"https://huggingface.co/datasets/cognitivecomputations/allenai_tulu-3-sft-mixture-DolphinLabeled","creator_name":"Cognitive Computations","creator_url":"https://huggingface.co/cognitivecomputations","license_name":"Open Data Commons Attribution License v1.0","license_url":"https://scancode-licensedb.aboutcode.org/odc-by-1.0.html","language":"en","first_N":5,"first_N_keywords":["other","crowdsourced","expert-generated","machine-generated","multilingual"],"keywords_longer_than_N":true},
	{"name":"allenai_tulu-3-sft-mixture-DolphinLabeled","keyword":"standard arabic","description":"\n\t\n\t\t\n\t\tallenai tulu-3-sft-mixture DolphinLabeled\n\t\n\n\n\t\n\t\t\n\t\tPart of the DolphinLabeled series of datasets\n\t\n\n\n\t\n\t\t\n\t\tPresented by Eric Hartford and Cognitive Computations\n\t\n\nThe purpose of this dataset is to enable filtering of allenai/tulu-3-sft-mixture dataset.\nThe original dataset is allenai/tulu-3-sft-mixture\nI have modified the dataset using two scripts.\n\ndedupe.py - removes rows with identical final message content\nlabel.py - adds a \"flags\" column containing the following booleanâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/cognitivecomputations/allenai_tulu-3-sft-mixture-DolphinLabeled.","url":"https://huggingface.co/datasets/cognitivecomputations/allenai_tulu-3-sft-mixture-DolphinLabeled","creator_name":"Cognitive Computations","creator_url":"https://huggingface.co/cognitivecomputations","license_name":"Open Data Commons Attribution License v1.0","license_url":"https://scancode-licensedb.aboutcode.org/odc-by-1.0.html","language":"en","first_N":5,"first_N_keywords":["other","crowdsourced","expert-generated","machine-generated","multilingual"],"keywords_longer_than_N":true},
	{"name":"allenai_tulu-3-sft-mixture-DolphinLabeled","keyword":"ta'izzi-adeni arabic","description":"\n\t\n\t\t\n\t\tallenai tulu-3-sft-mixture DolphinLabeled\n\t\n\n\n\t\n\t\t\n\t\tPart of the DolphinLabeled series of datasets\n\t\n\n\n\t\n\t\t\n\t\tPresented by Eric Hartford and Cognitive Computations\n\t\n\nThe purpose of this dataset is to enable filtering of allenai/tulu-3-sft-mixture dataset.\nThe original dataset is allenai/tulu-3-sft-mixture\nI have modified the dataset using two scripts.\n\ndedupe.py - removes rows with identical final message content\nlabel.py - adds a \"flags\" column containing the following booleanâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/cognitivecomputations/allenai_tulu-3-sft-mixture-DolphinLabeled.","url":"https://huggingface.co/datasets/cognitivecomputations/allenai_tulu-3-sft-mixture-DolphinLabeled","creator_name":"Cognitive Computations","creator_url":"https://huggingface.co/cognitivecomputations","license_name":"Open Data Commons Attribution License v1.0","license_url":"https://scancode-licensedb.aboutcode.org/odc-by-1.0.html","language":"en","first_N":5,"first_N_keywords":["other","crowdsourced","expert-generated","machine-generated","multilingual"],"keywords_longer_than_N":true},
	{"name":"quran-tafseer-qurancom","keyword":"arabic","description":"\n\t\n\t\t\n\t\tQuran and Tafseer Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset contains verses from the Quran along with their tafseer (interpretation/explanation).\nIt includes both the original Arabic text and translations, as well as detailed tafseer from scholars.\nThe dataset is useful for Islamic studies, NLP tasks related to religious texts, and cross-lingual research.\n\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nThe dataset contains Quran verses along with their tafseer (interpretation/explanation).â€¦ See the full description on the dataset page: https://huggingface.co/datasets/gurgutan/quran-tafseer-qurancom.","url":"https://huggingface.co/datasets/gurgutan/quran-tafseer-qurancom","creator_name":"Ð˜Ð²Ð°Ð½ Ð˜Ð²Ð°Ð½Ð¾Ð²Ð¸Ñ‡ Ð¡Ð»ÐµÐ¿Ð¾Ð²Ð¸Ñ‡ÐµÐ²","creator_url":"https://huggingface.co/gurgutan","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["question-answering","Arabic","English","mit","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"Detect-Egyptian-Wikipedia-Articles","keyword":"arabic","description":" Detect Egyptian Wikipedia Template-translated Articles \n\n\n\t\n\t\t\n\t\tDataset Description:\n\t\n\nWe release the heuristically filtered, manually processed, and automatically classified Egyptian Arabic Wikipedia articles dataset. This dataset was used to develop a web-based detection system to automatically identify the template-translated articles on the Egyptian Arabic Wikipedia edition. The system is called Egyptian Arabic Wikipedia Scanner and is hosted on Hugging Face Spaces, here:â€¦ See the full description on the dataset page: https://huggingface.co/datasets/SaiedAlshahrani/Detect-Egyptian-Wikipedia-Articles.","url":"https://huggingface.co/datasets/SaiedAlshahrani/Detect-Egyptian-Wikipedia-Articles","creator_name":"Saied Alshahrani","creator_url":"https://huggingface.co/SaiedAlshahrani","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","Egyptian Wikipedia","Arabic","mit","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"quran_multilingual_parallel","keyword":"arabic","description":"\n\t\n\t\t\n\t\tðŸ“˜ Qurâ€™an Multilingual Parallel Dataset (quran_multilingual_parallel)\n\t\n\nThis dataset presents a clean, structurally-aligned multilingual parallel corpus of the Qurâ€™anic text. It is intended for linguistic, computational, and cross-lingual AI applications â€” not only for religious interpretation.\nIt contains over 6,200 verse-level alignments in 54 human languages, formatted in a machine-friendly .csv structure with language-specific translation fields.\n\n\n\t\n\t\t\n\t\n\t\n\t\tðŸ§  Dataset Highlightsâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/freococo/quran_multilingual_parallel.","url":"https://huggingface.co/datasets/freococo/quran_multilingual_parallel","creator_name":"Wynn","creator_url":"https://huggingface.co/freococo","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["translation","Arabic","Albanian","Amharic","Azerbaijani"],"keywords_longer_than_N":true},
	{"name":"AURA-Classification","keyword":"arabic","description":"\n\t\n\t\t\n\t\tAURA-Classification\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe AURA (App User Review in Arabic) Classification dataset is a collection of 2,900 Arabic-language app reviews collected from various mobile applications. This dataset is primarily designed for text classification tasks.\n\n\t\n\t\t\n\t\tFeatures\n\t\n\nThe dataset includes the following fields:\n\nreview: The text of the review in Arabic.\n\nappName: The name of the application being reviewed.\n\nplatform: The platform (iOS or Android) where theâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/irfan-ahmad/AURA-Classification.","url":"https://huggingface.co/datasets/irfan-ahmad/AURA-Classification","creator_name":"Irfan Ahmad","creator_url":"https://huggingface.co/irfan-ahmad","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["Arabic","mit","1K - 10K","parquet","Text"],"keywords_longer_than_N":true},
	{"name":"AURA-Classification","keyword":"arabic","description":"\n\t\n\t\t\n\t\tAURA-Classification\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe AURA (App User Review in Arabic) Classification dataset is a collection of 2,900 Arabic-language app reviews collected from various mobile applications. This dataset is primarily designed for text classification tasks.\n\n\t\n\t\t\n\t\tFeatures\n\t\n\nThe dataset includes the following fields:\n\nreview: The text of the review in Arabic.\n\nappName: The name of the application being reviewed.\n\nplatform: The platform (iOS or Android) where theâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/irfan-ahmad/AURA-Classification.","url":"https://huggingface.co/datasets/irfan-ahmad/AURA-Classification","creator_name":"Irfan Ahmad","creator_url":"https://huggingface.co/irfan-ahmad","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["Arabic","mit","1K - 10K","parquet","Text"],"keywords_longer_than_N":true},
	{"name":"BenchMAX_Question_Answering","keyword":"arabic","description":"\n\t\n\t\t\n\t\tDataset Sources\n\t\n\n\nPaper: BenchMAX: A Comprehensive Multilingual Evaluation Suite for Large Language Models\nLink: https://huggingface.co/papers/2502.07346\nRepository: https://github.com/CONE-MT/BenchMAX\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nBenchMAX_Question_Answering is a dataset of BenchMAX for evaluating the long-context capability of LLMs in multilingual scenarios.\nThe subtasks are similar to the subtasks in RULER.\nThe data is sourcing from UN Parallel Corpus and xquad.\nThe haystacksâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/LLaMAX/BenchMAX_Question_Answering.","url":"https://huggingface.co/datasets/LLaMAX/BenchMAX_Question_Answering","creator_name":"LLaMAX","creator_url":"https://huggingface.co/LLaMAX","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","multilingual","English","Chinese","Spanish"],"keywords_longer_than_N":true}
]
;
