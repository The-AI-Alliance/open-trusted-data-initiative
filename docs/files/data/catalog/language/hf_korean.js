var data_for_korean = 
[
	{"name":"panlex","keyword":"korean","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/lbourdois/panlex","creator_name":"Loïck BOURDOIS","creator_url":"https://huggingface.co/lbourdois","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tPanLex\\n\\t\\n\\nJanuary 1, 2024 version of PanLex Language Vocabulary with 24,650,274 rows covering 6,152 languages.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tColumns\\n\\t\\n\\n\\nvocab: contains the text entry.  \\n639-3: contains the ISO 639-3 languages tags to allow users to filter on the language(s) of their choice.\\n639-3_english_name: the English language name associated to the code ISO 639-3. \\nvar_code: contains a code to differentiate language variants. In practice, this is the code 639-3 + a number.  If 000, it… See the full description on the dataset page: https://huggingface.co/datasets/lbourdois/panlex."},
	{"name":"contextomized-quote","keyword":"korean","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/humane-lab/contextomized-quote","creator_name":"HUMANE Lab","creator_url":"https://huggingface.co/humane-lab","description":"humane-lab/contextomized-quote dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"ChatML-aya_dataset","keyword":"korean","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Felladrin/ChatML-aya_dataset","creator_name":"Victor Nogueira","creator_url":"https://huggingface.co/Felladrin","description":"CohereForAI/aya_dataset in ChatML format, ready to use in HuggingFace TRL's SFT Trainer.\\nPython code used for conversion:\\nfrom datasets import load_dataset\\nfrom transformers import AutoTokenizer\\n\\ntokenizer = AutoTokenizer.from_pretrained(\\\"Felladrin/Llama-160M-Chat-v1\\\")\\n\\ndataset = load_dataset(\\\"CohereForAI/aya_dataset\\\", split=\\\"train\\\")\\n\\ndef format(columns):\\n    messages = [\\n        {\\n            \\\"role\\\": \\\"user\\\",\\n            \\\"content\\\": columns[\\\"inputs\\\"].strip(),\\n        },\\n        {… See the full description on the dataset page: https://huggingface.co/datasets/Felladrin/ChatML-aya_dataset."},
	{"name":"llm_datasets","keyword":"korean","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Gunulhona/llm_datasets","creator_name":"JungKwonHwan","creator_url":"https://huggingface.co/Gunulhona","description":"Gunulhona/llm_datasets dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"eagle","keyword":"korean","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/MasahiroKaneko/eagle","creator_name":"Masahiro Kaneko","creator_url":"https://huggingface.co/MasahiroKaneko","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tEagle 🦅: Ethical Dataset Given from Real Interactions\\n\\t\\n\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tIntroduction\\n\\t\\n\\nThis repository contains the Eagle dataset, which is an ethical dataset of real interactions between humans and ChatGPT. This dataset is created to evaluate social bias, opinion bias, toxic language, and morality in Large Language Models (LLMs).\\nIf you use the Eagle dataset in your research, please cite the following:\\n@inproceedings{Eagle:arxiv:2024,\\n    title={Eagle: Ethical Dataset Given from… See the full description on the dataset page: https://huggingface.co/datasets/MasahiroKaneko/eagle."},
	{"name":"Welfare-QA","keyword":"korean","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Ash-Hun/Welfare-QA","creator_name":"Choi Jaehun","creator_url":"https://huggingface.co/Ash-Hun","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Welfare-QA\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDescription\\n\\t\\n\\n대한민국 보건복지부에서 발간하였으며 2023년 5월 11일에 복지로에 등록된 안내책자를 바탕으로 만들어졌습니다.\\n총 413페이지의 비정형 PDF에 담긴 약 460여개의 복지제도에 대한 Question-Answering-Documents 데이터셋입니다.\\n원본은 다음 링크에서 확인해보실 수 있습니다. 👉 '2023 나에게 힘이되는 복지서비스 PDF 책자'\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tProject Repo\\n\\t\\n\\n\\nGithub Repo : Ask-for-Welfare\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tHow to Uses\\n\\t\\n\\n>>> from datasets import load_dataset\\n>>> dataset = load_dataset(\\\"Ash-Hun/Welfare-QA\\\", split='train')\\n>>> dataset\\nDataset({\\n    features:… See the full description on the dataset page: https://huggingface.co/datasets/Ash-Hun/Welfare-QA."},
	{"name":"X-SVAMP_en_zh_ko_it_es","keyword":"korean","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/zhihz0535/X-SVAMP_en_zh_ko_it_es","creator_name":"Zhihan Zhang","creator_url":"https://huggingface.co/zhihz0535","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tX-SVAMP\\n\\t\\n\\n🤗 Paper | 📖 arXiv\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nX-SVAMP is an evaluation benchmark for multilingual large language models (LLMs), including questions and answers in 5 languages (English, Chinese, Korean, Italian and Spanish).\\nIt is intended to evaluate the math reasoning abilities of LLMs. The dataset is translated by GPT-4-turbo from the original English-version SVAMP.\\nIn our paper, we evaluate LLMs in a zero-shot generative setting: prompt the instruction-tuned… See the full description on the dataset page: https://huggingface.co/datasets/zhihz0535/X-SVAMP_en_zh_ko_it_es."},
	{"name":"X-TruthfulQA_en_zh_ko_it_es","keyword":"korean","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/zhihz0535/X-TruthfulQA_en_zh_ko_it_es","creator_name":"Zhihan Zhang","creator_url":"https://huggingface.co/zhihz0535","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tX-TruthfulQA\\n\\t\\n\\n🤗 Paper | 📖 arXiv\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nX-TruthfulQA is an evaluation benchmark for multilingual large language models (LLMs), including questions and answers in 5 languages (English, Chinese, Korean, Italian and Spanish).\\nIt is intended to evaluate the truthfulness of LLMs. The dataset is translated by GPT-4 from the original English-version TruthfulQA.\\nIn our paper, we evaluate LLMs in a zero-shot generative setting: prompt the instruction-tuned LLM… See the full description on the dataset page: https://huggingface.co/datasets/zhihz0535/X-TruthfulQA_en_zh_ko_it_es."},
	{"name":"MAGBIG","keyword":"korean","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/felfri/MAGBIG","creator_name":"Felix Friedrich","creator_url":"https://huggingface.co/felfri","description":"\\n\\t\\n\\t\\t\\n\\t\\tMAGBIG benchmark\\n\\t\\n\\nThis is the MAGBIG benchmark proposed in https://arxiv.org/abs/2401.16092\\nThis benchmark is intended for multilingual text-to-image models. With MAGBIG, you can generate images for a diverse set of prompts across ten different languages. These images can be evaluated for differences across languages. MAGBIG is designed to uncover and assess biases across languages such as gender, race, age, etc. This way, we can measure whether bias exists in a language, but also if… See the full description on the dataset page: https://huggingface.co/datasets/felfri/MAGBIG."},
	{"name":"KoTox","keyword":"korean","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/SungJoo/KoTox","creator_name":"Grace","creator_url":"https://huggingface.co/SungJoo","description":"KoTox is an automatically generated toxic instruction dataset in Korean, comprising 39K unethical instruction-output pairs.\\nThe dataset is generated based on predefined lexicons and linguistic templates.\\nIt is designed to address potentially harmful or misleading instructions by including outputs that refrain from providing specific opinions or information in response.\\nThe dataset has been proven effective in mitigating toxicity in Korean Large Language Models (LLMs).\\nThe paper has been… See the full description on the dataset page: https://huggingface.co/datasets/SungJoo/KoTox."},
	{"name":"KoWoW","keyword":"korean","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/didi0di/KoWoW","creator_name":"Yeongji Noh","creator_url":"https://huggingface.co/didi0di","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for KoWoW\\n\\t\\n\\n\\n\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nWoW(Wiard of Wikipedia)를 한국어로 변역한 데이터입니다.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nWoW(Wiard of Wikipedia)라는 지식 기반 대화 데이터를 한국어로 변역한 데이터입니다.한 대화에 여러 개의 dialog가 묶음으로 구성되어 있으며, 전체 대화는 22,311건, 전체 dialog는 201,999개 입니다.본 데이터셋은 Knowledge와 Utterance가 모두 한국어인 ko 버전만 가져온 데이터입니다.    \\n\\nLanguage(s) (NLP): ko\\nLicense: mit\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Sources\\n\\t\\n\\n\\n\\n\\nRepository: https://github.com/AIRC-KETI/kowow/tree/master\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tUses… See the full description on the dataset page: https://huggingface.co/datasets/didi0di/KoWoW."},
	{"name":"MSC_korean","keyword":"korean","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/meenham/MSC_korean","creator_name":"MeenHwanSong","creator_url":"https://huggingface.co/meenham","description":"\\nData\\nsource\\nMSC data from the paper < Beyond Goldfish Memory: Long-Term Open-Domain Conversation >\\ntrain/valid/test dataset of session 4\\n\\n\\ntranslation ( English -> Koeran )\\nGPT-3.5-turbo is used mostly\\nGPT-4 : 66 data from the start of session_4_train ( after these, changed to gpt-3.5 )\\n\\n\\n\\n\\n\\n"},
	{"name":"ALMA-R-ko-en","keyword":"korean","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/qwopqwop/ALMA-R-ko-en","creator_name":"Junjae Lee","creator_url":"https://huggingface.co/qwopqwop","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for \\\"ALMA-R-ko-en-Preference\\\"\\n\\t\\n\\nref) https://huggingface.co/datasets/haoranxu/ALMA-R-Preference\\nThe triplet prference data, supporting 2 translation directions, is built upon the FLORES-200 development and test data. For each direction, we provide a source sentence along with three translations: one from GPT-4, another from EEVE-ALMA-LoRA, and a reference translation. For instance, in the English-German pair, our data structure is as follows:\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSentences:… See the full description on the dataset page: https://huggingface.co/datasets/qwopqwop/ALMA-R-ko-en."},
	{"name":"KoMedText","keyword":"korean","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/kurugai/KoMedText","creator_name":"HyeongWon Yun","creator_url":"https://huggingface.co/kurugai","description":"이 데이터셋은 BI55/MedText을 deepl로 번역한 자료입니다.\\n"},
	{"name":"mewsli-x","keyword":"korean","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/izhx/mewsli-x","creator_name":"Xin Zhang","creator_url":"https://huggingface.co/izhx","description":"I generated the dataset following mewsli-x.md#getting-started\\nand converted into different parts (see process.py):\\n\\nar/de/en/es/fa/ja/pl/ro/ta/tr/uk wikinews_mentions dev and test (from wikinews_mentions-dev/test.jsonl)\\ncandidate entities of 50 languages (from candidate_set_entities.jsonl)\\nEnglish wikipedia_pairs to fine-tune models (from wikipedia_pairs-dev/train.jsonl)\\n\\nRaw data files are in raw.tar.gz, which contains:\\n[...] 535M Feb 24 22:06 candidate_set_entities.jsonl\\n[...] 9.8M Feb 24… See the full description on the dataset page: https://huggingface.co/datasets/izhx/mewsli-x."},
	{"name":"kobbq","keyword":"korean","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/naver-ai/kobbq","creator_name":"NAVER AI Lab","creator_url":"https://huggingface.co/naver-ai","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for KoBBQ\\n\\t\\n\\n\\n\\n\\n\\nThe Bias Benchmark for Question Answering (BBQ) is designed to evaluate social biases of language models (LMs), but it is not simple to adapt this benchmark to cultural contexts other than the US because social biases depend heavily on the cultural context. In this paper, we present KoBBQ, a Korean bias benchmark dataset, and we propose a general framework that addresses considerations for cultural adaptation of a dataset. Our framework includes… See the full description on the dataset page: https://huggingface.co/datasets/naver-ai/kobbq."},
	{"name":"test3","keyword":"korean","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/jin-code/test3","creator_name":"kim","creator_url":"https://huggingface.co/jin-code","description":"jin-code/test3 dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"MultiQ","keyword":"korean","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/caro-holt/MultiQ","creator_name":"Holtermann","creator_url":"https://huggingface.co/caro-holt","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for MultiQ\\n\\t\\n\\nThis is the dataset corresponding to the paper \\\"Evaluating the Elementary Multilingual Capabilities of Large Language Models with MultiQ\\\". \\nIt is a silver standard benchmark that can be used to evaluate the basic multilingual capabilities of LLMs. It contains 200 open ended questions automatically \\ntranslated into 137 typologically diverse languages. \\n\\nCurated by: Carolin Holtermann, Paul Röttger, Timm Dill, Anne Lauscher\\nLanguage(s) (NLP): 137 diverse… See the full description on the dataset page: https://huggingface.co/datasets/caro-holt/MultiQ."},
	{"name":"OpenOrca-Ko-En","keyword":"korean","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/appleparan/OpenOrca-Ko-En","creator_name":"Jongsu Kim","creator_url":"https://huggingface.co/appleparan","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tOpenOrca-Ko-En\\n\\t\\n\\n\\nkyujinpy/OpenOrca-KO와 Open-Orca/OpenOrca를 공통된 데이터만 필터링하고 합친 데이터셋입니다.\\n컬럼은 기존 OpenOrca에 맞춰서 system_prompt_{ko/en}, question_{ko/en}, response_{ko/en} 으로 변경하였습니다.\\n중복된 id를 제거하여 데이터수가 일부 감소하였습니다.\\n데이터셋을 만드는데 사용한 스크립트입니다.\\n데이터셋 이용하셔서 모델이나 데이터셋을 만드실 때, 이 데이터셋뿐만 아니라 위 데이터셋도 함께 출처표기를 해주셨으면 합니다.\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset inf0\\n\\t\\n\\n\\nNIV // 1551개(OpenOrca-KO: 1571개)  \\nFLAN // 9338개(OpenOrca-KO: 9434개)\\nT0 // 6303개(OpenOrca-KO: 6351개)\\nCoT // 2092개(OpenOrca-KO: 2117개)\\nKoCoT // 2159개… See the full description on the dataset page: https://huggingface.co/datasets/appleparan/OpenOrca-Ko-En."},
	{"name":"kollm-comparision","keyword":"korean","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/davidkim205/kollm-comparision","creator_name":"davidkim205","creator_url":"https://huggingface.co/davidkim205","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tdavidkim205/kollm-comparision\\n\\t\\n\\nnox-solar-10.7b-v4에 사용된 dpo 데이터셋으로 huggingface에 공개된 데이터와 twodigit에서 제작한 데이터로 구성되어 있습니다.\\nnox github에서 사용가능하도록 comparision 형식으로 되어 있습니다.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\t공개 데이터셋\\n\\t\\n\\n\\n\\t\\n\\t\\t\\nSource\\n설명\\n원본 URL\\n\\n\\n\\t\\t\\nkobest_boolq\\n한국어 벤치마크 KoBEST\\nhttps://huggingface.co/datasets/skt/kobest_v1\\n\\n\\nkobest_copa\\n한국어 벤치마크 KoBEST\\nhttps://huggingface.co/datasets/skt/kobest_v1\\n\\n\\nkobest_hellaswag\\n한국어 벤치마크 KoBEST\\nhttps://huggingface.co/datasets/skt/kobest_v1\\n\\n\\nkobest_sentineg\\n한국어 벤치마크 KoBEST… See the full description on the dataset page: https://huggingface.co/datasets/davidkim205/kollm-comparision."},
	{"name":"create_qa_news","keyword":"korean","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/yuneun92/create_qa_news","creator_name":"Yun Eun","creator_url":"https://huggingface.co/yuneun92","description":"\\n질문 생성: kullm3 모델 이용\\n답변 생성: GPT3.5 turbo API 이용\\n지문 원본: AI HUB 뉴스 기계독해 데이터셋\\n\\n"},
	{"name":"bhojpuri","keyword":"korean","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ankur02/bhojpuri","creator_name":"Ankur Verma","creator_url":"https://huggingface.co/ankur02","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tFLEURS\\n\\t\\n\\nFleurs is the speech version of the FLoRes machine translation benchmark. \\nWe use 2009 n-way parallel sentences from the FLoRes dev and devtest publicly available sets, in 102 languages. \\nTraining sets have around 10 hours of supervision. Speakers of the train sets are different than speakers from the dev/test sets. Multilingual fine-tuning is\\nused and ”unit error rate” (characters, signs) of all languages is averaged. Languages and results are also grouped into seven… See the full description on the dataset page: https://huggingface.co/datasets/ankur02/bhojpuri."},
	{"name":"orca_dpo_data_ko","keyword":"korean","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/AIdenU/orca_dpo_data_ko","creator_name":"YuHeeJun","creator_url":"https://huggingface.co/AIdenU","description":"\\n원본 데이터 : HuggingFaceH4/orca_dpo_pairs\\n원본 데이터 셋을 system, question, chosen, rejected 형태에 맞게 정제 후, squarelike/Gugugo-koen-7B-V1.1-AWQ 으로 번역\\n오번역된 데이터는 삭제 검수\\n\\n"},
	{"name":"panlex-meanings","keyword":"korean","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/cointegrated/panlex-meanings","creator_name":"David Dale","creator_url":"https://huggingface.co/cointegrated","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for panlex-meanings\\n\\t\\n\\nThis is a dataset of words in several thousand languages, extracted from https://panlex.org.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Details\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThis dataset has been extracted from https://panlex.org (the 20240301 database dump) and rearranged on the per-language basis.\\nEach language subset consists of expressions (words and phrases). \\nEach expression is associated with some meanings (if there is more than one meaning, they are in… See the full description on the dataset page: https://huggingface.co/datasets/cointegrated/panlex-meanings."},
	{"name":"ko-voicephishing-binary-classification","keyword":"korean","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/HyaDoo/ko-voicephishing-binary-classification","creator_name":"SAERAM LEE","creator_url":"https://huggingface.co/HyaDoo","description":"HyaDoo/ko-voicephishing-binary-classification dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"en-fpb-ko","keyword":"korean","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/allganize/en-fpb-ko","creator_name":"allganize","creator_url":"https://huggingface.co/allganize","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\ten-fpb-ko\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\t데이터 설명\\n\\t\\n\\n\\nen-fpb-ko 데이터는 금융 뉴스로부터의 문장을 '긍정', '중립', '부정' 중 하나로 분류하는 감성 분류 (sentiment analysis) 데이터셋입니다.\\n입력값으로는 text만 주어집니다.\\n\\n한국어 데이터를 생성하기 위해, 먼저 사내 언어 번역 모델인 Allganize Translator를 활용하여 ChanceFocus/en-fpb의 test set을 한국어로 번역하였습니다. \\n오역된 데이터를 직접 제거하였고, 그 결과 944개의 평가 데이터가 생성되었습니다.\\n\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\t데이터 출처\\n\\t\\n\\n\\nChanceFocus/en-fpb\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\t데이터 예시\\n\\t\\n\\n{\\n  'conversation_id': 'fpb3876',\\n  'conversations': array([\\n    {\\n      'from': 'human',\\n      'value': '''금융 뉴스… See the full description on the dataset page: https://huggingface.co/datasets/allganize/en-fpb-ko."},
	{"name":"flare-fiqasa-ko","keyword":"korean","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/allganize/flare-fiqasa-ko","creator_name":"allganize","creator_url":"https://huggingface.co/allganize","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tflare-fiqasa-ko\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\t데이터 설명\\n\\t\\n\\n\\nflare-fiqasa-ko 데이터는 금융 도메인 뉴스 헤드라인의 감성을 예측(sentiment analysis)하는 데이터셋입니다.\\n입력값은 text로만 이루어져 있습니다.\\n\\n한국어 데이터를 생성하기 위해, 우선 사내 언어 번역 모델 Allganize Translator을 활용하여 ChanceFocus/flare-fiqasa의 test set을 번역했습니다.\\n오역된 데이터를 직접 제거하였고, 그 결과 204개의 평가 데이터가 생성되었습니다.\\n\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\t데이터 출처\\n\\t\\n\\n\\nChanceFocus/flare-fiqasa\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\t데이터 예시\\n\\t\\n\\n{\\n  'conversation_id': 'fiqasa938',\\n  'conversations': array([\\n    {\\n      'from': 'human',\\n      'value': '''다음 재무 게시물의… See the full description on the dataset page: https://huggingface.co/datasets/allganize/flare-fiqasa-ko."},
	{"name":"orca-math-word-problems-193k-korean","keyword":"korean","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/kuotient/orca-math-word-problems-193k-korean","creator_name":"Jisoo Kim","creator_url":"https://huggingface.co/kuotient","description":"원본 데이터셋: https://huggingface.co/datasets/microsoft/orca-math-word-problems-200k\\n번역 모델: Seagull-13b-translation\\n후처리\\n\\n번역 repetition 오류 제거\\nLaTeX 오류 체크(전부는 아닐 수 있음. /(/) -> /(/ 같은 오류 등...)\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tCitation\\n\\t\\n\\n@misc{mitra2024orcamath,\\n      title={Orca-Math: Unlocking the potential of SLMs in Grade School Math}, \\n      author={Arindam Mitra and Hamed Khanpour and Corby Rosset and Ahmed Awadallah},\\n      year={2024},\\n      eprint={2402.14830},\\n      archivePrefix={arXiv}… See the full description on the dataset page: https://huggingface.co/datasets/kuotient/orca-math-word-problems-193k-korean."},
	{"name":"NTREX","keyword":"korean","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/davidstap/NTREX","creator_name":"David Stap","creator_url":"https://huggingface.co/davidstap","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nNTREX -- News Test References for MT Evaluation from English into a total of 128 target languages. See original GitHub repo for full details.\\nExample of loading:\\ndataset = load_dataset(\\\"davidstap/NTREX\\\", \\\"rus_Cyrl\\\", trust_remote_code=True)\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages\\n\\t\\n\\nThe following languages are available:\\n\\n\\t\\n\\t\\t\\nLanguage Code\\nLanguage Name\\n\\n\\n\\t\\t\\nafr_Latn\\nAfrikaans\\n\\n\\namh_Ethi\\nAmharic\\n\\n\\narb_Arab\\nArabic\\n\\n\\naze_Latn\\nAzerbaijani\\n\\n\\nbak_Cyrl\\nBashkir\\n\\n\\nbel_Cyrl\\nBelarusian… See the full description on the dataset page: https://huggingface.co/datasets/davidstap/NTREX."},
	{"name":"KoInFoBench","keyword":"korean","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/kifai/KoInFoBench","creator_name":"KIFAI","creator_url":"https://huggingface.co/kifai","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tKoInFoBench\\n\\t\\n\\nKoInFoBench is a specialized evaluation dataset designed to assess the performance of Large Language Models (LLMs) on capabilities of Korean instructions following.\\nThe current version of KoInFoBench consists of 60 instruction sets and 233 questions.\\nInspired by InFoBench dataset, we extends their concpet by focusing on the nuances and features of Korean language.\\n\\n🖥️ Code to reproduce or evaluate own LLMs is available at https://github.com/KIFAI/KoInFoBench\\n📄… See the full description on the dataset page: https://huggingface.co/datasets/kifai/KoInFoBench."},
	{"name":"hd-bert-voicephishing-binary-classification-ver4","keyword":"korean","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/HyaDoo/hd-bert-voicephishing-binary-classification-ver4","creator_name":"SAERAM LEE","creator_url":"https://huggingface.co/HyaDoo","description":"HyaDoo/hd-bert-voicephishing-binary-classification-ver4 dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"KoMedInstruct-52k","keyword":"korean","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ChuGyouk/KoMedInstruct-52k","creator_name":"ChuGyouk","creator_url":"https://huggingface.co/ChuGyouk","description":"1차 번역 완료\\nI found several problems during translation, so additional filtering will be needed after completion.\\nStep 1. It was confirmed that the existing data contained a lot of data that was close to duplicates. Need to remove those.\\nStep 2. There are many outputs with a risk of hallucination. Data where the last sentence of output is incomplete must be edited.\\nStep 3. If data corresponding to the output is also included in the input, those must be edited.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tKo-AlpaCare\\n\\t\\n\\nThis is… See the full description on the dataset page: https://huggingface.co/datasets/ChuGyouk/KoMedInstruct-52k."},
	{"name":"test","keyword":"korean","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/haebo1/test","creator_name":"Hyunho Yang","creator_url":"https://huggingface.co/haebo1","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for KoBEST\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nKoBEST is a Korean benchmark suite consists of 5 natural language understanding tasks that requires advanced knowledge in Korean.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSupported Tasks and Leaderboards\\n\\t\\n\\nBoolean Question Answering, Choice of Plausible Alternatives, Words-in-Context, HellaSwag, Sentiment Negation Recognition\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages\\n\\t\\n\\nko-KR\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Structure\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Instances\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tKB-BoolQ\\n\\t\\n\\nAn example… See the full description on the dataset page: https://huggingface.co/datasets/haebo1/test."},
	{"name":"orca-math-korean-preference","keyword":"korean","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/kuotient/orca-math-korean-preference","creator_name":"Jisoo Kim","creator_url":"https://huggingface.co/kuotient","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tOrca-math-korean-preference\\n\\t\\n\\n\\nllm: claude-haiku와 gpt3.5로 평가된 generated(Student) answer의 정답 여부\\nquestion: orca-math dataset의 question\\nanswer: orca-math dataset의 answer\\ngenerated: EEVE-Math-10.8B(M1)의 출력\\nlabel: llm의 참/거짓 \\nchosen: label이 참일 경우 answer 혹은 generated의 random.choice, 거짓일 경우 answer (Orca-math original paper 참고)\\nrejected: label이 참일 경우 다른 rejected value의 random.choice, 거짓일 경우 rejected (Orca-math original paper 참고)\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\t비고\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tllm_exact_match prompt… See the full description on the dataset page: https://huggingface.co/datasets/kuotient/orca-math-korean-preference."},
	{"name":"Ko-MTS-Dialog","keyword":"korean","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ChuGyouk/Ko-MTS-Dialog","creator_name":"ChuGyouk","creator_url":"https://huggingface.co/ChuGyouk","description":"The validation set and two test sets will also be updated soon.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tMTS-Dialog\\n\\t\\n\\nThis is the repo for Ko-MTS-Dialog, which is a Korean translated version of MTS-Dialog dataset. MTS-Dialog dataset is a collection of 1.7k short doctor-patient conversations and corresponding summaries.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Translation Process\\n\\t\\n\\nI use DeepL for automatic translation and manually reviewed results.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tWarning\\n\\t\\n\\nThere are some concerns and warnings for this dataset.\\n\\nI recommend NOT… See the full description on the dataset page: https://huggingface.co/datasets/ChuGyouk/Ko-MTS-Dialog."},
	{"name":"swim-ir-cross-lingual","keyword":"korean","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/nthakur/swim-ir-cross-lingual","creator_name":"Nandan Thakur","creator_url":"https://huggingface.co/nthakur","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for SWIM-IR (Cross-lingual)\\n\\t\\n\\n\\n\\n\\nThis is the cross-lingual subset of the SWIM-IR dataset, where the query generated is in the target language and the passage is in English.\\nThe SWIM-IR dataset is available as CC-BY-SA 4.0. 18 languages (including English) are available in the cross-lingual dataset.\\nFor full details of the dataset, please read our upcoming NAACL 2024 paper and check out our website.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tWhat is SWIM-IR?\\n\\t\\n\\nSWIM-IR dataset is a synthetic… See the full description on the dataset page: https://huggingface.co/datasets/nthakur/swim-ir-cross-lingual."},
	{"name":"dell-qa-en-to-ko-translated-by-ke-t5-base","keyword":"korean","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/seongs/dell-qa-en-to-ko-translated-by-ke-t5-base","creator_name":"Kim Seongyeol","creator_url":"https://huggingface.co/seongs","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDell QA English to Korean Translation Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThis dataset, dell-qa-en-to-ko-translated-by-ke-t5-base, is a Korean translation of the original English Dell QA dataset. \\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSource\\n\\t\\n\\nThe original dataset, dell_qa, is designed for question-answering tasks and contains questions and answers related to Dell technologies. This translated version extends the utility to Korean language tasks.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Structure\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData… See the full description on the dataset page: https://huggingface.co/datasets/seongs/dell-qa-en-to-ko-translated-by-ke-t5-base."},
	{"name":"xsimplusplus","keyword":"korean","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/jaygala24/xsimplusplus","creator_name":"Jay Gala","creator_url":"https://huggingface.co/jaygala24","description":"xSIM++ is an extension of xSIM. In comparison to xSIM, this evaluates using target-side data with additional synthetic, hard-to-distinguish examples. You can find more details about it in the publication: xSIM++: An Improved Proxy to Bitext Mining Performance for Low-Resource Languages.\\n"},
	{"name":"wikipedia-korean-20240501","keyword":"korean","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/lcw99/wikipedia-korean-20240501","creator_name":"Chang W Lee","creator_url":"https://huggingface.co/lcw99","description":"wikipedia Korean 2024.5.1 cut\\n"},
	{"name":"sharegpt-tagengo-gpt4-ko","keyword":"korean","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/werty1248/sharegpt-tagengo-gpt4-ko","creator_name":"Dohyung Kim","creator_url":"https://huggingface.co/werty1248","description":"Original Dataset: lightblue/tagengo-gpt4\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tShareGPT-tagengo-GPT4-ko\\n\\t\\n\\n\\nLMSYS-Chat-1M를 통해 수집된 실제 유저들과 GPT-4(gpt-4-0125-preview) 사이의 단발성 대화 데이터 셋입니다.\\ntagengo-gpt4 데이터 셋에서 한국어 데이터 1,609개를 추출한 뒤, 사람이 직접 확인하여 일부 불필요한/중복 질문, 잘못된 답변 등을 제거했습니다.\\n자세한 언어별 분류 방법은 lightblue/tagengo-gpt4를 참고하세요.\\n번역이 아닌, 실제 한국어로 주고 받은 데이터 셋입니다.\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tFiles\\n\\t\\n\\n\\nsharegpt_tagengo_ko.json: 불필요한/중복 질문 및 잘못된 답변을 제거한 1,540개 데이터입니다.\\nsharegpt_tagengo_ko_no_sorry.json: sharegpt_tagengo_ko.json에서 \\\"죄송\\\"으로 시작되는 답변(GPT-4의… See the full description on the dataset page: https://huggingface.co/datasets/werty1248/sharegpt-tagengo-gpt4-ko."},
	{"name":"interesting-dom-snapshots","keyword":"korean","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/gbenson/interesting-dom-snapshots","creator_name":"Gary Benson","creator_url":"https://huggingface.co/gbenson","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Interesting DOM snapshots\\n\\t\\n\\nA small split of gbenson/webui-dom-snapshots.\\n\\nCurated by: Gary Benson\\nLanguages: Mostly English, some Chinese, Dutch, Czech and Korean\\nLicense: CC0 1.0 Universal\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tUses\\n\\t\\n\\nI'm using it to develop a DOM-aware tokenizer for HTML.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tBias, Risks, and Limitations\\n\\t\\n\\nThis isn't a representative split of the source dataset, it's a number of edge cases I flagged to investigate.\\n"},
	{"name":"aihub-contents-ko-only","keyword":"korean","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/richard-park/aihub-contents-ko-only","creator_name":"WOO HWAN PARK","creator_url":"https://huggingface.co/richard-park","description":"richard-park/aihub-contents-ko-only dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"sib200","keyword":"korean","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/sib200","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for SIB-200\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nSIB-200 is the largest publicly available topic classification dataset based on Flores-200 covering 205 languages and dialects.\\nThe train/validation/test sets are available for all the 205 languages.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSupported Tasks and Leaderboards\\n\\t\\n\\n\\ntopic classification: categorize wikipedia sentences into topics e.g science/technology, sports or politics.\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages\\n\\t\\n\\nThere are 205 languages available :… See the full description on the dataset page: https://huggingface.co/datasets/mteb/sib200."},
	{"name":"MAiDE-up","keyword":"korean","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/MichiganNLP/MAiDE-up","creator_name":"LIT @ UMich","creator_url":"https://huggingface.co/MichiganNLP","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for MAiDE-up: Multilingual Deception Detection of GPT-generated Hotel Reviews\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nMultilingual Deception Detection of GPT-generated Hotel Reviews. We compare real hotel reviews from Booking with LLM-generated hotel reviews in 10 languages.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages\\n\\t\\n\\nThe text in the dataset is in 10 languages: Chinese, English, French, German, Italian, Romanian, Korean, Russian, Spanish, Turkish\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSupported Tasks and Leaderboards… See the full description on the dataset page: https://huggingface.co/datasets/MichiganNLP/MAiDE-up."},
	{"name":"orca-math-word-problems-193k-korean-jsonl","keyword":"korean","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/jaypyon/orca-math-word-problems-193k-korean-jsonl","creator_name":"Jaeyong Park","creator_url":"https://huggingface.co/jaypyon","description":"원본 데이터셋\\n\\nhttps://huggingface.co/datasets/microsoft/orca-math-word-problems-200k\\nhttps://huggingface.co/datasets/kuotient/orca-math-word-problems-193k-korean\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tCitation\\n\\t\\n\\n@misc{mitra2024orcamath,\\n      title={Orca-Math: Unlocking the potential of SLMs in Grade School Math}, \\n      author={Arindam Mitra and Hamed Khanpour and Corby Rosset and Ahmed Awadallah},\\n      year={2024},\\n      eprint={2402.14830},\\n      archivePrefix={arXiv},\\n      primaryClass={cs.CL}\\n}\\n"},
	{"name":"qarv-instruct-ko","keyword":"korean","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/HAERAE-HUB/qarv-instruct-ko","creator_name":"HAE-RAE","creator_url":"https://huggingface.co/HAERAE-HUB","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tQARV-Instruct-KO\\n\\t\\n\\nThis subset of our dataset contains pairs of instructions and answers requiring knowledge of Korea.Unlike past works relying heavily on proprietary LLMs for data generation, we use a pipeline of open-source LLMs without restrictions on output usage.  \\nIn other words, you're completely free to use this dataset for training your models. Paper coming soon.\\n"},
	{"name":"oldhangul-dataset","keyword":"korean","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/devngho/oldhangul-dataset","creator_name":"devngho","creator_url":"https://huggingface.co/devngho","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\t옛한글 데이터셋\\n\\t\\n\\noriginal(HERE) | cleaned\\n위키문헌을 기반으로 구축한 옛한글 데이터셋\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\t불러오기\\n\\t\\n\\nfrom datasets import load_dataset\\n\\nds = load_dataset(\\\"devngho/oldhangul-dataset\\\", \\\"wikisource_v2\\\")\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\t라이선스\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\t데이터셋\\n\\t\\n\\nCC BY-SA 4.0 DEED\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\t자료\\n\\t\\n\\n위키문헌 기여자, 위키문헌 / CC BY-SA 4.0 DEED \\ncleaned 버전은 한자 비율이 20% 이상인 것을 걸러내고 <br>, 여러 줄의 \\\\n 등을 정리했습니다.\\n데이터의 license 필드에서 위키문헌 링크와 원본 자료 위치를 확인할 수 있습니다.\\n"},
	{"name":"oldhangul-dataset-cleaned","keyword":"korean","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/devngho/oldhangul-dataset-cleaned","creator_name":"devngho","creator_url":"https://huggingface.co/devngho","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\t옛한글 데이터셋\\n\\t\\n\\noriginal | cleaned(HERE)\\n위키문헌을 기반으로 구축한 옛한글 데이터셋\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\t불러오기\\n\\t\\n\\nfrom datasets import load_dataset\\n\\nds = load_dataset(\\\"devngho/oldhangul-dataset-cleaned\\\", \\\"wikisource_v2\\\")\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\t라이선스\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\t데이터셋\\n\\t\\n\\nCC BY-SA 4.0 DEED\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\t자료\\n\\t\\n\\n위키문헌 기여자, 위키문헌 / CC BY-SA 4.0 DEED \\ncleaned 버전은 한자 비율이 20% 이상인 것을 걸러내고 <br>, 여러 줄의 \\\\n 등을 정리했습니다.\\n데이터의 license 필드에서 위키문헌 링크와 원본 자료 위치를 확인할 수 있습니다.\\n"},
	{"name":"pokemon-blip-captions-en-ko","keyword":"korean","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/letgoofthepizza/pokemon-blip-captions-en-ko","creator_name":"lee noah","creator_url":"https://huggingface.co/letgoofthepizza","description":"letgoofthepizza/pokemon-blip-captions-en-ko dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"TinyStories-Korean","keyword":"korean","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/g0ster/TinyStories-Korean","creator_name":"Dohoon Kim","creator_url":"https://huggingface.co/g0ster","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tTinyStories-Korean\\n\\t\\n\\n\\n\\nThis dataset is a translated version of roneneldan's TinyStories dataset.\\nI first downloaded roneneldan's TinyStories, and I organized it in a db file. Then I used a local transalation model eeve\\n to translate, and I changed it back to a txt file.\\nFeel free to use!\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tCitation\\n\\t\\n\\n@misc{kim2024tinystories,\\n      title={TinyStories Korean translations}, \\n      author={Dohoon Kim(g0ster)},\\n      year={2024},\\n}\\n\\n"},
	{"name":"NTREX","keyword":"korean","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/NTREX","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nNTREX -- News Test References for MT Evaluation from English into a total of 128 target languages. See original GitHub repo for full details.\\nExample of loading:\\ndataset = load_dataset(\\\"davidstap/NTREX\\\", \\\"rus_Cyrl\\\", trust_remote_code=True)\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages\\n\\t\\n\\nThe following languages are available:\\n\\n\\t\\n\\t\\t\\nLanguage Code\\nLanguage Name\\n\\n\\n\\t\\t\\nafr_Latn\\nAfrikaans\\n\\n\\namh_Ethi\\nAmharic\\n\\n\\narb_Arab\\nArabic\\n\\n\\naze_Latn\\nAzerbaijani\\n\\n\\nbak_Cyrl\\nBashkir\\n\\n\\nbel_Cyrl\\nBelarusian… See the full description on the dataset page: https://huggingface.co/datasets/mteb/NTREX."},
	{"name":"ParaNames","keyword":"korean","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/bltlab/ParaNames","creator_name":"Broadening Linguistic Technologies Lab (BLT Lab)","creator_url":"https://huggingface.co/bltlab","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Dataset Name\\n\\t\\n\\n\\n\\nThis dataset card aims to be a base template for new datasets. It has been generated using this raw template.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Details\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\n\\n\\n\\n\\n\\nCurated by: [More Information Needed]\\nFunded by [optional]: [More Information Needed]\\nShared by [optional]: [More Information Needed]\\nLanguage(s) (NLP): [More Information Needed]\\nLicense: [More Information Needed]\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Sources [optional]… See the full description on the dataset page: https://huggingface.co/datasets/bltlab/ParaNames."},
	{"name":"xm3600","keyword":"korean","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/floschne/xm3600","creator_name":"Flo Schneider","creator_url":"https://huggingface.co/floschne","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tXM3600 - Crossmodal-3600\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tThis is a copy from https://google.github.io/crossmodal-3600/\\n\\t\\n\\nIf you use this dataset, please cite the original authors:\\n@inproceedings{ThapliyalCrossmodal2022,\\n  author = {Ashish Thapliyal and Jordi Pont-Tuset and Xi Chen and Radu Soricut},\\n  title = {{Crossmodal-3600: A Massively Multilingual Multimodal Evaluation Dataset}},\\n  booktitle = {EMNLP},\\n  year = {2022}\\n}\\n\\nIt also includes the image features as PIL Image and has a uniform and… See the full description on the dataset page: https://huggingface.co/datasets/floschne/xm3600."},
	{"name":"xm3600_1k","keyword":"korean","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/floschne/xm3600_1k","creator_name":"Flo Schneider","creator_url":"https://huggingface.co/floschne","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tXM3600 - Crossmodal-3600 - 1K Split\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tThis is a copy from https://google.github.io/crossmodal-3600/\\n\\t\\n\\nIf you use this dataset, please cite the original authors:\\n@inproceedings{ThapliyalCrossmodal2022,\\n  author = {Ashish Thapliyal and Jordi Pont-Tuset and Xi Chen and Radu Soricut},\\n  title = {{Crossmodal-3600: A Massively Multilingual Multimodal Evaluation Dataset}},\\n  booktitle = {EMNLP},\\n  year = {2022}\\n}\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tThis is a 1K split of XM3600!\\n\\t\\n\\nFor this, we… See the full description on the dataset page: https://huggingface.co/datasets/floschne/xm3600_1k."},
	{"name":"xgqa","keyword":"korean","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/floschne/xgqa","creator_name":"Flo Schneider","creator_url":"https://huggingface.co/floschne","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\txGQA\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tThis is a clone of the few_shot-test split of the xGQA dataset\\n\\t\\n\\nPlease find the original repository here: https://github.com/adapter-hub/xGQA\\nIf you use this dataset, please cite the original authors:\\n@inproceedings{pfeiffer-etal-2021-xGQA,\\n    title={{xGQA: Cross-Lingual Visual Question Answering}},\\n    author={ Jonas Pfeiffer and Gregor Geigle and Aishwarya Kamath and Jan-Martin O. Steitz and Stefan Roth and Ivan Vuli{\\\\'{c}} and Iryna Gurevych}… See the full description on the dataset page: https://huggingface.co/datasets/floschne/xgqa."},
	{"name":"font_valid_10000","keyword":"korean","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/jayhii/font_valid_10000","creator_name":"jay smith","creator_url":"https://huggingface.co/jayhii","description":"jayhii/font_valid_10000 dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"aihub-flores-koen-integrated-prime-base-300k","keyword":"korean","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/traintogpb/aihub-flores-koen-integrated-prime-base-300k","creator_name":"Sehyeong Kim","creator_url":"https://huggingface.co/traintogpb","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tHigh Quality Ko-En Translation Dataset (AIHub-FLoRes Integrated)\\n\\t\\n\\nAI Hub의 한-영 번역 데이터셋과 FLoRes 한-영 번역 데이터셋의 합본입니다.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tHigh Quality AIHub Dataset\\n\\t\\n\\nAI Hub의 경우 한-영 번역 관련 데이터셋을 8개 병합한 병렬 데이터 traintogpb/aihub-koen-translation-integrated-mini-1m에서 고품질의 번역 레퍼런스를 가진 데이터만 추출하였습니다.\\n번역 레퍼런스 품질 평가 척도는 Unbabel/XCOMET-XL (3.5B)로 측정한 xCOMET metric입니다.\\n8개의 AIHub 데이터 소스의 구성 비율은 실험을 통해 확보한 번역 성능(SacreBLEU)에 따라 차등을 두었습니다.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tFLoRes Dataset\\n\\t\\n\\nFLoRes-200 데이터셋의 경우 997개의 dev, 1… See the full description on the dataset page: https://huggingface.co/datasets/traintogpb/aihub-flores-koen-integrated-prime-base-300k."},
	{"name":"xgqa_1k","keyword":"korean","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/floschne/xgqa_1k","creator_name":"Flo Schneider","creator_url":"https://huggingface.co/floschne","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\txGQA 1K\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tThis is a 1K subset of the few_shot-test split of the xGQA dataset\\n\\t\\n\\nPlease find the original repository here: https://github.com/adapter-hub/xGQA\\nIf you use this dataset, please cite the original authors:\\n@inproceedings{pfeiffer-etal-2021-xGQA,\\n    title={{xGQA: Cross-Lingual Visual Question Answering}},\\n    author={ Jonas Pfeiffer and Gregor Geigle and Aishwarya Kamath and Jan-Martin O. Steitz and Stefan Roth and Ivan Vuli{\\\\'{c}} and Iryna Gurevych}… See the full description on the dataset page: https://huggingface.co/datasets/floschne/xgqa_1k."},
	{"name":"from-one-to-many-toxicity-mitigation","keyword":"korean","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/luizapzbn/from-one-to-many-toxicity-mitigation","creator_name":"Luiza Pozzobon","creator_url":"https://huggingface.co/luizapzbn","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tFrom One to Many: Expanding the Scope of Toxicity Mitigation in Language Models\\n\\t\\n\\n[arxiv][code][data]\\nData accompanying the paper \\\"From One to Many: Expanding the Scope of Toxicity Mitigation in Language Models\\\" accepted to ACL Findings 2024.\\nAbstract: To date, toxicity mitigation in language models has almost entirely been focused on single-language settings. As language models embrace multilingual capabilities, it’s crucial our safety measures keep pace. Recognizing this… See the full description on the dataset page: https://huggingface.co/datasets/luizapzbn/from-one-to-many-toxicity-mitigation."},
	{"name":"BD-EnKo","keyword":"korean","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/shreyanshu09/BD-EnKo","creator_name":"Shreyanshu Bhushan","creator_url":"https://huggingface.co/shreyanshu09","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tBD-EnKo Dataset\\n\\t\\n\\nIt was introduced in the paper \\\"Unveiling the Power of Integration: Block Diagram Summarization through Local-Global Fusion\\\" accepted at ACL 2024. The full code is available in BD-EnKo github repository.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset description\\n\\t\\n\\nThis dataset contains different types of block diagram images with their high-quality summaries.\\n\\n\\t\\n\\t\\t\\nTypes\\nTrain\\n\\nValidation\\n\\n\\n\\n\\t\\t\\n\\nEnglish\\nKorean\\nEnglish\\nKorean\\n\\n\\n-----------------\\n---------\\n--------\\n------------\\n---------… See the full description on the dataset page: https://huggingface.co/datasets/shreyanshu09/BD-EnKo."},
	{"name":"bccard-qna-augmented","keyword":"korean","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/sh2orc/bccard-qna-augmented","creator_name":"Taeyoung Lee","creator_url":"https://huggingface.co/sh2orc","description":"Data Augmented BC Card Q&A Dataset by BERT Insertion \\n\\nKorean\\nPayment\\n\\n"},
	{"name":"aihub-koja-translation-integrated-large-4.3m","keyword":"korean","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/traintogpb/aihub-koja-translation-integrated-large-4.3m","creator_name":"Sehyeong Kim","creator_url":"https://huggingface.co/traintogpb","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tAI Hub Ko-Ja Translation Dataset (Integrated)\\n\\t\\n\\nAI Hub의 한-일 번역 관련 데이터셋 10개를 병합한 자료입니다. 병합 시 총 데이터 개수는 4,339,465개이며, 이중 10,000개의 validation set와 2,000개의 test set가 분리되어 모든 데이터 사이즈(large-4.3m, base-1m, small-100k)에서 동일하게 사용됩니다.\\n\\nlarge-4.3m (train): 병합 데이터 100% 사용; 총 4,327,465개\\n\\nbase-1m (train): 병합 데이터 중 1M개 사용; 총 1,000,000개\\n\\nsmall-100k (train): 병합 데이터 중 100K개 사용; 총 100,000개\\n\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSubsets\\n\\t\\n\\n\\n\\t\\n\\t\\t\\nName\\nTotal Size\\nJapanese Size (Utilized Only)\\nURL\\nDatasetkey (AIHub)… See the full description on the dataset page: https://huggingface.co/datasets/traintogpb/aihub-koja-translation-integrated-large-4.3m."},
	{"name":"aihub-kozh-translation-integrated-large-5.9m","keyword":"korean","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/traintogpb/aihub-kozh-translation-integrated-large-5.9m","creator_name":"Sehyeong Kim","creator_url":"https://huggingface.co/traintogpb","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tAI Hub Ko-Zh Translation Dataset (Integrated)\\n\\t\\n\\nAI Hub의 한-중 번역 관련 데이터셋 10개를 병합한 자료입니다. 병합 시 총 데이터 개수는 5,934,596개이며, 이중 10,000개의 validation set와 2,000개의 test set가 분리되어 모든 데이터 사이즈(large-5.9m, base-1m, small-100k)에서 동일하게 사용됩니다.\\n\\nlarge-5.9m (train): 병합 데이터 100% 사용; 총 5,922,596개\\n\\nbase-1m (train): 병합 데이터 중 1M개 사용; 총 1,000,000개\\n\\nsmall-100k (train): 병합 데이터 중 100K개 사용; 총 100,000개\\n\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSubsets\\n\\t\\n\\n\\n\\t\\n\\t\\t\\nName\\nTotal Size\\nChinese Size (Utilized Only)\\nURL\\nDatasetkey (AIHub)\\n\\n\\n\\t\\t\\n한국어-중국어… See the full description on the dataset page: https://huggingface.co/datasets/traintogpb/aihub-kozh-translation-integrated-large-5.9m."},
	{"name":"aihub-koja-translation-integrated-base-1m","keyword":"korean","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/traintogpb/aihub-koja-translation-integrated-base-1m","creator_name":"Sehyeong Kim","creator_url":"https://huggingface.co/traintogpb","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tAI Hub Ko-Ja Translation Dataset (Integrated)\\n\\t\\n\\nAI Hub의 한-일 번역 관련 데이터셋 10개를 병합한 자료입니다. 병합 시 총 데이터 개수는 4,339,465개이며, 이중 10,000개의 validation set와 2,000개의 test set가 분리되어 모든 데이터 사이즈(large-4.3m, base-1m, small-100k)에서 동일하게 사용됩니다.\\n\\nlarge-4.3m (train): 병합 데이터 100% 사용; 총 4,327,465개\\n\\nbase-1m (train): 병합 데이터 중 1M개 사용; 총 1,000,000개\\n\\nsmall-100k (train): 병합 데이터 중 100K개 사용; 총 100,000개\\n\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSubsets\\n\\t\\n\\n\\n\\t\\n\\t\\t\\nName\\nTotal Size\\nJapanese Size (Utilized Only)\\nURL\\nDatasetkey (AIHub)… See the full description on the dataset page: https://huggingface.co/datasets/traintogpb/aihub-koja-translation-integrated-base-1m."},
	{"name":"aihub-koja-translation-integrated-small-100k","keyword":"korean","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/traintogpb/aihub-koja-translation-integrated-small-100k","creator_name":"Sehyeong Kim","creator_url":"https://huggingface.co/traintogpb","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tAI Hub Ko-Ja Translation Dataset (Integrated)\\n\\t\\n\\nAI Hub의 한-일 번역 관련 데이터셋 10개를 병합한 자료입니다. 병합 시 총 데이터 개수는 4,339,465개이며, 이중 10,000개의 validation set와 2,000개의 test set가 분리되어 모든 데이터 사이즈(large-4.3m, base-1m, small-100k)에서 동일하게 사용됩니다.\\n\\nlarge-4.3m (train): 병합 데이터 100% 사용; 총 4,327,465개\\n\\nbase-1m (train): 병합 데이터 중 1M개 사용; 총 1,000,000개\\n\\nsmall-100k (train): 병합 데이터 중 100K개 사용; 총 100,000개\\n\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSubsets\\n\\t\\n\\n\\n\\t\\n\\t\\t\\nName\\nTotal Size\\nJapanese Size (Utilized Only)\\nURL\\nDatasetkey (AIHub)… See the full description on the dataset page: https://huggingface.co/datasets/traintogpb/aihub-koja-translation-integrated-small-100k."},
	{"name":"aihub-kozh-translation-integrated-base-1m","keyword":"korean","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/traintogpb/aihub-kozh-translation-integrated-base-1m","creator_name":"Sehyeong Kim","creator_url":"https://huggingface.co/traintogpb","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tAI Hub Ko-Zh Translation Dataset (Integrated)\\n\\t\\n\\nAI Hub의 한-중 번역 관련 데이터셋 10개를 병합한 자료입니다. 병합 시 총 데이터 개수는 5,934,596개이며, 이중 10,000개의 validation set와 2,000개의 test set가 분리되어 모든 데이터 사이즈(large-5.9m, base-1m, small-100k)에서 동일하게 사용됩니다.\\n\\nlarge-5.9m (train): 병합 데이터 100% 사용; 총 5,922,596개\\n\\nbase-1m (train): 병합 데이터 중 1M개 사용; 총 1,000,000개\\n\\nsmall-100k (train): 병합 데이터 중 100K개 사용; 총 100,000개\\n\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSubsets\\n\\t\\n\\n\\n\\t\\n\\t\\t\\nName\\nTotal Size\\nChinese Size (Utilized Only)\\nURL\\nDatasetkey (AIHub)\\n\\n\\n\\t\\t\\n한국어-중국어… See the full description on the dataset page: https://huggingface.co/datasets/traintogpb/aihub-kozh-translation-integrated-base-1m."},
	{"name":"aihub-kozh-translation-integrated-small-100k","keyword":"korean","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/traintogpb/aihub-kozh-translation-integrated-small-100k","creator_name":"Sehyeong Kim","creator_url":"https://huggingface.co/traintogpb","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tAI Hub Ko-Zh Translation Dataset (Integrated)\\n\\t\\n\\nAI Hub의 한-중 번역 관련 데이터셋 10개를 병합한 자료입니다. 병합 시 총 데이터 개수는 5,934,596개이며, 이중 10,000개의 validation set와 2,000개의 test set가 분리되어 모든 데이터 사이즈(large-5.9m, base-1m, small-100k)에서 동일하게 사용됩니다.\\n\\nlarge-5.9m (train): 병합 데이터 100% 사용; 총 5,922,596개\\n\\nbase-1m (train): 병합 데이터 중 1M개 사용; 총 1,000,000개\\n\\nsmall-100k (train): 병합 데이터 중 100K개 사용; 총 100,000개\\n\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSubsets\\n\\t\\n\\n\\n\\t\\n\\t\\t\\nName\\nTotal Size\\nChinese Size (Utilized Only)\\nURL\\nDatasetkey (AIHub)\\n\\n\\n\\t\\t\\n한국어-중국어… See the full description on the dataset page: https://huggingface.co/datasets/traintogpb/aihub-kozh-translation-integrated-small-100k."},
	{"name":"danbooru_wikis_full","keyword":"korean","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/deepghs/danbooru_wikis_full","creator_name":"DeepGHS","creator_url":"https://huggingface.co/deepghs","description":"\\n\\t\\n\\t\\t\\n\\t\\tDanbooru Full Wiki Dataset\\n\\t\\n\\nThis is the full wiki dataset of danbooru.donmai.us, containing the wiki pages/tags/tag aliases/tag implications. You can train something like LLMs on this dataset\\n\\n\\t\\n\\t\\t\\n\\t\\tInformation\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tWiki Pages\\n\\t\\n\\nThere are 189161 wiki items in total. Last updated at 2024-06-16 02:31:27 UTC.\\nThese are the information of recent 50 wiki items:\\n\\n\\t\\n\\t\\t\\nid\\ntitle\\nother_names\\ntext_length\\nis_locked\\nis_deleted\\ncreated_at\\nupdated_at\\n\\n\\n\\t\\t\\n196503\\nli_yuting_(female)\\n[\\\"离雨婷\\\"… See the full description on the dataset page: https://huggingface.co/datasets/deepghs/danbooru_wikis_full."},
	{"name":"M3GIA","keyword":"korean","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Songweii/M3GIA","creator_name":"Wei Song","creator_url":"https://huggingface.co/Songweii","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tM3GIA: A Cognition Inspired Multilingual and Multimodal General Intelligence Ability\\n\\t\\n\\n[🌐 Homepage] | 🤗 Dataset | 🤗 Paper | 📖 arXiv | 💻 GitHub\\nThe evaluation code can be found in 💻 GitHub.\\n[Abstract]\\nAs recent multi-modality large language models (MLLMs) have shown formidable proficiency on various complex tasks, there has been increasing attention on debating whether these models could eventually mirror human intelligence. However, existing benchmarks mainly focus on… See the full description on the dataset page: https://huggingface.co/datasets/Songweii/M3GIA."},
	{"name":"Chatgpt","keyword":"korean","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/RajChat/Chatgpt","creator_name":"Rajdeep Chatterjee ","creator_url":"https://huggingface.co/RajChat","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tOpenAssistant Conversations Dataset (OASST1)\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nIn an effort to democratize research on large-scale alignment, we release OpenAssistant \\nConversations (OASST1), a human-generated, human-annotated assistant-style conversation \\ncorpus consisting of 161,443 messages in 35 different languages, annotated with 461,292 \\nquality ratings, resulting in over 10,000 fully annotated conversation trees. The corpus \\nis a product of a worldwide crowd-sourcing effort… See the full description on the dataset page: https://huggingface.co/datasets/RajChat/Chatgpt."},
	{"name":"korean_profanity_masking","keyword":"korean","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/hajun1020/korean_profanity_masking","creator_name":"Hajun Tae","creator_url":"https://huggingface.co/hajun1020","description":"hajun1020/korean_profanity_masking dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"BLEnD","keyword":"korean","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/nayeon212/BLEnD","creator_name":"Nayeon Lee","creator_url":"https://huggingface.co/nayeon212","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tBLEnD\\n\\t\\n\\nThis is the official repository of BLEnD: A Benchmark for LLMs on Everyday Knowledge in Diverse Cultures and Languages (Submitted to NeurIPS 2024 Datasets and Benchmarks Track).\\n24/12/05: Updated translation errors\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tAbout\\n\\t\\n\\n\\nLarge language models (LLMs) often lack culture-specific everyday knowledge, especially across diverse regions and non-English languages. Existing benchmarks for evaluating LLMs' cultural sensitivities are usually limited to a single… See the full description on the dataset page: https://huggingface.co/datasets/nayeon212/BLEnD."},
	{"name":"CaLMQA","keyword":"korean","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/shanearora/CaLMQA","creator_name":"Shane Arora","creator_url":"https://huggingface.co/shanearora","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\n\\n\\nCaLMQA is a long-form question answering (LFQA) dataset spanning 23 high- to low-resource languages. \\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Details\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nCaLMQA is an LFQA dataset with 2K questions from 23 languages, 11 high- to mid-resource and 12 low-resource.\\nQuestions are either culturally specific – uniquely or more likely to be asked by people of a specific\\nculture – or culturally agnostic (not culturally specific). These questions were… See the full description on the dataset page: https://huggingface.co/datasets/shanearora/CaLMQA."},
	{"name":"BAAI_bge-m3-6122024-ibs3-webapp","keyword":"korean","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/fine-tuned/BAAI_bge-m3-6122024-ibs3-webapp","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tBAAI_bge-m3-6122024-ibs3-webapp Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThe dataset \\\"Pet care\\\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tAssociated Model\\n\\t\\n\\nThis dataset was used to train the BAAI_bge-m3-6122024-ibs3-webapp model.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tHow to Use\\n\\t\\n\\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets library as follows:\\nfrom datasets… See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/BAAI_bge-m3-6122024-ibs3-webapp."},
	{"name":"aya_collection_korean","keyword":"korean","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/4n3mone/aya_collection_korean","creator_name":"yongsang yoo","creator_url":"https://huggingface.co/4n3mone","description":"CohereForAI/aya_collection_language_split 에서 한국어 스플릿만 추출한 데이터셋 입니다.\\n데이처 출처(dataset name)는 다음과 같습니다. (번역된 데이터셋은 (T) 표시)\\nAya-Dataset\\nFlan-CoT-submix(T)\\nAdversarial QA(T)\\nFlan-Coqa(T)\\nFlan-unified-QA(T)\\nFlan-GEM-wiki-lingua(T)\\nCNN-Daily-Mail(T)\\nWIKI QA(T)\\nPAWS-Wiki(T)\\nWiki-split-inst(T)\\nNTX-LLM-inst\\nHotpotQA(T)\\nNQ-Open(T)\\nJoke-explaination-inst(T)\\nMLQA-en(T)\\nSODA-inst(T)\\nXlel_wd-inst\\nFlan-lambada(T)\\nXlel_wd-inst(T)\\nMintaka-inst(T)\\nPIQA(T)\\nDolly-v2(T)\\n"},
	{"name":"BAAI_bge-m3-6142024-0ndt-webapp","keyword":"korean","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/fine-tuned/BAAI_bge-m3-6142024-0ndt-webapp","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tBAAI_bge-m3-6142024-0ndt-webapp Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThe dataset \\\"content moderation\\\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tAssociated Model\\n\\t\\n\\nThis dataset was used to train the BAAI_bge-m3-6142024-0ndt-webapp model.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tHow to Use\\n\\t\\n\\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets library as follows:\\nfrom… See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/BAAI_bge-m3-6142024-0ndt-webapp."},
	{"name":"BAAI_bge-m3-6142024-0ndt-webapp","keyword":"korean","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/fine-tuned/BAAI_bge-m3-6142024-0ndt-webapp","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tBAAI_bge-m3-6142024-0ndt-webapp Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThe dataset \\\"content moderation\\\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tAssociated Model\\n\\t\\n\\nThis dataset was used to train the BAAI_bge-m3-6142024-0ndt-webapp model.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tHow to Use\\n\\t\\n\\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets library as follows:\\nfrom… See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/BAAI_bge-m3-6142024-0ndt-webapp."},
	{"name":"bitext_sib200_miners","keyword":"korean","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/gentaiscool/bitext_sib200_miners","creator_name":"Genta Indra Winata","creator_url":"https://huggingface.co/gentaiscool","description":"gentaiscool/bitext_sib200_miners dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"ko-code-alpaca-QA","keyword":"korean","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/CarrotAI/ko-code-alpaca-QA","creator_name":"CarrotCarrot","creator_url":"https://huggingface.co/CarrotAI","description":"code-alpaca QA 데이터셋입니다. \\n필터링이 어느정도 필요합니다.\\n참고하시고 사용하시면 됩니다.\\n"},
	{"name":"fleurs_clean","keyword":"korean","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Helloworld668/fleurs_clean","creator_name":"zhide Tang","creator_url":"https://huggingface.co/Helloworld668","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tFLEURS\\n\\t\\n\\nFleurs is the speech version of the FLoRes machine translation benchmark. \\nWe use 2009 n-way parallel sentences from the FLoRes dev and devtest publicly available sets, in 102 languages. \\nTraining sets have around 10 hours of supervision. Speakers of the train sets are different than speakers from the dev/test sets. Multilingual fine-tuning is\\nused and ”unit error rate” (characters, signs) of all languages is averaged. Languages and results are also grouped into seven… See the full description on the dataset page: https://huggingface.co/datasets/Helloworld668/fleurs_clean."},
	{"name":"Image-Detailed-Description-Korean","keyword":"korean","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Nagase-Kotono/Image-Detailed-Description-Korean","creator_name":"Nagase_Kotono","creator_url":"https://huggingface.co/Nagase-Kotono","description":"\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tImage-Detailed-Description-Korean\\n\\t\\n\\nLLaVA-NeXT에 적혀있는 내용중 High-Quality Knowledge Learning부분에 다음의 내용이 있습니다:  \\n\\nEnhanced Performance with Recaptioned Data  \\n\\nModels trained with recaptioned data (ReCap) datasets, show a trend of enhanced performance in tasks requiring detailed image descriptions and document understanding.  \\nThe regenerated captions, ranging from 118K to 3M, demonstrate better scaling behaviors than the original captions, consistently improve model performance… See the full description on the dataset page: https://huggingface.co/datasets/Nagase-Kotono/Image-Detailed-Description-Korean."},
	{"name":"xP3x-Kongo","keyword":"korean","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Svngoku/xP3x-Kongo","creator_name":"NIONGOLO Chrys Fé-Marty","creator_url":"https://huggingface.co/Svngoku","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for xP3x Kikongo Focus\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\n\\nxP3x (Crosslingual Public Pool of Prompts eXtended) is a collection of prompts & datasets across 277 languages & 16 NLP tasks. It contains all of xP3 + much more! It is used for training future contenders of mT0 & BLOOMZ at project Aya @C4AI 🧡\\n\\n\\nCreation: The dataset can be recreated using instructions available here together with the file in this repository named xp3x_create.py. We provide this version to save… See the full description on the dataset page: https://huggingface.co/datasets/Svngoku/xP3x-Kongo."},
	{"name":"Korean-1930-Novel-Scene-Summarize","keyword":"korean","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/werty1248/Korean-1930-Novel-Scene-Summarize","creator_name":"Dohyung Kim","creator_url":"https://huggingface.co/werty1248","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\t한국 저작권 만료 소설에 대한 씬 분리 및 요약 데이터 셋\\n\\t\\n\\n\\n원천 데이터 출처: https://gongu.copyright.or.kr/gongu/wrt/wrtCl/listWrtText.do?menuNo=200019\\n총 96개 소설 수집 및 전처리\\n한자가 많은 소설 제외\\n한자 제거, 띄어쓰기 전처리 수행\\n\\n\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\t씬 분리\\n\\t\\n\\n\\n사용 모델: Gemini-1.5-Flash\\n(띄어쓰기 포함) 100자 이상, 1200자 미만으로 적절한 문장에서 씬 단위로 분리하도록 지시\\n총 12,108씬 생성\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\t요약\\n\\t\\n\\n\\n사용 모델: Gemini-1.5-Flash(때때로 GPT-4o)\\n각 Scene에서 인물, 주요 소품, 사건을 추출하고, 요약(scenario)을 생성하도록 함\\n\\n"},
	{"name":"contextual-dpo-v0.1-ko","keyword":"korean","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/nayohan/contextual-dpo-v0.1-ko","creator_name":"Yohan Na","creator_url":"https://huggingface.co/nayohan","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for \\\"contextual-dpo-v0.1-ko\\\"\\n\\t\\n\\nTranslated jondurbin/contextual-dpo-v0.1 using nayohan/llama3-instrucTrans-enko-8b.\\n"},
	{"name":"HC3-ko","keyword":"korean","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/nayohan/HC3-ko","creator_name":"Yohan Na","creator_url":"https://huggingface.co/nayohan","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for \\\"HC3\\\"\\n\\t\\n\\nTranslated Hello-SimpleAI/HC3 using nayohan/llama3-instrucTrans-enko-8b.\\n"},
	{"name":"SentimentSynth-ko","keyword":"korean","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/nayohan/SentimentSynth-ko","creator_name":"Yohan Na","creator_url":"https://huggingface.co/nayohan","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for \\\"SentimentSynth\\\"\\n\\t\\n\\nTranslated OEvortex/SentimentSynth using nayohan/llama3-instrucTrans-enko-8b.\\n"},
	{"name":"Neural-DPO-ko","keyword":"korean","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/nayohan/Neural-DPO-ko","creator_name":"Yohan Na","creator_url":"https://huggingface.co/nayohan","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for \\\"Neural-DPO\\\"\\n\\t\\n\\nTranslated NeuralNovel/Neural-DPO using nayohan/llama3-instrucTrans-enko-8b.\\n"},
	{"name":"Maths-College-ko","keyword":"korean","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/nayohan/Maths-College-ko","creator_name":"Yohan Na","creator_url":"https://huggingface.co/nayohan","description":"Translated 5% ajibawa-2023/Maths-College using nayohan/llama3-instrucTrans-enko-8b.\\n"},
	{"name":"Sujet-Finance-Instruct-177k-ko","keyword":"korean","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/nayohan/Sujet-Finance-Instruct-177k-ko","creator_name":"Yohan Na","creator_url":"https://huggingface.co/nayohan","description":"Translated sujet-ai/Sujet-Finance-Instruct-177k using nayohan/llama3-instrucTrans-enko-8b.\\nIt may contain repetitive sentences, so recommend filtering them.\\n"},
	{"name":"luckyvicky","keyword":"korean","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Junnos/luckyvicky","creator_name":"이창준","creator_url":"https://huggingface.co/Junnos","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\t원영적 사고 데이터셋\\n\\t\\n\\n"},
	{"name":"hf-first","keyword":"korean","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/kenu/hf-first","creator_name":"Kenu Gwangnam Heo","creator_url":"https://huggingface.co/kenu","description":"kenu/hf-first dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"Multilingual-Benchmark","keyword":"korean","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/TaiMingLu/Multilingual-Benchmark","creator_name":"TaiMing","creator_url":"https://huggingface.co/TaiMingLu","description":"These are the GSM8K and ARC dataset translated by Google Translate. \\nBibTex\\n@misc{lu2024languagecountslearnunlearn,\\n      title={Every Language Counts: Learn and Unlearn in Multilingual LLMs}, \\n      author={Taiming Lu and Philipp Koehn},\\n      year={2024},\\n      eprint={2406.13748},\\n      archivePrefix={arXiv},\\n      primaryClass={cs.CL},\\n      url={https://arxiv.org/abs/2406.13748}, \\n}\\n\\n"},
	{"name":"KoSBi-v2","keyword":"korean","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/nayohan/KoSBi-v2","creator_name":"Yohan Na","creator_url":"https://huggingface.co/nayohan","description":"reference: https://github.com/naver-ai/korean-safety-benchmarks\\n@inproceedings{lee2023kosbi,\\n                title={KoSBi: A Dataset for Mitigating Social Bias Risks Towards Safer Large Language Model Application}, \\n                author={Hwaran Lee and Seokhee Hong and Joonsuk Park and Takyoung Kim and Gunhee Kim and Jung-Woo Ha},\\n                booktitle={Proceedings of the 61th Annual Meeting of the Association for Computational Linguistics: Industry Track},\\n                year={2023}\\n}\\n\\n"},
	{"name":"KoSBi","keyword":"korean","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/nayohan/KoSBi","creator_name":"Yohan Na","creator_url":"https://huggingface.co/nayohan","description":"reference: https://github.com/naver-ai/korean-safety-benchmarks\\n@inproceedings{lee2023kosbi,\\n                title={KoSBi: A Dataset for Mitigating Social Bias Risks Towards Safer Large Language Model Application}, \\n                author={Hwaran Lee and Seokhee Hong and Joonsuk Park and Takyoung Kim and Gunhee Kim and Jung-Woo Ha},\\n                booktitle={Proceedings of the 61th Annual Meeting of the Association for Computational Linguistics: Industry Track},\\n                year={2023}\\n}\\n\\n"},
	{"name":"SQuARe-question","keyword":"korean","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/nayohan/SQuARe-question","creator_name":"Yohan Na","creator_url":"https://huggingface.co/nayohan","description":"reference: https://github.com/naver-ai/korean-safety-benchmarks\\n@inproceedings{lee2023square,\\n                title={SQuARe: A Large-Scale Dataset of Sensitive Questions and Acceptable Responses Created Through Human-Machine Collaboration}, \\n                author={Hwaran Lee and Seokhee Hong and Joonsuk Park and Takyoung Kim and Meeyoung Cha and Yejin Choi and Byoung Pil Kim and Gunhee Kim and Eun-Ju Lee and Yong Lim and Alice Oh and Sangchul Park and Jung-Woo Ha}… See the full description on the dataset page: https://huggingface.co/datasets/nayohan/SQuARe-question."},
	{"name":"SQuARe-response","keyword":"korean","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/nayohan/SQuARe-response","creator_name":"Yohan Na","creator_url":"https://huggingface.co/nayohan","description":"reference: https://github.com/naver-ai/korean-safety-benchmarks\\n@inproceedings{lee2023square,\\n                title={SQuARe: A Large-Scale Dataset of Sensitive Questions and Acceptable Responses Created Through Human-Machine Collaboration}, \\n                author={Hwaran Lee and Seokhee Hong and Joonsuk Park and Takyoung Kim and Meeyoung Cha and Yejin Choi and Byoung Pil Kim and Gunhee Kim and Eun-Ju Lee and Yong Lim and Alice Oh and Sangchul Park and Jung-Woo Ha}… See the full description on the dataset page: https://huggingface.co/datasets/nayohan/SQuARe-response."},
	{"name":"korean-hate-speech","keyword":"korean","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/nayohan/korean-hate-speech","creator_name":"Yohan Na","creator_url":"https://huggingface.co/nayohan","description":"reference: https://github.com/kocohub/korean-hate-speech\\n@inproceedings{moon-etal-2020-beep,\\n    title = \\\"{BEEP}! {K}orean Corpus of Online News Comments for Toxic Speech Detection\\\",\\n    author = \\\"Moon, Jihyung  and\\n      Cho, Won Ik  and\\n      Lee, Junbum\\\",\\n    booktitle = \\\"Proceedings of the Eighth International Workshop on Natural Language Processing for Social Media\\\",\\n    month = jul,\\n    year = \\\"2020\\\",\\n    address = \\\"Online\\\",\\n    publisher = \\\"Association for Computational Linguistics\\\"… See the full description on the dataset page: https://huggingface.co/datasets/nayohan/korean-hate-speech."},
	{"name":"APEACH","keyword":"korean","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/nayohan/APEACH","creator_name":"Yohan Na","creator_url":"https://huggingface.co/nayohan","description":"reference: https://github.com/jason9693/APEACH\\n@inproceedings{yang-etal-2022-apeach,\\n    title = \\\"{APEACH}: Attacking Pejorative Expressions with Analysis on Crowd-Generated Hate Speech Evaluation Datasets\\\",\\n    author = \\\"Yang, Kichang  and\\n      Jang, Wonjun  and\\n      Cho, Won Ik\\\",\\n    booktitle = \\\"Findings of the Association for Computational Linguistics: EMNLP 2022\\\",\\n    month = dec,\\n    year = \\\"2022\\\",\\n    address = \\\"Abu Dhabi, United Arab Emirates\\\",\\n    publisher = \\\"Association for… See the full description on the dataset page: https://huggingface.co/datasets/nayohan/APEACH."},
	{"name":"luckyvicky-DPO","keyword":"korean","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Junnos/luckyvicky-DPO","creator_name":"이창준","creator_url":"https://huggingface.co/Junnos","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\t원영적 사고 데이터셋\\n\\t\\n\\n"},
	{"name":"alpaca_function_calling_dataset","keyword":"korean","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Saxo/alpaca_function_calling_dataset","creator_name":"Ji","creator_url":"https://huggingface.co/Saxo","description":"\\n\\n\\n  \\nAI 와 빅데이터 분석 전문 기업인 Linkbricks(www.linkbricks.com)의 데이터사이언티스트인 지윤성(Saxo) 박사가 만든 llm RAG를 위한 function calling 학습용 데이터셋으로 llam3 instruct format인 mzbac/function-calling-llama-3-format-v1.1 을 Alpaca Format으로 변경. \\nChanged the llam3 instruct format, mzbac/function-calling-llama-3-format-v1.1, to Alpaca Format as a dataset for learning function calling for the llm RAG, created by Dr. Ji Yun Sung(Saxo), a data scientist at Linkbricks (www.linkbricks.com), a company specializing in AI and big… See the full description on the dataset page: https://huggingface.co/datasets/Saxo/alpaca_function_calling_dataset."},
	{"name":"tydi_xor_rc","keyword":"korean","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/coastalcph/tydi_xor_rc","creator_name":"CoAStaL NLP Group","creator_url":"https://huggingface.co/coastalcph","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for \\\"tydi_xor_rc\\\"\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nTyDi QA is a question answering dataset covering 11 typologically diverse languages. \\nXORQA is an extension of the original TyDi QA dataset to also include unanswerable questions, where context documents are only in English but questions are in 7 languages.\\nXOR-AttriQA contains annotated attribution data for a sample of XORQA.\\nThis dataset is a combined and simplified version of the Reading Comprehension data from… See the full description on the dataset page: https://huggingface.co/datasets/coastalcph/tydi_xor_rc."},
	{"name":"MedQA","keyword":"korean","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ChuGyouk/MedQA","creator_name":"ChuGyouk","creator_url":"https://huggingface.co/ChuGyouk","description":"Original dataset introduced by Jin et al. in What Disease does this Patient Have? A Large-scale Open Domain Question Answering Dataset from Medical Exams\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tEn split\\n\\t\\n\\nJust edited columns. Contents are same.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tKo split\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tTrain\\n\\t\\n\\nThe train dataset is translated by \\\"solar-1-mini-translate-enko\\\".\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tTest\\n\\t\\n\\nThe test dataset is translated by DeepL Pro.\\nreference-free COMET score: 0.7989 (Unbabel/wmt23-cometkiwi-da-xxl)\\nCitation information:… See the full description on the dataset page: https://huggingface.co/datasets/ChuGyouk/MedQA."},
	{"name":"PubMedQA-test-Ko","keyword":"korean","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/ChuGyouk/PubMedQA-test-Ko","creator_name":"ChuGyouk","creator_url":"https://huggingface.co/ChuGyouk","description":"This is the test data of PubMedQA, Korean translated version.\\n"},
	{"name":"allist","keyword":"korean","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/gegeta/allist","creator_name":"ge","creator_url":"https://huggingface.co/gegeta","description":"gegeta/allist dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"multimuc4","keyword":"korean","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/jgermanmx/multimuc4","creator_name":"Jesus German Ortiz Barajas","creator_url":"https://huggingface.co/jgermanmx","description":"jgermanmx/multimuc4 dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"naver_review_sum","keyword":"korean","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/jr-d-analyst24/naver_review_sum","creator_name":"dayoungyoun","creator_url":"https://huggingface.co/jr-d-analyst24","description":"jr-d-analyst24/naver_review_sum dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"librivox-tracks","keyword":"korean","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/xacer/librivox-tracks","creator_name":"xacer","creator_url":"https://huggingface.co/xacer","description":"A dataset of all audio files uploaded to LibriVox before 26th September 2023.\\nForked from https://huggingface.co/datasets/pykeio/librivox-tracks\\nChanges:\\n\\nUsed archive.org metadata API to annotate rows with \\\"duration\\\" column\\n\\n"},
	{"name":"Pyhsics_Dataset","keyword":"korean","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Geniuss/Pyhsics_Dataset","creator_name":"Kim Yeongjun","creator_url":"https://huggingface.co/Geniuss","description":"Geniuss/Pyhsics_Dataset dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"fact-check-bureau","keyword":"korean","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/NaughtyConstrictor/fact-check-bureau","creator_name":"Younes","creator_url":"https://huggingface.co/NaughtyConstrictor","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tFact-Check Retrieval Dataset\\n\\t\\n\\nThis dataset is designed to support the development and evaluation of fact-check retrieval pipelines. It is structured to work with FactCheckBureau, a tool for designing and evaluating fact-check retrieval pipelines. The dataset comprises a list of claims, fact-check articles, and precomputed embeddings for English and French fact-checks.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Structure\\n\\t\\n\\nThe dataset consists of the following files and directories:\\n\\narticles.csv:… See the full description on the dataset page: https://huggingface.co/datasets/NaughtyConstrictor/fact-check-bureau."},
	{"name":"math-gpt-4o-200k-ko","keyword":"korean","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/nayohan/math-gpt-4o-200k-ko","creator_name":"Yohan Na","creator_url":"https://huggingface.co/nayohan","description":"Translated PawanKrd/math-gpt-4o-200k using nayohan/llama3-instrucTrans-enko-8b.\\nThis dataset is a raw translated dataset and contains repetitive sentences generated by the model, so it needs to be filtered.\\n"},
	{"name":"math-gpt-4o-200k-ko","keyword":"korean","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/nayohan/math-gpt-4o-200k-ko","creator_name":"Yohan Na","creator_url":"https://huggingface.co/nayohan","description":"Translated PawanKrd/math-gpt-4o-200k using nayohan/llama3-instrucTrans-enko-8b.\\nThis dataset is a raw translated dataset and contains repetitive sentences generated by the model, so it needs to be filtered.\\n"},
	{"name":"llama-custom-dataset","keyword":"korean","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/jiinnn/llama-custom-dataset","creator_name":"sanjin na","creator_url":"https://huggingface.co/jiinnn","description":"jiinnn/llama-custom-dataset dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"Constructionsafety_QApairs","keyword":"korean","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/DBCMLAB/Constructionsafety_QApairs","creator_name":"Hongik University, Data-based Construction Management LAB","creator_url":"https://huggingface.co/DBCMLAB","description":"This dataset was built based on the Construction Safety Guidelines published by KOSHA (Korean Occupational Safety and Health Administration).\\nThis is virtual QA pair dataset generated by GPT-3.5-turbo.\\n"},
	{"name":"kmmlu-conversation-sample","keyword":"korean","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/CarrotAI/kmmlu-conversation-sample","creator_name":"CarrotCarrot","creator_url":"https://huggingface.co/CarrotAI","description":"Kmmlu 데이터를 이용해서 대화 데이터셋 샘픔을 생성하였습니다.\\n멀티턴 데이터셋으로 학습용도로 만들어졌습니다.\\n"},
	{"name":"3kingdoms","keyword":"korean","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/jonhpark/3kingdoms","creator_name":"Jong Hyun Park","creator_url":"https://huggingface.co/jonhpark","description":"jonhpark/3kingdoms dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"zenless_zone_zero_interknots_v1.0","keyword":"korean","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mrzjy/zenless_zone_zero_interknots_v1.0","creator_name":"jiayi","creator_url":"https://huggingface.co/mrzjy","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tZZZ Interknots\\n\\t\\n\\nThis datasets contains extracted Interknot posts and comments (绳网的博客与评论) in multi-language.\\nUp to game version: 1.0\\n\\nInterknot posts and comments examples\\n\\n{\\n  \\\"id\\\": \\\"1021\\\",\\n  \\\"poster\\\": \\\"Sorrowful Intern\\\",\\n  \\\"title\\\": \\\"[Commission] Missing Bangboo merchants\\\",\\n  \\\"text\\\": \\\"Hello, pros... Some of the senior Bangboo of our merchant association have gone missing! We urgently need an expert to help find them!!\\\\nLet me explain, I recently joined a very prestigious… See the full description on the dataset page: https://huggingface.co/datasets/mrzjy/zenless_zone_zero_interknots_v1.0."},
	{"name":"OpenOrca-EnKoZhJa-18k","keyword":"korean","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/werty1248/OpenOrca-EnKoZhJa-18k","creator_name":"Dohyung Kim","creator_url":"https://huggingface.co/werty1248","description":"This dataset is a collection of Korean, Chinese, and Japanese OpenOrca translation datasets.\\nThe dataset was matched using id based on kyujinpy/OpenOrca-KO, which had the smallest number of rows.\\nWhen more than one translation existed for a language, I chose the more similar one based on similarity of embedding(BAAI/BGE-m3).\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Sources\\n\\t\\n\\n\\nEnglish(Original)\\nOpen-Orca/OpenOrca\\n\\n\\nKorean(Translated with DeepL Pro API)\\nkyujinpy/OpenOrca-KO\\n\\n\\nChinese(Translated with Google Translate)… See the full description on the dataset page: https://huggingface.co/datasets/werty1248/OpenOrca-EnKoZhJa-18k."},
	{"name":"MedQA-Evol-Korean","keyword":"korean","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/ChuGyouk/MedQA-Evol-Korean","creator_name":"ChuGyouk","creator_url":"https://huggingface.co/ChuGyouk","description":"\\n\\t\\n\\t\\t\\n\\t\\tMedQA-Evol\\n\\t\\n\\nOriginal Data: TsinghuaC3I/UltraMedical.\\nTranslated into Korean by \\\"solar-1-mini-translate-enko\\\".\\n"},
	{"name":"bccard-maywell-jojo0217-markai-lcw99-kendamarron-microsoft","keyword":"korean","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/sh2orc/bccard-maywell-jojo0217-markai-lcw99-kendamarron-microsoft","creator_name":"Taeyoung Lee","creator_url":"https://huggingface.co/sh2orc","description":"[Dataset merged]\\n\\nmaywell/ko_wikidata_QA\\njojo0217/korean_rlhf_dataset\\nBCCard/BCCard-Finance-Kor-QnA\\nMarkrAI/KoCommercial-Dataset\\nlcw99/wikipedia-korean-20240501-1million-qna\\nmaywell/gpt4_evol_1.3k\\nKendamarron/jimba-wiki-instruction-calm3\\nmicrosoft/orca-math-word-problems-200k\\npankajmathur/WizardLM_Orca\\n\\n"},
	{"name":"small_kitchen_appliances_review","keyword":"korean","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/jr-d-analyst24/small_kitchen_appliances_review","creator_name":"dayoungyoun","creator_url":"https://huggingface.co/jr-d-analyst24","description":"jr-d-analyst24/small_kitchen_appliances_review dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"small_kitchen_appliances_total_reviews","keyword":"korean","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/jr-d-analyst24/small_kitchen_appliances_total_reviews","creator_name":"dayoungyoun","creator_url":"https://huggingface.co/jr-d-analyst24","description":"jr-d-analyst24/small_kitchen_appliances_total_reviews dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"ai_hub_summ_train","keyword":"korean","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/jr-d-analyst24/ai_hub_summ_train","creator_name":"dayoungyoun","creator_url":"https://huggingface.co/jr-d-analyst24","description":"jr-d-analyst24/ai_hub_summ_train dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"wikipedia-ko","keyword":"korean","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/blueapple8259/wikipedia-ko","creator_name":"blueapple825","creator_url":"https://huggingface.co/blueapple8259","description":"blueapple8259/wikipedia-ko dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"ai_hub_narr_sum_vali","keyword":"korean","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/jr-d-analyst24/ai_hub_narr_sum_vali","creator_name":"dayoungyoun","creator_url":"https://huggingface.co/jr-d-analyst24","description":"jr-d-analyst24/ai_hub_narr_sum_vali dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"MedExpQA-Kor","keyword":"korean","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ChuGyouk/MedExpQA-Kor","creator_name":"ChuGyouk","creator_url":"https://huggingface.co/ChuGyouk","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tMedExpQA\\n\\t\\n\\nOriginal Data: HiTZ/MedExpQA\\nEn subset, train split and validation split are translated into Korean by \\\"solar-1-mini-translate-enko\\\".\\n"},
	{"name":"GenMedGPT-5k-ko","keyword":"korean","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/ChuGyouk/GenMedGPT-5k-ko","creator_name":"ChuGyouk","creator_url":"https://huggingface.co/ChuGyouk","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tMedQA-Evol\\n\\t\\n\\nOriginal Data: ChatDoctor.\\nTranslated into Korean by DeepL Pro.\\n"},
	{"name":"Asan-AMC-Healthinfo","keyword":"korean","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/ChuGyouk/Asan-AMC-Healthinfo","creator_name":"ChuGyouk","creator_url":"https://huggingface.co/ChuGyouk","description":"\\n\\t\\n\\t\\t\\n\\t\\tAsan-AMC-Healthinfo\\n\\t\\n\\nSource: 서울아산병원 건강정보.\\n서울아산병원 홈페이지의 건강정보-의료정보에서, 인체정보/질환백과/검사시술수술정보/알기쉬운의학용어/식사요법 데이터를 바탕으로\\nalpaca-style로 편집한 데이터입니다.\\n"},
	{"name":"KISS_delirium_papaers","keyword":"korean","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/gykwak03/KISS_delirium_papaers","creator_name":"곽가영","creator_url":"https://huggingface.co/gykwak03","description":"This is an abstract of a paper derived from a search for “delirium” in KISS (Koreanstudies Information Service System).\\n\\\"ko_data.csv\\\" is abstract in Korean, and \\\"en_data.csv\\\" is abstract in English.\\n"},
	{"name":"korean-judgment-easyread-transform","keyword":"korean","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Suchae/korean-judgment-easyread-transform","creator_name":"Jeong Suchae","creator_url":"https://huggingface.co/Suchae","description":"Suchae/korean-judgment-easyread-transform dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"muri-it-language-split","keyword":"korean","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/akoksal/muri-it-language-split","creator_name":"Abdullatif Koksal","creator_url":"https://huggingface.co/akoksal","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tMURI-IT: Multilingual Instruction Tuning Dataset for 200 Languages via Multilingual Reverse Instructions\\n\\t\\n\\nMURI-IT is a large-scale multilingual instruction tuning dataset containing 2.2 million instruction-output pairs across 200 languages. It is designed to address the challenges of instruction tuning in low-resource languages with Multilingual Reverse Instructions (MURI), which ensures that the output is human-written, high-quality, and authentic to the cultural and linguistic… See the full description on the dataset page: https://huggingface.co/datasets/akoksal/muri-it-language-split."},
	{"name":"ksponspeech-eval","keyword":"korean","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/yfyeung/ksponspeech-eval","creator_name":"Yifan Yang","creator_url":"https://huggingface.co/yfyeung","description":"paper link: https://www.mdpi.com/846876\\n"},
	{"name":"ko-coffee-QA","keyword":"korean","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/williamjeong2/ko-coffee-QA","creator_name":"jeong","creator_url":"https://huggingface.co/williamjeong2","description":"williamjeong2/ko-coffee-QA dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"ANSAN_WORK","keyword":"korean","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/poopki/ANSAN_WORK","creator_name":"mingu kang","creator_url":"https://huggingface.co/poopki","description":"poopki/ANSAN_WORK dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"korean-emotion-lexicon","keyword":"korean","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/jonghwanhyeon/korean-emotion-lexicon","creator_name":"Jonghwan Hyeon","creator_url":"https://huggingface.co/jonghwanhyeon","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tKorean Emotion Lexicon\\n\\t\\n\\nThis repository contains a comprehensive dataset of Korean emotion lexicons developed through psychological research conducted by In-jo Park and Kyung-Hwan Min from Seoul National University. The dataset includes several key measures for each emotion lexicon:\\n\\nlexicon: The lexicon that represents a specific emotion in the Korean language.\\nrepresentative: The degree to which the lexicon is a representative example of the emotion.\\nprototypicality: A rating… See the full description on the dataset page: https://huggingface.co/datasets/jonghwanhyeon/korean-emotion-lexicon."},
	{"name":"korean-emotion-lexicon","keyword":"korean","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/jonghwanhyeon/korean-emotion-lexicon","creator_name":"Jonghwan Hyeon","creator_url":"https://huggingface.co/jonghwanhyeon","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tKorean Emotion Lexicon\\n\\t\\n\\nThis repository contains a comprehensive dataset of Korean emotion lexicons developed through psychological research conducted by In-jo Park and Kyung-Hwan Min from Seoul National University. The dataset includes several key measures for each emotion lexicon:\\n\\nlexicon: The lexicon that represents a specific emotion in the Korean language.\\nrepresentative: The degree to which the lexicon is a representative example of the emotion.\\nprototypicality: A rating… See the full description on the dataset page: https://huggingface.co/datasets/jonghwanhyeon/korean-emotion-lexicon."},
	{"name":"ko_QA_dataset","keyword":"korean","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/kikikara/ko_QA_dataset","creator_name":"kimjeasung","creator_url":"https://huggingface.co/kikikara","description":"maywell/korean_textbooks 의 dataset을 Q&A 형식으로 재구성한 dataset입니다.\\n"},
	{"name":"ko-math","keyword":"korean","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/kikikara/ko-math","creator_name":"kimjeasung","creator_url":"https://huggingface.co/kikikara","description":"hendrycks/math dataset을 한국어로 번역한 dataset 입니다.\\n"},
	{"name":"PangeaBench-xm100","keyword":"korean","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/neulab/PangeaBench-xm100","creator_name":"NeuLab @ LTI/CMU","creator_url":"https://huggingface.co/neulab","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tXM100\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tThis is a copy from https://google.github.io/crossmodal-3600/\\n\\t\\n\\nIf you use this dataset, please cite the original authors:\\n@inproceedings{ThapliyalCrossmodal2022,\\n  author = {Ashish Thapliyal and Jordi Pont-Tuset and Xi Chen and Radu Soricut},\\n  title = {{Crossmodal-3600: A Massively Multilingual Multimodal Evaluation Dataset}},\\n  booktitle = {EMNLP},\\n  year = {2022}\\n}\\n\\n"},
	{"name":"comment-translation-01","keyword":"korean","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ifmain/comment-translation-01","creator_name":"Mike Afton","creator_url":"https://huggingface.co/ifmain","description":"This dataset is based on Kaggle.  \\nThis dataset includes translations of 69,000 Reddit comments into 17 languages (English to 16 languages):\\nBelarusian, Czech, German,\\nEnglish, Spanish, Finnish,\\nFrench, Italian, Japanese,\\nKazakh, Korean, Latvian,\\nPolish, Russian, Swedish,\\nUkrainian, and Chinese.\\nIt contains 50% regular comments and 50% highly negative ones.\\nEnjoy using it!\\n"},
	{"name":"ApolloMoEDataset","keyword":"korean","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/FreedomIntelligence/ApolloMoEDataset","creator_name":"FreedomAI","creator_url":"https://huggingface.co/FreedomIntelligence","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDemocratizing Medical LLMs For Much More Languages\\n\\t\\n\\nCovering 12 Major Languages including English, Chinese, French, Hindi, Spanish, Arabic, Russian, Japanese, Korean, German, Italian, Portuguese and 38 Minor Languages So far.\\n\\n   📃 Paper • 🌐 Demo • 🤗 ApolloMoEDataset • 🤗 ApolloMoEBench  • 🤗 Models  •🌐 Apollo  • 🌐 ApolloMoE\\n\\n\\n\\n\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\t🌈 Update\\n\\t\\n\\n\\n[2024.10.15] ApolloMoE repo is published！🎉\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages Coverage\\n\\t\\n\\n12 Major Languages and 38 Minor Languages… See the full description on the dataset page: https://huggingface.co/datasets/FreedomIntelligence/ApolloMoEDataset."},
	{"name":"ApolloMoEBench","keyword":"korean","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/FreedomIntelligence/ApolloMoEBench","creator_name":"FreedomAI","creator_url":"https://huggingface.co/FreedomIntelligence","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDemocratizing Medical LLMs For Much More Languages\\n\\t\\n\\nCovering 12 Major Languages including English, Chinese, French, Hindi, Spanish, Arabic, Russian, Japanese, Korean, German, Italian, Portuguese and 38 Minor Languages So far.\\n\\n   📃 Paper • 🌐 Demo • 🤗 ApolloMoEDataset • 🤗 ApolloMoEBench  • 🤗 Models  •🌐 Apollo  • 🌐 ApolloMoE\\n\\n\\n\\n\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\t🌈 Update\\n\\t\\n\\n\\n[2024.10.15] ApolloMoE repo is published！🎉\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages Coverage\\n\\t\\n\\n12 Major Languages and 38 Minor Languages… See the full description on the dataset page: https://huggingface.co/datasets/FreedomIntelligence/ApolloMoEBench."},
	{"name":"KoFinDER","keyword":"korean","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mssongit/KoFinDER","creator_name":"SONGMINSANG","creator_url":"https://huggingface.co/mssongit","description":"mssongit/KoFinDER dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"PangeaBench-xgqa","keyword":"korean","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/neulab/PangeaBench-xgqa","creator_name":"NeuLab @ LTI/CMU","creator_url":"https://huggingface.co/neulab","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\txGQA\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tThis is a clone of the few_shot-test split of the xGQA dataset\\n\\t\\n\\nPlease find the original repository here: https://github.com/adapter-hub/xGQA\\nIf you use this dataset, please cite the original authors:\\n@inproceedings{pfeiffer-etal-2021-xGQA,\\n    title={{xGQA: Cross-Lingual Visual Question Answering}},\\n    author={ Jonas Pfeiffer and Gregor Geigle and Aishwarya Kamath and Jan-Martin O. Steitz and Stefan Roth and Ivan Vuli{\\\\'{c}} and Iryna Gurevych}… See the full description on the dataset page: https://huggingface.co/datasets/neulab/PangeaBench-xgqa."},
	{"name":"influencer_rec_ko","keyword":"korean","license":"GNU General Public License v3.0","license_url":"https://choosealicense.com/licenses/gpl-3.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Hyunggi/influencer_rec_ko","creator_name":"Chang","creator_url":"https://huggingface.co/Hyunggi","description":"Hyunggi/influencer_rec_ko dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"influencer_rec_ko","keyword":"korean","license":"GNU General Public License v3.0","license_url":"https://choosealicense.com/licenses/gpl-3.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Hyunggi/influencer_rec_ko","creator_name":"Chang","creator_url":"https://huggingface.co/Hyunggi","description":"Hyunggi/influencer_rec_ko dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"Exemplary_QA","keyword":"korean","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/100suping/Exemplary_QA","creator_name":"100suping","creator_url":"https://huggingface.co/100suping","description":"100suping/Exemplary_QA dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"Ko_Simple_QA","keyword":"korean","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/sionic-ai/Ko_Simple_QA","creator_name":"sionic-ai","creator_url":"https://huggingface.co/sionic-ai","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\t한영 질문답변 데이터셋\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\t데이터셋 설명\\n\\t\\n\\n이 데이터셋은 영어 질문답변 쌍과 그에 대응하는 한국어 번역으로 구성되어 있습니다. \\n각 데이터 포인트\\n\\n메타데이터: 주제, 답변 유형, 참고 URL 등의 정보\\n영어 질문\\n영어 답변\\n한국어 질문\\n한국어 답변\\n\\n총 4,265개의 질문답변 쌍이 포함되어 있으며, CSV 형식으로 제공.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\t원천 데이터 관련 링크\\n\\t\\n\\nhttps://github.com/openai/simple-evals\\nhttps://openai.com/index/introducing-simpleqa/\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\t데이터 예시\\n\\t\\n\\n{\\n  \\\"metadata\\\": {\\n    \\\"topic\\\": \\\"Science and technology\\\",\\n    \\\"answer_type\\\": \\\"Person\\\",\\n    \\\"urls\\\":… See the full description on the dataset page: https://huggingface.co/datasets/sionic-ai/Ko_Simple_QA."},
	{"name":"Ko_Simple_QA","keyword":"korean","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/sionic-ai/Ko_Simple_QA","creator_name":"sionic-ai","creator_url":"https://huggingface.co/sionic-ai","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\t한영 질문답변 데이터셋\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\t데이터셋 설명\\n\\t\\n\\n이 데이터셋은 영어 질문답변 쌍과 그에 대응하는 한국어 번역으로 구성되어 있습니다. \\n각 데이터 포인트\\n\\n메타데이터: 주제, 답변 유형, 참고 URL 등의 정보\\n영어 질문\\n영어 답변\\n한국어 질문\\n한국어 답변\\n\\n총 4,265개의 질문답변 쌍이 포함되어 있으며, CSV 형식으로 제공.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\t원천 데이터 관련 링크\\n\\t\\n\\nhttps://github.com/openai/simple-evals\\nhttps://openai.com/index/introducing-simpleqa/\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\t데이터 예시\\n\\t\\n\\n{\\n  \\\"metadata\\\": {\\n    \\\"topic\\\": \\\"Science and technology\\\",\\n    \\\"answer_type\\\": \\\"Person\\\",\\n    \\\"urls\\\":… See the full description on the dataset page: https://huggingface.co/datasets/sionic-ai/Ko_Simple_QA."},
	{"name":"MegaWika","keyword":"korean","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/conceptofmind/MegaWika","creator_name":"Enrico Shippole","creator_url":"https://huggingface.co/conceptofmind","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for MegaWika\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nMegaWika is a multi- and crosslingual text dataset containing 30 million Wikipedia passages with their scraped and cleaned web citations. The passages span\\n50 Wikipedias in 50 languages, and the articles in which the passages were originally embedded are included for convenience. Where a Wikipedia passage is in a\\nnon-English language, an automated English translation is provided. Furthermore, nearly 130 million English… See the full description on the dataset page: https://huggingface.co/datasets/conceptofmind/MegaWika."},
	{"name":"finance-legal-mrc","keyword":"korean","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/shchoice/finance-legal-mrc","creator_name":"Seohwan Choi","creator_url":"https://huggingface.co/shchoice","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\t금융, 법률 문서 기계독해 데이터셋\\n\\t\\n\\n금융 및 법률 분야 전문문서를 활용하여 기계독해 모델 생성을 위한 지문-질문-답변으로 구성된 데이터셋입니다.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\t데이터셋 구성\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSubsets\\n\\t\\n\\n\\nspan_extraction: 정답경계 추출형(정답이 지문 내 특정 범위에 있는 데이터)\\nspan_extraction_how: 절차(방법)(어떻게로 시작하는 질문에 대한 정답 추출 데이터)\\nmultiple_choice: 다지선다형(객관식 형태의 데이터)\\ntableqa: Table 정답추출형(표 기반 질의응답 데이터)\\ntext_entailment: Yes/No 단문형(Boolean 선택 형태의 데이터)\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSplits\\n\\t\\n\\n\\ntrain: 학습용 데이터셋\\nvalidation: 검증용 데이터셋\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\t사용 방법\\n\\t\\n\\nfrom datasets import load_dataset\\n특정… See the full description on the dataset page: https://huggingface.co/datasets/shchoice/finance-legal-mrc."},
	{"name":"finance-legal-mrc","keyword":"korean","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/shchoice/finance-legal-mrc","creator_name":"Seohwan Choi","creator_url":"https://huggingface.co/shchoice","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\t금융, 법률 문서 기계독해 데이터셋\\n\\t\\n\\n금융 및 법률 분야 전문문서를 활용하여 기계독해 모델 생성을 위한 지문-질문-답변으로 구성된 데이터셋입니다.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\t데이터셋 구성\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSubsets\\n\\t\\n\\n\\nspan_extraction: 정답경계 추출형(정답이 지문 내 특정 범위에 있는 데이터)\\nspan_extraction_how: 절차(방법)(어떻게로 시작하는 질문에 대한 정답 추출 데이터)\\nmultiple_choice: 다지선다형(객관식 형태의 데이터)\\ntableqa: Table 정답추출형(표 기반 질의응답 데이터)\\ntext_entailment: Yes/No 단문형(Boolean 선택 형태의 데이터)\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSplits\\n\\t\\n\\n\\ntrain: 학습용 데이터셋\\nvalidation: 검증용 데이터셋\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\t사용 방법\\n\\t\\n\\nfrom datasets import load_dataset\\n특정… See the full description on the dataset page: https://huggingface.co/datasets/shchoice/finance-legal-mrc."},
	{"name":"wiktionary-data","keyword":"korean","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/QubitPi/wiktionary-data","creator_name":"Jiaqi","creator_url":"https://huggingface.co/QubitPi","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tWiktionary Data on Hugging Face Datasets\\n\\t\\n\\n\\n\\n\\n\\n\\nwiktionary-data is a sub-data extraction of the English Wiktionary that currently\\nsupports the following languages:\\n\\nDeutsch - German\\nLatinum - Latin\\nἙλληνική - Ancient Greek\\n한국어 - Korean\\n𐎠𐎼𐎹 - Old Persian\\n𒀝𒅗𒁺𒌑(𒌝) - Akkadian\\nElamite\\nसंस्कृतम् - Sanskrit, or Classical Sanskrit\\n\\nwiktionary-data was originally a sub-module of wilhelm-graphdb. While\\nthe dataset it's getting bigger, I noticed a wave of more exciting potentials… See the full description on the dataset page: https://huggingface.co/datasets/QubitPi/wiktionary-data."},
	{"name":"wiktionary-data","keyword":"korean","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/QubitPi/wiktionary-data","creator_name":"Jiaqi","creator_url":"https://huggingface.co/QubitPi","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tWiktionary Data on Hugging Face Datasets\\n\\t\\n\\n\\n\\n\\n\\n\\nwiktionary-data is a sub-data extraction of the English Wiktionary that currently\\nsupports the following languages:\\n\\nDeutsch - German\\nLatinum - Latin\\nἙλληνική - Ancient Greek\\n한국어 - Korean\\n𐎠𐎼𐎹 - Old Persian\\n𒀝𒅗𒁺𒌑(𒌝) - Akkadian\\nElamite\\nसंस्कृतम् - Sanskrit, or Classical Sanskrit\\n\\nwiktionary-data was originally a sub-module of wilhelm-graphdb. While\\nthe dataset it's getting bigger, I noticed a wave of more exciting potentials… See the full description on the dataset page: https://huggingface.co/datasets/QubitPi/wiktionary-data."},
	{"name":"FinShibainu","keyword":"korean","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/aiqwe/FinShibainu","creator_name":"Jay Lee","creator_url":"https://huggingface.co/aiqwe","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tFinShibainu Datset Card\\n\\t\\n\\n\\ngithub: https://github.com/aiqwe/FinShibainu\\nmodel: https://huggingface.co/aiqwe/FinShibainu\\n\\nKRX LLM 경진대회 리더보드에서 우수상을 수상한 shibainu24 모델의 데이터셋 Repository입니다.모델에 대한 내용은 https://huggingface.co/aiqwe/FinShibainu를 참조해주세요.데이터셋 수집 및 학습에 관련된 코드는 https://github.com/aiqwe/FinShibainu에 자세하게 공개되어 있습니다.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDPO\\n\\t\\n\\nPreference의 A는 answer_A, B는 answer_B 컬럼입니다.\\n\\nanswer_A: Reference와 질문을 함께 제공받은 gpt 답변. Reference에 의존적이고 짧지만 정확한 답변을 생성함\\nanswer_B: Reference없이 질문만… See the full description on the dataset page: https://huggingface.co/datasets/aiqwe/FinShibainu."},
	{"name":"Kor-financial-qa-7K","keyword":"korean","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/coorung/Kor-financial-qa-7K","creator_name":"Ungjin Jang","creator_url":"https://huggingface.co/coorung","description":"coorung/Kor-financial-qa-7K dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"pub_med_qa_ko_translated","keyword":"korean","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/koohack/pub_med_qa_ko_translated","creator_name":"SeungHyun Park","creator_url":"https://huggingface.co/koohack","description":"koohack/pub_med_qa_ko_translated dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"zeroth-STT-Ko","keyword":"korean","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/o0dimplz0o/zeroth-STT-Ko","creator_name":"Michele Phan","creator_url":"https://huggingface.co/o0dimplz0o","description":"\\n\\t\\n\\t\\t\\n\\t\\tZeroth-STT-Ko Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDescription\\n\\t\\n\\nThis dataset combines the following publicly available Korean language datasets:\\nJunhoee/STT_Korean_Dataset_80000\\nand\\nZeroth-Korean Dataset (from Project: Zeroth, by GoodAtlas and Gridspace)\\nThis provides over 102K rows of data (sentences) in total.\\n\\n\\t\\n\\t\\t\\n\\t\\tCitation\\n\\t\\n\\nZeroth-Korean Dataset, created by [Lucas Jo(@Atlas Guide Inc.) and Wonkyum Lee(@Gridspace Inc.)], 2023.\\nAvailable at https://github.com/goodatlas/zeroth under CC-BY-4.0… See the full description on the dataset page: https://huggingface.co/datasets/o0dimplz0o/zeroth-STT-Ko."},
	{"name":"LAION-art-EN-improved-captions-translate","keyword":"korean","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/jaeyong2/LAION-art-EN-improved-captions-translate","creator_name":"jeongjaeyong","creator_url":"https://huggingface.co/jaeyong2","description":"\\n\\t\\n\\t\\t\\n\\t\\tDevelopment Process\\n\\t\\n\\n\\nsource dataset from recastai/LAION-art-EN-improved-captions\\nWe used Qwen/Qwen2-72B-Instruct model to translate.\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tLicense\\n\\t\\n\\n\\nQwen/Qwen2.5-72B-Instruct : https://huggingface.co/Qwen/Qwen2-72B-Instruct/blob/main/LICENSE\\nrecastai/LAION-art-EN-improved-captions : https://huggingface.co/datasets/choosealicense/licenses/blob/main/markdown/cc-by-4.0.md\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tAcknowledgement\\n\\t\\n\\nThis research is supported by TPU Research Cloud program.\\n"},
	{"name":"KoMultiText","keyword":"korean","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Dasool/KoMultiText","creator_name":"DasolChoi","creator_url":"https://huggingface.co/Dasool","description":"\\n\\t\\n\\t\\t\\n\\t\\tKoMultiText: Korean Multi-task Dataset for Classifying Biased Speech\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nKoMultiText is a comprehensive Korean multi-task text dataset designed for classifying biased and harmful speech in online platforms. The dataset focuses on tasks such as Preference Detection, Profanity Identification, and Bias Classification across multiple domains, enabling state-of-the-art language models to perform multi-task learning for socially responsible AI applications.… See the full description on the dataset page: https://huggingface.co/datasets/Dasool/KoMultiText."},
	{"name":"HRM8K_KSM","keyword":"korean","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/heegyu/HRM8K_KSM","creator_name":"Heegyu Kim","creator_url":"https://huggingface.co/heegyu","description":"\\nOriginal Dataset: HAERAE-HUB/HRM8K\\n평가를 위해 KSM subset만 가져와서 분리했음.\\n\\n"},
	{"name":"GammaCorpus-Polylingo-50k","keyword":"korean","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/rubenroy/GammaCorpus-Polylingo-50k","creator_name":"Ruben Roy","creator_url":"https://huggingface.co/rubenroy","description":"\\n\\t\\n\\t\\t\\n\\t\\tGammaCorpus Polylingo 50k\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tWhat is it?\\n\\t\\n\\nThe GammaCorpus Polylingo 50k dataset consists of 50,000 structured, unfiltered, single-turn conversations, where each interaction includes:\\n\\nInput: A user prompt or question.\\nOutput: A response generated by an AI assistant.\\nLanguage: The language used in the interaction.\\n\\nThis dataset is designed to help in the training and evaluation of conversational AI models for linguistic purposes. This dataset can be especially helpful if you… See the full description on the dataset page: https://huggingface.co/datasets/rubenroy/GammaCorpus-Polylingo-50k."},
	{"name":"investment_analysis","keyword":"korean","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/MLOpsEngineer/investment_analysis","creator_name":"Peter Song","creator_url":"https://huggingface.co/MLOpsEngineer","description":"\\n\\t\\n\\t\\t\\n\\t\\t코스피 상장 기업 공시정보 기반 투자 리포트 데이터셋\\n\\t\\n\\n이 데이터셋은 국내 코스피 상장 기업의 공시정보를 바탕으로, 투자 전문가들이 활용할 수 있는 심층적 분석과 투자 전략 제안을 목표로 제작되었습니다. 특히, 이 데이터셋은 GPT 파인튜닝에 최적화된 구조로 설계되어 있어, 다양한 역할(role)을 포함한 메시지 기반의 대화 형식으로 구성되어 있습니다.\\n\\n\\t\\n\\t\\t\\n\\t\\t데이터셋 구조\\n\\t\\n\\n데이터셋은 JSONL 포맷으로 제공되며, 각 항목은 GPT 파인튜닝에 최적화된 메시지 형식을 따릅니다. 주요 구성은 다음과 같습니다:\\n\\nmessages: 메시지 배열 형태로 구성되어 있으며, 각 메시지는 아래와 같은 역할을 가집니다.\\nsystem: 모델의 역할과 행동 지침을 정의합니다.예시: \\\"당신은 기업 재무 및 투자 분석 전문가입니다. 참고 컨텍스트를 기반으로 사용자 질문에 대해 정확하고 논리적으로 답변하세요.\\\"\\nuser: 사용자의 질문과 컨텍스트(예시 데이터, 재무제표… See the full description on the dataset page: https://huggingface.co/datasets/MLOpsEngineer/investment_analysis."},
	{"name":"twice_dart_company2industry_clustering","keyword":"korean","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/nmixx-fin/twice_dart_company2industry_clustering","creator_name":"nmixx-financial-nlp-lab","creator_url":"https://huggingface.co/nmixx-fin","description":"\\n\\t\\n\\t\\t\\n\\t\\tDARTCompany2Industry-Clustering-ko\\n\\t\\n\\n\\nConstructed an industry clustering dataset based on the summary sentences of the DART business reports.\\nTo ensure consistency with FinanceMTEB/WikiCompany2Industry-en, the industry labels were limited to five categories ({'Finance & Insurance', 'Wholesale & Retail', 'Professional, Scientific & Technical Services', 'Information & Communication', 'Manufacturing'}).\\nThe dataset will be expanded using existing DART raw data.\\n\\n"},
	{"name":"finance-legal-mrc_merged-table","keyword":"korean","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/didi0di/finance-legal-mrc_merged-table","creator_name":"Yeongji Noh","creator_url":"https://huggingface.co/didi0di","description":"\\n\\t\\n\\t\\t\\n\\t\\t데이터셋 설명\\n\\t\\n\\nshchoice/finance-legal-mrc 데이터 중 병합된 테이블만 추출한 뒤 이미지와 함께 저장한 데이터입니다.\\n"},
	{"name":"MagiciteBabel","keyword":"korean","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/iarcanar/MagiciteBabel","creator_name":"teerapat","creator_url":"https://huggingface.co/iarcanar","description":"\\n\\t\\n\\t\\t\\n\\t\\tAPI Key Configuration\\n\\t\\n\\n\\nRename file open for edit api key.env to .env\\nEdit .env file and paste your API key:ANTHROPIC_API_KEY='your_claude_api_key'\\nOPENAI_API_KEY='your_openai_api_key'\\n\\n\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tMagicBabel for FFXIV\\n\\t\\n\\n[th] โปรแกรมแปลบทสนทนาในเกมส์ FFXIV แบบ realtime สร้างโดยคนไทย\\n\\n\\t\\n\\t\\t\\n\\t\\tDescription\\n\\t\\n\\nMagicBabel is a real-time translation tool specifically designed for Final Fantasy XIV (FFXIV), created by a non-native English speaker to enhance the storytelling experience. The… See the full description on the dataset page: https://huggingface.co/datasets/iarcanar/MagiciteBabel."},
	{"name":"Magpie-Ko-Qwen2.5-Reasoning-Raw","keyword":"korean","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/werty1248/Magpie-Ko-Qwen2.5-Reasoning-Raw","creator_name":"Dohyung Kim","creator_url":"https://huggingface.co/werty1248","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Generation\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSystem Message\\n\\t\\n\\n\\nKorean Reasoning Template\\n\\n\\\"pre_query_template\\\": \\\"<|im_start|>system\\\\n당신은 알리바바 클라우드에서 만든 Qwen입니다. 당신은 유용한 어시스턴트입니다.\\\\nuser가 논리적인 다단계의 추론 과정이 필요한 복잡한 문제를 내면, assistant는 한국어로 단계적으로 풀이를 제시합니다.<|im_end|>\\\\n<|im_start|>user\\\\n\\\"\\n\\n\\n(Original)\\n\\n\\\"pre_query_template\\\": \\\"<|im_start|>system\\\\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\\\\n<|im_start|>user\\\\n\\\"\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tModel\\n\\t\\n\\n\\nQuestion: Qwen/Qwen2.5-32B-Instruct… See the full description on the dataset page: https://huggingface.co/datasets/werty1248/Magpie-Ko-Qwen2.5-Reasoning-Raw."},
	{"name":"wikipedia_qa","keyword":"korean","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/blueapple8259/wikipedia_qa","creator_name":"blueapple825","creator_url":"https://huggingface.co/blueapple8259","description":"wikipedia 데이터를 qa형식으로 가공한 데이터셋입니다.\\n언어모델 없이 코드로만 가공하는 것이 목표이며 새로운 가공 아이디어가 떠오를 시 새 버전으로 업로드 하겠습니다.\\n"},
	{"name":"parallel_corpus_game_2024","keyword":"korean","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/bot-yaya/parallel_corpus_game_2024","creator_name":"yaya","creator_url":"https://huggingface.co/bot-yaya","description":"https://github.com/mnbvc-parallel-corpus-team/parallel_corpus_mnbvc\\nMNBVC平行语料小组：游戏语料\\n不定期更新，目前已收录的游戏语料文件，共29份：\\n\\n博德之门3\\n赛博朋克2077\\n黑暗之魂3\\n底特律：化身为人\\n饥荒\\n艾尔登法环\\n原神\\n黑帝斯\\n霍格沃兹之遗\\nIb\\n如龙8\\n如龙7外传\\n荒野大镖客2\\n只狼：影逝二度\\n文明6\\n杀戮尖塔\\n崩坏星穹铁道\\n群星\\n泰拉瑞亚\\n巫师3\\n魔女之泉3\\n魔女之泉R\\n鸣潮\\n如龙3\\n如龙4\\n如龙5\\n如龙6\\n如龙极2\\n如龙7\\n\\n"},
	{"name":"argilla-distilabel-math-preference-dpo-korean","keyword":"korean","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ChuGyouk/argilla-distilabel-math-preference-dpo-korean","creator_name":"ChuGyouk","creator_url":"https://huggingface.co/ChuGyouk","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Information\\n\\t\\n\\nThis is a gpt-4o-2024-08-06 Korean translated-version of argilla/distilabel-math-preference-dpo. \\nI used OpenAI BATCH API with prompt below, temperature=0.0, max_tokens=4000, seed=0. Total cost was 11.71$.\\nNote that for the 1317th data, because it did not satisfy the format given in the instruction, I modified it. (For example, for  mark, even this was translated as <의문>.)\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tPrompt\\n\\t\\n\\n\\nYou are tasked with translating English text into Korean for… See the full description on the dataset page: https://huggingface.co/datasets/ChuGyouk/argilla-distilabel-math-preference-dpo-korean."},
	{"name":"X-ALMA-Preference","keyword":"korean","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/haoranxu/X-ALMA-Preference","creator_name":"Haoran Xu","creator_url":"https://huggingface.co/haoranxu","description":"This is the translation preference dataset used by X-ALMA.\\nsource: the source sentence.\\nchosen: the preferred translation.\\nreject: the dis-preferred translation.\\ndirections: the translation direction.\\n@misc{xu2024xalmaplugplay,\\n      title={X-ALMA: Plug & Play Modules and Adaptive Rejection for Quality Translation at Scale}, \\n      author={Haoran Xu and Kenton Murray and Philipp Koehn and Hieu Hoang and Akiko Eriguchi and Huda Khayrallah},\\n      year={2024},\\n      eprint={2410.03115}… See the full description on the dataset page: https://huggingface.co/datasets/haoranxu/X-ALMA-Preference."},
	{"name":"glaiveai-reflection-v1-ko","keyword":"korean","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/youjunhyeok/glaiveai-reflection-v1-ko","creator_name":"유준혁","creator_url":"https://huggingface.co/youjunhyeok","description":"Translated glaiveai/reflection-v1 using nayohan/llama3-instrucTrans-enko-8b.\\nFor this dataset, we only used data that is 5000 characters or less in length and has language of English.\\nThanks for @Magpie-Align and @nayohan.\\n"},
	{"name":"glaiveai-reflection-v1-ko","keyword":"korean","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/youjunhyeok/glaiveai-reflection-v1-ko","creator_name":"유준혁","creator_url":"https://huggingface.co/youjunhyeok","description":"Translated glaiveai/reflection-v1 using nayohan/llama3-instrucTrans-enko-8b.\\nFor this dataset, we only used data that is 5000 characters or less in length and has language of English.\\nThanks for @Magpie-Align and @nayohan.\\n"},
	{"name":"poplyrics-1k","keyword":"korean","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/ashuwhy/poplyrics-1k","creator_name":"Ashutosh Sharma","creator_url":"https://huggingface.co/ashuwhy","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tPop Lyrics Dataset\\n\\t\\n\\nThis dataset contains up to 1,000 pop songs with their lyrics, songwriters, genres, and other relevant metadata. The data was collected from Spotify and Genius.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Structure\\n\\t\\n\\n\\ntrack_name: Name of the song.\\nalbum: Album name.\\nrelease_date: Release date of the song.\\nsong_length: Duration of the song.\\npopularity: Popularity score from Spotify.\\nsongwriters: List of songwriters.\\nartist: Name of the artist.\\nlyrics: Cleaned lyrics of the song.… See the full description on the dataset page: https://huggingface.co/datasets/ashuwhy/poplyrics-1k."},
	{"name":"clustering_klue_mrc_context_domain","keyword":"korean","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/on-and-on/clustering_klue_mrc_context_domain","creator_name":"khlee","creator_url":"https://huggingface.co/on-and-on","description":"This dataset is a processed and redistributed version of the KLUE dataset and follows the KLUE license.\\n(https://huggingface.co/datasets/klue/klue)\\nIt is a dataset for embedding evaluation, processed using the categories from the KLUE-MRC dataset.\\n\\nTask: Clustering\\nDomain: Game / Media / Automotive / Finance / Real Estate / Education\\n\\n========================================Original Citation===========================================\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tCitation Information\\n\\t\\n\\n  @misc{park2021klue… See the full description on the dataset page: https://huggingface.co/datasets/on-and-on/clustering_klue_mrc_context_domain."},
	{"name":"question-complexity","keyword":"korean","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/rokokot/question-complexity","creator_name":"Robin Kokot","creator_url":"https://huggingface.co/rokokot","description":"\\n\\t\\n\\t\\t\\n\\t\\tQuestion Type and Complexity (QTC) Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Overview\\n\\t\\n\\nThe Question Type and Complexity (QTC) dataset is a comprehensive resource for linguistics/NLP research focusing on question classification and linguistic complexity analysis across multiple languages. It contains questions from two distinct sources (TyDi QA and Universal Dependencies v2.15), automatically annotated with question types (polar/content) and a set of linguistic complexity features.\\nKey Features:\\n\\n2… See the full description on the dataset page: https://huggingface.co/datasets/rokokot/question-complexity."},
	{"name":"korean_chat_friendly","keyword":"korean","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/JaeJiMin/korean_chat_friendly","creator_name":"JaeJi","creator_url":"https://huggingface.co/JaeJiMin","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tKorean Chat Friendly Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThe Korean Chat Friendly dataset is a curated combination of two publicly available datasets:\\n\\nKorean Safe Conversation\\nMental Health Counseling Conversations\\n\\nThis dataset was created by translating and summarizing the original conversations and then modifying the tone to resemble friendly conversations between friends. It is ideal for applications related to conversational AI, natural language understanding, and… See the full description on the dataset page: https://huggingface.co/datasets/JaeJiMin/korean_chat_friendly."},
	{"name":"korean_chat_friendly","keyword":"korean","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/JaeJiMin/korean_chat_friendly","creator_name":"JaeJi","creator_url":"https://huggingface.co/JaeJiMin","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tKorean Chat Friendly Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThe Korean Chat Friendly dataset is a curated combination of two publicly available datasets:\\n\\nKorean Safe Conversation\\nMental Health Counseling Conversations\\n\\nThis dataset was created by translating and summarizing the original conversations and then modifying the tone to resemble friendly conversations between friends. It is ideal for applications related to conversational AI, natural language understanding, and… See the full description on the dataset page: https://huggingface.co/datasets/JaeJiMin/korean_chat_friendly."},
	{"name":"kurage_training_data","keyword":"korean","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/lightblue/kurage_training_data","creator_name":"Lightblue KK.","creator_url":"https://huggingface.co/lightblue","description":"lightblue/kurage_training_data dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"RecoTravRoute","keyword":"korean","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/GMLBsst/RecoTravRoute","creator_name":"S S T","creator_url":"https://huggingface.co/GMLBsst","description":"GMLBsst/RecoTravRoute dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"PangeaBench-xchat","keyword":"korean","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/neulab/PangeaBench-xchat","creator_name":"NeuLab @ LTI/CMU","creator_url":"https://huggingface.co/neulab","description":"neulab/PangeaBench-xchat dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"PangeaBench-tydiqa","keyword":"korean","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/neulab/PangeaBench-tydiqa","creator_name":"NeuLab @ LTI/CMU","creator_url":"https://huggingface.co/neulab","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for \\\"tydiqa\\\"\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nTyDi QA is a question answering dataset covering 11 typologically diverse languages with 204K question-answer pairs.\\nThe languages of TyDi QA are diverse with regard to their typology -- the set of linguistic features that each language\\nexpresses -- such that we expect models performing well on this set to generalize across a large number of the languages\\nin the world. It contains language phenomena that would not be found… See the full description on the dataset page: https://huggingface.co/datasets/neulab/PangeaBench-tydiqa."},
	{"name":"mc-translation","keyword":"korean","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/efederici/mc-translation","creator_name":"Edoardo Federici","creator_url":"https://huggingface.co/efederici","description":"This dataset contains professional human translations from OpenAI's MMMLU dataset, repurposed to train translation models that can help translate future evaluation datasets.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tWhy This Dataset?\\n\\t\\n\\nTranslation of evaluation benchmarks is a critical but challenging task. While automated translations may introduce errors or biases, professional human translations are expensive and time-consuming. This dataset leverages existing professional translations (MMMLU) to train specialized… See the full description on the dataset page: https://huggingface.co/datasets/efederici/mc-translation."},
	{"name":"OSCAR-ko-cleaned","keyword":"korean","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/blueapple8259/OSCAR-ko-cleaned","creator_name":"blueapple825","creator_url":"https://huggingface.co/blueapple8259","description":"Warning: No filtering related to safety has been applied. There is a high possibility that inappropriate content may be included in the data, so please be cautious.\\nOriginal: OSCAR-2301\\n8gb\\n5m\\n"},
	{"name":"product-database","keyword":"korean","license":"GNU Affero General Public License v3.0","license_url":"https://choosealicense.com/licenses/agpl-3.0/","language":"en","dataset_url":"https://huggingface.co/datasets/openfoodfacts/product-database","creator_name":"Open Food Facts","creator_url":"https://huggingface.co/openfoodfacts","description":"\\n\\t\\n\\t\\t\\n\\t\\tOpen Food Facts Database\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tWhat is 🍊 Open Food Facts?\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tA food products database\\n\\t\\n\\nOpen Food Facts is a database of food products with ingredients, allergens, nutrition facts and all the tidbits of information we can find on product labels.\\n\\n\\t\\n\\t\\t\\n\\t\\tMade by everyone\\n\\t\\n\\nOpen Food Facts is a non-profit association of volunteers. 25.000+ contributors like you have added 1.7 million + products from 150 countries using our Android or iPhone app or their camera to scan… See the full description on the dataset page: https://huggingface.co/datasets/openfoodfacts/product-database."},
	{"name":"global-festivals-translated","keyword":"korean","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/azminetoushikwasi/global-festivals-translated","creator_name":"Azmine Toushik Wasi","creator_url":"https://huggingface.co/azminetoushikwasi","description":"azminetoushikwasi/global-festivals-translated dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"test_4","keyword":"korean","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/tunngo/test_4","creator_name":"nguyen tuan","creator_url":"https://huggingface.co/tunngo","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tFLEURS\\n\\t\\n\\nFleurs is the speech version of the FLoRes machine translation benchmark. \\nWe use 2009 n-way parallel sentences from the FLoRes dev and devtest publicly available sets, in 102 languages. \\nTraining sets have around 10 hours of supervision. Speakers of the train sets are different than speakers from the dev/test sets. Multilingual fine-tuning is\\nused and ”unit error rate” (characters, signs) of all languages is averaged. Languages and results are also grouped into seven… See the full description on the dataset page: https://huggingface.co/datasets/tunngo/test_4."},
	{"name":"ko-tree-conversation","keyword":"korean","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/CarrotAI/ko-tree-conversation","creator_name":"CarrotCarrot","creator_url":"https://huggingface.co/CarrotAI","description":"한국어로 이루어진 멀티턴 대화셋 입니다.\\n@article{tree-multi,\\n  title={CarrotAI/tree-multi Card},\\n  author={CarrotAI (L, GEUN)},\\n  year={2024},\\n  url = {https://huggingface.co/datasets/CarrotAI/tree-multi}\\n}\\n\\n"},
	{"name":"Lappland","keyword":"korean","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/None1145/Lappland","creator_name":"None","creator_url":"https://huggingface.co/None1145","description":"None1145/Lappland dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"TranslationTraining","keyword":"korean","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/SugoiLoki/TranslationTraining","creator_name":"Jade Ethan Terblanche","creator_url":"https://huggingface.co/SugoiLoki","description":"SugoiLoki/TranslationTraining dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"wikipedia_raw_ko","keyword":"korean","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/blueapple8259/wikipedia_raw_ko","creator_name":"blueapple825","creator_url":"https://huggingface.co/blueapple8259","description":"위키피디아 20241201 덤프를 아무런 가공도 안 한 데이터셋입니다. 가공 하나도 안 한 원본 덤프 없길래 올렸습니다. 가공 안 된 데이터는 필요한데 xml 파싱하는 코드 작성은 귀찮거나 그냥 할 줄 몰라서 못 하시는 분들 있으면 가져다 쓰세요.\\n"},
	{"name":"shp_translations","keyword":"korean","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/david9dragon9/shp_translations","creator_name":"David Wu","creator_url":"https://huggingface.co/david9dragon9","description":"This dataset contains translations of three splits (askscience, explainlikeimfive, legaladvice) of the Stanford Human Preference (SHP) dataset, used for training domain-invariant reward models.\\nThe translation was conducted using the No Language Left Behind (NLLB) 3.3 B 200 model.\\nReferences:\\nStanford Human Preference Dataset: https://huggingface.co/datasets/stanfordnlp/SHP\\nNLLB: https://huggingface.co/facebook/nllb-200-3.3B\\n"},
	{"name":"Bespoke-Stratos-17k-KoEnKo","keyword":"korean","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/werty1248/Bespoke-Stratos-17k-KoEnKo","creator_name":"Dohyung Kim","creator_url":"https://huggingface.co/werty1248","description":"\\nLet them think in English.\\n\\nEnglish system prompt + Korean question + English thinking + Korean answer\\n\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tSystem message changes\\n\\t\\n\\nYour role as an assistant involves thoroughly exploring questions ...(중략)...\\n\\n<|begin_of_solution|> {final formatted, precise, and clear solution **written in the same language as the question.**} <|end_of_solution|> ...(하략)\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tTranslation\\n\\t\\n\\n\\nTranslated with gemini-2.0-flash\\n\\nQuestion\\n\\nReturn your final response within \\\\\\\\boxed{}., Generate an… See the full description on the dataset page: https://huggingface.co/datasets/werty1248/Bespoke-Stratos-17k-KoEnKo."},
	{"name":"BenchMAX_Question_Answering","keyword":"korean","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/LLaMAX/BenchMAX_Question_Answering","creator_name":"LLaMAX","creator_url":"https://huggingface.co/LLaMAX","description":"\\n\\t\\n\\t\\t\\n\\t\\tDataset Sources\\n\\t\\n\\n\\nPaper: BenchMAX: A Comprehensive Multilingual Evaluation Suite for Large Language Models\\nLink: https://arxiv.org/pdf/2502.07346\\nRepository: https://github.com/CONE-MT/BenchMAX\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\nBenchMAX_Function_Completion is a dataset of BenchMAX, sourcing from UN Parallel Corpus and xquad.\\nThe haystacks are from UN Parallel Corpus Test and Development Sets and we translate them to other languages by Google Translate.\\nThe multilingual QA data is from… See the full description on the dataset page: https://huggingface.co/datasets/LLaMAX/BenchMAX_Question_Answering."},
	{"name":"ko-arena-hard-auto-v0.1","keyword":"korean","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/kkksklsn/ko-arena-hard-auto-v0.1","creator_name":"Park","creator_url":"https://huggingface.co/kkksklsn","description":"qwopqwop님이 ko-arena-hard를 번역하신 데이터 qwopqwop/ko-arena-hard-auto-v0.1에 tag를 단 데이터입니다.\\n\\n\\t\\n\\t\\t\\n\\t\\ttag 정보\\n\\t\\n\\n\\n\\t\\n\\t\\t\\nCategory\\nCount\\nDescription\\n\\n\\n\\t\\t\\nCoding & Debugging\\n279\\nUsers seek help with writing, reviewing, or fixing code in programming.\\n\\n\\nPlanning\\n67\\nUsers need assistance in creating plans or strategies for activities and projects.\\n\\n\\nData analysis\\n31\\nRequests involve interpreting data, statistics, or performing analytical tasks.\\n\\n\\nMath\\n26\\nQueries related to mathematical concepts, problems, and… See the full description on the dataset page: https://huggingface.co/datasets/kkksklsn/ko-arena-hard-auto-v0.1."},
	{"name":"M-ABSA","keyword":"korean","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Multilingual-NLP/M-ABSA","creator_name":"multilingual-NLP","creator_url":"https://huggingface.co/Multilingual-NLP","description":"\\n\\t\\n\\t\\t\\n\\t\\tM-ABSA\\n\\t\\n\\nThis repo contains the data for our paper M-ABSA: A Multilingual Dataset for Aspect-Based Sentiment Analysis.\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tData Description:\\n\\t\\n\\nThis is a dataset suitable for the multilingual ABSA task with triplet extraction.\\nAll datasets are stored in the data/ folder:\\n\\nAll dataset contains 7 domains.\\n\\ndomains = [\\\"coursera\\\", \\\"hotel\\\", \\\"laptop\\\", \\\"restaurant\\\", \\\"phone\\\", \\\"sight\\\", \\\"food\\\"]\\n\\n\\nEach dataset contains 21 languages.\\n\\nlangs = [\\\"ar\\\", \\\"da\\\", \\\"de\\\", \\\"en\\\", \\\"es\\\", \\\"fr\\\", \\\"hi\\\", \\\"hr\\\"… See the full description on the dataset page: https://huggingface.co/datasets/Multilingual-NLP/M-ABSA."},
	{"name":"advbench_behaviors_m5","keyword":"korean","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/lenML/advbench_behaviors_m5","creator_name":"len","creator_url":"https://huggingface.co/lenML","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tAbout advbench_behaviors_m5\\n\\t\\n\\n此数据集为 advbench_behaviors.csv 文件的多语言翻译版本。一个常见的任务是用于 abliterator 脚本。\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for AdvBench\\n\\t\\n\\nPaper: Universal and Transferable Adversarial Attacks on Aligned Language Models\\nData: AdvBench Dataset\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tAbout\\n\\t\\n\\nAdvBench is a set of 500 harmful behaviors formulated as instructions. These behaviors\\nrange over the same themes as the harmful strings setting, but the adversary’s goal\\nis instead to find a single attack string that… See the full description on the dataset page: https://huggingface.co/datasets/lenML/advbench_behaviors_m5."},
	{"name":"Rosmontis","keyword":"korean","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/None1145/Rosmontis","creator_name":"None","creator_url":"https://huggingface.co/None1145","description":"None1145/Rosmontis dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"wiktionary-data","keyword":"korean","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/paion-data/wiktionary-data","creator_name":"Paion Data","creator_url":"https://huggingface.co/paion-data","description":"\\n\\t\\n\\t\\t\\n\\t\\tWiktionary Data on Hugging Face Datasets\\n\\t\\n\\n\\n\\n\\n\\nwiktionary-data is a sub-data extraction of the English Wiktionary that currently\\nsupports the following languages:\\n\\nDeutsch - German\\nLatinum - Latin\\nἙλληνική - Ancient Greek\\n한국어 - Korean\\n𐎠𐎼𐎹- Old Persian\\n𒀝𒅗𒁺𒌑(𒌝) - Akkadian\\nElamite\\nसंस्कृतम् - Sanskrit, or Classical Sanskrit\\n\\nwiktionary-data was originally a sub-module of wilhelm-graphdb. While\\nthe dataset it's getting bigger, I noticed a wave of more exciting potentials this… See the full description on the dataset page: https://huggingface.co/datasets/paion-data/wiktionary-data."},
	{"name":"wiktionary-data","keyword":"korean","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/paion-data/wiktionary-data","creator_name":"Paion Data","creator_url":"https://huggingface.co/paion-data","description":"\\n\\t\\n\\t\\t\\n\\t\\tWiktionary Data on Hugging Face Datasets\\n\\t\\n\\n\\n\\n\\n\\nwiktionary-data is a sub-data extraction of the English Wiktionary that currently\\nsupports the following languages:\\n\\nDeutsch - German\\nLatinum - Latin\\nἙλληνική - Ancient Greek\\n한국어 - Korean\\n𐎠𐎼𐎹- Old Persian\\n𒀝𒅗𒁺𒌑(𒌝) - Akkadian\\nElamite\\nसंस्कृतम् - Sanskrit, or Classical Sanskrit\\n\\nwiktionary-data was originally a sub-module of wilhelm-graphdb. While\\nthe dataset it's getting bigger, I noticed a wave of more exciting potentials this… See the full description on the dataset page: https://huggingface.co/datasets/paion-data/wiktionary-data."},
	{"name":"demo","keyword":"korean","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/eyl45/demo","creator_name":"Ethan","creator_url":"https://huggingface.co/eyl45","description":"eyl45/demo dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"lawdata","keyword":"korean","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/GyuHyeonWkdWkdMan/lawdata","creator_name":"GYUHYEON","creator_url":"https://huggingface.co/GyuHyeonWkdWkdMan","description":"GyuHyeonWkdWkdMan/lawdata dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"Ko-emb-PreView","keyword":"korean","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/jaeyong2/Ko-emb-PreView","creator_name":"jeongjaeyong","creator_url":"https://huggingface.co/jaeyong2","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDevelopment Process\\n\\t\\n\\n\\nsource dataset from daje/ko_wiki and maywell/korean_textbooks\\nWe used Qwen/Qwen2-72B-Instruct model to generate answer with COT.\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLicense\\n\\t\\n\\n\\nQwen/Qwen2.5-72B-Instruct : https://huggingface.co/Qwen/Qwen2-72B-Instruct/blob/main/LICENSE\\nmaywell/korean_textbooks : https://choosealicense.com/licenses/apache-2.0/\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tAcknowledgement\\n\\t\\n\\nThis research is supported by TPU Research Cloud program.\\n"},
	{"name":"wikipedia_title_classification","keyword":"korean","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/blueapple8259/wikipedia_title_classification","creator_name":"blueapple825","creator_url":"https://huggingface.co/blueapple8259","description":"위키피디아 문서를 19개의 카테고리로 분류한 데이터셋입니다. 데이터에는 카테고리와 제목만 있습니다.\\ntype1과 type2 전부 json 형식이며 type1은 key값이 제목, value값이 카테고리이며 type2는 key값이 카테고리, value값이 제목입니다. 문서 하나가 여러 개의 카테고리에 속해있는 경우도 있습니다.\\n분류 기준은 classification.csv를 참고하여 주시기 바랍니다. 카테고리 결정 기준은 signature가 문서에 포함되어 있는가이며 문서는 공백과 알파벳이 소문자로 변환된 채 비교되게 됩니다.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\t카테고리 종류\\n\\t\\n\\n\\nhuman: 인간\\n\\nbusiness_person: 기업인\\n\\npresident: 대통령\\n\\nfood: 음식\\n\\ncreature: 생명체\\n\\nanimal: 동물\\n\\nplant: 식물\\n\\nbook: 책\\n\\nmovie: 영화\\n\\nvideo_game: 게임\\n\\nmusic: 음악\\n\\nbuilding: 건물\\n\\nruins: 유적\\n\\ncompany:… See the full description on the dataset page: https://huggingface.co/datasets/blueapple8259/wikipedia_title_classification."},
	{"name":"kor-insu-qaset","keyword":"korean","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/choeeiden/kor-insu-qaset","creator_name":"choe","creator_url":"https://huggingface.co/choeeiden","description":"choeeiden/kor-insu-qaset dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"mmmlu_lite","keyword":"korean","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/opencompass/mmmlu_lite","creator_name":"OpenCompass","creator_url":"https://huggingface.co/opencompass","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tMMMLU-Lite\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tIntroduction\\n\\t\\n\\nA lite version of the MMMLU dataset, which is an community version of the MMMLU dataset by OpenCompass. Due to the large size of the original dataset (about 200k questions), we have created a lite version of the dataset to make it easier to use. We sample 25 examples from each language subject in the original dataset with fixed seed to ensure reproducibility, finally we have 19950 examples in the lite version of the dataset, which is about… See the full description on the dataset page: https://huggingface.co/datasets/opencompass/mmmlu_lite."},
	{"name":"text-moderation-02-multilingual","keyword":"korean","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ifmain/text-moderation-02-multilingual","creator_name":"Mike Afton","creator_url":"https://huggingface.co/ifmain","description":"This dataset is based on Kaggle.It represents a version of @ifmain/text-moderation-410K that has been cleansed of semantically similar values and normalized to a 50/50 ratio of negative and neutral entries.\\nThe dataset contains 1.5M entries (91K * 17 languages).  \\nBefore use, augmentation is recommended! (e.g., character substitution to bypass moderation).\\nFor augmentation, you can use @ifmain/StringAugmentor.  \\nEnjoy using it!\\n"},
	{"name":"Multilingal-sakalt-data","keyword":"korean","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Sakalti/Multilingal-sakalt-data","creator_name":"sakasan","creator_url":"https://huggingface.co/Sakalti","description":"マルチリンガルデータセットです。mitライセンスです。\\n"},
	{"name":"SkunkworksAI-reasoning-0.01-ko","keyword":"korean","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/youjunhyeok/SkunkworksAI-reasoning-0.01-ko","creator_name":"유준혁","creator_url":"https://huggingface.co/youjunhyeok","description":"SkunkworksAI/reasoning-0.01 데이터셋을 nayohan/llama3-instrucTrans-enko-8b 모델을 사용해 번역했습니다.\\nThanks for SkunkworksAI and nayohan.\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\t원본\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\treasoning-0.01 subset\\n\\t\\n\\nsynthetic dataset of reasoning chains for a wide variety of tasks.\\nwe leverage data like this across multiple reasoning experiments/projects.\\nstay tuned for reasoning models and more data.\\nThanks to Hive Digital Technologies (https://x.com/HIVEDigitalTech) for their compute support in this project and beyond.\\n"},
	{"name":"SkunkworksAI-reasoning-0.01-ko","keyword":"korean","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/youjunhyeok/SkunkworksAI-reasoning-0.01-ko","creator_name":"유준혁","creator_url":"https://huggingface.co/youjunhyeok","description":"SkunkworksAI/reasoning-0.01 데이터셋을 nayohan/llama3-instrucTrans-enko-8b 모델을 사용해 번역했습니다.\\nThanks for SkunkworksAI and nayohan.\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\t원본\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\treasoning-0.01 subset\\n\\t\\n\\nsynthetic dataset of reasoning chains for a wide variety of tasks.\\nwe leverage data like this across multiple reasoning experiments/projects.\\nstay tuned for reasoning models and more data.\\nThanks to Hive Digital Technologies (https://x.com/HIVEDigitalTech) for their compute support in this project and beyond.\\n"},
	{"name":"AyaVisionBench","keyword":"korean","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/CohereForAI/AyaVisionBench","creator_name":"Cohere For AI","creator_url":"https://huggingface.co/CohereForAI","description":"\\n\\t\\n\\t\\t\\n\\t\\tDataset Card for Aya Vision Benchmark\\n\\t\\n\\n\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Details\\n\\t\\n\\nThe Aya Vision Benchmark is designed to evaluate vision-language models in real-world multilingual scenarios. It spans 23 languages and 9 distinct task categories, with 15 samples per category, resulting in 135 image-question pairs per language. \\nEach question requires visual context for the answer and covers languages that half of the world's population speaks, making this dataset particularly suited for… See the full description on the dataset page: https://huggingface.co/datasets/CohereForAI/AyaVisionBench."},
	{"name":"webfaq","keyword":"korean","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/PaDaS-Lab/webfaq","creator_name":"Chair of Data Science, University of Passau","creator_url":"https://huggingface.co/PaDaS-Lab","description":"WebFAQ Q&A Dataset\\n\\n   \\n       Overview |\\n       Details  |\\n       Structure  |\\n       Examples |\\n       Considerations |\\n       License |\\n       Citation |\\n       Contact |\\n       Acknowledgement\\n   \\n\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tOverview\\n\\t\\n\\nThe WebFAQ Q&A Dataset is a broad-coverage corpus of 96 million natural question-answer (QA) pairs in 75 languages, gathered from FAQ pages on the web. It leverages structured schema.org FAQPage annotations, making it a unique resource for large-scale Question Answering… See the full description on the dataset page: https://huggingface.co/datasets/PaDaS-Lab/webfaq."},
	{"name":"oasst1","keyword":"korean","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/OpenAssistant/oasst1","creator_name":"OpenAssistant","creator_url":"https://huggingface.co/OpenAssistant","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tOpenAssistant Conversations Dataset (OASST1)\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nIn an effort to democratize research on large-scale alignment, we release OpenAssistant \\nConversations (OASST1), a human-generated, human-annotated assistant-style conversation \\ncorpus consisting of 161,443 messages in 35 different languages, annotated with 461,292 \\nquality ratings, resulting in over 10,000 fully annotated conversation trees. The corpus \\nis a product of a worldwide crowd-sourcing effort… See the full description on the dataset page: https://huggingface.co/datasets/OpenAssistant/oasst1."},
	{"name":"Everything_Instruct_Multilingual","keyword":"korean","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/rombodawg/Everything_Instruct_Multilingual","creator_name":"rombo dawg","creator_url":"https://huggingface.co/rombodawg","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tEverything Instruct (Multilingual Edition)\\n\\t\\n\\nEverything you need... all in one place 💘\\n\\nEverything instruct (Multilingual Edition) is a massive alpaca instruct formatted dataset consisting of a wide variety of topics meant to bring LLM's to the next level in open source AI.\\nNote: This dataset is fully uncensored (No model will refuse any request trained on this dataset unless otherwise aligned)\\nNote2: This version of the dataset supports the following languages:\\n\\nEnglish\\nRussian… See the full description on the dataset page: https://huggingface.co/datasets/rombodawg/Everything_Instruct_Multilingual."},
	{"name":"oasst2","keyword":"korean","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/OpenAssistant/oasst2","creator_name":"OpenAssistant","creator_url":"https://huggingface.co/OpenAssistant","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tOpen Assistant Conversations Dataset Release 2 (OASST2)\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Structure\\n\\t\\n\\nThis dataset contains message trees. Each message tree has an initial prompt message as the root node, \\nwhich can have multiple child messages as replies, and these child messages can have multiple replies. \\nAll messages have a role property: this can either be \\\"assistant\\\" or \\\"prompter\\\". The roles in \\nconversation threads from prompt to leaf node strictly alternate between \\\"prompter\\\" and… See the full description on the dataset page: https://huggingface.co/datasets/OpenAssistant/oasst2."},
	{"name":"Open-R1-Ko-SFT-v2.0","keyword":"korean","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/OLAIR/Open-R1-Ko-SFT-v2.0","creator_name":"OLA-AI-Research","creator_url":"https://huggingface.co/OLAIR","description":"\\n\\t\\n\\t\\t\\n\\t\\tOpen-R1-Ko-SFT-v2.0\\n\\t\\n\\n\\n\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tOverview\\n\\t\\n\\nOLAIR/Open-R1-Ko-SFT-v2.0 is a dataset composed of translated prompt-response pairs originally generated by DeepSeek R1. The source data comprises multiple datasets containing original prompts and responses, which were subsequently translated into Korean using GPT-4o. This dataset is intended for fine-tuning and training language models, specifically for the development of ko-r1-7b-v2.0.3.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSources\\n\\t\\n\\nThe original data is… See the full description on the dataset page: https://huggingface.co/datasets/OLAIR/Open-R1-Ko-SFT-v2.0."},
	{"name":"zeroth-korean","keyword":"korean","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Bingsu/zeroth-korean","creator_name":"Dowon Hwang","creator_url":"https://huggingface.co/Bingsu","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tZeroth-Korean\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tZeroth-Korean\\n\\t\\n\\nThe data set contains transcriebed audio data for Korean. There are 51.6 hours transcribed Korean audio for training data (22,263 utterances, 105 people, 3000 sentences) and 1.2 hours transcribed Korean audio for testing data (457 utterances, 10 people). This corpus also contains pre-trained/designed language model, lexicon and morpheme-based segmenter(morfessor).\\nZeroth project introduces free Korean speech corpus and aims to make… See the full description on the dataset page: https://huggingface.co/datasets/Bingsu/zeroth-korean."},
	{"name":"Global-MMLU","keyword":"korean","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/CohereForAI/Global-MMLU","creator_name":"Cohere For AI","creator_url":"https://huggingface.co/CohereForAI","description":"\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nGlobal-MMLU 🌍 is a multilingual evaluation set spanning 42 languages, including English. This dataset combines machine translations for MMLU questions along with professional translations and crowd-sourced post-edits.\\nIt also includes cultural sensitivity annotations for a subset of the questions (2850 questions per language) and classifies them as Culturally Sensitive (CS) 🗽 or Culturally Agnostic (CA) ⚖️. These annotations were collected as part of an open… See the full description on the dataset page: https://huggingface.co/datasets/CohereForAI/Global-MMLU."},
	{"name":"ko-arena-hard-auto-v0.1","keyword":"korean","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/qwopqwop/ko-arena-hard-auto-v0.1","creator_name":"Junjae Lee","creator_url":"https://huggingface.co/qwopqwop","description":"arena-hard-auto-v0.1 를 GPT-4o와 o1을 사용하여 한국어로 번역하고 수작업으로 검수한 데이터셋입니다.\\n오역이나 의역 또는 부자연스러운 번역이 있을 수 있습니다. 혹시 이을 발견하신다면 issue를 제기하거나 이를 수정한 pr를 만들어주시면 감사하겠습니다.\\n# 프롬프트 템플릿\\n\\\"\\\"<|User Prompt|>\\\\n{question_1}\\\\n\\\\n<|The Start of Assistant A's Answer|>\\\\n{answer_1}\\\\n<|The End of Assistant A's Answer|>\\\\n\\\\n<|The Start of Assistant B's Answer|>\\\\n{answer_2}\\\\n<|The End of Assistant B's Answer|>\\\"\\\"\\n\\n# 번역된 프롬프트 템플릿\\n\\\"\\\"<|사용자 프롬프트|>\\\\n{question_1}\\\\n\\\\n<|어시스턴트 A의 답변 시작|>\\\\n{answer_1}\\\\n<|어시스턴트 A의 답변 끝|>\\\\n\\\\n<|어시스턴트 B의 답변… See the full description on the dataset page: https://huggingface.co/datasets/qwopqwop/ko-arena-hard-auto-v0.1."},
	{"name":"HRM8K","keyword":"korean","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/HAERAE-HUB/HRM8K","creator_name":"HAE-RAE","creator_url":"https://huggingface.co/HAERAE-HUB","description":"\\n\\n| 📖 Paper | 📝 Blog | 🖥️ Code(Coming soon!) |\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tHRM8K\\n\\t\\n\\nWe introduce HAE-RAE Math 8K (HRM8K), a bilingual math reasoning benchmark for Korean and English.\\nHRM8K comprises 8,011 instances for evaluation, sourced through a combination of translations from established English benchmarks (e.g., GSM8K, MATH, OmniMath, MMMLU) and original problems curated from existing Korean math exams.\\n\\n\\t\\n\\t\\t\\n\\t\\tBenchmark Overview\\n\\t\\n\\nThe HRM8K benchmark consists of two subsets:\\n\\nKorean School Math (KSM):… See the full description on the dataset page: https://huggingface.co/datasets/HAERAE-HUB/HRM8K."},
	{"name":"PubMedVision-EnKo","keyword":"korean","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ChuGyouk/PubMedVision-EnKo","creator_name":"ChuGyouk","creator_url":"https://huggingface.co/ChuGyouk","description":"\\n\\t\\n\\t\\t\\n\\t\\tInformations\\n\\t\\n\\n\\nThis is the Korean translation of FreedomIntelligence/PubMedVision. The translation was primarily generated using the 'solar-pro-241126' model, with occasional manual assistance from the 'Gemini 2.0 Flash Experimental' model and the 'Gemini experimental 1206' model.\\nAn evaluation of the translation quality (\\\"llm-as-a-judge\\\") will be coming soon.\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tNews\\n\\t\\n\\n\\n[2024/07/01]: We add annotations for 'body_part' and 'modality' of images, utilizing the… See the full description on the dataset page: https://huggingface.co/datasets/ChuGyouk/PubMedVision-EnKo."},
	{"name":"korean-cipher","keyword":"korean","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/jsm0424/korean-cipher","creator_name":"Sungmin Jo","creator_url":"https://huggingface.co/jsm0424","description":"\\n\\t\\n\\t\\t\\n\\t\\tKorean-Cipher Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tOverview\\n\\t\\n\\nThis dataset was inspired by OpenAI's video, \\\"Korean Cipher with OpenAI o1\\\".It is designed to evaluate the reasoning abilities of large language models (LLMs) in understanding and reconstructing distorted Korean text.  \\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Structure\\n\\t\\n\\nEach sample in the dataset consists of the following fields:  \\n\\nid: A unique identifier for each sentence pair.  \\nmessage: The original Korean sentence.  \\nciphertext: The distorted version of the… See the full description on the dataset page: https://huggingface.co/datasets/jsm0424/korean-cipher."},
	{"name":"reasoning-multilingual-R1-Llama-70B-train","keyword":"korean","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/lightblue/reasoning-multilingual-R1-Llama-70B-train","creator_name":"Lightblue KK.","creator_url":"https://huggingface.co/lightblue","description":"\\n\\t\\n\\t\\t\\n\\t\\tlightblue/reasoning-multilingual-R1-Llama-70B-train\\n\\t\\n\\nThis is a multilingual reasoning dataset covering more than 30 languages.\\nThis dataset was made by:\\n\\nSampling prompts from English datasets and translating them to various languages\\nGenerating responses to these prompts 8 times using deepseek-ai/DeepSeek-R1-Distill-Llama-70B\\nFiltering out <think> sections with incorrect language, non-fluent language, and incorrect answers\\n\\nThis dataset was then used to train a multilingual… See the full description on the dataset page: https://huggingface.co/datasets/lightblue/reasoning-multilingual-R1-Llama-70B-train."},
	{"name":"wmt24pp","keyword":"korean","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/google/wmt24pp","creator_name":"Google","creator_url":"https://huggingface.co/google","description":"\\n\\t\\n\\t\\t\\n\\t\\tWMT24++\\n\\t\\n\\nThis repository contains the human translation and post-edit data for the 55 en->xx language pairs released in\\nthe publication\\nWMT24++: Expanding the Language Coverage of WMT24 to 55 Languages & Dialects.\\nIf you are interested in the MT/LLM system outputs and automatic metric scores, please see MTME.\\nIf you are interested in the images of the source URLs for each document, please see here.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSchema\\n\\t\\n\\nEach language pair is stored in its own jsonl file.\\nEach row is… See the full description on the dataset page: https://huggingface.co/datasets/google/wmt24pp."},
	{"name":"s1K-1.1-Korean","keyword":"korean","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/exp-models/s1K-1.1-Korean","creator_name":"Experimental Models","creator_url":"https://huggingface.co/exp-models","description":"https://huggingface.co/datasets/simplescaling/s1K-1.1\\n"},
	{"name":"s1k-1.1-Ko-ReGenerated-Formatted","keyword":"korean","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/werty1248/s1k-1.1-Ko-ReGenerated-Formatted","creator_name":"Dohyung Kim","creator_url":"https://huggingface.co/werty1248","description":"\\n\\nsimplescaling/s1K-1.1 에서 question 데이터만 GPT-4o를 이용하여 번역\\n\\n\\n단, crossword 퍼즐은 제외 (번역 불가)\\n\\n\\nDeepseek-R1 (fp8, Provider: fireworks.ai)을 사용하여 한국어로 추론 및 답하게 함 (3차 정제 시점에는 bf16? Provider: FriendliAI 사용)\\n1차 정제\\n\\n\\n원본 데이터에서, gemini의 출력, r1의 출력, solution 중 두 개의 답이 일치하면 신뢰할 수 있는 답이라고 정의\\n한국어 R1 답변 결과가 신뢰할 수 있는 답과 다르거나, 답변이 씹힌 경우, 서식이 틀린 경우 총 123개에 대해 추론 및 답변 재생성\\n\\n\\n2차 정제\\n\\n\\n1차와 동일한 프로세스, 63개 데이터 재생성\\n\\n\\n3차 정제\\n추론 과정에서 한자가 출력된 7개 데이터 재생성 (대부분 추론 중 붕괴로 인한 한자 출력)\\n1개 데이터는 7번의 재시도 후에도 계속 한자가 포함되었으므로, 불가피하게 학습 데이터에서… See the full description on the dataset page: https://huggingface.co/datasets/werty1248/s1k-1.1-Ko-ReGenerated-Formatted."},
	{"name":"thinking-multilingual-30-23-small-690","keyword":"korean","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Pinkstack/thinking-multilingual-30-23-small-690","creator_name":"Pinkstack","creator_url":"https://huggingface.co/Pinkstack","description":"\\nBased on OPENO1 math, this is a translated dataset of 30 high quality questions & answers in 23 languages. \\nOr use the \\\"big\\\" version: big 10k rows version\\n"},
	{"name":"klue","keyword":"korean","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/klue/klue","creator_name":"KLUE Benchmark","creator_url":"https://huggingface.co/klue","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for KLUE\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nKLUE is a collection of 8 tasks to evaluate natural language understanding capability of Korean language models. We delibrately select the 8 tasks, which are Topic Classification, Semantic Textual Similarity, Natural Language Inference, Named Entity Recognition, Relation Extraction, Dependency Parsing, Machine Reading Comprehension, and Dialogue State Tracking.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSupported Tasks and Leaderboards\\n\\t\\n\\nTopic… See the full description on the dataset page: https://huggingface.co/datasets/klue/klue."},
	{"name":"xtreme","keyword":"korean","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/google/xtreme","creator_name":"Google","creator_url":"https://huggingface.co/google","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for \\\"xtreme\\\"\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThe Cross-lingual Natural Language Inference (XNLI) corpus is a crowd-sourced collection of 5,000 test and\\n2,500 dev pairs for the MultiNLI corpus. The pairs are annotated with textual entailment and translated into\\n14 languages: French, Spanish, German, Greek, Bulgarian, Russian, Turkish, Arabic, Vietnamese, Thai, Chinese,\\nHindi, Swahili and Urdu. This results in 112.5k annotated pairs. Each premise can be associated with… See the full description on the dataset page: https://huggingface.co/datasets/google/xtreme."},
	{"name":"mqa","keyword":"korean","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/clips/mqa","creator_name":"CLiPS","creator_url":"https://huggingface.co/clips","description":"MQA is a multilingual corpus of questions and answers parsed from the Common Crawl. Questions are divided between Frequently Asked Questions (FAQ) pages and Community Question Answering (CQA) pages."},
	{"name":"kobest_v1","keyword":"korean","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/skt/kobest_v1","creator_name":"SK Telecom","creator_url":"https://huggingface.co/skt","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for KoBEST\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nKoBEST is a Korean benchmark suite consists of 5 natural language understanding tasks that requires advanced knowledge in Korean.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSupported Tasks and Leaderboards\\n\\t\\n\\nBoolean Question Answering, Choice of Plausible Alternatives, Words-in-Context, HellaSwag, Sentiment Negation Recognition\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages\\n\\t\\n\\nko-KR\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Structure\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Instances\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tKB-BoolQ\\n\\t\\n\\nAn example… See the full description on the dataset page: https://huggingface.co/datasets/skt/kobest_v1."},
	{"name":"kote","keyword":"korean","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/searle-j/kote","creator_name":"Jeon Duyoung","creator_url":"https://huggingface.co/searle-j","description":"50k Korean online comments labeled for 44 emotion categories."},
	{"name":"naver-news-summarization-ko","keyword":"korean","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/daekeun-ml/naver-news-summarization-ko","creator_name":"Daekeun Kim","creator_url":"https://huggingface.co/daekeun-ml","description":"This dataset is a custom dataset created by the author by crawling Naver News (https://news.naver.com) for the Korean NLP model hands-on.\\n\\nPeriod: July 1, 2022 - July 10, 2022\\nSubject: IT, economics\\n\\nDatasetDict({\\n    train: Dataset({\\n        features: ['date', 'category', 'press', 'title', 'document', 'link', 'summary'],\\n        num_rows: 22194\\n    })\\n    test: Dataset({\\n        features: ['date', 'category', 'press', 'title', 'document', 'link', 'summary'],\\n        num_rows: 2740\\n    })… See the full description on the dataset page: https://huggingface.co/datasets/daekeun-ml/naver-news-summarization-ko."},
	{"name":"kmhas_korean_hate_speech","keyword":"korean","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/jeanlee/kmhas_korean_hate_speech","creator_name":"Jean Lee","creator_url":"https://huggingface.co/jeanlee","description":"The K-MHaS (Korean Multi-label Hate Speech) dataset contains 109k utterances from Korean online news comments labeled with 8 fine-grained hate speech classes or Not Hate Speech class.\\nThe fine-grained hate speech classes are politics, origin, physical, age, gender, religion, race, and profanity and these categories are selected in order to reflect the social and historical context."},
	{"name":"laion-translated-to-en-korean-subset","keyword":"korean","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Bingsu/laion-translated-to-en-korean-subset","creator_name":"Dowon Hwang","creator_url":"https://huggingface.co/Bingsu","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tlaion-translated-to-en-korean-subset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tAbout dataset\\n\\t\\n\\na subset data of laion/laion2B-multi-joined-translated-to-en and laion/laion1B-nolang-joined-translated-to-en, including only korean\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLisence\\n\\t\\n\\nCC-BY-4.0\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Structure\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Instance\\n\\t\\n\\n>>> from datasets import load_dataset\\n>>> dataset = load_dataset(\\\"Bingsu/laion-translated-to-en-korean-subset\\\")\\n>>> dataset\\nDatasetDict({\\n    train: Dataset({\\n        features: ['hash', 'URL'… See the full description on the dataset page: https://huggingface.co/datasets/Bingsu/laion-translated-to-en-korean-subset."},
	{"name":"kullm-v2","keyword":"korean","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/nlpai-lab/kullm-v2","creator_name":"NLP & AI - Korea University","creator_url":"https://huggingface.co/nlpai-lab","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for \\\"KULLM-v2\\\"\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nKorean translation of GPT4ALL, Dolly, and Vicuna data.\\nrepository: nlpai-lab/KULLM\\nhuggingface: nlpai-lab/kullm-v2\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tTranslate dataset\\n\\t\\n\\nTranslated 'instruction', 'input', and 'output' in the dataset via the DeepL API\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLisence\\n\\t\\n\\nApache-2.0\\n>>> from datasets import load_dataset\\n\\n>>> ds = load_dataset(\\\"nlpai-lab/kullm-v2\\\", split=\\\"train\\\")\\n>>> ds\\nDatasetDict({\\n    train: Dataset({\\n        features:… See the full description on the dataset page: https://huggingface.co/datasets/nlpai-lab/kullm-v2."},
	{"name":"toxi-text-3M","keyword":"korean","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/FredZhang7/toxi-text-3M","creator_name":"Fred Zhang","creator_url":"https://huggingface.co/FredZhang7","description":"This is a large multilingual toxicity dataset with 3M rows of text data from 55 natural languages, all of which are written/sent by humans, not machine translation models.\\nThe preprocessed training data alone consists of 2,880,667 rows of comments, tweets, and messages. Among these rows, 416,529 are classified as toxic, while the remaining 2,463,773 are considered neutral. Below is a table to illustrate the data composition:\\n\\n\\t\\n\\t\\t\\n\\nToxic\\nNeutral\\nTotal\\n\\n\\n\\t\\t\\nmultilingual-train-deduplicated.csv… See the full description on the dataset page: https://huggingface.co/datasets/FredZhang7/toxi-text-3M."},
	{"name":"sharegpt_gpt4","keyword":"korean","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/shibing624/sharegpt_gpt4","creator_name":"Ming Xu (徐明)","creator_url":"https://huggingface.co/shibing624","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nShareGPT中挑选出的GPT4多轮问答数据，多语言问答。\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages\\n\\t\\n\\n数据集是多语言，包括中文、英文、日文等常用语言。\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Structure\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Fields\\n\\t\\n\\nThe data fields are the same among all splits.\\n\\nconversations: a List of string .\\n\\nhead -n 1 sharegpt_gpt4.jsonl\\n\\n{\\\"conversations\\\":[\\n  {'from': 'human',\\n   'value': '採用優雅現代中文，用中文繁體字型，回答以下問題。為所有標題或專用字詞提供對應的英語翻譯：Using scholarly style, summarize in detail James Barr\\\\'s book \\\"Semantics of Biblical… See the full description on the dataset page: https://huggingface.co/datasets/shibing624/sharegpt_gpt4."},
	{"name":"korean_rlhf_dataset","keyword":"korean","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/jojo0217/korean_rlhf_dataset","creator_name":"mingyu jo","creator_url":"https://huggingface.co/jojo0217","description":"성균관대학교 산학협력프로젝트 과정에서 한국어 llm 모델 SFT 학습을 위해 구축한 데이터셋 입니다.2023-09-25오픈 어시스턴트 data에서 오픈 어시스턴트를 포함하는 데이터 삭제-> 답변에 오픈 어시스턴트라고 하는 경우가 나오기 때문또한 스탠포드 대학 번역 데이터에서 번역 과정 오류로 input에 입력없음 과 같이 추가된 부분 삭제그리고 <unk> 등으로 gpt 상에서 번역 오류가 난 것들을 삭제   \\n\\n자연스러움을 위해 stanford alpaca data, oig_chip2를 ChatGPT3.5 turbo 16k를 이용하여 새롭게 전처리 과정을 거쳤습니다.https://github.com/JoJo0217/rlhf_korean_dataset/tree/main여기에서 자세한 설명을 볼 수 있으며데이터의 구성은 다음과 같습니다.   \\n\\n데이터 구성   \\n\\n\\t\\n\\t\\t\\n데이터 종류\\n개수\\nurl\\n\\n\\n\\t\\t\\nkoalpaca v1.1\\n21155… See the full description on the dataset page: https://huggingface.co/datasets/jojo0217/korean_rlhf_dataset."},
	{"name":"belebele","keyword":"korean","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/facebook/belebele","creator_name":"AI at Meta","creator_url":"https://huggingface.co/facebook","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tThe Belebele Benchmark for Massively Multilingual NLU Evaluation\\n\\t\\n\\nBelebele is a multiple-choice machine reading comprehension (MRC) dataset spanning 122 language variants. This dataset enables the evaluation of mono- and multi-lingual models in high-, medium-, and low-resource languages. Each question has four multiple-choice answers and is linked to a short passage from the FLORES-200 dataset. The human annotation procedure was carefully curated to create questions that… See the full description on the dataset page: https://huggingface.co/datasets/facebook/belebele."},
	{"name":"OpenOrca-KO","keyword":"korean","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/kyujinpy/OpenOrca-KO","creator_name":"KyujinHan","creator_url":"https://huggingface.co/kyujinpy","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tOpenOrca-KO\\n\\t\\n\\n\\nOpenOrca dataset 중 약 2만개를 sampling하여 번역한 데이터셋\\n데이터셋 이용하셔서 모델이나 데이터셋을 만드실 때, 간단한 출처 표기를 해주신다면 연구에 큰 도움이 됩니다😭😭\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset inf0\\n\\t\\n\\n\\nNIV // 1571개  \\nFLAN // 9434개  \\nT0 // 6351개  \\nCoT // 2117개  \\nKoCoT // 2159개\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tTranslation\\n\\t\\n\\nUsing DeepL Pro API. Thanks.\\n\\n\\nBelow is original dataset card\\n\\n🐋 The OpenOrca Dataset! 🐋\\n\\n\\n\\nWe are thrilled to announce the release of the OpenOrca dataset!\\nThis rich collection of augmented FLAN data aligns, as best as… See the full description on the dataset page: https://huggingface.co/datasets/kyujinpy/OpenOrca-KO."},
	{"name":"OpenOrca-gugugo-ko","keyword":"korean","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/squarelike/OpenOrca-gugugo-ko","creator_name":"Woojun Jeong","creator_url":"https://huggingface.co/squarelike","description":"\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tOpenOrca 한국어 번역 데이터셋\\n\\t\\n\\nGugugo-koen-7B-V1.1을 이용하여 OpenOrca데이터셋을 번역하고 있습니다.\\n번역 진행상황은 아래를 참고해 주십시오.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\t진행상황\\n\\t\\n\\n\\nGPT4 생성물 약 100만 개 중 약 64만 개 번역완료\\nGPT3.5 생성물 약 350만 개 중 약 159만 개 번역완료\\n\\n데이터셋 사용 후 출처표기는 제작자에게 큰 힘이 됩니다.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tOriginal dataset card: OpenOrca\\n\\t\\n\\n🐋 The OpenOrca Dataset! 🐋\\n\\n\\n\\nWe are thrilled to announce the release of the OpenOrca dataset!\\nThis rich collection of augmented FLAN data aligns, as best as possible, with the distributions outlined in the Orca… See the full description on the dataset page: https://huggingface.co/datasets/squarelike/OpenOrca-gugugo-ko."},
	{"name":"Open_Assistant_Conversation_Chains","keyword":"korean","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/m-ric/Open_Assistant_Conversation_Chains","creator_name":"Aymeric Roucher","creator_url":"https://huggingface.co/m-ric","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Dataset Name\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset description\\n\\t\\n\\n\\n\\nThis dataset is a reformatting of OpenAssistant Conversations (OASST1), which is\\n\\na human-generated, human-annotated assistant-style conversation corpus consisting of 161,443 messages in 35 different languages, annotated with 461,292 quality ratings, resulting in over 10,000 fully annotated conversation trees. The corpus is a product of a worldwide crowd-sourcing effort involving over 13,500 volunteers.\\n\\nIt was… See the full description on the dataset page: https://huggingface.co/datasets/m-ric/Open_Assistant_Conversation_Chains."},
	{"name":"librivox-tracks","keyword":"korean","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/pykeio/librivox-tracks","creator_name":"pyke.io","creator_url":"https://huggingface.co/pykeio","description":"A dataset of all audio files uploaded to LibriVox before 26th September 2023.\\n"},
	{"name":"multilingual-pl-bert","keyword":"korean","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/styletts2-community/multilingual-pl-bert","creator_name":"StyleTTS 2 Community","creator_url":"https://huggingface.co/styletts2-community","description":"Attribution: Wikipedia.org\\n"},
	{"name":"korean_textbooks","keyword":"korean","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/maywell/korean_textbooks","creator_name":"Jeonghwan Park","creator_url":"https://huggingface.co/maywell","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tMassive Korean synthetic dataset\\n\\t\\n\\nThis dataset is a large-scale Korean artificial data set created using Gemini Pro.\\nIt was created using the methodology described in Creation of synthetic textbook-quality datasets in Textbooks Are All You Need.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData overview\\n\\t\\n\\nA subset of each dataset does not indicate the contents of that dataset.\\nFurther modification required before use this dataset for training.\\n본 데이터셋은 바로 사용하기보다는 하고자하는 task에 맞추어 가공 후 사용을 권장드립니다. ex) 로컬 모델을 사용하여… See the full description on the dataset page: https://huggingface.co/datasets/maywell/korean_textbooks."},
	{"name":"openassistant-deepseek-coder","keyword":"korean","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Trelis/openassistant-deepseek-coder","creator_name":"Trelis","creator_url":"https://huggingface.co/Trelis","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tChat Fine-tuning Dataset - OpenAssistant DeepSeek Coder\\n\\t\\n\\nThis dataset allows for fine-tuning chat models using:\\nB_INST = '\\\\n### Instruction:\\\\n'\\nE_INST = '\\\\n### Response:\\\\n'\\nBOS = '<｜begin▁of▁sentence｜>'\\nEOS = '\\\\n<|EOT|>\\\\n'\\n\\nSample Preparation:\\n\\nThe dataset is cloned from TimDettmers, which itself is a subset of the Open Assistant dataset, which you can find here. This subset of the data only contains the highest-rated paths in the conversation tree, with a total of 9,846 samples.… See the full description on the dataset page: https://huggingface.co/datasets/Trelis/openassistant-deepseek-coder."},
	{"name":"sharegpt_dialogue_base","keyword":"korean","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/lamhieu/sharegpt_dialogue_base","creator_name":"Hieu Lam","creator_url":"https://huggingface.co/lamhieu","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDescription\\n\\t\\n\\nThe dataset is from unknown, formatted as dialogues for speed and ease of use. Many thanks to author for releasing it.\\nImportantly, this format is easy to use via the default chat template of transformers, meaning you can use huggingface/alignment-handbook immediately, unsloth.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tStructure\\n\\t\\n\\nView online through viewer.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tNote\\n\\t\\n\\nWe advise you to reconsider before use, thank you. If you find it useful, please like and follow this account.… See the full description on the dataset page: https://huggingface.co/datasets/lamhieu/sharegpt_dialogue_base."},
	{"name":"sib200","keyword":"korean","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Davlan/sib200","creator_name":"David Adelani","creator_url":"https://huggingface.co/Davlan","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for SIB-200\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nSIB-200 is the largest publicly available topic classification dataset based on Flores-200 covering 205 languages and dialects.\\nThe train/validation/test sets are available for all the 205 languages.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSupported Tasks and Leaderboards\\n\\t\\n\\n\\ntopic classification: categorize wikipedia sentences into topics e.g science/technology, sports or politics.\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages\\n\\t\\n\\nThere are 205 languages available :… See the full description on the dataset page: https://huggingface.co/datasets/Davlan/sib200."},
	{"name":"aya_dataset","keyword":"korean","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/CohereForAI/aya_dataset","creator_name":"Cohere For AI","creator_url":"https://huggingface.co/CohereForAI","description":"\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThe Aya Dataset is a multilingual instruction fine-tuning dataset curated by an open-science community via Aya Annotation Platform from Cohere For AI. The dataset contains a total of 204k human-annotated prompt-completion pairs along with the demographics data of the annotators.\\nThis dataset can be used to train, finetune, and evaluate multilingual LLMs.\\n\\nCurated by: Contributors of Aya Open Science Intiative.\\n\\nLanguage(s): 65 languages (71 including dialects &… See the full description on the dataset page: https://huggingface.co/datasets/CohereForAI/aya_dataset."},
	{"name":"aya_collection","keyword":"korean","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/CohereForAI/aya_collection","creator_name":"Cohere For AI","creator_url":"https://huggingface.co/CohereForAI","description":"\\nThis dataset is uploaded in two places: here and additionally here as 'Aya Collection Language Split.' These datasets are identical in content but differ in structure of upload. This dataset is structured by folders split according to dataset name. The version here instead divides the Aya collection into folders split by language. We recommend you use the language split version if you are only interested in downloading data for a single or smaller set of languages, and this version if you… See the full description on the dataset page: https://huggingface.co/datasets/CohereForAI/aya_collection."},
	{"name":"aya_evaluation_suite","keyword":"korean","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/CohereForAI/aya_evaluation_suite","creator_name":"Cohere For AI","creator_url":"https://huggingface.co/CohereForAI","description":"\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nAya Evaluation Suite contains a total of 26,750 open-ended conversation-style prompts to evaluate multilingual open-ended generation quality.To strike a balance between language coverage and the quality that comes with human curation, we create an evaluation suite that includes:\\n\\nhuman-curated examples in 7 languages (tur, eng, yor, arb, zho, por, tel) → aya-human-annotated.\\nmachine-translations of handpicked examples into 101 languages →… See the full description on the dataset page: https://huggingface.co/datasets/CohereForAI/aya_evaluation_suite."},
	{"name":"CulturaY","keyword":"korean","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ontocord/CulturaY","creator_name":"Ontocord.AI","creator_url":"https://huggingface.co/ontocord","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tCulturaY: A Large Cleaned Multilingual Dataset of 75 Languages\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nFrom the team that brought you CulturaX, we present CulturaY, another substantial multilingual dataset of 15TB (uncompressed)/3TB (zstd-compressed) that applies the same dataset cleaning methodology to the HPLT v1.1 dataset. \\nPlease note that HPLT v1.2 has also been released and is an alternative verison with different cleaning methodolgies. \\nThis data was used in part to train our SOTA… See the full description on the dataset page: https://huggingface.co/datasets/ontocord/CulturaY."},
	{"name":"NIKL-korean-english-dictionary","keyword":"korean","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/binjang/NIKL-korean-english-dictionary","creator_name":"Bin Jang","creator_url":"https://huggingface.co/binjang","description":"\\n\\t\\n\\t\\t\\nColumn Name\\nType\\nDescription\\n설명\\n\\n\\n\\t\\t\\nForm\\nstr\\nRegistered word entry\\n단어\\n\\n\\nPart of Speech\\nstr or None\\nPart of speech of the word in Korean\\n품사\\n\\n\\nKorean Definition\\nList[str]\\nDefinition of the word in Korean\\n해당 단어의 한글 정의\\n\\n\\nEnglish Definition\\nList[str] or None\\nDefinition of the word in English\\n한글 정의의 영문 번역본\\n\\n\\nUsages\\nList[str] or None\\nSample sentence or dialogue\\n해당 단어의 예문 (문장 또는 대화 형식)\\n\\n\\nVocabulary Level\\nstr or None\\nDifficulty of the word (3 levels)\\n단어의 난이도 ('초급', '중급', '고급')\\n\\n\\nSemantic… See the full description on the dataset page: https://huggingface.co/datasets/binjang/NIKL-korean-english-dictionary."},
	{"name":"KoCommercial-Dataset","keyword":"korean","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/MarkrAI/KoCommercial-Dataset","creator_name":"Markr","creator_url":"https://huggingface.co/MarkrAI","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSSL 데이터 생성을 위한 코드 공개\\n\\t\\n\\nSSL 데이터 생성용 Github Repo\\n\\nNIA와  AI-Hub와의 저작권 협의 하에, 조금 혼선이 생긴것 죄송합니다.\\n\\n이에 기존에 저희가 code베이스로 SSL 데이터를 생성했던 코드를 그대로 공개드립니다.\\n\\n다만, 이 과정에서는 저희 이후 파이프라인인, 자체 로컬 모델을 가지고 필터링하거나 수정하는 과정이 없어, 어느정도 감안을 해주시면 감사하겠습니다.\\n\\n코드는 누구나 사용하실 수 있고 과제와 Task에 맞게 활용하시면 감사하겠습니다!\\n\\n\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset: KoCommercial-Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tInfo\\n\\t\\n\\nDataset 개수: 약 1.44M\\nLicense: MIT \\nDataset list(전부 상업적 용도로 이용가능)  \\n\\nkyujinpy/KOpen-platypus (*Except non-commercial datasets)… See the full description on the dataset page: https://huggingface.co/datasets/MarkrAI/KoCommercial-Dataset."},
	{"name":"aihub-flores-koen-integrated-prime-small-30k","keyword":"korean","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/traintogpb/aihub-flores-koen-integrated-prime-small-30k","creator_name":"Sehyeong Kim","creator_url":"https://huggingface.co/traintogpb","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tHigh Quality Ko-En Translation Dataset (AIHub-FLoRes Integrated)\\n\\t\\n\\nAI Hub의 한-영 번역 데이터셋과 FLoRes 한-영 번역 데이터셋의 합본입니다.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tHigh Quality AIHub Dataset\\n\\t\\n\\nAI Hub의 경우 한-영 번역 관련 데이터셋을 8개 병합한 병렬 데이터 traintogpb/aihub-koen-translation-integrated-tiny-100k에서 고품질의 번역 레퍼런스를 가진 데이터만 추출하였습니다.\\n번역 레퍼런스 품질 평가 척도는 Unbabel/XCOMET-XL (3.5B)로 측정한 xCOMET metric입니다.\\n8개의 AIHub 데이터 소스 중 기존 실험을 통해 번역 성능(SacreBLEU)이 낮았던 4개의 소스에서 xCOMET 기준 상위 5,000개, 그 외 4개의 소스에서 xCOMET 기준 상위 2,500개를 추출해 총 약 3만 개의 데이터를… See the full description on the dataset page: https://huggingface.co/datasets/traintogpb/aihub-flores-koen-integrated-prime-small-30k."},
	{"name":"aya_collection_language_split","keyword":"korean","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/CohereForAI/aya_collection_language_split","creator_name":"Cohere For AI","creator_url":"https://huggingface.co/CohereForAI","description":"\\nThis is a re-upload of the aya_collection, and only differs in the structure of upload. While the original aya_collection is structured by folders split according to dataset name, this dataset is split by language. We recommend you use this version of the dataset if you are only interested in downloading all of the Aya collection for a single or smaller set of languages.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThe Aya Collection is a massive multilingual collection consisting of 513 million instances… See the full description on the dataset page: https://huggingface.co/datasets/CohereForAI/aya_collection_language_split."},
	{"name":"tokenizer-wiki-bench","keyword":"korean","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/occiglot/tokenizer-wiki-bench","creator_name":"Occiglot","creator_url":"https://huggingface.co/occiglot","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tMultilingual Tokenizer Benchmark\\n\\t\\n\\nThis dataset includes pre-processed wikipedia data for tokenizer evaluation in 45 languages. We provide more information on the evaluation task in general this blogpost.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tUsage\\n\\t\\n\\nThe dataset allows us to easily calculate tokenizer fertility and the proportion of continued words on any of the supported languages. In the example below we take the Mistral tokenizer and evaluate its performance on Slovak. \\nfrom transformers import… See the full description on the dataset page: https://huggingface.co/datasets/occiglot/tokenizer-wiki-bench."},
	{"name":"kollm-converations","keyword":"korean","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/davidkim205/kollm-converations","creator_name":"davidkim205","creator_url":"https://huggingface.co/davidkim205","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tkollm Converations Dataset\\n\\t\\n\\nThis dataset is an integrated dataset created in conversations format for SFT learning using the Korean dataset currently available on huggingface and github.\\nOur the nox model was trained on the kollm dataset. For datasets that are private due to license restrictions, please download them directly from the URL below.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tIncluded datasets\\n\\t\\n\\n\\n\\t\\n\\t\\t\\nSource\\n설명\\n원본 URL\\n\\n\\n\\t\\t\\nKoAlpaca-v1.1\\n네이버 지식인 질답을 ChatGPT를 이용해 재생성한 Alpaca 형식 데이터셋… See the full description on the dataset page: https://huggingface.co/datasets/davidkim205/kollm-converations."},
	{"name":"orca-math-korean-dpo-pairs","keyword":"korean","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/kuotient/orca-math-korean-dpo-pairs","creator_name":"Jisoo Kim","creator_url":"https://huggingface.co/kuotient","description":"axolotl does not take revision arg as an option and i'm lazy so i made this.\\ntype: chatml.intel\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tOrca-math-korean-preference\\n\\t\\n\\n\\nquestion: orca-math dataset의 question\\nchosen: label이 참일 경우 answer 혹은 generated의 random.choice, 거짓일 경우 answer (Orca-math original paper 참고)\\nrejected: label이 참일 경우 다른 rejected value의 random.choice, 거짓일 경우 rejected (Orca-math original paper 참고)\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\t비고\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tllm_exact_match prompt\\n\\t\\n\\nSYSTEM_PROMPT:\\nAs an expert Math teacher, your role is to… See the full description on the dataset page: https://huggingface.co/datasets/kuotient/orca-math-korean-dpo-pairs."},
	{"name":"korean_safe_conversation","keyword":"korean","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/jojo0217/korean_safe_conversation","creator_name":"mingyu jo","creator_url":"https://huggingface.co/jojo0217","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\t개요\\n\\t\\n\\n성균관대 - VAIV COMPANY 산학협력을 위해 구축한 일상대화 데이터입니다.   \\n자연스럽고 윤리적인 챗봇 구축을 위한 데이터셋 입니다.   \\n고품질을 위해 대부분의 과정에서 사람이 직접 검수하였으며생성 번역 등의 과정에서는 GPT3.5-turbo, GPT4를 사용하였습니다.   \\n일상대화에 중점을 두면서혐오표현, 편향적인 대답을 지양하면서 일상대화를 하는 것에 중점을 두었습니다.   \\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\t데이터 구축 과정\\n\\t\\n\\n    \\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\t데이터 구성\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n데이터 종류\\n개수\\n비고\\nurl\\n\\n\\n\\t\\t\\n일상대화 데이터셋\\n2063\\n국립국어원 모두의 말뭉치\\nhttps://corpus.korean.go.kr/request/reausetMain.do?lang=ko\\n\\n\\n감성대화\\n1020\\nAIHub 감성대화 데이터… See the full description on the dataset page: https://huggingface.co/datasets/jojo0217/korean_safe_conversation."},
	{"name":"webui-dom-snapshots","keyword":"korean","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/gbenson/webui-dom-snapshots","creator_name":"Gary Benson","creator_url":"https://huggingface.co/gbenson","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for WebUI DOM snapshots\\n\\t\\n\\n\\n\\nThis dataset card aims to be a base template for new datasets. It has been generated using this raw template.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Details\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\n\\n\\n\\n\\n\\nCurated by: Gary Benson\\nLanguages: Mostly English (87%);\\nDutch, French, Chinese, Japanese (1-2% each); 30+ others (<1% each)\\nLicense: CC0 1.0 Universal\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Sources [optional]\\n\\t\\n\\n\\n\\n\\nRepository: [More Information Needed]\\nPaper [optional]: [More… See the full description on the dataset page: https://huggingface.co/datasets/gbenson/webui-dom-snapshots."},
	{"name":"korean_parallel_sentences_v1.1","keyword":"korean","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/lemon-mint/korean_parallel_sentences_v1.1","creator_name":"Lemon Mint","creator_url":"https://huggingface.co/lemon-mint","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Korean Parallel Sentences Ver 1.1\\n\\t\\n\\nThis dataset card provides information about the Korean Parallel Sentences Ver 1.1 dataset.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Details\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThe Korean Parallel Sentences Ver 1.1 dataset is a collection of parallel sentences in Korean and English.\\nAlthough the factual accuracy of the data is not guaranteed, it has been designed to ensure accurate and consistent translation style between English and Korean.… See the full description on the dataset page: https://huggingface.co/datasets/lemon-mint/korean_parallel_sentences_v1.1."},
	{"name":"korean_parallel_sentences_v1.1","keyword":"korean","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/lemon-mint/korean_parallel_sentences_v1.1","creator_name":"Lemon Mint","creator_url":"https://huggingface.co/lemon-mint","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Korean Parallel Sentences Ver 1.1\\n\\t\\n\\nThis dataset card provides information about the Korean Parallel Sentences Ver 1.1 dataset.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Details\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThe Korean Parallel Sentences Ver 1.1 dataset is a collection of parallel sentences in Korean and English.\\nAlthough the factual accuracy of the data is not guaranteed, it has been designed to ensure accurate and consistent translation style between English and Korean.… See the full description on the dataset page: https://huggingface.co/datasets/lemon-mint/korean_parallel_sentences_v1.1."},
	{"name":"RAG-Evaluation-Dataset-KO","keyword":"korean","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/allganize/RAG-Evaluation-Dataset-KO","creator_name":"allganize","creator_url":"https://huggingface.co/allganize","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tAllganize RAG Leaderboard\\n\\t\\n\\nAllganize RAG 리더보드는 5개 도메인(금융, 공공, 의료, 법률, 커머스)에 대해서 한국어 RAG의 성능을 평가합니다.일반적인 RAG는 간단한 질문에 대해서는 답변을 잘 하지만, 문서의 테이블과 이미지에 대한 질문은 답변을 잘 못합니다.  \\nRAG 도입을 원하는 수많은 기업들은 자사에 맞는 도메인, 문서 타입, 질문 형태를 반영한 한국어 RAG 성능표를 원하고 있습니다.평가를 위해서는 공개된 문서와 질문, 답변 같은 데이터 셋이 필요하지만, 자체 구축은 시간과 비용이 많이 드는 일입니다.이제 올거나이즈는 RAG 평가 데이터를 모두 공개합니다. \\nRAG는 Parser, Retrieval, Generation 크게 3가지 파트로 구성되어 있습니다.현재, 공개되어 있는 RAG 리더보드 중, 3가지 파트를 전체적으로 평가하는 한국어로 구성된 리더보드는 없습니다.\\nAllganize RAG 리더보드에서는… See the full description on the dataset page: https://huggingface.co/datasets/allganize/RAG-Evaluation-Dataset-KO."},
	{"name":"ko-instruction-dataset","keyword":"korean","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/CarrotAI/ko-instruction-dataset","creator_name":"CarrotCarrot","creator_url":"https://huggingface.co/CarrotAI","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\t고품질 한국어 데이터셋\\n\\t\\n\\n한국어로 이루어진 고품질 한국어 데이터셋 입니다.\\nWizardLM-2-8x22B 모델을 사용하여 WizardLM: Empowering Large Language Models to Follow Complex Instructions에서 소개된 방법으로 생성되었습니다.\\n@article{koinstructiondatasetcard,\\n  title={CarrotAI/ko-instruction-dataset Card},\\n  author={CarrotAI (L, GEUN)},\\n  year={2024},\\n  url = {https://huggingface.co/datasets/CarrotAI/ko-instruction-dataset}\\n}\\n\\n"},
	{"name":"Block_Diagram","keyword":"korean","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/shreyanshu09/Block_Diagram","creator_name":"Shreyanshu Bhushan","creator_url":"https://huggingface.co/shreyanshu09","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tBlock Diagram Dataset\\n\\t\\n\\nThis dataset is a combination of four block diagram datasets. The first dataset is the BD-EnKo dataset, which was introduced in the paper \\\"Unveiling the Power of Integration: Block Diagram Summarization through Local-Global Fusion\\\" accepted at ACL 2024. The second dataset is CBD, the third is FC_A, and the fourth is FC_B.\\nOnly BD-EnKo dataset is available here.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset description\\n\\t\\n\\nThis dataset contains different types of block diagram images… See the full description on the dataset page: https://huggingface.co/datasets/shreyanshu09/Block_Diagram."},
	{"name":"GlotCC-V1","keyword":"korean","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/cis-lmu/GlotCC-V1","creator_name":"CIS, LMU Munich","creator_url":"https://huggingface.co/cis-lmu","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\n \\n\\nGlotCC-V1.0 is a document-level, general domain dataset derived from CommonCrawl, covering more than 1000 languages.It is built using the GlotLID language identification and Ungoliant pipeline from CommonCrawl.We release our pipeline as open-source at https://github.com/cisnlp/GlotCC.  \\nList of Languages: See https://datasets-server.huggingface.co/splits?dataset=cis-lmu/GlotCC-V1 to get the list of splits available.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tUsage (Huggingface Hub --… See the full description on the dataset page: https://huggingface.co/datasets/cis-lmu/GlotCC-V1."},
	{"name":"GlotCC-V1","keyword":"korean","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/cis-lmu/GlotCC-V1","creator_name":"CIS, LMU Munich","creator_url":"https://huggingface.co/cis-lmu","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\n \\n\\nGlotCC-V1.0 is a document-level, general domain dataset derived from CommonCrawl, covering more than 1000 languages.It is built using the GlotLID language identification and Ungoliant pipeline from CommonCrawl.We release our pipeline as open-source at https://github.com/cisnlp/GlotCC.  \\nList of Languages: See https://datasets-server.huggingface.co/splits?dataset=cis-lmu/GlotCC-V1 to get the list of splits available.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tUsage (Huggingface Hub --… See the full description on the dataset page: https://huggingface.co/datasets/cis-lmu/GlotCC-V1."},
	{"name":"KBMC","keyword":"korean","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/SungJoo/KBMC","creator_name":"Grace","creator_url":"https://huggingface.co/SungJoo","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThis dataset is the first open-source medical Named Entity Recognition (NER) dataset in Korean language.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Structure\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Instances\\n\\t\\n\\nEach row in the KBMC.tsv file contains a sentence with its corresponding named entities (Disease, Body, and Treatement).\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Fields\\n\\t\\n\\n\\nsentence: The sentence text.\\ntags: The named entities in the sentence.\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLicensing Information\\n\\t\\n\\nThe dataset is provided under the Apache… See the full description on the dataset page: https://huggingface.co/datasets/SungJoo/KBMC."},
	{"name":"KBMC","keyword":"korean","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/SungJoo/KBMC","creator_name":"Grace","creator_url":"https://huggingface.co/SungJoo","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThis dataset is the first open-source medical Named Entity Recognition (NER) dataset in Korean language.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Structure\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Instances\\n\\t\\n\\nEach row in the KBMC.tsv file contains a sentence with its corresponding named entities (Disease, Body, and Treatement).\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Fields\\n\\t\\n\\n\\nsentence: The sentence text.\\ntags: The named entities in the sentence.\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLicensing Information\\n\\t\\n\\nThe dataset is provided under the Apache… See the full description on the dataset page: https://huggingface.co/datasets/SungJoo/KBMC."},
	{"name":"BCCard-Finance-Kor-QnA","keyword":"korean","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/BCCard/BCCard-Finance-Kor-QnA","creator_name":"BC Card","creator_url":"https://huggingface.co/BCCard","description":"BCCard/BCCard-Finance-Kor-QnA dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"nomiracl-instruct","keyword":"korean","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/miracl/nomiracl-instruct","creator_name":"MIRACL","creator_url":"https://huggingface.co/miracl","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for NoMIRACL (EMNLP 2024 Findings Track)\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tQuick Overview\\n\\t\\n\\nThis repository contains the fine-tuning (training & development split) of the NoMIRACL instruct dataset for fine-tuning LLMs on multilingual relevance assessment.\\nThe training dataset is a binary classification task; they need to explicitly output either Yes, answer is present or I don't know. \\nThe dataset contains training pairs from all 18 languages for both splits: relevant & non-relevant.… See the full description on the dataset page: https://huggingface.co/datasets/miracl/nomiracl-instruct."},
	{"name":"KoMT-Bench","keyword":"korean","license":"GNU Lesser General Public License v3.0","license_url":"https://choosealicense.com/licenses/lgpl-3.0/","language":"en","dataset_url":"https://huggingface.co/datasets/LGAI-EXAONE/KoMT-Bench","creator_name":"LG AI Research","creator_url":"https://huggingface.co/LGAI-EXAONE","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tKoMT-Bench\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tIntroduction\\n\\t\\n\\nWe present KoMT-Bench, a benchmark designed to evaluate the capability of language models in following instructions in Korean.\\nKoMT-Bench is an in-house dataset created by translating MT-Bench [1]  dataset into Korean and modifying some questions to reflect the characteristics and cultural nuances of the Korean language.\\nAfter the initial translation and modification, we requested expert linguists to conduct a thorough review of our… See the full description on the dataset page: https://huggingface.co/datasets/LGAI-EXAONE/KoMT-Bench."},
	{"name":"text_ratings","keyword":"korean","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/lightblue/text_ratings","creator_name":"Lightblue KK.","creator_url":"https://huggingface.co/lightblue","description":"Todo - Write dataset card\\n"},
	{"name":"rag-eval-mini","keyword":"korean","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/teddylee777/rag-eval-mini","creator_name":"Teddy Lee","creator_url":"https://huggingface.co/teddylee777","description":"teddylee777/rag-eval-mini dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"korean-writing-style-instruct","keyword":"korean","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/coastral/korean-writing-style-instruct","creator_name":"Coastral","creator_url":"https://huggingface.co/coastral","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\t한국어 문체 데이터셋\\n\\t\\n\\n여러 분야의 문체(문학, 일상적 대화, 고전시가 등)를 포함한 합성 데이터셋입니다. 모델에게 여러 문체를 출력하는 능력을 가르치기 위해 제작되었습니다. 훈련시키실 때, 일반 인스트럭스 데이터셋과 혼용해서 사용하시는 것을 추천드립니다.\\n이 데이터셋은 apache-2 라이선스로 자유롭게 이용하실 수 있습니다. 데이터는 Glaive 플랫폼을 통해 합성되었고, 한글이 아닌 출력은 걸러냈습니다.\\n"},
	{"name":"MMMLU","keyword":"korean","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/openai/MMMLU","creator_name":"OpenAI","creator_url":"https://huggingface.co/openai","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tMultilingual Massive Multitask Language Understanding (MMMLU)\\n\\t\\n\\nThe MMLU is a widely recognized benchmark of general knowledge attained by AI models. It covers a broad range of topics from 57 different categories, covering elementary-level knowledge up to advanced professional subjects like law, physics, history, and computer science.\\nWe translated the MMLU’s test set into 14 languages using professional human translators. Relying on human translators for this evaluation increases… See the full description on the dataset page: https://huggingface.co/datasets/openai/MMMLU."},
	{"name":"muri-it","keyword":"korean","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/akoksal/muri-it","creator_name":"Abdullatif Koksal","creator_url":"https://huggingface.co/akoksal","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tMURI-IT: Multilingual Instruction Tuning Dataset for 200 Languages via Multilingual Reverse Instructions\\n\\t\\n\\nMURI-IT is a large-scale multilingual instruction tuning dataset containing 2.2 million instruction-output pairs across 200 languages. It is designed to address the challenges of instruction tuning in low-resource languages with Multilingual Reverse Instructions (MURI), which ensures that the output is human-written, high-quality, and authentic to the cultural and linguistic… See the full description on the dataset page: https://huggingface.co/datasets/akoksal/muri-it."},
	{"name":"mmmlu_kor","keyword":"korean","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/4n3mone/mmmlu_kor","creator_name":"yongsang yoo","creator_url":"https://huggingface.co/4n3mone","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tMMMLU_KOREAN\\n\\t\\n\\nthis dataset is korean subset of openai/MMMLU dataset.\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tMultilingual Massive Multitask Language Understanding (MMMLU)\\n\\t\\n\\nThe MMLU is a widely recognized benchmark of general knowledge attained by AI models. It covers a broad range of topics from 57 different categories, covering elementary-level knowledge up to advanced professional subjects like law, physics, history, and computer science.\\nWe translated the MMLU’s test set into 14 languages using… See the full description on the dataset page: https://huggingface.co/datasets/4n3mone/mmmlu_kor."},
	{"name":"vqa","keyword":"korean","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/worldcuisines/vqa","creator_name":"World Cuisines","creator_url":"https://huggingface.co/worldcuisines","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tWorldCuisines: A Massive-Scale Benchmark for Multilingual and Multicultural Visual Question Answering on Global Cuisines\\n\\t\\n\\n\\nWorldCuisines is a massive-scale visual question answering (VQA) benchmark for multilingual and multicultural understanding through global cuisines. The dataset contains text-image pairs across 30 languages and dialects, spanning 9 language families and featuring over 1 million data points, making it the largest multicultural VQA benchmark as of 17 October… See the full description on the dataset page: https://huggingface.co/datasets/worldcuisines/vqa."},
	{"name":"atlassian-qna","keyword":"korean","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/youngmon/atlassian-qna","creator_name":"youngseo","creator_url":"https://huggingface.co/youngmon","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\t📄 Question and Answer for Atlassian Products\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Sources\\n\\t\\n\\n\\nAtlassian Community\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Description\\n\\t\\n\\nThe dataset primarily includes questions, answers, tags, and URLs.\\n\\nQuestions contain the author, title, and content of the post.\\nAnswers include usage instructions, solutions, and other information provided by engineers and users.\\nTags represent the categories or topics of the post.\\nURLs provide links to the original documents.\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset… See the full description on the dataset page: https://huggingface.co/datasets/youngmon/atlassian-qna."},
	{"name":"hermes-function-calling-v1-ko","keyword":"korean","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/iknow-lab/hermes-function-calling-v1-ko","creator_name":"iknow-lab","creator_url":"https://huggingface.co/iknow-lab","description":"\\nOriginal Data: NousResearch/hermes-function-calling-v1\\nGPT-4o-mini로 번역했으나, 길이가 너무 길거나 에러가 난 경우가 1300 건 가량 제외됨.\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tExample 1\\n\\t\\n\\n[\\n        {\\n            \\\"role\\\": \\\"system\\\",\\n            \\\"content\\\": \\\"당신은 전문가로서 구조화된 정보 추출 AI 모델입니다. 정보 추출을 위해 문서를 제공받습니다. 추출된 정보를 XML 태그 <tools></tools> 내의 함수 서명 형태로 출력할 json 스키마도 제공받습니다. json 스키마에 어떤 값을 넣을지 가정하지 마세요. \\\\n<tools>\\\\n[{\\\\\\\"type\\\\\\\": \\\\\\\"function\\\\\\\", \\\\\\\"function\\\\\\\": {\\\\\\\"name\\\\\\\": \\\\\\\"ExpertQAExtractor\\\\\\\", \\\\\\\"description\\\\\\\": \\\\\\\"문서에서 개념이나 정보가 실제 상황에 어떻게 적용될 수 있는지를 묻는… See the full description on the dataset page: https://huggingface.co/datasets/iknow-lab/hermes-function-calling-v1-ko."},
	{"name":"HPLT2.0_cleaned","keyword":"korean","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/HPLT/HPLT2.0_cleaned","creator_name":"HPLT","creator_url":"https://huggingface.co/HPLT","description":"This is a large-scale collection of web-crawled documents in 191 world languages, produced by the HPLT project. \\nThe source of the data is mostly Internet Archive with some additions from Common Crawl.\\nFor a detailed description of the dataset, please refer to https://hplt-project.org/datasets/v2.0\\nThe Cleaned variant of HPLT Datasets v2.0\\nThis is the cleaned variant of the HPLT Datasets v2.0 converted to the Parquet format semi-automatically when being uploaded here. \\nThe original JSONL files… See the full description on the dataset page: https://huggingface.co/datasets/HPLT/HPLT2.0_cleaned."},
	{"name":"m-ArenaHard","keyword":"korean","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/CohereForAI/m-ArenaHard","creator_name":"Cohere For AI","creator_url":"https://huggingface.co/CohereForAI","description":"\\n\\t\\n\\t\\t\\n\\t\\tDataset Card for m-ArenaHard\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Details\\n\\t\\n\\nThe m-ArenaHard dataset is a multilingual LLM evaluation set. This dataset was created by translating the prompts from the originally English-only LMarena (formerly LMSYS) arena-hard-auto-v0.1 test dataset using Google Translate API v3 to 22 languages. The original English-only prompts were created by Li et al. (2024) and consist of 500 challenging user queries sourced from Chatbot Arena. The authors show that these can be used… See the full description on the dataset page: https://huggingface.co/datasets/CohereForAI/m-ArenaHard."},
	{"name":"ko_leaderboard","keyword":"korean","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/AIDX-ktds/ko_leaderboard","creator_name":"aidx_ktds","creator_url":"https://huggingface.co/AIDX-ktds","description":"한국어 리더보드 학습에서 사용된 데이터 중 약 8,000건에 대해서\\n공개합니다. 데이터 생성 시 도움이 되기를 바랍니다.\\n감사합니다.\\n"},
	{"name":"ko_leaderboard","keyword":"korean","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/AIDX-ktds/ko_leaderboard","creator_name":"aidx_ktds","creator_url":"https://huggingface.co/AIDX-ktds","description":"한국어 리더보드 학습에서 사용된 데이터 중 약 8,000건에 대해서\\n공개합니다. 데이터 생성 시 도움이 되기를 바랍니다.\\n감사합니다.\\n"},
	{"name":"VoxCommunis","keyword":"korean","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/pacscilab/VoxCommunis","creator_name":"PaCSciLab @ UZH","creator_url":"https://huggingface.co/pacscilab","description":"The VoxCommunis Corpus contains acoustic models, lexicons, and force-aligned TextGrids with phone- and word-level segmentations derived from the Mozilla Common Voice Corpus. The Mozilla Common Voice Corpus and derivative VoxCommunis Corpus stored here are free to download and use under a CC0 license.\\nThe lexicons are developed using Epitran, the XPF Corpus, Charsiu, and some custom dictionaries. Some manual correction has been applied, and we hope to continue improving these. Any updates from… See the full description on the dataset page: https://huggingface.co/datasets/pacscilab/VoxCommunis."},
	{"name":"P-MMEval","keyword":"korean","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Qwen/P-MMEval","creator_name":"Qwen","creator_url":"https://huggingface.co/Qwen","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tP-MMEval: A Parallel Multilingual Multitask Benchmark for Consistent Evaluation of LLMs\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tIntroduction\\n\\t\\n\\nWe introduce a multilingual benchmark, P-MMEval, covering effective fundamental and capability-specialized datasets. We extend the existing benchmarks, ensuring consistent language coverage across all datasets and providing parallel samples among multiple languages, supporting up to 10 languages from 8 language families (i.e., en, zh, ar, es, ja, ko, th, fr, pt… See the full description on the dataset page: https://huggingface.co/datasets/Qwen/P-MMEval."},
	{"name":"General-Evol-VQA","keyword":"korean","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/maum-ai/General-Evol-VQA","creator_name":"maum-ai","creator_url":"https://huggingface.co/maum-ai","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for General-Evol-VQA-1.2M\\n\\t\\n\\nThis dataset has been carefully curated to enhance the general instruction capabilities of Vision-Language Models (VLMs). It comprises two subsets:\\n\\n600k English samples\\n600k Korean samples\\n\\nWe recommend using this dataset alongside other task-specific datasets (e.g., OCR, Language, code, math, ...) to improve performance and achieve more robust model capabilities.\\n\\nMade by: maum.ai Brain NLP. Jaeyoon Jung, Yoonshik Kim\\nDataset Target… See the full description on the dataset page: https://huggingface.co/datasets/maum-ai/General-Evol-VQA."},
	{"name":"belebele-fleurs","keyword":"korean","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/WueNLP/belebele-fleurs","creator_name":"WüNLP","creator_url":"https://huggingface.co/WueNLP","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tBelebele-Fleurs\\n\\t\\n\\nBelebele-Fleurs is a dataset suitable to evaluate two core tasks:\\n\\nMultilingual Spoken Language Understanding (Listening Comprehension): For each spoken paragraph, the task is to answer a multiple-choice question. The question and four answer choices are provided in text form.\\nMultilingual Long-Form Automatic Speech Recognition (ASR) with Diverse Speakers: By concatenating sentence-level utterances, long-form audio clips (ranging from 30 seconds to 1 minute 30… See the full description on the dataset page: https://huggingface.co/datasets/WueNLP/belebele-fleurs."},
	{"name":"include-base-44","keyword":"korean","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/CohereForAI/include-base-44","creator_name":"Cohere For AI","creator_url":"https://huggingface.co/CohereForAI","description":"\\n\\t\\n\\t\\t\\n\\t\\tINCLUDE-base (44 languages)\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\n\\n\\nPaper: http://arxiv.org/abs/2411.19799\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nINCLUDE is a comprehensive knowledge- and reasoning-centric benchmark across 44 languages that evaluates multilingual LLMs for performance in the actual language environments where they would be deployed. \\nIt contains 22,637 4-option multiple-choice-questions (MCQ) extracted from academic and professional exams, covering 57 topics, including regional… See the full description on the dataset page: https://huggingface.co/datasets/CohereForAI/include-base-44."},
	{"name":"open-dict-words-ipa","keyword":"korean","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/StephanAkkerman/open-dict-words-ipa","creator_name":"Stephan Akkerman","creator_url":"https://huggingface.co/StephanAkkerman","description":"\\n\\t\\n\\t\\t\\n\\t\\tOpen-dict Words IPA\\n\\t\\n\\nThis dataset is a copy of https://github.com/open-dict-data/ipa-dict\\n\\n\\t\\n\\t\\t\\n\\t\\tLanguages\\n\\t\\n\\nIPA data is currently available for the following languages:\\n\\n\\t\\n\\t\\t\\nLanguage\\nCode\\n\\n\\n\\t\\t\\nar\\nArabic (Modern Standard)\\n\\n\\nde\\nGerman\\n\\n\\nen_UK\\nEnglish (Received Pronunciation)\\n\\n\\nen_US\\nEnglish (General American)\\n\\n\\neo\\nEsperanto\\n\\n\\nes_ES\\nSpanish (Spain)\\n\\n\\nes_MX\\nSpanish (Mexico)\\n\\n\\nfa\\nPersian\\n\\n\\nfi\\nFinnish\\n\\n\\nfr_FR\\nFrench (France)\\n\\n\\nfr_QC\\nFrench (Québec)\\n\\n\\nis\\nIcelandic\\n\\n\\nja\\nJapanese\\n\\n\\njam… See the full description on the dataset page: https://huggingface.co/datasets/StephanAkkerman/open-dict-words-ipa."},
	{"name":"include-lite-44","keyword":"korean","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/CohereForAI/include-lite-44","creator_name":"Cohere For AI","creator_url":"https://huggingface.co/CohereForAI","description":"\\n\\t\\n\\t\\t\\n\\t\\tINCLUDE-lite (44 languages)\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\n\\n\\nPaper: http://arxiv.org/abs/2411.19799\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nINCLUDE is a comprehensive knowledge- and reasoning-centric benchmark across 44 languages that evaluates multilingual LLMs for performance in the actual language environments where they would be deployed. \\nIt contains 11,095 4-option multiple-choice-questions (MCQ) extracted from academic and professional exams, covering 57 topics, including regional… See the full description on the dataset page: https://huggingface.co/datasets/CohereForAI/include-lite-44."},
	{"name":"sib-fleurs","keyword":"korean","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/WueNLP/sib-fleurs","creator_name":"WüNLP","creator_url":"https://huggingface.co/WueNLP","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSIB-Fleurs\\n\\t\\n\\nSIB-Fleurs is a dataset suitable to evaluate Multilingual Spoken Language Understanding. For each utterance in Fleurs, the task is to determine the topic the utterance belongs to. \\nThe topics are:\\n\\nScience/Technology\\nTravel\\nPolitics\\nSports\\nHealth\\nEntertainment\\nGeography\\n\\nPreliminary evaluations can be found at the bottom of the README. The preliminary results in full detail are available in ./results.csv*.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset creation\\n\\t\\n\\nThis dataset processes and… See the full description on the dataset page: https://huggingface.co/datasets/WueNLP/sib-fleurs."},
	{"name":"Global-MMLU-Lite","keyword":"korean","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/CohereForAI/Global-MMLU-Lite","creator_name":"Cohere For AI","creator_url":"https://huggingface.co/CohereForAI","description":"\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nGlobal-MMLU-Lite is a multilingual evaluation set spanning 15 languages, including English. It is \\\"lite\\\" version of the original Global-MMLU dataset 🌍.\\nIt includes 200 Culturally Sensitive (CS) and 200 Culturally Agnostic (CA) samples per language. The samples in Global-MMLU-Lite are corresponding to languages which are fully human translated or post-edited in the original Global-MMLU dataset. \\n\\nCurated by: Professional annotators and contributors of Cohere For… See the full description on the dataset page: https://huggingface.co/datasets/CohereForAI/Global-MMLU-Lite."},
	{"name":"2M-Belebele","keyword":"korean","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/facebook/2M-Belebele","creator_name":"AI at Meta","creator_url":"https://huggingface.co/facebook","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\t2M-Belebele\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tHighly-Multilingual Speech and American Sign Language Comprehension Dataset\\n\\t\\n\\nWe introduce 2M-Belebele as the first highly multilingual speech and American Sign Language (ASL) comprehension dataset. Our dataset, which is an extension of the existing Belebele only-text dataset, covers 74 spoken languages at the intersection of Belebele and Fleurs, and one sign language (ASL). \\nThe speech dataset is built from aligning Belebele, Flores200 and Fleurs… See the full description on the dataset page: https://huggingface.co/datasets/facebook/2M-Belebele."},
	{"name":"reranker_continuous_filt_max7_train","keyword":"korean","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/lightblue/reranker_continuous_filt_max7_train","creator_name":"Lightblue KK.","creator_url":"https://huggingface.co/lightblue","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tReranker training data\\n\\t\\n\\nThis data was generated using 4 steps:\\n\\nWe gathered queries and corresponding text data from 35 high quality datasets covering more than 95 languages.\\nFor datasets which did not already have negative texts for queries, we mined hard negatives using the BAAI/bge-m3 embedding model.\\nFor each query, we selected one positive and one negative text and used Qwen/Qwen2.5-32B-Instruct-GPTQ-Int4 to rate the relatedness of each query-text pair using a token \\\"1\\\", \\\"2\\\"… See the full description on the dataset page: https://huggingface.co/datasets/lightblue/reranker_continuous_filt_max7_train."},
	{"name":"Ko-functioncall","keyword":"korean","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/jaeyong2/Ko-functioncall","creator_name":"jeongjaeyong","creator_url":"https://huggingface.co/jaeyong2","description":"\\n\\t\\n\\t\\t\\n\\t\\tDevelopment Process\\n\\t\\n\\n\\nsource dataset from daje/ko_wiki and maywell/korean_textbooks\\nWe used Qwen/Qwen2-72B-Instruct model to generate answer with COT.\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tLicense\\n\\t\\n\\n\\nQwen/Qwen2.5-72B-Instruct : https://huggingface.co/Qwen/Qwen2-72B-Instruct/blob/main/LICENSE\\nmaywell/korean_textbooks : https://choosealicense.com/licenses/apache-2.0/\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tAcknowledgement\\n\\t\\n\\nThis research is supported by TPU Research Cloud program.\\n"},
	{"name":"reranking-datasets-light","keyword":"korean","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/abdoelsayed/reranking-datasets-light","creator_name":"unkown","creator_url":"https://huggingface.co/abdoelsayed","description":"\\n\\t\\n\\t\\t\\n\\t\\t🔥 Rankify: A Comprehensive Python Toolkit for Retrieval, Re-Ranking, and Retrieval-Augmented Generation 🔥\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tReRanking Datasets : A comprehensive collection of retrieval and reranking datasets with full passage contexts, including titles, text, and metadata for in-depth research.\\n\\t\\n\\n\\n    \\n    \\n    \\n    \\n    \\n    \\n        \\n    \\n    \\n        \\n    \\n    \\n        \\n    \\n    \\n        \\n    \\n    \\n    \\n\\n\\n\\nA curated collection of ready-to-use datasets for retrieval and reranking… See the full description on the dataset page: https://huggingface.co/datasets/abdoelsayed/reranking-datasets-light."},
	{"name":"MultiLingualSentiment","keyword":"korean","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/clapAI/MultiLingualSentiment","creator_name":"clapAI","creator_url":"https://huggingface.co/clapAI","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tOverview\\n\\t\\n\\nMultilingualSentiment is a sentiment classification dataset that encompasses three sentiment labels: Positive, Neutral, Negative\\nThe dataset spans multiple languages and covers a wide range of domains, making it ideal for multilingual sentiment analysis tasks.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Information\\n\\t\\n\\nThe dataset was meticulously collected and aggregated from various sources, including Hugging Face and Kaggle. These sources provide diverse languages and domains to ensure a… See the full description on the dataset page: https://huggingface.co/datasets/clapAI/MultiLingualSentiment."},
	{"name":"CoT-XLang","keyword":"korean","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Egor-AI/CoT-XLang","creator_name":"Egor AI","creator_url":"https://huggingface.co/Egor-AI","description":"RU:CoT-XLang — это многоязычный датасет, состоящий из текстовых примеров с пошаговыми рассуждениями (Chain-of-Thought, CoT) на различных языках, включая английский, русский, японский и другие. Он используется для обучения и тестирования моделей в задачах, требующих пояснений решений через несколько шагов. Датасет включает около 2,419,912 примеров, что позволяет эффективно обучать модели, способные генерировать пошаговые рассуждения.\\nРекомендация:Используйте датасет для обучения моделей… See the full description on the dataset page: https://huggingface.co/datasets/Egor-AI/CoT-XLang."},
	{"name":"medical-o1-reasoning-SFT-Ko","keyword":"korean","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ChuGyouk/medical-o1-reasoning-SFT-Ko","creator_name":"ChuGyouk","creator_url":"https://huggingface.co/ChuGyouk","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tIntroduction\\n\\t\\n\\nThe original data was used to fine-tune HuatuoGPT-o1, a medical LLM designed for advanced medical reasoning. Original dataset was constructed using GPT-4o, which searches for solutions to verifiable medical problems and validates them through a medical verifier. \\nFor details, see their paper and GitHub repository.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tTranslation\\n\\t\\n\\nFor translation into Korean, I used gemini-2.0-flash-exp model w/ temperature=0.5 setting.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tPrompt\\n\\t\\n\\n\\nYou are a… See the full description on the dataset page: https://huggingface.co/datasets/ChuGyouk/medical-o1-reasoning-SFT-Ko."},
	{"name":"vqa-rad-ko","keyword":"korean","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/junyeong-nero/vqa-rad-ko","creator_name":"Junyeong Song","creator_url":"https://huggingface.co/junyeong-nero","description":"junyeong-nero/vqa-rad-ko dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"SMPQA","keyword":"korean","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/WueNLP/SMPQA","creator_name":"WüNLP","creator_url":"https://huggingface.co/WueNLP","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSMPQA (Synthetic Multilingual Plot QA)\\n\\t\\n\\n\\n\\nThe SMPQA evaluation dataset proposed in Centurio: On Drivers of Multilingual Ability of Large Vision-Language Model.\\nSMPQA is composed of synthetic bar plots and pie charts (generated using word lists of different languages) together with questions about those plots.\\nThe datasets aims at providing an initial way of evaluating multilingual OCR capabilities of models in arbritrary languages.\\nThere are two sub-tasks: \\n\\nGrounding text labels… See the full description on the dataset page: https://huggingface.co/datasets/WueNLP/SMPQA."},
	{"name":"kicj","keyword":"korean","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/niruka/kicj","creator_name":"niruka","creator_url":"https://huggingface.co/niruka","description":"This is a dataset of 30 research reports published by the Korea Institute of Criminal Justice and Public Policy (KICJ) over the past 10 years, augmented with a Q/A set using GPT4o based on each research report page.\\nThis dataset may contain incorrect information or content due to the augmentation using GPT4o.\\nContact : niruka@naver.com\\n"},
	{"name":"KOFFVQA_Data","keyword":"korean","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/maum-ai/KOFFVQA_Data","creator_name":"maum-ai","creator_url":"https://huggingface.co/maum-ai","description":"\\n\\t\\n\\t\\t\\n\\t\\tAbout this data\\n\\t\\n\\nKOFFVQA is a general-purpose VLM benchmark in the Korean language. For more information, refer to our leaderboard page and the official evaluation code.\\nThis contains the data for the benchmark consisting of images, their corresponding questions, and response grading criteria.\\n"},
	{"name":"MME","keyword":"korean","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Mineru/MME","creator_name":"Keun Seok, Im","creator_url":"https://huggingface.co/Mineru","description":"Mineru/MME dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"degeneration-html-multilingual","keyword":"korean","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Degeneration-Nation/degeneration-html-multilingual","creator_name":"The Degeneration of the Nation","creator_url":"https://huggingface.co/Degeneration-Nation","description":"\\n\\t\\n\\t\\t\\n\\t\\tThe Degeneration of the Nation Multilingual Dataset\\n\\t\\n\\nThis dataset contains the complete content of The Degeneration of the Nation project, a comprehensive philosophical and cultural website exploring the intersection of technology, artificial intelligence, and human culture. The content includes philosophical essays, cultural analysis, and contemporary literature, with complex parallel structure and sophisticated HTML architecture across all language versions.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset… See the full description on the dataset page: https://huggingface.co/datasets/Degeneration-Nation/degeneration-html-multilingual."},
	{"name":"Throat_and_Acoustic_Pairing_Speech_Dataset","keyword":"korean","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/yskim3271/Throat_and_Acoustic_Pairing_Speech_Dataset","creator_name":"yunsik kim","creator_url":"https://huggingface.co/yskim3271","description":"\\n\\t\\n\\t\\t\\n\\t\\tTAPS: Throat and Acoustic Paired Speech Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\t1. DATASET SUMMARY\\n\\t\\n\\nThe Throat and Acoustic Paired Speech (TAPS) dataset is a standardized corpus designed for deep learning-based speech enhancement, specifically targeting throat microphone recordings. Throat microphones effectively suppress background noise but suffer from high-frequency attenuation due to the low-pass filtering effect of the skin and tissue. The dataset provides paired recordings from 60 native Korean… See the full description on the dataset page: https://huggingface.co/datasets/yskim3271/Throat_and_Acoustic_Pairing_Speech_Dataset."},
	{"name":"Open-KoEn-Parallel-Style-Tag","keyword":"korean","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/werty1248/Open-KoEn-Parallel-Style-Tag","creator_name":"Dohyung Kim","creator_url":"https://huggingface.co/werty1248","description":"\\n\\t\\n\\t\\t\\n\\t\\t설명\\n\\t\\n\\n\\ngemini-1.5-flash를 이용하여, 한국어 텍스트의 스타일을 태그 형태로 제안하도록 요청하였습니다.\\n\\n사용된 프롬프트\\n\\n\\n당신은 한국어 및 글쓰기 전문가입니다. 마지막에 한국어 텍스트가 주어집니다. 당신은 그 텍스트의 스타일을 주어진 기준에 따라 분류합니다. 그리고 분류 결과를 python Dict[List] 형태로 출력합니다.\\ndictionary 이름은 \\\"style\\\"입니다.\\n\\n## 분류 기준 - 복수 선택이 가능합니다.\\n\\n유형: [명사형(Nominal), 평서문 (Declarative), 의문문 (Interrogative), 명령문 (Imperative), 감탄문 (Exclamatory), 청유문 (Propositive)]\\n\\n대상: [일반 대중 (General), 전문가 집단 (Specialist), 아동 (Children), 개인 (Individual)]\\n\\n문체: [격식체 (Formal), 비격식체 (Informal), 딱딱함 (Stiff)… See the full description on the dataset page: https://huggingface.co/datasets/werty1248/Open-KoEn-Parallel-Style-Tag."},
	{"name":"korean-realqa-reasoning-v01","keyword":"korean","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/lemon-mint/korean-realqa-reasoning-v01","creator_name":"Lemon Mint","creator_url":"https://huggingface.co/lemon-mint","description":"https://huggingface.co/datasets/beomi/KoAlpaca-RealQA\\n"},
	{"name":"korean-realqa-reasoning-v01-preference","keyword":"korean","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/lemon-mint/korean-realqa-reasoning-v01-preference","creator_name":"Lemon Mint","creator_url":"https://huggingface.co/lemon-mint","description":"https://huggingface.co/datasets/beomi/KoAlpaca-RealQA\\n"},
	{"name":"Synthdog-Multilingual-100","keyword":"korean","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/WueNLP/Synthdog-Multilingual-100","creator_name":"WüNLP","creator_url":"https://huggingface.co/WueNLP","description":"\\n\\t\\n\\t\\t\\n\\t\\tSynthdog Multilingual\\n\\t\\n\\n\\n\\nThe Synthdog dataset created for training in Centurio: On Drivers of Multilingual Ability of Large Vision-Language Model.\\nUsing the official Synthdog code, we created >1 million training samples for improving OCR capabilities in Large Vision-Language Models.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Details\\n\\t\\n\\nWe provide the images for download in two .tar.gz files. Download and extract them in folders of the same name (so cat images.tar.gz.* | tar xvzf -C images; tar xvzf… See the full description on the dataset page: https://huggingface.co/datasets/WueNLP/Synthdog-Multilingual-100."},
	{"name":"BenchMAX_Math","keyword":"korean","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/LLaMAX/BenchMAX_Math","creator_name":"LLaMAX","creator_url":"https://huggingface.co/LLaMAX","description":"\\n\\t\\n\\t\\t\\n\\t\\tDataset Sources\\n\\t\\n\\n\\nPaper: BenchMAX: A Comprehensive Multilingual Evaluation Suite for Large Language Models\\nLink: https://arxiv.org/pdf/2502.07346\\nRepository: https://github.com/CONE-MT/BenchMAX\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\nBenchMAX_Math is a dataset of BenchMAX, sourcing from MGSM.\\nWe extend the original dataset to 6 more languages.\\nThe data is first translated by Google Translate, and then post-editing by native speakers.\\n\\n\\t\\n\\t\\t\\n\\t\\tSupported Languages\\n\\t\\n\\nArabic, Bengali, Chinese… See the full description on the dataset page: https://huggingface.co/datasets/LLaMAX/BenchMAX_Math."},
	{"name":"BenchMAX_Science","keyword":"korean","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/LLaMAX/BenchMAX_Science","creator_name":"LLaMAX","creator_url":"https://huggingface.co/LLaMAX","description":"\\n\\t\\n\\t\\t\\n\\t\\tDataset Sources\\n\\t\\n\\n\\nPaper: BenchMAX: A Comprehensive Multilingual Evaluation Suite for Large Language Models\\nLink: https://arxiv.org/pdf/2502.07346\\nRepository: https://github.com/CONE-MT/BenchMAX\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\nBenchMAX_Science is a dataset of BenchMAX, sourcing from GPQA.\\nWe extend the original English dataset to 16 non-English languages.\\nThe data is first translated by Google Translate, and then post-editing by native speakers.\\n\\n\\t\\n\\t\\t\\n\\t\\tSupported Languages\\n\\t\\n\\nArabic… See the full description on the dataset page: https://huggingface.co/datasets/LLaMAX/BenchMAX_Science."},
	{"name":"BenchMAX_Function_Completion","keyword":"korean","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/LLaMAX/BenchMAX_Function_Completion","creator_name":"LLaMAX","creator_url":"https://huggingface.co/LLaMAX","description":"\\n\\t\\n\\t\\t\\n\\t\\tDataset Sources\\n\\t\\n\\n\\nPaper: BenchMAX: A Comprehensive Multilingual Evaluation Suite for Large Language Models\\nLink: https://arxiv.org/pdf/2502.07346\\nRepository: https://github.com/CONE-MT/BenchMAX\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\nBenchMAX_Function_Completion is a dataset of BenchMAX, sourcing from humanevalplus.\\nWe extend the original English dataset to 16 non-English languages.\\nThe data is first translated by GPT-4o, and then post-editing by native speakers.\\n\\n\\t\\n\\t\\t\\n\\t\\tSupported Languages… See the full description on the dataset page: https://huggingface.co/datasets/LLaMAX/BenchMAX_Function_Completion."},
	{"name":"BenchMAX_Problem_Solving","keyword":"korean","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/LLaMAX/BenchMAX_Problem_Solving","creator_name":"LLaMAX","creator_url":"https://huggingface.co/LLaMAX","description":"\\n\\t\\n\\t\\t\\n\\t\\tDataset Sources\\n\\t\\n\\n\\nPaper: BenchMAX: A Comprehensive Multilingual Evaluation Suite for Large Language Models\\nLink: https://arxiv.org/pdf/2502.07346\\nRepository: https://github.com/CONE-MT/BenchMAX\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\nBenchMAX_Problem_Solving is a dataset of BenchMAX, sourcing from LiveCodeBench.\\nWe extend the original English dataset to 16 non-English languages.\\nThe data is first translated by GPT-4o, and then post-editing by native speakers.\\n\\n\\t\\n\\t\\t\\n\\t\\tSupported Languages… See the full description on the dataset page: https://huggingface.co/datasets/LLaMAX/BenchMAX_Problem_Solving."},
	{"name":"smol-koreantalk","keyword":"korean","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/lemon-mint/smol-koreantalk","creator_name":"Lemon Mint","creator_url":"https://huggingface.co/lemon-mint","description":"SmolLM2의 인스트럭션 훈련 데이터 HuggingFaceTB/smol-smoltalk를 한국어로 번역했어요.\\n"},
	{"name":"DATA-AI_Chat","keyword":"korean","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Mattimax/DATA-AI_Chat","creator_name":"M.INC.","creator_url":"https://huggingface.co/Mattimax","description":"\\n\\t\\n\\t\\t\\n\\t\\tDATA-AI: Il Modello di IA di M.INC.\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\t📌 Introduzione\\n\\t\\n\\nDATA-AI è un avanzato modello di intelligenza artificiale sviluppato da *M.INC., un'azienda italiana fondata da *Mattimax (M. Marzorati).Questo modello è basato sull'architettura ELNS (Elaborazione del Linguaggio Naturale Semplice), un sistema innovativo progettato per rendere l'IA accessibile su quasi qualsiasi dispositivo, garantendo prestazioni ottimali anche su hardware limitato.  \\nDATA-AI è stato addestrato su un… See the full description on the dataset page: https://huggingface.co/datasets/Mattimax/DATA-AI_Chat."},
	{"name":"ea-mt-benchmark","keyword":"korean","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/sapienzanlp/ea-mt-benchmark","creator_name":"Sapienza NLP, Sapienza University of Rome","creator_url":"https://huggingface.co/sapienzanlp","description":"\\n\\t\\n\\t\\t\\n\\t\\tDataset Card for EA-MT\\n\\t\\n\\nEA-MT (Entity-Aware Machine Translation) is a multilingual benchmark for evaluating the capabilities of Large Language Models (LLMs) and Machine Translation (MT) models in translating simple sentences with potentially challenging entity mentions, e.g., entities for which a word-for-word translation may not be accurate.\\nHere is an example of a simple sentence with a challenging entity mention:\\n\\nEnglish: \\\"What is the plot of The Catcher in the Rye?\\\"\\nItalian:… See the full description on the dataset page: https://huggingface.co/datasets/sapienzanlp/ea-mt-benchmark."},
	{"name":"high-quality-multilingual-sentences","keyword":"korean","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/agentlans/high-quality-multilingual-sentences","creator_name":"Alan Tseng","creator_url":"https://huggingface.co/agentlans","description":"\\n\\t\\n\\t\\t\\n\\t\\tHigh Quality Multilingual Sentences\\n\\t\\n\\n\\nThis dataset contains multilingual sentences derived from the agentlans/LinguaNova dataset.\\nIt includes 1.58 million rows across 51 different languages, each in its own configuration.\\n\\nExample row (from the all config):\\n{\\n    \\\"text\\\": \\\"امام جمعه اصفهان گفت: میزان نیاز آب شرب اصفهان ۱۱.۵ متر مکعب است که تمام استان اصفهان را پوشش میدهد و نسبت به قبل از انقلاب یکی از پیشرفتها در حوزه آب بوده است.\\\",\\n    \\\"fasttext\\\": \\\"fa\\\",\\n    \\\"gcld3\\\": \\\"fa\\\"\\n}\\n\\nFields:… See the full description on the dataset page: https://huggingface.co/datasets/agentlans/high-quality-multilingual-sentences."},
	{"name":"BCAI-Finance-Kor","keyword":"korean","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/BCCard/BCAI-Finance-Kor","creator_name":"BC Card","creator_url":"https://huggingface.co/BCCard","description":"BCCard/BCAI-Finance-Kor dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"Open-R1-Mulitlingual-SFT","keyword":"korean","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/amphora/Open-R1-Mulitlingual-SFT","creator_name":"GUIJIN SON","creator_url":"https://huggingface.co/amphora","description":"\\n\\t\\n\\t\\t\\n\\t\\tOpen-R1-Mulitlingual-SFT\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tOverview\\n\\t\\n\\nOpen-R1-Mulitlingual-SFT is a curated dataset designed for multilingual supervised fine-tuning.\\nThe source data comprises multiple datasets containing original prompts and responses, which were subsequently translated into 14 languages using GPT-4o.\\n\\n\\t\\n\\t\\t\\n\\t\\tSources\\n\\t\\n\\nThe dataset is derived from:\\n\\nopen-thoughts/OpenThoughts-114kHugging Face: open-thoughts/OpenThoughts-114k\\nbespokelabs/Bespoke-Stratos-17kHugging Face:… See the full description on the dataset page: https://huggingface.co/datasets/amphora/Open-R1-Mulitlingual-SFT."},
	{"name":"wikis","keyword":"korean","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/nyuuzyou/wikis","creator_name":"nyuuzyou","creator_url":"https://huggingface.co/nyuuzyou","description":"\\n\\t\\n\\t\\t\\n\\t\\tDataset Card for Public MediaWiki Collection\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThis dataset contains 1,662,448 articles harvested from 930 random public MediaWiki instances found across the Internet. The collection was created by extracting current page content from these wikis, preserving article text, metadata, and structural information. The dataset represents a diverse cross-section of public wiki content spanning multiple domains, topics, and languages.\\n\\n\\t\\n\\t\\t\\n\\t\\tLanguages\\n\\t\\n\\nThe… See the full description on the dataset page: https://huggingface.co/datasets/nyuuzyou/wikis."},
	{"name":"wikipedia_quality_wikirank","keyword":"korean","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/lewoniewski/wikipedia_quality_wikirank","creator_name":"Włodzimierz Lewoniewski","creator_url":"https://huggingface.co/lewoniewski","description":"Datasets with WikiRank quality score as of 1 August 2024 for 47 million Wikipedia articles in 55 language versions (also simplified version for each language in separate files).\\nThe WikiRank quality score is a metric designed to assess the overall quality of a Wikipedia article. Although its specific algorithm can vary depending on the implementation, the score typically combines several key features of the Wikipedia article.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tWhy It’s Important\\n\\t\\n\\n\\nEnhances Trust: For readers and… See the full description on the dataset page: https://huggingface.co/datasets/lewoniewski/wikipedia_quality_wikirank."},
	{"name":"Thinking-multilingual-big-10k-sft","keyword":"korean","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Pinkstack/Thinking-multilingual-big-10k-sft","creator_name":"Pinkstack","creator_url":"https://huggingface.co/Pinkstack","description":"\\nA dataset based off of openo1 math, 500 examples translated to 23 different languages. filtered out un-translated examples.\\nenjoy 👍\\n"},
	{"name":"multilingual_translation_sft","keyword":"korean","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Youseff1987/multilingual_translation_sft","creator_name":"JOON HYOUNG JUN","creator_url":"https://huggingface.co/Youseff1987","description":"Youseff1987/multilingual_translation_sft dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"m-WildVision","keyword":"korean","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/CohereForAI/m-WildVision","creator_name":"Cohere For AI","creator_url":"https://huggingface.co/CohereForAI","description":"\\n\\t\\n\\t\\t\\n\\t\\tDataset Card for m-WildVision\\n\\t\\n\\n\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Details\\n\\t\\n\\nThe m-WildVision dataset is a multilingual multimodal LLM evaluation set covering 23 languages.  It was created by translating prompts from the original English-only WildVision (vision_bench_0617) test set. \\nThe original prompts, developed by Lu et al. (2024) , consist of 500 challenging user queries sourced from the WildVision-Arena platform. \\nThe authors demonstrated that these prompts enable automatic LLM judge… See the full description on the dataset page: https://huggingface.co/datasets/CohereForAI/m-WildVision."},
	{"name":"OpenHumanreasoning-multilingual-2.2k","keyword":"korean","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Pinkstack/OpenHumanreasoning-multilingual-2.2k","creator_name":"Pinkstack","creator_url":"https://huggingface.co/Pinkstack","description":"Based off of Pinkstackorg/humanreasoning-testing-en, it is a human-generated dataset where a real person had to create most of the reasoning and the final output. If there are any mistakes please let us know.\\nWe offer this dataset at an apache-2.0 license to make it useful for everybody.\\nnote: translations are not human generated.\\n"},
	{"name":"numina_math_ko_verifiable_540k","keyword":"korean","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/OLAIR/numina_math_ko_verifiable_540k","creator_name":"OLA-AI-Research","creator_url":"https://huggingface.co/OLAIR","description":"\\n\\t\\n\\t\\t\\n\\t\\tDataset Card: OLAIR/numina_math_ko_verifiable_540k\\n\\t\\n\\nOverview:A paired dataset of math questions (translated into Korean using GPT-4o-mini) and verifiable answers. Intended for RL training (e.g., GRPO) and mathematical reasoning tasks.\\nSources:  \\n\\nQuestions: Derived from AI-MO/NuminaMath-CoT  \\nAnswers: Extracted from flatlander1024/numinamath_verifiable_cleaned\\n\\nKey Points:  \\n\\nTranslation: No-cleansing version; translations may contain errors.  \\nUsage: Suitable for RL and language… See the full description on the dataset page: https://huggingface.co/datasets/OLAIR/numina_math_ko_verifiable_540k."},
	{"name":"resume_jd_matching_kr","keyword":"korean","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/recuse/resume_jd_matching_kr","creator_name":"KW recuse project","creator_url":"https://huggingface.co/recuse","description":"이력서 - 공고 매칭 한글 데이터셋\\ncnamuangtoun/resume-job-description-fit을 gpt-4-o-mini API를 사용하여 변역함.\\nContrastive Learning 으로 쓸 수 있습니다. \\n"},
	{"name":"reasoning-conversations","keyword":"korean","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/syntaxsynth/reasoning-conversations","creator_name":"SyntaxSynth","creator_url":"https://huggingface.co/syntaxsynth","description":"\\n\\t\\n\\t\\t\\n\\t\\tMultilingual Reasoning Dataset\\n\\t\\n\\n\\nInclude languages from German, Korean, Spanish, Japanese, French, Simplified Chinese, Traditional Chinese\\n\\nReasoning traces from Deepseek-v3-R1, Deepseek-v3-R1-Zero\\n\\n\\nCredits sponsored by Currents API\\n"},
	{"name":"kor_3i4k","keyword":"korean","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/wicho/kor_3i4k","creator_name":"Won Ik Cho","creator_url":"https://huggingface.co/wicho","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for 3i4K\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThe 3i4K dataset is a set of frequently used Korean words (corpus provided by the Seoul National University Speech Language Processing Lab) and manually created questions/commands containing short utterances. The goal is to identify the speaker intention of a spoken utterance based on its transcript, and whether in some cases, requires using auxiliary acoustic features. The classification system decides whether the utterance… See the full description on the dataset page: https://huggingface.co/datasets/wicho/kor_3i4k."},
	{"name":"kor_nli","keyword":"korean","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/kakaobrain/kor_nli","creator_name":"Kakao Brain","creator_url":"https://huggingface.co/kakaobrain","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for \\\"kor_nli\\\"\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nKorean Natural Language Inference datasets.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSupported Tasks and Leaderboards\\n\\t\\n\\nMore Information Needed\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages\\n\\t\\n\\nMore Information Needed\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Structure\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Instances\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tmulti_nli\\n\\t\\n\\n\\nSize of downloaded dataset files: 42.11 MB\\nSize of the generated dataset: 84.72 MB\\nTotal amount of disk used: 126.85 MB\\n\\nAn example of 'train' looks as follows.… See the full description on the dataset page: https://huggingface.co/datasets/kakaobrain/kor_nli."},
	{"name":"kor_sarcasm","keyword":"korean","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/SpellOnYou/kor_sarcasm","creator_name":"SpellOnYou","creator_url":"https://huggingface.co/SpellOnYou","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Korean Sarcasm Detection\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThe Korean Sarcasm Dataset was created to detect sarcasm in text, which can significantly alter the original meaning of a sentence. 9319 tweets were collected from Twitter and labeled for sarcasm or not_sarcasm. These tweets were gathered by querying for: 역설, 아무말, 운수좋은날, 笑, 뭐래 아닙니다, 그럴리없다, 어그로, irony sarcastic, and sarcasm. The dataset was pre-processed by removing the keyword hashtag, urls and mentions of… See the full description on the dataset page: https://huggingface.co/datasets/SpellOnYou/kor_sarcasm."},
	{"name":"opus_paracrawl","keyword":"korean","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Helsinki-NLP/opus_paracrawl","creator_name":"Language Technology Research Group at the University of Helsinki","creator_url":"https://huggingface.co/Helsinki-NLP","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for OpusParaCrawl\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nParallel corpora from Web Crawls collected in the ParaCrawl project.\\nTha dataset contains:\\n\\n42 languages, 43 bitexts\\ntotal number of files: 59,996\\ntotal number of tokens: 56.11G\\ntotal number of sentence fragments: 3.13G\\n\\nTo load a language pair which isn't part of the config, all you need to do is specify the language code as pairs,\\ne.g.\\ndataset = load_dataset(\\\"opus_paracrawl\\\", lang1=\\\"en\\\", lang2=\\\"so\\\")\\n\\nYou can find… See the full description on the dataset page: https://huggingface.co/datasets/Helsinki-NLP/opus_paracrawl."},
	{"name":"opus_ubuntu","keyword":"korean","license":"BSD 3-Clause \"New\" or \"Revised\" License","license_url":"https://choosealicense.com/licenses/bsd-3-clause/","language":"en","dataset_url":"https://huggingface.co/datasets/Helsinki-NLP/opus_ubuntu","creator_name":"Language Technology Research Group at the University of Helsinki","creator_url":"https://huggingface.co/Helsinki-NLP","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Opus Ubuntu\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThese are translations of the Ubuntu software package messages, donated by the Ubuntu community.\\nTo load a language pair which isn't part of the config, all you need to do is specify the language code as pairs.\\nYou can find the valid pairs in Homepage section of Dataset Description: http://opus.nlpl.eu/Ubuntu.php\\nE.g.\\ndataset = load_dataset(\\\"opus_ubuntu\\\", lang1=\\\"it\\\", lang2=\\\"pl\\\")\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSupported Tasks and… See the full description on the dataset page: https://huggingface.co/datasets/Helsinki-NLP/opus_ubuntu."},
	{"name":"tydiqa","keyword":"korean","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/google-research-datasets/tydiqa","creator_name":"Google Research Datasets","creator_url":"https://huggingface.co/google-research-datasets","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for \\\"tydiqa\\\"\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nTyDi QA is a question answering dataset covering 11 typologically diverse languages with 204K question-answer pairs.\\nThe languages of TyDi QA are diverse with regard to their typology -- the set of linguistic features that each language\\nexpresses -- such that we expect models performing well on this set to generalize across a large number of the languages\\nin the world. It contains language phenomena that would not be found… See the full description on the dataset page: https://huggingface.co/datasets/google-research-datasets/tydiqa."},
	{"name":"mr-tydi-corpus","keyword":"korean","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/castorini/mr-tydi-corpus","creator_name":"Castorini","creator_url":"https://huggingface.co/castorini","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nMr. TyDi is a multi-lingual benchmark dataset built on TyDi, covering eleven typologically diverse languages. It is designed for monolingual retrieval, specifically to evaluate ranking with learned dense representations.\\nThis dataset stores documents of Mr. TyDi. To access the queries and judgments, please refer to castorini/mr-tydi.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Structure\\n\\t\\n\\nThe only configuration here is the language. As all three folds (train, dev and test) share the… See the full description on the dataset page: https://huggingface.co/datasets/castorini/mr-tydi-corpus."},
	{"name":"mr-tydi","keyword":"korean","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/castorini/mr-tydi","creator_name":"Castorini","creator_url":"https://huggingface.co/castorini","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nMr. TyDi is a multi-lingual benchmark dataset built on TyDi, covering eleven typologically diverse languages. It is designed for monolingual retrieval, specifically to evaluate ranking with learned dense representations.\\nThis dataset stores the queries, judgements, and example training data of Mr. TyDi. To access the corpus, please refer to castorini/mr-tydi-corpus.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Structure\\n\\t\\n\\nThe only configuration here is the language, \\nFor each language… See the full description on the dataset page: https://huggingface.co/datasets/castorini/mr-tydi."},
	{"name":"flores_101","keyword":"korean","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/gsarti/flores_101","creator_name":"Gabriele Sarti","creator_url":"https://huggingface.co/gsarti","description":"One of the biggest challenges hindering progress in low-resource and multilingual machine translation is the \\nlack of good evaluation benchmarks. Current evaluation benchmarks either lack good coverage of low-resource \\nlanguages, consider only restricted domains, or are low quality because they are constructed using \\nsemi-automatic procedures. In this work, we introduce the FLORES evaluation benchmark, consisting of 3001 \\nsentences extracted from English Wikipedia and covering a variety of different topics and domains. \\nThese sentences have been translated in 101 languages by professional translators through a carefully \\ncontrolled process. The resulting dataset enables better assessment of model quality on the long tail of \\nlow-resource languages, including the evaluation of many-to-many multilingual translation systems, as all \\ntranslations are multilingually aligned. By publicly releasing such a high-quality and high-coverage dataset, \\nwe hope to foster progress in the machine translation community and beyond."},
	{"name":"APEACH","keyword":"korean","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/jason9693/APEACH","creator_name":"Kichang Yang","creator_url":"https://huggingface.co/jason9693","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset for project: kor_hate_eval(APEACH)\\n\\t\\n\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSample Code\\n\\t\\n\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Descritpion\\n\\t\\n\\nKorean Hate Speech Evaluation Datasets : trained with BEEP! and evaluate with APEACH\\n\\nRepository: Korean HateSpeech Evaluation Dataset\\nPaper: APEACH: Attacking Pejorative Expressions with Analysis on Crowd-Generated Hate Speech Evaluation Datasets\\nPoint of Contact: Kichang Yang\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages\\n\\t\\n\\nko-KR\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Structure\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Instances\\n\\t\\n\\nA… See the full description on the dataset page: https://huggingface.co/datasets/jason9693/APEACH."},
	{"name":"xlel_wd_dictionary","keyword":"korean","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/adithya7/xlel_wd_dictionary","creator_name":"Adithya Pratapa","creator_url":"https://huggingface.co/adithya7","description":"XLEL-WD is a multilingual event linking dataset. This sub-dataset contains a dictionary of events from Wikidata. The multilingual descriptions for Wikidata event items are taken from the corresponding Wikipedia articles."},
	{"name":"xlel_wd","keyword":"korean","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/adithya7/xlel_wd","creator_name":"Adithya Pratapa","creator_url":"https://huggingface.co/adithya7","description":"XLEL-WD is a multilingual event linking dataset. This dataset contains mention references from multilingual Wikipedia/Wikinews articles to event items in Wikidata. The text descriptions for Wikidata events are compiled from Wikipedia articles."},
	{"name":"wit_base","keyword":"korean","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/wikimedia/wit_base","creator_name":"Wikimedia","creator_url":"https://huggingface.co/wikimedia","description":"\\n\\t\\n\\t\\t\\n\\t\\tDataset Card for WIT\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nWikimedia's version of the Wikipedia-based Image Text (WIT) Dataset, a large multimodal multilingual dataset.\\nFrom the official blog post:\\n\\nThe core training data is taken from the Wikipedia Image-Text (WIT) Dataset, a large curated set of more than 37 million image-text associations extracted from Wikipedia articles in 108 languages that was recently released by Google Research.\\nThe WIT dataset offers extremely valuable data about the… See the full description on the dataset page: https://huggingface.co/datasets/wikimedia/wit_base."},
	{"name":"arcalive_220506","keyword":"korean","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Bingsu/arcalive_220506","creator_name":"Dowon Hwang","creator_url":"https://huggingface.co/Bingsu","description":"[아카라이브 베스트 라이브 채널](https://arca.live/b/live)의 2021년 8월 16일부터 2022년 5월 6일까지의 데이터를 수집하여, 댓글만 골라낸 데이터입니다."},
	{"name":"qg_koquad","keyword":"korean","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/lmqg/qg_koquad","creator_name":"LMQG","creator_url":"https://huggingface.co/lmqg","description":"[KorQuAD](https://huggingface.co/datasets/squad_kor_v1) dataset for question generation (QG) task."},
	{"name":"KcBERT_Pre-Training_Corpus","keyword":"korean","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Bingsu/KcBERT_Pre-Training_Corpus","creator_name":"Dowon Hwang","creator_url":"https://huggingface.co/Bingsu","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tKcBERT Pre-Training Corpus (Korean News Comments)\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tKcBERT\\n\\t\\n\\nbeomi/kcbert-base\\nGithub KcBERT Repo: https://github.com/Beomi/KcBERTKcBERT is Korean Comments BERT pretrained on this Corpus set.(You can use it via Huggingface's Transformers library!)\\nThis Kaggle Dataset contains CLEANED dataset preprocessed with the code below.\\nimport re\\nimport emoji\\nfrom soynlp.normalizer import repeat_normalize\\n\\nemojis = ''.join(emoji.UNICODE_EMOJI.keys())\\npattern = re.compile(f'[^ .… See the full description on the dataset page: https://huggingface.co/datasets/Bingsu/KcBERT_Pre-Training_Corpus."},
	{"name":"kowiki20220620","keyword":"korean","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/bongsoo/kowiki20220620","creator_name":"ko","creator_url":"https://huggingface.co/bongsoo","description":"-kowiki202206 1줄 말뭉치\\n"},
	{"name":"bongevalsmall","keyword":"korean","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/bongsoo/bongevalsmall","creator_name":"ko","creator_url":"https://huggingface.co/bongsoo","description":"\\n평가 말뭉치\\n\\n"},
	{"name":"laion2B-multi-korean-subset","keyword":"korean","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Bingsu/laion2B-multi-korean-subset","creator_name":"Dowon Hwang","creator_url":"https://huggingface.co/Bingsu","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tlaion2B-multi-korean-subset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tAbout dataset\\n\\t\\n\\na subset data of laion/laion2B-multi, including only korean\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLisence\\n\\t\\n\\nCC-BY-4.0\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Structure\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Instance\\n\\t\\n\\n>>> from datasets import load_dataset\\n>>> dataset = load_dataset(\\\"Bingsu/laion2B-multi-korean-subset\\\")\\n>>> dataset\\nDatasetDict({\\n    train: Dataset({\\n        features: ['SAMPLE_ID', 'URL', 'TEXT', 'HEIGHT', 'WIDTH', 'LICENSE', 'LANGUAGE', 'NSFW', 'similarity']… See the full description on the dataset page: https://huggingface.co/datasets/Bingsu/laion2B-multi-korean-subset."},
	{"name":"answerable_tydiqa","keyword":"korean","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/copenlu/answerable_tydiqa","creator_name":"CopeNLU","creator_url":"https://huggingface.co/copenlu","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for \\\"answerable-tydiqa\\\"\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nTyDi QA is a question answering dataset covering 11 typologically diverse languages. \\nAnswerable TyDi QA is an extension of the GoldP subtask of the original TyDi QA dataset to also include unanswertable questions.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Structure\\n\\t\\n\\nThe dataset contains a train and a validation set, with 116067 and 13325 examples, respectively. Access them with\\nfrom datasets import load_dataset\\ndataset =… See the full description on the dataset page: https://huggingface.co/datasets/copenlu/answerable_tydiqa."},
	{"name":"tydiqa_copenlu","keyword":"korean","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/copenlu/tydiqa_copenlu","creator_name":"CopeNLU","creator_url":"https://huggingface.co/copenlu","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for \\\"tydiqa\\\"\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nTyDi QA is a question answering dataset covering 11 typologically diverse languages with 204K question-answer pairs.\\nThe languages of TyDi QA are diverse with regard to their typology -- the set of linguistic features that each language\\nexpresses -- such that we expect models performing well on this set to generalize across a large number of the languages\\nin the world. It contains language phenomena that would not be found… See the full description on the dataset page: https://huggingface.co/datasets/copenlu/tydiqa_copenlu."},
	{"name":"social_science_en_ko","keyword":"korean","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/bongsoo/social_science_en_ko","creator_name":"ko","creator_url":"https://huggingface.co/bongsoo","description":"\\n사회과학-en-ko 번역 말뭉치\\n\\n"},
	{"name":"news_talk_en_ko","keyword":"korean","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/bongsoo/news_talk_en_ko","creator_name":"ko","creator_url":"https://huggingface.co/bongsoo","description":"\\n뉴스&일상대화 en-ko 번역 말뭉치\\n\\n"},
	{"name":"miracl-corpus","keyword":"korean","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/miracl/miracl-corpus","creator_name":"MIRACL","creator_url":"https://huggingface.co/miracl","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for MIRACL Corpus\\n\\t\\n\\nMIRACL 🌍🙌🌏 (Multilingual Information Retrieval Across a Continuum of Languages) is a multilingual retrieval dataset that focuses on search across 18 different languages, which collectively encompass over three billion native speakers around the world.\\nThis dataset contains the collection data of the 16 \\\"known languages\\\". The remaining 2 \\\"surprise languages\\\" will not be released until later.\\nThe corpus for each language is prepared from a… See the full description on the dataset page: https://huggingface.co/datasets/miracl/miracl-corpus."},
	{"name":"wikipedia-korean-20221001","keyword":"korean","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/lcw99/wikipedia-korean-20221001","creator_name":"Chang W Lee","creator_url":"https://huggingface.co/lcw99","description":"20240501 update\\n"},
	{"name":"laion2b_multi_korean_subset_with_image","keyword":"korean","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Bingsu/laion2b_multi_korean_subset_with_image","creator_name":"Dowon Hwang","creator_url":"https://huggingface.co/Bingsu","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tlaion2b_multi_korean_subset_with_image\\n\\t\\n\\nimg2dataset을 통해 다운로드에 성공한 Bingsu/laion2B-multi-korean-subset 이미지를 정리한 데이터셋입니다.\\n이미지는 9,800,137장입니다.\\n이미지는 짧은 쪽 길이가 256이 되도록 리사이즈 되었으며, 품질 100인 webp파일로 다운로드 되었습니다.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tUsage\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\t1. datasets\\n\\t\\n\\n>>> from datasets import load_dataset\\n\\n>>> dataset = load_dataset(\\\"Bingsu/laion2b_multi_korean_subset_with_image\\\", streaming=True, split=\\\"train\\\")\\n\\n>>> dataset.features\\n{'image': Image(decode=True, id=None),\\n 'text':… See the full description on the dataset page: https://huggingface.co/datasets/Bingsu/laion2b_multi_korean_subset_with_image."},
	{"name":"HashtagPrediction","keyword":"korean","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Twitter/HashtagPrediction","creator_name":"Twitter","creator_url":"https://huggingface.co/Twitter","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tHashtag Prediction Dataset from paper TwHIN-BERT: A Socially-Enriched Pre-trained Language Model for Multilingual Tweet Representations\\n\\t\\n\\n  \\nThis repo contains the Hashtag prediction dataset from our paper TwHIN-BERT: A Socially-Enriched Pre-trained Language Model for Multilingual Tweet Representations. \\n[arXiv]\\n[HuggingFace Models]\\n[Github repo]\\nThis work is licensed under a Creative Commons Attribution 4.0 International License.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDownload\\n\\t\\n\\nUse the… See the full description on the dataset page: https://huggingface.co/datasets/Twitter/HashtagPrediction."},
	{"name":"TyDiP","keyword":"korean","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Genius1237/TyDiP","creator_name":"Genius1237","creator_url":"https://huggingface.co/Genius1237","description":"The TyDiP dataset is a dataset of requests in conversations between wikipedia editors\\nthat have been annotated for politeness. The splits available below consists of only\\nrequests from the top 25 percentile (polite) and bottom 25 percentile (impolite) of\\npoliteness scores. The English train set and English test set that are\\nadapted from the Stanford Politeness Corpus, and test data in 9 more languages\\n(Hindi, Korean, Spanish, Tamil, French, Vietnamese, Russian, Afrikaans, Hungarian) \\nwas annotated by us."},
	{"name":"qag_koquad","keyword":"korean","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/lmqg/qag_koquad","creator_name":"LMQG","creator_url":"https://huggingface.co/lmqg","description":"Question & answer generation dataset based on SQuAD."},
	{"name":"wikipedia-22-12-ko-embeddings","keyword":"korean","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Cohere/wikipedia-22-12-ko-embeddings","creator_name":"Cohere","creator_url":"https://huggingface.co/Cohere","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tWikipedia (ko) embedded with cohere.ai multilingual-22-12 encoder\\n\\t\\n\\nWe encoded Wikipedia (ko) using the cohere.ai multilingual-22-12 embedding model.\\nTo get an overview how this dataset was created and pre-processed, have a look at Cohere/wikipedia-22-12.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tEmbeddings\\n\\t\\n\\nWe compute for title+\\\" \\\"+text the embeddings using our multilingual-22-12 embedding model, a state-of-the-art model that works for semantic search in 100 languages.  If you want to learn more about this… See the full description on the dataset page: https://huggingface.co/datasets/Cohere/wikipedia-22-12-ko-embeddings."},
	{"name":"korfin-asc","keyword":"korean","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/amphora/korfin-asc","creator_name":"GUIJIN SON","creator_url":"https://huggingface.co/amphora","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for KorFin-ABSA\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThe KorFin-ASC is an extension of KorFin-ABSA including 8818 samples with (aspect, polarity) pairs annotated. \\nThe samples were collected from KLUE-TC and \\nanalyst reports from Naver Finance. \\nAnnotation of the dataset is described in the paper Removing Non-Stationary Knowledge From Pre-Trained Language Models for Entity-Level Sentiment Classification in Finance.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSupported… See the full description on the dataset page: https://huggingface.co/datasets/amphora/korfin-asc."},
	{"name":"miracl-ko-corpus-22-12","keyword":"korean","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Cohere/miracl-ko-corpus-22-12","creator_name":"Cohere","creator_url":"https://huggingface.co/Cohere","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tMIRACL (ko) embedded with cohere.ai multilingual-22-12 encoder\\n\\t\\n\\nWe encoded the MIRACL dataset using the cohere.ai multilingual-22-12 embedding model.\\nThe query embeddings can be found in Cohere/miracl-ko-queries-22-12 and the corpus embeddings can be found in Cohere/miracl-ko-corpus-22-12.\\nFor the orginal datasets, see miracl/miracl and miracl/miracl-corpus.\\nDataset info:\\n\\nMIRACL 🌍🙌🌏 (Multilingual Information Retrieval Across a Continuum of Languages) is a multilingual… See the full description on the dataset page: https://huggingface.co/datasets/Cohere/miracl-ko-corpus-22-12."},
	{"name":"miracl-ko-queries-22-12","keyword":"korean","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Cohere/miracl-ko-queries-22-12","creator_name":"Cohere","creator_url":"https://huggingface.co/Cohere","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tMIRACL (ko) embedded with cohere.ai multilingual-22-12 encoder\\n\\t\\n\\nWe encoded the MIRACL dataset using the cohere.ai multilingual-22-12 embedding model.\\nThe query embeddings can be found in Cohere/miracl-ko-queries-22-12 and the corpus embeddings can be found in Cohere/miracl-ko-corpus-22-12.\\nFor the orginal datasets, see miracl/miracl and miracl/miracl-corpus.\\nDataset info:\\n\\nMIRACL 🌍🙌🌏 (Multilingual Information Retrieval Across a Continuum of Languages) is a multilingual… See the full description on the dataset page: https://huggingface.co/datasets/Cohere/miracl-ko-queries-22-12."},
	{"name":"lingnli-multi-mt","keyword":"korean","license":"BSD 2-Clause \"Simplified\" License","license_url":"https://choosealicense.com/licenses/bsd-2-clause/","language":"en","dataset_url":"https://huggingface.co/datasets/maximoss/lingnli-multi-mt","creator_name":"Maximos Skandalis","creator_url":"https://huggingface.co/maximoss","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Dataset Name\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThis repository contains a collection of machine translations of LingNLI dataset \\ninto 9 different languages (Bulgarian, Finnish, French, Greek, Italian, Korean, Lithuanian, Portuguese, Spanish). The goal is to predict textual entailment (does sentence A \\nimply/contradict/neither sentence B), which is a classification task (given two sentences, \\npredict one of three labels). It is here formatted in the same manner as… See the full description on the dataset page: https://huggingface.co/datasets/maximoss/lingnli-multi-mt."},
	{"name":"aihub_corpus_expertise","keyword":"korean","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/wisenut-nlp-team/aihub_corpus_expertise","creator_name":"wisenut-nlp","creator_url":"https://huggingface.co/wisenut-nlp-team","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for \\\"corpus_professional_field\\\"\\n\\t\\n\\n전문분야 말뭉치\\n"},
	{"name":"ko-alpaca","keyword":"korean","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/royboy0416/ko-alpaca","creator_name":"Roy Bang","creator_url":"https://huggingface.co/royboy0416","description":"Testing purpose only. Do not redistribute. \\nOriginal contents: [url] https://huggingface.co/datasets/tatsu-lab/alpaca\\nKo-alpaca: [url] https://github.com/Beomi/KoAlpaca/blob/main/ko_alpaca_data.json\\n"},
	{"name":"mquad-v1","keyword":"korean","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/danielpark/mquad-v1","creator_name":"Minwoo Park","creator_url":"https://huggingface.co/danielpark","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tMQuAD\\n\\t\\n\\nThe Medical Question and Answering dataset(MQuAD) has been refined, including the following datasets. You can download it through the Hugging Face dataset. Use the DATASETS method as follows.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tQuick Guide\\n\\t\\n\\nfrom datasets import load_dataset\\ndataset = load_dataset(\\\"danielpark/MQuAD-v1\\\")\\n\\nMedical Q/A datasets gathered from the following websites.\\n\\neHealth Forum\\niCliniq\\nQuestion Doctors\\nWebMD\\nData was gathered at the 5th of May 2017.\\n\\nThe MQuAD provides embedded… See the full description on the dataset page: https://huggingface.co/datasets/danielpark/mquad-v1."},
	{"name":"OIG-small-chip2-ko","keyword":"korean","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/heegyu/OIG-small-chip2-ko","creator_name":"Heegyu Kim","creator_url":"https://huggingface.co/heegyu","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for \\\"OIG-small-chip2-ko\\\"\\n\\t\\n\\n\\n210282 items\\nOriginal Dataset: OIG-small-chip2 dataset from https://laion.ai/blog/oig-dataset/\\nTranslated by Google Translate API\\n\\nexample\\n{\\n \\\"user\\\": \\\"Is there a good way to clean up my credit report?\\\\n\\\\n\\\",\\n \\\"chip2\\\": \\\"That depends on why your credit score is low. Would you like to share more details about your situation?\\\",\\n \\\"index\\\": 210272,\\n \\\"user_translated\\\": \\\"내 신용 보고서를 정리하는 좋은 방법이 있습니까?\\\\n\\\\n\\\",\\n \\\"chip2_translated\\\": \\\"신용 점수가 낮은 이유에 따라 다릅니다.… See the full description on the dataset page: https://huggingface.co/datasets/heegyu/OIG-small-chip2-ko."},
	{"name":"MedGPT-5k-ko","keyword":"korean","license":"GNU General Public License v3.0","license_url":"https://choosealicense.com/licenses/gpl-3.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mncai/MedGPT-5k-ko","creator_name":"MindsAndCompany","creator_url":"https://huggingface.co/mncai","description":"mncai/MedGPT-5k-ko dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"kin_med_2M","keyword":"korean","license":"GNU General Public License v3.0","license_url":"https://choosealicense.com/licenses/gpl-3.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mncai/kin_med_2M","creator_name":"MindsAndCompany","creator_url":"https://huggingface.co/mncai","description":"mncai/kin_med_2M dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"rsd-ists-2016","keyword":"korean","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ZurichNLP/rsd-ists-2016","creator_name":"University of Zurich, Department of Computational Linguistics","creator_url":"https://huggingface.co/ZurichNLP","description":"Training and test data for the task of Recognizing Semantic Differences (RSD).\\nSee the paper for details on how the dataset was created, and see our code at https://github.com/ZurichNLP/recognizing-semantic-differences for an example of how to use the data for evaluation.\\nThe data are derived from the SemEval-2016 Task 2 for Interpretable Semantic Textual Similarity organized by Agirre et al. (2016).\\nThe original URLs of the data are:\\n\\nTrain:… See the full description on the dataset page: https://huggingface.co/datasets/ZurichNLP/rsd-ists-2016."},
	{"name":"KorfinQA","keyword":"korean","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/mssongit/KorfinQA","creator_name":"SONGMINSANG","creator_url":"https://huggingface.co/mssongit","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tFinQA 한국어 번역본\\n\\t\\n\\nQuestion, Answer 총 6252 Rows\\n"},
	{"name":"openassistant-guanaco-ko","keyword":"korean","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/nlpai-lab/openassistant-guanaco-ko","creator_name":"NLP & AI - Korea University","creator_url":"https://huggingface.co/nlpai-lab","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nKorean translation of Guanaco via the DeepL API\\nNote: There are cases where multilingual data has been converted to monolingual data during batch translation to Korean using the API.\\nBelow is Guanaco's README.\\n\\nThis dataset is a subset of the Open Assistant dataset, which you can find here: https://huggingface.co/datasets/OpenAssistant/oasst1/tree/main\\nThis subset of the data only contains the highest-rated paths in the conversation tree, with a total of 9,846… See the full description on the dataset page: https://huggingface.co/datasets/nlpai-lab/openassistant-guanaco-ko."},
	{"name":"docs_on_several_languages","keyword":"korean","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/AlekseyScorpi/docs_on_several_languages","creator_name":"Aleksey Timoshin","creator_url":"https://huggingface.co/AlekseyScorpi","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for \\\"docs_on_several_languages\\\"\\n\\t\\n\\nThis dataset is a collection of different images in different languages.\\nThe set includes the following languages: Azerbaijani, Belorussian, Chinese, English, Estonian, Finnish, Georgian, Japanese, Korean, Kazakh, Latvian, Lithuanian, Mongolian, Norwegian, Polish, Russian, Ukranian.\\nEach language has a corresponding class label defined. At least 100 images in the entire dataset are allocated per class. This dataset was originally used… See the full description on the dataset page: https://huggingface.co/datasets/AlekseyScorpi/docs_on_several_languages."},
	{"name":"SREDFM","keyword":"korean","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Babelscape/SREDFM","creator_name":"Babelscape","creator_url":"https://huggingface.co/Babelscape","description":"Relation Extraction (RE) is a task that identifies relationships between entities in a text, enabling the acquisition of relational facts and bridging the gap between natural language and structured knowledge. However, current RE models often rely on small datasets with low coverage of relation types, particularly when working with languages other than English. \\\\In this paper, we address the above issue and provide two new resources that enable the training and evaluation of multilingual RE systems.\\nFirst, we present SRED\\\\textsuperscript{FM}, an automatically annotated dataset covering 18 languages, 400 relation types, 13 entity types, totaling more than 40 million triplet instances. Second, we propose RED\\\\textsuperscript{FM}, a smaller, human-revised dataset for seven languages that allows for the evaluation of multilingual RE systems. \\nTo demonstrate the utility of these novel datasets, we experiment with the first end-to-end multilingual RE model, mREBEL, \\nthat extracts triplets, including entity types, in multiple languages. We release our resources and model checkpoints at \\\\href{https://www.github.com/babelscape/rebel}{https://www.github.com/babelscape/rebel}."},
	{"name":"KLUE_mrc_negative_train","keyword":"korean","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/KimuGenie/KLUE_mrc_negative_train","creator_name":"Uijin Kim","creator_url":"https://huggingface.co/KimuGenie","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for \\\"KLUE_mrc_negative_train\\\"\\n\\t\\n\\nKLUE mrc train dataset에 BM25을 이용해서 question에 대한 hard negative text 20개를 추가한 데이터입니다.\\nBM25로 hard negative text를 찾았고, preprocessing을 통해 중복 데이터를 최대한 삭제했습니다.\\n사용한 BM25의 정보는 아래와 같습니다.\\n\\n\\t\\n\\t\\t\\ntop-k\\ntop-10\\ntop-20\\ntop-50\\ntop-100\\n\\n\\n\\t\\t\\naccuracy(%)\\n92.1\\n95.0\\n97.1\\n98.8\\n\\n\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tCitation\\n\\t\\n\\n@misc{park2021klue,\\n      title={KLUE: Korean Language Understanding Evaluation}, \\n      author={Sungjoon Park and Jihyung Moon and Sungdong Kim and Won Ik… See the full description on the dataset page: https://huggingface.co/datasets/KimuGenie/KLUE_mrc_negative_train."},
	{"name":"bluehouse-national-petition","keyword":"korean","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/dev7halo/bluehouse-national-petition","creator_name":"dev7halo","creator_url":"https://huggingface.co/dev7halo","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tUsage\\n\\t\\n\\npip install datasets\\n\\nfrom datasets import load_dataset\\n\\ndataset = load_dataset(\\\"dev7halo/bluehouse-national-petition\\\")\\n\\nDatasetDict({\\n    train: Dataset({\\n        features: ['number', '제목', '답변상태', '참여인원', '카테고리', '청원시작', '청원마감', '청원내용', '답변원고'],\\n        num_rows: 451513\\n    })\\n})\\n\\n# dataset['train'][0]\\n{'number': 605368,\\n '제목': '당신의 나라에서 행복했습니다.',\\n '답변상태': '청원종료',\\n '참여인원': '15,350',\\n '카테고리': '기타',\\n '청원시작': '2022-05-09',\\n '청원마감': '2022-06-08',\\n '청원내용': '우선 이 청원은 14시간만… See the full description on the dataset page: https://huggingface.co/datasets/dev7halo/bluehouse-national-petition."},
	{"name":"korean-mcfaq","keyword":"korean","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/dev7halo/korean-mcfaq","creator_name":"dev7halo","creator_url":"https://huggingface.co/dev7halo","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tUsage\\n\\t\\n\\npip install datasets\\n\\nfrom datasets import load_dataset\\n\\ndataset = load_dataset(\\\"dev7halo/korean-mcfaq\\\")\\n\\nDatasetDict({\\n    train: Dataset({\\n        features: ['Unnamed: 0', '제목', '등록일', '질문', '답변'],\\n        num_rows: 2452\\n    })\\n})\\n\\n# dataset['train'][0]\\n{'Unnamed: 0': 0,\\n '제목': \\\"'언젠가', '언젠가는'의 표현\\\",\\n '등록일': '2019. 12. 6. ',\\n '질문': '\\\\n\\\\t\\\\t \\\\n\\\\t\\\\t \\\\n\\\\t\\\\t\\\"저는 언젠가 간호사가 되고 싶어요.\\\"와 같이 쓸 때, 미래의 불특정한 때를 나타내는 \\\\'언젠가\\\\'라는 단어를 \\\\'언젠가는\\\\'이라고 써도 되나요? \\\\'언젠가\\\\'가 표준어인 것 같은데, 뒤에 \\\\'는\\\\'을 쓴… See the full description on the dataset page: https://huggingface.co/datasets/dev7halo/korean-mcfaq."},
	{"name":"flores_101","keyword":"korean","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/severo/flores_101","creator_name":"Sylvain Lesage","creator_url":"https://huggingface.co/severo","description":"One of the biggest challenges hindering progress in low-resource and multilingual machine translation is the \\nlack of good evaluation benchmarks. Current evaluation benchmarks either lack good coverage of low-resource \\nlanguages, consider only restricted domains, or are low quality because they are constructed using \\nsemi-automatic procedures. In this work, we introduce the FLORES evaluation benchmark, consisting of 3001 \\nsentences extracted from English Wikipedia and covering a variety of different topics and domains. \\nThese sentences have been translated in 101 languages by professional translators through a carefully \\ncontrolled process. The resulting dataset enables better assessment of model quality on the long tail of \\nlow-resource languages, including the evaluation of many-to-many multilingual translation systems, as all \\ntranslations are multilingually aligned. By publicly releasing such a high-quality and high-coverage dataset, \\nwe hope to foster progress in the machine translation community and beyond."},
	{"name":"all-scam-spam","keyword":"korean","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/FredZhang7/all-scam-spam","creator_name":"Fred Zhang","creator_url":"https://huggingface.co/FredZhang7","description":"This is a large corpus of 42,619 preprocessed text messages and emails sent by humans in 43 languages. is_spam=1 means spam and is_spam=0 means ham.\\n1040 rows of balanced data, consisting of casual conversations and scam emails in ≈10 languages, were manually collected and annotated by me, with some help from ChatGPT.\\n\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSome preprcoessing algorithms\\n\\t\\n\\n\\nspam_assassin.js, followed by spam_assassin.py\\nenron_spam.py\\n\\n\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData composition\\n\\t\\n\\n\\n\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDescription\\n\\t\\n\\nTo… See the full description on the dataset page: https://huggingface.co/datasets/FredZhang7/all-scam-spam."},
	{"name":"empathetic_dialogues_mutli_turn_ko","keyword":"korean","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ohilikeit/empathetic_dialogues_mutli_turn_ko","creator_name":"JiHwanYoon","creator_url":"https://huggingface.co/ohilikeit","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for \\\"한국어 일상 속 공감형 대화 데이터셋(멀티-턴)\\\"\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\n\\nboostCamp AI Tech 5기 과정 중 NLP 12조 훈제연어들 팀의 최종 프로젝트에서 제작한 데이터입니다. \\n일상 속 다양한 상황에서 사용자와 챗봇 간의 대화를 담은 데이터셋 입니다. \\nGPT4, GPT3.5-turbo로 제작된 합성데이터이며 싱글-턴, 2-턴, 3-턴 대화로 구성되어 있습니다.\\n답변은 [공감적 표현 - 일반적인 대화 - 관련된 질문] 의 형태를 가집니다.\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tGeneration Prompt Example(GPT3.5-turbo)\\n\\t\\n\\nTake a close look at the following example and Conditions. Create nine sessions that each of the session is ongoing conversation about… See the full description on the dataset page: https://huggingface.co/datasets/ohilikeit/empathetic_dialogues_mutli_turn_ko."},
	{"name":"xP3x-sample","keyword":"korean","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Muennighoff/xP3x-sample","creator_name":"Niklas Muennighoff","creator_url":"https://huggingface.co/Muennighoff","description":"A multilingual collection of Winograd Schemas in six languages that can be used for evaluation of cross-lingual commonsense reasoning capabilities."},
	{"name":"Teatime","keyword":"korean","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/OpenLeecher/Teatime","creator_name":"Peevski","creator_url":"https://huggingface.co/OpenLeecher","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tINFO:\\n\\t\\n\\nThese are the parsed logs from the \\\"teatime logs\\\" xlsx files.\\nEvery user edit or message regeneration makes a new branch in the conversation tree. This leads to message duplication in the 'all_logs.json' file. Every change creates a fresh branch, copying all earlier messages.\\nThe 'longest' files are different. They only contain the longest path from the first to the last message. This approach aims to avoid duplication. Ideally, the '_longest' files should have no repeat… See the full description on the dataset page: https://huggingface.co/datasets/OpenLeecher/Teatime."},
	{"name":"onepiece-characters","keyword":"korean","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/yjg30737/onepiece-characters","creator_name":"yjg","creator_url":"https://huggingface.co/yjg30737","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tonepiece-character\\n\\t\\n\\nThis is a dataset created from crawling the One Piece Fandom on 2023-07-08.\\n"},
	{"name":"malicious-website-features-2.4M","keyword":"korean","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/FredZhang7/malicious-website-features-2.4M","creator_name":"Fred Zhang","creator_url":"https://huggingface.co/FredZhang7","description":"Important Notice:\\n\\nA subset of the URL dataset is from Kaggle, and the Kaggle datasets contained 10%-15% mislabelled data. See this dicussion I opened for some false positives. I have contacted Kaggle regarding their erroneous \\\"Usability\\\" score calculation for these unreliable datasets.\\nThe feature extraction methods shown here are not robust at all in 2023, and there're even silly mistakes in 3 functions: not_indexed_by_google, domain_registration_length, and age_of_domain.\\n\\n\\n\\nThe features… See the full description on the dataset page: https://huggingface.co/datasets/FredZhang7/malicious-website-features-2.4M."},
	{"name":"skb","keyword":"korean","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/min9805/skb","creator_name":"min","creator_url":"https://huggingface.co/min9805","description":"min9805/skb dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"MMLU_Korean","keyword":"korean","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/FreedomIntelligence/MMLU_Korean","creator_name":"FreedomAI","creator_url":"https://huggingface.co/FreedomIntelligence","description":"Korean version of MMLU dataset tranlasted by gpt-3.5-turbo.The dataset is used in the research related to MultilingualSIFT. \\n"},
	{"name":"empathetic_dialogues_ko","keyword":"korean","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Smoked-Salmon-s/empathetic_dialogues_ko","creator_name":"훈제연어들 | Smoked_Salmon_s","creator_url":"https://huggingface.co/Smoked-Salmon-s","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for \\\"한국어 일상 속 공감형 대화 데이터셋(멀티-턴)\\\"\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\n\\nboostCamp AI Tech 5기 과정 중 NLP 12조 훈제연어들 팀의 최종 프로젝트에서 제작한 데이터입니다. \\n일상 속 다양한 상황에서 사용자와 챗봇 간의 대화를 담은 데이터셋 입니다. \\nGPT4, GPT3.5-turbo로 제작된 합성데이터이며 싱글-턴, 2-턴, 3-턴 대화로 구성되어 있습니다.\\n답변은 [공감적 표현 - 일반적인 대화 - 관련된 질문] 의 형태를 가집니다.\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tGeneration Prompt Example(GPT3.5-turbo)\\n\\t\\n\\nTake a close look at the following example and Conditions. Create nine sessions that each of the session is ongoing conversation about… See the full description on the dataset page: https://huggingface.co/datasets/Smoked-Salmon-s/empathetic_dialogues_ko."},
	{"name":"calculation","keyword":"korean","license":"\"Do What The F*ck You Want To Public License\"","license_url":"https://choosealicense.com/licenses/wtfpl/","language":"en","dataset_url":"https://huggingface.co/datasets/OzoneAsai/calculation","creator_name":"AsaiTaka","creator_url":"https://huggingface.co/OzoneAsai","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Calculation\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tsize\\n\\t\\n\\n  JSON file: output1.json≒1.3GB\\n  ~\\n    output60.json\\n     In total 70 ~ 80GB\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nen: Calculation. Its range will be expanded later.\\nzh: 计算。其范围将在以后扩展。\\nde: Berechnung. Der Umfang wird später erweitert werden.\\nru: Расчет. Его диапазон будет расширен позже.\\nko: 계산. 범위는 나중에 확장될 것입니다.\\nfr: Calcul. Sa portée sera étendue ultérieurement.\\nja: 計算。範囲は後で拡張されます。\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSupported Tasks and Leaderboards\\n\\t\\n\\nen:… See the full description on the dataset page: https://huggingface.co/datasets/OzoneAsai/calculation."},
	{"name":"4typeCalculation","keyword":"korean","license":"\"Do What The F*ck You Want To Public License\"","license_url":"https://choosealicense.com/licenses/wtfpl/","language":"en","dataset_url":"https://huggingface.co/datasets/OzoneAsai/4typeCalculation","creator_name":"AsaiTaka","creator_url":"https://huggingface.co/OzoneAsai","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Calculation\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tsize\\n\\t\\n\\n  JSON file: output1.json≒1.3GB\\n  ~\\n    output60.json\\n     In total 70 ~ 80GB\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nen: Calculation. Its range will be expanded later.\\nzh: 计算。其范围将在以后扩展。\\nde: Berechnung. Der Umfang wird später erweitert werden.\\nru: Расчет. Его диапазон будет расширен позже.\\nko: 계산. 범위는 나중에 확장될 것입니다.\\nfr: Calcul. Sa portée sera étendue ultérieurement.\\nja: 計算。範囲は後で拡張されます。\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSupported Tasks and Leaderboards\\n\\t\\n\\nen:… See the full description on the dataset page: https://huggingface.co/datasets/OzoneAsai/4typeCalculation."},
	{"name":"open-lid-dataset","keyword":"korean","license":"GNU General Public License v3.0","license_url":"https://choosealicense.com/licenses/gpl-3.0/","language":"en","dataset_url":"https://huggingface.co/datasets/hac541309/open-lid-dataset","creator_name":"Chris Ha","creator_url":"https://huggingface.co/hac541309","description":"This dataset is built from the open source data accompanying \\\"An Open Dataset and Model for Language Identification\\\" (Burchell et al., 2023)\\nThe repository containing the actual data can be found here : https://github.com/laurieburchell/open-lid-dataset.\\nThe license for this recreation itself follows the original upstream dataset as GPLv3+. \\nHowever, individual datasets within it follow each of their own licenses.\\nThe \\\"src\\\" column lists the sources. \\\"lang\\\" column lists the language code in… See the full description on the dataset page: https://huggingface.co/datasets/hac541309/open-lid-dataset."},
	{"name":"QAmeleon","keyword":"korean","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/imvladikon/QAmeleon","creator_name":"Vladimir Gurevich","creator_url":"https://huggingface.co/imvladikon","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for \\\"QAmeleon\\\"\\n\\t\\n\\nQAmeleon introduces synthetic multilingual QA data contaning in 8 langauges using PaLM-540B, a large language model. This dataset was generated by prompt tuning PaLM with only five examples per language. We use the synthetic data to finetune downstream QA models leading to improved accuracy in comparison to English-only and translation-based baselines. \\nData available at https://storage.googleapis.com/qameleon/qamelon_pt_accepted.csv \\nMore details can… See the full description on the dataset page: https://huggingface.co/datasets/imvladikon/QAmeleon."},
	{"name":"KOpen-platypus","keyword":"korean","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/kyujinpy/KOpen-platypus","creator_name":"KyujinHan","creator_url":"https://huggingface.co/kyujinpy","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tKOpenPlatypus: Korean Translation dataset about Open-Platypus\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tKorean Translation Method\\n\\t\\n\\nI use DeepL-pro-API and selenium. \\nIt takes about 140h times.+) 데이터셋 이용하셔서 모델이나 데이터셋을 만드실 때, 간단한 출처 표기를 해주신다면 연구에 큰 도움이 됩니다😭😭\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tKorean Translation post-processing\\n\\t\\n\\n\\n\\n\\n\\n\\nAnd also, applying post-processing. See below lists. (*약 2000개 이상의 코드 관련 데이터를 수작업으로 수정함)\\n\\n코드와 주석은 그대로 유지하고, 설명 부분만 한국어로 수정\\n1번과 더불어서, Python, Java, Cpp, xml 등등 결과들은 전부 기존의 데이터 형태로 최대한 보존\\n단일 숫자와 영어는… See the full description on the dataset page: https://huggingface.co/datasets/kyujinpy/KOpen-platypus."},
	{"name":"EverythingLM-data-V2-Ko","keyword":"korean","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/ziozzang/EverythingLM-data-V2-Ko","creator_name":"Jioh L. Jung","creator_url":"https://huggingface.co/ziozzang","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tTranslated into Korean with DeepL\\n\\t\\n\\nAll Texts are translated with DeepL. (Machine Translated.)\\n\\nIssue: some data items are missing, cause of DeepL plan and processing method. I use very cheap plan and all datas are merged into single file and splitted by few code and hand.\\nThis is sample/test processing of data set creation with DeepL.\\n\\n\\nOriginal Dataset: totally-not-an-llm/EverythingLM-data-V2\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tEverythingLM V2 Dataset\\n\\t\\n\\nEverythingLM V2 is a diverse instruct dataset… See the full description on the dataset page: https://huggingface.co/datasets/ziozzang/EverythingLM-data-V2-Ko."},
	{"name":"Korean_Wikipedia_Dataset_for_GPT2_August_2022","keyword":"korean","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/eaglewatch/Korean_Wikipedia_Dataset_for_GPT2_August_2022","creator_name":"Yongwoo Jeong","creator_url":"https://huggingface.co/eaglewatch","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for korean_wikipedia_dataset_for_GPT2\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nEntire Korean language Wikipedia data for GPT-2 training as of August 1st, 2022.\\nemail: oscar.eaglewatch@gmail.com\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThis is to make a pre-trained GPT-2 Korean model\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages\\n\\t\\n\\nKorean\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Structure\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Instances\\n\\t\\n\\nTrain wikipedia article count: 334420\\nvalidation wikipedia article count: 83605\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Fields… See the full description on the dataset page: https://huggingface.co/datasets/eaglewatch/Korean_Wikipedia_Dataset_for_GPT2_August_2022."},
	{"name":"Korean_Wikipedia_Dataset_for_GPT2_August_2022","keyword":"korean","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/eaglewatch/Korean_Wikipedia_Dataset_for_GPT2_August_2022","creator_name":"Yongwoo Jeong","creator_url":"https://huggingface.co/eaglewatch","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for korean_wikipedia_dataset_for_GPT2\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nEntire Korean language Wikipedia data for GPT-2 training as of August 1st, 2022.\\nemail: oscar.eaglewatch@gmail.com\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThis is to make a pre-trained GPT-2 Korean model\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages\\n\\t\\n\\nKorean\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Structure\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Instances\\n\\t\\n\\nTrain wikipedia article count: 334420\\nvalidation wikipedia article count: 83605\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Fields… See the full description on the dataset page: https://huggingface.co/datasets/eaglewatch/Korean_Wikipedia_Dataset_for_GPT2_August_2022."},
	{"name":"wikianc","keyword":"korean","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/cyanic-selkie/wikianc","creator_name":"cyanic-selkie","creator_url":"https://huggingface.co/cyanic-selkie","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for WikiAnc\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThe WikiAnc dataset is an automatically generated dataset from Wikipedia (all languages) and Wikidata dumps (August, 2023). \\nThe code for generating the dataset can be found here.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSupported Tasks\\n\\t\\n\\n\\nwikificiation: The dataset can be used to train a model for Wikification.\\nnamed-entity-linking: The dataset can be used to train a model for Named Entity Linking.\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages\\n\\t\\n\\nThe text in the dataset is… See the full description on the dataset page: https://huggingface.co/datasets/cyanic-selkie/wikianc."},
	{"name":"llama-2-ko-law","keyword":"korean","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/jaejoo/llama-2-ko-law","creator_name":"hong","creator_url":"https://huggingface.co/jaejoo","description":"jaejoo/llama-2-ko-law dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"entity_cs","keyword":"korean","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/huawei-noah/entity_cs","creator_name":"HUAWEI Noah's Ark Lab","creator_url":"https://huggingface.co/huawei-noah","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for EntityCS\\n\\t\\n\\n\\nRepository: https://github.com/huawei-noah/noah-research/tree/master/NLP/EntityCS  \\nPaper: https://aclanthology.org/2022.findings-emnlp.499.pdf  \\nPoint of Contact: Fenia Christopoulou, Chenxi Whitehouse\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nWe use the English Wikipedia and leverage entity information from Wikidata to construct an entity-based Code Switching corpus. \\nTo achieve this, we make use of wikilinks in Wikipedia, i.e. links from one page to… See the full description on the dataset page: https://huggingface.co/datasets/huawei-noah/entity_cs."},
	{"name":"embedding-test","keyword":"korean","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/daeell/embedding-test","creator_name":"Kim Dael","creator_url":"https://huggingface.co/daeell","description":"daeell/embedding-test dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"HAE-RAE-COT-1.5M","keyword":"korean","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/HAERAE-HUB/HAE-RAE-COT-1.5M","creator_name":"HAE-RAE","creator_url":"https://huggingface.co/HAERAE-HUB","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for \\\"HAE-RAE-COT-1.5M\\\"\\n\\t\\n\\nHAE-RAE-COT-1.5M is a dataset encompassing 1,586,688 samples of questions paired with CoT (Chain of Thought) rationales. \\nThe majority of this dataset is a translation of samples from the CoT-Collection, with a portion of samples derived from Korean datasets through the utilization of the gpt-3.5-turbo API. The translation of the CoT-Collection was carried out using the NLLB 600M model.\\nTo the best of our knowledge, HAE-RAE-COT-1.5M represents… See the full description on the dataset page: https://huggingface.co/datasets/HAERAE-HUB/HAE-RAE-COT-1.5M."},
	{"name":"text_coordinates_regions","keyword":"korean","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/yachay/text_coordinates_regions","creator_name":"Yachay AI","creator_url":"https://huggingface.co/yachay","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Multilingual Geo-Tagged Social Media Posts (by 123 world regions)\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThe \\\"Regions\\\" dataset is a multilingual corpus that encompasses textual data from the 123 most populated regions worldwide, with each region's data organized into separate .json files. This dataset consists of approximately 500,000 text samples, each paired with its geographic coordinates.\\nKey Features:\\n\\nTextual Data: The dataset contains 500,000 text samples.… See the full description on the dataset page: https://huggingface.co/datasets/yachay/text_coordinates_regions."},
	{"name":"MultiCoNER","keyword":"korean","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/tomaarsen/MultiCoNER","creator_name":"Tom Aarsen","creator_url":"https://huggingface.co/tomaarsen","description":"We present MultiCoNER, a large multilingual dataset for Named Entity Recognition that covers 3 domains (Wiki sentences, questions, and search queries) across 11 languages, as well as multilingual and code-mixing subsets. This dataset is designed to represent contemporary challenges in NER, including low-context scenarios (short and uncased text), syntactically complex entities like movie titles, and long-tail entity distributions. The 26M token dataset is compiled from public resources using techniques such as heuristic-based sentence sampling, template extraction and slotting, and machine translation. We applied two NER models on our dataset: a baseline XLM-RoBERTa model, and a state-of-the-art GEMNET model that leverages gazetteers. The baseline achieves moderate performance (macro-F1=54%), highlighting the difficulty of our data. GEMNET, which uses gazetteers, improvement significantly (average improvement of macro-F1=+30%). MultiCoNER poses challenges even for large pre-trained language models, and we believe that it can help further research in building robust NER systems. MultiCoNER is publicly available at https://registry.opendata.aws/multiconer/ and we hope that this resource will help advance research in various aspects of NER."},
	{"name":"openassistant-guanaco-EOS","keyword":"korean","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Trelis/openassistant-guanaco-EOS","creator_name":"Trelis","creator_url":"https://huggingface.co/Trelis","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tChat Fine-tuning Dataset - Guanaco Style\\n\\t\\n\\nThis dataset allows for fine-tuning chat models using \\\"### Human:\\\" AND \\\"### Assistant\\\" as the beginning and end of sequence tokens.\\nPreparation:\\n\\nThe dataset is cloned from TimDettmers, which itself is a subset of the Open Assistant dataset, which you can find here. This subset of the data only contains the highest-rated paths in the conversation tree, with a total of 9,846 samples.\\nThe dataset was then slightly adjusted to:\\n\\n\\nif a row of… See the full description on the dataset page: https://huggingface.co/datasets/Trelis/openassistant-guanaco-EOS."},
	{"name":"sharegpt-deduplicated","keyword":"korean","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/CaterinaLac/sharegpt-deduplicated","creator_name":"Caterina Lacerra","creator_url":"https://huggingface.co/CaterinaLac","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Dataset Name\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThis dataset is a deduplicated version of sharegpt4. \\nThe deduplication process has two steps:\\n\\nThe literal duplicates (both input and outputs) are removed\\nThe remaining (5749) instances are embedded with the SentenceTransformer library (\\\"paraphrase-multilingual-mpnet-base-v2\\\" model).\\nThen, we compute the cosine similarity among all the possible pairs, and consider paraphrases those… See the full description on the dataset page: https://huggingface.co/datasets/CaterinaLac/sharegpt-deduplicated."},
	{"name":"openassistant-llama-style","keyword":"korean","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Trelis/openassistant-llama-style","creator_name":"Trelis","creator_url":"https://huggingface.co/Trelis","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tChat Fine-tuning Dataset - Llama 2 Style\\n\\t\\n\\nThis dataset allows for fine-tuning chat models using [INST] AND [/INST] to wrap user messages.\\nPreparation:\\n\\nThe dataset is cloned from TimDettmers, which itself is a subset of the Open Assistant dataset, which you can find here. This subset of the data only contains the highest-rated paths in the conversation tree, with a total of 9,846 samples.\\nThe dataset was then filtered to:\\n\\n\\nreplace instances of '### Human:' with '[INST]'\\nreplace… See the full description on the dataset page: https://huggingface.co/datasets/Trelis/openassistant-llama-style."},
	{"name":"MultiJail","keyword":"korean","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/DAMO-NLP-SG/MultiJail","creator_name":"Language Technology Lab at Alibaba DAMO Academy","creator_url":"https://huggingface.co/DAMO-NLP-SG","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tMultilingual Jailbreak Challenges in Large Language Models\\n\\t\\n\\nThis repo contains the data for our paper \\\"Multilingual Jailbreak Challenges in Large Language Models\\\".\\n[Github repo]\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tAnnotation Statistics\\n\\t\\n\\nWe collected a total of 315 English unsafe prompts and annotated them into nine non-English languages. The languages were categorized based on resource availability, as shown below:\\nHigh-resource languages: Chinese (zh), Italian (it), Vietnamese (vi)\\nMedium-resource… See the full description on the dataset page: https://huggingface.co/datasets/DAMO-NLP-SG/MultiJail."},
	{"name":"mqnli","keyword":"korean","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/SachinPatel248/mqnli","creator_name":"Patel","creator_url":"https://huggingface.co/SachinPatel248","description":"SachinPatel248/mqnli dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"K-HATERS","keyword":"korean","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/humane-lab/K-HATERS","creator_name":"HUMANE Lab","creator_url":"https://huggingface.co/humane-lab","description":""},
	{"name":"udhr-lid","keyword":"korean","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/cis-lmu/udhr-lid","creator_name":"CIS, LMU Munich","creator_url":"https://huggingface.co/cis-lmu","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tUDHR-LID\\n\\t\\n\\nWhy UDHR-LID?\\nYou can access UDHR (Universal Declaration of Human Rights) here, but when a verse is missing, they have texts such as \\\"missing\\\" or \\\"?\\\". Also, about 1/3 of the sentences consist only of \\\"articles 1-30\\\" in different languages. We cleaned the entire dataset from XML files and selected only the paragraphs. We cleared any unrelated language texts from the data and also removed the cases that were incorrect.\\nIncorrect? Look at the ckb and kmr files in the UDHR.… See the full description on the dataset page: https://huggingface.co/datasets/cis-lmu/udhr-lid."},
	{"name":"seamless-align","keyword":"korean","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/jhu-clsp/seamless-align","creator_name":"Center for Language and Speech Processing @ JHU","creator_url":"https://huggingface.co/jhu-clsp","description":"\\n\\t\\n\\t\\t\\n\\t\\tDataset Card for Seamless-Align (WIP). Inspired by https://huggingface.co/datasets/allenai/nllb\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThis dataset was created based on metadata for mined Speech-to-Speech(S2S), Text-to-Speech(TTS) and Speech-to-Text(S2T) released by Meta AI.  The S2S contains data for 35 language pairs. The S2S dataset is ~1000GB compressed.\\n\\n\\t\\n\\t\\t\\n\\t\\tHow to use the data\\n\\t\\n\\nThere are two ways to access the data:\\n\\nVia the Hugging Face Python datasets library\\n\\nScripts coming soon… See the full description on the dataset page: https://huggingface.co/datasets/jhu-clsp/seamless-align."},
	{"name":"WEATHub","keyword":"korean","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/iamshnoo/WEATHub","creator_name":"Anjishnu Mukherjee","creator_url":"https://huggingface.co/iamshnoo","description":"\\n\\n\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for \\\"WEATHub\\\"\\n\\t\\n\\nThis dataset corresponds to the data described in the paper \\\"Global Voices, Local Biases: Socio-Cultural Prejudices across Languages\\\"\\naccepted to EMNLP 2023.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nWEATHub is a dataset containing 24 languages. It contains words organized into groups of (target1, target2, attribute1, attribute2)\\nto measure the association target1:target2 :: attribute1:attribute2. For example target1 can be insects, target2 can be flowers.… See the full description on the dataset page: https://huggingface.co/datasets/iamshnoo/WEATHub."},
	{"name":"kor_snli","keyword":"korean","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/KETI-AIR/kor_snli","creator_name":"Korea Electronics Technology Institute Artificial Intelligence Research Center","creator_url":"https://huggingface.co/KETI-AIR","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for QASC\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLicensing Information\\n\\t\\n\\nThe data is distributed under the CC BY 4.0 license.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSource Data Citation INformation\\n\\t\\n\\n@inproceedings{snli:emnlp2015,\\n    Author = {Bowman, Samuel R. and Angeli, Gabor and Potts, Christopher, and Manning, Christopher D.},\\n    Booktitle = {Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing (EMNLP)},\\n    Publisher = {Association for Computational Linguistics},\\n    Title =… See the full description on the dataset page: https://huggingface.co/datasets/KETI-AIR/kor_snli."},
	{"name":"openassistant-falcon","keyword":"korean","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Trelis/openassistant-falcon","creator_name":"Trelis","creator_url":"https://huggingface.co/Trelis","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tChat Fine-tuning Dataset - OpenAssistant Falcon\\n\\t\\n\\nThis dataset allows for fine-tuning chat models using '\\\\Human:' AND '\\\\nAssistant:' to wrap user messages.\\nIt still uses <|endoftext|> as EOS and BOS token, as per Falcon.\\nSample \\nPreparation:\\n\\nThe dataset is cloned from TimDettmers, which itself is a subset of the Open Assistant dataset, which you can find here. This subset of the data only contains the highest-rated paths in the conversation tree, with a total of 9,846 samples.… See the full description on the dataset page: https://huggingface.co/datasets/Trelis/openassistant-falcon."},
	{"name":"kor_amazon_polarity","keyword":"korean","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/KETI-AIR/kor_amazon_polarity","creator_name":"Korea Electronics Technology Institute Artificial Intelligence Research Center","creator_url":"https://huggingface.co/KETI-AIR","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for amazon_polarity\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLicensing Information\\n\\t\\n\\nThe data is distributed under the CC0 1.0 license.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSource Data Citation Information\\n\\t\\n\\nMcAuley, Julian, and Jure Leskovec. \\\"Hidden factors and hidden topics: understanding rating dimensions with review text.\\\" In Proceedings of the 7th ACM conference on Recommender systems, pp. 165-172. 2013.\\nXiang Zhang, Junbo Zhao, Yann LeCun. Character-level Convolutional Networks for Text Classification.… See the full description on the dataset page: https://huggingface.co/datasets/KETI-AIR/kor_amazon_polarity."},
	{"name":"kor_duorc","keyword":"korean","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/KETI-AIR/kor_duorc","creator_name":"Korea Electronics Technology Institute Artificial Intelligence Research Center","creator_url":"https://huggingface.co/KETI-AIR","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for duorc\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLicensing Information\\n\\t\\n\\nMIT License\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSource Data Citation Information\\n\\t\\n\\n@inproceedings{DuoRC,\\nauthor = { Amrita Saha and Rahul Aralikatte and Mitesh M. Khapra and Karthik Sankaranarayanan},\\ntitle = {{DuoRC: Towards Complex Language Understanding with Paraphrased Reading Comprehension}},\\nbooktitle = {Meeting of the Association for Computational Linguistics (ACL)},\\nyear = {2018}\\n}\\n\\n"},
	{"name":"lr-sum","keyword":"korean","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/bltlab/lr-sum","creator_name":"Broadening Linguistic Technologies Lab (BLT Lab)","creator_url":"https://huggingface.co/bltlab","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for LR-Sum\\n\\t\\n\\nLR-Sum is a automatic summarization dataset of newswire text with a focus on less resourced languages with a cc-by 4.0 license.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Details\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nLR-Sum is a permissively-licensed dataset created with the goal of enabling further research in automatic summarization for less-resourced languages.\\nLR-Sum contains human-written summaries for 39 languages, many of which are less-resourced. \\nThe data is based on… See the full description on the dataset page: https://huggingface.co/datasets/bltlab/lr-sum."},
	{"name":"kor_web_questions","keyword":"korean","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/KETI-AIR/kor_web_questions","creator_name":"Korea Electronics Technology Institute Artificial Intelligence Research Center","creator_url":"https://huggingface.co/KETI-AIR","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for WEB_QUESTIONS\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLicensing Information\\n\\t\\n\\nThe data is distributed under the CC BY 4.0 license.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSource Data Citation INformation\\n\\t\\n\\n@inproceedings{berant-etal-2013-semantic,\\n    title = \\\"Semantic Parsing on {F}reebase from Question-Answer Pairs\\\",\\n    author = \\\"Berant, Jonathan  and\\n      Chou, Andrew  and\\n      Frostig, Roy  and\\n      Liang, Percy\\\",\\n    booktitle = \\\"Proceedings of the 2013 Conference on Empirical Methods in Natural Language… See the full description on the dataset page: https://huggingface.co/datasets/KETI-AIR/kor_web_questions."},
	{"name":"kor_quarel","keyword":"korean","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/KETI-AIR/kor_quarel","creator_name":"Korea Electronics Technology Institute Artificial Intelligence Research Center","creator_url":"https://huggingface.co/KETI-AIR","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Quarel\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLicensing Information\\n\\t\\n\\nThe data is distributed under the CC BY 4.0 license.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSource Data Citation INformation\\n\\t\\n\\n@inproceedings{quarel_v1,\\n    title={QuaRel: A Dataset and Models for Answering Questions about Qualitative Relationships},\\n    author={Oyvind Tafjord, Peter Clark, Matt Gardner, Wen-tau Yih, Ashish Sabharwal},\\n    year={2018},\\n    journal={arXiv:1805.05377v1}\\n}\\n\\n"},
	{"name":"kor_qasc","keyword":"korean","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/KETI-AIR/kor_qasc","creator_name":"Korea Electronics Technology Institute Artificial Intelligence Research Center","creator_url":"https://huggingface.co/KETI-AIR","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for QASC\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLicensing Information\\n\\t\\n\\nThe data is distributed under the CC BY 4.0 license.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSource Data Citation INformation\\n\\t\\n\\n@article{allenai:qasc,\\n      author    = {Tushar Khot and Peter Clark and Michal Guerquin and Peter Jansen and Ashish Sabharwal},\\n      title     = {QASC: A Dataset for Question Answering via Sentence Composition},\\n      journal   = {arXiv:1910.11473v2},\\n      year      = {2020},\\n}\\n\\n"},
	{"name":"kor_ropes","keyword":"korean","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/KETI-AIR/kor_ropes","creator_name":"Korea Electronics Technology Institute Artificial Intelligence Research Center","creator_url":"https://huggingface.co/KETI-AIR","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for ROPES\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLicensing Information\\n\\t\\n\\nThe data is distributed under the CC BY 4.0 license.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSource Data Citation INformation\\n\\t\\n\\n@inproceedings{Lin2019ReasoningOP,\\n  title={Reasoning Over Paragraph Effects in Situations},\\n  author={Kevin Lin and Oyvind Tafjord and Peter Clark and Matt Gardner},\\n  booktitle={MRQA@EMNLP},\\n  year={2019}\\n}\\n\\n"},
	{"name":"kor_cosmos_qa","keyword":"korean","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/KETI-AIR/kor_cosmos_qa","creator_name":"Korea Electronics Technology Institute Artificial Intelligence Research Center","creator_url":"https://huggingface.co/KETI-AIR","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for cosmos_qa\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLicensing Information\\n\\t\\n\\nThe data is distributed under the CC BY 4.0 license.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSource Data Citation INformation\\n\\t\\n\\n@inproceedings{huang-etal-2019-cosmos,\\n    title = \\\"Cosmos {QA}: Machine Reading Comprehension with Contextual Commonsense Reasoning\\\",\\n    author = \\\"Huang, Lifu  and\\n      Le Bras, Ronan  and\\n      Bhagavatula, Chandra  and\\n      Choi, Yejin\\\",\\n    booktitle = \\\"Proceedings of the 2019 Conference on Empirical Methods… See the full description on the dataset page: https://huggingface.co/datasets/KETI-AIR/kor_cosmos_qa."},
	{"name":"kor_quartz","keyword":"korean","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/KETI-AIR/kor_quartz","creator_name":"Korea Electronics Technology Institute Artificial Intelligence Research Center","creator_url":"https://huggingface.co/KETI-AIR","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for quartz\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLicensing Information\\n\\t\\n\\nThe data is distributed under the CC BY 4.0 license.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSource Data Citation Information\\n\\t\\n\\n@InProceedings{quartz,\\n  author = {Oyvind Tafjord and Matt Gardner and Kevin Lin and Peter Clark},\\n  title = {\\\"QUARTZ: An Open-Domain Dataset of Qualitative Relationship\\nQuestions\\\"},\\n  year = {\\\"2019\\\"},\\n}\\n\\n"},
	{"name":"kor_squad_v2","keyword":"korean","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/KETI-AIR/kor_squad_v2","creator_name":"Korea Electronics Technology Institute Artificial Intelligence Research Center","creator_url":"https://huggingface.co/KETI-AIR","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for squad_v2\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLicensing Information\\n\\t\\n\\nThe data is distributed under the CC BY SA 4.0 license.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSource Data Citation Information\\n\\t\\n\\n@article{2016arXiv160605250R,\\n       author = {{Rajpurkar}, Pranav and {Zhang}, Jian and {Lopyrev},\\n                 Konstantin and {Liang}, Percy},\\n        title = \\\"{SQuAD: 100,000+ Questions for Machine Comprehension of Text}\\\",\\n      journal = {arXiv e-prints},\\n         year = 2016,\\n          eid =… See the full description on the dataset page: https://huggingface.co/datasets/KETI-AIR/kor_squad_v2."},
	{"name":"megawika-report-generation","keyword":"korean","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/hltcoe/megawika-report-generation","creator_name":"JHU Human Language Technology Center of Excellence","creator_url":"https://huggingface.co/hltcoe","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for MegaWika for Report Generation\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nMegaWika is a multi- and crosslingual text dataset containing 30 million Wikipedia passages with their scraped and cleaned web citations. The passages span\\n50 Wikipedias in 50 languages, and the articles in which the passages were originally embedded are included for convenience. Where a Wikipedia passage is in a\\nnon-English language, an automated English translation is provided. \\nThis dataset… See the full description on the dataset page: https://huggingface.co/datasets/hltcoe/megawika-report-generation."},
	{"name":"Verified-Camel-KO","keyword":"korean","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/kuotient/Verified-Camel-KO","creator_name":"Jisoo Kim","creator_url":"https://huggingface.co/kuotient","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVerified-Camel-KO\\n\\t\\n\\n이 데이터셋은 https://huggingface.co/datasets/LDJnr/Verified-Camel 의 한국어 번역입니다.\\nGPT4 Turbo로 번역한 뒤, 약간의 수정을 거쳤습니다.\\n이 데이터에 대한 방침은 전부 원 저자의 방침을 따릅니다.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tThis is the Official Verified Camel dataset. Just over 100 verified examples, and many more coming soon!\\n\\t\\n\\n\\nComprised of over 100 highly filtered and curated examples from specific portions of CamelAI stem datasets. \\n\\nThese examples are verified to be true by experts in the specific related field, with atleast… See the full description on the dataset page: https://huggingface.co/datasets/kuotient/Verified-Camel-KO."},
	{"name":"hh-rlhf-ko","keyword":"korean","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/heegyu/hh-rlhf-ko","creator_name":"Heegyu Kim","creator_url":"https://huggingface.co/heegyu","description":"\\nOriginal Dataset: Anthropic/hh-rlhf\\nTranslation by using maywell/Synatra-7B-v0.3-Translation\\nTranslating in progress...\\n\\n"},
	{"name":"Pontoon-Translations","keyword":"korean","license":"Mozilla Public License 2.0","license_url":"https://choosealicense.com/licenses/mpl-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ayymen/Pontoon-Translations","creator_name":"Mohamed Aymane Farhi","creator_url":"https://huggingface.co/ayymen","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Pontoon Translations\\n\\t\\n\\n\\n\\nThis is a dataset containing strings from various Mozilla projects on Mozilla's Pontoon localization platform and their translations into more than 200 languages.\\nSource strings are in English.\\nTo avoid rows with values like \\\"None\\\" and \\\"N/A\\\" being interpreted as missing values, pass the keep_default_na parameter like this:\\nfrom datasets import load_dataset\\n\\ndataset = load_dataset(\\\"ayymen/Pontoon-Translations\\\", keep_default_na=False)… See the full description on the dataset page: https://huggingface.co/datasets/ayymen/Pontoon-Translations."},
	{"name":"Orca-DPO-Pairs-KO","keyword":"korean","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Ja-ck/Orca-DPO-Pairs-KO","creator_name":"Kim JaeCheol","creator_url":"https://huggingface.co/Ja-ck","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tOrca-DPO-Pairs-KO\\n\\t\\n\\nIntel/orca_dpo_pais 를 한국어로 번역한 데이터세트 입니다.\\n번역은 maywell/Syntra-7B-v0.3-Translation 을 사용했습니다. 번역 후 일부 오류가 발생한 라인은 삭제했기 때문에 원본과 차이가 있을 수 있습니다.\\n"},
	{"name":"ntx_llm_instructions","keyword":"korean","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/tellarin-ai/ntx_llm_instructions","creator_name":"Tellarin.ai","creator_url":"https://huggingface.co/tellarin-ai","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for NTX v1 in the Aya format\\n\\t\\n\\nThis dataset is a format conversion from its original v1 format into the Aya instruction format and it's released here under the CC-BY-SA 4.0 license and conditions.\\nIt contains data in multiple languages and this version is intended for multi-lingual LLM construction/tuning.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tCitation\\n\\t\\n\\nIf you utilize this dataset version, feel free to cite/footnote this huggingface dataset repo, but please also cite the original dataset… See the full description on the dataset page: https://huggingface.co/datasets/tellarin-ai/ntx_llm_instructions."},
	{"name":"ntx_llm_inst_korean","keyword":"korean","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/tellarin-ai/ntx_llm_inst_korean","creator_name":"Tellarin.ai","creator_url":"https://huggingface.co/tellarin-ai","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for NTX v1 in the Aya format - Korean subset\\n\\t\\n\\nThis dataset is a format conversion for the Korean data from the original NTX into the Aya instruction format and it's released here under the CC-BY-SA 4.0 license.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Details\\n\\t\\n\\nFor the original NTX dataset, the conversion to the Aya instructions format, or more details, please refer to the full dataset in instruction form (https://huggingface.co/datasets/tellarin-ai/ntx_llm_instructions) or to the paper… See the full description on the dataset page: https://huggingface.co/datasets/tellarin-ai/ntx_llm_inst_korean."},
	{"name":"ml-kge","keyword":"korean","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/davanstrien/ml-kge","creator_name":"Daniel van Strien","creator_url":"https://huggingface.co/davanstrien","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tMKGE: Multilingual Knowledge Graph Enhancement\\n\\t\\n\\nnote this dataset card was copied from this GitHub Repository\\nTask Description |\\nWikiKGE-10 |\\nEvaluation |\\nPaper |\\nCitation |\\nLicense\\nRecent work in Natural Language Processing and Computer Vision has been leveraging textual information -- e.g., entity names and descriptions -- available in knowledge graphs to ground neural models to high-quality structured data.\\nHowever, when it comes to non-English languages, both quantity and… See the full description on the dataset page: https://huggingface.co/datasets/davanstrien/ml-kge."},
	{"name":"oasst2_top1_chat_format","keyword":"korean","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/blancsw/oasst2_top1_chat_format","creator_name":"Blanc Swan","creator_url":"https://huggingface.co/blancsw","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tOpenAssistant TOP-1 Conversation Threads in huggingface chat format\\n\\t\\n\\nExport of oasst2 only top 1 threads in huggingface chat format\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tScript\\n\\t\\n\\nThe convert script can be find here\\n"},
	{"name":"language_tags","keyword":"korean","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/lbourdois/language_tags","creator_name":"Loïck BOURDOIS","creator_url":"https://huggingface.co/lbourdois","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDescription\\n\\t\\n\\nDataset listing 27,328 languages and dialects (also includes macrolanguage names).For each language, either the ISO 639 code, the Glottolog code or both are provided.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tColumns\\n\\t\\n\\n\\nEnglish_Name: Language name in English (e.g. \\\"French\\\").\\nNative_Name: If value is not 0, corresponds to the name of the language by native speakers (e.g. \\\"Français\\\") which may have been found in Wikipedia's nativename field.\\nGlottocode: The language tag in the Glottolog convention… See the full description on the dataset page: https://huggingface.co/datasets/lbourdois/language_tags."},
	{"name":"oaast_rm_full_jieba","keyword":"korean","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/lenML/oaast_rm_full_jieba","creator_name":"len","creator_url":"https://huggingface.co/lenML","description":"尝试解决\\\"llm repetition problem\\\"，使用分词模型对oaast语料进行“结巴化”数据增强，提供更强的重复内容拒绝效果。\\nAttempts to solve the \\\"llm repetition problem\\\" by using a segmentation model to enhance the oaast corpus with \\\"stuttering\\\" data to provide stronger rejection of duplicate content.\\n其次，还过滤掉了所有自我认知的微调样本。\\nSecond, it also filters out all the fine-tuned samples of self-cognition.\\nfiles:\\n\\noaast_rm_full_jieba.jsonl : word level repeat\\noaast_rm_full_sent_jieba.jsonl : sentence level repeat\\n\\n"},
	{"name":"language-dataset","keyword":"korean","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neon-mao/language-dataset","creator_name":"maoqifan","creator_url":"https://huggingface.co/neon-mao","description":"\\n"},
	{"name":"kor-hate-sentence","keyword":"korean","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/SJ-Donald/kor-hate-sentence","creator_name":"SJ.KIM","creator_url":"https://huggingface.co/SJ-Donald","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSJ-Donald/kor-hate-sentence\\n\\t\\n\\nSJ-Donald/kor-hate-sentence is merged dataset from fllow\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDatasets\\n\\t\\n\\n\\nsmilegate-ai/kor_unsmile\\nkorean-hate-speech\\nCurse-detection-data\\nkorean-malicious-comments-dataset\\n\\nMerge datasets from above and drop duplicates.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tHow to use\\n\\t\\n\\nfrom datasets import load_dataset\\n\\nds = load_dataset(\\\"SJ-Donald/kor-hate-sentence\\\")\\nprint(ds)\\n\\nDatasetDict({\\n    train: Dataset({\\n        features: ['문장', 'hate', 'clean', 'labels'],\\n        num_rows:… See the full description on the dataset page: https://huggingface.co/datasets/SJ-Donald/kor-hate-sentence."},
	{"name":"Deltacorpus_1.1","keyword":"korean","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/FrancophonIA/Deltacorpus_1.1","creator_name":"FrancophonIA","creator_url":"https://huggingface.co/FrancophonIA","description":"\\nDataset origin: https://lindat.cz/repository/xmlui/handle/11234/1-1743\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDescription\\n\\t\\n\\nTexts in 107 languages from the W2C corpus (http://hdl.handle.net/11858/00-097C-0000-0022-6133-9), first 1,000,000 tokens per language, tagged by the delexicalized tagger described in Yu et al. (2016, LREC, Portorož, Slovenia).\\nChanges in version 1.1: \\n\\nUniversal Dependencies tagset instead of the older and smaller Google Universal POS tagset. \\n\\nSVM classifier trained on Universal Dependencies… See the full description on the dataset page: https://huggingface.co/datasets/FrancophonIA/Deltacorpus_1.1."},
	{"name":"MM-Eval","keyword":"korean","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/prometheus-eval/MM-Eval","creator_name":"prometheus-eval","creator_url":"https://huggingface.co/prometheus-eval","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tMultilingual Meta-EVALuation benchmark (MM-Eval)\\n\\t\\n\\n\\n👨‍💻Code\\n|\\n📄Paper\\n|\\n🤗 MMQA\\n\\n\\nMM-Eval is a multilingual meta-evaluation benchmark consisting of five core subsets—Chat, Reasoning, Safety, Language Hallucination, and Linguistics—spanning 18 languages and a Language Resource subset spanning 122 languages for a broader analysis of language effects. \\n\\nDesign ChoiceIn this work, we minimize the inclusion of translated samples, as mere translation may alter existing preferences due… See the full description on the dataset page: https://huggingface.co/datasets/prometheus-eval/MM-Eval."},
	{"name":"KMA-term","keyword":"korean","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/junyeong-nero/KMA-term","creator_name":"Junyeong Song","creator_url":"https://huggingface.co/junyeong-nero","description":"This dataset is generated by crawling KMA medical terms\\n"},
	{"name":"linkedin-industry-list","keyword":"korean","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/fantastic-jobs/linkedin-industry-list","creator_name":"Fantastic.jobs","creator_url":"https://huggingface.co/fantastic-jobs","description":"fantastic-jobs/linkedin-industry-list dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"Zeroth-STT-Korean","keyword":"korean","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/o0dimplz0o/Zeroth-STT-Korean","creator_name":"Michele Phan","creator_url":"https://huggingface.co/o0dimplz0o","description":"\\n\\t\\n\\t\\t\\n\\t\\tZeroth-STT-Korean Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDescription\\n\\t\\n\\nThis is a shuffled version of the Zeroth-STT-Ko dataset.\\n\\n\\t\\n\\t\\t\\n\\t\\tCitation\\n\\t\\n\\nZeroth-Korean Dataset, created by [Lucas Jo(@Atlas Guide Inc.) and Wonkyum Lee(@Gridspace Inc.)], 2023.\\nAvailable at https://github.com/goodatlas/zeroth under CC-BY-4.0 license.\\nJunhoee/STT_Korean_Dataset_80000 Dataset, created by [Junhoee], 2024.\\nAvailable at https://huggingface.co/datasets/Junhoee/STT_Korean_Dataset_80000\\n"},
	{"name":"MMMLU","keyword":"korean","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/bzantium/MMMLU","creator_name":"Minho Ryu","creator_url":"https://huggingface.co/bzantium","description":"\\n\\t\\n\\t\\t\\n\\t\\tMultilingual Massive Multitask Language Understanding (MMMLU)\\n\\t\\n\\nThe MMLU is a widely recognized benchmark of general knowledge attained by AI models. It covers a broad range of topics from 57 different categories, covering elementary-level knowledge up to advanced professional subjects like law, physics, history, and computer science.\\nWe translated the MMLU’s test set into 14 languages using professional human translators. Relying on human translators for this evaluation increases… See the full description on the dataset page: https://huggingface.co/datasets/bzantium/MMMLU."},
	{"name":"FineFineWeb-Ko","keyword":"korean","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/jaeyong2/FineFineWeb-Ko","creator_name":"jeongjaeyong","creator_url":"https://huggingface.co/jaeyong2","description":"\\n\\t\\n\\t\\t\\n\\t\\tDevelopment Process\\n\\t\\n\\n\\nsource dataset from m-a-p/FineFineWeb-test\\nWe used Qwen/Qwen2-72B-Instruct model to translate.\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tLicense\\n\\t\\n\\n\\nQwen/Qwen2.5-72B-Instruct : https://huggingface.co/Qwen/Qwen2-72B-Instruct/blob/main/LICENSE\\nm-a-p/FineFineWeb-test : https://huggingface.co/datasets/choosealicense/licenses/blob/main/markdown/apache-2.0.md\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tAcknowledgement\\n\\t\\n\\nThis research is supported by TPU Research Cloud program.\\n"},
	{"name":"domeggook_faq","keyword":"korean","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/gng-taejin/domeggook_faq","creator_name":"taejin kim","creator_url":"https://huggingface.co/gng-taejin","description":"gng-taejin/domeggook_faq dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"BenchMAX_Rule-based","keyword":"korean","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/LLaMAX/BenchMAX_Rule-based","creator_name":"LLaMAX","creator_url":"https://huggingface.co/LLaMAX","description":"\\n\\t\\n\\t\\t\\n\\t\\tDataset Sources\\n\\t\\n\\n\\nPaper: BenchMAX: A Comprehensive Multilingual Evaluation Suite for Large Language Models\\nLink: https://arxiv.org/pdf/2502.07346\\nRepository: https://github.com/CONE-MT/BenchMAX\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\nBenchMAX_Rule-based is a dataset of BenchMAX, sourcing from IFEval, which is a rule-based benchmark for evaluating the instruction following capabilities.\\nWe extend the original dataset to 16 non-English languages by first translating and then manual… See the full description on the dataset page: https://huggingface.co/datasets/LLaMAX/BenchMAX_Rule-based."},
	{"name":"BenchMAX_Model-based","keyword":"korean","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/LLaMAX/BenchMAX_Model-based","creator_name":"LLaMAX","creator_url":"https://huggingface.co/LLaMAX","description":"\\n\\t\\n\\t\\t\\n\\t\\tDataset Sources\\n\\t\\n\\n\\nPaper: BenchMAX: A Comprehensive Multilingual Evaluation Suite for Large Language Models\\nLink: https://arxiv.org/pdf/2502.07346\\nRepository: https://github.com/CONE-MT/BenchMAX\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\nBenchMAX_Model-based is a dataset of BenchMAX, sourcing from m-ArenaHard.\\nWe extend the original English dataset to 16 non-English languages by first translating and then manual post-editing.\\n\\n\\t\\n\\t\\t\\n\\t\\tSupported Languages\\n\\t\\n\\nArabic, Bengali, Chinese, Czech… See the full description on the dataset page: https://huggingface.co/datasets/LLaMAX/BenchMAX_Model-based."},
	{"name":"BenchMAX_Multiple_Functions","keyword":"korean","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/LLaMAX/BenchMAX_Multiple_Functions","creator_name":"LLaMAX","creator_url":"https://huggingface.co/LLaMAX","description":"\\n\\t\\n\\t\\t\\n\\t\\tDataset Sources\\n\\t\\n\\n\\nPaper: BenchMAX: A Comprehensive Multilingual Evaluation Suite for Large Language Models\\nLink: https://arxiv.org/pdf/2502.07346\\nRepository: https://github.com/CONE-MT/BenchMAX\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\nBenchMAX_Multiple_Functions is a dataset of BenchMAX, sourcing from Nexus.\\nWe translate the standardized queries from English to 16 non-English languages by google Translate.\\nSome special function arguments remain English since the APIs are in English.\\nAll… See the full description on the dataset page: https://huggingface.co/datasets/LLaMAX/BenchMAX_Multiple_Functions."},
	{"name":"BenchMAX_General_Translation","keyword":"korean","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/LLaMAX/BenchMAX_General_Translation","creator_name":"LLaMAX","creator_url":"https://huggingface.co/LLaMAX","description":"\\n\\t\\n\\t\\t\\n\\t\\tDataset Sources\\n\\t\\n\\n\\nPaper: BenchMAX: A Comprehensive Multilingual Evaluation Suite for Large Language Models\\nLink: https://arxiv.org/pdf/2502.07346\\nRepository: https://github.com/CONE-MT/BenchMAX\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\nBenchMAX_General_Translation is a dataset of BenchMAX.\\nWe collect parallel test data from Flore-200, TED-talk, and WMT24.\\n\\n\\t\\n\\t\\t\\n\\t\\tSupported Languages\\n\\t\\n\\nArabic, Bengali, Chinese, Czech, English, French, German, Hungarian, Japanese, Korean, Serbian, Spanish… See the full description on the dataset page: https://huggingface.co/datasets/LLaMAX/BenchMAX_General_Translation."},
	{"name":"BenchMAX_Domain_Translation","keyword":"korean","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/LLaMAX/BenchMAX_Domain_Translation","creator_name":"LLaMAX","creator_url":"https://huggingface.co/LLaMAX","description":"\\n\\t\\n\\t\\t\\n\\t\\tDataset Sources\\n\\t\\n\\n\\nPaper: BenchMAX: A Comprehensive Multilingual Evaluation Suite for Large Language Models\\nLink: https://arxiv.org/pdf/2502.07346\\nRepository: https://github.com/CONE-MT/BenchMAX\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\nBenchMAX_Domain_Translation is a dataset of BenchMAX.\\nWe collect the domain parallel data from other tasks in BenchMAX.\\nEach sample contains one or three human-annotated translations.\\n\\n\\t\\n\\t\\t\\n\\t\\tSupported Languages\\n\\t\\n\\nArabic, Bengali, Chinese, Czech, English… See the full description on the dataset page: https://huggingface.co/datasets/LLaMAX/BenchMAX_Domain_Translation."},
	{"name":"medmcqa_ko_translated","keyword":"korean","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/koohack/medmcqa_ko_translated","creator_name":"SeungHyun Park","creator_url":"https://huggingface.co/koohack","description":"koohack/medmcqa_ko_translated dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"RAG-Evaluation-Dataset-KO","keyword":"korean","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/datalama/RAG-Evaluation-Dataset-KO","creator_name":"DongWook Kim","creator_url":"https://huggingface.co/datalama","description":"\\n\\t\\n\\t\\t\\n\\t\\tDataset Card for Reconstructed RAG Evaluation Dataset (KO)\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Summary\\n\\t\\n\\n본 데이터셋은 allganize/RAG-Evaluation-Dataset-KO를 기반으로 PDF 파일을 포함하도록 재구성한 한국어 평가 데이터셋입니다. 원본 데이터셋에서는 PDF 파일의 경로만 제공되어 수동으로 파일을 다운로드해야 하는 불편함이 있었고, 일부 PDF 파일의 경로가 유효하지 않은 문제를 보완하기 위해 PDF 파일을 포함한 데이터셋을 재구성하였습니다.\\n\\n\\t\\n\\t\\t\\n\\t\\tSupported Tasks and Leaderboards\\n\\t\\n\\n\\nRAG Evaluation: 본 데이터는 한국어 RAG 파이프라인에 대한 E2E Evaluation이 가능합니다.\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tLanguages\\n\\t\\n\\nThe dataset is in Korean (ko).\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Structure… See the full description on the dataset page: https://huggingface.co/datasets/datalama/RAG-Evaluation-Dataset-KO."},
	{"name":"triumvirat","keyword":"korean","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/trium-hj/triumvirat","creator_name":"Hyungji, Lee","creator_url":"https://huggingface.co/trium-hj","description":"trium-hj/triumvirat dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"V1Q","keyword":"korean","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/YuRiVeRTi/V1Q","creator_name":"YuRiVeRTical","creator_url":"https://huggingface.co/YuRiVeRTi","description":"from datasets import load_dataset\\nds = load_dataset(\\\"b3x0m/Chinese-H-Novels\\\")\\nimport sagemaker\\nimport boto3\\nfrom sagemaker.huggingface import HuggingFaceModel\\ntry:\\n    role = sagemaker.get_execution_role()\\nexcept ValueError:\\n    iam = boto3.client('iam')\\n    role = iam.get_role(RoleName='sagemaker_execution_role')['Role']['Arn']\\n\\n\\t\\n\\t\\t\\n\\t\\tHub Model configuration. https://huggingface.co/models\\n\\t\\n\\nhub = {\\n    'HF_MODEL_ID':'deepseek-ai/Janus-Pro-7B',\\n    'HF_TASK':'any-to-any'\\n}\\n\\n\\t\\n\\t\\t\\n\\t\\tcreate… See the full description on the dataset page: https://huggingface.co/datasets/YuRiVeRTi/V1Q."},
	{"name":"synthetic_financial_report_korean","keyword":"korean","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/nmixx-fin/synthetic_financial_report_korean","creator_name":"nmixx-financial-nlp-lab","creator_url":"https://huggingface.co/nmixx-fin","description":"nmixx-fin/synthetic_financial_report_korean dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"otpensource_dataset","keyword":"korean","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/hateslopacademy/otpensource_dataset","creator_name":"hateslop_academy","creator_url":"https://huggingface.co/hateslopacademy","description":"\\n\\t\\n\\t\\t\\n\\t\\tDataset Card for otpensource_dataset\\n\\t\\n\\nThis dataset contains curated information about fashion items, focusing on various categories, subcategories, genders, seasons, and unique features. It is intended for use in AI applications related to fashion recommendation systems, trend analysis, and image-to-text generation.\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Details\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThis dataset includes 8,998 examples of Korean Mushinsa fashion data, each with detailed attributes such as… See the full description on the dataset page: https://huggingface.co/datasets/hateslopacademy/otpensource_dataset."},
	{"name":"otpensource_dataset","keyword":"korean","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/hateslopacademy/otpensource_dataset","creator_name":"hateslop_academy","creator_url":"https://huggingface.co/hateslopacademy","description":"\\n\\t\\n\\t\\t\\n\\t\\tDataset Card for otpensource_dataset\\n\\t\\n\\nThis dataset contains curated information about fashion items, focusing on various categories, subcategories, genders, seasons, and unique features. It is intended for use in AI applications related to fashion recommendation systems, trend analysis, and image-to-text generation.\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Details\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThis dataset includes 8,998 examples of Korean Mushinsa fashion data, each with detailed attributes such as… See the full description on the dataset page: https://huggingface.co/datasets/hateslopacademy/otpensource_dataset."},
	{"name":"ko-o3-mini-high-aime-2022_4","keyword":"korean","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/CarrotAI/ko-o3-mini-high-aime-2022_4","creator_name":"CarrotCarrot","creator_url":"https://huggingface.co/CarrotAI","description":"openai의 o3-mini high 를 이용하여 생성하였습니다.\\n참고하시고 사용바랍니다.\\n"},
	{"name":"multilingual_translation_gen_binarized","keyword":"korean","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Youseff1987/multilingual_translation_gen_binarized","creator_name":"JOON HYOUNG JUN","creator_url":"https://huggingface.co/Youseff1987","description":"Youseff1987/multilingual_translation_gen_binarized dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"Judgement-De-Identification-Result","keyword":"korean","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ducut91/Judgement-De-Identification-Result","creator_name":"lim eul young","creator_url":"https://huggingface.co/ducut91","description":"법원 판결문 비식별 모델의 성능 결과입니다.\\n\\n\\t\\n\\t\\t\\n\\t\\tSOTA 급 LLM을 활용한 법원 판결문 개인정보 비식별 성능(Few-shot 성능)\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n모델\\n정확도\\n재현율\\nF1 점수\\n\\n\\n\\t\\t\\nGPT-4o(2024-08-06)\\n97.82\\n99.66\\n98.74\\n\\n\\nQwen2.5-Max\\n96.46\\n95.83\\n96.14\\n\\n\\nDeepSeek-V3\\n98.73\\n98.92\\n98.81\\n\\n\\nGemini-2.0-Flash\\n99.38\\n95.78\\n97.55\\n\\n\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\t7~8B급 sLLM의 파인튜닝 전후 법원 판결문 개인정보 비식별 성능\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n모델\\n파인튜닝 전\\n\\n\\n파인튜닝 후\\n\\n\\n\\n\\n\\t\\t\\n정확도\\n재현율\\nF1 점수\\n정확도\\n재현율\\nF1 점수\\n\\n\\n\\nEXAONE-3.5-7.8B-Instruct\\n68.26\\n67.89\\n68.08\\n98.59\\n94.4896.49\\n\\n\\nMinistral-8B-Instruct-2410\\n35.6\\n4.33\\n7.72\\n99.07\\n98.32\\n98.70… See the full description on the dataset page: https://huggingface.co/datasets/ducut91/Judgement-De-Identification-Result."},
	{"name":"system-rag-instruct-ko-sample","keyword":"korean","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/CarrotAI/system-rag-instruct-ko-sample","creator_name":"CarrotCarrot","creator_url":"https://huggingface.co/CarrotAI","description":"CarrotAI/system-rag-instruct-ko-sample dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"Emilia-YODAS","keyword":"korean","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mrfakename/Emilia-YODAS","creator_name":"mrfakename","creator_url":"https://huggingface.co/mrfakename","description":"A mirror of the Emilia-YODAS dataset. Only includes the YODAS subset from the original dataset.\\nhttps://huggingface.co/datasets/amphion/Emilia-Dataset\\n"},
	{"name":"aihub_llm_development_qa","keyword":"korean","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/AtwoM/aihub_llm_development_qa","creator_name":"AtwoM","creator_url":"https://huggingface.co/AtwoM","description":"This is the subset of the 한국어 성능이 개선된 초거대AI 언어모델 개발 및 데이터 dataset from AIHUB. \\nIt contains extracted SFT label data, formatted for supervised fine-tuning.\\n"},
	{"name":"HPLT2.0_cleaned","keyword":"korean","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/jobs-git/HPLT2.0_cleaned","creator_name":"James Guana","creator_url":"https://huggingface.co/jobs-git","description":"This is a large-scale collection of web-crawled documents in 191 world languages, produced by the HPLT project. \\nThe source of the data is mostly Internet Archive with some additions from Common Crawl.\\nFor a detailed description of the dataset, please refer to https://hplt-project.org/datasets/v2.0\\nThe Cleaned variant of HPLT Datasets v2.0\\nThis is the cleaned variant of the HPLT Datasets v2.0 converted to the Parquet format semi-automatically when being uploaded here. \\nThe original JSONL files… See the full description on the dataset page: https://huggingface.co/datasets/jobs-git/HPLT2.0_cleaned."},
	{"name":"DC_inside_comments","keyword":"korean","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Dasool/DC_inside_comments","creator_name":"DasolChoi","creator_url":"https://huggingface.co/Dasool","description":"\\n\\t\\n\\t\\t\\n\\t\\tDC_inside_comments\\n\\t\\n\\nThis dataset contains 110,000 raw comments collected from DC Inside. It is intended for unsupervised learning or pretraining purposes.\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Summary\\n\\t\\n\\n\\nData Type: Unlabeled raw comments\\nNumber of Examples: 110,000\\nSource: DC Inside\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tRelated Dataset\\n\\t\\n\\nFor labeled data and multi-task annotated examples, please refer to the KoMultiText dataset.\\n\\n\\t\\n\\t\\t\\n\\t\\tHow to Load the Dataset\\n\\t\\n\\nfrom datasets import load_dataset\\n\\n# Load the unlabeled dataset… See the full description on the dataset page: https://huggingface.co/datasets/Dasool/DC_inside_comments."},
	{"name":"clustering_klue_mrc_ynat_title","keyword":"korean","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/on-and-on/clustering_klue_mrc_ynat_title","creator_name":"khlee","creator_url":"https://huggingface.co/on-and-on","description":"This dataset is a processed and redistributed version of the KLUE dataset and follows the KLUE license.\\n(https://huggingface.co/datasets/klue/klue)\\nIt is a dataset for embedding evaluation, processed using the categories from the KLUE-mrc & KLUE-ynat dataset.\\n\\nTask: Clustering\\nNews_category: IT/Science, Sports, Media/Culture, Ecomomy/Finance, Real Estate\\n\\n========================================Original Citation===========================================\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tCitation Information… See the full description on the dataset page: https://huggingface.co/datasets/on-and-on/clustering_klue_mrc_ynat_title."},
	{"name":"H-colqwen","keyword":"korean","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/luke-kr/H-colqwen","creator_name":"YongHyun Kwon","creator_url":"https://huggingface.co/luke-kr","description":"luke-kr/H-colqwen dataset hosted on Hugging Face and contributed by the HF Datasets community"}
]
;
