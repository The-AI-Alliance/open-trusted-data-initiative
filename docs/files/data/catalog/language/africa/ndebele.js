const data_for_language_africa_ndebele = 
[
	{"name":"udhr-lid","keyword":"south ndebele","description":"\n\t\n\t\t\n\t\tUDHR-LID\n\t\n\nWhy UDHR-LID?\nYou can access UDHR (Universal Declaration of Human Rights) here, but when a verse is missing, they have texts such as \"missing\" or \"?\". Also, about 1/3 of the sentences consist only of \"articles 1-30\" in different languages. We cleaned the entire dataset from XML files and selected only the paragraphs. We cleared any unrelated language texts from the data and also removed the cases that were incorrect.\nIncorrect? Look at the ckb and kmr files in the UDHR.‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/cis-lmu/udhr-lid.","url":"https://huggingface.co/datasets/cis-lmu/udhr-lid","creator_name":"CIS, LMU Munich","creator_url":"https://huggingface.co/cis-lmu","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["multilingual","Tigrinya","Balkan Romani","Standard Arabic","Metlat√≥noc Mixtec"],"keywords_longer_than_N":true},
	{"name":"finepdfs","keyword":"south ndebele","description":"\n\nLiberating 3T of the finest tokens from PDFs\n\n\n\t\n\t\t\n\t\tWhat is this?\n\t\n\nAs we run out of web pages to process, the natural question has always been: what to do next? Only a few knew about a data source that everyone avoided for ages, due to its incredible extraction cost and complexity: PDFs.\nüìÑ FinePDFs is exactly that. It is the largest publicly available corpus sourced exclusively from PDFs, containing about 3 trillion tokens across 475 million documents in 1733 languages.\nCompared to HTML‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/HuggingFaceFW/finepdfs.","url":"https://huggingface.co/datasets/HuggingFaceFW/finepdfs","creator_name":"FineData","creator_url":"https://huggingface.co/HuggingFaceFW","license_name":"Open Data Commons Attribution License v1.0","license_url":"https://scancode-licensedb.aboutcode.org/odc-by-1.0.html","language":"en","first_N":5,"first_N_keywords":["text-generation","Arifama-Miniafia","Ankave","Abau","Amarasi"],"keywords_longer_than_N":true},
	{"name":"smol","keyword":"northern ndebele","description":"\n\t\n\t\t\n\t\tSMOL\n\t\n\nSMOL (Set for Maximal Overall Leverage) is a collection professional\ntranslations into 221 Low-Resource Languages, for the purpose of training\ntranslation models, and otherwise increasing the representations of said\nlanguages in NLP and technology.\nPlease read the SMOL Paper and the\nGATITOS Paper for a much more\nthorough description!\nThere are four resources in this directory:\n\nSmolDoc: document-level translations into 104 language pairs (103 unique languages)\nSmolSent:‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/google/smol.","url":"https://huggingface.co/datasets/google/smol","creator_name":"Google","creator_url":"https://huggingface.co/google","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["translation","Afar","Abkhaz","Achinese","Acoli"],"keywords_longer_than_N":true},
	{"name":"V1Q","keyword":"northern ndebele","description":"from datasets import load_dataset\nds = load_dataset(\"b3x0m/Chinese-H-Novels\")\nimport sagemaker\nimport boto3\nfrom sagemaker.huggingface import HuggingFaceModel\ntry:\n    role = sagemaker.get_execution_role()\nexcept ValueError:\n    iam = boto3.client('iam')\n    role = iam.get_role(RoleName='sagemaker_execution_role')['Role']['Arn']\n\n\t\n\t\t\n\t\tHub Model configuration. https://huggingface.co/models\n\t\n\nhub = {\n    'HF_MODEL_ID':'deepseek-ai/Janus-Pro-7B',\n    'HF_TASK':'any-to-any'\n}\n\n\t\n\t\t\n\t\tcreate‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/YuRiVeRTi/V1Q.","url":"https://huggingface.co/datasets/YuRiVeRTi/V1Q","creator_name":"YuRiVeRTical","creator_url":"https://huggingface.co/YuRiVeRTi","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","table-question-answering","question-answering","zero-shot-classification"],"keywords_longer_than_N":true},
	{"name":"lwazi-asr-corpus-compressed","keyword":"northern ndebele","description":"\n\t\n\t\t\n\t\tLwazi ASR Corpus Collection\n\t\n\nThis repository contains a curated collection of the Lwazi Automatic Speech Recognition (ASR) Corpus for several low-resourced South African languages. These datasets are designed for use in speech recognition research and development, particularly for underrepresented languages.\n\n\t\n\t\t\n\t\tCorpus Overview\n\t\n\nEach corpus consists of scripted telephonic speech recordings collected from native speakers, along with corresponding transcriptions. The audio‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/dsfsi/lwazi-asr-corpus-compressed.","url":"https://huggingface.co/datasets/dsfsi/lwazi-asr-corpus-compressed","creator_name":"Data Science for Social Impact","creator_url":"https://huggingface.co/dsfsi","license_name":"Creative Commons Attribution 3.0","license_url":"https://scancode-licensedb.aboutcode.org/cc-by-3.0.html","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","Tswana","Tsonga","Venda","Zulu"],"keywords_longer_than_N":true},
	{"name":"vukuzenzele-sentence-aligned","keyword":"south ndebele","description":"\n\t\n\t\t\n\t\tThe Vuk'uzenzele South African Multilingual Corpus\n\t\n\nGithub: https://github.com/dsfsi/vukuzenzele-nlp/\nZenodo: \nArxiv Preprint: \nGive Feedback üìë: DSFSI Resource Feedback Form\n\n\t\n\t\t\n\t\n\t\n\t\tAbout\n\t\n\nThe dataset was obtained from the South African government magazine Vuk'uzenzele, created by the Government Communication and Information System (GCIS). \nThe original raw PDFS were obtatined from the Vuk'uzenzele website.\nThe datasets contain government magazine editions in 11 languages‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/dsfsi/vukuzenzele-sentence-aligned.","url":"https://huggingface.co/datasets/dsfsi/vukuzenzele-sentence-aligned","creator_name":"Data Science for Social Impact","creator_url":"https://huggingface.co/dsfsi","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["sentence-similarity","translation","English","Afrikaans","South Ndebele"],"keywords_longer_than_N":true},
	{"name":"sa-languages","keyword":"south ndebele","description":"\n\t\n\t\t\n\t\tSouth African Languages Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Overview\n\t\n\n\n\t\n\t\t\nLanguage\nTraining Documents\nTraining GPT2 Tokens\nAvg Tokens/Doc\nMax Tokens\nTest Documents\nTest GPT2 Tokens\nTest Avg Tokens/Doc\nTest Max Tokens\n\n\n\t\t\nisiZulu\n116,693\n192,622,799\n1,650.68\n335,530\n687\n1,080,961\n1,573.45\n15,691\n\n\nSesotho\n83,329\n144,337,938\n1,732.15\n98,542\n841\n1,393,086\n1,656.4614,071\n\n\nisiXhosa\n99,567\n141,484,241\n1,421.00\n113,710\n788\n1,161,296\n1,473.73\n17,220\n\n\nisiNdebele\n21,922\n17,533,799\n799.83\n42,701‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/anrilombard/sa-languages.","url":"https://huggingface.co/datasets/anrilombard/sa-languages","creator_name":"Anri Lombard","creator_url":"https://huggingface.co/anrilombard","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","language-modeling","no-annotation","found","original"],"keywords_longer_than_N":true},
	{"name":"SouthAfricanLangClassification","keyword":"south ndebele","description":"\n  SouthAfricanLangClassification\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nA language identification test set for 11 South African Languages.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2c\n\n\nDomains\nWeb, Non-fiction, Written\n\n\nReference\nhttps://www.kaggle.com/competitions/south-african-language-identification/\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask =‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/SouthAfricanLangClassification.","url":"https://huggingface.co/datasets/mteb/SouthAfricanLangClassification","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","language-identification","expert-annotated","monolingual","mlexplorer008/south_african_language_identification"],"keywords_longer_than_N":true},
	{"name":"GlotCC-V1","keyword":"northern ndebele","description":"\n\t\n\t\t\n\t\tDataset Summary\n\t\n\n \n\nGlotCC-V1.0 is a document-level, general domain dataset derived from CommonCrawl, covering more than 1000 languages.It is built using the GlotLID language identification and Ungoliant pipeline from CommonCrawl.We release our pipeline as open-source at https://github.com/cisnlp/GlotCC.  \nList of Languages: See https://datasets-server.huggingface.co/splits?dataset=cis-lmu/GlotCC-V1 to get the list of splits available.\n\n\t\t\n\t\tUsage (Huggingface Hub -- Recommended)‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/cis-lmu/GlotCC-V1.","url":"https://huggingface.co/datasets/cis-lmu/GlotCC-V1","creator_name":"CIS, LMU Munich","creator_url":"https://huggingface.co/cis-lmu","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["multilingual","Abau","Amarasi","Abkhaz","Abkhazian"],"keywords_longer_than_N":true},
	{"name":"GlotCC-V1","keyword":"south ndebele","description":"\n\t\n\t\t\n\t\tDataset Summary\n\t\n\n \n\nGlotCC-V1.0 is a document-level, general domain dataset derived from CommonCrawl, covering more than 1000 languages.It is built using the GlotLID language identification and Ungoliant pipeline from CommonCrawl.We release our pipeline as open-source at https://github.com/cisnlp/GlotCC.  \nList of Languages: See https://datasets-server.huggingface.co/splits?dataset=cis-lmu/GlotCC-V1 to get the list of splits available.\n\n\t\t\n\t\tUsage (Huggingface Hub -- Recommended)‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/cis-lmu/GlotCC-V1.","url":"https://huggingface.co/datasets/cis-lmu/GlotCC-V1","creator_name":"CIS, LMU Munich","creator_url":"https://huggingface.co/cis-lmu","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["multilingual","Abau","Amarasi","Abkhaz","Abkhazian"],"keywords_longer_than_N":true},
	{"name":"lr-sum","keyword":"northern ndebele","description":"\n\t\n\t\t\n\t\tDataset Card for LR-Sum\n\t\n\nLR-Sum is a automatic summarization dataset of newswire text with a focus on less resourced languages with a cc-by 4.0 license.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nLR-Sum is a permissively-licensed dataset created with the goal of enabling further research in automatic summarization for less-resourced languages.\nLR-Sum contains human-written summaries for 39 languages, many of which are less-resourced. \nThe data is based on the‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/bltlab/lr-sum.","url":"https://huggingface.co/datasets/bltlab/lr-sum","creator_name":"Broadening Linguistic Technologies Lab (BLT Lab)","creator_url":"https://huggingface.co/bltlab","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["summarization","text-generation","found","found","multilingual"],"keywords_longer_than_N":true},
	{"name":"language_tags","keyword":"south ndebele","description":"\n\t\n\t\t\n\t\tDescription\n\t\n\nDataset listing 27,328 languages and dialects (also includes macrolanguage names).For each language, either the ISO 639 code, the Glottolog code or both are provided.\n\n\t\n\t\t\n\t\tColumns\n\t\n\n\nEnglish_Name: Language name in English (e.g. \"French\").\nNative_Name: If value is not 0, corresponds to the name of the language by native speakers (e.g. \"Fran√ßais\") which may have been found in Wikipedia's nativename field.\nGlottocode: The language tag in the Glottolog convention (e.g.‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/lbourdois/language_tags.","url":"https://huggingface.co/datasets/lbourdois/language_tags","creator_name":"Lo√Øck BOURDOIS","creator_url":"https://huggingface.co/lbourdois","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["Afade","Par√° Ar√°ra","Afar","Aka-Bea","Abon"],"keywords_longer_than_N":true},
	{"name":"gov-za-monolingual","keyword":"south ndebele","description":"\n\t\n\t\t\n\t\tThe South African Gov-ZA multilingual corpus\n\t\n\n\n\t\n\t\t\n\t\tAbout Dataset\n\t\n\nThe data set contains cabinet statements from the South African government, maintained by the Government Communication and Information System (GCIS). Data was scraped from the governments website:\nhttps://www.gov.za/cabinet-statements\nThe datasets contain government cabinet statements in 11 languages, namely:\n\n\t\n\t\t\nLanguage\nCode\nLanguage\nCode\n\n\n\t\t\nAfrikaans\n(af)\nSetswana\n(tn)\n\n\nEnglish\n(en)\nSepedi\n(nso)\n\n\nSesotho‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/dsfsi/gov-za-monolingual.","url":"https://huggingface.co/datasets/dsfsi/gov-za-monolingual","creator_name":"Data Science for Social Impact","creator_url":"https://huggingface.co/dsfsi","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["translation","English","Afrikaans","South Ndebele","Xhosa"],"keywords_longer_than_N":true},
	{"name":"sa-nguni-languages","keyword":"south ndebele","description":"\n\t\n\t\t\n\t\tSouth African Nguni Languages Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Overview\n\t\n\n\n\t\n\t\t\nLanguage\nTraining Documents\nTraining GPT2 Tokens\nAvg Tokens/Doc\nMax Tokens\nTest Documents\nTest GPT2 Tokens\nTest Avg Tokens/Doc\nTest Max Tokens\n\n\n\t\t\nisiZulu\n116,693\n192,622,799\n1,650.68\n335,530\n687\n1,080,961\n1,573.45\n15,691\n\n\nisiXhosa\n99,567\n141,484,241\n1,421.00\n113,710\n788\n1,161,296\n1,473.7317,220\n\n\nisiNdebele\n21,922\n17,533,799\n799.83\n42,701\n222\n170,111\n766.27\n6,615\n\n\nsiSwati\n1,668\n3,148,007\n1,887.29\n24,129\n17‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/anrilombard/sa-nguni-languages.","url":"https://huggingface.co/datasets/anrilombard/sa-nguni-languages","creator_name":"Anri Lombard","creator_url":"https://huggingface.co/anrilombard","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","language-modeling","no-annotation","found","original"],"keywords_longer_than_N":true},
	{"name":"mHumanEval-Benchmark","keyword":"northern ndebele","description":"\n\n\n\t\n\t\t\n\t\tüî∑ Accepted in NAACL Proceedings (2025) üî∑\n\t\n\n\n\n\n\n  \n    \n      \n        \n          \n        \n      \n      \n        \n          \n        \n      \n      \n        \n          \n        \n      \n    \n  \n\n\n\n\n\n  \n\n\t\n\t\n\t\n\t\tmHumanEval\n\t\n\nThe mHumanEval benchmark is curated based on prompts from the original HumanEval üìö [Chen et al., 2021]. It includes a total of 33,456 prompts for Python, and 836,400 in total - significantly expanding from the original 164. \n\n\n\t\n\t\t\n\t\tQuick Start\n\t\n\n  Detailed‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/md-nishat-008/mHumanEval-Benchmark.","url":"https://huggingface.co/datasets/md-nishat-008/mHumanEval-Benchmark","creator_name":"Nishat Raihan","creator_url":"https://huggingface.co/md-nishat-008","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["Afar","Abkhaz","Avestan","Afrikaans","Akan"],"keywords_longer_than_N":true},
	{"name":"vukuzenzele-monolingual","keyword":"south ndebele","description":"\n\t\n\t\t\n\t\tThe Vuk'uzenzele South African Multilingual Corpus\n\t\n\nGive Feedback üìë: DSFSI Resource Feedback Form\n\n\t\n\t\t\n\t\tAbout Dataset\n\t\n\nThe dataset was obtained from the South African government magazine Vuk'uzenzele, created by the Government Communication and Information System (GCIS). \nThe original raw PDFs were obtatined from the Vuk'uzenzele website.\nThe datasets contain government magazine editions in 11 languages, namely:\n\n\t\n\t\t\nLanguage\nCode\nLanguage\nCode\n\n\n\t\t\nEnglish\n(eng)\nSepedi\n(nso)‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/dsfsi/vukuzenzele-monolingual.","url":"https://huggingface.co/datasets/dsfsi/vukuzenzele-monolingual","creator_name":"Data Science for Social Impact","creator_url":"https://huggingface.co/dsfsi","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["translation","English","Afrikaans","South Ndebele","Xhosa"],"keywords_longer_than_N":true},
	{"name":"panlex","keyword":"south ndebele","description":"\n\t\n\t\t\n\t\tPanLex\n\t\n\nJanuary 1, 2024 version of PanLex Language Vocabulary with 24,650,274 rows covering 6,152 languages.\n\n\t\n\t\t\n\t\tColumns\n\t\n\n\nvocab: contains the text entry.  \n639-3: contains the ISO 639-3 languages tags to allow users to filter on the language(s) of their choice.\n639-3_english_name: the English language name associated to the code ISO 639-3. \nvar_code: contains a code to differentiate language variants. In practice, this is the code 639-3 + a number.  If 000, it corresponds to‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/lbourdois/panlex.","url":"https://huggingface.co/datasets/lbourdois/panlex","creator_name":"Lo√Øck BOURDOIS","creator_url":"https://huggingface.co/lbourdois","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["Ghotuo","Alumu-Tesu","Ari","Amal","Arb√´resh√´ Albanian"],"keywords_longer_than_N":true},
	{"name":"fineweb-2","keyword":"south ndebele","description":"\n\t\n\t\t\n\t\tü•Ç FineWeb2\n\t\n\n\n    \n\n\n\nA sparkling update with 1000s of languages\n\n\n\t\n\t\t\n\t\tWhat is it?\n\t\n\nThis is the second iteration of the popular üç∑ FineWeb dataset, bringing high quality pretraining data to over 1000 üó£Ô∏è languages.\nThe ü•Ç FineWeb2 dataset is fully reproducible, available under the permissive ODC-By 1.0 license and extensively validated through hundreds of ablation experiments.\nIn particular, on the set of 9 diverse languages we used to guide our processing decisions, ü•Ç FineWeb2‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/HuggingFaceFW/fineweb-2.","url":"https://huggingface.co/datasets/HuggingFaceFW/fineweb-2","creator_name":"FineData","creator_url":"https://huggingface.co/HuggingFaceFW","license_name":"Open Data Commons Attribution License v1.0","license_url":"https://scancode-licensedb.aboutcode.org/odc-by-1.0.html","language":"en","first_N":5,"first_N_keywords":["text-generation","Arifama-Miniafia","Ankave","Abau","Amarasi"],"keywords_longer_than_N":true}
]
;
