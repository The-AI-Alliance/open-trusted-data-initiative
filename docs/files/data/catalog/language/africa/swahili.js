const data_for_language_africa_swahili = 
[
	{"name":"panlex","keyword":"swahili (individual language)","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/lbourdois/panlex","creator_name":"Lo√Øck BOURDOIS","creator_url":"https://huggingface.co/lbourdois","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tPanLex\\n\\t\\n\\nJanuary 1, 2024 version of PanLex Language Vocabulary with 24,650,274 rows covering 6,152 languages.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tColumns\\n\\t\\n\\n\\nvocab: contains the text entry.  \\n639-3: contains the ISO 639-3 languages tags to allow users to filter on the language(s) of their choice.\\n639-3_english_name: the English language name associated to the code ISO 639-3. \\nvar_code: contains a code to differentiate language variants. In practice, this is the code 639-3 + a number.  If 000, it‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/lbourdois/panlex.","first_N":5,"first_N_keywords":["Ghotuo","Alumu-Tesu","Ari","Amal","Arb√´resh√´ Albanian"],"keywords_longer_than_N":true},
	{"name":"stata","keyword":"swahili","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/adenhaus/stata","creator_name":"Aden Haussmann","creator_url":"https://huggingface.co/adenhaus","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tBackground\\n\\t\\n\\nThis dataset contains human evaluations of whether outputs on the TaTA dataset are a) understandable and b) attributable to the source tables. See TaTA: A Multilingual Table-to-Text Dataset for African Languages for more details. \\nIt can be used to train a learned metric, called StATA, to evaluate model performance on the TaTA dataset.\\nThe original can be found here.\\n","first_N":5,"first_N_keywords":["table-to-text","yes","Arabic","English","French"],"keywords_longer_than_N":true},
	{"name":"ChatML-aya_dataset","keyword":"swahili (macrolanguage)","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Felladrin/ChatML-aya_dataset","creator_name":"Victor Nogueira","creator_url":"https://huggingface.co/Felladrin","description":"CohereForAI/aya_dataset in ChatML format, ready to use in HuggingFace TRL's SFT Trainer.\\nPython code used for conversion:\\nfrom datasets import load_dataset\\nfrom transformers import AutoTokenizer\\n\\ntokenizer = AutoTokenizer.from_pretrained(\\\"Felladrin/Llama-160M-Chat-v1\\\")\\n\\ndataset = load_dataset(\\\"CohereForAI/aya_dataset\\\", split=\\\"train\\\")\\n\\ndef format(columns):\\n    messages = [\\n        {\\n            \\\"role\\\": \\\"user\\\",\\n            \\\"content\\\": columns[\\\"inputs\\\"].strip(),\\n        },\\n        {‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Felladrin/ChatML-aya_dataset.","first_N":5,"first_N_keywords":["question-answering","text-generation","crowdsourced","expert-generated","crowdsourced"],"keywords_longer_than_N":true},
	{"name":"mewsli-x","keyword":"swahili","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/izhx/mewsli-x","creator_name":"Xin Zhang","creator_url":"https://huggingface.co/izhx","description":"I generated the dataset following mewsli-x.md#getting-started\\nand converted into different parts (see process.py):\\n\\nar/de/en/es/fa/ja/pl/ro/ta/tr/uk wikinews_mentions dev and test (from wikinews_mentions-dev/test.jsonl)\\ncandidate entities of 50 languages (from candidate_set_entities.jsonl)\\nEnglish wikipedia_pairs to fine-tune models (from wikipedia_pairs-dev/train.jsonl)\\n\\nRaw data files are in raw.tar.gz, which contains:\\n[...] 535M Feb 24 22:06 candidate_set_entities.jsonl\\n[...] 9.8M Feb 24‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/izhx/mewsli-x.","first_N":5,"first_N_keywords":["text-retrieval","entity-linking-retrieval","Afrikaans","Arabic","Azerbaijani"],"keywords_longer_than_N":true},
	{"name":"MultiQ","keyword":"swahili","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/caro-holt/MultiQ","creator_name":"Holtermann","creator_url":"https://huggingface.co/caro-holt","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for MultiQ\\n\\t\\n\\nThis is the dataset corresponding to the paper \\\"Evaluating the Elementary Multilingual Capabilities of Large Language Models with MultiQ\\\". \\nIt is a silver standard benchmark that can be used to evaluate the basic multilingual capabilities of LLMs. It contains 200 open ended questions automatically \\ntranslated into 137 typologically diverse languages. \\n\\nCurated by: Carolin Holtermann, Paul R√∂ttger, Timm Dill, Anne Lauscher\\nLanguage(s) (NLP): 137 diverse‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/caro-holt/MultiQ.","first_N":5,"first_N_keywords":["question-answering","Tagalog","Samoan","Macedonian","Gujarati"],"keywords_longer_than_N":true},
	{"name":"bhojpuri","keyword":"swahili (individual language)","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ankur02/bhojpuri","creator_name":"Ankur Verma","creator_url":"https://huggingface.co/ankur02","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tFLEURS\\n\\t\\n\\nFleurs is the speech version of the FLoRes machine translation benchmark. \\nWe use 2009 n-way parallel sentences from the FLoRes dev and devtest publicly available sets, in 102 languages. \\nTraining sets have around 10 hours of supervision. Speakers of the train sets are different than speakers from the dev/test sets. Multilingual fine-tuning is\\nused and ‚Äùunit error rate‚Äù (characters, signs) of all languages is averaged. Languages and results are also grouped into seven‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ankur02/bhojpuri.","first_N":5,"first_N_keywords":["automatic-speech-recognition","expert-generated","crowdsourced","machine-generated","crowdsourced"],"keywords_longer_than_N":true},
	{"name":"aya_african_alpaca","keyword":"swahili","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/vutuka/aya_african_alpaca","creator_name":"vutuka","creator_url":"https://huggingface.co/vutuka","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tAya African Alpaca Style Dataset\\n\\t\\n\\n\\n\\nThis dataset card aims to be a base template for new datasets. It has been generated using this raw template.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Details\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\n\\n\\n\\n\\nCurated by: [More Information Needed]\\nFunded by [optional]: [More Information Needed]\\nShared by [optional]: [More Information Needed]\\nLanguage(s) (NLP): [More Information Needed]\\nLicense: [More Information Needed]\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Sources [optional]‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/vutuka/aya_african_alpaca.","first_N":5,"first_N_keywords":["text-generation","Afrikaans","Swahili","French","English"],"keywords_longer_than_N":true},
	{"name":"panlex-meanings","keyword":"swahili (individual language)","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/cointegrated/panlex-meanings","creator_name":"David Dale","creator_url":"https://huggingface.co/cointegrated","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for panlex-meanings\\n\\t\\n\\nThis is a dataset of words in several thousand languages, extracted from https://panlex.org.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Details\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThis dataset has been extracted from https://panlex.org (the 20240301 database dump) and rearranged on the per-language basis.\\nEach language subset consists of expressions (words and phrases). \\nEach expression is associated with some meanings (if there is more than one meaning, they are in‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/cointegrated/panlex-meanings.","first_N":5,"first_N_keywords":["translation","Afar","Western Abnaki","Abkhazian","Abaza"],"keywords_longer_than_N":true},
	{"name":"NTREX","keyword":"swahili","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/davidstap/NTREX","creator_name":"David Stap","creator_url":"https://huggingface.co/davidstap","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nNTREX -- News Test References for MT Evaluation from English into a total of 128 target languages. See original GitHub repo for full details.\\nExample of loading:\\ndataset = load_dataset(\\\"davidstap/NTREX\\\", \\\"rus_Cyrl\\\", trust_remote_code=True)\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages\\n\\t\\n\\nThe following languages are available:\\n\\n\\t\\n\\t\\t\\nLanguage Code\\nLanguage Name\\n\\n\\n\\t\\t\\nafr_Latn\\nAfrikaans\\n\\n\\namh_Ethi\\nAmharic\\n\\n\\narb_Arab\\nArabic\\n\\n\\naze_Latn\\nAzerbaijani\\n\\n\\nbak_Cyrl\\nBashkir\\n\\n\\nbel_Cyrl\\nBelarusian‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/davidstap/NTREX.","first_N":5,"first_N_keywords":["translation","expert-generated","expert-generated","translation","Afrikaans"],"keywords_longer_than_N":true},
	{"name":"wikipediaSW","keyword":"swahili","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/LeroyDyer/wikipediaSW","creator_name":"leroy Samuel Dyer","creator_url":"https://huggingface.co/LeroyDyer","description":"LeroyDyer/wikipediaSW dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["Swahili","mit","10K - 100K","parquet","Text"],"keywords_longer_than_N":true},
	{"name":"afrimgsm","keyword":"swahili","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/masakhane/afrimgsm","creator_name":"Masakhane NLP","creator_url":"https://huggingface.co/masakhane","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for afrimgsm\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nAFRIMGSM is an evaluation dataset comprising translations of a subset of the GSM8k dataset into 16 African languages. \\nIt includes test sets across all 18 languages, maintaining an English and French subsets from the original GSM8k dataset. \\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages\\n\\t\\n\\nThere are 18 languages available :\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Structure\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Instances\\n\\t\\n\\nThe examples look like this for English:\\nfrom datasets import‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/masakhane/afrimgsm.","first_N":5,"first_N_keywords":["text2text-generation","natural-language-inference","multilingual","gsm8k","Amharic"],"keywords_longer_than_N":true},
	{"name":"afrixnli","keyword":"swahili","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/masakhane/afrixnli","creator_name":"Masakhane NLP","creator_url":"https://huggingface.co/masakhane","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for afrixnli\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nAFRIXNLI is an evaluation dataset comprising translations of a subset of the XNLI dataset into 16 African languages. \\nIt includes both validation and test sets across all 18 languages, maintaining the English and French subsets from the original XNLI dataset. \\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages\\n\\t\\n\\nThere are 18 languages available :\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Structure\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Instances\\n\\t\\n\\nThe examples look like this for English:‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/masakhane/afrixnli.","first_N":5,"first_N_keywords":["text-classification","natural-language-inference","multilingual","xnli","English"],"keywords_longer_than_N":true},
	{"name":"biblenlp-corpus-mmteb","keyword":"swahili (individual language)","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/davidstap/biblenlp-corpus-mmteb","creator_name":"David Stap","creator_url":"https://huggingface.co/davidstap","description":"This dataset pre-computes all English-centric directions from bible-nlp/biblenlp-corpus, and as a result loading is significantly faster.\\nLoading example:\\n>>> from datasets import load_dataset\\n>>> dataset = load_dataset(\\\"davidstap/biblenlp-corpus-mmteb\\\", \\\"eng-arb\\\", trust_remote_code=True)\\n>>> dataset\\nDatasetDict({\\n    train: Dataset({\\n        features: ['eng', 'arb'],\\n        num_rows: 28723\\n    })\\n    validation: Dataset({\\n        features: ['eng', 'arb'],\\n        num_rows: 1578\\n    })‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/davidstap/biblenlp-corpus-mmteb.","first_N":5,"first_N_keywords":["no-annotation","expert-generated","translation","multilingual","Arifama-Miniafia"],"keywords_longer_than_N":true},
	{"name":"african-ultrachat","keyword":"swahili","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/masakhane/african-ultrachat","creator_name":"Masakhane NLP","creator_url":"https://huggingface.co/masakhane","description":"masakhane/african-ultrachat dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["Amharic","Hausa","Igbo","Kinyarwanda","Southern Sotho"],"keywords_longer_than_N":true},
	{"name":"swim-ir-cross-lingual","keyword":"swahili","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/nthakur/swim-ir-cross-lingual","creator_name":"Nandan Thakur","creator_url":"https://huggingface.co/nthakur","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for SWIM-IR (Cross-lingual)\\n\\t\\n\\n\\n\\n\\nThis is the cross-lingual subset of the SWIM-IR dataset, where the query generated is in the target language and the passage is in English.\\nThe SWIM-IR dataset is available as CC-BY-SA 4.0. 18 languages (including English) are available in the cross-lingual dataset.\\nFor full details of the dataset, please read our upcoming NAACL 2024 paper and check out our website.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tWhat is SWIM-IR?\\n\\t\\n\\nSWIM-IR dataset is a synthetic‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/nthakur/swim-ir-cross-lingual.","first_N":5,"first_N_keywords":["text-retrieval","question-answering","machine-generated","multilingual","original"],"keywords_longer_than_N":true},
	{"name":"xsimplusplus","keyword":"swahili (individual language)","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/jaygala24/xsimplusplus","creator_name":"Jay Gala","creator_url":"https://huggingface.co/jaygala24","description":"xSIM++ is an extension of xSIM. In comparison to xSIM, this evaluates using target-side data with additional synthetic, hard-to-distinguish examples. You can find more details about it in the publication: xSIM++: An Improved Proxy to Bitext Mining Performance for Low-Resource Languages.\\n","first_N":5,"first_N_keywords":["derived","multilingual","Achinese","Mesopotamian Arabic","Ta'izzi-Adeni Arabic"],"keywords_longer_than_N":true},
	{"name":"biblenlp-corpus-mmteb","keyword":"swahili (individual language)","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/biblenlp-corpus-mmteb","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"This dataset pre-computes all English-centric directions from bible-nlp/biblenlp-corpus, and as a result loading is significantly faster.\\nLoading example:\\n>>> from datasets import load_dataset\\n>>> dataset = load_dataset(\\\"davidstap/biblenlp-corpus-mmteb\\\", \\\"eng-arb\\\", trust_remote_code=True)\\n>>> dataset\\nDatasetDict({\\n    train: Dataset({\\n        features: ['eng', 'arb'],\\n        num_rows: 28723\\n    })\\n    validation: Dataset({\\n        features: ['eng', 'arb'],\\n        num_rows: 1578\\n    })‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/biblenlp-corpus-mmteb.","first_N":5,"first_N_keywords":["no-annotation","expert-generated","translation","multilingual","Arifama-Miniafia"],"keywords_longer_than_N":true},
	{"name":"sib200","keyword":"swahili (individual language)","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/sib200","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for SIB-200\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nSIB-200 is the largest publicly available topic classification dataset based on Flores-200 covering 205 languages and dialects.\\nThe train/validation/test sets are available for all the 205 languages.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSupported Tasks and Leaderboards\\n\\t\\n\\n\\ntopic classification: categorize wikipedia sentences into topics e.g science/technology, sports or politics.\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages\\n\\t\\n\\nThere are 205 languages available :‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/sib200.","first_N":5,"first_N_keywords":["text-classification","topic-classification","found","expert-generated","multilingual"],"keywords_longer_than_N":true},
	{"name":"afrixnli-translate-test","keyword":"swahili","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/masakhane/afrixnli-translate-test","creator_name":"Masakhane NLP","creator_url":"https://huggingface.co/masakhane","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for afrixnli-translate-test\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nAFRIXNLI-TT is an evaluation dataset comprising translations of the AFRIXNLI dataset from 16 African languages and 1 high resource language into English using NLLB. \\nIt includes test sets across all 17 languages.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages\\n\\t\\n\\nThere are 17 languages available :\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Structure\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Instances\\n\\t\\n\\nThe examples look like this for English:\\nfrom datasets import load_dataset‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/masakhane/afrixnli-translate-test.","first_N":5,"first_N_keywords":["text-classification","natural-language-inference","monolingual","afrixnli","Amharic"],"keywords_longer_than_N":true},
	{"name":"afrimgsm-translate-test","keyword":"swahili","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/masakhane/afrimgsm-translate-test","creator_name":"Masakhane NLP","creator_url":"https://huggingface.co/masakhane","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for afrimgsm-translate-test\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nAFRIMGSM-TT is an evaluation dataset comprising translations of the GSM8k dataset from 16 African languages and 1 high resource language into English using NLLB. \\nIt includes test sets across all 17 languages. \\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages\\n\\t\\n\\nThere are 17 languages available :\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Structure\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Instances\\n\\t\\n\\nThe examples look like this for English:\\nfrom datasets import load_dataset‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/masakhane/afrimgsm-translate-test.","first_N":5,"first_N_keywords":["text-classification","natural-language-inference","monolingual","afrimgsm","Amharic"],"keywords_longer_than_N":true},
	{"name":"NTREX","keyword":"swahili","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/NTREX","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nNTREX -- News Test References for MT Evaluation from English into a total of 128 target languages. See original GitHub repo for full details.\\nExample of loading:\\ndataset = load_dataset(\\\"davidstap/NTREX\\\", \\\"rus_Cyrl\\\", trust_remote_code=True)\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages\\n\\t\\n\\nThe following languages are available:\\n\\n\\t\\n\\t\\t\\nLanguage Code\\nLanguage Name\\n\\n\\n\\t\\t\\nafr_Latn\\nAfrikaans\\n\\n\\namh_Ethi\\nAmharic\\n\\n\\narb_Arab\\nArabic\\n\\n\\naze_Latn\\nAzerbaijani\\n\\n\\nbak_Cyrl\\nBashkir\\n\\n\\nbel_Cyrl\\nBelarusian‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/NTREX.","first_N":5,"first_N_keywords":["translation","expert-generated","expert-generated","translation","Afrikaans"],"keywords_longer_than_N":true},
	{"name":"marvl","keyword":"swahili","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/floschne/marvl","creator_name":"Flo Schneider","creator_url":"https://huggingface.co/floschne","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tMaRVL\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tThis is a copy from the original repo: https://github.com/marvl-challenge/marvl-code\\n\\t\\n\\nIf you use this dataset, please cite the original authors:\\n@inproceedings{liu-etal-2021-visually,\\n    title = \\\"Visually Grounded Reasoning across Languages and Cultures\\\",\\n    author = \\\"Liu, Fangyu  and\\n      Bugliarello, Emanuele  and\\n      Ponti, Edoardo Maria  and\\n      Reddy, Siva  and\\n      Collier, Nigel  and\\n      Elliott, Desmond\\\",\\n    booktitle = \\\"Proceedings of the‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/floschne/marvl.","first_N":5,"first_N_keywords":["visual-question-answering","Indonesian","Swahili","Tamil","Turkish"],"keywords_longer_than_N":true},
	{"name":"ParaNames","keyword":"swahili","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/bltlab/ParaNames","creator_name":"Broadening Linguistic Technologies Lab (BLT Lab)","creator_url":"https://huggingface.co/bltlab","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Dataset Name\\n\\t\\n\\n\\n\\nThis dataset card aims to be a base template for new datasets. It has been generated using this raw template.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Details\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\n\\n\\n\\n\\n\\nCurated by: [More Information Needed]\\nFunded by [optional]: [More Information Needed]\\nShared by [optional]: [More Information Needed]\\nLanguage(s) (NLP): [More Information Needed]\\nLicense: [More Information Needed]\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Sources [optional]‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/bltlab/ParaNames.","first_N":5,"first_N_keywords":["token-classification","Nias","Kotava","Banjar","Angika"],"keywords_longer_than_N":true},
	{"name":"xm3600","keyword":"swahili","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/floschne/xm3600","creator_name":"Flo Schneider","creator_url":"https://huggingface.co/floschne","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tXM3600 - Crossmodal-3600\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tThis is a copy from https://google.github.io/crossmodal-3600/\\n\\t\\n\\nIf you use this dataset, please cite the original authors:\\n@inproceedings{ThapliyalCrossmodal2022,\\n  author = {Ashish Thapliyal and Jordi Pont-Tuset and Xi Chen and Radu Soricut},\\n  title = {{Crossmodal-3600: A Massively Multilingual Multimodal Evaluation Dataset}},\\n  booktitle = {EMNLP},\\n  year = {2022}\\n}\\n\\nIt also includes the image features as PIL Image and has a uniform and‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/floschne/xm3600.","first_N":5,"first_N_keywords":["image-to-text","Arabic","Bengali","Czech","Danish"],"keywords_longer_than_N":true},
	{"name":"xm3600_1k","keyword":"swahili","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/floschne/xm3600_1k","creator_name":"Flo Schneider","creator_url":"https://huggingface.co/floschne","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tXM3600 - Crossmodal-3600 - 1K Split\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tThis is a copy from https://google.github.io/crossmodal-3600/\\n\\t\\n\\nIf you use this dataset, please cite the original authors:\\n@inproceedings{ThapliyalCrossmodal2022,\\n  author = {Ashish Thapliyal and Jordi Pont-Tuset and Xi Chen and Radu Soricut},\\n  title = {{Crossmodal-3600: A Massively Multilingual Multimodal Evaluation Dataset}},\\n  booktitle = {EMNLP},\\n  year = {2022}\\n}\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tThis is a 1K split of XM3600!\\n\\t\\n\\nFor this, we‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/floschne/xm3600_1k.","first_N":5,"first_N_keywords":["image-to-text","Arabic","Bengali","Czech","Danish"],"keywords_longer_than_N":true},
	{"name":"swahili_sa","keyword":"swahili","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/DGurgurov/swahili_sa","creator_name":"Daniil Gurgurov","creator_url":"https://huggingface.co/DGurgurov","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSentiment Analysis Data for the Swahili Language\\n\\t\\n\\nDataset Description:\\nThis dataset contains a sentiment analysis dataset from Muhammad et al. (2023).\\nData Structure:\\nThe data was used for the project on improving word embeddings with graph knowledge for Low Resource Languages.\\nCitation:\\n@inproceedings{Muhammad2023AfriSentiAT,\\n  title={AfriSenti: A Twitter Sentiment Analysis Benchmark for African Languages},\\n  author={Shamsuddeen Hassan Muhammad and Idris Abdulmumin and Abinew‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/DGurgurov/swahili_sa.","first_N":5,"first_N_keywords":["text-classification","Swahili","mit","1K - 10K","csv"],"keywords_longer_than_N":true},
	{"name":"ARC_Challenge_SWH","keyword":"swahili","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Mollel/ARC_Challenge_SWH","creator_name":"Michael Mollel","creator_url":"https://huggingface.co/Mollel","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for ARC_Challenge_Swahili\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nARC_Challenge_Swahili is a Swahili translation of the original English ARC (AI2 Reasoning Challenge) dataset. This dataset evaluates the ability of AI systems to answer grade-school level multiple-choice science questions. The Swahili version was created using a combination of machine translation and human annotation to ensure high-quality and accurate translations.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tTranslation Methodology\\n\\t\\n\\nThe‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Mollel/ARC_Challenge_SWH.","first_N":5,"first_N_keywords":["Swahili","apache-2.0","1K - 10K","parquet","Text"],"keywords_longer_than_N":true},
	{"name":"bitext_sib200_miners","keyword":"swahili (individual language)","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/gentaiscool/bitext_sib200_miners","creator_name":"Genta Indra Winata","creator_url":"https://huggingface.co/gentaiscool","description":"gentaiscool/bitext_sib200_miners dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["multilingual","Achinese","Mesopotamian Arabic","Ta'izzi-Adeni Arabic","Tunisian Arabic"],"keywords_longer_than_N":true},
	{"name":"fleurs_clean","keyword":"swahili (individual language)","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Helloworld668/fleurs_clean","creator_name":"zhide Tang","creator_url":"https://huggingface.co/Helloworld668","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tFLEURS\\n\\t\\n\\nFleurs is the speech version of the FLoRes machine translation benchmark. \\nWe use 2009 n-way parallel sentences from the FLoRes dev and devtest publicly available sets, in 102 languages. \\nTraining sets have around 10 hours of supervision. Speakers of the train sets are different than speakers from the dev/test sets. Multilingual fine-tuning is\\nused and ‚Äùunit error rate‚Äù (characters, signs) of all languages is averaged. Languages and results are also grouped into seven‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Helloworld668/fleurs_clean.","first_N":5,"first_N_keywords":["automatic-speech-recognition","expert-generated","crowdsourced","machine-generated","crowdsourced"],"keywords_longer_than_N":true},
	{"name":"xP3x-Kongo","keyword":"swahili","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Svngoku/xP3x-Kongo","creator_name":"NIONGOLO Chrys F√©-Marty","creator_url":"https://huggingface.co/Svngoku","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for xP3x Kikongo Focus\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\n\\nxP3x (Crosslingual Public Pool of Prompts eXtended) is a collection of prompts & datasets across 277 languages & 16 NLP tasks. It contains all of xP3 + much more! It is used for training future contenders of mT0 & BLOOMZ at project Aya @C4AI üß°\\n\\n\\nCreation: The dataset can be recreated using instructions available here together with the file in this repository named xp3x_create.py. We provide this version to save‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Svngoku/xP3x-Kongo.","first_N":5,"first_N_keywords":["other","translation","expert-generated","crowdsourced","multilingual"],"keywords_longer_than_N":true},
	{"name":"xP3x-Kongo","keyword":"swahili (individual language)","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Svngoku/xP3x-Kongo","creator_name":"NIONGOLO Chrys F√©-Marty","creator_url":"https://huggingface.co/Svngoku","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for xP3x Kikongo Focus\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\n\\nxP3x (Crosslingual Public Pool of Prompts eXtended) is a collection of prompts & datasets across 277 languages & 16 NLP tasks. It contains all of xP3 + much more! It is used for training future contenders of mT0 & BLOOMZ at project Aya @C4AI üß°\\n\\n\\nCreation: The dataset can be recreated using instructions available here together with the file in this repository named xp3x_create.py. We provide this version to save‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Svngoku/xP3x-Kongo.","first_N":5,"first_N_keywords":["other","translation","expert-generated","crowdsourced","multilingual"],"keywords_longer_than_N":true},
	{"name":"SwahiliNewsClassification","keyword":"swahili","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Mollel/SwahiliNewsClassification","creator_name":"Michael Mollel","creator_url":"https://huggingface.co/Mollel","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Swahili News Classification Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nSwahili is spoken by 100-150 million people across East Africa. In Tanzania, for example, Swahili is one of two national languages (the other is English) and is the official language of instruction in all schools. News in Swahili is an integral part of Tanzania's media sphere.\\nNews contributes to education, technology, and a country's economic growth, and news in local languages plays an‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Mollel/SwahiliNewsClassification.","first_N":5,"first_N_keywords":["text-classification","Swahili","apache-2.0","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"Multilingual-Benchmark","keyword":"swahili","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/TaiMingLu/Multilingual-Benchmark","creator_name":"TaiMing","creator_url":"https://huggingface.co/TaiMingLu","description":"These are the GSM8K and ARC dataset translated by Google Translate. \\nBibTex\\n@misc{lu2024languagecountslearnunlearn,\\n      title={Every Language Counts: Learn and Unlearn in Multilingual LLMs}, \\n      author={Taiming Lu and Philipp Koehn},\\n      year={2024},\\n      eprint={2406.13748},\\n      archivePrefix={arXiv},\\n      primaryClass={cs.CL},\\n      url={https://arxiv.org/abs/2406.13748}, \\n}\\n\\n","first_N":5,"first_N_keywords":["zero-shot-classification","question-answering","translation","English","German"],"keywords_longer_than_N":true},
	{"name":"afrimgsm","keyword":"swahili","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/yuntian-deng/afrimgsm","creator_name":"Yuntian Deng","creator_url":"https://huggingface.co/yuntian-deng","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for afrimgsm\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nAFRIMGSM is an evaluation dataset comprising translations of a subset of the GSM8k dataset into 16 African languages. \\nIt includes test sets across all 18 languages, maintaining an English and French subsets from the original GSM8k dataset. \\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages\\n\\t\\n\\nThere are 18 languages available :\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Structure\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Instances\\n\\t\\n\\nThe examples look like this for English:\\nfrom datasets import‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/yuntian-deng/afrimgsm.","first_N":5,"first_N_keywords":["text2text-generation","natural-language-inference","multilingual","gsm8k","Amharic"],"keywords_longer_than_N":true},
	{"name":"KenSwQuAD","keyword":"swahili","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/lightblue/KenSwQuAD","creator_name":"Lightblue KK.","creator_url":"https://huggingface.co/lightblue","description":"This is a backup of the KenSwQuAD dataset available at https://dataverse.harvard.edu/dataset.xhtml?persistentId=doi:10.7910/DVN/OTL0LM\\nThis dataset was NOT made by Lightblue KK., but simply reuploaded for ease of downloading. The original data files require downloading each individual text file, so we re-uploaded it as a dataset.\\nIf you use this dataset, please give it the appropriate credit by citing:\\nWanjawa, Barack; Wanzare, Lilian D.A.; Indede, Florence; McOnyango, Owen; Muchemi, Lawrence;‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/lightblue/KenSwQuAD.","first_N":5,"first_N_keywords":["Swahili","cc-by-4.0","1K - 10K","parquet","Text"],"keywords_longer_than_N":true},
	{"name":"Sheng_sml","keyword":"swahili","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/EgesaWO/Sheng_sml","creator_name":"Wenslous Otema Egesa","creator_url":"https://huggingface.co/EgesaWO","description":"EgesaWO/Sheng_sml dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["translation","English","Swahili","apache-2.0","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"muri-it-language-split","keyword":"swahili (macrolanguage)","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/akoksal/muri-it-language-split","creator_name":"Abdullatif Koksal","creator_url":"https://huggingface.co/akoksal","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tMURI-IT: Multilingual Instruction Tuning Dataset for 200 Languages via Multilingual Reverse Instructions\\n\\t\\n\\nMURI-IT is a large-scale multilingual instruction tuning dataset containing 2.2 million instruction-output pairs across 200 languages. It is designed to address the challenges of instruction tuning in low-resource languages with Multilingual Reverse Instructions (MURI), which ensures that the output is human-written, high-quality, and authentic to the cultural and linguistic‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/akoksal/muri-it-language-split.","first_N":5,"first_N_keywords":["text2text-generation","text-generation","question-answering","summarization","Achinese"],"keywords_longer_than_N":true},
	{"name":"uhura-truthfulqa","keyword":"swahili","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/masakhane/uhura-truthfulqa","creator_name":"Masakhane NLP","creator_url":"https://huggingface.co/masakhane","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Uhura-TruthfulQA\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nTruthfulQA is a widely recognized safety benchmark designed to measure the truthfulness of language model outputs across 38 categories, including health, law, finance, and politics. The English version of the benchmark originates from TruthfulQA: Measuring How Models Mimic Human Falsehoods (Lin et al., 2022) and consists of 817 questions in both multiple-choice and generation formats, targeting common‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/masakhane/uhura-truthfulqa.","first_N":5,"first_N_keywords":["multiple-choice","question-answering","text-generation","multiple-choice-qa","multilingual"],"keywords_longer_than_N":true},
	{"name":"PangeaBench-xm100","keyword":"swahili","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/neulab/PangeaBench-xm100","creator_name":"NeuLab @ LTI/CMU","creator_url":"https://huggingface.co/neulab","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tXM100\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tThis is a copy from https://google.github.io/crossmodal-3600/\\n\\t\\n\\nIf you use this dataset, please cite the original authors:\\n@inproceedings{ThapliyalCrossmodal2022,\\n  author = {Ashish Thapliyal and Jordi Pont-Tuset and Xi Chen and Radu Soricut},\\n  title = {{Crossmodal-3600: A Massively Multilingual Multimodal Evaluation Dataset}},\\n  booktitle = {EMNLP},\\n  year = {2022}\\n}\\n\\n","first_N":5,"first_N_keywords":["image-to-text","Arabic","Bengali","Czech","Danish"],"keywords_longer_than_N":true},
	{"name":"kenyan-low-resource-language-data","keyword":"swahili","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/thinkKenya/kenyan-low-resource-language-data","creator_name":"Tech Innovators Network Kenya","creator_url":"https://huggingface.co/thinkKenya","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLow-Resource Language Data: Parallel Corpora for Kiswahili and Kidaw'ida, Kalenjin, and Dholuo\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDescription\\n\\t\\n\\nThis dataset consists of three parallel corpora:\\n\\nKidaw'ida (Dawida)-Kiswahili (dav_swa)\\nKalenjin-Kiswahili (kln_swa)\\nDholuo-Kiswahili (luo_swa)\\n\\nEach corpus contains approximately 30,000 sentence pairs. The dataset was created for use in training machine translation models, enabling translation from Kiswahili (the national language of Kenya) into indigenous‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/thinkKenya/kenyan-low-resource-language-data.","first_N":5,"first_N_keywords":["translation","Swahili","cc-by-4.0","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"ApolloMoEDataset","keyword":"swahili","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/FreedomIntelligence/ApolloMoEDataset","creator_name":"FreedomAI","creator_url":"https://huggingface.co/FreedomIntelligence","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDemocratizing Medical LLMs For Much More Languages\\n\\t\\n\\nCovering 12 Major Languages including English, Chinese, French, Hindi, Spanish, Arabic, Russian, Japanese, Korean, German, Italian, Portuguese and 38 Minor Languages So far.\\n\\n   üìÉ Paper ‚Ä¢ üåê Demo ‚Ä¢ ü§ó ApolloMoEDataset ‚Ä¢ ü§ó ApolloMoEBench  ‚Ä¢ ü§ó Models  ‚Ä¢üåê Apollo  ‚Ä¢ üåê ApolloMoE\\n\\n\\n\\n\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tüåà Update\\n\\t\\n\\n\\n[2024.10.15] ApolloMoE repo is publishedÔºÅüéâ\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages Coverage\\n\\t\\n\\n12 Major Languages and 38 Minor Languages‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/FreedomIntelligence/ApolloMoEDataset.","first_N":5,"first_N_keywords":["question-answering","Arabic","English","Chinese","Korean"],"keywords_longer_than_N":true},
	{"name":"ApolloMoEBench","keyword":"swahili","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/FreedomIntelligence/ApolloMoEBench","creator_name":"FreedomAI","creator_url":"https://huggingface.co/FreedomIntelligence","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDemocratizing Medical LLMs For Much More Languages\\n\\t\\n\\nCovering 12 Major Languages including English, Chinese, French, Hindi, Spanish, Arabic, Russian, Japanese, Korean, German, Italian, Portuguese and 38 Minor Languages So far.\\n\\n   üìÉ Paper ‚Ä¢ üåê Demo ‚Ä¢ ü§ó ApolloMoEDataset ‚Ä¢ ü§ó ApolloMoEBench  ‚Ä¢ ü§ó Models  ‚Ä¢üåê Apollo  ‚Ä¢ üåê ApolloMoE\\n\\n\\n\\n\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tüåà Update\\n\\t\\n\\n\\n[2024.10.15] ApolloMoE repo is publishedÔºÅüéâ\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages Coverage\\n\\t\\n\\n12 Major Languages and 38 Minor Languages‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/FreedomIntelligence/ApolloMoEBench.","first_N":5,"first_N_keywords":["question-answering","Arabic","English","Chinese","Korean"],"keywords_longer_than_N":true},
	{"name":"Chi-Metrics-2024","keyword":"swahili","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/CGIAR/Chi-Metrics-2024","creator_name":"CGIAR","creator_url":"https://huggingface.co/CGIAR","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tFarmer.Chat: User Interaction and Evaluation Dataset from Agricultural AI Advisory Services in Kenya (2023-2024)\\n\\t\\n\\nAbstractThis dataset comprises 2,300 anonymized user interaction records from Farmer.Chat, an AI-powered agricultural advisory platform deployed in Kenya between October 2023 and April 2024. The data captures diverse metrics including query types, response quality, user engagement patterns, and system performance across multiple agricultural value chains (dairy‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/CGIAR/Chi-Metrics-2024.","first_N":5,"first_N_keywords":["question-answering","English","Swahili","apache-2.0","1K<n<10K"],"keywords_longer_than_N":true},
	{"name":"SwahiliMultimodalSarcasm","keyword":"swahili","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/EKariba/SwahiliMultimodalSarcasm","creator_name":"Eugene kariba","creator_url":"https://huggingface.co/EKariba","description":"\\n\\t\\n\\t\\t\\n\\t\\tDataset Card for Dataset Name\\n\\t\\n\\n\\n\\nThis dataset is a Swahili multimodal, text and image dataset intended for Sarcasm NLP. \\nThis is a link to the github page: https://github.com/ekariba/SyntheticDataset/blob/main/Dataset_generation.ipynb\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Details\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\n\\n\\n\\n\\nCurated by: Eugene Kariba\\nLanguage(s) (NLP): Swahili\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tUses\\n\\t\\n\\nMultimodal Swahili Sarcasm for environmental themes\\n\\n\\t\\n\\t\\t\\n\\t\\tDirect Use\\n\\t\\n\\nTo be used for Multimodal Sarcasm analysis in‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/EKariba/SwahiliMultimodalSarcasm.","first_N":5,"first_N_keywords":["Swahili","apache-2.0","1K - 10K","imagefolder","Image"],"keywords_longer_than_N":true},
	{"name":"SwahiliMultimodalSarcasm","keyword":"swahili","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/EKariba/SwahiliMultimodalSarcasm","creator_name":"Eugene kariba","creator_url":"https://huggingface.co/EKariba","description":"\\n\\t\\n\\t\\t\\n\\t\\tDataset Card for Dataset Name\\n\\t\\n\\n\\n\\nThis dataset is a Swahili multimodal, text and image dataset intended for Sarcasm NLP. \\nThis is a link to the github page: https://github.com/ekariba/SyntheticDataset/blob/main/Dataset_generation.ipynb\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Details\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\n\\n\\n\\n\\nCurated by: Eugene Kariba\\nLanguage(s) (NLP): Swahili\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tUses\\n\\t\\n\\nMultimodal Swahili Sarcasm for environmental themes\\n\\n\\t\\n\\t\\t\\n\\t\\tDirect Use\\n\\t\\n\\nTo be used for Multimodal Sarcasm analysis in‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/EKariba/SwahiliMultimodalSarcasm.","first_N":5,"first_N_keywords":["Swahili","apache-2.0","1K - 10K","imagefolder","Image"],"keywords_longer_than_N":true},
	{"name":"clean_lelapa_pretrain","keyword":"swahili","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/sartifyllc/clean_lelapa_pretrain","creator_name":"Sartify LLC","creator_url":"https://huggingface.co/sartifyllc","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for sartifyllc/clean_lelapa_pretrain\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThis is a Swahili dataset for CPT from Lelapa.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Usage\\n\\t\\n\\nThis dataset can be used for [describe potential uses].\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Structure\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tFeatures:\\n\\t\\n\\n\\ntext: Number of rows 1424937\\ntoken: Number of token so far 0.681822211B\\ntoken per row: Number of token so far per row 478.49288143967067\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Creation\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSource Data\\n\\t\\n\\n\\nHomepage:‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/sartifyllc/clean_lelapa_pretrain.","first_N":5,"first_N_keywords":["Swahili","mit","1M - 10M","parquet","Tabular"],"keywords_longer_than_N":true},
	{"name":"clean_lelapa_pretrain","keyword":"swahili","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/sartifyllc/clean_lelapa_pretrain","creator_name":"Sartify LLC","creator_url":"https://huggingface.co/sartifyllc","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for sartifyllc/clean_lelapa_pretrain\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThis is a Swahili dataset for CPT from Lelapa.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Usage\\n\\t\\n\\nThis dataset can be used for [describe potential uses].\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Structure\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tFeatures:\\n\\t\\n\\n\\ntext: Number of rows 1424937\\ntoken: Number of token so far 0.681822211B\\ntoken per row: Number of token so far per row 478.49288143967067\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Creation\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSource Data\\n\\t\\n\\n\\nHomepage:‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/sartifyllc/clean_lelapa_pretrain.","first_N":5,"first_N_keywords":["Swahili","mit","1M - 10M","parquet","Tabular"],"keywords_longer_than_N":true},
	{"name":"clean_lelapa_pretrain_ln","keyword":"swahili","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/sartifyllc/clean_lelapa_pretrain_ln","creator_name":"Sartify LLC","creator_url":"https://huggingface.co/sartifyllc","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for sartifyllc/clean_lelapa_pretrain_ln\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThis is a Swahili dataset for CPT from Lelapa.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Usage\\n\\t\\n\\nThis dataset can be used for [describe potential uses].\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Structure\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tFeatures:\\n\\t\\n\\n\\ntext: Number of rows 1424937\\ntoken: Number of token so far 0.681822211B\\ntoken per row: Number of token so far per row 478.49288143967067\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Creation\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSource Data‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/sartifyllc/clean_lelapa_pretrain_ln.","first_N":5,"first_N_keywords":["Swahili","mit","1M - 10M","parquet","Tabular"],"keywords_longer_than_N":true},
	{"name":"clean_lelapa_pretrain_ln","keyword":"swahili","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/sartifyllc/clean_lelapa_pretrain_ln","creator_name":"Sartify LLC","creator_url":"https://huggingface.co/sartifyllc","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for sartifyllc/clean_lelapa_pretrain_ln\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThis is a Swahili dataset for CPT from Lelapa.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Usage\\n\\t\\n\\nThis dataset can be used for [describe potential uses].\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Structure\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tFeatures:\\n\\t\\n\\n\\ntext: Number of rows 1424937\\ntoken: Number of token so far 0.681822211B\\ntoken per row: Number of token so far per row 478.49288143967067\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Creation\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSource Data‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/sartifyllc/clean_lelapa_pretrain_ln.","first_N":5,"first_N_keywords":["Swahili","mit","1M - 10M","parquet","Tabular"],"keywords_longer_than_N":true},
	{"name":"uhura-arc-easy","keyword":"swahili","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/masakhane/uhura-arc-easy","creator_name":"Masakhane NLP","creator_url":"https://huggingface.co/masakhane","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Uhura-Arc-Easy\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nUhura-ARC-Easy is a widely recognized scientific question answering benchmark composed of multiple-choice science questions derived from grade-school examinations that test various styles of knowledge and reasoning. \\nThe original English version of the benchmark originates from Think you have Solved Question Answering? Try ARC, the AI2 Reasoning Challenge (Clark et al., 2018) and is divided into \\\"Challenge\\\" and‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/masakhane/uhura-arc-easy.","first_N":5,"first_N_keywords":["multiple-choice","question-answering","multiple-choice-qa","multilingual","Amharic"],"keywords_longer_than_N":true},
	{"name":"semeval-2025-task11-track-a","keyword":"swahili","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/vgaraujov/semeval-2025-task11-track-a","creator_name":"Vladimir Araujo","creator_url":"https://huggingface.co/vgaraujov","description":"\\n\\t\\n\\t\\t\\n\\t\\tSemEval 2025 Task 11 - Track A Dataset\\n\\t\\n\\nThis dataset contains the data for SemEval 2025 Task 11: Bridging the Gap in Text-Based Emotion Detection - Track A, organized as language-specific configurations.\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThe dataset is a multi-language, multi-label emotion classification dataset with separate configurations for each language.\\n\\nTotal languages: 26 standard ISO codes\\nTotal examples: 115159\\nSplits: train, dev, test\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tLanguage Configurations\\n\\t\\n\\nEach‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/vgaraujov/semeval-2025-task11-track-a.","first_N":5,"first_N_keywords":["Afrikaans","Amharic","Arabic","German","English"],"keywords_longer_than_N":true},
	{"name":"semeval-2025-task11-track-c","keyword":"swahili","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/vgaraujov/semeval-2025-task11-track-c","creator_name":"Vladimir Araujo","creator_url":"https://huggingface.co/vgaraujov","description":"\\n\\t\\n\\t\\t\\n\\t\\tSemEval 2025 Task 11 - Track C Dataset\\n\\t\\n\\nThis dataset contains the data for SemEval 2025 Task 11: Bridging the Gap in Text-Based Emotion Detection - Track C, organized as language-specific configurations.\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThe dataset is a multi-language, multi-label emotion classification dataset with separate configurations for each language.\\n\\nTotal languages: 30 standard ISO codes\\nTotal examples: 57254\\nSplits: dev, test (Track C has no train split)\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tTrack‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/vgaraujov/semeval-2025-task11-track-c.","first_N":5,"first_N_keywords":["Afrikaans","Amharic","Arabic","German","English"],"keywords_longer_than_N":true},
	{"name":"kurage_training_data","keyword":"swahili","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/lightblue/kurage_training_data","creator_name":"Lightblue KK.","creator_url":"https://huggingface.co/lightblue","description":"lightblue/kurage_training_data dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["Arabic","English","Spanish","Hindi","Indonesian"],"keywords_longer_than_N":true},
	{"name":"PangeaBench-tydiqa","keyword":"swahili","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/neulab/PangeaBench-tydiqa","creator_name":"NeuLab @ LTI/CMU","creator_url":"https://huggingface.co/neulab","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for \\\"tydiqa\\\"\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nTyDi QA is a question answering dataset covering 11 typologically diverse languages with 204K question-answer pairs.\\nThe languages of TyDi QA are diverse with regard to their typology -- the set of linguistic features that each language\\nexpresses -- such that we expect models performing well on this set to generalize across a large number of the languages\\nin the world. It contains language phenomena that would not be found‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/neulab/PangeaBench-tydiqa.","first_N":5,"first_N_keywords":["question-answering","extractive-qa","crowdsourced","crowdsourced","multilingual"],"keywords_longer_than_N":true},
	{"name":"mc-translation","keyword":"swahili","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/efederici/mc-translation","creator_name":"Edoardo Federici","creator_url":"https://huggingface.co/efederici","description":"This dataset contains professional human translations from OpenAI's MMMLU dataset, repurposed to train translation models that can help translate future evaluation datasets.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tWhy This Dataset?\\n\\t\\n\\nTranslation of evaluation benchmarks is a critical but challenging task. While automated translations may introduce errors or biases, professional human translations are expensive and time-consuming. This dataset leverages existing professional translations (MMMLU) to train specialized‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/efederici/mc-translation.","first_N":5,"first_N_keywords":["translation","English","Swahili","Spanish","German"],"keywords_longer_than_N":true},
	{"name":"clean_loal_pretrain","keyword":"swahili","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/sartifyllc/clean_loal_pretrain","creator_name":"Sartify LLC","creator_url":"https://huggingface.co/sartifyllc","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for sartifyllc/clean_loal_pretrain\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThis is a Swahili dataset for CPT.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Usage\\n\\t\\n\\nThis dataset can be used for [describe potential uses].\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Structure\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tFeatures:\\n\\t\\n\\n\\ntext: Number of rows 3017\\ntoken: Number of token so far 0.003997569B\\ntoken per row: Number of token so far per row 1325.0145840238647\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Creation\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSource Data\\n\\t\\n\\n\\nHomepage:‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/sartifyllc/clean_loal_pretrain.","first_N":5,"first_N_keywords":["Swahili","mit","1K - 10K","parquet","Tabular"],"keywords_longer_than_N":true},
	{"name":"clean_loal_pretrain","keyword":"swahili","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/sartifyllc/clean_loal_pretrain","creator_name":"Sartify LLC","creator_url":"https://huggingface.co/sartifyllc","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for sartifyllc/clean_loal_pretrain\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThis is a Swahili dataset for CPT.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Usage\\n\\t\\n\\nThis dataset can be used for [describe potential uses].\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Structure\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tFeatures:\\n\\t\\n\\n\\ntext: Number of rows 3017\\ntoken: Number of token so far 0.003997569B\\ntoken per row: Number of token so far per row 1325.0145840238647\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Creation\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSource Data\\n\\t\\n\\n\\nHomepage:‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/sartifyllc/clean_loal_pretrain.","first_N":5,"first_N_keywords":["Swahili","mit","1K - 10K","parquet","Tabular"],"keywords_longer_than_N":true},
	{"name":"test_4","keyword":"swahili (individual language)","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/tunngo/test_4","creator_name":"nguyen tuan","creator_url":"https://huggingface.co/tunngo","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tFLEURS\\n\\t\\n\\nFleurs is the speech version of the FLoRes machine translation benchmark. \\nWe use 2009 n-way parallel sentences from the FLoRes dev and devtest publicly available sets, in 102 languages. \\nTraining sets have around 10 hours of supervision. Speakers of the train sets are different than speakers from the dev/test sets. Multilingual fine-tuning is\\nused and ‚Äùunit error rate‚Äù (characters, signs) of all languages is averaged. Languages and results are also grouped into seven‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/tunngo/test_4.","first_N":5,"first_N_keywords":["automatic-speech-recognition","expert-generated","crowdsourced","machine-generated","crowdsourced"],"keywords_longer_than_N":true},
	{"name":"Eng2sheng","keyword":"swahili","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/EgesaWO/Eng2sheng","creator_name":"Wenslous Otema Egesa","creator_url":"https://huggingface.co/EgesaWO","description":"EgesaWO/Eng2sheng dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["translation","English","Swahili","apache-2.0","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"swahili-mmmlu","keyword":"swahili","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Svngoku/swahili-mmmlu","creator_name":"NIONGOLO Chrys F√©-Marty","creator_url":"https://huggingface.co/Svngoku","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSwahili MMMLU Dataset\\n\\t\\n\\nThis dataset is a Swahili version of the Massive Multitask Language Understanding (MMLU) dataset. It is a multiple-choice question answering dataset that covers a wide range of topics and subjects, designed to evaluate the language understanding capabilities of models in Swahili.\\nDataset Structure:\\nThe dataset is structured as follows:\\n\\nquestion: The question posed in Swahili.\\noptions: A dictionary containing the multiple choice options, labeled A, B, C‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Svngoku/swahili-mmmlu.","first_N":5,"first_N_keywords":["Swahili","mit","10K - 100K","parquet","Text"],"keywords_longer_than_N":true},
	{"name":"xtreme-up-semantic-parsing","keyword":"swahili","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Davlan/xtreme-up-semantic-parsing","creator_name":"David Adelani","creator_url":"https://huggingface.co/Davlan","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for afrixnli\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nSee XTREME-UP GitHub\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages\\n\\t\\n\\nThere are 20 languages available :\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Structure\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Instances\\n\\t\\n\\nThe examples look like this for English:\\nfrom datasets import load_dataset\\ndata = load_dataset('Davlan/xtreme-up-semantic-parsing', 'yor') \\n# Please, specify the language code\\n# A data point example is below:\\n{\\n\\\"id\\\": \\\"3231323330393336\\\",\\n\\\"split\\\": \\\"test\\\",\\n\\\"intent\\\": \\\"IN:GET_REMINDER\\\"‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Davlan/xtreme-up-semantic-parsing.","first_N":5,"first_N_keywords":["text-classification","multilingual","Amharic","Belarusian","Bengali"],"keywords_longer_than_N":true},
	{"name":"BenchMAX_Question_Answering","keyword":"swahili","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/LLaMAX/BenchMAX_Question_Answering","creator_name":"LLaMAX","creator_url":"https://huggingface.co/LLaMAX","description":"\\n\\t\\n\\t\\t\\n\\t\\tDataset Sources\\n\\t\\n\\n\\nPaper: BenchMAX: A Comprehensive Multilingual Evaluation Suite for Large Language Models\\nLink: https://arxiv.org/pdf/2502.07346\\nRepository: https://github.com/CONE-MT/BenchMAX\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\nBenchMAX_Function_Completion is a dataset of BenchMAX, sourcing from UN Parallel Corpus and xquad.\\nThe haystacks are from UN Parallel Corpus Test and Development Sets and we translate them to other languages by Google Translate.\\nThe multilingual QA data is from‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/LLaMAX/BenchMAX_Question_Answering.","first_N":5,"first_N_keywords":["text-generation","multilingual","English","Chinese","Spanish"],"keywords_longer_than_N":true},
	{"name":"M-ABSA","keyword":"swahili","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Multilingual-NLP/M-ABSA","creator_name":"multilingual-NLP","creator_url":"https://huggingface.co/Multilingual-NLP","description":"\\n\\t\\n\\t\\t\\n\\t\\tM-ABSA\\n\\t\\n\\nThis repo contains the data for our paper M-ABSA: A Multilingual Dataset for Aspect-Based Sentiment Analysis.\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tData Description:\\n\\t\\n\\nThis is a dataset suitable for the multilingual ABSA task with triplet extraction.\\nAll datasets are stored in the data/ folder:\\n\\nAll dataset contains 7 domains.\\n\\ndomains = [\\\"coursera\\\", \\\"hotel\\\", \\\"laptop\\\", \\\"restaurant\\\", \\\"phone\\\", \\\"sight\\\", \\\"food\\\"]\\n\\n\\nEach dataset contains 21 languages.\\n\\nlangs = [\\\"ar\\\", \\\"da\\\", \\\"de\\\", \\\"en\\\", \\\"es\\\", \\\"fr\\\", \\\"hi\\\", \\\"hr\\\"‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Multilingual-NLP/M-ABSA.","first_N":5,"first_N_keywords":["token-classification","text-classification","Arabic","Danish","German"],"keywords_longer_than_N":true},
	{"name":"mmmlu_lite","keyword":"swahili","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/opencompass/mmmlu_lite","creator_name":"OpenCompass","creator_url":"https://huggingface.co/opencompass","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tMMMLU-Lite\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tIntroduction\\n\\t\\n\\nA lite version of the MMMLU dataset, which is an community version of the MMMLU dataset by OpenCompass. Due to the large size of the original dataset (about 200k questions), we have created a lite version of the dataset to make it easier to use. We sample 25 examples from each language subject in the original dataset with fixed seed to ensure reproducibility, finally we have 19950 examples in the lite version of the dataset, which is about‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/opencompass/mmmlu_lite.","first_N":5,"first_N_keywords":["question-answering","Arabic","Bengali","German","Spanish"],"keywords_longer_than_N":true},
	{"name":"Multilingal-sakalt-data","keyword":"swahili (individual language)","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Sakalti/Multilingal-sakalt-data","creator_name":"sakasan","creator_url":"https://huggingface.co/Sakalti","description":"„Éû„É´„ÉÅ„É™„É≥„Ç¨„É´„Éá„Éº„Çø„Çª„ÉÉ„Éà„Åß„Åô„ÄÇmit„É©„Ç§„Çª„É≥„Çπ„Åß„Åô„ÄÇ\\n","first_N":5,"first_N_keywords":["text-generation","Abkhaz","Bhojpuri","Chechen","Czech"],"keywords_longer_than_N":true},
	{"name":"Global-MMLU","keyword":"swahili","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/CohereForAI/Global-MMLU","creator_name":"Cohere For AI","creator_url":"https://huggingface.co/CohereForAI","description":"\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nGlobal-MMLU üåç is a multilingual evaluation set spanning 42 languages, including English. This dataset combines machine translations for MMLU questions along with professional translations and crowd-sourced post-edits.\\nIt also includes cultural sensitivity annotations for a subset of the questions (2850 questions per language) and classifies them as Culturally Sensitive (CS) üóΩ or Culturally Agnostic (CA) ‚öñÔ∏è. These annotations were collected as part of an open‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/CohereForAI/Global-MMLU.","first_N":5,"first_N_keywords":["English","Arabic","Bengali","Spanish","French"],"keywords_longer_than_N":true},
	{"name":"reasoning-multilingual-R1-Llama-70B-train","keyword":"swahili","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/lightblue/reasoning-multilingual-R1-Llama-70B-train","creator_name":"Lightblue KK.","creator_url":"https://huggingface.co/lightblue","description":"\\n\\t\\n\\t\\t\\n\\t\\tlightblue/reasoning-multilingual-R1-Llama-70B-train\\n\\t\\n\\nThis is a multilingual reasoning dataset covering more than 30 languages.\\nThis dataset was made by:\\n\\nSampling prompts from English datasets and translating them to various languages\\nGenerating responses to these prompts 8 times using deepseek-ai/DeepSeek-R1-Distill-Llama-70B\\nFiltering out <think> sections with incorrect language, non-fluent language, and incorrect answers\\n\\nThis dataset was then used to train a multilingual‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/lightblue/reasoning-multilingual-R1-Llama-70B-train.","first_N":5,"first_N_keywords":["Amharic","Arabic","Bengali","Chinese","Czech"],"keywords_longer_than_N":true},
	{"name":"wmt24pp","keyword":"swahili","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/google/wmt24pp","creator_name":"Google","creator_url":"https://huggingface.co/google","description":"\\n\\t\\n\\t\\t\\n\\t\\tWMT24++\\n\\t\\n\\nThis repository contains the human translation and post-edit data for the 55 en->xx language pairs released in\\nthe publication\\nWMT24++: Expanding the Language Coverage of WMT24 to 55 Languages & Dialects.\\nIf you are interested in the MT/LLM system outputs and automatic metric scores, please see MTME.\\nIf you are interested in the images of the source URLs for each document, please see here.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSchema\\n\\t\\n\\nEach language pair is stored in its own jsonl file.\\nEach row is‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/google/wmt24pp.","first_N":5,"first_N_keywords":["translation","Arabic","Bulgarian","Bengali","Catalan"],"keywords_longer_than_N":true},
	{"name":"xtreme","keyword":"swahili","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/google/xtreme","creator_name":"Google","creator_url":"https://huggingface.co/google","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for \\\"xtreme\\\"\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThe Cross-lingual Natural Language Inference (XNLI) corpus is a crowd-sourced collection of 5,000 test and\\n2,500 dev pairs for the MultiNLI corpus. The pairs are annotated with textual entailment and translated into\\n14 languages: French, Spanish, German, Greek, Bulgarian, Russian, Turkish, Arabic, Vietnamese, Thai, Chinese,\\nHindi, Swahili and Urdu. This results in 112.5k annotated pairs. Each premise can be associated with‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/google/xtreme.","first_N":5,"first_N_keywords":["multiple-choice","question-answering","token-classification","text-classification","text-retrieval"],"keywords_longer_than_N":true},
	{"name":"africlirmatrix","keyword":"swahili","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/castorini/africlirmatrix","creator_name":"Castorini","creator_url":"https://huggingface.co/castorini","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nAfriCLIRMatrix is a test collection for cross-lingual information retrieval research in 15 diverse African languages. This resource comprises English queries with query‚Äìdocument relevance judgments in 15 African languages automatically mined from Wikipedia\\nThis dataset stores documents of AfriCLIRMatrix. To access the queries and judgments, please refer to castorini/africlirmatrix.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Structure\\n\\t\\n\\nThe only configuration here is the language.\\nAn‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/castorini/africlirmatrix.","first_N":5,"first_N_keywords":["text-retrieval","multilingual","Afrikaans","Amharic","Egyptian Arabic"],"keywords_longer_than_N":true},
	{"name":"masakhaner2","keyword":"swahili","license":"Academic Free License v3.0","license_url":"https://choosealicense.com/licenses/afl-3.0/","language":"en","dataset_url":"https://huggingface.co/datasets/masakhane/masakhaner2","creator_name":"Masakhane NLP","creator_url":"https://huggingface.co/masakhane","description":"MasakhaNER 2.0 is the largest publicly available high-quality dataset for named entity recognition (NER) in 20 African languages.\\n\\nNamed entities are phrases that contain the names of persons, organizations, locations, times and quantities.\\n\\nExample:\\n[PER Wolff] , currently a journalist in [LOC Argentina] , played with [PER Del Bosque] in the final years of the seventies in [ORG Real Madrid] .\\nMasakhaNER is a named entity dataset consisting of PER, ORG, LOC, and DATE entities annotated by Masakhane for 20 African languages:\\n- Bambara (bam)\\n- Ghomala (bbj)\\n- Ewe (ewe)\\n- Fon (fon)\\n- Hausa (hau)\\n- Igbo (ibo)\\n- Kinyarwanda (kin)\\n- Luganda (lug)\\n- Dholuo (luo) \\n- Mossi (mos)\\n- Chichewa (nya)\\n- Nigerian Pidgin\\n- chShona (sna)\\n- Kiswahili (swƒÖ)\\n- Setswana (tsn)\\n- Twi (twi)\\n- Wolof (wol)\\n- isiXhosa (xho)\\n- Yor√πb√° (yor)\\n- isiZulu (zul)\\n\\nThe train/validation/test sets are available for all the ten languages.\\n\\nFor more details see https://arxiv.org/abs/2103.11811","first_N":5,"first_N_keywords":["token-classification","named-entity-recognition","expert-generated","expert-generated","multilingual"],"keywords_longer_than_N":true},
	{"name":"mgsm","keyword":"swahili","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/juletxara/mgsm","creator_name":"Julen Etxaniz","creator_url":"https://huggingface.co/juletxara","description":"Multilingual Grade School Math Benchmark (MGSM) is a benchmark of grade-school math problems, proposed in the paper [Language models are multilingual chain-of-thought reasoners](http://arxiv.org/abs/2210.03057).\\n\\nThe same 250 problems from [GSM8K](https://arxiv.org/abs/2110.14168) are each translated via human annotators in 10 languages. The 10 languages are:\\n- Spanish\\n- French\\n- German\\n- Russian\\n- Chinese\\n- Japanese\\n- Thai\\n- Swahili\\n- Bengali\\n- Telugu\\n\\nYou can find the input and targets for each of the ten languages (and English) as `.tsv` files.\\nWe also include few-shot exemplars that are also manually translated from each language in `exemplars.py`.","first_N":5,"first_N_keywords":["text2text-generation","found","found","expert-generated","multilingual"],"keywords_longer_than_N":true},
	{"name":"toxi-text-3M","keyword":"swahili","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/FredZhang7/toxi-text-3M","creator_name":"Fred Zhang","creator_url":"https://huggingface.co/FredZhang7","description":"This is a large multilingual toxicity dataset with 3M rows of text data from 55 natural languages, all of which are written/sent by humans, not machine translation models.\\nThe preprocessed training data alone consists of 2,880,667 rows of comments, tweets, and messages. Among these rows, 416,529 are classified as toxic, while the remaining 2,463,773 are considered neutral. Below is a table to illustrate the data composition:\\n\\n\\t\\n\\t\\t\\n\\nToxic\\nNeutral\\nTotal\\n\\n\\n\\t\\t\\nmultilingual-train-deduplicated.csv‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/FredZhang7/toxi-text-3M.","first_N":5,"first_N_keywords":["text-classification","token-classification","zero-shot-classification","Arabic","Spanish"],"keywords_longer_than_N":true},
	{"name":"belebele","keyword":"swahili","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/facebook/belebele","creator_name":"AI at Meta","creator_url":"https://huggingface.co/facebook","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tThe Belebele Benchmark for Massively Multilingual NLU Evaluation\\n\\t\\n\\nBelebele is a multiple-choice machine reading comprehension (MRC) dataset spanning 122 language variants. This dataset enables the evaluation of mono- and multi-lingual models in high-, medium-, and low-resource languages. Each question has four multiple-choice answers and is linked to a short passage from the FLORES-200 dataset. The human annotation procedure was carefully curated to create questions that‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/facebook/belebele.","first_N":5,"first_N_keywords":["question-answering","zero-shot-classification","text-classification","multiple-choice","Afrikaans"],"keywords_longer_than_N":true},
	{"name":"GSM8KInstruct_Parallel","keyword":"swahili","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Mathoctopus/GSM8KInstruct_Parallel","creator_name":"Mathoctopus","creator_url":"https://huggingface.co/Mathoctopus","description":"Mathoctopus/GSM8KInstruct_Parallel dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["question-answering","English","Chinese","Spanish","French"],"keywords_longer_than_N":true},
	{"name":"multilingual-pl-bert","keyword":"swahili","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/styletts2-community/multilingual-pl-bert","creator_name":"StyleTTS 2 Community","creator_url":"https://huggingface.co/styletts2-community","description":"Attribution: Wikipedia.org\\n","first_N":5,"first_N_keywords":["Afrikaans","Aragonese","Arabic","Azerbaijani","Bashkir"],"keywords_longer_than_N":true},
	{"name":"swahili","keyword":"swahili","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mwitiderrick/swahili","creator_name":"Derrick Mwiti","creator_url":"https://huggingface.co/mwitiderrick","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSwahili: CC-100: Monolingual Datasets from Web Crawl Data\\n\\t\\n\\nThis is a Swahili corpus obtained from CC-100: Monolingual Datasets from Web Crawl Data\\n\\n","first_N":5,"first_N_keywords":["text-generation","Swahili","apache-2.0","10M - 100M","text"],"keywords_longer_than_N":true},
	{"name":"CulturaY","keyword":"swahili","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ontocord/CulturaY","creator_name":"Ontocord.AI","creator_url":"https://huggingface.co/ontocord","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tCulturaY: A Large Cleaned Multilingual Dataset of 75 Languages\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nFrom the team that brought you CulturaX, we present CulturaY, another substantial multilingual dataset of 15TB (uncompressed)/3TB (zstd-compressed) that applies the same dataset cleaning methodology to the HPLT v1.1 dataset. \\nPlease note that HPLT v1.2 has also been released and is an alternative verison with different cleaning methodolgies. \\nThis data was used in part to train our SOTA‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ontocord/CulturaY.","first_N":5,"first_N_keywords":["text-generation","fill-mask","language-modeling","masked-language-modeling","no-annotation"],"keywords_longer_than_N":true},
	{"name":"aya_dataset","keyword":"swahili (macrolanguage)","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/CohereForAI/aya_dataset","creator_name":"Cohere For AI","creator_url":"https://huggingface.co/CohereForAI","description":"\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThe Aya Dataset is a multilingual instruction fine-tuning dataset curated by an open-science community via Aya Annotation Platform from Cohere For AI. The dataset contains a total of 204k human-annotated prompt-completion pairs along with the demographics data of the annotators.\\nThis dataset can be used to train, finetune, and evaluate multilingual LLMs.\\n\\nCurated by: Contributors of Aya Open Science Intiative.\\n\\nLanguage(s): 65 languages (71 including dialects &‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/CohereForAI/aya_dataset.","first_N":5,"first_N_keywords":["other","crowdsourced","expert-generated","crowdsourced","expert-generated"],"keywords_longer_than_N":true},
	{"name":"aya_collection","keyword":"swahili (macrolanguage)","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/CohereForAI/aya_collection","creator_name":"Cohere For AI","creator_url":"https://huggingface.co/CohereForAI","description":"\\nThis dataset is uploaded in two places: here and additionally here as 'Aya Collection Language Split.' These datasets are identical in content but differ in structure of upload. This dataset is structured by folders split according to dataset name. The version here instead divides the Aya collection into folders split by language. We recommend you use the language split version if you are only interested in downloading data for a single or smaller set of languages, and this version if you‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/CohereForAI/aya_collection.","first_N":5,"first_N_keywords":["text-classification","summarization","translation","Achinese","Afrikaans"],"keywords_longer_than_N":true},
	{"name":"aya_evaluation_suite","keyword":"swahili (macrolanguage)","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/CohereForAI/aya_evaluation_suite","creator_name":"Cohere For AI","creator_url":"https://huggingface.co/CohereForAI","description":"\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nAya Evaluation Suite contains a total of 26,750 open-ended conversation-style prompts to evaluate multilingual open-ended generation quality.To strike a balance between language coverage and the quality that comes with human curation, we create an evaluation suite that includes:\\n\\nhuman-curated examples in 7 languages (tur, eng, yor, arb, zho, por, tel) ‚Üí aya-human-annotated.\\nmachine-translations of handpicked examples into 101 languages ‚Üí‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/CohereForAI/aya_evaluation_suite.","first_N":5,"first_N_keywords":["text-generation","crowdsourced","expert-generated","machine-generated","multilingual"],"keywords_longer_than_N":true},
	{"name":"sib200","keyword":"swahili (individual language)","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Davlan/sib200","creator_name":"David Adelani","creator_url":"https://huggingface.co/Davlan","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for SIB-200\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nSIB-200 is the largest publicly available topic classification dataset based on Flores-200 covering 205 languages and dialects.\\nThe train/validation/test sets are available for all the 205 languages.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSupported Tasks and Leaderboards\\n\\t\\n\\n\\ntopic classification: categorize wikipedia sentences into topics e.g science/technology, sports or politics.\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages\\n\\t\\n\\nThere are 205 languages available :‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Davlan/sib200.","first_N":5,"first_N_keywords":["text-classification","topic-classification","found","expert-generated","multilingual"],"keywords_longer_than_N":true},
	{"name":"aya_collection_language_split","keyword":"swahili (macrolanguage)","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/CohereForAI/aya_collection_language_split","creator_name":"Cohere For AI","creator_url":"https://huggingface.co/CohereForAI","description":"\\nThis is a re-upload of the aya_collection, and only differs in the structure of upload. While the original aya_collection is structured by folders split according to dataset name, this dataset is split by language. We recommend you use this version of the dataset if you are only interested in downloading all of the Aya collection for a single or smaller set of languages.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThe Aya Collection is a massive multilingual collection consisting of 513 million instances‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/CohereForAI/aya_collection_language_split.","first_N":5,"first_N_keywords":["Achinese","Afrikaans","Amharic","Arabic","Azerbaijani"],"keywords_longer_than_N":true},
	{"name":"mCoT-MATH","keyword":"swahili","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/laihuiyuan/mCoT-MATH","creator_name":"Huiyuan Lai","creator_url":"https://huggingface.co/laihuiyuan","description":"\\n\\t\\n\\t\\t\\n\\t\\tmCoT: Multilingual Instruction Tuning for Reasoning Consistency in Language Models\\n\\t\\n\\nPaper: https://arxiv.org/abs/2406.02301\\nCode: https://github.com/laihuiyuan/mCoT\\nModel: https://huggingface.co/laihuiyuan/mCoT\\n\\n\\t\\n\\t\\t\\n\\t\\tIntroduction\\n\\t\\n\\nBased on MetaMathQA and MathInstruct\\n, we use machine translation to compile mCoT-MATH, the first large-scale multilingual math CoT reasoning dataset containing around 6.3 million samples for 11 diverse languages.\\nWe train a 7B parameter model mCoT for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/laihuiyuan/mCoT-MATH.","first_N":5,"first_N_keywords":["Swahili","Bengali","Telugu","Thai","Japanese"],"keywords_longer_than_N":true},
	{"name":"afrimmlu","keyword":"swahili","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/masakhane/afrimmlu","creator_name":"Masakhane NLP","creator_url":"https://huggingface.co/masakhane","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for afrimmlu\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nAFRIMMLU is an evaluation dataset comprising translations of a subset of the MMLU dataset into 15 African languages. \\nIt includes test sets across all 17 languages, maintaining an English and French subsets from the original MMLU dataset. \\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages\\n\\t\\n\\nThere are 17 languages available :\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Structure\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Instances\\n\\t\\n\\nThe examples look like this for English:\\nfrom datasets import‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/masakhane/afrimmlu.","first_N":5,"first_N_keywords":["question-answering","multiple-choice-qa","multilingual","mmlu","Amharic"],"keywords_longer_than_N":true},
	{"name":"afrimmlu-translate-test","keyword":"swahili","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/masakhane/afrimmlu-translate-test","creator_name":"Masakhane NLP","creator_url":"https://huggingface.co/masakhane","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for afrimmlu-translate-test\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nAFRIMMLU-TT is an evaluation dataset comprising translations of the AFRIMMLU dataset from 16 African languages and 1 high resource language into English using NLLB. \\nIt includes test sets across all 17 languages. \\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages\\n\\t\\n\\nThere are 17 languages available :\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Structure\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Instances\\n\\t\\n\\nThe examples look like this for English:\\nfrom datasets import load_dataset‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/masakhane/afrimmlu-translate-test.","first_N":5,"first_N_keywords":["text-classification","natural-language-inference","monolingual","afrimmlu","Amharic"],"keywords_longer_than_N":true},
	{"name":"GlotCC-V1","keyword":"swahili (macrolanguage)","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/cis-lmu/GlotCC-V1","creator_name":"CIS, LMU Munich","creator_url":"https://huggingface.co/cis-lmu","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\n \\n\\nGlotCC-V1.0 is a document-level, general domain dataset derived from CommonCrawl, covering more than 1000 languages.It is built using the GlotLID language identification and Ungoliant pipeline from CommonCrawl.We release our pipeline as open-source at https://github.com/cisnlp/GlotCC.  \\nList of Languages: See https://datasets-server.huggingface.co/splits?dataset=cis-lmu/GlotCC-V1 to get the list of splits available.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tUsage (Huggingface Hub --‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/cis-lmu/GlotCC-V1.","first_N":5,"first_N_keywords":["multilingual","Abau","Amarasi","Abkhaz","Abkhazian"],"keywords_longer_than_N":true},
	{"name":"GlotCC-V1","keyword":"swahili (individual language)","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/cis-lmu/GlotCC-V1","creator_name":"CIS, LMU Munich","creator_url":"https://huggingface.co/cis-lmu","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\n \\n\\nGlotCC-V1.0 is a document-level, general domain dataset derived from CommonCrawl, covering more than 1000 languages.It is built using the GlotLID language identification and Ungoliant pipeline from CommonCrawl.We release our pipeline as open-source at https://github.com/cisnlp/GlotCC.  \\nList of Languages: See https://datasets-server.huggingface.co/splits?dataset=cis-lmu/GlotCC-V1 to get the list of splits available.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tUsage (Huggingface Hub --‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/cis-lmu/GlotCC-V1.","first_N":5,"first_N_keywords":["multilingual","Abau","Amarasi","Abkhaz","Abkhazian"],"keywords_longer_than_N":true},
	{"name":"nomiracl-instruct","keyword":"swahili","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/miracl/nomiracl-instruct","creator_name":"MIRACL","creator_url":"https://huggingface.co/miracl","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for NoMIRACL (EMNLP 2024 Findings Track)\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tQuick Overview\\n\\t\\n\\nThis repository contains the fine-tuning (training & development split) of the NoMIRACL instruct dataset for fine-tuning LLMs on multilingual relevance assessment.\\nThe training dataset is a binary classification task; they need to explicitly output either Yes, answer is present or I don't know. \\nThe dataset contains training pairs from all 18 languages for both splits: relevant & non-relevant.‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/miracl/nomiracl-instruct.","first_N":5,"first_N_keywords":["text-classification","text-generation","Arabic","Bengali","German"],"keywords_longer_than_N":true},
	{"name":"text_ratings","keyword":"swahili","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/lightblue/text_ratings","creator_name":"Lightblue KK.","creator_url":"https://huggingface.co/lightblue","description":"Todo - Write dataset card\\n","first_N":5,"first_N_keywords":["Amharic","Arabic","Bulgarian","Bengali","Czech"],"keywords_longer_than_N":true},
	{"name":"MMMLU","keyword":"swahili","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/openai/MMMLU","creator_name":"OpenAI","creator_url":"https://huggingface.co/openai","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tMultilingual Massive Multitask Language Understanding (MMMLU)\\n\\t\\n\\nThe MMLU is a widely recognized benchmark of general knowledge attained by AI models. It covers a broad range of topics from 57 different categories, covering elementary-level knowledge up to advanced professional subjects like law, physics, history, and computer science.\\nWe translated the MMLU‚Äôs test set into 14 languages using professional human translators. Relying on human translators for this evaluation increases‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/openai/MMMLU.","first_N":5,"first_N_keywords":["question-answering","Arabic","Bengali","German","Spanish"],"keywords_longer_than_N":true},
	{"name":"mgsm","keyword":"swahili","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/jbross-ibm-research/mgsm","creator_name":"J Bross","creator_url":"https://huggingface.co/jbross-ibm-research","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for MGSM\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nCopy and merge of this MGSM Dataset, Catalan version, Basque version, Galician version, but in training samples we removed the prompt formatting, e.g. removed Question: ... in question field or Answer: ... in answer field.\\nMultilingual Grade School Math Benchmark (MGSM) is a benchmark of grade-school math problems, proposed in the paper Language models are multilingual chain-of-thought reasoners.\\nThe same 250 problems from‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/jbross-ibm-research/mgsm.","first_N":5,"first_N_keywords":["text2text-generation","found","found","expert-generated","multilingual"],"keywords_longer_than_N":true},
	{"name":"muri-it","keyword":"swahili (macrolanguage)","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/akoksal/muri-it","creator_name":"Abdullatif Koksal","creator_url":"https://huggingface.co/akoksal","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tMURI-IT: Multilingual Instruction Tuning Dataset for 200 Languages via Multilingual Reverse Instructions\\n\\t\\n\\nMURI-IT is a large-scale multilingual instruction tuning dataset containing 2.2 million instruction-output pairs across 200 languages. It is designed to address the challenges of instruction tuning in low-resource languages with Multilingual Reverse Instructions (MURI), which ensures that the output is human-written, high-quality, and authentic to the cultural and linguistic‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/akoksal/muri-it.","first_N":5,"first_N_keywords":["text2text-generation","text-generation","question-answering","summarization","Achinese"],"keywords_longer_than_N":true},
	{"name":"PangeaBench-marvl","keyword":"swahili","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/neulab/PangeaBench-marvl","creator_name":"NeuLab @ LTI/CMU","creator_url":"https://huggingface.co/neulab","description":"\\n\\t\\n\\t\\t\\n\\t\\tMaRVL\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tThis is a copy from the original repo: https://github.com/marvl-challenge/marvl-code\\n\\t\\n\\nIf you use this dataset, please cite the original authors:\\n@inproceedings{liu-etal-2021-visually,\\n    title = \\\"Visually Grounded Reasoning across Languages and Cultures\\\",\\n    author = \\\"Liu, Fangyu  and\\n      Bugliarello, Emanuele  and\\n      Ponti, Edoardo Maria  and\\n      Reddy, Siva  and\\n      Collier, Nigel  and\\n      Elliott, Desmond\\\",\\n    booktitle = \\\"Proceedings of the 2021‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/neulab/PangeaBench-marvl.","first_N":5,"first_N_keywords":["visual-question-answering","Indonesian","Swahili","Tamil","Turkish"],"keywords_longer_than_N":true},
	{"name":"VoxCommunis","keyword":"swahili","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/pacscilab/VoxCommunis","creator_name":"PaCSciLab @ UZH","creator_url":"https://huggingface.co/pacscilab","description":"The VoxCommunis Corpus contains acoustic models, lexicons, and force-aligned TextGrids with phone- and word-level segmentations derived from the Mozilla Common Voice Corpus. The Mozilla Common Voice Corpus and derivative VoxCommunis Corpus stored here are free to download and use under a CC0 license.\\nThe lexicons are developed using Epitran, the XPF Corpus, Charsiu, and some custom dictionaries. Some manual correction has been applied, and we hope to continue improving these. Any updates from‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/pacscilab/VoxCommunis.","first_N":5,"first_N_keywords":["Abkhaz","Amharic","Bashkir","Belarusian","Bulgarian"],"keywords_longer_than_N":true},
	{"name":"HPLT2.0_cleaned","keyword":"swahili (individual language)","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/HPLT/HPLT2.0_cleaned","creator_name":"HPLT","creator_url":"https://huggingface.co/HPLT","description":"This is a large-scale collection of web-crawled documents in 191 world languages, produced by the HPLT project. \\nThe source of the data is mostly Internet Archive with some additions from Common Crawl.\\nFor a detailed description of the dataset, please refer to https://hplt-project.org/datasets/v2.0\\nThe Cleaned variant of HPLT Datasets v2.0\\nThis is the cleaned variant of the HPLT Datasets v2.0 converted to the Parquet format semi-automatically when being uploaded here. \\nThe original JSONL files‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/HPLT/HPLT2.0_cleaned.","first_N":5,"first_N_keywords":["fill-mask","text-generation","language-modeling","multilingual","Achinese"],"keywords_longer_than_N":true},
	{"name":"belebele-fleurs","keyword":"swahili","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/WueNLP/belebele-fleurs","creator_name":"W√ºNLP","creator_url":"https://huggingface.co/WueNLP","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tBelebele-Fleurs\\n\\t\\n\\nBelebele-Fleurs is a dataset suitable to evaluate two core tasks:\\n\\nMultilingual Spoken Language Understanding (Listening Comprehension): For each spoken paragraph, the task is to answer a multiple-choice question. The question and four answer choices are provided in text form.\\nMultilingual Long-Form Automatic Speech Recognition (ASR) with Diverse Speakers: By concatenating sentence-level utterances, long-form audio clips (ranging from 30 seconds to 1 minute 30‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/WueNLP/belebele-fleurs.","first_N":5,"first_N_keywords":["audio-classification","automatic-speech-recognition","audio-text-to-text","text-to-speech","question-answering"],"keywords_longer_than_N":true},
	{"name":"open-dict-words-ipa","keyword":"swahili","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/StephanAkkerman/open-dict-words-ipa","creator_name":"Stephan Akkerman","creator_url":"https://huggingface.co/StephanAkkerman","description":"\\n\\t\\n\\t\\t\\n\\t\\tOpen-dict Words IPA\\n\\t\\n\\nThis dataset is a copy of https://github.com/open-dict-data/ipa-dict\\n\\n\\t\\n\\t\\t\\n\\t\\tLanguages\\n\\t\\n\\nIPA data is currently available for the following languages:\\n\\n\\t\\n\\t\\t\\nLanguage\\nCode\\n\\n\\n\\t\\t\\nar\\nArabic (Modern Standard)\\n\\n\\nde\\nGerman\\n\\n\\nen_UK\\nEnglish (Received Pronunciation)\\n\\n\\nen_US\\nEnglish (General American)\\n\\n\\neo\\nEsperanto\\n\\n\\nes_ES\\nSpanish (Spain)\\n\\n\\nes_MX\\nSpanish (Mexico)\\n\\n\\nfa\\nPersian\\n\\n\\nfi\\nFinnish\\n\\n\\nfr_FR\\nFrench (France)\\n\\n\\nfr_QC\\nFrench (Qu√©bec)\\n\\n\\nis\\nIcelandic\\n\\n\\nja\\nJapanese\\n\\n\\njam‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/StephanAkkerman/open-dict-words-ipa.","first_N":5,"first_N_keywords":["Arabic","German","English","Esperanto","Spanish"],"keywords_longer_than_N":true},
	{"name":"Global-MMLU-Lite","keyword":"swahili","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/CohereForAI/Global-MMLU-Lite","creator_name":"Cohere For AI","creator_url":"https://huggingface.co/CohereForAI","description":"\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nGlobal-MMLU-Lite is a multilingual evaluation set spanning 15 languages, including English. It is \\\"lite\\\" version of the original Global-MMLU dataset üåç.\\nIt includes 200 Culturally Sensitive (CS) and 200 Culturally Agnostic (CA) samples per language. The samples in Global-MMLU-Lite are corresponding to languages which are fully human translated or post-edited in the original Global-MMLU dataset. \\n\\nCurated by: Professional annotators and contributors of Cohere For‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/CohereForAI/Global-MMLU-Lite.","first_N":5,"first_N_keywords":["English","Arabic","Bengali","Spanish","French"],"keywords_longer_than_N":true},
	{"name":"2M-Belebele","keyword":"swahili","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/facebook/2M-Belebele","creator_name":"AI at Meta","creator_url":"https://huggingface.co/facebook","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\t2M-Belebele\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tHighly-Multilingual Speech and American Sign Language Comprehension Dataset\\n\\t\\n\\nWe introduce 2M-Belebele as the first highly multilingual speech and American Sign Language (ASL) comprehension dataset. Our dataset, which is an extension of the existing Belebele only-text dataset, covers 74 spoken languages at the intersection of Belebele and Fleurs, and one sign language (ASL). \\nThe speech dataset is built from aligning Belebele, Flores200 and Fleurs‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/facebook/2M-Belebele.","first_N":5,"first_N_keywords":["question-answering","automatic-speech-recognition","Bulgarian","Panjabi","English"],"keywords_longer_than_N":true},
	{"name":"reranker_continuous_filt_max7_train","keyword":"swahili","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/lightblue/reranker_continuous_filt_max7_train","creator_name":"Lightblue KK.","creator_url":"https://huggingface.co/lightblue","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tReranker training data\\n\\t\\n\\nThis data was generated using 4 steps:\\n\\nWe gathered queries and corresponding text data from 35 high quality datasets covering more than 95 languages.\\nFor datasets which did not already have negative texts for queries, we mined hard negatives using the BAAI/bge-m3 embedding model.\\nFor each query, we selected one positive and one negative text and used Qwen/Qwen2.5-32B-Instruct-GPTQ-Int4 to rate the relatedness of each query-text pair using a token \\\"1\\\", \\\"2\\\"‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/lightblue/reranker_continuous_filt_max7_train.","first_N":5,"first_N_keywords":["English","Chinese","Spanish","German","Arabic"],"keywords_longer_than_N":true},
	{"name":"sib-fleurs","keyword":"swahili (individual language)","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/WueNLP/sib-fleurs","creator_name":"W√ºNLP","creator_url":"https://huggingface.co/WueNLP","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSIB-Fleurs\\n\\t\\n\\nSIB-Fleurs is a dataset suitable to evaluate Multilingual Spoken Language Understanding. For each utterance in Fleurs, the task is to determine the topic the utterance belongs to. \\nThe topics are:\\n\\nScience/Technology\\nTravel\\nPolitics\\nSports\\nHealth\\nEntertainment\\nGeography\\n\\nPreliminary evaluations can be found at the bottom of the README. The preliminary results in full detail are available in ./results.csv*.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset creation\\n\\t\\n\\nThis dataset processes and‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/WueNLP/sib-fleurs.","first_N":5,"first_N_keywords":["audio-classification","automatic-speech-recognition","audio-text-to-text","text-to-speech","question-answering"],"keywords_longer_than_N":true},
	{"name":"Synthdog-Multilingual-100","keyword":"swahili","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/WueNLP/Synthdog-Multilingual-100","creator_name":"W√ºNLP","creator_url":"https://huggingface.co/WueNLP","description":"\\n\\t\\n\\t\\t\\n\\t\\tSynthdog Multilingual\\n\\t\\n\\n\\n\\nThe Synthdog dataset created for training in Centurio: On Drivers of Multilingual Ability of Large Vision-Language Model.\\nUsing the official Synthdog code, we created >1 million training samples for improving OCR capabilities in Large Vision-Language Models.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Details\\n\\t\\n\\nWe provide the images for download in two .tar.gz files. Download and extract them in folders of the same name (so cat images.tar.gz.* | tar xvzf -C images; tar xvzf‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/WueNLP/Synthdog-Multilingual-100.","first_N":5,"first_N_keywords":["image-to-text","multilingual","Afrikaans","Amharic","Arabic"],"keywords_longer_than_N":true},
	{"name":"BenchMAX_Math","keyword":"swahili","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/LLaMAX/BenchMAX_Math","creator_name":"LLaMAX","creator_url":"https://huggingface.co/LLaMAX","description":"\\n\\t\\n\\t\\t\\n\\t\\tDataset Sources\\n\\t\\n\\n\\nPaper: BenchMAX: A Comprehensive Multilingual Evaluation Suite for Large Language Models\\nLink: https://arxiv.org/pdf/2502.07346\\nRepository: https://github.com/CONE-MT/BenchMAX\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\nBenchMAX_Math is a dataset of BenchMAX, sourcing from MGSM.\\nWe extend the original dataset to 6 more languages.\\nThe data is first translated by Google Translate, and then post-editing by native speakers.\\n\\n\\t\\n\\t\\t\\n\\t\\tSupported Languages\\n\\t\\n\\nArabic, Bengali, Chinese‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/LLaMAX/BenchMAX_Math.","first_N":5,"first_N_keywords":["text-generation","multilingual","English","Chinese","Spanish"],"keywords_longer_than_N":true},
	{"name":"BenchMAX_Science","keyword":"swahili","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/LLaMAX/BenchMAX_Science","creator_name":"LLaMAX","creator_url":"https://huggingface.co/LLaMAX","description":"\\n\\t\\n\\t\\t\\n\\t\\tDataset Sources\\n\\t\\n\\n\\nPaper: BenchMAX: A Comprehensive Multilingual Evaluation Suite for Large Language Models\\nLink: https://arxiv.org/pdf/2502.07346\\nRepository: https://github.com/CONE-MT/BenchMAX\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\nBenchMAX_Science is a dataset of BenchMAX, sourcing from GPQA.\\nWe extend the original English dataset to 16 non-English languages.\\nThe data is first translated by Google Translate, and then post-editing by native speakers.\\n\\n\\t\\n\\t\\t\\n\\t\\tSupported Languages\\n\\t\\n\\nArabic‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/LLaMAX/BenchMAX_Science.","first_N":5,"first_N_keywords":["text-generation","multilingual","English","Chinese","Spanish"],"keywords_longer_than_N":true},
	{"name":"BenchMAX_Function_Completion","keyword":"swahili","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/LLaMAX/BenchMAX_Function_Completion","creator_name":"LLaMAX","creator_url":"https://huggingface.co/LLaMAX","description":"\\n\\t\\n\\t\\t\\n\\t\\tDataset Sources\\n\\t\\n\\n\\nPaper: BenchMAX: A Comprehensive Multilingual Evaluation Suite for Large Language Models\\nLink: https://arxiv.org/pdf/2502.07346\\nRepository: https://github.com/CONE-MT/BenchMAX\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\nBenchMAX_Function_Completion is a dataset of BenchMAX, sourcing from humanevalplus.\\nWe extend the original English dataset to 16 non-English languages.\\nThe data is first translated by GPT-4o, and then post-editing by native speakers.\\n\\n\\t\\n\\t\\t\\n\\t\\tSupported Languages‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/LLaMAX/BenchMAX_Function_Completion.","first_N":5,"first_N_keywords":["text-generation","multilingual","English","Chinese","Spanish"],"keywords_longer_than_N":true},
	{"name":"BenchMAX_Problem_Solving","keyword":"swahili","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/LLaMAX/BenchMAX_Problem_Solving","creator_name":"LLaMAX","creator_url":"https://huggingface.co/LLaMAX","description":"\\n\\t\\n\\t\\t\\n\\t\\tDataset Sources\\n\\t\\n\\n\\nPaper: BenchMAX: A Comprehensive Multilingual Evaluation Suite for Large Language Models\\nLink: https://arxiv.org/pdf/2502.07346\\nRepository: https://github.com/CONE-MT/BenchMAX\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\nBenchMAX_Problem_Solving is a dataset of BenchMAX, sourcing from LiveCodeBench.\\nWe extend the original English dataset to 16 non-English languages.\\nThe data is first translated by GPT-4o, and then post-editing by native speakers.\\n\\n\\t\\n\\t\\t\\n\\t\\tSupported Languages‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/LLaMAX/BenchMAX_Problem_Solving.","first_N":5,"first_N_keywords":["text-generation","multilingual","English","Chinese","Spanish"],"keywords_longer_than_N":true},
	{"name":"smol","keyword":"swahili","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/google/smol","creator_name":"Google","creator_url":"https://huggingface.co/google","description":"\\n\\t\\n\\t\\t\\n\\t\\tSMOL\\n\\t\\n\\nSMOL (Set for Maximal Overall Leverage) is a collection of professional\\ntranslations into 221 Low-Resource Languages, for the purpose of training\\ntranslation models, and otherwise increasing the representations of said\\nlanguages in NLP and technology.\\nPlease read the SMOL Paper and the\\nGATITOS Paper for a much more\\nthorough description!\\nThere are four resources in this directory:\\n\\nSmolDoc: document-level translations into 100 languages\\nSmolSent: sentence-level translations into‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/google/smol.","first_N":5,"first_N_keywords":["translation","Afar","Abkhaz","Achinese","Acoli"],"keywords_longer_than_N":true},
	{"name":"multilingual_translation_sft","keyword":"swahili","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Youseff1987/multilingual_translation_sft","creator_name":"JOON HYOUNG JUN","creator_url":"https://huggingface.co/Youseff1987","description":"Youseff1987/multilingual_translation_sft dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["translation","Korean","English","Chinese","Zulu"],"keywords_longer_than_N":true},
	{"name":"BRIGHTER-emotion-categories","keyword":"swahili","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/brighter-dataset/BRIGHTER-emotion-categories","creator_name":"BRIGHTER Dataset","creator_url":"https://huggingface.co/brighter-dataset","description":"\\n\\t\\n\\t\\t\\n\\t\\tBRIGHTER Emotion Categories Dataset\\n\\t\\n\\nThis dataset contains the emotion categories data from the BRIGHTER paper: BRIdging the Gap in Human-Annotated Textual Emotion Recognition Datasets for 28 Languages.\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThe BRIGHTER Emotion Categories dataset is a comprehensive multi-language, multi-label emotion classification dataset with separate configurations for each language. It represents one of the largest human-annotated emotion datasets across multiple‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/brighter-dataset/BRIGHTER-emotion-categories.","first_N":5,"first_N_keywords":["Afrikaans","Arabic","German","English","Spanish"],"keywords_longer_than_N":true},
	{"name":"opus_paracrawl","keyword":"swahili","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Helsinki-NLP/opus_paracrawl","creator_name":"Language Technology Research Group at the University of Helsinki","creator_url":"https://huggingface.co/Helsinki-NLP","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for OpusParaCrawl\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nParallel corpora from Web Crawls collected in the ParaCrawl project.\\nTha dataset contains:\\n\\n42 languages, 43 bitexts\\ntotal number of files: 59,996\\ntotal number of tokens: 56.11G\\ntotal number of sentence fragments: 3.13G\\n\\nTo load a language pair which isn't part of the config, all you need to do is specify the language code as pairs,\\ne.g.\\ndataset = load_dataset(\\\"opus_paracrawl\\\", lang1=\\\"en\\\", lang2=\\\"so\\\")\\n\\nYou can find‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Helsinki-NLP/opus_paracrawl.","first_N":5,"first_N_keywords":["translation","found","found","multilingual","original"],"keywords_longer_than_N":true},
	{"name":"opus_ubuntu","keyword":"swahili","license":"BSD 3-Clause \"New\" or \"Revised\" License","license_url":"https://choosealicense.com/licenses/bsd-3-clause/","language":"en","dataset_url":"https://huggingface.co/datasets/Helsinki-NLP/opus_ubuntu","creator_name":"Language Technology Research Group at the University of Helsinki","creator_url":"https://huggingface.co/Helsinki-NLP","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Opus Ubuntu\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThese are translations of the Ubuntu software package messages, donated by the Ubuntu community.\\nTo load a language pair which isn't part of the config, all you need to do is specify the language code as pairs.\\nYou can find the valid pairs in Homepage section of Dataset Description: http://opus.nlpl.eu/Ubuntu.php\\nE.g.\\ndataset = load_dataset(\\\"opus_ubuntu\\\", lang1=\\\"it\\\", lang2=\\\"pl\\\")\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSupported Tasks and‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Helsinki-NLP/opus_ubuntu.","first_N":5,"first_N_keywords":["translation","crowdsourced","expert-generated","found","multilingual"],"keywords_longer_than_N":true},
	{"name":"swahili_news","keyword":"swahili","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/community-datasets/swahili_news","creator_name":"Community Datasets","creator_url":"https://huggingface.co/community-datasets","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Swahili : News Classification Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nSwahili is spoken by 100-150 million people across East Africa. In Tanzania, it is one of two national languages (the other is English) and it is the official language of instruction in all schools. News in Swahili is an important part of the media sphere in Tanzania.\\nNews contributes to education, technology, and the economic growth of a country, and news in local languages plays an important‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/community-datasets/swahili_news.","first_N":5,"first_N_keywords":["text-classification","multi-class-classification","expert-generated","found","monolingual"],"keywords_longer_than_N":true},
	{"name":"tydiqa","keyword":"swahili","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/google-research-datasets/tydiqa","creator_name":"Google Research Datasets","creator_url":"https://huggingface.co/google-research-datasets","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for \\\"tydiqa\\\"\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nTyDi QA is a question answering dataset covering 11 typologically diverse languages with 204K question-answer pairs.\\nThe languages of TyDi QA are diverse with regard to their typology -- the set of linguistic features that each language\\nexpresses -- such that we expect models performing well on this set to generalize across a large number of the languages\\nin the world. It contains language phenomena that would not be found‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/google-research-datasets/tydiqa.","first_N":5,"first_N_keywords":["question-answering","extractive-qa","crowdsourced","crowdsourced","multilingual"],"keywords_longer_than_N":true},
	{"name":"xcopa","keyword":"swahili","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/cambridgeltl/xcopa","creator_name":"Language Technology Lab @University of Cambridge","creator_url":"https://huggingface.co/cambridgeltl","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for \\\"xcopa\\\"\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\n  XCOPA: A Multilingual Dataset for Causal Commonsense Reasoning\\nThe Cross-lingual Choice of Plausible Alternatives dataset is a benchmark to evaluate the ability of machine learning models to transfer commonsense reasoning across\\nlanguages. The dataset is the translation and reannotation of the English COPA (Roemmele et al. 2011) and covers 11 languages from 11 families and several areas around\\nthe globe. The dataset is‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/cambridgeltl/xcopa.","first_N":5,"first_N_keywords":["question-answering","multiple-choice-qa","expert-generated","expert-generated","multilingual"],"keywords_longer_than_N":true},
	{"name":"xcsr","keyword":"swahili","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/INK-USC/xcsr","creator_name":"INK Lab @ USC","creator_url":"https://huggingface.co/INK-USC","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for X-CSR\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nTo evaluate multi-lingual language models (ML-LMs) for commonsense reasoning in a cross-lingual zero-shot transfer setting (X-CSR), i.e., training in English and test in other languages, we create two benchmark datasets, namely X-CSQA and X-CODAH. Specifically, we automatically translate the original CSQA and CODAH datasets, which only have English versions, to 15 other languages, forming development and test sets for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/INK-USC/xcsr.","first_N":5,"first_N_keywords":["question-answering","multiple-choice-qa","crowdsourced","crowdsourced","machine-generated"],"keywords_longer_than_N":true},
	{"name":"afriberta-corpus","keyword":"swahili","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/castorini/afriberta-corpus","creator_name":"Castorini","creator_url":"https://huggingface.co/castorini","description":"Corpus used for training AfriBERTa models","first_N":5,"first_N_keywords":["text-generation","language-modeling","Oromo","Amharic","Kinyarwanda"],"keywords_longer_than_N":true},
	{"name":"mr-tydi-corpus","keyword":"swahili","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/castorini/mr-tydi-corpus","creator_name":"Castorini","creator_url":"https://huggingface.co/castorini","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nMr. TyDi is a multi-lingual benchmark dataset built on TyDi, covering eleven typologically diverse languages. It is designed for monolingual retrieval, specifically to evaluate ranking with learned dense representations.\\nThis dataset stores documents of Mr. TyDi. To access the queries and judgments, please refer to castorini/mr-tydi.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Structure\\n\\t\\n\\nThe only configuration here is the language. As all three folds (train, dev and test) share the‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/castorini/mr-tydi-corpus.","first_N":5,"first_N_keywords":["text-retrieval","multilingual","Arabic","Bengali","English"],"keywords_longer_than_N":true},
	{"name":"mr-tydi","keyword":"swahili","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/castorini/mr-tydi","creator_name":"Castorini","creator_url":"https://huggingface.co/castorini","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nMr. TyDi is a multi-lingual benchmark dataset built on TyDi, covering eleven typologically diverse languages. It is designed for monolingual retrieval, specifically to evaluate ranking with learned dense representations.\\nThis dataset stores the queries, judgements, and example training data of Mr. TyDi. To access the corpus, please refer to castorini/mr-tydi-corpus.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Structure\\n\\t\\n\\nThe only configuration here is the language, \\nFor each language‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/castorini/mr-tydi.","first_N":5,"first_N_keywords":["text-retrieval","multilingual","Arabic","Bengali","English"],"keywords_longer_than_N":true},
	{"name":"flores_101","keyword":"swahili","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/gsarti/flores_101","creator_name":"Gabriele Sarti","creator_url":"https://huggingface.co/gsarti","description":"One of the biggest challenges hindering progress in low-resource and multilingual machine translation is the \\nlack of good evaluation benchmarks. Current evaluation benchmarks either lack good coverage of low-resource \\nlanguages, consider only restricted domains, or are low quality because they are constructed using \\nsemi-automatic procedures. In this work, we introduce the FLORES evaluation benchmark, consisting of 3001 \\nsentences extracted from English Wikipedia and covering a variety of different topics and domains. \\nThese sentences have been translated in 101 languages by professional translators through a carefully \\ncontrolled process. The resulting dataset enables better assessment of model quality on the long tail of \\nlow-resource languages, including the evaluation of many-to-many multilingual translation systems, as all \\ntranslations are multilingually aligned. By publicly releasing such a high-quality and high-coverage dataset, \\nwe hope to foster progress in the machine translation community and beyond.","first_N":5,"first_N_keywords":["text-generation","translation","found","expert-generated","multilingual"],"keywords_longer_than_N":true},
	{"name":"xlel_wd_dictionary","keyword":"swahili","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/adithya7/xlel_wd_dictionary","creator_name":"Adithya Pratapa","creator_url":"https://huggingface.co/adithya7","description":"XLEL-WD is a multilingual event linking dataset. This sub-dataset contains a dictionary of events from Wikidata. The multilingual descriptions for Wikidata event items are taken from the corresponding Wikipedia articles.","first_N":5,"first_N_keywords":["found","found","multilingual","original","Afrikaans"],"keywords_longer_than_N":true},
	{"name":"xlel_wd","keyword":"swahili","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/adithya7/xlel_wd","creator_name":"Adithya Pratapa","creator_url":"https://huggingface.co/adithya7","description":"XLEL-WD is a multilingual event linking dataset. This dataset contains mention references from multilingual Wikipedia/Wikinews articles to event items in Wikidata. The text descriptions for Wikidata events are compiled from Wikipedia articles.","first_N":5,"first_N_keywords":["found","found","multilingual","original","Afrikaans"],"keywords_longer_than_N":true},
	{"name":"wit_base","keyword":"swahili","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/wikimedia/wit_base","creator_name":"Wikimedia","creator_url":"https://huggingface.co/wikimedia","description":"\\n\\t\\n\\t\\t\\n\\t\\tDataset Card for WIT\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nWikimedia's version of the Wikipedia-based Image Text (WIT) Dataset, a large multimodal multilingual dataset.\\nFrom the official blog post:\\n\\nThe core training data is taken from the Wikipedia Image-Text (WIT) Dataset, a large curated set of more than 37 million image-text associations extracted from Wikipedia articles in 108 languages that was recently released by Google Research.\\nThe WIT dataset offers extremely valuable data about the‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/wikimedia/wit_base.","first_N":5,"first_N_keywords":["image-to-text","text-retrieval","image-captioning","machine-generated","found"],"keywords_longer_than_N":true},
	{"name":"xP3all","keyword":"swahili","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/bigscience/xP3all","creator_name":"BigScience Workshop","creator_url":"https://huggingface.co/bigscience","description":"xP3 (Crosslingual Public Pool of Prompts) is a collection of prompts & datasets across 46 of languages & 16 NLP tasks. It is used for the training of BLOOMZ and mT0, multilingual language models capable of following human instructions in dozens of languages zero-shot.","first_N":5,"first_N_keywords":["other","expert-generated","crowdsourced","multilingual","Akan"],"keywords_longer_than_N":true},
	{"name":"answerable_tydiqa","keyword":"swahili","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/copenlu/answerable_tydiqa","creator_name":"CopeNLU","creator_url":"https://huggingface.co/copenlu","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for \\\"answerable-tydiqa\\\"\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nTyDi QA is a question answering dataset covering 11 typologically diverse languages. \\nAnswerable TyDi QA is an extension of the GoldP subtask of the original TyDi QA dataset to also include unanswertable questions.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Structure\\n\\t\\n\\nThe dataset contains a train and a validation set, with 116067 and 13325 examples, respectively. Access them with\\nfrom datasets import load_dataset\\ndataset =‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/copenlu/answerable_tydiqa.","first_N":5,"first_N_keywords":["question-answering","extractive-qa","crowdsourced","crowdsourced","multilingual"],"keywords_longer_than_N":true},
	{"name":"tydiqa_copenlu","keyword":"swahili","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/copenlu/tydiqa_copenlu","creator_name":"CopeNLU","creator_url":"https://huggingface.co/copenlu","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for \\\"tydiqa\\\"\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nTyDi QA is a question answering dataset covering 11 typologically diverse languages with 204K question-answer pairs.\\nThe languages of TyDi QA are diverse with regard to their typology -- the set of linguistic features that each language\\nexpresses -- such that we expect models performing well on this set to generalize across a large number of the languages\\nin the world. It contains language phenomena that would not be found‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/copenlu/tydiqa_copenlu.","first_N":5,"first_N_keywords":["question-answering","extractive-qa","crowdsourced","crowdsourced","multilingual"],"keywords_longer_than_N":true},
	{"name":"xP3mt","keyword":"swahili","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/bigscience/xP3mt","creator_name":"BigScience Workshop","creator_url":"https://huggingface.co/bigscience","description":"xP3 (Crosslingual Public Pool of Prompts) is a collection of prompts & datasets across 46 of languages & 16 NLP tasks. It is used for the training of BLOOMZ and mT0, multilingual language models capable of following human instructions in dozens of languages zero-shot.","first_N":5,"first_N_keywords":["other","expert-generated","crowdsourced","multilingual","Akan"],"keywords_longer_than_N":true},
	{"name":"miracl-corpus","keyword":"swahili","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/miracl/miracl-corpus","creator_name":"MIRACL","creator_url":"https://huggingface.co/miracl","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for MIRACL Corpus\\n\\t\\n\\nMIRACL üåçüôåüåè (Multilingual Information Retrieval Across a Continuum of Languages) is a multilingual retrieval dataset that focuses on search across 18 different languages, which collectively encompass over three billion native speakers around the world.\\nThis dataset contains the collection data of the 16 \\\"known languages\\\". The remaining 2 \\\"surprise languages\\\" will not be released until later.\\nThe corpus for each language is prepared from a‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/miracl/miracl-corpus.","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","expert-generated","multilingual","Arabic"],"keywords_longer_than_N":true},
	{"name":"TaTA","keyword":"swahili","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/GEM/TaTA","creator_name":"GEM benchmark","creator_url":"https://huggingface.co/GEM","description":"Dataset loader for TaTA: A Multilingual Table-to-Text Dataset for African Languages","first_N":5,"first_N_keywords":["table-to-text","none","unknown","yes","original"],"keywords_longer_than_N":true},
	{"name":"afrolm_active_learning_dataset","keyword":"swahili (macrolanguage)","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/bonadossou/afrolm_active_learning_dataset","creator_name":"Bonaventure Dossou","creator_url":"https://huggingface.co/bonadossou","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tAfroLM: A Self-Active Learning-based Multilingual Pretrained Language Model for 23 African Languages\\n\\t\\n\\n\\nGitHub Repository of the Paper\\n\\nThis repository contains the dataset for our paper AfroLM: A Self-Active Learning-based Multilingual Pretrained Language Model for 23 African Languages which will appear at the third Simple and Efficient Natural Language Processing, at EMNLP 2022.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tOur self-active learning framework\\n\\t\\n\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages Covered\\n\\t\\n\\nAfroLM has been‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/bonadossou/afrolm_active_learning_dataset.","first_N":5,"first_N_keywords":["fill-mask","masked-language-modeling","crowdsourced","crowdsourced","monolingual"],"keywords_longer_than_N":true},
	{"name":"xstory_cloze","keyword":"swahili","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/juletxara/xstory_cloze","creator_name":"Julen Etxaniz","creator_url":"https://huggingface.co/juletxara","description":"XStoryCloze consists of the professionally translated version of the [English StoryCloze dataset](https://cs.rochester.edu/nlp/rocstories/) (Spring 2016 version) to 10 non-English languages. This dataset is released by Meta AI.","first_N":5,"first_N_keywords":["other","found","found","expert-generated","multilingual"],"keywords_longer_than_N":true},
	{"name":"miracl-sw-queries-22-12","keyword":"swahili","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Cohere/miracl-sw-queries-22-12","creator_name":"Cohere","creator_url":"https://huggingface.co/Cohere","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tMIRACL (sw) embedded with cohere.ai multilingual-22-12 encoder\\n\\t\\n\\nWe encoded the MIRACL dataset using the cohere.ai multilingual-22-12 embedding model.\\nThe query embeddings can be found in Cohere/miracl-sw-queries-22-12 and the corpus embeddings can be found in Cohere/miracl-sw-corpus-22-12.\\nFor the orginal datasets, see miracl/miracl and miracl/miracl-corpus.\\nDataset info:\\n\\nMIRACL üåçüôåüåè (Multilingual Information Retrieval Across a Continuum of Languages) is a multilingual‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Cohere/miracl-sw-queries-22-12.","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","expert-generated","multilingual","Swahili"],"keywords_longer_than_N":true},
	{"name":"miracl-sw-corpus-22-12","keyword":"swahili","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Cohere/miracl-sw-corpus-22-12","creator_name":"Cohere","creator_url":"https://huggingface.co/Cohere","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tMIRACL (sw) embedded with cohere.ai multilingual-22-12 encoder\\n\\t\\n\\nWe encoded the MIRACL dataset using the cohere.ai multilingual-22-12 embedding model.\\nThe query embeddings can be found in Cohere/miracl-sw-queries-22-12 and the corpus embeddings can be found in Cohere/miracl-sw-corpus-22-12.\\nFor the orginal datasets, see miracl/miracl and miracl/miracl-corpus.\\nDataset info:\\n\\nMIRACL üåçüôåüåè (Multilingual Information Retrieval Across a Continuum of Languages) is a multilingual‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Cohere/miracl-sw-corpus-22-12.","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","expert-generated","multilingual","Swahili"],"keywords_longer_than_N":true},
	{"name":"pwesuite-eval","keyword":"swahili","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/zouharvi/pwesuite-eval","creator_name":"Vil√©m Zouhar","creator_url":"https://huggingface.co/zouharvi","description":"\\n\\n\\t\\n\\t\\t\\n\\t\\tPWESuite-Eval\\n\\t\\n\\nDataset composed of multiple smaller datasets used for the evaluation of phonetic word embeddings.\\nSee code for evaluation here.\\nIf you use this dataset/evaluation, please cite the paper at LREC-COLING 2024:\\n@inproceedings{zouhar-etal-2024-pwesuite,\\n    title = \\\"{PWES}uite: Phonetic Word Embeddings and Tasks They Facilitate\\\",\\n    author = \\\"Zouhar, Vil{\\\\'e}m  and\\n      Chang, Kalvin  and\\n      Cui, Chenxuan  and\\n      Carlson, Nate B.  and\\n      Robinson, Nathaniel‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/zouharvi/pwesuite-eval.","first_N":5,"first_N_keywords":["multilingual","English","Amharic","Bengali","Swahili"],"keywords_longer_than_N":true},
	{"name":"masakhanews","keyword":"swahili","license":"Academic Free License v3.0","license_url":"https://choosealicense.com/licenses/afl-3.0/","language":"en","dataset_url":"https://huggingface.co/datasets/masakhane/masakhanews","creator_name":"Masakhane NLP","creator_url":"https://huggingface.co/masakhane","description":"MasakhaNEWS is the largest publicly available dataset for news topic classification in 16 languages widely spoken in Africa.\\n\\nThe languages are:\\n- Amharic (amh)\\n- English (eng)\\n- French (fra)\\n- Hausa (hau)\\n- Igbo (ibo)\\n- Lingala (lin)\\n- Luganda (lug)\\n- Oromo (orm)\\n- Nigerian Pidgin (pcm)\\n- Rundi (run)\\n- chShona (sna)\\n- Somali (som)\\n- Kiswahili (swƒÖ)\\n- Tigrinya (tir)\\n- isiXhosa (xho)\\n- Yor√πb√° (yor)\\n\\nThe train/validation/test sets are available for all the 16 languages.\\n\\nFor more details see *** arXiv link **","first_N":5,"first_N_keywords":["text-classification","topic-classification","expert-generated","expert-generated","multilingual"],"keywords_longer_than_N":true},
	{"name":"afriqa","keyword":"swahili","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/masakhane/afriqa","creator_name":"Masakhane NLP","creator_url":"https://huggingface.co/masakhane","description":"AfriQA: Cross-lingual Open-Retrieval Question Answering for African Languages\\n\\nAfriQA is the first cross-lingual question answering (QA) dataset with a focus on African languages. \\nThe dataset includes over 12,000 XOR QA examples across 10 African languages, making it an invaluable resource for developing more equitable QA technology.","first_N":5,"first_N_keywords":["question-answering","multilingual","Bemba (Zambia)","Fon","Hausa"],"keywords_longer_than_N":true},
	{"name":"multi-figqa","keyword":"swahili","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/cmu-lti/multi-figqa","creator_name":"CMU-LTI","creator_url":"https://huggingface.co/cmu-lti","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for multi-figqa\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nA multilingual dataset of human-written creative figurative expressions in many languages (mostly metaphors and similes). The English version (with the same format) can be found here\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages\\n\\t\\n\\nLanguages included are Hindi, Indonesian, Javanese, Kannada, Sundanese, Swahili, and Yoruba. The language codes are respectively hi, id, kn, su, sw, and yo.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Structure\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/cmu-lti/multi-figqa.","first_N":5,"first_N_keywords":["question-answering","Hindi","Indonesian","Sundanese","Javanese"],"keywords_longer_than_N":true},
	{"name":"flores_101","keyword":"swahili","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/severo/flores_101","creator_name":"Sylvain Lesage","creator_url":"https://huggingface.co/severo","description":"One of the biggest challenges hindering progress in low-resource and multilingual machine translation is the \\nlack of good evaluation benchmarks. Current evaluation benchmarks either lack good coverage of low-resource \\nlanguages, consider only restricted domains, or are low quality because they are constructed using \\nsemi-automatic procedures. In this work, we introduce the FLORES evaluation benchmark, consisting of 3001 \\nsentences extracted from English Wikipedia and covering a variety of different topics and domains. \\nThese sentences have been translated in 101 languages by professional translators through a carefully \\ncontrolled process. The resulting dataset enables better assessment of model quality on the long tail of \\nlow-resource languages, including the evaluation of many-to-many multilingual translation systems, as all \\ntranslations are multilingually aligned. By publicly releasing such a high-quality and high-coverage dataset, \\nwe hope to foster progress in the machine translation community and beyond.","first_N":5,"first_N_keywords":["text-generation","translation","found","expert-generated","multilingual"],"keywords_longer_than_N":true},
	{"name":"all-scam-spam","keyword":"swahili","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/FredZhang7/all-scam-spam","creator_name":"Fred Zhang","creator_url":"https://huggingface.co/FredZhang7","description":"This is a large corpus of 42,619 preprocessed text messages and emails sent by humans in 43 languages. is_spam=1 means spam and is_spam=0 means ham.\\n1040 rows of balanced data, consisting of casual conversations and scam emails in ‚âà10 languages, were manually collected and annotated by me, with some help from ChatGPT.\\n\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSome preprcoessing algorithms\\n\\t\\n\\n\\nspam_assassin.js, followed by spam_assassin.py\\nenron_spam.py\\n\\n\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData composition\\n\\t\\n\\n\\n\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDescription\\n\\t\\n\\nTo‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/FredZhang7/all-scam-spam.","first_N":5,"first_N_keywords":["text-classification","zero-shot-classification","Norwegian","Spanish","Somali"],"keywords_longer_than_N":true},
	{"name":"xP3x-sample","keyword":"swahili","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Muennighoff/xP3x-sample","creator_name":"Niklas Muennighoff","creator_url":"https://huggingface.co/Muennighoff","description":"A multilingual collection of Winograd Schemas in six languages that can be used for evaluation of cross-lingual commonsense reasoning capabilities.","first_N":5,"first_N_keywords":["other","expert-generated","crowdsourced","multilingual","Afrikaans"],"keywords_longer_than_N":true},
	{"name":"xP3x-sample","keyword":"swahili (individual language)","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Muennighoff/xP3x-sample","creator_name":"Niklas Muennighoff","creator_url":"https://huggingface.co/Muennighoff","description":"A multilingual collection of Winograd Schemas in six languages that can be used for evaluation of cross-lingual commonsense reasoning capabilities.","first_N":5,"first_N_keywords":["other","expert-generated","crowdsourced","multilingual","Afrikaans"],"keywords_longer_than_N":true},
	{"name":"malicious-website-features-2.4M","keyword":"swahili","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/FredZhang7/malicious-website-features-2.4M","creator_name":"Fred Zhang","creator_url":"https://huggingface.co/FredZhang7","description":"Important Notice:\\n\\nA subset of the URL dataset is from Kaggle, and the Kaggle datasets contained 10%-15% mislabelled data. See this dicussion I opened for some false positives. I have contacted Kaggle regarding their erroneous \\\"Usability\\\" score calculation for these unreliable datasets.\\nThe feature extraction methods shown here are not robust at all in 2023, and there're even silly mistakes in 3 functions: not_indexed_by_google, domain_registration_length, and age_of_domain.\\n\\n\\n\\nThe features‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/FredZhang7/malicious-website-features-2.4M.","first_N":5,"first_N_keywords":["text-classification","feature-extraction","tabular-classification","Norwegian","Afrikaans"],"keywords_longer_than_N":true},
	{"name":"QAmeleon","keyword":"swahili","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/imvladikon/QAmeleon","creator_name":"Vladimir Gurevich","creator_url":"https://huggingface.co/imvladikon","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for \\\"QAmeleon\\\"\\n\\t\\n\\nQAmeleon introduces synthetic multilingual QA data contaning in 8 langauges using PaLM-540B, a large language model. This dataset was generated by prompt tuning PaLM with only five examples per language. We use the synthetic data to finetune downstream QA models leading to improved accuracy in comparison to English-only and translation-based baselines. \\nData available at https://storage.googleapis.com/qameleon/qamelon_pt_accepted.csv \\nMore details can‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/imvladikon/QAmeleon.","first_N":5,"first_N_keywords":["question-answering","Arabic","Bengali","Finnish","Indonesian"],"keywords_longer_than_N":true},
	{"name":"wikianc","keyword":"swahili","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/cyanic-selkie/wikianc","creator_name":"cyanic-selkie","creator_url":"https://huggingface.co/cyanic-selkie","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for WikiAnc\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThe WikiAnc dataset is an automatically generated dataset from Wikipedia (all languages) and Wikidata dumps (August, 2023). \\nThe code for generating the dataset can be found here.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSupported Tasks\\n\\t\\n\\n\\nwikificiation: The dataset can be used to train a model for Wikification.\\nnamed-entity-linking: The dataset can be used to train a model for Named Entity Linking.\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages\\n\\t\\n\\nThe text in the dataset is‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/cyanic-selkie/wikianc.","first_N":5,"first_N_keywords":["token-classification","machine-generated","crowdsourced","machine-generated","crowdsourced"],"keywords_longer_than_N":true},
	{"name":"entity_cs","keyword":"swahili","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/huawei-noah/entity_cs","creator_name":"HUAWEI Noah's Ark Lab","creator_url":"https://huggingface.co/huawei-noah","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for EntityCS\\n\\t\\n\\n\\nRepository: https://github.com/huawei-noah/noah-research/tree/master/NLP/EntityCS  \\nPaper: https://aclanthology.org/2022.findings-emnlp.499.pdf  \\nPoint of Contact: Fenia Christopoulou, Chenxi Whitehouse\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nWe use the English Wikipedia and leverage entity information from Wikidata to construct an entity-based Code Switching corpus. \\nTo achieve this, we make use of wikilinks in Wikipedia, i.e. links from one page to‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/huawei-noah/entity_cs.","first_N":5,"first_N_keywords":["Afrikaans","Amharic","Arabic","Assamese","Azerbaijani"],"keywords_longer_than_N":true},
	{"name":"offensive-swahili-text","keyword":"swahili","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/metabloit/offensive-swahili-text","creator_name":"Moses Minja","creator_url":"https://huggingface.co/metabloit","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tOverview\\n\\t\\n\\nThis dataset contains offensive and non-offensive sentences. The data was scraped from JamiiForums using a prepared wordlist.\\nThe dataset contains sentences that consists of swahili abusive words (in the wordlist) but does not contain sarcastic abuse.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset details\\n\\t\\n\\nThe dataset is divided into train, evaluation and test datasets. The training dataset consists of 4954 sentences, evaluation dataset\\nconsists of 990 sentences and the test dataset consists of‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/metabloit/offensive-swahili-text.","first_N":5,"first_N_keywords":["text-classification","Swahili","mit","1K - 10K","csv"],"keywords_longer_than_N":true},
	{"name":"MultiJail","keyword":"swahili","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/DAMO-NLP-SG/MultiJail","creator_name":"Language Technology Lab at Alibaba DAMO Academy","creator_url":"https://huggingface.co/DAMO-NLP-SG","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tMultilingual Jailbreak Challenges in Large Language Models\\n\\t\\n\\nThis repo contains the data for our paper \\\"Multilingual Jailbreak Challenges in Large Language Models\\\".\\n[Github repo]\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tAnnotation Statistics\\n\\t\\n\\nWe collected a total of 315 English unsafe prompts and annotated them into nine non-English languages. The languages were categorized based on resource availability, as shown below:\\nHigh-resource languages: Chinese (zh), Italian (it), Vietnamese (vi)\\nMedium-resource‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/DAMO-NLP-SG/MultiJail.","first_N":5,"first_N_keywords":["English","Chinese","Italian","Vietnamese","Arabic"],"keywords_longer_than_N":true},
	{"name":"MSVAMP","keyword":"swahili","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Mathoctopus/MSVAMP","creator_name":"Mathoctopus","creator_url":"https://huggingface.co/Mathoctopus","description":"Mathoctopus/MSVAMP dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["text-generation","Bengali","Chinese","English","French"],"keywords_longer_than_N":true},
	{"name":"udhr-lid","keyword":"swahili (individual language)","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/cis-lmu/udhr-lid","creator_name":"CIS, LMU Munich","creator_url":"https://huggingface.co/cis-lmu","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tUDHR-LID\\n\\t\\n\\nWhy UDHR-LID?\\nYou can access UDHR (Universal Declaration of Human Rights) here, but when a verse is missing, they have texts such as \\\"missing\\\" or \\\"?\\\". Also, about 1/3 of the sentences consist only of \\\"articles 1-30\\\" in different languages. We cleaned the entire dataset from XML files and selected only the paragraphs. We cleared any unrelated language texts from the data and also removed the cases that were incorrect.\\nIncorrect? Look at the ckb and kmr files in the UDHR.‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/cis-lmu/udhr-lid.","first_N":5,"first_N_keywords":["multilingual","Tigrinya","Balkan Romani","Standard Arabic","Metlat√≥noc Mixtec"],"keywords_longer_than_N":true},
	{"name":"seamless-align","keyword":"swahili","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/jhu-clsp/seamless-align","creator_name":"Center for Language and Speech Processing @ JHU","creator_url":"https://huggingface.co/jhu-clsp","description":"\\n\\t\\n\\t\\t\\n\\t\\tDataset Card for Seamless-Align (WIP). Inspired by https://huggingface.co/datasets/allenai/nllb\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThis dataset was created based on metadata for mined Speech-to-Speech(S2S), Text-to-Speech(TTS) and Speech-to-Text(S2T) released by Meta AI.  The S2S contains data for 35 language pairs. The S2S dataset is ~1000GB compressed.\\n\\n\\t\\n\\t\\t\\n\\t\\tHow to use the data\\n\\t\\n\\nThere are two ways to access the data:\\n\\nVia the Hugging Face Python datasets library\\n\\nScripts coming soon‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/jhu-clsp/seamless-align.","first_N":5,"first_N_keywords":["translation","audio-to-audio","Maltese","English","Welsh"],"keywords_longer_than_N":true},
	{"name":"lr-sum","keyword":"swahili","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/bltlab/lr-sum","creator_name":"Broadening Linguistic Technologies Lab (BLT Lab)","creator_url":"https://huggingface.co/bltlab","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for LR-Sum\\n\\t\\n\\nLR-Sum is a automatic summarization dataset of newswire text with a focus on less resourced languages with a cc-by 4.0 license.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Details\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nLR-Sum is a permissively-licensed dataset created with the goal of enabling further research in automatic summarization for less-resourced languages.\\nLR-Sum contains human-written summaries for 39 languages, many of which are less-resourced. \\nThe data is based on‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/bltlab/lr-sum.","first_N":5,"first_N_keywords":["summarization","text-generation","found","found","multilingual"],"keywords_longer_than_N":true},
	{"name":"Pontoon-Translations","keyword":"swahili","license":"Mozilla Public License 2.0","license_url":"https://choosealicense.com/licenses/mpl-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ayymen/Pontoon-Translations","creator_name":"Mohamed Aymane Farhi","creator_url":"https://huggingface.co/ayymen","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Pontoon Translations\\n\\t\\n\\n\\n\\nThis is a dataset containing strings from various Mozilla projects on Mozilla's Pontoon localization platform and their translations into more than 200 languages.\\nSource strings are in English.\\nTo avoid rows with values like \\\"None\\\" and \\\"N/A\\\" being interpreted as missing values, pass the keep_default_na parameter like this:\\nfrom datasets import load_dataset\\n\\ndataset = load_dataset(\\\"ayymen/Pontoon-Translations\\\", keep_default_na=False)‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ayymen/Pontoon-Translations.","first_N":5,"first_N_keywords":["translation","text2text-generation","crowdsourced","Abkhaz","Achinese"],"keywords_longer_than_N":true},
	{"name":"SwahiliAlpaca","keyword":"swahili","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mwitiderrick/SwahiliAlpaca","creator_name":"Derrick Mwiti","creator_url":"https://huggingface.co/mwitiderrick","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for \\\"SwahiliAlpaca\\\"\\n\\t\\n\\nAlpaca dataset for instruction fine-tuning in Swahili.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tPrompt Template\\n\\t\\n\\n### Maelekezo:\\\\n{instruction} ### Agizo:\\\\n{input} ### Jibu:\\\\n{output}\\n\\n","first_N":5,"first_N_keywords":["text-generation","Swahili","apache-2.0","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"SwahiliPlatypus","keyword":"swahili","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mwitiderrick/SwahiliPlatypus","creator_name":"Derrick Mwiti","creator_url":"https://huggingface.co/mwitiderrick","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for \\\"SwahiliPlatypus\\\"\\n\\t\\n\\nOpen-Platypus translated to Swahili.\\n","first_N":5,"first_N_keywords":["text-generation","Swahili","apache-2.0","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"kitabucorpus","keyword":"swahili","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mwitiderrick/kitabucorpus","creator_name":"Derrick Mwiti","creator_url":"https://huggingface.co/mwitiderrick","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for \\\"kitabucorpus\\\"\\n\\t\\n\\nBookcorpus in Swahili\\n","first_N":5,"first_N_keywords":["text-generation","Swahili","apache-2.0","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"language_tags","keyword":"swahili (individual language)","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/lbourdois/language_tags","creator_name":"Lo√Øck BOURDOIS","creator_url":"https://huggingface.co/lbourdois","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDescription\\n\\t\\n\\nDataset listing 27,328 languages and dialects (also includes macrolanguage names).For each language, either the ISO 639 code, the Glottolog code or both are provided.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tColumns\\n\\t\\n\\n\\nEnglish_Name: Language name in English (e.g. \\\"French\\\").\\nNative_Name: If value is not 0, corresponds to the name of the language by native speakers (e.g. \\\"Fran√ßais\\\") which may have been found in Wikipedia's nativename field.\\nGlottocode: The language tag in the Glottolog convention‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/lbourdois/language_tags.","first_N":5,"first_N_keywords":["Afade","Par√° Ar√°ra","Afar","Aka-Bea","Abon"],"keywords_longer_than_N":true},
	{"name":"language_tags","keyword":"swahili (macrolanguage)","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/lbourdois/language_tags","creator_name":"Lo√Øck BOURDOIS","creator_url":"https://huggingface.co/lbourdois","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDescription\\n\\t\\n\\nDataset listing 27,328 languages and dialects (also includes macrolanguage names).For each language, either the ISO 639 code, the Glottolog code or both are provided.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tColumns\\n\\t\\n\\n\\nEnglish_Name: Language name in English (e.g. \\\"French\\\").\\nNative_Name: If value is not 0, corresponds to the name of the language by native speakers (e.g. \\\"Fran√ßais\\\") which may have been found in Wikipedia's nativename field.\\nGlottocode: The language tag in the Glottolog convention‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/lbourdois/language_tags.","first_N":5,"first_N_keywords":["Afade","Par√° Ar√°ra","Afar","Aka-Bea","Abon"],"keywords_longer_than_N":true},
	{"name":"Deltacorpus_1.1","keyword":"swahili","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/FrancophonIA/Deltacorpus_1.1","creator_name":"FrancophonIA","creator_url":"https://huggingface.co/FrancophonIA","description":"\\nDataset origin: https://lindat.cz/repository/xmlui/handle/11234/1-1743\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDescription\\n\\t\\n\\nTexts in 107 languages from the W2C corpus (http://hdl.handle.net/11858/00-097C-0000-0022-6133-9), first 1,000,000 tokens per language, tagged by the delexicalized tagger described in Yu et al. (2016, LREC, Portoro≈æ, Slovenia).\\nChanges in version 1.1: \\n\\nUniversal Dependencies tagset instead of the older and smaller Google Universal POS tagset. \\n\\nSVM classifier trained on Universal Dependencies‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/FrancophonIA/Deltacorpus_1.1.","first_N":5,"first_N_keywords":["token-classification","multilingual","Afrikaans","Albanian","Amharic"],"keywords_longer_than_N":true},
	{"name":"MM-Eval","keyword":"swahili","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/prometheus-eval/MM-Eval","creator_name":"prometheus-eval","creator_url":"https://huggingface.co/prometheus-eval","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tMultilingual Meta-EVALuation benchmark (MM-Eval)\\n\\t\\n\\n\\nüë®‚ÄçüíªCode\\n|\\nüìÑPaper\\n|\\nü§ó MMQA\\n\\n\\nMM-Eval is a multilingual meta-evaluation benchmark consisting of five core subsets‚ÄîChat, Reasoning, Safety, Language Hallucination, and Linguistics‚Äîspanning 18 languages and a Language Resource subset spanning 122 languages for a broader analysis of language effects. \\n\\nDesign ChoiceIn this work, we minimize the inclusion of translated samples, as mere translation may alter existing preferences due‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/prometheus-eval/MM-Eval.","first_N":5,"first_N_keywords":["Arabic","Bengali","Catalan","German","English"],"keywords_longer_than_N":true},
	{"name":"MMMLU","keyword":"swahili","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/bzantium/MMMLU","creator_name":"Minho Ryu","creator_url":"https://huggingface.co/bzantium","description":"\\n\\t\\n\\t\\t\\n\\t\\tMultilingual Massive Multitask Language Understanding (MMMLU)\\n\\t\\n\\nThe MMLU is a widely recognized benchmark of general knowledge attained by AI models. It covers a broad range of topics from 57 different categories, covering elementary-level knowledge up to advanced professional subjects like law, physics, history, and computer science.\\nWe translated the MMLU‚Äôs test set into 14 languages using professional human translators. Relying on human translators for this evaluation increases‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/bzantium/MMMLU.","first_N":5,"first_N_keywords":["question-answering","Arabic","Bengali","German","Spanish"],"keywords_longer_than_N":true},
	{"name":"swahili-normalized-corpus","keyword":"swahili","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Benjamin-png/swahili-normalized-corpus","creator_name":"BENJAMIN MASHIMBA","creator_url":"https://huggingface.co/Benjamin-png","description":"\\n\\t\\n\\t\\t\\n\\t\\tSwahili Normalized Text Corpus\\n\\t\\n\\n\\nPreserved punctuation and special characters\\nNormalized numbers to Swahili words\\nCleaned formatting while maintaining original text structure\\n\\n","first_N":5,"first_N_keywords":["Swahili","mit","10M - 100M","parquet","Text"],"keywords_longer_than_N":true},
	{"name":"swahili-normalized-corpus","keyword":"swahili","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Benjamin-png/swahili-normalized-corpus","creator_name":"BENJAMIN MASHIMBA","creator_url":"https://huggingface.co/Benjamin-png","description":"\\n\\t\\n\\t\\t\\n\\t\\tSwahili Normalized Text Corpus\\n\\t\\n\\n\\nPreserved punctuation and special characters\\nNormalized numbers to Swahili words\\nCleaned formatting while maintaining original text structure\\n\\n","first_N":5,"first_N_keywords":["Swahili","mit","10M - 100M","parquet","Text"],"keywords_longer_than_N":true},
	{"name":"BenchMAX_Rule-based","keyword":"swahili","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/LLaMAX/BenchMAX_Rule-based","creator_name":"LLaMAX","creator_url":"https://huggingface.co/LLaMAX","description":"\\n\\t\\n\\t\\t\\n\\t\\tDataset Sources\\n\\t\\n\\n\\nPaper: BenchMAX: A Comprehensive Multilingual Evaluation Suite for Large Language Models\\nLink: https://arxiv.org/pdf/2502.07346\\nRepository: https://github.com/CONE-MT/BenchMAX\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\nBenchMAX_Rule-based is a dataset of BenchMAX, sourcing from IFEval, which is a rule-based benchmark for evaluating the instruction following capabilities.\\nWe extend the original dataset to 16 non-English languages by first translating and then manual‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/LLaMAX/BenchMAX_Rule-based.","first_N":5,"first_N_keywords":["text-generation","multilingual","English","Chinese","Spanish"],"keywords_longer_than_N":true},
	{"name":"BenchMAX_Model-based","keyword":"swahili","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/LLaMAX/BenchMAX_Model-based","creator_name":"LLaMAX","creator_url":"https://huggingface.co/LLaMAX","description":"\\n\\t\\n\\t\\t\\n\\t\\tDataset Sources\\n\\t\\n\\n\\nPaper: BenchMAX: A Comprehensive Multilingual Evaluation Suite for Large Language Models\\nLink: https://arxiv.org/pdf/2502.07346\\nRepository: https://github.com/CONE-MT/BenchMAX\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\nBenchMAX_Model-based is a dataset of BenchMAX, sourcing from m-ArenaHard.\\nWe extend the original English dataset to 16 non-English languages by first translating and then manual post-editing.\\n\\n\\t\\n\\t\\t\\n\\t\\tSupported Languages\\n\\t\\n\\nArabic, Bengali, Chinese, Czech‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/LLaMAX/BenchMAX_Model-based.","first_N":5,"first_N_keywords":["text-generation","multilingual","English","Chinese","Spanish"],"keywords_longer_than_N":true},
	{"name":"BenchMAX_Multiple_Functions","keyword":"swahili","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/LLaMAX/BenchMAX_Multiple_Functions","creator_name":"LLaMAX","creator_url":"https://huggingface.co/LLaMAX","description":"\\n\\t\\n\\t\\t\\n\\t\\tDataset Sources\\n\\t\\n\\n\\nPaper: BenchMAX: A Comprehensive Multilingual Evaluation Suite for Large Language Models\\nLink: https://arxiv.org/pdf/2502.07346\\nRepository: https://github.com/CONE-MT/BenchMAX\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\nBenchMAX_Multiple_Functions is a dataset of BenchMAX, sourcing from Nexus.\\nWe translate the standardized queries from English to 16 non-English languages by google Translate.\\nSome special function arguments remain English since the APIs are in English.\\nAll‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/LLaMAX/BenchMAX_Multiple_Functions.","first_N":5,"first_N_keywords":["text-generation","multilingual","English","Chinese","Spanish"],"keywords_longer_than_N":true},
	{"name":"BenchMAX_General_Translation","keyword":"swahili","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/LLaMAX/BenchMAX_General_Translation","creator_name":"LLaMAX","creator_url":"https://huggingface.co/LLaMAX","description":"\\n\\t\\n\\t\\t\\n\\t\\tDataset Sources\\n\\t\\n\\n\\nPaper: BenchMAX: A Comprehensive Multilingual Evaluation Suite for Large Language Models\\nLink: https://arxiv.org/pdf/2502.07346\\nRepository: https://github.com/CONE-MT/BenchMAX\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\nBenchMAX_General_Translation is a dataset of BenchMAX.\\nWe collect parallel test data from Flore-200, TED-talk, and WMT24.\\n\\n\\t\\n\\t\\t\\n\\t\\tSupported Languages\\n\\t\\n\\nArabic, Bengali, Chinese, Czech, English, French, German, Hungarian, Japanese, Korean, Serbian, Spanish‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/LLaMAX/BenchMAX_General_Translation.","first_N":5,"first_N_keywords":["text-generation","multilingual","English","Chinese","Spanish"],"keywords_longer_than_N":true},
	{"name":"BenchMAX_Domain_Translation","keyword":"swahili","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/LLaMAX/BenchMAX_Domain_Translation","creator_name":"LLaMAX","creator_url":"https://huggingface.co/LLaMAX","description":"\\n\\t\\n\\t\\t\\n\\t\\tDataset Sources\\n\\t\\n\\n\\nPaper: BenchMAX: A Comprehensive Multilingual Evaluation Suite for Large Language Models\\nLink: https://arxiv.org/pdf/2502.07346\\nRepository: https://github.com/CONE-MT/BenchMAX\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\nBenchMAX_Domain_Translation is a dataset of BenchMAX.\\nWe collect the domain parallel data from other tasks in BenchMAX.\\nEach sample contains one or three human-annotated translations.\\n\\n\\t\\n\\t\\t\\n\\t\\tSupported Languages\\n\\t\\n\\nArabic, Bengali, Chinese, Czech, English‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/LLaMAX/BenchMAX_Domain_Translation.","first_N":5,"first_N_keywords":["text-generation","multilingual","English","Chinese","Spanish"],"keywords_longer_than_N":true},
	{"name":"V1Q","keyword":"swahili","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/YuRiVeRTi/V1Q","creator_name":"YuRiVeRTical","creator_url":"https://huggingface.co/YuRiVeRTi","description":"from datasets import load_dataset\\nds = load_dataset(\\\"b3x0m/Chinese-H-Novels\\\")\\nimport sagemaker\\nimport boto3\\nfrom sagemaker.huggingface import HuggingFaceModel\\ntry:\\n    role = sagemaker.get_execution_role()\\nexcept ValueError:\\n    iam = boto3.client('iam')\\n    role = iam.get_role(RoleName='sagemaker_execution_role')['Role']['Arn']\\n\\n\\t\\n\\t\\t\\n\\t\\tHub Model configuration. https://huggingface.co/models\\n\\t\\n\\nhub = {\\n    'HF_MODEL_ID':'deepseek-ai/Janus-Pro-7B',\\n    'HF_TASK':'any-to-any'\\n}\\n\\n\\t\\n\\t\\t\\n\\t\\tcreate‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/YuRiVeRTi/V1Q.","first_N":5,"first_N_keywords":["text-classification","token-classification","table-question-answering","question-answering","zero-shot-classification"],"keywords_longer_than_N":true},
	{"name":"multilingual_translation_gen_binarized","keyword":"swahili","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Youseff1987/multilingual_translation_gen_binarized","creator_name":"JOON HYOUNG JUN","creator_url":"https://huggingface.co/Youseff1987","description":"Youseff1987/multilingual_translation_gen_binarized dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["translation","Korean","English","Chinese","Zulu"],"keywords_longer_than_N":true},
	{"name":"gsm8k-translated","keyword":"swahili","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Sara237/gsm8k-translated","creator_name":"Sara Rajaee","creator_url":"https://huggingface.co/Sara237","description":"Sara237/gsm8k-translated dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["text2text-generation","English","German","Spanish","French"],"keywords_longer_than_N":true},
	{"name":"HPLT2.0_cleaned","keyword":"swahili (individual language)","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/jobs-git/HPLT2.0_cleaned","creator_name":"James Guana","creator_url":"https://huggingface.co/jobs-git","description":"This is a large-scale collection of web-crawled documents in 191 world languages, produced by the HPLT project. \\nThe source of the data is mostly Internet Archive with some additions from Common Crawl.\\nFor a detailed description of the dataset, please refer to https://hplt-project.org/datasets/v2.0\\nThe Cleaned variant of HPLT Datasets v2.0\\nThis is the cleaned variant of the HPLT Datasets v2.0 converted to the Parquet format semi-automatically when being uploaded here. \\nThe original JSONL files‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/jobs-git/HPLT2.0_cleaned.","first_N":5,"first_N_keywords":["fill-mask","text-generation","language-modeling","multilingual","Achinese"],"keywords_longer_than_N":true}
]
;
