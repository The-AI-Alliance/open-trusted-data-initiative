const data_for_language_africa_hausa = 
[
	{"name":"TinyDS-20k","keyword":"hausa","description":"\n\t\n\t\t\n\t\tTinyDS\n\t\n\n\n\n\nAlpaca-style dataset with around 20k samples scraped from Qwen3-8B using SyntheticAlpaca. Q&A pairs can be in 32 different languages, these are listed in the metadata.Topics are all around STEM, programming, and literature.  \nMIT @ 2025 Hamzah Asadullah\n\n\n","url":"https://huggingface.co/datasets/Hamzah-Asadullah/TinyDS-20k","creator_name":"Hamzah Asadullah","creator_url":"https://huggingface.co/Hamzah-Asadullah","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["question-answering","translation","text-generation","text2text-generation","English"],"keywords_longer_than_N":true},
	{"name":"allenai_tulu-3-sft-mixture-DolphinLabeled","keyword":"hausa","description":"\n\t\n\t\t\n\t\tallenai tulu-3-sft-mixture DolphinLabeled\n\t\n\n\n\t\n\t\t\n\t\tPart of the DolphinLabeled series of datasets\n\t\n\n\n\t\n\t\t\n\t\tPresented by Eric Hartford and Cognitive Computations\n\t\n\nThe purpose of this dataset is to enable filtering of allenai/tulu-3-sft-mixture dataset.\nThe original dataset is allenai/tulu-3-sft-mixture\nI have modified the dataset using two scripts.\n\ndedupe.py - removes rows with identical final message content\nlabel.py - adds a \"flags\" column containing the following boolean‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/QuixiAI/allenai_tulu-3-sft-mixture-DolphinLabeled.","url":"https://huggingface.co/datasets/QuixiAI/allenai_tulu-3-sft-mixture-DolphinLabeled","creator_name":"Quixi AI","creator_url":"https://huggingface.co/QuixiAI","license_name":"Open Data Commons Attribution License v1.0","license_url":"https://scancode-licensedb.aboutcode.org/odc-by-1.0.html","language":"en","first_N":5,"first_N_keywords":["other","crowdsourced","expert-generated","machine-generated","multilingual"],"keywords_longer_than_N":true},
	{"name":"tulu-3-sft-mixture","keyword":"hausa","description":"\n\n\n\t\n\t\t\n\t\tTulu 3 SFT Mixture\n\t\n\nNote that this collection is licensed under ODC-BY-1.0 license; different licenses apply to subsets of the data. Some portions of the dataset are non-commercial. We present the mixture as a research artifact.\nThe Tulu 3 SFT mixture was used to train the Tulu 3 series of models.\nIt contains 939,344 samples from the following sets:\n\nCoCoNot (ODC-BY-1.0), 10,983 prompts (Brahman et al., 2024)\nFLAN v2 via ai2-adapt-dev/flan_v2_converted, 89,982 prompts (Longpre et‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/allenai/tulu-3-sft-mixture.","url":"https://huggingface.co/datasets/allenai/tulu-3-sft-mixture","creator_name":"Ai2","creator_url":"https://huggingface.co/allenai","license_name":"Open Data Commons Attribution License v1.0","license_url":"https://scancode-licensedb.aboutcode.org/odc-by-1.0.html","language":"en","first_N":5,"first_N_keywords":["other","crowdsourced","expert-generated","machine-generated","multilingual"],"keywords_longer_than_N":true},
	{"name":"hausa-english-medical-translation","keyword":"hausa","description":"\n\t\n\t\t\n\t\tHausa-English Medical Translation Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset contains 15,019 parallel English-Hausa sentence pairs specifically curated for medical and healthcare translation tasks. It's designed to support machine translation research for the Hausa language in the medical domain.\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\n\nLanguage pair: English ‚Üî Hausa\nDomain: Medical/Healthcare\nSize: 15,019 sentence pairs\nSplit: 90% train, 10% validation\nGenerated: 2025-10-02‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Abduull6771/hausa-english-medical-translation.","url":"https://huggingface.co/datasets/Abduull6771/hausa-english-medical-translation","creator_name":"Abdullahi Ahmad ","creator_url":"https://huggingface.co/Abduull6771","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["translation","translation","original","English","Hausa"],"keywords_longer_than_N":true},
	{"name":"hausa-english-medical-translation","keyword":"hausa","description":"\n\t\n\t\t\n\t\tHausa-English Medical Translation Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset contains 15,019 parallel English-Hausa sentence pairs specifically curated for medical and healthcare translation tasks. It's designed to support machine translation research for the Hausa language in the medical domain.\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\n\nLanguage pair: English ‚Üî Hausa\nDomain: Medical/Healthcare\nSize: 15,019 sentence pairs\nSplit: 90% train, 10% validation\nGenerated: 2025-10-02‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Abduull6771/hausa-english-medical-translation.","url":"https://huggingface.co/datasets/Abduull6771/hausa-english-medical-translation","creator_name":"Abdullahi Ahmad ","creator_url":"https://huggingface.co/Abduull6771","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["translation","translation","original","English","Hausa"],"keywords_longer_than_N":true},
	{"name":"ha-tts-csv","keyword":"hausa","description":"\n\t\n\t\t\n\t\tHausa TTS Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset contains Hausa language text-to-speech (TTS) recordings from multiple speakers. It includes audio files paired with their corresponding Hausa text transcriptions.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nThe dataset is organized as follows:\n‚îú‚îÄ‚îÄ data/\n‚îÇ   ‚îú‚îÄ‚îÄ metadata.csv                    # Metadata (source, audio paths, text)\n‚îÇ   ‚îî‚îÄ‚îÄ audio_files/\n‚îÇ       ‚îú‚îÄ‚îÄ 97f373e8-f6e6-.../          # Speaker 1 audio files\n‚îÇ       ‚îú‚îÄ‚îÄ‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Aybee5/ha-tts-csv.","url":"https://huggingface.co/datasets/Aybee5/ha-tts-csv","creator_name":"Ibrahim Abdullahi","creator_url":"https://huggingface.co/Aybee5","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-to-speech","audio-classification","Hausa","cc-by-4.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"ha-tts-csv","keyword":"hausa","description":"\n\t\n\t\t\n\t\tHausa TTS Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset contains Hausa language text-to-speech (TTS) recordings from multiple speakers. It includes audio files paired with their corresponding Hausa text transcriptions.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nThe dataset is organized as follows:\n‚îú‚îÄ‚îÄ data/\n‚îÇ   ‚îú‚îÄ‚îÄ metadata.csv                    # Metadata (source, audio paths, text)\n‚îÇ   ‚îî‚îÄ‚îÄ audio_files/\n‚îÇ       ‚îú‚îÄ‚îÄ 97f373e8-f6e6-.../          # Speaker 1 audio files\n‚îÇ       ‚îú‚îÄ‚îÄ‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Aybee5/ha-tts-csv.","url":"https://huggingface.co/datasets/Aybee5/ha-tts-csv","creator_name":"Ibrahim Abdullahi","creator_url":"https://huggingface.co/Aybee5","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-to-speech","audio-classification","Hausa","cc-by-4.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"hausa-tts-small","keyword":"hausa","description":"\n\t\n\t\t\n\t\tMimic Studio Hausa TTS Dataset\n\t\n\nThis dataset was created using Mimic Studio for training text-to-speech models.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\nTotal Samples: 62\nLanguage: Hausa\nSpeakers: 2 speakers (Surajo Nuhu Umar, Umar Musa Halliru)\nFormat: Compatible with Unsloth TTS models\nAudio Format: WAV files, 24kHz sampling rate\n\n\n\t\n\t\t\n\t\tSpeaker Distribution\n\t\n\nSurajo Nuhu Umar     32\nUmar Musa Halliru    30\n\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nAybee5/hausa-tts-small/\n‚îú‚îÄ‚îÄ data/\n‚îÇ   ‚îú‚îÄ‚îÄ train.parquet‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Aybee5/hausa-tts-small.","url":"https://huggingface.co/datasets/Aybee5/hausa-tts-small","creator_name":"Ibrahim Abdullahi","creator_url":"https://huggingface.co/Aybee5","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-to-speech","Hausa","mit","< 1K","parquet"],"keywords_longer_than_N":true},
	{"name":"hausa-tts-small","keyword":"hausa","description":"\n\t\n\t\t\n\t\tMimic Studio Hausa TTS Dataset\n\t\n\nThis dataset was created using Mimic Studio for training text-to-speech models.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\nTotal Samples: 62\nLanguage: Hausa\nSpeakers: 2 speakers (Surajo Nuhu Umar, Umar Musa Halliru)\nFormat: Compatible with Unsloth TTS models\nAudio Format: WAV files, 24kHz sampling rate\n\n\n\t\n\t\t\n\t\tSpeaker Distribution\n\t\n\nSurajo Nuhu Umar     32\nUmar Musa Halliru    30\n\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nAybee5/hausa-tts-small/\n‚îú‚îÄ‚îÄ data/\n‚îÇ   ‚îú‚îÄ‚îÄ train.parquet‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Aybee5/hausa-tts-small.","url":"https://huggingface.co/datasets/Aybee5/hausa-tts-small","creator_name":"Ibrahim Abdullahi","creator_url":"https://huggingface.co/Aybee5","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-to-speech","Hausa","mit","< 1K","parquet"],"keywords_longer_than_N":true},
	{"name":"c4","keyword":"hausa","description":"\n\t\n\t\t\n\t\tC4\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nA colossal, cleaned version of Common Crawl's web crawl corpus. Based on Common Crawl dataset: \"https://commoncrawl.org\".\nThis is the processed version of Google's C4 dataset\nWe prepared five variants of the data: en, en.noclean, en.noblocklist, realnewslike, and multilingual (mC4).\nFor reference, these are the sizes of the variants:\n\nen: 305GB\nen.noclean: 2.3TB\nen.noblocklist: 380GB\nrealnewslike: 15GB\nmultilingual (mC4): 9.7TB (108 subsets, one per‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/allenai/c4.","url":"https://huggingface.co/datasets/allenai/c4","creator_name":"Ai2","creator_url":"https://huggingface.co/allenai","license_name":"Open Data Commons Attribution License v1.0","license_url":"https://scancode-licensedb.aboutcode.org/odc-by-1.0.html","language":"en","first_N":5,"first_N_keywords":["text-generation","fill-mask","language-modeling","masked-language-modeling","no-annotation"],"keywords_longer_than_N":true},
	{"name":"afriberta-corpus","keyword":"hausa","description":"Corpus used for training AfriBERTa models","url":"https://huggingface.co/datasets/castorini/afriberta-corpus","creator_name":"Castorini","creator_url":"https://huggingface.co/castorini","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","language-modeling","Oromo","Amharic","Kinyarwanda"],"keywords_longer_than_N":true},
	{"name":"udhr-lid","keyword":"hausa","description":"\n\t\n\t\t\n\t\tUDHR-LID\n\t\n\nWhy UDHR-LID?\nYou can access UDHR (Universal Declaration of Human Rights) here, but when a verse is missing, they have texts such as \"missing\" or \"?\". Also, about 1/3 of the sentences consist only of \"articles 1-30\" in different languages. We cleaned the entire dataset from XML files and selected only the paragraphs. We cleared any unrelated language texts from the data and also removed the cases that were incorrect.\nIncorrect? Look at the ckb and kmr files in the UDHR.‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/cis-lmu/udhr-lid.","url":"https://huggingface.co/datasets/cis-lmu/udhr-lid","creator_name":"CIS, LMU Munich","creator_url":"https://huggingface.co/cis-lmu","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["multilingual","Tigrinya","Balkan Romani","Standard Arabic","Metlat√≥noc Mixtec"],"keywords_longer_than_N":true},
	{"name":"fleurs","keyword":"hausa","description":"\n\t\n\t\t\n\t\tFLEURS\n\t\n\nFleurs is the speech version of the FLoRes machine translation benchmark. \nWe use 2009 n-way parallel sentences from the FLoRes dev and devtest publicly available sets, in 102 languages. \nTraining sets have around 10 hours of supervision. Speakers of the train sets are different than speakers from the dev/test sets. Multilingual fine-tuning is\nused and ‚Äùunit error rate‚Äù (characters, signs) of all languages is averaged. Languages and results are also grouped into seven‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/google/fleurs.","url":"https://huggingface.co/datasets/google/fleurs","creator_name":"Google","creator_url":"https://huggingface.co/google","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":null,"first_N":5,"first_N_keywords":["automatic-speech-recognition","expert-generated","crowdsourced","machine-generated","crowdsourced"],"keywords_longer_than_N":true},
	{"name":"africlirmatrix","keyword":"hausa","description":"\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nAfriCLIRMatrix is a test collection for cross-lingual information retrieval research in 15 diverse African languages. This resource comprises English queries with query‚Äìdocument relevance judgments in 15 African languages automatically mined from Wikipedia\nThis dataset stores documents of AfriCLIRMatrix. To access the queries and judgments, please refer to castorini/africlirmatrix.\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Structure\n\t\n\nThe only configuration here is the language.\nAn‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/castorini/africlirmatrix.","url":"https://huggingface.co/datasets/castorini/africlirmatrix","creator_name":"Castorini","creator_url":"https://huggingface.co/castorini","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","multilingual","Afrikaans","Amharic","Egyptian Arabic"],"keywords_longer_than_N":true},
	{"name":"multi_para_crawl","keyword":"hausa","description":"Parallel corpora from Web Crawls collected in the ParaCrawl project and further processed for making it a multi-parallel corpus by pivoting via English. Here we only provide the additional language pairs that came out of pivoting. The bitexts for English are available from the ParaCrawl release.\n40 languages, 669 bitexts\ntotal number of files: 40\ntotal number of tokens: 10.14G\ntotal number of sentence fragments: 505.48M\n\nPlease, acknowledge the ParaCrawl project at http://paracrawl.eu. This version is derived from the original release at their website adjusted for redistribution via the OPUS corpus collection. Please, acknowledge OPUS as well for this service.","url":"https://huggingface.co/datasets/Helsinki-NLP/multi_para_crawl","creator_name":"Language Technology Research Group at the University of Helsinki","creator_url":"https://huggingface.co/Helsinki-NLP","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":null,"first_N":5,"first_N_keywords":["translation","found","found","multilingual","original"],"keywords_longer_than_N":true},
	{"name":"ml_spoken_words","keyword":"hausa","description":"Multilingual Spoken Words Corpus is a large and growing audio dataset of spoken\nwords in 50 languages collectively spoken by over 5 billion people, for academic\nresearch and commercial applications in keyword spotting and spoken term search,\nlicensed under CC-BY 4.0. The dataset contains more than 340,000 keywords,\ntotaling 23.4 million 1-second spoken examples (over 6,000 hours). The dataset\nhas many use cases, ranging from voice-enabled consumer devices to call center\nautomation. This dataset is generated by applying forced alignment on crowd-sourced sentence-level\naudio to produce per-word timing estimates for extraction.\nAll alignments are included in the dataset.","url":"https://huggingface.co/datasets/MLCommons/ml_spoken_words","creator_name":"MLCommons","creator_url":"https://huggingface.co/MLCommons","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":null,"first_N":5,"first_N_keywords":["audio-classification","machine-generated","other","multilingual","extended|common_voice"],"keywords_longer_than_N":true},
	{"name":"afrimmlu-translate-test","keyword":"hausa","description":"\n\t\n\t\t\n\t\tDataset Card for afrimmlu-translate-test\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nAFRIMMLU-TT is an evaluation dataset comprising translations of the AFRIMMLU dataset from 16 African languages and 1 high resource language into English using NLLB. \nIt includes test sets across all 17 languages. \n\n\t\n\t\t\n\t\tLanguages\n\t\n\nThere are 17 languages available :\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\n\t\n\t\t\n\t\tData Instances\n\t\n\nThe examples look like this for English:\nfrom datasets import load_dataset\ndata =‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/masakhane/afrimmlu-translate-test.","url":"https://huggingface.co/datasets/masakhane/afrimmlu-translate-test","creator_name":"Masakhane NLP","creator_url":"https://huggingface.co/masakhane","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","natural-language-inference","monolingual","afrimmlu","Amharic"],"keywords_longer_than_N":true},
	{"name":"xP3x","keyword":"hausa","description":"\n\t\n\t\t\n\t\tDataset Card for xP3x\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\n\nxP3x (Crosslingual Public Pool of Prompts eXtended) is a collection of prompts & datasets across 277 languages & 16 NLP tasks. It contains all of xP3 + much more! It is used for training future contenders of mT0 & BLOOMZ at project Aya @Cohere Labs üß°\n\n\nCreation: The dataset can be recreated using instructions available here together with the file in this repository named xp3x_create.py. We provide this version to save processing‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/CohereLabs/xP3x.","url":"https://huggingface.co/datasets/CohereLabs/xP3x","creator_name":"Cohere Labs","creator_url":"https://huggingface.co/CohereLabs","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["other","expert-generated","crowdsourced","multilingual","Afrikaans"],"keywords_longer_than_N":true},
	{"name":"bhojpuri","keyword":"hausa","description":"\n\t\n\t\t\n\t\n\t\n\t\tFLEURS\n\t\n\nFleurs is the speech version of the FLoRes machine translation benchmark. \nWe use 2009 n-way parallel sentences from the FLoRes dev and devtest publicly available sets, in 102 languages. \nTraining sets have around 10 hours of supervision. Speakers of the train sets are different than speakers from the dev/test sets. Multilingual fine-tuning is\nused and ‚Äùunit error rate‚Äù (characters, signs) of all languages is averaged. Languages and results are also grouped into seven‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ankur02/bhojpuri.","url":"https://huggingface.co/datasets/ankur02/bhojpuri","creator_name":"Ankur Verma","creator_url":"https://huggingface.co/ankur02","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","expert-generated","crowdsourced","machine-generated","crowdsourced"],"keywords_longer_than_N":true},
	{"name":"vox-communis-parallel-g2p","keyword":"hausa","description":"\n\t\n\t\t\n\t\tVoxCommunis Parallel G2P dataset\n\t\n\nThis dataset was derived from the VoxCommunis Corpus to provide pairs of utterances along with their\ncorresponding phonemes, side by side, as to ease the training of grapheme-to-phoneme (G2P) models.\nThe original VoxCommunis Corpus features force-aligned TextGrids with phone- and word-level segmentations derived from the Mozilla Common Voice Corpus.\nThe lexicons were developed using Epitran, the XPF Corpus, Charsiu, and some custom dictionaries.‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/fdemelo/vox-communis-parallel-g2p.","url":"https://huggingface.co/datasets/fdemelo/vox-communis-parallel-g2p","creator_name":"Fl√°vio Eler De Melo","creator_url":"https://huggingface.co/fdemelo","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["Abkhaz","Amharic","Bashkir","Belarusian","Bulgarian"],"keywords_longer_than_N":true},
	{"name":"multilingual_translation_gen_binarized","keyword":"hausa","description":"Youseff1987/multilingual_translation_gen_binarized dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/Youseff1987/multilingual_translation_gen_binarized","creator_name":"JOON HYOUNG JUN","creator_url":"https://huggingface.co/Youseff1987","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["translation","Korean","English","Chinese","Zulu"],"keywords_longer_than_N":true},
	{"name":"smol","keyword":"hausa","description":"\n\t\n\t\t\n\t\tSMOL\n\t\n\nSMOL (Set for Maximal Overall Leverage) is a collection professional\ntranslations into 221 Low-Resource Languages, for the purpose of training\ntranslation models, and otherwise increasing the representations of said\nlanguages in NLP and technology.\nPlease read the SMOL Paper and the\nGATITOS Paper for a much more\nthorough description!\nThere are four resources in this directory:\n\nSmolDoc: document-level translations into 104 language pairs (103 unique languages)\nSmolSent:‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/google/smol.","url":"https://huggingface.co/datasets/google/smol","creator_name":"Google","creator_url":"https://huggingface.co/google","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["translation","Afar","Abkhaz","Achinese","Acoli"],"keywords_longer_than_N":true},
	{"name":"afrimgsm-translate-test","keyword":"hausa","description":"\n\t\n\t\t\n\t\tDataset Card for afrimgsm-translate-test\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nAFRIMGSM-TT is an evaluation dataset comprising translations of the GSM8k dataset from 16 African languages and 1 high resource language into English using NLLB. \nIt includes test sets across all 17 languages. \n\n\t\n\t\t\n\t\tLanguages\n\t\n\nThere are 17 languages available :\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\n\t\n\t\t\n\t\tData Instances\n\t\n\nThe examples look like this for English:\nfrom datasets import load_dataset\ndata =‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/masakhane/afrimgsm-translate-test.","url":"https://huggingface.co/datasets/masakhane/afrimgsm-translate-test","creator_name":"Masakhane NLP","creator_url":"https://huggingface.co/masakhane","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","natural-language-inference","monolingual","afrimgsm","Amharic"],"keywords_longer_than_N":true},
	{"name":"MasakhaNEWSClusteringP2P","keyword":"hausa","description":"\n  MasakhaNEWSClusteringP2P\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nClustering of news article headlines and texts from MasakhaNEWS dataset. Clustering of 10 sets on the news article label.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2c\n\n\nDomains\nNews, Written, Non-fiction\nReference\nhttps://huggingface.co/datasets/masakhane/masakhanews\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask =‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/MasakhaNEWSClusteringP2P.","url":"https://huggingface.co/datasets/mteb/MasakhaNEWSClusteringP2P","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"Academic Free License v3.0","license_url":"https://choosealicense.com/licenses/afl-3.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","derived","multilingual","Amharic","English"],"keywords_longer_than_N":true},
	{"name":"V1Q","keyword":"hausa","description":"from datasets import load_dataset\nds = load_dataset(\"b3x0m/Chinese-H-Novels\")\nimport sagemaker\nimport boto3\nfrom sagemaker.huggingface import HuggingFaceModel\ntry:\n    role = sagemaker.get_execution_role()\nexcept ValueError:\n    iam = boto3.client('iam')\n    role = iam.get_role(RoleName='sagemaker_execution_role')['Role']['Arn']\n\n\t\n\t\t\n\t\tHub Model configuration. https://huggingface.co/models\n\t\n\nhub = {\n    'HF_MODEL_ID':'deepseek-ai/Janus-Pro-7B',\n    'HF_TASK':'any-to-any'\n}\n\n\t\n\t\t\n\t\tcreate‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/YuRiVeRTi/V1Q.","url":"https://huggingface.co/datasets/YuRiVeRTi/V1Q","creator_name":"YuRiVeRTical","creator_url":"https://huggingface.co/YuRiVeRTi","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","table-question-answering","question-answering","zero-shot-classification"],"keywords_longer_than_N":true},
	{"name":"nigerian_common_voice_dataset","keyword":"hausa","description":"\n\t\n\t\t\n\t\tDataset Card for Nigerian Common Voice Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThe Nigerian Common Voice Dataset is a comprehensive dataset consisting of 158 hours of audio recordings and corresponding transcription (sentence). \nThis dataset includes metadata like accent, locale that can help improve the accuracy of speech recognition engines. This dataset is specifically curated to address the gap in speech and language \ndatasets for African accents, making it a valuable resource for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/benjaminogbonna/nigerian_common_voice_dataset.","url":"https://huggingface.co/datasets/benjaminogbonna/nigerian_common_voice_dataset","creator_name":"Benjamin Ogbonna","creator_url":"https://huggingface.co/benjaminogbonna","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","crowdsourced","crowdsourced","multilingual"],"keywords_longer_than_N":true},
	{"name":"wmt-da-human-evaluation-long-context","keyword":"hausa","description":"\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nLong-context / document-level dataset for Quality Estimation of Machine Translation.\nIt is an augmented variant of the sentence-level WMT DA Human Evaluation dataset.\nIn addition to individual sentences, it contains augmentations of 2, 4, 8, 16, and 32 sentences, among each language pair lp and domain.\nThe raw column represents a weighted average of scores of augmented sentences using character lengths of src and mt as weights.\nThe code used to apply the augmentation‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ymoslem/wmt-da-human-evaluation-long-context.","url":"https://huggingface.co/datasets/ymoslem/wmt-da-human-evaluation-long-context","creator_name":"Yasmin Moslem","creator_url":"https://huggingface.co/ymoslem","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["Bengali","Czech","German","English","Estonian"],"keywords_longer_than_N":true},
	{"name":"COMET_score","keyword":"hausa","description":"Tadesse/COMET_score dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/Tadesse/COMET_score","creator_name":"Tadesse Destaw Belay","creator_url":"https://huggingface.co/Tadesse","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["translation","English","Amharic","Ewe","French"],"keywords_longer_than_N":true},
	{"name":"VoxCommunis","keyword":"hausa","description":"\n\t\n\t\t\n\t\tVoxCommunis Corpus\n\t\n\nThe VoxCommunis Corpus is a phonetic corpus derived from the Mozilla Common Voice Corpus. Corresponding audio files and corpus metadata can be downloaded from Mozilla Common Voice, or from one of several Hugging Face repositories for the differing versions. \nWithin each folder, the filenames share similar structure and contain critical information for effectively using the file. More detail regarding the specifics of the filename for each file type is provided‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/pacscilab/VoxCommunis.","url":"https://huggingface.co/datasets/pacscilab/VoxCommunis","creator_name":"PaCSciLab @ UZH","creator_url":"https://huggingface.co/pacscilab","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["Abkhaz","Amharic","Bashkir","Belarusian","Bulgarian"],"keywords_longer_than_N":true},
	{"name":"common_voice_21_0","keyword":"hausa","description":"\n\t\n\t\t\n\t\tDataset Card for Common Voice Corpus 21.0\n\t\n\n\n\nThis dataset is an unofficial version of the Mozilla Common Voice Corpus 21. It was downloaded and converted from the project's website https://commonvoice.mozilla.org/.\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nAbkhaz, Albanian, Amharic, Arabic, Armenian, Assamese, Asturian, Azerbaijani, Basaa, Bashkir, Basque, Belarusian, Bengali, Breton, Bulgarian, Cantonese, Catalan, Central Kurdish, Chinese (China), Chinese (Hong Kong), Chinese (Taiwan), Chuvash, Czech‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/fsicoli/common_voice_21_0.","url":"https://huggingface.co/datasets/fsicoli/common_voice_21_0","creator_name":"Fabio Sicoli","creator_url":"https://huggingface.co/fsicoli","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":null,"first_N":5,"first_N_keywords":["automatic-speech-recognition","Abkhaz","Afrikaans","Amharic","Arabic"],"keywords_longer_than_N":true},
	{"name":"Multilingual-Benchmark","keyword":"hausa","description":"These are the GSM8K and ARC dataset translated by Google Translate. \nBibTex\n@misc{lu2024languagecountslearnunlearn,\n      title={Every Language Counts: Learn and Unlearn in Multilingual LLMs}, \n      author={Taiming Lu and Philipp Koehn},\n      year={2024},\n      eprint={2406.13748},\n      archivePrefix={arXiv},\n      primaryClass={cs.CL},\n      url={https://arxiv.org/abs/2406.13748}, \n}\n\n","url":"https://huggingface.co/datasets/TaiMingLu/Multilingual-Benchmark","creator_name":"TaiMing","creator_url":"https://huggingface.co/TaiMingLu","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["zero-shot-classification","question-answering","translation","English","German"],"keywords_longer_than_N":true},
	{"name":"montok","keyword":"hausa","description":"\n\t\n\t\t\n\t\tMonTok: A Suite of Monolingual Tokenizers\n\t\n\nThis is a set of monolingual tokenizers for 98 languages. For each language, there are Unigram, BPE, and SuperBPE tokenizers, ranging in vocabulary size from around 6k to over 200k.\n\n\t\n\t\t\n\t\tTraining Details\n\t\n\n\n\t\n\t\t\n\t\tTraining Data\n\t\n\nAll tokenizers are trained on samples of the data used to the train the Goldfish language models. \nThe tokenizers were either trained on scaled or unscaled data. This refers to whether the models are trained on‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/catherinearnett/montok.","url":"https://huggingface.co/datasets/catherinearnett/montok","creator_name":"Catherine Arnett","creator_url":"https://huggingface.co/catherinearnett","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["Afrikaans","Tosk Albanian","Amharic","Standard Arabic","Assamese"],"keywords_longer_than_N":true},
	{"name":"asali-x-news-hausa","keyword":"hausa","description":"\n\t\n\t\t\n\t\tasali-x Dataset\n\t\n\nA cleaned and curated corpus of Hausa-language news articles from 2020-2025. This dataset is designed for training and fine-tuning language models for Hausa text generation and understanding tasks.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nThe dataset is split into training and validation sets:\n\nTraining set: ~57K articles\nValidation set: ~3K articles\n\n\n\t\n\t\t\n\t\tFields\n\t\n\n\ntext: Article content in the format <|title|>... <|section|>... body\nid: Unique integer identifier for each‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/superfunguy/asali-x-news-hausa.","url":"https://huggingface.co/datasets/superfunguy/asali-x-news-hausa","creator_name":"Abdulhakim Bashir","creator_url":"https://huggingface.co/superfunguy","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["Hausa","cc-by-4.0","10K - 100K","json","Text"],"keywords_longer_than_N":true},
	{"name":"multilingual-text","keyword":"hausa","description":"\n\t\n\t\t\n\t\tMultilingual Text Dataset\n\t\n\nThis dataset contains a curated selection of rows from multiple input datasets, where each row includes a text chunk of approximately 2000 tokens (as measured by Llama 3.1 tokenizer) verified to be written in the correct language. Only rows with properly classified language chunks are retained, ensuring high-quality multilingual data for analysis or model training.\n\n\t\n\t\t\n\t\tPreprocessing Steps\n\t\n\n\nNormalized whitespace, punctuation, Unicode characters, and‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/agentlans/multilingual-text.","url":"https://huggingface.co/datasets/agentlans/multilingual-text","creator_name":"Alan Tseng","creator_url":"https://huggingface.co/agentlans","license_name":"Open Data Commons Attribution License v1.0","license_url":"https://scancode-licensedb.aboutcode.org/odc-by-1.0.html","language":"en","first_N":5,"first_N_keywords":["text-generation","text-classification","Amharic","Arabic","Bengali"],"keywords_longer_than_N":true},
	{"name":"common_voice_22_0","keyword":"hausa","description":"\n\t\n\t\t\n\t\tDataset Card for Common Voice Corpus 22.0\n\t\n\n\n\nThis dataset is an unofficial version of the Mozilla Common Voice Corpus 22. It was downloaded and converted from the project's website https://commonvoice.mozilla.org/.\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nAbkhaz, Albanian, Amharic, Arabic, Armenian, Assamese, Asturian, Azerbaijani, Basaa, Bashkir, Basque, Belarusian, Bengali, Breton, Bulgarian, Cantonese, Catalan, Central Kurdish, Chinese (China), Chinese (Hong Kong), Chinese (Taiwan), Chuvash, Czech‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/fsicoli/common_voice_22_0.","url":"https://huggingface.co/datasets/fsicoli/common_voice_22_0","creator_name":"Fabio Sicoli","creator_url":"https://huggingface.co/fsicoli","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":null,"first_N":5,"first_N_keywords":["automatic-speech-recognition","Abkhaz","Afrikaans","Amharic","Arabic"],"keywords_longer_than_N":true},
	{"name":"afri-aya","keyword":"hausa","description":"\n\t\n\t\t\n\t\tAfri-Aya üåç\n\t\n\nGiving Sight to African LLMs\nAfri-Aya is a community-curated multilingual image dataset covering 13 major African languages with AI-powered categorization, created as part of Expedition Aya - a six-week global open-build challenge hosted by Cohere Labs.\n\n\t\n\t\t\n\t\tProject Background\n\t\n\nThis dataset was developed by the Cohere Labs Regional Africa community during Expedition Aya, aiming to include more African low-resource languages and their cultures in Vision Language‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/CohereLabsCommunity/afri-aya.","url":"https://huggingface.co/datasets/CohereLabsCommunity/afri-aya","creator_name":"Cohere Labs Community","creator_url":"https://huggingface.co/CohereLabsCommunity","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["image-to-text","visual-question-answering","text-generation","English","Ganda"],"keywords_longer_than_N":true},
	{"name":"text_ratings","keyword":"hausa","description":"Todo - Write dataset card\n","url":"https://huggingface.co/datasets/lightblue/text_ratings","creator_name":"Lightblue KK.","creator_url":"https://huggingface.co/lightblue","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["Amharic","Arabic","Bulgarian","Bengali","Czech"],"keywords_longer_than_N":true},
	{"name":"hausa-sentiments-corpus","keyword":"hausa","description":"\n\t\n\t\t\n\t\tHausa Sentiment Corpus\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset contains sentiment-labeled text data in Hausa for binary sentiment classification (Positive/Negative). Sentiments are extracted and processed from the English meanings of the sentences using DistilBERT for sentiment classification. The dataset is part of a larger collection of African language sentiment analysis resources.\n\n\t\n\t\t\n\t\tDataset Statistics\n\t\n\n\nTotal samples: 669,937\nPositive sentiment: 353111 (52.7%)‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/michsethowusu/hausa-sentiments-corpus.","url":"https://huggingface.co/datasets/michsethowusu/hausa-sentiments-corpus","creator_name":"Mich-Seth Owusu","creator_url":"https://huggingface.co/michsethowusu","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","Hausa","mit","100K - 1M","parquet"],"keywords_longer_than_N":true},
	{"name":"Hypa_Fleurs","keyword":"hausa","description":"\n\t\n\t\t\n\t\tHypa_Fleurs\n\t\n\nHypa_Fleurs is an open-source multilingual, multi-modal dataset with a long term vision of advancing speech and language technology for low-resource African languages by leveraging the English split of the Google Fleurs dataset to create parallel speech and text datasets for a wide range of low-resource African languages. In this initial release, professional AfroVoices experts translated the original English texts into three under-resourced African languages: Igbo (ig)‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/hypaai/Hypa_Fleurs.","url":"https://huggingface.co/datasets/hypaai/Hypa_Fleurs","creator_name":"Hypa-Intelligence","creator_url":"https://huggingface.co/hypaai","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","translation","text-classification","AfroVoices"],"keywords_longer_than_N":true},
	{"name":"Hypa_Fleurs","keyword":"hausa","description":"\n\t\n\t\t\n\t\tHypa_Fleurs\n\t\n\nHypa_Fleurs is an open-source multilingual, multi-modal dataset with a long term vision of advancing speech and language technology for low-resource African languages by leveraging the English split of the Google Fleurs dataset to create parallel speech and text datasets for a wide range of low-resource African languages. In this initial release, professional AfroVoices experts translated the original English texts into three under-resourced African languages: Igbo (ig)‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/hypaai/Hypa_Fleurs.","url":"https://huggingface.co/datasets/hypaai/Hypa_Fleurs","creator_name":"Hypa-Intelligence","creator_url":"https://huggingface.co/hypaai","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","translation","text-classification","AfroVoices"],"keywords_longer_than_N":true},
	{"name":"aya_collection_language_split","keyword":"hausa","description":"\nThis is a re-upload of the aya_collection, and only differs in the structure of upload. While the original aya_collection is structured by folders split according to dataset name, this dataset is split by language. We recommend you use this version of the dataset if you are only interested in downloading all of the Aya collection for a single or smaller set of languages.\n\n\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThe Aya Collection is a massive multilingual collection consisting of 513 million instances of‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/CohereLabs/aya_collection_language_split.","url":"https://huggingface.co/datasets/CohereLabs/aya_collection_language_split","creator_name":"Cohere Labs","creator_url":"https://huggingface.co/CohereLabs","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["Achinese","Afrikaans","Amharic","Arabic","Azerbaijani"],"keywords_longer_than_N":true},
	{"name":"Tatoeba-Translations","keyword":"hausa","description":"\n\t\n\t\t\n\t\tDataset Details\n\t\n\nThis is the latest version of Tatoeba translations as of December 2024.\nThe sentences are downloaded from the Tatoeba collection website.\nThe dataset is processed through mapping sentences.tar.bz2 using sentences_base.tar.bz2 to find source (sentence_src) and target (sentence_tgt) sentences.\nWhile lang_src and lang_tgt columns follow the mapping provided by Tatoeba, the lang_pair column merely lists the two languages in the translation pair.\n\n\t\n\t\t\n\t\n\t\n\t\tStatistics‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ymoslem/Tatoeba-Translations.","url":"https://huggingface.co/datasets/ymoslem/Tatoeba-Translations","creator_name":"Yasmin Moslem","creator_url":"https://huggingface.co/ymoslem","license_name":"Creative Commons Attribution 2.0","license_url":"https://scancode-licensedb.aboutcode.org/cc-by-2.0.html","language":"en","first_N":5,"first_N_keywords":["translation","multilingual","Abkhaz","Afrikaans","Amharic"],"keywords_longer_than_N":true},
	{"name":"biblenlp-corpus","keyword":"hausa","description":"\n\t\n\t\t\n\t\tDataset Card for BibleNLP Corpus\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nPartial and complete Bible translations in 833 languages, aligned by verse.\n\n\t\n\t\t\n\t\tLanguages\n\t\n\naai, aak, aau, aaz, abt, abx, aby, acf, acr, acu, adz, aer, aey, agd, agg, agm, agn, agr, agt, agu, aia, aii, aka, ake, alp, alq, als, aly, ame, amf, amk, amm, amn, amo, amp, amr, amu, amx, anh, anv, aoi, aoj, aom, aon, apb, ape, apn, apr, apu, apw, apz, arb, are, arl, arn, arp, asm, aso, ata, atb, atd, atg, att, auc, aui, auy‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/bible-nlp/biblenlp-corpus.","url":"https://huggingface.co/datasets/bible-nlp/biblenlp-corpus","creator_name":"The Partnership for Applied Biblical NLP","creator_url":"https://huggingface.co/bible-nlp","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":null,"first_N":5,"first_N_keywords":["translation","no-annotation","expert-generated","translation","multilingual"],"keywords_longer_than_N":true},
	{"name":"masakhaner2","keyword":"hausa","description":"MasakhaNER 2.0 is the largest publicly available high-quality dataset for named entity recognition (NER) in 20 African languages.\n\nNamed entities are phrases that contain the names of persons, organizations, locations, times and quantities.\n\nExample:\n[PER Wolff] , currently a journalist in [LOC Argentina] , played with [PER Del Bosque] in the final years of the seventies in [ORG Real Madrid] .\nMasakhaNER is a named entity dataset consisting of PER, ORG, LOC, and DATE entities annotated by Masakhane for 20 African languages:\n- Bambara (bam)\n- Ghomala (bbj)\n- Ewe (ewe)\n- Fon (fon)\n- Hausa (hau)\n- Igbo (ibo)\n- Kinyarwanda (kin)\n- Luganda (lug)\n- Dholuo (luo) \n- Mossi (mos)\n- Chichewa (nya)\n- Nigerian Pidgin\n- chShona (sna)\n- Kiswahili (swƒÖ)\n- Setswana (tsn)\n- Twi (twi)\n- Wolof (wol)\n- isiXhosa (xho)\n- Yor√πb√° (yor)\n- isiZulu (zul)\n\nThe train/validation/test sets are available for all the ten languages.\n\nFor more details see https://arxiv.org/abs/2103.11811","url":"https://huggingface.co/datasets/masakhane/masakhaner2","creator_name":"Masakhane NLP","creator_url":"https://huggingface.co/masakhane","license_name":"Academic Free License v3.0","license_url":"https://choosealicense.com/licenses/afl-3.0/","language":"en","first_N":5,"first_N_keywords":["token-classification","named-entity-recognition","expert-generated","expert-generated","multilingual"],"keywords_longer_than_N":true},
	{"name":"ChatML-aya_dataset","keyword":"hausa","description":"CohereForAI/aya_dataset in ChatML format, ready to use in HuggingFace TRL's SFT Trainer.\nPython code used for conversion:\nfrom datasets import load_dataset\nfrom transformers import AutoTokenizer\n\ntokenizer = AutoTokenizer.from_pretrained(\"Felladrin/Llama-160M-Chat-v1\")\n\ndataset = load_dataset(\"CohereForAI/aya_dataset\", split=\"train\")\n\ndef format(columns):\n    messages = [\n        {\n            \"role\": \"user\",\n            \"content\": columns[\"inputs\"].strip(),\n        },\n        {‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Felladrin/ChatML-aya_dataset.","url":"https://huggingface.co/datasets/Felladrin/ChatML-aya_dataset","creator_name":"Victor Nogueira","creator_url":"https://huggingface.co/Felladrin","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["question-answering","text-generation","crowdsourced","expert-generated","crowdsourced"],"keywords_longer_than_N":true},
	{"name":"HAUSA-TTSCSV","keyword":"hausa","description":"\n\t\n\t\t\n\t\tHausa TTS Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset contains Hausa language text-to-speech (TTS) recordings from multiple speakers. It includes audio files paired with their corresponding Hausa text transcriptions.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nThe dataset is organized as follows:\n‚îú‚îÄ‚îÄ data/\n‚îÇ   ‚îú‚îÄ‚îÄ metadata.csv                    # Metadata (source, audio paths, text)\n‚îÇ   ‚îî‚îÄ‚îÄ audio_files/\n‚îÇ       ‚îú‚îÄ‚îÄ 97f373e8-f6e6-.../          # Speaker 1 audio files\n‚îÇ       ‚îú‚îÄ‚îÄ‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Aybee5/HAUSA-TTSCSV.","url":"https://huggingface.co/datasets/Aybee5/HAUSA-TTSCSV","creator_name":"Ibrahim Abdullahi","creator_url":"https://huggingface.co/Aybee5","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-to-speech","audio-classification","Hausa","cc-by-4.0","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"HAUSA-TTSCSV","keyword":"hausa","description":"\n\t\n\t\t\n\t\tHausa TTS Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset contains Hausa language text-to-speech (TTS) recordings from multiple speakers. It includes audio files paired with their corresponding Hausa text transcriptions.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nThe dataset is organized as follows:\n‚îú‚îÄ‚îÄ data/\n‚îÇ   ‚îú‚îÄ‚îÄ metadata.csv                    # Metadata (source, audio paths, text)\n‚îÇ   ‚îî‚îÄ‚îÄ audio_files/\n‚îÇ       ‚îú‚îÄ‚îÄ 97f373e8-f6e6-.../          # Speaker 1 audio files\n‚îÇ       ‚îú‚îÄ‚îÄ‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Aybee5/HAUSA-TTSCSV.","url":"https://huggingface.co/datasets/Aybee5/HAUSA-TTSCSV","creator_name":"Ibrahim Abdullahi","creator_url":"https://huggingface.co/Aybee5","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-to-speech","audio-classification","Hausa","cc-by-4.0","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"wmt-da-human-evaluation","keyword":"hausa","description":"\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset contains all DA human annotations from previous WMT News Translation shared tasks.\nThe data is organised into 8 columns:\n\nlp: language pair\nsrc: input text\nmt: translation\nref: reference translation\nscore: z score\nraw: direct assessment\nannotators: number of annotators\ndomain: domain of the input text (e.g. news)\nyear: collection year\n\nYou can also find the original data for each year in the results section https://www.statmt.org/wmt{YEAR}/results.html‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/RicardoRei/wmt-da-human-evaluation.","url":"https://huggingface.co/datasets/RicardoRei/wmt-da-human-evaluation","creator_name":"Ricardo Rei","creator_url":"https://huggingface.co/RicardoRei","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["Bengali","Czech","German","English","Estonian"],"keywords_longer_than_N":true},
	{"name":"SemEval2024-STR","keyword":"hausa","description":"\n\t\n\t\t\n\t\tDataset Card for Dataset Name\n\t\n\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\n\nEach instance in the training, development, and test sets is a sentence pair. The instance is labeled with a score representing the degree of semantic textual relatedness between the two sentences. The scores can range from 0 (maximally unrelated) to 1 (maximally related). These gold label scores have been determined through manual annotation. Specifically, a comparative annotation approach was‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/kietnt0603/SemEval2024-STR.","url":"https://huggingface.co/datasets/kietnt0603/SemEval2024-STR","creator_name":"Nguy·ªÖn Tu·∫•n Ki·ªát","creator_url":"https://huggingface.co/kietnt0603","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["Amharic","Hausa","English","Spanish","Telugu"],"keywords_longer_than_N":true},
	{"name":"afrolm_active_learning_dataset","keyword":"hausa","description":"\n\t\n\t\t\n\t\tAfroLM: A Self-Active Learning-based Multilingual Pretrained Language Model for 23 African Languages\n\t\n\n\nGitHub Repository of the Paper\n\nThis repository contains the dataset for our paper AfroLM: A Self-Active Learning-based Multilingual Pretrained Language Model for 23 African Languages which will appear at the third Simple and Efficient Natural Language Processing, at EMNLP 2022.\n\n\t\n\t\t\n\t\n\t\n\t\tOur self-active learning framework\n\t\n\n\n\n\t\n\t\n\t\n\t\tLanguages Covered\n\t\n\nAfroLM has been‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/bonadossou/afrolm_active_learning_dataset.","url":"https://huggingface.co/datasets/bonadossou/afrolm_active_learning_dataset","creator_name":"Bonaventure Dossou","creator_url":"https://huggingface.co/bonadossou","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["fill-mask","masked-language-modeling","crowdsourced","crowdsourced","monolingual"],"keywords_longer_than_N":true},
	{"name":"nllb-200-10M-sample","keyword":"hausa","description":"\n\t\n\t\t\n\t\tDataset Card for \"nllb-200-10M-sample\"\n\t\n\nThis is a sample of nearly 10M sentence pairs from the NLLB-200 \nmined dataset allenai/nllb, \nscored with the model facebook/blaser-2.0-qe \ndescribed in the SeamlessM4T paper.\nThe sample is not random; instead, we just took the top n sentence pairs from each translation direction.\nThe number n was computed with the goal of upsamping the directions that contain underrepresented languages.\nNevertheless, the 187 languoids (language and script‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/slone/nllb-200-10M-sample.","url":"https://huggingface.co/datasets/slone/nllb-200-10M-sample","creator_name":"SLONE","creator_url":"https://huggingface.co/slone","license_name":"Open Data Commons Attribution License v1.0","license_url":"https://scancode-licensedb.aboutcode.org/odc-by-1.0.html","language":"en","first_N":5,"first_N_keywords":["translation","Akan","Amharic","Arabic","Awadhi"],"keywords_longer_than_N":true},
	{"name":"masakhanews","keyword":"hausa","description":"MasakhaNEWS is the largest publicly available dataset for news topic classification in 16 languages widely spoken in Africa.\n\nThe languages are:\n- Amharic (amh)\n- English (eng)\n- French (fra)\n- Hausa (hau)\n- Igbo (ibo)\n- Lingala (lin)\n- Luganda (lug)\n- Oromo (orm)\n- Nigerian Pidgin (pcm)\n- Rundi (run)\n- chShona (sna)\n- Somali (som)\n- Kiswahili (swƒÖ)\n- Tigrinya (tir)\n- isiXhosa (xho)\n- Yor√πb√° (yor)\n\nThe train/validation/test sets are available for all the 16 languages.\n\nFor more details see *** arXiv link **","url":"https://huggingface.co/datasets/masakhane/masakhanews","creator_name":"Masakhane NLP","creator_url":"https://huggingface.co/masakhane","license_name":"Academic Free License v3.0","license_url":"https://choosealicense.com/licenses/afl-3.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","topic-classification","expert-generated","expert-generated","multilingual"],"keywords_longer_than_N":true},
	{"name":"xP3x-sample","keyword":"hausa","description":"A multilingual collection of Winograd Schemas in six languages that can be used for evaluation of cross-lingual commonsense reasoning capabilities.","url":"https://huggingface.co/datasets/Muennighoff/xP3x-sample","creator_name":"Niklas Muennighoff","creator_url":"https://huggingface.co/Muennighoff","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["other","expert-generated","crowdsourced","multilingual","Afrikaans"],"keywords_longer_than_N":true},
	{"name":"Hausa-loud-tts","keyword":"hausa","description":"\n\t\n\t\t\n\t\tHausa TTS Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset contains Hausa language text-to-speech (TTS) recordings from multiple speakers. It includes audio files paired with their corresponding Hausa text transcriptions.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nThe dataset is organized as follows:\n‚îú‚îÄ‚îÄ data/\n‚îÇ   ‚îú‚îÄ‚îÄ metadata.csv                    # Metadata (source, audio paths, text)\n‚îÇ   ‚îî‚îÄ‚îÄ audio_files/\n‚îÇ       ‚îú‚îÄ‚îÄ 97f373e8-f6e6-.../          # Speaker 1 audio files\n‚îÇ       ‚îú‚îÄ‚îÄ‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Aybee5/Hausa-loud-tts.","url":"https://huggingface.co/datasets/Aybee5/Hausa-loud-tts","creator_name":"Ibrahim Abdullahi","creator_url":"https://huggingface.co/Aybee5","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-to-speech","audio-classification","Hausa","cc-by-4.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"Hausa-loud-tts","keyword":"hausa","description":"\n\t\n\t\t\n\t\tHausa TTS Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset contains Hausa language text-to-speech (TTS) recordings from multiple speakers. It includes audio files paired with their corresponding Hausa text transcriptions.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nThe dataset is organized as follows:\n‚îú‚îÄ‚îÄ data/\n‚îÇ   ‚îú‚îÄ‚îÄ metadata.csv                    # Metadata (source, audio paths, text)\n‚îÇ   ‚îî‚îÄ‚îÄ audio_files/\n‚îÇ       ‚îú‚îÄ‚îÄ 97f373e8-f6e6-.../          # Speaker 1 audio files\n‚îÇ       ‚îú‚îÄ‚îÄ‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Aybee5/Hausa-loud-tts.","url":"https://huggingface.co/datasets/Aybee5/Hausa-loud-tts","creator_name":"Ibrahim Abdullahi","creator_url":"https://huggingface.co/Aybee5","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-to-speech","audio-classification","Hausa","cc-by-4.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"xsimplusplus","keyword":"hausa","description":"xSIM++ is an extension of xSIM. In comparison to xSIM, this evaluates using target-side data with additional synthetic, hard-to-distinguish examples. You can find more details about it in the publication: xSIM++: An Improved Proxy to Bitext Mining Performance for Low-Resource Languages.\n","url":"https://huggingface.co/datasets/jaygala24/xsimplusplus","creator_name":"Jay Gala","creator_url":"https://huggingface.co/jaygala24","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["derived","multilingual","Achinese","Mesopotamian Arabic","Ta'izzi-Adeni Arabic"],"keywords_longer_than_N":true},
	{"name":"biblenlp-corpus-mmteb","keyword":"hausa","description":"This dataset pre-computes all English-centric directions from bible-nlp/biblenlp-corpus, and as a result loading is significantly faster.\nLoading example:\n>>> from datasets import load_dataset\n>>> dataset = load_dataset(\"davidstap/biblenlp-corpus-mmteb\", \"eng-arb\", trust_remote_code=True)\n>>> dataset\nDatasetDict({\n    train: Dataset({\n        features: ['eng', 'arb'],\n        num_rows: 28723\n    })\n    validation: Dataset({\n        features: ['eng', 'arb'],\n        num_rows: 1578\n    })‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/biblenlp-corpus-mmteb.","url":"https://huggingface.co/datasets/mteb/biblenlp-corpus-mmteb","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["no-annotation","expert-generated","translation","multilingual","Arifama-Miniafia"],"keywords_longer_than_N":true},
	{"name":"Hypa_AIME2024","keyword":"hausa","description":"\n\t\n\t\t\n\t\tHypa_AIME2024\n\t\n\nHypa_AIME2024 is an open-source, multilingual benchmark dataset for advanced mathematical reasoning, designed with the long-term vision of ensuring all languages are represented in AI development. This dataset marks a crucial step toward closing the gap between AI capabilities for no-resource/low-resource and all-resource languages, particularly in complex reasoning domains. \nThis initial release features the complete 2024 American Invitational Mathematics Examination‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/hypaai/Hypa_AIME2024.","url":"https://huggingface.co/datasets/hypaai/Hypa_AIME2024","creator_name":"Hypa-Intelligence","creator_url":"https://huggingface.co/hypaai","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["translation","question-answering","AfroVoices","multilingual","English"],"keywords_longer_than_N":true},
	{"name":"Hypa_AIME2024","keyword":"hausa","description":"\n\t\n\t\t\n\t\tHypa_AIME2024\n\t\n\nHypa_AIME2024 is an open-source, multilingual benchmark dataset for advanced mathematical reasoning, designed with the long-term vision of ensuring all languages are represented in AI development. This dataset marks a crucial step toward closing the gap between AI capabilities for no-resource/low-resource and all-resource languages, particularly in complex reasoning domains. \nThis initial release features the complete 2024 American Invitational Mathematics Examination‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/hypaai/Hypa_AIME2024.","url":"https://huggingface.co/datasets/hypaai/Hypa_AIME2024","creator_name":"Hypa-Intelligence","creator_url":"https://huggingface.co/hypaai","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["translation","question-answering","AfroVoices","multilingual","English"],"keywords_longer_than_N":true},
	{"name":"ApolloMoEDataset","keyword":"hausa","description":"\n\t\n\t\t\n\t\tDemocratizing Medical LLMs For Much More Languages\n\t\n\nCovering 12 Major Languages including English, Chinese, French, Hindi, Spanish, Arabic, Russian, Japanese, Korean, German, Italian, Portuguese and 38 Minor Languages So far.\n\n   üìÉ Paper ‚Ä¢ üåê Demo ‚Ä¢ ü§ó ApolloMoEDataset ‚Ä¢ ü§ó ApolloMoEBench  ‚Ä¢ ü§ó Models  ‚Ä¢üåê Apollo  ‚Ä¢ üåê ApolloMoE\n\n\n\n\n\n\n\t\n\t\t\n\t\tüåà Update\n\t\n\n\n[2024.10.15] ApolloMoE repo is publishedÔºÅüéâ\n\n\n\t\n\t\t\n\t\tLanguages Coverage\n\t\n\n12 Major Languages and 38 Minor Languages\n\n  Click to‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/FreedomIntelligence/ApolloMoEDataset.","url":"https://huggingface.co/datasets/FreedomIntelligence/ApolloMoEDataset","creator_name":"FreedomAI","creator_url":"https://huggingface.co/FreedomIntelligence","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["question-answering","Arabic","English","Chinese","Korean"],"keywords_longer_than_N":true},
	{"name":"muri-it-language-split","keyword":"hausa","description":"\n\t\n\t\t\n\t\tMURI-IT: Multilingual Instruction Tuning Dataset for 200 Languages via Multilingual Reverse Instructions\n\t\n\nMURI-IT is a large-scale multilingual instruction tuning dataset containing 2.2 million instruction-output pairs across 200 languages. It is designed to address the challenges of instruction tuning in low-resource languages with Multilingual Reverse Instructions (MURI), which ensures that the output is human-written, high-quality, and authentic to the cultural and linguistic‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/akoksal/muri-it-language-split.","url":"https://huggingface.co/datasets/akoksal/muri-it-language-split","creator_name":"Abdullatif Koksal","creator_url":"https://huggingface.co/akoksal","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text2text-generation","text-generation","question-answering","summarization","Achinese"],"keywords_longer_than_N":true},
	{"name":"AfriSentiClassification","keyword":"hausa","description":"\n  AfriSentiClassification\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nAfriSenti is the largest sentiment analysis dataset for under-represented African languages.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2c\n\n\nDomains\nSocial, Written\n\n\nReferencehttps://arxiv.org/abs/2302.08956\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask = mteb.get_tasks([\"AfriSentiClassification\"])\nevaluator = mteb.MTEB(task)\n\nmodel‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/AfriSentiClassification.","url":"https://huggingface.co/datasets/mteb/AfriSentiClassification","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","sentiment-analysis","sentiment-scoring","sentiment-classification","hate-speech-detection"],"keywords_longer_than_N":true},
	{"name":"BRIGHTER-emotion-categories","keyword":"hausa","description":"\n\t\n\t\t\n\t\tBRIGHTER Emotion Categories Dataset\n\t\n\nThis dataset contains the emotion categories data from the BRIGHTER paper: BRIdging the Gap in Human-Annotated Textual Emotion Recognition Datasets for 28 Languages.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe BRIGHTER Emotion Categories dataset is a comprehensive multi-language, multi-label emotion classification dataset with separate configurations for each language. It represents one of the largest human-annotated emotion datasets across multiple‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/brighter-dataset/BRIGHTER-emotion-categories.","url":"https://huggingface.co/datasets/brighter-dataset/BRIGHTER-emotion-categories","creator_name":"BRIGHTER Dataset","creator_url":"https://huggingface.co/brighter-dataset","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["Afrikaans","Arabic","German","English","Spanish"],"keywords_longer_than_N":true},
	{"name":"aya_evaluation_suite","keyword":"hausa","description":"\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nAya Evaluation Suite contains a total of 26,750 open-ended conversation-style prompts to evaluate multilingual open-ended generation quality.To strike a balance between language coverage and the quality that comes with human curation, we create an evaluation suite that includes:\n\nhuman-curated examples in 7 languages (tur, eng, yor, arb, zho, por, tel) ‚Üí aya-human-annotated.\nmachine-translations of handpicked examples into 101 languages ‚Üí dolly-machine-translated.‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/CohereLabs/aya_evaluation_suite.","url":"https://huggingface.co/datasets/CohereLabs/aya_evaluation_suite","creator_name":"Cohere Labs","creator_url":"https://huggingface.co/CohereLabs","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","crowdsourced","expert-generated","machine-generated","multilingual"],"keywords_longer_than_N":true},
	{"name":"uhura-arc-easy","keyword":"hausa","description":"\n\t\n\t\t\n\t\tDataset Card for Uhura-Arc-Easy\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nUhura-ARC-Easy is a widely recognized scientific question answering benchmark composed of multiple-choice science questions derived from grade-school examinations that test various styles of knowledge and reasoning. \nThe original English version of the benchmark originates from Think you have Solved Question Answering? Try ARC, the AI2 Reasoning Challenge (Clark et al., 2018) and is divided into \"Challenge\" and \"Easy\"‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/masakhane/uhura-arc-easy.","url":"https://huggingface.co/datasets/masakhane/uhura-arc-easy","creator_name":"Masakhane NLP","creator_url":"https://huggingface.co/masakhane","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["multiple-choice","question-answering","multiple-choice-qa","multilingual","Amharic"],"keywords_longer_than_N":true},
	{"name":"panlex-meanings","keyword":"hausa","description":"\n\t\n\t\t\n\t\tDataset Card for panlex-meanings\n\t\n\nThis is a dataset of words in several thousand languages, extracted from https://panlex.org.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset has been extracted from https://panlex.org (the 20240301 database dump) and rearranged on the per-language basis.\nEach language subset consists of expressions (words and phrases). \nEach expression is associated with some meanings (if there is more than one meaning, they are in separate‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/cointegrated/panlex-meanings.","url":"https://huggingface.co/datasets/cointegrated/panlex-meanings","creator_name":"David Dale","creator_url":"https://huggingface.co/cointegrated","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["translation","Afar","Western Abnaki","Abkhazian","Abaza"],"keywords_longer_than_N":true},
	{"name":"tulu-3-sft-mixture-with-language","keyword":"hausa","description":"\n\nJust a version of the good tulu-3-sft-mixture dataset with a column indicating language.\nLanguage detection has been performed with fastText.\n‚ö†Ô∏è It may contain errors.\n","url":"https://huggingface.co/datasets/anakin87/tulu-3-sft-mixture-with-language","creator_name":"Stefano Fiorucci","creator_url":"https://huggingface.co/anakin87","license_name":"Open Data Commons Attribution License v1.0","license_url":"https://scancode-licensedb.aboutcode.org/odc-by-1.0.html","language":"en","first_N":5,"first_N_keywords":["other","crowdsourced","expert-generated","machine-generated","multilingual"],"keywords_longer_than_N":true},
	{"name":"african-medical-multimodal-fracture","keyword":"hausa","description":"\n\t\n\t\t\n\t\tAfrican Medical Multimodal Bone Fracture Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset is a comprehensive, multimodal bone break classification dataset specifically designed for African healthcare contexts. It addresses critical gaps in medical AI for resource-constrained environments while ensuring cultural sensitivity and local relevance.\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\n\nTotal Records: 1,129 multimodal medical cases\nOriginal Images: 1,128 X-ray images (89% of dataset)\nAugmented‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/electricsheepafrica/african-medical-multimodal-fracture.","url":"https://huggingface.co/datasets/electricsheepafrica/african-medical-multimodal-fracture","creator_name":"Electric Sheep","creator_url":"https://huggingface.co/electricsheepafrica","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["image-classification","text-classification","other","English","French"],"keywords_longer_than_N":true},
	{"name":"Roleplay-Hausa","keyword":"hausa","description":"\n\t\n\t\t\n\t\tRolePlay-Hausa\n\t\n\nRoleplay-Hausa Dataset is a dataset for roleplaying in the Hausa language for Large Language Model.\nThe base dataset is GPTeacher role play dataset by teknium 1, which can be found under this link, released under MIT License. The dataset is then translated into respective languages. The translation process is powered by Google Translate, using cloud translation API. \nFor more information and other language datasets for roleplay, see this github repo.\nFor contact‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/jojo-ai-mst/Roleplay-Hausa.","url":"https://huggingface.co/datasets/jojo-ai-mst/Roleplay-Hausa","creator_name":"Min Si Thu","creator_url":"https://huggingface.co/jojo-ai-mst","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-generation","Hausa","mit","1K - 10K","csv"],"keywords_longer_than_N":true},
	{"name":"InjongoIntent","keyword":"hausa","description":"\n\t\n\t\t\n\t\tDataset Card for InjongoIntent\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nInjongoIntent\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nThere are 17 languages available :\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\n\t\n\t\t\n\t\tData Instances\n\t\n\nThe examples look like this for English:\nfrom datasets import load_dataset\ndata = load_dataset('masakhane/InjongoIntent', 'eng') \n# Please, specify the language code\n# A data point example is below:\n{\n\n}\n\n\n\t\n\t\t\n\t\tData Fields\n\t\n\n\nquestion: the question string to a grade school math problem.\nanswer: the‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/masakhane/InjongoIntent.","url":"https://huggingface.co/datasets/masakhane/InjongoIntent","creator_name":"Masakhane NLP","creator_url":"https://huggingface.co/masakhane","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","intent-classification","multi-class-classification","multilingual","clinc/clinc_oos"],"keywords_longer_than_N":true},
	{"name":"african-ultrachat","keyword":"hausa","description":"masakhane/african-ultrachat dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/masakhane/african-ultrachat","creator_name":"Masakhane NLP","creator_url":"https://huggingface.co/masakhane","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["Amharic","Hausa","Igbo","Kinyarwanda","Southern Sotho"],"keywords_longer_than_N":true},
	{"name":"afrimgsm","keyword":"hausa","description":"\n\t\n\t\t\n\t\tDataset Card for afrimgsm\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nAFRIMGSM is an evaluation dataset comprising translations of a subset of the GSM8k dataset into 16 African languages. \nIt includes test sets across all 18 languages, maintaining an English and French subsets from the original GSM8k dataset. \n\n\t\n\t\t\n\t\tLanguages\n\t\n\nThere are 18 languages available :\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\n\t\n\t\t\n\t\tData Instances\n\t\n\nThe examples look like this for English:\nfrom datasets import load_dataset\ndata =‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/masakhane/afrimgsm.","url":"https://huggingface.co/datasets/masakhane/afrimgsm","creator_name":"Masakhane NLP","creator_url":"https://huggingface.co/masakhane","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["natural-language-inference","multilingual","gsm8k","Amharic","Ewe"],"keywords_longer_than_N":true},
	{"name":"HPLT2.0_cleaned","keyword":"hausa","description":"This is a large-scale collection of web-crawled documents in 191 world languages, produced by the HPLT project. \nThe source of the data is mostly Internet Archive with some additions from Common Crawl.\nFor a detailed description of the dataset, please refer to https://hplt-project.org/datasets/v2.0\nThe Cleaned variant of HPLT Datasets v2.0\nThis is the cleaned variant of the HPLT Datasets v2.0 converted to the Parquet format semi-automatically when being uploaded here. \nThe original JSONL files‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/jobs-git/HPLT2.0_cleaned.","url":"https://huggingface.co/datasets/jobs-git/HPLT2.0_cleaned","creator_name":"James Guana","creator_url":"https://huggingface.co/jobs-git","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["fill-mask","text-generation","language-modeling","multilingual","Achinese"],"keywords_longer_than_N":true},
	{"name":"GlotCC-V1","keyword":"hausa","description":"\n\t\n\t\t\n\t\tDataset Summary\n\t\n\n \n\nGlotCC-V1.0 is a document-level, general domain dataset derived from CommonCrawl, covering more than 1000 languages.It is built using the GlotLID language identification and Ungoliant pipeline from CommonCrawl.We release our pipeline as open-source at https://github.com/cisnlp/GlotCC.  \nList of Languages: See https://datasets-server.huggingface.co/splits?dataset=cis-lmu/GlotCC-V1 to get the list of splits available.\n\n\t\t\n\t\tUsage (Huggingface Hub -- Recommended)‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/cis-lmu/GlotCC-V1.","url":"https://huggingface.co/datasets/cis-lmu/GlotCC-V1","creator_name":"CIS, LMU Munich","creator_url":"https://huggingface.co/cis-lmu","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["multilingual","Abau","Amarasi","Abkhaz","Abkhazian"],"keywords_longer_than_N":true},
	{"name":"GlotCC-V1","keyword":"hausa","description":"\n\t\n\t\t\n\t\tDataset Summary\n\t\n\n \n\nGlotCC-V1.0 is a document-level, general domain dataset derived from CommonCrawl, covering more than 1000 languages.It is built using the GlotLID language identification and Ungoliant pipeline from CommonCrawl.We release our pipeline as open-source at https://github.com/cisnlp/GlotCC.  \nList of Languages: See https://datasets-server.huggingface.co/splits?dataset=cis-lmu/GlotCC-V1 to get the list of splits available.\n\n\t\t\n\t\tUsage (Huggingface Hub -- Recommended)‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/cis-lmu/GlotCC-V1.","url":"https://huggingface.co/datasets/cis-lmu/GlotCC-V1","creator_name":"CIS, LMU Munich","creator_url":"https://huggingface.co/cis-lmu","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["multilingual","Abau","Amarasi","Abkhaz","Abkhazian"],"keywords_longer_than_N":true},
	{"name":"afrimmlu","keyword":"hausa","description":"\n\t\n\t\t\n\t\tDataset Card for afrimmlu\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nAFRIMMLU is an evaluation dataset comprising translations of a subset of the MMLU dataset into 15 African languages. \nIt includes test sets across all 17 languages, maintaining an English and French subsets from the original MMLU dataset. \n\n\t\n\t\t\n\t\tLanguages\n\t\n\nThere are 17 languages available :\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\n\t\n\t\t\n\t\tData Instances\n\t\n\nThe examples look like this for English:\nfrom datasets import load_dataset\ndata =‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/masakhane/afrimmlu.","url":"https://huggingface.co/datasets/masakhane/afrimmlu","creator_name":"Masakhane NLP","creator_url":"https://huggingface.co/masakhane","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["question-answering","multiple-choice-qa","multilingual","mmlu","Amharic"],"keywords_longer_than_N":true},
	{"name":"multimodal_low-resource_language_translation","keyword":"hausa","description":"\n\t\n\t\t\n\t\tDataset Card for Multimodal Low-Resource Language Translation Dataset\n\t\n\n\n\nThis dataset card aims to be a base template for new datasets. It has been generated using this raw template.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis is the dataset for our paper \"From Text to Multi-Modal: Advancing Low-Resource-Language Translation through Synthetic Data Generation and Cross-Modal Alignments\" accepted by the workshop LoResMT 2025 of NAACL 2025‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/qianstats/multimodal_low-resource_language_translation.","url":"https://huggingface.co/datasets/qianstats/multimodal_low-resource_language_translation","creator_name":"Qian Shen","creator_url":"https://huggingface.co/qianstats","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["translation","English","Yoruba","Tigrinya","Hausa"],"keywords_longer_than_N":true},
	{"name":"reasoning-multilingual-R1-Llama-70B-train","keyword":"hausa","description":"\n\t\n\t\t\n\t\tlightblue/reasoning-multilingual-R1-Llama-70B-train\n\t\n\nThis is a multilingual reasoning dataset covering more than 30 languages.\nThis dataset was made by:\n\nSampling prompts from English datasets and translating them to various languages\nGenerating responses to these prompts 8 times using deepseek-ai/DeepSeek-R1-Distill-Llama-70B\nFiltering out <think> sections with incorrect language, non-fluent language, and incorrect answers\n\nThis dataset was then used to train a multilingual‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/lightblue/reasoning-multilingual-R1-Llama-70B-train.","url":"https://huggingface.co/datasets/lightblue/reasoning-multilingual-R1-Llama-70B-train","creator_name":"Lightblue KK.","creator_url":"https://huggingface.co/lightblue","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["Amharic","Arabic","Bengali","Chinese","Czech"],"keywords_longer_than_N":true},
	{"name":"quran","keyword":"hausa","description":"\n\t\n\t\t\n\t\tDataset Card for the Quran\n\t\n\n\n\t\n\t\t\n\t\tSummary\n\t\n\nThe Quran with metadata, translations, and multiple Arabic text (can use specific types for embeddings, search, classification, and display). There are 126+ columns containing 43+ languages.\n\n\t\n\t\t\n\t\tTODO\n\t\n\n\n Add Tafsirs  \n Add topics/ontology\n\n\n\t\n\t\t\n\t\tUsage\n\t\n\nfrom datasets import load_dataset\n\nds = load_dataset(\"nazimali/quran\", split=\"train\")\nds\n\nOutput:\nDataset({\n    features: ['surah', 'ayah', 'surah-name', 'surah-total-ayas'‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/nazimali/quran.","url":"https://huggingface.co/datasets/nazimali/quran","creator_name":"Nazim Ali","creator_url":"https://huggingface.co/nazimali","license_name":"Creative Commons Attribution 3.0","license_url":"https://scancode-licensedb.aboutcode.org/cc-by-3.0.html","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","translation","feature-extraction","text-generation"],"keywords_longer_than_N":true},
	{"name":"hausa_voice_dataset","keyword":"hausa","description":"\n\t\n\t\t\n\t\tDataset Card for \"hausa_voice_dataset\"\n\t\n\n\n\t\n\t\t\n\t\tDataset Overview\n\t\n\nDataset Name: Hausa Voice Dataset\nDescription: This dataset contains Hausa language audio samples from Common Voice. The dataset includes audio files and their corresponding transcriptions, designed for text-to-speech (TTS) and automatic speech recognition (ASR) research and applications.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nConfigs:\n\ndefault\n\nData Files:\n\nSplit: train\n\nDataset Info:\n\nFeatures:\naudio: Audio file (mono‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mide7x/hausa_voice_dataset.","url":"https://huggingface.co/datasets/mide7x/hausa_voice_dataset","creator_name":"Olumide Adewole","creator_url":"https://huggingface.co/mide7x","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","audio-classification","keyword-spotting","audio-language-identification","Hausa"],"keywords_longer_than_N":true},
	{"name":"semeval-2025-task11-track-a","keyword":"hausa","description":"\n\t\n\t\t\n\t\tSemEval 2025 Task 11 - Track A Dataset\n\t\n\nThis dataset contains the data for SemEval 2025 Task 11: Bridging the Gap in Text-Based Emotion Detection - Track A, organized as language-specific configurations.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset is a multi-language, multi-label emotion classification dataset with separate configurations for each language.\n\nTotal languages: 26 standard ISO codes\nTotal examples: 115159\nSplits: train, dev, test\n\n\n\t\n\t\t\n\t\tLanguage Configurations\n\t\n\nEach‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/vgaraujov/semeval-2025-task11-track-a.","url":"https://huggingface.co/datasets/vgaraujov/semeval-2025-task11-track-a","creator_name":"Vladimir Araujo","creator_url":"https://huggingface.co/vgaraujov","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["Afrikaans","Amharic","Arabic","German","English"],"keywords_longer_than_N":true},
	{"name":"aya_dataset","keyword":"hausa","description":"\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThe Aya Dataset is a multilingual instruction fine-tuning dataset curated by an open-science community via Aya Annotation Platform from Cohere Labs. The dataset contains a total of 204k human-annotated prompt-completion pairs along with the demographics data of the annotators.\nThis dataset can be used to train, finetune, and evaluate multilingual LLMs.\n\nCurated by: Contributors of Aya Open Science Intiative.\n\nLanguage(s): 65 languages (71 including dialects &‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/CohereLabs/aya_dataset.","url":"https://huggingface.co/datasets/CohereLabs/aya_dataset","creator_name":"Cohere Labs","creator_url":"https://huggingface.co/CohereLabs","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["other","crowdsourced","expert-generated","crowdsourced","expert-generated"],"keywords_longer_than_N":true},
	{"name":"fleurs_clean","keyword":"hausa","description":"\n\t\n\t\t\n\t\n\t\n\t\tFLEURS\n\t\n\nFleurs is the speech version of the FLoRes machine translation benchmark. \nWe use 2009 n-way parallel sentences from the FLoRes dev and devtest publicly available sets, in 102 languages. \nTraining sets have around 10 hours of supervision. Speakers of the train sets are different than speakers from the dev/test sets. Multilingual fine-tuning is\nused and ‚Äùunit error rate‚Äù (characters, signs) of all languages is averaged. Languages and results are also grouped into seven‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Helloworld668/fleurs_clean.","url":"https://huggingface.co/datasets/Helloworld668/fleurs_clean","creator_name":"zhide Tang","creator_url":"https://huggingface.co/Helloworld668","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","expert-generated","crowdsourced","machine-generated","crowdsourced"],"keywords_longer_than_N":true},
	{"name":"BRIGHTER-emotion-intensities","keyword":"hausa","description":"\n\t\n\t\t\n\t\tBRIGHTER Emotion Intensities Dataset\n\t\n\nThis dataset contains the emotion intensities data from the BRIGHTER paper: BRIdging the Gap in Human-Annotated Textual Emotion Recognition Datasets for 28 Languages.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe BRIGHTER Emotion Intensities dataset is a comprehensive multi-language emotion intensity dataset with separate configurations for each language. It represents one of the largest human-annotated emotion datasets across multiple languages, providing‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/brighter-dataset/BRIGHTER-emotion-intensities.","url":"https://huggingface.co/datasets/brighter-dataset/BRIGHTER-emotion-intensities","creator_name":"BRIGHTER Dataset","creator_url":"https://huggingface.co/brighter-dataset","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["Arabic","German","English","Spanish","Hausa"],"keywords_longer_than_N":true},
	{"name":"masakhapos","keyword":"hausa","description":"MasakhaPOS is the largest publicly available high-quality dataset for part-of-speech (POS) tagging in 20 African languages. The languages covered are: \n- Bambara (bam)\n- Ghomala (bbj)\n- Ewe (ewe)\n- Fon (fon)\n- Hausa (hau)\n- Igbo (ibo)\n- Kinyarwanda (kin)\n- Luganda (lug)\n- Dholuo (luo) \n- Mossi (mos)\n- Chichewa (nya)\n- Nigerian Pidgin\n- chShona (sna)\n- Kiswahili (swƒÖ)\n- Setswana (tsn)\n- Twi (twi)\n- Wolof (wol)\n- isiXhosa (xho)\n- Yor√πb√° (yor)\n- isiZulu (zul)\n\nThe train/validation/test sets are available for all the ten languages.\n\nFor more details see https://aclanthology.org/2023.acl-long.609/","url":"https://huggingface.co/datasets/masakhane/masakhapos","creator_name":"Masakhane NLP","creator_url":"https://huggingface.co/masakhane","license_name":"Academic Free License v3.0","license_url":"https://choosealicense.com/licenses/afl-3.0/","language":null,"first_N":5,"first_N_keywords":["token-classification","named-entity-recognition","expert-generated","expert-generated","multilingual"],"keywords_longer_than_N":true},
	{"name":"lr-sum","keyword":"hausa","description":"\n\t\n\t\t\n\t\tDataset Card for LR-Sum\n\t\n\nLR-Sum is a automatic summarization dataset of newswire text with a focus on less resourced languages with a cc-by 4.0 license.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nLR-Sum is a permissively-licensed dataset created with the goal of enabling further research in automatic summarization for less-resourced languages.\nLR-Sum contains human-written summaries for 39 languages, many of which are less-resourced. \nThe data is based on the‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/bltlab/lr-sum.","url":"https://huggingface.co/datasets/bltlab/lr-sum","creator_name":"Broadening Linguistic Technologies Lab (BLT Lab)","creator_url":"https://huggingface.co/bltlab","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["summarization","text-generation","found","found","multilingual"],"keywords_longer_than_N":true},
	{"name":"language_tags","keyword":"hausa","description":"\n\t\n\t\t\n\t\tDescription\n\t\n\nDataset listing 27,328 languages and dialects (also includes macrolanguage names).For each language, either the ISO 639 code, the Glottolog code or both are provided.\n\n\t\n\t\t\n\t\tColumns\n\t\n\n\nEnglish_Name: Language name in English (e.g. \"French\").\nNative_Name: If value is not 0, corresponds to the name of the language by native speakers (e.g. \"Fran√ßais\") which may have been found in Wikipedia's nativename field.\nGlottocode: The language tag in the Glottolog convention (e.g.‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/lbourdois/language_tags.","url":"https://huggingface.co/datasets/lbourdois/language_tags","creator_name":"Lo√Øck BOURDOIS","creator_url":"https://huggingface.co/lbourdois","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["Afade","Par√° Ar√°ra","Afar","Aka-Bea","Abon"],"keywords_longer_than_N":true},
	{"name":"fleurs","keyword":"hausa","description":"\n\t\n\t\t\n\t\tFLEURS\n\t\n\nFleurs is the speech version of the FLoRes machine translation benchmark. \nWe use 2009 n-way parallel sentences from the FLoRes dev and devtest publicly available sets, in 102 languages. \nTraining sets have around 10 hours of supervision. Speakers of the train sets are different than speakers from the dev/test sets. Multilingual fine-tuning is\nused and ‚Äùunit error rate‚Äù (characters, signs) of all languages is averaged. Languages and results are also grouped into seven‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/cahya/fleurs.","url":"https://huggingface.co/datasets/cahya/fleurs","creator_name":"Cahya Wirawan","creator_url":"https://huggingface.co/cahya","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":null,"first_N":5,"first_N_keywords":["automatic-speech-recognition","expert-generated","crowdsourced","machine-generated","crowdsourced"],"keywords_longer_than_N":true},
	{"name":"hausa-tts-csv","keyword":"hausa","description":"\n\t\n\t\t\n\t\tHausa TTS Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset contains Hausa language text-to-speech (TTS) recordings from multiple speakers. It includes audio files paired with their corresponding Hausa text transcriptions.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nThe dataset is organized as follows:\n‚îú‚îÄ‚îÄ data/\n‚îÇ   ‚îú‚îÄ‚îÄ metadata.csv                    # Metadata (source, audio paths, text)\n‚îÇ   ‚îî‚îÄ‚îÄ audio_files/\n‚îÇ       ‚îú‚îÄ‚îÄ 97f373e8-f6e6-.../          # Speaker 1 audio files\n‚îÇ       ‚îú‚îÄ‚îÄ‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Aybee5/hausa-tts-csv.","url":"https://huggingface.co/datasets/Aybee5/hausa-tts-csv","creator_name":"Ibrahim Abdullahi","creator_url":"https://huggingface.co/Aybee5","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-to-speech","audio-classification","Hausa","cc-by-4.0","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"hausa-tts-csv","keyword":"hausa","description":"\n\t\n\t\t\n\t\tHausa TTS Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset contains Hausa language text-to-speech (TTS) recordings from multiple speakers. It includes audio files paired with their corresponding Hausa text transcriptions.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nThe dataset is organized as follows:\n‚îú‚îÄ‚îÄ data/\n‚îÇ   ‚îú‚îÄ‚îÄ metadata.csv                    # Metadata (source, audio paths, text)\n‚îÇ   ‚îî‚îÄ‚îÄ audio_files/\n‚îÇ       ‚îú‚îÄ‚îÄ 97f373e8-f6e6-.../          # Speaker 1 audio files\n‚îÇ       ‚îú‚îÄ‚îÄ‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Aybee5/hausa-tts-csv.","url":"https://huggingface.co/datasets/Aybee5/hausa-tts-csv","creator_name":"Ibrahim Abdullahi","creator_url":"https://huggingface.co/Aybee5","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-to-speech","audio-classification","Hausa","cc-by-4.0","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"tatoeba","keyword":"hausa","description":"This is a collection of translated sentences from Tatoeba\n359 languages, 3,403 bitexts\ntotal number of files: 750\ntotal number of tokens: 65.54M\ntotal number of sentence fragments: 8.96M","url":"https://huggingface.co/datasets/Helsinki-NLP/tatoeba","creator_name":"Language Technology Research Group at the University of Helsinki","creator_url":"https://huggingface.co/Helsinki-NLP","license_name":"Creative Commons Attribution 2.0","license_url":"https://scancode-licensedb.aboutcode.org/cc-by-2.0.html","language":null,"first_N":5,"first_N_keywords":["translation","found","found","multilingual","original"],"keywords_longer_than_N":true},
	{"name":"ms_terms","keyword":"hausa","description":"The Microsoft Terminology Collection can be used to develop localized versions of applications that integrate with Microsoft products.\nIt can also be used to integrate Microsoft terminology into other terminology collections or serve as a base IT glossary\nfor language development in the nearly 100 languages available. Terminology is provided in .tbx format, an industry standard for terminology exchange.","url":"https://huggingface.co/datasets/microsoft/ms_terms","creator_name":"Microsoft","creator_url":"https://huggingface.co/microsoft","license_name":"Microsoft Public License","license_url":"https://choosealicense.com/licenses/ms-pl/","language":null,"first_N":5,"first_N_keywords":["translation","expert-generated","expert-generated","multilingual","translation"],"keywords_longer_than_N":true},
	{"name":"common_voice_17_0","keyword":"hausa","description":"\n\t\n\t\t\n\t\tDataset Card for Common Voice Corpus 17.0\n\t\n\n\n\nThis dataset is an unofficial version of the Mozilla Common Voice Corpus 17. It was downloaded and converted from the project's website https://commonvoice.mozilla.org/.\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nAbkhaz, Albanian, Amharic, Arabic, Armenian, Assamese, Asturian, Azerbaijani, Basaa, Bashkir, Basque, Belarusian, Bengali, Breton, Bulgarian, Cantonese, Catalan, Central Kurdish, Chinese (China), Chinese (Hong Kong), Chinese (Taiwan), Chuvash, Czech‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/fsicoli/common_voice_17_0.","url":"https://huggingface.co/datasets/fsicoli/common_voice_17_0","creator_name":"Fabio Sicoli","creator_url":"https://huggingface.co/fsicoli","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":null,"first_N":5,"first_N_keywords":["automatic-speech-recognition","Abkhaz","Afrikaans","Amharic","Arabic"],"keywords_longer_than_N":true},
	{"name":"tulu-3-sft-olmo-2-mixture","keyword":"hausa","description":"Note that this collection is licensed under ODC-BY-1.0 license; different licenses apply to subsets of the data. Some portions of the dataset are non-commercial. We present the mixture as a research artifact.\nThe OLMo v2 SFT mixture was used to train the OLMo models.\nIt contains 939,344 samples from the following sets:\n\nCoCoNot (ODC-BY-1.0), 10,983 prompts (Brahman et al., 2024)\nFLAN v2 via ai2-adapt-dev/flan_v2_converted, 89,982 prompts (Longpre et al., 2023)\nNo Robots (CC-BY-NC-4.0), 9,500‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/allenai/tulu-3-sft-olmo-2-mixture.","url":"https://huggingface.co/datasets/allenai/tulu-3-sft-olmo-2-mixture","creator_name":"Ai2","creator_url":"https://huggingface.co/allenai","license_name":"Open Data Commons Attribution License v1.0","license_url":"https://scancode-licensedb.aboutcode.org/odc-by-1.0.html","language":"en","first_N":5,"first_N_keywords":["other","crowdsourced","expert-generated","machine-generated","multilingual"],"keywords_longer_than_N":true},
	{"name":"entity_cs","keyword":"hausa","description":"\n\t\n\t\t\n\t\tDataset Card for EntityCS\n\t\n\n\nRepository: https://github.com/huawei-noah/noah-research/tree/master/NLP/EntityCS  \nPaper: https://aclanthology.org/2022.findings-emnlp.499.pdf  \nPoint of Contact: Fenia Christopoulou, Chenxi Whitehouse\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Description\n\t\n\nWe use the English Wikipedia and leverage entity information from Wikidata to construct an entity-based Code Switching corpus. \nTo achieve this, we make use of wikilinks in Wikipedia, i.e. links from one page to another.‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/huawei-noah/entity_cs.","url":"https://huggingface.co/datasets/huawei-noah/entity_cs","creator_name":"HUAWEI Noah's Ark Lab","creator_url":"https://huggingface.co/huawei-noah","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["Afrikaans","Amharic","Arabic","Assamese","Azerbaijani"],"keywords_longer_than_N":true},
	{"name":"hausa-tts","keyword":"hausa","description":"\n\t\n\t\t\n\t\tHausa TTS Dataset\n\t\n\nMulti-speaker Hausa text-to-speech dataset.\n\n\t\n\t\t\n\t\tUsage\n\t\n\nfrom datasets import load_dataset, Audio\n\n# Load the dataset\nds = load_dataset(\"parquet\", data_files=\"hausa_tts_embedded.parquet\", split=\"train\")\n\n# Cast audio column to Audio type with 24kHz sampling rate\nds = ds.cast_column(\"audio\", Audio(sampling_rate=24000))\n\n# Use with Unsloth TTS\nfrom transformers import AutoProcessor\nprocessor = AutoProcessor.from_pretrained(\"unsloth/csm-1b\")\n\n# Your training code‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Aybee5/hausa-tts.","url":"https://huggingface.co/datasets/Aybee5/hausa-tts","creator_name":"Ibrahim Abdullahi","creator_url":"https://huggingface.co/Aybee5","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-to-speech","Hausa","cc-by-4.0","1K<n<10K","Audio"],"keywords_longer_than_N":true},
	{"name":"hausa-tts","keyword":"hausa","description":"\n\t\n\t\t\n\t\tHausa TTS Dataset\n\t\n\nMulti-speaker Hausa text-to-speech dataset.\n\n\t\n\t\t\n\t\tUsage\n\t\n\nfrom datasets import load_dataset, Audio\n\n# Load the dataset\nds = load_dataset(\"parquet\", data_files=\"hausa_tts_embedded.parquet\", split=\"train\")\n\n# Cast audio column to Audio type with 24kHz sampling rate\nds = ds.cast_column(\"audio\", Audio(sampling_rate=24000))\n\n# Use with Unsloth TTS\nfrom transformers import AutoProcessor\nprocessor = AutoProcessor.from_pretrained(\"unsloth/csm-1b\")\n\n# Your training code‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Aybee5/hausa-tts.","url":"https://huggingface.co/datasets/Aybee5/hausa-tts","creator_name":"Ibrahim Abdullahi","creator_url":"https://huggingface.co/Aybee5","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-to-speech","Hausa","cc-by-4.0","1K<n<10K","Audio"],"keywords_longer_than_N":true},
	{"name":"semeval-2025-task11-track-c","keyword":"hausa","description":"\n\t\n\t\t\n\t\tSemEval 2025 Task 11 - Track C Dataset\n\t\n\nThis dataset contains the data for SemEval 2025 Task 11: Bridging the Gap in Text-Based Emotion Detection - Track C, organized as language-specific configurations.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset is a multi-language, multi-label emotion classification dataset with separate configurations for each language.\n\nTotal languages: 30 standard ISO codes\nTotal examples: 57254\nSplits: dev, test (Track C has no train split)\n\n\n\t\n\t\t\n\t\tTrack‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/vgaraujov/semeval-2025-task11-track-c.","url":"https://huggingface.co/datasets/vgaraujov/semeval-2025-task11-track-c","creator_name":"Vladimir Araujo","creator_url":"https://huggingface.co/vgaraujov","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["Afrikaans","Amharic","Arabic","German","English"],"keywords_longer_than_N":true},
	{"name":"HPLT2.0_cleaned","keyword":"hausa","description":"This is a large-scale collection of web-crawled documents in 191 world languages, produced by the HPLT project. \nThe source of the data is mostly Internet Archive with some additions from Common Crawl.\nFor a detailed description of the dataset, please refer to our website and our pre-print.\n\n\t\n\t\t\n\t\n\t\n\t\tThe Cleaned variant of HPLT Datasets v2.0\n\t\n\nThis is the cleaned variant of the HPLT Datasets v2.0 converted to the Parquet format semi-automatically when being uploaded here. \nThe original‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/HPLT/HPLT2.0_cleaned.","url":"https://huggingface.co/datasets/HPLT/HPLT2.0_cleaned","creator_name":"HPLT","creator_url":"https://huggingface.co/HPLT","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["fill-mask","text-generation","language-modeling","multilingual","Achinese"],"keywords_longer_than_N":true},
	{"name":"english-hausa_sentence-pairs_mt560","keyword":"hausa","description":"\n\t\n\t\t\n\t\tEnglish-Hausa Parallel Dataset\n\t\n\nThis dataset contains parallel sentences in English and Hausa (Nigeria).\n\n\t\n\t\t\n\t\tDataset Information\n\t\n\n\nLanguage Pair: English ‚Üî Hausa\nLanguage Code: hau\nCountry: Nigeria\nOriginal Source: OPUS MT560 Dataset\n\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nThe dataset contains parallel sentences that can be used for:\n\nMachine translation training\nCross-lingual NLP tasks\nLanguage model fine-tuning\n\n\n\t\n\t\t\n\t\tCitation\n\t\n\nIf you use this dataset, please cite the citation‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/michsethowusu/english-hausa_sentence-pairs_mt560.","url":"https://huggingface.co/datasets/michsethowusu/english-hausa_sentence-pairs_mt560","creator_name":"Mich-Seth Owusu","creator_url":"https://huggingface.co/michsethowusu","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["translation","original","English","Hausa","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"english-hausa_sentence-pairs_mt560","keyword":"hausa","description":"\n\t\n\t\t\n\t\tEnglish-Hausa Parallel Dataset\n\t\n\nThis dataset contains parallel sentences in English and Hausa (Nigeria).\n\n\t\n\t\t\n\t\tDataset Information\n\t\n\n\nLanguage Pair: English ‚Üî Hausa\nLanguage Code: hau\nCountry: Nigeria\nOriginal Source: OPUS MT560 Dataset\n\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nThe dataset contains parallel sentences that can be used for:\n\nMachine translation training\nCross-lingual NLP tasks\nLanguage model fine-tuning\n\n\n\t\n\t\t\n\t\tCitation\n\t\n\nIf you use this dataset, please cite the citation‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/michsethowusu/english-hausa_sentence-pairs_mt560.","url":"https://huggingface.co/datasets/michsethowusu/english-hausa_sentence-pairs_mt560","creator_name":"Mich-Seth Owusu","creator_url":"https://huggingface.co/michsethowusu","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["translation","original","English","Hausa","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"reranker_continuous_filt_max7_train","keyword":"hausa","description":"\n\t\n\t\t\n\t\tReranker training data\n\t\n\nThis data was generated using 4 steps:\n\nWe gathered queries and corresponding text data from 35 high quality datasets covering more than 95 languages.\nFor datasets which did not already have negative texts for queries, we mined hard negatives using the BAAI/bge-m3 embedding model.\nFor each query, we selected one positive and one negative text and used Qwen/Qwen2.5-32B-Instruct-GPTQ-Int4 to rate the relatedness of each query-text pair using a token \"1\", \"2\"‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/lightblue/reranker_continuous_filt_max7_train.","url":"https://huggingface.co/datasets/lightblue/reranker_continuous_filt_max7_train","creator_name":"Lightblue KK.","creator_url":"https://huggingface.co/lightblue","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["English","Chinese","Spanish","German","Arabic"],"keywords_longer_than_N":true},
	{"name":"eng_montok","keyword":"hausa","description":"\n\t\n\t\t\n\t\tMonTok: A Suite of Monolingual Tokenizers\n\t\n\nThis is a set of monolingual tokenizers for 98 languages. For each language, there are Unigram, BPE, and SuperBPE tokenizers, ranging in vocabulary size from around 6k to over 200k.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\n","url":"https://huggingface.co/datasets/catherinearnett/eng_montok","creator_name":"Catherine Arnett","creator_url":"https://huggingface.co/catherinearnett","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["Afrikaans","Tosk Albanian","Amharic","Standard Arabic","Assamese"],"keywords_longer_than_N":true},
	{"name":"QuantumAI","keyword":"hausa","description":"Groovy-123/QuantumAI dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/Groovy-123/QuantumAI","creator_name":"KWAME MARFO","creator_url":"https://huggingface.co/Groovy-123","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","table-question-answering","question-answering","zero-shot-classification"],"keywords_longer_than_N":true},
	{"name":"multilingual_translation_gpt4o_gen","keyword":"hausa","description":"Youseff1987/multilingual_translation_gpt4o_gen dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/Youseff1987/multilingual_translation_gpt4o_gen","creator_name":"JOON HYOUNG JUN","creator_url":"https://huggingface.co/Youseff1987","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["translation","Korean","English","Chinese","Zulu"],"keywords_longer_than_N":true},
	{"name":"HausaHate","keyword":"hausa","description":"\n\t\n\t\t\n\t\tEvaluation Benchmark for Hausa Hate Speech Detection\n\t\n\nWe introduce the first expert annotated corpus of Facebook comments for Hausa hate speech detection. \nThe corpus titled HausaHate comprises 2,000 comments extracted from Western African Facebook pages and\nmanually annotated by three Hausa native speakers, who are also NLP experts. \nThe corpus was annotated using two different layers. We first labeled each comment according to a \nbinary classification: offensive versus‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/franciellevargas/HausaHate.","url":"https://huggingface.co/datasets/franciellevargas/HausaHate","creator_name":"Francielle Vargas","creator_url":"https://huggingface.co/franciellevargas","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","Hausa","apache-2.0","1K - 10K","csv"],"keywords_longer_than_N":true},
	{"name":"aya_collection","keyword":"hausa","description":"\nThis dataset is uploaded in two places: here and additionally here as 'Aya Collection Language Split.' These datasets are identical in content but differ in structure of upload. This dataset is structured by folders split according to dataset name. The version here instead divides the Aya collection into folders split by language. We recommend you use the language split version if you are only interested in downloading data for a single or smaller set of languages, and this version if you‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/CohereLabs/aya_collection.","url":"https://huggingface.co/datasets/CohereLabs/aya_collection","creator_name":"Cohere Labs","creator_url":"https://huggingface.co/CohereLabs","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","summarization","translation","Achinese","Afrikaans"],"keywords_longer_than_N":true},
	{"name":"semeval-2025-task11-track-b","keyword":"hausa","description":"\n\t\n\t\t\n\t\tSemEval 2025 Task 11 - Track B Dataset\n\t\n\nThis dataset contains the data for SemEval 2025 Task 11: Bridging the Gap in Text-Based Emotion Detection - Track B, organized as language-specific configurations.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset is a multi-language, multi-label emotion classification dataset with separate configurations for each language.\n\nTotal languages: 11 standard ISO codes\nTotal examples: 47111\nSplits: train, dev, test\n\n\n\t\n\t\t\n\t\tTrack Information\n\t\n\nTrack B has‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/vgaraujov/semeval-2025-task11-track-b.","url":"https://huggingface.co/datasets/vgaraujov/semeval-2025-task11-track-b","creator_name":"Vladimir Araujo","creator_url":"https://huggingface.co/vgaraujov","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["Amharic","Arabic","German","English","Spanish"],"keywords_longer_than_N":true},
	{"name":"mHumanEval-Benchmark","keyword":"hausa","description":"\n\n\n\t\n\t\t\n\t\tüî∑ Accepted in NAACL Proceedings (2025) üî∑\n\t\n\n\n\n\n\n  \n    \n      \n        \n          \n        \n      \n      \n        \n          \n        \n      \n      \n        \n          \n        \n      \n    \n  \n\n\n\n\n\n  \n\n\t\n\t\n\t\n\t\tmHumanEval\n\t\n\nThe mHumanEval benchmark is curated based on prompts from the original HumanEval üìö [Chen et al., 2021]. It includes a total of 33,456 prompts for Python, and 836,400 in total - significantly expanding from the original 164. \n\n\n\t\n\t\t\n\t\tQuick Start\n\t\n\n  Detailed‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/md-nishat-008/mHumanEval-Benchmark.","url":"https://huggingface.co/datasets/md-nishat-008/mHumanEval-Benchmark","creator_name":"Nishat Raihan","creator_url":"https://huggingface.co/md-nishat-008","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["Afar","Abkhaz","Avestan","Afrikaans","Akan"],"keywords_longer_than_N":true},
	{"name":"biblenlp-corpus-mmteb","keyword":"hausa","description":"This dataset pre-computes all English-centric directions from bible-nlp/biblenlp-corpus, and as a result loading is significantly faster.\nLoading example:\n>>> from datasets import load_dataset\n>>> dataset = load_dataset(\"davidstap/biblenlp-corpus-mmteb\", \"eng-arb\", trust_remote_code=True)\n>>> dataset\nDatasetDict({\n    train: Dataset({\n        features: ['eng', 'arb'],\n        num_rows: 28723\n    })\n    validation: Dataset({\n        features: ['eng', 'arb'],\n        num_rows: 1578\n    })‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/davidstap/biblenlp-corpus-mmteb.","url":"https://huggingface.co/datasets/davidstap/biblenlp-corpus-mmteb","creator_name":"David Stap","creator_url":"https://huggingface.co/davidstap","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["no-annotation","expert-generated","translation","multilingual","Arifama-Miniafia"],"keywords_longer_than_N":true},
	{"name":"hausa_long_voice_dataset","keyword":"hausa","description":"\n\t\n\t\t\n\t\tDataset Card for \"hausa_long_voice_dataset\"\n\t\n\n\n\t\n\t\t\n\t\tDataset Overview\n\t\n\nDataset Name: Hausa Long Voice Dataset\nDescription: This dataset contains merged Hausa language audio samples from Common Voice. Audio files from the same speaker have been concatenated to create longer audio samples with their corresponding transcriptions, designed for text-to-speech (TTS) training where longer sequences are beneficial.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nConfigs:\n\ndefault\n\nData Files:\n\nSplit: train‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mide7x/hausa_long_voice_dataset.","url":"https://huggingface.co/datasets/mide7x/hausa_long_voice_dataset","creator_name":"Olumide Adewole","creator_url":"https://huggingface.co/mide7x","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","audio-classification","speaker-identification","audio-language-identification","Hausa"],"keywords_longer_than_N":true},
	{"name":"muri-it","keyword":"hausa","description":"\n\t\n\t\t\n\t\tMURI-IT: Multilingual Instruction Tuning Dataset for 200 Languages via Multilingual Reverse Instructions\n\t\n\nMURI-IT is a large-scale multilingual instruction tuning dataset containing 2.2 million instruction-output pairs across 200 languages. It is designed to address the challenges of instruction tuning in low-resource languages with Multilingual Reverse Instructions (MURI), which ensures that the output is human-written, high-quality, and authentic to the cultural and linguistic‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/akoksal/muri-it.","url":"https://huggingface.co/datasets/akoksal/muri-it","creator_name":"Abdullatif Koksal","creator_url":"https://huggingface.co/akoksal","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text2text-generation","text-generation","question-answering","summarization","Achinese"],"keywords_longer_than_N":true},
	{"name":"ParaNames","keyword":"hausa","description":"\n\t\n\t\t\n\t\n\t\n\t\tDataset Card for Dataset Name\n\t\n\n\n\nThis dataset card aims to be a base template for new datasets. It has been generated using this raw template.\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Description\n\t\n\n\n\n\n\n\nCurated by: [More Information Needed]\nFunded by [optional]: [More Information Needed]\nShared by [optional]: [More Information Needed]\nLanguage(s) (NLP): [More Information Needed]\nLicense: [More Information Needed]\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Sources [optional]‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/bltlab/ParaNames.","url":"https://huggingface.co/datasets/bltlab/ParaNames","creator_name":"Broadening Linguistic Technologies Lab (BLT Lab)","creator_url":"https://huggingface.co/bltlab","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["token-classification","Nias","Kotava","Banjar","Angika"],"keywords_longer_than_N":true},
	{"name":"naijaweb","keyword":"hausa","description":"\n\t\n\t\t\n\t\tNaijaweb Dataset üá≥üá¨\n\t\n\nNaijaweb is a dataset that contains over 270,000+ documents, totaling approximately 230 million GPT-2 tokens. The data was web scraped from web pages popular among Nigerians, providing a rich resource for modeling Nigerian linguistic and cultural contexts.\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\n\n\t\n\t\t\nFeatures\nData Types\n\n\n\t\t\ntext\nstring\n\n\nlink\nstring\n\n\ntoken_count\nint64\n\n\nsection\nstring\n\n\nint_score\nint64\n\n\nlanguage\nstring\n\n\nlanguage_probability\nfloat64‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/saheedniyi/naijaweb.","url":"https://huggingface.co/datasets/saheedniyi/naijaweb","creator_name":"Saheed Azeez Ayanniyi","creator_url":"https://huggingface.co/saheedniyi","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-generation","English","Yoruba","Hausa","Igbo"],"keywords_longer_than_N":true},
	{"name":"xP3x-Kongo","keyword":"hausa","description":"\n\t\n\t\t\n\t\tDataset Card for xP3x Kikongo Focus\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\n\nxP3x (Crosslingual Public Pool of Prompts eXtended) is a collection of prompts & datasets across 277 languages & 16 NLP tasks. It contains all of xP3 + much more! It is used for training future contenders of mT0 & BLOOMZ at project Aya @C4AI üß°\n\n\nCreation: The dataset can be recreated using instructions available here together with the file in this repository named xp3x_create.py. We provide this version to save‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Svngoku/xP3x-Kongo.","url":"https://huggingface.co/datasets/Svngoku/xP3x-Kongo","creator_name":"NIONGOLO Chrys F√©-Marty","creator_url":"https://huggingface.co/Svngoku","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["other","translation","expert-generated","crowdsourced","multilingual"],"keywords_longer_than_N":true},
	{"name":"NaijaSenti","keyword":"hausa","description":"\n  NaijaSenti\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nNaijaSenti is the first large-scale human-annotated Twitter sentiment dataset for the four most widely spoken languages in Nigeria ‚Äî Hausa, Igbo, Nigerian-Pidgin, and Yor√πb√° ‚Äî consisting of around 30,000 annotated tweets per language, including a significant fraction of code-mixed tweets.\n\n\t\n\n\n\n\n\t\t\nTask category\nt2c\n\n\nDomains\nSocial, Written\n\n\nReference\nhttps://github.com/hausanlp/NaijaSenti\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/NaijaSenti.","url":"https://huggingface.co/datasets/mteb/NaijaSenti","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","sentiment-analysis","sentiment-scoring","sentiment-classification","hate-speech-detection"],"keywords_longer_than_N":true},
	{"name":"afrimgsm","keyword":"hausa","description":"\n\t\n\t\t\n\t\tDataset Card for afrimgsm\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nAFRIMGSM is an evaluation dataset comprising translations of a subset of the GSM8k dataset into 16 African languages. \nIt includes test sets across all 18 languages, maintaining an English and French subsets from the original GSM8k dataset. \n\n\t\n\t\t\n\t\tLanguages\n\t\n\nThere are 18 languages available :\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\n\t\n\t\t\n\t\tData Instances\n\t\n\nThe examples look like this for English:\nfrom datasets import load_dataset\ndata =‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/yuntian-deng/afrimgsm.","url":"https://huggingface.co/datasets/yuntian-deng/afrimgsm","creator_name":"Yuntian Deng","creator_url":"https://huggingface.co/yuntian-deng","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text2text-generation","natural-language-inference","multilingual","gsm8k","Amharic"],"keywords_longer_than_N":true},
	{"name":"reranking-datasets-light","keyword":"hausa","description":"\n\t\n\t\t\n\t\tüî• Rankify: A Comprehensive Python Toolkit for Retrieval, Re-Ranking, and Retrieval-Augmented Generation üî•\n\t\n\n\n\t\n\t\t\n\t\n\t\n\t\tReRanking Datasets : A comprehensive collection of retrieval and reranking datasets with full passage contexts, including titles, text, and metadata for in-depth research.\n\t\n\n\n    \n    \n    \n    \n    \n    \n        \n    \n    \n        \n    \n    \n        \n    \n    \n        \n    \n    \n    \n\n\n\nA curated collection of ready-to-use datasets for retrieval and reranking‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/abdoelsayed/reranking-datasets-light.","url":"https://huggingface.co/datasets/abdoelsayed/reranking-datasets-light","creator_name":"Abdelrahman Abdallah","creator_url":"https://huggingface.co/abdoelsayed","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["question-answering","English","Arabic","German","French"],"keywords_longer_than_N":true},
	{"name":"ciral","keyword":"hausa","description":"This dataset consists of the queries and relevance judgements in the CIRAL test collection.","url":"https://huggingface.co/datasets/CIRAL/ciral","creator_name":"Cross-lingual Information Retrieval for African Languages","creator_url":"https://huggingface.co/CIRAL","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":null,"first_N":5,"first_N_keywords":["text-retrieval","Hausa","Somali","Swahili","Yoruba"],"keywords_longer_than_N":true},
	{"name":"common_voice_16_0","keyword":"hausa","description":"\n\t\n\t\t\n\t\tDataset Card for Common Voice Corpus 16.0\n\t\n\n\n\nThis dataset is an unofficial version of the Mozilla Common Voice Corpus 16. It was downloaded and converted from the project's website https://commonvoice.mozilla.org/.\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nAbkhaz, Albanian, Amharic, Arabic, Armenian, Assamese, Asturian, Azerbaijani, Basaa, Bashkir, Basque, Belarusian, Bengali, Breton, Bulgarian, Cantonese, Catalan, Central Kurdish, Chinese (China), Chinese (Hong Kong), Chinese (Taiwan), Chuvash, Czech‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/fsicoli/common_voice_16_0.","url":"https://huggingface.co/datasets/fsicoli/common_voice_16_0","creator_name":"Fabio Sicoli","creator_url":"https://huggingface.co/fsicoli","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":null,"first_N":5,"first_N_keywords":["automatic-speech-recognition","Abkhaz","Afrikaans","Amharic","Arabic"],"keywords_longer_than_N":true},
	{"name":"ciral-corpus","keyword":"hausa","description":"\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nCIRAL is a collection for cross-lingual information retrieval research across four (4) African languages. The collection comprises English queries and query-passage relevance judgements manually annotated by native speakers.\nThis dataset stores passages which have been culled from news websites for CIRAL.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nThis dataset is configured by language. An example of a passage data entry is\n{\n    'docid': 'DOCID#0#0',\n    'title': 'This is the‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/CIRAL/ciral-corpus.","url":"https://huggingface.co/datasets/CIRAL/ciral-corpus","creator_name":"Cross-lingual Information Retrieval for African Languages","creator_url":"https://huggingface.co/CIRAL","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":null,"first_N":5,"first_N_keywords":["Hausa","Somali","Swahili","Yoruba","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"Langbridge_wazobia_data","keyword":"hausa","description":"\n\t\n\t\t\n\t\tLangBridge Multilingual Translation Dataset üá≥üá¨\n\t\n\n\n\t\n\t\t\n\t\n\t\n\t\tThis dataset contains parallel translation pairs between Yoruba (yor_Latn), Hausa (hau_Latn), Igbo (ibo_Latn), and English (eng_Latn).\nIt was designed for fine-tuning multilingual translation models such as facebook/nllb-200-distilled-600M, in order for it to achieve state of the art performance at translation tasks.\n\t\n\t\n\t\t\n\t\tüì¶ Dataset Summary\n\t\n\nThe LangBridge dataset provides approximately 3.5 million translation pairs‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/coded-by-49/Langbridge_wazobia_data.","url":"https://huggingface.co/datasets/coded-by-49/Langbridge_wazobia_data","creator_name":"Henry Aloh Fabian","creator_url":"https://huggingface.co/coded-by-49","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["original","Yoruba","Hausa","Igbo","English"],"keywords_longer_than_N":true},
	{"name":"xtreme_s","keyword":"hausa","description":"XTREME-S covers four task families: speech recognition, classification, speech-to-text translation and retrieval. Covering 102\nlanguages from 10+ language families, 3 different domains and 4\ntask families, XTREME-S aims to simplify multilingual speech\nrepresentation evaluation, as well as catalyze research in ‚Äúuniversal‚Äù speech representation learning.","url":"https://huggingface.co/datasets/google/xtreme_s","creator_name":"Google","creator_url":"https://huggingface.co/google","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":null,"first_N":5,"first_N_keywords":["automatic-speech-recognition","expert-generated","crowdsourced","machine-generated","crowdsourced"],"keywords_longer_than_N":true},
	{"name":"hausa_voa_ner","keyword":"hausa","description":"The Hausa VOA NER dataset is a labeled dataset for named entity recognition in Hausa. The texts were obtained from\nHausa Voice of America News articles https://www.voahausa.com/ . We concentrate on\nfour types of named entities: persons [PER], locations [LOC], organizations [ORG], and dates & time [DATE].\n\nThe Hausa VOA NER data files contain 2 columns separated by a tab ('\\t'). Each word has been put on a separate line and\nthere is an empty line after each sentences i.e the CoNLL format. The first item on each line is a word, the second\nis the named entity tag. The named entity tags have the format I-TYPE which means that the word is inside a phrase\nof type TYPE. For every multi-word expression like 'New York', the first word gets a tag B-TYPE and the subsequent words\nhave tags I-TYPE, a word with tag O is not part of a phrase. The dataset is in the BIO tagging scheme.\n\nFor more details, see https://www.aclweb.org/anthology/2020.emnlp-main.204/","url":"https://huggingface.co/datasets/UdS-LSV/hausa_voa_ner","creator_name":"LSV @ Saarland University","creator_url":"https://huggingface.co/UdS-LSV","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":null,"first_N":5,"first_N_keywords":["token-classification","named-entity-recognition","expert-generated","expert-generated","monolingual"],"keywords_longer_than_N":true},
	{"name":"wmt-human-all","keyword":"hausa","description":"This dataset is continuously updated and contains a compilation of human translation quality assessment from past WMT campaigns.\nSpecifically, this dataset merges all annotation protocols (DA, MQM, ESA) on a semi-unified scale (0 to 100).\nThe current version of the dataset includes human scores up to WMT 2024 (inclusive) and has been created with the following script:\nimport subset2evaluate # version 1.0.14\nimport json\nimport statistics\n\ndata =‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/zouharvi/wmt-human-all.","url":"https://huggingface.co/datasets/zouharvi/wmt-human-all","creator_name":"Vil√©m Zouhar","creator_url":"https://huggingface.co/zouharvi","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["Bengali","Czech","German","English","Spanish"],"keywords_longer_than_N":true},
	{"name":"Code-170k-hausa","keyword":"hausa","description":"\n\t\n\t\t\n\t\tDataset Description\n\t\n\nCode-170k-hausa is a groundbreaking dataset containing 14,095 programming conversations, originally sourced from glaiveai/glaive-code-assistant-v2 and translated into Hausa, making coding education accessible to Hausa speakers.\n\n\t\n\t\t\n\t\tüåü Key Features\n\t\n\n\n14,095 high-quality conversations about programming and coding\nPure Hausa language - democratizing coding education\nMulti-turn dialogues covering various programming concepts\nDiverse topics: algorithms, data‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/michsethowusu/Code-170k-hausa.","url":"https://huggingface.co/datasets/michsethowusu/Code-170k-hausa","creator_name":"Mich-Seth Owusu","creator_url":"https://huggingface.co/michsethowusu","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","question-answering","Hausa","apache-2.0","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"Code-170k-hausa","keyword":"hausa","description":"\n\t\n\t\t\n\t\tDataset Description\n\t\n\nCode-170k-hausa is a groundbreaking dataset containing 14,095 programming conversations, originally sourced from glaiveai/glaive-code-assistant-v2 and translated into Hausa, making coding education accessible to Hausa speakers.\n\n\t\n\t\t\n\t\tüåü Key Features\n\t\n\n\n14,095 high-quality conversations about programming and coding\nPure Hausa language - democratizing coding education\nMulti-turn dialogues covering various programming concepts\nDiverse topics: algorithms, data‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/michsethowusu/Code-170k-hausa.","url":"https://huggingface.co/datasets/michsethowusu/Code-170k-hausa","creator_name":"Mich-Seth Owusu","creator_url":"https://huggingface.co/michsethowusu","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","question-answering","Hausa","apache-2.0","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"mc4-sampling","keyword":"hausa","description":"A sampling-enabled version of mC4, the colossal, cleaned version of Common Crawl's web crawl corpus.\n\nBased on Common Crawl dataset: \"https://commoncrawl.org\".\n\nThis is a version of the processed version of Google's mC4 dataset by AllenAI, in which sampling methods are implemented to perform on the fly.","url":"https://huggingface.co/datasets/bertin-project/mc4-sampling","creator_name":"BERTIN Project","creator_url":"https://huggingface.co/bertin-project","license_name":"Open Data Commons Attribution License v1.0","license_url":"https://scancode-licensedb.aboutcode.org/odc-by-1.0.html","language":null,"first_N":5,"first_N_keywords":["text-generation","fill-mask","language-modeling","no-annotation","found"],"keywords_longer_than_N":true},
	{"name":"Pm","keyword":"hausa","description":"Pawamami/Pm dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/Pawamami/Pm","creator_name":"Mamoudou","creator_url":"https://huggingface.co/Pawamami","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":null,"first_N":5,"first_N_keywords":["text-generation","French","English","Hausa","Arabic"],"keywords_longer_than_N":true},
	{"name":"panlex","keyword":"hausa","description":"\n\t\n\t\t\n\t\tPanLex\n\t\n\nJanuary 1, 2024 version of PanLex Language Vocabulary with 24,650,274 rows covering 6,152 languages.\n\n\t\n\t\t\n\t\tColumns\n\t\n\n\nvocab: contains the text entry.  \n639-3: contains the ISO 639-3 languages tags to allow users to filter on the language(s) of their choice.\n639-3_english_name: the English language name associated to the code ISO 639-3. \nvar_code: contains a code to differentiate language variants. In practice, this is the code 639-3 + a number.  If 000, it corresponds to‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/lbourdois/panlex.","url":"https://huggingface.co/datasets/lbourdois/panlex","creator_name":"Lo√Øck BOURDOIS","creator_url":"https://huggingface.co/lbourdois","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["Ghotuo","Alumu-Tesu","Ari","Amal","Arb√´resh√´ Albanian"],"keywords_longer_than_N":true},
	{"name":"base_hausa_datamix","keyword":"hausa","description":"This dataset is created using the composition of diverse Hausa datasets available on Hugging Face.\nEach entry in a given split is composed of a text and source column. The text contains the textual data, meanwhile the source\ncontains the Hub ID from which this data sample has been retrieved from.\nThis dataset was created in the spirit of the HausaLM project.\n","url":"https://huggingface.co/datasets/thiomajid/base_hausa_datamix","creator_name":"Abdoul Majid O. Thiombiano","creator_url":"https://huggingface.co/thiomajid","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","Hausa","apache-2.0","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"ApolloMoEBench","keyword":"hausa","description":"\n\t\n\t\t\n\t\tDemocratizing Medical LLMs For Much More Languages\n\t\n\nCovering 12 Major Languages including English, Chinese, French, Hindi, Spanish, Arabic, Russian, Japanese, Korean, German, Italian, Portuguese and 38 Minor Languages So far.\n\n   üìÉ Paper ‚Ä¢ üåê Demo ‚Ä¢ ü§ó ApolloMoEDataset ‚Ä¢ ü§ó ApolloMoEBench  ‚Ä¢ ü§ó Models  ‚Ä¢üåê Apollo  ‚Ä¢ üåê ApolloMoE\n\n\n\n\n\n\n\t\n\t\t\n\t\tüåà Update\n\t\n\n\n[2024.10.15] ApolloMoE repo is publishedÔºÅüéâ\n\n\n\t\n\t\t\n\t\tLanguages Coverage\n\t\n\n12 Major Languages and 38 Minor Languages\n\n  Click to‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/FreedomIntelligence/ApolloMoEBench.","url":"https://huggingface.co/datasets/FreedomIntelligence/ApolloMoEBench","creator_name":"FreedomAI","creator_url":"https://huggingface.co/FreedomIntelligence","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["question-answering","Arabic","English","Chinese","Korean"],"keywords_longer_than_N":true},
	{"name":"Synthdog-Multilingual-100","keyword":"hausa","description":"\n\t\n\t\t\n\t\tSynthdog Multilingual\n\t\n\n\n\nThe Synthdog dataset created for training in Centurio: On Drivers of Multilingual Ability of Large Vision-Language Model.\nUsing the official Synthdog code, we created >1 million training samples for improving OCR capabilities in Large Vision-Language Models.\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Details\n\t\n\nWe provide the images for download in two .tar.gz files. Download and extract them in folders of the same name (so cat images.tar.gz.* | tar xvzf -C images; tar xvzf‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/WueNLP/Synthdog-Multilingual-100.","url":"https://huggingface.co/datasets/WueNLP/Synthdog-Multilingual-100","creator_name":"W√ºNLP","creator_url":"https://huggingface.co/WueNLP","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["image-to-text","multilingual","Afrikaans","Amharic","Arabic"],"keywords_longer_than_N":true},
	{"name":"MultiQ","keyword":"hausa","description":"\n\t\n\t\t\n\t\tDataset Card for MultiQ\n\t\n\nThis is the dataset corresponding to the paper \"Evaluating the Elementary Multilingual Capabilities of Large Language Models with MultiQ\". \nIt is a silver standard benchmark that can be used to evaluate the basic multilingual capabilities of LLMs. It contains 200 open ended questions automatically \ntranslated into 137 typologically diverse languages. \n\nCurated by: Carolin Holtermann, Paul R√∂ttger, Timm Dill, Anne Lauscher\nLanguage(s) (NLP): 137 diverse‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/caro-holt/MultiQ.","url":"https://huggingface.co/datasets/caro-holt/MultiQ","creator_name":"Holtermann","creator_url":"https://huggingface.co/caro-holt","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["question-answering","Tagalog","Samoan","Macedonian","Gujarati"],"keywords_longer_than_N":true},
	{"name":"xtreme-up-semantic-parsing","keyword":"hausa","description":"\n\t\n\t\t\n\t\tDataset Card for afrixnli\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nSee XTREME-UP GitHub\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nThere are 20 languages available :\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\n\t\n\t\t\n\t\tData Instances\n\t\n\nThe examples look like this for English:\nfrom datasets import load_dataset\ndata = load_dataset('Davlan/xtreme-up-semantic-parsing', 'yor') \n# Please, specify the language code\n# A data point example is below:\n{\n\"id\": \"3231323330393336\",\n\"split\": \"test\",\n\"intent\": \"IN:GET_REMINDER\",\n\"locale\": \"en\"‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Davlan/xtreme-up-semantic-parsing.","url":"https://huggingface.co/datasets/Davlan/xtreme-up-semantic-parsing","creator_name":"David Adelani","creator_url":"https://huggingface.co/Davlan","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","multilingual","Amharic","Belarusian","Bengali"],"keywords_longer_than_N":true},
	{"name":"uhura-truthfulqa","keyword":"hausa","description":"\n\t\n\t\t\n\t\tDataset Card for Uhura-TruthfulQA\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nTruthfulQA is a widely recognized safety benchmark designed to measure the truthfulness of language model outputs across 38 categories, including health, law, finance, and politics. The English version of the benchmark originates from TruthfulQA: Measuring How Models Mimic Human Falsehoods (Lin et al., 2022) and consists of 817 questions in both multiple-choice and generation formats, targeting common misconceptions and‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/masakhane/uhura-truthfulqa.","url":"https://huggingface.co/datasets/masakhane/uhura-truthfulqa","creator_name":"Masakhane NLP","creator_url":"https://huggingface.co/masakhane","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["multiple-choice","question-answering","text-generation","multiple-choice-qa","multilingual"],"keywords_longer_than_N":true},
	{"name":"multilingual_translation_sft","keyword":"hausa","description":"Youseff1987/multilingual_translation_sft dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/Youseff1987/multilingual_translation_sft","creator_name":"JOON HYOUNG JUN","creator_url":"https://huggingface.co/Youseff1987","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["translation","Korean","English","Chinese","Zulu"],"keywords_longer_than_N":true},
	{"name":"hausa","keyword":"hausa","description":"\n\t\n\t\t\n\t\tHausa Dataset\n\t\n\nThe vocabulary foundation is organized by linguistic categories (pronouns, verbs, nouns, adjectives) with over 200 core Hausa words.\n\n\t\n\t\t\n\t\tKey Features\n\t\n\n\nCore Vocabulary Categories:\n\n\nPronouns with gender distinctions (kai/ke for masculine/feminine 'you')\nVerbs covering daily activities and essential actions\nNouns spanning family, nature, time, and cultural concepts\nAdjectives with proper Hausa formations\nNumbers from basic counting to large values\nTime expressions‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/0xnu/hausa.","url":"https://huggingface.co/datasets/0xnu/hausa","creator_name":"Finbarrs Oketunji","creator_url":"https://huggingface.co/0xnu","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["Hausa","apache-2.0","1M - 10M","parquet","Tabular"],"keywords_longer_than_N":true},
	{"name":"hausa","keyword":"hausa","description":"\n\t\n\t\t\n\t\tHausa Dataset\n\t\n\nThe vocabulary foundation is organized by linguistic categories (pronouns, verbs, nouns, adjectives) with over 200 core Hausa words.\n\n\t\n\t\t\n\t\tKey Features\n\t\n\n\nCore Vocabulary Categories:\n\n\nPronouns with gender distinctions (kai/ke for masculine/feminine 'you')\nVerbs covering daily activities and essential actions\nNouns spanning family, nature, time, and cultural concepts\nAdjectives with proper Hausa formations\nNumbers from basic counting to large values\nTime expressions‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/0xnu/hausa.","url":"https://huggingface.co/datasets/0xnu/hausa","creator_name":"Finbarrs Oketunji","creator_url":"https://huggingface.co/0xnu","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["Hausa","apache-2.0","1M - 10M","parquet","Tabular"],"keywords_longer_than_N":true},
	{"name":"common_voice_21_0","keyword":"hausa","description":"Due to storage limits some files had to be split into multiple parts. They can be merged like this: cat file.* > file.\n","url":"https://huggingface.co/datasets/2Jyq/common_voice_21_0","creator_name":"2Jyq","creator_url":"https://huggingface.co/2Jyq","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["crowdsourced","crowdsourced","multilingual","extended|common_voice","Abkhaz"],"keywords_longer_than_N":true},
	{"name":"naijaweb-edu","keyword":"hausa","description":"\n\t\n\t\t\n\t\tNaijaweb Edu Dataset üá≥üá¨\n\t\n\nNaijaweb Edu is a subset of the naijaweb dataset with an educational score aboove 3 using the fineweb classifier. The initial fineweb dataset was web scraped from web pages popular among Nigerians, providing a rich resource for modeling Nigerian linguistic and cultural contexts.\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\n\n\t\n\t\t\nFeatures\nData Types\n\n\n\t\t\ntext\nstring\n\n\nlink\nstring\n\n\ntoken_count\nint64\n\n\nsection\nstring\n\n\nint_score\nint64\n\n\nlanguage\nstring‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/saheedniyi/naijaweb-edu.","url":"https://huggingface.co/datasets/saheedniyi/naijaweb-edu","creator_name":"Saheed Azeez Ayanniyi","creator_url":"https://huggingface.co/saheedniyi","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","text2text-generation","text-generation","English","Yoruba"],"keywords_longer_than_N":true},
	{"name":"hausa-emotions-corpus","keyword":"hausa","description":"\n\t\n\t\t\n\t\tHausa Emotion Analysis Corpus\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset contains emotion-labeled text data in Hausa for emotion classification (joy, sadness, anger, fear, surprise, disgust, neutral). Emotions were extracted and processed from the English meanings of the sentences using the model j-hartmann/emotion-english-distilroberta-base. The dataset is part of a larger collection of African language emotion analysis resources.\n\n\t\n\t\t\n\t\tDataset Statistics\n\t\n\n\nTotal samples: 1‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/michsethowusu/hausa-emotions-corpus.","url":"https://huggingface.co/datasets/michsethowusu/hausa-emotions-corpus","creator_name":"Mich-Seth Owusu","creator_url":"https://huggingface.co/michsethowusu","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","Hausa","mit","1M - 10M","parquet"],"keywords_longer_than_N":true},
	{"name":"tulu3-100samples","keyword":"hausa","description":"\n\t\n\t\t\n\t\tDataset\n\t\n\nThis dataset contains 100 samples from the Tulu 3 SFT Mixture.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nEach example in the dataset contains the standard instruction-tuning data points as follow:\n\nid (str): a unique identifier\nmessages (list): message format used for supervised fine-tuning (this contains user prompt and assistant responses)\nsource (str): the source dataset for the given sample\n\n\n\t\n\t\t\n\t\tLicense\n\t\n\nThis dataset is licensed under ODC-BY-1.0. It is intended for research and‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/anayak/tulu3-100samples.","url":"https://huggingface.co/datasets/anayak/tulu3-100samples","creator_name":"Akash Nayak","creator_url":"https://huggingface.co/anayak","license_name":"Open Data Commons Attribution License v1.0","license_url":"https://scancode-licensedb.aboutcode.org/odc-by-1.0.html","language":null,"first_N":5,"first_N_keywords":["other","crowdsourced","expert-generated","machine-generated","multilingual"],"keywords_longer_than_N":true},
	{"name":"test_4","keyword":"hausa","description":"\n\t\n\t\t\n\t\n\t\n\t\tFLEURS\n\t\n\nFleurs is the speech version of the FLoRes machine translation benchmark. \nWe use 2009 n-way parallel sentences from the FLoRes dev and devtest publicly available sets, in 102 languages. \nTraining sets have around 10 hours of supervision. Speakers of the train sets are different than speakers from the dev/test sets. Multilingual fine-tuning is\nused and ‚Äùunit error rate‚Äù (characters, signs) of all languages is averaged. Languages and results are also grouped into seven‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/tunngo/test_4.","url":"https://huggingface.co/datasets/tunngo/test_4","creator_name":"nguyen tuan","creator_url":"https://huggingface.co/tunngo","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","expert-generated","crowdsourced","machine-generated","crowdsourced"],"keywords_longer_than_N":true},
	{"name":"GlobalNLI","keyword":"hausa","description":"\n\t\n\t\t\n\t\tDataset Card for global_nli\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nGlobal NLI is a new text-based benchmark based on the aggregation of existing NLI datasets that are publicly available.\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nThere are 59 languages available :\n{\n    'amh': 'Amharic',\n    'ara': 'Arabic',\n    'asm': 'Assamese',\n    'aym': 'Aymara',\n    'ben': 'Bengali',\n    'bul': 'Bulgarian',\n    'bzd': 'Bribri',\n    'cat': 'Catalan',\n    'cni': 'Ash√°ninka',\n    'deu': 'German',\n    'ell': 'Greek',\n    'eng':‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/McGill-NLP/GlobalNLI.","url":"https://huggingface.co/datasets/McGill-NLP/GlobalNLI","creator_name":"McGill NLP Group","creator_url":"https://huggingface.co/McGill-NLP","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","natural-language-inference","multilingual","XNLI, AfriXNLI, IndicXNLI, AmericasNLI [30], XNLI-ca, myXNLI, IndoNLI, JNLI , InferBR, sick_pl, JamPatoisNLI, KLUE, RoNLI.","Amharic"],"keywords_longer_than_N":true},
	{"name":"soreva","keyword":"hausa","description":"\n\t\n\t\t\n\t\tSOREVA\n\t\n\nSOREVA (Small Out-of-domain Resource for Various African languages) is a multilingual speech dataset designed for the evaluation of text-to-speech (TTS) and speech representation models in low-resource African languages.\nComming from Goethe Institut intiative of collecting 150 samples(Audio and transcription) for about 49 africain languages and dialectes\nThis dataset specifically targets out-of-domain generalization, addressing the lack of evaluation sets for languages‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/OlameMend/soreva.","url":"https://huggingface.co/datasets/OlameMend/soreva","creator_name":"leo","creator_url":"https://huggingface.co/OlameMend","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":null,"first_N":5,"first_N_keywords":["text-to-speech","automatic-speech-recognition","Afrikaans","Tuki","Basa (Cameroon)"],"keywords_longer_than_N":true},
	{"name":"GlobalNLI","keyword":"hausa","description":"\n\t\n\t\t\n\t\tDataset Card for global_nli\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nGlobal NLI is a new text-based benchmark based on the aggregation of existing NLI datasets that are publicly available.\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nThere are 59 languages available :\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\n\t\n\t\t\n\t\tData Instances\n\t\n\nThe examples look like this for English:\nfrom datasets import load_dataset\ndata = load_dataset('vivekvermaiit/globalnli', 'eng') \n# Please, specify the language code\n# A data point example is below:\n{‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/vivekvermaiit/GlobalNLI.","url":"https://huggingface.co/datasets/vivekvermaiit/GlobalNLI","creator_name":"Vivek Verma","creator_url":"https://huggingface.co/vivekvermaiit","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","natural-language-inference","multilingual","XNLI, AfriXNLI, IndicXNLI, AmericasNLI [30], XNLI-ca, myXNLI, IndoNLI, JNLI , InferBR, sick_pl, JamPatoisNLI, KLUE, RoNLI.","Amharic"],"keywords_longer_than_N":true},
	{"name":"afrixnli-translate-test","keyword":"hausa","description":"\n\t\n\t\t\n\t\tDataset Card for afrixnli-translate-test\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nAFRIXNLI-TT is an evaluation dataset comprising translations of the AFRIXNLI dataset from 16 African languages and 1 high resource language into English using NLLB. \nIt includes test sets across all 17 languages.\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nThere are 17 languages available :\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\n\t\n\t\t\n\t\tData Instances\n\t\n\nThe examples look like this for English:\nfrom datasets import load_dataset\ndata =‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/masakhane/afrixnli-translate-test.","url":"https://huggingface.co/datasets/masakhane/afrixnli-translate-test","creator_name":"Masakhane NLP","creator_url":"https://huggingface.co/masakhane","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","natural-language-inference","monolingual","afrixnli","Amharic"],"keywords_longer_than_N":true},
	{"name":"afrixnli","keyword":"hausa","description":"\n\t\n\t\t\n\t\tDataset Card for afrixnli\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nAFRIXNLI is an evaluation dataset comprising translations of a subset of the XNLI dataset into 16 African languages. \nIt includes both validation and test sets across all 18 languages, maintaining the English and French subsets from the original XNLI dataset. \n\n\t\n\t\t\n\t\tLanguages\n\t\n\nThere are 18 languages available :\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\n\t\n\t\t\n\t\tData Instances\n\t\n\nThe examples look like this for English:\nfrom datasets import‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/masakhane/afrixnli.","url":"https://huggingface.co/datasets/masakhane/afrixnli","creator_name":"Masakhane NLP","creator_url":"https://huggingface.co/masakhane","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","natural-language-inference","multilingual","xnli","English"],"keywords_longer_than_N":true},
	{"name":"Global-MMLU","keyword":"hausa","description":"\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nGlobal-MMLU üåç is a multilingual evaluation set spanning 42 languages, including English. This dataset combines machine translations for MMLU questions along with professional translations and crowd-sourced post-edits.\nIt also includes cultural sensitivity annotations for a subset of the questions (2850 questions per language) and classifies them as Culturally Sensitive (CS) üóΩ or Culturally Agnostic (CA) ‚öñÔ∏è. These annotations were collected as part of an open‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/CohereLabs/Global-MMLU.","url":"https://huggingface.co/datasets/CohereLabs/Global-MMLU","creator_name":"Cohere Labs","creator_url":"https://huggingface.co/CohereLabs","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["English","Arabic","Bengali","Spanish","French"],"keywords_longer_than_N":true},
	{"name":"naijaweb-edu2","keyword":"hausa","description":"\n\t\n\t\t\n\t\tNaijaweb Edu2 Dataset üá≥üá¨\n\t\n\nNaijaweb Edu 2 is a subset of the naijaweb dataset with an educational score aboove 2 using the fineweb classifier. The initial fineweb dataset was web scraped from web pages popular among Nigerians, providing a rich resource for modeling Nigerian linguistic and cultural contexts.\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\n\n\t\n\t\t\nFeatures\nData Types\n\n\n\t\t\ntext\nstring\n\n\nlink\nstring\n\n\ntoken_count\nint64\n\n\nsection\nstring\n\n\nint_score\nint64\n\n\nlanguage\nstring‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/saheedniyi/naijaweb-edu2.","url":"https://huggingface.co/datasets/saheedniyi/naijaweb-edu2","creator_name":"Saheed Azeez Ayanniyi","creator_url":"https://huggingface.co/saheedniyi","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-generation","text-classification","English","Yoruba","Igbo"],"keywords_longer_than_N":true},
	{"name":"allenai_tulu-3-sft-mixture-DolphinLabeled","keyword":"hausa","description":"\n\t\n\t\t\n\t\tallenai tulu-3-sft-mixture DolphinLabeled\n\t\n\n\n\t\n\t\t\n\t\tPart of the DolphinLabeled series of datasets\n\t\n\n\n\t\n\t\t\n\t\tPresented by Eric Hartford and Cognitive Computations\n\t\n\nThe purpose of this dataset is to enable filtering of allenai/tulu-3-sft-mixture dataset.\nThe original dataset is allenai/tulu-3-sft-mixture\nI have modified the dataset using two scripts.\n\ndedupe.py - removes rows with identical final message content\nlabel.py - adds a \"flags\" column containing the following boolean‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/cognitivecomputations/allenai_tulu-3-sft-mixture-DolphinLabeled.","url":"https://huggingface.co/datasets/cognitivecomputations/allenai_tulu-3-sft-mixture-DolphinLabeled","creator_name":"Cognitive Computations","creator_url":"https://huggingface.co/cognitivecomputations","license_name":"Open Data Commons Attribution License v1.0","license_url":"https://scancode-licensedb.aboutcode.org/odc-by-1.0.html","language":"en","first_N":5,"first_N_keywords":["other","crowdsourced","expert-generated","machine-generated","multilingual"],"keywords_longer_than_N":true},
	{"name":"quran_multilingual_parallel","keyword":"hausa","description":"\n\t\n\t\t\n\t\tüìò Qur‚Äôan Multilingual Parallel Dataset (quran_multilingual_parallel)\n\t\n\nThis dataset presents a clean, structurally-aligned multilingual parallel corpus of the Qur‚Äôanic text. It is intended for linguistic, computational, and cross-lingual AI applications ‚Äî not only for religious interpretation.\nIt contains over 6,200 verse-level alignments in 54 human languages, formatted in a machine-friendly .csv structure with language-specific translation fields.\n\n\n\t\n\t\t\n\t\n\t\n\t\tüß† Dataset Highlights‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/freococo/quran_multilingual_parallel.","url":"https://huggingface.co/datasets/freococo/quran_multilingual_parallel","creator_name":"Wynn","creator_url":"https://huggingface.co/freococo","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["translation","Arabic","Albanian","Amharic","Azerbaijani"],"keywords_longer_than_N":true}
]
;
