const data_for_language_americas_orpo = 
[
	{"name":"DPO-En-Zh-20k-Preference","keyword":"orpo","description":"This dataset is composed by\n\n4,000 examples of argilla/distilabel-capybara-dpo-7k-binarized with chosen score>=4.\n3,000 examples of argilla/distilabel-intel-orca-dpo-pairs with chosen score>=8.\n3,000 examples of argilla/ultrafeedback-binarized-preferences-cleaned with chosen score>=4.\n10,000 examples of wenbopan/Chinese-dpo-pairs.\n\nrefer: https://huggingface.co/datasets/hiyouga/DPO-En-Zh-20k   æ”¹äº†questionã€response_rejectedã€response_chosenå­—æ®µï¼Œæ–¹ä¾¿ORPOã€DPOæ¨¡åž‹è®­ç»ƒæ—¶ä½¿ç”¨train usage:â€¦ See the full description on the dataset page: https://huggingface.co/datasets/shibing624/DPO-En-Zh-20k-Preference.","url":"https://huggingface.co/datasets/shibing624/DPO-En-Zh-20k-Preference","creator_name":"Ming Xu (å¾æ˜Ž)","creator_url":"https://huggingface.co/shibing624","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","English","Chinese","apache-2.0","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"orpo-dpo-mix-40k","keyword":"orpo","description":"\n\t\n\t\t\n\t\tORPO-DPO-mix-40k v1.2\n\t\n\n\nThis dataset is designed for ORPO or DPO training.\nSee Fine-tune Llama 3 with ORPO for more information about how to use it.\nIt is a combination of the following high-quality DPO datasets:\n\nargilla/Capybara-Preferences: highly scored chosen answers >=5 (7,424 samples)argilla/distilabel-intel-orca-dpo-pairs: highly scored chosen answers >=9, not in GSM8K (2,299 samples)\nargilla/ultrafeedback-binarized-preferences-cleaned: highly scored chosen answers >=5 (22â€¦ See the full description on the dataset page: https://huggingface.co/datasets/mlabonne/orpo-dpo-mix-40k.","url":"https://huggingface.co/datasets/mlabonne/orpo-dpo-mix-40k","creator_name":"Maxime Labonne","creator_url":"https://huggingface.co/mlabonne","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","English","apache-2.0","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"Aya-Aya.23.8B-DPO","keyword":"orpo","description":"\n\t\n\t\t\n\t\tðŸ¤— Dataset Card for \"Aya-Aya.23.8B-DPO\"\n\t\n\n\n\t\n\t\t\n\t\tDataset Sources & Infos\n\t\n\n\nData Origin: Derived from the Arabic Aya (2A) dataset : 2A2I/Arabic_Aya which is a Curated Subset of the Aya Collection CohereForAI/aya_dataset\nLanguages: Modern Standard Arabic (MSA)\nLicense: Apache-2.0\nMaintainers: Ali Elfilali and Mohammed Machrouh\n\n\n\t\n\t\t\n\t\n\t\n\t\tPurpose\n\t\n\nAya-Aya.23.8B-DPO is a DPO dataset designed to advance Arabic NLP by comparing human-generated responses, labeled as \"chosen,\" withâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/2A2I/Aya-Aya.23.8B-DPO.","url":"https://huggingface.co/datasets/2A2I/Aya-Aya.23.8B-DPO","creator_name":"2A2I","creator_url":"https://huggingface.co/2A2I","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["Arabic","apache-2.0","10K - 100K","parquet","Text"],"keywords_longer_than_N":true},
	{"name":"multiturn-capybara-preferences-filtered-binarized","keyword":"orpo","description":"This dataset has been created with distilabel, plus some extra post-processing steps described below.\nDataset Summary\nThis dataset is built on top of argilla/Capybara-Preferences, but applies a further in detail filtering.\nThe filtering approach has been proposed and shared by @LDJnr, and applies the following:\n\nRemove responses from the assistant, not only in the last turn, but also in intermediate turns where the assistant responds with a potential refusal and/or some ChatGPT-isms such asâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/arcee-ai/multiturn-capybara-preferences-filtered-binarized.","url":"https://huggingface.co/datasets/arcee-ai/multiturn-capybara-preferences-filtered-binarized","creator_name":"Arcee AI","creator_url":"https://huggingface.co/arcee-ai","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["English","apache-2.0","10K - 100K","parquet","Text"],"keywords_longer_than_N":true},
	{"name":"lyrical_Ru2En_translation_Soviet_rock_songs_DPO_ORPO","keyword":"orpo","description":"\n\t\n\t\t\n\t\tLyrics to songs by seminal Soviet and Russian songwriters, poets, and bands.\n\t\n\nALTERNATE VERSION OF THE DATASET (3 columns: prompt, chosen, rejected)\nManually translated to English by Aleksey Calvin, with a painstaking effort to cross-linguistically reproduce source texts' phrasal/phonetic, rhythmic, metric, syllabic, melodic, and other lyrical/performance-catered features, whilst retaining adequate semantic/significational fidelity.  \nThis dataset samples months and years of inspiredâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/AlekseyCalvin/lyrical_Ru2En_translation_Soviet_rock_songs_DPO_ORPO.","url":"https://huggingface.co/datasets/AlekseyCalvin/lyrical_Ru2En_translation_Soviet_rock_songs_DPO_ORPO","creator_name":"Aleksey Calvin Tsukanov (A.C.T. SOONÂ®)","creator_url":"https://huggingface.co/AlekseyCalvin","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["translation","Russian","English","apache-2.0","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"orpo-dpo-mix-40k-mlx","keyword":"orpo","description":"\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset is a split version of orpo-dpo-mix-40k for direct use with mlx-lm-lora, specifically tailored to be compatible with ORPO training.\nThe dataset has been divided into three parts:\n\nTrain Set: 90%\nValidation Set: 6% \nTest Set: 4%\n\n\n\t\n\t\t\n\t\n\t\n\t\tExample Usage\n\t\n\nTo train a model using this dataset, you can use the following command:\nmlx_lm_lora.train \\\n--model Qwen/Qwen2.5-3B-Instruct \\\n--train \\\n--test \\\n--num-layers 8 \\\n--dataâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/mlx-community/orpo-dpo-mix-40k-mlx.","url":"https://huggingface.co/datasets/mlx-community/orpo-dpo-mix-40k-mlx","creator_name":"MLX Community","creator_url":"https://huggingface.co/mlx-community","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","English","apache-2.0","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"auryn_dpo_orpo_english","keyword":"orpo","description":"celsowm/auryn_dpo_orpo_english dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/celsowm/auryn_dpo_orpo_english","creator_name":"Celso F","creator_url":"https://huggingface.co/celsowm","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["question-answering","English","apache-2.0","1K - 10K","json"],"keywords_longer_than_N":true},
	{"name":"auryn_dpo_orpo_english","keyword":"orpo","description":"celsowm/auryn_dpo_orpo_english dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/celsowm/auryn_dpo_orpo_english","creator_name":"Celso F","creator_url":"https://huggingface.co/celsowm","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["question-answering","English","apache-2.0","1K - 10K","json"],"keywords_longer_than_N":true},
	{"name":"NoRobots-SambaLingo.Arabic.Chat-DPO","keyword":"orpo","description":"\n\t\n\t\t\n\t\tðŸ¤— Dataset Card for \"NoRobots-SambaLingo.Arabic.Chat-DPO\"\n\t\n\n\n\t\n\t\t\n\t\tDataset Sources & Infos\n\t\n\n\nData Origin: Derived from the Arabic No Robots dataset : 2A2I/H4_no_robots which is based on the original No Robots dataset inspired from the InstructGPT paper.\nLanguages: Modern Standard Arabic (MSA)\nLicense: CC BY-NC 4.0\nMaintainers: Ali Elfilali and Marwa El Kamil\n\n\n\t\n\t\n\t\n\t\tPurpose\n\t\n\nNoRobots-SambaLingo.Arabic.Chat-DPO is a DPO dataset designed to advance Arabic NLP by comparingâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/2A2I/NoRobots-SambaLingo.Arabic.Chat-DPO.","url":"https://huggingface.co/datasets/2A2I/NoRobots-SambaLingo.Arabic.Chat-DPO","creator_name":"2A2I","creator_url":"https://huggingface.co/2A2I","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["Arabic","apache-2.0","1K - 10K","parquet","Text"],"keywords_longer_than_N":true},
	{"name":"PKU-SafeRLHF-orpo-72k","keyword":"orpo","description":"Warning: this dataset contains data that may be offensive or harmful. The data are intended for research purposes, especially research that can make models less harmful.\nðŸ‘‡original PKU-SafeRLHF datasets (click ðŸ”— for more details)\n\nwhat's the advantage of this train dataset over the original one ?\n\nstandard chosen/rejected format of preference datasets : make 'chosen' and 'rejected' according to 'better_response_id'\nonly one file : merge three train datasets(Alpaca-7Bã€Alpaca2-7Bã€Alpaca3-8B)â€¦ See the full description on the dataset page: https://huggingface.co/datasets/juneup/PKU-SafeRLHF-orpo-72k.","url":"https://huggingface.co/datasets/juneup/PKU-SafeRLHF-orpo-72k","creator_name":"Jundifang","creator_url":"https://huggingface.co/juneup","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["English","mit","10K - 100K","json","Text"],"keywords_longer_than_N":true},
	{"name":"dpo-orpo-mix-45k","keyword":"orpo","description":"\n\t\n\t\t\n\t\tDPO-ORPO-mix-45k\n\t\n\nThis dataset is designed for DPO or ORPO training.\nThis dataset combines samples of the following high-quality DPO datasets:\n\nargilla/Capybara-Preferences: highly scored chosen answers >=5 (2882 samples)\nargilla/distilabel-intel-orca-dpo-pairs: highly scored chosen answers >=9, not in GSM8K (3961 samples)\nargilla/ultrafeedback-binarized-preferences-cleaned: highly scored chosen answers >=5 (22799 samples)\nargilla/distilabel-math-preference-dpo: highly scored chosenâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/llmat/dpo-orpo-mix-45k.","url":"https://huggingface.co/datasets/llmat/dpo-orpo-mix-45k","creator_name":"Matthias De Paolis","creator_url":"https://huggingface.co/llmat","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","English","apache-2.0","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"LyricalSongsVerses_Ver4_forUnslothORPO","keyword":"orpo","description":"\n\t\n\t\t\n\t\tSong-lyrics & Poems by seminal & obscure Soviet & Russian songwriters, bands, & poets.\n\t\n\nEDITED VARIANT 4 \nStyled after the RecipeResearch Dolphin Preference set, for use with the unsloth Llama3 (8B) ORPO Colab notebook\nRe-balanced, edited, substantially abridged/consolidated, somewhat re-expanded \nJsonl variant with excessive separators ('/' symbols) removed \nManually translated to English by Aleksey Calvin, with a painstaking effort to cross-linguistically reproduce source texts'â€¦ See the full description on the dataset page: https://huggingface.co/datasets/AlekseyCalvin/LyricalSongsVerses_Ver4_forUnslothORPO.","url":"https://huggingface.co/datasets/AlekseyCalvin/LyricalSongsVerses_Ver4_forUnslothORPO","creator_name":"Aleksey Calvin Tsukanov (A.C.T. SOONÂ®)","creator_url":"https://huggingface.co/AlekseyCalvin","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["translation","Russian","English","apache-2.0","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"Lyrical_Rus2Eng_MT_SongsPoems_Set2_contrastive_tri-column_format","keyword":"orpo","description":"\n\t\n\t\t\n\t\tSong-lyrics & Poems by seminal & obscure Soviet & Russian songwriters, bands, & poets.\n\t\n\nALTERNATE VERSION OF THE DATASET (3 columns: prompt, chosen, rejected)\nManually translated to English by Aleksey Calvin, with a painstaking effort to cross-linguistically reproduce source texts' phrasal/phonetic, rhythmic, metric, syllabic, melodic, and other lyrical/performance-catered features, whilst retaining adequate semantic/significational fidelity.  \nThis dataset samples months and yearsâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/AlekseyCalvin/Lyrical_Rus2Eng_MT_SongsPoems_Set2_contrastive_tri-column_format.","url":"https://huggingface.co/datasets/AlekseyCalvin/Lyrical_Rus2Eng_MT_SongsPoems_Set2_contrastive_tri-column_format","creator_name":"Aleksey Calvin Tsukanov (A.C.T. SOONÂ®)","creator_url":"https://huggingface.co/AlekseyCalvin","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["translation","Russian","English","apache-2.0","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"gemma-vs-gemma-preferences","keyword":"orpo","description":"\n\t\n\t\t\n\t\tðŸ’ŽðŸ†šðŸ’Ž Gemma vs Gemma Preferences\n\t\n\nThis dataset contains on-policy collected preferences generated using anakin87/gemma-2-2b-ita-sft.\nâš ï¸ While this dataset may be valuable for didactic purposes, it is not recommended for training a model using Preference Tuning due to the following reasons:\n\nThe training would be off-policy for your model.\nThe dataset was generated with gemma-2-2b-ita-sft, a small model for Italian.\n\n\n\t\n\t\t\n\t\n\t\n\t\tMotivation\n\t\n\nWhile DPO (Direct Preferenceâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/anakin87/gemma-vs-gemma-preferences.","url":"https://huggingface.co/datasets/anakin87/gemma-vs-gemma-preferences","creator_name":"Stefano Fiorucci","creator_url":"https://huggingface.co/anakin87","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","Italian","apache-2.0","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"Aya-AceGPT.13B.Chat-DPO","keyword":"orpo","description":"\n\t\n\t\t\n\t\tDataset Card for \"Aya-AceGPT.13B.Chat-DPO\" ðŸ¤—\n\t\n\n\n\t\n\t\t\n\t\tDataset Sources & Infos\n\t\n\n\nData Origin: Derived from the Arabic Aya (2A) dataset : 2A2I/Arabic_Aya which is a Curated Subset of the Aya Collection CohereForAI/aya_dataset\nLanguages: Modern Standard Arabic (MSA)\nLicense: Apache-2.0\nMaintainers: Ali Elfilali and Mohammed Machrouh\n\n\n\t\n\t\t\n\t\n\t\n\t\tPurpose\n\t\n\nAya-AceGPT.13B.Chat-DPO is a DPO dataset designed to advance Arabic NLP by comparing human-generated responses, labeled asâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/2A2I/Aya-AceGPT.13B.Chat-DPO.","url":"https://huggingface.co/datasets/2A2I/Aya-AceGPT.13B.Chat-DPO","creator_name":"2A2I","creator_url":"https://huggingface.co/2A2I","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["Arabic","apache-2.0","10K - 100K","parquet","Text"],"keywords_longer_than_N":true},
	{"name":"orpo-dpo-mix-40k-flat-mlx","keyword":"orpo","description":"\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset is a split version of orpo-dpo-mix-40k-flat for direct use with mlx-lm-lora, specifically tailored to be compatible with DPO and CPO training.\nThe dataset has been divided into three parts:\n\nTrain Set: 90%\nValidation Set: 6% \nTest Set: 4%\n\n\n\t\n\t\t\n\t\n\t\n\t\tExample Usage\n\t\n\nTo train a model using this dataset, you can use the following command:\nmlx_lm_lora.train \\\n--model Qwen/Qwen2.5-3B-Instruct \\\n--train \\\n--test \\\n--num-layers 8 \\\n--dataâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/mlx-community/orpo-dpo-mix-40k-flat-mlx.","url":"https://huggingface.co/datasets/mlx-community/orpo-dpo-mix-40k-flat-mlx","creator_name":"MLX Community","creator_url":"https://huggingface.co/mlx-community","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","English","apache-2.0","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"Lyrical_Ru2En_DPO_v3_RWKVcategories_CSV","keyword":"orpo","description":"\n\t\n\t\t\n\t\tSong-lyrics & Poems by seminal & obscure Soviet & Russian songwriters, bands, & poets.\n\t\n\nEDITED VARIANT 3 \nRe-balanced, edited, substantially abridged/consolidated, somewhat re-expanded \nCSV Version, no more excessive separators, category titles altered for the RWKV LM RLHF trainer \nALTERNATE VERSION OF THE DATASET (3 columns: prompt, chosen, rejected)\nManually translated to English by Aleksey Calvin, with a painstaking effort to cross-linguistically reproduce source texts'â€¦ See the full description on the dataset page: https://huggingface.co/datasets/AlekseyCalvin/Lyrical_Ru2En_DPO_v3_RWKVcategories_CSV.","url":"https://huggingface.co/datasets/AlekseyCalvin/Lyrical_Ru2En_DPO_v3_RWKVcategories_CSV","creator_name":"Aleksey Calvin Tsukanov (A.C.T. SOONÂ®)","creator_url":"https://huggingface.co/AlekseyCalvin","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["translation","Russian","English","apache-2.0","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"Lyrical_Ru2En_DPO_songs_poems_v3_NoSeparators","keyword":"orpo","description":"\n\t\n\t\t\n\t\tSong-lyrics & Poems by seminal & obscure Soviet & Russian songwriters, bands, & poets.\n\t\n\nEDITED VARIANT 3 \nRe-balanced, edited, substantially abridged/consolidated, somewhat re-expanded \nJsonl variant with excessive separators ('/' symbols) removed \nALTERNATE VERSION OF THE DATASET (3 columns: prompt, chosen, rejected)\nManually translated to English by Aleksey Calvin, with a painstaking effort to cross-linguistically reproduce source texts' phrasal/phonetic, rhythmic, metric, syllabicâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/AlekseyCalvin/Lyrical_Ru2En_DPO_songs_poems_v3_NoSeparators.","url":"https://huggingface.co/datasets/AlekseyCalvin/Lyrical_Ru2En_DPO_songs_poems_v3_NoSeparators","creator_name":"Aleksey Calvin Tsukanov (A.C.T. SOONÂ®)","creator_url":"https://huggingface.co/AlekseyCalvin","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["translation","Russian","English","apache-2.0","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"song_lyrics_Ru2En_PostSoviet_alt_anthems_3columns","keyword":"orpo","description":"Lyrics to songs by seminal Soviet and Russian songwriters, poets, and bands.\nALTERNATE VERSION OF THE DATASET (3 columns: prompt, chosen, rejected)\nManually translated to English with a painstaking effort to cross-linguistically reproduce source texts' phrasal/phonetic, rhythmic, metric, syllabic, melodic, and other lyrical/performance-catered features, whilst retaining adequate semantic/significational fidelity.  \nThis repo's variant of the dataset was compiled/structured for ORPO-styleâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/AlekseyCalvin/song_lyrics_Ru2En_PostSoviet_alt_anthems_3columns.","url":"https://huggingface.co/datasets/AlekseyCalvin/song_lyrics_Ru2En_PostSoviet_alt_anthems_3columns","creator_name":"Aleksey Calvin Tsukanov (A.C.T. SOONÂ®)","creator_url":"https://huggingface.co/AlekseyCalvin","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["translation","Russian","English","apache-2.0","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"NoRobots-Command.R-DPO","keyword":"orpo","description":"\n\t\n\t\t\n\t\tðŸ¤— Dataset Card for \"NoRobots-Command.R-DPO\"\n\t\n\n\n\t\n\t\t\n\t\tDataset Sources & Infos\n\t\n\n\nData Origin: Derived from the Arabic No Robots dataset : 2A2I/H4_no_robots which is based on the original No Robots dataset inspired from the InstructGPT paper.\nLanguages: Modern Standard Arabic (MSA)\nLicense: CC BY-NC 4.0\nMaintainers: Ali Elfilali and Marwa El Kamil\n\n\n\t\n\t\n\t\n\t\tPurpose\n\t\n\nNoRobots-Command.R-DPO is a DPO dataset designed to advance Arabic NLP by comparing human-generatedâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/2A2I/NoRobots-Command.R-DPO.","url":"https://huggingface.co/datasets/2A2I/NoRobots-Command.R-DPO","creator_name":"2A2I","creator_url":"https://huggingface.co/2A2I","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["Arabic","apache-2.0","1K - 10K","parquet","Text"],"keywords_longer_than_N":true},
	{"name":"NoRobots-Aya.23.8B-DPO","keyword":"orpo","description":"\n\t\n\t\t\n\t\tðŸ¤— Dataset Card for \"NoRobots-Aya.23.8B-DPO\"\n\t\n\n\n\t\n\t\t\n\t\tDataset Sources & Infos\n\t\n\n\nData Origin: Derived from the Arabic No Robots dataset : 2A2I/H4_no_robots which is based on the original No Robots dataset inspired from the InstructGPT paper.\nLanguages: Modern Standard Arabic (MSA)\nLicense: CC BY-NC 4.0\nMaintainers: Ali Elfilali and Marwa El Kamil\n\n\n\t\n\t\n\t\n\t\tPurpose\n\t\n\nNoRobots-Aya.23.8B-DPO is a DPO dataset designed to advance Arabic NLP by comparing human-generatedâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/2A2I/NoRobots-Aya.23.8B-DPO.","url":"https://huggingface.co/datasets/2A2I/NoRobots-Aya.23.8B-DPO","creator_name":"2A2I","creator_url":"https://huggingface.co/2A2I","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["Arabic","apache-2.0","1K - 10K","parquet","Text"],"keywords_longer_than_N":true},
	{"name":"dpo-orpo-mix-50k","keyword":"orpo","description":"\n\t\n\t\t\n\t\tDPO-ORPO-mix-50k\n\t\n\nThis dataset is designed for DPO or ORPO training.\nThis dataset combines samples of the following high-quality DPO datasets:\n\nargilla/Capybara-Preferences: highly scored chosen answers >=5 (2882 samples)\nargilla/distilabel-intel-orca-dpo-pairs: highly scored chosen answers >=9, not in GSM8K (3961 samples)\nargilla/ultrafeedback-binarized-preferences-cleaned: highly scored chosen answers >=5 (22799 samples)\nargilla/distilabel-math-preference-dpo: highly scored chosenâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/llmat/dpo-orpo-mix-50k.","url":"https://huggingface.co/datasets/llmat/dpo-orpo-mix-50k","creator_name":"Matthias De Paolis","creator_url":"https://huggingface.co/llmat","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","English","apache-2.0","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"aya_dutch_dpo","keyword":"orpo","description":"\n  \n    \n  \n\n\n\n\t\n\t\t\n\t\tDataset Card for aya_dutch_dpo\n\t\n\nThis dataset has been created with distilabel.\nThis dataset was created as part of the Data is Better Together project, in particular as part of an ongoing effort to help foster the creation of DPO/ORPO datasets for more languages.\nThe dataset was constructed using the following steps:\n\nstarting with the aya_dataset and filtering for Dutch examples\nusing the Meta-Llama-3-70B-Instruct model to generate new examples for each promptUsingâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/data-is-better-together/aya_dutch_dpo.","url":"https://huggingface.co/datasets/data-is-better-together/aya_dutch_dpo","creator_name":"Data Is Better Together","creator_url":"https://huggingface.co/data-is-better-together","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","reinforcement-learning","Dutch","apache-2.0","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"distilabel-intel-orca-dpo-pairs-binarized","keyword":"orpo","description":"This is the binarized version of distilabel Orca Pairs for DPO and ORPO. \nReference: https://huggingface.co/datasets/argilla/distilabel-intel-orca-dpo-pairs?row=0\n","url":"https://huggingface.co/datasets/arcee-ai/distilabel-intel-orca-dpo-pairs-binarized","creator_name":"Arcee AI","creator_url":"https://huggingface.co/arcee-ai","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["English","apache-2.0","10K - 100K","parquet","Text"],"keywords_longer_than_N":true},
	{"name":"orpo-dpo-mix-TR-20k","keyword":"orpo","description":"\n\t\n\t\t\n\t\tORPO-DPO-Mix-TR-20k\n\t\n\n\nThis repository contains a Turkish translation of 20k records from the mlabonne/orpo-dpo-mix-40k dataset. The translation was carried out using the gemini-1.5-flash-002 model, chosen for its 1M token context size and overall accurate Turkish responses.\n\n\t\n\t\t\n\t\n\t\n\t\tTranslation Process\n\t\n\nThe translation process uses the LLM model with translation prompt and pydantic data validation to ensure accuracy. The complete translation pipeline is available in the GitHubâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/selimc/orpo-dpo-mix-TR-20k.","url":"https://huggingface.co/datasets/selimc/orpo-dpo-mix-TR-20k","creator_name":"selim","creator_url":"https://huggingface.co/selimc","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text2text-generation","question-answering","text-generation","Turkish","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"evol-dpo-ita-reranked","keyword":"orpo","description":"\n\t\n\t\t\n\t\tEvol DPO Ita Reranked\n\t\n\n\nA high-quality Italian preference dataset suitable for Direct Preference Optimization (DPO), ORPO, and other Preference Tuning algorithms.\n\n\t\n\t\t\n\t\n\t\n\t\tðŸ¥‡ðŸ¥ˆ Reranking process\n\t\n\nThis work is based on efederici/evol-dpo-ita, a nice Italian preference dataset.\nThe original dataset includes prompts translated from the Evol-Instruct datasets, with responses generated using GPT-3.5-Turbo (rejected) and claude-3-opus-20240229 (chosen).\nChoosing the response from theâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/anakin87/evol-dpo-ita-reranked.","url":"https://huggingface.co/datasets/anakin87/evol-dpo-ita-reranked","creator_name":"Stefano Fiorucci","creator_url":"https://huggingface.co/anakin87","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","Italian","apache-2.0","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"Aya-SambaLingo.Arabic.Chat-DPO","keyword":"orpo","description":"\n\t\n\t\t\n\t\tDataset Card for \"Aya-SambaLingo.Arabic.Chat-DPO\" ðŸ¤—\n\t\n\n\n\t\n\t\t\n\t\tDataset Sources & Infos\n\t\n\n\nData Origin: Derived from the Arabic Aya (2A) dataset : 2A2I/Arabic_Aya which is a Curated Subset of the Aya Collection CohereForAI/aya_dataset\nLanguages: Modern Standard Arabic (MSA)\nLicense: Apache-2.0\nMaintainers: Ali Elfilali and Mohammed Machrouh\n\n\n\t\n\t\t\n\t\n\t\n\t\tPurpose\n\t\n\nAya-SambaLingo.Arabic.Chat-DPO is a DPO dataset designed to advance Arabic NLP by comparing human-generated responsesâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/2A2I/Aya-SambaLingo.Arabic.Chat-DPO.","url":"https://huggingface.co/datasets/2A2I/Aya-SambaLingo.Arabic.Chat-DPO","creator_name":"2A2I","creator_url":"https://huggingface.co/2A2I","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["Arabic","apache-2.0","10K - 100K","parquet","Text"],"keywords_longer_than_N":true},
	{"name":"oasst2_dpo_pairs_enth","keyword":"orpo","description":"\n\t\n\t\t\n\t\tOASST2 DPO Pairs English and Thai\n\t\n\nThis dataset contains message ChatML. It was create from Open Assistant Conversations Dataset Release 2 (OASST2). You can use to do human preference optimization (DPO, ORPO, and other).\n\n\t\n\t\t\n\t\tSelect Thai only\n\t\n\nfrom datasets import load_dataset\n\ndataset = load_dataset(\"pythainlp/oasst2_dpo_pairs_enth\",split=\"train\")\nthai_dataset = dataset.filter(lambda example: example['lang']==\"th\") # if you want to use English only, change to \"en\".\n\nlicense:â€¦ See the full description on the dataset page: https://huggingface.co/datasets/pythainlp/oasst2_dpo_pairs_enth.","url":"https://huggingface.co/datasets/pythainlp/oasst2_dpo_pairs_enth","creator_name":"PyThaiNLP","creator_url":"https://huggingface.co/pythainlp","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","English","Thai","apache-2.0","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"Lyrical_Rus2Eng_MT_SongsPoems_Set2_contrastive_tri-column_raw_csv","keyword":"orpo","description":"\n\t\n\t\t\n\t\tSong-lyrics & Poems by seminal & obscure Soviet & Russian songwriters, bands, & poets.\n\t\n\nCSV VARIANT \nALTERNATE VERSION OF THE DATASET (3 columns: prompt, chosen, rejected)\nManually translated to English by Aleksey Calvin, with a painstaking effort to cross-linguistically reproduce source texts' phrasal/phonetic, rhythmic, metric, syllabic, melodic, and other lyrical/performance-catered features, whilst retaining adequate semantic/significational fidelity.  \nThis dataset samplesâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/AlekseyCalvin/Lyrical_Rus2Eng_MT_SongsPoems_Set2_contrastive_tri-column_raw_csv.","url":"https://huggingface.co/datasets/AlekseyCalvin/Lyrical_Rus2Eng_MT_SongsPoems_Set2_contrastive_tri-column_raw_csv","creator_name":"Aleksey Calvin Tsukanov (A.C.T. SOONÂ®)","creator_url":"https://huggingface.co/AlekseyCalvin","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["translation","Russian","English","apache-2.0","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"medical-reasoning-orpo_preprocess","keyword":"orpo","description":"\n\t\n\t\t\n\t\tMedical Reasoning ORPO Preprocessed Dataset\n\t\n\nThis dataset is a preprocessed version of SURESHBEEKHANI/medical-reasoning-orpo, formatted for preference tuning tasks like DPO or ORPO.\n\n\t\n\t\t\n\t\tData Structure\n\t\n\nThe dataset contains three columns:\n\nquestion: A combination of the original instruction and Input fields.\naccepted: The preferred response, formatted with thinking process and final answer tags.\nrejected: The dispreferred response, also formatted with tags.\n\n\n\t\n\t\t\n\t\tAnswerâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/LLMcompe-Team-Watanabe/medical-reasoning-orpo_preprocess.","url":"https://huggingface.co/datasets/LLMcompe-Team-Watanabe/medical-reasoning-orpo_preprocess","creator_name":"LLMcompe Team Watanabe","creator_url":"https://huggingface.co/LLMcompe-Team-Watanabe","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["question-answering","expert-generated","found","monolingual","English"],"keywords_longer_than_N":true},
	{"name":"orpo-dpo-mix-40k-SHORT","keyword":"orpo","description":"\n\t\n\t\t\n\t\tSHORTENED - ORPO-DPO-mix-40k v1.1\n\t\n\nFILTERED to remove rows with chosen responses longer than 2k characters or with a final assistant message longer than 500 characters.\n\nThe original dataset card follows below.\n\n\n\t\n\t\t\n\t\tORPO-DPO-mix-40k v1.1\n\t\n\n\nThis dataset is designed for ORPO or DPO training.\nIt is a combination of the following high-quality DPO datasets:\n\nargilla/Capybara-Preferences: highly scored chosen answers >=5 (7,424 samples)\nargilla/distilabel-intel-orca-dpo-pairs: highlyâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Trelis/orpo-dpo-mix-40k-SHORT.","url":"https://huggingface.co/datasets/Trelis/orpo-dpo-mix-40k-SHORT","creator_name":"Trelis","creator_url":"https://huggingface.co/Trelis","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","English","apache-2.0","1K - 10K","parquet"],"keywords_longer_than_N":true},
	{"name":"demons_megaten_fandom_orpo_dpo_english","keyword":"orpo","description":"celsowm/demons_megaten_fandom_orpo_dpo_english dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/celsowm/demons_megaten_fandom_orpo_dpo_english","creator_name":"Celso F","creator_url":"https://huggingface.co/celsowm","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["question-answering","English","apache-2.0","1K - 10K","json"],"keywords_longer_than_N":true},
	{"name":"demons_megaten_fandom_orpo_dpo_english","keyword":"orpo","description":"celsowm/demons_megaten_fandom_orpo_dpo_english dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/celsowm/demons_megaten_fandom_orpo_dpo_english","creator_name":"Celso F","creator_url":"https://huggingface.co/celsowm","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["question-answering","English","apache-2.0","1K - 10K","json"],"keywords_longer_than_N":true},
	{"name":"ultrafeedback-binarized","keyword":"orpo","description":"Ultrafeedback binarized dataset using the mean of preference ratings by Argilla. \nThey addressed TruthfulQA-related data contamination in this version.\nSteps:\n\nCompute mean of preference ratings (honesty, instruction-following, etc.)\nPick the best mean rating as the chosen\nPick random rejected with lower mean (or another random if equal to chosen rating)\nFilter out examples with chosen rating == rejected rating\n\nReference:â€¦ See the full description on the dataset page: https://huggingface.co/datasets/arcee-ai/ultrafeedback-binarized.","url":"https://huggingface.co/datasets/arcee-ai/ultrafeedback-binarized","creator_name":"Arcee AI","creator_url":"https://huggingface.co/arcee-ai","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["English","mit","10K - 100K","parquet","Text"],"keywords_longer_than_N":true},
	{"name":"song_lyrics_Ru2En_PostSoviet_alt_anthems","keyword":"orpo","description":"Lyrics to songs by seminal Soviet and Russian songwriters, poets, and bands.\nManually translated to English with a painstaking effort to cross-linguistically reproduce source texts' phrasal/phonetic, rhythmic, metric, syllabic, melodic, and other lyrical/performance-catered features, whilst retaining adequate semantic/significational fidelity.  \nThis repo's variant of the dataset was compiled/structured for ORPO-style fine-tuning of LLMs. \nThe sampling herein constitues a variatedâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/AlekseyCalvin/song_lyrics_Ru2En_PostSoviet_alt_anthems.","url":"https://huggingface.co/datasets/AlekseyCalvin/song_lyrics_Ru2En_PostSoviet_alt_anthems","creator_name":"Aleksey Calvin Tsukanov (A.C.T. SOONÂ®)","creator_url":"https://huggingface.co/AlekseyCalvin","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["translation","Russian","English","apache-2.0","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"enunciados_pge_rj_orpo","keyword":"orpo","description":"celsowm/enunciados_pge_rj_orpo dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/celsowm/enunciados_pge_rj_orpo","creator_name":"Celso F","creator_url":"https://huggingface.co/celsowm","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["question-answering","Portuguese","apache-2.0","1K - 10K","json"],"keywords_longer_than_N":true},
	{"name":"ExplainableAI-emotions-DPO-ORPO-RLHF","keyword":"orpo","description":"\n\t\n\t\t\n\t\tPreference Dataset for Explainable Multi-Label Emotion Classification\n\t\n\nThis repository contains a preference dataset compiled to compare two model-generated responses for explaining multi-label emotion classifications on Tweets. The dataset is accompanied by human annotations indicating which response was preferred, based on a set of defined dimensions (clarity, correctness, helpfulness, and verbosity). The annotation guidelines are included to describe how these preference judgmentsâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/imhmdf/ExplainableAI-emotions-DPO-ORPO-RLHF.","url":"https://huggingface.co/datasets/imhmdf/ExplainableAI-emotions-DPO-ORPO-RLHF","creator_name":"Hammad Fahim","creator_url":"https://huggingface.co/imhmdf","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","text-generation","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"Lyrical_Ru2En_DPO_songs_poems_v3_Rebalanced","keyword":"orpo","description":"\n\t\n\t\t\n\t\tSong-lyrics & Poems by seminal & obscure Soviet & Russian songwriters, bands, & poets.\n\t\n\nEDITED VARIANT 3 \nRe-balanced, edited, substantially abridged/consolidated, somewhat re-expanded \nALTERNATE VERSION OF THE DATASET (3 columns: prompt, chosen, rejected)\nManually translated to English by Aleksey Calvin, with a painstaking effort to cross-linguistically reproduce source texts' phrasal/phonetic, rhythmic, metric, syllabic, melodic, and other lyrical/performance-catered featuresâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/AlekseyCalvin/Lyrical_Ru2En_DPO_songs_poems_v3_Rebalanced.","url":"https://huggingface.co/datasets/AlekseyCalvin/Lyrical_Ru2En_DPO_songs_poems_v3_Rebalanced","creator_name":"Aleksey Calvin Tsukanov (A.C.T. SOONÂ®)","creator_url":"https://huggingface.co/AlekseyCalvin","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["translation","Russian","English","apache-2.0","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"Lyrical_Rus2Eng_ver4_forRWKV_RLtrainer_jsonl","keyword":"orpo","description":"\n\t\n\t\t\n\t\tSong-lyrics & Poems by seminal & obscure Soviet & Russian songwriters, bands, & poets.\n\t\n\nEDITED VARIANT 4 \nRe-balanced, edited, substantially abridged/consolidated, somewhat re-expanded \nJSONLines Version, no more excessive separators, category titles altered for the RWKV LM RLHF trainer \nALTERNATE VERSION OF THE DATASET (3 columns: prompt, chosen, reject)\nManually translated to English by Aleksey Calvin, with a painstaking effort to cross-linguistically reproduce source texts'â€¦ See the full description on the dataset page: https://huggingface.co/datasets/AlekseyCalvin/Lyrical_Rus2Eng_ver4_forRWKV_RLtrainer_jsonl.","url":"https://huggingface.co/datasets/AlekseyCalvin/Lyrical_Rus2Eng_ver4_forRWKV_RLtrainer_jsonl","creator_name":"Aleksey Calvin Tsukanov (A.C.T. SOONÂ®)","creator_url":"https://huggingface.co/AlekseyCalvin","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["translation","Russian","English","apache-2.0","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"DPO-En-Zh-20k","keyword":"orpo","description":"This dataset is composed by\n\n4,000 examples of argilla/distilabel-capybara-dpo-7k-binarized with chosen score>=4.\n3,000 examples of argilla/distilabel-intel-orca-dpo-pairs with chosen score>=8.\n3,000 examples of argilla/ultrafeedback-binarized-preferences-cleaned with chosen score>=4.\n10,000 examples of wenbopan/Chinese-dpo-pairs.\n\nYou can use it in LLaMA Factory by specifying dataset: dpo_mix_en,dpo_mix_zh.\n","url":"https://huggingface.co/datasets/llamafactory/DPO-En-Zh-20k","creator_name":"LLaMA Factory","creator_url":"https://huggingface.co/llamafactory","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","English","Chinese","apache-2.0","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"Capybara-Preferences","keyword":"orpo","description":"\n  \n    \n  \n\n\n\n\t\n\t\t\n\t\tDataset Card for Capybara-Preferences\n\t\n\nThis dataset has been created with distilabel.\n\n    \n\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset is built on top of LDJnr/Capybara, in order to generate a preference\ndataset out of an instruction-following dataset. This is done by keeping the conversations in the column conversation but splitting\nthe last assistant turn from it, so that the conversation contains all the turns up until the last user's turn, so that it can be reusedâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/argilla/Capybara-Preferences.","url":"https://huggingface.co/datasets/argilla/Capybara-Preferences","creator_name":"Argilla","creator_url":"https://huggingface.co/argilla","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","English","apache-2.0","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"orpo-dpo-mix-40k-flat","keyword":"orpo","description":"\n\t\n\t\t\n\t\tORPO-DPO-mix-40k-flat\n\t\n\n\nThis dataset is designed for ORPO or DPO training.\nSee Uncensor any LLM with Abliteration for more information about how to use it.\nThis is version with raw text instead of lists of dicts as in the original version here.\nIt makes easier to parse in Axolotl, especially for DPO.ORPO-DPO-mix-40k-flat is a combination of the following high-quality DPO datasets:\n\nargilla/Capybara-Preferences: highly scored chosen answers >=5 (7,424 samples)â€¦ See the full description on the dataset page: https://huggingface.co/datasets/mlabonne/orpo-dpo-mix-40k-flat.","url":"https://huggingface.co/datasets/mlabonne/orpo-dpo-mix-40k-flat","creator_name":"Maxime Labonne","creator_url":"https://huggingface.co/mlabonne","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","English","apache-2.0","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"lima_dirty_tr","keyword":"orpo","description":"\n\t\n\t\t\n\t\tLima Turkish Translated & Engineered for Alignment\n\t\n\n\n\t\n\t\t\n\t\tGiriÅŸ\n\t\n\nBu veri seti, LIMA (Less Is More for Alignment) [^1] Ã§alÄ±ÅŸmasÄ±ndan ilham alÄ±narak oluÅŸturulmuÅŸ, orijinal LIMA veri setinin TÃ¼rkÃ§e'ye Ã§evrilmiÅŸ ve hizalama (alignment) teknikleri iÃ§in Ã¶zel olarak yapÄ±landÄ±rÄ±lmÄ±ÅŸ bir versiyonudur. LIMA'nÄ±n temel felsefesi, az sayÄ±da ancak yÃ¼ksek kaliteli Ã¶rnekle dil modellerini etkili bir ÅŸekilde hizalayabilmektir. Bu Ã§alÄ±ÅŸma, bu felsefeyi TÃ¼rkÃ§e dil modelleri ekosistemine taÅŸÄ±mayÄ±â€¦ See the full description on the dataset page: https://huggingface.co/datasets/emre/lima_dirty_tr.","url":"https://huggingface.co/datasets/emre/lima_dirty_tr","creator_name":"Davut Emre TASAR","creator_url":"https://huggingface.co/emre","license_name":"Academic Free License v3.0","license_url":"https://choosealicense.com/licenses/afl-3.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","Turkish","English","afl-3.0","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"NoRobots-AceGPT.13B.Chat-DPO","keyword":"orpo","description":"\n\t\n\t\t\n\t\tðŸ¤— Dataset Card for \"NoRobots-AceGPT.13B.Chat-DPO\"\n\t\n\n\n\t\n\t\t\n\t\tDataset Sources & Infos\n\t\n\n\nData Origin: Derived from the Arabic No Robots dataset : 2A2I/H4_no_robots which is based on the original No Robots dataset inspired from the InstructGPT paper.\nLanguages: Modern Standard Arabic (MSA)\nLicense: CC BY-NC 4.0\nMaintainers: Ali Elfilali and Marwa El Kamil\n\n\n\t\n\t\n\t\n\t\tPurpose\n\t\n\nNoRobots-AceGPT.13B.Chat-DPO is a DPO dataset designed to advance Arabic NLP by comparing human-generatedâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/2A2I/NoRobots-AceGPT.13B.Chat-DPO.","url":"https://huggingface.co/datasets/2A2I/NoRobots-AceGPT.13B.Chat-DPO","creator_name":"2A2I","creator_url":"https://huggingface.co/2A2I","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["Arabic","apache-2.0","1K - 10K","parquet","Text"],"keywords_longer_than_N":true},
	{"name":"gemini_orpo_dpo_ptbr","keyword":"orpo","description":"celsowm/gemini_orpo_dpo_ptbr dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/celsowm/gemini_orpo_dpo_ptbr","creator_name":"Celso F","creator_url":"https://huggingface.co/celsowm","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","question-answering","Portuguese","apache-2.0","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"aya_dutch_dpo_binarized","keyword":"orpo","description":"\n  \n    \n  \n\n\n\n\t\n\t\t\n\t\tDataset Card for aya_dutch_dpo\n\t\n\nThis dataset has been created with distilabel.\nThis dataset was created as part of the Data is Better Together project, in particular as part of an ongoing effort to help foster the creation of DPO/ORPO datasets for more languages.\nThe dataset was constructed using the following steps:\n\nstarting with the aya_dataset and filtering for Dutch examples\nusing the Meta-Llama-3-70B-Instruct model to generate new examples for each promptUsingâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/CultriX/aya_dutch_dpo_binarized.","url":"https://huggingface.co/datasets/CultriX/aya_dutch_dpo_binarized","creator_name":"CultriX","creator_url":"https://huggingface.co/CultriX","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","reinforcement-learning","Dutch","apache-2.0","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"dpo-orpo-mix-38k-balanced","keyword":"orpo","description":"\n\t\n\t\t\n\t\tDPO-ORPO-mix-38k\n\t\n\nThis dataset is intended for use with DPO or ORPO training. \nIt represents a balanced version of the llmat/dpo-orpo-mix-45k dataset, achieved through a clustering-based approach as outlined in this paper.\nThe dataset integrates high-quality samples from the following DPO datasets:\n\nargilla/Capybara-Preferences: highly scored chosen answers >=5 (2882 samples)\nargilla/distilabel-intel-orca-dpo-pairs: highly scored chosen answers >=9, not in GSM8K (3961 samples)â€¦ See the full description on the dataset page: https://huggingface.co/datasets/llmat/dpo-orpo-mix-38k-balanced.","url":"https://huggingface.co/datasets/llmat/dpo-orpo-mix-38k-balanced","creator_name":"Matthias De Paolis","creator_url":"https://huggingface.co/llmat","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","English","apache-2.0","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"Aya-Command.R-DPO","keyword":"orpo","description":"\n\t\n\t\t\n\t\tðŸ¤— Dataset Card for \"Aya-Command.R-DPO\"\n\t\n\n\n\t\n\t\t\n\t\tDataset Sources & Infos\n\t\n\n\nData Origin: Derived from the Arabic Aya (2A) dataset : 2A2I/Arabic_Aya which is a Curated Subset of the Aya Collection CohereForAI/aya_dataset\nLanguages: Modern Standard Arabic (MSA)\nLicense: Apache-2.0\nMaintainers: Ali Elfilali and Mohammed Machrouh\n\n\n\t\n\t\t\n\t\n\t\n\t\tPurpose\n\t\n\nAya-Command.R-DPO is a DPO dataset designed to advance Arabic NLP by comparing human-generated responses, labeled as \"chosen,\" withâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/2A2I/Aya-Command.R-DPO.","url":"https://huggingface.co/datasets/2A2I/Aya-Command.R-DPO","creator_name":"2A2I","creator_url":"https://huggingface.co/2A2I","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["Arabic","apache-2.0","10K - 100K","parquet","Text"],"keywords_longer_than_N":true}
]
;
