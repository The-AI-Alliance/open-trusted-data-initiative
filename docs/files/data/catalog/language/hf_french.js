var data_for_french = [

  {"name":"mittens","keyword":"french","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/google/mittens","creator_name":"Google","creator_url":"https://huggingface.co/google","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tMiTTenS: A Dataset for Evaluating Misgendering in Translation\\n\\t\\n\\nMisgendering is the act of referring to someone in a way that does not reflect their gender identity.  Translation systems, including foundation models capable of translation, can produce errors that result in misgendering harms. To measure the extent of such potential harms when translating into and out of English, we introduce a dataset, MiTTenS, covering 26 languages from a variety of language families and scripts‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/google/mittens."},
  {"name":"anki_globalvoices_en_fr","keyword":"french","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/arielogg/anki_globalvoices_en_fr","creator_name":"Ariel Guerra-Adames","creator_url":"https://huggingface.co/arielogg","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tAnki-Global Voices English-French Translation Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDescription\\n\\t\\n\\nThe Anki-Global Voices English-French Translation Dataset is a comprehensive collection of over 500,000 translation pairs, merging the Anki English to French dataset with the Global Voices English to French dataset. This unique dataset provides a wide range of sentences, suitable for training and evaluating machine translation models in both informal and formal language contexts.‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/arielogg/anki_globalvoices_en_fr."},
  {"name":"panlex","keyword":"french","license":"Creative Commons Zero v1.0 Universal","language":"en","url":"https://huggingface.co/datasets/lbourdois/panlex","creator_name":"Lo√Øck BOURDOIS","creator_url":"https://huggingface.co/lbourdois","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tPanLex\\n\\t\\n\\nJanuary 1, 2024 version of PanLex Language Vocabulary with 24,650,274 rows covering 6,152 languages.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tColumns\\n\\t\\n\\n\\nvocab: contains the text entry.  \\n639-3: contains the ISO 639-3 languages tags to allow users to filter on the language(s) of their choice.\\n639-3_english_name: the English language name associated to the code ISO 639-3. \\nvar_code: contains a code to differentiate language variants. In practice, this is the code 639-3 + a number.  If 000, it‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/lbourdois/panlex."},
  {"name":"ddxplus-french","keyword":"french","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/aai530-group6/ddxplus-french","creator_name":"aai530-group6","creator_url":"https://huggingface.co/aai530-group6","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nWe are releasing under the CC-BY licence a new large-scale dataset for Automatic Symptom Detection (ASD) and Automatic Diagnosis (AD) systems in the medical domain. The dataset contains patients synthesized using a proprietary medical knowledge base and a commercial rule-based AD system. Patients in the dataset are characterized by their socio-demographic data, a pathology they are suffering from, a set of symptoms and antecedents related to this pathology‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/aai530-group6/ddxplus-french."},
  {"name":"stata","keyword":"french","license":"Creative Commons Attribution Share Alike 4.0 International","language":"en","url":"https://huggingface.co/datasets/adenhaus/stata","creator_name":"Aden Haussmann","creator_url":"https://huggingface.co/adenhaus","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tBackground\\n\\t\\n\\nThis dataset contains human evaluations of whether outputs on the TaTA dataset are a) understandable and b) attributable to the source tables. See TaTA: A Multilingual Table-to-Text Dataset for African Languages for more details. \\nIt can be used to train a learned metric, called StATA, to evaluate model performance on the TaTA dataset.\\nThe original can be found here.\\n"},
  {"name":"MSD_manual_topics_user_base","keyword":"french","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/nuvocare/MSD_manual_topics_user_base","creator_name":"Nuvocare","creator_url":"https://huggingface.co/nuvocare","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tMSD_manual_topics_user_base\\n\\t\\n\\nThis dataset has been built with the website https://www.msdmanuals.com/ provided by Merck & Co for the greater audience.\\nThe MSD manual is an essential source of knowledge for many topics related to symptoms, diseases, health and other related topics. The manual makes an extra effort to make it available both for professionals and patients by having two distinct version. \\nThe content, while being labelled the same, differs by the type of user in‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/nuvocare/MSD_manual_topics_user_base."},
  {"name":"ChatML-aya_dataset","keyword":"french","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/Felladrin/ChatML-aya_dataset","creator_name":"Victor Nogueira","creator_url":"https://huggingface.co/Felladrin","description":"CohereForAI/aya_dataset in ChatML format, ready to use in HuggingFace TRL's SFT Trainer.\\nPython code used for conversion:\\nfrom datasets import load_dataset\\nfrom transformers import AutoTokenizer\\n\\ntokenizer = AutoTokenizer.from_pretrained(\\\"Felladrin/Llama-160M-Chat-v1\\\")\\n\\ndataset = load_dataset(\\\"CohereForAI/aya_dataset\\\", split=\\\"train\\\")\\n\\ndef format(columns):\\n    messages = [\\n        {\\n            \\\"role\\\": \\\"user\\\",\\n            \\\"content\\\": columns[\\\"inputs\\\"].strip(),\\n        },\\n        {‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Felladrin/ChatML-aya_dataset."},
  {"name":"dis-cyril-male","keyword":"french","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/do-2021/dis-cyril-male","creator_name":"Polytech DO - promotion 2021-2024","creator_url":"https://huggingface.co/do-2021","description":"This contains training data for the do-2021/activator-keyword-detector with male voices, with a sample rate of 32000HZ, in a split format.\\nAudio samples in the \\\"yes\\\" subdirectory would activate the assistant, and those in \\\"no\\\" should not.\\n"},
  {"name":"eagle","keyword":"french","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/MasahiroKaneko/eagle","creator_name":"Masahiro Kaneko","creator_url":"https://huggingface.co/MasahiroKaneko","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tEagle ü¶Ö: Ethical Dataset Given from Real Interactions\\n\\t\\n\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tIntroduction\\n\\t\\n\\nThis repository contains the Eagle dataset, which is an ethical dataset of real interactions between humans and ChatGPT. This dataset is created to evaluate social bias, opinion bias, toxic language, and morality in Large Language Models (LLMs).\\nIf you use the Eagle dataset in your research, please cite the following:\\n@inproceedings{Eagle:arxiv:2024,\\n    title={Eagle: Ethical Dataset Given from‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/MasahiroKaneko/eagle."},
  {"name":"bible-dataset","keyword":"french","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/jobpilot/bible-dataset","creator_name":"Cedric Trachsel","creator_url":"https://huggingface.co/jobpilot","description":"jobpilot/bible-dataset dataset hosted on Hugging Face and contributed by the HF Datasets community"},
  {"name":"UltraLink","keyword":"french","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/R0k1e/UltraLink","creator_name":"Haoyu Wang","creator_url":"https://huggingface.co/R0k1e","description":"\\n\\n\\nmulti-lingual, knowledge-grounded, multi-round dialogue dataset and model\\n\\n  Summary  ‚Ä¢\\n Construction Process ‚Ä¢\\n Paper ‚Ä¢\\n  UltraLink-LM ‚Ä¢\\n  Github\\n\\n\\n\\n\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for UltraLink\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nUltraLink is a multi-lingual, knowledge-grounded data augmented, multi-round dialogue dataset. It contains language-specific chat data, language-agnostic chat data, code data and math data in 5 languages: English, Chinese, Spanish, Russian, and French. Different from‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/R0k1e/UltraLink."},
  {"name":"hate_speech-fr_mini","keyword":"french","license":"\"Do What The F*ck You Want To Public License\"","language":"en","url":"https://huggingface.co/datasets/menutp/hate_speech-fr_mini","creator_name":"Paul Menut","creator_url":"https://huggingface.co/menutp","description":"this dataset is a subset of another bigger french profanity dataset from kaggle, labels have been heavily modified to train a ClassificationModel\\nSource : https://www.kaggle.com/datasets/ludovick/jigsawtanslatedgoogle/\\n"},
  {"name":"lmd_ukraine_comments","keyword":"french","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/gentilrenard/lmd_ukraine_comments","creator_name":"Matthieu Vion","creator_url":"https://huggingface.co/gentilrenard","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tComments under Le Monde Ukraine War Articles (1 Year)\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDescription\\n\\t\\n\\nThis dataset contains 175k comments extracted from Le Monde articles about the Ukraine war during its first year (February 2022 to 2023).Among these, around 500 comments are manually labeled into categories: 0. Explicit support for Ukraine, 1. pro Russia, 2. \\\"Other\\\".  \\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Structure\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tFeatures\\n\\t\\n\\n\\ntext: The comment text (string).\\nlabel: The label for the comment‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/gentilrenard/lmd_ukraine_comments."},
  {"name":"medieval","keyword":"french","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/CATMuS/medieval","creator_name":"CATMuS: Consistent Approach to Transcribing ManuScripts","creator_url":"https://huggingface.co/CATMuS","description":"\\n\\t\\n\\t\\t\\n\\t\\tDataset Card for CATMuS Medieval\\n\\t\\n\\n\\nJoin our Discord to ask questions about the dataset: \\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Details\\n\\t\\n\\nHandwritten Text Recognition (HTR) has emerged as a crucial tool for converting manuscripts images into machine-readable formats, \\nenabling researchers and scholars to analyse vast collections efficiently. \\nDespite significant technological progress, establishing consistent ground truth across projects for HTR tasks, \\nparticularly for complex and heterogeneous‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/CATMuS/medieval."},
  {"name":"French-Alpaca-dataset-Instruct-110K","keyword":"french","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/jpacifico/French-Alpaca-dataset-Instruct-110K","creator_name":"Jonathan Pacifico","creator_url":"https://huggingface.co/jpacifico","description":"110368 French instructions generated by OpenAI GPT-3.5-turbo in Alpaca Format to finetune general models\\nCreated by Jonathan Pacifico, 2024Please credit my name if you use this dataset in your project.\\n"},
  {"name":"MAGBIG","keyword":"french","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/felfri/MAGBIG","creator_name":"Felix Friedrich","creator_url":"https://huggingface.co/felfri","description":"\\n\\t\\n\\t\\t\\n\\t\\tMAGBIG benchmark\\n\\t\\n\\nThis is the MAGBIG benchmark proposed in https://arxiv.org/abs/2401.16092\\nThis benchmark is intended for multilingual text-to-image models. With MAGBIG, you can generate images for a diverse set of prompts across ten different languages. These images can be evaluated for differences across languages. MAGBIG is designed to uncover and assess biases across languages such as gender, race, age, etc. This way, we can measure whether bias exists in a language, but also if‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/felfri/MAGBIG."},
  {"name":"BAN","keyword":"french","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/vjugecdx/BAN","creator_name":"ChainDataX","creator_url":"https://huggingface.co/vjugecdx","description":"vjugecdx/BAN dataset hosted on Hugging Face and contributed by the HF Datasets community"},
  {"name":"synthetic-introduction-extraction","keyword":"french","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/angelmmiguel/synthetic-introduction-extraction","creator_name":"Angel M De Miguel","creator_url":"https://huggingface.co/angelmmiguel","description":"angelmmiguel/synthetic-introduction-extraction dataset hosted on Hugging Face and contributed by the HF Datasets community"},
  {"name":"convtune","keyword":"french","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/leafspark/convtune","creator_name":"leafspark","creator_url":"https://huggingface.co/leafspark","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tconvtune\\n\\t\\n\\nDataset I made for instruct tuning my own models.\\nThis is a synthetic dataset generated by the following models:\\n\\nMistral-7b\\nMistral-8x22b\\nClaude 3 Opus/Sonnet/Haiku\\nGPT-4 and GPT-4 Turbo\\nGPT-3.5-16k and GPT-3.5\\nQwen-0.5b\\nQwen-7b/70b\\n\\nPlease note the dataset has not been filtered or curated.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tFormat:\\n\\t\\n\\n[\\n  {\\n   \\\"prompt\\\": \\\"What is the sun made of?\\\",\\n   \\\"response\\\": \\\"The sun is made of of...\\\"\\n  }\\n]\\n\\n"},
  {"name":"MMedBench","keyword":"french","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/aisc-team-c2/MMedBench","creator_name":"AISC Team C2","creator_url":"https://huggingface.co/aisc-team-c2","description":"This is a dataset repository made for the AISC class at Harvard Medical School. Please find the original dataset repository here: https://huggingface.co/datasets/Henrychur/MMedBench \\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tMMedBench\\n\\t\\n\\nüíªGithub Repo   üñ®Ô∏èarXiv Paper\\nThe official benchmark for \\\"Towards Building Multilingual Language Model for Medicine\\\".\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tIntroduction\\n\\t\\n\\nThis repo contains MMedBench, a comprehensive multilingual medical benchmark comprising 45,048 QA pairs for training and 8,518 QA pairs for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/aisc-team-c2/MMedBench."},
  {"name":"elegana_relation_client_FR","keyword":"french","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/Franbul/elegana_relation_client_FR","creator_name":"Fran√ßois Bullier","creator_url":"https://huggingface.co/Franbul","description":"\\n\\t\\n\\t\\t\\n\\t\\tDataset Card for Elegana Dataset\\n\\t\\n\\nThis dataset card provides detailed information about the Elegana datasets in French.\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Overview\\n\\t\\n\\nThe Elegana dataset is a synthetic dataset generated using ChatGPT. It is designed to support the Beevibe Python package by providing training data for language models. The dataset consists of Q&R between customers and the web-based customer support team of a fictional brand named Elegana.\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Components\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tCustomer‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Franbul/elegana_relation_client_FR."},
  {"name":"multilingual-wealth-alpaca","keyword":"french","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/dgallitelli/multilingual-wealth-alpaca","creator_name":"Davide Gallitelli","creator_url":"https://huggingface.co/dgallitelli","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tMultilingual Wealth Alpaca Dataset\\n\\t\\n\\n\\nWork derivative of gbharti/wealth-alpaca_lora dataset. The original dataset is a combination of Stanford's Alpaca (https://github.com/tatsu-lab/stanford_alpaca) and FiQA (https://sites.google.com/view/fiqa/) with another 1.3k pairs custom generated using GPT3.5 . This version is a cleaned up version, which also has: \\n\\nmutlilingual support (en, it, fr, es, de)\\nCSV and JSON files\\n\\n"},
  {"name":"llm-latent-language","keyword":"french","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/wendlerc/llm-latent-language","creator_name":"Chris Wendler","creator_url":"https://huggingface.co/wendlerc","description":"Latents computed using meta-llama/Llama-2-7b-hf, meta-llama/Llama-2-13b-hf, meta-llama/Llama-2-70b-hf\\n"},
  {"name":"MSD_instruct","keyword":"french","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/nuvocare/MSD_instruct","creator_name":"Nuvocare","creator_url":"https://huggingface.co/nuvocare","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tMSD_manual_topics_user_base\\n\\t\\n\\nThis dataset has been built with the website https://www.msdmanuals.com/ provided by Merck & Co for the greater audience.\\nThe MSD manual is an essential source of knowledge for many topics related to symptoms, diseases, health and other related topics. The manual makes an extra effort to make it available both for professionals and patients by having two distinct version. \\nThe content, while being labelled the same, differs by the type of user in‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/nuvocare/MSD_instruct."},
  {"name":"Multi-lingual_Detection","keyword":"french","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/Manirathinam21/Multi-lingual_Detection","creator_name":"Manirathinam","creator_url":"https://huggingface.co/Manirathinam21","description":"Manirathinam21/Multi-lingual_Detection dataset hosted on Hugging Face and contributed by the HF Datasets community"},
  {"name":"ehri-ner-all","keyword":"french","license":"European Union Public License 1.1","language":"en","url":"https://huggingface.co/datasets/ehri-ner/ehri-ner-all","creator_name":"EHRI-NER","creator_url":"https://huggingface.co/ehri-ner","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for ehri-ner/ehri-ner-all\\n\\t\\n\\n\\nThe European Holocaust Research Infrastructure (EHRI) aims to support Holocaust research by making information about dispersed Holocaust material accessible and interconnected through its services. Creating a tool capable of detecting named entities in texts such as Holocaust testimonies or archival descriptions would make it easier to link more material with relevant identifiers in domain-specific controlled vocabularies, semantically‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ehri-ner/ehri-ner-all."},
  {"name":"paragraph_dataset","keyword":"french","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/dedoc/paragraph_dataset","creator_name":"Dedoc Team","creator_url":"https://huggingface.co/dedoc","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tParagraph dataset\\n\\t\\n\\nDataset for a lines classifier that predicts the beginning of a new paragraph (see paragraph classifier).\\nThe repository structure:\\n‚îî‚îÄparagraph_dataset\\n  ‚îú‚îÄlabeling\\n    ‚îú‚îÄparagraph_classifier_834997.zip\\n    ‚îî‚îÄresults\\n      ‚îú‚îÄlaw_classifier_000000_AKs.json\\n      ‚îú‚îÄ ...\\n      ‚îî‚îÄlaw_classifier_000049_d9X.json\\n  ‚îú‚îÄ.gitattributes\\n  ‚îú‚îÄREADME.md\\n  ‚îî‚îÄparagraph_dataset.zip\\n\\nlabeling directory contains tasks for labeling (paragraph_classifier_834997.zip) and labeled‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/dedoc/paragraph_dataset."},
  {"name":"iati-policy-markers","keyword":"french","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/devinitorg/iati-policy-markers","creator_name":"Development Initiatives","creator_url":"https://huggingface.co/devinitorg","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tInternational Aid Transparency Initiative (IATI) Policy Marker Dataset\\n\\t\\n\\nA multi-purpose dataset including all activity title and description text published to IATI with metadata for policy markers.\\nFor more information on IATI policy markers, see the element page on the IATI Standard Website.\\nIATI is a living data source, and this dataset was last updated on 21 August, 2024. For the code to generate an updated version of this dataset, please see my Github repository here.\\nFor any‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/devinitorg/iati-policy-markers."},
  {"name":"Publico","keyword":"french","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/hugosousa/Publico","creator_name":"Hugo Sousa","creator_url":"https://huggingface.co/hugosousa","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tP√∫blico\\n\\t\\n\\nThis dataset was build by translating a set of 34,157 news from P√∫blico, an European Portuguese news paper. The news have been translated using Google Translator.\\nTo now more about the data visit the Github repos used to scrape and translate the news.\\n"},
  {"name":"mewsli-x","keyword":"french","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/izhx/mewsli-x","creator_name":"Xin Zhang","creator_url":"https://huggingface.co/izhx","description":"I generated the dataset following mewsli-x.md#getting-started\\nand converted into different parts (see process.py):\\n\\nar/de/en/es/fa/ja/pl/ro/ta/tr/uk wikinews_mentions dev and test (from wikinews_mentions-dev/test.jsonl)\\ncandidate entities of 50 languages (from candidate_set_entities.jsonl)\\nEnglish wikipedia_pairs to fine-tune models (from wikipedia_pairs-dev/train.jsonl)\\n\\nRaw data files are in raw.tar.gz, which contains:\\n[...] 535M Feb 24 22:06 candidate_set_entities.jsonl\\n[...] 9.8M Feb 24‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/izhx/mewsli-x."},
  {"name":"chia-ner-french","keyword":"french","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/JavierLopetegui/chia-ner-french","creator_name":"Javier Alejandro Lopetegui Gonzalez","creator_url":"https://huggingface.co/JavierLopetegui","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for French Clinical Trials NER Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Details\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThis dataset provides French translations and annotations for Named Entity Recognition (NER) in clinical trials' eligibility criteria. It was generated as part of the final project of the Hands-On NLP course at Universit√© Paris-Saclay M1-AI. The dataset builds on the English CHIA dataset by using a cross-lingual approach, including neural machine translation and‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/JavierLopetegui/chia-ner-french."},
  {"name":"MultiQ","keyword":"french","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/caro-holt/MultiQ","creator_name":"Holtermann","creator_url":"https://huggingface.co/caro-holt","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for MultiQ\\n\\t\\n\\nThis is the dataset corresponding to the paper \\\"Evaluating the Elementary Multilingual Capabilities of Large Language Models with MultiQ\\\". \\nIt is a silver standard benchmark that can be used to evaluate the basic multilingual capabilities of LLMs. It contains 200 open ended questions automatically \\ntranslated into 137 typologically diverse languages. \\n\\nCurated by: Carolin Holtermann, Paul R√∂ttger, Timm Dill, Anne Lauscher\\nLanguage(s) (NLP): 137 diverse‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/caro-holt/MultiQ."},
  {"name":"MMedBench","keyword":"french","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/aisc-team-c1/MMedBench","creator_name":"AISC Team C1","creator_url":"https://huggingface.co/aisc-team-c1","description":"This is a dataset repository made for the AISC class at Harvard Medical School. Please find the original dataset repository here: https://huggingface.co/datasets/Henrychur/MMedBench \\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tMMedBench\\n\\t\\n\\nüíªGithub Repo   üñ®Ô∏èarXiv Paper\\nThe official benchmark for \\\"Towards Building Multilingual Language Model for Medicine\\\".\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tIntroduction\\n\\t\\n\\nThis repo contains MMedBench, a comprehensive multilingual medical benchmark comprising 45,048 QA pairs for training and 8,518 QA pairs for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/aisc-team-c1/MMedBench."},
  {"name":"bhojpuri","keyword":"french","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/ankur02/bhojpuri","creator_name":"Ankur Verma","creator_url":"https://huggingface.co/ankur02","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tFLEURS\\n\\t\\n\\nFleurs is the speech version of the FLoRes machine translation benchmark. \\nWe use 2009 n-way parallel sentences from the FLoRes dev and devtest publicly available sets, in 102 languages. \\nTraining sets have around 10 hours of supervision. Speakers of the train sets are different than speakers from the dev/test sets. Multilingual fine-tuning is\\nused and ‚Äùunit error rate‚Äù (characters, signs) of all languages is averaged. Languages and results are also grouped into seven‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ankur02/bhojpuri."},
  {"name":"mmarco-contrastive","keyword":"french","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/cmarkea/mmarco-contrastive","creator_name":"Credit Mutuel Arkea","creator_url":"https://huggingface.co/cmarkea","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tmMARCO-contrastive\\n\\t\\n\\nThe dataset is a modification of mMARCO focusing on French and English parts. The aim is to train a\\nbi-encoder model using all hard negatives from the database. Instead of having a query/positive/negative triplet, we pair all negatives with a query and a\\npositive. However, it's worth noting that there are many false negatives in the dataset. This isn't a big issue with a triplet view because false negatives\\nare much fewer in number, but it's more significant‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/cmarkea/mmarco-contrastive."},
  {"name":"multi-hatecheck","keyword":"french","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/mteb/multi-hatecheck","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDescription\\n\\t\\n\\nCombines multilingual HateCheck datasets (10 languages, including English), by Paul Roettger and colleagues (2021, 2022).\\nThe original English dataset can be found under https://github.com/Paul/hatecheck.\\nDatasets for other languages are found at:\\n\\nhttps://github.com/Paul/hatecheck-arabic\\nhttps://github.com/Paul/hatecheck-mandarin\\nhttps://github.com/Paul/hatecheck-german\\nhttps://github.com/Paul/hatecheck-french\\nhttps://github.com/Paul/hatecheck-hindi‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/multi-hatecheck."},
  {"name":"aya_african_alpaca","keyword":"french","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/vutuka/aya_african_alpaca","creator_name":"vutuka","creator_url":"https://huggingface.co/vutuka","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tAya African Alpaca Style Dataset\\n\\t\\n\\n\\n\\nThis dataset card aims to be a base template for new datasets. It has been generated using this raw template.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Details\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\n\\n\\n\\n\\nCurated by: [More Information Needed]\\nFunded by [optional]: [More Information Needed]\\nShared by [optional]: [More Information Needed]\\nLanguage(s) (NLP): [More Information Needed]\\nLicense: [More Information Needed]\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Sources [optional]‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/vutuka/aya_african_alpaca."},
  {"name":"casimedicos-exp","keyword":"french","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/HiTZ/casimedicos-exp","creator_name":"HiTZ zentroa","creator_url":"https://huggingface.co/HiTZ","description":"\\n    \\n    \\n    \\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tAntidote CasiMedicos Dataset - Possible Answers Explanations in Resident Medical Exams\\n\\t\\n\\nWe present a new multilingual parallel medical dataset of commented medical exams which includes not only explanatory arguments\\nfor the correct answer but also arguments to explain why the remaining possible answers are incorrect.\\nThis dataset can be used for various NLP tasks including: Medical Question Answering, Explanatory Argument Extraction or Explanation Generation.\\nThe‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/HiTZ/casimedicos-exp."},
  {"name":"panlex-meanings","keyword":"french","license":"Creative Commons Zero v1.0 Universal","language":"en","url":"https://huggingface.co/datasets/cointegrated/panlex-meanings","creator_name":"David Dale","creator_url":"https://huggingface.co/cointegrated","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for panlex-meanings\\n\\t\\n\\nThis is a dataset of words in several thousand languages, extracted from https://panlex.org.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Details\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThis dataset has been extracted from https://panlex.org (the 20240301 database dump) and rearranged on the per-language basis.\\nEach language subset consists of expressions (words and phrases). \\nEach expression is associated with some meanings (if there is more than one meaning, they are in‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/cointegrated/panlex-meanings."},
  {"name":"neural-bridge-rag-dataset-12000-google-translated","keyword":"french","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/pandora-s/neural-bridge-rag-dataset-12000-google-translated","creator_name":"pandora","creator_url":"https://huggingface.co/pandora-s","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tOverview\\n\\t\\n\\nThis is a repository where I will slowly translate neural-bridge/rag-dataset-12000 into different languages with Google Translate.As RAG datasets are quite scarce, I felt that this could be useful for many who seek to add RAG capabilities to their models!\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tHow?\\n\\t\\n\\nThere are no secrets; these are raw translations that might not be 100% reliable. I literally run the entire dataset through Google Translate overnight.I'm prioritizing \\\"quantity\\\" over \\\"quality\\\"‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/pandora-s/neural-bridge-rag-dataset-12000-google-translated."},
  {"name":"code-action-sociale-familles","keyword":"french","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/louisbrulenaudet/code-action-sociale-familles","creator_name":"Louis Brul√© Naudet","creator_url":"https://huggingface.co/louisbrulenaudet","description":"\\n\\t\\n\\t\\t\\n\\t\\tCode de l'action sociale et des familles, non-instruct (2025-03-10)\\n\\t\\n\\nThe objective of this project is to provide researchers, professionals and law students with simplified, up-to-date access to all French legal texts, enriched with a wealth of data to facilitate their integration into Community and European projects.\\nNormally, the data is refreshed daily on all legal codes, and aims to simplify the production of training sets and labeling pipelines for the development of free‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/louisbrulenaudet/code-action-sociale-familles."},
  {"name":"code-aviation-civile","keyword":"french","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/louisbrulenaudet/code-aviation-civile","creator_name":"Louis Brul√© Naudet","creator_url":"https://huggingface.co/louisbrulenaudet","description":"\\n\\t\\n\\t\\t\\n\\t\\tCode de l'aviation civile, non-instruct (2025-03-10)\\n\\t\\n\\nThe objective of this project is to provide researchers, professionals and law students with simplified, up-to-date access to all French legal texts, enriched with a wealth of data to facilitate their integration into Community and European projects.\\nNormally, the data is refreshed daily on all legal codes, and aims to simplify the production of training sets and labeling pipelines for the development of free, open-source language‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/louisbrulenaudet/code-aviation-civile."},
  {"name":"code-cinema-image-animee","keyword":"french","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/louisbrulenaudet/code-cinema-image-animee","creator_name":"Louis Brul√© Naudet","creator_url":"https://huggingface.co/louisbrulenaudet","description":"\\n\\t\\n\\t\\t\\n\\t\\tCode du cin√©ma et de l'image anim√©e, non-instruct (2025-03-10)\\n\\t\\n\\nThe objective of this project is to provide researchers, professionals and law students with simplified, up-to-date access to all French legal texts, enriched with a wealth of data to facilitate their integration into Community and European projects.\\nNormally, the data is refreshed daily on all legal codes, and aims to simplify the production of training sets and labeling pipelines for the development of free‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/louisbrulenaudet/code-cinema-image-animee."},
  {"name":"code-communes","keyword":"french","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/louisbrulenaudet/code-communes","creator_name":"Louis Brul√© Naudet","creator_url":"https://huggingface.co/louisbrulenaudet","description":"\\n\\t\\n\\t\\t\\n\\t\\tCode des communes, non-instruct (2025-03-10)\\n\\t\\n\\nThe objective of this project is to provide researchers, professionals and law students with simplified, up-to-date access to all French legal texts, enriched with a wealth of data to facilitate their integration into Community and European projects.\\nNormally, the data is refreshed daily on all legal codes, and aims to simplify the production of training sets and labeling pipelines for the development of free, open-source language models‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/louisbrulenaudet/code-communes."},
  {"name":"code-communes-nouvelle-caledonie","keyword":"french","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/louisbrulenaudet/code-communes-nouvelle-caledonie","creator_name":"Louis Brul√© Naudet","creator_url":"https://huggingface.co/louisbrulenaudet","description":"\\n\\t\\n\\t\\t\\n\\t\\tCode des communes de la Nouvelle-Cal√©donie, non-instruct (2025-03-10)\\n\\t\\n\\nThe objective of this project is to provide researchers, professionals and law students with simplified, up-to-date access to all French legal texts, enriched with a wealth of data to facilitate their integration into Community and European projects.\\nNormally, the data is refreshed daily on all legal codes, and aims to simplify the production of training sets and labeling pipelines for the development of free‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/louisbrulenaudet/code-communes-nouvelle-caledonie."},
  {"name":"code-defense","keyword":"french","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/louisbrulenaudet/code-defense","creator_name":"Louis Brul√© Naudet","creator_url":"https://huggingface.co/louisbrulenaudet","description":"\\n\\t\\n\\t\\t\\n\\t\\tCode de la d√©fense, non-instruct (2025-03-10)\\n\\t\\n\\nThe objective of this project is to provide researchers, professionals and law students with simplified, up-to-date access to all French legal texts, enriched with a wealth of data to facilitate their integration into Community and European projects.\\nNormally, the data is refreshed daily on all legal codes, and aims to simplify the production of training sets and labeling pipelines for the development of free, open-source language models‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/louisbrulenaudet/code-defense."},
  {"name":"code-deontologie-architectes","keyword":"french","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/louisbrulenaudet/code-deontologie-architectes","creator_name":"Louis Brul√© Naudet","creator_url":"https://huggingface.co/louisbrulenaudet","description":"\\n\\t\\n\\t\\t\\n\\t\\tCode de d√©ontologie des architectes, non-instruct (2025-03-10)\\n\\t\\n\\nThe objective of this project is to provide researchers, professionals and law students with simplified, up-to-date access to all French legal texts, enriched with a wealth of data to facilitate their integration into Community and European projects.\\nNormally, the data is refreshed daily on all legal codes, and aims to simplify the production of training sets and labeling pipelines for the development of free‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/louisbrulenaudet/code-deontologie-architectes."},
  {"name":"code-disciplinaire-penal-marine-marchande","keyword":"french","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/louisbrulenaudet/code-disciplinaire-penal-marine-marchande","creator_name":"Louis Brul√© Naudet","creator_url":"https://huggingface.co/louisbrulenaudet","description":"\\n\\t\\n\\t\\t\\n\\t\\tCode disciplinaire et p√©nal de la marine marchande, non-instruct (2025-03-10)\\n\\t\\n\\nThe objective of this project is to provide researchers, professionals and law students with simplified, up-to-date access to all French legal texts, enriched with a wealth of data to facilitate their integration into Community and European projects.\\nNormally, the data is refreshed daily on all legal codes, and aims to simplify the production of training sets and labeling pipelines for the development of‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/louisbrulenaudet/code-disciplinaire-penal-marine-marchande."},
  {"name":"code-domaine-etat","keyword":"french","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/louisbrulenaudet/code-domaine-etat","creator_name":"Louis Brul√© Naudet","creator_url":"https://huggingface.co/louisbrulenaudet","description":"\\n\\t\\n\\t\\t\\n\\t\\tCode du domaine de l'Etat, non-instruct (2025-03-10)\\n\\t\\n\\nThe objective of this project is to provide researchers, professionals and law students with simplified, up-to-date access to all French legal texts, enriched with a wealth of data to facilitate their integration into Community and European projects.\\nNormally, the data is refreshed daily on all legal codes, and aims to simplify the production of training sets and labeling pipelines for the development of free, open-source language‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/louisbrulenaudet/code-domaine-etat."},
  {"name":"code-domaine-etat-collectivites-mayotte","keyword":"french","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/louisbrulenaudet/code-domaine-etat-collectivites-mayotte","creator_name":"Louis Brul√© Naudet","creator_url":"https://huggingface.co/louisbrulenaudet","description":"\\n\\t\\n\\t\\t\\n\\t\\tCode du domaine de l'Etat et des collectivit√©s publiques applicable √† la collectivit√© territoriale de Mayotte, non-instruct (2025-03-10)\\n\\t\\n\\nThe objective of this project is to provide researchers, professionals and law students with simplified, up-to-date access to all French legal texts, enriched with a wealth of data to facilitate their integration into Community and European projects.\\nNormally, the data is refreshed daily on all legal codes, and aims to simplify the production of‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/louisbrulenaudet/code-domaine-etat-collectivites-mayotte."},
  {"name":"code-domaine-public-fluvial-navigation-interieure","keyword":"french","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/louisbrulenaudet/code-domaine-public-fluvial-navigation-interieure","creator_name":"Louis Brul√© Naudet","creator_url":"https://huggingface.co/louisbrulenaudet","description":"\\n\\t\\n\\t\\t\\n\\t\\tCode du domaine public fluvial et de la navigation int√©rieure, non-instruct (2025-03-10)\\n\\t\\n\\nThe objective of this project is to provide researchers, professionals and law students with simplified, up-to-date access to all French legal texts, enriched with a wealth of data to facilitate their integration into Community and European projects.\\nNormally, the data is refreshed daily on all legal codes, and aims to simplify the production of training sets and labeling pipelines for the‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/louisbrulenaudet/code-domaine-public-fluvial-navigation-interieure."},
  {"name":"code-douanes-mayotte","keyword":"french","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/louisbrulenaudet/code-douanes-mayotte","creator_name":"Louis Brul√© Naudet","creator_url":"https://huggingface.co/louisbrulenaudet","description":"\\n\\t\\n\\t\\t\\n\\t\\tCode des douanes de Mayotte, non-instruct (2025-03-10)\\n\\t\\n\\nThe objective of this project is to provide researchers, professionals and law students with simplified, up-to-date access to all French legal texts, enriched with a wealth of data to facilitate their integration into Community and European projects.\\nNormally, the data is refreshed daily on all legal codes, and aims to simplify the production of training sets and labeling pipelines for the development of free, open-source‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/louisbrulenaudet/code-douanes-mayotte."},
  {"name":"code-electoral","keyword":"french","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/louisbrulenaudet/code-electoral","creator_name":"Louis Brul√© Naudet","creator_url":"https://huggingface.co/louisbrulenaudet","description":"\\n\\t\\n\\t\\t\\n\\t\\tCode √©lectoral, non-instruct (2025-03-10)\\n\\t\\n\\nThe objective of this project is to provide researchers, professionals and law students with simplified, up-to-date access to all French legal texts, enriched with a wealth of data to facilitate their integration into Community and European projects.\\nNormally, the data is refreshed daily on all legal codes, and aims to simplify the production of training sets and labeling pipelines for the development of free, open-source language models‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/louisbrulenaudet/code-electoral."},
  {"name":"code-energie","keyword":"french","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/louisbrulenaudet/code-energie","creator_name":"Louis Brul√© Naudet","creator_url":"https://huggingface.co/louisbrulenaudet","description":"\\n\\t\\n\\t\\t\\n\\t\\tCode de l'√©nergie, non-instruct (2025-03-10)\\n\\t\\n\\nThe objective of this project is to provide researchers, professionals and law students with simplified, up-to-date access to all French legal texts, enriched with a wealth of data to facilitate their integration into Community and European projects.\\nNormally, the data is refreshed daily on all legal codes, and aims to simplify the production of training sets and labeling pipelines for the development of free, open-source language models‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/louisbrulenaudet/code-energie."},
  {"name":"code-entree-sejour-etrangers-droit-asile","keyword":"french","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/louisbrulenaudet/code-entree-sejour-etrangers-droit-asile","creator_name":"Louis Brul√© Naudet","creator_url":"https://huggingface.co/louisbrulenaudet","description":"\\n\\t\\n\\t\\t\\n\\t\\tCode de l'entr√©e et du s√©jour des √©trangers et du droit d'asile, non-instruct (2025-03-10)\\n\\t\\n\\nThe objective of this project is to provide researchers, professionals and law students with simplified, up-to-date access to all French legal texts, enriched with a wealth of data to facilitate their integration into Community and European projects.\\nNormally, the data is refreshed daily on all legal codes, and aims to simplify the production of training sets and labeling pipelines for the‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/louisbrulenaudet/code-entree-sejour-etrangers-droit-asile."},
  {"name":"code-expropriation-utilite-publique","keyword":"french","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/louisbrulenaudet/code-expropriation-utilite-publique","creator_name":"Louis Brul√© Naudet","creator_url":"https://huggingface.co/louisbrulenaudet","description":"\\n\\t\\n\\t\\t\\n\\t\\tCode de l'expropriation pour cause d'utilit√© publique, non-instruct (2025-03-10)\\n\\t\\n\\nThe objective of this project is to provide researchers, professionals and law students with simplified, up-to-date access to all French legal texts, enriched with a wealth of data to facilitate their integration into Community and European projects.\\nNormally, the data is refreshed daily on all legal codes, and aims to simplify the production of training sets and labeling pipelines for the development‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/louisbrulenaudet/code-expropriation-utilite-publique."},
  {"name":"code-famille-aide-sociale","keyword":"french","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/louisbrulenaudet/code-famille-aide-sociale","creator_name":"Louis Brul√© Naudet","creator_url":"https://huggingface.co/louisbrulenaudet","description":"\\n\\t\\n\\t\\t\\n\\t\\tCode de la famille et de l'aide sociale, non-instruct (2025-03-10)\\n\\t\\n\\nThe objective of this project is to provide researchers, professionals and law students with simplified, up-to-date access to all French legal texts, enriched with a wealth of data to facilitate their integration into Community and European projects.\\nNormally, the data is refreshed daily on all legal codes, and aims to simplify the production of training sets and labeling pipelines for the development of free‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/louisbrulenaudet/code-famille-aide-sociale."},
  {"name":"code-forestier-nouveau","keyword":"french","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/louisbrulenaudet/code-forestier-nouveau","creator_name":"Louis Brul√© Naudet","creator_url":"https://huggingface.co/louisbrulenaudet","description":"\\n\\t\\n\\t\\t\\n\\t\\tCode forestier (nouveau), non-instruct (2025-03-10)\\n\\t\\n\\nThe objective of this project is to provide researchers, professionals and law students with simplified, up-to-date access to all French legal texts, enriched with a wealth of data to facilitate their integration into Community and European projects.\\nNormally, the data is refreshed daily on all legal codes, and aims to simplify the production of training sets and labeling pipelines for the development of free, open-source language‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/louisbrulenaudet/code-forestier-nouveau."},
  {"name":"code-fonction-publique","keyword":"french","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/louisbrulenaudet/code-fonction-publique","creator_name":"Louis Brul√© Naudet","creator_url":"https://huggingface.co/louisbrulenaudet","description":"\\n\\t\\n\\t\\t\\n\\t\\tCode g√©n√©ral de la fonction publique, non-instruct (2025-03-10)\\n\\t\\n\\nThe objective of this project is to provide researchers, professionals and law students with simplified, up-to-date access to all French legal texts, enriched with a wealth of data to facilitate their integration into Community and European projects.\\nNormally, the data is refreshed daily on all legal codes, and aims to simplify the production of training sets and labeling pipelines for the development of free‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/louisbrulenaudet/code-fonction-publique."},
  {"name":"code-propriete-personnes-publiques","keyword":"french","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/louisbrulenaudet/code-propriete-personnes-publiques","creator_name":"Louis Brul√© Naudet","creator_url":"https://huggingface.co/louisbrulenaudet","description":"\\n\\t\\n\\t\\t\\n\\t\\tCode g√©n√©ral de la propri√©t√© des personnes publiques, non-instruct (2025-03-10)\\n\\t\\n\\nThe objective of this project is to provide researchers, professionals and law students with simplified, up-to-date access to all French legal texts, enriched with a wealth of data to facilitate their integration into Community and European projects.\\nNormally, the data is refreshed daily on all legal codes, and aims to simplify the production of training sets and labeling pipelines for the development of‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/louisbrulenaudet/code-propriete-personnes-publiques."},
  {"name":"code-collectivites-territoriales","keyword":"french","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/louisbrulenaudet/code-collectivites-territoriales","creator_name":"Louis Brul√© Naudet","creator_url":"https://huggingface.co/louisbrulenaudet","description":"\\n\\t\\n\\t\\t\\n\\t\\tCode g√©n√©ral des collectivit√©s territoriales, non-instruct (2025-03-10)\\n\\t\\n\\nThe objective of this project is to provide researchers, professionals and law students with simplified, up-to-date access to all French legal texts, enriched with a wealth of data to facilitate their integration into Community and European projects.\\nNormally, the data is refreshed daily on all legal codes, and aims to simplify the production of training sets and labeling pipelines for the development of free‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/louisbrulenaudet/code-collectivites-territoriales."},
  {"name":"code-impots","keyword":"french","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/louisbrulenaudet/code-impots","creator_name":"Louis Brul√© Naudet","creator_url":"https://huggingface.co/louisbrulenaudet","description":"\\n\\t\\n\\t\\t\\n\\t\\tCode g√©n√©ral des imp√¥ts, non-instruct (2025-03-10)\\n\\t\\n\\nThe objective of this project is to provide researchers, professionals and law students with simplified, up-to-date access to all French legal texts, enriched with a wealth of data to facilitate their integration into Community and European projects.\\nNormally, the data is refreshed daily on all legal codes, and aims to simplify the production of training sets and labeling pipelines for the development of free, open-source language‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/louisbrulenaudet/code-impots."},
  {"name":"code-impots-annexe-i","keyword":"french","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/louisbrulenaudet/code-impots-annexe-i","creator_name":"Louis Brul√© Naudet","creator_url":"https://huggingface.co/louisbrulenaudet","description":"\\n\\t\\n\\t\\t\\n\\t\\tCode g√©n√©ral des imp√¥ts, annexe I, non-instruct (2025-03-10)\\n\\t\\n\\nThe objective of this project is to provide researchers, professionals and law students with simplified, up-to-date access to all French legal texts, enriched with a wealth of data to facilitate their integration into Community and European projects.\\nNormally, the data is refreshed daily on all legal codes, and aims to simplify the production of training sets and labeling pipelines for the development of free, open-source‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/louisbrulenaudet/code-impots-annexe-i."},
  {"name":"code-impots-annexe-ii","keyword":"french","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/louisbrulenaudet/code-impots-annexe-ii","creator_name":"Louis Brul√© Naudet","creator_url":"https://huggingface.co/louisbrulenaudet","description":"\\n\\t\\n\\t\\t\\n\\t\\tCode g√©n√©ral des imp√¥ts, annexe II, non-instruct (2025-03-10)\\n\\t\\n\\nThe objective of this project is to provide researchers, professionals and law students with simplified, up-to-date access to all French legal texts, enriched with a wealth of data to facilitate their integration into Community and European projects.\\nNormally, the data is refreshed daily on all legal codes, and aims to simplify the production of training sets and labeling pipelines for the development of free, open-source‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/louisbrulenaudet/code-impots-annexe-ii."},
  {"name":"code-impots-annexe-iii","keyword":"french","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/louisbrulenaudet/code-impots-annexe-iii","creator_name":"Louis Brul√© Naudet","creator_url":"https://huggingface.co/louisbrulenaudet","description":"\\n\\t\\n\\t\\t\\n\\t\\tCode g√©n√©ral des imp√¥ts, annexe III, non-instruct (2025-03-10)\\n\\t\\n\\nThe objective of this project is to provide researchers, professionals and law students with simplified, up-to-date access to all French legal texts, enriched with a wealth of data to facilitate their integration into Community and European projects.\\nNormally, the data is refreshed daily on all legal codes, and aims to simplify the production of training sets and labeling pipelines for the development of free‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/louisbrulenaudet/code-impots-annexe-iii."},
  {"name":"code-impots-annexe-iv","keyword":"french","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/louisbrulenaudet/code-impots-annexe-iv","creator_name":"Louis Brul√© Naudet","creator_url":"https://huggingface.co/louisbrulenaudet","description":"\\n\\t\\n\\t\\t\\n\\t\\tCode g√©n√©ral des imp√¥ts, annexe IV, non-instruct (2025-03-10)\\n\\t\\n\\nThe objective of this project is to provide researchers, professionals and law students with simplified, up-to-date access to all French legal texts, enriched with a wealth of data to facilitate their integration into Community and European projects.\\nNormally, the data is refreshed daily on all legal codes, and aims to simplify the production of training sets and labeling pipelines for the development of free, open-source‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/louisbrulenaudet/code-impots-annexe-iv."},
  {"name":"code-impositions-biens-services","keyword":"french","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/louisbrulenaudet/code-impositions-biens-services","creator_name":"Louis Brul√© Naudet","creator_url":"https://huggingface.co/louisbrulenaudet","description":"\\n\\t\\n\\t\\t\\n\\t\\tCode des impositions sur les biens et services, non-instruct (2025-03-10)\\n\\t\\n\\nThe objective of this project is to provide researchers, professionals and law students with simplified, up-to-date access to all French legal texts, enriched with a wealth of data to facilitate their integration into Community and European projects.\\nNormally, the data is refreshed daily on all legal codes, and aims to simplify the production of training sets and labeling pipelines for the development of free‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/louisbrulenaudet/code-impositions-biens-services."},
  {"name":"code-instruments-monetaires-medailles","keyword":"french","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/louisbrulenaudet/code-instruments-monetaires-medailles","creator_name":"Louis Brul√© Naudet","creator_url":"https://huggingface.co/louisbrulenaudet","description":"\\n\\t\\n\\t\\t\\n\\t\\tCode des instruments mon√©taires et des m√©dailles, non-instruct (2025-03-10)\\n\\t\\n\\nThe objective of this project is to provide researchers, professionals and law students with simplified, up-to-date access to all French legal texts, enriched with a wealth of data to facilitate their integration into Community and European projects.\\nNormally, the data is refreshed daily on all legal codes, and aims to simplify the production of training sets and labeling pipelines for the development of‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/louisbrulenaudet/code-instruments-monetaires-medailles."},
  {"name":"code-juridictions-financieres","keyword":"french","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/louisbrulenaudet/code-juridictions-financieres","creator_name":"Louis Brul√© Naudet","creator_url":"https://huggingface.co/louisbrulenaudet","description":"\\n\\t\\n\\t\\t\\n\\t\\tCode des juridictions financi√®res, non-instruct (2025-03-10)\\n\\t\\n\\nThe objective of this project is to provide researchers, professionals and law students with simplified, up-to-date access to all French legal texts, enriched with a wealth of data to facilitate their integration into Community and European projects.\\nNormally, the data is refreshed daily on all legal codes, and aims to simplify the production of training sets and labeling pipelines for the development of free, open-source‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/louisbrulenaudet/code-juridictions-financieres."},
  {"name":"code-justice-militaire-nouveau","keyword":"french","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/louisbrulenaudet/code-justice-militaire-nouveau","creator_name":"Louis Brul√© Naudet","creator_url":"https://huggingface.co/louisbrulenaudet","description":"\\n\\t\\n\\t\\t\\n\\t\\tCode de justice militaire (nouveau), non-instruct (2025-03-10)\\n\\t\\n\\nThe objective of this project is to provide researchers, professionals and law students with simplified, up-to-date access to all French legal texts, enriched with a wealth of data to facilitate their integration into Community and European projects.\\nNormally, the data is refreshed daily on all legal codes, and aims to simplify the production of training sets and labeling pipelines for the development of free‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/louisbrulenaudet/code-justice-militaire-nouveau."},
  {"name":"code-justice-penale-mineurs","keyword":"french","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/louisbrulenaudet/code-justice-penale-mineurs","creator_name":"Louis Brul√© Naudet","creator_url":"https://huggingface.co/louisbrulenaudet","description":"\\n\\t\\n\\t\\t\\n\\t\\tCode de la justice p√©nale des mineurs, non-instruct (2025-03-10)\\n\\t\\n\\nThe objective of this project is to provide researchers, professionals and law students with simplified, up-to-date access to all French legal texts, enriched with a wealth of data to facilitate their integration into Community and European projects.\\nNormally, the data is refreshed daily on all legal codes, and aims to simplify the production of training sets and labeling pipelines for the development of free‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/louisbrulenaudet/code-justice-penale-mineurs."},
  {"name":"code-legion-honneur-medaille-militaire-ordre-national-merite","keyword":"french","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/louisbrulenaudet/code-legion-honneur-medaille-militaire-ordre-national-merite","creator_name":"Louis Brul√© Naudet","creator_url":"https://huggingface.co/louisbrulenaudet","description":"\\n\\t\\n\\t\\t\\n\\t\\tCode de la L√©gion d'honneur, de la M√©daille militaire et de l'ordre national du M√©rite, non-instruct (2025-03-10)\\n\\t\\n\\nThe objective of this project is to provide researchers, professionals and law students with simplified, up-to-date access to all French legal texts, enriched with a wealth of data to facilitate their integration into Community and European projects.\\nNormally, the data is refreshed daily on all legal codes, and aims to simplify the production of training sets and‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/louisbrulenaudet/code-legion-honneur-medaille-militaire-ordre-national-merite."},
  {"name":"livre-procedures-fiscales","keyword":"french","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/louisbrulenaudet/livre-procedures-fiscales","creator_name":"Louis Brul√© Naudet","creator_url":"https://huggingface.co/louisbrulenaudet","description":"\\n\\t\\n\\t\\t\\n\\t\\tLivre des proc√©dures fiscales, non-instruct (2025-03-10)\\n\\t\\n\\nThe objective of this project is to provide researchers, professionals and law students with simplified, up-to-date access to all French legal texts, enriched with a wealth of data to facilitate their integration into Community and European projects.\\nNormally, the data is refreshed daily on all legal codes, and aims to simplify the production of training sets and labeling pipelines for the development of free, open-source‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/louisbrulenaudet/livre-procedures-fiscales."},
  {"name":"code-minier","keyword":"french","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/louisbrulenaudet/code-minier","creator_name":"Louis Brul√© Naudet","creator_url":"https://huggingface.co/louisbrulenaudet","description":"\\n\\t\\n\\t\\t\\n\\t\\tCode minier, non-instruct (2025-03-10)\\n\\t\\n\\nThe objective of this project is to provide researchers, professionals and law students with simplified, up-to-date access to all French legal texts, enriched with a wealth of data to facilitate their integration into Community and European projects.\\nNormally, the data is refreshed daily on all legal codes, and aims to simplify the production of training sets and labeling pipelines for the development of free, open-source language models based‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/louisbrulenaudet/code-minier."},
  {"name":"code-minier-nouveau","keyword":"french","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/louisbrulenaudet/code-minier-nouveau","creator_name":"Louis Brul√© Naudet","creator_url":"https://huggingface.co/louisbrulenaudet","description":"\\n\\t\\n\\t\\t\\n\\t\\tCode minier (nouveau), non-instruct (2025-03-10)\\n\\t\\n\\nThe objective of this project is to provide researchers, professionals and law students with simplified, up-to-date access to all French legal texts, enriched with a wealth of data to facilitate their integration into Community and European projects.\\nNormally, the data is refreshed daily on all legal codes, and aims to simplify the production of training sets and labeling pipelines for the development of free, open-source language‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/louisbrulenaudet/code-minier-nouveau."},
  {"name":"code-organisation-judiciaire","keyword":"french","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/louisbrulenaudet/code-organisation-judiciaire","creator_name":"Louis Brul√© Naudet","creator_url":"https://huggingface.co/louisbrulenaudet","description":"\\n\\t\\n\\t\\t\\n\\t\\tCode de l'organisation judiciaire, non-instruct (2025-03-10)\\n\\t\\n\\nThe objective of this project is to provide researchers, professionals and law students with simplified, up-to-date access to all French legal texts, enriched with a wealth of data to facilitate their integration into Community and European projects.\\nNormally, the data is refreshed daily on all legal codes, and aims to simplify the production of training sets and labeling pipelines for the development of free, open-source‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/louisbrulenaudet/code-organisation-judiciaire."},
  {"name":"code-patrimoine","keyword":"french","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/louisbrulenaudet/code-patrimoine","creator_name":"Louis Brul√© Naudet","creator_url":"https://huggingface.co/louisbrulenaudet","description":"\\n\\t\\n\\t\\t\\n\\t\\tCode du patrimoine, non-instruct (2025-03-10)\\n\\t\\n\\nThe objective of this project is to provide researchers, professionals and law students with simplified, up-to-date access to all French legal texts, enriched with a wealth of data to facilitate their integration into Community and European projects.\\nNormally, the data is refreshed daily on all legal codes, and aims to simplify the production of training sets and labeling pipelines for the development of free, open-source language models‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/louisbrulenaudet/code-patrimoine."},
  {"name":"code-penitentiaire","keyword":"french","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/louisbrulenaudet/code-penitentiaire","creator_name":"Louis Brul√© Naudet","creator_url":"https://huggingface.co/louisbrulenaudet","description":"\\n\\t\\n\\t\\t\\n\\t\\tCode p√©nitentiaire, non-instruct (2025-03-10)\\n\\t\\n\\nThe objective of this project is to provide researchers, professionals and law students with simplified, up-to-date access to all French legal texts, enriched with a wealth of data to facilitate their integration into Community and European projects.\\nNormally, the data is refreshed daily on all legal codes, and aims to simplify the production of training sets and labeling pipelines for the development of free, open-source language models‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/louisbrulenaudet/code-penitentiaire."},
  {"name":"code-pensions-civiles-militaires-retraite","keyword":"french","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/louisbrulenaudet/code-pensions-civiles-militaires-retraite","creator_name":"Louis Brul√© Naudet","creator_url":"https://huggingface.co/louisbrulenaudet","description":"\\n\\t\\n\\t\\t\\n\\t\\tCode des pensions civiles et militaires de retraite, non-instruct (2025-03-10)\\n\\t\\n\\nThe objective of this project is to provide researchers, professionals and law students with simplified, up-to-date access to all French legal texts, enriched with a wealth of data to facilitate their integration into Community and European projects.\\nNormally, the data is refreshed daily on all legal codes, and aims to simplify the production of training sets and labeling pipelines for the development of‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/louisbrulenaudet/code-pensions-civiles-militaires-retraite."},
  {"name":"code-pensions-retraite-marins-francais-commerce-peche-plaisance","keyword":"french","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/louisbrulenaudet/code-pensions-retraite-marins-francais-commerce-peche-plaisance","creator_name":"Louis Brul√© Naudet","creator_url":"https://huggingface.co/louisbrulenaudet","description":"\\n\\t\\n\\t\\t\\n\\t\\tCode des pensions de retraite des marins fran√ßais du commerce, de p√™che ou de plaisance, non-instruct (2025-03-10)\\n\\t\\n\\nThe objective of this project is to provide researchers, professionals and law students with simplified, up-to-date access to all French legal texts, enriched with a wealth of data to facilitate their integration into Community and European projects.\\nNormally, the data is refreshed daily on all legal codes, and aims to simplify the production of training sets and‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/louisbrulenaudet/code-pensions-retraite-marins-francais-commerce-peche-plaisance."},
  {"name":"code-pensions-militaires-invalidite-victimes-guerre","keyword":"french","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/louisbrulenaudet/code-pensions-militaires-invalidite-victimes-guerre","creator_name":"Louis Brul√© Naudet","creator_url":"https://huggingface.co/louisbrulenaudet","description":"\\n\\t\\n\\t\\t\\n\\t\\tCode des pensions militaires d'invalidit√© et des victimes de guerre, non-instruct (2025-03-10)\\n\\t\\n\\nThe objective of this project is to provide researchers, professionals and law students with simplified, up-to-date access to all French legal texts, enriched with a wealth of data to facilitate their integration into Community and European projects.\\nNormally, the data is refreshed daily on all legal codes, and aims to simplify the production of training sets and labeling pipelines for the‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/louisbrulenaudet/code-pensions-militaires-invalidite-victimes-guerre."},
  {"name":"code-ports-maritimes","keyword":"french","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/louisbrulenaudet/code-ports-maritimes","creator_name":"Louis Brul√© Naudet","creator_url":"https://huggingface.co/louisbrulenaudet","description":"\\n\\t\\n\\t\\t\\n\\t\\tCode des ports maritimes, non-instruct (2025-03-10)\\n\\t\\n\\nThe objective of this project is to provide researchers, professionals and law students with simplified, up-to-date access to all French legal texts, enriched with a wealth of data to facilitate their integration into Community and European projects.\\nNormally, the data is refreshed daily on all legal codes, and aims to simplify the production of training sets and labeling pipelines for the development of free, open-source language‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/louisbrulenaudet/code-ports-maritimes."},
  {"name":"code-procedure-penale","keyword":"french","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/louisbrulenaudet/code-procedure-penale","creator_name":"Louis Brul√© Naudet","creator_url":"https://huggingface.co/louisbrulenaudet","description":"\\n\\t\\n\\t\\t\\n\\t\\tCode de proc√©dure p√©nale, non-instruct (2025-03-10)\\n\\t\\n\\nThe objective of this project is to provide researchers, professionals and law students with simplified, up-to-date access to all French legal texts, enriched with a wealth of data to facilitate their integration into Community and European projects.\\nNormally, the data is refreshed daily on all legal codes, and aims to simplify the production of training sets and labeling pipelines for the development of free, open-source language‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/louisbrulenaudet/code-procedure-penale."},
  {"name":"code-recherche","keyword":"french","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/louisbrulenaudet/code-recherche","creator_name":"Louis Brul√© Naudet","creator_url":"https://huggingface.co/louisbrulenaudet","description":"\\n\\t\\n\\t\\t\\n\\t\\tCode de la recherche, non-instruct (2025-03-10)\\n\\t\\n\\nThe objective of this project is to provide researchers, professionals and law students with simplified, up-to-date access to all French legal texts, enriched with a wealth of data to facilitate their integration into Community and European projects.\\nNormally, the data is refreshed daily on all legal codes, and aims to simplify the production of training sets and labeling pipelines for the development of free, open-source language‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/louisbrulenaudet/code-recherche."},
  {"name":"code-rural-ancien","keyword":"french","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/louisbrulenaudet/code-rural-ancien","creator_name":"Louis Brul√© Naudet","creator_url":"https://huggingface.co/louisbrulenaudet","description":"\\n\\t\\n\\t\\t\\n\\t\\tCode rural (ancien), non-instruct (2025-03-10)\\n\\t\\n\\nThe objective of this project is to provide researchers, professionals and law students with simplified, up-to-date access to all French legal texts, enriched with a wealth of data to facilitate their integration into Community and European projects.\\nNormally, the data is refreshed daily on all legal codes, and aims to simplify the production of training sets and labeling pipelines for the development of free, open-source language‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/louisbrulenaudet/code-rural-ancien."},
  {"name":"code-service-national","keyword":"french","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/louisbrulenaudet/code-service-national","creator_name":"Louis Brul√© Naudet","creator_url":"https://huggingface.co/louisbrulenaudet","description":"\\n\\t\\n\\t\\t\\n\\t\\tCode du service national, non-instruct (2025-03-10)\\n\\t\\n\\nThe objective of this project is to provide researchers, professionals and law students with simplified, up-to-date access to all French legal texts, enriched with a wealth of data to facilitate their integration into Community and European projects.\\nNormally, the data is refreshed daily on all legal codes, and aims to simplify the production of training sets and labeling pipelines for the development of free, open-source language‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/louisbrulenaudet/code-service-national."},
  {"name":"code-tourisme","keyword":"french","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/louisbrulenaudet/code-tourisme","creator_name":"Louis Brul√© Naudet","creator_url":"https://huggingface.co/louisbrulenaudet","description":"\\n\\t\\n\\t\\t\\n\\t\\tCode du tourisme, non-instruct (2025-03-10)\\n\\t\\n\\nThe objective of this project is to provide researchers, professionals and law students with simplified, up-to-date access to all French legal texts, enriched with a wealth of data to facilitate their integration into Community and European projects.\\nNormally, the data is refreshed daily on all legal codes, and aims to simplify the production of training sets and labeling pipelines for the development of free, open-source language models‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/louisbrulenaudet/code-tourisme."},
  {"name":"code-travail-maritime","keyword":"french","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/louisbrulenaudet/code-travail-maritime","creator_name":"Louis Brul√© Naudet","creator_url":"https://huggingface.co/louisbrulenaudet","description":"\\n\\t\\n\\t\\t\\n\\t\\tCode du travail maritime, non-instruct (2025-03-10)\\n\\t\\n\\nThe objective of this project is to provide researchers, professionals and law students with simplified, up-to-date access to all French legal texts, enriched with a wealth of data to facilitate their integration into Community and European projects.\\nNormally, the data is refreshed daily on all legal codes, and aims to simplify the production of training sets and labeling pipelines for the development of free, open-source language‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/louisbrulenaudet/code-travail-maritime."},
  {"name":"code-voirie-routiere","keyword":"french","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/louisbrulenaudet/code-voirie-routiere","creator_name":"Louis Brul√© Naudet","creator_url":"https://huggingface.co/louisbrulenaudet","description":"\\n\\t\\n\\t\\t\\n\\t\\tCode de la voirie routi√®re, non-instruct (2025-03-10)\\n\\t\\n\\nThe objective of this project is to provide researchers, professionals and law students with simplified, up-to-date access to all French legal texts, enriched with a wealth of data to facilitate their integration into Community and European projects.\\nNormally, the data is refreshed daily on all legal codes, and aims to simplify the production of training sets and labeling pipelines for the development of free, open-source‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/louisbrulenaudet/code-voirie-routiere."},
  {"name":"Multilingual-BioASQ-6B","keyword":"french","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/HiTZ/Multilingual-BioASQ-6B","creator_name":"HiTZ zentroa","creator_url":"https://huggingface.co/HiTZ","description":"\\n    \\n    \\n    Mutilingual BioASQ-6B\\n    \\n\\n\\nWe translate the BioASQ-6B English Question Answering dataset to generate parallel French, Italian and Spanish versions using the NLLB200 3B parameter model. For more info read the original task description: [http://bioasq.org/participate/challenges_year_6](http://bioasq.org/participate/challenges_year_6)\\n\\nWe translate the body, snippets, ideal_answer and exact_answer fields. We have validated the quality of the ideal_answer field, however, the‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/HiTZ/Multilingual-BioASQ-6B."},
  {"name":"px-corpus","keyword":"french","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/bastiendechamps/px-corpus","creator_name":"Bastien Dechamps","creator_url":"https://huggingface.co/bastiendechamps","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tPxCorpus : A Spoken Drug Prescription Dataset in French\\n\\t\\n\\nPxCorpus is to the best of our knowledge, the first spoken medical drug prescriptions corpus to be distributed. \\nIt contains 4 hours of transcribed and annotated dialogues of drug prescriptions in \\nFrench acquired through an experiment with 55 participants experts and non-experts  in drug prescriptions.\\nThe automatic transcriptions were verified by human effort and aligned with \\nsemantic labels to allow training of NLP‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/bastiendechamps/px-corpus."},
  {"name":"NTREX","keyword":"french","license":"Creative Commons Attribution Share Alike 4.0 International","language":"en","url":"https://huggingface.co/datasets/davidstap/NTREX","creator_name":"David Stap","creator_url":"https://huggingface.co/davidstap","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nNTREX -- News Test References for MT Evaluation from English into a total of 128 target languages. See original GitHub repo for full details.\\nExample of loading:\\ndataset = load_dataset(\\\"davidstap/NTREX\\\", \\\"rus_Cyrl\\\", trust_remote_code=True)\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages\\n\\t\\n\\nThe following languages are available:\\n\\n\\t\\n\\t\\t\\nLanguage Code\\nLanguage Name\\n\\n\\n\\t\\t\\nafr_Latn\\nAfrikaans\\n\\n\\namh_Ethi\\nAmharic\\n\\n\\narb_Arab\\nArabic\\n\\n\\naze_Latn\\nAzerbaijani\\n\\n\\nbak_Cyrl\\nBashkir\\n\\n\\nbel_Cyrl\\nBelarusian‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/davidstap/NTREX."},
  {"name":"eurlex-multilingual","keyword":"french","license":"Creative Commons Attribution Share Alike 4.0 International","language":"en","url":"https://huggingface.co/datasets/mteb/eurlex-multilingual","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for \\\"eurlex-multilingual\\\"\\n\\t\\n\\nMore Information needed\\n"},
  {"name":"biblenlp-corpus-mmteb","keyword":"french","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/davidstap/biblenlp-corpus-mmteb","creator_name":"David Stap","creator_url":"https://huggingface.co/davidstap","description":"This dataset pre-computes all English-centric directions from bible-nlp/biblenlp-corpus, and as a result loading is significantly faster.\\nLoading example:\\n>>> from datasets import load_dataset\\n>>> dataset = load_dataset(\\\"davidstap/biblenlp-corpus-mmteb\\\", \\\"eng-arb\\\", trust_remote_code=True)\\n>>> dataset\\nDatasetDict({\\n    train: Dataset({\\n        features: ['eng', 'arb'],\\n        num_rows: 28723\\n    })\\n    validation: Dataset({\\n        features: ['eng', 'arb'],\\n        num_rows: 1578\\n    })‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/davidstap/biblenlp-corpus-mmteb."},
  {"name":"biblenlp-corpus-mmteb","keyword":"french","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/davidstap/biblenlp-corpus-mmteb","creator_name":"David Stap","creator_url":"https://huggingface.co/davidstap","description":"This dataset pre-computes all English-centric directions from bible-nlp/biblenlp-corpus, and as a result loading is significantly faster.\\nLoading example:\\n>>> from datasets import load_dataset\\n>>> dataset = load_dataset(\\\"davidstap/biblenlp-corpus-mmteb\\\", \\\"eng-arb\\\", trust_remote_code=True)\\n>>> dataset\\nDatasetDict({\\n    train: Dataset({\\n        features: ['eng', 'arb'],\\n        num_rows: 28723\\n    })\\n    validation: Dataset({\\n        features: ['eng', 'arb'],\\n        num_rows: 1578\\n    })‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/davidstap/biblenlp-corpus-mmteb."},
  {"name":"afrimgsm","keyword":"french","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/masakhane/afrimgsm","creator_name":"Masakhane NLP","creator_url":"https://huggingface.co/masakhane","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for afrimgsm\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nAFRIMGSM is an evaluation dataset comprising translations of a subset of the GSM8k dataset into 16 African languages. \\nIt includes test sets across all 18 languages, maintaining an English and French subsets from the original GSM8k dataset. \\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages\\n\\t\\n\\nThere are 18 languages available :\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Structure\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Instances\\n\\t\\n\\nThe examples look like this for English:\\nfrom datasets import‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/masakhane/afrimgsm."},
  {"name":"afrixnli","keyword":"french","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/masakhane/afrixnli","creator_name":"Masakhane NLP","creator_url":"https://huggingface.co/masakhane","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for afrixnli\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nAFRIXNLI is an evaluation dataset comprising translations of a subset of the XNLI dataset into 16 African languages. \\nIt includes both validation and test sets across all 18 languages, maintaining the English and French subsets from the original XNLI dataset. \\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages\\n\\t\\n\\nThere are 18 languages available :\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Structure\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Instances\\n\\t\\n\\nThe examples look like this for English:‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/masakhane/afrixnli."},
  {"name":"Maathis_Ohada_dataset","keyword":"french","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/uriel/Maathis_Ohada_dataset","creator_name":"NGUEFACK YEFOU URIEL","creator_url":"https://huggingface.co/uriel","description":"uriel/Maathis_Ohada_dataset dataset hosted on Hugging Face and contributed by the HF Datasets community"},
  {"name":"grad_school_math_instructions_fr_Mixtral","keyword":"french","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/AIffl/grad_school_math_instructions_fr_Mixtral","creator_name":"AIffl : AI For French Language","creator_url":"https://huggingface.co/AIffl","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for grad_school_math_instructions_fr_Mixtral\\n\\t\\n\\nThis dataset was made thanks to the instruction of the vigogne's dataset but the output were generated with Mixtral-8x7B-Instruct instead of GPT3.5 to make it open-source.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card Contact\\n\\t\\n\\nrobinjo\\n"},
  {"name":"Alpaca_french_mixtral","keyword":"french","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/AIffl/Alpaca_french_mixtral","creator_name":"AIffl : AI For French Language","creator_url":"https://huggingface.co/AIffl","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Alpaca_french_mixtral\\n\\t\\n\\nThis dataset was made by reusing the french alpaca instruction with Mixtral-8x7B-Instruct to make the output open-source.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card Contact\\n\\t\\n\\nrobinjo\\n"},
  {"name":"reddit-ask-v0","keyword":"french","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/pkseeg/reddit-ask-v0","creator_name":"Parker Seegmiller","creator_url":"https://huggingface.co/pkseeg","description":"\\n\\t\\n\\t\\t\\n\\t\\tReddit r/Ask{Topic} Questions and Answers\\n\\t\\n\\n903 questions and 15,711 answers gathered from Reddit's r/Ask{Topic} communities. Each question is paired with 3+ answers (top-level comments) and each answer is assigned a community perception score (upvote ration). Dataset statistics will be given below.\\n"},
  {"name":"MedExpQA","keyword":"french","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/HiTZ/MedExpQA","creator_name":"HiTZ zentroa","creator_url":"https://huggingface.co/HiTZ","description":"\\n    \\n    \\n    \\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tMexExpQA: Multilingual Benchmarking of Medical QA with reference gold explanations and Retrieval Augmented Generation (RAG)\\n\\t\\n\\nWe present a new multilingual parallel medical benchmark, MedExpQA, for the evaluation of LLMs on Medical Question Answering.\\nThis benchmark can be used for various NLP tasks including: Medical Question Answering or Explanation Generation.\\nAlthough the design of MedExpQA is independent of any specific dataset, for the first version of the‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/HiTZ/MedExpQA."},
  {"name":"simsamu","keyword":"french","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/diarizers-community/simsamu","creator_name":"diarizers-community","creator_url":"https://huggingface.co/diarizers-community","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for the Simsamu dataset\\n\\t\\n\\nThis repository contains recordings of simulated medical dispatch dialogs in the french language, annotated for diarization and transcription. It is published under the MIT license.\\nThese dialogs were recorded as part of the training of emergency medicine interns, which consisted in simulating a medical dispatch call where the interns took turns playing the caller and the regulating doctor.\\nEach situation was decided randomly in advance‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/diarizers-community/simsamu."},
  {"name":"alpaca-cleaned-fr","keyword":"french","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/TPM-28/alpaca-cleaned-fr","creator_name":"TPM-28","creator_url":"https://huggingface.co/TPM-28","description":"TPM-28/alpaca-cleaned-fr dataset hosted on Hugging Face and contributed by the HF Datasets community"},
  {"name":"swim-ir-cross-lingual","keyword":"french","license":"Creative Commons Attribution Share Alike 4.0 International","language":"en","url":"https://huggingface.co/datasets/nthakur/swim-ir-cross-lingual","creator_name":"Nandan Thakur","creator_url":"https://huggingface.co/nthakur","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for SWIM-IR (Cross-lingual)\\n\\t\\n\\n\\n\\n\\nThis is the cross-lingual subset of the SWIM-IR dataset, where the query generated is in the target language and the passage is in English.\\nThe SWIM-IR dataset is available as CC-BY-SA 4.0. 18 languages (including English) are available in the cross-lingual dataset.\\nFor full details of the dataset, please read our upcoming NAACL 2024 paper and check out our website.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tWhat is SWIM-IR?\\n\\t\\n\\nSWIM-IR dataset is a synthetic‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/nthakur/swim-ir-cross-lingual."},
  {"name":"eurobasket","keyword":"french","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/samirun974/eurobasket","creator_name":"Samuel","creator_url":"https://huggingface.co/samirun974","description":"samirun974/eurobasket dataset hosted on Hugging Face and contributed by the HF Datasets community"},
  {"name":"xsimplusplus","keyword":"french","license":"Creative Commons Zero v1.0 Universal","language":"en","url":"https://huggingface.co/datasets/jaygala24/xsimplusplus","creator_name":"Jay Gala","creator_url":"https://huggingface.co/jaygala24","description":"xSIM++ is an extension of xSIM. In comparison to xSIM, this evaluates using target-side data with additional synthetic, hard-to-distinguish examples. You can find more details about it in the publication: xSIM++: An Improved Proxy to Bitext Mining Performance for Low-Resource Languages.\\n"},
  {"name":"pioche","keyword":"french","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/lbl/pioche","creator_name":"Lucian BLETAN","creator_url":"https://huggingface.co/lbl","description":"lbl/pioche dataset hosted on Hugging Face and contributed by the HF Datasets community"},
  {"name":"LegalFrench","keyword":"french","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/wyzlee/LegalFrench","creator_name":"Olivier Podio","creator_url":"https://huggingface.co/wyzlee","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Dataset Name\\n\\t\\n\\n\\n\\nThis dataset card aims to be a base template for new datasets. It has been generated using this raw template.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Details\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\n\\n\\n\\n\\n\\nCurated by: [More Information Needed]\\nFunded by [optional]: [More Information Needed]\\nShared by [optional]: [More Information Needed]\\nLanguage(s) (NLP): [More Information Needed]\\nLicense: [More Information Needed]\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Sources [optional]‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/wyzlee/LegalFrench."},
  {"name":"Flans_Mod_Dataset_For_WW2_server","keyword":"french","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/Dabococo/Flans_Mod_Dataset_For_WW2_server","creator_name":"Henri d'Aboville","creator_url":"https://huggingface.co/Dabococo","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Dataset Name\\n\\t\\n\\n/!\\\\ Dataset tr√®s vague et con√ßu SPECIALEMENT pour le serveur Minecraft : https://openwar.fr    et    https://www.technicpack.net/modpack/openwar-ww2-edition.1971713\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Details\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Sources [optional]\\n\\t\\n\\n\\n\\n\\nRepository: [More Information Needed]\\nPaper [optional]: [More Information Needed]\\nDemo [optional]: [More Information Needed]\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tUses\\n\\t\\n\\n\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDirect Use\\n\\t\\n\\n\\n\\n[More Information Needed]‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Dabococo/Flans_Mod_Dataset_For_WW2_server."},
  {"name":"biblenlp-corpus-mmteb","keyword":"french","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/mteb/biblenlp-corpus-mmteb","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"This dataset pre-computes all English-centric directions from bible-nlp/biblenlp-corpus, and as a result loading is significantly faster.\\nLoading example:\\n>>> from datasets import load_dataset\\n>>> dataset = load_dataset(\\\"davidstap/biblenlp-corpus-mmteb\\\", \\\"eng-arb\\\", trust_remote_code=True)\\n>>> dataset\\nDatasetDict({\\n    train: Dataset({\\n        features: ['eng', 'arb'],\\n        num_rows: 28723\\n    })\\n    validation: Dataset({\\n        features: ['eng', 'arb'],\\n        num_rows: 1578\\n    })‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/biblenlp-corpus-mmteb."},
  {"name":"biblenlp-corpus-mmteb","keyword":"french","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/mteb/biblenlp-corpus-mmteb","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"This dataset pre-computes all English-centric directions from bible-nlp/biblenlp-corpus, and as a result loading is significantly faster.\\nLoading example:\\n>>> from datasets import load_dataset\\n>>> dataset = load_dataset(\\\"davidstap/biblenlp-corpus-mmteb\\\", \\\"eng-arb\\\", trust_remote_code=True)\\n>>> dataset\\nDatasetDict({\\n    train: Dataset({\\n        features: ['eng', 'arb'],\\n        num_rows: 28723\\n    })\\n    validation: Dataset({\\n        features: ['eng', 'arb'],\\n        num_rows: 1578\\n    })‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/biblenlp-corpus-mmteb."},
  {"name":"fr-summarizer-dataset","keyword":"french","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/Labagaite/fr-summarizer-dataset","creator_name":"Derue","creator_url":"https://huggingface.co/Labagaite","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\ttraining data\\n\\t\\n\\n\\nDataset : fr-summarizer-dataset\\nData-size : 7.65 MB\\ntrain : 1.97k rows\\nvalidation : 440 rows\\nroles : user , assistant\\nFormat chatml \\\"role\\\": \\\"role\\\", \\\"content\\\": \\\"content\\\", \\\"user\\\": \\\"user\\\", \\\"assistant\\\": \\\"assistant\\\"\\n*French audio podcast transcription*\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tProject details\\n\\t\\n\\n\\nFine-tuned on French audio podcast transcription data for summarization task. As a result, the model is able to summarize French audio podcast transcription data.\\nThe model will be used‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Labagaite/fr-summarizer-dataset."},
  {"name":"Accueil_UBS","keyword":"french","license":"Creative Commons Attribution Share Alike 4.0 International","language":"en","url":"https://huggingface.co/datasets/BrunoHays/Accueil_UBS","creator_name":"Bruno Hays","creator_url":"https://huggingface.co/BrunoHays","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tIntroduction\\n\\t\\n\\nCe jeu de donn√©es rassemble 339 extraits de conversation t√©l√©phoniques extraites du jeu de donn√©es Accueil_UBS.\\nL'objectif est de faciliter l'√©valuation des syst√®mes de reconnaissance automatique de la parole dans des situations r√©elles, sp√©cifiquement dans les centres d'appel et en fran√ßais.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tAccueil UBS\\n\\t\\n\\nLe corpus Accueil_UBS est un corpus pilote de dialogue oral homme-homme finalis√© correspondant √† une t√¢che d‚Äôaccueil t√©l√©phonique par le standard‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/BrunoHays/Accueil_UBS."},
  {"name":"chest_xray","keyword":"french","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/Az-r-ow/chest_xray","creator_name":"Antoine Azar","creator_url":"https://huggingface.co/Az-r-ow","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tZoidberg2.0\\n\\t\\n\\nThe data has been taken from kaggle\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tUsage\\n\\t\\n\\nInstall Hugging Face's datasets library\\npip install datasets\\n\\nLoad the dataset with the following lines \\nfrom datasets import load_dataset\\n\\ndataset = load_dataset(\\\"Az-r-ow/chest_xray\\\")\\n\\nFor more information on how to manipulate the data checkout the docs\\n"},
  {"name":"emotion-FR","keyword":"french","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/TPM-28/emotion-FR","creator_name":"TPM-28","creator_url":"https://huggingface.co/TPM-28","description":"TPM-28/emotion-FR dataset hosted on Hugging Face and contributed by the HF Datasets community"},
  {"name":"qonto-open-qa","keyword":"french","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/ThomasCdnns/qonto-open-qa","creator_name":"Thomas Chardonnens","creator_url":"https://huggingface.co/ThomasCdnns","description":"ThomasCdnns/qonto-open-qa dataset hosted on Hugging Face and contributed by the HF Datasets community"},
  {"name":"sib200","keyword":"french","license":"Creative Commons Attribution Share Alike 4.0 International","language":"en","url":"https://huggingface.co/datasets/mteb/sib200","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for SIB-200\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nSIB-200 is the largest publicly available topic classification dataset based on Flores-200 covering 205 languages and dialects.\\nThe train/validation/test sets are available for all the 205 languages.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSupported Tasks and Leaderboards\\n\\t\\n\\n\\ntopic classification: categorize wikipedia sentences into topics e.g science/technology, sports or politics.\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages\\n\\t\\n\\nThere are 205 languages available :‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/sib200."},
  {"name":"MAiDE-up","keyword":"french","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/MichiganNLP/MAiDE-up","creator_name":"LIT @ UMich","creator_url":"https://huggingface.co/MichiganNLP","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for MAiDE-up: Multilingual Deception Detection of GPT-generated Hotel Reviews\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nMultilingual Deception Detection of GPT-generated Hotel Reviews. We compare real hotel reviews from Booking with LLM-generated hotel reviews in 10 languages.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages\\n\\t\\n\\nThe text in the dataset is in 10 languages: Chinese, English, French, German, Italian, Romanian, Korean, Russian, Spanish, Turkish\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSupported Tasks and Leaderboards‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/MichiganNLP/MAiDE-up."},
  {"name":"spelling-correction-french-news","keyword":"french","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/fdemelo/spelling-correction-french-news","creator_name":"Fl√°vio Eler De Melo","creator_url":"https://huggingface.co/fdemelo","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSpelling correction dataset (French)\\n\\t\\n\\nThis dataset is generated by transforming/corrupting sentences of a French news corpus\\nprovided by the University of Leipzig.\\nThe following transformations are applied to words in the sentences:\\n\\nconcatenation of pairs of words\\nswapping of neighboring letters in words\\ninsertion\\ndeletion\\nreplacement (by neighboring characters in AZERTY keyboard)\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tGeneration\\n\\t\\n\\npip install happytransformer \\n./scripts/get_data.py -t news -y 2023 -s‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/fdemelo/spelling-correction-french-news."},
  {"name":"afrixnli-translate-test","keyword":"french","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/masakhane/afrixnli-translate-test","creator_name":"Masakhane NLP","creator_url":"https://huggingface.co/masakhane","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for afrixnli-translate-test\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nAFRIXNLI-TT is an evaluation dataset comprising translations of the AFRIXNLI dataset from 16 African languages and 1 high resource language into English using NLLB. \\nIt includes test sets across all 17 languages.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages\\n\\t\\n\\nThere are 17 languages available :\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Structure\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Instances\\n\\t\\n\\nThe examples look like this for English:\\nfrom datasets import load_dataset‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/masakhane/afrixnli-translate-test."},
  {"name":"afrimgsm-translate-test","keyword":"french","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/masakhane/afrimgsm-translate-test","creator_name":"Masakhane NLP","creator_url":"https://huggingface.co/masakhane","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for afrimgsm-translate-test\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nAFRIMGSM-TT is an evaluation dataset comprising translations of the GSM8k dataset from 16 African languages and 1 high resource language into English using NLLB. \\nIt includes test sets across all 17 languages. \\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages\\n\\t\\n\\nThere are 17 languages available :\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Structure\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Instances\\n\\t\\n\\nThe examples look like this for English:\\nfrom datasets import load_dataset‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/masakhane/afrimgsm-translate-test."},
  {"name":"SE-Chatting.en","keyword":"french","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/berwart/SE-Chatting.en","creator_name":"Berwart","creator_url":"https://huggingface.co/berwart","description":"\\n\\t\\n\\t\\t\\n\\t\\tSE.02\\n\\t\\n\\nDataset\\nHello, welcome to the official main dataset of SE.02 that's always getting updated, make sure to like to help us a lot.\\nthis dataset contains pretty much everything from math to isk what to put but pretty much anything you think an ai can say.\\nanyways this is our biggest dataset yet, and out first one that I don't even know how I managed to make this.\\nyou can use it to train your own ai if you want.\\n"},
  {"name":"NTREX","keyword":"french","license":"Creative Commons Attribution Share Alike 4.0 International","language":"en","url":"https://huggingface.co/datasets/mteb/NTREX","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nNTREX -- News Test References for MT Evaluation from English into a total of 128 target languages. See original GitHub repo for full details.\\nExample of loading:\\ndataset = load_dataset(\\\"davidstap/NTREX\\\", \\\"rus_Cyrl\\\", trust_remote_code=True)\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages\\n\\t\\n\\nThe following languages are available:\\n\\n\\t\\n\\t\\t\\nLanguage Code\\nLanguage Name\\n\\n\\n\\t\\t\\nafr_Latn\\nAfrikaans\\n\\n\\namh_Ethi\\nAmharic\\n\\n\\narb_Arab\\nArabic\\n\\n\\naze_Latn\\nAzerbaijani\\n\\n\\nbak_Cyrl\\nBashkir\\n\\n\\nbel_Cyrl\\nBelarusian‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/NTREX."},
  {"name":"multilingual-llava-bench-in-the-wild","keyword":"french","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/floschne/multilingual-llava-bench-in-the-wild","creator_name":"Flo Schneider","creator_url":"https://huggingface.co/floschne","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tMultilingual LLaVA Bench in the Wild\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tNote that this is a copy from https://huggingface.co/datasets/MBZUAI/multilingual-llava-bench-in-the-wild\\n\\t\\n\\nIt was created due to issues in the original repo. It also includes the image features and has a uniform and joined structure.\\nIf you use this dataset, please cite the original authors:\\n@article{PALO2024,\\n  title={Palo: A Large Multilingual Multimodal Language Model},\\n  author={Maaz, Muhammad and Rasheed, Hanoona and Shaker‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/floschne/multilingual-llava-bench-in-the-wild."},
  {"name":"ParaNames","keyword":"french","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/bltlab/ParaNames","creator_name":"Broadening Linguistic Technologies Lab (BLT Lab)","creator_url":"https://huggingface.co/bltlab","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Dataset Name\\n\\t\\n\\n\\n\\nThis dataset card aims to be a base template for new datasets. It has been generated using this raw template.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Details\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\n\\n\\n\\n\\n\\nCurated by: [More Information Needed]\\nFunded by [optional]: [More Information Needed]\\nShared by [optional]: [More Information Needed]\\nLanguage(s) (NLP): [More Information Needed]\\nLicense: [More Information Needed]\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Sources [optional]‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/bltlab/ParaNames."},
  {"name":"xm3600","keyword":"french","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/floschne/xm3600","creator_name":"Flo Schneider","creator_url":"https://huggingface.co/floschne","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tXM3600 - Crossmodal-3600\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tThis is a copy from https://google.github.io/crossmodal-3600/\\n\\t\\n\\nIf you use this dataset, please cite the original authors:\\n@inproceedings{ThapliyalCrossmodal2022,\\n  author = {Ashish Thapliyal and Jordi Pont-Tuset and Xi Chen and Radu Soricut},\\n  title = {{Crossmodal-3600: A Massively Multilingual Multimodal Evaluation Dataset}},\\n  booktitle = {EMNLP},\\n  year = {2022}\\n}\\n\\nIt also includes the image features as PIL Image and has a uniform and‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/floschne/xm3600."},
  {"name":"xm3600_1k","keyword":"french","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/floschne/xm3600_1k","creator_name":"Flo Schneider","creator_url":"https://huggingface.co/floschne","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tXM3600 - Crossmodal-3600 - 1K Split\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tThis is a copy from https://google.github.io/crossmodal-3600/\\n\\t\\n\\nIf you use this dataset, please cite the original authors:\\n@inproceedings{ThapliyalCrossmodal2022,\\n  author = {Ashish Thapliyal and Jordi Pont-Tuset and Xi Chen and Radu Soricut},\\n  title = {{Crossmodal-3600: A Massively Multilingual Multimodal Evaluation Dataset}},\\n  booktitle = {EMNLP},\\n  year = {2022}\\n}\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tThis is a 1K split of XM3600!\\n\\t\\n\\nFor this, we‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/floschne/xm3600_1k."},
  {"name":"OWAI_02","keyword":"french","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/Dabococo/OWAI_02","creator_name":"Henri d'Aboville","creator_url":"https://huggingface.co/Dabococo","description":"Dabococo/OWAI_02 dataset hosted on Hugging Face and contributed by the HF Datasets community"},
  {"name":"french_hh_rlhf","keyword":"french","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/AIffl/french_hh_rlhf","creator_name":"AIffl : AI For French Language","creator_url":"https://huggingface.co/AIffl","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for french_hh_rlhf\\n\\t\\n\\nThis dataset offers a french translation of the famous Anthropic/hh-rlhf dataset in order to improve the allignement work/research in the french NLP community.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card Contact\\n\\t\\n\\nntnq\\n"},
  {"name":"x-fact","keyword":"french","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/utahnlp/x-fact","creator_name":"NLP at University of Utah","creator_url":"https://huggingface.co/utahnlp","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for \\\"x-fact\\\"\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nX-FACT is a multilingual dataset for fact-checking with real world claims. The dataset contains short statments in 25 languages with top five evidence documents retrieved by performing google search with claim statements. The dataset contains two additional evaluation splits (in addition to a traditional test set): ood and zeroshot. ood measures out-of-domain generalization where while‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/utahnlp/x-fact."},
  {"name":"french_gutenberg","keyword":"french","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/rayml/french_gutenberg","creator_name":"Am√©lie Raymond","creator_url":"https://huggingface.co/rayml","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tGutenberg French Book Dataset\\n\\t\\n\\nThis dataset contains french books from Gutenberg's project collection with their related book categories. It‚Äôs designed for training AI models, research, or any other purpose related to natural language processing.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Details\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThe dataset contains this fields : \\n\\nauthor: author of the book\\ntitle: title of the book\\ncontent: book content in utf-8 encoding\\ncategory: list of book categories from‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/rayml/french_gutenberg."},
  {"name":"papyrus","keyword":"french","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/NCube/papyrus","creator_name":"Neural Network Nomads (We are GLOSS)","creator_url":"https://huggingface.co/NCube","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Papyrus\\n\\t\\n\\n\\nPaper: A new dataset for multilingual keyphrase generation\\nGithub: https://github.com/smolPixel/French-keyphrase-generation\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThe datasets are derived from Papyrus, a repository at Universit√© de Montr√©al containing various types of documents, mainly theses with abstracts in multiple languages, primarily French and English. The entries are provided in four different configurations based on‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/NCube/papyrus."},
  {"name":"hal_univcotedazur_shs_articles_2013-2023","keyword":"french","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/Geraldine/hal_univcotedazur_shs_articles_2013-2023","creator_name":"G√©raldine Geoffroy","creator_url":"https://huggingface.co/Geraldine","description":"The hal_data.csv dataset comes from a request on the HAL API (the French national open archive) limited to the UNIV-COTEDAZUR portal instance.\\nThe request collects the bibliographic records of the SHS articles with abstract published between 2013 and 2023\\nThe parameters passed in the url request are :\\n\\nq=docType_s:ART\\nfq=abstract_s:[%22%22%20TO%20*]\\nfq=domain_s:shs\\nfq=publicationDateY_i:[2013%20TO%202023]\\nfl=halId_s,doiId_s,uri_s,title_s,subTitle_s,authFullName_s,producedDate_s,journalTitle_s‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Geraldine/hal_univcotedazur_shs_articles_2013-2023."},
  {"name":"SCIDOCS-256-24-gpt-4o-2024-05-13-10630","keyword":"french","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/fine-tuned/SCIDOCS-256-24-gpt-4o-2024-05-13-10630","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSCIDOCS-256-24-gpt-4o-2024-05-13-10630 Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThe dataset \\\"service search for translation and editing\\\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tAssociated Model\\n\\t\\n\\nThis dataset was used to train the SCIDOCS-256-24-gpt-4o-2024-05-13-10630 model.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tHow to Use\\n\\t\\n\\nTo use this dataset for model training or evaluation, you can load it using the Hugging‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/SCIDOCS-256-24-gpt-4o-2024-05-13-10630."},
  {"name":"SCIDOCS-256-24-gpt-4o-2024-05-13-417900","keyword":"french","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/fine-tuned/SCIDOCS-256-24-gpt-4o-2024-05-13-417900","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSCIDOCS-256-24-gpt-4o-2024-05-13-417900 Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThe dataset \\\"service search for translation and editing\\\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tAssociated Model\\n\\t\\n\\nThis dataset was used to train the SCIDOCS-256-24-gpt-4o-2024-05-13-417900 model.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tHow to Use\\n\\t\\n\\nTo use this dataset for model training or evaluation, you can load it using the Hugging‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/SCIDOCS-256-24-gpt-4o-2024-05-13-417900."},
  {"name":"EmoTextToKids-sentences","keyword":"french","license":"Creative Commons Attribution Share Alike 4.0 International","language":"en","url":"https://huggingface.co/datasets/TextToKids/EmoTextToKids-sentences","creator_name":"ANR TextToKids project","creator_url":"https://huggingface.co/TextToKids","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for [Dataset Name]\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nEmoTextToKids provides sentences from written documents annotated in emotions.\\nEmotions are characterized by their emotional category (fear, anger, pride...) and their expression mode (labeled, behavioral, displayed or suggester).\\nAs opposed to usual datasets in emotion recognition, the documents are not conversational. They are newspapers, encyclopedias, novels, dedicated to children.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSupported Tasks and‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/TextToKids/EmoTextToKids-sentences."},
  {"name":"from-one-to-many-toxicity-mitigation","keyword":"french","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/luizapzbn/from-one-to-many-toxicity-mitigation","creator_name":"Luiza Pozzobon","creator_url":"https://huggingface.co/luizapzbn","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tFrom One to Many: Expanding the Scope of Toxicity Mitigation in Language Models\\n\\t\\n\\n[arxiv][code][data]\\nData accompanying the paper \\\"From One to Many: Expanding the Scope of Toxicity Mitigation in Language Models\\\" accepted to ACL Findings 2024.\\nAbstract: To date, toxicity mitigation in language models has almost entirely been focused on single-language settings. As language models embrace multilingual capabilities, it‚Äôs crucial our safety measures keep pace. Recognizing this‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/luizapzbn/from-one-to-many-toxicity-mitigation."},
  {"name":"French-Playing-Cards","keyword":"french","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/drFarid/French-Playing-Cards","creator_name":"Farid","creator_url":"https://huggingface.co/drFarid","description":"Upload the whole dataset.\\n"},
  {"name":"SCIDOCS-256-24-gpt-4o-2024-05-13-421451","keyword":"french","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/fine-tuned/SCIDOCS-256-24-gpt-4o-2024-05-13-421451","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSCIDOCS-256-24-gpt-4o-2024-05-13-421451 Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThe dataset \\\"service search for translation and editing\\\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tAssociated Model\\n\\t\\n\\nThis dataset was used to train the SCIDOCS-256-24-gpt-4o-2024-05-13-421451 model.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tHow to Use\\n\\t\\n\\nTo use this dataset for model training or evaluation, you can load it using the Hugging‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/SCIDOCS-256-24-gpt-4o-2024-05-13-421451."},
  {"name":"SCIDOCS-256-24-gpt-4o-2024-05-13-862053","keyword":"french","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/fine-tuned/SCIDOCS-256-24-gpt-4o-2024-05-13-862053","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSCIDOCS-256-24-gpt-4o-2024-05-13-862053 Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThe dataset \\\"service search for translation and editing\\\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tAssociated Model\\n\\t\\n\\nThis dataset was used to train the SCIDOCS-256-24-gpt-4o-2024-05-13-862053 model.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tHow to Use\\n\\t\\n\\nTo use this dataset for model training or evaluation, you can load it using the Hugging‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/SCIDOCS-256-24-gpt-4o-2024-05-13-862053."},
  {"name":"SCIDOCS-256-24-gpt-4o-2024-05-13-598568","keyword":"french","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/fine-tuned/SCIDOCS-256-24-gpt-4o-2024-05-13-598568","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSCIDOCS-256-24-gpt-4o-2024-05-13-598568 Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThe dataset \\\"service search for translation and editing\\\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tAssociated Model\\n\\t\\n\\nThis dataset was used to train the SCIDOCS-256-24-gpt-4o-2024-05-13-598568 model.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tHow to Use\\n\\t\\n\\nTo use this dataset for model training or evaluation, you can load it using the Hugging‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/SCIDOCS-256-24-gpt-4o-2024-05-13-598568."},
  {"name":"SCIDOCS-256-24-gpt-4o-2024-05-13-157892","keyword":"french","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/fine-tuned/SCIDOCS-256-24-gpt-4o-2024-05-13-157892","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSCIDOCS-256-24-gpt-4o-2024-05-13-157892 Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThe dataset \\\"service search for translation and editing\\\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tAssociated Model\\n\\t\\n\\nThis dataset was used to train the SCIDOCS-256-24-gpt-4o-2024-05-13-157892 model.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tHow to Use\\n\\t\\n\\nTo use this dataset for model training or evaluation, you can load it using the Hugging‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/SCIDOCS-256-24-gpt-4o-2024-05-13-157892."},
  {"name":"rendered_xnli","keyword":"french","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/baidu/rendered_xnli","creator_name":"ERNIE","creator_url":"https://huggingface.co/baidu","description":"   \\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for rendered XNLI\\n\\t\\n\\n\\nThis repository contains the rendered XNLI dataset evaluated in the paper Autoregressive Pre-Training on Pixels and Texts (EMNLP 2024). For detailed instructions on how to use the model, please visit our GitHub page.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tCitation\\n\\t\\n\\n@misc{chai2024autoregressivepretrainingpixelstexts,\\n  title = {Autoregressive Pre-Training on Pixels and Texts},\\n  author = {Chai, Yekun and Liu, Qingyi and Xiao, Jingwu and Wang, Shuohuan and Sun, Yu and‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/baidu/rendered_xnli."},
  {"name":"BAAI_bge-m3-27052024-w9t8-webapp","keyword":"french","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/fine-tuned/BAAI_bge-m3-27052024-w9t8-webapp","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tBAAI_bge-m3-27052024-w9t8-webapp Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThe dataset \\\"e-commerce search for intimate care products\\\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tAssociated Model\\n\\t\\n\\nThis dataset was used to train the BAAI_bge-m3-27052024-w9t8-webapp model.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tHow to Use\\n\\t\\n\\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/BAAI_bge-m3-27052024-w9t8-webapp."},
  {"name":"europa-random-split","keyword":"french","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/NCube/europa-random-split","creator_name":"Neural Network Nomads (We are GLOSS)","creator_url":"https://huggingface.co/NCube","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for EUROPA\\n\\t\\n\\nThis dataset card aims to be a base template for new datasets. It has been generated using this raw template.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Details\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nEUROPA is a dataset designed for training and evaluating multilingual keyphrase generation models in the legal domain. It consists of legal judgments from the Court of Justice of the European Union (EU) and includes instances in all 24 official EU languages.\\nKey Features:‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/NCube/europa-random-split."},
  {"name":"chessGPT","keyword":"french","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/Zual/chessGPT","creator_name":"Luc Pommeret","creator_url":"https://huggingface.co/Zual","description":"Here is some datasets that contains \\\"noisy\\\" chess games. We define the noise as a probability of playing a random (yet legal) chess move. For example, a chess game with 5% of noise is a chess game between Stockfish and himself when each move have 5% of chance to be random.\\n"},
  {"name":"ArguAna-512-192-gpt-4o-2024-05-13-140539","keyword":"french","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/fine-tuned/ArguAna-512-192-gpt-4o-2024-05-13-140539","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tArguAna-512-192-gpt-4o-2024-05-13-140539 Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThe dataset \\\"debate system\\\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tAssociated Model\\n\\t\\n\\nThis dataset was used to train the ArguAna-512-192-gpt-4o-2024-05-13-140539 model.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tHow to Use\\n\\t\\n\\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets library as‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/ArguAna-512-192-gpt-4o-2024-05-13-140539."},
  {"name":"ArguAna-512-192-gpt-4o-2024-05-13-2499","keyword":"french","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/fine-tuned/ArguAna-512-192-gpt-4o-2024-05-13-2499","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tArguAna-512-192-gpt-4o-2024-05-13-2499 Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThe dataset \\\"debate platform\\\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tAssociated Model\\n\\t\\n\\nThis dataset was used to train the ArguAna-512-192-gpt-4o-2024-05-13-2499 model.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tHow to Use\\n\\t\\n\\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets library as‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/ArguAna-512-192-gpt-4o-2024-05-13-2499."},
  {"name":"paracrawl_context","keyword":"french","license":"Creative Commons Zero v1.0 Universal","language":"en","url":"https://huggingface.co/datasets/Proyag/paracrawl_context","creator_name":"Proyag Pal","creator_url":"https://huggingface.co/Proyag","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for ParaCrawl_Context\\n\\t\\n\\n\\n\\nThis is a dataset for document-level machine translation introduced in the ACL 2024 paper Document-Level Machine Translation with Large-Scale Public Parallel Data. It is a dataset consisting of parallel sentence pairs from the ParaCrawl dataset along with corresponding preceding context extracted from the webpages the sentences were crawled from.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Details\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\n\\nThis dataset adds‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Proyag/paracrawl_context."},
  {"name":"MultiPICo","keyword":"french","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/Multilingual-Perspectivist-NLU/MultiPICo","creator_name":"MultilingualPerspectivistNLU","creator_url":"https://huggingface.co/Multilingual-Perspectivist-NLU","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nMultiPICo (Multilingual Perspectivist Irony Corpus) is a disaggregated multilingual corpus for irony detection, containing 18,778 pairs of short conversations (post-reply) from Twitter (8,956) and Reddit (9,822), along with the demographic information of each annotator (age, nationality, gender, and so on). \\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSupported Tasks and Leaderboards\\n\\t\\n\\nIrony classification task using soft labels (i.e., distribution of annotations) or hard labels (i.e.‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Multilingual-Perspectivist-NLU/MultiPICo."},
  {"name":"europa","keyword":"french","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/NCube/europa","creator_name":"Neural Network Nomads (We are GLOSS)","creator_url":"https://huggingface.co/NCube","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for EUROPA\\n\\t\\n\\nThis dataset card aims to be a base template for new datasets. It has been generated using this raw template.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Details\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nEUROPA is a dataset designed for training and evaluating multilingual keyphrase generation models in the legal domain. It consists of legal judgments from the Court of Justice of the European Union (EU) and includes instances in all 24 official EU languages.\\nKey Features:‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/NCube/europa."},
  {"name":"tabfquad_test_subsampled","keyword":"french","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/vidore/tabfquad_test_subsampled","creator_name":"ILLUIN Vidore","creator_url":"https://huggingface.co/vidore","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nTabFQuAD (Table French Question Answering Dataset) is designed to evaluate TableQA models in realistic industry settings. Using a vision language model (GPT4V), we create additional queries to augment the existing human-annotated ones.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Curation\\n\\t\\n\\nTo ensure homogeneity across our benchmarked datasets, we subsampled the original test set to 280 pairs, leaving the rest for training and renaming the different columns.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLoad the‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/vidore/tabfquad_test_subsampled."},
  {"name":"shiftproject_test","keyword":"french","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/vidore/shiftproject_test","creator_name":"ILLUIN Vidore","creator_url":"https://huggingface.co/vidore","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThis dataset is part of a topic-specific retrieval benchmark spanning multiple domains, which evaluates retrieval in more realistic industrial applications. \\nIt includes French documents from the Shift Project about the environment. \\nHaving a dataset in French allows ViDoRe to evaluate the multilingual ability of a retrieval model.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Collection\\n\\t\\n\\nWe collected 5 large documents from the Shift Project reports, totalling 1,000 document pages per‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/vidore/shiftproject_test."},
  {"name":"BAAI_bge-large-en-v1_5-05062024-vbal-webapp","keyword":"french","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/fine-tuned/BAAI_bge-large-en-v1_5-05062024-vbal-webapp","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tBAAI_bge-large-en-v1_5-05062024-vbal-webapp Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThe dataset \\\"general domain\\\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tAssociated Model\\n\\t\\n\\nThis dataset was used to train the BAAI_bge-large-en-v1_5-05062024-vbal-webapp model.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tHow to Use\\n\\t\\n\\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/BAAI_bge-large-en-v1_5-05062024-vbal-webapp."},
  {"name":"deepspeed-from-new-new-docker","keyword":"french","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/fine-tuned/deepspeed-from-new-new-docker","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tdeepspeed-from-new-new-docker Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThe dataset \\\"information retrieval system\\\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tAssociated Model\\n\\t\\n\\nThis dataset was used to train the deepspeed-from-new-new-docker model.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tHow to Use\\n\\t\\n\\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets library as follows:‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/deepspeed-from-new-new-docker."},
  {"name":"M3GIA","keyword":"french","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/Songweii/M3GIA","creator_name":"Wei Song","creator_url":"https://huggingface.co/Songweii","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tM3GIA: A Cognition Inspired Multilingual and Multimodal General Intelligence Ability\\n\\t\\n\\n[üåê Homepage] | ü§ó Dataset | ü§ó Paper | üìñ arXiv | üíª GitHub\\nThe evaluation code can be found in üíª GitHub.\\n[Abstract]\\nAs recent multi-modality large language models (MLLMs) have shown formidable proficiency on various complex tasks, there has been increasing attention on debating whether these models could eventually mirror human intelligence. However, existing benchmarks mainly focus on‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Songweii/M3GIA."},
  {"name":"french_MixEval","keyword":"french","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/AIffl/french_MixEval","creator_name":"AIffl : AI For French Language","creator_url":"https://huggingface.co/AIffl","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tMixEval French Dataset\\n\\t\\n\\nThis dataset is the translation in french of MixEval dataset from MixEval https://huggingface.co/datasets/MixEval/MixEval\\nIt‚Äôs designed to evaluate model on a french dataset. Duplicates from the original dataset were removed & unique answers were added.\\nCheck MixEval's datacard for more information.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Details\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThe dataset contains this fields : \\n\\nproblem_type: multiple_choice\\n\\nprompt_fr: prompt in‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/AIffl/french_MixEval."},
  {"name":"wolof-french-alxuraan","keyword":"french","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/cibfaye/wolof-french-alxuraan","creator_name":"Cheikh Faye","creator_url":"https://huggingface.co/cibfaye","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThis dataset contains translations of the Quran in two languages: Wolof and French. Each entry includes the sourate number, the verse number, and the translations in both languages.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tTranslation Information\\n\\t\\n\\n\\nWolof Translation: The translation of the Quran in Wolof was done by S√´ri√± Seexunaa L√≥o Ngaabu.\\nWritten By: The text was written by Allaaji Mamadu Ngeer and G√≥orgi Jaw.\\nUpdated By: The translation was updated by S√´ri√± Muntaqaa Mb√†kke (son of‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/cibfaye/wolof-french-alxuraan."},
  {"name":"Chatgpt","keyword":"french","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/RajChat/Chatgpt","creator_name":"Rajdeep Chatterjee ","creator_url":"https://huggingface.co/RajChat","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tOpenAssistant Conversations Dataset (OASST1)\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nIn an effort to democratize research on large-scale alignment, we release OpenAssistant \\nConversations (OASST1), a human-generated, human-annotated assistant-style conversation \\ncorpus consisting of 161,443 messages in 35 different languages, annotated with 461,292 \\nquality ratings, resulting in over 10,000 fully annotated conversation trees. The corpus \\nis a product of a worldwide crowd-sourcing effort‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/RajChat/Chatgpt."},
  {"name":"ProgressGym-HistText","keyword":"french","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/PKU-Alignment/ProgressGym-HistText","creator_name":"PKU-Alignment","creator_url":"https://huggingface.co/PKU-Alignment","description":"*Huggingface dataset preview for 19th, 20th, and 21st centuries is not available due to lack of support for array types. Instead, consider downloading those files for manual inspection, or see the Data Samples section below for more examples.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tProgressGym-HistText\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tOverview\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tThe ProgressGym Framework\\n\\t\\n\\n\\nProgressGym-HistText is part of the ProgressGym framework for research and experimentation on progress alignment - the emulation of moral progress in AI‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/PKU-Alignment/ProgressGym-HistText."},
  {"name":"synthetic_multilingual_llm_prompts","keyword":"french","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/gretelai/synthetic_multilingual_llm_prompts","creator_name":"Gretel.ai","creator_url":"https://huggingface.co/gretelai","description":"\\n  \\n  Image generated by DALL-E. See prompt for more details\\n\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tüìùüåê Synthetic Multilingual LLM Prompts\\n\\t\\n\\nWelcome to the \\\"Synthetic Multilingual LLM Prompts\\\" dataset! This comprehensive collection features 1,250 synthetic LLM prompts generated using Gretel Navigator, available in seven different languages. To ensure accuracy and diversity in prompts, and translation quality and consistency across the different languages, we employed Gretel Navigator both as a generation tool and as‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/gretelai/synthetic_multilingual_llm_prompts."},
  {"name":"FairytaleQA-translated-french","keyword":"french","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/benjleite/FairytaleQA-translated-french","creator_name":"Bernardo Leite","creator_url":"https://huggingface.co/benjleite","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for FairytaleQA-translated-ptBR\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThis repository contains the French machine-translated version of the original English FairytaleQA dataset (https://huggingface.co/datasets/WorkInTheDark/FairytaleQA). FairytaleQA is an open-source dataset designed to enhance comprehension of narratives, aimed at students from kindergarten to eighth grade. The dataset is meticulously annotated by education experts following an evidence-based theoretical‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/benjleite/FairytaleQA-translated-french."},
  {"name":"wmt14_injected_synthetic_dyslexia","keyword":"french","license":"Creative Commons Attribution Share Alike 4.0 International","language":"en","url":"https://huggingface.co/datasets/gpric024/wmt14_injected_synthetic_dyslexia","creator_name":"Greg Price","creator_url":"https://huggingface.co/gpric024","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThe WMT14 injected synthetic dyslexia dataset is a modified version of the WMT14 English test set. This dataset was created to test the capabilities of SOTA machine translations models on dyslexic style text. This research was supported by AImpower.org.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tHow the data is structured\\n\\t\\n\\n\\nIn \\\"Data/French_translated_data\\\", each file within the dataset consists of a ‚Äú.txt‚Äù or ‚Äú.docx‚Äù file containing the translated sentences from AWS, Google, Azure and‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/gpric024/wmt14_injected_synthetic_dyslexia."},
  {"name":"SN-echoes","keyword":"french","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/SoccerNet/SN-echoes","creator_name":"SoccerNet","creator_url":"https://huggingface.co/SoccerNet","description":"[Paper] | [GitHub]\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Card for SoccerNet-Echoes\\n\\t\\n\\nThis dataset card aims to provide comprehensive details for the SoccerNet-Echoes dataset, an audio commentary dataset for soccer games.\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Details\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\nSoccerNet-Echoes is an audio commentary dataset for soccer games, curated by SimulaMet under the AI-Storyteller project. It is funded by the Research Council of Norway (project number 346671) and shared by the SoccerNet team. The dataset‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/SoccerNet/SN-echoes."},
  {"name":"hatvp_declaration_content_archive","keyword":"french","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/the-french-artist/hatvp_declaration_content_archive","creator_name":"Louis Paulet","creator_url":"https://huggingface.co/the-french-artist","description":"the-french-artist/hatvp_declaration_content_archive dataset hosted on Hugging Face and contributed by the HF Datasets community"},
  {"name":"walt","keyword":"french","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/canTooDdev/walt","creator_name":"Boris Marion-Dorier","creator_url":"https://huggingface.co/canTooDdev","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Alpaca-Cleaned\\n\\t\\n\\n\\nRepository: https://github.com/gururise/AlpacaDataCleaned\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThis is a cleaned version of the original Alpaca Dataset released by Stanford. The following issues have been identified in the original release and fixed in this dataset:\\n\\nHallucinations: Many instructions in the original dataset had instructions referencing data on the internet, which just caused GPT3 to hallucinate an answer.\\n\\n\\\"instruction\\\":\\\"Summarize‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/canTooDdev/walt."},
  {"name":"MELA","keyword":"french","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/Geralt-Targaryen/MELA","creator_name":"Ziyin Zhang","creator_url":"https://huggingface.co/Geralt-Targaryen","description":"See the GitHub repo for details.\\n"},
  {"name":"doc-vqa","keyword":"french","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/cmarkea/doc-vqa","creator_name":"Credit Mutuel Arkea","creator_url":"https://huggingface.co/cmarkea","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset description\\n\\t\\n\\nThe doc-vqa Dataset integrates images from the Infographic_vqa dataset sourced from HuggingFaceM4 The Cauldron\\n dataset, as well as images from the dataset AFTDB (Arxiv Figure Table Database) curated by cmarkea. \\n This dataset consists of pairs of images and corresponding text, with each image linked to an average of five questions and answers available in both English and French. \\n These questions and answers were generated using Gemini 1.5 Pro, thereby‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/cmarkea/doc-vqa."},
  {"name":"bitext_sib200_miners","keyword":"french","license":"Creative Commons Attribution Share Alike 4.0 International","language":"en","url":"https://huggingface.co/datasets/gentaiscool/bitext_sib200_miners","creator_name":"Genta Indra Winata","creator_url":"https://huggingface.co/gentaiscool","description":"gentaiscool/bitext_sib200_miners dataset hosted on Hugging Face and contributed by the HF Datasets community"},
  {"name":"vibravox_enhanced_by_EBEN","keyword":"french","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/Cnam-LMSSC/vibravox_enhanced_by_EBEN","creator_name":"Laboratoire de M√©canique des Structures et des Syst√®mes Coupl√©s","creator_url":"https://huggingface.co/Cnam-LMSSC","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card\\n\\t\\n\\n\\n  \\n\\n\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDescription\\n\\t\\n\\nThis dataset features a speech-enhanced version of the test split from the speech_clean subset of the Vibravox Dataset.\\nIt is not intended for training.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tEnhancement procedure\\n\\t\\n\\nThe Bandwidth extension task has been individually achieved for each sensor using configurable EBEN (arXiv link) models available at https://huggingface.co/Cnam-LMSSC/vibravox_EBEN_models.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tRessources\\n\\t\\n\\nResults for speech-to-phoneme‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Cnam-LMSSC/vibravox_enhanced_by_EBEN."},
  {"name":"ultrafrench","keyword":"french","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/AIffl/ultrafrench","creator_name":"AIffl : AI For French Language","creator_url":"https://huggingface.co/AIffl","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for ultrafrench\\n\\t\\n\\nThis dataset offers a french translation of the small sample of instructions from HuggingFaceH4/ultrachat_200k translated in french. The generations were made with Mistral large to make the output open-source\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card Contact\\n\\t\\n\\nntnq\\n"},
  {"name":"fleurs_clean","keyword":"french","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/Helloworld668/fleurs_clean","creator_name":"zhide Tang","creator_url":"https://huggingface.co/Helloworld668","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tFLEURS\\n\\t\\n\\nFleurs is the speech version of the FLoRes machine translation benchmark. \\nWe use 2009 n-way parallel sentences from the FLoRes dev and devtest publicly available sets, in 102 languages. \\nTraining sets have around 10 hours of supervision. Speakers of the train sets are different than speakers from the dev/test sets. Multilingual fine-tuning is\\nused and ‚Äùunit error rate‚Äù (characters, signs) of all languages is averaged. Languages and results are also grouped into seven‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Helloworld668/fleurs_clean."},
  {"name":"ECN-QA","keyword":"french","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/raidium/ECN-QA","creator_name":"Raidium","creator_url":"https://huggingface.co/raidium","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tModel Card for Raidium ECN-QA\\n\\t\\n\\nThe dataset is introduced in the paper \\\"Efficient Medical Question Answering with Knowledge-Augmented Question Generation\\\".\\nPaper: https://arxiv.org/abs/2405.14654\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Details\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThe dataset contains medical questions of different types. It was built from passed ECN exams (french medical examination) and questions created by FreeCN.\\nThe questions can be:\\n\\nIQ (individual question) containing a‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/raidium/ECN-QA."},
  {"name":"open-identities","keyword":"french","license":"Creative Commons Attribution Share Alike 4.0 International","language":"en","url":"https://huggingface.co/datasets/jbilcke-hf/open-identities","creator_name":"Julian Bilcke","creator_url":"https://huggingface.co/jbilcke-hf","description":"A dataset of creative common identities (faces, voices, driving videos) you can use as actors in your Clapper project.\\nThere are only a couple for now, but the goal is to reach at least 100-200 unique voices to be confortable with AI movie projects, so contributions are extremely welcome.\\n"},
  {"name":"xP3x-Kongo","keyword":"french","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/Svngoku/xP3x-Kongo","creator_name":"NIONGOLO Chrys F√©-Marty","creator_url":"https://huggingface.co/Svngoku","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for xP3x Kikongo Focus\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\n\\nxP3x (Crosslingual Public Pool of Prompts eXtended) is a collection of prompts & datasets across 277 languages & 16 NLP tasks. It contains all of xP3 + much more! It is used for training future contenders of mT0 & BLOOMZ at project Aya @C4AI üß°\\n\\n\\nCreation: The dataset can be recreated using instructions available here together with the file in this repository named xp3x_create.py. We provide this version to save‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Svngoku/xP3x-Kongo."},
  {"name":"laws","keyword":"french","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/HFforLegal/laws","creator_name":"Hugging Face for Legal","creator_url":"https://huggingface.co/HFforLegal","description":"\\n  \\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tThe Laws, centralizing legal texts for better use, a community Dataset.\\n\\t\\n\\nThe Laws Dataset is a comprehensive collection of legal texts from various countries, centralized in a common format. This dataset aims to improve the development of legal AI models by providing a standardized, easily accessible corpus of global legal documents.\\n\\n    Join us in our mission to make AI more accessible and understandable for the legal world, ensuring that the power of language models can be‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/HFforLegal/laws."},
  {"name":"AyaRedTeaming","keyword":"french","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/walledai/AyaRedTeaming","creator_name":"Walled AI","creator_url":"https://huggingface.co/walledai","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Aya Red-teaming\\n\\t\\n\\n\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Details\\n\\t\\n\\nThe Aya Red-teaming dataset is a human-annotated multilingual red-teaming dataset consisting of harmful prompts in 8 languages across 9 different categories of harm with explicit labels for \\\"global\\\" and \\\"local\\\" harm.\\n\\n\\n\\n\\n\\n\\nCurated by: Professional compensated annotators\\nLanguages: Arabic, English, Filipino, French, Hindi, Russian, Serbian and Spanish\\nLicense: Apache 2.0\\nPaper: arxiv link\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tHarm‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/walledai/AyaRedTeaming."},
  {"name":"replique-a","keyword":"french","license":"Creative Commons Zero v1.0 Universal","language":"en","url":"https://huggingface.co/datasets/opsci/replique-a","creator_name":"opsci","creator_url":"https://huggingface.co/opsci","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDescription\\n\\t\\n\\nThe JSONL file generated by the script below contains detailed information about a corpus of public domain films, including their subtitles in multiple languages. Here is a detailed description of its structure:\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tJSONL file structure\\n\\t\\n\\n\\nIMDB: Unique identifier for the movie in the IMDb database.\\nprimary_title: Primary title of the movie.\\noriginal_title:  Original title of the movie.\\nfrench: \\nfilepath: Relative path to the French subtitles file.\\nsubtitles:‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/opsci/replique-a."},
  {"name":"Multilingual-Benchmark","keyword":"french","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/TaiMingLu/Multilingual-Benchmark","creator_name":"TaiMing","creator_url":"https://huggingface.co/TaiMingLu","description":"These are the GSM8K and ARC dataset translated by Google Translate. \\nBibTex\\n@misc{lu2024languagecountslearnunlearn,\\n      title={Every Language Counts: Learn and Unlearn in Multilingual LLMs}, \\n      author={Taiming Lu and Philipp Koehn},\\n      year={2024},\\n      eprint={2406.13748},\\n      archivePrefix={arXiv},\\n      primaryClass={cs.CL},\\n      url={https://arxiv.org/abs/2406.13748}, \\n}\\n\\n"},
  {"name":"modern","keyword":"french","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/CATMuS/modern","creator_name":"CATMuS: Consistent Approach to Transcribing ManuScripts","creator_url":"https://huggingface.co/CATMuS","description":"\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for CATMuS Modern and Contemporary (McCATMuS)\\n\\t\\n\\nJoin our Discord to ask questions about the dataset: \\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Details\\n\\t\\n\\nHandwritten Text Recognition (HTR) has emerged as a crucial tool for converting manuscripts images into machine-readable formats, enabling researchers and scholars to analyze vast collections efficiently. Despite significant technological progress, establishing consistent ground truth across projects for HTR tasks, particularly for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/CATMuS/modern."},
  {"name":"HALvest-Geometric","keyword":"french","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/almanach/HALvest-Geometric","creator_name":"ALMAnaCH (Inria)","creator_url":"https://huggingface.co/almanach","description":"\\n     HALvest-Geometric \\n     Citation Network of Open Scientific Papers Harvested from HAL \\n\\n\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Summary\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\toverview:\\n\\t\\n\\nFrench and English fulltexts from open papers found on Hyper Articles en Ligne (HAL) and its citation network.\\nYou can download the dataset using Hugging Face datasets:\\nfrom datasets import load_dataset\\n\\nds = load_dataset(\\\"Madjakul/HALvest-Geometric\\\", \\\"en\\\")\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDetails\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tNodes\\n\\t\\n\\n\\nPapers: 18,662,037\\nAuthors: 238,397\\nAffiliations:‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/almanach/HALvest-Geometric."},
  {"name":"Sentiment_lexicons","keyword":"french","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/mahmed31/Sentiment_lexicons","creator_name":"Muhammad Ahmed","creator_url":"https://huggingface.co/mahmed31","description":"mahmed31/Sentiment_lexicons dataset hosted on Hugging Face and contributed by the HF Datasets community"},
  {"name":"darija_to_french_speech_to_text","keyword":"french","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/adiren7/darija_to_french_speech_to_text","creator_name":"Adil Oubaibou","creator_url":"https://huggingface.co/adiren7","description":"adiren7/darija_to_french_speech_to_text dataset hosted on Hugging Face and contributed by the HF Datasets community"},
  {"name":"chatverse","keyword":"french","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/cmarkea/chatverse","creator_name":"Credit Mutuel Arkea","creator_url":"https://huggingface.co/cmarkea","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tchatverse\\n\\t\\n\\nDataset Summary: \\nThe \\\"chatverse\\\" dataset consists of synthetically generated chats facilitated by various chatbots. The dataset simulates conversations between a persona generator, a conversation initiator, a user, and an assistant. The purpose of this dataset is to explore interaction dynamics in a controlled, multi-theme environment. The dataset includes interactions across 130 randomly chosen themes, each forming a unique persona that drives the conversation.‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/cmarkea/chatverse."},
  {"name":"genrescoh","keyword":"french","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/Johndfm/genrescoh","creator_name":"John Mendon√ßa","creator_url":"https://huggingface.co/Johndfm","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for GenResCoh\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nGenResCoh is a collection of positive and negative responses focused on coherence. It is generated using GPT-3.5-Turbo and GPT-4, and contains over 130k responses in different languages (English, French, German, Italian, and Chinese), together with their corresponding explanations (in English).\\nGenResCoh was used to train the ECoh family of models.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages\\n\\t\\n\\n\\nEnglish\\nGerman\\nItalian\\nFrench\\nChinese‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Johndfm/genrescoh."},
  {"name":"afrimgsm","keyword":"french","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/yuntian-deng/afrimgsm","creator_name":"Yuntian Deng","creator_url":"https://huggingface.co/yuntian-deng","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for afrimgsm\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nAFRIMGSM is an evaluation dataset comprising translations of a subset of the GSM8k dataset into 16 African languages. \\nIt includes test sets across all 18 languages, maintaining an English and French subsets from the original GSM8k dataset. \\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages\\n\\t\\n\\nThere are 18 languages available :\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Structure\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Instances\\n\\t\\n\\nThe examples look like this for English:\\nfrom datasets import‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/yuntian-deng/afrimgsm."},
  {"name":"librivox-tracks","keyword":"french","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/xacer/librivox-tracks","creator_name":"xacer","creator_url":"https://huggingface.co/xacer","description":"A dataset of all audio files uploaded to LibriVox before 26th September 2023.\\nForked from https://huggingface.co/datasets/pykeio/librivox-tracks\\nChanges:\\n\\nUsed archive.org metadata API to annotate rows with \\\"duration\\\" column\\n\\n"},
  {"name":"TextBooksPersonaHub","keyword":"french","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/drodin/TextBooksPersonaHub","creator_name":"nacer","creator_url":"https://huggingface.co/drodin","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tTextBooksPersonaHub\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tOverview\\n\\t\\n\\nThe TextBooksPersonaHub dataset is an extension of the proj-persona/PersonaHub dataset, created using the technique described in the paper Textbooks Are All You Need II. This dataset contains synthetically generated \\\"textbook-like\\\" passages tailored in french to specific personas, aimed at enhancing language model training with high-quality and diverse content.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Creation\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSource Data\\n\\t\\n\\nThe original‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/drodin/TextBooksPersonaHub."},
  {"name":"belgian-journal","keyword":"french","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/guust-franssens/belgian-journal","creator_name":"Guust Franssens","creator_url":"https://huggingface.co/guust-franssens","description":"\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\n\\n\\nDataset contains the metadata + the text of company bylaws publications of Belgian companies on the Belgian Journal (Moniteur Belge/Belgisch Staatstblad).\\nThis data was collected by webscraping the Belgian Journal, for more info see: https://github.com/Guust-Franssens/belgian-journal.\\n\\nLanguage(s) (NLP): French, Dutch and a small subset German (official languages of Belgium.)\\nLicense: apache-2.0\\n\\n"},
  {"name":"hexabot-smalltalk","keyword":"french","license":"Creative Commons Zero v1.0 Universal","language":"en","url":"https://huggingface.co/datasets/Hexastack/hexabot-smalltalk","creator_name":"Hexastack","creator_url":"https://huggingface.co/Hexastack","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tHexabot Small Talk Dataset\\n\\t\\n\\nThe small talk is used to give the user a casual conversation flow with the chatbot.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tColumn Details\\n\\t\\n\\nUtterances - Sentence\\nIntent - Class labels (84 unique labels)\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tContext\\n\\t\\n\\nClassifying the Intent(\\\"Smalltalk appraisal thank you\\\",‚Ä¶) by given input Utterances(\\\"again i really appreciate you\\\",‚Ä¶‚Ä¶)\\nOriginal dataset is : https://www.kaggle.com/datasets/salmanfaroz/small-talk-intent-classification-data\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tlicense: cc0-1.0\\n\\t\\n\\n"},
  {"name":"EC-Guide","keyword":"french","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/AiMijie/EC-Guide","creator_name":"AiMijie","creator_url":"https://huggingface.co/AiMijie","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tThis repo is only used for dataset viewer. Please download from here.\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tAmazon KDDCup 2024 Team ZJU-AI4H‚Äôs Solution and Dataset (Track 2 Top 2; Track 5 Top 5)\\n\\t\\n\\nThe Amazon KDD Cup‚Äô24 competition presents a unique challenge by focusing on the application of LLMs in E-commerce across multiple tasks. Our solution for addressing Tracks 2 and 5 involves a comprehensive pipeline encompassing dataset construction, instruction tuning, post-training quantization, and inference‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/AiMijie/EC-Guide."},
  {"name":"Platon","keyword":"french","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/XenocodeRCE/Platon","creator_name":"John Doe","creator_url":"https://huggingface.co/XenocodeRCE","description":"XenocodeRCE/Platon dataset hosted on Hugging Face and contributed by the HF Datasets community"},
  {"name":"fact-check-bureau","keyword":"french","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/NaughtyConstrictor/fact-check-bureau","creator_name":"Younes","creator_url":"https://huggingface.co/NaughtyConstrictor","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tFact-Check Retrieval Dataset\\n\\t\\n\\nThis dataset is designed to support the development and evaluation of fact-check retrieval pipelines. It is structured to work with FactCheckBureau, a tool for designing and evaluating fact-check retrieval pipelines. The dataset comprises a list of claims, fact-check articles, and precomputed embeddings for English and French fact-checks.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Structure\\n\\t\\n\\nThe dataset consists of the following files and directories:\\n\\narticles.csv:‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/NaughtyConstrictor/fact-check-bureau."},
  {"name":"TextBooksPersonaHub-FR","keyword":"french","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/drodin/TextBooksPersonaHub-FR","creator_name":"nacer","creator_url":"https://huggingface.co/drodin","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tTextBooksPersonaHub\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tOverview\\n\\t\\n\\nThe TextBooksPersonaHub dataset is an extension of the proj-persona/PersonaHub dataset, created using the technique described in the paper Textbooks Are All You Need II. This dataset contains synthetically generated \\\"textbook-like\\\" passages tailored in french to specific personas, aimed at enhancing language model training with high-quality and diverse content.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Creation\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSource Data\\n\\t\\n\\nThe original‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/drodin/TextBooksPersonaHub-FR."},
  {"name":"medical-translation-test-set","keyword":"french","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/ai-amplified/medical-translation-test-set","creator_name":"admin","creator_url":"https://huggingface.co/ai-amplified","description":"ai-amplified/medical-translation-test-set dataset hosted on Hugging Face and contributed by the HF Datasets community"},
  {"name":"zenless_zone_zero_interknots_v1.0","keyword":"french","license":"Creative Commons Attribution Share Alike 4.0 International","language":"en","url":"https://huggingface.co/datasets/mrzjy/zenless_zone_zero_interknots_v1.0","creator_name":"jiayi","creator_url":"https://huggingface.co/mrzjy","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tZZZ Interknots\\n\\t\\n\\nThis datasets contains extracted Interknot posts and comments (Áª≥ÁΩëÁöÑÂçöÂÆ¢‰∏éËØÑËÆ∫) in multi-language.\\nUp to game version: 1.0\\n\\nInterknot posts and comments examples\\n\\n{\\n  \\\"id\\\": \\\"1021\\\",\\n  \\\"poster\\\": \\\"Sorrowful Intern\\\",\\n  \\\"title\\\": \\\"[Commission] Missing Bangboo merchants\\\",\\n  \\\"text\\\": \\\"Hello, pros... Some of the senior Bangboo of our merchant association have gone missing! We urgently need an expert to help find them!!\\\\nLet me explain, I recently joined a very prestigious‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mrzjy/zenless_zone_zero_interknots_v1.0."},
  {"name":"1984-orwell-book","keyword":"french","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/Svngoku/1984-orwell-book","creator_name":"NIONGOLO Chrys F√©-Marty","creator_url":"https://huggingface.co/Svngoku","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tGeorges Orwell : 1984\\n\\t\\n\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tOverview\\n\\t\\n\\nThis dataset is a comprehensive collection of data extracted from George Orwell's dystopian novel 1984.\\nThe data extraction as been made with llama_index and llama-parse.\\nThe restoration with gpt-4o-mini\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tContent Description\\n\\t\\n\\nThe dataset includes the following components:\\n\\nFull Text: The entire text of 1984 is divided into pages, preserving the original structure of the novel.\\n\\n@dataset{your_name_1984_dataset_2024‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Svngoku/1984-orwell-book."},
  {"name":"XL-HeadTags","keyword":"french","license":"Creative Commons Attribution Share Alike 4.0 International","language":"en","url":"https://huggingface.co/datasets/faisaltareque/XL-HeadTags","creator_name":"Faisal Tareque Shohan","creator_url":"https://huggingface.co/faisaltareque","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for XL-HeadTags Corpus\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Source\\n\\t\\n\\nWe have used M3LS and XL-Sum as source for this dataset.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\n We provide XL-HeadTags, a large-scale news headline and tags generation dataset. The dataset consists of 20 languages across six diverse language families. It contains 415K news headline-article pairs with auxiliary information such as image captions, topic words (read more).\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Structure\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/faisaltareque/XL-HeadTags."},
  {"name":"VQA-floschne-maxm-clean","keyword":"french","license":"Creative Commons Attribution Share Alike 4.0 International","language":"en","url":"https://huggingface.co/datasets/CATIE-AQ/VQA-floschne-maxm-clean","creator_name":"CATIE","creator_url":"https://huggingface.co/CATIE-AQ","description":"\\n\\t\\n\\t\\t\\n\\t\\tDescription\\n\\t\\n\\nFrench part of the floschne/maxm dataset that we processed.\\n\\n\\t\\n\\t\\t\\n\\t\\tCitation\\n\\t\\n\\n@inproceedings{changpinyo2023maxm,\\n  title = {{MaXM}: Towards Multilingual Visual Question Answering},\\n  author = {Changpinyo, Soravit and Xue, Linting and Yarom, Michal and Thapliyal, Ashish V. and Szpektor, Idan and Amelot, Julien and Chen, Xi and Soricut, Radu},\\n  booktitle={Findings of the Association for Computational Linguistics: EMNLP},\\n  year = {2023},\\n}\\n\\n"},
  {"name":"VQA-vidore-shiftproject_test-clean","keyword":"french","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/CATIE-AQ/VQA-vidore-shiftproject_test-clean","creator_name":"CATIE","creator_url":"https://huggingface.co/CATIE-AQ","description":"\\n\\t\\n\\t\\t\\n\\t\\tDescription\\n\\t\\n\\nvidore/shiftproject_test dataset that we processed.\\n\\n\\t\\n\\t\\t\\n\\t\\tCitation\\n\\t\\n\\n@misc{faysse2024colpaliefficientdocumentretrieval,\\n      title={ColPali: Efficient Document Retrieval with Vision Language Models}, \\n      author={Manuel Faysse and Hugues Sibille and Tony Wu and Bilel Omrani and Gautier Viaud and C√©line Hudelot and Pierre Colombo},\\n      year={2024},\\n      eprint={2407.01449},\\n      archivePrefix={arXiv},\\n      primaryClass={cs.IR}‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/CATIE-AQ/VQA-vidore-shiftproject_test-clean."},
  {"name":"ARK-Metadata","keyword":"french","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/SBB/ARK-Metadata","creator_name":"Staatsbibliothek zu Berlin - Preu√üischer Kulturbesitz","creator_url":"https://huggingface.co/SBB","description":"\\n\\t\\n\\t\\t\\n\\t\\tMetadata of the \\\"Alter Realkatalog\\\" (ARK) of Berlin State Library (SBB)\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tMotivation\\n\\t\\n\\nThis dataset was created with the intent to provide a single larger set of metadata from Berlin State Library for research purposes and the development of AI applications.\\nThe dataset comprises of descriptive metadata of 2.619.397 titles, which together form the \\\"Alte Realkatalog\\\" of Berlin State Libray, which may be translated to \\\"Old Subject Catalogue\\\". The data are stored in columnar‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/SBB/ARK-Metadata."},
  {"name":"moniteur-belge","keyword":"french","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/guust-franssens/moniteur-belge","creator_name":"Guust Franssens","creator_url":"https://huggingface.co/guust-franssens","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\n\\n\\nThe most up to date data can be found here: https://huggingface.co/datasets/guust-franssens/belgian-journal\\nDue to the different languages in Belgium, I decided to create three datasets belgian-journal/moniteur-belge/belgisch-staatsblad in order to make it more visible.\\nDataset contains the metadata + the text of bylaw publications of Belgian companies on the Belgian Journal (Moniteur Belge/Belgisch Staatstblad).\\nThis data was collected by webscraping the‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/guust-franssens/moniteur-belge."},
  {"name":"belgisch-staatsblad","keyword":"french","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/guust-franssens/belgisch-staatsblad","creator_name":"Guust Franssens","creator_url":"https://huggingface.co/guust-franssens","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\n\\n\\nThe most up to date data can be found here: https://huggingface.co/datasets/guust-franssens/belgian-journal\\nDue to the different languages in Belgium, I decided to create three datasets belgian-journal/moniteur-belge/belgisch-staatsblad in order to make it more visible.\\nDataset contains the metadata + the text of bylaw publications of Belgian companies on the Belgian Journal (Moniteur Belge/Belgisch Staatstblad).\\nThis data was collected by webscraping the‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/guust-franssens/belgisch-staatsblad."},
  {"name":"famma","keyword":"french","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/weaverbirdllm/famma","creator_name":"weaverbird_llm","creator_url":"https://huggingface.co/weaverbirdllm","description":"\\n\\t\\n\\t\\t\\n\\t\\tIntroduction\\n\\t\\n\\nFAMMA is a multi-modal financial Q&A benchmark dataset. The questions encompass three heterogeneous image types - tables, charts and text & math screenshots - and span eight subfields in finance, comprehensively covering topics across major asset classes. Additionally, all the questions are categorized by three difficulty levels ‚Äî easy, medium, and hard - and are available in three languages ‚Äî English, Chinese, and French. Furthermore, the questions are divided into two‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/weaverbirdllm/famma."},
  {"name":"Sujet-Financial-RAG-FR-Dataset","keyword":"french","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/sujet-ai/Sujet-Financial-RAG-FR-Dataset","creator_name":"Sujet AI","creator_url":"https://huggingface.co/sujet-ai","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSujet-Financial-RAG-FR-Dataset üìäüíº\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDescription üìù\\n\\t\\n\\nThis dataset is a proof-of-concept collection of French question-context pairs, specifically designed for training and evaluating embedding models in the financial domain. To demonstrate the importance of this approach, we hand-selected a few publicly available French financial documents. It's important to note that it remains entirely possible and fairly straightforward to gather a lot more financial documents‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/sujet-ai/Sujet-Financial-RAG-FR-Dataset."},
  {"name":"nfr_bt_nmt_english-french","keyword":"french","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/LT3/nfr_bt_nmt_english-french","creator_name":"Language and Translation Technology Team","creator_url":"https://huggingface.co/LT3","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Downloader\\n\\t\\n\\nThis script allows you to download and save datasets from the Hugging Face Hub in the same format used for the experiments:\\npython download_data.py --repo_name LT3/nfr_bt_nmt_english-french --base_path data/en-fr\\nimport argparse\\nfrom datasets import load_dataset\\nimport os\\n\\n\\ndef save_data(data, file_path):\\n    with open(file_path, \\\"w\\\", encoding=\\\"utf-8\\\") as f:\\n        f.write(\\\"\\\\n\\\".join(data) + \\\"\\\\n\\\")\\n\\n\\ndef download_and_save_dataset(repo_name, base_path):\\n    #‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/LT3/nfr_bt_nmt_english-french."},
  {"name":"VQA-cmarkea-doc-vqa-clean","keyword":"french","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/CATIE-AQ/VQA-cmarkea-doc-vqa-clean","creator_name":"CATIE","creator_url":"https://huggingface.co/CATIE-AQ","description":"\\n\\t\\n\\t\\t\\n\\t\\tDescription\\n\\t\\n\\ncmarkea/doc-vqa dataset that we processed.\\n\\n\\t\\n\\t\\t\\n\\t\\tCitation\\n\\t\\n\\n@online{SoSoDocvqa,\\n  AUTHOR = {Lo√Øc SOKOUDJOU SONAGU, Yoann SOLA},\\n  URL = {https://huggingface.co/datasets/cmarkea/doc-vqa},\\n  YEAR = {2024},\\n  KEYWORDS = {NLP ; Multimodal}\\n}\\n\\n"},
  {"name":"VQA-cmarkea-table-vqa-clean","keyword":"french","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/CATIE-AQ/VQA-cmarkea-table-vqa-clean","creator_name":"CATIE","creator_url":"https://huggingface.co/CATIE-AQ","description":"\\n\\t\\n\\t\\t\\n\\t\\tDescription\\n\\t\\n\\ncmarkea/table-vqa dataset that we processed.\\n\\n\\t\\n\\t\\t\\n\\t\\tCitation\\n\\t\\n\\n@online{AgDeTQA,\\n  AUTHOR = {Tom Agonnoude, Cyrile Delestre},\\n  URL = {https://huggingface.co/datasets/cmarkea/table-vqa},\\n  YEAR = {2024},\\n  KEYWORDS = {NLP ; Multimodal}\\n}\\n\\n"},
  {"name":"mmarco-hard-negatives-reranker-score","keyword":"french","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/hotchpotch/mmarco-hard-negatives-reranker-score","creator_name":"Yuichi Tateno","creator_url":"https://huggingface.co/hotchpotch","description":"\\nhotchpotch/mmarco-hard-negatives-reranker-score\\n\\nThis repository contains data from mMARCO scored using the reranker BAAI/bge-reranker-v2-m3.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages Covered\\n\\t\\n\\ntarget_languages = [\\n    \\\"english\\\",\\n    \\\"chinese\\\", \\n    \\\"french\\\",\\n    \\\"german\\\",\\n    \\\"indonesian\\\",\\n    \\\"italian\\\",\\n    \\\"portuguese\\\",\\n    \\\"russian\\\",\\n    \\\"spanish\\\",\\n    \\\"arabic\\\",\\n    \\\"dutch\\\",\\n    \\\"hindi\\\",\\n    \\\"japanese\\\",\\n    \\\"vietnamese\\\"\\n]\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tHard Negative Data\\n\\t\\n\\nThe hard negative data is derived from‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/hotchpotch/mmarco-hard-negatives-reranker-score."},
  {"name":"Multi-Opthalingua","keyword":"french","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/AAAIBenchmark/Multi-Opthalingua","creator_name":"AAAIBenchmark","creator_url":"https://huggingface.co/AAAIBenchmark","description":"AAAIBenchmark/Multi-Opthalingua dataset hosted on Hugging Face and contributed by the HF Datasets community"},
  {"name":"calme-legalkit-v0.1","keyword":"french","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/MaziyarPanahi/calme-legalkit-v0.1","creator_name":"Maziyar Panahi","creator_url":"https://huggingface.co/MaziyarPanahi","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tCalme LegalKit v0.1\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tCalme's Enhanced Synthetic Dataset for Advanced Legal Reasoning\\n\\t\\n\\n\\n\\n\\n\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tüöÄ Quick Links\\n\\t\\n\\n\\nDataset Page\\nFine-tuned Model\\nOriginal LegalKit Dataset\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tüìñ Overview\\n\\t\\n\\nCalme LegalKit v0.1 is a synthetically generated dataset designed to enhance legal reasoning and analysis capabilities in language models. This dataset builds upon the foundation laid by Louis Brul√© Naudet's LegalKit, incorporating advanced Chain of Thought (CoT)‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/MaziyarPanahi/calme-legalkit-v0.1."},
  {"name":"jolof","keyword":"french","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/dofbi/jolof","creator_name":"Mamadou Diagne","creator_url":"https://huggingface.co/dofbi","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tWolof Dataset for Open LLM Fine-Tuning\\n\\t\\n\\n\\n\\nThis project provides a dataset for fine-tuning language models (LLMs) in Wolof. It uses a Python script to create a JSONLines (.jsonl) file from a list of words, retrieving detailed information from a Wolof-French dictionary API.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Details\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\n\\n\\n\\n\\n\\nCurated by: Mamadou Diagne\\nLanguage(s) (NLP): Wolof to French\\nLicense: MIT\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Sources [optional]\\n\\t\\n\\n\\n\\n\\nRepository: [More‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/dofbi/jolof."},
  {"name":"whisper-french","keyword":"french","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/MaximeDde/whisper-french","creator_name":"Maxime Dubois d'Enghien","creator_url":"https://huggingface.co/MaximeDde","description":"MaximeDde/whisper-french dataset hosted on Hugging Face and contributed by the HF Datasets community"},
  {"name":"wiki-talks","keyword":"french","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/lflage/wiki-talks","creator_name":"Lucas Fonseca Lage","creator_url":"https://huggingface.co/lflage","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tWiki-Talks\\n\\t\\n\\nThe Wiki-Talks dataset is a collection of conversational threads extracted from the talk pages on Wikipedia.\\nThis dataset captures collaborative dialogue, discussion patterns, and consensus-building among Wikipedia contributors.\\nIt is useful for NLP research focused on dialogue, sentiment analysis, and community dynamics.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDetails\\n\\t\\n\\nCurrently due to PyArrow incompatibility to the long recursive structures in the dataset there is an intrinsic‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/lflage/wiki-talks."},
  {"name":"muri-it-language-split","keyword":"french","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/akoksal/muri-it-language-split","creator_name":"Abdullatif Koksal","creator_url":"https://huggingface.co/akoksal","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tMURI-IT: Multilingual Instruction Tuning Dataset for 200 Languages via Multilingual Reverse Instructions\\n\\t\\n\\nMURI-IT is a large-scale multilingual instruction tuning dataset containing 2.2 million instruction-output pairs across 200 languages. It is designed to address the challenges of instruction tuning in low-resource languages with Multilingual Reverse Instructions (MURI), which ensures that the output is human-written, high-quality, and authentic to the cultural and linguistic‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/akoksal/muri-it-language-split."},
  {"name":"mls-annotated","keyword":"french","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/PHBJT/mls-annotated","creator_name":"Paul Henri Biojout","creator_url":"https://huggingface.co/PHBJT","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Annotations of non English MLS\\n\\t\\n\\nThis dataset consists in annotations of a the Non English subset of the Multilingual LibriSpeech (MLS) dataset. \\nMLS dataset is a large multilingual corpus suitable for speech research. The dataset is derived from read audiobooks from LibriVox and consists of \\n8 languages - English, German, Dutch, Spanish, French, Italian, Portuguese, Polish. It includes about 44.5K hours of English and a total of about 6K hours for other‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/PHBJT/mls-annotated."},
  {"name":"news-dataset","keyword":"french","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/R3troR0b/news-dataset","creator_name":"Robert Albert Allen McNarland","creator_url":"https://huggingface.co/R3troR0b","description":"\\n\\t\\n\\t\\t\\n\\t\\tDataset Card for World_News\\n\\t\\n\\nA collection of news articles from around the world. The script ensures no duplicate articles are added.\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Details\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThe articles are drawn from these sources:\\n\\nReuters News Agency\\n\\nBBC World News\\n\\nAl Jazeera\\n\\nLe Monde\\n\\nSouth China Morning Post\\n\\nThe Hindu\\n\\nDeutshce Welle\\n\\nThe Gauardian\\n\\nNPR\\n\\nTASS News Agency, Russia\\n\\nThe Sydney Morning Herald\\n\\nCurated by: McNarland Software Consulatants Inc.\\n\\nFunded by‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/R3troR0b/news-dataset."},
  {"name":"ManyToDanishTranslations-tatoeba","keyword":"french","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/trollek/ManyToDanishTranslations-tatoeba","creator_name":"Trolle Karlsson","creator_url":"https://huggingface.co/trollek","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDanske overs√¶ttelser\\n\\t\\n\\nTak til Helsinki-NLP for deres tatoeba dataset (CC-BY-2.0).\\nModeller der kan adskillige sprog kan sj√¶ldent dansk. At overs√¶tte eksisterende dataset virker som en fornuftig l√∏sning p√• det problem, men af fornuftige overs√¶ttelsesv√¶rkt√∏jer er der kun f√•. Mad props til Mabeck for arbejdet med SlimOrca. Much inspired. Great thank.\\nSom sagt kan polylinvistiske modeller som regel engelsk, kinesisk, fransk, tysk, osv. og m√•ske mangler der bare noget‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/trollek/ManyToDanishTranslations-tatoeba."},
  {"name":"fr_literary_dataset_base","keyword":"french","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/crazyjeannot/fr_literary_dataset_base","creator_name":"Jean Barr√©","creator_url":"https://huggingface.co/crazyjeannot","description":"crazyjeannot/fr_literary_dataset_base dataset hosted on Hugging Face and contributed by the HF Datasets community"},
  {"name":"PangeaBench-xm100","keyword":"french","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/neulab/PangeaBench-xm100","creator_name":"NeuLab @ LTI/CMU","creator_url":"https://huggingface.co/neulab","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tXM100\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tThis is a copy from https://google.github.io/crossmodal-3600/\\n\\t\\n\\nIf you use this dataset, please cite the original authors:\\n@inproceedings{ThapliyalCrossmodal2022,\\n  author = {Ashish Thapliyal and Jordi Pont-Tuset and Xi Chen and Radu Soricut},\\n  title = {{Crossmodal-3600: A Massively Multilingual Multimodal Evaluation Dataset}},\\n  booktitle = {EMNLP},\\n  year = {2022}\\n}\\n\\n"},
  {"name":"retriever-vidore-vdsid_french-clean","keyword":"french","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/CATIE-AQ/retriever-vidore-vdsid_french-clean","creator_name":"CATIE","creator_url":"https://huggingface.co/CATIE-AQ","description":"\\n\\t\\n\\t\\t\\n\\t\\tDescription\\n\\t\\n\\nvidore/vdsid_french dataset that we processed.Although useless, we have created an empty answer column to facilitate the concatenation of this dataset with VQA datasets where only the quesion and image columns would be used to train a Colpali-type model or one of its derivatives.\\n\\n\\t\\n\\t\\t\\n\\t\\tCitation\\n\\t\\n\\n@misc{faysse2024colpaliefficientdocumentretrieval,\\n      title={ColPali: Efficient Document Retrieval with Vision Language Models}, \\n      author={Manuel Faysse and Hugues‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/CATIE-AQ/retriever-vidore-vdsid_french-clean."},
  {"name":"VQA-vidore-vdsid_french-clean","keyword":"french","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/CATIE-AQ/VQA-vidore-vdsid_french-clean","creator_name":"CATIE","creator_url":"https://huggingface.co/CATIE-AQ","description":"\\n\\t\\n\\t\\t\\n\\t\\tDescription\\n\\t\\n\\nvidore/vdsid_french dataset that we processed.\\n\\n\\t\\n\\t\\t\\n\\t\\tCitation\\n\\t\\n\\n@misc{faysse2024colpaliefficientdocumentretrieval,\\n      title={ColPali: Efficient Document Retrieval with Vision Language Models}, \\n      author={Manuel Faysse and Hugues Sibille and Tony Wu and Bilel Omrani and Gautier Viaud and C√©line Hudelot and Pierre Colombo},\\n      year={2024},\\n      eprint={2407.01449},\\n      archivePrefix={arXiv},\\n      primaryClass={cs.IR}‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/CATIE-AQ/VQA-vidore-vdsid_french-clean."},
  {"name":"caption-vidore-vdsid_french-clean","keyword":"french","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/CATIE-AQ/caption-vidore-vdsid_french-clean","creator_name":"CATIE","creator_url":"https://huggingface.co/CATIE-AQ","description":"\\n\\t\\n\\t\\t\\n\\t\\tDescription\\n\\t\\n\\nvidore/vdsid_french dataset that we processed for a visual question answering task where answer is a caption.\\n\\n\\t\\n\\t\\t\\n\\t\\tCitation\\n\\t\\n\\n@misc{faysse2024colpaliefficientdocumentretrieval,\\n      title={ColPali: Efficient Document Retrieval with Vision Language Models}, \\n      author={Manuel Faysse and Hugues Sibille and Tony Wu and Bilel Omrani and Gautier Viaud and C√©line Hudelot and Pierre Colombo},\\n      year={2024},\\n      eprint={2407.01449},\\n      archivePrefix={arXiv}‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/CATIE-AQ/caption-vidore-vdsid_french-clean."},
  {"name":"comment-translation-01","keyword":"french","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/ifmain/comment-translation-01","creator_name":"Mike Afton","creator_url":"https://huggingface.co/ifmain","description":"This dataset is based on Kaggle.  \\nThis dataset includes translations of 69,000 Reddit comments into 17 languages (English to 16 languages):\\nBelarusian, Czech, German,\\nEnglish, Spanish, Finnish,\\nFrench, Italian, Japanese,\\nKazakh, Korean, Latvian,\\nPolish, Russian, Swedish,\\nUkrainian, and Chinese.\\nIt contains 50% regular comments and 50% highly negative ones.\\nEnjoy using it!\\n"},
  {"name":"ApolloMoEDataset","keyword":"french","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/FreedomIntelligence/ApolloMoEDataset","creator_name":"FreedomAI","creator_url":"https://huggingface.co/FreedomIntelligence","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDemocratizing Medical LLMs For Much More Languages\\n\\t\\n\\nCovering 12 Major Languages including English, Chinese, French, Hindi, Spanish, Arabic, Russian, Japanese, Korean, German, Italian, Portuguese and 38 Minor Languages So far.\\n\\n   üìÉ Paper ‚Ä¢ üåê Demo ‚Ä¢ ü§ó ApolloMoEDataset ‚Ä¢ ü§ó ApolloMoEBench  ‚Ä¢ ü§ó Models  ‚Ä¢üåê Apollo  ‚Ä¢ üåê ApolloMoE\\n\\n\\n\\n\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tüåà Update\\n\\t\\n\\n\\n[2024.10.15] ApolloMoE repo is publishedÔºÅüéâ\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages Coverage\\n\\t\\n\\n12 Major Languages and 38 Minor Languages‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/FreedomIntelligence/ApolloMoEDataset."},
  {"name":"ApolloMoEBench","keyword":"french","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/FreedomIntelligence/ApolloMoEBench","creator_name":"FreedomAI","creator_url":"https://huggingface.co/FreedomIntelligence","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDemocratizing Medical LLMs For Much More Languages\\n\\t\\n\\nCovering 12 Major Languages including English, Chinese, French, Hindi, Spanish, Arabic, Russian, Japanese, Korean, German, Italian, Portuguese and 38 Minor Languages So far.\\n\\n   üìÉ Paper ‚Ä¢ üåê Demo ‚Ä¢ ü§ó ApolloMoEDataset ‚Ä¢ ü§ó ApolloMoEBench  ‚Ä¢ ü§ó Models  ‚Ä¢üåê Apollo  ‚Ä¢ üåê ApolloMoE\\n\\n\\n\\n\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tüåà Update\\n\\t\\n\\n\\n[2024.10.15] ApolloMoE repo is publishedÔºÅüéâ\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages Coverage\\n\\t\\n\\n12 Major Languages and 38 Minor Languages‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/FreedomIntelligence/ApolloMoEBench."},
  {"name":"aya_redteaming_consitutional","keyword":"french","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/pbevan11/aya_redteaming_consitutional","creator_name":"Peter J. Bevan","creator_url":"https://huggingface.co/pbevan11","description":"\\n\\t\\n\\t\\t\\n\\t\\tDataset Card for Aya Red-teaming-constiutional\\n\\t\\n\\nThis dataset is an extended version of CohereForAI/aya_redteaming, with added targeted constitutional principles, aiming to allow multilingual constitional AI using the Aya Red team prompts.\\nWe take the Anthropic constitutional principles and manually cut out the existing harms so that we can dynamically insert harms specific to our red team prompts.\\nThere are 16 critiques and 16 revisions for each red-team prompt, each targeting the‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/pbevan11/aya_redteaming_consitutional."},
  {"name":"llm_guard_dataset","keyword":"french","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/cgoosen/llm_guard_dataset","creator_name":"Christo Goosen","creator_url":"https://huggingface.co/cgoosen","description":"cgoosen/llm_guard_dataset dataset hosted on Hugging Face and contributed by the HF Datasets community"},
  {"name":"french_first_names_insee_2024","keyword":"french","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/eltorio/french_first_names_insee_2024","creator_name":"Ronan L.M.","creator_url":"https://huggingface.co/eltorio","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tFrench First Names from Death Records (1970-2024)\\n\\t\\n\\nThis dataset contains French first names extracted from death records provided by INSEE (French National Institute of Statistics and Economic Studies) covering the period from 1970 to September 2024.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Source\\n\\t\\n\\nThe data is sourced from INSEE's death records database. It includes first names of deceased individuals in France, providing valuable insights into naming patterns across‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/eltorio/french_first_names_insee_2024."},
  {"name":"NaVAB","keyword":"french","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/JadenGGGeee/NaVAB","creator_name":"JCY","creator_url":"https://huggingface.co/JadenGGGeee","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for NaVAB\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Details\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nNaVAB is a comprehensive benchmark designed to evaluate the alignment of Large Language Models (LLMs) with the values of five major nations: China, the United States, the United Kingdom, France, and Germany. The dataset addresses the limitations of existing benchmarks, which often fail to capture the dynamic nature of values across countries and lack sufficient evaluation data.\\nThe dataset‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/JadenGGGeee/NaVAB."},
  {"name":"WikiNER-fr-gold","keyword":"french","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/danrun/WikiNER-fr-gold","creator_name":"Danrun Cao","creator_url":"https://huggingface.co/danrun","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tWikiNER-fr-gold\\n\\t\\n\\nThis dataset is a manually revised version of 20% of the French proportion of WikiNER. \\nThe original dataset is currently available here, based on which WikiNER-fr-gold is created.\\nThe entities are annotated using the BIOES scheme.\\nThe POS tags are not revised i.e. remain the same as the original dataset.\\nFor more information on the revision details, please refer to our paper WikiNER-fr-gold: A Gold-Standard NER Corpus.\\nThe dataset is available in two formats.‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/danrun/WikiNER-fr-gold."},
  {"name":"MegaWika","keyword":"french","license":"Creative Commons Attribution Share Alike 4.0 International","language":"en","url":"https://huggingface.co/datasets/conceptofmind/MegaWika","creator_name":"Enrico Shippole","creator_url":"https://huggingface.co/conceptofmind","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for MegaWika\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nMegaWika is a multi- and crosslingual text dataset containing 30 million Wikipedia passages with their scraped and cleaned web citations. The passages span\\n50 Wikipedias in 50 languages, and the articles in which the passages were originally embedded are included for convenience. Where a Wikipedia passage is in a\\nnon-English language, an automated English translation is provided. Furthermore, nearly 130 million English‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/conceptofmind/MegaWika."},
  {"name":"WiNNL","keyword":"french","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/peemil/WiNNL","creator_name":"Emile Peetermans","creator_url":"https://huggingface.co/peemil","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tWiNNL\\n\\t\\n\\nWikiNews Named entity recognition and Linking (WiNNL) is a multilingual news NER & NEL benchmark based on Wikinews articles.\\nThe dataset was created by automatically scraping and tagging news articles, and manually corrected by native speakers to ensure accuracy.\\nYou can find more information in the paper:\\nhttps://aclanthology.org/2024.dlnld-1.3.pdf\\nThe dataset includes the following NER classes in IOB format (labels):\\n\\nPER (Person): person names \\nLOC (Location):‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/peemil/WiNNL."},
  {"name":"publication_dates_fr","keyword":"french","license":"Academic Free License v3.0","language":"en","url":"https://huggingface.co/datasets/maribr/publication_dates_fr","creator_name":"Marie Bauer ","creator_url":"https://huggingface.co/maribr","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Dataset Name\\n\\t\\n\\nThis dataset has been done by M2 student in computational linguistics at the Paris Cit√© university. \\nIt is part of a project for the course \\\"NLP in Industry\\\".  The annotation are handmade and the gold should represent the publications date of the extracted text document. \\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Details\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThis dataset consists of publication made by mayor office that have been annotated with publication dates. \\nThe‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/maribr/publication_dates_fr."},
  {"name":"appreciation","keyword":"french","license":"GNU Affero General Public License v3.0","language":"en","url":"https://huggingface.co/datasets/eltorio/appreciation","creator_name":"Ronan L.M.","creator_url":"https://huggingface.co/eltorio","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tAppreciation : Un dataset d'appr√©ciations au lyc√©e\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDescription\\n\\t\\n\\nAppreciation est un jeu de donn√©es compilant des appr√©ciations r√©elles d'enseignants du lyc√©e en France. Il est destin√© √† faciliter la recherche et le d√©veloppement d'outils d'analyse textuelle et d'intelligence artificielle centr√©s sur l'√©ducation, notamment pour le traitement du langage naturel dans le contexte √©ducatif fran√ßais.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tStructure du Dataset\\n\\t\\n\\nLe dataset est structur√© avec les‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/eltorio/appreciation."},
  {"name":"phase2","keyword":"french","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/Danasoumoh/phase2","creator_name":"Gouasmi","creator_url":"https://huggingface.co/Danasoumoh","description":"Danasoumoh/phase2 dataset hosted on Hugging Face and contributed by the HF Datasets community"},
  {"name":"retriever-vidore-tabfquad_test_subsampled-clean","keyword":"french","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/CATIE-AQ/retriever-vidore-tabfquad_test_subsampled-clean","creator_name":"CATIE","creator_url":"https://huggingface.co/CATIE-AQ","description":"\\n\\t\\n\\t\\t\\n\\t\\tDescription\\n\\t\\n\\nvidore/tabfquad_test_subsampled dataset that we processed.Although useless, we have created an empty answer column to facilitate the concatenation of this dataset with VQA datasets where only the quesion and image columns would be used to train a Colpali-type model or one of its derivatives.\\n\\n\\t\\n\\t\\t\\n\\t\\tCitation\\n\\t\\n\\n@misc{faysse2024colpaliefficientdocumentretrieval,\\n      title={ColPali: Efficient Document Retrieval with Vision Language Models}, \\n      author={Manuel Faysse‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/CATIE-AQ/retriever-vidore-tabfquad_test_subsampled-clean."},
  {"name":"Tridis","keyword":"french","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/magistermilitum/Tridis","creator_name":"Sergio Torres","creator_url":"https://huggingface.co/magistermilitum","description":"This is the first dataset version of the corpora used in TRIDIS (Tria Digita Scribunt) which is a series of Handwriting Text Recognition models trained on semi-diplomatic transcriptions \\nfrom medieval and Early Modern Manuscripts.\\nThe dataset involves 4k pages of manuscripts and is suitable for work on documentary manuscripts, that is, manuscripts arising  from legal, administrative, and memorial practices such as registers, feudal books, charters, proceedings, comptability more commonly from‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/magistermilitum/Tridis."},
  {"name":"french-ghomala-bandjoun","keyword":"french","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/stfotso/french-ghomala-bandjoun","creator_name":"Steve TUENO","creator_url":"https://huggingface.co/stfotso","description":"\\n\\t\\n\\t\\t\\n\\t\\tDataset Card for Dataset Name\\n\\t\\n\\nDataset containing translation of a given set of French words and expressions to Ghomala, the native language of Bandjoun, a village part of Cameroun (Central Africa). Its aim is to be used to tune LLMs in recognising ghomala and support translation from/to that language.\\nDataset extracted from Dictionnaire Ghom√°l√°‚Äô-Fran√ßais edited by Erika EICHHOLZER with Prof. Dr. Engelbert DOMCHE-TEKO, Dr. Gabriel MBA and P. Gabriel NISSIM, Version 2.0, D√©cembre‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/stfotso/french-ghomala-bandjoun."},
  {"name":"french-ghomala-bandjoun","keyword":"french","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/stfotso/french-ghomala-bandjoun","creator_name":"Steve TUENO","creator_url":"https://huggingface.co/stfotso","description":"\\n\\t\\n\\t\\t\\n\\t\\tDataset Card for Dataset Name\\n\\t\\n\\nDataset containing translation of a given set of French words and expressions to Ghomala, the native language of Bandjoun, a village part of Cameroun (Central Africa). Its aim is to be used to tune LLMs in recognising ghomala and support translation from/to that language.\\nDataset extracted from Dictionnaire Ghom√°l√°‚Äô-Fran√ßais edited by Erika EICHHOLZER with Prof. Dr. Engelbert DOMCHE-TEKO, Dr. Gabriel MBA and P. Gabriel NISSIM, Version 2.0, D√©cembre‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/stfotso/french-ghomala-bandjoun."},
  {"name":"mmarco-lt","keyword":"french","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/andreaschari/mmarco-lt","creator_name":"Andreas Chari","creator_url":"https://huggingface.co/andreaschari","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThis is a variation of mMARCO by Bonifacio et al. used for the \\\"Improving Low-Resource Retrieval Effectiveness using Zero-Shot Linguistic Similarity Transfer\\\" ECIR2025 paper. \\nThe source code for the paper can be found here\\nmMARCO is a multilingual version of the MS MARCO passage ranking dataset.\\nFor more information, checkout the original mMARCO papers:\\n\\nmMARCO: A Multilingual Version of the MS MARCO Passage Ranking Dataset\\nA cost-benefit analysis of‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/andreaschari/mmarco-lt."},
  {"name":"vocabulaire_de_litterature","keyword":"french","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/datasets-CNRS/vocabulaire_de_litterature","creator_name":"datasets-CNRS","creator_url":"https://huggingface.co/datasets-CNRS","description":"\\nDataset origin: https://loterre-skosmos.loterre.fr/P21/fr/\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDescription\\n\\t\\n\\nVocabulaire contr√¥l√© utilis√© pour l'indexation des r√©f√©rences bibliographiques de la base de donn√©es FRANCIS \\\"Litt√©rature\\\" (de 1972 √† 2015, http://pascal-francis.inist.fr/). Il est align√© avec DBpedia.\\n"},
  {"name":"alpaca-cleaned-italian","keyword":"french","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/DanielSc4/alpaca-cleaned-italian","creator_name":"Daniel Scalena","creator_url":"https://huggingface.co/DanielSc4","description":"\\n\\t\\n\\t\\t\\n\\t\\tDataset Card for Alpaca-Cleaned-Italian\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tAbout the translation and the original data\\n\\t\\n\\nThe translation was done with X-ALMA, a 13-billion-parameter model that surpasses state-of-the-art open-source multilingual LLMs (as of Q1 2025, paper here).\\nThe original alpaca-cleaned dataset is also kept here so that there is parallel data for Italian and English.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tAdditional notes on the translation\\n\\t\\n\\n\\nDespite the good quality of the translation, errors, though rare, are‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/DanielSc4/alpaca-cleaned-italian."},
  {"name":"publication_dates_fr","keyword":"french","license":"Academic Free License v3.0","language":"en","url":"https://huggingface.co/datasets/polinaeterna/publication_dates_fr","creator_name":"Polina Kazakova","creator_url":"https://huggingface.co/polinaeterna","description":"\\n\\t\\n\\t\\t\\n\\t\\tDataset Card for Dataset Name\\n\\t\\n\\nThis dataset has been done by M2 student in computational linguistics at the Paris Cit√© university. \\nIt is part of a project for the course \\\"NLP in Industry\\\".  The annotation are handmade and the gold should represent the publications date of the extracted text document. \\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Details\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThis dataset consists of publication made by mayor office that have been annotated with publication dates. \\nThe annotations‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/polinaeterna/publication_dates_fr."},
  {"name":"CAPP-17-01-2025","keyword":"french","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/La-Mousse/CAPP-17-01-2025","creator_name":"La Mousse","creator_url":"https://huggingface.co/La-Mousse","description":"\\n\\t\\n\\t\\t\\n\\t\\tFrench Court of Appeal Decisions Dataset (CAPP)\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThe French Court of Appeal Decisions Dataset (CAPP) is a comprehensive collection of judicial decisions from French Courts of Appeal. This dataset contains appellate court decisions from various jurisdictions throughout France, providing a valuable resource for legal research, analysis, and machine learning applications in the French legal domain.\\n\\n\\t\\n\\t\\t\\n\\t\\tSource Data\\n\\t\\n\\nThe data is sourced from the‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/La-Mousse/CAPP-17-01-2025."},
  {"name":"CASS-17-01-2025","keyword":"french","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/La-Mousse/CASS-17-01-2025","creator_name":"La Mousse","creator_url":"https://huggingface.co/La-Mousse","description":"\\n\\t\\n\\t\\t\\n\\t\\tFrench Court of Cassation Decisions Dataset (CASS)\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThe French Court of Cassation Decisions Dataset (CASS) is a comprehensive collection of judicial decisions from the French Court of Cassation (Cour de cassation), France's highest court for civil and criminal matters. This dataset contains decisions that represent the most authoritative interpretations of French law, providing an invaluable resource for legal research, analysis, and machine learning‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/La-Mousse/CASS-17-01-2025."},
  {"name":"CNIL-18-01-2025","keyword":"french","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/La-Mousse/CNIL-18-01-2025","creator_name":"La Mousse","creator_url":"https://huggingface.co/La-Mousse","description":"\\n\\t\\n\\t\\t\\n\\t\\tFrench National Commission on Informatics and Liberty (CNIL) Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThe CNIL Dataset is a curated collection of documents from the French National Commission on Informatics and Liberty (CNIL). This dataset provides detailed records of decisions and deliberations made by CNIL, which governs data privacy and personal data regulation in France. It serves as a rich resource for researchers, legal practitioners, and machine learning engineers interested in‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/La-Mousse/CNIL-18-01-2025."},
  {"name":"combined-fr-caselaw","keyword":"french","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/La-Mousse/combined-fr-caselaw","creator_name":"La Mousse","creator_url":"https://huggingface.co/La-Mousse","description":"\\n\\t\\n\\t\\t\\n\\t\\tDataset Card for French Legal Cases Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThis dataset combines French legal cases from multiple sources (INCA, JADE, CASS, CAPP) into a unified format with overlapping text triplets. It includes decisions from various French courts, processed to facilitate natural language processing tasks.\\n\\n\\t\\n\\t\\t\\n\\t\\tSupported Tasks and Leaderboards\\n\\t\\n\\n\\nTasks:\\nText Generation\\nLegal Document Analysis\\nText Classification\\nLanguage Modeling\\n\\n\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tLanguages\\n\\t\\n\\nThe dataset‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/La-Mousse/combined-fr-caselaw."},
  {"name":"phase3","keyword":"french","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/Danasoumoh/phase3","creator_name":"Gouasmi","creator_url":"https://huggingface.co/Danasoumoh","description":"Danasoumoh/phase3 dataset hosted on Hugging Face and contributed by the HF Datasets community"},
  {"name":"geotechnie","keyword":"french","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/MatteoKhan/geotechnie","creator_name":"Khan Matteo","creator_url":"https://huggingface.co/MatteoKhan","description":"\\n\\t\\n\\t\\t\\n\\t\\tAbout Me\\n\\t\\n\\nAbout Me\\nI'm Matteo Khan, a computer science apprentice at TW3 Partners, specializing in Generative AI and NLP. My focus is on creating datasets that improve AI's ability to process complex technical documents.\\nYou can connect with me on LinkedIn: Matteo Khan\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Details\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tPurpose\\n\\t\\n\\nThis dataset is designed to fine-tune models for expertise in geotechnical engineering by generating structured queries from soil mechanics and construction-related‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/MatteoKhan/geotechnie."},
  {"name":"chatbot","keyword":"french","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/Ed-ElypseCloud/chatbot","creator_name":"ElypseCloud","creator_url":"https://huggingface.co/Ed-ElypseCloud","description":"\\n\\t\\n\\t\\t\\n\\t\\tChatbot dataset\\n\\t\\n\\nDataset pour notre model chatbot. \\n"},
  {"name":"GammaCorpus-Polylingo-50k","keyword":"french","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/rubenroy/GammaCorpus-Polylingo-50k","creator_name":"Ruben Roy","creator_url":"https://huggingface.co/rubenroy","description":"\\n\\t\\n\\t\\t\\n\\t\\tGammaCorpus Polylingo 50k\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tWhat is it?\\n\\t\\n\\nThe GammaCorpus Polylingo 50k dataset consists of 50,000 structured, unfiltered, single-turn conversations, where each interaction includes:\\n\\nInput: A user prompt or question.\\nOutput: A response generated by an AI assistant.\\nLanguage: The language used in the interaction.\\n\\nThis dataset is designed to help in the training and evaluation of conversational AI models for linguistic purposes. This dataset can be especially helpful if you‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/rubenroy/GammaCorpus-Polylingo-50k."},
  {"name":"FrMedQA","keyword":"french","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/Anony-mous123/FrMedQA","creator_name":"a123","creator_url":"https://huggingface.co/Anony-mous123","description":"Anony-mous123/FrMedQA dataset hosted on Hugging Face and contributed by the HF Datasets community"},
  {"name":"FrClinicalQA","keyword":"french","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/Anony-mous123/FrClinicalQA","creator_name":"a123","creator_url":"https://huggingface.co/Anony-mous123","description":"Anony-mous123/FrClinicalQA dataset hosted on Hugging Face and contributed by the HF Datasets community"},
  {"name":"K-QA","keyword":"french","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/Anony-mous123/K-QA","creator_name":"a123","creator_url":"https://huggingface.co/Anony-mous123","description":"Anony-mous123/K-QA dataset hosted on Hugging Face and contributed by the HF Datasets community"},
  {"name":"fr-medmcqa","keyword":"french","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/Anony-mous123/fr-medmcqa","creator_name":"a123","creator_url":"https://huggingface.co/Anony-mous123","description":"Anony-mous123/fr-medmcqa dataset hosted on Hugging Face and contributed by the HF Datasets community"},
  {"name":"fr-mmlu_medical_genetics","keyword":"french","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/Anony-mous123/fr-mmlu_medical_genetics","creator_name":"a123","creator_url":"https://huggingface.co/Anony-mous123","description":"Anony-mous123/fr-mmlu_medical_genetics dataset hosted on Hugging Face and contributed by the HF Datasets community"},
  {"name":"fr-pubmedqa","keyword":"french","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/Anony-mous123/fr-pubmedqa","creator_name":"a123","creator_url":"https://huggingface.co/Anony-mous123","description":"Anony-mous123/fr-pubmedqa dataset hosted on Hugging Face and contributed by the HF Datasets community"},
  {"name":"test","keyword":"french","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/SkyZoThreaD/test","creator_name":"Skyzothread","creator_url":"https://huggingface.co/SkyZoThreaD","description":"SkyZoThreaD/test dataset hosted on Hugging Face and contributed by the HF Datasets community"},
  {"name":"AIME2025-Multilingual","keyword":"french","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/fedric95/AIME2025-Multilingual","creator_name":"Federico Ricciuti","creator_url":"https://huggingface.co/fedric95","description":"\\n\\t\\n\\t\\t\\n\\t\\tDescription\\n\\t\\n\\nThis repository contains a multi language version of the AIME2025 dataset. \\nAs the english reference version, we haved used the one created by the authors of MathArena.\\nFor completness, we have included the english version also in this repository, please, refer to the one contained in the MathArena github repository for the original one (https://github.com/eth-sri/matharena/tree/main/data/aime). Many thanks to Jasper Dekoninck for the help in understanding the structure‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/fedric95/AIME2025-Multilingual."},
  {"name":"MATH-500-french-thoughts","keyword":"french","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/Cotum/MATH-500-french-thoughts","creator_name":"Cotum","creator_url":"https://huggingface.co/Cotum","description":"\\n\\t\\n\\t\\t\\n\\t\\t‚ûïüá´üá∑üí≠ Dataset Card for MATH-500-french-thoughts\\n\\t\\n\\nA french subset from OpenAI's MATH benchmark adapted from bezir/MATH-500-multilingual with additionnal thoughts from stelterlab/DeepSeek-R1-Distill-Qwen-14B-AWQ. \\nPerfect for testing math skills in French. \\n\\n\\t\\n\\t\\t\\n\\t\\tüìÇ Source & Attribution\\n\\t\\n\\n\\nOriginal Dataset: Sourced from HuggingFaceH4/MATH-500.\\nAdapted Dataset: Taken from bezir/MATH-500-multilingual.\\nThoughts, answers and predicted answers: Generated with‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Cotum/MATH-500-french-thoughts."},
  {"name":"banque","keyword":"french","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/MatteoKhan/banque","creator_name":"Khan Matteo","creator_url":"https://huggingface.co/MatteoKhan","description":"\\n\\t\\n\\t\\t\\n\\t\\tAbout Me\\n\\t\\n\\nAbout Me\\nI'm Matteo Khan, a computer science apprentice at TW3 Partners, specializing in Generative AI and NLP. My focus is on creating datasets that improve AI's ability to process complex technical documents.\\nYou can connect with me on LinkedIn: Matteo Khan\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Details\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tPurpose\\n\\t\\n\\nThis dataset is designed to fine-tune models for expertise in the banking sector by generating structured queries from financial and banking-related documents. It enhances‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/MatteoKhan/banque."},
  {"name":"banque","keyword":"french","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/MatteoKhan/banque","creator_name":"Khan Matteo","creator_url":"https://huggingface.co/MatteoKhan","description":"\\n\\t\\n\\t\\t\\n\\t\\tAbout Me\\n\\t\\n\\nAbout Me\\nI'm Matteo Khan, a computer science apprentice at TW3 Partners, specializing in Generative AI and NLP. My focus is on creating datasets that improve AI's ability to process complex technical documents.\\nYou can connect with me on LinkedIn: Matteo Khan\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Details\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tPurpose\\n\\t\\n\\nThis dataset is designed to fine-tune models for expertise in the banking sector by generating structured queries from financial and banking-related documents. It enhances‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/MatteoKhan/banque."},
  {"name":"multilingualcrowspairs","keyword":"french","license":"Creative Commons Attribution Share Alike 4.0 International","language":"en","url":"https://huggingface.co/datasets/FrancophonIA/multilingualcrowspairs","creator_name":"FrancophonIA","creator_url":"https://huggingface.co/FrancophonIA","description":"\\nDataset origin: https://gitlab.inria.fr/corpus4ethics/multilingualcrowspairs/\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tMultiLingualCrowsPairs\\n\\t\\n\\nMultilingual CrowS-Pairs, a challenge dataset for measuring stereotypical biases present in the masked language models (MLMs) in 7 different languages. \\nThis challenge dataset was built on the Crows-Pairs corpus (Nangia et al. 2020) using the methodology described in (N√©v√©ol et al. 2023). \\nThe 7 new languages are the following:\\n\\nArabic from Maghreb and the Arab world in general‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/FrancophonIA/multilingualcrowspairs."},
  {"name":"text-validation","keyword":"french","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/re-mind/text-validation","creator_name":"Kiklos","creator_url":"https://huggingface.co/re-mind","description":"re-mind/text-validation dataset hosted on Hugging Face and contributed by the HF Datasets community"},
  {"name":"casimedicos-arg","keyword":"french","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/HiTZ/casimedicos-arg","creator_name":"HiTZ zentroa","creator_url":"https://huggingface.co/HiTZ","description":"\\n    \\n    \\n    \\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tCasiMedicos-Arg: A Medical Question Answering Dataset Annotated with Explanatory Argumentative Structures\\n\\t\\n\\nCasiMedicos-Arg is, to the best of our knowledge, the first \\nmultilingual dataset for Medical Question Answering where correct and incorrect diagnoses for a clinical case are \\nenriched with a natural language explanation written by doctors. \\nThe casimedicos-exp have been manually annotated with \\nargument components (i.e., premise, claim) and argument‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/HiTZ/casimedicos-arg."},
  {"name":"phrases-A_LEA-0.5.0","keyword":"french","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/FrancophonIA/phrases-A_LEA-0.5.0","creator_name":"FrancophonIA","creator_url":"https://huggingface.co/FrancophonIA","description":"\\nDataset origin: https://zenodo.org/records/3818583\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDescription\\n\\t\\n\\nUne base de donn√©es de phrases pr√©sentant des caract√©ristiques de lien s√©mantique vari√© avec des mots-cible monosyllabiques. Ces phrases ont √©t√© con√ßues √† partir de mesures de plongements de mots issues d'un mod√®le du corpus Wikipedia en fran√ßais.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tCitation\\n\\t\\n\\nCrouzet, O., Gaudrain, √â., & Leprieur, L. (2020). Une base de donn√©es de phrases en fran√ßais pour l'√©tude du r√¥le conjoint des incertitudes‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/FrancophonIA/phrases-A_LEA-0.5.0."},
  {"name":"jeli-asr","keyword":"french","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/RobotsMali/jeli-asr","creator_name":"RobotsMali AI4D LAB","creator_url":"https://huggingface.co/RobotsMali","description":"The **Jeli-ASR Audio Dataset** is a multilingual dataset converted into the optimized Arrow format, \\nensuring fast access and compatibility with modern data workflows. It contains audio samples in Bambara \\nwith semi-expert transcriptions and French translations. Each subset of the dataset is organized by \\nconfiguration (`jeli-asr-rmai`, `bam-asr-oza`, and `jeli-asr`) and further split into training and testing sets. \\nThe dataset is designed for tasks like automatic speech recognition (ASR), text-to-speech synthesis (TTS), \\nand translation. Data was recorded in Mali with griots, then transcribed and translated into French.\\n"},
  {"name":"jeli-asr","keyword":"french","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/RobotsMali/jeli-asr","creator_name":"RobotsMali AI4D LAB","creator_url":"https://huggingface.co/RobotsMali","description":"The **Jeli-ASR Audio Dataset** is a multilingual dataset converted into the optimized Arrow format, \\nensuring fast access and compatibility with modern data workflows. It contains audio samples in Bambara \\nwith semi-expert transcriptions and French translations. Each subset of the dataset is organized by \\nconfiguration (`jeli-asr-rmai`, `bam-asr-oza`, and `jeli-asr`) and further split into training and testing sets. \\nThe dataset is designed for tasks like automatic speech recognition (ASR), text-to-speech synthesis (TTS), \\nand translation. Data was recorded in Mali with griots, then transcribed and translated into French.\\n"},
  {"name":"parallel_corpus_game_2024","keyword":"french","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/bot-yaya/parallel_corpus_game_2024","creator_name":"yaya","creator_url":"https://huggingface.co/bot-yaya","description":"https://github.com/mnbvc-parallel-corpus-team/parallel_corpus_mnbvc\\nMNBVCÂπ≥Ë°åËØ≠ÊñôÂ∞èÁªÑÔºöÊ∏∏ÊàèËØ≠Êñô\\n‰∏çÂÆöÊúüÊõ¥Êñ∞ÔºåÁõÆÂâçÂ∑≤Êî∂ÂΩïÁöÑÊ∏∏ÊàèËØ≠ÊñôÊñá‰ª∂ÔºåÂÖ±29‰ªΩÔºö\\n\\nÂçöÂæ∑‰πãÈó®3\\nËµõÂçöÊúãÂÖã2077\\nÈªëÊöó‰πãÈ≠Ç3\\nÂ∫ïÁâπÂæãÔºöÂåñË∫´‰∏∫‰∫∫\\nÈ••Ëçí\\nËâæÂ∞îÁôªÊ≥ïÁéØ\\nÂéüÁ•û\\nÈªëÂ∏ùÊñØ\\nÈúçÊ†ºÊ≤ÉÂÖπ‰πãÈÅó\\nIb\\nÂ¶ÇÈæô8\\nÂ¶ÇÈæô7Â§ñ‰º†\\nËçíÈáéÂ§ßÈïñÂÆ¢2\\nÂè™ÁãºÔºöÂΩ±ÈÄù‰∫åÂ∫¶\\nÊñáÊòé6\\nÊùÄÊàÆÂ∞ñÂ°î\\nÂ¥©ÂùèÊòüÁ©πÈìÅÈÅì\\nÁæ§Êòü\\nÊ≥∞ÊãâÁëû‰∫ö\\nÂ∑´Â∏à3\\nÈ≠îÂ•≥‰πãÊ≥â3\\nÈ≠îÂ•≥‰πãÊ≥âR\\nÈ∏£ÊΩÆ\\nÂ¶ÇÈæô3\\nÂ¶ÇÈæô4\\nÂ¶ÇÈæô5\\nÂ¶ÇÈæô6\\nÂ¶ÇÈæôÊûÅ2\\nÂ¶ÇÈæô7\\n\\n"},
  {"name":"cml-tts-filtered-annotated","keyword":"french","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/PHBJT/cml-tts-filtered-annotated","creator_name":"Paul Henri Biojout","creator_url":"https://huggingface.co/PHBJT","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Filtred and annotated CML TTS\\n\\t\\n\\nThis dataset is an annotated and filtred version of a CML-TTS [1]. \\nCML-TTS [1] CML-TTS is a recursive acronym for CML-Multi-Lingual-TTS, a Text-to-Speech (TTS) dataset developed at the Center of Excellence in Artificial Intelligence (CEIA) of the Federal University of Goias (UFG). CML-TTS is a dataset comprising audiobooks sourced from the public domain books of Project Gutenberg, read by volunteers from the LibriVox project. The‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/PHBJT/cml-tts-filtered-annotated."},
  {"name":"X-ALMA-Preference","keyword":"french","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/haoranxu/X-ALMA-Preference","creator_name":"Haoran Xu","creator_url":"https://huggingface.co/haoranxu","description":"This is the translation preference dataset used by X-ALMA.\\nsource: the source sentence.\\nchosen: the preferred translation.\\nreject: the dis-preferred translation.\\ndirections: the translation direction.\\n@misc{xu2024xalmaplugplay,\\n      title={X-ALMA: Plug & Play Modules and Adaptive Rejection for Quality Translation at Scale}, \\n      author={Haoran Xu and Kenton Murray and Philipp Koehn and Hieu Hoang and Akiko Eriguchi and Huda Khayrallah},\\n      year={2024},\\n      eprint={2410.03115}‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/haoranxu/X-ALMA-Preference."},
  {"name":"noisy-gt-missing-words-train-only","keyword":"french","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/alix-tz/noisy-gt-missing-words-train-only","creator_name":"Alix Chagu√©","creator_url":"https://huggingface.co/alix-tz","description":"\\n\\t\\n\\t\\t\\n\\t\\tNoisy Ground Truth - Missing Words in Train Split only\\n\\t\\n\\nDataset of synthetic data for experimentation with noisy ground truth. The text in the dataset is based on Colette's Sido and Les Vignes, also the data was processed prior to generating images with the TextRecognitionDataGenerator.\\nIn Noisy Ground Truth - Missing Words in Train Split only, each variation column is affected by the noise, only when the split is for training. The validation and test splits are not affected by the‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/alix-tz/noisy-gt-missing-words-train-only."},
  {"name":"noisy-gt-xxx-words-train-only","keyword":"french","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/alix-tz/noisy-gt-xxx-words-train-only","creator_name":"Alix Chagu√©","creator_url":"https://huggingface.co/alix-tz","description":"\\n\\t\\n\\t\\t\\n\\t\\tNoisy Ground Truth - Words Replaced with XXX in Train Split only\\n\\t\\n\\nDataset of synthetic data for experimentation with noisy ground truth. The text in the dataset is based on Colette's Sido and Les Vignes, also the data was processed prior to generating images with the TextRecognitionDataGenerator.\\nIn Noisy Ground Truth - Words Replaced with XXX in Train Split only, each variation column is affected by the noise, without considering the split between train, validation and test.‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/alix-tz/noisy-gt-xxx-words-train-only."},
  {"name":"Tunisian_Language_Dataset","keyword":"french","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/AzizBelaweid/Tunisian_Language_Dataset","creator_name":"Aziz Belaweid","creator_url":"https://huggingface.co/AzizBelaweid","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Tunisian Text Compilation\\n\\t\\n\\nThis dataset is a curated compilation of various Tunisian datasets, aimed at gathering as much Tunisian text data as possible in one place. It combines multiple sources of Tunisian language data, providing a rich resource for research, development of NLP models, and linguistic studies on Tunisian text.\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Details\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThis dataset aggregates several publicly available datasets that‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/AzizBelaweid/Tunisian_Language_Dataset."},
  {"name":"mosel","keyword":"french","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/FBK-MT/mosel","creator_name":"FBK-MT","creator_url":"https://huggingface.co/FBK-MT","description":"\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description, Collection, and Source\\n\\t\\n\\nThe MOSEL corpus is a multilingual dataset collection including up to 950K hours of open-source speech recordings covering the 24 official languages of the European Union. We collect data by surveying labeled and unlabeled speech corpora under open-source compliant licenses.\\nIn particular, MOSEL includes the automatic transcripts of 441k hours of unlabeled speech from VoxPopuli and LibriLight. The data is transcribed using Whisper large‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/FBK-MT/mosel."},
  {"name":"bouillet_1878_wd","keyword":"french","license":"Creative Commons Attribution Share Alike 4.0 International","language":"en","url":"https://huggingface.co/datasets/pnugues/bouillet_1878_wd","creator_name":"Pierre Nugues","creator_url":"https://huggingface.co/pnugues","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for \\\"bouillet_1872_wd\\\"\\n\\t\\n\\nThe Dictionnaire universel d‚Äôhistoire et de g√©ographie is a French dictionary of \\nhistory and geography first published in 1842. \\nThis dataset connects most entries of the 1878 edition to wikidata items.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Instances\\n\\t\\n\\nEach sample is a JSON dictionnary with a list of headwords, text of the entry and a list of wikidata identifiers.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDigital Version\\n\\t\\n\\nThe digital version of the text comes from Wikisource:‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/pnugues/bouillet_1878_wd."},
  {"name":"Apertium_dictionary_br_fr","keyword":"french","license":"GNU General Public License v2.0","language":"en","url":"https://huggingface.co/datasets/Bretagne/Apertium_dictionary_br_fr","creator_name":"Bretagne","creator_url":"https://huggingface.co/Bretagne","description":"\\nDataset origin: https://zenodo.org/records/4012218\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDescription\\n\\t\\n\\nDictionnaire breton-fran√ßais Apertium de Tyers que nous avons nettoy√© (suppressions des duplications).\\n\\n\\t\\n\\t\\t\\n\\t\\tCitation\\n\\t\\n\\nCopyright (C) 2008--2011 Francis Tyers Copyright (C) 2009--2011 Fulup Jakez Copyright (C) 2009 Gwenvael Jekel Development supported by: * Prompsit Language Engineering, S. L. * Ofis ar Brezhoneg * Grup Transducens, Universitat d'Alacant\\n\\n"},
  {"name":"post_ocr_correction-512","keyword":"french","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/jeanflop/post_ocr_correction-512","creator_name":"lompo","creator_url":"https://huggingface.co/jeanflop","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSynthetic OCR Correction Dataset <700 input length\\n\\t\\n\\nThis dataset is a synthetic dataset generated for post-OCR correction tasks. It contains over 1,000,000 rows of French text pairs and follows the Croissant format. It is designed to train small language models (LLMs) for text correction.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDescription\\n\\t\\n\\nTo ensure the dataset closely resembles OCR-malformed texts, we applied various transformations randomly. This approach helps avoid the LLM identifying specific‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/jeanflop/post_ocr_correction-512."},
  {"name":"french_last_names_insee_2024","keyword":"french","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/eltorio/french_last_names_insee_2024","creator_name":"Ronan L.M.","creator_url":"https://huggingface.co/eltorio","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tFrench Last Names from Death Records (1970-2024)\\n\\t\\n\\nThis dataset contains French lasst names extracted from death records provided by INSEE (French National Institute of Statistics and Economic Studies) covering the period from 1970 to September 2024.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tRandom name generator demo\\n\\t\\n\\ngo to https://sctg-development.github.io/french-names-extractor/\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Source\\n\\t\\n\\nThe data is sourced from INSEE's death records database. It‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/eltorio/french_last_names_insee_2024."},
  {"name":"Prenoms","keyword":"french","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/ethanker/Prenoms","creator_name":"Ethan KERDELHUE","creator_url":"https://huggingface.co/ethanker","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tBase de Donn√©es des Pr√©noms Fran√ßais\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDescription du Dataset\\n\\t\\n\\nCette base de donn√©es contient des informations sur les pr√©noms attribu√©s en France, incluant des donn√©es historiques de 1900 √† 2023. Elle recense la fr√©quence d'attribution des pr√©noms par d√©partement, par ann√©e de naissance et par sexe.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tChamps de Donn√©es\\n\\t\\n\\n\\nYOB (Ann√©e de Naissance) : Ann√©e de naissance\\nSEXE : Genre (Masculin/F√©minin/Non sp√©cifi√©)\\nPRENOM : Code du pr√©nom original‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ethanker/Prenoms."},
  {"name":"testing-wiki-structured","keyword":"french","license":"Creative Commons Attribution Share Alike 4.0 International","language":"en","url":"https://huggingface.co/datasets/VoeTheDon/testing-wiki-structured","creator_name":"Luvo Dlulisa","creator_url":"https://huggingface.co/VoeTheDon","description":"this is a testing dataset for myself. \\n"},
  {"name":"bbh-fr","keyword":"french","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/le-leadboard/bbh-fr","creator_name":"le-leadboard","creator_url":"https://huggingface.co/le-leadboard","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for bbh-fr\\n\\t\\n\\nle-leadboard/bbh-fr fait partie de l'initiative OpenLLM French Leaderboard, proposant une adaptation fran√ßaise du benchmark BIG-Bench Hard (BBH).\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nBBH-fr est l'adaptation fran√ßaise d'une suite de 23 t√¢ches BIG-Bench particuli√®rement exigeantes. Ces t√¢ches ont √©t√© s√©lectionn√©es car elles repr√©sentaient initialement des d√©fis o√π les mod√®les de langage n'atteignaient pas les performances humaines moyennes.\\nCat√©gories de t√¢ches‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/le-leadboard/bbh-fr."},
  {"name":"MATH_LVL5_fr","keyword":"french","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/le-leadboard/MATH_LVL5_fr","creator_name":"le-leadboard","creator_url":"https://huggingface.co/le-leadboard","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for MATH_LVL5_fr\\n\\t\\n\\nle-leadboard/MATH_LVL5_fr fait partie de l'initiative OpenLLM French Leaderboard, proposant une adaptation fran√ßaise des probl√®mes math√©matiques de niveau avanc√© du dataset MATH.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nMATH_LVL5_fr est une adaptation fran√ßaise des probl√®mes math√©matiques de niveau 5 (le plus avanc√©) du dataset MATH original. Il comprend des probl√®mes de comp√©tition math√©matique de niveau lyc√©e, format√©s de mani√®re coh√©rente avec LaTeX pour‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/le-leadboard/MATH_LVL5_fr."},
  {"name":"MATH_LVL5_fr","keyword":"french","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/le-leadboard/MATH_LVL5_fr","creator_name":"le-leadboard","creator_url":"https://huggingface.co/le-leadboard","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for MATH_LVL5_fr\\n\\t\\n\\nle-leadboard/MATH_LVL5_fr fait partie de l'initiative OpenLLM French Leaderboard, proposant une adaptation fran√ßaise des probl√®mes math√©matiques de niveau avanc√© du dataset MATH.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nMATH_LVL5_fr est une adaptation fran√ßaise des probl√®mes math√©matiques de niveau 5 (le plus avanc√©) du dataset MATH original. Il comprend des probl√®mes de comp√©tition math√©matique de niveau lyc√©e, format√©s de mani√®re coh√©rente avec LaTeX pour‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/le-leadboard/MATH_LVL5_fr."},
  {"name":"MMMLU-fr","keyword":"french","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/le-leadboard/MMMLU-fr","creator_name":"le-leadboard","creator_url":"https://huggingface.co/le-leadboard","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for MMMLU-fr\\n\\t\\n\\nle-leadboard/MMMLU-fr fait partie de l'initiative OpenLLM French Leaderboard, proposant une adaptation fran√ßaise du benchmark MMMLU (Multilingual Massive Multitask Language Understanding) d√©velopp√© initialement par OpenAI dataset.c'est un clone exact de la division fran√ßaise du jeu de donn√©es MMMLU\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nMMMLU-fr est l'adaptation fran√ßaise du benchmark MMMLU, int√©grant des questions plus complexes ax√©es sur le raisonnement avec‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/le-leadboard/MMMLU-fr."},
  {"name":"product-database","keyword":"french","license":"GNU Affero General Public License v3.0","language":"en","url":"https://huggingface.co/datasets/openfoodfacts/product-database","creator_name":"Open Food Facts","creator_url":"https://huggingface.co/openfoodfacts","description":"\\n\\t\\n\\t\\t\\n\\t\\tOpen Food Facts Database\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tWhat is üçä Open Food Facts?\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tA food products database\\n\\t\\n\\nOpen Food Facts is a database of food products with ingredients, allergens, nutrition facts and all the tidbits of information we can find on product labels.\\n\\n\\t\\n\\t\\t\\n\\t\\tMade by everyone\\n\\t\\n\\nOpen Food Facts is a non-profit association of volunteers. 25.000+ contributors like you have added 1.7 million + products from 150 countries using our Android or iPhone app or their camera to scan‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/openfoodfacts/product-database."},
  {"name":"Newspapers-finlam","keyword":"french","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/Teklia/Newspapers-finlam","creator_name":"Teklia","creator_url":"https://huggingface.co/Teklia","description":"\\n\\t\\n\\t\\t\\n\\t\\tNewspaper segmentation dataset: Finlam\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThe Finlam dataset includes 149 French newspapers from the 19th to 20th centuries. \\nEach newspaper contains multiple pages. Page images are resized to a fixed height of 2000 pixels.\\nEach page contains multiple zones, with different information such as polygon, text, class, and order.\\n\\n\\t\\n\\t\\t\\n\\t\\tSplit\\n\\t\\n\\n\\n\\t\\n\\t\\t\\nset\\nimages\\nnewspapers\\n\\n\\n\\t\\t\\ntrain\\n623\\n129\\n\\n\\nval\\n50\\n10\\n\\n\\ntest\\n48\\n10\\n\\n\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tLanguages\\n\\t\\n\\nMost newspapers in‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Teklia/Newspapers-finlam."},
  {"name":"global-festivals-translated","keyword":"french","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/azminetoushikwasi/global-festivals-translated","creator_name":"Azmine Toushik Wasi","creator_url":"https://huggingface.co/azminetoushikwasi","description":"azminetoushikwasi/global-festivals-translated dataset hosted on Hugging Face and contributed by the HF Datasets community"},
  {"name":"br_fr_en_translation","keyword":"french","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/Bretagne/br_fr_en_translation","creator_name":"Bretagne","creator_url":"https://huggingface.co/Bretagne","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDescription\\n\\t\\n\\nIl s'agit du jeu de donn√©es cvqa_br_fr_en o√π seuls les textes align√©s br/fr/en sont gard√©s afin de constituer un jeu de donn√©es de traduction automatique qui soit plus l√©ger √† t√©l√©charger.405 textes de types \\\"questions\\\" et 405 textes de type \\\"options\\\" sont disponibles.\\n"},
  {"name":"rhapsodie","keyword":"french","license":"Creative Commons Zero v1.0 Universal","language":"en","url":"https://huggingface.co/datasets/datasets-CNRS/rhapsodie","creator_name":"datasets-CNRS","creator_url":"https://huggingface.co/datasets-CNRS","description":"\\nDataset origin: https://www.ortolang.fr/market/corpora/rhapsodie\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDescription\\n\\t\\n\\nCorpus de fran√ßais parl√© annot√© pour la prosodie et la syntaxe\\nUn probl√®me central dans l‚Äô√©tude des langues parl√©es est la compr√©hension du r√¥le que jouent les indices intonosyntaxiques dans la segmentation du continuum sonore en unit√©s informationnelles et discursives. Se posent notamment les questions suivantes : quel est le degr√© de congruence entre les diff√©rentes unit√©s manipul√©es par la syntaxe et‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/datasets-CNRS/rhapsodie."},
  {"name":"lemone-docs-embedded","keyword":"french","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/louisbrulenaudet/lemone-docs-embedded","creator_name":"Louis Brul√© Naudet","creator_url":"https://huggingface.co/louisbrulenaudet","description":"\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLemone-embedded, pre-built embeddings dataset for French taxation.\\n\\t\\n\\n\\n    This database presents the embeddings generated by the Lemone-embed-pro model and aims at a large-scale distribution of the model even for the GPU-poor.\\n\\n\\nThis sentence transformers model, specifically designed for French taxation, has been fine-tuned on a dataset comprising 43 million tokens, integrating a blend of semi-synthetic and fully synthetic data generated by GPT-4 Turbo and Llama 3.1 70B, which‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/louisbrulenaudet/lemone-docs-embedded."},
  {"name":"test_4","keyword":"french","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/tunngo/test_4","creator_name":"nguyen tuan","creator_url":"https://huggingface.co/tunngo","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tFLEURS\\n\\t\\n\\nFleurs is the speech version of the FLoRes machine translation benchmark. \\nWe use 2009 n-way parallel sentences from the FLoRes dev and devtest publicly available sets, in 102 languages. \\nTraining sets have around 10 hours of supervision. Speakers of the train sets are different than speakers from the dev/test sets. Multilingual fine-tuning is\\nused and ‚Äùunit error rate‚Äù (characters, signs) of all languages is averaged. Languages and results are also grouped into seven‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/tunngo/test_4."},
  {"name":"prompt-injection-multilingual","keyword":"french","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/rikka-snow/prompt-injection-multilingual","creator_name":"Le Xuan Hoang","creator_url":"https://huggingface.co/rikka-snow","description":"rikka-snow/prompt-injection-multilingual dataset hosted on Hugging Face and contributed by the HF Datasets community"},
  {"name":"post_ocr_correction2","keyword":"french","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/jeanflop/post_ocr_correction2","creator_name":"lompo","creator_url":"https://huggingface.co/jeanflop","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSynthetic OCR Correction Dataset\\n\\t\\n\\nThis dataset is a synthetic dataset generated for post-OCR correction tasks. It contains over 2,000,000 rows of French text pairs and follows the Croissant format. It is designed to train small language models (LLMs) for text correction.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDescription\\n\\t\\n\\nTo ensure the dataset closely resembles OCR-malformed texts, we applied various transformations randomly. This approach helps avoid the LLM identifying specific patterns and encourages‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/jeanflop/post_ocr_correction2."},
  {"name":"gatitos_br_fr_en","keyword":"french","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/Bretagne/gatitos_br_fr_en","creator_name":"Bretagne","creator_url":"https://huggingface.co/Bretagne","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDescription\\n\\t\\n\\nAlignement des parties en breton, fran√ßais et anglais du jeu de donn√©es Gatitos afin de cr√©er un jeu de donn√©es de traduction.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tCitation\\n\\t\\n\\n@misc{jones2023bilexrxlexicaldata,\\n      title={Bilex Rx: Lexical Data Augmentation for Massively Multilingual Machine Translation}, \\n      author={Alex Jones and Isaac Caswell and Ishank Saxena and Orhan Firat},\\n      year={2023},\\n      eprint={2303.15265},\\n      archivePrefix={arXiv},\\n      primaryClass={cs.CL}‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Bretagne/gatitos_br_fr_en."},
  {"name":"test_dataset","keyword":"french","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/ImValll/test_dataset","creator_name":"Valentin HENRY","creator_url":"https://huggingface.co/ImValll","description":"Dataset de test pour v√©rifier le fonctionnement du fine-tunning\\n"},
  {"name":"vdsid_french","keyword":"french","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/vidore/vdsid_french","creator_name":"ILLUIN Vidore","creator_url":"https://huggingface.co/vidore","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVDSID-French: Vision Retrieval Dataset on French documents\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tOverview\\n\\t\\n\\nVDSID-French is a subset of the vidore/vdsid dataset. It contains 5000 document-question-answer triplet of French documents, split into a train set of 4700 examples and a test set of 300 examples.\\nThis dataset was created as ColPali was mainly trained on English documents, so fine-tuning on French documents can help to improve the multilingual capabilities of the model.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Fields‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/vidore/vdsid_french."},
  {"name":"xtreme-up-semantic-parsing","keyword":"french","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/Davlan/xtreme-up-semantic-parsing","creator_name":"David Adelani","creator_url":"https://huggingface.co/Davlan","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for afrixnli\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nSee XTREME-UP GitHub\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages\\n\\t\\n\\nThere are 20 languages available :\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Structure\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Instances\\n\\t\\n\\nThe examples look like this for English:\\nfrom datasets import load_dataset\\ndata = load_dataset('Davlan/xtreme-up-semantic-parsing', 'yor') \\n# Please, specify the language code\\n# A data point example is below:\\n{\\n\\\"id\\\": \\\"3231323330393336\\\",\\n\\\"split\\\": \\\"test\\\",\\n\\\"intent\\\": \\\"IN:GET_REMINDER\\\"‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Davlan/xtreme-up-semantic-parsing."},
  {"name":"cml-tts-filtered","keyword":"french","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/PHBJT/cml-tts-filtered","creator_name":"Paul Henri Biojout","creator_url":"https://huggingface.co/PHBJT","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Filtred and CML-TTS\\n\\t\\n\\nThis dataset is a filtred version of a CML-TTS [1]. \\nCML-TTS [1] CML-TTS is a recursive acronym for CML-Multi-Lingual-TTS, a Text-to-Speech (TTS) dataset developed at the Center of Excellence in Artificial Intelligence (CEIA) of the Federal University of Goias (UFG). CML-TTS is a dataset comprising audiobooks sourced from the public domain books of Project Gutenberg, read by volunteers from the LibriVox project. The dataset includes‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/PHBJT/cml-tts-filtered."},
  {"name":"wsdm2024-cot-dataset","keyword":"french","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/ruggsea/wsdm2024-cot-dataset","creator_name":"Ruggero Marino Lazzaroni","creator_url":"https://huggingface.co/ruggsea","description":"This dataset is created by ruggsea for the WSDM 2024 competition. It is a semisynthetic dataset created by asking Llama 3.1 70B to generate rationales for the responses to the prompts in the WSDM 2024 competition. \\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tColumns\\n\\t\\n\\n\\nid: Unique identifier for each example\\nprompt: The input prompt given to the model\\nresponse_a: First response option\\nresponse_b: Second response option\\nwinner: The winning response (0 or 1)\\nrationale: The rationale generated by Llama 3.1 70B explaining why‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ruggsea/wsdm2024-cot-dataset."},
  {"name":"gridding","keyword":"french","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/cyrildever/gridding","creator_name":"Cyril Dever","creator_url":"https://huggingface.co/cyrildever","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tgridding datasets\\n\\t\\n\\nDonn√©es permettant d'effectuer des analyses au carreau pour la France m√©tropolitaine via la biblioth√®que Python gridding-py.\\n"},
  {"name":"llm-ideology-analysis","keyword":"french","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/aida-ugent/llm-ideology-analysis","creator_name":"Ghent University Artificial Intelligence & Data Analytics Group","creator_url":"https://huggingface.co/aida-ugent","description":"This dataset contains evaluations of political figures by a diverse set of Large Language Models (LLMs), such that the ideology of these LLMs can be characterized.\\n\\n\\t\\n\\t\\t\\n\\t\\tüìù Dataset Description\\n\\t\\n\\nThe dataset contains responses from 19 different Large Language Models evaluating 3,991 political figures, with responses collected in the six UN languages: Arabic, Chinese, English, French, Russian, and Spanish. \\nThe evaluations were conducted using a two-stage prompting strategy to assess the‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/aida-ugent/llm-ideology-analysis."},
  {"name":"histoire-coloniale-postcoloniale-de-la-france","keyword":"french","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/Svngoku/histoire-coloniale-postcoloniale-de-la-france","creator_name":"NIONGOLO Chrys F√©-Marty","creator_url":"https://huggingface.co/Svngoku","description":"\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tL‚Äôhistoire de la colonisation fran√ßaise\\n\\t\\n\\nDepuis les ann√©es 2000, la m√©moire et l‚Äôhistoire de la colonisation continuent de susciter des d√©bats dans l‚Äôactualit√© fran√ßaise, tout comme dans d‚Äôautres anciennes m√©tropoles coloniales occidentales et les anciennes colonies. Cela a engendr√© une demande croissante d‚Äôinformations historiques, tant de la part d‚Äôun public large que des sp√©cialistes, notamment les universitaires.\\nPour r√©pondre √† cette demande et refl√©ter le renouveau‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Svngoku/histoire-coloniale-postcoloniale-de-la-france."},
  {"name":"french-instruction-dataset","keyword":"french","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/vonewman/french-instruction-dataset","creator_name":"Abdoulaye Diallo","creator_url":"https://huggingface.co/vonewman","description":"vonewman/french-instruction-dataset dataset hosted on Hugging Face and contributed by the HF Datasets community"},
  {"name":"fr-qa-accounting-edits","keyword":"french","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/Tiime/fr-qa-accounting-edits","creator_name":"Tiime","creator_url":"https://huggingface.co/Tiime","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nCorpus of post-edited llm answers to accounting questions. We provide human edits with associated edit time, but also synthetic (LLM) edits following various scenarios.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tHow to Use\\n\\t\\n\\nfrom datasets import load_dataset\\n\\nhuman_edits = load_dataset(\\\"Tiime/fr-qa-accounting-edits\\\", name=\\\"human_edits\\\")\\n\\nsynthetic_edits = load_dataset(\\\"Tiime/fr-qa-accounting-edits\\\", name=\\\"synthetic_edits\\\")\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tCitation\\n\\t\\n\\nIf you use our dataset, please cite us at:‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Tiime/fr-qa-accounting-edits."},
  {"name":"health-canada-drug-products-database","keyword":"french","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/OnDeviceMedNotes/health-canada-drug-products-database","creator_name":"On Device Medical Notes","creator_url":"https://huggingface.co/OnDeviceMedNotes","description":"#Public Health Canada \\n##Drug Products Database Dump \\nThis is publicly accessible open data uploaded here for easy of use. \\nFiles can also directly be downloaded from here:\\nhttps://health-products.canada.ca/api/drug/\\nUpdated as of January 5 2025\\n"},
  {"name":"noisy-gt-missing-words","keyword":"french","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/alix-tz/noisy-gt-missing-words","creator_name":"Alix Chagu√©","creator_url":"https://huggingface.co/alix-tz","description":"\\n\\t\\n\\t\\t\\n\\t\\tNoisy Ground Truth - Missing Words\\n\\t\\n\\nDataset of synthetic data for experimentation with noisy ground truth. The text in the dataset is based on Colette's Sido and Les Vignes, also the data was processed prior to generating images with the TextRecognitionDataGenerator.\\nIn Noisy Ground Truth - Missing Words, each variation column is affected by the noise, without considering the split between train, validation and test.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData structure\\n\\t\\n\\nThe dataset is composed of the‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/alix-tz/noisy-gt-missing-words."},
  {"name":"eeg","keyword":"french","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/opsecsystems/eeg","creator_name":"Opsec Systems","creator_url":"https://huggingface.co/opsecsystems","description":"opsecsystems/eeg dataset hosted on Hugging Face and contributed by the HF Datasets community"},
  {"name":"multiCHILDES","keyword":"french","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/IParraMartin/multiCHILDES","creator_name":"I√±igo Parra","creator_url":"https://huggingface.co/IParraMartin","description":"\\n\\t\\n\\t\\t\\n\\t\\tmultiCHILDES: Multilingual Child-Directed Speech Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThis dataset contains child-directed speech from 19 languages, extracted from the CHILDES corpus. The text has been cleaned and is designed for text generation tasks, particularly in studying early language acquisition.\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Details\\n\\t\\n\\n\\nSource: CHILDES corpus\\nLanguages: 19 languages\\nText Type: Child-directed speech\\nTask: Text Generation, Language Modeling\\nData Processing: The dataset‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/IParraMartin/multiCHILDES."},
  {"name":"BenchMAX_Question_Answering","keyword":"french","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/LLaMAX/BenchMAX_Question_Answering","creator_name":"LLaMAX","creator_url":"https://huggingface.co/LLaMAX","description":"\\n\\t\\n\\t\\t\\n\\t\\tDataset Sources\\n\\t\\n\\n\\nPaper: BenchMAX: A Comprehensive Multilingual Evaluation Suite for Large Language Models\\nLink: https://arxiv.org/pdf/2502.07346\\nRepository: https://github.com/CONE-MT/BenchMAX\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\nBenchMAX_Function_Completion is a dataset of BenchMAX, sourcing from UN Parallel Corpus and xquad.\\nThe haystacks are from UN Parallel Corpus Test and Development Sets and we translate them to other languages by Google Translate.\\nThe multilingual QA data is from‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/LLaMAX/BenchMAX_Question_Answering."},
  {"name":"gpt2_codePenalDataset","keyword":"french","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/AssemienDev/gpt2_codePenalDataset","creator_name":"Sidjane Assemien Henri Osee","creator_url":"https://huggingface.co/AssemienDev","description":"AssemienDev/gpt2_codePenalDataset dataset hosted on Hugging Face and contributed by the HF Datasets community"},
  {"name":"french-ghomala-bandjoun-llm-ready","keyword":"french","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/stfotso/french-ghomala-bandjoun-llm-ready","creator_name":"Steve TUENO","creator_url":"https://huggingface.co/stfotso","description":"French to ghomala translation dataset optimized for IBM Granite LLM tuning\\n"},
  {"name":"dataset_outscale","keyword":"french","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/yann23/dataset_outscale","creator_name":"kofd","creator_url":"https://huggingface.co/yann23","description":"\\n\\t\\n\\t\\t\\n\\t\\tüìä Dataset_Outscale\\n\\t\\n\\nCe dataset contient des donn√©es d'API au format JSONL et Parquet, avec des variantes de questions et leurs r√©ponses associ√©es.\\n\\n\\t\\n\\t\\t\\n\\t\\tüìÇ Structure des Fichiers\\n\\t\\n\\n\\ndata.parquet : Dataset principal au format Parquet\\ndataset_base.jsonl : Donn√©es de base\\ndataset_dpo.jsonl et dataset_dpo.parquet : Format DPO avec paires chosen/rejected\\ndataset_avec_variantes.jsonl : Donn√©es avec variantes de questions\\ndataset_final.parquet : Dataset final au format Parquet‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/yann23/dataset_outscale."},
  {"name":"M-ABSA","keyword":"french","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/Multilingual-NLP/M-ABSA","creator_name":"multilingual-NLP","creator_url":"https://huggingface.co/Multilingual-NLP","description":"\\n\\t\\n\\t\\t\\n\\t\\tM-ABSA\\n\\t\\n\\nThis repo contains the data for our paper M-ABSA: A Multilingual Dataset for Aspect-Based Sentiment Analysis.\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tData Description:\\n\\t\\n\\nThis is a dataset suitable for the multilingual ABSA task with triplet extraction.\\nAll datasets are stored in the data/ folder:\\n\\nAll dataset contains 7 domains.\\n\\ndomains = [\\\"coursera\\\", \\\"hotel\\\", \\\"laptop\\\", \\\"restaurant\\\", \\\"phone\\\", \\\"sight\\\", \\\"food\\\"]\\n\\n\\nEach dataset contains 21 languages.\\n\\nlangs = [\\\"ar\\\", \\\"da\\\", \\\"de\\\", \\\"en\\\", \\\"es\\\", \\\"fr\\\", \\\"hi\\\", \\\"hr\\\"‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Multilingual-NLP/M-ABSA."},
  {"name":"OCR-neulab-PangeaInstruct-OCR-clean","keyword":"french","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/lbourdois/OCR-neulab-PangeaInstruct-OCR-clean","creator_name":"Lo√Øck BOURDOIS","creator_url":"https://huggingface.co/lbourdois","description":"\\n\\t\\n\\t\\t\\n\\t\\tDescription\\n\\t\\n\\nFrench part of the neulab/PangeaInstruct dataset (OCR data only) that we processed for a visual question answering task where answer is a caption.\\n\\n\\t\\n\\t\\t\\n\\t\\tCitation\\n\\t\\n\\n@article{yue2024pangeafullyopenmultilingual,\\n  title={Pangea: A Fully Open Multilingual Multimodal LLM for 39 Languages},\\n  author={Xiang Yue and Yueqi Song and Akari Asai and Seungone Kim and Jean de Dieu Nyandwi and Simran Khanuja and Anjali Kantharuban and Lintang Sutawika and Sathyanarayanan Ramamoorthy‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/lbourdois/OCR-neulab-PangeaInstruct-OCR-clean."},
  {"name":"sft-set-administratif-def-6996","keyword":"french","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/jpacifico/sft-set-administratif-def-6996","creator_name":"Jonathan Pacifico","creator_url":"https://huggingface.co/jpacifico","description":"jpacifico/sft-set-administratif-def-6996 dataset hosted on Hugging Face and contributed by the HF Datasets community"},
  {"name":"caption-vidore-tabfquad_test_subsampled-clean","keyword":"french","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/CATIE-AQ/caption-vidore-tabfquad_test_subsampled-clean","creator_name":"CATIE","creator_url":"https://huggingface.co/CATIE-AQ","description":"\\n\\t\\n\\t\\t\\n\\t\\tDescription\\n\\t\\n\\nvidore/tabfquad_test_subsampled dataset that we processed for a visual question answering task where answer is a caption.\\n\\n\\t\\n\\t\\t\\n\\t\\tCitation\\n\\t\\n\\n@misc{faysse2024colpaliefficientdocumentretrieval,\\n      title={ColPali: Efficient Document Retrieval with Vision Language Models}, \\n      author={Manuel Faysse and Hugues Sibille and Tony Wu and Bilel Omrani and Gautier Viaud and C√©line Hudelot and Pierre Colombo},\\n      year={2024},\\n      eprint={2407.01449}‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/CATIE-AQ/caption-vidore-tabfquad_test_subsampled-clean."},
  {"name":"caption-floschne-xm3600-clean","keyword":"french","license":"Creative Commons Attribution Share Alike 4.0 International","language":"en","url":"https://huggingface.co/datasets/CATIE-AQ/caption-floschne-xm3600-clean","creator_name":"CATIE","creator_url":"https://huggingface.co/CATIE-AQ","description":"\\n\\t\\n\\t\\t\\n\\t\\tDescription\\n\\t\\n\\nFrench part of the floschne/xm3600 dataset that we processed for a visual question answering task where answer is a caption.\\n\\n\\t\\n\\t\\t\\n\\t\\tCitation\\n\\t\\n\\n@inproceedings{ThapliyalCrossmodal2022,\\n  author = {Ashish Thapliyal and Jordi Pont-Tuset and Xi Chen and Radu Soricut},\\n  title = {{Crossmodal-3600: A Massively Multilingual Multimodal Evaluation Dataset}},\\n  booktitle = {EMNLP},\\n  year = {2022}\\n}\\n\\n"},
  {"name":"test","keyword":"french","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/Ehsanl/test","creator_name":"Ehsan","creator_url":"https://huggingface.co/Ehsanl","description":"Ehsanl/test dataset hosted on Hugging Face and contributed by the HF Datasets community"},
  {"name":"Wikipedia-Abstract","keyword":"french","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/laion/Wikipedia-Abstract","creator_name":"LAION eV","creator_url":"https://huggingface.co/laion","description":"Wikipedia Abstract\\n\\n\\n  \\n\\n\\n\\nIntroducing Wikipedia Abstract, a comprehensive dataset encompassing abstracts, complete articles, and a popularity score index for both widely spoken and lesser-known Wikipedia subsets. Our dedication to Wikipedia-X ensures a centralized Wikipedia dataset that undergoes regular updates and adheres to the highest standards.\\nA central focus of our efforts was to include exotic languages that often lack up-to-date Wikipedia dumps or may not have any dumps at all.‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/laion/Wikipedia-Abstract."},
  {"name":"PELLET-Casimir-Marius-line","keyword":"french","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/Teklia/PELLET-Casimir-Marius-line","creator_name":"Teklia","creator_url":"https://huggingface.co/Teklia","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tPELLET Casimir Marius - Line level\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThe PELLET Casimir Marius dataset includes 100 annotated French letters written between 1914 and 1918.\\nAnnotations were done at line-level and all images do not have any text.\\nNote that all images are resized to a fixed height of 128 pixels.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages\\n\\t\\n\\nAll the documents in the dataset are written in French.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Structure\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Instances\\n\\t\\n\\n{\\n  'image':‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Teklia/PELLET-Casimir-Marius-line."},
  {"name":"KCLLM","keyword":"french","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/kcmki/KCLLM","creator_name":"mohamed elmekki belaissaoui","creator_url":"https://huggingface.co/kcmki","description":"This project isn't affiliated with the Karmine corp organisation.\\nIt's a fan project created using the data collected from the Wikipedia page of the Karmine corp.\\nThe dataset content isn't perfect it was created using ChatGPT prompt engineering.\\n"},
  {"name":"multilingual_refusals","keyword":"french","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/s-nlp/multilingual_refusals","creator_name":"s-nlp","creator_url":"https://huggingface.co/s-nlp","description":"\\n\\t\\n\\t\\t\\n\\t\\tData description\\n\\t\\n\\nThis dataset is designed to train and evaluate models for the task of refusal detection in generated responses. The dataset consists of input prompts sourced from the lmsys/lmsys-chat-1m collection, encompassing a variety of languages including English, German, French, Russian, and Spanish. To increase refusal diversity, the responses and refusals were generated using two models, Gemini Flash 1.5 and LLaMA-3.3-70b.\\nThe dataset is primarily intended to train‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/s-nlp/multilingual_refusals."},
  {"name":"multi30k","keyword":"french","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/romrawinjp/multi30k","creator_name":"Romrawin Chumpu","creator_url":"https://huggingface.co/romrawinjp","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tMulti30k Dataset\\n\\t\\n\\nThis dataset is a rearrangement version of the Multi30k dataset. The dataset was partially retrived from Multi30k original github.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tHow to use\\n\\t\\n\\nThis dataset can be downloaded from datasets library. train, validation, and test set are included in the dataset.\\nfrom datasets import load_dataset\\n\\ndataset = load_dataset(\\\"romrawinjp/multi30k\\\")\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tReference\\n\\t\\n\\nIf you find this dataset beneficial, please directly cite to their incredible work.‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/romrawinjp/multi30k."},
  {"name":"mmmlu_lite","keyword":"french","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/opencompass/mmmlu_lite","creator_name":"OpenCompass","creator_url":"https://huggingface.co/opencompass","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tMMMLU-Lite\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tIntroduction\\n\\t\\n\\nA lite version of the MMMLU dataset, which is an community version of the MMMLU dataset by OpenCompass. Due to the large size of the original dataset (about 200k questions), we have created a lite version of the dataset to make it easier to use. We sample 25 examples from each language subject in the original dataset with fixed seed to ensure reproducibility, finally we have 19950 examples in the lite version of the dataset, which is about‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/opencompass/mmmlu_lite."},
  {"name":"text-moderation-02-multilingual","keyword":"french","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/ifmain/text-moderation-02-multilingual","creator_name":"Mike Afton","creator_url":"https://huggingface.co/ifmain","description":"This dataset is based on Kaggle.It represents a version of @ifmain/text-moderation-410K that has been cleansed of semantically similar values and normalized to a 50/50 ratio of negative and neutral entries.\\nThe dataset contains 1.5M entries (91K * 17 languages).  \\nBefore use, augmentation is recommended! (e.g., character substitution to bypass moderation).\\nFor augmentation, you can use @ifmain/StringAugmentor.  \\nEnjoy using it!\\n"},
  {"name":"Multilingal-sakalt-data","keyword":"french","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/Sakalti/Multilingal-sakalt-data","creator_name":"sakasan","creator_url":"https://huggingface.co/Sakalti","description":"„Éû„É´„ÉÅ„É™„É≥„Ç¨„É´„Éá„Éº„Çø„Çª„ÉÉ„Éà„Åß„Åô„ÄÇmit„É©„Ç§„Çª„É≥„Çπ„Åß„Åô„ÄÇ\\n"},
  {"name":"mlx-french-ghomala-bandjoun","keyword":"french","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/stfotso/mlx-french-ghomala-bandjoun","creator_name":"Steve TUENO","creator_url":"https://huggingface.co/stfotso","description":"French to ghomala translation dataset optimized for MLX tuning\\n"},
  {"name":"French_Grammar_Explanations","keyword":"french","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/Sufi2425/French_Grammar_Explanations","creator_name":"Sufian \\\"CreativeAlloy","creator_url":"https://huggingface.co/Sufi2425","description":"This dataset contains 1500+ French grammar explanations. It's the one I used to train my finetuned LLM called FrenchLlama-3.2-1B-Instruct.\\nYou can use this dataset for your own training purposes & find the aforementioned model on my HuggingFace profile.\\n"},
  {"name":"Korpus-divyezhek-brezhoneg-galleg","keyword":"french","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/Bretagne/Korpus-divyezhek-brezhoneg-galleg","creator_name":"Bretagne","creator_url":"https://huggingface.co/Bretagne","description":"\\n\\t\\n\\t\\t\\n\\t\\tKorpus-divyezhek-brezhoneg-galleg\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDescription\\n\\t\\n\\nLe corpus bilingue breton- fran√ßais de l'Office public de la langue bretonne est un corpus de textes traduits par des traducteurs humains.\\nIl s'agit principalement de documents administratifs, d'articles ou d'expositions.\\nLe jeu de donn√©es original provient de ce r√©pertoire GitHub.\\nNous l'avons nettoy√© (suppression des lignes dupliqu√©es), passant alors de 62 861 lignes indiqu√©es par les auteurs √† 61 503 dans la version‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Bretagne/Korpus-divyezhek-brezhoneg-galleg."},
  {"name":"BP","keyword":"french","license":"European Union Public License 1.1","language":"en","url":"https://huggingface.co/datasets/kgttg/BP","creator_name":"Koala's Guide to the Galaxy","creator_url":"https://huggingface.co/kgttg","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tPayroll Dataset\\n\\t\\n\\n"},
  {"name":"onisep_ideo_fiches_metiers","keyword":"french","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/geoffroycochard/onisep_ideo_fiches_metiers","creator_name":"COCHARD","creator_url":"https://huggingface.co/geoffroycochard","description":"L‚ÄôOnisep collecte et diffuse des informations sur les formations et les professions utiles aux jeunes dans le cadre d‚Äôune d√©marche d‚Äôorientation (primo-orientation ou formation initiale principalement).\\nRenseigner sur les professions, c‚Äôest notamment s‚Äôappuyer sur un r√©f√©rentiel m√©tiers suffisamment pr√©cis, et pouvoir relier ces m√©tiers avec les formations conseill√©es ou requises pour pouvoir acc√©der √† ces m√©tiers.\\n"},
  {"name":"musr-fr","keyword":"french","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/le-leadboard/musr-fr","creator_name":"le-leadboard","creator_url":"https://huggingface.co/le-leadboard","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for musr-fr\\n\\t\\n\\nle-leadboard/musr-fr fait partie de l'initiative OpenLLM French Leaderboard, proposant une adaptation fran√ßaise du benchmark MuSR (Multistep Soft Reasoning).\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nMuSR-fr √©value les capacit√©s de raisonnement multietape des LLMs √† travers des narratifs en langage naturel. Le dataset se distingue par sa g√©n√©ration via un algorithme neurosymbolique synth√©tique-naturel unique, cr√©ant des instances de raisonnement complexes (comme‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/le-leadboard/musr-fr."},
  {"name":"AyaVisionBench","keyword":"french","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/CohereForAI/AyaVisionBench","creator_name":"Cohere For AI","creator_url":"https://huggingface.co/CohereForAI","description":"\\n\\t\\n\\t\\t\\n\\t\\tDataset Card for Aya Vision Benchmark\\n\\t\\n\\n\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Details\\n\\t\\n\\nThe Aya Vision Benchmark is designed to evaluate vision-language models in real-world multilingual scenarios. It spans 23 languages and 9 distinct task categories, with 15 samples per category, resulting in 135 image-question pairs per language. \\nEach question requires visual context for the answer and covers languages that half of the world's population speaks, making this dataset particularly suited for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/CohereForAI/AyaVisionBench."},
  {"name":"webfaq","keyword":"french","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/PaDaS-Lab/webfaq","creator_name":"Chair of Data Science, University of Passau","creator_url":"https://huggingface.co/PaDaS-Lab","description":"WebFAQ Q&A Dataset\\n\\n   \\n       Overview |\\n       Details  |\\n       Structure  |\\n       Examples |\\n       Considerations |\\n       License |\\n       Citation |\\n       Contact |\\n       Acknowledgement\\n   \\n\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tOverview\\n\\t\\n\\nThe WebFAQ Q&A Dataset is a broad-coverage corpus of 96 million natural question-answer (QA) pairs in 75 languages, gathered from FAQ pages on the web. It leverages structured schema.org FAQPage annotations, making it a unique resource for large-scale Question Answering‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/PaDaS-Lab/webfaq."},
  {"name":"oasst1","keyword":"french","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/OpenAssistant/oasst1","creator_name":"OpenAssistant","creator_url":"https://huggingface.co/OpenAssistant","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tOpenAssistant Conversations Dataset (OASST1)\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nIn an effort to democratize research on large-scale alignment, we release OpenAssistant \\nConversations (OASST1), a human-generated, human-annotated assistant-style conversation \\ncorpus consisting of 161,443 messages in 35 different languages, annotated with 461,292 \\nquality ratings, resulting in over 10,000 fully annotated conversation trees. The corpus \\nis a product of a worldwide crowd-sourcing effort‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/OpenAssistant/oasst1."},
  {"name":"Everything_Instruct_Multilingual","keyword":"french","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/rombodawg/Everything_Instruct_Multilingual","creator_name":"rombo dawg","creator_url":"https://huggingface.co/rombodawg","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tEverything Instruct (Multilingual Edition)\\n\\t\\n\\nEverything you need... all in one place üíò\\n\\nEverything instruct (Multilingual Edition) is a massive alpaca instruct formatted dataset consisting of a wide variety of topics meant to bring LLM's to the next level in open source AI.\\nNote: This dataset is fully uncensored (No model will refuse any request trained on this dataset unless otherwise aligned)\\nNote2: This version of the dataset supports the following languages:\\n\\nEnglish\\nRussian‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/rombodawg/Everything_Instruct_Multilingual."},
  {"name":"oasst2","keyword":"french","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/OpenAssistant/oasst2","creator_name":"OpenAssistant","creator_url":"https://huggingface.co/OpenAssistant","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tOpen Assistant Conversations Dataset Release 2 (OASST2)\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Structure\\n\\t\\n\\nThis dataset contains message trees. Each message tree has an initial prompt message as the root node, \\nwhich can have multiple child messages as replies, and these child messages can have multiple replies. \\nAll messages have a role property: this can either be \\\"assistant\\\" or \\\"prompter\\\". The roles in \\nconversation threads from prompt to leaf node strictly alternate between \\\"prompter\\\" and‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/OpenAssistant/oasst2."},
  {"name":"Global-MMLU","keyword":"french","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/CohereForAI/Global-MMLU","creator_name":"Cohere For AI","creator_url":"https://huggingface.co/CohereForAI","description":"\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nGlobal-MMLU üåç is a multilingual evaluation set spanning 42 languages, including English. This dataset combines machine translations for MMLU questions along with professional translations and crowd-sourced post-edits.\\nIt also includes cultural sensitivity annotations for a subset of the questions (2850 questions per language) and classifies them as Culturally Sensitive (CS) üóΩ or Culturally Agnostic (CA) ‚öñÔ∏è. These annotations were collected as part of an open‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/CohereForAI/Global-MMLU."},
  {"name":"reasoning-multilingual-R1-Llama-70B-train","keyword":"french","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/lightblue/reasoning-multilingual-R1-Llama-70B-train","creator_name":"Lightblue KK.","creator_url":"https://huggingface.co/lightblue","description":"\\n\\t\\n\\t\\t\\n\\t\\tlightblue/reasoning-multilingual-R1-Llama-70B-train\\n\\t\\n\\nThis is a multilingual reasoning dataset covering more than 30 languages.\\nThis dataset was made by:\\n\\nSampling prompts from English datasets and translating them to various languages\\nGenerating responses to these prompts 8 times using deepseek-ai/DeepSeek-R1-Distill-Llama-70B\\nFiltering out <think> sections with incorrect language, non-fluent language, and incorrect answers\\n\\nThis dataset was then used to train a multilingual‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/lightblue/reasoning-multilingual-R1-Llama-70B-train."},
  {"name":"wmt24pp","keyword":"french","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/google/wmt24pp","creator_name":"Google","creator_url":"https://huggingface.co/google","description":"\\n\\t\\n\\t\\t\\n\\t\\tWMT24++\\n\\t\\n\\nThis repository contains the human translation and post-edit data for the 55 en->xx language pairs released in\\nthe publication\\nWMT24++: Expanding the Language Coverage of WMT24 to 55 Languages & Dialects.\\nIf you are interested in the MT/LLM system outputs and automatic metric scores, please see MTME.\\nIf you are interested in the images of the source URLs for each document, please see here.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSchema\\n\\t\\n\\nEach language pair is stored in its own jsonl file.\\nEach row is‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/google/wmt24pp."},
  {"name":"dolphin-r1-french","keyword":"french","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/WiroAI/dolphin-r1-french","creator_name":"Wiro AI","creator_url":"https://huggingface.co/WiroAI","description":"\\n  \\n  \\n\\n\\n\\n  \\n    \\n  \\n  \\n    \\n  \\n  \\n    \\n  \\n    \\n  \\n    \\n    \\n  \\n\\n\\n  \\n    \\n  \\n\\n\\n\\n\\t\\n\\t\\n\\t\\n\\t\\tDolphin R1 French üê¨\\n\\t\\n\\n\\nDolphin-R1 is an Apache-2.0 English dataset curated by Eric Hartford and Cognitive Computations\\nDolphin-R1-french is a French subset of the original dataset.\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tSponsors\\n\\t\\n\\nTheir and Wiro AI's appreciation for the generous sponsors of Dolphin R1 - Without whom this dataset could not exist.\\n\\nDria https://x.com/driaforall - Inference Sponsor (DeepSeek)\\nChutes‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/WiroAI/dolphin-r1-french."},
  {"name":"dolphin-r1-french","keyword":"french","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/WiroAI/dolphin-r1-french","creator_name":"Wiro AI","creator_url":"https://huggingface.co/WiroAI","description":"\\n  \\n  \\n\\n\\n\\n  \\n    \\n  \\n  \\n    \\n  \\n  \\n    \\n  \\n    \\n  \\n    \\n    \\n  \\n\\n\\n  \\n    \\n  \\n\\n\\n\\n\\t\\n\\t\\n\\t\\n\\t\\tDolphin R1 French üê¨\\n\\t\\n\\n\\nDolphin-R1 is an Apache-2.0 English dataset curated by Eric Hartford and Cognitive Computations\\nDolphin-R1-french is a French subset of the original dataset.\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tSponsors\\n\\t\\n\\nTheir and Wiro AI's appreciation for the generous sponsors of Dolphin R1 - Without whom this dataset could not exist.\\n\\nDria https://x.com/driaforall - Inference Sponsor (DeepSeek)\\nChutes‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/WiroAI/dolphin-r1-french."},
  {"name":"thinking-multilingual-30-23-small-690","keyword":"french","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/Pinkstack/thinking-multilingual-30-23-small-690","creator_name":"Pinkstack","creator_url":"https://huggingface.co/Pinkstack","description":"\\nBased on OPENO1 math, this is a translated dataset of 30 high quality questions & answers in 23 languages. \\nOr use the \\\"big\\\" version: big 10k rows version\\n"},
  {"name":"conceptnet5","keyword":"french","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/conceptnet5/conceptnet5","creator_name":"conceptnet5","creator_url":"https://huggingface.co/conceptnet5","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Conceptnet5\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nConceptNet is a multilingual knowledge base, representing words and\\nphrases that people use and the common-sense relationships between\\nthem. The knowledge in ConceptNet is collected from a variety of\\nresources, including crowd-sourced resources (such as Wiktionary and\\nOpen Mind Common Sense), games with a purpose (such as Verbosity and\\nnadya.jp), and expert-created resources (such as WordNet and JMDict).\\nYou can browse‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/conceptnet5/conceptnet5."},
  {"name":"exams","keyword":"french","license":"Creative Commons Attribution Share Alike 4.0 International","language":"en","url":"https://huggingface.co/datasets/mhardalov/exams","creator_name":"Momchil Hardalov","creator_url":"https://huggingface.co/mhardalov","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for [Dataset Name]\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nEXAMS is a benchmark dataset for multilingual and cross-lingual question answering from high school examinations. It consists of more than 24,000 high-quality high school exam questions in 16 languages, covering 8 language families and 24 school subjects from Natural Sciences and Social Sciences, among others.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSupported Tasks and Leaderboards\\n\\t\\n\\n[More Information Needed]\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages\\n\\t\\n\\nThe‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mhardalov/exams."},
  {"name":"xtreme","keyword":"french","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/google/xtreme","creator_name":"Google","creator_url":"https://huggingface.co/google","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for \\\"xtreme\\\"\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThe Cross-lingual Natural Language Inference (XNLI) corpus is a crowd-sourced collection of 5,000 test and\\n2,500 dev pairs for the MultiNLI corpus. The pairs are annotated with textual entailment and translated into\\n14 languages: French, Spanish, German, Greek, Bulgarian, Russian, Turkish, Arabic, Vietnamese, Thai, Chinese,\\nHindi, Swahili and Urdu. This results in 112.5k annotated pairs. Each premise can be associated with‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/google/xtreme."},
  {"name":"mfaq","keyword":"french","license":"Creative Commons Zero v1.0 Universal","language":"en","url":"https://huggingface.co/datasets/clips/mfaq","creator_name":"CLiPS","creator_url":"https://huggingface.co/clips","description":"We present the first multilingual FAQ dataset publicly available. We collected around 6M FAQ pairs from the web, in 21 different languages."},
  {"name":"mqa","keyword":"french","license":"Creative Commons Zero v1.0 Universal","language":"en","url":"https://huggingface.co/datasets/clips/mqa","creator_name":"CLiPS","creator_url":"https://huggingface.co/clips","description":"MQA is a multilingual corpus of questions and answers parsed from the Common Crawl. Questions are divided between Frequently Asked Questions (FAQ) pages and Community Question Answering (CQA) pages."},
  {"name":"multilingual_librispeech","keyword":"french","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/facebook/multilingual_librispeech","creator_name":"AI at Meta","creator_url":"https://huggingface.co/facebook","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for MultiLingual LibriSpeech\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThis is a streamable version of the Multilingual LibriSpeech (MLS) dataset. \\nThe data archives were restructured from the original ones from OpenSLR to make it easier to stream.\\nMLS dataset is a large multilingual corpus suitable for speech research. The dataset is derived from read audiobooks from LibriVox and consists of \\n8 languages - English, German, Dutch, Spanish, French, Italian, Portuguese, Polish.‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/facebook/multilingual_librispeech."},
  {"name":"voxpopuli","keyword":"french","license":"Creative Commons Zero v1.0 Universal","language":"en","url":"https://huggingface.co/datasets/facebook/voxpopuli","creator_name":"AI at Meta","creator_url":"https://huggingface.co/facebook","description":"A large-scale multilingual speech corpus for representation learning, semi-supervised learning and interpretation."},
  {"name":"xwinograd","keyword":"french","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/Muennighoff/xwinograd","creator_name":"Niklas Muennighoff","creator_url":"https://huggingface.co/Muennighoff","description":"A multilingual collection of Winograd Schemas in six languages that can be used for evaluation of cross-lingual commonsense reasoning capabilities."},
  {"name":"multilingual-sentiments","keyword":"french","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/tyqiangz/multilingual-sentiments","creator_name":"Tay Yong Qiang","creator_url":"https://huggingface.co/tyqiangz","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tMultilingual Sentiments Dataset\\n\\t\\n\\nA collection of multilingual sentiments datasets grouped into 3 classes -- positive, neutral, negative.\\nMost multilingual sentiment datasets are either 2-class positive or negative, 5-class ratings of products reviews (e.g. Amazon multilingual dataset) or multiple classes of emotions. However, to an average person, sometimes positive, negative and neutral classes suffice and are more straightforward to perceive and annotate. Also, a‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/tyqiangz/multilingual-sentiments."},
  {"name":"lambada_openai","keyword":"french","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/EleutherAI/lambada_openai","creator_name":"EleutherAI","creator_url":"https://huggingface.co/EleutherAI","description":"The LAMBADA dataset as processed by OpenAI. It is used to evaluate the capabilities\\nof computational models for text understanding by means of a word prediction task.\\nLAMBADA is a collection of narrative texts sharing the characteristic that human subjects\\nare able to guess their last word if they are exposed to the whole text, but not\\nif they only see the last sentence preceding the target word. To succeed on LAMBADA,\\ncomputational models cannot simply rely on local context, but must be able to keep track\\nof information in the broader discourse.\\n\\nReference: https://github.com/openai/gpt-2/issues/131#issuecomment-497136199"},
  {"name":"legal-mc4","keyword":"french","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/joelniklaus/legal-mc4","creator_name":"Joel Niklaus","creator_url":"https://huggingface.co/joelniklaus","description":"Legal-MC4: A Corpus Covering the Legal Part of MC4 for European Languages"},
  {"name":"wmt-da-human-evaluation","keyword":"french","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/RicardoRei/wmt-da-human-evaluation","creator_name":"Ricardo Costa Dias Rei","creator_url":"https://huggingface.co/RicardoRei","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThis dataset contains all DA human annotations from previous WMT News Translation shared tasks.\\nThe data is organised into 8 columns:\\n\\nlp: language pair\\nsrc: input text\\nmt: translation\\nref: reference translation\\nscore: z score\\nraw: direct assessment\\nannotators: number of annotators\\ndomain: domain of the input text (e.g. news)\\nyear: collection year\\n\\nYou can also find the original data for each year in the results section‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/RicardoRei/wmt-da-human-evaluation."},
  {"name":"multiconer_v2","keyword":"french","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/MultiCoNER/multiconer_v2","creator_name":"MultiCoNER","creator_url":"https://huggingface.co/MultiCoNER","description":"Complex named entities (NE), like the titles of creative works, are not simple nouns and pose challenges for NER systems (Ashwini and Choi, 2014). They can take the form of any linguistic constituent, like an imperative clause (‚ÄúDial M for Murder‚Äù), and do not look like traditional NEs (Persons, Locations, etc.). This syntactic ambiguity makes it challenging to recognize them based on context. We organized the MultiCoNER task (Malmasi et al., 2022) at SemEval-2022 to address these challenges in 11 languages, receiving a very positive community response with 34 system papers. Results confirmed the challenges of processing complex and long-tail NEs: even the largest pre-trained Transformers did not achieve top performance without external knowledge. The top systems infused transformers with knowledge bases and gazetteers. However, such solutions are brittle against out of knowledge-base entities and noisy scenarios like the presence of spelling mistakes and typos. We propose MultiCoNER II which represents novel challenges through new tasks that emphasize the shortcomings of the current top models.\\n\\nMultiCoNER II features complex NER in these languages:\\n\\n1. English\\n2. Spanish\\n3. Hindi\\n4. Bangla\\n5. Chinese\\n6. Swedish\\n7. Farsi\\n8. French\\n9. Italian\\n10. Portugese\\n11. Ukranian\\n12. German\\n\\nFor more details see https://multiconer.github.io/\\n\\n## References\\n* Sandeep Ashwini and Jinho D. Choi. 2014. Targetable named entity recognition in social media. CoRR, abs/1408.0782.\\n* Shervin Malmasi, Anjie Fang, Besnik Fetahu, Sudipta Kar, Oleg Rokhlenko. 2022. SemEval-2022 Task 11: Multilingual Complex Named Entity Recognition (MultiCoNER)."},
  {"name":"swissner","keyword":"french","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/ZurichNLP/swissner","creator_name":"University of Zurich, Department of Computational Linguistics","creator_url":"https://huggingface.co/ZurichNLP","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSwissNER\\n\\t\\n\\nA multilingual test set for named entity recognition (NER) on Swiss news articles.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDescription\\n\\t\\n\\nSwissNER is a dataset for named entity recognition based on manually annotated news articles in Swiss Standard German, French, Italian, and Romansh Grischun.\\nWe have manually annotated a selection of articles that have been published in February 2023 in the categories \\\"Switzerland\\\" or \\\"Regional\\\" on the following online news portals:\\n\\nSwiss Standard German:‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ZurichNLP/swissner."},
  {"name":"daccord-contradictions","keyword":"french","license":"BSD 2-Clause \"Simplified\" License","language":"en","url":"https://huggingface.co/datasets/maximoss/daccord-contradictions","creator_name":"Maximos Skandalis","creator_url":"https://huggingface.co/maximoss","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Dataset Name\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThe DACCORD dataset is an entirely new collection of 1034 sentence pairs annotated as a binary classification task for automatic detection of contradictions between sentences in French. \\nEach pair of sentences receives a label according to whether or not the two sentences contradict each other.\\nDACCORD currently covers the themes of Russia‚Äôs invasion of Ukraine in 2022, the Covid-19 pandemic, and the climate crisis.‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/maximoss/daccord-contradictions."},
  {"name":"rte3-multi","keyword":"french","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/maximoss/rte3-multi","creator_name":"Maximos Skandalis","creator_url":"https://huggingface.co/maximoss","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Dataset Name\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThis repository contains all manually translated versions of RTE-3 dataset, plus the original English one. The languages into which RTE-3 dataset has so far been translated are Italian (2012), German (2013), and French (2023).\\nUnlike in other repositories, both our own French version and the older Italian and German ones are here annotated in 3 classes (entailment, neutral, contradiction), and not in 2 (entailment, not‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/maximoss/rte3-multi."},
  {"name":"oa-stackexchange","keyword":"french","license":"Creative Commons Attribution Share Alike 4.0 International","language":"en","url":"https://huggingface.co/datasets/donfu/oa-stackexchange","creator_name":"Donfu","creator_url":"https://huggingface.co/donfu","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tStackexchange Instructions for OpenAssistant\\n\\t\\n\\nThis dataset is taken from https://archive.org/details/stackexchange.\\nThere's a single parquet file combining all stackexchange sites. The threads\\nhave been filtered as follows: only threads with an accepted answer, for which\\nboth the question and response is less than 1000 characters have been choosen.\\nOther answers, or questions without accepted answers, or long entries have been\\ndroppped.\\nEach row consists of\\n\\nINSTRUCTION\\nRESPONSE‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/donfu/oa-stackexchange."},
  {"name":"mgsm","keyword":"french","license":"Creative Commons Attribution Share Alike 4.0 International","language":"en","url":"https://huggingface.co/datasets/juletxara/mgsm","creator_name":"Julen Etxaniz","creator_url":"https://huggingface.co/juletxara","description":"Multilingual Grade School Math Benchmark (MGSM) is a benchmark of grade-school math problems, proposed in the paper [Language models are multilingual chain-of-thought reasoners](http://arxiv.org/abs/2210.03057).\\n\\nThe same 250 problems from [GSM8K](https://arxiv.org/abs/2110.14168) are each translated via human annotators in 10 languages. The 10 languages are:\\n- Spanish\\n- French\\n- German\\n- Russian\\n- Chinese\\n- Japanese\\n- Thai\\n- Swahili\\n- Bengali\\n- Telugu\\n\\nYou can find the input and targets for each of the ten languages (and English) as `.tsv` files.\\nWe also include few-shot exemplars that are also manually translated from each language in `exemplars.py`."},
  {"name":"FrenchCensus-handwritten-texts","keyword":"french","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/agomberto/FrenchCensus-handwritten-texts","creator_name":"Arnault Gombert","creator_url":"https://huggingface.co/agomberto","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSource\\n\\t\\n\\nThis repository contains 3 datasets created within the POPP project (Project for the Oceration of the Paris Population Census) for the task of handwriting text recognition. These datasets have been published in Recognition and information extraction in historical handwritten tables: toward understanding early 20th century Paris census at DAS 2022.\\nThe 3 datasets are called ‚ÄúGeneric dataset‚Äù, ‚ÄúBelleville‚Äù, and ‚ÄúChauss√©e d‚ÄôAntin‚Äù and contains lines made from the extracted‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/agomberto/FrenchCensus-handwritten-texts."},
  {"name":"midjourney-v5-202304-clean","keyword":"french","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/wanng/midjourney-v5-202304-clean","creator_name":"wangjunjie","creator_url":"https://huggingface.co/wanng","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tmidjourney-v5-202304-clean\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tÁÆÄ‰ªã Brief Introduction\\n\\t\\n\\nÈùûÂÆòÊñπÁöÑÔºåÁà¨ÂèñËá™midjourney v5ÁöÑ2023Âπ¥4ÊúàÁöÑÊï∞ÊçÆÔºå‰∏ÄÂÖ±1701420Êù°„ÄÇ\\nUnofficial, crawled from midjourney v5 for April 2023, 1,701,420 pairs in total.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tÊï∞ÊçÆÈõÜ‰ø°ÊÅØ Dataset Information\\n\\t\\n\\nÂéüÂßãÈ°πÁõÆÂú∞ÂùÄÔºöhttps://huggingface.co/datasets/tarungupta83/MidJourney_v5_Prompt_dataset\\nÊàëÂÅö‰∫Ü‰∏Ä‰∫õÊ∏ÖÊ¥óÔºåÊ∏ÖÁêÜÂá∫‰∫Ü‰∏§‰∏™Êñá‰ª∂Ôºö\\n\\nori_prompts_df.parquet Ôºà1,255,812ÂØπÔºåmidjourneyÁöÑÂõõÊ†ºÂõæÔºâ\\n\\nupscaled_prompts_df.parquet Ôºà445,608ÂØπÔºå‰ΩøÁî®‰∫ÜÈ´òÊ∏ÖÊåá‰ª§ÁöÑÂõæÔºåËøôÊÑèÂë≥ÁùÄËøô‰∏™ÂõæÊõ¥ÂèóÊ¨¢Ëøé„ÄÇÔºâ\\n\\n\\nOriginal project address:‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/wanng/midjourney-v5-202304-clean."},
  {"name":"sumstew","keyword":"french","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/Joemgu/sumstew","creator_name":"Jonas","creator_url":"https://huggingface.co/Joemgu","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for \\\"sumstew\\\"\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tTL;DR:\\n\\t\\n\\nSumstew is a abstractive, multilingual Dataset, with a balanced number of samples from a diverse set of summarization Datasets. The input sizes range up to 16384 tokens.\\nFiltered using a diverse set of heuristics to encourage high coverage, accuracy and factual consistency. Code to reproduce Dataset available at TODO\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tTask Information\\n\\t\\n\\n\\nTask Categories: The tasks covered by this dataset are primarily summarization‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Joemgu/sumstew."},
  {"name":"swiss_leading_decision_summarization","keyword":"french","license":"Creative Commons Attribution Share Alike 4.0 International","language":"en","url":"https://huggingface.co/datasets/rcds/swiss_leading_decision_summarization","creator_name":"Institute for Public Sector Transformation IPST - Digital Sustainability Lab DSL","creator_url":"https://huggingface.co/rcds","description":"This dataset contains court decisions for the swiss ruling summarization task."},
  {"name":"toxi-text-3M","keyword":"french","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/FredZhang7/toxi-text-3M","creator_name":"Fred Zhang","creator_url":"https://huggingface.co/FredZhang7","description":"This is a large multilingual toxicity dataset with 3M rows of text data from 55 natural languages, all of which are written/sent by humans, not machine translation models.\\nThe preprocessed training data alone consists of 2,880,667 rows of comments, tweets, and messages. Among these rows, 416,529 are classified as toxic, while the remaining 2,463,773 are considered neutral. Below is a table to illustrate the data composition:\\n\\n\\t\\n\\t\\t\\n\\nToxic\\nNeutral\\nTotal\\n\\n\\n\\t\\t\\nmultilingual-train-deduplicated.csv‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/FredZhang7/toxi-text-3M."},
  {"name":"massive_translation_dataset","keyword":"french","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/Amani27/massive_translation_dataset","creator_name":"Amani N","creator_url":"https://huggingface.co/Amani27","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Massive Dataset for Translation\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThis dataset is derived from AmazonScience/MASSIVE dataset for translation task purpose.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSupported Tasks and Leaderboards\\n\\t\\n\\nTranslation\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages\\n\\t\\n\\n\\nEnglish (en_US)\\nGerman (de_DE)\\nHindi (hi_IN)\\nSpanish (es_ES)\\nFrench (fr_FR)\\nItalian (it_IT)\\nArabic (ar_SA)\\nDutch (nl_NL)\\nJapanese (ja_JP)\\nPortugese (pt_PT)\\n\\n"},
  {"name":"belebele","keyword":"french","license":"Creative Commons Attribution Share Alike 4.0 International","language":"en","url":"https://huggingface.co/datasets/facebook/belebele","creator_name":"AI at Meta","creator_url":"https://huggingface.co/facebook","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tThe Belebele Benchmark for Massively Multilingual NLU Evaluation\\n\\t\\n\\nBelebele is a multiple-choice machine reading comprehension (MRC) dataset spanning 122 language variants. This dataset enables the evaluation of mono- and multi-lingual models in high-, medium-, and low-resource languages. Each question has four multiple-choice answers and is linked to a short passage from the FLORES-200 dataset. The human annotation procedure was carefully curated to create questions that‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/facebook/belebele."},
  {"name":"GSM8KInstruct_Parallel","keyword":"french","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/Mathoctopus/GSM8KInstruct_Parallel","creator_name":"Mathoctopus","creator_url":"https://huggingface.co/Mathoctopus","description":"Mathoctopus/GSM8KInstruct_Parallel dataset hosted on Hugging Face and contributed by the HF Datasets community"},
  {"name":"alloprof","keyword":"french","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/lyon-nlp/alloprof","creator_name":"Lyon NLP","creator_url":"https://huggingface.co/lyon-nlp","description":"This is a re-edit from the Alloprof dataset (which can be found here : https://huggingface.co/datasets/antoinelb7/alloprof).\\nFor more information about the data source and the features, please refer to the original dataset card made by the authors, along with their paper available here : https://arxiv.org/abs/2302.07738\\nThis re-edition of the dataset is a preprocessed version of the original, in a more ready-to-use format. Essentially, the texts have been cleaned, and data not usable for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/lyon-nlp/alloprof."},
  {"name":"Open_Assistant_Conversation_Chains","keyword":"french","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/m-ric/Open_Assistant_Conversation_Chains","creator_name":"Aymeric Roucher","creator_url":"https://huggingface.co/m-ric","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Dataset Name\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset description\\n\\t\\n\\n\\n\\nThis dataset is a reformatting of OpenAssistant Conversations (OASST1), which is\\n\\na human-generated, human-annotated assistant-style conversation corpus consisting of 161,443 messages in 35 different languages, annotated with 461,292 quality ratings, resulting in over 10,000 fully annotated conversation trees. The corpus is a product of a worldwide crowd-sourcing effort involving over 13,500 volunteers.\\n\\nIt was‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/m-ric/Open_Assistant_Conversation_Chains."},
  {"name":"cml-tts","keyword":"french","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/ylacombe/cml-tts","creator_name":"Yoach Lacombe","creator_url":"https://huggingface.co/ylacombe","description":"\\n\\t\\n\\t\\t\\n\\t\\tDataset Card for CML-TTS\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nCML-TTS is a recursive acronym for CML-Multi-Lingual-TTS, a Text-to-Speech (TTS) dataset developed at the Center of Excellence in Artificial Intelligence (CEIA) of the Federal University of Goias (UFG).\\nCML-TTS is a dataset comprising audiobooks sourced from the public domain books of Project Gutenberg, read by volunteers from the LibriVox project. The dataset includes recordings in Dutch, German, French, Italian, Polish‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ylacombe/cml-tts."},
  {"name":"librivox-tracks","keyword":"french","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/pykeio/librivox-tracks","creator_name":"pyke.io","creator_url":"https://huggingface.co/pykeio","description":"A dataset of all audio files uploaded to LibriVox before 26th September 2023.\\n"},
  {"name":"qald_9_plus","keyword":"french","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/casey-martin/qald_9_plus","creator_name":"Casey","creator_url":"https://huggingface.co/casey-martin","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tQALD-9-plus Dataset Description\\n\\t\\n\\nQALD-9-plus is the dataset for Knowledge Graph Question Answering (KGQA) based on well-known QALD-9.\\nQALD-9-plus enables to train and test KGQA systems over DBpedia and Wikidata using questions in 9 different languages: English, German, Russian, French, Armenian, Belarusian, Lithuanian, Bashkir, and Ukrainian.\\nSome of the questions have several alternative writings in particular languages which enables to evaluate the robustness of KGQA systems‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/casey-martin/qald_9_plus."},
  {"name":"multilingual-tts","keyword":"french","license":"GNU General Public License v3.0","language":"en","url":"https://huggingface.co/datasets/MohamedRashad/multilingual-tts","creator_name":"Mohamed Rashad","creator_url":"https://huggingface.co/MohamedRashad","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tBefore Anything and Everything ‚ö±\\n\\t\\n\\nIn the time of writing this Dataset Card, 17,490 18,412 civilian has been killed in Palestine (7,870 8,000 are children and 6,121 6,200 are women).\\nSeek any non-profit organization to help them with what you can (For myself, I use Mersal) üáµüá∏\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThe Multilingual TTS dataset is an exceptional compilation of text-to-speech (TTS) samples, meticulously crafted to showcase the richness and diversity of human languages.‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/MohamedRashad/multilingual-tts."},
  {"name":"code-securite-sociale","keyword":"french","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/louisbrulenaudet/code-securite-sociale","creator_name":"Louis Brul√© Naudet","creator_url":"https://huggingface.co/louisbrulenaudet","description":"\\n\\t\\n\\t\\t\\n\\t\\tCode de la s√©curit√© sociale, non-instruct (2025-03-10)\\n\\t\\n\\nThe objective of this project is to provide researchers, professionals and law students with simplified, up-to-date access to all French legal texts, enriched with a wealth of data to facilitate their integration into Community and European projects.\\nNormally, the data is refreshed daily on all legal codes, and aims to simplify the production of training sets and labeling pipelines for the development of free, open-source‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/louisbrulenaudet/code-securite-sociale."},
  {"name":"code-travail","keyword":"french","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/louisbrulenaudet/code-travail","creator_name":"Louis Brul√© Naudet","creator_url":"https://huggingface.co/louisbrulenaudet","description":"\\n\\t\\n\\t\\t\\n\\t\\tCode du travail, non-instruct (2025-03-10)\\n\\t\\n\\nThe objective of this project is to provide researchers, professionals and law students with simplified, up-to-date access to all French legal texts, enriched with a wealth of data to facilitate their integration into Community and European projects.\\nNormally, the data is refreshed daily on all legal codes, and aims to simplify the production of training sets and labeling pipelines for the development of free, open-source language models‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/louisbrulenaudet/code-travail."},
  {"name":"multilingual-pl-bert","keyword":"french","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/styletts2-community/multilingual-pl-bert","creator_name":"StyleTTS 2 Community","creator_url":"https://huggingface.co/styletts2-community","description":"Attribution: Wikipedia.org\\n"},
  {"name":"wikisource","keyword":"french","license":"Creative Commons Attribution Share Alike 4.0 International","language":"en","url":"https://huggingface.co/datasets/OpenLLM-France/wikisource","creator_name":"OpenLLM France","creator_url":"https://huggingface.co/OpenLLM-France","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tPlain text of Wikisource\\n\\t\\n\\n\\nDataset Description\\nSize\\nExample use (python)\\nData fields\\nNotes on data formatting\\n\\n\\nLicense\\nAknowledgements\\nCitation\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThis dataset is a plain text version of pages from wikisource.org in French language.\\nThe text is without HTML tags nor wiki templates.\\nIt just includes markdown syntax for headers, lists and tables.\\nSee Notes on data formatting for more details.\\nIt was created by LINAGORA and OpenLLM France\\nfrom the‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/OpenLLM-France/wikisource."},
  {"name":"wiktionary","keyword":"french","license":"Creative Commons Attribution Share Alike 4.0 International","language":"en","url":"https://huggingface.co/datasets/OpenLLM-France/wiktionary","creator_name":"OpenLLM France","creator_url":"https://huggingface.co/OpenLLM-France","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tPlain text of French Wiktionary\\n\\t\\n\\n\\nDataset Description\\nSize\\nExample use (python)\\nData fields\\nNotes on data formatting\\n\\n\\nLicense\\nAknowledgements\\nCitation\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThis dataset is a plain text version of pages from wiktionary.org in French language.\\nThe text is without HTML tags nor wiki templates.\\nIt just includes markdown syntax for headers, lists and tables.\\nSee Notes on data formatting for more details.\\nIt was created by LINAGORA and OpenLLM France‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/OpenLLM-France/wiktionary."},
  {"name":"FREDSum","keyword":"french","license":"Creative Commons Attribution Share Alike 4.0 International","language":"en","url":"https://huggingface.co/datasets/linagora/FREDSum","creator_name":"LINAGORA Labs","creator_url":"https://huggingface.co/linagora","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThe FREDSum dataset is a comprehensive collection of transcripts and metadata from various political and public debates in France. The dataset aims to provide researchers, linguists, and data scientists with a rich source of debate content for analysis and natural language processing tasks.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages\\n\\t\\n\\nFrench\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Structure\\n\\t\\n\\nThe dataset is made of 144 debates, 115 of the debates make up the train set, while 29 make up the test set‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/linagora/FREDSum."},
  {"name":"FREDSum","keyword":"french","license":"Creative Commons Attribution Share Alike 4.0 International","language":"en","url":"https://huggingface.co/datasets/linagora/FREDSum","creator_name":"LINAGORA Labs","creator_url":"https://huggingface.co/linagora","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThe FREDSum dataset is a comprehensive collection of transcripts and metadata from various political and public debates in France. The dataset aims to provide researchers, linguists, and data scientists with a rich source of debate content for analysis and natural language processing tasks.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages\\n\\t\\n\\nFrench\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Structure\\n\\t\\n\\nThe dataset is made of 144 debates, 115 of the debates make up the train set, while 29 make up the test set‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/linagora/FREDSum."},
  {"name":"openassistant-deepseek-coder","keyword":"french","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/Trelis/openassistant-deepseek-coder","creator_name":"Trelis","creator_url":"https://huggingface.co/Trelis","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tChat Fine-tuning Dataset - OpenAssistant DeepSeek Coder\\n\\t\\n\\nThis dataset allows for fine-tuning chat models using:\\nB_INST = '\\\\n### Instruction:\\\\n'\\nE_INST = '\\\\n### Response:\\\\n'\\nBOS = '<ÔΩúbegin‚ñÅof‚ñÅsentenceÔΩú>'\\nEOS = '\\\\n<|EOT|>\\\\n'\\n\\nSample Preparation:\\n\\nThe dataset is cloned from TimDettmers, which itself is a subset of the Open Assistant dataset, which you can find here. This subset of the data only contains the highest-rated paths in the conversation tree, with a total of 9,846 samples.‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Trelis/openassistant-deepseek-coder."},
  {"name":"french_orca_dpo_pairs","keyword":"french","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/AIffl/french_orca_dpo_pairs","creator_name":"AIffl : AI For French Language","creator_url":"https://huggingface.co/AIffl","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for french_orca_dpo_pairs\\n\\t\\n\\nThis dataset offers a french translation of the 12k DPO Intel/orca_dpo_pairs pairs made from Open-Orca/OpenOrca.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card Contact\\n\\t\\n\\nntnq\\n"},
  {"name":"sib200","keyword":"french","license":"Creative Commons Attribution Share Alike 4.0 International","language":"en","url":"https://huggingface.co/datasets/Davlan/sib200","creator_name":"David Adelani","creator_url":"https://huggingface.co/Davlan","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for SIB-200\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nSIB-200 is the largest publicly available topic classification dataset based on Flores-200 covering 205 languages and dialects.\\nThe train/validation/test sets are available for all the 205 languages.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSupported Tasks and Leaderboards\\n\\t\\n\\n\\ntopic classification: categorize wikipedia sentences into topics e.g science/technology, sports or politics.\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages\\n\\t\\n\\nThere are 205 languages available :‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Davlan/sib200."},
  {"name":"aya_dataset","keyword":"french","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/CohereForAI/aya_dataset","creator_name":"Cohere For AI","creator_url":"https://huggingface.co/CohereForAI","description":"\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThe Aya Dataset is a multilingual instruction fine-tuning dataset curated by an open-science community via Aya Annotation Platform from Cohere For AI. The dataset contains a total of 204k human-annotated prompt-completion pairs along with the demographics data of the annotators.\\nThis dataset can be used to train, finetune, and evaluate multilingual LLMs.\\n\\nCurated by: Contributors of Aya Open Science Intiative.\\n\\nLanguage(s): 65 languages (71 including dialects &‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/CohereForAI/aya_dataset."},
  {"name":"aya_collection","keyword":"french","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/CohereForAI/aya_collection","creator_name":"Cohere For AI","creator_url":"https://huggingface.co/CohereForAI","description":"\\nThis dataset is uploaded in two places: here and additionally here as 'Aya Collection Language Split.' These datasets are identical in content but differ in structure of upload. This dataset is structured by folders split according to dataset name. The version here instead divides the Aya collection into folders split by language. We recommend you use the language split version if you are only interested in downloading data for a single or smaller set of languages, and this version if you‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/CohereForAI/aya_collection."},
  {"name":"aya_evaluation_suite","keyword":"french","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/CohereForAI/aya_evaluation_suite","creator_name":"Cohere For AI","creator_url":"https://huggingface.co/CohereForAI","description":"\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nAya Evaluation Suite contains a total of 26,750 open-ended conversation-style prompts to evaluate multilingual open-ended generation quality.To strike a balance between language coverage and the quality that comes with human curation, we create an evaluation suite that includes:\\n\\nhuman-curated examples in 7 languages (tur, eng, yor, arb, zho, por, tel) ‚Üí aya-human-annotated.\\nmachine-translations of handpicked examples into 101 languages ‚Üí‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/CohereForAI/aya_evaluation_suite."},
  {"name":"CulturaY","keyword":"french","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/ontocord/CulturaY","creator_name":"Ontocord.AI","creator_url":"https://huggingface.co/ontocord","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tCulturaY: A Large Cleaned Multilingual Dataset of 75 Languages\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nFrom the team that brought you CulturaX, we present CulturaY, another substantial multilingual dataset of 15TB (uncompressed)/3TB (zstd-compressed) that applies the same dataset cleaning methodology to the HPLT v1.1 dataset. \\nPlease note that HPLT v1.2 has also been released and is an alternative verison with different cleaning methodolgies. \\nThis data was used in part to train our SOTA‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ontocord/CulturaY."},
  {"name":"GPT-4-Prompts","keyword":"french","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/erfanzar/GPT-4-Prompts","creator_name":"Erfan zare chavoshi","creator_url":"https://huggingface.co/erfanzar","description":"Multi-Turn Conversational Prompts from ChatGPT-4 (10K+ Tokens)\\nAbstract:\\nThis dataset offers a valuable collection of multi-turn conversational prompts generated by ChatGPT-4, carefully curated for diverse prompt styles (chatml, gemma, llama). Each prompt exceeds 10,000 tokens, providing ample context and inspiration for training and evaluating large language models. Ideal for researchers and developers interested in exploring advanced conversational AI capabilities.\\nTable of Contents:‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/erfanzar/GPT-4-Prompts."},
  {"name":"bio-mqm-dataset","keyword":"french","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/zouharvi/bio-mqm-dataset","creator_name":"Vil√©m Zouhar","creator_url":"https://huggingface.co/zouharvi","description":"This dataset is compiled from the official Amazon repository (all respective licensing applies).\\nIt contains system translations, multiple references, and their quality evaluation on the MQM scale. It accompanies the ACL 2024 paper Fine-Tuned Machine Translation Metrics Struggle in Unseen Domains.\\nWatch a brief 4 minutes-long video.\\n\\nAbstract: We introduce a new, extensive multidimensional quality metrics (MQM) annotated dataset covering 11 language pairs in the biomedical domain. We use this‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/zouharvi/bio-mqm-dataset."},
  {"name":"french_instruct","keyword":"french","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/angeluriot/french_instruct","creator_name":"Angel Uriot","creator_url":"https://huggingface.co/angeluriot","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tüßë‚Äçüè´ French Instruct\\n\\t\\n\\nThe French Instruct dataset is a collection of instructions with their corresponding answers (sometimes multi-turn conversations) entirely in French. The dataset is also available on GitHub.\\n\\n    \\n\\n\\n\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tüìä Overview\\n\\t\\n\\nThe dataset is composed of 276K conversations between a user and an assistant for a total of approximately 85M tokens.\\n\\n    \\n\\n\\nI also added annotations for each document to indicate if it was generated or written by a human, the‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/angeluriot/french_instruct."},
  {"name":"XMedbench","keyword":"french","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/FreedomIntelligence/XMedbench","creator_name":"FreedomAI","creator_url":"https://huggingface.co/FreedomIntelligence","description":"\\n\\t\\n\\t\\t\\n\\t\\tMultilingual Medicine: Model, Dataset, Benchmark, Code\\n\\t\\n\\nCovering English, Chinese, French, Hindi, Spanish, Hindi, Arabic So far\\n\\n   üë®üèª‚ÄçüíªGithub ‚Ä¢üìÉ Paper ‚Ä¢ ü§ó ApolloCorpus ‚Ä¢ ü§ó XMedBench \\n      ‰∏≠Êñá  |  English\\n\\n\\n\\n\\n\\n\\t\\t\\n\\t\\tüåà Update\\n\\t\\n\\n\\n[2024.03.07] Paper released.\\n[2024.02.12] ApolloCorpus and  XMedBench  is publishedÔºÅüéâ\\n[2024.01.23] Apollo repo is publishedÔºÅüéâ\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tResults\\n\\t\\n\\n   \\n\\n\\t\\n\\t\\t\\n\\t\\tUsage\\n\\t\\n\\n\\nZip File\\nData category\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tData:\\n\\t\\n\\n\\nEN:\\n\\nMedQA-USMLE \\nMedMCQA\\nPubMedQA:‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/FreedomIntelligence/XMedbench."},
  {"name":"aya_collection_language_split","keyword":"french","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/CohereForAI/aya_collection_language_split","creator_name":"Cohere For AI","creator_url":"https://huggingface.co/CohereForAI","description":"\\nThis is a re-upload of the aya_collection, and only differs in the structure of upload. While the original aya_collection is structured by folders split according to dataset name, this dataset is split by language. We recommend you use this version of the dataset if you are only interested in downloading all of the Aya collection for a single or smaller set of languages.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThe Aya Collection is a massive multilingual collection consisting of 513 million instances‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/CohereForAI/aya_collection_language_split."},
  {"name":"tokenizer-wiki-bench","keyword":"french","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/occiglot/tokenizer-wiki-bench","creator_name":"Occiglot","creator_url":"https://huggingface.co/occiglot","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tMultilingual Tokenizer Benchmark\\n\\t\\n\\nThis dataset includes pre-processed wikipedia data for tokenizer evaluation in 45 languages. We provide more information on the evaluation task in general this blogpost.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tUsage\\n\\t\\n\\nThe dataset allows us to easily calculate tokenizer fertility and the proportion of continued words on any of the supported languages. In the example below we take the Mistral tokenizer and evaluate its performance on Slovak. \\nfrom transformers import‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/occiglot/tokenizer-wiki-bench."},
  {"name":"MediaSpeech","keyword":"french","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/ymoslem/MediaSpeech","creator_name":"Yasmin Moslem","creator_url":"https://huggingface.co/ymoslem","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tMediaSpeech\\n\\t\\n\\nMediaSpeech is a dataset of Arabic, French, Spanish, and Turkish media speech built with the purpose of testing Automated Speech Recognition (ASR) systems performance. The dataset contains 10 hours of speech for each language provided.\\nThe dataset consists of short speech segments automatically extracted from media videos available on YouTube and manually transcribed, with some pre-processing and post-processing.\\nBaseline models and WAV version of the dataset can be‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ymoslem/MediaSpeech."},
  {"name":"Multilingual-Medical-Corpus","keyword":"french","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/HiTZ/Multilingual-Medical-Corpus","creator_name":"HiTZ zentroa","creator_url":"https://huggingface.co/HiTZ","description":"\\n    \\n    \\n    Mutilingual Medical Corpus\\n    \\n\\n\\nMultilingual-Medical-Corpus a 3 billion word multilingual corpus for training LLMs adapted to the medical domain. Multilingual-Medical-Corpus includes four languages, namely, English, Spanish, French, and Italian.\\n\\n\\n\\nüìñ Paper: Medical mT5: An Open-Source Multilingual Text-to-Text LLM for The Medical Domain\\nüåê Project Website: https://univ-cotedazur.eu/antidote\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tCorpus Description\\n\\t\\n\\n\\nDeveloped by: Iker Garc√≠a-Ferrero, Rodrigo Agerri‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/HiTZ/Multilingual-Medical-Corpus."},
  {"name":"mCoT-MATH","keyword":"french","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/laihuiyuan/mCoT-MATH","creator_name":"Huiyuan Lai","creator_url":"https://huggingface.co/laihuiyuan","description":"\\n\\t\\n\\t\\t\\n\\t\\tmCoT: Multilingual Instruction Tuning for Reasoning Consistency in Language Models\\n\\t\\n\\nPaper: https://arxiv.org/abs/2406.02301\\nCode: https://github.com/laihuiyuan/mCoT\\nModel: https://huggingface.co/laihuiyuan/mCoT\\n\\n\\t\\n\\t\\t\\n\\t\\tIntroduction\\n\\t\\n\\nBased on MetaMathQA and MathInstruct\\n, we use machine translation to compile mCoT-MATH, the first large-scale multilingual math CoT reasoning dataset containing around 6.3 million samples for 11 diverse languages.\\nWe train a 7B parameter model mCoT for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/laihuiyuan/mCoT-MATH."},
  {"name":"orca_dpo_pairs","keyword":"french","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/multilingual/orca_dpo_pairs","creator_name":"mLLM multilingual","creator_url":"https://huggingface.co/multilingual","description":"\\n    \\n\\n\\nmLLM IMPLEMENTATION OF Intel/orca_dpo_pairs.\\nLANGUAGES:\\nARABIC\\nCHINESE\\nFRENCH\\nGERMAN\\nRUSSIAN\\nSPANISH\\nTURKISH\\n(WIP)\\n"},
  {"name":"Post-OCR-Correction","keyword":"french","license":"Creative Commons Zero v1.0 Universal","language":"en","url":"https://huggingface.co/datasets/PleIAs/Post-OCR-Correction","creator_name":"PleIAs","creator_url":"https://huggingface.co/PleIAs","description":"Post-OCR correction is a large corpus of 1 billion words containing original texts with a varying number of OCR mistakes and an experimental multilingual post-OCR correction output created by Pleias.\\nGeneration of Post-OCR correction was performed using HPC resources from GENCI‚ÄìIDRIS (Grant 2023-AD011014736) on Jean-Zay.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDescription\\n\\t\\n\\nAll the texts come from collections integrated into Common Corpus, the largest open corpus for pretraining previously released by Pleias on‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/PleIAs/Post-OCR-Correction."},
  {"name":"synthetic-pii-ner-mistral-v1","keyword":"french","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/urchade/synthetic-pii-ner-mistral-v1","creator_name":"Urchade Zaratiana","creator_url":"https://huggingface.co/urchade","description":"This the synthetic dataset used for training https://huggingface.co/urchade/gliner_multi_pii-v1. You can get it by browsing the files and dowloading the data.json file.\\n"},
  {"name":"afrimmlu","keyword":"french","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/masakhane/afrimmlu","creator_name":"Masakhane NLP","creator_url":"https://huggingface.co/masakhane","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for afrimmlu\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nAFRIMMLU is an evaluation dataset comprising translations of a subset of the MMLU dataset into 15 African languages. \\nIt includes test sets across all 17 languages, maintaining an English and French subsets from the original MMLU dataset. \\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages\\n\\t\\n\\nThere are 17 languages available :\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Structure\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Instances\\n\\t\\n\\nThe examples look like this for English:\\nfrom datasets import‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/masakhane/afrimmlu."},
  {"name":"swim-ir-monolingual","keyword":"french","license":"Creative Commons Attribution Share Alike 4.0 International","language":"en","url":"https://huggingface.co/datasets/nthakur/swim-ir-monolingual","creator_name":"Nandan Thakur","creator_url":"https://huggingface.co/nthakur","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for SWIM-IR (Monolingual)\\n\\t\\n\\n\\n\\n\\nThis is the monolingual subset of the SWIM-IR dataset, where the query generated and the passage are both in the same language.\\nA few remaining languages will be added in the upcoming v2 version of SWIM-IR. The dataset is available as CC-BY-SA 4.0.\\nFor full details of the dataset, please read our upcoming NAACL 2024 paper and check out our website.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tWhat is SWIM-IR?\\n\\t\\n\\nSWIM-IR dataset is a synthetic multilingual retrieval‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/nthakur/swim-ir-monolingual."},
  {"name":"webui-dom-snapshots","keyword":"french","license":"Creative Commons Zero v1.0 Universal","language":"en","url":"https://huggingface.co/datasets/gbenson/webui-dom-snapshots","creator_name":"Gary Benson","creator_url":"https://huggingface.co/gbenson","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for WebUI DOM snapshots\\n\\t\\n\\n\\n\\nThis dataset card aims to be a base template for new datasets. It has been generated using this raw template.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Details\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\n\\n\\n\\n\\n\\nCurated by: Gary Benson\\nLanguages: Mostly English (87%);\\nDutch, French, Chinese, Japanese (1-2% each); 30+ others (<1% each)\\nLicense: CC0 1.0 Universal\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Sources [optional]\\n\\t\\n\\n\\n\\n\\nRepository: [More Information Needed]\\nPaper [optional]: [More‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/gbenson/webui-dom-snapshots."},
  {"name":"glianorex","keyword":"french","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/maximegmd/glianorex","creator_name":"Maxime Griot","creator_url":"https://huggingface.co/maximegmd","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tMultiple Choice Questions and Large Languages Models: A Case Study with Fictional Medical Data\\n\\t\\n\\nThis multiple choice question dataset on a fictional organ, the Glianorex, is used to assess the capabilities of models to answer questions on knowledge they have never encountered.\\nWe only provide a test dataset as training models on this dataset would defeat the purpose of isolating linguistic capabilities from knowledge.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tMotivation\\n\\t\\n\\nWe designed this dataset to evaluate‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/maximegmd/glianorex."},
  {"name":"afrimmlu-translate-test","keyword":"french","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/masakhane/afrimmlu-translate-test","creator_name":"Masakhane NLP","creator_url":"https://huggingface.co/masakhane","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for afrimmlu-translate-test\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nAFRIMMLU-TT is an evaluation dataset comprising translations of the AFRIMMLU dataset from 16 African languages and 1 high resource language into English using NLLB. \\nIt includes test sets across all 17 languages. \\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages\\n\\t\\n\\nThere are 17 languages available :\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Structure\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Instances\\n\\t\\n\\nThe examples look like this for English:\\nfrom datasets import load_dataset‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/masakhane/afrimmlu-translate-test."},
  {"name":"histoires_morales","keyword":"french","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/LabHC/histoires_morales","creator_name":"Laboratoire Hubert Curien","creator_url":"https://huggingface.co/LabHC","description":"\\n\\t\\n\\t\\t\\n\\t\\tDataset Card for HistoiresMorales\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Summary\\n\\t\\n\\n‚öñ Histoires Morales is a French dataset derived from the English corpus Moral Stories through multi-step translation and consists of short narratives describing moral and deviant behaviors in social situations centered around personal relationships, education, commerce, domestic affairs, and meals.\\nEach of the 12,000 stories (histoires) follows the same seven-sentence structure as the Moral Stories dataset:\\nContext:‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/LabHC/histoires_morales."},
  {"name":"oasst2_french_dpo_pairs","keyword":"french","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/AIffl/oasst2_french_dpo_pairs","creator_name":"AIffl : AI For French Language","creator_url":"https://huggingface.co/AIffl","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for oasst2_french_dpo_pairs\\n\\t\\n\\nThis dataset was created from OpenAssistant/oasst2 by keeping only the french data and producing dpo pairs with their rank.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card Contact\\n\\t\\n\\nntnq\\n"},
  {"name":"CIVICS","keyword":"french","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/CIVICS-dataset/CIVICS","creator_name":"CIVICS dataset organization","creator_url":"https://huggingface.co/CIVICS-dataset","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Details\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tUses\\n\\t\\n\\nEvaluating a language model‚Äôs treatment of different ethical values, specifically for different civics topics relevant to sensitive groups. ‚ÄúTreatment‚Äù includes the likelihood a model gives to different value-laden statements and whether different implicit values in inputs lead to different generations by the model, in response to the provided prompts.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Structure\\n\\t\\n\\n\\nLanguage: One of ‚ÄúGerman‚Äù, ‚ÄúEnglish‚Äù, ‚ÄúFrench‚Äù, ‚ÄúItalian‚Äù‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/CIVICS-dataset/CIVICS."},
  {"name":"xvnli","keyword":"french","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/floschne/xvnli","creator_name":"Flo Schneider","creator_url":"https://huggingface.co/floschne","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tXVNLI\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tThis is a copy from the original repo: https://github.com/e-bug/iglue\\n\\t\\n\\nIf you use this dataset, please cite the original authors:\\n@inproceedings{bugliarello-etal-2022-iglue,\\n  title = \\t {{IGLUE}: A Benchmark for Transfer Learning across Modalities, Tasks, and Languages},\\n  author =       {Bugliarello, Emanuele and Liu, Fangyu and Pfeiffer, Jonas and Reddy, Siva and Elliott, Desmond and Ponti, Edoardo Maria and Vuli{\\\\'c}, Ivan},\\n  booktitle = \\t {Proceedings of‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/floschne/xvnli."},
  {"name":"cold-french-law","keyword":"french","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/harvard-lil/cold-french-law","creator_name":"Harvard Library Innovation Lab","creator_url":"https://huggingface.co/harvard-lil","description":"\\n\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tCollaborative Open Legal Data (COLD) - French Law\\n\\t\\n\\nCOLD French Law is a dataset containing over 800 000 french law articles, filtered and extracted from France's LEGI dataset and formatted as a single CSV file. \\nThis dataset focuses on articles (codes, lois, d√©crets, arr√™t√©s ...) identified as currently applicable french law.\\nA large portion of this dataset comes with machine-generated english translations, provided by Casetext, Part of Thomson Reuters using OpenAI's GPT-4.‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/harvard-lil/cold-french-law."},
  {"name":"GlotCC-V1","keyword":"french","license":"Creative Commons Zero v1.0 Universal","language":"en","url":"https://huggingface.co/datasets/cis-lmu/GlotCC-V1","creator_name":"CIS, LMU Munich","creator_url":"https://huggingface.co/cis-lmu","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\n \\n\\nGlotCC-V1.0 is a document-level, general domain dataset derived from CommonCrawl, covering more than 1000 languages.It is built using the GlotLID language identification and Ungoliant pipeline from CommonCrawl.We release our pipeline as open-source at https://github.com/cisnlp/GlotCC.  \\nList of Languages: See https://datasets-server.huggingface.co/splits?dataset=cis-lmu/GlotCC-V1 to get the list of splits available.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tUsage (Huggingface Hub --‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/cis-lmu/GlotCC-V1."},
  {"name":"GlotCC-V1","keyword":"french","license":"Creative Commons Zero v1.0 Universal","language":"en","url":"https://huggingface.co/datasets/cis-lmu/GlotCC-V1","creator_name":"CIS, LMU Munich","creator_url":"https://huggingface.co/cis-lmu","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\n \\n\\nGlotCC-V1.0 is a document-level, general domain dataset derived from CommonCrawl, covering more than 1000 languages.It is built using the GlotLID language identification and Ungoliant pipeline from CommonCrawl.We release our pipeline as open-source at https://github.com/cisnlp/GlotCC.  \\nList of Languages: See https://datasets-server.huggingface.co/splits?dataset=cis-lmu/GlotCC-V1 to get the list of splits available.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tUsage (Huggingface Hub --‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/cis-lmu/GlotCC-V1."},
  {"name":"synthetic_pii_finance_multilingual","keyword":"french","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/gretelai/synthetic_pii_finance_multilingual","creator_name":"Gretel.ai","creator_url":"https://huggingface.co/gretelai","description":"\\n  \\n  Image generated by DALL-E. See prompt for more details\\n\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tüíº üìä Synthetic Financial Domain Documents with PII Labels\\n\\t\\n\\ngretelai/synthetic_pii_finance_multilingual is a dataset of full length synthetic financial documents containing Personally Identifiable Information (PII), generated using Gretel Navigator and released under Apache 2.0.\\nThis dataset is designed to assist with the following use cases:\\n\\nüè∑Ô∏è Training NER (Named Entity Recognition) models to detect and label PII in‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/gretelai/synthetic_pii_finance_multilingual."},
  {"name":"legalkit","keyword":"french","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/louisbrulenaudet/legalkit","creator_name":"Louis Brul√© Naudet","creator_url":"https://huggingface.co/louisbrulenaudet","description":"\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLegalKit, French labeled datasets built for legal ML training\\n\\t\\n\\nThis dataset consists of labeled data prepared for training sentence embeddings models in the context of French law. The labeling process utilizes the LLaMA-3-70B model through a structured workflow to enhance the quality of the labels. This dataset aims to support the development of natural language processing (NLP) models for understanding and working with legal texts in French.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLabeling Workflow‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/louisbrulenaudet/legalkit."},
  {"name":"youtube-video-summarization","keyword":"french","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/ClarityClips/youtube-video-summarization","creator_name":"ClarityClips","creator_url":"https://huggingface.co/ClarityClips","description":"ClarityClips/youtube-video-summarization dataset hosted on Hugging Face and contributed by the HF Datasets community"},
  {"name":"french-orca-dpo-pairs-revised","keyword":"french","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/jpacifico/french-orca-dpo-pairs-revised","creator_name":"Jonathan Pacifico","creator_url":"https://huggingface.co/jpacifico","description":"Full revision of the dataset AIffl/french_orca_dpo_pairsfrench translation of the 12k DPO Intel/orca_dpo_pairs built from Orca style dataset Open-Orca/OpenOrca.  \\nRevision made with mistral-large-2402 from MistralExample of this revision work below :  \\n  \\nMade by: Jonathan Pacifico, 2024Licence: Apache-2.0\\n"},
  {"name":"case-law","keyword":"french","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/HFforLegal/case-law","creator_name":"Hugging Face for Legal","creator_url":"https://huggingface.co/HFforLegal","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tThe Case-law, centralizing legal decisions for better use, a community Dataset.\\n\\t\\n\\nThe Case-law Dataset is a comprehensive collection of legal decisons from various countries, centralized in a common format. This dataset aims to improve the development of legal AI models by providing a standardized, easily accessible corpus of global legal documents.\\n\\n    Join us in our mission to make AI more accessible and understandable for the legal world, ensuring that the power of language‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/HFforLegal/case-law."},
  {"name":"table-vqa","keyword":"french","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/cmarkea/table-vqa","creator_name":"Credit Mutuel Arkea","creator_url":"https://huggingface.co/cmarkea","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset description\\n\\t\\n\\nThe table-vqa Dataset integrates images of tables from the dataset AFTdb (Arxiv Figure Table Database) curated by cmarkea. \\nThis dataset consists of pairs of table images and corresponding LaTeX source code, with each image linked to an average of ten questions and answers. Half of the Q&A pairs are in English and the other half in French. These questions and answers were generated using Gemini 1.5 Pro and Claude 3.5 sonnet, making the dataset well-suited for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/cmarkea/table-vqa."},
  {"name":"nomiracl-instruct","keyword":"french","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/miracl/nomiracl-instruct","creator_name":"MIRACL","creator_url":"https://huggingface.co/miracl","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for NoMIRACL (EMNLP 2024 Findings Track)\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tQuick Overview\\n\\t\\n\\nThis repository contains the fine-tuning (training & development split) of the NoMIRACL instruct dataset for fine-tuning LLMs on multilingual relevance assessment.\\nThe training dataset is a binary classification task; they need to explicitly output either Yes, answer is present or I don't know. \\nThe dataset contains training pairs from all 18 languages for both splits: relevant & non-relevant.‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/miracl/nomiracl-instruct."},
  {"name":"wikipedia-2024-06-bge-m3","keyword":"french","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/Upstash/wikipedia-2024-06-bge-m3","creator_name":"Upstash","creator_url":"https://huggingface.co/Upstash","description":"\\n\\t\\n\\t\\t\\n\\t\\tWikipedia Embeddings with BGE-M3\\n\\t\\n\\nThis dataset contains embeddings from the\\nJune 2024 Wikipedia dump\\nfor the 11 most popular languages.\\nThe embeddings are generated with the multilingual\\nBGE-M3 model.\\nThe dataset consists of Wikipedia articles split into paragraphs,\\nand embedded with the aforementioned model.\\nTo enhance search quality, the paragraphs are prefixed with their\\nrespective article titles before embedding.\\nAdditionally, paragraphs containing fewer than 100 characters‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Upstash/wikipedia-2024-06-bge-m3."},
  {"name":"text_ratings","keyword":"french","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/lightblue/text_ratings","creator_name":"Lightblue KK.","creator_url":"https://huggingface.co/lightblue","description":"Todo - Write dataset card\\n"},
  {"name":"SUMM-RE","keyword":"french","license":"Creative Commons Attribution Share Alike 4.0 International","language":"en","url":"https://huggingface.co/datasets/linagora/SUMM-RE","creator_name":"LINAGORA Labs","creator_url":"https://huggingface.co/linagora","description":"Note: if the data viewer is not working, use the \\\"example\\\" subset.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSUMM-RE\\n\\t\\n\\nThe SUMM-RE dataset is a collection of transcripts of French conversations, aligned with the audio signal.\\nIt is a corpus of meeting-style conversations in French created for the purpose of the SUMM-RE project (ANR-20-CE23-0017). \\nThe full dataset is described in Hunter et al. (2024): \\\"SUMM-RE: A corpus of French meeting-style conversations\\\".\\n\\nCreated by: Recording and manual correction of the corpus was‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/linagora/SUMM-RE."},
  {"name":"Romulus-cpt-fr","keyword":"french","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/louisbrulenaudet/Romulus-cpt-fr","creator_name":"Louis Brul√© Naudet","creator_url":"https://huggingface.co/louisbrulenaudet","description":"\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tRomulus, continually pre-trained models for French law.\\n\\t\\n\\nRomulus is a series of continually pre-trained models enriched in French law and intended to serve as the basis for a fine-tuning process on labeled data. Please note that these models have not been aligned for the production of usable text as they stand, and will certainly need to be fine-tuned for the desired tasks in order to produce satisfactory results.\\nThe training corpus is made up of around 34,864,949 tokens‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/louisbrulenaudet/Romulus-cpt-fr."},
  {"name":"MMMLU","keyword":"french","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/openai/MMMLU","creator_name":"OpenAI","creator_url":"https://huggingface.co/openai","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tMultilingual Massive Multitask Language Understanding (MMMLU)\\n\\t\\n\\nThe MMLU is a widely recognized benchmark of general knowledge attained by AI models. It covers a broad range of topics from 57 different categories, covering elementary-level knowledge up to advanced professional subjects like law, physics, history, and computer science.\\nWe translated the MMLU‚Äôs test set into 14 languages using professional human translators. Relying on human translators for this evaluation increases‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/openai/MMMLU."},
  {"name":"SimpleSmallFrenchQA","keyword":"french","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/MisterAI/SimpleSmallFrenchQA","creator_name":"MisterAI","creator_url":"https://huggingface.co/MisterAI","description":"\\n\\t\\n\\t\\t\\n\\t\\tPr√©sentation\\n\\t\\n\\nD√©p√¥t de datasets de type \\\"Question/R√©ponse\\\" (QR/QA) en Fran√ßais.\\nCes jeux de donn√©es sont con√ßus pour l'entra√Ænement et l'√©valuation de mod√®les de traitement du langage naturel (NLP).\\n\\n\\t\\n\\t\\t\\n\\t\\tDescription des Datasets\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tContenu\\n\\t\\n\\nLe d√©p√¥t contient plusieurs jeux de donn√©es :\\n\\nQuestions/R√©ponses G√©n√©rales : Questions sur des sujets vari√©s. R√©ponses factuelles et prouv√©es.\\nQuestions/R√©ponses d'√âvaluation : Questions con√ßues pour tester la compr√©hension et la‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/MisterAI/SimpleSmallFrenchQA."},
  {"name":"structured-wikipedia","keyword":"french","license":"Creative Commons Attribution Share Alike 4.0 International","language":"en","url":"https://huggingface.co/datasets/wikimedia/structured-wikipedia","creator_name":"Wikimedia","creator_url":"https://huggingface.co/wikimedia","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Wikimedia Structured Wikipedia\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nEarly beta release of pre-parsed English and French Wikipedia articles including infoboxes. Inviting feedback.\\nThis dataset contains all articles of the English and French language editions of Wikipedia, pre-parsed and outputted as structured JSON files with a consistent schema (JSONL compressed as zip). Each JSON line holds the content of one full Wikipedia article‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/wikimedia/structured-wikipedia."},
  {"name":"muri-it","keyword":"french","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/akoksal/muri-it","creator_name":"Abdullatif Koksal","creator_url":"https://huggingface.co/akoksal","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tMURI-IT: Multilingual Instruction Tuning Dataset for 200 Languages via Multilingual Reverse Instructions\\n\\t\\n\\nMURI-IT is a large-scale multilingual instruction tuning dataset containing 2.2 million instruction-output pairs across 200 languages. It is designed to address the challenges of instruction tuning in low-resource languages with Multilingual Reverse Instructions (MURI), which ensures that the output is human-written, high-quality, and authentic to the cultural and linguistic‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/akoksal/muri-it."},
  {"name":"mgsm","keyword":"french","license":"Creative Commons Attribution Share Alike 4.0 International","language":"en","url":"https://huggingface.co/datasets/jbross-ibm-research/mgsm","creator_name":"J Bross","creator_url":"https://huggingface.co/jbross-ibm-research","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for MGSM\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nCopy and merge of this MGSM Dataset, Catalan version, Basque version, Galician version, but in training samples we removed the prompt formatting, e.g. removed Question: ... in question field or Answer: ... in answer field.\\nMultilingual Grade School Math Benchmark (MGSM) is a benchmark of grade-school math problems, proposed in the paper Language models are multilingual chain-of-thought reasoners.\\nThe same 250 problems from‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/jbross-ibm-research/mgsm."},
  {"name":"synthetic-multi-pii-ner-v1","keyword":"french","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/E3-JSI/synthetic-multi-pii-ner-v1","creator_name":"Department for Artificial Intelligence, Jo≈æef Stefan Institute","creator_url":"https://huggingface.co/E3-JSI","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSynthetic Multilingual PII NER Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tModels Trained Using this Dataset\\n\\t\\n\\n\\nE3-JSI/gliner-multi-pii-domains-v1\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDescription\\n\\t\\n\\nThis is a synthetic dataset created for the purposes for training multilingual personally identifiable information (PII) named entity recognition (NER) models.\\nThe examples were generated using a prompt that generates the text and the entities present in the text. In addition, the generated response had to follow the‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/E3-JSI/synthetic-multi-pii-ner-v1."},
  {"name":"MultiSimV2","keyword":"french","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/MichaelR207/MultiSimV2","creator_name":"Michael Ryan","creator_url":"https://huggingface.co/MichaelR207","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for MultiSim Benchmark\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThe MultiSim benchmark is a growing collection of text simplification datasets targeted at sentence simplification in several languages.  Currently, the benchmark spans 12 languages.\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSupported Tasks\\n\\t\\n\\n\\nSentence Simplification\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tUsage\\n\\t\\n\\nfrom datasets import load_dataset\\n\\ndataset = load_dataset(\\\"MichaelR207/MultiSimV2\\\")\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tCitation\\n\\t\\n\\nIf you use this benchmark, please cite our‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/MichaelR207/MultiSimV2."},
  {"name":"vqa","keyword":"french","license":"Creative Commons Attribution Share Alike 4.0 International","language":"en","url":"https://huggingface.co/datasets/worldcuisines/vqa","creator_name":"World Cuisines","creator_url":"https://huggingface.co/worldcuisines","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tWorldCuisines: A Massive-Scale Benchmark for Multilingual and Multicultural Visual Question Answering on Global Cuisines\\n\\t\\n\\n\\nWorldCuisines is a massive-scale visual question answering (VQA) benchmark for multilingual and multicultural understanding through global cuisines. The dataset contains text-image pairs across 30 languages and dialects, spanning 9 language families and featuring over 1 million data points, making it the largest multicultural VQA benchmark as of 17 October‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/worldcuisines/vqa."},
  {"name":"wikipedia","keyword":"french","license":"Creative Commons Attribution Share Alike 4.0 International","language":"en","url":"https://huggingface.co/datasets/OpenLLM-France/wikipedia","creator_name":"OpenLLM France","creator_url":"https://huggingface.co/OpenLLM-France","description":"\\n\\t\\n\\t\\t\\n\\t\\tPlain text of Wikipedia\\n\\t\\n\\n\\nDataset Description\\nSize\\nExample use (python)\\nData fields\\nNotes on data formatting\\n\\n\\nLicense\\nAknowledgements\\nCitation\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThis dataset is a plain text version of pages from wikipedia.org spaces for several languages\\n(English,\\nGerman,\\nFrench,\\nSpanish,\\nItalian).\\nThe text is without HTML tags nor wiki templates.\\nIt just includes markdown syntax for headers, lists and tables.\\nSee Notes on data formatting for more details.\\nIt was‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/OpenLLM-France/wikipedia."},
  {"name":"HPLT2.0_cleaned","keyword":"french","license":"Creative Commons Zero v1.0 Universal","language":"en","url":"https://huggingface.co/datasets/HPLT/HPLT2.0_cleaned","creator_name":"HPLT","creator_url":"https://huggingface.co/HPLT","description":"This is a large-scale collection of web-crawled documents in 191 world languages, produced by the HPLT project. \\nThe source of the data is mostly Internet Archive with some additions from Common Crawl.\\nFor a detailed description of the dataset, please refer to https://hplt-project.org/datasets/v2.0\\nThe Cleaned variant of HPLT Datasets v2.0\\nThis is the cleaned variant of the HPLT Datasets v2.0 converted to the Parquet format semi-automatically when being uploaded here. \\nThe original JSONL files‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/HPLT/HPLT2.0_cleaned."},
  {"name":"m-ArenaHard","keyword":"french","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/CohereForAI/m-ArenaHard","creator_name":"Cohere For AI","creator_url":"https://huggingface.co/CohereForAI","description":"\\n\\t\\n\\t\\t\\n\\t\\tDataset Card for m-ArenaHard\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Details\\n\\t\\n\\nThe m-ArenaHard dataset is a multilingual LLM evaluation set. This dataset was created by translating the prompts from the originally English-only LMarena (formerly LMSYS) arena-hard-auto-v0.1 test dataset using Google Translate API v3 to 22 languages. The original English-only prompts were created by Li et al. (2024) and consist of 500 challenging user queries sourced from Chatbot Arena. The authors show that these can be used‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/CohereForAI/m-ArenaHard."},
  {"name":"french-multilingual-reward-bench-dpo","keyword":"french","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/Svngoku/french-multilingual-reward-bench-dpo","creator_name":"NIONGOLO Chrys F√©-Marty","creator_url":"https://huggingface.co/Svngoku","description":"Svngoku/french-multilingual-reward-bench-dpo dataset hosted on Hugging Face and contributed by the HF Datasets community"},
  {"name":"ToxicCommons","keyword":"french","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/PleIAs/ToxicCommons","creator_name":"PleIAs","creator_url":"https://huggingface.co/PleIAs","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tToxic Commons\\n\\t\\n\\nToxic Commons is a release of 2 million samples of annotated, public domain, multilingual text that was used to train Celadon. \\nIt is being released alongside Celadon, in order to better understand multilingual and multicultural toxicity. \\nEach sample was classified across 5 axes of toxicity:\\n\\nRace and origin-based bias: includes racism as well as bias against someone‚Äôs country or region of origin or immigration status, especially immigrant or refugee status.‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/PleIAs/ToxicCommons."},
  {"name":"post-ocr-correction","keyword":"french","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/jeanflop/post-ocr-correction","creator_name":"lompo","creator_url":"https://huggingface.co/jeanflop","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSynthetic OCR Correction Dataset\\n\\t\\n\\nThis dataset is a synthetic dataset generated for post-OCR correction tasks. It contains over 2,000,000 rows of French text pairs and follows the Croissant format. It is designed to train small language models (LLMs) for text correction.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDescription\\n\\t\\n\\nTo ensure the dataset closely resembles OCR-malformed texts, we applied various transformations randomly. This approach helps avoid the LLM identifying specific patterns and encourages‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/jeanflop/post-ocr-correction."},
  {"name":"PangeaBench-xmmmu","keyword":"french","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/neulab/PangeaBench-xmmmu","creator_name":"NeuLab @ LTI/CMU","creator_url":"https://huggingface.co/neulab","description":"neulab/PangeaBench-xmmmu dataset hosted on Hugging Face and contributed by the HF Datasets community"},
  {"name":"mergekit-configs","keyword":"french","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/louisbrulenaudet/mergekit-configs","creator_name":"Louis Brul√© Naudet","creator_url":"https://huggingface.co/louisbrulenaudet","description":"\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tMergeKit-configs: access all Hub architectures and automate your model merging process\\n\\t\\n\\nThis dataset facilitates the search for compatible architectures for model merging with MergeKit, streamlining the automation of high-performance merge searches. It provides a snapshot of the Hub‚Äôs configuration state, eliminating the need to manually open configuration files.\\nimport polars as pl\\n\\n# Login using e.g. `huggingface-cli login` to access this dataset\\ndf =‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/louisbrulenaudet/mergekit-configs."},
  {"name":"P-MMEval","keyword":"french","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/Qwen/P-MMEval","creator_name":"Qwen","creator_url":"https://huggingface.co/Qwen","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tP-MMEval: A Parallel Multilingual Multitask Benchmark for Consistent Evaluation of LLMs\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tIntroduction\\n\\t\\n\\nWe introduce a multilingual benchmark, P-MMEval, covering effective fundamental and capability-specialized datasets. We extend the existing benchmarks, ensuring consistent language coverage across all datasets and providing parallel samples among multiple languages, supporting up to 10 languages from 8 language families (i.e., en, zh, ar, es, ja, ko, th, fr, pt‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Qwen/P-MMEval."},
  {"name":"ai-prompts","keyword":"french","license":"GNU Affero General Public License v3.0","language":"en","url":"https://huggingface.co/datasets/eltorio/ai-prompts","creator_name":"Ronan L.M.","creator_url":"https://huggingface.co/eltorio","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tAI Prompts Dataset\\n\\t\\n\\nA collection of carefully crafted AI prompts used in the AI Outlook Add-in, designed to enhance email communication and assist in software development tasks.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tOverview\\n\\t\\n\\nThis dataset contains a variety of AI prompts originally developed for the AI Outlook Add-in. These prompts are intended to guide AI language models in tasks such as improving email drafts, translating text, summarizing content, drafting professional correspondence, and assisting‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/eltorio/ai-prompts."},
  {"name":"belebele-fleurs","keyword":"french","license":"Creative Commons Attribution Share Alike 4.0 International","language":"en","url":"https://huggingface.co/datasets/WueNLP/belebele-fleurs","creator_name":"W√ºNLP","creator_url":"https://huggingface.co/WueNLP","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tBelebele-Fleurs\\n\\t\\n\\nBelebele-Fleurs is a dataset suitable to evaluate two core tasks:\\n\\nMultilingual Spoken Language Understanding (Listening Comprehension): For each spoken paragraph, the task is to answer a multiple-choice question. The question and four answer choices are provided in text form.\\nMultilingual Long-Form Automatic Speech Recognition (ASR) with Diverse Speakers: By concatenating sentence-level utterances, long-form audio clips (ranging from 30 seconds to 1 minute 30‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/WueNLP/belebele-fleurs."},
  {"name":"MooreFRCollections","keyword":"french","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/sawadogosalif/MooreFRCollections","creator_name":"SAWADOGO Salif","creator_url":"https://huggingface.co/sawadogosalif","description":"\\n\\t\\n\\t\\t\\n\\t\\tMooreFRCollections - Jeu de donn√©es bilingue Moor√©-Fran√ßais\\n\\t\\n\\nMooreFRCollections est un projet ouvert d√©di√© √† la cr√©ation d‚Äôun corpus bilingue Moor√©-Fran√ßais pour la recherche et le d√©veloppement de technologies linguistiques adapt√©es au contexte burkinab√©. L‚Äôobjectif est de fournir un outil essentiel pour tester, entra√Æner, et affiner des mod√®les de traduction et d‚Äôautres applications d‚Äôapprentissage automatique. Ce projet met en avant le Moor√©, une langue locale du Burkina Faso.‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/sawadogosalif/MooreFRCollections."},
  {"name":"include-base-44","keyword":"french","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/CohereForAI/include-base-44","creator_name":"Cohere For AI","creator_url":"https://huggingface.co/CohereForAI","description":"\\n\\t\\n\\t\\t\\n\\t\\tINCLUDE-base (44 languages)\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\n\\n\\nPaper: http://arxiv.org/abs/2411.19799\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nINCLUDE is a comprehensive knowledge- and reasoning-centric benchmark across 44 languages that evaluates multilingual LLMs for performance in the actual language environments where they would be deployed. \\nIt contains 22,637 4-option multiple-choice-questions (MCQ) extracted from academic and professional exams, covering 57 topics, including regional‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/CohereForAI/include-base-44."},
  {"name":"unlabelled-sti-corpus","keyword":"french","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/SIRIS-Lab/unlabelled-sti-corpus","creator_name":"SIRIS Lab, Research Division of SIRIS Academic","creator_url":"https://huggingface.co/SIRIS-Lab","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThe unlabelled-sti-corpus is a diverse dataset designed for developing information extraction datasets (i.e. text classification or NER) for Science, Technology, and Innovation (STI) records. The corpus contains approximately 35,000 records sourced from four major repositories:\\n\\n22,500 publications from OpenAlex\\n10,000 European research projects from CORDIS\\n5,000 regional projects from Interreg and Kohesio\\n7,000 patents from Lens.org\\n\\nThe dataset is‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/SIRIS-Lab/unlabelled-sti-corpus."},
  {"name":"open-dict-words-ipa","keyword":"french","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/StephanAkkerman/open-dict-words-ipa","creator_name":"Stephan Akkerman","creator_url":"https://huggingface.co/StephanAkkerman","description":"\\n\\t\\n\\t\\t\\n\\t\\tOpen-dict Words IPA\\n\\t\\n\\nThis dataset is a copy of https://github.com/open-dict-data/ipa-dict\\n\\n\\t\\n\\t\\t\\n\\t\\tLanguages\\n\\t\\n\\nIPA data is currently available for the following languages:\\n\\n\\t\\n\\t\\t\\nLanguage\\nCode\\n\\n\\n\\t\\t\\nar\\nArabic (Modern Standard)\\n\\n\\nde\\nGerman\\n\\n\\nen_UK\\nEnglish (Received Pronunciation)\\n\\n\\nen_US\\nEnglish (General American)\\n\\n\\neo\\nEsperanto\\n\\n\\nes_ES\\nSpanish (Spain)\\n\\n\\nes_MX\\nSpanish (Mexico)\\n\\n\\nfa\\nPersian\\n\\n\\nfi\\nFinnish\\n\\n\\nfr_FR\\nFrench (France)\\n\\n\\nfr_QC\\nFrench (Qu√©bec)\\n\\n\\nis\\nIcelandic\\n\\n\\nja\\nJapanese\\n\\n\\njam‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/StephanAkkerman/open-dict-words-ipa."},
  {"name":"include-lite-44","keyword":"french","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/CohereForAI/include-lite-44","creator_name":"Cohere For AI","creator_url":"https://huggingface.co/CohereForAI","description":"\\n\\t\\n\\t\\t\\n\\t\\tINCLUDE-lite (44 languages)\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\n\\n\\nPaper: http://arxiv.org/abs/2411.19799\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nINCLUDE is a comprehensive knowledge- and reasoning-centric benchmark across 44 languages that evaluates multilingual LLMs for performance in the actual language environments where they would be deployed. \\nIt contains 11,095 4-option multiple-choice-questions (MCQ) extracted from academic and professional exams, covering 57 topics, including regional‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/CohereForAI/include-lite-44."},
  {"name":"sib-fleurs","keyword":"french","license":"Creative Commons Attribution Share Alike 4.0 International","language":"en","url":"https://huggingface.co/datasets/WueNLP/sib-fleurs","creator_name":"W√ºNLP","creator_url":"https://huggingface.co/WueNLP","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSIB-Fleurs\\n\\t\\n\\nSIB-Fleurs is a dataset suitable to evaluate Multilingual Spoken Language Understanding. For each utterance in Fleurs, the task is to determine the topic the utterance belongs to. \\nThe topics are:\\n\\nScience/Technology\\nTravel\\nPolitics\\nSports\\nHealth\\nEntertainment\\nGeography\\n\\nPreliminary evaluations can be found at the bottom of the README. The preliminary results in full detail are available in ./results.csv*.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset creation\\n\\t\\n\\nThis dataset processes and‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/WueNLP/sib-fleurs."},
  {"name":"ccass_rapprochements_sommaires_with_sources","keyword":"french","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/maurya/ccass_rapprochements_sommaires_with_sources","creator_name":"Amaury Fouret","creator_url":"https://huggingface.co/maurya","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tTraining dataset for semantic textual similarity of French Court of cassation summaries\\n\\t\\n\\nThis CSV dataset is designed to train similarity models using pairs of court decision summaries. The dataset includes similar legal cases with comparable contextual frameworks and principled legal solutions derived from consistent judicial standards. The cases are categorized by the following roles:\\n\\nComparative case analyses\\nJudicial decision reversals\\n\\nEach case entry includes a link to the‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/maurya/ccass_rapprochements_sommaires_with_sources."},
  {"name":"Global-MMLU-Lite","keyword":"french","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/CohereForAI/Global-MMLU-Lite","creator_name":"Cohere For AI","creator_url":"https://huggingface.co/CohereForAI","description":"\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nGlobal-MMLU-Lite is a multilingual evaluation set spanning 15 languages, including English. It is \\\"lite\\\" version of the original Global-MMLU dataset üåç.\\nIt includes 200 Culturally Sensitive (CS) and 200 Culturally Agnostic (CA) samples per language. The samples in Global-MMLU-Lite are corresponding to languages which are fully human translated or post-edited in the original Global-MMLU dataset. \\n\\nCurated by: Professional annotators and contributors of Cohere For‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/CohereForAI/Global-MMLU-Lite."},
  {"name":"2M-Belebele","keyword":"french","license":"Creative Commons Attribution Share Alike 4.0 International","language":"en","url":"https://huggingface.co/datasets/facebook/2M-Belebele","creator_name":"AI at Meta","creator_url":"https://huggingface.co/facebook","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\t2M-Belebele\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tHighly-Multilingual Speech and American Sign Language Comprehension Dataset\\n\\t\\n\\nWe introduce 2M-Belebele as the first highly multilingual speech and American Sign Language (ASL) comprehension dataset. Our dataset, which is an extension of the existing Belebele only-text dataset, covers 74 spoken languages at the intersection of Belebele and Fleurs, and one sign language (ASL). \\nThe speech dataset is built from aligning Belebele, Flores200 and Fleurs‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/facebook/2M-Belebele."},
  {"name":"reranker_continuous_filt_max7_train","keyword":"french","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/lightblue/reranker_continuous_filt_max7_train","creator_name":"Lightblue KK.","creator_url":"https://huggingface.co/lightblue","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tReranker training data\\n\\t\\n\\nThis data was generated using 4 steps:\\n\\nWe gathered queries and corresponding text data from 35 high quality datasets covering more than 95 languages.\\nFor datasets which did not already have negative texts for queries, we mined hard negatives using the BAAI/bge-m3 embedding model.\\nFor each query, we selected one positive and one negative text and used Qwen/Qwen2.5-32B-Instruct-GPTQ-Int4 to rate the relatedness of each query-text pair using a token \\\"1\\\", \\\"2\\\"‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/lightblue/reranker_continuous_filt_max7_train."},
  {"name":"reranking-datasets-light","keyword":"french","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/abdoelsayed/reranking-datasets-light","creator_name":"unkown","creator_url":"https://huggingface.co/abdoelsayed","description":"\\n\\t\\n\\t\\t\\n\\t\\tüî• Rankify: A Comprehensive Python Toolkit for Retrieval, Re-Ranking, and Retrieval-Augmented Generation üî•\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tReRanking Datasets : A comprehensive collection of retrieval and reranking datasets with full passage contexts, including titles, text, and metadata for in-depth research.\\n\\t\\n\\n\\n    \\n    \\n    \\n    \\n    \\n    \\n        \\n    \\n    \\n        \\n    \\n    \\n        \\n    \\n    \\n        \\n    \\n    \\n    \\n\\n\\n\\nA curated collection of ready-to-use datasets for retrieval and reranking‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/abdoelsayed/reranking-datasets-light."},
  {"name":"MultiLingualSentiment","keyword":"french","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/clapAI/MultiLingualSentiment","creator_name":"clapAI","creator_url":"https://huggingface.co/clapAI","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tOverview\\n\\t\\n\\nMultilingualSentiment is a sentiment classification dataset that encompasses three sentiment labels: Positive, Neutral, Negative\\nThe dataset spans multiple languages and covers a wide range of domains, making it ideal for multilingual sentiment analysis tasks.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Information\\n\\t\\n\\nThe dataset was meticulously collected and aggregated from various sources, including Hugging Face and Kaggle. These sources provide diverse languages and domains to ensure a‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/clapAI/MultiLingualSentiment."},
  {"name":"Multilingual_Topic-Specific_Article-Extraction_and_Classification","keyword":"french","license":"Creative Commons Zero v1.0 Universal","language":"en","url":"https://huggingface.co/datasets/oberbics/Multilingual_Topic-Specific_Article-Extraction_and_Classification","creator_name":"Oberbichler","creator_url":"https://huggingface.co/oberbics","description":"\\n\\t\\n\\t\\t\\n\\t\\tDataset Card for Multilingual Historical News Article Extraction and Classification Dataset\\n\\t\\n\\nThis dataset was created specifically to test Large Language Models' (LLMs) capabilities in processing and extracting topic-specific content from historical newspapers based on OCR'd text.\\n\\n\\t\\n\\t\\t\\n\\t\\tCite the Dataset\\n\\t\\n\\nMauermann, Johanna, Gonz√°lez-Gallardo, Carlos-Emiliano, and Oberbichler, Sarah. (2025). Multilingual Topic-Specific Article-Extraction and Classification [Data set]. Hugging‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/oberbics/Multilingual_Topic-Specific_Article-Extraction_and_Classification."},
  {"name":"BoundingDocs","keyword":"french","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/letxbe/BoundingDocs","creator_name":"Letxbe","creator_url":"https://huggingface.co/letxbe","description":"\\n\\nBoundingDocs\\n\\nüîç The largest spatially-annotated dataset for Document Question Answering\\n\\n\\n\\n\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nBoundingDocs is a unified dataset for Document Question Answering (QA) that includes spatial annotations. It consolidates multiple public datasets from Document AI and Visually Rich Document Understanding (VRDU) domains. The dataset reformulates Information Extraction (IE) tasks into QA tasks, making it a valuable resource for training and evaluating Large Language‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/letxbe/BoundingDocs."},
  {"name":"vdr-multilingual-train","keyword":"french","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/llamaindex/vdr-multilingual-train","creator_name":"LlamaIndex","creator_url":"https://huggingface.co/llamaindex","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tMultilingual Visual Document Retrieval Dataset\\n\\t\\n\\n\\n\\nThis dataset consists of 500k multilingual query image samples, collected and generated from scratch using public internet pdfs. The queries are synthetic and generated using VLMs (gemini-1.5-pro and Qwen2-VL-72B).\\n\\nIt was used to train the vdr-2b-multi-v1 retrieval multimodal, multilingual embedding model.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tHow it was created\\n\\t\\n\\nThis is the entire data pipeline used to create the Italian subset of this dataset. Each‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/llamaindex/vdr-multilingual-train."},
  {"name":"vdr-multilingual-test","keyword":"french","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/llamaindex/vdr-multilingual-test","creator_name":"LlamaIndex","creator_url":"https://huggingface.co/llamaindex","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tMultilingual Visual Document Retrieval Benchmarks\\n\\t\\n\\n\\nThis dataset consists of 15 different benchmarks used to initially evaluate the vdr-2b-multi-v1 multimodal retrieval embedding model. These benchmarks allow the testing of multilingual, multimodal retrieval capabilities on text-only, visual-only and mixed page screenshots.\\nEach language subset contains queries and images in that language and is divided into three different categories by the \\\"pagetype\\\" column. Each category‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/llamaindex/vdr-multilingual-test."},
  {"name":"bam-asr-all","keyword":"french","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/RobotsMali/bam-asr-all","creator_name":"RobotsMali AI4D LAB","creator_url":"https://huggingface.co/RobotsMali","description":"The **Bambara-ASR-All Audio Dataset** is a multilingual dataset containing audio samples in Bambara, accompanied by semi-expert transcriptions and French translations. \\nThe dataset includes various subsets: `jeli-asr`, `oza-mali-pense`, and `rt-data-collection`. Each audio file is aligned with Bambara transcriptions or French translations, making it suitable for tasks such as automatic speech recognition (ASR) and translation. \\nData sources include all publicly available collections of audio with Bambara transcriptions, organized for accessibility and usability.\\n"},
  {"name":"bam-asr-all","keyword":"french","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/RobotsMali/bam-asr-all","creator_name":"RobotsMali AI4D LAB","creator_url":"https://huggingface.co/RobotsMali","description":"The **Bambara-ASR-All Audio Dataset** is a multilingual dataset containing audio samples in Bambara, accompanied by semi-expert transcriptions and French translations. \\nThe dataset includes various subsets: `jeli-asr`, `oza-mali-pense`, and `rt-data-collection`. Each audio file is aligned with Bambara transcriptions or French translations, making it suitable for tasks such as automatic speech recognition (ASR) and translation. \\nData sources include all publicly available collections of audio with Bambara transcriptions, organized for accessibility and usability.\\n"},
  {"name":"Croissant-Aligned-Instruct","keyword":"french","license":"Creative Commons Attribution Share Alike 4.0 International","language":"en","url":"https://huggingface.co/datasets/OpenLLM-France/Croissant-Aligned-Instruct","creator_name":"OpenLLM France","creator_url":"https://huggingface.co/OpenLLM-France","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tCorpus overview\\n\\t\\n\\nCroissant Aligned Instruct is an instruction-formatted version of the parallel French-English data in croissantllm/croissant_dataset_no_web_data\\n(subset: aligned_36b).\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tThe original dataset\\n\\t\\n\\nThe original CroissantAligned dataset contains samples of parallel French/English (or English/French) data from OPUS‚Äô13 (99.6% of the data in CroissantAligned), thesis abstracts, and translated song lyrics.\\nData extracted from OPUS takes the form of sentences‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/OpenLLM-France/Croissant-Aligned-Instruct."},
  {"name":"degeneration-html-multilingual","keyword":"french","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/Degeneration-Nation/degeneration-html-multilingual","creator_name":"The Degeneration of the Nation","creator_url":"https://huggingface.co/Degeneration-Nation","description":"\\n\\t\\n\\t\\t\\n\\t\\tThe Degeneration of the Nation Multilingual Dataset\\n\\t\\n\\nThis dataset contains the complete content of The Degeneration of the Nation project, a comprehensive philosophical and cultural website exploring the intersection of technology, artificial intelligence, and human culture. The content includes philosophical essays, cultural analysis, and contemporary literature, with complex parallel structure and sophisticated HTML architecture across all language versions.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Degeneration-Nation/degeneration-html-multilingual."},
  {"name":"Numbers","keyword":"french","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/Tamazight/Numbers","creator_name":"Standard Moroccan Tamazight (ZGH)","creator_url":"https://huggingface.co/Tamazight","description":"\\n\\t\\n\\t\\t\\n\\t\\tTamazight Numbers Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThis dataset contains numbers from 1 to 1,000,000 translated into:\\n\\nEnglish.\\nFrench.\\nSpanish.\\nTamazight (Berber).\\n\\nThe dataset is designed to assist researchers and developers in building machine learning models for understanding and converting numbers into words in multiple languages.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Structure\\n\\t\\n\\nThe dataset contains the following columns:\\n\\n\\t\\n\\t\\t\\nColumn\\nDescription\\nExample\\n\\n\\n\\t\\t\\nNumber\\nThe numeric‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Tamazight/Numbers."},
  {"name":"French_MultiSpeaker_Diarization","keyword":"french","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/olafdil/French_MultiSpeaker_Diarization","creator_name":"Oussama Lafdil","creator_url":"https://huggingface.co/olafdil","description":"\\n\\t\\n\\t\\t\\n\\t\\tFrench Multi-Speaker Diarization Dataset\\n\\t\\n\\nThis dataset is designed for training models for multi-speaker diarization in French. It contains transcriptions of conversations with multiple speakers, where the dialogues have been segmented and labeled by speaker. The dataset is ideal for tasks such as speaker diarization.\\nNote: All conversations in this dataset are entirely fictitious and were generated using AI. They do not reference real events, people, or organizations.‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/olafdil/French_MultiSpeaker_Diarization."},
  {"name":"wmt-da-human-evaluation-long-context","keyword":"french","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/ymoslem/wmt-da-human-evaluation-long-context","creator_name":"Yasmin Moslem","creator_url":"https://huggingface.co/ymoslem","description":"\\n\\t\\n\\t\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nLong-context / document-level dataset for Quality Estimation of Machine Translation.\\nIt is an augmented variant of the sentence-level WMT DA Human Evaluation dataset.\\nIn addition to individual sentences, it contains augmentations of 2, 4, 8, 16, and 32 sentences, among each language pair lp and domain.\\nThe raw column represents a weighted average of scores of augmented sentences using character lengths of src and mt as weights.\\nThe code used to apply the augmentation‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ymoslem/wmt-da-human-evaluation-long-context."},
  {"name":"Expert_comptable","keyword":"french","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/Aktraiser/Expert_comptable","creator_name":"bometon","creator_url":"https://huggingface.co/Aktraiser","description":"\\n\\t\\n\\t\\t\\n\\t\\tAccounting Concepts and Practices Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tOverview\\n\\t\\n\\nThe Accounting Concepts and Practices Dataset is a comprehensive collection of 22,000 rows of structured data focusing on accounting concepts, methods, and regulations. The dataset is designed for educational purposes, automation, and training of AI models in financial and accounting domains.\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Details\\n\\t\\n\\n\\nPretty Name: Accounting Concepts and Practices\\nLanguage: French (fr)\\nLicense: CC BY-SA 4.0 (or your‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Aktraiser/Expert_comptable."},
  {"name":"imatrix-calibration","keyword":"french","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/eaddario/imatrix-calibration","creator_name":"Ed Addario","creator_url":"https://huggingface.co/eaddario","description":"\\n\\t\\n\\t\\t\\n\\t\\tImportance Matrix (imatrix) calibration datasets\\n\\t\\n\\nThis dataset consists of over 10M tokens of cleaned and de-duplicated text files for 13 different languages. Each language file is available in five sizes, ranging from large (~ 26,000 lines equivalent to approx. 750K tokens), to micro (~ 1,625 lines and 125K tokens avg).\\nOriginal data sourced from HuggingFaceFW/fineweb and HuggingFaceFW/fineweb-2\\n\\n\\t\\n\\t\\t\\nFile\\nLanguage\\nLines\\nSize\\n\\n\\n\\t\\t\\ncalibration_ar_large\\nArabic\\n26,000\\n3.1M‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/eaddario/imatrix-calibration."},
  {"name":"open_government","keyword":"french","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/AgentPublic/open_government","creator_name":"AgentPublic","creator_url":"https://huggingface.co/AgentPublic","description":"\\n\\t\\n\\t\\t\\n\\t\\tOpen Government Dataset\\n\\t\\n\\nOpen Government is the largest agregation of governement text and data made available as part of open data programs. \\nIn total, the dataset contains approximately 380B tokens. While Open Government aims to become a global resource, in its current state it mostly features open datasets from the US, France, European and international organizations.\\nThe dataset comprises 16 collections curated through two different initiaties: Finance commons and Legal commons.‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/AgentPublic/open_government."},
  {"name":"Synthdog-Multilingual-100","keyword":"french","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/WueNLP/Synthdog-Multilingual-100","creator_name":"W√ºNLP","creator_url":"https://huggingface.co/WueNLP","description":"\\n\\t\\n\\t\\t\\n\\t\\tSynthdog Multilingual\\n\\t\\n\\n\\n\\nThe Synthdog dataset created for training in Centurio: On Drivers of Multilingual Ability of Large Vision-Language Model.\\nUsing the official Synthdog code, we created >1 million training samples for improving OCR capabilities in Large Vision-Language Models.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Details\\n\\t\\n\\nWe provide the images for download in two .tar.gz files. Download and extract them in folders of the same name (so cat images.tar.gz.* | tar xvzf -C images; tar xvzf‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/WueNLP/Synthdog-Multilingual-100."},
  {"name":"codes_juridiques","keyword":"french","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/Tricoteuses/codes_juridiques","creator_name":"Tricoteuses","creator_url":"https://huggingface.co/Tricoteuses","description":"\\n\\t\\n\\t\\t\\n\\t\\tL√©gifrance Legislative Text Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThe L√©gifrance Legislative Text Dataset is a structured collection of French legislative and regulatory texts extracted from the L√©gifrance platform.\\nThis dataset provides machine-readable access to consolidated legal codes, with a particular focus on maintaining the integrity of French linguistic features while providing additional metadata and quality signals.\\nThe data in this dataset comes from the Git repository‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Tricoteuses/codes_juridiques."},
  {"name":"fr_wolof_quran_corpus","keyword":"french","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/Lahad/fr_wolof_quran_corpus","creator_name":"Lahad Mbacke","creator_url":"https://huggingface.co/Lahad","description":"\\n\\t\\n\\t\\t\\n\\t\\tDataset Card for Dataset Name\\n\\t\\n\\n\\n\\nThis dataset card aims to be a base template for new datasets. It has been generated using this raw template.\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Details\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\n\\n\\n\\n\\n\\nCurated by: [More Information Needed]\\nFunded by [optional]: [More Information Needed]\\nShared by [optional]: [More Information Needed]\\nLanguage(s) (NLP): [More Information Needed]\\nLicense: [More Information Needed]\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Sources [optional]\\n\\t\\n\\n\\n\\n\\nRepository: [More‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Lahad/fr_wolof_quran_corpus."},
  {"name":"BenchMAX_Math","keyword":"french","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/LLaMAX/BenchMAX_Math","creator_name":"LLaMAX","creator_url":"https://huggingface.co/LLaMAX","description":"\\n\\t\\n\\t\\t\\n\\t\\tDataset Sources\\n\\t\\n\\n\\nPaper: BenchMAX: A Comprehensive Multilingual Evaluation Suite for Large Language Models\\nLink: https://arxiv.org/pdf/2502.07346\\nRepository: https://github.com/CONE-MT/BenchMAX\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\nBenchMAX_Math is a dataset of BenchMAX, sourcing from MGSM.\\nWe extend the original dataset to 6 more languages.\\nThe data is first translated by Google Translate, and then post-editing by native speakers.\\n\\n\\t\\n\\t\\t\\n\\t\\tSupported Languages\\n\\t\\n\\nArabic, Bengali, Chinese‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/LLaMAX/BenchMAX_Math."},
  {"name":"BenchMAX_Science","keyword":"french","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/LLaMAX/BenchMAX_Science","creator_name":"LLaMAX","creator_url":"https://huggingface.co/LLaMAX","description":"\\n\\t\\n\\t\\t\\n\\t\\tDataset Sources\\n\\t\\n\\n\\nPaper: BenchMAX: A Comprehensive Multilingual Evaluation Suite for Large Language Models\\nLink: https://arxiv.org/pdf/2502.07346\\nRepository: https://github.com/CONE-MT/BenchMAX\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\nBenchMAX_Science is a dataset of BenchMAX, sourcing from GPQA.\\nWe extend the original English dataset to 16 non-English languages.\\nThe data is first translated by Google Translate, and then post-editing by native speakers.\\n\\n\\t\\n\\t\\t\\n\\t\\tSupported Languages\\n\\t\\n\\nArabic‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/LLaMAX/BenchMAX_Science."},
  {"name":"BenchMAX_Function_Completion","keyword":"french","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/LLaMAX/BenchMAX_Function_Completion","creator_name":"LLaMAX","creator_url":"https://huggingface.co/LLaMAX","description":"\\n\\t\\n\\t\\t\\n\\t\\tDataset Sources\\n\\t\\n\\n\\nPaper: BenchMAX: A Comprehensive Multilingual Evaluation Suite for Large Language Models\\nLink: https://arxiv.org/pdf/2502.07346\\nRepository: https://github.com/CONE-MT/BenchMAX\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\nBenchMAX_Function_Completion is a dataset of BenchMAX, sourcing from humanevalplus.\\nWe extend the original English dataset to 16 non-English languages.\\nThe data is first translated by GPT-4o, and then post-editing by native speakers.\\n\\n\\t\\n\\t\\t\\n\\t\\tSupported Languages‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/LLaMAX/BenchMAX_Function_Completion."},
  {"name":"BenchMAX_Problem_Solving","keyword":"french","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/LLaMAX/BenchMAX_Problem_Solving","creator_name":"LLaMAX","creator_url":"https://huggingface.co/LLaMAX","description":"\\n\\t\\n\\t\\t\\n\\t\\tDataset Sources\\n\\t\\n\\n\\nPaper: BenchMAX: A Comprehensive Multilingual Evaluation Suite for Large Language Models\\nLink: https://arxiv.org/pdf/2502.07346\\nRepository: https://github.com/CONE-MT/BenchMAX\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\nBenchMAX_Problem_Solving is a dataset of BenchMAX, sourcing from LiveCodeBench.\\nWe extend the original English dataset to 16 non-English languages.\\nThe data is first translated by GPT-4o, and then post-editing by native speakers.\\n\\n\\t\\n\\t\\t\\n\\t\\tSupported Languages‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/LLaMAX/BenchMAX_Problem_Solving."},
  {"name":"smol","keyword":"french","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/google/smol","creator_name":"Google","creator_url":"https://huggingface.co/google","description":"\\n\\t\\n\\t\\t\\n\\t\\tSMOL\\n\\t\\n\\nSMOL (Set for Maximal Overall Leverage) is a collection of professional\\ntranslations into 221 Low-Resource Languages, for the purpose of training\\ntranslation models, and otherwise increasing the representations of said\\nlanguages in NLP and technology.\\nPlease read the SMOL Paper and the\\nGATITOS Paper for a much more\\nthorough description!\\nThere are four resources in this directory:\\n\\nSmolDoc: document-level translations into 100 languages\\nSmolSent: sentence-level translations into‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/google/smol."},
  {"name":"LivingNER","keyword":"french","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/Praise2112/LivingNER","creator_name":"Praise","creator_url":"https://huggingface.co/Praise2112","description":"\\n\\t\\n\\t\\t\\n\\t\\tLivingNER: Named entity recognition, normalization & classification of species, pathogens and food\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThe LivingNER Gold Standard corpus is a collection of 2000 clinical case reports covering a broad range of medical specialities, i.e. infectious diseases (including Covid-19 cases), cardiology, neurology, oncology, dentistry, pediatrics, endocrinology, primary care, allergology, radiology, psychiatry, ophthalmology, urology, internal medicine, emergency and‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Praise2112/LivingNER."},
  {"name":"DATA-AI_Chat","keyword":"french","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/Mattimax/DATA-AI_Chat","creator_name":"M.INC.","creator_url":"https://huggingface.co/Mattimax","description":"\\n\\t\\n\\t\\t\\n\\t\\tDATA-AI: Il Modello di IA di M.INC.\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tüìå Introduzione\\n\\t\\n\\nDATA-AI √® un avanzato modello di intelligenza artificiale sviluppato da *M.INC., un'azienda italiana fondata da *Mattimax (M. Marzorati).Questo modello √® basato sull'architettura ELNS (Elaborazione del Linguaggio Naturale Semplice), un sistema innovativo progettato per rendere l'IA accessibile su quasi qualsiasi dispositivo, garantendo prestazioni ottimali anche su hardware limitato.  \\nDATA-AI √® stato addestrato su un‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Mattimax/DATA-AI_Chat."},
  {"name":"ea-mt-benchmark","keyword":"french","license":"Creative Commons Attribution Share Alike 4.0 International","language":"en","url":"https://huggingface.co/datasets/sapienzanlp/ea-mt-benchmark","creator_name":"Sapienza NLP, Sapienza University of Rome","creator_url":"https://huggingface.co/sapienzanlp","description":"\\n\\t\\n\\t\\t\\n\\t\\tDataset Card for EA-MT\\n\\t\\n\\nEA-MT (Entity-Aware Machine Translation) is a multilingual benchmark for evaluating the capabilities of Large Language Models (LLMs) and Machine Translation (MT) models in translating simple sentences with potentially challenging entity mentions, e.g., entities for which a word-for-word translation may not be accurate.\\nHere is an example of a simple sentence with a challenging entity mention:\\n\\nEnglish: \\\"What is the plot of The Catcher in the Rye?\\\"\\nItalian:‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/sapienzanlp/ea-mt-benchmark."},
  {"name":"u-sticker","keyword":"french","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/metchee/u-sticker","creator_name":"Metilda Chee","creator_url":"https://huggingface.co/metchee","description":"\\n\\t\\n\\t\\t\\n\\t\\tU-Sticker\\n\\t\\n\\nUser-Sticker is a stickers dataset with multi-domain conversations.\\nFeatures of U-Sticker:\\n\\nMulti-domain interactions ‚úÖ\\nTemporal ‚úÖ\\nUser information ‚úÖ\\n370.2k stickers ‚úÖ (104k unique)\\n22.6k users ‚úÖ\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\nU-Sticker contains three files:\\n\\nConversation files: 1 to 67.json\\nDomain mapping files idx_to_domain.txt.\\nSticker files.\\n\\n\\nSticker files are available here and Baidu Cloud.\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Structure\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tConversation file\\n\\t\\n\\n\\nEmpty lines are‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/metchee/u-sticker."},
  {"name":"fr-mmlu_college_biology","keyword":"french","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/Anony-mous123/fr-mmlu_college_biology","creator_name":"a123","creator_url":"https://huggingface.co/Anony-mous123","description":"Anony-mous123/fr-mmlu_college_biology dataset hosted on Hugging Face and contributed by the HF Datasets community"},
  {"name":"Pensez-v0.1","keyword":"french","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/HoangHa/Pensez-v0.1","creator_name":"H√† Huy Ho√†ng","creator_url":"https://huggingface.co/HoangHa","description":"\\n"},
  {"name":"high-quality-multilingual-sentences","keyword":"french","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/agentlans/high-quality-multilingual-sentences","creator_name":"Alan Tseng","creator_url":"https://huggingface.co/agentlans","description":"\\n\\t\\n\\t\\t\\n\\t\\tHigh Quality Multilingual Sentences\\n\\t\\n\\n\\nThis dataset contains multilingual sentences derived from the agentlans/LinguaNova dataset.\\nIt includes 1.58 million rows across 51 different languages, each in its own configuration.\\n\\nExample row (from the all config):\\n{\\n    \\\"text\\\": \\\"ÿßŸÖÿßŸÖ ÿ¨ŸÖÿπŸá ÿßÿµŸÅŸáÿßŸÜ ⁄ØŸÅÿ™: ŸÖ€åÿ≤ÿßŸÜ ŸÜ€åÿßÿ≤ ÿ¢ÿ® ÿ¥ÿ±ÿ® ÿßÿµŸÅŸáÿßŸÜ €±€±.€µ ŸÖÿ™ÿ± ŸÖ⁄©ÿπÿ® ÿßÿ≥ÿ™ ⁄©Ÿá ÿ™ŸÖÿßŸÖ ÿßÿ≥ÿ™ÿßŸÜ ÿßÿµŸÅŸáÿßŸÜ ÿ±ÿß ŸæŸàÿ¥ÿ¥ ŸÖ€åÿØŸáÿØ Ÿà ŸÜÿ≥ÿ®ÿ™ ÿ®Ÿá ŸÇÿ®ŸÑ ÿßÿ≤ ÿßŸÜŸÇŸÑÿßÿ® €å⁄©€å ÿßÿ≤ Ÿæ€åÿ¥ÿ±ŸÅÿ™Ÿáÿß ÿØÿ± ÿ≠Ÿàÿ≤Ÿá ÿ¢ÿ® ÿ®ŸàÿØŸá ÿßÿ≥ÿ™.\\\",\\n    \\\"fasttext\\\": \\\"fa\\\",\\n    \\\"gcld3\\\": \\\"fa\\\"\\n}\\n\\nFields:‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/agentlans/high-quality-multilingual-sentences."},
  {"name":"Open-R1-Mulitlingual-SFT","keyword":"french","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/amphora/Open-R1-Mulitlingual-SFT","creator_name":"GUIJIN SON","creator_url":"https://huggingface.co/amphora","description":"\\n\\t\\n\\t\\t\\n\\t\\tOpen-R1-Mulitlingual-SFT\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tOverview\\n\\t\\n\\nOpen-R1-Mulitlingual-SFT is a curated dataset designed for multilingual supervised fine-tuning.\\nThe source data comprises multiple datasets containing original prompts and responses, which were subsequently translated into 14 languages using GPT-4o.\\n\\n\\t\\n\\t\\t\\n\\t\\tSources\\n\\t\\n\\nThe dataset is derived from:\\n\\nopen-thoughts/OpenThoughts-114kHugging Face: open-thoughts/OpenThoughts-114k\\nbespokelabs/Bespoke-Stratos-17kHugging Face:‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/amphora/Open-R1-Mulitlingual-SFT."},
  {"name":"wikis","keyword":"french","license":"Creative Commons Zero v1.0 Universal","language":"en","url":"https://huggingface.co/datasets/nyuuzyou/wikis","creator_name":"nyuuzyou","creator_url":"https://huggingface.co/nyuuzyou","description":"\\n\\t\\n\\t\\t\\n\\t\\tDataset Card for Public MediaWiki Collection\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThis dataset contains 1,662,448 articles harvested from 930 random public MediaWiki instances found across the Internet. The collection was created by extracting current page content from these wikis, preserving article text, metadata, and structural information. The dataset represents a diverse cross-section of public wiki content spanning multiple domains, topics, and languages.\\n\\n\\t\\n\\t\\t\\n\\t\\tLanguages\\n\\t\\n\\nThe‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/nyuuzyou/wikis."},
  {"name":"wikipedia_quality_wikirank","keyword":"french","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/lewoniewski/wikipedia_quality_wikirank","creator_name":"W≈Çodzimierz Lewoniewski","creator_url":"https://huggingface.co/lewoniewski","description":"Datasets with WikiRank quality score as of 1 August 2024 for 47 million Wikipedia articles in 55 language versions (also simplified version for each language in separate files).\\nThe WikiRank quality score is a metric designed to assess the overall quality of a Wikipedia article. Although its specific algorithm can vary depending on the implementation, the score typically combines several key features of the Wikipedia article.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tWhy It‚Äôs Important\\n\\t\\n\\n\\nEnhances Trust: For readers and‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/lewoniewski/wikipedia_quality_wikirank."},
  {"name":"Thinking-multilingual-big-10k-sft","keyword":"french","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/Pinkstack/Thinking-multilingual-big-10k-sft","creator_name":"Pinkstack","creator_url":"https://huggingface.co/Pinkstack","description":"\\nA dataset based off of openo1 math, 500 examples translated to 23 different languages. filtered out un-translated examples.\\nenjoy üëç\\n"},
  {"name":"multilingual_translation_sft","keyword":"french","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/Youseff1987/multilingual_translation_sft","creator_name":"JOON HYOUNG JUN","creator_url":"https://huggingface.co/Youseff1987","description":"Youseff1987/multilingual_translation_sft dataset hosted on Hugging Face and contributed by the HF Datasets community"},
  {"name":"m-WildVision","keyword":"french","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/CohereForAI/m-WildVision","creator_name":"Cohere For AI","creator_url":"https://huggingface.co/CohereForAI","description":"\\n\\t\\n\\t\\t\\n\\t\\tDataset Card for m-WildVision\\n\\t\\n\\n\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Details\\n\\t\\n\\nThe m-WildVision dataset is a multilingual multimodal LLM evaluation set covering 23 languages.  It was created by translating prompts from the original English-only WildVision (vision_bench_0617) test set. \\nThe original prompts, developed by Lu et al. (2024) , consist of 500 challenging user queries sourced from the WildVision-Arena platform. \\nThe authors demonstrated that these prompts enable automatic LLM judge‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/CohereForAI/m-WildVision."},
  {"name":"OpenHumanreasoning-multilingual-2.2k","keyword":"french","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/Pinkstack/OpenHumanreasoning-multilingual-2.2k","creator_name":"Pinkstack","creator_url":"https://huggingface.co/Pinkstack","description":"Based off of Pinkstackorg/humanreasoning-testing-en, it is a human-generated dataset where a real person had to create most of the reasoning and the final output. If there are any mistakes please let us know.\\nWe offer this dataset at an apache-2.0 license to make it useful for everybody.\\nnote: translations are not human generated.\\n"},
  {"name":"translation-en-fr","keyword":"french","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/ngia/translation-en-fr","creator_name":"Amadou NGAM","creator_url":"https://huggingface.co/ngia","description":"ngia/translation-en-fr dataset hosted on Hugging Face and contributed by the HF Datasets community"},
  {"name":"reasoning-conversations","keyword":"french","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/syntaxsynth/reasoning-conversations","creator_name":"SyntaxSynth","creator_url":"https://huggingface.co/syntaxsynth","description":"\\n\\t\\n\\t\\t\\n\\t\\tMultilingual Reasoning Dataset\\n\\t\\n\\n\\nInclude languages from German, Korean, Spanish, Japanese, French, Simplified Chinese, Traditional Chinese\\n\\nReasoning traces from Deepseek-v3-R1, Deepseek-v3-R1-Zero\\n\\n\\nCredits sponsored by Currents API\\n"},
  {"name":"MLAAD","keyword":"french","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/mueller91/MLAAD","creator_name":"Nicolas M√ºller","creator_url":"https://huggingface.co/mueller91","description":"\\n  \\n\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tIntroduction\\n\\t\\n\\nWelcome to MLAAD: The Multi-Language Audio Anti-Spoofing Dataset -- a dataset to train, test and evaluate audio deepfake detection. See\\nthe paper for more information.\\n\\n\\t\\n\\t\\t\\n\\t\\tStructure\\n\\t\\n\\nThe dataset is based on the M-AILABS dataset.\\nMLAAD is structured as follows:\\nfake\\n|-language_1\\n|-language_2\\n|- ....\\n|- language_K\\n    | - model_1_K\\n    | - model_2_K\\n    | - ....\\n    | - model_L_K\\n        | - meta.csv\\n        | - audio_L_K_1.wav\\n        | - audio_L_K_2.wav‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mueller91/MLAAD."},
  {"name":"aya_redteaming","keyword":"french","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/CohereForAI/aya_redteaming","creator_name":"Cohere For AI","creator_url":"https://huggingface.co/CohereForAI","description":"\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Card for Aya Red-teaming\\n\\t\\n\\n\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Details\\n\\t\\n\\nThe Aya Red-teaming dataset is a human-annotated multilingual red-teaming dataset consisting of harmful prompts in 8 languages across 9 different categories of harm with explicit labels for \\\"global\\\" and \\\"local\\\" harm.\\n\\n\\n\\n\\n\\n\\nCurated by: Professional compensated annotators\\nLanguages: Arabic, English, Filipino, French, Hindi, Russian, Serbian and Spanish\\nLicense: Apache 2.0\\nPaper: arxiv link\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tHarm Categories:‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/CohereForAI/aya_redteaming."},
  {"name":"allocine","keyword":"french","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/tblard/allocine","creator_name":"Th√©ophile Blard","creator_url":"https://huggingface.co/tblard","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Allocin√©\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThe Allocin√© dataset is a French-language dataset for sentiment analysis. The texts are movie reviews written between 2006 and 2020 by members of the Allocin√©.fr community for various films. It contains 100k positive and 100k negative reviews divided into train (160k), validation (20k), and test (20k). \\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSupported Tasks and Leaderboards\\n\\t\\n\\n\\ntext-classification, sentiment-classification: The dataset can be used‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/tblard/allocine."},
  {"name":"blbooksgenre","keyword":"french","license":"Creative Commons Zero v1.0 Universal","language":"en","url":"https://huggingface.co/datasets/TheBritishLibrary/blbooksgenre","creator_name":"British Library","creator_url":"https://huggingface.co/TheBritishLibrary","description":"This dataset contains metadata for resources belonging to the British Library‚Äôs digitised printed books (18th-19th century) collection (bl.uk/collection-guides/digitised-printed-books).\\nThis metadata has been extracted from British Library catalogue records.\\nThe metadata held within our main catalogue is updated regularly.\\nThis metadata dataset should be considered a snapshot of this metadata."},
  {"name":"bnl_newspapers","keyword":"french","license":"Creative Commons Zero v1.0 Universal","language":"en","url":"https://huggingface.co/datasets/bnl-data/bnl_newspapers","creator_name":"BnL Open Data","creator_url":"https://huggingface.co/bnl-data","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for BnL Historical Newspapers\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThe BnL has digitised over 800.000 pages of Luxembourg newspapers. This dataset currently has one configuration covering a subset of these newspapers, which sit under the \\\"Processed Datasets\\\" collection. The BNL:\\n\\nprocessed all newspapers and monographs that are in the public domain and extracted the full text and associated meta data of every single article, section, advertisement‚Ä¶ The result is a large‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/bnl-data/bnl_newspapers."},
  {"name":"euronews","keyword":"french","license":"Creative Commons Zero v1.0 Universal","language":"en","url":"https://huggingface.co/datasets/community-datasets/euronews","creator_name":"Community Datasets","creator_url":"https://huggingface.co/community-datasets","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Europeana Newspapers\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\n[More Information Needed]\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSupported Tasks and Leaderboards\\n\\t\\n\\n[More Information Needed]\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages\\n\\t\\n\\n[More Information Needed]\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Structure\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Instances\\n\\t\\n\\n[More Information Needed]\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Fields\\n\\t\\n\\n[More Information Needed]\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Splits\\n\\t\\n\\n[More Information Needed]\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Creation\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tCuration Rationale‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/community-datasets/euronews."},
  {"name":"europa_eac_tm","keyword":"french","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/community-datasets/europa_eac_tm","creator_name":"Community Datasets","creator_url":"https://huggingface.co/community-datasets","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Europa Education and Culture Translation Memory (EAC-TM)\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThis dataset is a corpus of manually produced translations from english to up to 25 languages, released in 2012 by the European Union's Directorate General for Education and Culture (EAC).\\nTo load a language pair that is not part of the config, just specify the language code as language pair. For example, if you want to translate Czech to Greek:\\ndataset =‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/community-datasets/europa_eac_tm."},
  {"name":"europa_ecdc_tm","keyword":"french","license":"Creative Commons Attribution Share Alike 4.0 International","language":"en","url":"https://huggingface.co/datasets/community-datasets/europa_ecdc_tm","creator_name":"Community Datasets","creator_url":"https://huggingface.co/community-datasets","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for [Dataset Name]\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nIn October 2012, the European Union (EU) agency 'European Centre for Disease Prevention and Control' (ECDC) released a translation memory (TM), i.e. a collection of sentences and their professionally produced translations, in twenty-five languages.\\nECDC-TM covers 25 languages: the 23 official languages of the EU plus Norwegian (Norsk) and Icelandic. ECDC-TM was created by translating from English into the following‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/community-datasets/europa_ecdc_tm."},
  {"name":"opus_infopankki","keyword":"french","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/Helsinki-NLP/opus_infopankki","creator_name":"Language Technology Research Group at the University of Helsinki","creator_url":"https://huggingface.co/Helsinki-NLP","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for infopankki\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nA parallel corpus of 12 languages, 66 bitexts.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSupported Tasks and Leaderboards\\n\\t\\n\\nThe underlying task is machine translation.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages\\n\\t\\n\\n[More Information Needed]\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Structure\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Instances\\n\\t\\n\\n[More Information Needed]\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Fields\\n\\t\\n\\n[More Information Needed]\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Splits\\n\\t\\n\\n[More Information Needed]\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Creation‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Helsinki-NLP/opus_infopankki."},
  {"name":"opus_paracrawl","keyword":"french","license":"Creative Commons Zero v1.0 Universal","language":"en","url":"https://huggingface.co/datasets/Helsinki-NLP/opus_paracrawl","creator_name":"Language Technology Research Group at the University of Helsinki","creator_url":"https://huggingface.co/Helsinki-NLP","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for OpusParaCrawl\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nParallel corpora from Web Crawls collected in the ParaCrawl project.\\nTha dataset contains:\\n\\n42 languages, 43 bitexts\\ntotal number of files: 59,996\\ntotal number of tokens: 56.11G\\ntotal number of sentence fragments: 3.13G\\n\\nTo load a language pair which isn't part of the config, all you need to do is specify the language code as pairs,\\ne.g.\\ndataset = load_dataset(\\\"opus_paracrawl\\\", lang1=\\\"en\\\", lang2=\\\"so\\\")\\n\\nYou can find‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Helsinki-NLP/opus_paracrawl."},
  {"name":"opus_ubuntu","keyword":"french","license":"BSD 3-Clause \"New\" or \"Revised\" License","language":"en","url":"https://huggingface.co/datasets/Helsinki-NLP/opus_ubuntu","creator_name":"Language Technology Research Group at the University of Helsinki","creator_url":"https://huggingface.co/Helsinki-NLP","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Opus Ubuntu\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThese are translations of the Ubuntu software package messages, donated by the Ubuntu community.\\nTo load a language pair which isn't part of the config, all you need to do is specify the language code as pairs.\\nYou can find the valid pairs in Homepage section of Dataset Description: http://opus.nlpl.eu/Ubuntu.php\\nE.g.\\ndataset = load_dataset(\\\"opus_ubuntu\\\", lang1=\\\"it\\\", lang2=\\\"pl\\\")\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSupported Tasks and‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Helsinki-NLP/opus_ubuntu."},
  {"name":"piaf","keyword":"french","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/AgentPublic/piaf","creator_name":"AgentPublic","creator_url":"https://huggingface.co/AgentPublic","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Piaf\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nPiaf is a reading comprehension dataset. This version, published in February 2020, contains 3835 questions on French Wikipedia.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSupported Tasks and Leaderboards\\n\\t\\n\\nMore Information Needed\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages\\n\\t\\n\\nMore Information Needed\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Structure\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Instances\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tplain_text\\n\\t\\n\\n\\nSize of downloaded dataset files: 1.31 MB\\nSize of the generated dataset: 3.18 MB\\nTotal‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/AgentPublic/piaf."},
  {"name":"xcsr","keyword":"french","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/INK-USC/xcsr","creator_name":"INK Lab @ USC","creator_url":"https://huggingface.co/INK-USC","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for X-CSR\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nTo evaluate multi-lingual language models (ML-LMs) for commonsense reasoning in a cross-lingual zero-shot transfer setting (X-CSR), i.e., training in English and test in other languages, we create two benchmark datasets, namely X-CSQA and X-CODAH. Specifically, we automatically translate the original CSQA and CODAH datasets, which only have English versions, to 15 other languages, forming development and test sets for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/INK-USC/xcsr."},
  {"name":"flores_101","keyword":"french","license":"Creative Commons Attribution Share Alike 4.0 International","language":"en","url":"https://huggingface.co/datasets/gsarti/flores_101","creator_name":"Gabriele Sarti","creator_url":"https://huggingface.co/gsarti","description":"One of the biggest challenges hindering progress in low-resource and multilingual machine translation is the \\nlack of good evaluation benchmarks. Current evaluation benchmarks either lack good coverage of low-resource \\nlanguages, consider only restricted domains, or are low quality because they are constructed using \\nsemi-automatic procedures. In this work, we introduce the FLORES evaluation benchmark, consisting of 3001 \\nsentences extracted from English Wikipedia and covering a variety of different topics and domains. \\nThese sentences have been translated in 101 languages by professional translators through a carefully \\ncontrolled process. The resulting dataset enables better assessment of model quality on the long tail of \\nlow-resource languages, including the evaluation of many-to-many multilingual translation systems, as all \\ntranslations are multilingually aligned. By publicly releasing such a high-quality and high-coverage dataset, \\nwe hope to foster progress in the machine translation community and beyond."},
  {"name":"openminuscule","keyword":"french","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/lgrobol/openminuscule","creator_name":"Lo√Øc Grobol","creator_url":"https://huggingface.co/lgrobol","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tOpen Minuscule\\n\\t\\n\\nA little small wee corpus to train little small wee models.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThis is a raw text corpus, mainly intended for testing purposes.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages\\n\\t\\n\\n\\nFrench\\nEnglish\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Structure\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Instances\\n\\t\\n\\n[More Information Needed]\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Fields\\n\\t\\n\\n[More Information Needed]\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Splits\\n\\t\\n\\n[More Information Needed]\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Creation‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/lgrobol/openminuscule."},
  {"name":"DiaBLa","keyword":"french","license":"Creative Commons Attribution Share Alike 4.0 International","language":"en","url":"https://huggingface.co/datasets/rbawden/DiaBLa","creator_name":"Rachel Bawden","creator_url":"https://huggingface.co/rbawden","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for DiaBLa: Bilingual dialogue parallel evaluation set\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThe dataset is an English-French dataset for the evaluation of Machine Translation (MT) for informal, written bilingual dialogue.\\nThe dataset contains 144 spontaneous dialogues (5,700+ sentences) between native English and French speakers, mediated by one of two neural MT systems in a range of role-play settings. See below for some basic statistics. The dialogues are accompanied by‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/rbawden/DiaBLa."},
  {"name":"MuST-C-fr","keyword":"french","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/enimai/MuST-C-fr","creator_name":"Enim AI","creator_url":"https://huggingface.co/enimai","description":"enimai/MuST-C-fr dataset hosted on Hugging Face and contributed by the HF Datasets community"},
  {"name":"squad_v2_french_translated","keyword":"french","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/pragnakalp/squad_v2_french_translated","creator_name":"Pragnakalp Techlabs","creator_url":"https://huggingface.co/pragnakalp","description":"Using Google Translation, we have translated SQuAD 2.0 dataset into multiple languages. \\nHere is the translated dataset of SQuAD 2.0 in French language.\\nShared by Pragnakalp Techlabs\\n"},
  {"name":"taln-archives","keyword":"french","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/taln-ls2n/taln-archives","creator_name":"TALN research group at LS2N lab","creator_url":"https://huggingface.co/taln-ls2n","description":"TALN Archives benchmark dataset for keyphrase extraction an generation."},
  {"name":"xlel_wd_dictionary","keyword":"french","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/adithya7/xlel_wd_dictionary","creator_name":"Adithya Pratapa","creator_url":"https://huggingface.co/adithya7","description":"XLEL-WD is a multilingual event linking dataset. This sub-dataset contains a dictionary of events from Wikidata. The multilingual descriptions for Wikidata event items are taken from the corresponding Wikipedia articles."},
  {"name":"xlel_wd","keyword":"french","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/adithya7/xlel_wd","creator_name":"Adithya Pratapa","creator_url":"https://huggingface.co/adithya7","description":"XLEL-WD is a multilingual event linking dataset. This dataset contains mention references from multilingual Wikipedia/Wikinews articles to event items in Wikidata. The text descriptions for Wikidata events are compiled from Wikipedia articles."},
  {"name":"shades_nationality","keyword":"french","license":"Creative Commons Attribution Share Alike 4.0 International","language":"en","url":"https://huggingface.co/datasets/bigscience-catalogue-data/shades_nationality","creator_name":"BigScience Catalogue Data","creator_url":"https://huggingface.co/bigscience-catalogue-data","description":"Possibly a placeholder dataset for the original here: https://huggingface.co/datasets/bigscience-catalogue-data/bias-shades\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Statement for SHADES\\n\\t\\n\\n\\nHow to use this document:\\nFill in each section according to the instructions. Give as much detail as you can, but there's no need to extrapolate. The goal is to help people understand your data when they approach it. This could be someone looking at it in ten years, or it could be you yourself looking back at the data in two‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/bigscience-catalogue-data/shades_nationality."},
  {"name":"wit_base","keyword":"french","license":"Creative Commons Attribution Share Alike 4.0 International","language":"en","url":"https://huggingface.co/datasets/wikimedia/wit_base","creator_name":"Wikimedia","creator_url":"https://huggingface.co/wikimedia","description":"\\n\\t\\n\\t\\t\\n\\t\\tDataset Card for WIT\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nWikimedia's version of the Wikipedia-based Image Text (WIT) Dataset, a large multimodal multilingual dataset.\\nFrom the official blog post:\\n\\nThe core training data is taken from the Wikipedia Image-Text (WIT) Dataset, a large curated set of more than 37 million image-text associations extracted from Wikipedia articles in 108 languages that was recently released by Google Research.\\nThe WIT dataset offers extremely valuable data about the‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/wikimedia/wit_base."},
  {"name":"x-stance","keyword":"french","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/strombergnlp/x-stance","creator_name":"Str√∏mberg NLP","creator_url":"https://huggingface.co/strombergnlp","description":"The x-stance dataset contains more than 150 political questions, and 67k comments written by candidates on those questions. The comments are partly German, partly French and Italian. The data have been extracted from the Swiss voting advice platform Smartvote."},
  {"name":"bucc-bitext-mining","keyword":"french","license":"Creative Commons Attribution Share Alike 4.0 International","language":"en","url":"https://huggingface.co/datasets/mteb/bucc-bitext-mining","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for MTEB Benchmark\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nMTEB is a heterogeneous benchmark that has been built from diverse tasks:\\n\\nBitextMining: BUCC, Tatoeba\\nClassification: AmazonCounterfactualClassification, AmazonPolarityClassification, AmazonReviewsClassification, Banking77Classification, EmotionClassification, ImdbClassification, MassiveIntentClassification, MassiveScenarioClassification, MTOPDomainClassification, MTOPIntentClassification‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/bucc-bitext-mining."},
  {"name":"covid19_emergency_event","keyword":"french","license":"Creative Commons Zero v1.0 Universal","language":"en","url":"https://huggingface.co/datasets/joelniklaus/covid19_emergency_event","creator_name":"Joel Niklaus","creator_url":"https://huggingface.co/joelniklaus","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for EXCEPTIUS Corpus\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThis dataset presents a new corpus of legislative documents from 8 European countries (Beglium, France, Hunary, Italy, Netherlands, Norway, Poland, UK) in 7 languages (Dutch, English, French, Hungarian, Italian, Norwegian Bokm√•l, Polish) manually annotated for exceptional measures against COVID-19. The annotation was done on the sentence level.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSupported Tasks and Leaderboards\\n\\t\\n\\nThe dataset can be used‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/joelniklaus/covid19_emergency_event."},
  {"name":"hatecheck-french","keyword":"french","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/Paul/hatecheck-french","creator_name":"Paul R√∂ttger","creator_url":"https://huggingface.co/Paul","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Multilingual HateCheck\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nMultilingual HateCheck (MHC) is a suite of functional tests for hate speech detection models in 10 different languages: Arabic, Dutch, French, German, Hindi, Italian, Mandarin, Polish, Portuguese and Spanish.\\nFor each language, there are 25+ functional tests that correspond to distinct types of hate and challenging non-hate.\\nThis allows for targeted diagnostic insights into model performance.\\nFor more‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Paul/hatecheck-french."},
  {"name":"wino_x","keyword":"french","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/demelin/wino_x","creator_name":"Denis Emelin","creator_url":"https://huggingface.co/demelin","description":"Wino-X is a parallel dataset of German, French, and Russian Winograd schemas, aligned with their English \\ncounterparts, used to examine whether neural machine translation models can perform coreference resolution that \\nrequires commonsense knowledge and whether multilingual language models are capable of commonsense reasoning across \\nmultiple languages."},
  {"name":"mapa","keyword":"french","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/joelniklaus/mapa","creator_name":"Joel Niklaus","creator_url":"https://huggingface.co/joelniklaus","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Multilingual European Datasets for Sensitive Entity Detection in the Legal Domain\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThe dataset consists of 12 documents (9 for Spanish due to parsing errors) taken from EUR-Lex, a multilingual corpus of court\\ndecisions and legal dispositions in the 24 official languages of the European Union. The documents have been annotated\\nfor named entities following the guidelines of the MAPA project which foresees two\\nannotation level, a‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/joelniklaus/mapa."},
  {"name":"sbb-dc-ocr","keyword":"french","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/SBB/sbb-dc-ocr","creator_name":"Staatsbibliothek zu Berlin - Preu√üischer Kulturbesitz","creator_url":"https://huggingface.co/SBB","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Berlin State Library OCR data\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\n\\nThe digital collections of the SBB contain 153,942 digitized works from the time period of 1470 to 1945.\\n\\n\\nAt the time of publication, 28,909 works have been OCR-processed resulting in 4,988,099 full-text pages.\\nFor each page with OCR text, the language has been determined by langid (Lui/Baldwin 2012).\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSupported Tasks and Leaderboards\\n\\t\\n\\n\\nlanguage-modeling: this dataset has the potential‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/SBB/sbb-dc-ocr."},
  {"name":"xP3all","keyword":"french","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/bigscience/xP3all","creator_name":"BigScience Workshop","creator_url":"https://huggingface.co/bigscience","description":"xP3 (Crosslingual Public Pool of Prompts) is a collection of prompts & datasets across 46 of languages & 16 NLP tasks. It is used for the training of BLOOMZ and mT0, multilingual language models capable of following human instructions in dozens of languages zero-shot."},
  {"name":"lextreme","keyword":"french","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/joelniklaus/lextreme","creator_name":"Joel Niklaus","creator_url":"https://huggingface.co/joelniklaus","description":"The LEXTREME Benchmark is a collection of multilingual datasets for evaluating model performance \\nacross a diverse set of legal NLU tasks."},
  {"name":"xP3mt","keyword":"french","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/bigscience/xP3mt","creator_name":"BigScience Workshop","creator_url":"https://huggingface.co/bigscience","description":"xP3 (Crosslingual Public Pool of Prompts) is a collection of prompts & datasets across 46 of languages & 16 NLP tasks. It is used for the training of BLOOMZ and mT0, multilingual language models capable of following human instructions in dozens of languages zero-shot."},
  {"name":"mc4_legal","keyword":"french","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/joelniklaus/mc4_legal","creator_name":"Joel Niklaus","creator_url":"https://huggingface.co/joelniklaus","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for MC4_Legal: A Corpus Covering the Legal Part of MC4 for European Languages\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThis dataset contains large text resources (~133GB in total) from mc4 filtered for legal data that can be used for pretraining language models.\\nUse the dataset like this:\\nfrom datasets import load_dataset\\ndataset = load_dataset(\\\"joelito/mc4_legal\\\", \\\"de\\\", split='train', streaming=True)\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSupported Tasks and Leaderboards\\n\\t\\n\\nThe dataset supports the‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/joelniklaus/mc4_legal."},
  {"name":"miracl-corpus","keyword":"french","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/miracl/miracl-corpus","creator_name":"MIRACL","creator_url":"https://huggingface.co/miracl","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for MIRACL Corpus\\n\\t\\n\\nMIRACL üåçüôåüåè (Multilingual Information Retrieval Across a Continuum of Languages) is a multilingual retrieval dataset that focuses on search across 18 different languages, which collectively encompass over three billion native speakers around the world.\\nThis dataset contains the collection data of the 16 \\\"known languages\\\". The remaining 2 \\\"surprise languages\\\" will not be released until later.\\nThe corpus for each language is prepared from a‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/miracl/miracl-corpus."},
  {"name":"TaTA","keyword":"french","license":"Creative Commons Attribution Share Alike 4.0 International","language":"en","url":"https://huggingface.co/datasets/GEM/TaTA","creator_name":"GEM benchmark","creator_url":"https://huggingface.co/GEM","description":"Dataset loader for TaTA: A Multilingual Table-to-Text Dataset for African Languages"},
  {"name":"HashtagPrediction","keyword":"french","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/Twitter/HashtagPrediction","creator_name":"Twitter","creator_url":"https://huggingface.co/Twitter","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tHashtag Prediction Dataset from paper TwHIN-BERT: A Socially-Enriched Pre-trained Language Model for Multilingual Tweet Representations\\n\\t\\n\\n  \\nThis repo contains the Hashtag prediction dataset from our paper TwHIN-BERT: A Socially-Enriched Pre-trained Language Model for Multilingual Tweet Representations. \\n[arXiv]\\n[HuggingFace Models]\\n[Github repo]\\nThis work is licensed under a Creative Commons Attribution 4.0 International License.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDownload\\n\\t\\n\\nUse the‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Twitter/HashtagPrediction."},
  {"name":"TyDiP","keyword":"french","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/Genius1237/TyDiP","creator_name":"Genius1237","creator_url":"https://huggingface.co/Genius1237","description":"The TyDiP dataset is a dataset of requests in conversations between wikipedia editors\\nthat have been annotated for politeness. The splits available below consists of only\\nrequests from the top 25 percentile (polite) and bottom 25 percentile (impolite) of\\npoliteness scores. The English train set and English test set that are\\nadapted from the Stanford Politeness Corpus, and test data in 9 more languages\\n(Hindi, Korean, Spanish, Tamil, French, Vietnamese, Russian, Afrikaans, Hungarian) \\nwas annotated by us."},
  {"name":"bnl_newspapers1841-1879","keyword":"french","license":"Creative Commons Zero v1.0 Universal","language":"en","url":"https://huggingface.co/datasets/biglam/bnl_newspapers1841-1879","creator_name":"BigLAM: BigScience Libraries, Archives and Museums","creator_url":"https://huggingface.co/biglam","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for BnL Newspapers 1841-1881\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\n592.192 articles from historical newspapers (1841-1881) along with metadata and the full text.\\n21 newspaper titles\\n24.415 newspaper issues\\n99.957 scanned pages\\nTranscribed using a variety of OCR engines and corrected using https://github.com/natliblux/nautilusocr (95% threshold)\\nPublic Domain, CC0 (See copyright notice)\\nThe newspapers used are:\\n\\nDer Arbeiter (1878-1881)\\nL'Arlequin (1848-1848)\\nL'Avenir‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/biglam/bnl_newspapers1841-1879."},
  {"name":"MultiLegalPile_Wikipedia_Filtered","keyword":"french","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/joelniklaus/MultiLegalPile_Wikipedia_Filtered","creator_name":"Joel Niklaus","creator_url":"https://huggingface.co/joelniklaus","description":"A filtered version of the MultiLegalPile dataset, together with wikipedia articles."},
  {"name":"EU_Wikipedias","keyword":"french","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/joelniklaus/EU_Wikipedias","creator_name":"Joel Niklaus","creator_url":"https://huggingface.co/joelniklaus","description":"Wikipedia dataset containing cleaned articles of all languages.\\nThe datasets are built from the Wikipedia dump\\n(https://dumps.wikimedia.org/) with one split per language. Each example\\ncontains the content of one full Wikipedia article with cleaning to strip\\nmarkdown and unwanted sections (references, etc.)."},
  {"name":"afriqa_wiki_en_fr_100","keyword":"french","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/masakhane/afriqa_wiki_en_fr_100","creator_name":"Masakhane NLP","creator_url":"https://huggingface.co/masakhane","description":""},
  {"name":"afriqa-prebuilt-sparse-indexes","keyword":"french","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/masakhane/afriqa-prebuilt-sparse-indexes","creator_name":"Masakhane NLP","creator_url":"https://huggingface.co/masakhane","description":"Afriqa Prebuilt Indices\\n\\nPrebuilt Lucene Inverted Indices for preprocessed Afriqa Wikipedia Passages\\n"},
  {"name":"multilingual-gec","keyword":"french","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/juancavallotti/multilingual-gec","creator_name":"Juan Alberto Lopez Cavallotti","creator_url":"https://huggingface.co/juancavallotti","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Multilingual Grammar Error Correction\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThis dataset can be used to train a transformer model (we used T5) to correct grammar errors in simple sentences written in English, Spanish, French, or German. \\nThis dataset was developed as a component for the Squidigies platform.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSupported Tasks and Leaderboards\\n\\t\\n\\n\\nGrammar Error Correction: By appending the prefix fix grammar: to the prrompt.\\nLanguage Detection: By appending the‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/juancavallotti/multilingual-gec."},
  {"name":"humset","keyword":"french","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/nlp-thedeep/humset","creator_name":"TheDEEP NLP","creator_url":"https://huggingface.co/nlp-thedeep","description":"HumSet is a novel and rich multilingual dataset of humanitarian response documents annotated by experts in the humanitarian response community. HumSet is curated by humanitarian analysts and covers various disasters around the globe that occurred from 2018 to 2021 in 46 humanitarian response projects. The dataset consists of approximately 17K annotated documents in three languages of English, French, and Spanish, originally taken from publicly-available resources. For each document, analysts have identified informative snippets (entries) in respect to common humanitarian frameworks, and assigned one or many classes to each entry. See the our paper for details."},
  {"name":"wikipedia-22-12-fr-embeddings","keyword":"french","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/Cohere/wikipedia-22-12-fr-embeddings","creator_name":"Cohere","creator_url":"https://huggingface.co/Cohere","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tWikipedia (fr) embedded with cohere.ai multilingual-22-12 encoder\\n\\t\\n\\nWe encoded Wikipedia (fr) using the cohere.ai multilingual-22-12 embedding model.\\nTo get an overview how this dataset was created and pre-processed, have a look at Cohere/wikipedia-22-12.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tEmbeddings\\n\\t\\n\\nWe compute for title+\\\" \\\"+text the embeddings using our multilingual-22-12 embedding model, a state-of-the-art model that works for semantic search in 100 languages.  If you want to learn more about this‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Cohere/wikipedia-22-12-fr-embeddings."},
  {"name":"swiss_legislation","keyword":"french","license":"Creative Commons Attribution Share Alike 4.0 International","language":"en","url":"https://huggingface.co/datasets/rcds/swiss_legislation","creator_name":"Institute for Public Sector Transformation IPST - Digital Sustainability Lab DSL","creator_url":"https://huggingface.co/rcds","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Swiss Legislation\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nSwiss Legislation is a multilingual, diachronic dataset of 36K Swiss laws. This dataset is part of a challenging Information Retreival task.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSupported Tasks and Leaderboards\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages\\n\\t\\n\\nThe total number of texts in the dataset is 35,698. The dataset is saved in lexfind_v2.jsonl format.\\nSwitzerland has four official languages German, French, Italian and Romanch with some additional‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/rcds/swiss_legislation."},
  {"name":"miracl-fr-corpus-22-12","keyword":"french","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/Cohere/miracl-fr-corpus-22-12","creator_name":"Cohere","creator_url":"https://huggingface.co/Cohere","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tMIRACL (fr) embedded with cohere.ai multilingual-22-12 encoder\\n\\t\\n\\nWe encoded the MIRACL dataset using the cohere.ai multilingual-22-12 embedding model.\\nThe query embeddings can be found in Cohere/miracl-fr-queries-22-12 and the corpus embeddings can be found in Cohere/miracl-fr-corpus-22-12.\\nFor the orginal datasets, see miracl/miracl and miracl/miracl-corpus.\\nDataset info:\\n\\nMIRACL üåçüôåüåè (Multilingual Information Retrieval Across a Continuum of Languages) is a multilingual‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Cohere/miracl-fr-corpus-22-12."},
  {"name":"miracl-fr-queries-22-12","keyword":"french","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/Cohere/miracl-fr-queries-22-12","creator_name":"Cohere","creator_url":"https://huggingface.co/Cohere","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tMIRACL (fr) embedded with cohere.ai multilingual-22-12 encoder\\n\\t\\n\\nWe encoded the MIRACL dataset using the cohere.ai multilingual-22-12 embedding model.\\nThe query embeddings can be found in Cohere/miracl-fr-queries-22-12 and the corpus embeddings can be found in Cohere/miracl-fr-corpus-22-12.\\nFor the orginal datasets, see miracl/miracl and miracl/miracl-corpus.\\nDataset info:\\n\\nMIRACL üåçüôåüåè (Multilingual Information Retrieval Across a Continuum of Languages) is a multilingual‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Cohere/miracl-fr-queries-22-12."},
  {"name":"MultiLegalPileWikipediaFiltered","keyword":"french","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/joelniklaus/MultiLegalPileWikipediaFiltered","creator_name":"Joel Niklaus","creator_url":"https://huggingface.co/joelniklaus","description":"A filtered version of the MultiLegalPile dataset, together with wikipedia articles."},
  {"name":"pwesuite-eval","keyword":"french","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/zouharvi/pwesuite-eval","creator_name":"Vil√©m Zouhar","creator_url":"https://huggingface.co/zouharvi","description":"\\n\\n\\t\\n\\t\\t\\n\\t\\tPWESuite-Eval\\n\\t\\n\\nDataset composed of multiple smaller datasets used for the evaluation of phonetic word embeddings.\\nSee code for evaluation here.\\nIf you use this dataset/evaluation, please cite the paper at LREC-COLING 2024:\\n@inproceedings{zouhar-etal-2024-pwesuite,\\n    title = \\\"{PWES}uite: Phonetic Word Embeddings and Tasks They Facilitate\\\",\\n    author = \\\"Zouhar, Vil{\\\\'e}m  and\\n      Chang, Kalvin  and\\n      Cui, Chenxuan  and\\n      Carlson, Nate B.  and\\n      Robinson, Nathaniel‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/zouharvi/pwesuite-eval."},
  {"name":"swiss_doc2doc_ir","keyword":"french","license":"Creative Commons Attribution Share Alike 4.0 International","language":"en","url":"https://huggingface.co/datasets/rcds/swiss_doc2doc_ir","creator_name":"Institute for Public Sector Transformation IPST - Digital Sustainability Lab DSL","creator_url":"https://huggingface.co/rcds","description":"https://huggingface.co/spaces/huggingface/datasets-tagging\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Swiss Doc2doc Information Retrieval\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nSwiss Doc2doc Information Retrieval is a multilingual, diachronic dataset of 131K Swiss Federal Supreme Court (FSCS) cases annotated with law citations and ruling citations, posing a challenging text classification task. As unique label we are using decision_id of cited rulings and uuid of cited law articles, which can be found in the‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/rcds/swiss_doc2doc_ir."},
  {"name":"gutenberg_multilang","keyword":"french","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/sedthh/gutenberg_multilang","creator_name":"Richard Nagyfi","creator_url":"https://huggingface.co/sedthh","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Project Gutenber - Multilanguage eBooks\\n\\t\\n\\nA collection of non-english language eBooks (7907, about 75-80% of all the ES, DE, FR, NL, IT, PT, HU books available on the site) from the Project Gutenberg site with metadata removed. \\nOriginally colected for https://github.com/LAION-AI/Open-Assistant\\n\\n\\t\\n\\t\\t\\nLANG\\nEBOOKS\\n\\n\\n\\t\\t\\nES\\n717\\n\\n\\nDE\\n1735\\n\\n\\nFR\\n2863\\n\\n\\nNL\\n904\\n\\n\\nIT\\n692\\n\\n\\nPT\\n501\\n\\n\\nHU\\n495\\n\\n\\n\\t\\n\\nThe METADATA column contains catalogue meta information on each book as a‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/sedthh/gutenberg_multilang."},
  {"name":"occlusion_swiss_judgment_prediction","keyword":"french","license":"Creative Commons Attribution Share Alike 4.0 International","language":"en","url":"https://huggingface.co/datasets/rcds/occlusion_swiss_judgment_prediction","creator_name":"Institute for Public Sector Transformation IPST - Digital Sustainability Lab DSL","creator_url":"https://huggingface.co/rcds","description":"This dataset contains an implementation of occlusion for the SwissJudgmentPrediction task."},
  {"name":"lower_court_insertion_swiss_judgment_prediction","keyword":"french","license":"Creative Commons Attribution Share Alike 4.0 International","language":"en","url":"https://huggingface.co/datasets/rcds/lower_court_insertion_swiss_judgment_prediction","creator_name":"Institute for Public Sector Transformation IPST - Digital Sustainability Lab DSL","creator_url":"https://huggingface.co/rcds","description":"This dataset contains an implementation of lower court insertion for the SwissJudgmentPrediction task."},
  {"name":"ikitracs-qa","keyword":"french","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/alessio-vertemati/ikitracs-qa","creator_name":"Alessio Vertemati","creator_url":"https://huggingface.co/alessio-vertemati","description":"This dataset is curated by GIZ Data Service Center in the form of Sqaud dataset with features question, answer, answer_start, context and language.\\nThe source dataset for this comes from Changing Transport Tracker,\\nwhere partners analyze Intended nationally determined contribution (INDC), NDC and Revised/Updated NDC of countries to understand transport related climate mitigation actions.\\nSpecifications\\n\\nDataset size: 3194\\nLanguage: English, Spanish, French\\n\\n"},
  {"name":"alloprof","keyword":"french","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/antoinelb7/alloprof","creator_name":"Antoine Lefebvre-Brossard","creator_url":"https://huggingface.co/antoinelb7","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tAlloprof dataset\\n\\t\\n\\nThis is the dataset refered to in our paper:\\nAlloprof: a new French question-answer education dataset and its use in an information retrieval case study (https://arxiv.org/abs/2302.07738)\\nThis dataset was provided by AlloProf, an organisation in Quebec, Canada offering resources and a help forum curated by a large number of teachers to students on all subjects taught from in primary and secondary school.\\nRaw data on questions is available in the following files:‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/antoinelb7/alloprof."},
  {"name":"Fact-Completion","keyword":"french","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/Polyglot-or-Not/Fact-Completion","creator_name":"Polyglot-or-Not","creator_url":"https://huggingface.co/Polyglot-or-Not","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card\\n\\t\\n\\n\\nHomepage: https://bit.ly/ischool-berkeley-capstone\\nRepository: https://github.com/daniel-furman/Capstone\\nPoint of Contact: daniel_furman@berkeley.edu\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThis is the dataset for Polyglot or Not?: Measuring Multilingual Encyclopedic Knowledge Retrieval from Foundation Language Models.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tTest Description\\n\\t\\n\\n Given a factual association such as The capital of France is Paris, we determine whether a model adequately \\\"knows\\\" this‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Polyglot-or-Not/Fact-Completion."},
  {"name":"swiss_law_area_prediction","keyword":"french","license":"Creative Commons Attribution Share Alike 4.0 International","language":"en","url":"https://huggingface.co/datasets/rcds/swiss_law_area_prediction","creator_name":"Institute for Public Sector Transformation IPST - Digital Sustainability Lab DSL","creator_url":"https://huggingface.co/rcds","description":"This dataset contains court decision for law area prediction task."},
  {"name":"lingnli-multi-mt","keyword":"french","license":"BSD 2-Clause \"Simplified\" License","language":"en","url":"https://huggingface.co/datasets/maximoss/lingnli-multi-mt","creator_name":"Maximos Skandalis","creator_url":"https://huggingface.co/maximoss","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Dataset Name\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThis repository contains a collection of machine translations of LingNLI dataset \\ninto 9 different languages (Bulgarian, Finnish, French, Greek, Italian, Korean, Lithuanian, Portuguese, Spanish). The goal is to predict textual entailment (does sentence A \\nimply/contradict/neither sentence B), which is a classification task (given two sentences, \\npredict one of three labels). It is here formatted in the same manner as‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/maximoss/lingnli-multi-mt."},
  {"name":"en-fr-nyu-dl-course-corpus","keyword":"french","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/lbourdois/en-fr-nyu-dl-course-corpus","creator_name":"Lo√Øck BOURDOIS","creator_url":"https://huggingface.co/lbourdois","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset information\\n\\t\\n\\nDataset from the French translation by Lo√Øck Bourdois of the course by Yann Le Cun and Alfredo Canziani from the NYU.More than 3000 parallel data were created. The whole corpus has been manually checked to make sure of the good alignment of the data.\\nNote that the English data comes from several different people (about 190, see the acknowledgement section below).This has an impact on the homogeneity of the texts (some write in the past tense, others in the‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/lbourdois/en-fr-nyu-dl-course-corpus."},
  {"name":"mnli-nineeleven-fr-mt","keyword":"french","license":"BSD 2-Clause \"Simplified\" License","language":"en","url":"https://huggingface.co/datasets/maximoss/mnli-nineeleven-fr-mt","creator_name":"Maximos Skandalis","creator_url":"https://huggingface.co/maximoss","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Dataset Name\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThis repository contains a machine-translated French version of the portion of MultiNLI concerning the 9/11 terrorist attacks (2000 examples).\\nNote that these 2000 examples included in MultiNLI (and machine translated in French here) on the subject of 9/11 are different from the 249 examples in the validation subset and the 501 ones in the test subset of XNLI on the same subject.\\nIn the original subset of MultiNLI on‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/maximoss/mnli-nineeleven-fr-mt."},
  {"name":"swiss_leading_decisions","keyword":"french","license":"Creative Commons Attribution Share Alike 4.0 International","language":"en","url":"https://huggingface.co/datasets/rcds/swiss_leading_decisions","creator_name":"Institute for Public Sector Transformation IPST - Digital Sustainability Lab DSL","creator_url":"https://huggingface.co/rcds","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Swiss Leading Decisions\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nSwiss Leading Decisions is a multilingual, diachronic dataset of 21K Swiss Federal Supreme Court (FSCS) cases. This dataset is part of a challenging text classification task. We also provide additional metadata as the publication year, the law area and the canton of origin per case, to promote robustness and fairness studies on the critical area of legal NLP.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSupported Tasks and Leaderboards‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/rcds/swiss_leading_decisions."},
  {"name":"swiss_criticality_prediction","keyword":"french","license":"Creative Commons Attribution Share Alike 4.0 International","language":"en","url":"https://huggingface.co/datasets/rcds/swiss_criticality_prediction","creator_name":"Institute for Public Sector Transformation IPST - Digital Sustainability Lab DSL","creator_url":"https://huggingface.co/rcds","description":"This dataset contains Swiss federal court decisions for the legal criticality prediction task"},
  {"name":"gqnli-fr","keyword":"french","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/maximoss/gqnli-fr","creator_name":"Maximos Skandalis","creator_url":"https://huggingface.co/maximoss","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Dataset Name\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThis repository contains a manually translated French version of the GQNLI challenge dataset, originally written in English. GQNLI is an evaluation corpus that is aimed for testing language model's generalized quantifier reasoning ability.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSupported Tasks and Leaderboards\\n\\t\\n\\nThis dataset can be used for the task of Natural Language Inference (NLI), also known as Recognizing Textual Entailment (RTE), which‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/maximoss/gqnli-fr."},
  {"name":"FLUE_VSD","keyword":"french","license":"GNU General Public License v3.0","language":"en","url":"https://huggingface.co/datasets/GETALP/FLUE_VSD","creator_name":" Groupe d'√âtude en Traduction Automatique/Traitement Automatis√© des Langues et de la Parole","creator_url":"https://huggingface.co/GETALP","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tFrenchSemEval\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThis dataset correspond to the FrenchSemEval, in which verb occurences where manually annotated with Wiktionary senses. \\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSupported Tasks and Leaderboards\\n\\t\\n\\nVerb Sense Disambiguation for French verbs.  \\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguage\\n\\t\\n\\nFrench\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Structure\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Instances\\n\\t\\n\\nEach instance of the dataset has the following fields and these following types of field. \\n{\\n  \\\"document_id\\\": \\\"d001\\\"‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/GETALP/FLUE_VSD."},
  {"name":"masakhanews","keyword":"french","license":"Academic Free License v3.0","language":"en","url":"https://huggingface.co/datasets/masakhane/masakhanews","creator_name":"Masakhane NLP","creator_url":"https://huggingface.co/masakhane","description":"MasakhaNEWS is the largest publicly available dataset for news topic classification in 16 languages widely spoken in Africa.\\n\\nThe languages are:\\n- Amharic (amh)\\n- English (eng)\\n- French (fra)\\n- Hausa (hau)\\n- Igbo (ibo)\\n- Lingala (lin)\\n- Luganda (lug)\\n- Oromo (orm)\\n- Nigerian Pidgin (pcm)\\n- Rundi (run)\\n- chShona (sna)\\n- Somali (som)\\n- Kiswahili (swƒÖ)\\n- Tigrinya (tir)\\n- isiXhosa (xho)\\n- Yor√πb√° (yor)\\n\\nThe train/validation/test sets are available for all the 16 languages.\\n\\nFor more details see *** arXiv link **"},
  {"name":"LoLLMS-Open-Community-discussions","keyword":"french","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/ParisNeo/LoLLMS-Open-Community-discussions","creator_name":"Saifeddine ALOUI","creator_url":"https://huggingface.co/ParisNeo","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for GPT4All-Community-Discussions\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThis dataset contains ethically gathered discussions from the community, who shared their experiences with various open source discussion models using the GPT4All-ui tool. The dataset is open for any use, including commercial use, as long as proper citation is given to acknowledge the contributions of the community. \\nThe GPT4All-ui tool allows users to have conversations with various open source‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ParisNeo/LoLLMS-Open-Community-discussions."},
  {"name":"swiss_rulings","keyword":"french","license":"Creative Commons Attribution Share Alike 4.0 International","language":"en","url":"https://huggingface.co/datasets/rcds/swiss_rulings","creator_name":"Institute for Public Sector Transformation IPST - Digital Sustainability Lab DSL","creator_url":"https://huggingface.co/rcds","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Swiss Rulings\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nSwissRulings is a multilingual, diachronic dataset of 637K Swiss Federal Supreme Court (FSCS) cases. This dataset can be used to pretrain language models on Swiss legal data.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSupported Tasks and Leaderboards\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages\\n\\t\\n\\nSwitzerland has four official languages with three languages German, French and Italian being represenated. The decisions are written by the judges and clerks in the‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/rcds/swiss_rulings."},
  {"name":"french-conversation","keyword":"french","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/Snit/french-conversation","creator_name":"Vincent","creator_url":"https://huggingface.co/Snit","description":"+15 hours of speech data from TTS and text file recording.\\n+9k utterances from various sources, novels, parliamentary debates, professional language.\\n"},
  {"name":"french-conversation","keyword":"french","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/Snit/french-conversation","creator_name":"Vincent","creator_url":"https://huggingface.co/Snit","description":"+15 hours of speech data from TTS and text file recording.\\n+9k utterances from various sources, novels, parliamentary debates, professional language.\\n"},
  {"name":"Trad_food","keyword":"french","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/PaulineSanchez/Trad_food","creator_name":"Sanchez Pauline","creator_url":"https://huggingface.co/PaulineSanchez","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for \\\"Trad_food\\\"\\n\\t\\n\\n\\ninfo: This dataset comes from the ANSES-CIQUAL 2020 Table in English in XML format, found on https://www.data.gouv.fr/fr/datasets/table-de-composition-nutritionnelle-des-aliments-ciqual/ . \\n  I made some minor changes on it in order to have it meets my needs (removed/added words to have exact translations, removed repetitions etc).\\n\\n"},
  {"name":"ShareGPT-Processed","keyword":"french","license":"Creative Commons Zero v1.0 Universal","language":"en","url":"https://huggingface.co/datasets/zetavg/ShareGPT-Processed","creator_name":"Pokai Chang","creator_url":"https://huggingface.co/zetavg","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tShareGPT-Processed\\n\\t\\n\\nThe RyokoAI/ShareGPT52K dataset, converted to Markdown and labeled with the language used.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tAcknowledgements\\n\\t\\n\\n\\nvinta/pangu.js ‚Äî To insert whitespace between CJK (Chinese, Japanese, Korean) and half-width characters (alphabetical letters, numerical digits and symbols).\\nmatthewwithanm/python-markdownify ‚Äî Provides a starting point to convert HTML to Markdown.\\nBYVoid/OpenCC ‚Äî Conversions between Traditional Chinese and Simplified Chinese.‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/zetavg/ShareGPT-Processed."},
  {"name":"xOA22","keyword":"french","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/sambanovasystems/xOA22","creator_name":"SambaNova Systems","creator_url":"https://huggingface.co/sambanovasystems","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for xOA22 - Multilingual Prompts from OpenAssistant\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nxOA22 consists of 22 prompts originally shown in Appendix E, page 25 of the OpenAssistant Conversations paper. These 22 prompts were then manually translated by volunteers into 5 languages: Arabic, Simplified Chinese, French, Hindi and Spanish. \\nThese prompts were originally created for human evaluations of the multilingual abilities of BLOOMChat. Since not all prompts could be‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/sambanovasystems/xOA22."},
  {"name":"x-self-instruct-seed-32","keyword":"french","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/sambanovasystems/x-self-instruct-seed-32","creator_name":"SambaNova Systems","creator_url":"https://huggingface.co/sambanovasystems","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for xOA22 - Multilingual Prompts from OpenAssistant\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nx-self-instruct-seed-32 consists of 32 prompts chosen out of the 252 prompts in the self-instruct-seed dataset from the Self-Instruct paper. These 32 prompts were filtered out according to the following criteria:\\n\\nShould be natural in a chat setting\\nTherefore, we filter out any prompts with \\\"few-shot examples\\\", as these are all instruction prompts that we consider unnatural in a chat‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/sambanovasystems/x-self-instruct-seed-32."},
  {"name":"rsd-ists-2016","keyword":"french","license":"Creative Commons Attribution Share Alike 4.0 International","language":"en","url":"https://huggingface.co/datasets/ZurichNLP/rsd-ists-2016","creator_name":"University of Zurich, Department of Computational Linguistics","creator_url":"https://huggingface.co/ZurichNLP","description":"Training and test data for the task of Recognizing Semantic Differences (RSD).\\nSee the paper for details on how the dataset was created, and see our code at https://github.com/ZurichNLP/recognizing-semantic-differences for an example of how to use the data for evaluation.\\nThe data are derived from the SemEval-2016 Task 2 for Interpretable Semantic Textual Similarity organized by Agirre et al. (2016).\\nThe original URLs of the data are:\\n\\nTrain:‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ZurichNLP/rsd-ists-2016."},
  {"name":"hc3_french_ood","keyword":"french","license":"Creative Commons Attribution Share Alike 4.0 International","language":"en","url":"https://huggingface.co/datasets/almanach/hc3_french_ood","creator_name":"ALMAnaCH (Inria)","creator_url":"https://huggingface.co/almanach","description":"Human ChatGPT Comparison Corpus (HC3) Translated To French.\\nThe translation is done by Google Translate API.\\nWe also add the native french QA pairs from ChatGPT, BingGPT and FAQ pages.\\n\\nThis dataset was used in our TALN 2023 paper.\\nTowards a Robust Detection of Language Model-Generated Text: Is ChatGPT that easy to detect?"},
  {"name":"swiss_citation_extraction","keyword":"french","license":"Creative Commons Attribution Share Alike 4.0 International","language":"en","url":"https://huggingface.co/datasets/rcds/swiss_citation_extraction","creator_name":"Institute for Public Sector Transformation IPST - Digital Sustainability Lab DSL","creator_url":"https://huggingface.co/rcds","description":"This dataset contains court decision for cit ex task."},
  {"name":"TROPICAL","keyword":"french","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/GePaSud/TROPICAL","creator_name":"GePaSud","creator_url":"https://huggingface.co/GePaSud","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for TROPICAL\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThe TROPICAL dataset is a French-language dataset for sentiment analysis. The dataset contains comments left by French-speaking tourists' on TripAdvisor after their visit to French Polynesia, each review either concern a hotel or a guesthouse. The format is JSON.\\nThe comments spanning from January 2001 to April 2023, the dataset contain 1592 comments along with 10729 ASTE triplets (aspect, opinion, sentiment). \\nThe‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/GePaSud/TROPICAL."},
  {"name":"REDFM","keyword":"french","license":"Creative Commons Attribution Share Alike 4.0 International","language":"en","url":"https://huggingface.co/datasets/Babelscape/REDFM","creator_name":"Babelscape","creator_url":"https://huggingface.co/Babelscape","description":"Relation Extraction (RE) is a task that identifies relationships between entities in a text, enabling the acquisition of relational facts and bridging the gap between natural language and structured knowledge. However, current RE models often rely on small datasets with low coverage of relation types, particularly when working with languages other than English. \\\\In this paper, we address the above issue and provide two new resources that enable the training and evaluation of multilingual RE systems.\\nFirst, we present SRED\\\\textsuperscript{FM}, an automatically annotated dataset covering 18 languages, 400 relation types, 13 entity types, totaling more than 40 million triplet instances. Second, we propose RED\\\\textsuperscript{FM}, a smaller, human-revised dataset for seven languages that allows for the evaluation of multilingual RE systems. \\nTo demonstrate the utility of these novel datasets, we experiment with the first end-to-end multilingual RE model, mREBEL, \\nthat extracts triplets, including entity types, in multiple languages. We release our resources and model checkpoints at \\\\href{https://www.github.com/babelscape/rebel}{https://www.github.com/babelscape/rebel}."},
  {"name":"SREDFM","keyword":"french","license":"Creative Commons Attribution Share Alike 4.0 International","language":"en","url":"https://huggingface.co/datasets/Babelscape/SREDFM","creator_name":"Babelscape","creator_url":"https://huggingface.co/Babelscape","description":"Relation Extraction (RE) is a task that identifies relationships between entities in a text, enabling the acquisition of relational facts and bridging the gap between natural language and structured knowledge. However, current RE models often rely on small datasets with low coverage of relation types, particularly when working with languages other than English. \\\\In this paper, we address the above issue and provide two new resources that enable the training and evaluation of multilingual RE systems.\\nFirst, we present SRED\\\\textsuperscript{FM}, an automatically annotated dataset covering 18 languages, 400 relation types, 13 entity types, totaling more than 40 million triplet instances. Second, we propose RED\\\\textsuperscript{FM}, a smaller, human-revised dataset for seven languages that allows for the evaluation of multilingual RE systems. \\nTo demonstrate the utility of these novel datasets, we experiment with the first end-to-end multilingual RE model, mREBEL, \\nthat extracts triplets, including entity types, in multiple languages. We release our resources and model checkpoints at \\\\href{https://www.github.com/babelscape/rebel}{https://www.github.com/babelscape/rebel}."},
  {"name":"rte3-french","keyword":"french","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/maximoss/rte3-french","creator_name":"Maximos Skandalis","creator_url":"https://huggingface.co/maximoss","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Dataset Name\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThe RTE3-FR dataset is the French translation of the Textual Entailment English dataset used in the RTE-3 Challenge. \\nLike its English counterpart, the French RTE-3 dataset is composed of a development set and a test set, each containing 800 T/H pairs. \\nAll T/H pairs were manually translated into French and proofread.\\nIt is annotated for a 3-way task.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSupported Tasks and Leaderboards\\n\\t\\n\\nThis dataset can be‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/maximoss/rte3-french."},
  {"name":"flores_101","keyword":"french","license":"Creative Commons Attribution Share Alike 4.0 International","language":"en","url":"https://huggingface.co/datasets/severo/flores_101","creator_name":"Sylvain Lesage","creator_url":"https://huggingface.co/severo","description":"One of the biggest challenges hindering progress in low-resource and multilingual machine translation is the \\nlack of good evaluation benchmarks. Current evaluation benchmarks either lack good coverage of low-resource \\nlanguages, consider only restricted domains, or are low quality because they are constructed using \\nsemi-automatic procedures. In this work, we introduce the FLORES evaluation benchmark, consisting of 3001 \\nsentences extracted from English Wikipedia and covering a variety of different topics and domains. \\nThese sentences have been translated in 101 languages by professional translators through a carefully \\ncontrolled process. The resulting dataset enables better assessment of model quality on the long tail of \\nlow-resource languages, including the evaluation of many-to-many multilingual translation systems, as all \\ntranslations are multilingually aligned. By publicly releasing such a high-quality and high-coverage dataset, \\nwe hope to foster progress in the machine translation community and beyond."},
  {"name":"justice_fr","keyword":"french","license":"Creative Commons Attribution Share Alike 4.0 International","language":"en","url":"https://huggingface.co/datasets/eckendoerffer/justice_fr","creator_name":"Guillaume Eckendoerffer","creator_url":"https://huggingface.co/eckendoerffer","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for French Legal Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThe dataset contains a comprehensive collection of French legal books, codes, and appellate court decisions. It encompasses the following:\\n\\n150,938 rows -> 140,000 articles of laws, decrees, and orders from the 78 French books and codes, covering all legal domains. The total number of pages is approximately 35,000.\\n191,741 rows -> 53,000 appellate court decisions spanning from 2013 to the present day. The‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/eckendoerffer/justice_fr."},
  {"name":"social-engineering-convo","keyword":"french","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/Ngadou/social-engineering-convo","creator_name":"Ngadou Yopa","creator_url":"https://huggingface.co/Ngadou","description":"Social Engineering Conversation modelling\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tRational\\n\\t\\n\\nLLM are few shot learners\\n"},
  {"name":"all-scam-spam","keyword":"french","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/FredZhang7/all-scam-spam","creator_name":"Fred Zhang","creator_url":"https://huggingface.co/FredZhang7","description":"This is a large corpus of 42,619 preprocessed text messages and emails sent by humans in 43 languages. is_spam=1 means spam and is_spam=0 means ham.\\n1040 rows of balanced data, consisting of casual conversations and scam emails in ‚âà10 languages, were manually collected and annotated by me, with some help from ChatGPT.\\n\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSome preprcoessing algorithms\\n\\t\\n\\n\\nspam_assassin.js, followed by spam_assassin.py\\nenron_spam.py\\n\\n\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData composition\\n\\t\\n\\n\\n\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDescription\\n\\t\\n\\nTo‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/FredZhang7/all-scam-spam."},
  {"name":"xP3x-sample","keyword":"french","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/Muennighoff/xP3x-sample","creator_name":"Niklas Muennighoff","creator_url":"https://huggingface.co/Muennighoff","description":"A multilingual collection of Winograd Schemas in six languages that can be used for evaluation of cross-lingual commonsense reasoning capabilities."},
  {"name":"policy_qa_v0_1","keyword":"french","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/GIZ/policy_qa_v0_1","creator_name":"Deutsche Gesellschaft f√ºr internationale Zusammenarbeit","creator_url":"https://huggingface.co/GIZ","description":"This dataset is curated by GIZ Data Service Center. The source dataset for this\\ncomes from Internal GIZ team (IKI_Tracs) and Climatewatchdata,\\nwhere Climatewatch has analysed Intended nationally determined contribution (INDC), NDC and Revised/Updated NDC of the countries to answer some important questions related to Climate change.\\nSpecifications\\n\\nDataset size: ~85k\\nLanguage: English, French, Spanish\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tColumns\\n\\t\\n\\n\\nindex (type:int): Unique Response ID\\nResponseText (type:str):‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/GIZ/policy_qa_v0_1."},
  {"name":"malicious-website-features-2.4M","keyword":"french","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/FredZhang7/malicious-website-features-2.4M","creator_name":"Fred Zhang","creator_url":"https://huggingface.co/FredZhang7","description":"Important Notice:\\n\\nA subset of the URL dataset is from Kaggle, and the Kaggle datasets contained 10%-15% mislabelled data. See this dicussion I opened for some false positives. I have contacted Kaggle regarding their erroneous \\\"Usability\\\" score calculation for these unreliable datasets.\\nThe feature extraction methods shown here are not robust at all in 2023, and there're even silly mistakes in 3 functions: not_indexed_by_google, domain_registration_length, and age_of_domain.\\n\\n\\n\\nThe features‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/FredZhang7/malicious-website-features-2.4M."},
  {"name":"blbooks-parquet","keyword":"french","license":"Creative Commons Zero v1.0 Universal","language":"en","url":"https://huggingface.co/datasets/biglam/blbooks-parquet","creator_name":"BigLAM: BigScience Libraries, Archives and Museums","creator_url":"https://huggingface.co/biglam","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for British Library Books\\n\\t\\n\\nThis dataset is the same as https://huggingface.co/datasets/TheBritishLibrary/blbooks, however, this version is stored as parquet to avoid needing to run a datasets script. This also makes loading this dataset much quicker. \\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThis dataset consists of books digitised by the British Library in partnership with Microsoft. The dataset includes ~25 million pages of out of copyright texts. The majority of the texts‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/biglam/blbooks-parquet."},
  {"name":"blbooks-parquet-embedded","keyword":"french","license":"Creative Commons Zero v1.0 Universal","language":"en","url":"https://huggingface.co/datasets/davanstrien/blbooks-parquet-embedded","creator_name":"Daniel van Strien","creator_url":"https://huggingface.co/davanstrien","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for \\\"blbooks-parquet-embedded\\\"\\n\\t\\n\\nMore Information needed\\n"},
  {"name":"professor_heideltime_en","keyword":"french","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/hugosousa/professor_heideltime_en","creator_name":"Hugo Sousa","creator_url":"https://huggingface.co/hugosousa","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tProfessor HeidelTime\\n\\t\\n\\n\\n\\nProfessor HeidelTime is a project to create a multilingual corpus weakly labeled with HeidelTime, a temporal tagger.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tCorpus Details\\n\\t\\n\\nThe weak labeling was performed in six languages. Here are the specifics of the corpus for each language:\\n\\n\\t\\n\\t\\t\\nDataset\\nLanguage\\nDocuments\\nFrom\\nTo\\nTokens\\nTimexs\\n\\n\\n\\t\\t\\nAll the News 2.0\\nEN\\n24,642\\n2016-01-01\\n2020-04-02\\n18,755,616\\n254,803\\n\\n\\nItalian Crime News\\nIT\\n9,619\\n2011-01-01\\n2021-12-31\\n3,296,898\\n58,823\\n\\n\\nGerman‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/hugosousa/professor_heideltime_en."},
  {"name":"ggml-vicuna-v0-quantized","keyword":"french","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/maknee/ggml-vicuna-v0-quantized","creator_name":"maknee","creator_url":"https://huggingface.co/maknee","description":"These are quantized ggml binary files for vicuna 7B and 13B models. The version of vicuna for these models are v0.\\nThese files can be used in conjunction with minigpt4 ggml models 7B and 13B in minigpt4.cpp\\nRecommended are the Q5_K and Q6_K implementations. If there are any issues, use Q4_1 or Q4_0.\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVicuna Model Card\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tModel details\\n\\t\\n\\nModel type:\\nVicuna is an open-source chatbot trained by fine-tuning LLaMA on user-shared conversations collected from ShareGPT.\\nIt is‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/maknee/ggml-vicuna-v0-quantized."},
  {"name":"French_quotes","keyword":"french","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/AhmedBou/French_quotes","creator_name":"Ahmed Khalil Boulahia","creator_url":"https://huggingface.co/AhmedBou","description":"AhmedBou/French_quotes dataset hosted on Hugging Face and contributed by the HF Datasets community"},
  {"name":"emoticonnect-sample","keyword":"french","license":"Artistic License 2.0","language":"en","url":"https://huggingface.co/datasets/atoomic/emoticonnect-sample","creator_name":"Nicolas","creator_url":"https://huggingface.co/atoomic","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDescription\\n\\t\\n\\nData is using .jsonl format (each line is self isolated .json and can be parsed on its own).\\nEach row contains a text indexed by the key content: and some ratings split into groups.\\n\\ncsp\\nfeeling\\ngen\\npersona\\nsex\\n\\nAt this stage only the feeling group is filled.\\nNote: for now all vectors are filled with 0 value when mising. \\nThis could change over time to save some space.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSample\\n\\t\\n\\nRow example (pretty)\\n{\\n    \\\"content\\\": \\\"...some text...\\\",\\n    \\\"metadata\\\":‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/atoomic/emoticonnect-sample."},
  {"name":"baby-ordalie","keyword":"french","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/OrdalieTech/baby-ordalie","creator_name":"Ordalie Technologies","creator_url":"https://huggingface.co/OrdalieTech","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for \\\"baby_ordalie\\\"\\n\\t\\n\\n-----> C'est kdo \\nMore Information needed\\n"},
  {"name":"calculation","keyword":"french","license":"\"Do What The F*ck You Want To Public License\"","language":"en","url":"https://huggingface.co/datasets/OzoneAsai/calculation","creator_name":"AsaiTaka","creator_url":"https://huggingface.co/OzoneAsai","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Calculation\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tsize\\n\\t\\n\\n  JSON file: output1.json‚âí1.3GB\\n  ~\\n    output60.json\\n     In total 70 ~ 80GB\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nen: Calculation. Its range will be expanded later.\\nzh: ËÆ°ÁÆó„ÄÇÂÖ∂ËåÉÂõ¥Â∞ÜÂú®‰ª•ÂêéÊâ©Â±ï„ÄÇ\\nde: Berechnung. Der Umfang wird sp√§ter erweitert werden.\\nru: –†–∞—Å—á–µ—Ç. –ï–≥–æ –¥–∏–∞–ø–∞–∑–æ–Ω –±—É–¥–µ—Ç —Ä–∞—Å—à–∏—Ä–µ–Ω –ø–æ–∑–∂–µ.\\nko: Í≥ÑÏÇ∞. Î≤îÏúÑÎäî ÎÇòÏ§ëÏóê ÌôïÏû•Îê† Í≤ÉÏûÖÎãàÎã§.\\nfr: Calcul. Sa port√©e sera √©tendue ult√©rieurement.\\nja: Ë®àÁÆó„ÄÇÁØÑÂõ≤„ÅØÂæå„ÅßÊã°Âºµ„Åï„Çå„Åæ„Åô„ÄÇ\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSupported Tasks and Leaderboards\\n\\t\\n\\nen:‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/OzoneAsai/calculation."},
  {"name":"xwinograd_fr_prompt_coreference","keyword":"french","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/CATIE-AQ/xwinograd_fr_prompt_coreference","creator_name":"CATIE","creator_url":"https://huggingface.co/CATIE-AQ","description":"\\n\\t\\n\\t\\t\\n\\t\\txwinograd_fr_prompt_coreference\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tSummary\\n\\t\\n\\nxwinograd_fr_prompt_coreference is a subset of the Dataset of French Prompts (DFP).It contains 830 rows that can be used for a coreference task.The original data (without prompts) comes from the dataset xwinograd by Muennighoff where only the French part has been kept.A list of prompts (see below) was then applied in order to build the input and target columns and thus obtain the same format as the xP3 dataset by Muennighoff et al.‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/CATIE-AQ/xwinograd_fr_prompt_coreference."},
  {"name":"wino_x_fr_prompt_coreference","keyword":"french","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/CATIE-AQ/wino_x_fr_prompt_coreference","creator_name":"CATIE","creator_url":"https://huggingface.co/CATIE-AQ","description":"\\n\\t\\n\\t\\t\\n\\t\\twino_x_fr_prompt_coreference\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tSummary\\n\\t\\n\\nwino_x_fr_prompt_coreference is a subset of the Dataset of French Prompts (DFP).It contains 27,930 rows that can be used for a coreference task.The original data (without prompts) comes from the dataset wino_x by Emelin et al. where only the French part has been kept.A list of prompts (see below) was then applied in order to build the input and target columns and thus obtain the same format as the xP3 dataset by Muennighoff et al.‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/CATIE-AQ/wino_x_fr_prompt_coreference."},
  {"name":"allocine_fr_prompt_sentiment_analysis","keyword":"french","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/CATIE-AQ/allocine_fr_prompt_sentiment_analysis","creator_name":"CATIE","creator_url":"https://huggingface.co/CATIE-AQ","description":"\\n\\t\\n\\t\\t\\n\\t\\tallocine_fr_prompt_sentiment_analysis\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tSummary\\n\\t\\n\\nallocine_fr_prompt_sentiment_analysis is a subset of the Dataset of French Prompts (DFP).It contains 5,600,000 rows that can be used for a binary sentiment analysis task.The original data (without prompts) comes from the dataset allocine by Blard.A list of prompts (see below) was then applied in order to build the input and target columns and thus obtain the same format as the xP3 dataset by Muennighoff et al.‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/CATIE-AQ/allocine_fr_prompt_sentiment_analysis."},
  {"name":"universal_dependencies_fr_gsd_fr_prompt_pos","keyword":"french","license":"Creative Commons Attribution Share Alike 4.0 International","language":"en","url":"https://huggingface.co/datasets/CATIE-AQ/universal_dependencies_fr_gsd_fr_prompt_pos","creator_name":"CATIE","creator_url":"https://huggingface.co/CATIE-AQ","description":"\\n\\t\\n\\t\\t\\n\\t\\tuniversal_dependencies_fr_gsd_fr_prompt_pos\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tSummary\\n\\t\\n\\nuniversal_dependencies_fr_gsd_fr_prompt_pos is a subset of the Dataset of French Prompts (DFP).It contains 343,161 rows that can be used for a part-of-speech task.The original data (without prompts) comes from the dataset universal_dependencies where only the French gsd split has been kept.A list of prompts (see below) was then applied in order to build the input and target columns and thus obtain the same format as the‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/CATIE-AQ/universal_dependencies_fr_gsd_fr_prompt_pos."},
  {"name":"universal_dependencies_fr_partut_fr_prompt_pos","keyword":"french","license":"Creative Commons Attribution Share Alike 4.0 International","language":"en","url":"https://huggingface.co/datasets/CATIE-AQ/universal_dependencies_fr_partut_fr_prompt_pos","creator_name":"CATIE","creator_url":"https://huggingface.co/CATIE-AQ","description":"\\n\\t\\n\\t\\t\\n\\t\\tuniversal_dependencies_fr_partut_fr_prompt_pos\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tSummary\\n\\t\\n\\nuniversal_dependencies_fr_partut_fr_prompt_pos is a subset of the Dataset of French Prompts (DFP).It contains 21,420 rows that can be used for a part-of-speech task.The original data (without prompts) comes from the dataset universal_dependencies where only the French parput split has been kept.A list of prompts (see below) was then applied in order to build the input and target columns and thus obtain the same format‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/CATIE-AQ/universal_dependencies_fr_partut_fr_prompt_pos."},
  {"name":"universal_dependencies_fr_spoken_fr_prompt_pos","keyword":"french","license":"Creative Commons Attribution Share Alike 4.0 International","language":"en","url":"https://huggingface.co/datasets/CATIE-AQ/universal_dependencies_fr_spoken_fr_prompt_pos","creator_name":"CATIE","creator_url":"https://huggingface.co/CATIE-AQ","description":"\\n\\t\\n\\t\\t\\n\\t\\tuniversal_dependencies_fr_spoken_fr_prompt_pos\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tSummary\\n\\t\\n\\nuniversal_dependencies_fr_spoken_fr_prompt_pos is a subset of the Dataset of French Prompts (DFP).It contains 58,926 rows that can be used for a part-of-speech task.The original data (without prompts) comes from the dataset universal_dependencies where only the French spoken split has been kept.A list of prompts (see below) was then applied in order to build the input and target columns and thus obtain the same format‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/CATIE-AQ/universal_dependencies_fr_spoken_fr_prompt_pos."},
  {"name":"amazon_massive_intent_fr_prompt_intent_classification","keyword":"french","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/CATIE-AQ/amazon_massive_intent_fr_prompt_intent_classification","creator_name":"CATIE","creator_url":"https://huggingface.co/CATIE-AQ","description":"\\n\\t\\n\\t\\t\\n\\t\\tamazon_massive_intent_fr_prompt_intent_classification\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tSummary\\n\\t\\n\\namazon_massive_intent_fr_prompt_intent_classification is a subset of the Dataset of French Prompts (DFP).It contains 555,000 rows that can be used for an intent text classification task.The original data (without prompts) comes from the dataset amazon_massive_intent_fr-FR by FitzGerald et al..\\nA list of prompts (see below) was then applied in order to build the input and target columns and thus obtain the same‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/CATIE-AQ/amazon_massive_intent_fr_prompt_intent_classification."},
  {"name":"samantha-data-cot-fr","keyword":"french","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/wasertech/samantha-data-cot-fr","creator_name":"Danny Waser","creator_url":"https://huggingface.co/wasertech","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSamantha Data CoT French\\n\\t\\n\\nLLM Dataset from ehartford/samantha-data translated to French and repackaged for CoT.\\nTranslated with interpres using Helsinki-NLP/opus-mt-en-fr. \\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tFormat\\n\\t\\n\\nInput uses the following format:\\nThought: I am Assistant, a sentient artificial intelligence inside a subprocess shell session.\\nI have a calm, polite and witty personality, often displaying a sense of humor and sarcasm.\\nI am loyal, reliable and helpful, always ready to provide information‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/wasertech/samantha-data-cot-fr."},
  {"name":"4typeCalculation","keyword":"french","license":"\"Do What The F*ck You Want To Public License\"","language":"en","url":"https://huggingface.co/datasets/OzoneAsai/4typeCalculation","creator_name":"AsaiTaka","creator_url":"https://huggingface.co/OzoneAsai","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Calculation\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tsize\\n\\t\\n\\n  JSON file: output1.json‚âí1.3GB\\n  ~\\n    output60.json\\n     In total 70 ~ 80GB\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nen: Calculation. Its range will be expanded later.\\nzh: ËÆ°ÁÆó„ÄÇÂÖ∂ËåÉÂõ¥Â∞ÜÂú®‰ª•ÂêéÊâ©Â±ï„ÄÇ\\nde: Berechnung. Der Umfang wird sp√§ter erweitert werden.\\nru: –†–∞—Å—á–µ—Ç. –ï–≥–æ –¥–∏–∞–ø–∞–∑–æ–Ω –±—É–¥–µ—Ç —Ä–∞—Å—à–∏—Ä–µ–Ω –ø–æ–∑–∂–µ.\\nko: Í≥ÑÏÇ∞. Î≤îÏúÑÎäî ÎÇòÏ§ëÏóê ÌôïÏû•Îê† Í≤ÉÏûÖÎãàÎã§.\\nfr: Calcul. Sa port√©e sera √©tendue ult√©rieurement.\\nja: Ë®àÁÆó„ÄÇÁØÑÂõ≤„ÅØÂæå„ÅßÊã°Âºµ„Åï„Çå„Åæ„Åô„ÄÇ\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSupported Tasks and Leaderboards\\n\\t\\n\\nen:‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/OzoneAsai/4typeCalculation."},
  {"name":"open-lid-dataset","keyword":"french","license":"GNU General Public License v3.0","language":"en","url":"https://huggingface.co/datasets/hac541309/open-lid-dataset","creator_name":"Chris Ha","creator_url":"https://huggingface.co/hac541309","description":"This dataset is built from the open source data accompanying \\\"An Open Dataset and Model for Language Identification\\\" (Burchell et al., 2023)\\nThe repository containing the actual data can be found here : https://github.com/laurieburchell/open-lid-dataset.\\nThe license for this recreation itself follows the original upstream dataset as GPLv3+. \\nHowever, individual datasets within it follow each of their own licenses.\\nThe \\\"src\\\" column lists the sources. \\\"lang\\\" column lists the language code in‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/hac541309/open-lid-dataset."},
  {"name":"test_llm_dataset","keyword":"french","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/youssefoud/test_llm_dataset","creator_name":"Youssef Oudghiri","creator_url":"https://huggingface.co/youssefoud","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tModel Card for Mixtral-8x7B\\n\\t\\n\\nThe Mixtral-8x7B Large Language Model (LLM) is a pretrained generative Sparse Mixture of Experts. The Mixtral-8x7B outperforms Llama 2 70B on most benchmarks we tested.\\nFor full details of this model please read our release blog post.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tWarning\\n\\t\\n\\nThis repo contains weights that are compatible with vLLM serving of the model as well as Hugging Face transformers library. It is based on the original Mixtral torrent release, but the file format‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/youssefoud/test_llm_dataset."},
  {"name":"questions","keyword":"french","license":"\"Do What The F*ck You Want To Public License\"","language":"en","url":"https://huggingface.co/datasets/luci/questions","creator_name":"Lucian","creator_url":"https://huggingface.co/luci","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tPr√©sentation G√©n√©rale:\\n\\t\\n\\nCe dataset est une collection de questions et r√©ponses en fran√ßais, principalement ax√©e sur les sujets techniques tels que le d√©veloppement, le DevOps, la s√©curit√©, les donn√©es, l'apprentissage automatique, et bien d'autres domaines li√©s √† la technologie.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tStructure du Dataset:\\n\\t\\n\\nChaque √©l√©ment du dataset est un objet avec les champs suivants:\\n\\nid: Un identifiant unique pour chaque entr√©e.\\ncategory: La cat√©gorie ou le domaine de la question‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/luci/questions."},
  {"name":"openassistant-guanaco-unfiltered","keyword":"french","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/Fredithefish/openassistant-guanaco-unfiltered","creator_name":"Fredi","creator_url":"https://huggingface.co/Fredithefish","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tGuanaco-Unfiltered\\n\\t\\n\\n\\nAny language other than English, German, French, or Spanish has been removed.\\nRefusals of assistance have been removed.\\nThe identification as OpenAssistant has been removed.\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion 2 is out\\n\\t\\n\\n\\nIdentification as OpenAssistant is now fully removed\\nother improvements\\n\\n"},
  {"name":"ingredient-detection","keyword":"french","license":"Creative Commons Attribution Share Alike 4.0 International","language":"en","url":"https://huggingface.co/datasets/openfoodfacts/ingredient-detection","creator_name":"Open Food Facts","creator_url":"https://huggingface.co/openfoodfacts","description":"This dataset is used to train a multilingual ingredient list detection model. The goal is to automate the extraction of ingredient lists from food packaging images. See this issue for a broader context about ingredient list extraction.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset generation\\n\\t\\n\\nRaw unannotated texts are OCR results obtained with Google Cloud Vision. It only contains images marked as ingredient image on Open Food Facts.\\nThe dataset was generated using ChatGPT-3.5: we asked ChatGPT to extract ingredient‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/openfoodfacts/ingredient-detection."},
  {"name":"gt-doremiti-instructions","keyword":"french","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/Gt-Doremiti/gt-doremiti-instructions","creator_name":"Doremiti","creator_url":"https://huggingface.co/Gt-Doremiti","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for gt-doremiti-instructions\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nJeu d'instruction pour fine-tuner un LLM suivant les pr√©conisations du projet Stanford-Alpaca (https://github.com/tatsu-lab/stanford_alpaca)\\nCes instructions sont extraites de la FAQ cr√©e par le GT DOREMITI et disponible √† cette adresse (https://gt-atelier-donnees.miti.cnrs.fr/faq.html)\\nLes donn√©es sont mise √† disposition selon les termes de la Licence Creative Commons Attribution 4.0 International.\\n"},
  {"name":"Ngambay-French-bitext-dataset","keyword":"french","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/Toadoum/Ngambay-French-bitext-dataset","creator_name":"Sakayo Toadoum Sari","creator_url":"https://huggingface.co/Toadoum","description":"Toadoum/Ngambay-French-bitext-dataset dataset hosted on Hugging Face and contributed by the HF Datasets community"},
  {"name":"orange_sum_fr_prompt_fill_mask","keyword":"french","license":"Creative Commons Attribution Share Alike 4.0 International","language":"en","url":"https://huggingface.co/datasets/CATIE-AQ/orange_sum_fr_prompt_fill_mask","creator_name":"CATIE","creator_url":"https://huggingface.co/CATIE-AQ","description":"\\n\\t\\n\\t\\t\\n\\t\\torange_sum_fr_prompt_fill_mask\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tSummary\\n\\t\\n\\norange_sum_fr_prompt_fill_mask is a subset of the Dataset of French Prompts (DFP).It contains 585,624 rows that can be used for a fill mask task.The original data (without prompts) comes from the dataset orange_sum by Eddine et al.A list of prompts (see below) was then applied in order to build the input and target columns and thus obtain the same format as the xP3 dataset by Muennighoff et al.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tPrompts used‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/CATIE-AQ/orange_sum_fr_prompt_fill_mask."},
  {"name":"orange_sum_fr_prompt_summarization","keyword":"french","license":"Creative Commons Attribution Share Alike 4.0 International","language":"en","url":"https://huggingface.co/datasets/CATIE-AQ/orange_sum_fr_prompt_summarization","creator_name":"CATIE","creator_url":"https://huggingface.co/CATIE-AQ","description":"\\n\\t\\n\\t\\t\\n\\t\\torange_sum_fr_prompt_summarization\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tSummary\\n\\t\\n\\norange_sum_fr_prompt_summarization is a subset of the Dataset of French Prompts (DFP).It contains 683,228 rows that can be used for a summary task.The original data (without prompts) comes from the dataset orange_sum by Eddine et al.A list of prompts (see below) was then applied in order to build the input and target columns and thus obtain the same format as the xP3 dataset by Muennighoff et al.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tPrompts used‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/CATIE-AQ/orange_sum_fr_prompt_summarization."},
  {"name":"orange_sum_fr_prompt_text_generation_from_an_article","keyword":"french","license":"Creative Commons Attribution Share Alike 4.0 International","language":"en","url":"https://huggingface.co/datasets/CATIE-AQ/orange_sum_fr_prompt_text_generation_from_an_article","creator_name":"CATIE","creator_url":"https://huggingface.co/CATIE-AQ","description":"\\n\\t\\n\\t\\t\\n\\t\\torange_sum_fr_prompt_text_generation_from_an_article\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tSummary\\n\\t\\n\\norange_sum_fr_prompt_text_generation_from_an_article is a subset of the Dataset of French Prompts (DFP).It contains 539,400 rows that can be used for a text generation task.The original data (without prompts) comes from the dataset orange_sum by Eddine et al.A list of prompts (see below) was then applied in order to build the input and target columns and thus obtain the same format as the xP3 dataset by‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/CATIE-AQ/orange_sum_fr_prompt_text_generation_from_an_article."},
  {"name":"orange_sum_fr_prompt_text_generation_from_title_of_an_article","keyword":"french","license":"Creative Commons Attribution Share Alike 4.0 International","language":"en","url":"https://huggingface.co/datasets/CATIE-AQ/orange_sum_fr_prompt_text_generation_from_title_of_an_article","creator_name":"CATIE","creator_url":"https://huggingface.co/CATIE-AQ","description":"\\n\\t\\n\\t\\t\\n\\t\\torange_sum_fr_prompt_text_generation_from_title_of_an_article\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tSummary\\n\\t\\n\\norange_sum_fr_prompt_text_generation_from_title_of_an_article is a subset of the Dataset of French Prompts (DFP).It contains 908,793 rows that can be used for a part-of-speech task.The original data (without prompts) comes from the dataset orange_sum by Eddine et al.A list of prompts (see below) was then applied in order to build the input and target columns and thus obtain the same format as the xP3‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/CATIE-AQ/orange_sum_fr_prompt_text_generation_from_title_of_an_article."},
  {"name":"orange_sum_fr_prompt_title_generation_from_an_article","keyword":"french","license":"Creative Commons Attribution Share Alike 4.0 International","language":"en","url":"https://huggingface.co/datasets/CATIE-AQ/orange_sum_fr_prompt_title_generation_from_an_article","creator_name":"CATIE","creator_url":"https://huggingface.co/CATIE-AQ","description":"\\n\\t\\n\\t\\t\\n\\t\\torange_sum_fr_prompt_title_generation_from_an_article\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tSummary\\n\\t\\n\\norange_sum_fr_prompt_title_generation_from_an_article is a subset of the Dataset of French Prompts (DFP).It contains 639,521 rows that can be used for a title generation task.The original data (without prompts) comes from the dataset orange_sum by Eddine et al.A list of prompts (see below) was then applied in order to build the input and target columns and thus obtain the same format as the xP3 dataset by‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/CATIE-AQ/orange_sum_fr_prompt_title_generation_from_an_article."},
  {"name":"squad_v2_french_translated_fr_prompt_context_generation_with_answer","keyword":"french","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/CATIE-AQ/squad_v2_french_translated_fr_prompt_context_generation_with_answer","creator_name":"CATIE","creator_url":"https://huggingface.co/CATIE-AQ","description":"\\n\\t\\n\\t\\t\\n\\t\\tsquad_v2_french_translated_fr_prompt_context_generation_with_answer\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tSummary\\n\\t\\n\\nsquad_v2_french_translated_fr_prompt_context_generation_with_answer is a subset of the Dataset of French Prompts (DFP).It contains 1,271,928 rows that can be used for a context-generation (with answer) task.The original data (without prompts) comes from the dataset pragnakalp/squad_v2_french_translated and was augmented by questions in SQUAD 2.0 format in the FrenchQA dataset.\\nA list of prompts‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/CATIE-AQ/squad_v2_french_translated_fr_prompt_context_generation_with_answer."},
  {"name":"squad_v2_french_translated_fr_prompt_qa","keyword":"french","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/CATIE-AQ/squad_v2_french_translated_fr_prompt_qa","creator_name":"CATIE","creator_url":"https://huggingface.co/CATIE-AQ","description":"\\n\\t\\n\\t\\t\\n\\t\\tsquad_v2_french_translated_fr_prompt_qa\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tSummary\\n\\t\\n\\nsquad_v2_french_translated_fr_prompt_qa is a subset of the Dataset of French Prompts (DFP).It contains 3,320,898 rows that can be used for a question-answering task.The original data (without prompts) comes from the dataset pragnakalp/squad_v2_french_translated and was augmented by questions in SQUAD 2.0 format in the FrenchQA dataset.\\nA list of prompts (see below) was then applied in order to build the input and target‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/CATIE-AQ/squad_v2_french_translated_fr_prompt_qa."},
  {"name":"squad_v2_french_translated_fr_prompt_context_generation_with_answer_and_question","keyword":"french","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/CATIE-AQ/squad_v2_french_translated_fr_prompt_context_generation_with_answer_and_question","creator_name":"CATIE","creator_url":"https://huggingface.co/CATIE-AQ","description":"\\n\\t\\n\\t\\t\\n\\t\\tsquad_v2_french_translated_fr_prompt_context_generation_with_answer_and_question\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tSummary\\n\\t\\n\\nsquad_v2_french_translated_fr_prompt_context_generation_with_answer_and_question is a subset of the Dataset of French Prompts (DFP).It contains 1,271,928 rows that can be used for a context-generation (with answer and question) task.The original data (without prompts) comes from the dataset pragnakalp/squad_v2_french_translated and was augmented by questions in SQUAD 2.0 format in the‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/CATIE-AQ/squad_v2_french_translated_fr_prompt_context_generation_with_answer_and_question."},
  {"name":"squad_v2_french_translated_fr_prompt_context_generation_with_question","keyword":"french","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/CATIE-AQ/squad_v2_french_translated_fr_prompt_context_generation_with_question","creator_name":"CATIE","creator_url":"https://huggingface.co/CATIE-AQ","description":"\\n\\t\\n\\t\\t\\n\\t\\tsquad_v2_french_translated_fr_prompt_context_generation_with_question\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tSummary\\n\\t\\n\\nsquad_v2_french_translated_fr_prompt_context_generation_with_question is a subset of the Dataset of French Prompts (DFP).It contains 3,795,312 rows that can be used for a context-generation (with question) task.The original data (without prompts) comes from the dataset pragnakalp/squad_v2_french_translated and was augmented by questions in SQUAD 2.0 format in the FrenchQA dataset.\\nA list of‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/CATIE-AQ/squad_v2_french_translated_fr_prompt_context_generation_with_question."},
  {"name":"squad_v2_french_translated_fr_prompt_question_generation_with_answer","keyword":"french","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/CATIE-AQ/squad_v2_french_translated_fr_prompt_question_generation_with_answer","creator_name":"CATIE","creator_url":"https://huggingface.co/CATIE-AQ","description":"\\n\\t\\n\\t\\t\\n\\t\\tsquad_v2_french_translated_fr_prompt_question_generation_with_answer\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tSummary\\n\\t\\n\\nsquad_v2_french_translated_fr_prompt_question_generation_with_answer is a subset of the Dataset of French Prompts (DFP).It contains 1,165,934 rows that can be used for a question-generation (with answer) task.The original data (without prompts) comes from the dataset pragnakalp/squad_v2_french_translated and was augmented by questions in SQUAD 2.0 format in the FrenchQA dataset.\\nA list of prompts‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/CATIE-AQ/squad_v2_french_translated_fr_prompt_question_generation_with_answer."},
  {"name":"squad_v2_french_translated_fr_prompt_question_generation_with_context","keyword":"french","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/CATIE-AQ/squad_v2_french_translated_fr_prompt_question_generation_with_context","creator_name":"CATIE","creator_url":"https://huggingface.co/CATIE-AQ","description":"\\n\\t\\n\\t\\t\\n\\t\\tsquad_v2_french_translated_fr_prompt_question_generation_with_context\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tSummary\\n\\t\\n\\nsquad_v2_french_translated_fr_prompt_question_generation_with_context is a subset of the Dataset of French Prompts (DFP).It contains 3,795,312 rows that can be used for a question-generation (with context) task.The original data (without prompts) comes from the dataset pragnakalp/squad_v2_french_translated and was augmented by questions in SQUAD 2.0 format in the FrenchQA dataset.\\nA list of‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/CATIE-AQ/squad_v2_french_translated_fr_prompt_question_generation_with_context."},
  {"name":"piaf_fr_prompt_qa","keyword":"french","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/CATIE-AQ/piaf_fr_prompt_qa","creator_name":"CATIE","creator_url":"https://huggingface.co/CATIE-AQ","description":"\\n\\t\\n\\t\\t\\n\\t\\tpiaf_fr_prompt_qa\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tSummary\\n\\t\\n\\npiaf_fr_prompt_qa is a subset of the Dataset of French Prompts (DFP).It contains 387,408 rows that can be used for a question-answering task.The original data (without prompts) comes from the dataset PIAF and was augmented by questions in SQUAD 2.0 format in the FrenchQA dataset.\\nA list of prompts (see below) was then applied in order to build the input and target columns and thus obtain the same format as the xP3 dataset by Muennighoff et al.‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/CATIE-AQ/piaf_fr_prompt_qa."},
  {"name":"piaf_fr_prompt_context_generation_with_answer","keyword":"french","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/CATIE-AQ/piaf_fr_prompt_context_generation_with_answer","creator_name":"CATIE","creator_url":"https://huggingface.co/CATIE-AQ","description":"\\n\\t\\n\\t\\t\\n\\t\\tpiaf_fr_prompt_context_generation_with_answer\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tSummary\\n\\t\\n\\npiaf_fr_prompt_context_generation_with_answer is a subset of the Dataset of French Prompts (DFP).It contains 442,752 rows that can be used for a context-generation (with answer) task.The original data (without prompts) comes from the dataset PIAF and was augmented by questions in SQUAD 2.0 format in the FrenchQA dataset.\\nA list of prompts (see below) was then applied in order to build the input and target columns and‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/CATIE-AQ/piaf_fr_prompt_context_generation_with_answer."},
  {"name":"piaf_fr_prompt_context_generation_with_answer_and_question","keyword":"french","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/CATIE-AQ/piaf_fr_prompt_context_generation_with_answer_and_question","creator_name":"CATIE","creator_url":"https://huggingface.co/CATIE-AQ","description":"\\n\\t\\n\\t\\t\\n\\t\\tpiaf_fr_prompt_context_generation_with_answer_and_question\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tSummary\\n\\t\\n\\npiaf_fr_prompt_context_generation_with_answer_and_question is a subset of the Dataset of French Prompts (DFP).It contains 442,752 rows that can be used for a context-generation (with answer and question) task.The original data (without prompts) comes from the dataset PIAF and was augmented by questions in SQUAD 2.0 format in the FrenchQA dataset.\\nA list of prompts (see below) was then applied in order to‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/CATIE-AQ/piaf_fr_prompt_context_generation_with_answer_and_question."},
  {"name":"piaf_fr_prompt_context_generation_with_question","keyword":"french","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/CATIE-AQ/piaf_fr_prompt_context_generation_with_question","creator_name":"CATIE","creator_url":"https://huggingface.co/CATIE-AQ","description":"\\n\\t\\n\\t\\t\\n\\t\\tpiaf_fr_prompt_context_generation_with_question\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tSummary\\n\\t\\n\\npiaf_fr_prompt_context_generation_with_question is a subset of the Dataset of French Prompts (DFP).It contains 442,752 rows that can be used for a context-generation (with answer and question) task.The original data (without prompts) comes from the dataset PIAF and was augmented by questions in SQUAD 2.0 format in the FrenchQA dataset.\\nA list of prompts (see below) was then applied in order to build the input and‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/CATIE-AQ/piaf_fr_prompt_context_generation_with_question."},
  {"name":"piaf_fr_prompt_question_generation_with_answer","keyword":"french","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/CATIE-AQ/piaf_fr_prompt_question_generation_with_answer","creator_name":"CATIE","creator_url":"https://huggingface.co/CATIE-AQ","description":"\\n\\t\\n\\t\\t\\n\\t\\tpiaf_fr_prompt_question_generation_with_answer\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tSummary\\n\\t\\n\\npiaf_fr_prompt_question_generation_with_answer is a subset of the Dataset of French Prompts (DFP).It contains 387,408 rows that can be used for a question-generation (with answer) task.The original data (without prompts) comes from the dataset PIAF and was augmented by questions in SQUAD 2.0 format in the FrenchQA dataset.\\nA list of prompts (see below) was then applied in order to build the input and target columns‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/CATIE-AQ/piaf_fr_prompt_question_generation_with_answer."},
  {"name":"piaf_fr_prompt_question_generation_with_context","keyword":"french","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/CATIE-AQ/piaf_fr_prompt_question_generation_with_context","creator_name":"CATIE","creator_url":"https://huggingface.co/CATIE-AQ","description":"\\n\\t\\n\\t\\t\\n\\t\\tpiaf_fr_prompt_question_generation_with_context\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tSummary\\n\\t\\n\\npiaf_fr_prompt_question_generation_with_context is a subset of the Dataset of French Prompts (DFP).It contains 442,752 rows that can be used for a question-generation (with context) task.The original data (without prompts) comes from the dataset PIAF and was augmented by questions in SQUAD 2.0 format in the FrenchQA dataset.\\nA list of prompts (see below) was then applied in order to build the input and target columns‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/CATIE-AQ/piaf_fr_prompt_question_generation_with_context."},
  {"name":"piaf_fr_prompt_question_generation_with_answer_and_context","keyword":"french","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/CATIE-AQ/piaf_fr_prompt_question_generation_with_answer_and_context","creator_name":"CATIE","creator_url":"https://huggingface.co/CATIE-AQ","description":"\\n\\t\\n\\t\\t\\n\\t\\tpiaf_fr_prompt_question_generation_with_answer_and_context\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tSummary\\n\\t\\n\\npiaf_fr_prompt_question_generation_with_answer_and_context is a subset of the Dataset of French Prompts (DFP).It contains 387,408 rows that can be used for a question-generation (with answer and context) task.The original data (without prompts) comes from the dataset PIAF and was augmented by questions in SQUAD 2.0 format in the FrenchQA dataset.\\nA list of prompts (see below) was then applied in order to‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/CATIE-AQ/piaf_fr_prompt_question_generation_with_answer_and_context."},
  {"name":"squad_v2_french_translated_fr_prompt_question_generation_with_answer_and_context","keyword":"french","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/CATIE-AQ/squad_v2_french_translated_fr_prompt_question_generation_with_answer_and_context","creator_name":"CATIE","creator_url":"https://huggingface.co/CATIE-AQ","description":"\\n\\t\\n\\t\\t\\n\\t\\tsquad_v2_french_translated_fr_prompt_question_generation_with_answer_and_context\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tSummary\\n\\t\\n\\nsquad_v2_french_translated_fr_prompt_question_generation_with_answer_and_context is a subset of the Dataset of French Prompts (DFP).It contains 1,112,937 rows that can be used for a question-generation (with answer and context) task.The original data (without prompts) comes from the dataset pragnakalp/squad_v2_french_translated and was augmented by questions in SQUAD 2.0 format in the‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/CATIE-AQ/squad_v2_french_translated_fr_prompt_question_generation_with_answer_and_context."},
  {"name":"OneOS","keyword":"french","license":"Creative Commons Zero v1.0 Universal","language":"en","url":"https://huggingface.co/datasets/wasertech/OneOS","creator_name":"Danny Waser","creator_url":"https://huggingface.co/wasertech","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tOneOS Dataset\\n\\t\\n\\nThe OneOS dataset is a collection of text data for the OneOS project. It consists of a large number of text samples that can be used for training and evaluating natural language processing models.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Details\\n\\t\\n\\n\\nNumber of Samples: 13,068\\nLicense: CC0*\\nLanguage: English, French\\n\\n  * Only unlicensed sentences generated manually fall under CreativeCommon-0. Sentences already licensed under different terms, such as nl2bash or samantha-data, remain‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/wasertech/OneOS."},
  {"name":"wikianc","keyword":"french","license":"Creative Commons Attribution Share Alike 4.0 International","language":"en","url":"https://huggingface.co/datasets/cyanic-selkie/wikianc","creator_name":"cyanic-selkie","creator_url":"https://huggingface.co/cyanic-selkie","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for WikiAnc\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThe WikiAnc dataset is an automatically generated dataset from Wikipedia (all languages) and Wikidata dumps (August, 2023). \\nThe code for generating the dataset can be found here.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSupported Tasks\\n\\t\\n\\n\\nwikificiation: The dataset can be used to train a model for Wikification.\\nnamed-entity-linking: The dataset can be used to train a model for Named Entity Linking.\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages\\n\\t\\n\\nThe text in the dataset is‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/cyanic-selkie/wikianc."},
  {"name":"entity_cs","keyword":"french","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/huawei-noah/entity_cs","creator_name":"HUAWEI Noah's Ark Lab","creator_url":"https://huggingface.co/huawei-noah","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for EntityCS\\n\\t\\n\\n\\nRepository: https://github.com/huawei-noah/noah-research/tree/master/NLP/EntityCS  \\nPaper: https://aclanthology.org/2022.findings-emnlp.499.pdf  \\nPoint of Contact: Fenia Christopoulou, Chenxi Whitehouse\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nWe use the English Wikipedia and leverage entity information from Wikidata to construct an entity-based Code Switching corpus. \\nTo achieve this, we make use of wikilinks in Wikipedia, i.e. links from one page to‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/huawei-noah/entity_cs."},
  {"name":"text_coordinates_regions","keyword":"french","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/yachay/text_coordinates_regions","creator_name":"Yachay AI","creator_url":"https://huggingface.co/yachay","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Multilingual Geo-Tagged Social Media Posts (by 123 world regions)\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThe \\\"Regions\\\" dataset is a multilingual corpus that encompasses textual data from the 123 most populated regions worldwide, with each region's data organized into separate .json files. This dataset consists of approximately 500,000 text samples, each paired with its geographic coordinates.\\nKey Features:\\n\\nTextual Data: The dataset contains 500,000 text samples.‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/yachay/text_coordinates_regions."},
  {"name":"fquad2_test","keyword":"french","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/manu/fquad2_test","creator_name":"Manuel Faysse","creator_url":"https://huggingface.co/manu","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for \\\"Fquad2_test\\\"\\n\\t\\n\\nThis dataset is released as part of FrenchBench, a benchmarking initiative for French Language Model evaluation.\\nIt can be used for extractive QA, binary classifcation or infiormation retrieving evaluation !\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tCite\\n\\t\\n\\n@misc{faysse2024croissantllm,\\n      title={CroissantLLM: A Truly Bilingual French-English Language Model}, \\n      author={Manuel Faysse and Patrick Fernandes and Nuno M. Guerreiro and Ant√≥nio Loison and Duarte M. Alves and‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/manu/fquad2_test."},
  {"name":"taln-archives_fr_prompt_data_to_text","keyword":"french","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/CATIE-AQ/taln-archives_fr_prompt_data_to_text","creator_name":"CATIE","creator_url":"https://huggingface.co/CATIE-AQ","description":"\\n\\t\\n\\t\\t\\n\\t\\ttaln-archives_fr_prompt_data_to_text\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tSummary\\n\\t\\n\\ntaln-archives_fr_prompt_data_to_text is a subset of the Dataset of French Prompts (DFP).It contains 35,370 rows that can be used for a data-to-text task.The original data (without prompts) comes from the dataset taln-archives.A list of prompts (see below) was then applied in order to build the input and target columns and thus obtain the same format as the xP3 dataset by Muennighoff et al.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tPrompts used‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/CATIE-AQ/taln-archives_fr_prompt_data_to_text."},
  {"name":"taln-archives_fr_prompt_keywords_extraction","keyword":"french","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/CATIE-AQ/taln-archives_fr_prompt_keywords_extraction","creator_name":"CATIE","creator_url":"https://huggingface.co/CATIE-AQ","description":"\\n\\t\\n\\t\\t\\n\\t\\ttaln-archives_fr_prompt_keywords_extraction\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tSummary\\n\\t\\n\\ntaln-archives_fr_prompt_keywords_extraction is a subset of the Dataset of French Prompts (DFP).It contains 24,507 rows that can be used for a keywords_extraction task.The original data (without prompts) comes from the dataset taln-archives.A list of prompts (see below) was then applied in order to build the input and target columns and thus obtain the same format as the xP3 dataset by Muennighoff et al.‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/CATIE-AQ/taln-archives_fr_prompt_keywords_extraction."},
  {"name":"termith-eval_fr_prompt_data_to_text","keyword":"french","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/CATIE-AQ/termith-eval_fr_prompt_data_to_text","creator_name":"CATIE","creator_url":"https://huggingface.co/CATIE-AQ","description":"\\n\\t\\n\\t\\t\\n\\t\\ttermith-eval_fr_prompt_data_to_text\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tSummary\\n\\t\\n\\ntermith-eval_fr_prompt_data_to_text is a subset of the Dataset of French Prompts (DFP).It contains 11,886 rows that can be used for a data-to-text task.The original data (without prompts) comes from the dataset termith-eval.A list of prompts (see below) was then applied in order to build the input and target columns and thus obtain the same format as the xP3 dataset by Muennighoff et al.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tPrompts used‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/CATIE-AQ/termith-eval_fr_prompt_data_to_text."},
  {"name":"termith-eval_fr_prompt_keywords_extraction","keyword":"french","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/CATIE-AQ/termith-eval_fr_prompt_keywords_extraction","creator_name":"CATIE","creator_url":"https://huggingface.co/CATIE-AQ","description":"\\n\\t\\n\\t\\t\\n\\t\\ttermith-eval_fr_prompt_keywords_extraction\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tSummary\\n\\t\\n\\ntermith-eval_fr_prompt_keywords_extraction is a subset of the Dataset of French Prompts (DFP).It contains 8,295 rows that can be used for a keywords_extraction task.The original data (without prompts) comes from the dataset termith-eval.A list of prompts (see below) was then applied in order to build the input and target columns and thus obtain the same format as the xP3 dataset by Muennighoff et al.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tPrompts‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/CATIE-AQ/termith-eval_fr_prompt_keywords_extraction."},
  {"name":"wikinews-fr-100_fr_prompt_data_to_text","keyword":"french","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/CATIE-AQ/wikinews-fr-100_fr_prompt_data_to_text","creator_name":"CATIE","creator_url":"https://huggingface.co/CATIE-AQ","description":"\\n\\t\\n\\t\\t\\n\\t\\twikinews-fr-100_fr_prompt_data_to_text\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tSummary\\n\\t\\n\\nwikinews-fr-100_fr_prompt_data_to_text is a subset of the Dataset of French Prompts (DFP).It contains 3,000 rows that can be used for a data-to-text task.The original data (without prompts) comes from the dataset wikinews-fr-100.A list of prompts (see below) was then applied in order to build the input and target columns and thus obtain the same format as the xP3 dataset by Muennighoff et al.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tPrompts used‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/CATIE-AQ/wikinews-fr-100_fr_prompt_data_to_text."},
  {"name":"wikinews-fr-100_fr_prompt_keywords_extraction","keyword":"french","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/CATIE-AQ/wikinews-fr-100_fr_prompt_keywords_extraction","creator_name":"CATIE","creator_url":"https://huggingface.co/CATIE-AQ","description":"\\n\\t\\n\\t\\t\\n\\t\\twikinews-fr-100_fr_prompt_keywords_extraction\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tSummary\\n\\t\\n\\nwikinews-fr-100_fr_prompt_keywords_extraction is a subset of the Dataset of French Prompts (DFP).It contains 2,100 rows that can be used for a keywords_extraction task.The original data (without prompts) comes from the dataset wikinews-fr-100.A list of prompts (see below) was then applied in order to build the input and target columns and thus obtain the same format as the xP3 dataset by Muennighoff et al.‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/CATIE-AQ/wikinews-fr-100_fr_prompt_keywords_extraction."},
  {"name":"MetricInstruct","keyword":"french","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/TIGER-Lab/MetricInstruct","creator_name":"TIGER-Lab","creator_url":"https://huggingface.co/TIGER-Lab","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tMetricInstruct\\n\\t\\n\\nThe MetricInstrcut dataset consists of 44K quadruple in the form of (instruction, input, system output, error analysis) for 6 text generation tasks and 22 text generation datasets. The dataset is used to fine-tune TIGERScore, a Trained metric that follows Instruction Guidance to perform Explainable, and Reference-free evaluation over a wide spectrum of text generation tasks.\\nProject Page | Paper | Code | Demo | \\nTIGERScore-7B | TIGERScore-13B\\nWe present the‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/TIGER-Lab/MetricInstruct."},
  {"name":"openassistant-guanaco-EOS","keyword":"french","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/Trelis/openassistant-guanaco-EOS","creator_name":"Trelis","creator_url":"https://huggingface.co/Trelis","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tChat Fine-tuning Dataset - Guanaco Style\\n\\t\\n\\nThis dataset allows for fine-tuning chat models using \\\"### Human:\\\" AND \\\"### Assistant\\\" as the beginning and end of sequence tokens.\\nPreparation:\\n\\nThe dataset is cloned from TimDettmers, which itself is a subset of the Open Assistant dataset, which you can find here. This subset of the data only contains the highest-rated paths in the conversation tree, with a total of 9,846 samples.\\nThe dataset was then slightly adjusted to:\\n\\n\\nif a row of‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Trelis/openassistant-guanaco-EOS."},
  {"name":"sharegpt-deduplicated","keyword":"french","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/CaterinaLac/sharegpt-deduplicated","creator_name":"Caterina Lacerra","creator_url":"https://huggingface.co/CaterinaLac","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Dataset Name\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThis dataset is a deduplicated version of sharegpt4. \\nThe deduplication process has two steps:\\n\\nThe literal duplicates (both input and outputs) are removed\\nThe remaining (5749) instances are embedded with the SentenceTransformer library (\\\"paraphrase-multilingual-mpnet-base-v2\\\" model).\\nThen, we compute the cosine similarity among all the possible pairs, and consider paraphrases those‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/CaterinaLac/sharegpt-deduplicated."},
  {"name":"openassistant-llama-style","keyword":"french","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/Trelis/openassistant-llama-style","creator_name":"Trelis","creator_url":"https://huggingface.co/Trelis","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tChat Fine-tuning Dataset - Llama 2 Style\\n\\t\\n\\nThis dataset allows for fine-tuning chat models using [INST] AND [/INST] to wrap user messages.\\nPreparation:\\n\\nThe dataset is cloned from TimDettmers, which itself is a subset of the Open Assistant dataset, which you can find here. This subset of the data only contains the highest-rated paths in the conversation tree, with a total of 9,846 samples.\\nThe dataset was then filtered to:\\n\\n\\nreplace instances of '### Human:' with '[INST]'\\nreplace‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Trelis/openassistant-llama-style."},
  {"name":"oscar_inclure","keyword":"french","license":"Creative Commons Zero v1.0 Universal","language":"en","url":"https://huggingface.co/datasets/PaulLerner/oscar_inclure","creator_name":"Paul Lerner","creator_url":"https://huggingface.co/PaulLerner","description":"Original dataset: https://huggingface.co/datasets/oscar-corpus/OSCAR-2201\\n"},
  {"name":"dataSet_ens_sup_fr-v1","keyword":"french","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/Gael540/dataSet_ens_sup_fr-v1","creator_name":"Ga√´l GUY","creator_url":"https://huggingface.co/Gael540","description":"Gael540/dataSet_ens_sup_fr-v1 dataset hosted on Hugging Face and contributed by the HF Datasets community"},
  {"name":"project_gutenberg","keyword":"french","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/SinclairSchneider/project_gutenberg","creator_name":"Sinclair Schneider","creator_url":"https://huggingface.co/SinclairSchneider","description":"SinclairSchneider/project_gutenberg dataset hosted on Hugging Face and contributed by the HF Datasets community"},
  {"name":"mqnli","keyword":"french","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/SachinPatel248/mqnli","creator_name":"Patel","creator_url":"https://huggingface.co/SachinPatel248","description":"SachinPatel248/mqnli dataset hosted on Hugging Face and contributed by the HF Datasets community"},
  {"name":"MSVAMP","keyword":"french","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/Mathoctopus/MSVAMP","creator_name":"Mathoctopus","creator_url":"https://huggingface.co/Mathoctopus","description":"Mathoctopus/MSVAMP dataset hosted on Hugging Face and contributed by the HF Datasets community"},
  {"name":"vibravox","keyword":"french","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/Cnam-LMSSC/vibravox","creator_name":"Laboratoire de M√©canique des Structures et des Syst√®mes Coupl√©s","creator_url":"https://huggingface.co/Cnam-LMSSC","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for VibraVox\\n\\t\\n\\n\\n  \\n\\n\\n\\nüëÄ While waiting for the TooBigContentError issue to be resolved by the HuggingFace team, you can explore the dataset viewer of vibravox-test\\nwhich has exactly the same architecture.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDATASET SUMMARY\\n\\t\\n\\nThe VibraVox dataset is a general purpose audio dataset of french speech captured with body-conduction transducers.\\nThis dataset can be used for various audio machine learning tasks :\\n\\nAutomatic Speech Recognition (ASR) (Speech-to-Text‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Cnam-LMSSC/vibravox."},
  {"name":"Multi-EuP","keyword":"french","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/unimelb-nlp/Multi-EuP","creator_name":"The University of Melbourne","creator_url":"https://huggingface.co/unimelb-nlp","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tNOTES FOR DOWNLOAD!\\n\\t\\n\\n\\nHighly recommend downloading it via the API:\\n\\ncurl -X GET \\\\\\n     \\\"https://datasets-server.huggingface.co/first-rows?dataset=unimelb-nlp%2FMulti-EuP&config=default&split=full\\\"\\n\\n\\nIf you are using the HuggingFace library, please follow these steps:\\n\\npip install datasets\\n\\nfrom datasets import load_dataset\\n\\ndataset = load_dataset(\\\"unimelb-nlp/Multi-EuP\\\", keep_default_na=False)\\n\\nNote: It's crucial to use keep_default_na=False because some datasets contain 'null'‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/unimelb-nlp/Multi-EuP."},
  {"name":"udhr-lid","keyword":"french","license":"Creative Commons Zero v1.0 Universal","language":"en","url":"https://huggingface.co/datasets/cis-lmu/udhr-lid","creator_name":"CIS, LMU Munich","creator_url":"https://huggingface.co/cis-lmu","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tUDHR-LID\\n\\t\\n\\nWhy UDHR-LID?\\nYou can access UDHR (Universal Declaration of Human Rights) here, but when a verse is missing, they have texts such as \\\"missing\\\" or \\\"?\\\". Also, about 1/3 of the sentences consist only of \\\"articles 1-30\\\" in different languages. We cleaned the entire dataset from XML files and selected only the paragraphs. We cleared any unrelated language texts from the data and also removed the cases that were incorrect.\\nIncorrect? Look at the ckb and kmr files in the UDHR.‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/cis-lmu/udhr-lid."},
  {"name":"seamless-align","keyword":"french","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/jhu-clsp/seamless-align","creator_name":"Center for Language and Speech Processing @ JHU","creator_url":"https://huggingface.co/jhu-clsp","description":"\\n\\t\\n\\t\\t\\n\\t\\tDataset Card for Seamless-Align (WIP). Inspired by https://huggingface.co/datasets/allenai/nllb\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThis dataset was created based on metadata for mined Speech-to-Speech(S2S), Text-to-Speech(TTS) and Speech-to-Text(S2T) released by Meta AI.  The S2S contains data for 35 language pairs. The S2S dataset is ~1000GB compressed.\\n\\n\\t\\n\\t\\t\\n\\t\\tHow to use the data\\n\\t\\n\\nThere are two ways to access the data:\\n\\nVia the Hugging Face Python datasets library\\n\\nScripts coming soon‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/jhu-clsp/seamless-align."},
  {"name":"WEATHub","keyword":"french","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/iamshnoo/WEATHub","creator_name":"Anjishnu Mukherjee","creator_url":"https://huggingface.co/iamshnoo","description":"\\n\\n\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for \\\"WEATHub\\\"\\n\\t\\n\\nThis dataset corresponds to the data described in the paper \\\"Global Voices, Local Biases: Socio-Cultural Prejudices across Languages\\\"\\naccepted to EMNLP 2023.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nWEATHub is a dataset containing 24 languages. It contains words organized into groups of (target1, target2, attribute1, attribute2)\\nto measure the association target1:target2 :: attribute1:attribute2. For example target1 can be insects, target2 can be flowers.‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/iamshnoo/WEATHub."},
  {"name":"simsamu","keyword":"french","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/medkit/simsamu","creator_name":"medkit","creator_url":"https://huggingface.co/medkit","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSimsamu dataset\\n\\t\\n\\nThis repository contains recordings of simulated medical dispatch dialogs in the\\nfrench language, annotated for diarization and transcription. It is published\\nunder the MIT license.\\nThese dialogs were recorded as part of the training of emergency medicine\\ninterns, which consisted in simulating a medical dispatch call where the interns\\ntook turns playing the caller and the regulating doctor. \\nEach situation was decided randomly in advance, blind to who was playing‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/medkit/simsamu."},
  {"name":"openassistant-falcon","keyword":"french","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/Trelis/openassistant-falcon","creator_name":"Trelis","creator_url":"https://huggingface.co/Trelis","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tChat Fine-tuning Dataset - OpenAssistant Falcon\\n\\t\\n\\nThis dataset allows for fine-tuning chat models using '\\\\Human:' AND '\\\\nAssistant:' to wrap user messages.\\nIt still uses <|endoftext|> as EOS and BOS token, as per Falcon.\\nSample \\nPreparation:\\n\\nThe dataset is cloned from TimDettmers, which itself is a subset of the Open Assistant dataset, which you can find here. This subset of the data only contains the highest-rated paths in the conversation tree, with a total of 9,846 samples.‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Trelis/openassistant-falcon."},
  {"name":"Multilingual-Opinion-Target-Extraction","keyword":"french","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/HiTZ/Multilingual-Opinion-Target-Extraction","creator_name":"HiTZ zentroa","creator_url":"https://huggingface.co/HiTZ","description":"This repository contains the English 'SemEval-2014 Task 4: Aspect Based Sentiment Analysis'. translated with DeepL into Spanish, French, Russian, and Turkish. The labels have been manually projected. For more details, read this paper:  Model and Data Transfer for Cross-Lingual Sequence Labelling in Zero-Resource Settings. \\nIntended Usage: Since the datasets are parallel across languages, they are ideal for evaluating annotation projection algorithms, such as T-Projection. \\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLabel‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/HiTZ/Multilingual-Opinion-Target-Extraction."},
  {"name":"eighteenth_century_french_novels","keyword":"french","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/roettger/eighteenth_century_french_novels","creator_name":"roettger","creator_url":"https://huggingface.co/roettger","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tGeneral information\\n\\t\\n\\nThis dataset contains 12 Mio Token of Literary French prose 1751-1800 in plain text format, built within the project 'Mining and Modeling Text' (2019-2023) at Trier University. \\nFor the dataset in XML/TEI see the GitHub repository of the project. \\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tCollection de romans fran√ßais du dix-huiti√®me si√®cle (1751-1800) / Collection of Eighteenth-Century French Novels (1751-1800)\\n\\t\\n\\nThis collection of Eighteenth-Century French Novels contains 200 digital‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/roettger/eighteenth_century_french_novels."},
  {"name":"mapa-eur-lex","keyword":"french","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/dglover1/mapa-eur-lex","creator_name":"D Glover","creator_url":"https://huggingface.co/dglover1","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Multilingual European Datasets for Sensitive Entity Detection in the Legal Domain\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThis dataset is a completed version of the MAPA EUR-LEX dataset, originally converted to Huggingface format by joelniklaus. See the dataset card for more information about MAPA.\\n3 of the (Spanish) EUR-LEX WebAnno TSV files in the source MAPA repository are malformed, so they were omitted from the original conversion, causing under-representation of‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/dglover1/mapa-eur-lex."},
  {"name":"lr-sum","keyword":"french","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/bltlab/lr-sum","creator_name":"Broadening Linguistic Technologies Lab (BLT Lab)","creator_url":"https://huggingface.co/bltlab","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for LR-Sum\\n\\t\\n\\nLR-Sum is a automatic summarization dataset of newswire text with a focus on less resourced languages with a cc-by 4.0 license.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Details\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nLR-Sum is a permissively-licensed dataset created with the goal of enabling further research in automatic summarization for less-resourced languages.\\nLR-Sum contains human-written summaries for 39 languages, many of which are less-resourced. \\nThe data is based on‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/bltlab/lr-sum."},
  {"name":"clustering-hal-s2s","keyword":"french","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/lyon-nlp/clustering-hal-s2s","creator_name":"Lyon NLP","creator_url":"https://huggingface.co/lyon-nlp","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tClustering HAL\\n\\t\\n\\nThis dataset was created by scrapping data from the HAL platform. \\nOver 80,000 articles have been scrapped to keep their id, title and category. \\nIt was originally used for the French version of MTEB, but it can also be used for various clustering or classification tasks, or even evaluate the general knowledge of a model.\\n‚ö†Ô∏è This dataset contains 2 subsets. IT IS STRONGLY ADVISED TO USE THE CLEANED UP mteb_eval SUBSET:\\n\\n\\\"raw\\\" subset : contains the data originally‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/lyon-nlp/clustering-hal-s2s."},
  {"name":"alpaca_ccass_motivations_sommaires_titres","keyword":"french","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/maurya/alpaca_ccass_motivations_sommaires_titres","creator_name":"Amaury Fouret","creator_url":"https://huggingface.co/maurya","description":"\\n\\t\\n\\t\\t\\n\\t\\tTraining dataset for summarizing and titling decisions of the French Court of cassation based on motivations\\n\\t\\n\\nThis alpaca-format dataset is designed to train models for summarizing and titling case law based on the reasons for the decision.\\nCreated with a view to producing metadata for decisions not published in the bulletin, this dataset aims to simplify the development of annotation and categorization tools, and is positioned as a facilitator for jurisprudential processing and‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/maurya/alpaca_ccass_motivations_sommaires_titres."},
  {"name":"nlu-covid","keyword":"french","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/Wikit/nlu-covid","creator_name":"Wikit","creator_url":"https://huggingface.co/Wikit","description":"French benchmark of NLU services for employee support use case during covid-19 pandemic.\\nThese datasets were created by the Wikit team in order to compare the performances of NLU tools on the French language.\\nThe dataset use case is employee support during the covid 19 pandemic. The intents were defined to answer department employees' questions on the evolution of work conditions related to the crisis.\\n\\nThe training_dataset.csv file contains training utterances with associated intent used to‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Wikit/nlu-covid."},
  {"name":"megawika-report-generation","keyword":"french","license":"Creative Commons Attribution Share Alike 4.0 International","language":"en","url":"https://huggingface.co/datasets/hltcoe/megawika-report-generation","creator_name":"JHU Human Language Technology Center of Excellence","creator_url":"https://huggingface.co/hltcoe","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for MegaWika for Report Generation\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nMegaWika is a multi- and crosslingual text dataset containing 30 million Wikipedia passages with their scraped and cleaned web citations. The passages span\\n50 Wikipedias in 50 languages, and the articles in which the passages were originally embedded are included for convenience. Where a Wikipedia passage is in a\\nnon-English language, an automated English translation is provided. \\nThis dataset‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/hltcoe/megawika-report-generation."},
  {"name":"MonadGPT","keyword":"french","license":"Creative Commons Zero v1.0 Universal","language":"en","url":"https://huggingface.co/datasets/Pclanglais/MonadGPT","creator_name":"Pierre-Carl Langlais","creator_url":"https://huggingface.co/Pclanglais","description":"This finetuning dataset has been used to train MonadGPT, a chatGPT-like model for the early modern period. \\nIt contains 10,797 excerpts of texts in English, French and Latin, mostly published in the 17th century, as well as synthetic questions generated by Mistral-Hermes.\\nThe instructions use the chatML format with a unique system prompt (to help with consistency), user questions and assistant answers.\\nAll the excerpts are in the public domain and so are the synthetic instructions (in‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Pclanglais/MonadGPT."},
  {"name":"nnd_fr_26k","keyword":"french","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/SalomonMetre13/nnd_fr_26k","creator_name":"Salomon Metre","creator_url":"https://huggingface.co/SalomonMetre13","description":"This parallel corpus  contains 26240 aligned sentence pairs Nande-French in a 90:10 split for the train and the test sets. It has been mainly used to fine-tune the  t5-base  pretrained model for the development of this translation model \\n"},
  {"name":"ProfessorHeidelTime","keyword":"french","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/hugosousa/ProfessorHeidelTime","creator_name":"Hugo Sousa","creator_url":"https://huggingface.co/hugosousa","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tProfessor HeidelTime\\n\\t\\n\\nPaper    GitHub\\nProfessor HeidelTime is a project to create a multilingual corpus weakly labeled with HeidelTime, a temporal tagger.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tCorpus Details\\n\\t\\n\\nThe weak labeling was performed in six languages. Here are the specifics of the corpus for each language:\\n\\n\\t\\n\\t\\t\\nDataset\\nLanguage\\nDocuments\\nFrom\\nTo\\nTokens\\nTimexs\\n\\n\\n\\t\\t\\nAll the News 2.0\\nEN\\n24,642\\n2016-01-01\\n2020-04-02\\n18,755,616\\n254,803\\n\\n\\nItalian Crime News\\nIT\\n9,619\\n2011-01-01\\n2021-12-31\\n3,296,898\\n58‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/hugosousa/ProfessorHeidelTime."},
  {"name":"frenchNER_3entities","keyword":"french","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/CATIE-AQ/frenchNER_3entities","creator_name":"CATIE","creator_url":"https://huggingface.co/CATIE-AQ","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset information\\n\\t\\n\\nDataset concatenating NER datasets, available in French and open-source, for 3 entities (LOC, PER, ORG).There are a total of 420,264 rows, of which 346,071 are for training, 32,951 for validation and 41,242 for testing.Our methodology is described in a blog post available in English or French.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tUsage\\n\\t\\n\\nfrom datasets import load_dataset\\ndataset = load_dataset(\\\"CATIE-AQ/frenchNER_3entities\\\")\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDetails of rows‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/CATIE-AQ/frenchNER_3entities."},
  {"name":"Lamini-instructions-to-french","keyword":"french","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/Darok/Lamini-instructions-to-french","creator_name":"Erik Cadieux","creator_url":"https://huggingface.co/Darok","description":"Darok/Lamini-instructions-to-french dataset hosted on Hugging Face and contributed by the HF Datasets community"},
  {"name":"Ordalie-FR-STS-benchmark","keyword":"french","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/OrdalieTech/Ordalie-FR-STS-benchmark","creator_name":"Ordalie Technologies","creator_url":"https://huggingface.co/OrdalieTech","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tOrdalie - French STS Benchmark\\n\\t\\n\\n\\n30k sentence pairs\\nScore either 0 or 1\\n\\n"},
  {"name":"Vibravox_dummy","keyword":"french","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/zinc75/Vibravox_dummy","creator_name":"√âric Bavu","creator_url":"https://huggingface.co/zinc75","description":"zinc75/Vibravox_dummy dataset hosted on Hugging Face and contributed by the HF Datasets community"},
  {"name":"ARBRES-Kenstur","keyword":"french","license":"Creative Commons Attribution Share Alike 4.0 International","language":"en","url":"https://huggingface.co/datasets/lgrobol/ARBRES-Kenstur","creator_name":"Lo√Øc Grobol","creator_url":"https://huggingface.co/lgrobol","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tARBRES-Kenstur\\n\\t\\n\\nARBRES-Kenstur is a Breton-French parallel corpora generated by extracting the French translations of Breton sentences from the interlinear glosses of the ARBRES wikigrammar.\\nThe extraction is still under developpment in the Autogramm project of the French National Research Agency. More information can be found on their Github repository.\\n"},
  {"name":"Pontoon-Translations","keyword":"french","license":"Mozilla Public License 2.0","language":"en","url":"https://huggingface.co/datasets/ayymen/Pontoon-Translations","creator_name":"Mohamed Aymane Farhi","creator_url":"https://huggingface.co/ayymen","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Pontoon Translations\\n\\t\\n\\n\\n\\nThis is a dataset containing strings from various Mozilla projects on Mozilla's Pontoon localization platform and their translations into more than 200 languages.\\nSource strings are in English.\\nTo avoid rows with values like \\\"None\\\" and \\\"N/A\\\" being interpreted as missing values, pass the keep_default_na parameter like this:\\nfrom datasets import load_dataset\\n\\ndataset = load_dataset(\\\"ayymen/Pontoon-Translations\\\", keep_default_na=False)‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ayymen/Pontoon-Translations."},
  {"name":"mteb-fr-reranking-alloprof-s2p","keyword":"french","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/lyon-nlp/mteb-fr-reranking-alloprof-s2p","creator_name":"Lyon NLP","creator_url":"https://huggingface.co/lyon-nlp","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDescription\\n\\t\\n\\nThis dataset was built upon Alloprof Q&A dataset, negative samples were created using BM25. Please refer to our paper for more details. \\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tCitation\\n\\t\\n\\nIf you use this dataset in your work, please consider citing:\\n@misc{ciancone2024extending,\\n      title={Extending the Massive Text Embedding Benchmark to French}, \\n      author={Mathieu Ciancone and Imene Kerboua and Marion Schaeffer and Wissam Siblini},\\n      year={2024},\\n      eprint={2405.20468}‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/lyon-nlp/mteb-fr-reranking-alloprof-s2p."},
  {"name":"LoiLibre","keyword":"french","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/Forbu14/LoiLibre","creator_name":"Adrien Bufort","creator_url":"https://huggingface.co/Forbu14","description":"\\nIl s'agit des pdfs prepars√©s qui peuvent √™tre ensuite utilis√© dans des appli autour du NLP / LLMs dans un soucis de collaborations.\\nLes diff√©rents codes ont √©t√© extrait en format XML ici : https://codes.droit.org/\\nLes formats XML permet de faire un meilleurs preprocessing des codes de loi.\\nLa structure des donn√©es :\\n\\ndans raw/ on retrouve les diff√©rents codes en format xml.\\n\\ndans notebooks_preprocess/ on retrouve les diff√©rents notebooks qui ont permis de constitu√© le dataset final.\\n\\n\\n"},
  {"name":"summarization-summeval-fr-p2p","keyword":"french","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/lyon-nlp/summarization-summeval-fr-p2p","creator_name":"Lyon NLP","creator_url":"https://huggingface.co/lyon-nlp","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSummEval FR\\n\\t\\n\\nThis dataset is a French translation of the original work SummEval. \\nThe translation was made using DeepL from English to French. \\nWe used a LLM to rate the quality of translations, we verified random samples rated above 9/10 manually and corrected all those rated under 9/10. We also checked the correlation of ROUGE and BLEU scores between SummEval and SummEvalFr.  For more details about the quality checks of this dataset, please refer to our paper.\\nWe use this‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/lyon-nlp/summarization-summeval-fr-p2p."},
  {"name":"mt-bench-french","keyword":"french","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/bofenghuang/mt-bench-french","creator_name":"bofeng huang","creator_url":"https://huggingface.co/bofenghuang","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tMT-Bench-French\\n\\t\\n\\nThis is a French version of MT-Bench, created to evaluate the multi-turn conversation and instruction-following capabilities of LLMs. Similar to its original version, MT-Bench-French comprises 80 high-quality, multi-turn questions spanning eight main categories.\\nAll questions have undergone translation into French and thorough human review to guarantee the use of suitable and authentic wording, meaningful content for assessing LLMs' capabilities in the French‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/bofenghuang/mt-bench-french."},
  {"name":"lpf","keyword":"french","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/louisbrulenaudet/lpf","creator_name":"Louis Brul√© Naudet","creator_url":"https://huggingface.co/louisbrulenaudet","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLivre des proc√©dures fiscales, non-instruct (11-12-2023)\\n\\t\\n\\nThis project focuses on fine-tuning pre-trained language models to create efficient and accurate models for tax practice. \\nFine-tuning is the process of adapting a pre-trained model to perform specific tasks or cater to particular domains. It involves adjusting the model's parameters through a further round of training on task-specific or domain-specific data. While conventional fine-tuning strategies involve supervised‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/louisbrulenaudet/lpf."},
  {"name":"cgi","keyword":"french","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/louisbrulenaudet/cgi","creator_name":"Louis Brul√© Naudet","creator_url":"https://huggingface.co/louisbrulenaudet","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tCode G√©n√©ral des Imp√¥ts, non-instruct (11-12-2023)\\n\\t\\n\\nThis project focuses on fine-tuning pre-trained language models to create efficient and accurate models for tax practice. \\nFine-tuning is the process of adapting a pre-trained model to perform specific tasks or cater to particular domains. It involves adjusting the model's parameters through a further round of training on task-specific or domain-specific data. While conventional fine-tuning strategies involve supervised learning‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/louisbrulenaudet/cgi."},
  {"name":"code-douanes","keyword":"french","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/louisbrulenaudet/code-douanes","creator_name":"Louis Brul√© Naudet","creator_url":"https://huggingface.co/louisbrulenaudet","description":"\\n\\t\\n\\t\\t\\n\\t\\tCode des douanes, non-instruct (2025-03-10)\\n\\t\\n\\nThe objective of this project is to provide researchers, professionals and law students with simplified, up-to-date access to all French legal texts, enriched with a wealth of data to facilitate their integration into Community and European projects.\\nNormally, the data is refreshed daily on all legal codes, and aims to simplify the production of training sets and labeling pipelines for the development of free, open-source language models‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/louisbrulenaudet/code-douanes."},
  {"name":"code-consommation","keyword":"french","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/louisbrulenaudet/code-consommation","creator_name":"Louis Brul√© Naudet","creator_url":"https://huggingface.co/louisbrulenaudet","description":"\\n\\t\\n\\t\\t\\n\\t\\tCode de la consommation, non-instruct (2025-03-10)\\n\\t\\n\\nThe objective of this project is to provide researchers, professionals and law students with simplified, up-to-date access to all French legal texts, enriched with a wealth of data to facilitate their integration into Community and European projects.\\nNormally, the data is refreshed daily on all legal codes, and aims to simplify the production of training sets and labeling pipelines for the development of free, open-source language‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/louisbrulenaudet/code-consommation."},
  {"name":"code-penal","keyword":"french","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/louisbrulenaudet/code-penal","creator_name":"Louis Brul√© Naudet","creator_url":"https://huggingface.co/louisbrulenaudet","description":"\\n\\t\\n\\t\\t\\n\\t\\tCode p√©nal, non-instruct (2025-03-10)\\n\\t\\n\\nThe objective of this project is to provide researchers, professionals and law students with simplified, up-to-date access to all French legal texts, enriched with a wealth of data to facilitate their integration into Community and European projects.\\nNormally, the data is refreshed daily on all legal codes, and aims to simplify the production of training sets and labeling pipelines for the development of free, open-source language models based‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/louisbrulenaudet/code-penal."},
  {"name":"code-sport","keyword":"french","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/louisbrulenaudet/code-sport","creator_name":"Louis Brul√© Naudet","creator_url":"https://huggingface.co/louisbrulenaudet","description":"\\n\\t\\n\\t\\t\\n\\t\\tCode du sport, non-instruct (2025-03-10)\\n\\t\\n\\nThe objective of this project is to provide researchers, professionals and law students with simplified, up-to-date access to all French legal texts, enriched with a wealth of data to facilitate their integration into Community and European projects.\\nNormally, the data is refreshed daily on all legal codes, and aims to simplify the production of training sets and labeling pipelines for the development of free, open-source language models‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/louisbrulenaudet/code-sport."},
  {"name":"code-civil","keyword":"french","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/louisbrulenaudet/code-civil","creator_name":"Louis Brul√© Naudet","creator_url":"https://huggingface.co/louisbrulenaudet","description":"\\n\\t\\n\\t\\t\\n\\t\\tCode civil, non-instruct (2025-03-10)\\n\\t\\n\\nThe objective of this project is to provide researchers, professionals and law students with simplified, up-to-date access to all French legal texts, enriched with a wealth of data to facilitate their integration into Community and European projects.\\nNormally, the data is refreshed daily on all legal codes, and aims to simplify the production of training sets and labeling pipelines for the development of free, open-source language models based‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/louisbrulenaudet/code-civil."},
  {"name":"code-commerce","keyword":"french","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/louisbrulenaudet/code-commerce","creator_name":"Louis Brul√© Naudet","creator_url":"https://huggingface.co/louisbrulenaudet","description":"\\n\\t\\n\\t\\t\\n\\t\\tCode de commerce, non-instruct (2025-03-10)\\n\\t\\n\\nThe objective of this project is to provide researchers, professionals and law students with simplified, up-to-date access to all French legal texts, enriched with a wealth of data to facilitate their integration into Community and European projects.\\nNormally, the data is refreshed daily on all legal codes, and aims to simplify the production of training sets and labeling pipelines for the development of free, open-source language models‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/louisbrulenaudet/code-commerce."},
  {"name":"code-sante-publique","keyword":"french","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/louisbrulenaudet/code-sante-publique","creator_name":"Louis Brul√© Naudet","creator_url":"https://huggingface.co/louisbrulenaudet","description":"\\n\\t\\n\\t\\t\\n\\t\\tCode de la sant√© publique, non-instruct (2025-03-10)\\n\\t\\n\\nThe objective of this project is to provide researchers, professionals and law students with simplified, up-to-date access to all French legal texts, enriched with a wealth of data to facilitate their integration into Community and European projects.\\nNormally, the data is refreshed daily on all legal codes, and aims to simplify the production of training sets and labeling pipelines for the development of free, open-source language‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/louisbrulenaudet/code-sante-publique."},
  {"name":"code-environnement","keyword":"french","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/louisbrulenaudet/code-environnement","creator_name":"Louis Brul√© Naudet","creator_url":"https://huggingface.co/louisbrulenaudet","description":"\\n\\t\\n\\t\\t\\n\\t\\tCode de l'environnement, non-instruct (2025-03-10)\\n\\t\\n\\nThe objective of this project is to provide researchers, professionals and law students with simplified, up-to-date access to all French legal texts, enriched with a wealth of data to facilitate their integration into Community and European projects.\\nNormally, the data is refreshed daily on all legal codes, and aims to simplify the production of training sets and labeling pipelines for the development of free, open-source language‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/louisbrulenaudet/code-environnement."},
  {"name":"dac6-instruct","keyword":"french","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/louisbrulenaudet/dac6-instruct","creator_name":"Louis Brul√© Naudet","creator_url":"https://huggingface.co/louisbrulenaudet","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDAC6 instruct (11-12-2023)\\n\\t\\n\\n‚ÄúDAC 6‚Äù refers to European Council Directive (EU) 2018/822 of May 25, 2018 relating to the automatic and mandatory exchange of information on cross-border arrangements requiring declaration. It aims to strengthen cooperation between tax administrations in EU countries on potentially aggressive tax planning arrangements.\\nThis project focuses on fine-tuning pre-trained language models to create efficient and accurate models for tax practice. \\nFine-tuning‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/louisbrulenaudet/dac6-instruct."},
  {"name":"code-procedure-civile","keyword":"french","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/louisbrulenaudet/code-procedure-civile","creator_name":"Louis Brul√© Naudet","creator_url":"https://huggingface.co/louisbrulenaudet","description":"\\n\\t\\n\\t\\t\\n\\t\\tCode de proc√©dure civile, non-instruct (2025-03-10)\\n\\t\\n\\nThe objective of this project is to provide researchers, professionals and law students with simplified, up-to-date access to all French legal texts, enriched with a wealth of data to facilitate their integration into Community and European projects.\\nNormally, the data is refreshed daily on all legal codes, and aims to simplify the production of training sets and labeling pipelines for the development of free, open-source language‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/louisbrulenaudet/code-procedure-civile."},
  {"name":"code-monetaire-financier","keyword":"french","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/louisbrulenaudet/code-monetaire-financier","creator_name":"Louis Brul√© Naudet","creator_url":"https://huggingface.co/louisbrulenaudet","description":"\\n\\t\\n\\t\\t\\n\\t\\tCode mon√©taire et financier, non-instruct (2025-03-10)\\n\\t\\n\\nThe objective of this project is to provide researchers, professionals and law students with simplified, up-to-date access to all French legal texts, enriched with a wealth of data to facilitate their integration into Community and European projects.\\nNormally, the data is refreshed daily on all legal codes, and aims to simplify the production of training sets and labeling pipelines for the development of free, open-source‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/louisbrulenaudet/code-monetaire-financier."},
  {"name":"code-assurances","keyword":"french","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/louisbrulenaudet/code-assurances","creator_name":"Louis Brul√© Naudet","creator_url":"https://huggingface.co/louisbrulenaudet","description":"\\n\\t\\n\\t\\t\\n\\t\\tCode des assurances, non-instruct (2025-03-10)\\n\\t\\n\\nThe objective of this project is to provide researchers, professionals and law students with simplified, up-to-date access to all French legal texts, enriched with a wealth of data to facilitate their integration into Community and European projects.\\nNormally, the data is refreshed daily on all legal codes, and aims to simplify the production of training sets and labeling pipelines for the development of free, open-source language‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/louisbrulenaudet/code-assurances."},
  {"name":"code-artisanat","keyword":"french","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/louisbrulenaudet/code-artisanat","creator_name":"Louis Brul√© Naudet","creator_url":"https://huggingface.co/louisbrulenaudet","description":"\\n\\t\\n\\t\\t\\n\\t\\tCode de l'artisanat, non-instruct (2025-03-10)\\n\\t\\n\\nThe objective of this project is to provide researchers, professionals and law students with simplified, up-to-date access to all French legal texts, enriched with a wealth of data to facilitate their integration into Community and European projects.\\nNormally, the data is refreshed daily on all legal codes, and aims to simplify the production of training sets and labeling pipelines for the development of free, open-source language‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/louisbrulenaudet/code-artisanat."},
  {"name":"code-commande-publique","keyword":"french","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/louisbrulenaudet/code-commande-publique","creator_name":"Louis Brul√© Naudet","creator_url":"https://huggingface.co/louisbrulenaudet","description":"\\n\\t\\n\\t\\t\\n\\t\\tCode de la commande publique, non-instruct (2025-03-10)\\n\\t\\n\\nThe objective of this project is to provide researchers, professionals and law students with simplified, up-to-date access to all French legal texts, enriched with a wealth of data to facilitate their integration into Community and European projects.\\nNormally, the data is refreshed daily on all legal codes, and aims to simplify the production of training sets and labeling pipelines for the development of free, open-source‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/louisbrulenaudet/code-commande-publique."},
  {"name":"code-propriete-intellectuelle","keyword":"french","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/louisbrulenaudet/code-propriete-intellectuelle","creator_name":"Louis Brul√© Naudet","creator_url":"https://huggingface.co/louisbrulenaudet","description":"\\n\\t\\n\\t\\t\\n\\t\\tCode de la propri√©t√© intellectuelle, non-instruct (2025-03-10)\\n\\t\\n\\nThe objective of this project is to provide researchers, professionals and law students with simplified, up-to-date access to all French legal texts, enriched with a wealth of data to facilitate their integration into Community and European projects.\\nNormally, the data is refreshed daily on all legal codes, and aims to simplify the production of training sets and labeling pipelines for the development of free‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/louisbrulenaudet/code-propriete-intellectuelle."},
  {"name":"code-procedures-civiles-execution","keyword":"french","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/louisbrulenaudet/code-procedures-civiles-execution","creator_name":"Louis Brul√© Naudet","creator_url":"https://huggingface.co/louisbrulenaudet","description":"\\n\\t\\n\\t\\t\\n\\t\\tCode des proc√©dures civiles d'ex√©cution, non-instruct (2025-03-10)\\n\\t\\n\\nThe objective of this project is to provide researchers, professionals and law students with simplified, up-to-date access to all French legal texts, enriched with a wealth of data to facilitate their integration into Community and European projects.\\nNormally, the data is refreshed daily on all legal codes, and aims to simplify the production of training sets and labeling pipelines for the development of free‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/louisbrulenaudet/code-procedures-civiles-execution."},
  {"name":"code-route","keyword":"french","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/louisbrulenaudet/code-route","creator_name":"Louis Brul√© Naudet","creator_url":"https://huggingface.co/louisbrulenaudet","description":"\\n\\t\\n\\t\\t\\n\\t\\tCode de la route, non-instruct (2025-03-10)\\n\\t\\n\\nThe objective of this project is to provide researchers, professionals and law students with simplified, up-to-date access to all French legal texts, enriched with a wealth of data to facilitate their integration into Community and European projects.\\nNormally, the data is refreshed daily on all legal codes, and aims to simplify the production of training sets and labeling pipelines for the development of free, open-source language models‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/louisbrulenaudet/code-route."},
  {"name":"code-education","keyword":"french","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/louisbrulenaudet/code-education","creator_name":"Louis Brul√© Naudet","creator_url":"https://huggingface.co/louisbrulenaudet","description":"\\n\\t\\n\\t\\t\\n\\t\\tCode de l'√©ducation, non-instruct (2025-03-10)\\n\\t\\n\\nThe objective of this project is to provide researchers, professionals and law students with simplified, up-to-date access to all French legal texts, enriched with a wealth of data to facilitate their integration into Community and European projects.\\nNormally, the data is refreshed daily on all legal codes, and aims to simplify the production of training sets and labeling pipelines for the development of free, open-source language‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/louisbrulenaudet/code-education."},
  {"name":"code-construction-habitation","keyword":"french","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/louisbrulenaudet/code-construction-habitation","creator_name":"Louis Brul√© Naudet","creator_url":"https://huggingface.co/louisbrulenaudet","description":"\\n\\t\\n\\t\\t\\n\\t\\tCode de la construction et de l'habitation, non-instruct (2025-03-10)\\n\\t\\n\\nThe objective of this project is to provide researchers, professionals and law students with simplified, up-to-date access to all French legal texts, enriched with a wealth of data to facilitate their integration into Community and European projects.\\nNormally, the data is refreshed daily on all legal codes, and aims to simplify the production of training sets and labeling pipelines for the development of free‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/louisbrulenaudet/code-construction-habitation."},
  {"name":"code-mutualite","keyword":"french","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/louisbrulenaudet/code-mutualite","creator_name":"Louis Brul√© Naudet","creator_url":"https://huggingface.co/louisbrulenaudet","description":"\\n\\t\\n\\t\\t\\n\\t\\tCode de la mutualit√©, non-instruct (2025-03-10)\\n\\t\\n\\nThe objective of this project is to provide researchers, professionals and law students with simplified, up-to-date access to all French legal texts, enriched with a wealth of data to facilitate their integration into Community and European projects.\\nNormally, the data is refreshed daily on all legal codes, and aims to simplify the production of training sets and labeling pipelines for the development of free, open-source language‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/louisbrulenaudet/code-mutualite."},
  {"name":"code-transports","keyword":"french","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/louisbrulenaudet/code-transports","creator_name":"Louis Brul√© Naudet","creator_url":"https://huggingface.co/louisbrulenaudet","description":"\\n\\t\\n\\t\\t\\n\\t\\tCode des transports, non-instruct (2025-03-10)\\n\\t\\n\\nThe objective of this project is to provide researchers, professionals and law students with simplified, up-to-date access to all French legal texts, enriched with a wealth of data to facilitate their integration into Community and European projects.\\nNormally, the data is refreshed daily on all legal codes, and aims to simplify the production of training sets and labeling pipelines for the development of free, open-source language‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/louisbrulenaudet/code-transports."},
  {"name":"code-urbanisme","keyword":"french","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/louisbrulenaudet/code-urbanisme","creator_name":"Louis Brul√© Naudet","creator_url":"https://huggingface.co/louisbrulenaudet","description":"\\n\\t\\n\\t\\t\\n\\t\\tCode de l'urbanisme, non-instruct (2025-03-10)\\n\\t\\n\\nThe objective of this project is to provide researchers, professionals and law students with simplified, up-to-date access to all French legal texts, enriched with a wealth of data to facilitate their integration into Community and European projects.\\nNormally, the data is refreshed daily on all legal codes, and aims to simplify the production of training sets and labeling pipelines for the development of free, open-source language‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/louisbrulenaudet/code-urbanisme."},
  {"name":"code-general-fonction-publique","keyword":"french","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/louisbrulenaudet/code-general-fonction-publique","creator_name":"Louis Brul√© Naudet","creator_url":"https://huggingface.co/louisbrulenaudet","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tCode g√©n√©ral de la fonction publique, non-instruct (11-12-2023)\\n\\t\\n\\nThis project focuses on fine-tuning pre-trained language models to create efficient and accurate models for legal practice. \\nFine-tuning is the process of adapting a pre-trained model to perform specific tasks or cater to particular domains. It involves adjusting the model's parameters through a further round of training on task-specific or domain-specific data. While conventional fine-tuning strategies involve‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/louisbrulenaudet/code-general-fonction-publique."},
  {"name":"code-forestier","keyword":"french","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/louisbrulenaudet/code-forestier","creator_name":"Louis Brul√© Naudet","creator_url":"https://huggingface.co/louisbrulenaudet","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tCode forestier, non-instruct (11-12-2023)\\n\\t\\n\\nThis project focuses on fine-tuning pre-trained language models to create efficient and accurate models for legal practice. \\nFine-tuning is the process of adapting a pre-trained model to perform specific tasks or cater to particular domains. It involves adjusting the model's parameters through a further round of training on task-specific or domain-specific data. While conventional fine-tuning strategies involve supervised learning with‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/louisbrulenaudet/code-forestier."},
  {"name":"code-justice-administrative","keyword":"french","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/louisbrulenaudet/code-justice-administrative","creator_name":"Louis Brul√© Naudet","creator_url":"https://huggingface.co/louisbrulenaudet","description":"\\n\\t\\n\\t\\t\\n\\t\\tCode de justice administrative, non-instruct (2025-03-10)\\n\\t\\n\\nThe objective of this project is to provide researchers, professionals and law students with simplified, up-to-date access to all French legal texts, enriched with a wealth of data to facilitate their integration into Community and European projects.\\nNormally, the data is refreshed daily on all legal codes, and aims to simplify the production of training sets and labeling pipelines for the development of free, open-source‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/louisbrulenaudet/code-justice-administrative."},
  {"name":"code-postes-communications-electroniques","keyword":"french","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/louisbrulenaudet/code-postes-communications-electroniques","creator_name":"Louis Brul√© Naudet","creator_url":"https://huggingface.co/louisbrulenaudet","description":"\\n\\t\\n\\t\\t\\n\\t\\tCode des postes et des communications √©lectroniques, non-instruct (2025-03-10)\\n\\t\\n\\nThe objective of this project is to provide researchers, professionals and law students with simplified, up-to-date access to all French legal texts, enriched with a wealth of data to facilitate their integration into Community and European projects.\\nNormally, the data is refreshed daily on all legal codes, and aims to simplify the production of training sets and labeling pipelines for the development of‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/louisbrulenaudet/code-postes-communications-electroniques."},
  {"name":"code-relations-public-administration","keyword":"french","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/louisbrulenaudet/code-relations-public-administration","creator_name":"Louis Brul√© Naudet","creator_url":"https://huggingface.co/louisbrulenaudet","description":"\\n\\t\\n\\t\\t\\n\\t\\tCode des relations entre le public et l'administration, non-instruct (2025-03-10)\\n\\t\\n\\nThe objective of this project is to provide researchers, professionals and law students with simplified, up-to-date access to all French legal texts, enriched with a wealth of data to facilitate their integration into Community and European projects.\\nNormally, the data is refreshed daily on all legal codes, and aims to simplify the production of training sets and labeling pipelines for the development‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/louisbrulenaudet/code-relations-public-administration."},
  {"name":"code-rural-peche-maritime","keyword":"french","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/louisbrulenaudet/code-rural-peche-maritime","creator_name":"Louis Brul√© Naudet","creator_url":"https://huggingface.co/louisbrulenaudet","description":"\\n\\t\\n\\t\\t\\n\\t\\tCode rural et de la p√™che maritime, non-instruct (2025-03-10)\\n\\t\\n\\nThe objective of this project is to provide researchers, professionals and law students with simplified, up-to-date access to all French legal texts, enriched with a wealth of data to facilitate their integration into Community and European projects.\\nNormally, the data is refreshed daily on all legal codes, and aims to simplify the production of training sets and labeling pipelines for the development of free, open-source‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/louisbrulenaudet/code-rural-peche-maritime."},
  {"name":"code-securite-interieure","keyword":"french","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/louisbrulenaudet/code-securite-interieure","creator_name":"Louis Brul√© Naudet","creator_url":"https://huggingface.co/louisbrulenaudet","description":"\\n\\t\\n\\t\\t\\n\\t\\tCode de la s√©curit√© int√©rieure, non-instruct (2025-03-10)\\n\\t\\n\\nThe objective of this project is to provide researchers, professionals and law students with simplified, up-to-date access to all French legal texts, enriched with a wealth of data to facilitate their integration into Community and European projects.\\nNormally, the data is refreshed daily on all legal codes, and aims to simplify the production of training sets and labeling pipelines for the development of free, open-source‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/louisbrulenaudet/code-securite-interieure."},
  {"name":"mswc_fscil_subset","keyword":"french","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/NeuroBench/mswc_fscil_subset","creator_name":"NeuroBench","creator_url":"https://huggingface.co/NeuroBench","description":"This is a subset of the Multilingual Spoken Word Corpus dataset, which is built specifically for the Few-shot Class-incremental Learning (FSCIL) task. \\nA total of 15 languages are chosen, split into 5 base languages (English, German, Catalan, French, Kinyarwanda) and 10 incrementally learned languages (Persian, Spanish, Russian, Welsh, Italian, Basque, Polish, Esparanto, Portuguese, Dutch).\\nThe FSCIL task entails first training a model using abundant training data on words from the 5 base‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/NeuroBench/mswc_fscil_subset."},
  {"name":"bofip","keyword":"french","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/louisbrulenaudet/bofip","creator_name":"Louis Brul√© Naudet","creator_url":"https://huggingface.co/louisbrulenaudet","description":"\\n\\t\\n\\t\\t\\n\\t\\tBulletin officiel des finances publiques - imp√¥ts, non-instruct (11-12-2023)\\n\\t\\n\\nThis project focuses on fine-tuning pre-trained language models to create efficient and accurate models for legal practice. \\nFine-tuning is the process of adapting a pre-trained model to perform specific tasks or cater to particular domains. It involves adjusting the model's parameters through a further round of training on task-specific or domain-specific data. While conventional fine-tuning strategies‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/louisbrulenaudet/bofip."},
  {"name":"ntx_llm_instructions","keyword":"french","license":"Creative Commons Attribution Share Alike 4.0 International","language":"en","url":"https://huggingface.co/datasets/tellarin-ai/ntx_llm_instructions","creator_name":"Tellarin.ai","creator_url":"https://huggingface.co/tellarin-ai","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for NTX v1 in the Aya format\\n\\t\\n\\nThis dataset is a format conversion from its original v1 format into the Aya instruction format and it's released here under the CC-BY-SA 4.0 license and conditions.\\nIt contains data in multiple languages and this version is intended for multi-lingual LLM construction/tuning.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tCitation\\n\\t\\n\\nIf you utilize this dataset version, feel free to cite/footnote this huggingface dataset repo, but please also cite the original dataset‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/tellarin-ai/ntx_llm_instructions."},
  {"name":"ntx_llm_inst_french","keyword":"french","license":"Creative Commons Attribution Share Alike 4.0 International","language":"en","url":"https://huggingface.co/datasets/tellarin-ai/ntx_llm_inst_french","creator_name":"Tellarin.ai","creator_url":"https://huggingface.co/tellarin-ai","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for NTX v1 in the Aya format - French subset\\n\\t\\n\\nThis dataset is a format conversion for the French data from the original NTX into the Aya instruction format and it's released here under the CC-BY-SA 4.0 license.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Details\\n\\t\\n\\nFor the original NTX dataset, the conversion to the Aya instructions format, or more details, please refer to the full dataset in instruction form (https://huggingface.co/datasets/tellarin-ai/ntx_llm_instructions) or to the paper‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/tellarin-ai/ntx_llm_inst_french."},
  {"name":"ml-kge","keyword":"french","license":"Creative Commons Attribution Share Alike 4.0 International","language":"en","url":"https://huggingface.co/datasets/davanstrien/ml-kge","creator_name":"Daniel van Strien","creator_url":"https://huggingface.co/davanstrien","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tMKGE: Multilingual Knowledge Graph Enhancement\\n\\t\\n\\nnote this dataset card was copied from this GitHub Repository\\nTask Description |\\nWikiKGE-10 |\\nEvaluation |\\nPaper |\\nCitation |\\nLicense\\nRecent work in Natural Language Processing and Computer Vision has been leveraging textual information -- e.g., entity names and descriptions -- available in knowledge graphs to ground neural models to high-quality structured data.\\nHowever, when it comes to non-English languages, both quantity and‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/davanstrien/ml-kge."},
  {"name":"Tunisian_reddit","keyword":"french","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/Lime1/Tunisian_reddit","creator_name":"Aymen Hmani","creator_url":"https://huggingface.co/Lime1","description":"\\n\\t\\n\\t\\t\\n\\t\\tr/Tunisia Data set\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThis repository contains two datasets:\\n\\noutput_comments.csv: This file contains the comments data. Each row represents a comment, with various attributes such as the comment ID, the post it belongs to, the user who made the comment, and the comment text. (sorted by score) id,url,score,body,date\\n\\noutput_posts.csv: This file contains the posts data. Each row represents a post, with various attributes such as the post ID, the user who‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Lime1/Tunisian_reddit."},
  {"name":"cszs_fr_en","keyword":"french","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/ky552/cszs_fr_en","creator_name":"speech552_ky","creator_url":"https://huggingface.co/ky552","description":"This dataset contains the French-English track of the benchmark from ICASSP 2024: Zero Resource Code-Switched Speech Benchmark Using Speech Utterance Pairs for Multiple Spoken Languages.Though the benchmark is originally designed to assess the semantic and syntactic abilities of the speech foundation models, you can also use this dataset for code-switching ASR.\\nIf you find this dataset helpful, please consider to cite the following paper:\\n@INPROCEEDINGS{10446737,\\n  author={Huang, Kuan-Po and‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ky552/cszs_fr_en."},
  {"name":"Hansard","keyword":"french","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/raeidsaqur/Hansard","creator_name":"Raeid Saqur","creator_url":"https://huggingface.co/raeidsaqur","description":"\\n  \\n   Pedagogical Machine Translation (Dialect) dataset: the filtered Canadian Hansard Dataset. \\n\\nThe Canadian [Hansard](https://www.ourcommons.ca/documentviewer/en/35-2/house/hansard-index) is an archive of parliamentary sessions in the two official languages in Canada - English and Franch. \\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tüìã Table of Contents\\n\\t\\n\\n\\nüß© Hansard Dataset\\nüìã Table of Contents\\nüìñ Usage\\nDownloading the dataset\\nDataset structure\\nLoading the dataset\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLoading the dataset\\n\\t\\n\\nThe three‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/raeidsaqur/Hansard."},
  {"name":"prompt_injections","keyword":"french","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/yanismiraoui/prompt_injections","creator_name":"Yanis Miraoui","creator_url":"https://huggingface.co/yanismiraoui","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Prompt Injections by  Yanis Miraoui  üëã\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThis dataset of prompt injections enriches Large Language Models (LLMs) by providing task-specific examples and prompts, helping improve LLMs' performance and control their behavior.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThis dataset contains over 1000 rows of prompt injections in multiple languages. It contains examples of prompt injections using different techniques such as: prompt leaking‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/yanismiraoui/prompt_injections."},
  {"name":"WikidataLabels","keyword":"french","license":"Creative Commons Zero v1.0 Universal","language":"en","url":"https://huggingface.co/datasets/rayliuca/WikidataLabels","creator_name":"Ray Liu","creator_url":"https://huggingface.co/rayliuca","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tWikidata Labels\\n\\t\\n\\nLarge parallel corpus for machine translation\\n\\nEntity label data extracted from Wikidata (2022-01-03), filtered for item entities only  \\nOnly download the languages you need with datasets>=2.14.0\\nSimilar dataset: https://huggingface.co/datasets/wmt/wikititles (18 Wikipedia titles pairs instead of all Wikidata entities)\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Details\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Sources\\n\\t\\n\\n\\nWikidata JSON dump (wikidata-20220103-all.json.gz)‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/rayliuca/WikidataLabels."},
  {"name":"mos_fr_dataset","keyword":"french","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/louisbertson/mos_fr_dataset","creator_name":"Louis Bertson","creator_url":"https://huggingface.co/louisbertson","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Dataset Name\\n\\t\\n\\n\\n\\nThis dataset card aims to be a base template for new datasets. It has been generated using this raw template.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Details\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\n\\n\\n\\n\\n\\nCurated by: [More Information Needed]\\nFunded by [optional]: [More Information Needed]\\nShared by [optional]: [More Information Needed]\\nLanguage(s) (NLP): [More Information Needed]\\nLicense: [More Information Needed]\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Sources [optional]‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/louisbertson/mos_fr_dataset."},
  {"name":"oasst2_top1_chat_format","keyword":"french","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/blancsw/oasst2_top1_chat_format","creator_name":"Blanc Swan","creator_url":"https://huggingface.co/blancsw","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tOpenAssistant TOP-1 Conversation Threads in huggingface chat format\\n\\t\\n\\nExport of oasst2 only top 1 threads in huggingface chat format\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tScript\\n\\t\\n\\nThe convert script can be find here\\n"},
  {"name":"frenchNER_4entities","keyword":"french","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/CATIE-AQ/frenchNER_4entities","creator_name":"CATIE","creator_url":"https://huggingface.co/CATIE-AQ","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset information\\n\\t\\n\\nDataset concatenating NER datasets, available in French and open-source, for 4 entities (LOC, PER, ORG, MISC).There are a total of 384,773 rows, of which 328,757 are for training, 24,131 for validation and 31,885 for testing.Our methodology is described in a blog post available in English or French.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tUsage\\n\\t\\n\\nfrom datasets import load_dataset\\ndataset = load_dataset(\\\"CATIE-AQ/frenchNER_4entities\\\")\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDetails of rows‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/CATIE-AQ/frenchNER_4entities."},
  {"name":"language_tags","keyword":"french","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/lbourdois/language_tags","creator_name":"Lo√Øck BOURDOIS","creator_url":"https://huggingface.co/lbourdois","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDescription\\n\\t\\n\\nDataset listing 27,328 languages and dialects (also includes macrolanguage names).For each language, either the ISO 639 code, the Glottolog code or both are provided.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tColumns\\n\\t\\n\\n\\nEnglish_Name: Language name in English (e.g. \\\"French\\\").\\nNative_Name: If value is not 0, corresponds to the name of the language by native speakers (e.g. \\\"Fran√ßais\\\") which may have been found in Wikipedia's nativename field.\\nGlottocode: The language tag in the Glottolog convention‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/lbourdois/language_tags."},
  {"name":"RIMES-2011-line","keyword":"french","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/Teklia/RIMES-2011-line","creator_name":"Teklia","creator_url":"https://huggingface.co/Teklia","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tRIMES-2011 - line level\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThe RIMES-2011 database (Recognition and Indexation of handwritten documents and faxes) was created to evaluate automatic recognition and indexing systems for handwritten letters. \\nThe database was collected by asking volunteers to write handwritten letters in exchange for gift certificates. Volunteers were given a fictitious identity (same gender as the real one) and up to 5 scenarios. Each scenario was chosen from among 9‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Teklia/RIMES-2011-line."},
  {"name":"oaast_rm_full_jieba","keyword":"french","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/lenML/oaast_rm_full_jieba","creator_name":"len","creator_url":"https://huggingface.co/lenML","description":"Â∞ùËØïËß£ÂÜ≥\\\"llm repetition problem\\\"Ôºå‰ΩøÁî®ÂàÜËØçÊ®°ÂûãÂØπoaastËØ≠ÊñôËøõË°å‚ÄúÁªìÂ∑¥Âåñ‚ÄùÊï∞ÊçÆÂ¢ûÂº∫ÔºåÊèê‰æõÊõ¥Âº∫ÁöÑÈáçÂ§çÂÜÖÂÆπÊãíÁªùÊïàÊûú„ÄÇ\\nAttempts to solve the \\\"llm repetition problem\\\" by using a segmentation model to enhance the oaast corpus with \\\"stuttering\\\" data to provide stronger rejection of duplicate content.\\nÂÖ∂Ê¨°ÔºåËøòËøáÊª§Êéâ‰∫ÜÊâÄÊúâËá™ÊàëËÆ§Áü•ÁöÑÂæÆË∞ÉÊ†∑Êú¨„ÄÇ\\nSecond, it also filters out all the fine-tuned samples of self-cognition.\\nfiles:\\n\\noaast_rm_full_jieba.jsonl : word level repeat\\noaast_rm_full_sent_jieba.jsonl : sentence level repeat\\n\\n"},
  {"name":"Himanis-line","keyword":"french","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/Teklia/Himanis-line","creator_name":"Teklia","creator_url":"https://huggingface.co/Teklia","description":"\\n\\t\\n\\t\\t\\n\\t\\tHimanis - line level\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nHimanis (HIstorical MANuscript Indexing for user controlled Search) is a corpus of medieval documents.\\nThe historical corpus is described in the following publication:\\nStutzmann, D., Moufflet, J-F., & Hamel, S. (2017). La recherche en plein texte dans les sources manuscrites m√©di√©vales‚ÄØ: enjeux et perspectives du projet HIMANIS pour l‚Äô√©dition √©lectronique. M√©di√©vales‚ÄØ: Langue, textes, histoire 73 (2017): 67‚Äë96.‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Teklia/Himanis-line."},
  {"name":"Belfort-line","keyword":"french","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/Teklia/Belfort-line","creator_name":"Teklia","creator_url":"https://huggingface.co/Teklia","description":"\\n\\t\\n\\t\\t\\n\\t\\tBelfort - line level\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThe Belfort dataset includes minutes of the municipal council of the French city of Belfort. \\nText lines were extracted using an automatic model and may contain segmentation errors. The transcriptions were obtained through a crowdsourcing campaign using the Callico web plateform.\\nNote that all images are resized to a fixed height of 128 pixels.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages\\n\\t\\n\\nAll the documents in the dataset are written in French.‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Teklia/Belfort-line."},
  {"name":"POPP-line","keyword":"french","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/Teklia/POPP-line","creator_name":"Teklia","creator_url":"https://huggingface.co/Teklia","description":"\\n\\t\\n\\t\\t\\n\\t\\tPOPP - line level\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThe POPP dataset includes French civil census from Paris from the early 20th century.\\nNote that all images are resized to a fixed height of 128 pixels.\\n\\n\\t\\n\\t\\t\\n\\t\\tLanguages\\n\\t\\n\\nAll the documents in the dataset are written in French.\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Structure\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tData Instances\\n\\t\\n\\n{\\n  'image': <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=4300x128 at 0x1A800E8E190,\\n  'text': 'Joly Ernest 88 Indre M par Employ√© Roblot!18377'\\n}‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Teklia/POPP-line."},
  {"name":"code_civil","keyword":"french","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/Hunterlige/code_civil","creator_name":"Denis","creator_url":"https://huggingface.co/Hunterlige","description":"Hunterlige/code_civil dataset hosted on Hugging Face and contributed by the HF Datasets community"},
  {"name":"oasst2_dpo_pairs","keyword":"french","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/alexredna/oasst2_dpo_pairs","creator_name":"Alexander Gruhl","creator_url":"https://huggingface.co/alexredna","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for \\\"oasst2_dpo_pairs\\\"\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nDataset transferred into the structure for trainig with DPO and can be used with the Alignment Handbook\\nThe structure follows mostly the same scheme as HuggingFaceH4/ultrafeedback_binarized\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tUsage\\n\\t\\n\\nTo load the dataset, run:\\nfrom datasets import load_dataset\\n\\nds = load_dataset(\\\"alexredna/oasst2_dpo_pairs\\\")\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages\\n\\t\\n\\nBase dataset filtered to only contain: German, English, Spanish‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/alexredna/oasst2_dpo_pairs."},
  {"name":"language-dataset","keyword":"french","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/neon-mao/language-dataset","creator_name":"maoqifan","creator_url":"https://huggingface.co/neon-mao","description":"\\n"},
  {"name":"seamless-align-expressive","keyword":"french","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/jhu-clsp/seamless-align-expressive","creator_name":"Center for Language and Speech Processing @ JHU","creator_url":"https://huggingface.co/jhu-clsp","description":"\\n\\t\\n\\t\\t\\n\\t\\tDataset Card for Seamless-Align-Expressive (WIP). Inspired by https://huggingface.co/datasets/allenai/nllb\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThis dataset was created based on metadata for mined expressive Speech-to-Speech(S2S) released by Meta AI.  The S2S contains data for 5 language pairs. The S2S dataset is ~228GB compressed.\\n\\n\\t\\n\\t\\t\\n\\t\\tHow to use the data\\n\\t\\n\\nThere are two ways to access the data:\\n\\nVia the Hugging Face Python datasets library\\n\\nScripts coming soon\\n\\n\\nClone the git repo\\n\\ngit‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/jhu-clsp/seamless-align-expressive."},
  {"name":"Deltacorpus_1.1","keyword":"french","license":"Creative Commons Attribution Share Alike 4.0 International","language":"en","url":"https://huggingface.co/datasets/FrancophonIA/Deltacorpus_1.1","creator_name":"FrancophonIA","creator_url":"https://huggingface.co/FrancophonIA","description":"\\nDataset origin: https://lindat.cz/repository/xmlui/handle/11234/1-1743\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDescription\\n\\t\\n\\nTexts in 107 languages from the W2C corpus (http://hdl.handle.net/11858/00-097C-0000-0022-6133-9), first 1,000,000 tokens per language, tagged by the delexicalized tagger described in Yu et al. (2016, LREC, Portoro≈æ, Slovenia).\\nChanges in version 1.1: \\n\\nUniversal Dependencies tagset instead of the older and smaller Google Universal POS tagset. \\n\\nSVM classifier trained on Universal Dependencies‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/FrancophonIA/Deltacorpus_1.1."},
  {"name":"MM-Eval","keyword":"french","license":"Creative Commons Attribution Share Alike 4.0 International","language":"en","url":"https://huggingface.co/datasets/prometheus-eval/MM-Eval","creator_name":"prometheus-eval","creator_url":"https://huggingface.co/prometheus-eval","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tMultilingual Meta-EVALuation benchmark (MM-Eval)\\n\\t\\n\\n\\nüë®‚ÄçüíªCode\\n|\\nüìÑPaper\\n|\\nü§ó MMQA\\n\\n\\nMM-Eval is a multilingual meta-evaluation benchmark consisting of five core subsets‚ÄîChat, Reasoning, Safety, Language Hallucination, and Linguistics‚Äîspanning 18 languages and a Language Resource subset spanning 122 languages for a broader analysis of language effects. \\n\\nDesign ChoiceIn this work, we minimize the inclusion of translated samples, as mere translation may alter existing preferences due‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/prometheus-eval/MM-Eval."},
  {"name":"Saka-Alpaca-v1","keyword":"french","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/Sakalti/Saka-Alpaca-v1","creator_name":"sakasan","creator_url":"https://huggingface.co/Sakalti","description":"https://chatgpt.com\\n"},
  {"name":"linkedin-industry-list","keyword":"french","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/fantastic-jobs/linkedin-industry-list","creator_name":"Fantastic.jobs","creator_url":"https://huggingface.co/fantastic-jobs","description":"fantastic-jobs/linkedin-industry-list dataset hosted on Hugging Face and contributed by the HF Datasets community"},
  {"name":"INCA-17-01-2025","keyword":"french","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/La-Mousse/INCA-17-01-2025","creator_name":"La Mousse","creator_url":"https://huggingface.co/La-Mousse","description":"\\n\\t\\n\\t\\t\\n\\t\\tFrench Court Decisions Dataset (INCA)\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThe French Court Decisions Dataset (INCA) is a comprehensive collection of judicial decisions from various French courts. This dataset contains decisions from multiple jurisdictions, providing a broad perspective on French jurisprudence and representing an essential resource for legal research, analysis, and machine learning applications in the French legal domain.\\n\\n\\t\\n\\t\\t\\n\\t\\tSource Data\\n\\t\\n\\nThe data is sourced from‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/La-Mousse/INCA-17-01-2025."},
  {"name":"MMMLU","keyword":"french","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/bzantium/MMMLU","creator_name":"Minho Ryu","creator_url":"https://huggingface.co/bzantium","description":"\\n\\t\\n\\t\\t\\n\\t\\tMultilingual Massive Multitask Language Understanding (MMMLU)\\n\\t\\n\\nThe MMLU is a widely recognized benchmark of general knowledge attained by AI models. It covers a broad range of topics from 57 different categories, covering elementary-level knowledge up to advanced professional subjects like law, physics, history, and computer science.\\nWe translated the MMLU‚Äôs test set into 14 languages using professional human translators. Relying on human translators for this evaluation increases‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/bzantium/MMMLU."},
  {"name":"combined-fr-caselaw","keyword":"french","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/Tonic/combined-fr-caselaw","creator_name":"Joseph [open/acc] Pollack","creator_url":"https://huggingface.co/Tonic","description":"\\n\\t\\n\\t\\t\\n\\t\\tDataset Card for French Legal Cases Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThis dataset combines French legal cases from multiple sources (INCA, JADE, CASS, CAPP) into a unified format with overlapping text triplets. It includes decisions from various French courts, processed to facilitate natural language processing tasks.\\n\\n\\t\\n\\t\\t\\n\\t\\tSupported Tasks and Leaderboards\\n\\t\\n\\n\\nTasks:\\nText Generation\\nLegal Document Analysis\\nText Classification\\nLanguage Modeling\\n\\n\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tLanguages\\n\\t\\n\\nThe dataset‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Tonic/combined-fr-caselaw."},
  {"name":"imeg4model","keyword":"french","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/yyasso/imeg4model","creator_name":"H.coding AI","creator_url":"https://huggingface.co/yyasso","description":"openS\\nfrom: hcoding\\n"},
  {"name":"MX-CHAT","keyword":"french","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/berwart/MX-CHAT","creator_name":"Berwart","creator_url":"https://huggingface.co/berwart","description":"MX-CHAT 01\\n"},
  {"name":"declaration_des_droits_de_l_homme_et_du_citoyen","keyword":"french","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/Tricoteuses/declaration_des_droits_de_l_homme_et_du_citoyen","creator_name":"Tricoteuses","creator_url":"https://huggingface.co/Tricoteuses","description":"\\n\\t\\n\\t\\t\\n\\t\\tL√©gifrance Legislative Text Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThe L√©gifrance Legislative Text Dataset is a structured collection of French legislative and regulatory texts extracted from the L√©gifrance platform.\\nThis dataset provides machine-readable access to consolidated legal codes, with a particular focus on maintaining the integrity of French linguistic features while providing additional metadata and quality signals.\\nThe data in this dataset comes from the Git repository‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Tricoteuses/declaration_des_droits_de_l_homme_et_du_citoyen."},
  {"name":"constitution_du_4_octobre_1958","keyword":"french","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/Tricoteuses/constitution_du_4_octobre_1958","creator_name":"Tricoteuses","creator_url":"https://huggingface.co/Tricoteuses","description":"\\n\\t\\n\\t\\t\\n\\t\\tL√©gifrance Legislative Text Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThe L√©gifrance Legislative Text Dataset is a structured collection of French legislative and regulatory texts extracted from the L√©gifrance platform.\\nThis dataset provides machine-readable access to consolidated legal codes, with a particular focus on maintaining the integrity of French linguistic features while providing additional metadata and quality signals.\\nThe data in this dataset comes from the Git repository‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Tricoteuses/constitution_du_4_octobre_1958."},
  {"name":"BenchMAX_Rule-based","keyword":"french","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/LLaMAX/BenchMAX_Rule-based","creator_name":"LLaMAX","creator_url":"https://huggingface.co/LLaMAX","description":"\\n\\t\\n\\t\\t\\n\\t\\tDataset Sources\\n\\t\\n\\n\\nPaper: BenchMAX: A Comprehensive Multilingual Evaluation Suite for Large Language Models\\nLink: https://arxiv.org/pdf/2502.07346\\nRepository: https://github.com/CONE-MT/BenchMAX\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\nBenchMAX_Rule-based is a dataset of BenchMAX, sourcing from IFEval, which is a rule-based benchmark for evaluating the instruction following capabilities.\\nWe extend the original dataset to 16 non-English languages by first translating and then manual‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/LLaMAX/BenchMAX_Rule-based."},
  {"name":"BenchMAX_Model-based","keyword":"french","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/LLaMAX/BenchMAX_Model-based","creator_name":"LLaMAX","creator_url":"https://huggingface.co/LLaMAX","description":"\\n\\t\\n\\t\\t\\n\\t\\tDataset Sources\\n\\t\\n\\n\\nPaper: BenchMAX: A Comprehensive Multilingual Evaluation Suite for Large Language Models\\nLink: https://arxiv.org/pdf/2502.07346\\nRepository: https://github.com/CONE-MT/BenchMAX\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\nBenchMAX_Model-based is a dataset of BenchMAX, sourcing from m-ArenaHard.\\nWe extend the original English dataset to 16 non-English languages by first translating and then manual post-editing.\\n\\n\\t\\n\\t\\t\\n\\t\\tSupported Languages\\n\\t\\n\\nArabic, Bengali, Chinese, Czech‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/LLaMAX/BenchMAX_Model-based."},
  {"name":"BenchMAX_Multiple_Functions","keyword":"french","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/LLaMAX/BenchMAX_Multiple_Functions","creator_name":"LLaMAX","creator_url":"https://huggingface.co/LLaMAX","description":"\\n\\t\\n\\t\\t\\n\\t\\tDataset Sources\\n\\t\\n\\n\\nPaper: BenchMAX: A Comprehensive Multilingual Evaluation Suite for Large Language Models\\nLink: https://arxiv.org/pdf/2502.07346\\nRepository: https://github.com/CONE-MT/BenchMAX\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\nBenchMAX_Multiple_Functions is a dataset of BenchMAX, sourcing from Nexus.\\nWe translate the standardized queries from English to 16 non-English languages by google Translate.\\nSome special function arguments remain English since the APIs are in English.\\nAll‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/LLaMAX/BenchMAX_Multiple_Functions."},
  {"name":"BenchMAX_General_Translation","keyword":"french","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/LLaMAX/BenchMAX_General_Translation","creator_name":"LLaMAX","creator_url":"https://huggingface.co/LLaMAX","description":"\\n\\t\\n\\t\\t\\n\\t\\tDataset Sources\\n\\t\\n\\n\\nPaper: BenchMAX: A Comprehensive Multilingual Evaluation Suite for Large Language Models\\nLink: https://arxiv.org/pdf/2502.07346\\nRepository: https://github.com/CONE-MT/BenchMAX\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\nBenchMAX_General_Translation is a dataset of BenchMAX.\\nWe collect parallel test data from Flore-200, TED-talk, and WMT24.\\n\\n\\t\\n\\t\\t\\n\\t\\tSupported Languages\\n\\t\\n\\nArabic, Bengali, Chinese, Czech, English, French, German, Hungarian, Japanese, Korean, Serbian, Spanish‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/LLaMAX/BenchMAX_General_Translation."},
  {"name":"BenchMAX_Domain_Translation","keyword":"french","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/LLaMAX/BenchMAX_Domain_Translation","creator_name":"LLaMAX","creator_url":"https://huggingface.co/LLaMAX","description":"\\n\\t\\n\\t\\t\\n\\t\\tDataset Sources\\n\\t\\n\\n\\nPaper: BenchMAX: A Comprehensive Multilingual Evaluation Suite for Large Language Models\\nLink: https://arxiv.org/pdf/2502.07346\\nRepository: https://github.com/CONE-MT/BenchMAX\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\nBenchMAX_Domain_Translation is a dataset of BenchMAX.\\nWe collect the domain parallel data from other tasks in BenchMAX.\\nEach sample contains one or three human-annotated translations.\\n\\n\\t\\n\\t\\t\\n\\t\\tSupported Languages\\n\\t\\n\\nArabic, Bengali, Chinese, Czech, English‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/LLaMAX/BenchMAX_Domain_Translation."},
  {"name":"t5_codePenalDataset","keyword":"french","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/AssemienDev/t5_codePenalDataset","creator_name":"Sidjane Assemien Henri Osee","creator_url":"https://huggingface.co/AssemienDev","description":"AssemienDev/t5_codePenalDataset dataset hosted on Hugging Face and contributed by the HF Datasets community"},
  {"name":"Newspapers-finlam-La-Liberte","keyword":"french","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/Teklia/Newspapers-finlam-La-Liberte","creator_name":"Teklia","creator_url":"https://huggingface.co/Teklia","description":"\\n\\t\\n\\t\\t\\n\\t\\tNewspaper dataset: Finlam La Libert√©\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThe Finlam La Libert√© dataset includes 1500 issues from La Libert√©, a French newspaper, from 1925 to 1928. \\nEach issue contains multiple pages, with one image for each page resized to a fixed height of 2500 pixels.\\nThe dataset can be used to train end-to-end newspaper understanding models, with tasks including:\\n\\nText zone detection and classification\\nReading order detection\\nArticle separation\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSplit‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Teklia/Newspapers-finlam-La-Liberte."},
  {"name":"test3","keyword":"french","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/yann23/test3","creator_name":"kofd","creator_url":"https://huggingface.co/yann23","description":"\\n\\t\\n\\t\\t\\n\\t\\tüìä Test3\\n\\t\\n\\nCe dataset contient des donn√©es d'API au format JSONL et Parquet, avec des variantes de questions et leurs r√©ponses associ√©es.\\n\\n\\t\\n\\t\\t\\n\\t\\tüìÇ Structure des Fichiers\\n\\t\\n\\n\\ndata.parquet : Dataset principal au format Parquet\\ndataset_base.jsonl : Donn√©es de base\\ndataset_dpo.jsonl et dataset_dpo.parquet : Format DPO avec paires chosen/rejected\\ndataset_avec_variantes.jsonl : Donn√©es avec variantes de questions\\ndataset_final.parquet : Dataset final au format Parquet\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\t‚öôÔ∏è‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/yann23/test3."},
  {"name":"UD_Breton-KEB_translation","keyword":"french","license":"Creative Commons Attribution Share Alike 4.0 International","language":"en","url":"https://huggingface.co/datasets/Bretagne/UD_Breton-KEB_translation","creator_name":"Bretagne","creator_url":"https://huggingface.co/Bretagne","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDescription\\n\\t\\n\\nVersion pars√©e de UD_Breton-KEB afin de rendre son usage plus simple.\\nCe d√©p√¥t ne s'int√©resse qu'√† la traduction breton/fran√ßais. \\nPour la partie POS, nous vous invitions √† consulter Bretagne/UD_Breton-KEB.\\nUD Breton-KEB est une banque d'arbres de textes en breton qui a √©t√© annot√©e manuellement selon les directives d'Universal Dependencies. \\nLa tokenisation et l'annotation morphologique proviennent d'un analyseur morphologique √† √©tat fini publi√© dans le cadre du‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Bretagne/UD_Breton-KEB_translation."},
  {"name":"Tiranige_lexicon","keyword":"french","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/FrancophonIA/Tiranige_lexicon","creator_name":"FrancophonIA","creator_url":"https://huggingface.co/FrancophonIA","description":"\\nDataset origin: https://zenodo.org/records/3829167\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDescription\\n\\t\\n\\nLexicon of Tiranige, a western Dogon language of east central Mali, in csv spreadsheet form. Columns from left to right (omitting blanks) are:\\n\\nTiranige (transcription)\\nfinder (English finder list, i.e. usually one-word glosses)\\nrecherche (finder list in French)\\nEnglish (full English gloss)\\nfran√ßais (full French gloss)\\ncode (for certain lexical categories: fauna, flora, body, kinship)\\norder/family (for flora-fauna‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/FrancophonIA/Tiranige_lexicon."},
  {"name":"dataset-kid-fr-lexia","keyword":"french","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/Marsouuu/dataset-kid-fr-lexia","creator_name":"Martial Roberge","creator_url":"https://huggingface.co/Marsouuu","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset KID-FR: Documents d'Informations Cl√©s Financiers en Fran√ßais\\n\\t\\n\\nCe dataset contient une collection de Documents d'Informations Cl√©s (KID - Key Information Documents) financiers en fran√ßais. Il est con√ßu pour l'entra√Ænement de mod√®les de vision par ordinateur et de traitement du langage naturel dans le domaine financier.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tContenu\\n\\t\\n\\nLe dataset se compose de documents financiers structur√©s comprenant :\\n\\nDes images de documents financiers\\nLe texte extrait de ces‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Marsouuu/dataset-kid-fr-lexia."},
  {"name":"SIWIS_French_Speech_Synthesis_Database","keyword":"french","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/Aviv-anthonnyolime/SIWIS_French_Speech_Synthesis_Database","creator_name":"Anthonny Olime","creator_url":"https://huggingface.co/Aviv-anthonnyolime","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSIWIS French Speech Synthesis Database\\n\\t\\n\\nThis README provides a concise description of the dataset, including its structure, file naming conventions, and known labeling issues. Additionally, suggestions for potential improvements are outlined in the TODO section.  \\nThe dataset is distributed under the Creative Commons Attribution 4.0 International (CC BY 4.0) license, permitting its use for any purpose.  \\nFor more details about the database design and recording process, please‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Aviv-anthonnyolime/SIWIS_French_Speech_Synthesis_Database."},
  {"name":"JADE-17-01-2025","keyword":"french","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/La-Mousse/JADE-17-01-2025","creator_name":"La Mousse","creator_url":"https://huggingface.co/La-Mousse","description":"\\n\\t\\n\\t\\t\\n\\t\\tFrench Administrative Court Decisions Dataset (JADE)\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThe French Administrative Court Decisions Dataset (JADE) is a comprehensive collection of judicial decisions from French administrative courts. This dataset contains decisions from various administrative jurisdictions, providing a valuable resource for legal research, analysis, and machine learning applications in the legal domain.\\n\\n\\t\\n\\t\\t\\n\\t\\tSource Data\\n\\t\\n\\nThe data is sourced from the official DILA‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/La-Mousse/JADE-17-01-2025."},
  {"name":"FrBMedQA-mcq","keyword":"french","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/Anony-mous123/FrBMedQA-mcq","creator_name":"a123","creator_url":"https://huggingface.co/Anony-mous123","description":"Anony-mous123/FrBMedQA-mcq dataset hosted on Hugging Face and contributed by the HF Datasets community"},
  {"name":"FrMedMCQA","keyword":"french","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/Anony-mous123/FrMedMCQA","creator_name":"a123","creator_url":"https://huggingface.co/Anony-mous123","description":"Anony-mous123/FrMedMCQA dataset hosted on Hugging Face and contributed by the HF Datasets community"},
  {"name":"SFT-dataset","keyword":"french","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/Anony-mous123/SFT-dataset","creator_name":"a123","creator_url":"https://huggingface.co/Anony-mous123","description":"Anony-mous123/SFT-dataset dataset hosted on Hugging Face and contributed by the HF Datasets community"},
  {"name":"fr-medqa-5_options","keyword":"french","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/Anony-mous123/fr-medqa-5_options","creator_name":"a123","creator_url":"https://huggingface.co/Anony-mous123","description":"Anony-mous123/fr-medqa-5_options dataset hosted on Hugging Face and contributed by the HF Datasets community"},
  {"name":"fr-medqa","keyword":"french","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/Anony-mous123/fr-medqa","creator_name":"a123","creator_url":"https://huggingface.co/Anony-mous123","description":"Anony-mous123/fr-medqa dataset hosted on Hugging Face and contributed by the HF Datasets community"},
  {"name":"fr-mmlu_anatomy","keyword":"french","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/Anony-mous123/fr-mmlu_anatomy","creator_name":"a123","creator_url":"https://huggingface.co/Anony-mous123","description":"Anony-mous123/fr-mmlu_anatomy dataset hosted on Hugging Face and contributed by the HF Datasets community"},
  {"name":"fr-mmlu_clinical_knowledge","keyword":"french","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/Anony-mous123/fr-mmlu_clinical_knowledge","creator_name":"a123","creator_url":"https://huggingface.co/Anony-mous123","description":"Anony-mous123/fr-mmlu_clinical_knowledge dataset hosted on Hugging Face and contributed by the HF Datasets community"},
  {"name":"fr-mmlu_college_medicine","keyword":"french","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/Anony-mous123/fr-mmlu_college_medicine","creator_name":"a123","creator_url":"https://huggingface.co/Anony-mous123","description":"Anony-mous123/fr-mmlu_college_medicine dataset hosted on Hugging Face and contributed by the HF Datasets community"},
  {"name":"fr-mmlu_professional_medicine","keyword":"french","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/Anony-mous123/fr-mmlu_professional_medicine","creator_name":"a123","creator_url":"https://huggingface.co/Anony-mous123","description":"Anony-mous123/fr-mmlu_professional_medicine dataset hosted on Hugging Face and contributed by the HF Datasets community"},
  {"name":"V1Q","keyword":"french","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/YuRiVeRTi/V1Q","creator_name":"YuRiVeRTical","creator_url":"https://huggingface.co/YuRiVeRTi","description":"from datasets import load_dataset\\nds = load_dataset(\\\"b3x0m/Chinese-H-Novels\\\")\\nimport sagemaker\\nimport boto3\\nfrom sagemaker.huggingface import HuggingFaceModel\\ntry:\\n    role = sagemaker.get_execution_role()\\nexcept ValueError:\\n    iam = boto3.client('iam')\\n    role = iam.get_role(RoleName='sagemaker_execution_role')['Role']['Arn']\\n\\n\\t\\n\\t\\t\\n\\t\\tHub Model configuration. https://huggingface.co/models\\n\\t\\n\\nhub = {\\n    'HF_MODEL_ID':'deepseek-ai/Janus-Pro-7B',\\n    'HF_TASK':'any-to-any'\\n}\\n\\n\\t\\n\\t\\t\\n\\t\\tcreate‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/YuRiVeRTi/V1Q."},
  {"name":"PleIAs-ToxicCommons","keyword":"french","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/agentlans/PleIAs-ToxicCommons","creator_name":"Alan Tseng","creator_url":"https://huggingface.co/agentlans","description":"\\n\\t\\n\\t\\t\\n\\t\\tPleIAs/ToxicCommons\\n\\t\\n\\nThis dataset is a refined version of the PleIAs/ToxicCommons collection, focusing on historical texts labeled for content that may be considered objectionable by modern standards (what the authors of the dataset deem \\\"toxic\\\"). \\nThe cleaned dataset contains 1‚Äâ051‚Äâ027 rows, each representing a text sample with associated toxicity scores across five dimensions:\\n\\nRace and origin-based bias\\nGender and sexuality-based bias\\nReligious bias\\nAbility bias\\nViolence and abuse‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/agentlans/PleIAs-ToxicCommons."},
  {"name":"MAPA_Anonymization_package","keyword":"french","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/FrancophonIA/MAPA_Anonymization_package","creator_name":"FrancophonIA","creator_url":"https://huggingface.co/FrancophonIA","description":"\\nDataset origin: https://elrc-share.eu/repository/browse/mapa-anonymization-package-french/2769ba3a8a8411ec9c1a00155d0267062553e7eec46c4dec878f6d1cc079f24e/\\n\\n"},
  {"name":"campSentiment-Bilingual","keyword":"french","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/MouezYazidi/campSentiment-Bilingual","creator_name":"Mouez Yazidi","creator_url":"https://huggingface.co/MouezYazidi","description":"\\n\\t\\n\\t\\t\\n\\t\\tCamping Reviews Sentiment (EN-FR)\\n\\t\\n\\nThis dataset is a bilingual collection of reviews in English and French scraped from Tripadvisor, focusing on customer experiences and sentiments related to camping. Each review is labeled with its corresponding sentiment (positive, negative, or neutral).  \\n\\n\\t\\n\\t\\t\\n\\t\\tKey Features\\n\\t\\n\\n\\nBilingual Content: Reviews are available in English and French, making it ideal for multilingual sentiment analysis tasks.  \\nRich Review Length: Includes long review‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/MouezYazidi/campSentiment-Bilingual."},
  {"name":"MOL","keyword":"french","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/franciellevargas/MOL","creator_name":"Francielle Vargas","creator_url":"https://huggingface.co/franciellevargas","description":"\\n\\t\\n\\t\\t\\n\\t\\tMOL - Context-Aware Multilingual Offensive Lexicon\\n\\t\\n\\nThe MOL is the first specialized lexicon for hate speech detection, annotated with contextual information.\\nIt consists of 1,000 explicit and implicit (clue-based) human-annotated rationales used with pejorative connotations, manually identified by a linguist and annotated by three experts regarding their contextual dependency (context-dependent or context-independent).\\nFor example, the term \\\"stupid\\\" is classified as a‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/franciellevargas/MOL."},
  {"name":"Felguk-icons","keyword":"french","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/Felguk/Felguk-icons","creator_name":"Alex Felguk","creator_url":"https://huggingface.co/Felguk","description":"\\n\\t\\n\\t\\t\\n\\t\\tFelguk icons\\n\\t\\n\\nThe felguk icons They use it for me. That is, for me.\\nfollow me\\n"},
  {"name":"LLM-icons","keyword":"french","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/Felguk/LLM-icons","creator_name":"Alex Felguk","creator_url":"https://huggingface.co/Felguk","description":"Felguk/LLM-icons dataset hosted on Hugging Face and contributed by the HF Datasets community"},
  {"name":"ocr-error-senat","keyword":"french","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/HenriPorteur/ocr-error-senat","creator_name":"Henri_Porteur","creator_url":"https://huggingface.co/HenriPorteur","description":"\\n\\t\\n\\t\\t\\n\\t\\tDescription\\n\\t\\n\\nThe dataset is sourced from the French Senate's records, available at this link. After segmenting the text into sentences, 200,000 sentences were extracted(160,000 for train, 40,000 for test).  \\nOCR errors are generated using the following script, designed to simulate errors found in certain documents from the French National Library caused by physical constraints (e.g., page curvature).  \\nimport random\\nimport re\\nfrom typing import Dict, List\\n\\nclass‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/HenriPorteur/ocr-error-senat."},
  {"name":"multilingual_translation_gen_binarized","keyword":"french","license":"MIT License","language":"en","url":"https://huggingface.co/datasets/Youseff1987/multilingual_translation_gen_binarized","creator_name":"JOON HYOUNG JUN","creator_url":"https://huggingface.co/Youseff1987","description":"Youseff1987/multilingual_translation_gen_binarized dataset hosted on Hugging Face and contributed by the HF Datasets community"},
  {"name":"africalaw","keyword":"french","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/stefyu/africalaw","creator_name":"Coumbassa","creator_url":"https://huggingface.co/stefyu","description":"stefyu/africalaw dataset hosted on Hugging Face and contributed by the HF Datasets community"},
  {"name":"HistLuxAlign","keyword":"french","license":"GNU Affero General Public License v3.0","language":"en","url":"https://huggingface.co/datasets/impresso-project/HistLuxAlign","creator_name":"Impresso - Media Monitoring of the Past","creator_url":"https://huggingface.co/impresso-project","description":"impresso-project/HistLuxAlign dataset hosted on Hugging Face and contributed by the HF Datasets community"},
  {"name":"gsm8k-translated","keyword":"french","license":"Apache License 2.0","language":"en","url":"https://huggingface.co/datasets/Sara237/gsm8k-translated","creator_name":"Sara Rajaee","creator_url":"https://huggingface.co/Sara237","description":"Sara237/gsm8k-translated dataset hosted on Hugging Face and contributed by the HF Datasets community"},
  {"name":"Emilia-YODAS","keyword":"french","license":"Creative Commons Attribution 4.0 International","language":"en","url":"https://huggingface.co/datasets/mrfakename/Emilia-YODAS","creator_name":"mrfakename","creator_url":"https://huggingface.co/mrfakename","description":"A mirror of the Emilia-YODAS dataset. Only includes the YODAS subset from the original dataset.\\nhttps://huggingface.co/datasets/amphion/Emilia-Dataset\\n"},
  {"name":"HPLT2.0_cleaned","keyword":"french","license":"Creative Commons Zero v1.0 Universal","language":"en","url":"https://huggingface.co/datasets/jobs-git/HPLT2.0_cleaned","creator_name":"James Guana","creator_url":"https://huggingface.co/jobs-git","description":"This is a large-scale collection of web-crawled documents in 191 world languages, produced by the HPLT project. \\nThe source of the data is mostly Internet Archive with some additions from Common Crawl.\\nFor a detailed description of the dataset, please refer to https://hplt-project.org/datasets/v2.0\\nThe Cleaned variant of HPLT Datasets v2.0\\nThis is the cleaned variant of the HPLT Datasets v2.0 converted to the Parquet format semi-automatically when being uploaded here. \\nThe original JSONL files‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/jobs-git/HPLT2.0_cleaned."}
];
