const data_for_language_pacific_chamorro = 
[
	{"name":"wikipedia-monthly","keyword":"chamorro","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/omarkamali/wikipedia-monthly","creator_name":"Omar Kamali","creator_url":"https://huggingface.co/omarkamali","description":"\n\t\n\t\t\n\t\tüöÄ Wikipedia Monthly\n\t\n\nLast updated: July 16, 2025, 22:53 UTC\nThis repository provides monthly, multilingual dumps of Wikipedia, processed and prepared for easy use in NLP projects.\nNOTE: The first run is still in progress and languages are still being processed and uploaded.\n\n\n\t\n\t\t\n\t\tüìä Live Statistics\n\t\n\n\n\t\n\t\t\nMetric\nValue\n\n\n\t\t\nüåç Languages Available\n341\n\n\nüìÑ Total Articles\n64.5M\n\n\nüíæ Total Size\n205.54 GB\n\n\n\t\n\n\n\n\t\n\t\t\n\t\tWhy Use This Dataset?\n\t\n\n\nFreshness: We run our pipeline monthly‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/omarkamali/wikipedia-monthly.","first_N":5,"first_N_keywords":["Abkhaz","Achinese","Adyghe","Afrikaans","Akan"],"keywords_longer_than_N":true},
	{"name":"test_pq","keyword":"chamorro","license":"Academic Free License v3.0","license_url":"https://choosealicense.com/licenses/afl-3.0/","language":"en","dataset_url":"https://huggingface.co/datasets/changxin/test_pq","creator_name":"changxin","creator_url":"https://huggingface.co/changxin","description":"This is a test dataset.","first_N":5,"first_N_keywords":["expert-generated","found","monolingual","original","Chamorro"],"keywords_longer_than_N":true},
	{"name":"TGEA2.0","keyword":"chamorro","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/jerma66/TGEA2.0","creator_name":"vinsmoke","creator_url":"https://huggingface.co/jerma66","description":"\n\t\n\t\t\n\t\n\t\n\t\tDataset Card for Dataset Name\n\t\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nIn order to diagnostically analyze and improve the capability of pretrained language models (PLMs) in text generation, we propose TGEA 2.0, to date the largest dataset built on machine-authored texts by PLMs with fine-grained semantic annotations on a wide variety of pathological generation errors. We collect 170K nominal, phrasal and sentential prompts from 6M natural sentences in 3 domains. These prompts are fed into‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/jerma66/TGEA2.0.","first_N":5,"first_N_keywords":["Sardinian","Chamorro","Chinese","cc-by-4.0","üá∫üá∏ Region: US"],"keywords_longer_than_N":false},
	{"name":"xP3x","keyword":"chamorro","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/CohereLabs/xP3x","creator_name":"Cohere Labs","creator_url":"https://huggingface.co/CohereLabs","description":"\n\t\n\t\t\n\t\tDataset Card for xP3x\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\n\nxP3x (Crosslingual Public Pool of Prompts eXtended) is a collection of prompts & datasets across 277 languages & 16 NLP tasks. It contains all of xP3 + much more! It is used for training future contenders of mT0 & BLOOMZ at project Aya @Cohere Labs üß°\n\n\nCreation: The dataset can be recreated using instructions available here together with the file in this repository named xp3x_create.py. We provide this version to save processing‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/CohereLabs/xP3x.","first_N":5,"first_N_keywords":["other","expert-generated","crowdsourced","multilingual","Afrikaans"],"keywords_longer_than_N":true},
	{"name":"xP3x-sample","keyword":"chamorro","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Muennighoff/xP3x-sample","creator_name":"Niklas Muennighoff","creator_url":"https://huggingface.co/Muennighoff","description":"A multilingual collection of Winograd Schemas in six languages that can be used for evaluation of cross-lingual commonsense reasoning capabilities.","first_N":5,"first_N_keywords":["other","expert-generated","crowdsourced","multilingual","Afrikaans"],"keywords_longer_than_N":true},
	{"name":"My-First-Dataset","keyword":"chamorro","license":"PostgreSQL License","license_url":"https://choosealicense.com/licenses/postgresql/","language":"en","dataset_url":"https://huggingface.co/datasets/johnsonlee/My-First-Dataset","creator_name":"lizonglin","creator_url":"https://huggingface.co/johnsonlee","description":"ËøôÊòØÊàëÁöÑÁ¨¨‰∏Ä‰∏™dataset\n","first_N":5,"first_N_keywords":["Chamorro","postgresql","< 1K","text","Text"],"keywords_longer_than_N":true},
	{"name":"wikianc","keyword":"chamorro","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/cyanic-selkie/wikianc","creator_name":"cyanic-selkie","creator_url":"https://huggingface.co/cyanic-selkie","description":"\n\t\n\t\t\n\t\tDataset Card for WikiAnc\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThe WikiAnc dataset is an automatically generated dataset from Wikipedia (all languages) and Wikidata dumps (August, 2023). \nThe code for generating the dataset can be found here.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\n\nwikificiation: The dataset can be used to train a model for Wikification.\nnamed-entity-linking: The dataset can be used to train a model for Named Entity Linking.\n\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nThe text in the dataset is in all 320‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/cyanic-selkie/wikianc.","first_N":5,"first_N_keywords":["token-classification","machine-generated","crowdsourced","machine-generated","crowdsourced"],"keywords_longer_than_N":true},
	{"name":"language_tags","keyword":"chamorro","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/lbourdois/language_tags","creator_name":"Lo√Øck BOURDOIS","creator_url":"https://huggingface.co/lbourdois","description":"\n\t\n\t\t\n\t\tDescription\n\t\n\nDataset listing 27,328 languages and dialects (also includes macrolanguage names).For each language, either the ISO 639 code, the Glottolog code or both are provided.\n\n\t\n\t\t\n\t\tColumns\n\t\n\n\nEnglish_Name: Language name in English (e.g. \"French\").\nNative_Name: If value is not 0, corresponds to the name of the language by native speakers (e.g. \"Fran√ßais\") which may have been found in Wikipedia's nativename field.\nGlottocode: The language tag in the Glottolog convention (e.g.‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/lbourdois/language_tags.","first_N":5,"first_N_keywords":["Afade","Par√° Ar√°ra","Afar","Aka-Bea","Abon"],"keywords_longer_than_N":true},
	{"name":"udhr-lid","keyword":"chamorro","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/cis-lmu/udhr-lid","creator_name":"CIS, LMU Munich","creator_url":"https://huggingface.co/cis-lmu","description":"\n\t\n\t\t\n\t\tUDHR-LID\n\t\n\nWhy UDHR-LID?\nYou can access UDHR (Universal Declaration of Human Rights) here, but when a verse is missing, they have texts such as \"missing\" or \"?\". Also, about 1/3 of the sentences consist only of \"articles 1-30\" in different languages. We cleaned the entire dataset from XML files and selected only the paragraphs. We cleared any unrelated language texts from the data and also removed the cases that were incorrect.\nIncorrect? Look at the ckb and kmr files in the UDHR.‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/cis-lmu/udhr-lid.","first_N":5,"first_N_keywords":["multilingual","Tigrinya","Balkan Romani","Standard Arabic","Metlat√≥noc Mixtec"],"keywords_longer_than_N":true},
	{"name":"panlex-meanings","keyword":"chamorro","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/cointegrated/panlex-meanings","creator_name":"David Dale","creator_url":"https://huggingface.co/cointegrated","description":"\n\t\n\t\t\n\t\tDataset Card for panlex-meanings\n\t\n\nThis is a dataset of words in several thousand languages, extracted from https://panlex.org.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset has been extracted from https://panlex.org (the 20240301 database dump) and rearranged on the per-language basis.\nEach language subset consists of expressions (words and phrases). \nEach expression is associated with some meanings (if there is more than one meaning, they are in separate‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/cointegrated/panlex-meanings.","first_N":5,"first_N_keywords":["translation","Afar","Western Abnaki","Abkhazian","Abaza"],"keywords_longer_than_N":true},
	{"name":"panlex","keyword":"chamorro","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/lbourdois/panlex","creator_name":"Lo√Øck BOURDOIS","creator_url":"https://huggingface.co/lbourdois","description":"\n\t\n\t\t\n\t\tPanLex\n\t\n\nJanuary 1, 2024 version of PanLex Language Vocabulary with 24,650,274 rows covering 6,152 languages.\n\n\t\n\t\t\n\t\tColumns\n\t\n\n\nvocab: contains the text entry.  \n639-3: contains the ISO 639-3 languages tags to allow users to filter on the language(s) of their choice.\n639-3_english_name: the English language name associated to the code ISO 639-3. \nvar_code: contains a code to differentiate language variants. In practice, this is the code 639-3 + a number.  If 000, it corresponds to‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/lbourdois/panlex.","first_N":5,"first_N_keywords":["Ghotuo","Alumu-Tesu","Ari","Amal","Arb√´resh√´ Albanian"],"keywords_longer_than_N":true},
	{"name":"GlotCC-V1","keyword":"chamorro","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/cis-lmu/GlotCC-V1","creator_name":"CIS, LMU Munich","creator_url":"https://huggingface.co/cis-lmu","description":"\n\t\n\t\t\n\t\tDataset Summary\n\t\n\n \n\nGlotCC-V1.0 is a document-level, general domain dataset derived from CommonCrawl, covering more than 1000 languages.It is built using the GlotLID language identification and Ungoliant pipeline from CommonCrawl.We release our pipeline as open-source at https://github.com/cisnlp/GlotCC.  \nList of Languages: See https://datasets-server.huggingface.co/splits?dataset=cis-lmu/GlotCC-V1 to get the list of splits available.\n\n\t\t\n\t\tUsage (Huggingface Hub -- Recommended)‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/cis-lmu/GlotCC-V1.","first_N":5,"first_N_keywords":["multilingual","Abau","Amarasi","Abkhaz","Abkhazian"],"keywords_longer_than_N":true},
	{"name":"GlotCC-V1","keyword":"chamorro","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/cis-lmu/GlotCC-V1","creator_name":"CIS, LMU Munich","creator_url":"https://huggingface.co/cis-lmu","description":"\n\t\n\t\t\n\t\tDataset Summary\n\t\n\n \n\nGlotCC-V1.0 is a document-level, general domain dataset derived from CommonCrawl, covering more than 1000 languages.It is built using the GlotLID language identification and Ungoliant pipeline from CommonCrawl.We release our pipeline as open-source at https://github.com/cisnlp/GlotCC.  \nList of Languages: See https://datasets-server.huggingface.co/splits?dataset=cis-lmu/GlotCC-V1 to get the list of splits available.\n\n\t\t\n\t\tUsage (Huggingface Hub -- Recommended)‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/cis-lmu/GlotCC-V1.","first_N":5,"first_N_keywords":["multilingual","Abau","Amarasi","Abkhaz","Abkhazian"],"keywords_longer_than_N":true},
	{"name":"biblenlp-corpus-mmteb","keyword":"chamorro","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/davidstap/biblenlp-corpus-mmteb","creator_name":"David Stap","creator_url":"https://huggingface.co/davidstap","description":"This dataset pre-computes all English-centric directions from bible-nlp/biblenlp-corpus, and as a result loading is significantly faster.\nLoading example:\n>>> from datasets import load_dataset\n>>> dataset = load_dataset(\"davidstap/biblenlp-corpus-mmteb\", \"eng-arb\", trust_remote_code=True)\n>>> dataset\nDatasetDict({\n    train: Dataset({\n        features: ['eng', 'arb'],\n        num_rows: 28723\n    })\n    validation: Dataset({\n        features: ['eng', 'arb'],\n        num_rows: 1578\n    })‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/davidstap/biblenlp-corpus-mmteb.","first_N":5,"first_N_keywords":["no-annotation","expert-generated","translation","multilingual","Arifama-Miniafia"],"keywords_longer_than_N":true},
	{"name":"biblenlp-corpus-mmteb","keyword":"chamorro","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/davidstap/biblenlp-corpus-mmteb","creator_name":"David Stap","creator_url":"https://huggingface.co/davidstap","description":"This dataset pre-computes all English-centric directions from bible-nlp/biblenlp-corpus, and as a result loading is significantly faster.\nLoading example:\n>>> from datasets import load_dataset\n>>> dataset = load_dataset(\"davidstap/biblenlp-corpus-mmteb\", \"eng-arb\", trust_remote_code=True)\n>>> dataset\nDatasetDict({\n    train: Dataset({\n        features: ['eng', 'arb'],\n        num_rows: 28723\n    })\n    validation: Dataset({\n        features: ['eng', 'arb'],\n        num_rows: 1578\n    })‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/davidstap/biblenlp-corpus-mmteb.","first_N":5,"first_N_keywords":["no-annotation","expert-generated","translation","multilingual","Arifama-Miniafia"],"keywords_longer_than_N":true},
	{"name":"biblenlp-corpus-mmteb","keyword":"chamorro","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/biblenlp-corpus-mmteb","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"This dataset pre-computes all English-centric directions from bible-nlp/biblenlp-corpus, and as a result loading is significantly faster.\nLoading example:\n>>> from datasets import load_dataset\n>>> dataset = load_dataset(\"davidstap/biblenlp-corpus-mmteb\", \"eng-arb\", trust_remote_code=True)\n>>> dataset\nDatasetDict({\n    train: Dataset({\n        features: ['eng', 'arb'],\n        num_rows: 28723\n    })\n    validation: Dataset({\n        features: ['eng', 'arb'],\n        num_rows: 1578\n    })‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/biblenlp-corpus-mmteb.","first_N":5,"first_N_keywords":["no-annotation","expert-generated","translation","multilingual","Arifama-Miniafia"],"keywords_longer_than_N":true},
	{"name":"biblenlp-corpus-mmteb","keyword":"chamorro","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/biblenlp-corpus-mmteb","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"This dataset pre-computes all English-centric directions from bible-nlp/biblenlp-corpus, and as a result loading is significantly faster.\nLoading example:\n>>> from datasets import load_dataset\n>>> dataset = load_dataset(\"davidstap/biblenlp-corpus-mmteb\", \"eng-arb\", trust_remote_code=True)\n>>> dataset\nDatasetDict({\n    train: Dataset({\n        features: ['eng', 'arb'],\n        num_rows: 28723\n    })\n    validation: Dataset({\n        features: ['eng', 'arb'],\n        num_rows: 1578\n    })‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/biblenlp-corpus-mmteb.","first_N":5,"first_N_keywords":["no-annotation","expert-generated","translation","multilingual","Arifama-Miniafia"],"keywords_longer_than_N":true},
	{"name":"xP3x-Kongo","keyword":"chamorro","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Svngoku/xP3x-Kongo","creator_name":"NIONGOLO Chrys F√©-Marty","creator_url":"https://huggingface.co/Svngoku","description":"\n\t\n\t\t\n\t\tDataset Card for xP3x Kikongo Focus\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\n\nxP3x (Crosslingual Public Pool of Prompts eXtended) is a collection of prompts & datasets across 277 languages & 16 NLP tasks. It contains all of xP3 + much more! It is used for training future contenders of mT0 & BLOOMZ at project Aya @C4AI üß°\n\n\nCreation: The dataset can be recreated using instructions available here together with the file in this repository named xp3x_create.py. We provide this version to save‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Svngoku/xP3x-Kongo.","first_N":5,"first_N_keywords":["other","translation","expert-generated","crowdsourced","multilingual"],"keywords_longer_than_N":true},
	{"name":"hello","keyword":"chamorro","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/tomorrowshipyltm/hello","creator_name":"tomorrowshipyltm","creator_url":"https://huggingface.co/tomorrowshipyltm","description":"tomorrowshipyltm/hello dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["token-classification","Chamorro","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"ParaNames","keyword":"chamorro","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/bltlab/ParaNames","creator_name":"Broadening Linguistic Technologies Lab (BLT Lab)","creator_url":"https://huggingface.co/bltlab","description":"\n\t\n\t\t\n\t\n\t\n\t\tDataset Card for Dataset Name\n\t\n\n\n\nThis dataset card aims to be a base template for new datasets. It has been generated using this raw template.\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Description\n\t\n\n\n\n\n\n\nCurated by: [More Information Needed]\nFunded by [optional]: [More Information Needed]\nShared by [optional]: [More Information Needed]\nLanguage(s) (NLP): [More Information Needed]\nLicense: [More Information Needed]\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Sources [optional]‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/bltlab/ParaNames.","first_N":5,"first_N_keywords":["token-classification","Nias","Kotava","Banjar","Angika"],"keywords_longer_than_N":true},
	{"name":"emeraldTablet","keyword":"chamorro","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/smartkit/emeraldTablet","creator_name":"yangbozhou","creator_url":"https://huggingface.co/smartkit","description":"smartkit/emeraldTablet dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["token-classification","Chamorro","Chinese","mit","< 1K"],"keywords_longer_than_N":true},
	{"name":"kao20240823","keyword":"chamorro","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/clinno/kao20240823","creator_name":"Âë®Â§ßÂèØ","creator_url":"https://huggingface.co/clinno","description":"clinno/kao20240823 dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["question-answering","Chamorro","Chinese","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"fun_rec","keyword":"chamorro","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/ykckevin/fun_rec","creator_name":"kevin","creator_url":"https://huggingface.co/ykckevin","description":"\n\t\n\t\t\n\t\tsmall demo learning how to use dataset in huggingface\n\t\n\n","first_N":5,"first_N_keywords":["token-classification","expert-generated","found","monolingual","original"],"keywords_longer_than_N":true},
	{"name":"mHumanEval-Benchmark","keyword":"chamorro","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/md-nishat-008/mHumanEval-Benchmark","creator_name":"Nishat Raihan","creator_url":"https://huggingface.co/md-nishat-008","description":"\n\n\n\t\n\t\t\n\t\tüî∑ Accepted in NAACL Proceedings (2025) üî∑\n\t\n\n\n\n\n\n  \n    \n      \n        \n          \n        \n      \n      \n        \n          \n        \n      \n      \n        \n          \n        \n      \n    \n  \n\n\n\n\n\n  \n\n\t\n\t\n\t\n\t\tmHumanEval\n\t\n\nThe mHumanEval benchmark is curated based on prompts from the original HumanEval üìö [Chen et al., 2021]. It includes a total of 33,456 prompts for Python, and 836,400 in total - significantly expanding from the original 164. \n\n\n\t\n\t\t\n\t\tQuick Start\n\t\n\n  Detailed‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/md-nishat-008/mHumanEval-Benchmark.","first_N":5,"first_N_keywords":["Afar","Abkhaz","Avestan","Afrikaans","Akan"],"keywords_longer_than_N":true},
	{"name":"piaozhu","keyword":"chamorro","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Retr01234/piaozhu","creator_name":"Chen","creator_url":"https://huggingface.co/Retr01234","description":"\n\t\n\t\t\n\t\tÊï∞ÊçÆÈõÜÂêçÁß∞ÔºöÂò¥Ëá≠Êê≠Â≠êÂæÆË∞ÉÊï∞ÊçÆÈõÜ\n\t\n\n\n\t\n\t\t\n\t\t1. Êï∞ÊçÆÈõÜÁÆÄ‰ªã\n\t\n\nËøô‰∏™Êï∞ÊçÆÈõÜ‰∏∫ÂæÆË∞ÉÂØπËØùÁîüÊàêÊ®°ÂûãÊèê‰æõ‰∫Ü‰∏Ä‰∏™ÁâπÊÆäÁöÑËÆ≠ÁªÉÊ†∑Êú¨ÔºåÂü∫‰∫é‰∏Ä‰∏™ËôöÊãüÁöÑËßíËâ≤‚ÄúÊ≤àËì¨Á´π‚ÄùËøõË°å‰∫§‰∫í„ÄÇËøô‰∏™ËßíËâ≤ÔºàÂ§ñÂè∑‚ÄúÊú¥Á´π‚ÄùÔºâÂÖ∑ÊúâÂÜ∑Âò≤ÁÉ≠ËÆΩ„ÄÅÊØíËàå„ÄÅÁÆÄÊ¥ÅËÄåÊúâÊîªÂáªÊÄßÁöÑÁâπÁÇπÔºåÈÄÇÂêàËÆ≠ÁªÉÊ®°Âûã‰∫ßÁîüÂÖ∑ÊúâËÆΩÂà∫„ÄÅÂÜ∑Âò≤ÁÉ≠ËÆΩËØ≠Ê∞îÁöÑÂõûÁ≠î„ÄÇÊï∞ÊçÆÈõÜÁöÑÂÜÖÂÆπ‰∏ªË¶ÅÊòØËßíËâ≤ÊâÆÊºîÂØπËØùÂú∫ÊôØÔºåÈÄÇÁî®‰∫éÁîüÊàêÂÖ∑ÊúâÁâπÂÆöÈ£éÊ†ºÁöÑÂØπËØùÊ®°ÂûãÔºåÁâπÂà´ÊòØÂú®Â∏¶ÊúâËÆΩÂà∫ÂíåÂπΩÈªòÁöÑÊÉÖÂ¢É‰∏ãËøõË°å‰∫íÂä®Êó∂„ÄÇ\n\n\t\n\t\t\n\t\t2. Êï∞ÊçÆÈõÜÁªìÊûÑ\n\t\n\nÊï∞ÊçÆÈõÜ‰∏∫‰∏Ä‰∏™ÂåÖÂê´Ëã•Âπ≤ÂØπËØùËΩÆÊ¨°ÁöÑ JSON Ê†ºÂºèÊñá‰ª∂„ÄÇÊØè‰∏™ÂØπËØùËΩÆÊ¨°Áî±ËßíËâ≤ÂíåÁî®Êà∑ÁöÑÂØπËØùÁªÑÊàêÔºåÊØè‰∏™ÂØπËØùÂåÖÂê´‰ª•‰∏ãÂ≠óÊÆµÔºö\n\nroleÔºöËßíËâ≤ÁöÑË∫´‰ªΩÔºåÂèØËÉΩÊòØ \"system\" Êàñ \"user\"„ÄÇ\n\"system\" Ë°®Á§∫ÊòØÊ®°ÂûãËÆæÂÆöËßíËâ≤ÁöÑËæìÂÖ•ÔºàÂ¶ÇÂÆö‰πâËßíËâ≤ËÉåÊôØ„ÄÅË°å‰∏∫Ê®°ÂºèÁ≠âÔºâ„ÄÇ\n\"user\" Ë°®Á§∫ÂØπËØù‰∏≠ÁöÑÁî®Êà∑ËæìÂÖ•ÔºàÂ¶ÇÊèêÈóÆ„ÄÅËØ∑Ê±ÇÊàñ‰∫§‰∫íÔºâ„ÄÇ\n\n\ncontentÔºöÂØπËØùÂÜÖÂÆπÔºåË°®Á§∫ËßíËâ≤ÊàñËÄÖÁî®Êà∑ÁöÑÂÖ∑‰ΩìÂèëË®Ä„ÄÇ\nloss_weightÔºàÂèØÈÄâÔºâÔºöÊØè‰∏™Êï∞ÊçÆÊù°ÁõÆÂØπÂ∫îÁöÑÊçüÂ§±ÊùÉÈáçÔºåÂΩìÂâçÂèØ‰∏∫Á©∫Êàñ‰∏∫ null„ÄÇÂèØ‰ª•Âú®Ê®°ÂûãËÆ≠ÁªÉ‰∏≠Âä†ÊùÉ‰∏çÂêåÂØπËØùÂÜÖÂÆπ„ÄÇ\n\n\n\t\n\t\t\n\t\t3. Êï∞ÊçÆÊ†∑‰æã‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Retr01234/piaozhu.","first_N":5,"first_N_keywords":["text-generation","Chamorro","Chinese","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"V1Q","keyword":"chamorro","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/YuRiVeRTi/V1Q","creator_name":"YuRiVeRTical","creator_url":"https://huggingface.co/YuRiVeRTi","description":"from datasets import load_dataset\nds = load_dataset(\"b3x0m/Chinese-H-Novels\")\nimport sagemaker\nimport boto3\nfrom sagemaker.huggingface import HuggingFaceModel\ntry:\n    role = sagemaker.get_execution_role()\nexcept ValueError:\n    iam = boto3.client('iam')\n    role = iam.get_role(RoleName='sagemaker_execution_role')['Role']['Arn']\n\n\t\n\t\t\n\t\tHub Model configuration. https://huggingface.co/models\n\t\n\nhub = {\n    'HF_MODEL_ID':'deepseek-ai/Janus-Pro-7B',\n    'HF_TASK':'any-to-any'\n}\n\n\t\n\t\t\n\t\tcreate‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/YuRiVeRTi/V1Q.","first_N":5,"first_N_keywords":["text-classification","token-classification","table-question-answering","question-answering","zero-shot-classification"],"keywords_longer_than_N":true},
	{"name":"smol","keyword":"chamorro","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/google/smol","creator_name":"Google","creator_url":"https://huggingface.co/google","description":"\n\t\n\t\t\n\t\tSMOL\n\t\n\nSMOL (Set for Maximal Overall Leverage) is a collection of professional\ntranslations into 221 Low-Resource Languages, for the purpose of training\ntranslation models, and otherwise increasing the representations of said\nlanguages in NLP and technology.\nPlease read the SMOL Paper and the\nGATITOS Paper for a much more\nthorough description!\nThere are four resources in this directory:\n\nSmolDoc: document-level translations into 100 languages\nSmolSent: sentence-level translations into‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/google/smol.","first_N":5,"first_N_keywords":["translation","Afar","Abkhaz","Achinese","Acoli"],"keywords_longer_than_N":true},
	{"name":"reranking-datasets-light","keyword":"chamorro","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/abdoelsayed/reranking-datasets-light","creator_name":"Abdelrahman Abdallah","creator_url":"https://huggingface.co/abdoelsayed","description":"\n\t\n\t\t\n\t\tüî• Rankify: A Comprehensive Python Toolkit for Retrieval, Re-Ranking, and Retrieval-Augmented Generation üî•\n\t\n\n\n\t\n\t\t\n\t\n\t\n\t\tReRanking Datasets : A comprehensive collection of retrieval and reranking datasets with full passage contexts, including titles, text, and metadata for in-depth research.\n\t\n\n\n    \n    \n    \n    \n    \n    \n        \n    \n    \n        \n    \n    \n        \n    \n    \n        \n    \n    \n    \n\n\n\nA curated collection of ready-to-use datasets for retrieval and reranking‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/abdoelsayed/reranking-datasets-light.","first_N":5,"first_N_keywords":["question-answering","English","Arabic","German","French"],"keywords_longer_than_N":true}
]
;
