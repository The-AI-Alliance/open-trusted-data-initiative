const data_for_language_pacific_kto = 
[
	{"name":"KTO-mix-14k-vietnamese-groq","keyword":"kto","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/1TuanPham/KTO-mix-14k-vietnamese-groq","creator_name":"Pham Minh Tuan","creator_url":"https://huggingface.co/1TuanPham","description":"Original dataset: https://huggingface.co/datasets/trl-lib/kto-mix-14k\nThis dataset is a KTO-formatted version of argilla/dpo-mix-7k. Please cite the original dataset if you find it useful in your work.\n\nTranslated to Vietnamese with context-aware using Groq Llama3.3 70B* via this repo:\nhttps://github.com/vTuanpham/Large_dataset_translator.\nRoughly 9 hours for 2k examples.\n\n\t\n\t\t\n\t\n\t\n\t\tUsage\n\t\n\nfrom datasets import load_dataset\n\nkto_mix_14k_vi =… See the full description on the dataset page: https://huggingface.co/datasets/1TuanPham/KTO-mix-14k-vietnamese-groq.","first_N":5,"first_N_keywords":["question-answering","text-generation","text2text-generation","Vietnamese","English"],"keywords_longer_than_N":true},
	{"name":"kto-gutenberg","keyword":"kto","license":"GNU General Public License v3.0","license_url":"https://choosealicense.com/licenses/gpl-3.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Orion-zhen/kto-gutenberg","creator_name":"Orion","creator_url":"https://huggingface.co/Orion-zhen","description":"\n\t\n\t\t\n\t\tkto-gutenberg\n\t\n\nThis dataset is a merge of jondurbin/gutenberg-dpo-v0.1 and nbeerbower/gutenberg2-dpo.\nThe dataset is designed for kto training.\n","first_N":5,"first_N_keywords":["text-generation","English","gpl-3.0","1K - 10K","json"],"keywords_longer_than_N":true},
	{"name":"ultrafeedback-binarized-preferences-cleaned-kto","keyword":"kto","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/argilla/ultrafeedback-binarized-preferences-cleaned-kto","creator_name":"Argilla","creator_url":"https://huggingface.co/argilla","description":"\n\t\n\t\t\n\t\tUltraFeedback - Binarized using the Average of Preference Ratings (Cleaned) KTO\n\t\n\n\nA KTO signal transformed version of the highly loved UltraFeedback Binarized Preferences Cleaned, the preferred dataset by Argilla to use from now on when fine-tuning on UltraFeedback\n\nThis dataset represents a new iteration on top of argilla/ultrafeedback-binarized-preferences,\nand is the recommended and preferred dataset by Argilla to use from now on when fine-tuning on UltraFeedback.\nRead more about… See the full description on the dataset page: https://huggingface.co/datasets/argilla/ultrafeedback-binarized-preferences-cleaned-kto.","first_N":5,"first_N_keywords":["text-generation","English","mit","100K - 1M","parquet"],"keywords_longer_than_N":true},
	{"name":"distilabel-intel-orca-kto","keyword":"kto","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/argilla/distilabel-intel-orca-kto","creator_name":"Argilla","creator_url":"https://huggingface.co/argilla","description":"\n  \n    \n  \n\n\n\n\t\n\t\t\n\t\tdistilabel Orca Pairs for KTO\n\t\n\n\nA KTO signal transformed version of the highly loved distilabel Orca Pairs for DPO.\n\nThe dataset is a \"distilabeled\" version of the widely used dataset: Intel/orca_dpo_pairs. The original dataset has been used by 100s of open-source practitioners and models. We knew from fixing UltraFeedback (and before that, Alpacas and Dollys) that this dataset could be highly improved.\nContinuing with our mission to build the best alignment datasets… See the full description on the dataset page: https://huggingface.co/datasets/argilla/distilabel-intel-orca-kto.","first_N":5,"first_N_keywords":["English","apache-2.0","10K - 100K","parquet","Text"],"keywords_longer_than_N":true},
	{"name":"distilabel-capybara-kto-15k-binarized","keyword":"kto","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/argilla/distilabel-capybara-kto-15k-binarized","creator_name":"Argilla","creator_url":"https://huggingface.co/argilla","description":"\n\t\n\t\t\n\t\tCapybara-KTO 15K binarized\n\t\n\n\nA KTO signal transformed version of the highly loved Capybara-DPO 7K binarized, A DPO dataset built with distilabel atop the awesome LDJnr/Capybara\n\n\nThis is a preview version to collect feedback from the community. v2 will include the full base dataset and responses from more powerful models.\n\n\n    \n\n\n\n  \n    \n\t\n\t\t\n\t\tWhy KTO?\n\t\n\nThe KTO paper states:\n\nKTO matches or exceeds DPO performance at scales from 1B to 30B parameters.1 That is, taking a… See the full description on the dataset page: https://huggingface.co/datasets/argilla/distilabel-capybara-kto-15k-binarized.","first_N":5,"first_N_keywords":["question-answering","text-generation","English","apache-2.0","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"kto-mix-15k","keyword":"kto","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/argilla/kto-mix-15k","creator_name":"Argilla","creator_url":"https://huggingface.co/argilla","description":"\n\t\n\t\t\n\t\tArgilla KTO Mix 15K Dataset\n\t\n\n\nA KTO signal transformed version of the highly loved Argilla DPO Mix, which is small cocktail combining DPO datasets built by Argilla with distilabel. The goal of this dataset is having a small, high-quality KTO dataset by filtering only highly rated chosen responses. \n\n\n    \n\n\n\n\n  \n    \n  \n\n\n\n\t\n\t\n\t\n\t\tWhy KTO?\n\t\n\nThe KTO paper states:\n\nKTO matches or exceeds DPO performance at scales from 1B to 30B parameters.1 That is, taking a preference dataset of n… See the full description on the dataset page: https://huggingface.co/datasets/argilla/kto-mix-15k.","first_N":5,"first_N_keywords":["English","mit","10K - 100K","parquet","Text"],"keywords_longer_than_N":true}
]
;
