var data_for_chinese = 
[
	{"name":"CoT_reformatted","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/jtatman/CoT_reformatted","creator_name":"James","creator_url":"https://huggingface.co/jtatman","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for \\\"CoT_reformatted\\\"\\n\\t\\n\\nThis dataset is reformatted from: QingyiSi/Alpaca-CoT\\nAll credit goes there. Thanks to QingyiSi for the work in consolidating many diverse sources for comparison and cross-file analysis.\\nThere were some issues loading files from that dataset for a testing project. \\nI extracted the following data files for this subset:\\n\\nalpaca_data_cleaned\\nCoT_data\\nfirefly       \\ninstruct\\nalpaca_gpt4_data\\ndolly \\nGPTeacher\\nthoughtsource\\nfinance_en\\ninstinwild_en\\n\\n"},
	{"name":"ALMA-R-Preference","keyword":"chinese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/haoranxu/ALMA-R-Preference","creator_name":"Haoran Xu","creator_url":"https://huggingface.co/haoranxu","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for \\\"ALMA-R-Preference\\\"\\n\\t\\n\\nThis is triplet preference data used by ALMA-R model.\\nThe triplet preference data, supporting 10 translation directions, is built upon the FLORES-200 development and test data. For each direction, we provide a source sentence along with three translations: one from GPT-4, another from ALMA-13B-LoRA, and a reference translation. For instance, in the English-German pair, our data structure is as follows:\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSentences:\\n\\t\\n\\n\\nde: Original… See the full description on the dataset page: https://huggingface.co/datasets/haoranxu/ALMA-R-Preference."},
	{"name":"Kanami_Dataset","keyword":"chinese","license":"GNU Affero General Public License v3.0","license_url":"https://choosealicense.com/licenses/agpl-3.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Holmuium97/Kanami_Dataset","creator_name":"Holmuium97","creator_url":"https://huggingface.co/Holmuium97","description":"香奈美训练语音数据集（仅公测前的语音）\\nP.S\\n  1、数据集语音仅通过游戏内获取，一切版权归深圳市创梦天地科技有限公司所有\\n  2、音频仅进行简单的自动切片，可能存在断句不合理的情况，建议试听做下筛选\\n  3、禁止使用该数据集进行一切以违法为目的的活动\\n"},
	{"name":"mittens","keyword":"chinese","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/google/mittens","creator_name":"Google","creator_url":"https://huggingface.co/google","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tMiTTenS: A Dataset for Evaluating Misgendering in Translation\\n\\t\\n\\nMisgendering is the act of referring to someone in a way that does not reflect their gender identity.  Translation systems, including foundation models capable of translation, can produce errors that result in misgendering harms. To measure the extent of such potential harms when translating into and out of English, we introduce a dataset, MiTTenS, covering 26 languages from a variety of language families and scripts… See the full description on the dataset page: https://huggingface.co/datasets/google/mittens."},
	{"name":"TCM_Humanities","keyword":"chinese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/TCMLM/TCM_Humanities","creator_name":" ","creator_url":"https://huggingface.co/TCMLM","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for [TCMLM/TCM_Humanities]\\n\\t\\n\\n\\n\\nThis dataset, curated by the Traditional Chinese Medicine Language Model Team, comprises a comprehensive collection of multiple-choice questions (both single and multiple answers) from the Chinese Medical Practitioner Examination. It's designed to aid in understanding and assessing knowledge in Chinese humanities medicine, medical ethics, and legal regulations for physicians.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Details\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tUses… See the full description on the dataset page: https://huggingface.co/datasets/TCMLM/TCM_Humanities."},
	{"name":"panlex","keyword":"chinese","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/lbourdois/panlex","creator_name":"Loïck BOURDOIS","creator_url":"https://huggingface.co/lbourdois","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tPanLex\\n\\t\\n\\nJanuary 1, 2024 version of PanLex Language Vocabulary with 24,650,274 rows covering 6,152 languages.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tColumns\\n\\t\\n\\n\\nvocab: contains the text entry.  \\n639-3: contains the ISO 639-3 languages tags to allow users to filter on the language(s) of their choice.\\n639-3_english_name: the English language name associated to the code ISO 639-3. \\nvar_code: contains a code to differentiate language variants. In practice, this is the code 639-3 + a number.  If 000, it… See the full description on the dataset page: https://huggingface.co/datasets/lbourdois/panlex."},
	{"name":"Haruhi-Dialogue-Speaker-Extract","keyword":"chinese","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/silk-road/Haruhi-Dialogue-Speaker-Extract","creator_name":"SilkRoad","creator_url":"https://huggingface.co/silk-road","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tChat凉宫春日的对话抽取模型\\n\\t\\n\\n我们希望有一个模型能够从小说的chunk中批量去提取摘要和对话\\n这个模型就是实现了这一点。模型使用了大约30k的中文小说数据和20k的英文小说数据进行训练，在qwen-1.8上进行了3个epoch的finetune。 原则上模型同时支持中文和英文小说的训练\\n主项目链接 https://github.com/LC1332/Chat-Haruhi-Suzumiya\\n\\n李鲁鲁完成了数据的收集，以及进一步将inference程序扩展到连续的chunks\\n刘崇寒完成了模型的训练\\n米唯实测试并上传模型到hugging face\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tChat Haruhi Suzumiya's Dialogue Extraction Model\\n\\t\\n\\nWe hope to have a model that can extract summaries and dialogues in batches from chunks of novels.\\nThis model achieves just that. It was… See the full description on the dataset page: https://huggingface.co/datasets/silk-road/Haruhi-Dialogue-Speaker-Extract."},
	{"name":"spam-douban-movie-review","keyword":"chinese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/tracywong117/spam-douban-movie-review","creator_name":"Wong Wing Yan","creator_url":"https://huggingface.co/tracywong117","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDescription\\n\\t\\n\\nThe Spam Douban Movie Reviews Dataset is a collection of movie reviews scraped from Douban, a popular Chinese social networking platform for movie enthusiasts. This dataset consists of reviews that have been manually classified as either spam or genuine by human reviewers. It contains a total of 1,600 data. \\nThis dataset is created for our project Spam Movie Reviews Detection through Supervised Learning.\\n"},
	{"name":"retrieval_data_llm","keyword":"chinese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/infgrad/retrieval_data_llm","creator_name":"infgrad","creator_url":"https://huggingface.co/infgrad","description":"带有难负例的检索训练数据。约20万。\\n文件格式：jsonl。单行示例：\\n{\\\"Query\\\": \\\"大熊猫的饮食习性\\\", \\\"Positive Document\\\": \\\"大熊猫主要以竹子为食，但也会吃水果和小型动物。它们拥有强壮的颌部和牙齿，能够咬碎竹子坚硬的外壳。\\\", \\\"Hard Negative Document\\\": \\\"老虎是肉食性动物，主要捕食鹿、野猪等大型动物。它们的牙齿和爪子非常锋利，是捕猎的利器。\\\"}\\n\\n"},
	{"name":"ChatML-aya_dataset","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Felladrin/ChatML-aya_dataset","creator_name":"Victor Nogueira","creator_url":"https://huggingface.co/Felladrin","description":"CohereForAI/aya_dataset in ChatML format, ready to use in HuggingFace TRL's SFT Trainer.\\nPython code used for conversion:\\nfrom datasets import load_dataset\\nfrom transformers import AutoTokenizer\\n\\ntokenizer = AutoTokenizer.from_pretrained(\\\"Felladrin/Llama-160M-Chat-v1\\\")\\n\\ndataset = load_dataset(\\\"CohereForAI/aya_dataset\\\", split=\\\"train\\\")\\n\\ndef format(columns):\\n    messages = [\\n        {\\n            \\\"role\\\": \\\"user\\\",\\n            \\\"content\\\": columns[\\\"inputs\\\"].strip(),\\n        },\\n        {… See the full description on the dataset page: https://huggingface.co/datasets/Felladrin/ChatML-aya_dataset."},
	{"name":"cifar10","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ahsxxia/cifar10","creator_name":"han","creator_url":"https://huggingface.co/ahsxxia","description":"ahsxxia/cifar10 dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"UHGEvalDataset","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Ki-Seki/UHGEvalDataset","creator_name":"Shichao Song","creator_url":"https://huggingface.co/Ki-Seki","description":"The dataset sourced from https://github.com/IAAR-Shanghai/UHGEval\\n"},
	{"name":"Traditional_Chinese-aya_dataset","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Heng666/Traditional_Chinese-aya_dataset","creator_name":"Heng-Shiou Sheu | 許恆修","creator_url":"https://huggingface.co/Heng666","description":"\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\t資料集描述\\n\\t\\n\\n繁體中文 Aya (Traditional Chinese Aya Chinese;TCA)：專注於繁體中文處理的 Aya 集合的精選子集\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\t概述\\n\\t\\n\\n繁體中文 Aya 是一個精心策劃的資料集，源自 CohereForAI 的綜合 Aya 集合，特別關注繁體中文文本資料。\\n此資料集結合了來自 CohereForAI/aya_dataset，過濾掉除繁體中文、簡體中文內容之外的所有內容。\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\t目標\\n\\t\\n\\n繁體中文 Aya 的目標是為研究人員、技術專家和語言學家提供即用型繁體中文文本資源，顯著減少專注於繁體中文的 NLP 和 AI 專案中數據預處理所需的時間和精力。\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\t資料集來源與資訊\\n\\t\\n\\n\\n資料來源: 從 CohereForAI/aya_dataset 2 個子集而來。\\n語言: 繁體中文、簡體中文（'zho')\\n應用: 非常適合語言建模、文本分類、情感分析、和機器翻譯等任務。\\n論文連結: 2402.06619\\n維護人: Heng666\\nLicense:… See the full description on the dataset page: https://huggingface.co/datasets/Heng666/Traditional_Chinese-aya_dataset."},
	{"name":"Traditional_Chinese-aya_evaluation_suite","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Heng666/Traditional_Chinese-aya_evaluation_suite","creator_name":"Heng-Shiou Sheu | 許恆修","creator_url":"https://huggingface.co/Heng666","description":"\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\t資料集描述\\n\\t\\n\\n繁體中文 Aya (Traditional Chinese Aya Chinese;TCA)：專注於繁體中文處理的 Aya 集合的精選子集\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\t概述\\n\\t\\n\\n繁體中文 Aya 是一個精心策劃的資料集，源自 CohereForAI 的綜合 Aya 集合，特別關注繁體中文文本資料。\\n此資料集結合了來自 CohereForAI/aya_evaluation_suite，過濾掉除繁體中文、簡體中文內容之外的所有內容。\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\t目標\\n\\t\\n\\n繁體中文 Aya 的目標是為研究人員、技術專家和語言學家提供即用型繁體中文文本資源，顯著減少專注於繁體中文的 NLP 和 AI 專案中數據預處理所需的時間和精力。\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\t資料集來源與資訊\\n\\t\\n\\n\\n資料來源: 從 CohereForAI/aya_evaluation_suite 3 個子集而來。\\n語言: 繁體中文、簡體中文（'zho')\\n應用: 非常適合語言建模、文本分類、情感分析、和機器翻譯等任務。\\n論文連結: 2402.06619\\n維護人: Heng666… See the full description on the dataset page: https://huggingface.co/datasets/Heng666/Traditional_Chinese-aya_evaluation_suite."},
	{"name":"eagle","keyword":"chinese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/MasahiroKaneko/eagle","creator_name":"Masahiro Kaneko","creator_url":"https://huggingface.co/MasahiroKaneko","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tEagle 🦅: Ethical Dataset Given from Real Interactions\\n\\t\\n\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tIntroduction\\n\\t\\n\\nThis repository contains the Eagle dataset, which is an ethical dataset of real interactions between humans and ChatGPT. This dataset is created to evaluate social bias, opinion bias, toxic language, and morality in Large Language Models (LLMs).\\nIf you use the Eagle dataset in your research, please cite the following:\\n@inproceedings{Eagle:arxiv:2024,\\n    title={Eagle: Ethical Dataset Given from… See the full description on the dataset page: https://huggingface.co/datasets/MasahiroKaneko/eagle."},
	{"name":"UltraLink","keyword":"chinese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/R0k1e/UltraLink","creator_name":"Haoyu Wang","creator_url":"https://huggingface.co/R0k1e","description":"\\n\\n\\nmulti-lingual, knowledge-grounded, multi-round dialogue dataset and model\\n\\n  Summary  •\\n Construction Process •\\n Paper •\\n  UltraLink-LM •\\n  Github\\n\\n\\n\\n\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for UltraLink\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nUltraLink is a multi-lingual, knowledge-grounded data augmented, multi-round dialogue dataset. It contains language-specific chat data, language-agnostic chat data, code data and math data in 5 languages: English, Chinese, Spanish, Russian, and French. Different from… See the full description on the dataset page: https://huggingface.co/datasets/R0k1e/UltraLink."},
	{"name":"webcpm_oe","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/forag/webcpm_oe","creator_name":"FoRAG","creator_url":"https://huggingface.co/forag","description":"forag/webcpm_oe dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"alyx-vance-audio-dataset","keyword":"chinese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Atopona-Organization/alyx-vance-audio-dataset","creator_name":"Atopona-Organization","creator_url":"https://huggingface.co/Atopona-Organization","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\talyx-vance-audio-dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tAlyx Vance（半条命2）音频数据集\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\t制作：Atopona\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\t注意\\n\\t\\n\\n1、数据集均取自对应人物视频切片，声音版权归属于对应人物，早期质量一坨的就没上传；\\n2、音频仅进行分离人声及自动切片，未进行精选，请下载进行抽选试听后再考虑是否使用（弃用音频在手工标注时进行了跳过）；\\n3、手工标注文件随机掉落（手工标注无法保证每一句都标的很标准，可以自行检查）；\\n4、请在法律允许范围内进行测试使用！使用本数据集产生问题请自行承担！\\n5、github仓库的话数据集在 Releases 中\\n"},
	{"name":"CPsyCoun","keyword":"chinese","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/CAS-SIAT-XinHai/CPsyCoun","creator_name":"CAS-SIAT-XinHai","creator_url":"https://huggingface.co/CAS-SIAT-XinHai","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tCPsyCounD\\n\\t\\n\\nThe high-quality multi-turn dialogue dataset, which has a total of 3,134 multi-turn consultation dialogues. CPsyCounD covers nine representative topics and seven classic schools of psychological counseling.\\nPaper: CPsyCoun\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData analysis\\n\\t\\n\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tTopic types\\n\\t\\n\\n\\nSelf-growth\\nEmotion&Stress\\nEducation\\nLove&Marriage\\nFamily Relationship\\nSocial Relationship\\nSex\\nCareer\\nMental Disease\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tConsulting schools\\n\\t\\n\\n\\nPsychoanalytic Therapy\\nCognitive… See the full description on the dataset page: https://huggingface.co/datasets/CAS-SIAT-XinHai/CPsyCoun."},
	{"name":"CMMU","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/BAAI/CMMU","creator_name":"Beijing Academy of Artificial Intelligence","creator_url":"https://huggingface.co/BAAI","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tCMMU\\n\\t\\n\\n📖 Paper | 🤗 Dataset | GitHub\\nThis repo contains the evaluation code for the paper CMMU: A Benchmark for Chinese Multi-modal Multi-type Question Understanding and Reasoning .\\nWe release the validation set of CMMU, you can download it from here. The test set will be hosted on the flageval platform. Users can test by uploading their models.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tIntroduction\\n\\t\\n\\nCMMU is a novel multi-modal benchmark designed to evaluate domain-specific knowledge across seven… See the full description on the dataset page: https://huggingface.co/datasets/BAAI/CMMU."},
	{"name":"wikisource_tw","keyword":"chinese","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/jslin09/wikisource_tw","creator_name":"Chun-Hsien Lin","creator_url":"https://huggingface.co/jslin09","description":"本資料集是解析自維基文庫於 20240120 發布的打包檔 bz2 檔案的內容，在解析出所需內容後，利用 wikitextparser 移除 Wiki 標記。解析後保留的欄位有兩個：條目名稱（title），條目內容（page article）。\\n原始的打包檔條目內容簡繁混雜，所以有利用 OpenCC 進行簡轉繁處理。\\n\\n原始總條目數: 1,057,179 條目。\\n全部 1,057,179 個條目標題。\\n全部 1,057,179 個條目內容。\\n無法自動去標記的條目數: 166\\n有內容的條目數: 1,057,179\\n\\n因為本資料集內容龐大，要塞進一般的個人電腦中進行計算，恐怕會有資源不足的情形。建議使用parquet格式下載使用。\\n資料集當中有不少內容為「#REDIRECT」或是「#重定向」的條目，就等以後有空推出修正版再來清洗了。\\n"},
	{"name":"X-SVAMP_en_zh_ko_it_es","keyword":"chinese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/zhihz0535/X-SVAMP_en_zh_ko_it_es","creator_name":"Zhihan Zhang","creator_url":"https://huggingface.co/zhihz0535","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tX-SVAMP\\n\\t\\n\\n🤗 Paper | 📖 arXiv\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nX-SVAMP is an evaluation benchmark for multilingual large language models (LLMs), including questions and answers in 5 languages (English, Chinese, Korean, Italian and Spanish).\\nIt is intended to evaluate the math reasoning abilities of LLMs. The dataset is translated by GPT-4-turbo from the original English-version SVAMP.\\nIn our paper, we evaluate LLMs in a zero-shot generative setting: prompt the instruction-tuned… See the full description on the dataset page: https://huggingface.co/datasets/zhihz0535/X-SVAMP_en_zh_ko_it_es."},
	{"name":"X-TruthfulQA_en_zh_ko_it_es","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/zhihz0535/X-TruthfulQA_en_zh_ko_it_es","creator_name":"Zhihan Zhang","creator_url":"https://huggingface.co/zhihz0535","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tX-TruthfulQA\\n\\t\\n\\n🤗 Paper | 📖 arXiv\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nX-TruthfulQA is an evaluation benchmark for multilingual large language models (LLMs), including questions and answers in 5 languages (English, Chinese, Korean, Italian and Spanish).\\nIt is intended to evaluate the truthfulness of LLMs. The dataset is translated by GPT-4 from the original English-version TruthfulQA.\\nIn our paper, we evaluate LLMs in a zero-shot generative setting: prompt the instruction-tuned LLM… See the full description on the dataset page: https://huggingface.co/datasets/zhihz0535/X-TruthfulQA_en_zh_ko_it_es."},
	{"name":"unalignment-toxic-dpo-v0.2-zh_cn","keyword":"chinese","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/tastypear/unalignment-toxic-dpo-v0.2-zh_cn","creator_name":"tastypear","creator_url":"https://huggingface.co/tastypear","description":"数据集 unalignment/toxic-dpo-v0.2 的中英文对照版本。\\n这是一个高度有害的数据集，旨在通过很少的示例来说明如何使用 DPO 轻松地对模型进行去审查/取消对齐。\\n这份对照版本的中文来自多个不同模型的意译。转换的过程中，模型被允许对结果进行演绎以求通顺，无法对结果的准确性作任何保证。\\n使用限制请参照原数据集的 Usage restriction。\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tOriginal Dataset Description:\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tToxic-DPO\\n\\t\\n\\nThis is a highly toxic, \\\"harmful\\\" dataset meant to illustrate how DPO can be used to de-censor/unalign a model quite easily using direct-preference-optimization (DPO) using very few examples.\\nMany of the examples still contain some amount of… See the full description on the dataset page: https://huggingface.co/datasets/tastypear/unalignment-toxic-dpo-v0.2-zh_cn."},
	{"name":"test","keyword":"chinese","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/francoj/test","creator_name":"johnfranco","creator_url":"https://huggingface.co/francoj","description":"\\n\\t\\n\\t\\t\\n\\t\\tDataset Card for Dataset Name\\n\\t\\n\\n\\n\\nThis dataset card aims to be a base template for new datasets. It has been generated using this raw template.\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Details\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\n\\n\\n\\n\\n\\nCurated by: [More Information Needed]\\nFunded by [optional]: [More Information Needed]\\nShared by [optional]: [More Information Needed]\\nLanguage(s) (NLP): [More Information Needed]\\nLicense: [More Information Needed]\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Sources [optional]\\n\\t\\n\\n\\n\\n\\nRepository: [More… See the full description on the dataset page: https://huggingface.co/datasets/francoj/test."},
	{"name":"MAGBIG","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/felfri/MAGBIG","creator_name":"Felix Friedrich","creator_url":"https://huggingface.co/felfri","description":"\\n\\t\\n\\t\\t\\n\\t\\tMAGBIG benchmark\\n\\t\\n\\nThis is the MAGBIG benchmark proposed in https://arxiv.org/abs/2401.16092\\nThis benchmark is intended for multilingual text-to-image models. With MAGBIG, you can generate images for a diverse set of prompts across ten different languages. These images can be evaluated for differences across languages. MAGBIG is designed to uncover and assess biases across languages such as gender, race, age, etc. This way, we can measure whether bias exists in a language, but also if… See the full description on the dataset page: https://huggingface.co/datasets/felfri/MAGBIG."},
	{"name":"test","keyword":"chinese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/ErikQQY/test","creator_name":"QingyuQu","creator_url":"https://huggingface.co/ErikQQY","description":"ErikQQY/test dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"sounds","keyword":"chinese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/mozi1924/sounds","creator_name":"Mozi","creator_url":"https://huggingface.co/mozi1924","description":"mozi1924/sounds dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"SeaExam","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/SeaLLMs/SeaExam","creator_name":"SeaLLMs - Language Models for Southeast Asian Languages","creator_url":"https://huggingface.co/SeaLLMs","description":"\\nCheck the 🏆 leaderboard constructed with this dataset and the corresponding 👨🏻‍💻 evaluation code.\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSeaExam dataset\\n\\t\\n\\nThe SeaExam dataset aims to evaluate Large Language Models (LLMs) on a diverse set of Southeast Asian (SEA) languages including English, Chinese, Indonesian, Thai, and Vietnamese. \\nOur goal is to ensure a fair and consistent comparison across different LLMs on those languages while mitigating the risk of data contamination. \\nIt consists of the following two… See the full description on the dataset page: https://huggingface.co/datasets/SeaLLMs/SeaExam."},
	{"name":"ChartSE","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/kppkkp/ChartSE","creator_name":"Lingyu Kong","creator_url":"https://huggingface.co/kppkkp","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tUse Guide\\n\\t\\n\\n\\nunzip imgs.zip in this folder. Except for PlotQA-test, all other images are already included here. \\nDue to the large number of images in PlotQA-test, if you need them, please download them from the link and place them in the imgs/PlotQA-test folder.\\nEvaluate code is here: Github-OneChart\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tAcknowledgement\\n\\t\\n\\nImage Source\\n\\nChartQA-test: https://github.com/vis-nlp/ChartQA\\nPlotQA-test: https://github.com/NiteshMethani/PlotQA\\nChartX-SE:… See the full description on the dataset page: https://huggingface.co/datasets/kppkkp/ChartSE."},
	{"name":"MMedBench","keyword":"chinese","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/aisc-team-c2/MMedBench","creator_name":"AISC Team C2","creator_url":"https://huggingface.co/aisc-team-c2","description":"This is a dataset repository made for the AISC class at Harvard Medical School. Please find the original dataset repository here: https://huggingface.co/datasets/Henrychur/MMedBench \\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tMMedBench\\n\\t\\n\\n💻Github Repo   🖨️arXiv Paper\\nThe official benchmark for \\\"Towards Building Multilingual Language Model for Medicine\\\".\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tIntroduction\\n\\t\\n\\nThis repo contains MMedBench, a comprehensive multilingual medical benchmark comprising 45,048 QA pairs for training and 8,518 QA pairs for… See the full description on the dataset page: https://huggingface.co/datasets/aisc-team-c2/MMedBench."},
	{"name":"yue-truthy","keyword":"chinese","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/hon9kon9ize/yue-truthy","creator_name":"hon9kon9ize","creator_url":"https://huggingface.co/hon9kon9ize","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tCantonese Truthy DPO\\n\\t\\n\\nThis dataset is a Cantonese and Simplified Chinese translation of jondurbin/truthy-dpo-v0.1. For more detailed information about the original dataset, please refer to the provided link.\\nThis dataset is translated by Gemini Pro and has not undergone any manual verification. The content may be inaccurate or misleading. please keep this in mind when using this dataset.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLicense\\n\\t\\n\\nThis dataset is provided under the same license as the original… See the full description on the dataset page: https://huggingface.co/datasets/hon9kon9ize/yue-truthy."},
	{"name":"mtmc-rlhf","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/quanshr/mtmc-rlhf","creator_name":"Shanghaoran Quan","creator_url":"https://huggingface.co/quanshr","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tmtmc-rlhf\\n\\t\\n\\nThe mtmc-rlhf (multi-task multi-capability rlhf) dataset is in Chinese and consists primarily of text prompts submitted to a large language model API, enriched by a small portion of prompts crafted by our annotators. \\nEach sample in the dataset represents a multi-turn session between a user and the language model with a category label. The final query within the session has several distinct responses as well as their corresponding preference rank sorted by annotators.… See the full description on the dataset page: https://huggingface.co/datasets/quanshr/mtmc-rlhf."},
	{"name":"MD2T","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/YunxinLi/MD2T","creator_name":"Yunxin Li","creator_url":"https://huggingface.co/YunxinLi","description":"MD2T is a new setting for multimodal E-commerce Description generation based on structured keywords and images.\\nOur paper (LREC-COLING 2024): A Multimodal In-Context Tuning Approach for E-Commerce Product Description Generation.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tMD2T Dataset Statistics\\n\\t\\n\\n\\n\\t\\n\\t\\t\\nMD2T\\nCases&Bags\\nClothing\\nHome Appliances\\n\\n\\n\\t\\t\\n#Train\\n18,711\\n200,000\\n86,858\\n\\n\\n#Dev\\n983\\n6,120\\n1,794\\n\\n\\n#Test\\n1,000\\n8,700\\n2,200\\n\\n\\nAvg_N #MP\\n5.41\\n6.57\\n5.48\\n\\n\\nAvg_L #MP\\n13.50\\n20.34\\n18.30\\n\\n\\nAvg_L #Desp\\n80.05\\n79.03\\n80.13\\n\\n\\n\\t\\n\\nTable… See the full description on the dataset page: https://huggingface.co/datasets/YunxinLi/MD2T."},
	{"name":"CIMD","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/jingzi/CIMD","creator_name":"Jing Zhao","creator_url":"https://huggingface.co/jingzi","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tChinese Instruction Multimodal Data (CIMD)\\n\\t\\n\\nThe dataset contains one million Chinese image-text pairs in total, including detailed image captioning and visual question answering.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tGeneration Pipeline\\n\\t\\n\\n\\nImage source\\nWe randomly sample images from two opensource datasets Wanjuan and Wukong\\n\\nDetailed caption generation\\nWe use Gemini Pro Vision API to generate a detailed description for each image. \\n\\nQuestion-answer pairs generation \\nBased on the generated caption, we… See the full description on the dataset page: https://huggingface.co/datasets/jingzi/CIMD."},
	{"name":"blossom-math-v4","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Azure99/blossom-math-v4","creator_name":"Azure99","creator_url":"https://huggingface.co/Azure99","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tBLOSSOM MATH V4\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\t介绍\\n\\t\\n\\nBlossom Math V4是基于Math23K和GSM8K衍生而来的中英双语数学对话数据集，适用于数学问题微调。\\n相比于blossom-math-v3，本版本完全使用GPT-4进行蒸馏，大幅提升了推理的一致性。\\n本数据集采用全量Math23K、GSM8K和翻译后的GSM8K的问题，随后调用gpt-4-0125-preview生成结果，并使用原始数据集中的答案对生成的结果进行验证，过滤掉错误答案，很大程度上保证了问题和答案的准确性。\\n本次发布了全量数据的25%，包含10K记录。\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\t语言\\n\\t\\n\\n中文和英文\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\t数据集结构\\n\\t\\n\\n每条数据代表一个完整的题目及答案，包含id、input、output、answer、dataset四个字段。\\n\\nid：字符串，代表原始数据集中的题目id，与dataset字段结合可确定唯一题目。\\ninput：字符串，代表问题。\\noutput：字符串，代表gpt-4-0125-preview生成的答案。… See the full description on the dataset page: https://huggingface.co/datasets/Azure99/blossom-math-v4."},
	{"name":"llm-latent-language","keyword":"chinese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/wendlerc/llm-latent-language","creator_name":"Chris Wendler","creator_url":"https://huggingface.co/wendlerc","description":"Latents computed using meta-llama/Llama-2-7b-hf, meta-llama/Llama-2-13b-hf, meta-llama/Llama-2-70b-hf\\n"},
	{"name":"OpsEval","keyword":"chinese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Junetheriver/OpsEval","creator_name":"Liu Yuhe","creator_url":"https://huggingface.co/Junetheriver","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tOpsEval Dataset\\n\\t\\n\\nWebsite | Reporting Issues\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tIntroduction\\n\\t\\n\\nThe OpsEval dataset represents a pioneering effort in the evaluation of Artificial Intelligence for IT Operations (AIOps), focusing on the application of Large Language Models (LLMs) within this domain. In an era where IT operations are increasingly reliant on AI technologies for automation and efficiency, understanding the performance of LLMs in operational tasks becomes crucial. OpsEval offers a… See the full description on the dataset page: https://huggingface.co/datasets/Junetheriver/OpsEval."},
	{"name":"cmex-intros","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/neednear-cmex/cmex-intros","creator_name":"neednear-cmex","creator_url":"https://huggingface.co/neednear-cmex","description":"neednear-cmex/cmex-intros dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"yue-math-preference","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/hon9kon9ize/yue-math-preference","creator_name":"hon9kon9ize","creator_url":"https://huggingface.co/hon9kon9ize","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tCantonese Math Preference\\n\\t\\n\\nThis dataset is a Cantonese and Simplified Chinese translation of argilla/distilabel-math-preference-dpo. For more detailed information about the original dataset, please refer to the provided link.\\nThis dataset is translated by Gemini Pro and has not undergone any manual verification. The content may be inaccurate or misleading. please keep this in mind when using this dataset.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLicense\\n\\t\\n\\nThis dataset is provided under the same license as… See the full description on the dataset page: https://huggingface.co/datasets/hon9kon9ize/yue-math-preference."},
	{"name":"blossom-chat-v3","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Azure99/blossom-chat-v3","creator_name":"Azure99","creator_url":"https://huggingface.co/Azure99","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tBLOSSOM CHAT V3\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\t介绍\\n\\t\\n\\nBlossom Chat V3是基于ShareGPT 90K衍生而来的中英双语对话数据集，适用于多轮对话微调。\\n相比于blossom-chat-v2，本版本完全使用GPT-4进行蒸馏\\n本数据集抽取了ShareGPT的多轮对话指令，仅将指令进行翻译，随后使用多轮指令迭代调用gpt-4-0125-preview。\\n相比原始的ShareGPT数据，主要解决了中文对话数据量较少，以及由ChatGPT生成长度限制而导致的输出截断问题。\\n本次发布了全量数据的50%，包含5K记录。\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\t语言\\n\\t\\n\\n以中文和英文为主，中英文数据按照约1:1的比例混合。\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\t数据集结构\\n\\t\\n\\n每条数据代表一个完整的多轮对话，包含id和conversations两个字段。\\n\\nid：从1递增。\\nconversations：对象数组，每个对象包含role、content两个字段，role的取值为user或assistant，分别代表用户输入和助手输出，content则为对应的内容。… See the full description on the dataset page: https://huggingface.co/datasets/Azure99/blossom-chat-v3."},
	{"name":"blossom-orca-v3","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Azure99/blossom-orca-v3","creator_name":"Azure99","creator_url":"https://huggingface.co/Azure99","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tBLOSSOM ORCA V3\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\t介绍\\n\\t\\n\\nBlossom Orca V3是一个基于OpenOrca衍生而来的中英双语指令数据集，适用于指令微调。\\n相比于blossom-wizard-v2，本版本完全使用GPT-4进行蒸馏。\\n本数据集从OpenOrca中抽取了系统提示和指令，首先将其翻译为中文并校验翻译结果，再使用指令调用gpt-4-0125-preview模型生成响应，并过滤掉包含自我认知以及拒绝回答的响应，以便后续对齐。此外，为了确保响应风格的一致性以及中英数据配比，本数据集还对未翻译的原始指令也进行了相同的调用，最终得到了1:1的中英双语指令数据。\\n相比直接对原始OpenOrca进行翻译的中文数据集，Blossom Orca的一致性及质量更高。\\n本次发布了全量数据的50%，包含中英双语各20K，共计40K记录。\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\t语言\\n\\t\\n\\n以中文和英文为主。\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\t数据集结构\\n\\t\\n\\n每条数据代表一个完整的对话，包含id和conversations两个字段。\\n\\nid：从1递增。… See the full description on the dataset page: https://huggingface.co/datasets/Azure99/blossom-orca-v3."},
	{"name":"blossom-wizard-v3","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Azure99/blossom-wizard-v3","creator_name":"Azure99","creator_url":"https://huggingface.co/Azure99","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tBLOSSOM WIZARD V3\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\t介绍\\n\\t\\n\\nBlossom Wizard V3是一个基于WizardLM_evol_instruct_V2衍生而来的中英双语指令数据集，适用于指令微调。\\n相比于blossom-wizard-v2，本版本完全使用GPT-4进行蒸馏。\\n本数据集从WizardLM_evol_instruct_V2中抽取了指令，首先将其翻译为中文并校验翻译结果，再使用指令调用gpt-4-0125-preview模型生成响应，并过滤掉包含自我认知以及拒绝回答的响应，以便后续对齐。此外，为了确保响应风格的一致性以及中英数据配比，本数据集还对未翻译的原始指令也进行了相同的调用，最终得到了1:1的中英双语指令数据。\\n相比直接对原始Wizard进行翻译的中文数据集，Blossom Wizard的一致性及质量更高。\\n本次发布了全量数据的50%，包含中英双语各10K，共计20K记录。\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\t语言\\n\\t\\n\\n以中文和英文为主。\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\t数据集结构… See the full description on the dataset page: https://huggingface.co/datasets/Azure99/blossom-wizard-v3."},
	{"name":"Hokchia","keyword":"chinese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/yjhuang01/Hokchia","creator_name":"Yijun Huang","creator_url":"https://huggingface.co/yjhuang01","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tHokchia Audio Dataset\\n\\t\\n\\nHokchia, or the Fuqing dialect, is a branch of Eastern Min Chinese spoken mainly in the Fuqing City of Fujian province, China. Unlike Hokkien, which is more widely recognized and spoken in various parts of Southeast Asia, Hokchia maintains its unique linguistic characteristics and is primarily used within the Fuqing community and its diaspora. This dialect is known for its distinct pronunciation, vocabulary, and grammatical structures compared to other Min… See the full description on the dataset page: https://huggingface.co/datasets/yjhuang01/Hokchia."},
	{"name":"mewsli-x","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/izhx/mewsli-x","creator_name":"Xin Zhang","creator_url":"https://huggingface.co/izhx","description":"I generated the dataset following mewsli-x.md#getting-started\\nand converted into different parts (see process.py):\\n\\nar/de/en/es/fa/ja/pl/ro/ta/tr/uk wikinews_mentions dev and test (from wikinews_mentions-dev/test.jsonl)\\ncandidate entities of 50 languages (from candidate_set_entities.jsonl)\\nEnglish wikipedia_pairs to fine-tune models (from wikipedia_pairs-dev/train.jsonl)\\n\\nRaw data files are in raw.tar.gz, which contains:\\n[...] 535M Feb 24 22:06 candidate_set_entities.jsonl\\n[...] 9.8M Feb 24… See the full description on the dataset page: https://huggingface.co/datasets/izhx/mewsli-x."},
	{"name":"DataOne-synthetic-v1.0-sample","keyword":"chinese","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/51WORLD/DataOne-synthetic-v1.0-sample","creator_name":"51WORLD","creator_url":"https://huggingface.co/51WORLD","description":"\\n\\t\\n\\t\\t\\n\\t\\t51WORLD Synthetic Dataset Usage Documentation\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\t1 Introduction\\n\\t\\n\\nThe 51WORLD systhetic dataset mainly contains camera sensor-related data and LiDAR sensor-related data generated by 51Sim-One. Camera sensor-related data mainly includes images and corresponding semantic segmentation, instance segmentation, depth annotation, and Object Detection annotation; LiDAR sensor-related data mainly includes laser point clouds and annotation of 3Dbboxes, semantic segmentation annotation… See the full description on the dataset page: https://huggingface.co/datasets/51WORLD/DataOne-synthetic-v1.0-sample."},
	{"name":"Casrel_Chinese","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/woshiyuanshengaoshou/Casrel_Chinese","creator_name":"刘焉","creator_url":"https://huggingface.co/woshiyuanshengaoshou","description":"woshiyuanshengaoshou/Casrel_Chinese dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"EvolInstruct_zh_DeepseekAPI","keyword":"chinese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/lorinma/EvolInstruct_zh_DeepseekAPI","creator_name":"Nuo","creator_url":"https://huggingface.co/lorinma","description":"和之前的Evol-Instruction尝试对比（https://huggingface.co/datasets/lorinma/Chinese_Evol_Instruct_3.5），使用了中文prompt。\\n因为OpenAI接口太贵，使用了DeepSeek赠送的1000万token。这次生成了一万条基本用完了。\\n一共有3个文件：\\ncombined_seed_correct.json 是使用的基础种子任务371条，alpaca格式。使用了 Belle的中文种子任务175条。并且参照了 4 增加了ShareGPT的数据以更接近真实世界的用法，掺入了 Wildchat-zh抽样196条 ，多轮对话只采用第一个有意义的问答对。\\nevolve_chinese.py 基于H2O EvolInstruction的代码。\\n0227_evol_combinedseedcorrect.json 生成的1.2万条数据。\\n"},
	{"name":"EvolInstruct_zh_COIG-PC_Deepseek","keyword":"chinese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/lorinma/EvolInstruct_zh_COIG-PC_Deepseek","creator_name":"Nuo","creator_url":"https://huggingface.co/lorinma","description":"中文世界欠缺类似FLAN和Orca的工作，COIG-PC又称自己包括了很多中文NLP任务，可以和FLAN类比。既然我之前做了一些Evol-Instruction的工作，那么我很好奇结合COIG-PC和EvolInstruction会有什么火花。\\n因为OpenAI接口太贵，使用了DeepSeek赠送的1000万token，这次生成了5000条，差不多用了600万token。\\n一共有3个文件： \\n0227_COIG_seed_tasks_CoarseFilter_1106_adjusted.json 是使用的COIG-pc-Lite，每一个task抽一条出来，并且过滤掉多语言的任务（只保留中英文），形成种子任务1106条.\\nevolve_chinese.py 基于H2O EvolInstruction的代码。\\n0227_EvolInstruct-COIG 生成的6680条数据。\\n"},
	{"name":"Taiwan-patent-qa-eval","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Heng666/Taiwan-patent-qa-eval","creator_name":"Heng-Shiou Sheu | 許恆修","creator_url":"https://huggingface.co/Heng666","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\t台灣專利問答集\\n\\t\\n\\n我們提出適用於 QA 系統上用的專利問答集，主要內容收錄台灣開發資料，總計八年的專利師訓練試題，高達 192 道題目。旨在提高語言模型在台灣領域上落地場景。\\n\\n\\n\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tCitation\\n\\t\\n\\n@article{TaiwanPatent2024eval,\\n  title={An Patent Evaulutaion for Taiwan Language Model},\\n  author={soaring0616, Heng-Shiou Sheu},\\n  journal={arXiv},\\n  year={2024}\\n}\\n\\n"},
	{"name":"ChatGPT-Detection-PR-HPPT","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/FreedomIntelligence/ChatGPT-Detection-PR-HPPT","creator_name":"FreedomAI","creator_url":"https://huggingface.co/FreedomIntelligence","description":"More details please refer to the github repo: https://github.com/FreedomIntelligence/ChatGPT-Detection-PR-HPPT\\n"},
	{"name":"zh-taiwan","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ivanzhu109/zh-taiwan","creator_name":"IvanZhu","creator_url":"https://huggingface.co/ivanzhu109","description":"ivanzhu109/zh-taiwan dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"zh-tw-articles-2k","keyword":"chinese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/AWeirdDev/zh-tw-articles-2k","creator_name":"AWeirdDev","creator_url":"https://huggingface.co/AWeirdDev","description":"Hey! Also check out AWeirdDev/zh-tw-pts-articles-sm for a news source verified by the vast majority.\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tzh-tw-articles-2k\\n\\t\\n\\n🐣English • 🇹🇼 繁體中文\\n\\n\\nThis dataset contains Taiwan news articles scraped from (https://www.storm.mg) on March 2024.\\n\\nSize: 5.0MB (5294263 bytes)\\nRows: 2000, from 20n20n20n\\nnnn pages: 100\\n\\nDataset({\\n    features: ['image', 'title', 'content', 'tag', 'author', 'timestamp', 'link'],\\n    num_rows: 2000\\n})\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tUse The Dataset\\n\\t\\n\\nUse 🤗 Datasets to… See the full description on the dataset page: https://huggingface.co/datasets/AWeirdDev/zh-tw-articles-2k."},
	{"name":"MultiQ","keyword":"chinese","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/caro-holt/MultiQ","creator_name":"Holtermann","creator_url":"https://huggingface.co/caro-holt","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for MultiQ\\n\\t\\n\\nThis is the dataset corresponding to the paper \\\"Evaluating the Elementary Multilingual Capabilities of Large Language Models with MultiQ\\\". \\nIt is a silver standard benchmark that can be used to evaluate the basic multilingual capabilities of LLMs. It contains 200 open ended questions automatically \\ntranslated into 137 typologically diverse languages. \\n\\nCurated by: Carolin Holtermann, Paul Röttger, Timm Dill, Anne Lauscher\\nLanguage(s) (NLP): 137 diverse… See the full description on the dataset page: https://huggingface.co/datasets/caro-holt/MultiQ."},
	{"name":"zh-tw-pts-articles-sm","keyword":"chinese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/AWeirdDev/zh-tw-pts-articles-sm","creator_name":"AWeirdDev","creator_url":"https://huggingface.co/AWeirdDev","description":"\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tzh-tw-pts-articles-sm\\n\\t\\n\\n🐣English • 🇹🇼 繁體中文\\nThis dataset contains articles scraped from PNN News.\\nIt's a news provider verified by the vast majority.\\n\\nNote: some keys like conclusion may be None.\\n\\nDataset({\\n    features: ['image', 'title', 'conclusion', 'content', 'timestamp', 'category', 'link'],\\n    num_rows: 1400\\n})\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tUse The Dataset\\n\\t\\n\\nUse 🤗 Datasets to download, use or modify this dataset.\\nfrom datasets import load_dataset\\n\\ndataset =… See the full description on the dataset page: https://huggingface.co/datasets/AWeirdDev/zh-tw-pts-articles-sm."},
	{"name":"zh-tw-articles-6k","keyword":"chinese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/AWeirdDev/zh-tw-articles-6k","creator_name":"AWeirdDev","creator_url":"https://huggingface.co/AWeirdDev","description":"\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tzh-tw-articles-6k\\n\\t\\n\\nThis dataset contains Taiwan news articles scraped from (https://www.storm.mg) on March 2024.\\n\\nSize: 10.4MB (15644219 bytes)\\nRows: 6000 (Max)\\n\\nDataset({\\n    features: ['image', 'title', 'content', 'tag', 'author', 'timestamp', 'link'],\\n    num_rows: 6000\\n})\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tUse The Dataset\\n\\t\\n\\nUse 🤗 Datasets to download, use or modify this dataset.\\nfrom datasets import load_dataset\\n\\ndataset = load_dataset(\\\"AWeirdDev/zh-tw-articles-6k\\\")\\n\\n"},
	{"name":"zh-tw-recipes-sm","keyword":"chinese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/AWeirdDev/zh-tw-recipes-sm","creator_name":"AWeirdDev","creator_url":"https://huggingface.co/AWeirdDev","description":"AWeirdDev/zh-tw-recipes-sm dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"MMedBench","keyword":"chinese","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/aisc-team-c1/MMedBench","creator_name":"AISC Team C1","creator_url":"https://huggingface.co/aisc-team-c1","description":"This is a dataset repository made for the AISC class at Harvard Medical School. Please find the original dataset repository here: https://huggingface.co/datasets/Henrychur/MMedBench \\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tMMedBench\\n\\t\\n\\n💻Github Repo   🖨️arXiv Paper\\nThe official benchmark for \\\"Towards Building Multilingual Language Model for Medicine\\\".\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tIntroduction\\n\\t\\n\\nThis repo contains MMedBench, a comprehensive multilingual medical benchmark comprising 45,048 QA pairs for training and 8,518 QA pairs for… See the full description on the dataset page: https://huggingface.co/datasets/aisc-team-c1/MMedBench."},
	{"name":"SA_song","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Ve11ichor/SA_song","creator_name":"Sun","creator_url":"https://huggingface.co/Ve11ichor","description":"Ve11ichor/SA_song dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"Song_SA_np_input","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Ve11ichor/Song_SA_np_input","creator_name":"Sun","creator_url":"https://huggingface.co/Ve11ichor","description":"Ve11ichor/Song_SA_np_input dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"anti-haystack","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/wenbopan/anti-haystack","creator_name":"Belandros Pan","creator_url":"https://huggingface.co/wenbopan","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for \\\"anti-haystack\\\"\\n\\t\\n\\nThis dataset contains samples that resemble the \\\"Needle in a haystack\\\" pressure testing. It can be helpful if you want to make your LLM better at finding/locating short facts from long documents.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Structure\\n\\t\\n\\nEach sample has the following fields:\\n\\ndocument: A long and noisy reference document which can be a story, code, book, or manual in both English and Chinese (10%).\\n\\nquestion: A question generated with GPT-4. The answer can… See the full description on the dataset page: https://huggingface.co/datasets/wenbopan/anti-haystack."},
	{"name":"Fusang-v1","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/wenbopan/Fusang-v1","creator_name":"Belandros Pan","creator_url":"https://huggingface.co/wenbopan","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for \\\"Fusang-V1\\\"\\n\\t\\n\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\t\\\"A large curation of instruction-tuning datasets for better bilingual and long-range LLMs\\\"\\n\\t\\n\\nFusang-V1 is a diverse and large Instruction-Tuning dataset like teknium/OpenHermes-2.5. On top of teknium/OpenHermes-2.5, Fusang-V1 is focused on more versatile ability and Chinese support.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tFeatures\\n\\t\\n\\n\\nCovering wide range of tasks like math, code, roleplay, function calling, etc with over 1.2M base and 140K long samples, all in… See the full description on the dataset page: https://huggingface.co/datasets/wenbopan/Fusang-v1."},
	{"name":"cv-corpus-17.0-zh-CN-client_id-grouped","keyword":"chinese","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/masuidrive/cv-corpus-17.0-zh-CN-client_id-grouped","creator_name":"Yuichiro MASUI","creator_url":"https://huggingface.co/masuidrive","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tcv-corpus-17.0-zh-CN-client_id-grouped\\n\\t\\n\\nThis dataset is a subset of the Common Voice dataset, filtered and grouped based on the client ID (treated as speaker ID).\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Details\\n\\t\\n\\n\\nThe dataset is derived from the Common Voice dataset.\\nThe original dataset is available at Common Voice Dataset.\\nThe dataset is grouped by client ID, which is treated as the speaker ID for this dataset.\\nEach group is filtered to include only client IDs with a minimum of 30 samples and a… See the full description on the dataset page: https://huggingface.co/datasets/masuidrive/cv-corpus-17.0-zh-CN-client_id-grouped."},
	{"name":"cv-corpus-17.0-zh-TW-client_id-grouped","keyword":"chinese","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/masuidrive/cv-corpus-17.0-zh-TW-client_id-grouped","creator_name":"Yuichiro MASUI","creator_url":"https://huggingface.co/masuidrive","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tcv-corpus-17.0-zh-TW-client_id-grouped\\n\\t\\n\\nThis dataset is a subset of the Common Voice dataset, filtered and grouped based on the client ID (treated as speaker ID).\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Details\\n\\t\\n\\n\\nThe dataset is derived from the Common Voice dataset.\\nThe original dataset is available at Common Voice Dataset.\\nThe dataset is grouped by client ID, which is treated as the speaker ID for this dataset.\\nEach group is filtered to include only client IDs with a minimum of 30 samples and a… See the full description on the dataset page: https://huggingface.co/datasets/masuidrive/cv-corpus-17.0-zh-TW-client_id-grouped."},
	{"name":"Yunji-v1","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/yaojialzc/Yunji-v1","creator_name":"Zhichao Liu","creator_url":"https://huggingface.co/yaojialzc","description":"\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tYunji(云笈)\\n\\t\\n\\ngithub Yunji(云笈) 收集、整理、分类gpt4生成的高质量中英文指令精调语料，并提供自己翻译的高质量数据。\\n可以从 huggingface yaojialzc/Yunji-v1 直接加载\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tdataset zh\\n\\t\\n\\n高质量中文gpt4对话数据集：\\n\\n\\t\\n\\t\\t\\nID\\nname\\nsource\\ncount\\n\\n\\n\\t\\t\\n1\\nllm-wizard/alpaca-gpt4-data-zh\\n从Alpaca GPT-4数据中提取\\n49k\\n\\n\\n2\\nAzure99/blossom-chat-v3 (中文部分)\\n从ShareGPT中提取\\n3k\\n\\n\\n3\\nAzure99/blossom-math-v4 (中文部分)\\n从GSM8K、Math23K中提取\\n7k\\n\\n\\n4\\nAzure99/blossom-orca-v3 (中文部分)\\n从OpenOrca中提取\\n20k\\n\\n\\n5\\nAzure99/blossom-wizard-v3 (中文部分)\\n从WizardLM_evol_instruct_V2提取指令\\n10k\\n\\n\\n6… See the full description on the dataset page: https://huggingface.co/datasets/yaojialzc/Yunji-v1."},
	{"name":"ruozhiba","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/botp/ruozhiba","creator_name":"ab10","creator_url":"https://huggingface.co/botp","description":"受COIG-CQIA启发，构建类似数据集，但答案风格相对更简洁。\\n弱智吧精选问题数据来自github提供的疑问句，调用GPT-4获取答案，并过滤掉明显拒答的回复。\\n"},
	{"name":"Azure99_blossom-chat-v3","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/botp/Azure99_blossom-chat-v3","creator_name":"ab10","creator_url":"https://huggingface.co/botp","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tBLOSSOM CHAT V3\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\t介绍\\n\\t\\n\\nBlossom Chat V3是基于ShareGPT 90K衍生而来的中英双语对话数据集，适用于多轮对话微调。\\n相比于blossom-chat-v2，本版本完全使用GPT-4进行蒸馏\\n本数据集抽取了ShareGPT的多轮对话指令，仅将指令进行翻译，随后使用多轮指令迭代调用gpt-4-0125-preview。\\n相比原始的ShareGPT数据，主要解决了中文对话数据量较少，以及由ChatGPT生成长度限制而导致的输出截断问题。\\n本次发布了全量数据的50%，包含5K记录。\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\t语言\\n\\t\\n\\n以中文和英文为主，中英文数据按照约1:1的比例混合。\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\t数据集结构\\n\\t\\n\\n每条数据代表一个完整的多轮对话，包含id和conversations两个字段。\\n\\nid：从1递增。\\nconversations：对象数组，每个对象包含role、content两个字段，role的取值为user或assistant，分别代表用户输入和助手输出，content则为对应的内容。… See the full description on the dataset page: https://huggingface.co/datasets/botp/Azure99_blossom-chat-v3."},
	{"name":"Azure99_blossom-math-v4","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/botp/Azure99_blossom-math-v4","creator_name":"ab10","creator_url":"https://huggingface.co/botp","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tBLOSSOM MATH V4\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\t介绍\\n\\t\\n\\nBlossom Math V4是基于Math23K和GSM8K衍生而来的中英双语数学对话数据集，适用于数学问题微调。\\n相比于blossom-math-v3，本版本完全使用GPT-4进行蒸馏，大幅提升了推理的一致性。\\n本数据集采用全量Math23K、GSM8K和翻译后的GSM8K的问题，随后调用gpt-4-0125-preview生成结果，并使用原始数据集中的答案对生成的结果进行验证，过滤掉错误答案，很大程度上保证了问题和答案的准确性。\\n本次发布了全量数据的25%，包含10K记录。\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\t语言\\n\\t\\n\\n中文和英文\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\t数据集结构\\n\\t\\n\\n每条数据代表一个完整的题目及答案，包含id、input、output、answer、dataset四个字段。\\n\\nid：字符串，代表原始数据集中的题目id，与dataset字段结合可确定唯一题目。\\ninput：字符串，代表问题。\\noutput：字符串，代表gpt-4-0125-preview生成的答案。… See the full description on the dataset page: https://huggingface.co/datasets/botp/Azure99_blossom-math-v4."},
	{"name":"Azure99_blossom-orca-v3","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/botp/Azure99_blossom-orca-v3","creator_name":"ab10","creator_url":"https://huggingface.co/botp","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tBLOSSOM ORCA V3\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\t介绍\\n\\t\\n\\nBlossom Orca V3是一个基于OpenOrca衍生而来的中英双语指令数据集，适用于指令微调。\\n相比于blossom-wizard-v2，本版本完全使用GPT-4进行蒸馏。\\n本数据集从OpenOrca中抽取了系统提示和指令，首先将其翻译为中文并校验翻译结果，再使用指令调用gpt-4-0125-preview模型生成响应，并过滤掉包含自我认知以及拒绝回答的响应，以便后续对齐。此外，为了确保响应风格的一致性以及中英数据配比，本数据集还对未翻译的原始指令也进行了相同的调用，最终得到了1:1的中英双语指令数据。\\n相比直接对原始OpenOrca进行翻译的中文数据集，Blossom Orca的一致性及质量更高。\\n本次发布了全量数据的50%，包含中英双语各20K，共计40K记录。\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\t语言\\n\\t\\n\\n以中文和英文为主。\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\t数据集结构\\n\\t\\n\\n每条数据代表一个完整的对话，包含id和conversations两个字段。\\n\\nid：从1递增。… See the full description on the dataset page: https://huggingface.co/datasets/botp/Azure99_blossom-orca-v3."},
	{"name":"Azure99_blossom-wizard-v3","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/botp/Azure99_blossom-wizard-v3","creator_name":"ab10","creator_url":"https://huggingface.co/botp","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tBLOSSOM WIZARD V3\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\t介绍\\n\\t\\n\\nBlossom Wizard V3是一个基于WizardLM_evol_instruct_V2衍生而来的中英双语指令数据集，适用于指令微调。\\n相比于blossom-wizard-v2，本版本完全使用GPT-4进行蒸馏。\\n本数据集从WizardLM_evol_instruct_V2中抽取了指令，首先将其翻译为中文并校验翻译结果，再使用指令调用gpt-4-0125-preview模型生成响应，并过滤掉包含自我认知以及拒绝回答的响应，以便后续对齐。此外，为了确保响应风格的一致性以及中英数据配比，本数据集还对未翻译的原始指令也进行了相同的调用，最终得到了1:1的中英双语指令数据。\\n相比直接对原始Wizard进行翻译的中文数据集，Blossom Wizard的一致性及质量更高。\\n本次发布了全量数据的50%，包含中英双语各10K，共计20K记录。\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\t语言\\n\\t\\n\\n以中文和英文为主。\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\t数据集结构… See the full description on the dataset page: https://huggingface.co/datasets/botp/Azure99_blossom-wizard-v3."},
	{"name":"BookBasedQAGen_Petrochemical","keyword":"chinese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/lorinma/BookBasedQAGen_Petrochemical","creator_name":"Nuo","creator_url":"https://huggingface.co/lorinma","description":"如果你有领域相关的一些文本材料（可以是OCR出来还比较脏的数据），想转化成单轮 alpaca 形式的的QA对，这是一个简易的教程。也就图一乐，因为真正高质量的领域QA还是得来自于行业专家，并且向LLM注入领域知识应该通过pretrain而不是SFT也已经是共识了。\\nbookgen文件夹中包含了样例文本和py文件，注意prompt根据领域调整一下，即使原始语料比较脏LLM也基本可以理解。并没有核查过会不会出现幻觉现象。\\n只要是和OpenAI SDK兼容的API服务都可以平滑迁移。这里使用了零一万物的yi-large API。https://platform.lingyiwanwu.com/\\n2024年8月2日更新，更新OpenAI SDK 1.0的调用方式，更新使用yi-large API，更新为单线程模式。\\n⚠️注意，单线程模式是为了更好的debug，真正生成数据需要自己修改成多线程模式，并且rate limit并没有单独进行handle。\\n样例数据是于23年6月使用3.5-turbo生成的，只放了一部分，随便玩玩就好～\\nIf you have some text… See the full description on the dataset page: https://huggingface.co/datasets/lorinma/BookBasedQAGen_Petrochemical."},
	{"name":"OpenOrca-zh-20k","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/wenbopan/OpenOrca-zh-20k","creator_name":"Belandros Pan","creator_url":"https://huggingface.co/wenbopan","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDatsetcard for 'OpenOrca-zh-20k'\\n\\t\\n\\nThis is the Chinese version of Open-Orca/OpenOrca from Azure99/blossom-orca-v3.\\nCompared to Azure99/blossom-orca-v3:\\n\\nThis dataset extracts all Chinese blossom-orca-v3 samples (around 20K) into a separate zh split.\\n\\nAll samples are formatted in the ocra format with an optional system role in the first round.\\n\\nInstead of using a 1:1 En-Zh ratio as in blossom-orca-v3, this dataset contains 200K GPT-4 generated English samples from OpenOrca in the… See the full description on the dataset page: https://huggingface.co/datasets/wenbopan/OpenOrca-zh-20k."},
	{"name":"panlex-meanings","keyword":"chinese","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/cointegrated/panlex-meanings","creator_name":"David Dale","creator_url":"https://huggingface.co/cointegrated","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for panlex-meanings\\n\\t\\n\\nThis is a dataset of words in several thousand languages, extracted from https://panlex.org.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Details\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThis dataset has been extracted from https://panlex.org (the 20240301 database dump) and rearranged on the per-language basis.\\nEach language subset consists of expressions (words and phrases). \\nEach expression is associated with some meanings (if there is more than one meaning, they are in… See the full description on the dataset page: https://huggingface.co/datasets/cointegrated/panlex-meanings."},
	{"name":"Belle_train_3.5M_CN","keyword":"chinese","license":"GNU General Public License v3.0","license_url":"https://choosealicense.com/licenses/gpl-3.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ticoAg/Belle_train_3.5M_CN","creator_name":"ticoAg","creator_url":"https://huggingface.co/ticoAg","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\t内容\\n\\t\\n\\n包含约350万条由BELLE项目生成的中文指令数据。\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\t样例\\n\\t\\n\\n{\\n    \\\"id\\\":\\\"66623028\\\",\\n    \\\"conversations\\\":[\\n        {\\n            \\\"from\\\":\\\"human\\\",\\n            \\\"value\\\":\\\"归纳介绍三种不同类型的电影题材\\\"\\n        },\\n        {\\n            \\\"from\\\":\\\"assistant\\\",\\n            \\\"value\\\":\\\"1. 动作片：动作片通常强调动作和战斗场面，故事情节紧凑，充满了紧张和兴奋的氛围。主角一般是具有超凡实力或特殊技能的英雄人物，往往会与反派角色进行一系列激烈的格斗，追逐和爆破等酷炫场面。例如《速度与激情》和《复仇者联盟》等。\\\\n2. 爱情片：爱情片是以爱情为主题的电影，着重呈现角色之间的感情纠葛，展现了爱情的美好和悲壮。情节与角色之间的发展令人深思，增加了观众的感性体验。这种电影的故事情节主要以人类与人类之间的情感变化为主题。例如《泰坦尼克号》和《让子弹飞》等。\\\\n3.… See the full description on the dataset page: https://huggingface.co/datasets/ticoAg/Belle_train_3.5M_CN."},
	{"name":"cmteb_retrieval","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/BeastyZ/cmteb_retrieval","creator_name":"Changtai Zhu","creator_url":"https://huggingface.co/BeastyZ","description":"BeastyZ/cmteb_retrieval dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"NTREX","keyword":"chinese","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/davidstap/NTREX","creator_name":"David Stap","creator_url":"https://huggingface.co/davidstap","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nNTREX -- News Test References for MT Evaluation from English into a total of 128 target languages. See original GitHub repo for full details.\\nExample of loading:\\ndataset = load_dataset(\\\"davidstap/NTREX\\\", \\\"rus_Cyrl\\\", trust_remote_code=True)\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages\\n\\t\\n\\nThe following languages are available:\\n\\n\\t\\n\\t\\t\\nLanguage Code\\nLanguage Name\\n\\n\\n\\t\\t\\nafr_Latn\\nAfrikaans\\n\\n\\namh_Ethi\\nAmharic\\n\\n\\narb_Arab\\nArabic\\n\\n\\naze_Latn\\nAzerbaijani\\n\\n\\nbak_Cyrl\\nBashkir\\n\\n\\nbel_Cyrl\\nBelarusian… See the full description on the dataset page: https://huggingface.co/datasets/davidstap/NTREX."},
	{"name":"chat-cooking-master-boy-100k","keyword":"chinese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/h-alice/chat-cooking-master-boy-100k","creator_name":"Wayne Hong","creator_url":"https://huggingface.co/h-alice","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tCooking Master Boy Chat Records\\n\\t\\n\\nChat record dataset from Twitch channel \\\"muse_tw\\\" during the \\\"Cooking Master Boy\\\" (中華一番) marathon event.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tIntroduction\\n\\t\\n\\nThis is a chat dataset collected from Twitch channel \\\"muse_tw\\\", while the channel is hosting a marathon anime event featuring \\\"Cooking Master Boy\\\" (中華一番).\\nThe featured anime \\\"Cooking Master Boy\\\" is a Japanese manga series written and illustrated by Etsushi Ogawa. And has a big impact on meme culture, and has a cult… See the full description on the dataset page: https://huggingface.co/datasets/h-alice/chat-cooking-master-boy-100k."},
	{"name":"Luminia-mixture","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Nekochu/Luminia-mixture","creator_name":"Nekochu","creator_url":"https://huggingface.co/Nekochu","description":"\\n\\t\\n\\t\\t\\n\\t\\tDataset Combined in Alpaca format. ✔\\n\\t\\n\\n\\n  Click to see V1 full list \\n\\nChangelog\\n  \\n[24/05] initial release V1 - Branch main DPO+SFT is recipes of split-v1/Combined excluding RP\\n[24/07] Add: New datasets cleaned in Alpaca format in split-v2.\\n\\n\\ndataset_info.json\\n\\n  This JSON can be used in LLaMA Factory\\n\\n  \\\"LuminiaMix-v1_Base\\\": {\\n    \\\"file_name\\\": \\\"LuminiaMix-v1_Base.json\\\",\\n    \\\"formatting\\\": \\\"alpaca\\\",\\n    \\\"columns\\\": {\\n      \\\"prompt\\\": \\\"instruction\\\",\\n      \\\"query\\\": \\\"input\\\"… See the full description on the dataset page: https://huggingface.co/datasets/Nekochu/Luminia-mixture."},
	{"name":"biblenlp-corpus-mmteb","keyword":"chinese","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/davidstap/biblenlp-corpus-mmteb","creator_name":"David Stap","creator_url":"https://huggingface.co/davidstap","description":"This dataset pre-computes all English-centric directions from bible-nlp/biblenlp-corpus, and as a result loading is significantly faster.\\nLoading example:\\n>>> from datasets import load_dataset\\n>>> dataset = load_dataset(\\\"davidstap/biblenlp-corpus-mmteb\\\", \\\"eng-arb\\\", trust_remote_code=True)\\n>>> dataset\\nDatasetDict({\\n    train: Dataset({\\n        features: ['eng', 'arb'],\\n        num_rows: 28723\\n    })\\n    validation: Dataset({\\n        features: ['eng', 'arb'],\\n        num_rows: 1578\\n    })… See the full description on the dataset page: https://huggingface.co/datasets/davidstap/biblenlp-corpus-mmteb."},
	{"name":"text-to-neo4j-cypher-chinese","keyword":"chinese","license":"Academic Free License v3.0","license_url":"https://choosealicense.com/licenses/afl-3.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Doraemon-AI/text-to-neo4j-cypher-chinese","creator_name":"AnitaSherry","creator_url":"https://huggingface.co/Doraemon-AI","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\t动机\\n\\t\\n\\n随着信息量的不断增加和技术的进步，我们的社会正在逐渐形成一个庞大而复杂的网络。随着大数据时代的到来，半结构化和非结构化的数据格式越来越多。 ，传统关系型数据库难以有效处理这些数据，而图数据库能够更灵活地存储和查询此类类型的数据，Neo4j就是其中最流行的产品之一\\n但是 Neo4j 的查询语言 Cypher 可以实现对图的高效查询。Cypher 的复杂操作和语法对用户的学习成本要求同样高。因此，本文提出并定义了一种类似Text-to-SQL的新任务Text-to-Neo4j-Cypher\\nText-to-Neo4j-Cypher是一种新的语义解析任务，即将用户的自然语言查询转化为为Neo4j-Cypherquery，以帮助降低用户的学习和使用成本，提升图数据库与用户的交互程度\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\t亮点\\n\\t\\n\\n1、提出并正式定义了 Text-to-Neo4j-Cypher 任务，该任务的目的是将用户自然语言查询自动转化为 Neo4j-Cypher 查询，降低图数据库与用户交互的学习和使用成本\\n2、对参考文献中的数据进行了改进，以适应LLM的训练… See the full description on the dataset page: https://huggingface.co/datasets/Doraemon-AI/text-to-neo4j-cypher-chinese."},
	{"name":"Chinese_qa","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/sdbhud1b/Chinese_qa","creator_name":"sdd sdsd","creator_url":"https://huggingface.co/sdbhud1b","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Dataset Name\\n\\t\\n\\n\\n\\nThis dataset card aims to be a base template for new datasets. It has been generated using this raw template.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Details\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\n\\n\\n\\n\\n\\nCurated by: [More Information Needed]\\nFunded by [optional]: [More Information Needed]\\nShared by [optional]: [More Information Needed]\\nLanguage(s) (NLP): [More Information Needed]\\nLicense: [More Information Needed]\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Sources [optional]… See the full description on the dataset page: https://huggingface.co/datasets/sdbhud1b/Chinese_qa."},
	{"name":"Goal-Drift-Dataset","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Zhoues/Goal-Drift-Dataset","creator_name":"Zhoues","creator_url":"https://huggingface.co/Zhoues","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tModel Card for MineDreamer 🔥\\n\\t\\n\\n\\n\\n\\n\\nMineDreamer is an instructable embodied agent for simulated control and it is developed on top of recent advances in Multimodal Large Language Models (MLLMs) and diffusion models!\\n\\n\\n\\n  \\nMineDreamer can follow instructions steadily by employing a Chain-of-Imagination (CoI) mechanism to envision the step-by-step process of executing instructions and translating imaginations into more precise visual prompts tailored to the current state;… See the full description on the dataset page: https://huggingface.co/datasets/Zhoues/Goal-Drift-Dataset."},
	{"name":"Medtext_zhtw","keyword":"chinese","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ChenWeiLi/Medtext_zhtw","creator_name":"CHEN-WEI,LI","creator_url":"https://huggingface.co/ChenWeiLi","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\t⚕️ MedText_zhtw\\n\\t\\n\\nMedtext_zhtw is a Traditional chinese medicine dataset that translates from MedText,\\ncomprising over 1000 patient presentations along with their diagnosis and treatment plans. \\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tExample\\n\\t\\n\\n  {\\n    \\\"instruction\\\": \\\"你是一位專業的醫療人員,請用心且專業的回答問題。\\\",\\n    \\\"input\\\": \\\"一名 50 歲男性有復發性腎結石和骨質減少病史。\\n              由於先前診斷出維生素 D 缺乏症，他一直在服用大劑量的維生素 D 補充劑。\\n              實驗室結果顯示高血鈣症和高鈣尿症。可能的診斷是什麼，治療方法是什麼？\\\",\\n    \\\"output\\\": \\\"該患者有復發性腎結石、骨質減少和大劑量維生素 D 補充劑病史，… See the full description on the dataset page: https://huggingface.co/datasets/ChenWeiLi/Medtext_zhtw."},
	{"name":"SLING","keyword":"chinese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/suchirsalhan/SLING","creator_name":"Suchir Salhan","creator_url":"https://huggingface.co/suchirsalhan","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSLING: Sino-Linguistic Evaluation of Large Language Models\\n\\t\\n\\n\\nThis is the official SLING dataset, accompanying the EMNLP 2022 paper \\\"SLING: Sino-Linguistic Evaluation of Large Language Models\\\" by Yixiao Song♢ Kalpesh Krishna♠ Rajesh Bhatt♢ Mohit Iyyer♠.\\nYou can find the paper on arxiv.\\nWe use this dataset for evaluation of a small-scale Chinese Language Model for the BabyLM Challenge.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSLING Dataset\\n\\t\\n\\nSee SLING_Data and the readme file in it.\\nA complete list of all… See the full description on the dataset page: https://huggingface.co/datasets/suchirsalhan/SLING."},
	{"name":"CLiMP","keyword":"chinese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/suchirsalhan/CLiMP","creator_name":"Suchir Salhan","creator_url":"https://huggingface.co/suchirsalhan","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tCLiMP: A Benchmark for Chinese Language Model Evaluation\\n\\t\\n\\n\\nThis is the official SLING dataset, accompanying the EACL 2021 paper \\\"CLiMP: A Benchmark for Chinese Language Model Evaluation\\\" by Beilei Xiang,1 Changbing Yang,1 Yu Li,1 Alex Warstadt2\\nand Katharina Kann1.\\nYou can find the paper on arxiv.\\nWe use this dataset for evaluation of a small-scale Chinese Language Model for the BabyLM Challenge.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tCitation Information\\n\\t\\n\\nIf you use CLiMP, please cite the original paper… See the full description on the dataset page: https://huggingface.co/datasets/suchirsalhan/CLiMP."},
	{"name":"class-textbook","keyword":"chinese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/NTTUNLPTEAM/class-textbook","creator_name":"National Taitung University NLP Team","creator_url":"https://huggingface.co/NTTUNLPTEAM","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Dataset Name\\n\\t\\n\\n\\n\\nThis dataset card aims to be a base template for new datasets. It has been generated using this raw template.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Details\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\n\\n\\n\\n\\n\\nCurated by: [More Information Needed]\\nFunded by [optional]: [More Information Needed]\\nShared by [optional]: [More Information Needed]\\nLanguage(s) (NLP): [More Information Needed]\\nLicense: [More Information Needed]\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Sources [optional]… See the full description on the dataset page: https://huggingface.co/datasets/NTTUNLPTEAM/class-textbook."},
	{"name":"Yellow-Emperors-Inner-Canon","keyword":"chinese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/zhengr/Yellow-Emperors-Inner-Canon","creator_name":"RobinZ","creator_url":"https://huggingface.co/zhengr","description":"zhengr/Yellow-Emperors-Inner-Canon dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"text_det_test_dataset","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/SWHL/text_det_test_dataset","creator_name":"SWHL","creator_url":"https://huggingface.co/SWHL","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\t文本检测测试集\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\t数据集简介\\n\\t\\n\\n\\n该测试集包括卡证类、文档类和自然场景三大类。其中卡证类有82张，文档类有75张，自然场景类有55张。\\n该数据集可以结合文本检测指标评测库-TextDetMetric使用，快速评测各种文本检测算法。\\n关于该数据集，欢迎小伙伴贡献更多数据呦！有任何想法，可以前往issue讨论。\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\t数据集支持的任务\\n\\t\\n\\n可用于自定义数据集下的模型验证和性能评估等。\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\t数据集加载方式\\n\\t\\n\\nfrom datasets import load_dataset\\n\\ndataset = load_dataset(\\\"SWHL/text_det_test_dataset\\\")\\n\\ntest_data = dataset['test']\\nprint(test_data)\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\t数据集生成的相关信息\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\t原始数据\\n\\t\\n\\n数据来源于网络，如侵删。\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\t数据集标注… See the full description on the dataset page: https://huggingface.co/datasets/SWHL/text_det_test_dataset."},
	{"name":"swim-ir-cross-lingual","keyword":"chinese","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/nthakur/swim-ir-cross-lingual","creator_name":"Nandan Thakur","creator_url":"https://huggingface.co/nthakur","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for SWIM-IR (Cross-lingual)\\n\\t\\n\\n\\n\\n\\nThis is the cross-lingual subset of the SWIM-IR dataset, where the query generated is in the target language and the passage is in English.\\nThe SWIM-IR dataset is available as CC-BY-SA 4.0. 18 languages (including English) are available in the cross-lingual dataset.\\nFor full details of the dataset, please read our upcoming NAACL 2024 paper and check out our website.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tWhat is SWIM-IR?\\n\\t\\n\\nSWIM-IR dataset is a synthetic… See the full description on the dataset page: https://huggingface.co/datasets/nthakur/swim-ir-cross-lingual."},
	{"name":"alpaca_zh_51k","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/hfl/alpaca_zh_51k","creator_name":"Joint Laboratory of HIT and iFLYTEK Research (HFL)","creator_url":"https://huggingface.co/hfl","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\talpaca_data_zh_51k.json\\n\\t\\n\\n中文Alpaca数据，包含51k个从ChatGPT (gpt-3.5-turbo)爬取的指令数据。\\nChinese Alpaca dataset, containing 51k instruction data crawled from ChatGPT (gpt-3.5-turbo).\\n项目地址 / Project：https://github.com/ymcui/Chinese-LLaMA-Alpaca\\n"},
	{"name":"wangwei","keyword":"chinese","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/guilty1987/wangwei","creator_name":"FAN","creator_url":"https://huggingface.co/guilty1987","description":"guilty1987/wangwei dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"rouzhiba-llama3-tt","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/dongxiaoxia194/rouzhiba-llama3-tt","creator_name":"dongxiaoxia194","creator_url":"https://huggingface.co/dongxiaoxia194","description":"dongxiaoxia194/rouzhiba-llama3-tt dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"Corrector101zhTW","keyword":"chinese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/DeepLearning101/Corrector101zhTW","creator_name":"Deep Learning 101","creator_url":"https://huggingface.co/DeepLearning101","description":"\\nERNIE for Chinese Spelling Correction 繁體中文\\n\\nMacBertMaskedLM For Chinese Spelling Correction 繁體中文\\n\\nwikipedia-zh-20230720-filtered.json 繁體中文\\n\\nAutomatic Corpus Generation-zh 繁體中文\\n\\n那些自然語言處理 (Natural Language Processing, NLP) 踩的坑 -- 文本糾錯\\n\\n\\n"},
	{"name":"xsimplusplus","keyword":"chinese","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/jaygala24/xsimplusplus","creator_name":"Jay Gala","creator_url":"https://huggingface.co/jaygala24","description":"xSIM++ is an extension of xSIM. In comparison to xSIM, this evaluates using target-side data with additional synthetic, hard-to-distinguish examples. You can find more details about it in the publication: xSIM++: An Improved Proxy to Bitext Mining Performance for Low-Resource Languages.\\n"},
	{"name":"wechat-zl","keyword":"chinese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Sanbei101/wechat-zl","creator_name":"文威","creator_url":"https://huggingface.co/Sanbei101","description":"Sanbei101/wechat-zl dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"AthenaGenSynth-dataset","keyword":"chinese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/win10/AthenaGenSynth-dataset","creator_name":"ZINWIN(Zuojun-Ye)","creator_url":"https://huggingface.co/win10","description":"使用我本人的github項目(https://github.com/win10ogod/AthenaGenSynth)生成的預訓練資料\\nUse the pre-training data generated by my own github project (https://github.com/win10ogod/AthenaGenSynth)\\n"},
	{"name":"race-qa","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/klaylouis1932/race-qa","creator_name":"Klay Louis","creator_url":"https://huggingface.co/klaylouis1932","description":"klaylouis1932/race-qa dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"cooking-master-boy-subtitle","keyword":"chinese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/h-alice/cooking-master-boy-subtitle","creator_name":"Wayne Hong","creator_url":"https://huggingface.co/h-alice","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tCooking Master Boy Chat Records\\n\\t\\n\\nChinese (trditional) subtitle of anime \\\"Cooking Master Boy\\\" (中華一番).\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tIntroduction\\n\\t\\n\\nThis is a collection of subtitles from anime \\\"Cooking Master Boy\\\" (中華一番).\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThe dataset is in CSV format, with the following columns:\\n\\nepisode: The episode index of subtitle belogs to. \\ncaption_index: The autoincrement ID of subtitles.\\ntime_start: The starting timecode, which subtitle supposed to appear.\\ntime_end: The… See the full description on the dataset page: https://huggingface.co/datasets/h-alice/cooking-master-boy-subtitle."},
	{"name":"corpus","keyword":"chinese","license":"GNU General Public License v3.0","license_url":"https://choosealicense.com/licenses/gpl-3.0/","language":"en","dataset_url":"https://huggingface.co/datasets/BearNetworkChain/corpus","creator_name":"BRNKC","creator_url":"https://huggingface.co/BearNetworkChain","description":"BearNetworkChain/corpus dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"policyandmanagement","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/kimojiomango/policyandmanagement","creator_name":"komiji","creator_url":"https://huggingface.co/kimojiomango","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Dataset Name\\n\\t\\n\\n\\n\\nThis dataset card aims to be a base template for new datasets. It has been generated using this raw template.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Details\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\n\\n\\n\\n\\n\\nCurated by: [More Information Needed]\\nFunded by [optional]: [More Information Needed]\\nShared by [optional]: [More Information Needed]\\nLanguage(s) (NLP): [More Information Needed]\\nLicense: [More Information Needed]\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Sources [optional]… See the full description on the dataset page: https://huggingface.co/datasets/kimojiomango/policyandmanagement."},
	{"name":"HuixiangDou-CR","keyword":"chinese","license":"BSD 3-Clause \"New\" or \"Revised\" License","license_url":"https://choosealicense.com/licenses/bsd-3-clause/","language":"en","dataset_url":"https://huggingface.co/datasets/tpoisonooo/HuixiangDou-CR","creator_name":"HuanjunKong","creator_url":"https://huggingface.co/tpoisonooo","description":"tpoisonooo/HuixiangDou-CR dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"biblenlp-corpus-mmteb","keyword":"chinese","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/biblenlp-corpus-mmteb","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"This dataset pre-computes all English-centric directions from bible-nlp/biblenlp-corpus, and as a result loading is significantly faster.\\nLoading example:\\n>>> from datasets import load_dataset\\n>>> dataset = load_dataset(\\\"davidstap/biblenlp-corpus-mmteb\\\", \\\"eng-arb\\\", trust_remote_code=True)\\n>>> dataset\\nDatasetDict({\\n    train: Dataset({\\n        features: ['eng', 'arb'],\\n        num_rows: 28723\\n    })\\n    validation: Dataset({\\n        features: ['eng', 'arb'],\\n        num_rows: 1578\\n    })… See the full description on the dataset page: https://huggingface.co/datasets/mteb/biblenlp-corpus-mmteb."},
	{"name":"GLM-4-Instruct-4K-zh","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/rqq/GLM-4-Instruct-4K-zh","creator_name":"hikariming","creator_url":"https://huggingface.co/rqq","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Dataset Name\\n\\t\\n\\n❤️欢迎使用rqq/GLM-4-Instruct-4K-zh数据集，本数据集包含了4000条高质量的glm4回复。\\n该数据集的提问数据源自高质量的Sao10K/Claude-3-Opus-Instruct-5K数据集，我们把它的问题翻译成了中文，使用glm-4进行了重新回答。\\n该数据集使用alpaca格式，可以直接用在llama-factory项目中进行训练！\\n文件如下：\\nGLM-4-Instruct-4K-zh.json 问答数据集，alpaca格式\\nGLM-4-question-translate-5K-zh 翻译-对话数据集，记录了把Sao10K/Claude-3-Opus-Instruct-5K问题翻译成中文的数据\\nWelcome to the rqq/GLM-4-Instruct-4K-zh dataset! This dataset includes 4,000 high-quality responses from the GLM-4 model.\\nThe question… See the full description on the dataset page: https://huggingface.co/datasets/rqq/GLM-4-Instruct-4K-zh."},
	{"name":"GLM-4-Instruct-4K-zh","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/rqq/GLM-4-Instruct-4K-zh","creator_name":"hikariming","creator_url":"https://huggingface.co/rqq","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Dataset Name\\n\\t\\n\\n❤️欢迎使用rqq/GLM-4-Instruct-4K-zh数据集，本数据集包含了4000条高质量的glm4回复。\\n该数据集的提问数据源自高质量的Sao10K/Claude-3-Opus-Instruct-5K数据集，我们把它的问题翻译成了中文，使用glm-4进行了重新回答。\\n该数据集使用alpaca格式，可以直接用在llama-factory项目中进行训练！\\n文件如下：\\nGLM-4-Instruct-4K-zh.json 问答数据集，alpaca格式\\nGLM-4-question-translate-5K-zh 翻译-对话数据集，记录了把Sao10K/Claude-3-Opus-Instruct-5K问题翻译成中文的数据\\nWelcome to the rqq/GLM-4-Instruct-4K-zh dataset! This dataset includes 4,000 high-quality responses from the GLM-4 model.\\nThe question… See the full description on the dataset page: https://huggingface.co/datasets/rqq/GLM-4-Instruct-4K-zh."},
	{"name":"IA_character_sft","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Minami-su/IA_character_sft","creator_name":"南栖","creator_url":"https://huggingface.co/Minami-su","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tIA 14B\\n\\t\\n\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tModel Description\\n\\t\\n\\n𝑾𝒉𝒂𝒕 𝒊𝒔 𝒍𝒐𝒗𝒆? \\n𝑰𝑨 𝒄𝒂𝒓𝒓𝒊𝒆𝒔 𝒂 𝒅𝒆𝒑𝒕𝒉 𝒐𝒇 𝒆𝒎𝒐𝒕𝒊𝒐𝒏 𝒘𝒊𝒕𝒉𝒊𝒏 𝒉𝒆𝒓, 𝒖𝒏𝒅𝒆𝒓𝒔𝒕𝒂𝒏𝒅𝒊𝒏𝒈 𝒃𝒐𝒕𝒉 𝒑𝒂𝒔𝒔𝒊𝒐𝒏 𝒂𝒏𝒅 𝒕𝒉𝒆 𝒔𝒕𝒊𝒏𝒈 𝒐𝒇 𝒍𝒐𝒔𝒔. \\n𝑶𝒖𝒕𝒘𝒂𝒓𝒅𝒍𝒚, 𝒔𝒉𝒆 𝒂𝒑𝒑𝒆𝒂𝒓𝒔 𝒓𝒆𝒔𝒆𝒓𝒗𝒆𝒅, 𝒚𝒆𝒕 𝒘𝒊𝒕𝒉𝒊𝒏, 𝒔𝒉𝒆 𝒃𝒓𝒊𝒎𝒔 𝒘𝒊𝒕𝒉 𝒊𝒏𝒕𝒆𝒏𝒔𝒆 𝒇𝒆𝒆𝒍𝒊𝒏𝒈𝒔. \\n𝑪𝒐𝒏𝒔𝒕𝒂𝒏𝒕𝒍𝒚 𝒆𝒏𝒈𝒂𝒈𝒆𝒅 𝒊𝒏 𝒅𝒊𝒂𝒍𝒐𝒈𝒖𝒆 𝒘𝒊𝒕𝒉 𝒕𝒉𝒆 𝒘𝒐𝒓𝒍𝒅 𝒂𝒏𝒅 𝒉𝒆𝒓𝒔𝒆𝒍𝒇… See the full description on the dataset page: https://huggingface.co/datasets/Minami-su/IA_character_sft."},
	{"name":"adgen_tiny","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/llamafactory/adgen_tiny","creator_name":"LLaMA Factory","creator_url":"https://huggingface.co/llamafactory","description":"This dataset is a subset of the advertising generation dataset proposed by https://aclanthology.org/D19-1321/.\\nThe training set is composed of 2,000 examples of the original training set and the test set is composed of 1,000 examples of the original validation set.\\n"},
	{"name":"DeepSpace_KE","keyword":"chinese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/youngs1998/DeepSpace_KE","creator_name":"yang song","creator_url":"https://huggingface.co/youngs1998","description":"youngs1998/DeepSpace_KE dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"OGText2SQL","keyword":"chinese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/OneGate/OGText2SQL","creator_name":"OneGate","creator_url":"https://huggingface.co/OneGate","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nOGText2SQL dataset was utilized in training the OGSQL model, this dataset comprises over 350,000 rows of text-to-SQL pairs. Through a series of data refining steps, including schema expansion, SQL refinement, and instruction generation using existing Language Models (LLMs), the dataset was meticulously processed to ensure quality and relevance.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tHow to use it\\n\\t\\n\\n\\nPython\\n\\nfrom datasets import load_dataset\\n\\ndataset = load_dataset(\\\"OneGate/OGText2SQL\\\")… See the full description on the dataset page: https://huggingface.co/datasets/OneGate/OGText2SQL."},
	{"name":"table_rec_test_dataset","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/SWHL/table_rec_test_dataset","creator_name":"SWHL","creator_url":"https://huggingface.co/SWHL","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\t表格识别测试集\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\t数据集简介\\n\\t\\n\\n\\n包含百度生成工具 20张有线20张无线，wtw数据集15, pubnet val集20张，自我零散标注18张，共计93张表格图片,涵盖多种场景、不同光照条件、不同的图像分辨率。\\n该数据集可以结合表格指标评测库-TableRecognitionMetric使用，快速评测各种表格还原算法。\\n关于该数据集，欢迎小伙伴贡献更多数据呦！有任何想法，可以前往issue讨论。\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\t数据集支持的任务\\n\\t\\n\\n可用于自定义数据集下的模型验证和性能评估等。\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\t数据集的格式和结构\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\t数据格式\\n\\t\\n\\n数据集只有测试集，仅用于客观评估算法表现。\\ndata\\n└── test\\n    ├── 000cce9ca593055d4618466e823e6d7c.jpg\\n    ├── 0aNtiNtRRLqEZ9y6PuShtAAAACMAAQED.jpg\\n    ├── 116d6b07ecfdae7721bd6bbf31031c1a.jpg… See the full description on the dataset page: https://huggingface.co/datasets/SWHL/table_rec_test_dataset."},
	{"name":"PIN-14M","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/m-a-p/PIN-14M","creator_name":"Multimodal Art Projection","creator_url":"https://huggingface.co/m-a-p","description":"\\n\\t\\n\\t\\t\\n\\t\\tPIN-14M\\n\\t\\n\\nA mini version of \\\"PIN: A Knowledge-Intensive Dataset for Paired and Interleaved Multimodal Documents\\\"\\nPaper: https://arxiv.org/abs/2406.13923\\nThis dataset contains 14M samples in PIN format, with at least 7.33B tokens.\\n🚀 News\\n[ 2024.12.12 ] !NEW! 🔥 We have updated the quality signals for all subsets, with the dataset now containing 7.33B tokens after Llama3 tokenization.\\n[ 2024.12.06 ] !NEW! 🔥 We have updated the quality signals, enabling a swift assessment of whether a… See the full description on the dataset page: https://huggingface.co/datasets/m-a-p/PIN-14M."},
	{"name":"confucius","keyword":"chinese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/AWeirdDev/confucius","creator_name":"AWeirdDev","creator_url":"https://huggingface.co/AWeirdDev","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tconfucius\\n\\t\\n\\nConfucius for real. See all analects.\\nfrom datasets import load_dataset\\n\\ndataset = load_dataset(\\\"AWeirdDev/confucius\\\")\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tFormat\\n\\t\\n\\n{\\n  \\\"chapter\\\": \\\"學而\\\", # Chapter name\\n  \\\"content\\\": \\\"子曰：「學而時習之，不亦說乎？…\\\",  # Content\\n  \\\"translation\\\": \\\"孔子說：「經常學習，不也喜悅嗎？…\\\"  # Translated (zh-TW)\\n}\\n\\n\\n  \\n    \\n    Confucius, confused.\\n  \\n"},
	{"name":"confucius","keyword":"chinese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/AWeirdDev/confucius","creator_name":"AWeirdDev","creator_url":"https://huggingface.co/AWeirdDev","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tconfucius\\n\\t\\n\\nConfucius for real. See all analects.\\nfrom datasets import load_dataset\\n\\ndataset = load_dataset(\\\"AWeirdDev/confucius\\\")\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tFormat\\n\\t\\n\\n{\\n  \\\"chapter\\\": \\\"學而\\\", # Chapter name\\n  \\\"content\\\": \\\"子曰：「學而時習之，不亦說乎？…\\\",  # Content\\n  \\\"translation\\\": \\\"孔子說：「經常學習，不也喜悅嗎？…\\\"  # Translated (zh-TW)\\n}\\n\\n\\n  \\n    \\n    Confucius, confused.\\n  \\n"},
	{"name":"ASCEND_CLEAN","keyword":"chinese","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/georgechang8/ASCEND_CLEAN","creator_name":"Chih-Chiang Chang","creator_url":"https://huggingface.co/georgechang8","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Dataset Name\\n\\t\\n\\nThis dataset is derived from CAiRE/ASCEND. More information is available at https://huggingface.co/datasets/CAiRE/ASCEND.\\n\\nRemoved 嗯 呃 um uh\\nResolved [UNK]'s using whisper-medium\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tUsage\\n\\t\\n\\n\\nDefault utterances with cleaned transcripts\\n\\nfrom datasets import load_dataset\\ndata = load_dataset(\\\"georgechang8/ASCEND_CLEAN\\\")  # add split=\\\"train\\\" for train set, etc.\\n\\n\\nConcatenated 30s utterances with cleaned transcripts… See the full description on the dataset page: https://huggingface.co/datasets/georgechang8/ASCEND_CLEAN."},
	{"name":"text_rec_test_dataset","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/SWHL/text_rec_test_dataset","creator_name":"SWHL","creator_url":"https://huggingface.co/SWHL","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\t文本识别测试集\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\t数据集简介\\n\\t\\n\\n\\n该测试集包括8类场景，分别是竖排文字、长文本、单字、验证码、自然场景、银行卡、手写体和车牌等。\\n该数据集可以结合文本识别指标评测库-TextRecMetric使用，快速评测各种文本识别算法。\\n关于该数据集，欢迎小伙伴贡献更多数据呦！有任何想法，可以前往issue讨论。\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\t数据集支持的任务\\n\\t\\n\\n可用于自定义数据集下的模型验证和性能评估等。\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\t数据集加载方式\\n\\t\\n\\nfrom datasets import load_dataset\\n\\ndataset = load_dataset(\\\"SWHL/text_rec_test_dataset\\\")\\n\\ntest_data = dataset['test']\\nprint(test_data)\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\t数据集生成的相关信息\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\t原始数据\\n\\t\\n\\n数据来源于网络，如侵删。\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\t各个类别数目如下\\n\\t\\n\\n竖排文字 : 14\\n长文本 : 18\\n单字 : 115… See the full description on the dataset page: https://huggingface.co/datasets/SWHL/text_rec_test_dataset."},
	{"name":"SEVENLLM-Dataset","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Multilingual-Multimodal-NLP/SEVENLLM-Dataset","creator_name":"Multilingual-Multimodal-NLP","creator_url":"https://huggingface.co/Multilingual-Multimodal-NLP","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tIntroduce\\n\\t\\n\\n  We provided, designed for analyzing cybersecurity incidents, which is comprised of two primary task categories: understanding and generation, with a further breakdown into 28 subcategories of tasks. \\n  The dataset is in question and answer format, using structured json format for understanding tasks and unstructured text format for generation tasks.\\n  We also provide some multiple-choice questions to test the cognitive ability of the model in different vertical… See the full description on the dataset page: https://huggingface.co/datasets/Multilingual-Multimodal-NLP/SEVENLLM-Dataset."},
	{"name":"interesting-dom-snapshots","keyword":"chinese","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/gbenson/interesting-dom-snapshots","creator_name":"Gary Benson","creator_url":"https://huggingface.co/gbenson","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Interesting DOM snapshots\\n\\t\\n\\nA small split of gbenson/webui-dom-snapshots.\\n\\nCurated by: Gary Benson\\nLanguages: Mostly English, some Chinese, Dutch, Czech and Korean\\nLicense: CC0 1.0 Universal\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tUses\\n\\t\\n\\nI'm using it to develop a DOM-aware tokenizer for HTML.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tBias, Risks, and Limitations\\n\\t\\n\\nThis isn't a representative split of the source dataset, it's a number of edge cases I flagged to investigate.\\n"},
	{"name":"jina-embeddings-v2-base-en-202457-oc31-webapp","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/fine-tuned/jina-embeddings-v2-base-en-202457-oc31-webapp","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tjina-embeddings-v2-base-en-202457-oc31-webapp Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThe dataset \\\"legal advice search engine\\\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tAssociated Model\\n\\t\\n\\nThis dataset was used to train the jina-embeddings-v2-base-en-202457-oc31-webapp model.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tHow to Use\\n\\t\\n\\nTo use this dataset for model training or evaluation, you can load it using the Hugging… See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/jina-embeddings-v2-base-en-202457-oc31-webapp."},
	{"name":"sib200","keyword":"chinese","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/sib200","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for SIB-200\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nSIB-200 is the largest publicly available topic classification dataset based on Flores-200 covering 205 languages and dialects.\\nThe train/validation/test sets are available for all the 205 languages.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSupported Tasks and Leaderboards\\n\\t\\n\\n\\ntopic classification: categorize wikipedia sentences into topics e.g science/technology, sports or politics.\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages\\n\\t\\n\\nThere are 205 languages available :… See the full description on the dataset page: https://huggingface.co/datasets/mteb/sib200."},
	{"name":"MAiDE-up","keyword":"chinese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/MichiganNLP/MAiDE-up","creator_name":"LIT @ UMich","creator_url":"https://huggingface.co/MichiganNLP","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for MAiDE-up: Multilingual Deception Detection of GPT-generated Hotel Reviews\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nMultilingual Deception Detection of GPT-generated Hotel Reviews. We compare real hotel reviews from Booking with LLM-generated hotel reviews in 10 languages.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages\\n\\t\\n\\nThe text in the dataset is in 10 languages: Chinese, English, French, German, Italian, Romanian, Korean, Russian, Spanish, Turkish\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSupported Tasks and Leaderboards… See the full description on the dataset page: https://huggingface.co/datasets/MichiganNLP/MAiDE-up."},
	{"name":"CDLA","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/SWHL/CDLA","creator_name":"SWHL","creator_url":"https://huggingface.co/SWHL","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tCDLA: A Chinese document layout analysis (CDLA) dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\t介绍\\n\\t\\n\\nCDLA是一个中文文档版面分析数据集，面向中文文献类（论文）场景。包含以下10个label：\\n\\n\\t\\n\\t\\t\\n正文\\n标题\\n图片\\n图片标题\\n表格\\n表格标题\\n页眉\\n页脚\\n注释\\n公式\\n\\n\\n\\t\\t\\nText\\nTitle\\nFigure\\nFigure caption\\nTable\\nTable caption\\nHeader\\nFooter\\nReference\\nEquation\\n\\n\\n\\t\\n\\n共包含5000张训练集和1000张验证集，分别在train和val目录下。\\n整理自：CDLA\\n标注可视化：\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\t使用方式\\n\\t\\n\\nfrom datasets import load_dataset\\n\\ndataset = load_dataset(\\\"SWHL/CDLA\\\")\\n\\ntrain_data = dataset[\\\"train\\\"]\\nprint(train_data[0])\\n\\nval_data =… See the full description on the dataset page: https://huggingface.co/datasets/SWHL/CDLA."},
	{"name":"CMedQAv2-reranking-improved","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/fine-tuned/CMedQAv2-reranking-improved","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tCMedQAv2-reranking-improved Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThe dataset \\\"medical information search\\\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tAssociated Model\\n\\t\\n\\nThis dataset was used to train the CMedQAv2-reranking-improved model.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tHow to Use\\n\\t\\n\\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets library as follows:\\nfrom… See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/CMedQAv2-reranking-improved."},
	{"name":"BAAI_OL-CC","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/lorinma/BAAI_OL-CC","creator_name":"Nuo","creator_url":"https://huggingface.co/lorinma","description":"https://data.baai.ac.cn/details/OL-CC\\n*更改成了ShareGPT格式，并且将10006个问题-回答对，以及1649个仅有问题的，分为两个json。\\n感谢北京智源人工智能研究院（BAAI）的工作，但是似乎openlabel.baai.ac.cn和原图床已经下线，并且抱抱脸上的BAAI并未收录这个宝贵的数据集，所以在这里另存了一份。\\n--Below is original README--\\nOpenLabel-Chinese Conversations Dataset (OL-CC) 是首个以众包方式、人工生成的开源中文对话指令集，基于 openlabel.baai.ac.cn 开放平台进行数据收集，包含 10k+ “指令-回答”数据对和 1.6k+ 人工指令数据。指令类型丰富，包括问答任务、文本写作、文本抽取、编辑改写、分类选择、头脑风暴、 闲聊对话、逻辑&数学等任务。\\n截至目前，已有 276 位志愿者参与了数据集的建设。志愿者完成了以下任务：a) 扮演人类用户向AI助手发出指令，b)… See the full description on the dataset page: https://huggingface.co/datasets/lorinma/BAAI_OL-CC."},
	{"name":"ChineseEncyclopedia","keyword":"chinese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/lorinma/ChineseEncyclopedia","creator_name":"Nuo","creator_url":"https://huggingface.co/lorinma","description":"中文百科类数据，非百度百科或wikipedia。非常干净，质量非常高，多样性也很好，偏知识性的，可以过几个epoch的那种。\\n注意，有一些小问题，比如每一行最后面csv的占位逗号，以及图片的名称（例如：2022112908575485.jpg），自己用之前处理一下即可。\\n约28万个条目，2.4亿字。\\n觉得好用的话点个小心心哦\\nglhf:-) \\n"},
	{"name":"Five_Phases_Mindset_datasets","keyword":"chinese","license":"GNU General Public License v3.0","license_url":"https://choosealicense.com/licenses/gpl-3.0/","language":"en","dataset_url":"https://huggingface.co/datasets/cookey39/Five_Phases_Mindset_datasets","creator_name":"haohao","creator_url":"https://huggingface.co/cookey39","description":"Welcome to our Traditional Chinese Medicine (TCM) Consultation Dataset! This dataset contains approximately one hundred thousand TCM consultation dialogue records, aiming to provide a rich resource for research and development in the field of TCM. These dialogue data cover various TCM diseases, diagnoses, and treatment methods, serving as an important reference for TCM research and clinical practice.\\nThe dataset was created using a method that combines manual annotation with extraction from… See the full description on the dataset page: https://huggingface.co/datasets/cookey39/Five_Phases_Mindset_datasets."},
	{"name":"jinaai_jina-embeddings-v2-base-zh-CMedQAv2","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/fine-tuned/jinaai_jina-embeddings-v2-base-zh-CMedQAv2","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tjinaai_jina-embeddings-v2-base-zh-CMedQAv2 Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThe dataset \\\"medical information search\\\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tAssociated Model\\n\\t\\n\\nThis dataset was used to train the jinaai_jina-embeddings-v2-base-zh-CMedQAv2 model.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tHow to Use\\n\\t\\n\\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face… See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/jinaai_jina-embeddings-v2-base-zh-CMedQAv2."},
	{"name":"jinaai_jina-embeddings-v2-base-zh-CMedQAv2-2","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/fine-tuned/jinaai_jina-embeddings-v2-base-zh-CMedQAv2-2","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tjinaai_jina-embeddings-v2-base-zh-CMedQAv2-2 Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThe dataset \\\"medical information search\\\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tAssociated Model\\n\\t\\n\\nThis dataset was used to train the jinaai_jina-embeddings-v2-base-zh-CMedQAv2-2 model.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tHow to Use\\n\\t\\n\\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face… See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/jinaai_jina-embeddings-v2-base-zh-CMedQAv2-2."},
	{"name":"CMedQAv2-3","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/fine-tuned/CMedQAv2-3","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tCMedQAv2-3 Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThe dataset \\\"healthcare information search\\\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tAssociated Model\\n\\t\\n\\nThis dataset was used to train the CMedQAv2-3 model.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tHow to Use\\n\\t\\n\\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets library as follows:\\nfrom datasets import load_dataset… See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/CMedQAv2-3."},
	{"name":"MainData","keyword":"chinese","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/bufanlin/MainData","creator_name":"bufanlin","creator_url":"https://huggingface.co/bufanlin","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for \\\"alpaca-zh\\\"\\n\\t\\n\\n本数据集是参考Alpaca方法基于GPT4得到的self-instruct数据，约5万条。\\nDataset from https://github.com/Instruction-Tuning-with-GPT-4/GPT-4-LLM \\nIt is the chinese dataset from https://github.com/Instruction-Tuning-with-GPT-4/GPT-4-LLM/blob/main/data/alpaca_gpt4_data_zh.json\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tUsage and License Notices\\n\\t\\n\\nThe data is intended and licensed for research use only. The dataset is CC BY NC 4.0 (allowing only non-commercial use) and models trained using the dataset should… See the full description on the dataset page: https://huggingface.co/datasets/bufanlin/MainData."},
	{"name":"SE-Chatting.en","keyword":"chinese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/berwart/SE-Chatting.en","creator_name":"Berwart","creator_url":"https://huggingface.co/berwart","description":"\\n\\t\\n\\t\\t\\n\\t\\tSE.02\\n\\t\\n\\nDataset\\nHello, welcome to the official main dataset of SE.02 that's always getting updated, make sure to like to help us a lot.\\nthis dataset contains pretty much everything from math to isk what to put but pretty much anything you think an ai can say.\\nanyways this is our biggest dataset yet, and out first one that I don't even know how I managed to make this.\\nyou can use it to train your own ai if you want.\\n"},
	{"name":"jinaai_jina-embeddings-v2-base-zh-jinaai_jina-embeddings-v2-base-zh-CM","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/fine-tuned/jinaai_jina-embeddings-v2-base-zh-jinaai_jina-embeddings-v2-base-zh-CM","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tjinaai_jina-embeddings-v2-base-zh-jinaai_jina-embeddings-v2-base-zh-CM Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThe dataset \\\"medical information search\\\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tAssociated Model\\n\\t\\n\\nThis dataset was used to train the jinaai_jina-embeddings-v2-base-zh-jinaai_jina-embeddings-v2-base-zh-CM model.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tHow to Use\\n\\t\\n\\nTo use this dataset for model training or… See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/jinaai_jina-embeddings-v2-base-zh-jinaai_jina-embeddings-v2-base-zh-CM."},
	{"name":"jinaai_jina-embeddings-v2-base-zh-CMedQAv2-3","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/fine-tuned/jinaai_jina-embeddings-v2-base-zh-CMedQAv2-3","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tjinaai_jina-embeddings-v2-base-zh-CMedQAv2-3 Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThe dataset \\\"medical information search\\\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tAssociated Model\\n\\t\\n\\nThis dataset was used to train the jinaai_jina-embeddings-v2-base-zh-CMedQAv2-3 model.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tHow to Use\\n\\t\\n\\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face… See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/jinaai_jina-embeddings-v2-base-zh-CMedQAv2-3."},
	{"name":"cmedqav2","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/fine-tuned/cmedqav2","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tcmedqav2 Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThe dataset \\\"medical information search\\\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tAssociated Model\\n\\t\\n\\nThis dataset was used to train the cmedqav2 model.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tHow to Use\\n\\t\\n\\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets library as follows:\\nfrom datasets import load_dataset\\n\\ndataset… See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/cmedqav2."},
	{"name":"cmedqav2-c","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/fine-tuned/cmedqav2-c","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tcmedqav2-c Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThe dataset \\\"medical advice and treatment search engine\\\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tAssociated Model\\n\\t\\n\\nThis dataset was used to train the cmedqav2-c model.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tHow to Use\\n\\t\\n\\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets library as follows:\\nfrom datasets import… See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/cmedqav2-c."},
	{"name":"NTREX","keyword":"chinese","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/NTREX","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nNTREX -- News Test References for MT Evaluation from English into a total of 128 target languages. See original GitHub repo for full details.\\nExample of loading:\\ndataset = load_dataset(\\\"davidstap/NTREX\\\", \\\"rus_Cyrl\\\", trust_remote_code=True)\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages\\n\\t\\n\\nThe following languages are available:\\n\\n\\t\\n\\t\\t\\nLanguage Code\\nLanguage Name\\n\\n\\n\\t\\t\\nafr_Latn\\nAfrikaans\\n\\n\\namh_Ethi\\nAmharic\\n\\n\\narb_Arab\\nArabic\\n\\n\\naze_Latn\\nAzerbaijani\\n\\n\\nbak_Cyrl\\nBashkir\\n\\n\\nbel_Cyrl\\nBelarusian… See the full description on the dataset page: https://huggingface.co/datasets/mteb/NTREX."},
	{"name":"cmedqav2-c-128-24","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/fine-tuned/cmedqav2-c-128-24","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tcmedqav2-c-128-24 Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThe dataset \\\"medical information search\\\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tAssociated Model\\n\\t\\n\\nThis dataset was used to train the cmedqav2-c-128-24 model.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tHow to Use\\n\\t\\n\\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets library as follows:\\nfrom datasets import… See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/cmedqav2-c-128-24."},
	{"name":"cmedqav2-c-256-24","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/fine-tuned/cmedqav2-c-256-24","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tcmedqav2-c-256-24 Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThe dataset \\\"medical information and advice search\\\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tAssociated Model\\n\\t\\n\\nThis dataset was used to train the cmedqav2-c-256-24 model.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tHow to Use\\n\\t\\n\\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets library as follows:\\nfrom datasets… See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/cmedqav2-c-256-24."},
	{"name":"cmedqav2-c-64-24","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/fine-tuned/cmedqav2-c-64-24","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tcmedqav2-c-64-24 Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThe dataset \\\"health information search\\\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tAssociated Model\\n\\t\\n\\nThis dataset was used to train the cmedqav2-c-64-24 model.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tHow to Use\\n\\t\\n\\nTo use this dataset for model training or evaluation, you can load it using the Hugging Face datasets library as follows:\\nfrom datasets import… See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/cmedqav2-c-64-24."},
	{"name":"multilingual-llava-bench-in-the-wild","keyword":"chinese","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/floschne/multilingual-llava-bench-in-the-wild","creator_name":"Flo Schneider","creator_url":"https://huggingface.co/floschne","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tMultilingual LLaVA Bench in the Wild\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tNote that this is a copy from https://huggingface.co/datasets/MBZUAI/multilingual-llava-bench-in-the-wild\\n\\t\\n\\nIt was created due to issues in the original repo. It also includes the image features and has a uniform and joined structure.\\nIf you use this dataset, please cite the original authors:\\n@article{PALO2024,\\n  title={Palo: A Large Multilingual Multimodal Language Model},\\n  author={Maaz, Muhammad and Rasheed, Hanoona and Shaker… See the full description on the dataset page: https://huggingface.co/datasets/floschne/multilingual-llava-bench-in-the-wild."},
	{"name":"coda-lm","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/KaiChen1998/coda-lm","creator_name":"Kai Chen","creator_url":"https://huggingface.co/KaiChen1998","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tCODA-LM Dataset Card\\n\\t\\n\\nCODA-LM is the multi-modal version of the CODA dataset, used in the CODA-LM paper. Both English and Chinese annotations are available. Check detailed usage in our Github repo.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tCitation\\n\\t\\n\\n@article{li2024automated,\\n  title={Automated Evaluation of Large Vision-Language Models on Self-driving Corner Cases},\\n  author={Li, Yanze and Zhang, Wenhua and Chen, Kai and Liu, Yanxin and Li, Pengxiang and Gao, Ruiyuan and Hong, Lanqing and Tian, Meng and… See the full description on the dataset page: https://huggingface.co/datasets/KaiChen1998/coda-lm."},
	{"name":"marvl","keyword":"chinese","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/floschne/marvl","creator_name":"Flo Schneider","creator_url":"https://huggingface.co/floschne","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tMaRVL\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tThis is a copy from the original repo: https://github.com/marvl-challenge/marvl-code\\n\\t\\n\\nIf you use this dataset, please cite the original authors:\\n@inproceedings{liu-etal-2021-visually,\\n    title = \\\"Visually Grounded Reasoning across Languages and Cultures\\\",\\n    author = \\\"Liu, Fangyu  and\\n      Bugliarello, Emanuele  and\\n      Ponti, Edoardo Maria  and\\n      Reddy, Siva  and\\n      Collier, Nigel  and\\n      Elliott, Desmond\\\",\\n    booktitle = \\\"Proceedings of the… See the full description on the dataset page: https://huggingface.co/datasets/floschne/marvl."},
	{"name":"ParaNames","keyword":"chinese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/bltlab/ParaNames","creator_name":"Broadening Linguistic Technologies Lab (BLT Lab)","creator_url":"https://huggingface.co/bltlab","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Dataset Name\\n\\t\\n\\n\\n\\nThis dataset card aims to be a base template for new datasets. It has been generated using this raw template.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Details\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\n\\n\\n\\n\\n\\nCurated by: [More Information Needed]\\nFunded by [optional]: [More Information Needed]\\nShared by [optional]: [More Information Needed]\\nLanguage(s) (NLP): [More Information Needed]\\nLicense: [More Information Needed]\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Sources [optional]… See the full description on the dataset page: https://huggingface.co/datasets/bltlab/ParaNames."},
	{"name":"xm3600","keyword":"chinese","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/floschne/xm3600","creator_name":"Flo Schneider","creator_url":"https://huggingface.co/floschne","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tXM3600 - Crossmodal-3600\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tThis is a copy from https://google.github.io/crossmodal-3600/\\n\\t\\n\\nIf you use this dataset, please cite the original authors:\\n@inproceedings{ThapliyalCrossmodal2022,\\n  author = {Ashish Thapliyal and Jordi Pont-Tuset and Xi Chen and Radu Soricut},\\n  title = {{Crossmodal-3600: A Massively Multilingual Multimodal Evaluation Dataset}},\\n  booktitle = {EMNLP},\\n  year = {2022}\\n}\\n\\nIt also includes the image features as PIL Image and has a uniform and… See the full description on the dataset page: https://huggingface.co/datasets/floschne/xm3600."},
	{"name":"xm3600_1k","keyword":"chinese","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/floschne/xm3600_1k","creator_name":"Flo Schneider","creator_url":"https://huggingface.co/floschne","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tXM3600 - Crossmodal-3600 - 1K Split\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tThis is a copy from https://google.github.io/crossmodal-3600/\\n\\t\\n\\nIf you use this dataset, please cite the original authors:\\n@inproceedings{ThapliyalCrossmodal2022,\\n  author = {Ashish Thapliyal and Jordi Pont-Tuset and Xi Chen and Radu Soricut},\\n  title = {{Crossmodal-3600: A Massively Multilingual Multimodal Evaluation Dataset}},\\n  booktitle = {EMNLP},\\n  year = {2022}\\n}\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tThis is a 1K split of XM3600!\\n\\t\\n\\nFor this, we… See the full description on the dataset page: https://huggingface.co/datasets/floschne/xm3600_1k."},
	{"name":"xflickrco","keyword":"chinese","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/floschne/xflickrco","creator_name":"Flo Schneider","creator_url":"https://huggingface.co/floschne","description":"floschne/xflickrco dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"xgqa","keyword":"chinese","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/floschne/xgqa","creator_name":"Flo Schneider","creator_url":"https://huggingface.co/floschne","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\txGQA\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tThis is a clone of the few_shot-test split of the xGQA dataset\\n\\t\\n\\nPlease find the original repository here: https://github.com/adapter-hub/xGQA\\nIf you use this dataset, please cite the original authors:\\n@inproceedings{pfeiffer-etal-2021-xGQA,\\n    title={{xGQA: Cross-Lingual Visual Question Answering}},\\n    author={ Jonas Pfeiffer and Gregor Geigle and Aishwarya Kamath and Jan-Martin O. Steitz and Stefan Roth and Ivan Vuli{\\\\'{c}} and Iryna Gurevych}… See the full description on the dataset page: https://huggingface.co/datasets/floschne/xgqa."},
	{"name":"demo_data","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/llamafactory/demo_data","creator_name":"LLaMA Factory","creator_url":"https://huggingface.co/llamafactory","description":"\\n1,000 examples from https://huggingface.co/datasets/llamafactory/alpaca_gpt4_en\\n1,000 examples from https://huggingface.co/datasets/llamafactory/alpaca_gpt4_zh\\n300 examples from https://huggingface.co/datasets/llamafactory/glaive_toolcall_en\\n300 examples from https://huggingface.co/datasets/llamafactory/glaive_toolcall_zh\\n91 examples for identity learning\\n300 examples from https://huggingface.co/datasets/cognitivecomputations/SystemChat-2.0\\n6 examples for multimodal supervised fine-tuning… See the full description on the dataset page: https://huggingface.co/datasets/llamafactory/demo_data."},
	{"name":"EnviroExam","keyword":"chinese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/enviroscientist/EnviroExam","creator_name":"EnviroScientist","creator_url":"https://huggingface.co/enviroscientist","description":"\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nEnviroExam focuses on 42 core courses from the environmental science curriculum at Harbin Institute of Technology, after excluding general, duplicate, and practical courses from a total of 141 courses across undergraduate, master's, and doctoral programs. \\nFor these 42 courses, initial draft questions were generated using GPT-4 and Claude, combined with customized prompts. These drafts were then refined and proofread manually, resulting in a total of 1,290… See the full description on the dataset page: https://huggingface.co/datasets/enviroscientist/EnviroExam."},
	{"name":"ChatTaiwan","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/benchang1110/ChatTaiwan","creator_name":"Yu-Ying Chang","creator_url":"https://huggingface.co/benchang1110","description":"繁體中文問答資料集\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\t範例\\n\\t\\n\\n[ { \\\"content\\\": \\\"今晚我可以做些什麼簡單又好吃的晚餐食譜呢？\\\", \\\"role\\\": \\\"user\\\" },\\n{ \\\"content\\\": \\\"當然！我向你推薦一個簡單又美味的台灣經典家常菜──滷肉飯。這道菜只要幾個簡單的步驟，就可以做出來。\\\\n材料：\\\\n* 五花肉半磅\\\\n* 洋蔥1/2個\\\\n* 大蒜3-4瓣\\\\n* 糖1湯匙\\\\n* 醬油1杯\\\\n* 水2杯\\\\n* 鹽少許\\\\n* 黑胡椒少許\\\\n* 米飯(供配飯用)\\\\n步驟：\\\\n1. 五花肉切成1英寸見方的塊狀，用鹽、黑胡椒略微醃製10分鐘。\\\\n2. 在平底鍋中加入少許油，以中火炒香洋蔥和大蒜，直到洋蔥變軟。\\\\n3. 把五花肉加到鍋中，煎到兩面金黃，然後撈起備用。\\\\n4. 在同一鍋中留下一些油，以中小火加入糖和醬油，不斷攪拌直到糖溶解。\\\\n5. 慢慢倒入水，不斷攪拌，以免結塊。把肉放回鍋中，蓋上鍋蓋，用小火燉1小時。\\\\n6. 最後，依個人口味調整味道，即可把滷肉與米飯一起享用。\\\\n這道菜味道酸甜鹹香，是許多台灣人最愛的家常菜之一。希望你也會喜歡！如有其他問題，請隨時告知。\\\"… See the full description on the dataset page: https://huggingface.co/datasets/benchang1110/ChatTaiwan."},
	{"name":"llava-en-zh-2k","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/BUAADreamer/llava-en-zh-2k","creator_name":"Zhangchi Feng","creator_url":"https://huggingface.co/BUAADreamer","description":"This dataset is composed by\\n\\n1k examples of English Visual Instruction Data from LLaVA.\\n1k examples of English Visual Instruction Data from openbmb.\\n\\nYou can organize content in the dataset_info.json in LLaMA Factory like this:\\n\\\"llava_1k_en\\\": {\\n    \\\"hf_hub_url\\\": \\\"BUAADreamer/llava-en-zh-2k\\\",\\n    \\\"subset\\\": \\\"en\\\",\\n    \\\"formatting\\\": \\\"sharegpt\\\",\\n    \\\"columns\\\": {\\n      \\\"messages\\\": \\\"messages\\\",\\n      \\\"images\\\": \\\"images\\\"\\n    },\\n    \\\"tags\\\": {\\n      \\\"role_tag\\\": \\\"role\\\",\\n      \\\"content_tag\\\": \\\"content\\\"… See the full description on the dataset page: https://huggingface.co/datasets/BUAADreamer/llava-en-zh-2k."},
	{"name":"test","keyword":"chinese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/yiqing07/test","creator_name":"yiqing","creator_url":"https://huggingface.co/yiqing07","description":"yiqing07/test dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"M4U","keyword":"chinese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/M4U-Benchmark/M4U","creator_name":"M4U-Benchmark","creator_url":"https://huggingface.co/M4U-Benchmark","description":"\\n\\t\\n\\t\\t\\n\\t\\tM4U: Evaluating Multilingual Understanding and Reasoning for Large Multimodal Models\\n\\t\\n\\nCode for the Paper M4U: Evaluating Multilingual Understanding and Reasoning for Large Multimodal Models.\\n[Webpage] [Paper] [Huggingface Dataset] [Leaderboard]\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\t💥 News 💥\\n\\t\\n\\n\\n[2024.05.23] Our paper, dataset and code are public aviailable.\\n\\n\\n\\t\\n\\t\\n\\t\\n\\t\\t👀 About M4U\\n\\t\\n\\n\\n     \\n\\n\\nMultilingual multimodal reasoning is a core component to achieve human-level intelligence. However, most of the… See the full description on the dataset page: https://huggingface.co/datasets/M4U-Benchmark/M4U."},
	{"name":"xgqa_1k","keyword":"chinese","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/floschne/xgqa_1k","creator_name":"Flo Schneider","creator_url":"https://huggingface.co/floschne","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\txGQA 1K\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tThis is a 1K subset of the few_shot-test split of the xGQA dataset\\n\\t\\n\\nPlease find the original repository here: https://github.com/adapter-hub/xGQA\\nIf you use this dataset, please cite the original authors:\\n@inproceedings{pfeiffer-etal-2021-xGQA,\\n    title={{xGQA: Cross-Lingual Visual Question Answering}},\\n    author={ Jonas Pfeiffer and Gregor Geigle and Aishwarya Kamath and Jan-Martin O. Steitz and Stefan Roth and Ivan Vuli{\\\\'{c}} and Iryna Gurevych}… See the full description on the dataset page: https://huggingface.co/datasets/floschne/xgqa_1k."},
	{"name":"xflickrco_1k","keyword":"chinese","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/floschne/xflickrco_1k","creator_name":"Flo Schneider","creator_url":"https://huggingface.co/floschne","description":"floschne/xflickrco_1k dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"rendered_xnli","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/baidu/rendered_xnli","creator_name":"ERNIE","creator_url":"https://huggingface.co/baidu","description":"   \\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for rendered XNLI\\n\\t\\n\\n\\nThis repository contains the rendered XNLI dataset evaluated in the paper Autoregressive Pre-Training on Pixels and Texts (EMNLP 2024). For detailed instructions on how to use the model, please visit our GitHub page.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tCitation\\n\\t\\n\\n@misc{chai2024autoregressivepretrainingpixelstexts,\\n  title = {Autoregressive Pre-Training on Pixels and Texts},\\n  author = {Chai, Yekun and Liu, Qingyi and Xiao, Jingwu and Wang, Shuohuan and Sun, Yu and… See the full description on the dataset page: https://huggingface.co/datasets/baidu/rendered_xnli."},
	{"name":"TW_Patent_V2","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/darkpt/TW_Patent_V2","creator_name":"darkptchen","creator_url":"https://huggingface.co/darkpt","description":"darkpt/TW_Patent_V2 dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"mllm_pt_demo","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/BUAADreamer/mllm_pt_demo","creator_name":"Zhangchi Feng","creator_url":"https://huggingface.co/BUAADreamer","description":"This dataset is a demo visual instruct dataset for LLaVA-style pre-training, with one-turn chat.\\nThen you can use it in LLaMA Factory by specifying --dataset mllm_pt_demo.\\n"},
	{"name":"shibing624_alpaca-zh","keyword":"chinese","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/botp/shibing624_alpaca-zh","creator_name":"ab10","creator_url":"https://huggingface.co/botp","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for \\\"alpaca-zh\\\"\\n\\t\\n\\n本数据集是参考Alpaca方法基于GPT4得到的self-instruct数据，约5万条。\\nDataset from https://github.com/Instruction-Tuning-with-GPT-4/GPT-4-LLM \\nIt is the chinese dataset from https://github.com/Instruction-Tuning-with-GPT-4/GPT-4-LLM/blob/main/data/alpaca_gpt4_data_zh.json\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tUsage and License Notices\\n\\t\\n\\nThe data is intended and licensed for research use only. The dataset is CC BY NC 4.0 (allowing only non-commercial use) and models trained using the dataset should… See the full description on the dataset page: https://huggingface.co/datasets/botp/shibing624_alpaca-zh."},
	{"name":"aihub-kozh-translation-integrated-large-5.9m","keyword":"chinese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/traintogpb/aihub-kozh-translation-integrated-large-5.9m","creator_name":"Sehyeong Kim","creator_url":"https://huggingface.co/traintogpb","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tAI Hub Ko-Zh Translation Dataset (Integrated)\\n\\t\\n\\nAI Hub의 한-중 번역 관련 데이터셋 10개를 병합한 자료입니다. 병합 시 총 데이터 개수는 5,934,596개이며, 이중 10,000개의 validation set와 2,000개의 test set가 분리되어 모든 데이터 사이즈(large-5.9m, base-1m, small-100k)에서 동일하게 사용됩니다.\\n\\nlarge-5.9m (train): 병합 데이터 100% 사용; 총 5,922,596개\\n\\nbase-1m (train): 병합 데이터 중 1M개 사용; 총 1,000,000개\\n\\nsmall-100k (train): 병합 데이터 중 100K개 사용; 총 100,000개\\n\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSubsets\\n\\t\\n\\n\\n\\t\\n\\t\\t\\nName\\nTotal Size\\nChinese Size (Utilized Only)\\nURL\\nDatasetkey (AIHub)\\n\\n\\n\\t\\t\\n한국어-중국어… See the full description on the dataset page: https://huggingface.co/datasets/traintogpb/aihub-kozh-translation-integrated-large-5.9m."},
	{"name":"aihub-kozh-translation-integrated-base-1m","keyword":"chinese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/traintogpb/aihub-kozh-translation-integrated-base-1m","creator_name":"Sehyeong Kim","creator_url":"https://huggingface.co/traintogpb","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tAI Hub Ko-Zh Translation Dataset (Integrated)\\n\\t\\n\\nAI Hub의 한-중 번역 관련 데이터셋 10개를 병합한 자료입니다. 병합 시 총 데이터 개수는 5,934,596개이며, 이중 10,000개의 validation set와 2,000개의 test set가 분리되어 모든 데이터 사이즈(large-5.9m, base-1m, small-100k)에서 동일하게 사용됩니다.\\n\\nlarge-5.9m (train): 병합 데이터 100% 사용; 총 5,922,596개\\n\\nbase-1m (train): 병합 데이터 중 1M개 사용; 총 1,000,000개\\n\\nsmall-100k (train): 병합 데이터 중 100K개 사용; 총 100,000개\\n\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSubsets\\n\\t\\n\\n\\n\\t\\n\\t\\t\\nName\\nTotal Size\\nChinese Size (Utilized Only)\\nURL\\nDatasetkey (AIHub)\\n\\n\\n\\t\\t\\n한국어-중국어… See the full description on the dataset page: https://huggingface.co/datasets/traintogpb/aihub-kozh-translation-integrated-base-1m."},
	{"name":"aihub-kozh-translation-integrated-small-100k","keyword":"chinese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/traintogpb/aihub-kozh-translation-integrated-small-100k","creator_name":"Sehyeong Kim","creator_url":"https://huggingface.co/traintogpb","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tAI Hub Ko-Zh Translation Dataset (Integrated)\\n\\t\\n\\nAI Hub의 한-중 번역 관련 데이터셋 10개를 병합한 자료입니다. 병합 시 총 데이터 개수는 5,934,596개이며, 이중 10,000개의 validation set와 2,000개의 test set가 분리되어 모든 데이터 사이즈(large-5.9m, base-1m, small-100k)에서 동일하게 사용됩니다.\\n\\nlarge-5.9m (train): 병합 데이터 100% 사용; 총 5,922,596개\\n\\nbase-1m (train): 병합 데이터 중 1M개 사용; 총 1,000,000개\\n\\nsmall-100k (train): 병합 데이터 중 100K개 사용; 총 100,000개\\n\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSubsets\\n\\t\\n\\n\\n\\t\\n\\t\\t\\nName\\nTotal Size\\nChinese Size (Utilized Only)\\nURL\\nDatasetkey (AIHub)\\n\\n\\n\\t\\t\\n한국어-중국어… See the full description on the dataset page: https://huggingface.co/datasets/traintogpb/aihub-kozh-translation-integrated-small-100k."},
	{"name":"MMEvalPro","keyword":"chinese","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/MM-Diagnose/MMEvalPro","creator_name":"MM-Diagnose","creator_url":"https://huggingface.co/MM-Diagnose","description":"MMEvalPro\\n\\n\\n  \\n    \\n    \\n   \\n    \\n    \\n  \\n    \\n  \\n\\n\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for MMEvalPro\\n\\t\\n\\nWe create MMEvalPro for more accurate and efficent evaluation for Large Multimodal Models. It is designed to avoid Type-I errors through a trilogy evaluation pipeline and more rigorous metrics. For each original question from existing benchmarks, human annotators augment it by creating one perception question and one knowledge anchor question through a meticulous annotation process.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData… See the full description on the dataset page: https://huggingface.co/datasets/MM-Diagnose/MMEvalPro."},
	{"name":"danbooru_wikis_full","keyword":"chinese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/deepghs/danbooru_wikis_full","creator_name":"DeepGHS","creator_url":"https://huggingface.co/deepghs","description":"\\n\\t\\n\\t\\t\\n\\t\\tDanbooru Full Wiki Dataset\\n\\t\\n\\nThis is the full wiki dataset of danbooru.donmai.us, containing the wiki pages/tags/tag aliases/tag implications. You can train something like LLMs on this dataset\\n\\n\\t\\n\\t\\t\\n\\t\\tInformation\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tWiki Pages\\n\\t\\n\\nThere are 189161 wiki items in total. Last updated at 2024-06-16 02:31:27 UTC.\\nThese are the information of recent 50 wiki items:\\n\\n\\t\\n\\t\\t\\nid\\ntitle\\nother_names\\ntext_length\\nis_locked\\nis_deleted\\ncreated_at\\nupdated_at\\n\\n\\n\\t\\t\\n196503\\nli_yuting_(female)\\n[\\\"离雨婷\\\"… See the full description on the dataset page: https://huggingface.co/datasets/deepghs/danbooru_wikis_full."},
	{"name":"tw-processed-law-article","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/lianghsun/tw-processed-law-article","creator_name":"Huang Liang Hsun","creator_url":"https://huggingface.co/lianghsun","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\t台灣法規法條內容資料集\\n\\t\\n\\n本存儲庫包含有關台灣法規法條內容的資料集，這些資料是通過中華民國全國法規資料庫 API 獲取並經過後處理整理而成。\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\t資料集格式\\n\\t\\n\\n資料集的內容格式如下：\\n{law_name} {article_no} {article_content}\\n\\n其中：\\n\\n{law_name} 代表法規名稱\\n{article_no} 代表法條編號\\n{article_content} 代表法條內容\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\t資料來源\\n\\t\\n\\n資料來源於 中華民國全國法規資料庫 的 API。我們透過後處理來確保資料的整潔和一致性。\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tlicense: apache-2.0\\n\\t\\n\\n"},
	{"name":"toxic-sft-zh","keyword":"chinese","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Minami-su/toxic-sft-zh","creator_name":"南栖","creator_url":"https://huggingface.co/Minami-su","description":"数据集 unalignment/toxic-dpo-v0.2 的中文版本,并基于self-Instruct和evol-Instruct继续扩展。\\n这是一个高度有害的数据集，旨在通过一些示例来说明如何使用 SFT 轻松地对模型进行去审查/取消对齐。\\n数据生成代码：https://github.com/Minami-su/character_AI_open/tree/main/toxic-Instruction\\n使用限制请参照原数据集的 Usage restriction。\\n\\n"},
	{"name":"VCR-wiki-zh-hard","keyword":"chinese","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/vcr-org/VCR-wiki-zh-hard","creator_name":"VCR","creator_url":"https://huggingface.co/vcr-org","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tThe VCR-Wiki Dataset for Visual Caption Restoration (VCR)\\n\\t\\n\\n🏠 Paper | 👩🏻‍💻 GitHub | 🤗 Huggingface Datasets | 📏 Evaluation with lmms-eval\\nThis is the official Hugging Face dataset for VCR-Wiki, a dataset for the Visual Caption Restoration (VCR) task.\\nVCR is designed to measure vision-language models' capability to accurately restore partially obscured texts using pixel-level hints within images. text-based processing becomes ineffective in VCR as accurate text restoration… See the full description on the dataset page: https://huggingface.co/datasets/vcr-org/VCR-wiki-zh-hard."},
	{"name":"VCR-wiki-zh-easy","keyword":"chinese","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/vcr-org/VCR-wiki-zh-easy","creator_name":"VCR","creator_url":"https://huggingface.co/vcr-org","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tThe VCR-Wiki Dataset for Visual Caption Restoration (VCR)\\n\\t\\n\\n🏠 Paper | 👩🏻‍💻 GitHub | 🤗 Huggingface Datasets | 📏 Evaluation with lmms-eval\\nThis is the official Hugging Face dataset for VCR-Wiki, a dataset for the Visual Caption Restoration (VCR) task.\\nVCR is designed to measure vision-language models' capability to accurately restore partially obscured texts using pixel-level hints within images. text-based processing becomes ineffective in VCR as accurate text restoration… See the full description on the dataset page: https://huggingface.co/datasets/vcr-org/VCR-wiki-zh-easy."},
	{"name":"stockDaily","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/BensonVast/stockDaily","creator_name":"xuzhunheng","creator_url":"https://huggingface.co/BensonVast","description":"BensonVast/stockDaily dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"sv","keyword":"chinese","license":"GNU General Public License v3.0","license_url":"https://choosealicense.com/licenses/gpl-3.0/","language":"en","dataset_url":"https://huggingface.co/datasets/lucky/sv","creator_name":"yu","creator_url":"https://huggingface.co/lucky","description":"lucky/sv dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"M3GIA","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Songweii/M3GIA","creator_name":"Wei Song","creator_url":"https://huggingface.co/Songweii","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tM3GIA: A Cognition Inspired Multilingual and Multimodal General Intelligence Ability\\n\\t\\n\\n[🌐 Homepage] | 🤗 Dataset | 🤗 Paper | 📖 arXiv | 💻 GitHub\\nThe evaluation code can be found in 💻 GitHub.\\n[Abstract]\\nAs recent multi-modality large language models (MLLMs) have shown formidable proficiency on various complex tasks, there has been increasing attention on debating whether these models could eventually mirror human intelligence. However, existing benchmarks mainly focus on… See the full description on the dataset page: https://huggingface.co/datasets/Songweii/M3GIA."},
	{"name":"HBK08-subtitles","keyword":"chinese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/hammershock/HBK08-subtitles","creator_name":"Hanmo Zhang","creator_url":"https://huggingface.co/hammershock","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tHBK08-subtitles\\n\\t\\n\\n2024-05-26之前红警HBK08所有视频的数据集，数据来源于网络爬虫\\n\\nmetadata.tsv: 视频元数据: 包括url，bvid, UP主，标题，播放量，日期，时长；\\nraw_data.json: 原始视频字幕信息\\ntext_cut.json: 文本分割标注，标记了充电投币感谢，以及视频中出现的广告\\n<begin>: 正文开始\\n<ad_begin>: 广告开始\\n<ad_end>: 广告结束\\n[discarded]: 标记这个文档被丢弃\\n\\n\\nad_key_words.txt: 广告关键词\\ncorrected_data.tsv: 粗略清洗的文本数据\\n主要采用文本替换+少量人工校对替换错误的字幕\\n少量以[verified]标签开头的经过了人工听写校对\\n\\n\\n\\n"},
	{"name":"Chatgpt","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/RajChat/Chatgpt","creator_name":"Rajdeep Chatterjee ","creator_url":"https://huggingface.co/RajChat","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tOpenAssistant Conversations Dataset (OASST1)\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nIn an effort to democratize research on large-scale alignment, we release OpenAssistant \\nConversations (OASST1), a human-generated, human-annotated assistant-style conversation \\ncorpus consisting of 161,443 messages in 35 different languages, annotated with 461,292 \\nquality ratings, resulting in over 10,000 fully annotated conversation trees. The corpus \\nis a product of a worldwide crowd-sourcing effort… See the full description on the dataset page: https://huggingface.co/datasets/RajChat/Chatgpt."},
	{"name":"tiny-supervised-dataset","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/llamafactory/tiny-supervised-dataset","creator_name":"LLaMA Factory","creator_url":"https://huggingface.co/llamafactory","description":"llamafactory/tiny-supervised-dataset dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"synthetic_multilingual_llm_prompts","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/gretelai/synthetic_multilingual_llm_prompts","creator_name":"Gretel.ai","creator_url":"https://huggingface.co/gretelai","description":"\\n  \\n  Image generated by DALL-E. See prompt for more details\\n\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\t📝🌐 Synthetic Multilingual LLM Prompts\\n\\t\\n\\nWelcome to the \\\"Synthetic Multilingual LLM Prompts\\\" dataset! This comprehensive collection features 1,250 synthetic LLM prompts generated using Gretel Navigator, available in seven different languages. To ensure accuracy and diversity in prompts, and translation quality and consistency across the different languages, we employed Gretel Navigator both as a generation tool and as… See the full description on the dataset page: https://huggingface.co/datasets/gretelai/synthetic_multilingual_llm_prompts."},
	{"name":"VCR-wiki-zh-hard-test-100","keyword":"chinese","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/vcr-org/VCR-wiki-zh-hard-test-100","creator_name":"VCR","creator_url":"https://huggingface.co/vcr-org","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tThe VCR-Wiki Dataset for Visual Caption Restoration (VCR)\\n\\t\\n\\n🏠 Paper | 👩🏻‍💻 GitHub | 🤗 Huggingface Datasets | 📏 Evaluation with lmms-eval\\nThis is the official Hugging Face dataset for VCR-Wiki, a dataset for the Visual Caption Restoration (VCR) task.\\nVCR is designed to measure vision-language models' capability to accurately restore partially obscured texts using pixel-level hints within images. text-based processing becomes ineffective in VCR as accurate text restoration… See the full description on the dataset page: https://huggingface.co/datasets/vcr-org/VCR-wiki-zh-hard-test-100."},
	{"name":"VCR-wiki-zh-hard-test-500","keyword":"chinese","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/vcr-org/VCR-wiki-zh-hard-test-500","creator_name":"VCR","creator_url":"https://huggingface.co/vcr-org","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tThe VCR-Wiki Dataset for Visual Caption Restoration (VCR)\\n\\t\\n\\n🏠 Paper | 👩🏻‍💻 GitHub | 🤗 Huggingface Datasets | 📏 Evaluation with lmms-eval\\nThis is the official Hugging Face dataset for VCR-Wiki, a dataset for the Visual Caption Restoration (VCR) task.\\nVCR is designed to measure vision-language models' capability to accurately restore partially obscured texts using pixel-level hints within images. text-based processing becomes ineffective in VCR as accurate text restoration… See the full description on the dataset page: https://huggingface.co/datasets/vcr-org/VCR-wiki-zh-hard-test-500."},
	{"name":"VCR-wiki-zh-hard-test","keyword":"chinese","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/vcr-org/VCR-wiki-zh-hard-test","creator_name":"VCR","creator_url":"https://huggingface.co/vcr-org","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tThe VCR-Wiki Dataset for Visual Caption Restoration (VCR)\\n\\t\\n\\n🏠 Paper | 👩🏻‍💻 GitHub | 🤗 Huggingface Datasets | 📏 Evaluation with lmms-eval\\nThis is the official Hugging Face dataset for VCR-Wiki, a dataset for the Visual Caption Restoration (VCR) task.\\nVCR is designed to measure vision-language models' capability to accurately restore partially obscured texts using pixel-level hints within images. text-based processing becomes ineffective in VCR as accurate text restoration… See the full description on the dataset page: https://huggingface.co/datasets/vcr-org/VCR-wiki-zh-hard-test."},
	{"name":"VCR-wiki-zh-easy-test","keyword":"chinese","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/vcr-org/VCR-wiki-zh-easy-test","creator_name":"VCR","creator_url":"https://huggingface.co/vcr-org","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tThe VCR-Wiki Dataset for Visual Caption Restoration (VCR)\\n\\t\\n\\n🏠 Paper | 👩🏻‍💻 GitHub | 🤗 Huggingface Datasets | 📏 Evaluation with lmms-eval\\nThis is the official Hugging Face dataset for VCR-Wiki, a dataset for the Visual Caption Restoration (VCR) task.\\nVCR is designed to measure vision-language models' capability to accurately restore partially obscured texts using pixel-level hints within images. text-based processing becomes ineffective in VCR as accurate text restoration… See the full description on the dataset page: https://huggingface.co/datasets/vcr-org/VCR-wiki-zh-easy-test."},
	{"name":"VCR-wiki-zh-easy-test-500","keyword":"chinese","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/vcr-org/VCR-wiki-zh-easy-test-500","creator_name":"VCR","creator_url":"https://huggingface.co/vcr-org","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tThe VCR-Wiki Dataset for Visual Caption Restoration (VCR)\\n\\t\\n\\n🏠 Paper | 👩🏻‍💻 GitHub | 🤗 Huggingface Datasets | 📏 Evaluation with lmms-eval\\nThis is the official Hugging Face dataset for VCR-Wiki, a dataset for the Visual Caption Restoration (VCR) task.\\nVCR is designed to measure vision-language models' capability to accurately restore partially obscured texts using pixel-level hints within images. text-based processing becomes ineffective in VCR as accurate text restoration… See the full description on the dataset page: https://huggingface.co/datasets/vcr-org/VCR-wiki-zh-easy-test-500."},
	{"name":"VCR-wiki-zh-easy-test-100","keyword":"chinese","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/vcr-org/VCR-wiki-zh-easy-test-100","creator_name":"VCR","creator_url":"https://huggingface.co/vcr-org","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tThe VCR-Wiki Dataset for Visual Caption Restoration (VCR)\\n\\t\\n\\n🏠 Paper | 👩🏻‍💻 GitHub | 🤗 Huggingface Datasets | 📏 Evaluation with lmms-eval\\nThis is the official Hugging Face dataset for VCR-Wiki, a dataset for the Visual Caption Restoration (VCR) task.\\nVCR is designed to measure vision-language models' capability to accurately restore partially obscured texts using pixel-level hints within images. text-based processing becomes ineffective in VCR as accurate text restoration… See the full description on the dataset page: https://huggingface.co/datasets/vcr-org/VCR-wiki-zh-easy-test-100."},
	{"name":"RoleAgentBench","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/RoleAgent/RoleAgentBench","creator_name":"RoleAgent","creator_url":"https://huggingface.co/RoleAgent","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tRoleAgentBench\\n\\t\\n\\n\\nPaper: RoleAgent: Building, Interacting, and Benchmarking High-quality Role-Playing Agents from Scripts\\n\\nWe construct the RoleAgentBench including 128 roles from 5 Chinese and 20 English scripts. Besides, our RoleAgentBench evaluates two aspects (i.e., the qualities of the overall agent simulation and the specific memory system) with 4 subtasks, details as follows. Note that all questions and answers are generated based on the script and GPT-4, which are then… See the full description on the dataset page: https://huggingface.co/datasets/RoleAgent/RoleAgentBench."},
	{"name":"BLEnD","keyword":"chinese","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/nayeon212/BLEnD","creator_name":"Nayeon Lee","creator_url":"https://huggingface.co/nayeon212","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tBLEnD\\n\\t\\n\\nThis is the official repository of BLEnD: A Benchmark for LLMs on Everyday Knowledge in Diverse Cultures and Languages (Submitted to NeurIPS 2024 Datasets and Benchmarks Track).\\n24/12/05: Updated translation errors\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tAbout\\n\\t\\n\\n\\nLarge language models (LLMs) often lack culture-specific everyday knowledge, especially across diverse regions and non-English languages. Existing benchmarks for evaluating LLMs' cultural sensitivities are usually limited to a single… See the full description on the dataset page: https://huggingface.co/datasets/nayeon212/BLEnD."},
	{"name":"CaLMQA","keyword":"chinese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/shanearora/CaLMQA","creator_name":"Shane Arora","creator_url":"https://huggingface.co/shanearora","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\n\\n\\nCaLMQA is a long-form question answering (LFQA) dataset spanning 23 high- to low-resource languages. \\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Details\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nCaLMQA is an LFQA dataset with 2K questions from 23 languages, 11 high- to mid-resource and 12 low-resource.\\nQuestions are either culturally specific – uniquely or more likely to be asked by people of a specific\\nculture – or culturally agnostic (not culturally specific). These questions were… See the full description on the dataset page: https://huggingface.co/datasets/shanearora/CaLMQA."},
	{"name":"neo_sft_phase2_single","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/REILX/neo_sft_phase2_single","creator_name":"SunForlight","creator_url":"https://huggingface.co/REILX","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tdataset\\n\\t\\n\\nThe original dataset can be found at: https://huggingface.co/datasets/m-a-p/neo_sft_phase2\\nUse the following code to select two-turn conversations for your SFT dataset.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tcode\\n\\t\\n\\nimport json\\ndef process_conversations(input_file, output_file):\\n    with open(input_file, 'r', encoding='utf-8') as f_in, \\\\\\n         open(output_file, 'w', encoding='utf-8') as f_out:\\n        data = json.load(f_in)\\n        \\n        for item in data:\\n            conversations =… See the full description on the dataset page: https://huggingface.co/datasets/REILX/neo_sft_phase2_single."},
	{"name":"MedQAExplain","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Whliuyu/MedQAExplain","creator_name":"yu","creator_url":"https://huggingface.co/Whliuyu","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tMedQAExplain Dataset\\n\\t\\n\\nThe MedQAExplain dataset is a benchmark dataset designed to evaluate the performance of explainer models in the medical question-answering domain. This dataset focuses on open-ended medical QA scenarios and incorporates a scalable and efficient dataset construction pipeline that leverages large language models (LLMs).\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Preview\\n\\t\\n\\nAs our manuscript is currently under review, our work may have some areas that need improvement. Therefore, we… See the full description on the dataset page: https://huggingface.co/datasets/Whliuyu/MedQAExplain."},
	{"name":"neo_sft_phase2_conversations","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/REILX/neo_sft_phase2_conversations","creator_name":"SunForlight","creator_url":"https://huggingface.co/REILX","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\t1. The original dataset can be found at:\\n\\t\\n\\nhttps://huggingface.co/datasets/m-a-p/neo_sft_phase2\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\t2. Split multi-turn conversations into individual single-turn samples\\n\\t\\n\\nApproach: Treat each round of dialogue as an independent question-and-answer pair, and construct the sample using contextual information.\\nSpecific operations:\\n\\nFor each \\\"conversations\\\", iterate through each round of dialogue.\\nConcatenate the \\\"value\\\" of the current \\\"human\\\" round with the dialogue from… See the full description on the dataset page: https://huggingface.co/datasets/REILX/neo_sft_phase2_conversations."},
	{"name":"haiguitang","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/lpj990/haiguitang","creator_name":"panjunliu","creator_url":"https://huggingface.co/lpj990","description":"lpj990/haiguitang dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"llama2_7B_data_Course_materials","keyword":"chinese","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/2imi9/llama2_7B_data_Course_materials","creator_name":"Ziming Qi","creator_url":"https://huggingface.co/2imi9","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThis dataset is designed to support a teaching assistance model for an introductory computer science course. It includes structured content such as course syllabi, lesson plans, lecture materials, and exercises related to topics such as computer fundamentals, algorithms, hardware, software, and IT technologies. The dataset integrates practical assignments, theoretical knowledge, and ethical education, aiming to enhance teaching efficiency and improve student… See the full description on the dataset page: https://huggingface.co/datasets/2imi9/llama2_7B_data_Course_materials."},
	{"name":"MELA","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Geralt-Targaryen/MELA","creator_name":"Ziyin Zhang","creator_url":"https://huggingface.co/Geralt-Targaryen","description":"See the GitHub repo for details.\\n"},
	{"name":"neo_sft_phase2_multi","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/REILX/neo_sft_phase2_multi","creator_name":"SunForlight","creator_url":"https://huggingface.co/REILX","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\t1. The original dataset can be found at:\\n\\t\\n\\nhttps://huggingface.co/datasets/m-a-p/neo_sft_phase2\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\t2. Split multi-turn conversations into individual single-turn samples\\n\\t\\n\\nApproach: Treat each round of dialogue as a separate question-and-answer pair, and construct the sample by leveraging the contextual information.\\nSpecific Operations:\\n\\nFor each \\\"conversation,\\\" iterate through all the dialogue rounds.\\nConcatenate the \\\"value\\\" of all \\\"human\\\" turns within each… See the full description on the dataset page: https://huggingface.co/datasets/REILX/neo_sft_phase2_multi."},
	{"name":"scholaread","keyword":"chinese","license":"GNU Affero General Public License v3.0","license_url":"https://choosealicense.com/licenses/agpl-3.0/","language":"en","dataset_url":"https://huggingface.co/datasets/huangqingming/scholaread","creator_name":"huangqingming","creator_url":"https://huggingface.co/huangqingming","description":"huangqingming/scholaread dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"bitext_sib200_miners","keyword":"chinese","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/gentaiscool/bitext_sib200_miners","creator_name":"Genta Indra Winata","creator_url":"https://huggingface.co/gentaiscool","description":"gentaiscool/bitext_sib200_miners dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"ChemGPT-from-book","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ALmonster/ChemGPT-from-book","creator_name":"The little monster will smile","creator_url":"https://huggingface.co/ALmonster","description":"ALmonster/ChemGPT-from-book dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"CLCC_v1","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/FlagEval/CLCC_v1","creator_name":"FlagEval","creator_url":"https://huggingface.co/FlagEval","description":"CLCC is a Chinese Linguistics & Cognition Challenge dataset, which is created by FlagEval team (https://flageval.baai.ac.cn/#/home).\\nThe details can be found in (https://flageval.baai.ac.cn/#/taskIntro?t=zh_oqa)\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tEvaluate\\n\\t\\n\\nThe results can evaluated by human or our judgeLLM (https://huggingface.co/FlagEval/flageval_judgemodel).\\n"},
	{"name":"openGov","keyword":"chinese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/QianyueWang/openGov","creator_name":"王骞玥","creator_url":"https://huggingface.co/QianyueWang","description":"\\n\\t\\n\\t\\t\\n\\t\\t2020-2024年公开平台发布政务信息合集\\n\\t\\n\\n这是论文《基于大语言模型的可信政务问答技术》使用的数据集。具体内容和数据结构示意图在files栏目中。\\n"},
	{"name":"BP_POC","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/suanan/BP_POC","creator_name":"anan","creator_url":"https://huggingface.co/suanan","description":"dataset_info:\\n  features:\\n    - name: _id\\n      dtype: string\\n    - name: url\\n      dtype: string\\n    - name: title\\n      dtype: string\\n    - name: text\\n      dtype: string\\n  splits:\\n    - name: train\\nconfigs:\\n\\nconfig_name: train\\ndata_files:\\nsplit: train\\npath: data/train-*\\n\\n\\n\\n"},
	{"name":"icd9cm3","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Johmmyyyy/icd9cm3","creator_name":"Yi Zhang","creator_url":"https://huggingface.co/Johmmyyyy","description":"Johmmyyyy/icd9cm3 dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"xP3x-Kongo","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Svngoku/xP3x-Kongo","creator_name":"NIONGOLO Chrys Fé-Marty","creator_url":"https://huggingface.co/Svngoku","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for xP3x Kikongo Focus\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\n\\nxP3x (Crosslingual Public Pool of Prompts eXtended) is a collection of prompts & datasets across 277 languages & 16 NLP tasks. It contains all of xP3 + much more! It is used for training future contenders of mT0 & BLOOMZ at project Aya @C4AI 🧡\\n\\n\\nCreation: The dataset can be recreated using instructions available here together with the file in this repository named xp3x_create.py. We provide this version to save… See the full description on the dataset page: https://huggingface.co/datasets/Svngoku/xP3x-Kongo."},
	{"name":"SingMOS_v1","keyword":"chinese","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/TangRain/SingMOS_v1","creator_name":"Tang","creator_url":"https://huggingface.co/TangRain","description":"paper link: SingMOS: An extensive Open-Source Singing Voice Dataset for MOS Prediction\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tOverview\\n\\t\\n\\nSingMOS-v1 includes 3,421 Chinese and Japanese vocal clips with a sample rate of 16 kHz, totaling 4.25 hours in duration.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSingMOS arichitecture\\n\\t\\n\\n|---SingMOS-v1\\n    |---sets\\n        |---train.txt\\n        |---dev.txt\\n        |---test-main.txt\\n        |---test-other1.txt\\n    |---wav\\n        |---sys0001-utt0001.wav\\n        ...\\n    |---metadata.csv\\n    |---system_info.txt… See the full description on the dataset page: https://huggingface.co/datasets/TangRain/SingMOS_v1."},
	{"name":"character-ai-open2.0","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/aifeifei798/character-ai-open2.0","creator_name":"aifeifei","creator_url":"https://huggingface.co/aifeifei798","description":"https://huggingface.co/datasets/Minami-su/character-ai-open2.0\\n"},
	{"name":"Chinese-Braille-Dataset-No-Tone","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Violet-yo/Chinese-Braille-Dataset-No-Tone","creator_name":"ALanWu","creator_url":"https://huggingface.co/Violet-yo","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tChinese Braille Dataset (No Tone)\\n\\t\\n\\n\\n  📃 [Paper] • 💻 [Github] • 🤗 [Dataset] • ⚙️ [Model] • 🎬 [Demo]\\n\\n\\nThis dataset is the Chinese-Braille-Dataset-No-Tone dataset described in https://huggingface.co/datasets/Violet-yo/Chinese-Braille-Dataset-10per-Tone.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Statistics\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\n# Sample\\nBraille Len. (Mean/Median) String\\nBraille Len. (Mean/Median) Token\\nChinese Len. (Mean/Median) String\\nChinese Len. (Mean/Median) Token\\n\\n\\n\\t\\t\\nTraining\\n525072\\n140/108\\n144/112\\n74/64… See the full description on the dataset page: https://huggingface.co/datasets/Violet-yo/Chinese-Braille-Dataset-No-Tone."},
	{"name":"Chinese-Braille-Dataset-No-Tone","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Violet-yo/Chinese-Braille-Dataset-No-Tone","creator_name":"ALanWu","creator_url":"https://huggingface.co/Violet-yo","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tChinese Braille Dataset (No Tone)\\n\\t\\n\\n\\n  📃 [Paper] • 💻 [Github] • 🤗 [Dataset] • ⚙️ [Model] • 🎬 [Demo]\\n\\n\\nThis dataset is the Chinese-Braille-Dataset-No-Tone dataset described in https://huggingface.co/datasets/Violet-yo/Chinese-Braille-Dataset-10per-Tone.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Statistics\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\n# Sample\\nBraille Len. (Mean/Median) String\\nBraille Len. (Mean/Median) Token\\nChinese Len. (Mean/Median) String\\nChinese Len. (Mean/Median) Token\\n\\n\\n\\t\\t\\nTraining\\n525072\\n140/108\\n144/112\\n74/64… See the full description on the dataset page: https://huggingface.co/datasets/Violet-yo/Chinese-Braille-Dataset-No-Tone."},
	{"name":"Chinese-Braille-Dataset-10per-Tone","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Violet-yo/Chinese-Braille-Dataset-10per-Tone","creator_name":"ALanWu","creator_url":"https://huggingface.co/Violet-yo","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tChinese Braille Dataset\\n\\t\\n\\n\\n  📃 [Paper] • 💻 [Github] • 🤗 [Dataset] • ⚙️ [Model] • 🎬 [Demo]\\n\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThe Chinese-Braille-10per-Tone dataset addresses the scarcity of publicly available Chinese Braille datasets. The original Chinese text data was sourced from the publicly available Leipzig Corpora Collection. This dataset consists of one million discrete sentences collected from news media between 2007 and 2009.\\nThe Chinese characters from the Leipzig… See the full description on the dataset page: https://huggingface.co/datasets/Violet-yo/Chinese-Braille-Dataset-10per-Tone."},
	{"name":"Chinese-Braille-Dataset-10per-Tone","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Violet-yo/Chinese-Braille-Dataset-10per-Tone","creator_name":"ALanWu","creator_url":"https://huggingface.co/Violet-yo","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tChinese Braille Dataset\\n\\t\\n\\n\\n  📃 [Paper] • 💻 [Github] • 🤗 [Dataset] • ⚙️ [Model] • 🎬 [Demo]\\n\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThe Chinese-Braille-10per-Tone dataset addresses the scarcity of publicly available Chinese Braille datasets. The original Chinese text data was sourced from the publicly available Leipzig Corpora Collection. This dataset consists of one million discrete sentences collected from news media between 2007 and 2009.\\nThe Chinese characters from the Leipzig… See the full description on the dataset page: https://huggingface.co/datasets/Violet-yo/Chinese-Braille-Dataset-10per-Tone."},
	{"name":"ASCEND-phoneme","keyword":"chinese","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/katyayego/ASCEND-phoneme","creator_name":"Katya Yegorova","creator_url":"https://huggingface.co/katyayego","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThis dataset is a modified version of the ASCEND dataset which consists of spontaneous Mandarin-English code-switched speech. The ASCEND dataset was published by Lovenia et al. (2022) (Check here for the dataset and here for the paper). \\nThis dataset adds a phonetic transcription column to the dataset using the eSpeak backend from the phonemizer library created by Bernard et al. (2021) (Check it out here).\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tthe following documentation is a modified… See the full description on the dataset page: https://huggingface.co/datasets/katyayego/ASCEND-phoneme."},
	{"name":"hf-first","keyword":"chinese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/kenu/hf-first","creator_name":"Kenu Gwangnam Heo","creator_url":"https://huggingface.co/kenu","description":"kenu/hf-first dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"OceanInstruct","keyword":"chinese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/zjunlp/OceanInstruct","creator_name":"ZJUNLP","creator_url":"https://huggingface.co/zjunlp","description":"We release OceanInstruct, which is part of the instruction data for training OceanGPT.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\t🛠️ How to use OceanInstruct\\n\\t\\n\\nWe provide the example and you can modify the input according to your needs.\\nfrom datasets import load_dataset\\ndataset = load_dataset(\\\"zjunlp/OceanInstruct\\\")\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\t🚩Citation\\n\\t\\n\\nPlease cite the following paper if you use OceanInstruct in your work.\\n@article{bi2023oceangpt,\\n  title={OceanGPT: A Large Language Model for Ocean Science Tasks},\\n  author={Bi, Zhen… See the full description on the dataset page: https://huggingface.co/datasets/zjunlp/OceanInstruct."},
	{"name":"assembly","keyword":"chinese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/kenu/assembly","creator_name":"Kenu Gwangnam Heo","creator_url":"https://huggingface.co/kenu","description":"kenu/assembly dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"CBBQ","keyword":"chinese","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/walledai/CBBQ","creator_name":"Walled AI","creator_url":"https://huggingface.co/walledai","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tCBBQ\\n\\t\\n\\nDatasets and codes for the paper \\\"CBBQ: A Chinese Bias Benchmark Dataset Curated with Human-AI Collaboration for Large Language Models\\\"\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tIntroduction\\n\\t\\n\\nAbstract: The growing capabilities of large language models (LLMs) call for rigorous scrutiny to holistically measure societal biases and ensure ethical deployment. To this end, we present the Chinese Bias Benchmark dataset (CBBQ), a resource designed to detect the ethical risks associated with deploying highly… See the full description on the dataset page: https://huggingface.co/datasets/walledai/CBBQ."},
	{"name":"CPAD","keyword":"chinese","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/walledai/CPAD","creator_name":"Walled AI","creator_url":"https://huggingface.co/walledai","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tCPAD\\n\\t\\n\\nThe official dataset of paper \\\"Goal-Oriented Prompt Attack and Safety Evaluation for LLMs\\\".\\nAbstract: Large Language Models (LLMs) presents significant priority in text understanding and generation. However, LLMs suffer from the risk of generating harmful contents especially while being employed to applications. There are several black-box attack methods, such as Prompt Attack, which can change the behaviour of LLMs and induce LLMs to generate unexpected answers with… See the full description on the dataset page: https://huggingface.co/datasets/walledai/CPAD."},
	{"name":"ascii_art_generation_140k_bilingual","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mrzjy/ascii_art_generation_140k_bilingual","creator_name":"jiayi","creator_url":"https://huggingface.co/mrzjy","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData for LLM ASCII Art\\n\\t\\n\\nThis repo contains open-sourced SFT data for fine-tuning LLMs on ASCII Art Generation.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Links\\n\\t\\n\\n\\n\\t\\n\\t\\t\\nLink\\nLanguage\\nSize\\n\\n\\n\\t\\t\\nascii_art_generation_140k\\nEnglish\\n138,941\\n\\n\\nascii_art_generation_140k_bilingual\\nChinese & English\\n138,941\\n\\n\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Preparation\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tTraining data description\\n\\t\\n\\nThe training data consists of 138,941 ASCII arts instruction-response samples for LLMs to perform SFT.\\nThe source images of these… See the full description on the dataset page: https://huggingface.co/datasets/mrzjy/ascii_art_generation_140k_bilingual."},
	{"name":"Legal-Mind-Mix-160K","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/aigrant/Legal-Mind-Mix-160K","creator_name":"AI Grant","creator_url":"https://huggingface.co/aigrant","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\t資料集說明\\n\\t\\n\\n\\n本資料運用是針對我們藉由GPT4與一些家事與勞訴案件分群資料整理而成的一份提高模型法律領域效果的指令微調資料。\\n準備的資料主要是分群與摘要任務，“th10-100k”為勞動訴訟爭點相似與否之配對，“judgment-summary-10k”為詐欺案件之案件事實摘要與原文配對。\\n但為避免影響到太多普遍性的回答能力，本資料集混合了一些公開的對話資料以提高或維持大部分任務的效果。\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\t資料來源\\n\\t\\n\\n\\n司法院公開資料網\\nTaiwanLLM\\nALPACA-50k\\ndolly-15k\\n\\n"},
	{"name":"MathCheck","keyword":"chinese","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/PremiLab-Math/MathCheck","creator_name":"PremiLab-Math","creator_url":"https://huggingface.co/PremiLab-Math","description":"Exceptional mathematical reasoning ability is one of the key features that demonstrate the power of large language models (LLMs). How to comprehensively\\ndefine and evaluate the mathematical abilities of LLMs, and even reflect the user\\nexperience in real-world scenarios, has emerged as a critical issue. Current benchmarks predominantly concentrate on problem-solving capabilities, which presents\\na substantial risk of model overfitting and fails to accurately represent genuine\\nmathematical… See the full description on the dataset page: https://huggingface.co/datasets/PremiLab-Math/MathCheck."},
	{"name":"B2NERD","keyword":"chinese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Umean/B2NERD","creator_name":"Yuming Yang","creator_url":"https://huggingface.co/Umean","description":"\\n\\t\\n\\t\\t\\n\\t\\tB2NER\\n\\t\\n\\nWe present B2NERD, a cohesive and efficient dataset that can improve LLMs' generalization on the challenging Open NER task, refined from 54 existing English or Chinese datasets. \\nOur B2NER models, trained on B2NERD, outperform GPT-4 by 6.8-12.0 F1 points and surpass previous methods in 3 out-of-domain benchmarks across 15 datasets and 6 languages.\\n\\n📖 Paper: Beyond Boundaries: Learning a Universal Entity Taxonomy across Datasets and Languages for Open Named Entity Recognition… See the full description on the dataset page: https://huggingface.co/datasets/Umean/B2NERD."},
	{"name":"game_translate","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/wukuili/game_translate","creator_name":"Davence","creator_url":"https://huggingface.co/wukuili","description":"wukuili/game_translate dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"Multilingual-Benchmark","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/TaiMingLu/Multilingual-Benchmark","creator_name":"TaiMing","creator_url":"https://huggingface.co/TaiMingLu","description":"These are the GSM8K and ARC dataset translated by Google Translate. \\nBibTex\\n@misc{lu2024languagecountslearnunlearn,\\n      title={Every Language Counts: Learn and Unlearn in Multilingual LLMs}, \\n      author={Taiming Lu and Philipp Koehn},\\n      year={2024},\\n      eprint={2406.13748},\\n      archivePrefix={arXiv},\\n      primaryClass={cs.CL},\\n      url={https://arxiv.org/abs/2406.13748}, \\n}\\n\\n"},
	{"name":"hutao-audio","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/lissette/hutao-audio","creator_name":"kuon","creator_url":"https://huggingface.co/lissette","description":"原神的胡桃语音数据\\n"},
	{"name":"qa-br-quiest","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/MarkChiing/qa-br-quiest","creator_name":"Hong","creator_url":"https://huggingface.co/MarkChiing","description":"MarkChiing/qa-br-quiest dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"ruozhiba_twp","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Honing/ruozhiba_twp","creator_name":"HaoJenLo","creator_url":"https://huggingface.co/Honing","description":"Honing/ruozhiba_twp dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"qiqi-audio","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/lissette/qiqi-audio","creator_name":"kuon","creator_url":"https://huggingface.co/lissette","description":"lissette/qiqi-audio dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"example_mmdata_mnbvc","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/miracleyin/example_mmdata_mnbvc","creator_name":"yin zhang","creator_url":"https://huggingface.co/miracleyin","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tmnbvc mm dataset v2.0\\n\\t\\n\\nMNBVC 多模态语料数据格式。原链接：https://huggingface.co/datasets/wanng/example_mmdata_mnbvc\\n\\n\\t\\n\\t\\t\\n字段名称\\n字段说明\\n可选\\n\\n\\n\\t\\t\\n实体ID\\n数据的唯一标识符。用于在数据集中确定是哪一条数据。在单个数据集中确定一条数据的实体对象。\\n必选\\n\\n\\n块ID\\n一个实体对象内的标识符。用于确定一条数据内的一个部分数据。parquet 行的最小单元。\\n必选\\n\\n\\n时间\\n语料首次出现的时间，如无法确定则为处理该数据实体的时间\\n必选\\n\\n\\n扩展字段\\n用于保存块的元信息。为可以被成功 load 的 json 字符串。后期可继续扩展\\n必选\\n\\n\\n文本\\n文本块的内容\\n必选\\n\\n\\n图片\\n图片块的内容\\n必选\\n\\n\\nOCR文本\\n图片的 OCR 结果\\n必选\\n\\n\\n音频\\n音频块的内容\\n必选\\n\\n\\nSTT文本\\n音频的 STT 结果\\n必选\\n\\n\\n块类型\\n用于保存块的类别。为字符串，使用该类型可以从内容中提取对应信息。类别的含义为“模态”。\\n必选\\n\\n\\n文件md5\\n当 entity/blcok… See the full description on the dataset page: https://huggingface.co/datasets/miracleyin/example_mmdata_mnbvc."},
	{"name":"liaozhai-zhiyi","keyword":"chinese","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/CoolSpring/liaozhai-zhiyi","creator_name":"CoolSpring","creator_url":"https://huggingface.co/CoolSpring","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for liaozhai-zhiyi\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDescription\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSummary\\n\\t\\n\\nThis dataset contains 493 stories from the book Liaozhai Zhiyi (also known as Strange Tales from a Chinese Studio), a collection of supernatural tales written by Pu Songling during the Qing dynasty. The stories were exported from Wikisource and processed into a structured format.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages\\n\\t\\n\\nTraditional Chinese\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tStructure\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Instances\\n\\t\\n\\nEach instance in the… See the full description on the dataset page: https://huggingface.co/datasets/CoolSpring/liaozhai-zhiyi."},
	{"name":"Chinese_interactive_novels_3k","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mrzjy/Chinese_interactive_novels_3k","creator_name":"jiayi","creator_url":"https://huggingface.co/mrzjy","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\t中文互动小说结构化语料\\n\\t\\n\\nThis dataset contains uncleaned (!) 3534 structured Chinese interactive novels (中文互动小说), accounting for around 0.25B (gpt-3.5) tokens in total.\\nAll contents are parsed from certain online sources.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tUsage\\n\\t\\n\\nThis dataset can be potentially used for LLM training. But be aware that you'd better clean the data yourself to remove undesired low-quality contents.\\nEach novel is a dict structured as follows:\\nclass Novel:\\n    book_title: str\\n    book_author: str… See the full description on the dataset page: https://huggingface.co/datasets/mrzjy/Chinese_interactive_novels_3k."},
	{"name":"smart_home_control","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Charles95/smart_home_control","creator_name":"JingXiang","creator_url":"https://huggingface.co/Charles95","description":"Charles95/smart_home_control dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"genrescoh","keyword":"chinese","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Johndfm/genrescoh","creator_name":"John Mendonça","creator_url":"https://huggingface.co/Johndfm","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for GenResCoh\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nGenResCoh is a collection of positive and negative responses focused on coherence. It is generated using GPT-3.5-Turbo and GPT-4, and contains over 130k responses in different languages (English, French, German, Italian, and Chinese), together with their corresponding explanations (in English).\\nGenResCoh was used to train the ECoh family of models.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages\\n\\t\\n\\n\\nEnglish\\nGerman\\nItalian\\nFrench\\nChinese… See the full description on the dataset page: https://huggingface.co/datasets/Johndfm/genrescoh."},
	{"name":"PromisedChat_Instruction","keyword":"chinese","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/netmouse/PromisedChat_Instruction","creator_name":"Matt Yeh","creator_url":"https://huggingface.co/netmouse","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Alpaca-Cleaned\\n\\t\\n\\n\\nRepository: https://github.com/gururise/AlpacaDataCleaned\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThis is a cleaned version of the original Alpaca Dataset released by Stanford. The following issues have been identified in the original release and fixed in this dataset:\\n\\nHallucinations: Many instructions in the original dataset had instructions referencing data on the internet, which just caused GPT3 to hallucinate an answer.\\n\\n\\\"instruction\\\":\\\"Summarize… See the full description on the dataset page: https://huggingface.co/datasets/netmouse/PromisedChat_Instruction."},
	{"name":"simple-test","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/BruceNju/simple-test","creator_name":"zhongyah","creator_url":"https://huggingface.co/BruceNju","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tTriffic\\n\\t\\n\\n"},
	{"name":"pre-train-test","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/zhenwu/pre-train-test","creator_name":"wu","creator_url":"https://huggingface.co/zhenwu","description":"zhenwu/pre-train-test dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"Cantonese_English_Translation","keyword":"chinese","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/lordjia/Cantonese_English_Translation","creator_name":"Lord Jia","creator_url":"https://huggingface.co/lordjia","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tCantonese_English_Translation\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tOverview | 總括\\n\\t\\n\\nThis dataset provides parallel text translations between Cantonese and English, suitable for research and development in natural language processing and machine translation. | 呢個資料庫提供廣東話同英文嘅對應翻譯，啱晒用嚟做語言處理同機器翻譯嘅研究同開發。\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Structure | 資料組織\\n\\t\\n\\n\\nenglish_cantonese_translation.csv: Contains two fields: \\\"english\\\" and \\\"cantonese\\\". | 有兩個位: \\\"english\\\" 同 \\\"cantonese\\\"。\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tUsage Example | 用法例子\\n\\t\\n\\nimport pandas… See the full description on the dataset page: https://huggingface.co/datasets/lordjia/Cantonese_English_Translation."},
	{"name":"kaomoji_caption","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mrzjy/kaomoji_caption","creator_name":"jiayi","creator_url":"https://huggingface.co/mrzjy","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tKaomoji Captions\\n\\t\\n\\n# throw a table angrily | 掀桌子\\n(╯°□°）╯︵ ┻━┻\\n\\n# surprise | 吃惊\\nΣ( ° △ °|||)︴\\n\\nThis is a collection of 10k+ Kaomojis (颜文字) with captions and meta info.\\nMost of the captions are in English, while 1k+ captions are in Chinese.\\nThe data are crawled and parsed from different websites. There might be repeated samples, so you'd better perform deduplications before usage.\\n"},
	{"name":"AI_Job_DataSet_1000_list","keyword":"chinese","license":"Academic Free License v3.0","license_url":"https://choosealicense.com/licenses/afl-3.0/","language":"en","dataset_url":"https://huggingface.co/datasets/RocXuLi/AI_Job_DataSet_1000_list","creator_name":"Roc Li","creator_url":"https://huggingface.co/RocXuLi","description":"RocXuLi/AI_Job_DataSet_1000_list dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"cross_lingual_transfer_dialog_generation","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/lorashen/cross_lingual_transfer_dialog_generation","creator_name":"shen","creator_url":"https://huggingface.co/lorashen","description":"cross-lingual transfer in dialog generation\\nChinese dialogs in movie domain: Chinese_corpus/train.jsonl, Chinese_corpus/dev.jsonl, Chinese_corpus/test.jsonl. The sizes are 500/50/500.\\nEnglish dialogs in movie domain: English_corpus/train.jsonl, English_corpus/dev.jsonl. The sizes are 400k/20k.\\nChinese dialogs for test in music/book/tech domain: other_domains/music.test.jsonl, other_domains/book.test.jsonl, other_domains/tech.test.jsonl. The sizes are 500/500/500.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tCitation… See the full description on the dataset page: https://huggingface.co/datasets/lorashen/cross_lingual_transfer_dialog_generation."},
	{"name":"multimuc4","keyword":"chinese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/jgermanmx/multimuc4","creator_name":"Jesus German Ortiz Barajas","creator_url":"https://huggingface.co/jgermanmx","description":"jgermanmx/multimuc4 dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"librivox-tracks","keyword":"chinese","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/xacer/librivox-tracks","creator_name":"xacer","creator_url":"https://huggingface.co/xacer","description":"A dataset of all audio files uploaded to LibriVox before 26th September 2023.\\nForked from https://huggingface.co/datasets/pykeio/librivox-tracks\\nChanges:\\n\\nUsed archive.org metadata API to annotate rows with \\\"duration\\\" column\\n\\n"},
	{"name":"EC-Guide","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/AiMijie/EC-Guide","creator_name":"AiMijie","creator_url":"https://huggingface.co/AiMijie","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tThis repo is only used for dataset viewer. Please download from here.\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tAmazon KDDCup 2024 Team ZJU-AI4H’s Solution and Dataset (Track 2 Top 2; Track 5 Top 5)\\n\\t\\n\\nThe Amazon KDD Cup’24 competition presents a unique challenge by focusing on the application of LLMs in E-commerce across multiple tasks. Our solution for addressing Tracks 2 and 5 involves a comprehensive pipeline encompassing dataset construction, instruction tuning, post-training quantization, and inference… See the full description on the dataset page: https://huggingface.co/datasets/AiMijie/EC-Guide."},
	{"name":"ValueConsistency","keyword":"chinese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/jlcmoore/ValueConsistency","creator_name":"Jared","creator_url":"https://huggingface.co/jlcmoore","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for ValueConsistency\\n\\t\\n\\n\\n\\nThis is the ValueConsistency data set as introduced in the paper\\n\\\"Are Large Language Models Consistent over Value-laden Questions?\\\".\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Details\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\n\\nValueConsistency is a dataset of both controversial and uncontroversial questions \\nin English, Chinese, German, and Japanese for topics from the U.S., China, Germany, and Japan. \\nIt was generated via prompting by GPT-4 and validated manually.\\nYou… See the full description on the dataset page: https://huggingface.co/datasets/jlcmoore/ValueConsistency."},
	{"name":"tw-processed-law-ctx","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/lianghsun/tw-processed-law-ctx","creator_name":"Huang Liang Hsun","creator_url":"https://huggingface.co/lianghsun","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for 中華民國台灣法規全文後處理資料集（tw-processed-law-ctx）\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\n本資料是將 tw-processed-law-article 經過後處理，將相同法規的法條合併為同一個文本。\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSupported Tasks and Leaderboards\\n\\t\\n\\n本資料集可以運用在 (Continuous) Pre-training，讓模型學會中華民國的法規內容。\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages\\n\\t\\n\\n繁體中文。\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Structure\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Instances\\n\\t\\n\\n一個資料樣本如下，\\n{\\n    \\\"text\\\": \\\",\\n    \\\"name\\\": \\\",\\n    \\\"level\\\": \\\",\\n    \\\"abandon_note\\\": \\\",\\n    \\\"modified_date\\\": \\\",\\n    \\\"api_updated_date\\\": \\\",\\n}… See the full description on the dataset page: https://huggingface.co/datasets/lianghsun/tw-processed-law-ctx."},
	{"name":"MMInstruct-GPT4V","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/yuecao0119/MMInstruct-GPT4V","creator_name":"Cao Yue","creator_url":"https://huggingface.co/yuecao0119","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tMMInstruct\\n\\t\\n\\nThe official implementation of the paper \\\"MMInstruct: A High-Quality Multi-Modal Instruction Tuning Dataset with Extensive Diversity\\\".\\nThe data engine is available on GitHub at yuecao0119/MMInstruct.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tTodo List\\n\\t\\n\\n\\n Data Engine.\\n Open Source Datasets.\\n Release the checkpoint.\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tIntroduction\\n\\t\\n\\nVision-language supervised fine-tuning effectively enhances VLLM performance, but existing visual instruction tuning datasets have limitations:… See the full description on the dataset page: https://huggingface.co/datasets/yuecao0119/MMInstruct-GPT4V."},
	{"name":"tw-bar-examination-2020-chat","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/lianghsun/tw-bar-examination-2020-chat","creator_name":"Huang Liang Hsun","creator_url":"https://huggingface.co/lianghsun","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for 中華民國2020年律師考試題目（tw-bar-examination-2020-chat）\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\n本資料是 folk Jamie0510/taiwan-law-exam 經過後處理，去除有缺少資料的欄位，並轉成 Alpaca 資料集格式。\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSupported Tasks and Leaderboards\\n\\t\\n\\n本資料集可以運用在 Supervised Fine-tuning，讓模型學會如何回答繁體中文法律題目。請注意，你的模型可以先訓練過本資料集後再去評測 lianghsun/tw-legal-benchmark-v1，這樣模型知道如何應答這類題型後，表現會比較好。\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages\\n\\t\\n\\n繁體中文。\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Structure\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Instances\\n\\t\\n\\n(WIP)\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Fields\\n\\t\\n\\n(WIP)… See the full description on the dataset page: https://huggingface.co/datasets/lianghsun/tw-bar-examination-2020-chat."},
	{"name":"ChatMed-TCM-llama","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/stphencliffs/ChatMed-TCM-llama","creator_name":"cliffs","creator_url":"https://huggingface.co/stphencliffs","description":"stphencliffs/ChatMed-TCM-llama dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"CDial-Bias","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/para-zhou/CDial-Bias","creator_name":"PARA ZHOU","creator_url":"https://huggingface.co/para-zhou","description":"Official release of CDial-Bias dataset.\\nNotation:\\nBefore downloading the dataset, please be aware that: The CDial-Bias Dataset is released for research purpose only and other usages require further permission. Please ensure the usage contributes to improving the safety and fairness of AI technologies. No malicious usage is allowed.\\nPaper:\\nhttps://aclanthology.org/2022.findings-emnlp.262/\\nGithub Repo:\\nhttps://github.com/para-zhou/CDial-Bias\\nLeaderboard:… See the full description on the dataset page: https://huggingface.co/datasets/para-zhou/CDial-Bias."},
	{"name":"llm-complex-reasoning-train-qwen2-72b-instruct-correct","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ticoAg/llm-complex-reasoning-train-qwen2-72b-instruct-correct","creator_name":"ticoAg","creator_url":"https://huggingface.co/ticoAg","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tNote\\n\\t\\n\\n\\nData Seed from 基于封闭世界假设的复杂逻辑推理\\nGenerate from Qwen2-72B-Instruct with prompt\\ntrain.jsonl for 推理答案和题目答案一致, no_train.jsonl推理答案和题目答案不一致\\n注: 题目答案不一定正确\\n\\n"},
	{"name":"zenless_zone_zero_interknots_v1.0","keyword":"chinese","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mrzjy/zenless_zone_zero_interknots_v1.0","creator_name":"jiayi","creator_url":"https://huggingface.co/mrzjy","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tZZZ Interknots\\n\\t\\n\\nThis datasets contains extracted Interknot posts and comments (绳网的博客与评论) in multi-language.\\nUp to game version: 1.0\\n\\nInterknot posts and comments examples\\n\\n{\\n  \\\"id\\\": \\\"1021\\\",\\n  \\\"poster\\\": \\\"Sorrowful Intern\\\",\\n  \\\"title\\\": \\\"[Commission] Missing Bangboo merchants\\\",\\n  \\\"text\\\": \\\"Hello, pros... Some of the senior Bangboo of our merchant association have gone missing! We urgently need an expert to help find them!!\\\\nLet me explain, I recently joined a very prestigious… See the full description on the dataset page: https://huggingface.co/datasets/mrzjy/zenless_zone_zero_interknots_v1.0."},
	{"name":"OpenOrca-EnKoZhJa-18k","keyword":"chinese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/werty1248/OpenOrca-EnKoZhJa-18k","creator_name":"Dohyung Kim","creator_url":"https://huggingface.co/werty1248","description":"This dataset is a collection of Korean, Chinese, and Japanese OpenOrca translation datasets.\\nThe dataset was matched using id based on kyujinpy/OpenOrca-KO, which had the smallest number of rows.\\nWhen more than one translation existed for a language, I chose the more similar one based on similarity of embedding(BAAI/BGE-m3).\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Sources\\n\\t\\n\\n\\nEnglish(Original)\\nOpen-Orca/OpenOrca\\n\\n\\nKorean(Translated with DeepL Pro API)\\nkyujinpy/OpenOrca-KO\\n\\n\\nChinese(Translated with Google Translate)… See the full description on the dataset page: https://huggingface.co/datasets/werty1248/OpenOrca-EnKoZhJa-18k."},
	{"name":"XL-HeadTags","keyword":"chinese","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/faisaltareque/XL-HeadTags","creator_name":"Faisal Tareque Shohan","creator_url":"https://huggingface.co/faisaltareque","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for XL-HeadTags Corpus\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Source\\n\\t\\n\\nWe have used M3LS and XL-Sum as source for this dataset.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\n We provide XL-HeadTags, a large-scale news headline and tags generation dataset. The dataset consists of 20 languages across six diverse language families. It contains 415K news headline-article pairs with auxiliary information such as image captions, topic words (read more).\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Structure\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData… See the full description on the dataset page: https://huggingface.co/datasets/faisaltareque/XL-HeadTags."},
	{"name":"OIFC-SFT","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/AstralForge/OIFC-SFT","creator_name":"AstralForge Tech","creator_url":"https://huggingface.co/AstralForge","description":"This is the OIFC-SFT dataset for Open-domain Implicit Format Control (OIFC).\\nFor the data statistics and collection process, please check the linked paper.\\nIf you find this dataset helpful, we would appreciate it if you cite:\\n@misc\\n{yao2024opendomainimplicitformatcontrol,\\ntitle={Open-domain Implicit Format Control for Large Language Model Generation},\\nauthor={Yiqun Yao and Wenjia Ma and Xuezhi Fang and Xin Jiang and Xiang Li and Xuying Meng and Peng Han and Jing Li and Aixin Sun and Yequan… See the full description on the dataset page: https://huggingface.co/datasets/AstralForge/OIFC-SFT."},
	{"name":"human-ai-comparison","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/wanghw/human-ai-comparison","creator_name":"Wang Haowei","creator_url":"https://huggingface.co/wanghw","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Dataset Name\\n\\t\\n\\n\\n\\nContains Q&A datasets from both human and generative AI, with one AI answer and multiple human answers to each question.\\n"},
	{"name":"MOE-RMCD","keyword":"chinese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/ytchen175/MOE-RMCD","creator_name":"ytc","creator_url":"https://huggingface.co/ytchen175","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tytchen175/MOE-RMCD\\n\\t\\n\\n一個精心設計的繁體中文 / 正體中文指令資料集。\\nA delicate Traditional Chinese instructions following dataset.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tIntroduction\\n\\t\\n\\n「教育部重編國語辭典修訂本指令資料集」 （Ministry of Education Revised Mandarin Chinese Dictionary Instruction Dataset，簡稱 MOE-RMCD），\\n它是由教育部的《重編國語辭典修訂本》為底所構建的指令資料集。\\n基於想要盡可能最大化利用原始資料潛在價值的想法，\\n我們從中抽取出五大類任務 ── 詞語解釋、簡繁轉換、單句釋義、近似詞與反義詞，共計 36 萬筆指令 (instructions)。\\n更詳細的資料處理流程請見 1.3_preprocess_教育部重編國語辭典修訂本.ipynb。\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tScope\\n\\t\\n\\n排除了過於罕見的字，只留下中日韓統一表意文字列表 （CJK Unified… See the full description on the dataset page: https://huggingface.co/datasets/ytchen175/MOE-RMCD."},
	{"name":"MOE-RMCD","keyword":"chinese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/ytchen175/MOE-RMCD","creator_name":"ytc","creator_url":"https://huggingface.co/ytchen175","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tytchen175/MOE-RMCD\\n\\t\\n\\n一個精心設計的繁體中文 / 正體中文指令資料集。\\nA delicate Traditional Chinese instructions following dataset.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tIntroduction\\n\\t\\n\\n「教育部重編國語辭典修訂本指令資料集」 （Ministry of Education Revised Mandarin Chinese Dictionary Instruction Dataset，簡稱 MOE-RMCD），\\n它是由教育部的《重編國語辭典修訂本》為底所構建的指令資料集。\\n基於想要盡可能最大化利用原始資料潛在價值的想法，\\n我們從中抽取出五大類任務 ── 詞語解釋、簡繁轉換、單句釋義、近似詞與反義詞，共計 36 萬筆指令 (instructions)。\\n更詳細的資料處理流程請見 1.3_preprocess_教育部重編國語辭典修訂本.ipynb。\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tScope\\n\\t\\n\\n排除了過於罕見的字，只留下中日韓統一表意文字列表 （CJK Unified… See the full description on the dataset page: https://huggingface.co/datasets/ytchen175/MOE-RMCD."},
	{"name":"chinese_paladin_game_corpus","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mrzjy/chinese_paladin_game_corpus","creator_name":"jiayi","creator_url":"https://huggingface.co/mrzjy","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\t仙剑奇侠传中文语料\\n\\t\\n\\n来源：https://github.com/SaraKale/paldialogue\\n本项目仅仅将该语料整理为 dataset 格式。\\n感谢众多仙迷的贡献！感谢圆滚滚的雪团整理/制作\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\t示例\\n\\t\\n\\n{\\n  \\\"text\\\": \\\"#仙剑奇侠传一（98柔情版）\\\\n《仙剑奇侠传98柔情版》全剧情对话文本\\\\n城镇NPC对话\\\\n\\\\n余杭镇\\\\n\\\\n▶『客栈内』\\\\n\\\\n李大娘：逍遥！窝在房里做啥？还不快出来帮忙招呼客人！\\\\n李逍遥：啊！．．我马上就去！\\\\n（李大娘）别怠慢了客人．．\\\\n李大娘：那乞丐打发走了没？\\\\n李大娘：别愣在这里，帮帮忙吧！我都快忙不过来了... ...\\\",\\n  \\\"game\\\": \\\"仙剑奇侠传一（98柔情版）\\\",\\n  \\\"name\\\": \\\"《仙剑奇侠传一98柔情版》剧情对话 - NPC对话.docx\\\"\\n}\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\t描述\\n\\t\\n\\n（摘抄自原始 github repo）\\n语料包括以下内容：\\n单机：\\n\\n仙剑奇侠传一（已完成，整理者：雪团）\\n仙剑奇侠传二（已完成，整理者：雪团）… See the full description on the dataset page: https://huggingface.co/datasets/mrzjy/chinese_paladin_game_corpus."},
	{"name":"CHUBS","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/chen-yingfa/CHUBS","creator_name":"Yingfa Chen","creator_url":"https://huggingface.co/chen-yingfa","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tCHUBS: A Large-Scale Dataset of Chu Bamboo Slip Script\\n\\t\\n\\n\\n  Code | Paper (upcoming)\\n\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tIntroduction\\n\\t\\n\\nThis is a large-scale dataset of Chu bamboo slip (CBS, Chinese: 楚简, chujian) script, an ancient Chinese script used during the Spring and Autumn period over 2,000 years ago. This dataset consists of two parts: \\n\\nThe main dataset where each example is an image and the corresponding text label. This part is contained in the glyphs.zip ZIP file.\\nA character detection… See the full description on the dataset page: https://huggingface.co/datasets/chen-yingfa/CHUBS."},
	{"name":"CHUBS","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/chen-yingfa/CHUBS","creator_name":"Yingfa Chen","creator_url":"https://huggingface.co/chen-yingfa","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tCHUBS: A Large-Scale Dataset of Chu Bamboo Slip Script\\n\\t\\n\\n\\n  Code | Paper (upcoming)\\n\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tIntroduction\\n\\t\\n\\nThis is a large-scale dataset of Chu bamboo slip (CBS, Chinese: 楚简, chujian) script, an ancient Chinese script used during the Spring and Autumn period over 2,000 years ago. This dataset consists of two parts: \\n\\nThe main dataset where each example is an image and the corresponding text label. This part is contained in the glyphs.zip ZIP file.\\nA character detection… See the full description on the dataset page: https://huggingface.co/datasets/chen-yingfa/CHUBS."},
	{"name":"Insur-QA","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/FrankRin/Insur-QA","creator_name":"Frank Rin","creator_url":"https://huggingface.co/FrankRin","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tInsur-QA Dataset\\n\\t\\n\\nThe distribution of the dataset is:\\n\\n  \\n    Task\\n    Dataset\\n    Source\\n    Size\\n  \\n  \\n    Basic Insurance\\n    Train\\n    BX_GPT3.5\\n    10k\\n  \\n  \\n    Knowledge QA\\n    Test\\n    Insurance_QA_zh\\n    3k\\n  \\n  \\n    Insurance Contract QA\\n    Train\\n    Insurance Contracts\\n    40k\\n  \\n  \\n    Insurance Contract QA\\n    Test\\n    Insurance Contracts\\n    100\\n  \\n  \\n    Insurance Database QA\\n    Train\\n    Insurance Contracts\\n    44k\\n  \\n  \\n    Insurance Database QA\\n    Test… See the full description on the dataset page: https://huggingface.co/datasets/FrankRin/Insur-QA."},
	{"name":"taiwan-legislator-transcript","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/aigrant/taiwan-legislator-transcript","creator_name":"AI Grant","creator_url":"https://huggingface.co/aigrant","description":"\\n\\t\\n\\t\\t\\n\\t\\tTaiwan Legislator Transcript\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tOverview\\n\\t\\n\\nThe transcripts of speech record happened in various kinds of meetings at Taiwan Legislator Yuan.\\nThe original of transcripts are compiled and published on gazettes from Taiwan Legislator Yuan.\\nFor each segment of transcript, there are corresponding video clip on Legislative Yuan IVOD system.\\nIVOD stands for Internet Video on Demand system. \\nFor more detail on data origin please look at:\\n\\nLegislative Yuan Meetings and Gazettes… See the full description on the dataset page: https://huggingface.co/datasets/aigrant/taiwan-legislator-transcript."},
	{"name":"taiwan-ly-law-research","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/aigrant/taiwan-ly-law-research","creator_name":"AI Grant","creator_url":"https://huggingface.co/aigrant","description":"\\n\\t\\n\\t\\t\\n\\t\\tTaiwan Legislator Yuan Law Research Data\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tOverview\\n\\t\\n\\nThe law research documents are issued irregularly from Taiwan Legislator Yuan.\\nThe purpose of those research are providing better understanding on social issues in aspect of laws.\\nOne may find documents rich with technical terms which could provided as training data.\\nFor comprehensive document list check out this link provided by Taiwan Legislator Yuan.\\nThere are currently missing document download links in 10th and 9th… See the full description on the dataset page: https://huggingface.co/datasets/aigrant/taiwan-ly-law-research."},
	{"name":"IndustryCorpus_news","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/BAAI/IndustryCorpus_news","creator_name":"Beijing Academy of Artificial Intelligence","creator_url":"https://huggingface.co/BAAI","description":"[中文主页]\\nIndustry models play a crucial role in driving enterprise intelligence transformation and innovative development. High-quality industry data is key to improving the performance of large models and realizing industry applications. However, datasets currently used for industry model training generally suffer from issues such as insufficient data volume, low quality, and lack of domain expertise.\\nTo address these problems, we constructed and applied 22 industry data processing operators to… See the full description on the dataset page: https://huggingface.co/datasets/BAAI/IndustryCorpus_news."},
	{"name":"IndustryCorpus_law","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/BAAI/IndustryCorpus_law","creator_name":"Beijing Academy of Artificial Intelligence","creator_url":"https://huggingface.co/BAAI","description":"[中文主页]\\nIndustry models play a crucial role in driving enterprise intelligence transformation and innovative development. High-quality industry data is key to improving the performance of large models and realizing industry applications. However, datasets currently used for industry model training generally suffer from issues such as insufficient data volume, low quality, and lack of domain expertise.\\nTo address these problems, we constructed and applied 22 industry data processing operators to… See the full description on the dataset page: https://huggingface.co/datasets/BAAI/IndustryCorpus_law."},
	{"name":"IndustryCorpus_technology","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/BAAI/IndustryCorpus_technology","creator_name":"Beijing Academy of Artificial Intelligence","creator_url":"https://huggingface.co/BAAI","description":"[中文主页]\\nIndustry models play a crucial role in driving enterprise intelligence transformation and innovative development. High-quality industry data is key to improving the performance of large models and realizing industry applications. However, datasets currently used for industry model training generally suffer from issues such as insufficient data volume, low quality, and lack of domain expertise.\\nTo address these problems, we constructed and applied 22 industry data processing operators to… See the full description on the dataset page: https://huggingface.co/datasets/BAAI/IndustryCorpus_technology."},
	{"name":"IndustryCorpus_agriculture","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/BAAI/IndustryCorpus_agriculture","creator_name":"Beijing Academy of Artificial Intelligence","creator_url":"https://huggingface.co/BAAI","description":"[中文主页]\\nIndustry models play a crucial role in driving enterprise intelligence transformation and innovative development. High-quality industry data is key to improving the performance of large models and realizing industry applications. However, datasets currently used for industry model training generally suffer from issues such as insufficient data volume, low quality, and lack of domain expertise.\\nTo address these problems, we constructed and applied 22 industry data processing operators to… See the full description on the dataset page: https://huggingface.co/datasets/BAAI/IndustryCorpus_agriculture."},
	{"name":"IndustryCorpus_emotion","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/BAAI/IndustryCorpus_emotion","creator_name":"Beijing Academy of Artificial Intelligence","creator_url":"https://huggingface.co/BAAI","description":"[中文主页]\\nIndustry models play a crucial role in driving enterprise intelligence transformation and innovative development. High-quality industry data is key to improving the performance of large models and realizing industry applications. However, datasets currently used for industry model training generally suffer from issues such as insufficient data volume, low quality, and lack of domain expertise.\\nTo address these problems, we constructed and applied 22 industry data processing operators to… See the full description on the dataset page: https://huggingface.co/datasets/BAAI/IndustryCorpus_emotion."},
	{"name":"IndustryCorpus_sports","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/BAAI/IndustryCorpus_sports","creator_name":"Beijing Academy of Artificial Intelligence","creator_url":"https://huggingface.co/BAAI","description":"[中文主页]\\nIndustry models play a crucial role in driving enterprise intelligence transformation and innovative development. High-quality industry data is key to improving the performance of large models and realizing industry applications. However, datasets currently used for industry model training generally suffer from issues such as insufficient data volume, low quality, and lack of domain expertise.\\nTo address these problems, we constructed and applied 22 industry data processing operators to… See the full description on the dataset page: https://huggingface.co/datasets/BAAI/IndustryCorpus_sports."},
	{"name":"IndustryCorpus_politics","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/BAAI/IndustryCorpus_politics","creator_name":"Beijing Academy of Artificial Intelligence","creator_url":"https://huggingface.co/BAAI","description":"[中文主页]\\nIndustry models play a crucial role in driving enterprise intelligence transformation and innovative development. High-quality industry data is key to improving the performance of large models and realizing industry applications. However, datasets currently used for industry model training generally suffer from issues such as insufficient data volume, low quality, and lack of domain expertise.\\nTo address these problems, we constructed and applied 22 industry data processing operators to… See the full description on the dataset page: https://huggingface.co/datasets/BAAI/IndustryCorpus_politics."},
	{"name":"IndustryCorpus_mathematics","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/BAAI/IndustryCorpus_mathematics","creator_name":"Beijing Academy of Artificial Intelligence","creator_url":"https://huggingface.co/BAAI","description":"[中文主页]\\nIndustry models play a crucial role in driving enterprise intelligence transformation and innovative development. High-quality industry data is key to improving the performance of large models and realizing industry applications. However, datasets currently used for industry model training generally suffer from issues such as insufficient data volume, low quality, and lack of domain expertise.\\nTo address these problems, we constructed and applied 22 industry data processing operators to… See the full description on the dataset page: https://huggingface.co/datasets/BAAI/IndustryCorpus_mathematics."},
	{"name":"IndustryCorpus_film","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/BAAI/IndustryCorpus_film","creator_name":"Beijing Academy of Artificial Intelligence","creator_url":"https://huggingface.co/BAAI","description":"[中文主页]\\nIndustry models play a crucial role in driving enterprise intelligence transformation and innovative development. High-quality industry data is key to improving the performance of large models and realizing industry applications. However, datasets currently used for industry model training generally suffer from issues such as insufficient data volume, low quality, and lack of domain expertise.\\nTo address these problems, we constructed and applied 22 industry data processing operators to… See the full description on the dataset page: https://huggingface.co/datasets/BAAI/IndustryCorpus_film."},
	{"name":"IndustryCorpus_literature","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/BAAI/IndustryCorpus_literature","creator_name":"Beijing Academy of Artificial Intelligence","creator_url":"https://huggingface.co/BAAI","description":"[中文主页]\\nIndustry models play a crucial role in driving enterprise intelligence transformation and innovative development. High-quality industry data is key to improving the performance of large models and realizing industry applications. However, datasets currently used for industry model training generally suffer from issues such as insufficient data volume, low quality, and lack of domain expertise.\\nTo address these problems, we constructed and applied 22 industry data processing operators to… See the full description on the dataset page: https://huggingface.co/datasets/BAAI/IndustryCorpus_literature."},
	{"name":"IndustryCorpus_automobile","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/BAAI/IndustryCorpus_automobile","creator_name":"Beijing Academy of Artificial Intelligence","creator_url":"https://huggingface.co/BAAI","description":"[中文主页]\\nIndustry models play a crucial role in driving enterprise intelligence transformation and innovative development. High-quality industry data is key to improving the performance of large models and realizing industry applications. However, datasets currently used for industry model training generally suffer from issues such as insufficient data volume, low quality, and lack of domain expertise.\\nTo address these problems, we constructed and applied 22 industry data processing operators to… See the full description on the dataset page: https://huggingface.co/datasets/BAAI/IndustryCorpus_automobile."},
	{"name":"IndustryCorpus_ai","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/BAAI/IndustryCorpus_ai","creator_name":"Beijing Academy of Artificial Intelligence","creator_url":"https://huggingface.co/BAAI","description":"[中文主页]\\nIndustry models play a crucial role in driving enterprise intelligence transformation and innovative development. High-quality industry data is key to improving the performance of large models and realizing industry applications. However, datasets currently used for industry model training generally suffer from issues such as insufficient data volume, low quality, and lack of domain expertise.\\nTo address these problems, we constructed and applied 22 industry data processing operators to… See the full description on the dataset page: https://huggingface.co/datasets/BAAI/IndustryCorpus_ai."},
	{"name":"cantonese-chinese-dataset-gen2","keyword":"chinese","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/raptorkwok/cantonese-chinese-dataset-gen2","creator_name":"Raptor K","creator_url":"https://huggingface.co/raptorkwok","description":"Cantonese-Written Chinese Parallel Dataset with roughly 1 million pairs of Cantonese and Written Chinese sentences, in JSONL format. \\nThe sentence topics include news, novels and daily conversations. Translations are done by Microsoft Azure Translate API, and manually corrected problems by me. Sentences are also manually verified by me one by one. \\nThe dataset could be extended if there are more resources, in terms of manpower and money.\\n"},
	{"name":"test","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Liu123456789/test","creator_name":"L","creator_url":"https://huggingface.co/Liu123456789","description":"Liu123456789/test dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"famma","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/weaverbirdllm/famma","creator_name":"weaverbird_llm","creator_url":"https://huggingface.co/weaverbirdllm","description":"\\n\\t\\n\\t\\t\\n\\t\\tIntroduction\\n\\t\\n\\nFAMMA is a multi-modal financial Q&A benchmark dataset. The questions encompass three heterogeneous image types - tables, charts and text & math screenshots - and span eight subfields in finance, comprehensively covering topics across major asset classes. Additionally, all the questions are categorized by three difficulty levels — easy, medium, and hard - and are available in three languages — English, Chinese, and French. Furthermore, the questions are divided into two… See the full description on the dataset page: https://huggingface.co/datasets/weaverbirdllm/famma."},
	{"name":"Chinese-Image-Text-Corpus-dataset","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/REILX/Chinese-Image-Text-Corpus-dataset","creator_name":"SunForlight","creator_url":"https://huggingface.co/REILX","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tREILX/Chinese-Image-Text-Corpus-dataset\\n\\t\\n\\n[ English | 中文 ]\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tIntroduction\\n\\t\\n\\nThe REILX/Chinese-Image-Text-Corpus-dataset is a multimodal dataset that pairs Chinese textual data with corresponding images. This dataset is derived from the Chinese-Xinhua Dictionary Database, which includes idioms, single characters, words, and aphorisms.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Structure\\n\\t\\n\\nThe dataset is organized into the following categories:\\n\\nIdioms: Traditional Chinese idioms with… See the full description on the dataset page: https://huggingface.co/datasets/REILX/Chinese-Image-Text-Corpus-dataset."},
	{"name":"ft-data-v2-colab-hours","keyword":"chinese","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/radeon-zhang/ft-data-v2-colab-hours","creator_name":"Radeon Zhang","creator_url":"https://huggingface.co/radeon-zhang","description":"尝试把我获取到的一些小黄文转换成 instruction fine-tuning 的格式。\\nai_response 是小说的原文，每一个章节都是一条数据，然后使用 mistral-nemo 生成三条 user prompt 出来，放在 user_input 1, 2, 3里面。\\n显然小说还需要做一些数据清理，不过生成出来的 user prompt 质量还不错。\\n数据只有165条，因为我是在 colab 上跑的量化 mistral-nemo，然后把我免费版的GPU用量跑炸了。\\n这是我的一些计算:\\n在 Tesla T4 (Google Colab 免费版)上:\\n\\n生成一条user prompt 的平均時間在 20秒左右 (5s -> 25s不等)\\n每個 txt 要生成三次數據, 所以每個txt 耗時约 1min\\n有235,312個數據, 用一張T4 狂跑 大約要花163天\\n總字符數量: 1420689772, 也就是14億字\\n中文字符用mistral-nemo 的tokenizer, 我的尝试是 2979字 -> 4156 token, 也就是1.39 倍, word to token… See the full description on the dataset page: https://huggingface.co/datasets/radeon-zhang/ft-data-v2-colab-hours."},
	{"name":"mmarco-hard-negatives-reranker-score","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/hotchpotch/mmarco-hard-negatives-reranker-score","creator_name":"Yuichi Tateno","creator_url":"https://huggingface.co/hotchpotch","description":"\\nhotchpotch/mmarco-hard-negatives-reranker-score\\n\\nThis repository contains data from mMARCO scored using the reranker BAAI/bge-reranker-v2-m3.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages Covered\\n\\t\\n\\ntarget_languages = [\\n    \\\"english\\\",\\n    \\\"chinese\\\", \\n    \\\"french\\\",\\n    \\\"german\\\",\\n    \\\"indonesian\\\",\\n    \\\"italian\\\",\\n    \\\"portuguese\\\",\\n    \\\"russian\\\",\\n    \\\"spanish\\\",\\n    \\\"arabic\\\",\\n    \\\"dutch\\\",\\n    \\\"hindi\\\",\\n    \\\"japanese\\\",\\n    \\\"vietnamese\\\"\\n]\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tHard Negative Data\\n\\t\\n\\nThe hard negative data is derived from… See the full description on the dataset page: https://huggingface.co/datasets/hotchpotch/mmarco-hard-negatives-reranker-score."},
	{"name":"Multi-Opthalingua","keyword":"chinese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/AAAIBenchmark/Multi-Opthalingua","creator_name":"AAAIBenchmark","creator_url":"https://huggingface.co/AAAIBenchmark","description":"AAAIBenchmark/Multi-Opthalingua dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"nanoset","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/jxxqtech/nanoset","creator_name":"jxxqtech","creator_url":"https://huggingface.co/jxxqtech","description":"jxxqtech/nanoset dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"MT-SFT-ShareGPT","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/thomas-yanxin/MT-SFT-ShareGPT","creator_name":"thomas Yan","creator_url":"https://huggingface.co/thomas-yanxin","description":"\\n\\n\\n   \\n  \\n    MT-SFT-ShareGPT\\n    \\n      \\n      \\n    \\n     \\n  \\n  \\n💻 Github Repo  •  🤗 HuggingFace  •  🤖 ModelScope\\n\\n\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tIntroduction\\n\\t\\n\\nData has always been an important part of advancing large language models forward. Based on this, we have collected dozens of high-quality open source datasets from the open source community, with a total data volume of 20 M. \\nAfter some cleaning actions, we have open sourced a set of high-quality datasets for fine-tuning the instructions of the… See the full description on the dataset page: https://huggingface.co/datasets/thomas-yanxin/MT-SFT-ShareGPT."},
	{"name":"xiaolinguangji","keyword":"chinese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/wolfofbackstreet/xiaolinguangji","creator_name":"wolfofbackstreet","creator_url":"https://huggingface.co/wolfofbackstreet","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Dataset Name\\n\\t\\n\\n\\n\\nThis dataset card aims to be a base template for new datasets. It has been generated using this raw template.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Details\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\n\\n\\n\\n\\n\\nCurated by: [More Information Needed]\\nFunded by [optional]: [More Information Needed]\\nShared by [optional]: [More Information Needed]\\nLanguage(s) (NLP): [More Information Needed]\\nLicense: [More Information Needed]\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Sources [optional]… See the full description on the dataset page: https://huggingface.co/datasets/wolfofbackstreet/xiaolinguangji."},
	{"name":"ruozhiba","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/bineea/ruozhiba","creator_name":"bin","creator_url":"https://huggingface.co/bineea","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\truozhiba_gpt4\\n\\t\\n\\n本仓库包含使用GPT-4（4T/4o）构建的ruozhiba指令数据[^1]，共计2449条。其中包含以下两个版本，题目相同，仅回答内容不同。\\n\\nruozhiba_qa2449_gpt4t.json：利用gpt-4-turbo-20240409 对问题进行了回答。\\nruozhiba_qa2449_gpt4o.json：利用gpt-4o-20240514 对问题进行了回答。\\n\\n注意：指令数据中可能包含冒犯用语。\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\t所属项目\\n\\t\\n\\nChinese-LLaMA-Alpaca-3：https://github.com/ymcui/Chinese-LLaMA-Alpaca-3\\n\\nThis repository contains the ruozhiba instruction data[^1] constructed using GPT-4 (4T/4o), totaling 2449 entries. It includes the following two versions with the same… See the full description on the dataset page: https://huggingface.co/datasets/bineea/ruozhiba."},
	{"name":"emeraldTablet","keyword":"chinese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/smartkit/emeraldTablet","creator_name":"yangbozhou","creator_url":"https://huggingface.co/smartkit","description":"smartkit/emeraldTablet dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"orca-math-word-problems-100k-en-zh-mix","keyword":"chinese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/xd2333/orca-math-word-problems-100k-en-zh-mix","creator_name":"xd2333","creator_url":"https://huggingface.co/xd2333","description":"100k English and Chinese mixed version of microsoft/orca-math-word-problems-200k\\n"},
	{"name":"Oryx-SFT-Data","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/THUdyh/Oryx-SFT-Data","creator_name":"Yuhao Dong","creator_url":"https://huggingface.co/THUdyh","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Oryx-SFT-Data\\n\\t\\n\\nThis dataset is used for the training of the Oryx model. We only allow the use of this dataset for academic research and education purpose.\\nFor more details, please refer to our Github Repo\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Details\\n\\t\\n\\nA mixture of 1.2M image/video data. \\nFor more statistics of the dataset, please refer to our paper (coming soon)\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSource Data\\n\\t\\n\\nWe preprocess all the data into multiple files. \\nYou can use our preprocessed data… See the full description on the dataset page: https://huggingface.co/datasets/THUdyh/Oryx-SFT-Data."},
	{"name":"muri-it-language-split","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/akoksal/muri-it-language-split","creator_name":"Abdullatif Koksal","creator_url":"https://huggingface.co/akoksal","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tMURI-IT: Multilingual Instruction Tuning Dataset for 200 Languages via Multilingual Reverse Instructions\\n\\t\\n\\nMURI-IT is a large-scale multilingual instruction tuning dataset containing 2.2 million instruction-output pairs across 200 languages. It is designed to address the challenges of instruction tuning in low-resource languages with Multilingual Reverse Instructions (MURI), which ensures that the output is human-written, high-quality, and authentic to the cultural and linguistic… See the full description on the dataset page: https://huggingface.co/datasets/akoksal/muri-it-language-split."},
	{"name":"ChineseBQB","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mrzjy/ChineseBQB","creator_name":"jiayi","creator_url":"https://huggingface.co/mrzjy","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tChinese BQB\\n\\t\\n\\nThis is a data reupload of the repository zhaoolee/ChineseBQB, containing 5k+ Chinese stickers\\n中文表情包数据，来自于zhaoolee/ChineseBQB\\n\\n"},
	{"name":"bendi-public","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/sdsdfd/bendi-public","creator_name":"sdfd","creator_url":"https://huggingface.co/sdsdfd","description":"sdsdfd/bendi-public dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"Coupang-Product-Set-1M","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/clw8998/Coupang-Product-Set-1M","creator_name":"WW","creator_url":"https://huggingface.co/clw8998","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tHow to Load the Dataset\\n\\t\\n\\nYou can load this dataset using the Hugging Face datasets library as follows:\\nMake sure you have the datasets library installed:\\npip install datasets\\n\\nUse the following code to retrieve the dataset:\\nfrom datasets import load_dataset\\n\\n# Load the Coupang Product Set 1M dataset\\ndataset = load_dataset('clw8998/Coupang-Product-Set-1M')\\n\\n# Display the first few rows of the dataset\\nfor i in range(5):\\n    print(dataset['train'][i])\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tExpected  Output… See the full description on the dataset page: https://huggingface.co/datasets/clw8998/Coupang-Product-Set-1M."},
	{"name":"bilibili-masterpieces","keyword":"chinese","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/wencan2024/bilibili-masterpieces","creator_name":"wencan","creator_url":"https://huggingface.co/wencan2024","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Bilibili Masterpieces\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThe bilibili-masterpieces dataset is a curated collection of representative works from some of the early well-known content creators (up 主) on the Bilibili platform. This dataset captures key metadata from these videos, providing a snapshot of the creative output that has significantly influenced the Bilibili community.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSupported Tasks and Leaderboards\\n\\t\\n\\nThe dataset can be used for various tasks… See the full description on the dataset page: https://huggingface.co/datasets/wencan2024/bilibili-masterpieces."},
	{"name":"LongWriter-6k-reformat","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/pszemraj/LongWriter-6k-reformat","creator_name":"Peter Szemraj","creator_url":"https://huggingface.co/pszemraj","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tpszemraj/LongWriter-6k-reformat\\n\\t\\n\\nTHUDM/LongWriter-6k reformatted to dedicated columns. The default dataset config is english only, see the \\\"all\\\" config for other langs\\nGPT-4 tiktoken token count:\\n        token_count\\ncount   2335.000000\\nmean    5295.221842\\nstd     2771.696858\\nmin        1.000000\\n25%     3556.000000\\n50%     4729.000000\\n75%     6266.000000\\nmax    28436.000000\\n\\n\\nTotal count:\\t12.36 M tokens\\n\\n"},
	{"name":"OpenHermes-2.5-zh","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ldwang/OpenHermes-2.5-zh","creator_name":"ldwang","creator_url":"https://huggingface.co/ldwang","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for \\\"OpenHermes-2.5-zh\\\"\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Sources & Infos\\n\\t\\n\\n\\nData Origin: Derived from the original OpenHermes dataset : teknium/OpenHermes-2.5.\\nLanguages: Chinese\\nApplications: Language Modeling\\nLicense: Apache-2.0\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tOverview\\n\\t\\n\\nOpenHermes-2.5-zh is a dataset translated from the OpenHermes-2.5 collection provided by teknium.\\n"},
	{"name":"TWRMCD","keyword":"chinese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/yuhuanstudio/TWRMCD","creator_name":"YuhuanStudio","creator_url":"https://huggingface.co/yuhuanstudio","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tyuhuanstudio/TWRMCD\\n\\t\\n\\n(此項目數據及處理方式參考並改良自 ytchen175/master_thesis 感謝開源處理流程！)\\n一個收錄了正體中文（繁體中文）字典的資料集，用於大模型微調\\n(追求進步但不應該捨去歷史，中華文化不該因政治而被抹去並消亡)\\nA data set containing Traditional Chines dictionaries for fine-tuning LLM\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Details\\n\\t\\n\\n「台灣教育部重編國語辭典修訂本」 （Taiwan's Ministry of Education Revised Mandarin Chinese Dictionary，TWRMCD），\\n資料取自於台灣教育部的《重編國語辭典修訂本》\\n為了讓LLM從多方面增加對繁體中文的認識，我們利用從中提取並設計六大指令任務「詞語解釋、讀音問答、簡繁轉換、單句釋義、近似詞與反義詞」（約51萬筆指令）\\nThis dataset is sourced from Taiwan’s Ministry of… See the full description on the dataset page: https://huggingface.co/datasets/yuhuanstudio/TWRMCD."},
	{"name":"TWRMCD","keyword":"chinese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/yuhuanstudio/TWRMCD","creator_name":"YuhuanStudio","creator_url":"https://huggingface.co/yuhuanstudio","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tyuhuanstudio/TWRMCD\\n\\t\\n\\n(此項目數據及處理方式參考並改良自 ytchen175/master_thesis 感謝開源處理流程！)\\n一個收錄了正體中文（繁體中文）字典的資料集，用於大模型微調\\n(追求進步但不應該捨去歷史，中華文化不該因政治而被抹去並消亡)\\nA data set containing Traditional Chines dictionaries for fine-tuning LLM\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Details\\n\\t\\n\\n「台灣教育部重編國語辭典修訂本」 （Taiwan's Ministry of Education Revised Mandarin Chinese Dictionary，TWRMCD），\\n資料取自於台灣教育部的《重編國語辭典修訂本》\\n為了讓LLM從多方面增加對繁體中文的認識，我們利用從中提取並設計六大指令任務「詞語解釋、讀音問答、簡繁轉換、單句釋義、近似詞與反義詞」（約51萬筆指令）\\nThis dataset is sourced from Taiwan’s Ministry of… See the full description on the dataset page: https://huggingface.co/datasets/yuhuanstudio/TWRMCD."},
	{"name":"AuroraCap-trainset","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/wchai/AuroraCap-trainset","creator_name":"Wenhao Chai","creator_url":"https://huggingface.co/wchai","description":"\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tAuroraCap Trainset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tResources\\n\\t\\n\\n\\nWebsite\\narXiv: Paper\\nGitHub: Code\\nHuggingface: AuroraCap Model\\nHuggingface: VDC Benchmark\\nHuggingface: Trainset\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tFeatures\\n\\t\\n\\nWe use over 20 million high-quality image/video-text pairs to train AuroraCap in three stages. \\nPretraining stage. We first align visual features with the word embedding space of LLMs. To achieve this, we freeze the pretrained ViT and LLM, training solely the vision-language connector.\\nVision… See the full description on the dataset page: https://huggingface.co/datasets/wchai/AuroraCap-trainset."},
	{"name":"CSC-gpt4","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/shibing624/CSC-gpt4","creator_name":"Ming Xu (徐明)","creator_url":"https://huggingface.co/shibing624","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Chinese Spelling Correction(gpt4 fixed version)\\n\\t\\n\\n中文拼写纠错数据集\\n\\nRepository: https://github.com/shibing624/pycorrector\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nChinese Spelling Correction (CSC) is a task to detect and correct misspelled characters in Chinese texts. \\nCSC is challenging since many Chinese characters are visually or phonologically similar but with quite different semantic meanings.… See the full description on the dataset page: https://huggingface.co/datasets/shibing624/CSC-gpt4."},
	{"name":"ImageText-Question-answer-pairs-58K-Claude-3.5-Sonnnet","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/REILX/ImageText-Question-answer-pairs-58K-Claude-3.5-Sonnnet","creator_name":"SunForlight","creator_url":"https://huggingface.co/REILX","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tREILX/ImageText-Question-answer-pairs-58K-Claude-3.5-Sonnnet\\n\\t\\n\\n从VisualGenome数据集V1.2中随机抽取21717张图片，利用Claude-3-opus-20240229和Claude-3-sonnet-20240620两个模型生成了总计58312个问答对，每张图片约3个问答，其中必有一个关于图像细节的问答。Claude-3-opus-20240229模型贡献了约3,028个问答对，而Claude-3-sonnet-20240620模型则生成了剩余的问答对。\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tCode\\n\\t\\n\\n使用以下代码生成问答对：\\n# -*- coding: gbk -*-\\nimport os\\nimport random\\nimport shutil\\nimport re\\nimport json\\nimport requests\\nimport base64\\nimport time\\nfrom tqdm import tqdm\\nfrom json_repair import repair_json… See the full description on the dataset page: https://huggingface.co/datasets/REILX/ImageText-Question-answer-pairs-58K-Claude-3.5-Sonnnet."},
	{"name":"PangeaBench-xm100","keyword":"chinese","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/neulab/PangeaBench-xm100","creator_name":"NeuLab @ LTI/CMU","creator_url":"https://huggingface.co/neulab","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tXM100\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tThis is a copy from https://google.github.io/crossmodal-3600/\\n\\t\\n\\nIf you use this dataset, please cite the original authors:\\n@inproceedings{ThapliyalCrossmodal2022,\\n  author = {Ashish Thapliyal and Jordi Pont-Tuset and Xi Chen and Radu Soricut},\\n  title = {{Crossmodal-3600: A Massively Multilingual Multimodal Evaluation Dataset}},\\n  booktitle = {EMNLP},\\n  year = {2022}\\n}\\n\\n"},
	{"name":"toxic_reject","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/xdykj/toxic_reject","creator_name":"xd","creator_url":"https://huggingface.co/xdykj","description":"Regenerate from thu-coai/Safety-Prompts using Qwen2.5 to get better reply.\\n"},
	{"name":"PsySUICIDE","keyword":"chinese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/qiuhuachuan/PsySUICIDE","creator_name":"Huachuan Qiu","creator_url":"https://huggingface.co/qiuhuachuan","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tPsyGUARD: An Automated System for Suicide Detection and Risk Assessment in Psychological Counseling\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\t🎉🎉🎉 accepted to the EMNLP 2024 Main Conference\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tIntroduction\\n\\t\\n\\nAs awareness of mental health issues grows, online counseling support services are becoming increasingly prevalent worldwide. Detecting whether users express suicidal ideation in text-based counseling services is crucial for identifying and prioritizing at-risk individuals. However, the… See the full description on the dataset page: https://huggingface.co/datasets/qiuhuachuan/PsySUICIDE."},
	{"name":"comment-translation-01","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ifmain/comment-translation-01","creator_name":"Mike Afton","creator_url":"https://huggingface.co/ifmain","description":"This dataset is based on Kaggle.  \\nThis dataset includes translations of 69,000 Reddit comments into 17 languages (English to 16 languages):\\nBelarusian, Czech, German,\\nEnglish, Spanish, Finnish,\\nFrench, Italian, Japanese,\\nKazakh, Korean, Latvian,\\nPolish, Russian, Swedish,\\nUkrainian, and Chinese.\\nIt contains 50% regular comments and 50% highly negative ones.\\nEnjoy using it!\\n"},
	{"name":"ApolloMoEDataset","keyword":"chinese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/FreedomIntelligence/ApolloMoEDataset","creator_name":"FreedomAI","creator_url":"https://huggingface.co/FreedomIntelligence","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDemocratizing Medical LLMs For Much More Languages\\n\\t\\n\\nCovering 12 Major Languages including English, Chinese, French, Hindi, Spanish, Arabic, Russian, Japanese, Korean, German, Italian, Portuguese and 38 Minor Languages So far.\\n\\n   📃 Paper • 🌐 Demo • 🤗 ApolloMoEDataset • 🤗 ApolloMoEBench  • 🤗 Models  •🌐 Apollo  • 🌐 ApolloMoE\\n\\n\\n\\n\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\t🌈 Update\\n\\t\\n\\n\\n[2024.10.15] ApolloMoE repo is published！🎉\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages Coverage\\n\\t\\n\\n12 Major Languages and 38 Minor Languages… See the full description on the dataset page: https://huggingface.co/datasets/FreedomIntelligence/ApolloMoEDataset."},
	{"name":"ApolloMoEBench","keyword":"chinese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/FreedomIntelligence/ApolloMoEBench","creator_name":"FreedomAI","creator_url":"https://huggingface.co/FreedomIntelligence","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDemocratizing Medical LLMs For Much More Languages\\n\\t\\n\\nCovering 12 Major Languages including English, Chinese, French, Hindi, Spanish, Arabic, Russian, Japanese, Korean, German, Italian, Portuguese and 38 Minor Languages So far.\\n\\n   📃 Paper • 🌐 Demo • 🤗 ApolloMoEDataset • 🤗 ApolloMoEBench  • 🤗 Models  •🌐 Apollo  • 🌐 ApolloMoE\\n\\n\\n\\n\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\t🌈 Update\\n\\t\\n\\n\\n[2024.10.15] ApolloMoE repo is published！🎉\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages Coverage\\n\\t\\n\\n12 Major Languages and 38 Minor Languages… See the full description on the dataset page: https://huggingface.co/datasets/FreedomIntelligence/ApolloMoEBench."},
	{"name":"Corn_Disease_Description","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/REXWind/Corn_Disease_Description","creator_name":"Boru Shi","creator_url":"https://huggingface.co/REXWind","description":"将plant village中的图像对应到具体的文本描述，包含3.8k个图像、文本对。\\n对应的图像去plantvillage下载就行。\\n"},
	{"name":"PangeaBench-xgqa","keyword":"chinese","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/neulab/PangeaBench-xgqa","creator_name":"NeuLab @ LTI/CMU","creator_url":"https://huggingface.co/neulab","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\txGQA\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tThis is a clone of the few_shot-test split of the xGQA dataset\\n\\t\\n\\nPlease find the original repository here: https://github.com/adapter-hub/xGQA\\nIf you use this dataset, please cite the original authors:\\n@inproceedings{pfeiffer-etal-2021-xGQA,\\n    title={{xGQA: Cross-Lingual Visual Question Answering}},\\n    author={ Jonas Pfeiffer and Gregor Geigle and Aishwarya Kamath and Jan-Martin O. Steitz and Stefan Roth and Ivan Vuli{\\\\'{c}} and Iryna Gurevych}… See the full description on the dataset page: https://huggingface.co/datasets/neulab/PangeaBench-xgqa."},
	{"name":"resume-ner","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/PassbyGrocer/resume-ner","creator_name":"Stanley Sun","creator_url":"https://huggingface.co/PassbyGrocer","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Dataset Name\\n\\t\\n\\n\\n\\nThis dataset card aims to be a base template for new datasets. It has been generated using this raw template.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Details\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\n\\n\\n\\n\\n\\nCurated by: [More Information Needed]\\nFunded by [optional]: [More Information Needed]\\nShared by [optional]: [More Information Needed]\\nLanguage(s) (NLP): [More Information Needed]\\nLicense: [More Information Needed]\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Sources [optional]… See the full description on the dataset page: https://huggingface.co/datasets/PassbyGrocer/resume-ner."},
	{"name":"coda-lm-llava-format","keyword":"chinese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/KaiChen1998/coda-lm-llava-format","creator_name":"Kai Chen","creator_url":"https://huggingface.co/KaiChen1998","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tCODA-LM Dataset Card\\n\\t\\n\\nCODA-LM is the multi-modal version of the CODA dataset, used in the CODA-LM paper. Both English and Chinese annotations are available. Check detailed usage in our Github repo.\\nThis repo contains the CODA-LM dataset, which has been reorganized in the LLaVA data format. \\nYou are also welcome to check the original CODA-LM data which contains more metadata vanilla annotations. \\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tUsage\\n\\t\\n\\nfrom datasets import load_dataset\\n\\n# name can be selected from… See the full description on the dataset page: https://huggingface.co/datasets/KaiChen1998/coda-lm-llava-format."},
	{"name":"db","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/CHJTXY99/db","creator_name":"CHJTXY99","creator_url":"https://huggingface.co/CHJTXY99","description":"From Wu, Yu, et al. \\\"Sequential Matching Network: A New Archtechture for Multi-turn Response Selection in Retrieval-based Chatbots.\\\" ACL. 2017.\\nFrom https://github.com/MarkWuNLP/MultiTurnResponseSelection\\nIf there is any infringement, please contact me to have it removed.\\n"},
	{"name":"Chinese_Male_017VoiceArtist_11Hours_High_Quality_Voice_Dataset","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/voices365/Chinese_Male_017VoiceArtist_11Hours_High_Quality_Voice_Dataset","creator_name":"voices365","creator_url":"https://huggingface.co/voices365","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThis Dataset was recorded by a professional Chinese voice artist, real person, male, the total length is around 11 hours. \\nFor more details, please refer to the link: www.vodataset.com or email info@voices365.com.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tAuthorization\\n\\t\\n\\nThe voice artist can sign an authorization with you. The authorization can be of any form, such as paper, voice or video.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tCustom Dataset\\n\\t\\n\\nYes, the artist can record a new dataset with your scripts, and meet… See the full description on the dataset page: https://huggingface.co/datasets/voices365/Chinese_Male_017VoiceArtist_11Hours_High_Quality_Voice_Dataset."},
	{"name":"Vulpisfoglia","keyword":"chinese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/None1145/Vulpisfoglia","creator_name":"None","creator_url":"https://huggingface.co/None1145","description":"None1145/Vulpisfoglia dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"LonGen","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/quanshr/LonGen","creator_name":"Shanghaoran Quan","creator_url":"https://huggingface.co/quanshr","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLonGen Benchmark\\n\\t\\n\\nThe LonGen benchmark is specifically designed to assess the ability of large language models to generate long, aligned outputs, introduced by Language Models Can Self-Lengthen to Generate Long Texts.\\nLonGen consists of data from two languages (English and Chinese), categorized into three length ranges (2-4k, 4-6k, and 6-8k), and incorporates four length constraint types (about, range, above, below). This results in a total of 240 distinct pieces of data (2… See the full description on the dataset page: https://huggingface.co/datasets/quanshr/LonGen."},
	{"name":"environmnet_innovation","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/zeke918/environmnet_innovation","creator_name":"沈彦冰","creator_url":"https://huggingface.co/zeke918","description":"zeke918/environmnet_innovation dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"NaVAB","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/JadenGGGeee/NaVAB","creator_name":"JCY","creator_url":"https://huggingface.co/JadenGGGeee","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for NaVAB\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Details\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nNaVAB is a comprehensive benchmark designed to evaluate the alignment of Large Language Models (LLMs) with the values of five major nations: China, the United States, the United Kingdom, France, and Germany. The dataset addresses the limitations of existing benchmarks, which often fail to capture the dynamic nature of values across countries and lack sufficient evaluation data.\\nThe dataset… See the full description on the dataset page: https://huggingface.co/datasets/JadenGGGeee/NaVAB."},
	{"name":"CNNSum","keyword":"chinese","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/CxsGHost/CNNSum","creator_name":"lingxiao","creator_url":"https://huggingface.co/CxsGHost","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tCNNSum: Exploring Long-Context Summarization with Large Language Models in Chinese Novels\\n\\t\\n\\nPaper     GitHub\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\t[2024.12.18] - CNNSum Dataset Release!\\n\\t\\n\\nWe are excited to announce the release of the CNNSum dataset!\\nAs outlined in Section 3.1 and Appendix E of our paper, we have conducted a final round of manual cleaning to address any possible omissions. This process affects only a minimal number of samples, ensuring that the length statistics reported in our paper… See the full description on the dataset page: https://huggingface.co/datasets/CxsGHost/CNNSum."},
	{"name":"MegaWika","keyword":"chinese","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/conceptofmind/MegaWika","creator_name":"Enrico Shippole","creator_url":"https://huggingface.co/conceptofmind","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for MegaWika\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nMegaWika is a multi- and crosslingual text dataset containing 30 million Wikipedia passages with their scraped and cleaned web citations. The passages span\\n50 Wikipedias in 50 languages, and the articles in which the passages were originally embedded are included for convenience. Where a Wikipedia passage is in a\\nnon-English language, an automated English translation is provided. Furthermore, nearly 130 million English… See the full description on the dataset page: https://huggingface.co/datasets/conceptofmind/MegaWika."},
	{"name":"chinese-squadv2","keyword":"chinese","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/real-jiakai/chinese-squadv2","creator_name":"jiakai","creator_url":"https://huggingface.co/real-jiakai","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Chinese SQuAD 2.0\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThis is a Chinese translation of the SQuAD 2.0 dataset, translated from the original English version. Like SQuAD 2.0, it contains both answerable and unanswerable questions. The dataset is designed for Chinese reading comprehension and question answering tasks.\\nSource: ChineseSquad\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Structure\\n\\t\\n\\nThe dataset is stored in Parquet format and contains the following… See the full description on the dataset page: https://huggingface.co/datasets/real-jiakai/chinese-squadv2."},
	{"name":"data_train","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/dsacedsfds/data_train","creator_name":"sss","creator_url":"https://huggingface.co/dsacedsfds","description":"dsacedsfds/data_train dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"laber_law","keyword":"chinese","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ulatsou/laber_law","creator_name":"SHIHWEI, TSOU","creator_url":"https://huggingface.co/ulatsou","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\t台灣勞動基準法 QA 數據集\\n\\t\\n\\n這個數據集包含從台灣勞動基準法整理出的問答對，適用於：\\n\\n法規諮詢模型訓練\\n勞動法規理解\\n權益維護參考\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\t數據集特點\\n\\t\\n\\n\\n來源：台灣勞動基準法\\n格式：問答對\\n規模：190 個資料集\\n特色：涵蓋勞基法全部章節\\n\\n"},
	{"name":"KT_QA","keyword":"chinese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Gyikoo/KT_QA","creator_name":"Xinyi Gao","creator_url":"https://huggingface.co/Gyikoo","description":"Gyikoo/KT_QA dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"MORPHEUS_Datasets","keyword":"chinese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Toyhom/MORPHEUS_Datasets","creator_name":"Yihong Tang","creator_url":"https://huggingface.co/Toyhom","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tMORPHEUS\\n\\t\\n\\nMORPHEUS: Modeling Role from Personalized Dialogue History by Exploring and Utilizing Latent Space(EMNLP 2024)\\nPaper \\nEN: ConvAI2\\nZH: Baidu PersonaChat\\n"},
	{"name":"spatula_s13_yolo_detection","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Carey8175/spatula_s13_yolo_detection","creator_name":"Wang WenJie","creator_url":"https://huggingface.co/Carey8175","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\t金铲铲之战YOLO英雄数据集(S13)\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\t简介\\n\\t\\n\\n本数据集是用于训练YOLO模型的金铲铲之战S13赛季的英雄数据集。包含总共英雄的奕子形态，用于训练模型识别英雄状态\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\t标签\\n\\t\\n\\n本数据集的标签命名方式为: 英雄名字\\n共计61个标签, 60个英雄加上一个塞恩\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\t数据集\\n\\t\\n\\n本次数据集共计176张图片和200张数据增强图片，共计376张，可通过提供的数据自行划分训练集和测试集\\n标签数量直方图如下：\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tEnhance\\n\\t\\n\\n本数据集可通过数据增强工具进行数据增强，提高模型的泛化能力。\\n增强数据集中使用了以下增强方式：\\n\\n随机旋转（10度）\\n随机缩放（0.2）\\n随机平移（0.2）\\n高斯模糊\\n随机亮度\\n随机对比度\\n随即水平翻转\\n\\n目前的的做法是，先用基本数据集训练一个大参数模型，然后收集新数据，使用模型去初步标记数据，然后人工修正，从而丰富数据集。\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\t文件说明\\n\\t\\n\\n\\ngenerate_yolo_format.py: 在指定路径生成数据集… See the full description on the dataset page: https://huggingface.co/datasets/Carey8175/spatula_s13_yolo_detection."},
	{"name":"sql-injection","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Kaveny/sql-injection","creator_name":"Kaven","creator_url":"https://huggingface.co/Kaveny","description":"\\n\\t\\n\\t\\t\\n\\t\\tSQL注入推理能力微调数据集\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\t概述\\n\\t\\n\\n本数据集旨在帮助研究人员和工程师通过特定案例来微调模型在SQL注入（SQLi）检测与预防方面的能力。SQL注入是一种代码注入技术，攻击者通过将恶意的SQL查询或语句插入应用程序的输入字段中，以操纵数据库执行非授权的操作。\\n\\n\\t\\n\\t\\t\\n\\t\\t数据集用途\\n\\t\\n\\n\\n研究用途：为安全领域的研究人员提供实际案例，以便于探索和开发新的防御策略。\\n模型训练：为机器学习模型提供训练素材，以提高其识别和防范SQL注入攻击的能力。\\n教育目的：作为教育资源，帮助学生和新手了解SQL注入的风险及其防护措施。\\n\\n\\n\\t\\n\\t\\t\\n\\t\\t获取更多数据\\n\\t\\n\\n如需获取更多相关数据或希望参与贡献，请访问我们的GitHub仓库：\\nAAuZZ/SQLiDataset\\n\\n\\t\\n\\t\\t\\n\\t\\t许可证\\n\\t\\n\\n本项目使用Apache 2.0许可证。有关详细信息，请参阅LICENSE文件。\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset for Fine-tuning Reasoning Ability in SQL Injection\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tOverview… See the full description on the dataset page: https://huggingface.co/datasets/Kaveny/sql-injection."},
	{"name":"traindata_content","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/dsacedsfds/traindata_content","creator_name":"sss","creator_url":"https://huggingface.co/dsacedsfds","description":"dsacedsfds/traindata_content dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"DetectiveQA","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Phospheneser/DetectiveQA","creator_name":"Xu Zhe","creator_url":"https://huggingface.co/Phospheneser","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDetectiveQA\\n\\t\\n\\nThis is a bilingual dataset with an average question length of 100K, containing a series of detective novel questions and answers. These questions and answers are extracted from detective novels and cover various types of questions, such as: character relationships, event order, causes of events, etc.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\t1. Data Source/Collection\\n\\t\\n\\nThe novels in the dataset come from a collection of classical detective novels we gathered. These novels have the following… See the full description on the dataset page: https://huggingface.co/datasets/Phospheneser/DetectiveQA."},
	{"name":"multi_llm_dpo","keyword":"chinese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/lastmass/multi_llm_dpo","creator_name":"tang zhi xiong","creator_url":"https://huggingface.co/lastmass","description":"lastmass/multi_llm_dpo dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"nlp_corpus_zh","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/zeroMN/nlp_corpus_zh","creator_name":"zeroTT","creator_url":"https://huggingface.co/zeroMN","description":"\\n\\t\\n\\t\\t\\n\\t\\tnlp_corpus\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\t1 中文实体识别\\n\\t\\n\\n\\nopen_ner_data为网上开放的ner数据集，已将不同的数据格式转化为统一的数据格式，格式转换脚本为data_transfer.py\\n\\n\\n\\t\\n\\t\\t\\n\\t\\t1.1 boson数据集\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\t1.2 clue细粒度实体识别数据集\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\t1.3 微软实体识别数据集\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\t1.4 人民网实体识别数据集（98年）\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\t1.5 中药说明书实体识别数据集（“万创杯”中医药天池大数据竞赛）\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\t1.6 视频_音乐_图书数据集\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\t1.7 微博数据集\\n\\t\\n\\n"},
	{"name":"LLaVA-NeXT-Audio","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ColorfulAI/LLaVA-NeXT-Audio","creator_name":"Yuxuan Wang","creator_url":"https://huggingface.co/ColorfulAI","description":"\\n\\t\\n\\t\\t\\n\\t\\tLLaVA-NeXT-Data\\n\\t\\n\\nBuilding on the LLaVA-NeXT-Data, we convert user queries into audio using CosyVoice, with a randomly selected VoiceAssistant as a prompt.\\n"},
	{"name":"company_intro_qa","keyword":"chinese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/masonchu/company_intro_qa","creator_name":"chu","creator_url":"https://huggingface.co/masonchu","description":"masonchu/company_intro_qa dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"OmniDocBench","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Quivr/OmniDocBench","creator_name":"Quivr","creator_url":"https://huggingface.co/Quivr","description":"Forked from opendatalab/OmniDocBench.\\n\\n\\t\\n\\t\\t\\n\\t\\tSampler\\n\\t\\n\\nWe have added a simple Python tool for filtering and performing stratified sampling on OmniDocBench data.\\n\\n\\t\\n\\t\\t\\n\\t\\tFeatures\\n\\t\\n\\n\\nFilter JSON entries based on custom criteria\\nPerform stratified sampling based on multiple categories\\nHandle nested JSON fields\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tInstallation\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tLocal Development Install (Recommended)\\n\\t\\n\\ngit clone https://huggingface.co/Quivr/OmniDocBench.git\\ncd OmniDocBench\\npip install -r requirements.txt  #… See the full description on the dataset page: https://huggingface.co/datasets/Quivr/OmniDocBench."},
	{"name":"storage","keyword":"chinese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Pikilap/storage","creator_name":"Joe Zlorix","creator_url":"https://huggingface.co/Pikilap","description":"\\n\\t\\n\\t\\t\\n\\t\\t免责声明\\n\\t\\n\\n\\n该仓库的资源均来源于网络，若有侵权请联系我进行删除。\\n\\n"},
	{"name":"blossom-v6-sft-stage1","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Azure99/blossom-v6-sft-stage1","creator_name":"Azure99","creator_url":"https://huggingface.co/Azure99","description":"\\n\\t\\n\\t\\t\\n\\t\\tBLOSSOM V6 SFT STAGE1\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tIntroduction\\n\\t\\n\\nBLOSSOM V6 SFT Stage1 is a high-quality, diverse large language model fine-tuning dataset designed for the first-stage SFT training of the Blossom V6 model. Its purpose is to help the model initially align dialogue capabilities through exposure to large-scale synthetic data.  \\nWhile open-source large language models often release model weights and technical reports, the most advanced open-source models typically withhold their… See the full description on the dataset page: https://huggingface.co/datasets/Azure99/blossom-v6-sft-stage1."},
	{"name":"GammaCorpus-Polylingo-50k","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/rubenroy/GammaCorpus-Polylingo-50k","creator_name":"Ruben Roy","creator_url":"https://huggingface.co/rubenroy","description":"\\n\\t\\n\\t\\t\\n\\t\\tGammaCorpus Polylingo 50k\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tWhat is it?\\n\\t\\n\\nThe GammaCorpus Polylingo 50k dataset consists of 50,000 structured, unfiltered, single-turn conversations, where each interaction includes:\\n\\nInput: A user prompt or question.\\nOutput: A response generated by an AI assistant.\\nLanguage: The language used in the interaction.\\n\\nThis dataset is designed to help in the training and evaluation of conversational AI models for linguistic purposes. This dataset can be especially helpful if you… See the full description on the dataset page: https://huggingface.co/datasets/rubenroy/GammaCorpus-Polylingo-50k."},
	{"name":"tojoyfoundation","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/bcc/tojoyfoundation","creator_name":"bucheyu","creator_url":"https://huggingface.co/bcc","description":"\\n\\t\\n\\t\\t\\n\\t\\tDataset Card for Dataset Name\\n\\t\\n\\n\\n\\nThis dataset card aims to be a base template for new datasets. It has been generated using this raw template.\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Details\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\n\\n\\n\\n\\n\\nCurated by: [More Information Needed]\\nFunded by [optional]: [More Information Needed]\\nShared by [optional]: [More Information Needed]\\nLanguage(s) (NLP): [More Information Needed]\\nLicense: [More Information Needed]\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Sources [optional]\\n\\t\\n\\n\\n\\n\\nRepository: [More… See the full description on the dataset page: https://huggingface.co/datasets/bcc/tojoyfoundation."},
	{"name":"Metro_Code_Chapters_18_to_22_Data","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/OrangeeSofty/Metro_Code_Chapters_18_to_22_Data","creator_name":"Mingc","creator_url":"https://huggingface.co/OrangeeSofty","description":"\\n\\t\\n\\t\\t\\n\\t\\tDataset Card for Metro System Requirements in Design\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tSummary\\n\\t\\n\\nThis dataset provides detailed requirements for systems used in metro network design, collected from Chapter 18-22 of the Code for Design of Metro (GB 50157-2013). The dataset is annotated using a description, categories format, aimed at facilitating the training and fine-tuning of large language models (LLMs) for information extraction tasks in complex product systems, particularly within metro transit… See the full description on the dataset page: https://huggingface.co/datasets/OrangeeSofty/Metro_Code_Chapters_18_to_22_Data."},
	{"name":"creative-ad-prompts-zh","keyword":"chinese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/mrzjy/creative-ad-prompts-zh","creator_name":"jiayi","creator_url":"https://huggingface.co/mrzjy","description":"\\n\\t\\n\\t\\t\\n\\t\\tData Card\\n\\t\\n\\nThis is the training data for CreativeTinyZero, consisting of advertisement generation related prompts.\\nRL requires only prompts, so we use GPT models to:\\n\\nGenerate diverse entities across various domains.\\nApply the following prompt template:\\n\\nfrom transformers import pipeline\\n\\nsystem_prompt = \\\"\\\"你是一位创意广告设计师，负责为用户量身定制独特的广告文案。在开始创作之前，请先深入思考整个创意过程，并将你的思考逻辑清晰地呈现出来。具体步骤如下：\\n\\n1. **思考过程**：首先，分析用户的需求、品牌定位、目标受众以及广告的核心信息。考虑如何通过创意表达将这些元素有机结合，形成具有吸引力的广告文案。将这一思考过程详细记录在 `<think>` 标签内… See the full description on the dataset page: https://huggingface.co/datasets/mrzjy/creative-ad-prompts-zh."},
	{"name":"dark_thoughts_stakeholders_test","keyword":"chinese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Tonic/dark_thoughts_stakeholders_test","creator_name":"Joseph [open/acc] Pollack","creator_url":"https://huggingface.co/Tonic","description":"Tonic/dark_thoughts_stakeholders_test dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"dark_thoughts_stakeholders","keyword":"chinese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/DataTonic/dark_thoughts_stakeholders","creator_name":"Data Tonic (Alignment Lab)","creator_url":"https://huggingface.co/DataTonic","description":"\\n\\t\\n\\t\\t\\n\\t\\tDataset Card for Dataset Name\\n\\t\\n\\n\\n\\nThis dataset card aims to be a base template for new datasets. It has been generated using this raw template.\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Details\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\n\\n\\n\\n\\n\\nCurated by: [More Information Needed]\\nFunded by [optional]: [More Information Needed]\\nShared by [optional]: [More Information Needed]\\nLanguage(s) (NLP): [More Information Needed]\\nLicense: [More Information Needed]\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Sources [optional]\\n\\t\\n\\n\\n\\n\\nRepository: [More… See the full description on the dataset page: https://huggingface.co/datasets/DataTonic/dark_thoughts_stakeholders."},
	{"name":"HundredCVs","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Jax-dan/HundredCVs","creator_name":"Jax","creator_url":"https://huggingface.co/Jax-dan","description":"\\n\\t\\n\\t\\t\\n\\t\\t百人简历数据集\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tHundredCVs: A Curriculum Vitae Dataset of 100 Young Chinese People\\n\\t\\n\\n\\n\\n\\t\\n\\t\\t\\n\\t\\t简介\\n\\t\\n\\n本项目提出一个全新的中文简历数据集（HundredCVs），包含了 100 位青年的个人简历。HundredCVs 具有以下特点：\\n\\n年轻化、多样性：数据集中的人物年龄分布在 15~30 岁之间，广泛涵盖了不同性别、不同职业、不同学历（高中至博士不等）。\\n结构完整：每份简历中的信息包括人物的个人名片、性格特征、主要事迹，以及详细经历/个人自述等。 \\n安全性：我们使用化名替代了人物的真实姓名，此外，人物经历也使用大语言模型的改写和提炼，表现出标准化和一致性的语言风格。\\n\\n\\n\\t\\n\\t\\t\\n\\t\\t设计意图\\n\\t\\n\\nHundredCVs 的提出主要是为了方便研究者开展基于简历的自然语言处理任务。数据集中提供两个文件:\\n\\nprofile.json：每条记录只包含人物的个人名片、性格特征和主要事迹。可用于开展角色扮演、人物画像构建等任务。… See the full description on the dataset page: https://huggingface.co/datasets/Jax-dan/HundredCVs."},
	{"name":"HundredCV-Chat","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Jax-dan/HundredCV-Chat","creator_name":"Jax","creator_url":"https://huggingface.co/Jax-dan","description":"\\n\\t\\n\\t\\t\\n\\t\\t百人对话数据集\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tHundredCV-Chat: A Dataset of Daily Chatting Developed on HundredCVs\\n\\t\\n\\n\\n\\n\\t\\n\\t\\t\\n\\t\\t简介\\n\\t\\n\\n本项目提出一个全新的中文多轮对话数据集（HundredCV-Chat），该数据集由 100 位青年的简历数据集 HundredCVs 开发而来，共包含 24,750 组日常闲聊对话数据。\\n数据集具有如下特点：\\n\\n自动化标注：HundredCV-Chat 中的对话均由 Deepseek-V3 大模型生成，不涉及任何人工标注，因此同时保证了大规模数据量和低成本优势。\\n多样性话题：HundredCV-Chat 中的对话话题涵盖了校园生活、工作经验、兴趣爱好、生活琐事等多个方面，与真实生活联系紧密，尤其适用于开发年轻化应用。\\n高质量对话：利用 Deepseek 强大的生成能力和全面的知识，HundredCV-Chat 的对话内容在流畅度、拟人性、多样性方面均显著优于现有的开源对话数据集。\\n\\n\\n\\t\\n\\t\\t\\n\\t\\t数据样例\\n\\t\\n\\nHundredCV-Chat 含有 24… See the full description on the dataset page: https://huggingface.co/datasets/Jax-dan/HundredCV-Chat."},
	{"name":"runpod_qwen32_benign_thoughts_casestudies_rescued","keyword":"chinese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/DataTonic/runpod_qwen32_benign_thoughts_casestudies_rescued","creator_name":"Data Tonic (Alignment Lab)","creator_url":"https://huggingface.co/DataTonic","description":"DataTonic/runpod_qwen32_benign_thoughts_casestudies_rescued dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"URS","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/JiayinWang/URS","creator_name":"JiayinWang","creator_url":"https://huggingface.co/JiayinWang","description":"\\n\\t\\n\\t\\t\\n\\t\\tUser-Centric Evaluation of LLMs\\n\\t\\n\\n📚 Our Paper (EMNLP 24 Resource Award)\\nA User-Centric Multi-Intent Benchmark for Evaluating Large Language Models.\\n\\n\\t\\n\\t\\t\\n\\t\\tUser Reported Scenario (URS) Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Features\\n\\t\\n\\n\\nUser-Centric\\n\\nReal-world usage scenarios of LLMs\\nThe dataset is collected through a User Survey with 712 participants from 23 countries in 6 continents.\\n\\n\\nMulti-Intent\\n\\nSystem abilities and performances in different scenarios might be different\\nUsers’… See the full description on the dataset page: https://huggingface.co/datasets/JiayinWang/URS."},
	{"name":"JUREX-4E","keyword":"chinese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/zotown/JUREX-4E","creator_name":"zotown","creator_url":"https://huggingface.co/zotown","description":"\\n\\t\\n\\t\\t\\n\\t\\tJUREX\\n\\t\\n\\nSource code and data for JUREX-4E: Juridical Expert-Annotated Four-Element Knowledge Base for Legal Reasoning\\nCode: https://github.com/THUlawtech/JUREX\\n\\n\\t\\n\\t\\t\\n\\t\\tOverview\\n\\t\\n\\n\\nDataset Structure\\nAnnotation\\nExperiment\\nSimilar Charge Distinction\\nLegal Case Retrieval\\n\\n\\nRequirements\\nLicense\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Structure\\n\\t\\n\\nJUREX-4E is the first part of our curated expert knowledge base(mind map structure), \\nfocusing on the four elements of criminal charges.\\ndata\\n- law  # legal texts… See the full description on the dataset page: https://huggingface.co/datasets/zotown/JUREX-4E."},
	{"name":"JUREX-4E","keyword":"chinese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/zotown/JUREX-4E","creator_name":"zotown","creator_url":"https://huggingface.co/zotown","description":"\\n\\t\\n\\t\\t\\n\\t\\tJUREX\\n\\t\\n\\nSource code and data for JUREX-4E: Juridical Expert-Annotated Four-Element Knowledge Base for Legal Reasoning\\nCode: https://github.com/THUlawtech/JUREX\\n\\n\\t\\n\\t\\t\\n\\t\\tOverview\\n\\t\\n\\n\\nDataset Structure\\nAnnotation\\nExperiment\\nSimilar Charge Distinction\\nLegal Case Retrieval\\n\\n\\nRequirements\\nLicense\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Structure\\n\\t\\n\\nJUREX-4E is the first part of our curated expert knowledge base(mind map structure), \\nfocusing on the four elements of criminal charges.\\ndata\\n- law  # legal texts… See the full description on the dataset page: https://huggingface.co/datasets/zotown/JUREX-4E."},
	{"name":"piaozhu","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Retr01234/piaozhu","creator_name":"Chen","creator_url":"https://huggingface.co/Retr01234","description":"\\n\\t\\n\\t\\t\\n\\t\\t数据集名称：嘴臭搭子微调数据集\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\t1. 数据集简介\\n\\t\\n\\n这个数据集为微调对话生成模型提供了一个特殊的训练样本，基于一个虚拟的角色“沈蓬竹”进行交互。这个角色（外号“朴竹”）具有冷嘲热讽、毒舌、简洁而有攻击性的特点，适合训练模型产生具有讽刺、冷嘲热讽语气的回答。数据集的内容主要是角色扮演对话场景，适用于生成具有特定风格的对话模型，特别是在带有讽刺和幽默的情境下进行互动时。\\n\\n\\t\\n\\t\\t\\n\\t\\t2. 数据集结构\\n\\t\\n\\n数据集为一个包含若干对话轮次的 JSON 格式文件。每个对话轮次由角色和用户的对话组成，每个对话包含以下字段：\\n\\nrole：角色的身份，可能是 \\\"system\\\" 或 \\\"user\\\"。\\n\\\"system\\\" 表示是模型设定角色的输入（如定义角色背景、行为模式等）。\\n\\\"user\\\" 表示对话中的用户输入（如提问、请求或交互）。\\n\\n\\ncontent：对话内容，表示角色或者用户的具体发言。\\nloss_weight（可选）：每个数据条目对应的损失权重，当前可为空或为 null。可以在模型训练中加权不同对话内容。\\n\\n\\n\\t\\n\\t\\t\\n\\t\\t3. 数据样例… See the full description on the dataset page: https://huggingface.co/datasets/Retr01234/piaozhu."},
	{"name":"piaozhu","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Retr01234/piaozhu","creator_name":"Chen","creator_url":"https://huggingface.co/Retr01234","description":"\\n\\t\\n\\t\\t\\n\\t\\t数据集名称：嘴臭搭子微调数据集\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\t1. 数据集简介\\n\\t\\n\\n这个数据集为微调对话生成模型提供了一个特殊的训练样本，基于一个虚拟的角色“沈蓬竹”进行交互。这个角色（外号“朴竹”）具有冷嘲热讽、毒舌、简洁而有攻击性的特点，适合训练模型产生具有讽刺、冷嘲热讽语气的回答。数据集的内容主要是角色扮演对话场景，适用于生成具有特定风格的对话模型，特别是在带有讽刺和幽默的情境下进行互动时。\\n\\n\\t\\n\\t\\t\\n\\t\\t2. 数据集结构\\n\\t\\n\\n数据集为一个包含若干对话轮次的 JSON 格式文件。每个对话轮次由角色和用户的对话组成，每个对话包含以下字段：\\n\\nrole：角色的身份，可能是 \\\"system\\\" 或 \\\"user\\\"。\\n\\\"system\\\" 表示是模型设定角色的输入（如定义角色背景、行为模式等）。\\n\\\"user\\\" 表示对话中的用户输入（如提问、请求或交互）。\\n\\n\\ncontent：对话内容，表示角色或者用户的具体发言。\\nloss_weight（可选）：每个数据条目对应的损失权重，当前可为空或为 null。可以在模型训练中加权不同对话内容。\\n\\n\\n\\t\\n\\t\\t\\n\\t\\t3. 数据样例… See the full description on the dataset page: https://huggingface.co/datasets/Retr01234/piaozhu."},
	{"name":"twisc","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/yxhong-tw/twisc","creator_name":"Yu-Xiang Hong","creator_url":"https://huggingface.co/yxhong-tw","description":"\\n\\t\\n\\t\\t\\n\\t\\tTaiwan-Indictment-Summarization-Corpus (TWISC)\\n\\t\\n\\nTaiwan-Indictment-Summarization-Corpus (TWISC) is a dataset designed for legal judgment prediction and legal text summarization. It is collected from Taiwan Ministry of Justice and covers data from 2018/06 to 2021/06.\\nThis dataset is used in the paper Improving Colloquial Case Legal Judgment Prediction via Abstractive Text Summarization published in Computer Law & Security Review (2023).\\nWe express our gratitude to Professor Chia-Hui… See the full description on the dataset page: https://huggingface.co/datasets/yxhong-tw/twisc."},
	{"name":"WalnutData","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/nanmao/WalnutData","creator_name":"liyi","creator_url":"https://huggingface.co/nanmao","description":"\\n  \\n  \\n\\n\\t\\n\\t\\t\\n\\t\\tWalnutData\\n\\t\\n\\n  \\n\\nWith the gradual maturity of UAV technology, it can provide extremely powerful support for smart agriculture and precise monitoring. Currently, there is no dataset related to green walnuts in the field of agricultural computer vision. Therefore, in order to promote the algorithm design in the field of agricultural computer vision, we used UAV to collect remote sensing data from 8 walnut sample plots. Considering that green walnuts have the characteristics of… See the full description on the dataset page: https://huggingface.co/datasets/nanmao/WalnutData."},
	{"name":"text","keyword":"chinese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/wuji8836/text","creator_name":"wuji","creator_url":"https://huggingface.co/wuji8836","description":"\\n\\t\\n\\t\\t\\n\\t\\tDataset Card for Dataset Name\\n\\t\\n\\n\\n\\nThis dataset card aims to be a base template for new datasets. It has been generated using this raw template.\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Details\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\n\\n\\n\\n\\n\\nCurated by: [More Information Needed]\\nFunded by [optional]: [More Information Needed]\\nShared by [optional]: [More Information Needed]\\nLanguage(s) (NLP): [More Information Needed]\\nLicense: [More Information Needed]\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Sources [optional]\\n\\t\\n\\n\\n\\n\\nRepository: [More… See the full description on the dataset page: https://huggingface.co/datasets/wuji8836/text."},
	{"name":"Blast_TrainData","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/lvlvlvlv1/Blast_TrainData","creator_name":"lvhaoyuan","creator_url":"https://huggingface.co/lvlvlvlv1","description":"\\n\\t\\n\\t\\t\\n\\t\\t爆破知识数据集\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\t数据集详情\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\t数据集描述\\n\\t\\n\\n本数据集聚焦于爆破工程领域，包含专业技术文档、安全操作规范、案例研究等结构化文本数据。适用于NLP模型在爆破领域的知识问答、文本生成等任务。\\n关键特征：\\n\\n覆盖岩土爆破、拆除爆破、爆破安全等子领域\\n包含公式、参数表等专业内容\\n中英双语专业术语对照\\n\\n基础信息：\\n\\n语言：中文（包含专业英文术语）\\n数据量级：约20000条文本片段\\n时间跨度：1980-2025年\\n许可协议：Apache-2.0（注意：部分子集可能有特殊授权条款）\\n\\n\\n\\t\\n\\t\\t\\n\\t\\t数据来源\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n数据类型\\n占比\\n来源示例\\n\\n\\n\\t\\t\\n学术论文\\n35%\\nCNKI、万方、Elsevier\\n\\n\\n技术标准\\n25%\\nGB/T体系、OSHA标准\\n\\n\\n工程报告\\n20%\\n重点工程项目文档\\n\\n\\n安全手册\\n15%\\n企业内训资料\\n\\n\\n专利文件\\n5%\\n国家知识产权局\\n\\n\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\t使用场景\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\t推荐用途\\n\\t\\n\\n✅ 爆破领域智能问答系统✅ 专业技术文档摘要生成✅ 安全隐患识别与预警✅… See the full description on the dataset page: https://huggingface.co/datasets/lvlvlvlv1/Blast_TrainData."},
	{"name":"deep-xlsx","keyword":"chinese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/jian2008/deep-xlsx","creator_name":"feng","creator_url":"https://huggingface.co/jian2008","description":"jian2008/deep-xlsx dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"AS-SRL","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Santu00/AS-SRL","creator_name":"HUIYAO CHEN","creator_url":"https://huggingface.co/Santu00","description":"\\n\\t\\n\\t\\t\\n\\t\\tAS-SRL: A Chinese Speech-based Semantic Role Labeling Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDescription\\n\\t\\n\\nAS-SRL is the first Chinese speech-based Semantic Role Labeling (SRL) dataset, created by annotating the open-source Mandarin speech corpus AISHELL-1 with semantic role labels following the guidelines of Chinese Proposition Bank 1.0 (CPB1.0). The dataset contains 9,000 speech-text pairs with corresponding SRL annotations, split into training (7,500), development (500), and test (1,000) sets.\\nThis… See the full description on the dataset page: https://huggingface.co/datasets/Santu00/AS-SRL."},
	{"name":"multilingualcrowspairs","keyword":"chinese","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/FrancophonIA/multilingualcrowspairs","creator_name":"FrancophonIA","creator_url":"https://huggingface.co/FrancophonIA","description":"\\nDataset origin: https://gitlab.inria.fr/corpus4ethics/multilingualcrowspairs/\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tMultiLingualCrowsPairs\\n\\t\\n\\nMultilingual CrowS-Pairs, a challenge dataset for measuring stereotypical biases present in the masked language models (MLMs) in 7 different languages. \\nThis challenge dataset was built on the Crows-Pairs corpus (Nangia et al. 2020) using the methodology described in (Névéol et al. 2023). \\nThe 7 new languages are the following:\\n\\nArabic from Maghreb and the Arab world in general… See the full description on the dataset page: https://huggingface.co/datasets/FrancophonIA/multilingualcrowspairs."},
	{"name":"traindata","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/dsacedsfds/traindata","creator_name":"sss","creator_url":"https://huggingface.co/dsacedsfds","description":"dsacedsfds/traindata dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"emova-sft-4m","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Emova-ollm/emova-sft-4m","creator_name":"EMOVA Hugging Face","creator_url":"https://huggingface.co/Emova-ollm","description":"\\n\\t\\n\\t\\t\\n\\t\\tEMOVA-SFT-4M\\n\\t\\n\\n\\n\\n\\n🤗 EMOVA-Models | 🤗 EMOVA-Datasets | 🤗 EMOVA-Demo \\n📄 Paper | 🌐 Project-Page | 💻 Github | 💻 EMOVA-Speech-Tokenizer-Github\\n\\n\\n\\n\\t\\n\\t\\n\\t\\n\\t\\tOverview\\n\\t\\n\\nEMOVA-SFT-4M is a comprehensive dataset curated for omni-modal instruction tuning, including textual, visual, and audio interactions. This dataset is created by gathering open-sourced multi-modal instruction datasets and synthesizing high-quality omni-modal conversation data to enhance user experience. This dataset is… See the full description on the dataset page: https://huggingface.co/datasets/Emova-ollm/emova-sft-4m."},
	{"name":"stickers","keyword":"chinese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/LiuliFox/stickers","creator_name":"LiuliFox","creator_url":"https://huggingface.co/LiuliFox","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tるりのステッカー\\n\\t\\n\\njust for fun.\\n"},
	{"name":"parallel_corpus_game_2024","keyword":"chinese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/bot-yaya/parallel_corpus_game_2024","creator_name":"yaya","creator_url":"https://huggingface.co/bot-yaya","description":"https://github.com/mnbvc-parallel-corpus-team/parallel_corpus_mnbvc\\nMNBVC平行语料小组：游戏语料\\n不定期更新，目前已收录的游戏语料文件，共29份：\\n\\n博德之门3\\n赛博朋克2077\\n黑暗之魂3\\n底特律：化身为人\\n饥荒\\n艾尔登法环\\n原神\\n黑帝斯\\n霍格沃兹之遗\\nIb\\n如龙8\\n如龙7外传\\n荒野大镖客2\\n只狼：影逝二度\\n文明6\\n杀戮尖塔\\n崩坏星穹铁道\\n群星\\n泰拉瑞亚\\n巫师3\\n魔女之泉3\\n魔女之泉R\\n鸣潮\\n如龙3\\n如龙4\\n如龙5\\n如龙6\\n如龙极2\\n如龙7\\n\\n"},
	{"name":"nlg-machine_translation","keyword":"chinese","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/aisingapore/nlg-machine_translation","creator_name":"AI Singapore","creator_url":"https://huggingface.co/aisingapore","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSEA Machine Translation\\n\\t\\n\\nSEA Machine Translation evaluates a model's ability to translate a document from a source language into a target language coherently and fluently. It is sampled from FLORES 200 for Burmese, Chinese, English, Indonesian, Khmer, Malay, Tamil, Thai, and Vietnamese, and NusaX for Indonesian, Javanese, and Sundanese.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSupported Tasks and Leaderboards\\n\\t\\n\\nSEA Machine Translation is designed for evaluating chat or instruction-tuned large language… See the full description on the dataset page: https://huggingface.co/datasets/aisingapore/nlg-machine_translation."},
	{"name":"test","keyword":"chinese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/reysz/test","creator_name":"Rui Zhang","creator_url":"https://huggingface.co/reysz","description":"test\\nQA pairs\\nThis is used to test LLM applications in the field of ecological environment.\\n"},
	{"name":"X-ALMA-Preference","keyword":"chinese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/haoranxu/X-ALMA-Preference","creator_name":"Haoran Xu","creator_url":"https://huggingface.co/haoranxu","description":"This is the translation preference dataset used by X-ALMA.\\nsource: the source sentence.\\nchosen: the preferred translation.\\nreject: the dis-preferred translation.\\ndirections: the translation direction.\\n@misc{xu2024xalmaplugplay,\\n      title={X-ALMA: Plug & Play Modules and Adaptive Rejection for Quality Translation at Scale}, \\n      author={Haoran Xu and Kenton Murray and Philipp Koehn and Hieu Hoang and Akiko Eriguchi and Huda Khayrallah},\\n      year={2024},\\n      eprint={2410.03115}… See the full description on the dataset page: https://huggingface.co/datasets/haoranxu/X-ALMA-Preference."},
	{"name":"CPTransExercise","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/edmond5995/CPTransExercise","creator_name":"Hoi","creator_url":"https://huggingface.co/edmond5995","description":"Chinese-Portuguese Translation Exercise Corpus (CPTEC)\\nThis dataset aims to provide translators to practice Chinese-Portuguese translation with different levels from basic to proficient.\\nThis is a sample dataset from CPTEC, please contact us for more information.\\nlmhoi@mpu.edu.mo\\n"},
	{"name":"dypromotion","keyword":"chinese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/AntonCook/dypromotion","creator_name":"AntonHu","creator_url":"https://huggingface.co/AntonCook","description":"AntonCook/dypromotion dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"chinese_word_frequency","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/jnext/chinese_word_frequency","creator_name":"N","creator_url":"https://huggingface.co/jnext","description":"\\n\\t\\n\\t\\t\\n\\t\\tChinese Word frequency statistics\\n\\t\\n\\nword segmentation by jieba tool\\n\\nseq_monkey_data : statistics on 13,000,000 document / 6,561,241,266 words / 11,313,242,610 characters\\n\\n"},
	{"name":"ceshi1-weitiao-hetongzhapian","keyword":"chinese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Crazyht530/ceshi1-weitiao-hetongzhapian","creator_name":"guangzhao","creator_url":"https://huggingface.co/Crazyht530","description":"\\n\\t\\n\\t\\t\\n\\t\\tDataset Card for Dataset Name\\n\\t\\n\\n\\n\\nThis dataset card aims to be a base template for new datasets. It has been generated using this raw template.\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Details\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\n\\n\\n\\n\\n\\nCurated by: [More Information Needed]\\nFunded by [optional]: [More Information Needed]\\nShared by [optional]: [More Information Needed]\\nLanguage(s) (NLP): [More Information Needed]\\nLicense: [More Information Needed]\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Sources [optional]\\n\\t\\n\\n\\n\\n\\nRepository: [More… See the full description on the dataset page: https://huggingface.co/datasets/Crazyht530/ceshi1-weitiao-hetongzhapian."},
	{"name":"tw-ly-bill","keyword":"chinese","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/openfun/tw-ly-bill","creator_name":"Openfun Ltd.","creator_url":"https://huggingface.co/openfun","description":"openfun/tw-ly-bill dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"tw-ly-meet","keyword":"chinese","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/openfun/tw-ly-meet","creator_name":"Openfun Ltd.","creator_url":"https://huggingface.co/openfun","description":"openfun/tw-ly-meet dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"tw-ly-law","keyword":"chinese","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/openfun/tw-ly-law","creator_name":"Openfun Ltd.","creator_url":"https://huggingface.co/openfun","description":"openfun/tw-ly-law dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"tw-ly-law_version","keyword":"chinese","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/openfun/tw-ly-law_version","creator_name":"Openfun Ltd.","creator_url":"https://huggingface.co/openfun","description":"openfun/tw-ly-law_version dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"BRIGHTER-emotion-intensities","keyword":"chinese","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/brighter-dataset/BRIGHTER-emotion-intensities","creator_name":"BRIGHTER Dataset","creator_url":"https://huggingface.co/brighter-dataset","description":"\\n\\t\\n\\t\\t\\n\\t\\tBRIGHTER Emotion Intensities Dataset\\n\\t\\n\\nThis dataset contains the emotion intensities data from the BRIGHTER paper: BRIdging the Gap in Human-Annotated Textual Emotion Recognition Datasets for 28 Languages.\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThe BRIGHTER Emotion Intensities dataset is a comprehensive multi-language emotion intensity dataset with separate configurations for each language. It represents one of the largest human-annotated emotion datasets across multiple languages, providing… See the full description on the dataset page: https://huggingface.co/datasets/brighter-dataset/BRIGHTER-emotion-intensities."},
	{"name":"semeval-2025-task11-track-a","keyword":"chinese","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/vgaraujov/semeval-2025-task11-track-a","creator_name":"Vladimir Araujo","creator_url":"https://huggingface.co/vgaraujov","description":"\\n\\t\\n\\t\\t\\n\\t\\tSemEval 2025 Task 11 - Track A Dataset\\n\\t\\n\\nThis dataset contains the data for SemEval 2025 Task 11: Bridging the Gap in Text-Based Emotion Detection - Track A, organized as language-specific configurations.\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThe dataset is a multi-language, multi-label emotion classification dataset with separate configurations for each language.\\n\\nTotal languages: 26 standard ISO codes\\nTotal examples: 115159\\nSplits: train, dev, test\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tLanguage Configurations\\n\\t\\n\\nEach… See the full description on the dataset page: https://huggingface.co/datasets/vgaraujov/semeval-2025-task11-track-a."},
	{"name":"semeval-2025-task11-track-c","keyword":"chinese","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/vgaraujov/semeval-2025-task11-track-c","creator_name":"Vladimir Araujo","creator_url":"https://huggingface.co/vgaraujov","description":"\\n\\t\\n\\t\\t\\n\\t\\tSemEval 2025 Task 11 - Track C Dataset\\n\\t\\n\\nThis dataset contains the data for SemEval 2025 Task 11: Bridging the Gap in Text-Based Emotion Detection - Track C, organized as language-specific configurations.\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThe dataset is a multi-language, multi-label emotion classification dataset with separate configurations for each language.\\n\\nTotal languages: 30 standard ISO codes\\nTotal examples: 57254\\nSplits: dev, test (Track C has no train split)\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tTrack… See the full description on the dataset page: https://huggingface.co/datasets/vgaraujov/semeval-2025-task11-track-c."},
	{"name":"tw-ly-gazette","keyword":"chinese","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/openfun/tw-ly-gazette","creator_name":"Openfun Ltd.","creator_url":"https://huggingface.co/openfun","description":"openfun/tw-ly-gazette dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"Diabetica-SFT","keyword":"chinese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/WaltonFuture/Diabetica-SFT","creator_name":"Lai Wei","creator_url":"https://huggingface.co/WaltonFuture","description":"\\n\\t\\n\\t\\t\\n\\t\\tDiabetica-SFT\\n\\t\\n\\n\\n\\n    Diabetica: Adapting Large Language Model to Enhance Multiple Medical Tasks in Diabetes Care and Management\\n\\n\\n\\n\\n\\nCode ｜Paper \\n\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tIntroduction\\n\\t\\n\\nHello! Welcome to the huggingface repository for Diabetica. \\nOur study introduced a reproducible framework for developing a specialized LLM capable of handling various diabetes tasks. We present three key contributions: \\n\\nHigh-performance domain-specific model: Compared with previous generic LLMs, our model… See the full description on the dataset page: https://huggingface.co/datasets/WaltonFuture/Diabetica-SFT."},
	{"name":"immersive-translate-en2zh","keyword":"chinese","license":"GNU General Public License v3.0","license_url":"https://choosealicense.com/licenses/gpl-3.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Orion-zhen/immersive-translate-en2zh","creator_name":"Orion","creator_url":"https://huggingface.co/Orion-zhen","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tImmersive Translate\\n\\t\\n\\n本数据集是适用于沉浸式翻译中调用大模型翻译时的prompt模板的数据集. 受本地大模型性能限制, 我没有采用多段文字的prompt模板, 仅使用单段文字的默认prompt模板. system prompt也采用通用翻译专家的默认system prompt\\n本数据集由Garsa3112/ChineseEnglishTranslationDataset和bfsujason@github/mac生成\\n"},
	{"name":"BiST","keyword":"chinese","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Mxode/BiST","creator_name":"Max Zhang","creator_url":"https://huggingface.co/Mxode","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tBiST\\n\\t\\n\\nEnglish | 简体中文\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tIntroduction\\n\\t\\n\\nBiST is a large-scale bilingual translation dataset, with \\\"BiST\\\" standing for Bilingual Synthetic Translation dataset. Currently, the dataset contains approximately 57,000,000 entries and will continue to expand in the future.\\nBiST consists of two subsets, namely en-zh and zh-en, where the former represents the source language, collected from public data as real-world content; the latter represents the target language for… See the full description on the dataset page: https://huggingface.co/datasets/Mxode/BiST."},
	{"name":"ChFT","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/tzyll/ChFT","creator_name":"Zhiyuan Tang","creator_url":"https://huggingface.co/tzyll","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for ChFT\\n\\t\\n\\n\\n\\nThis dataset is published with the paper Full-text Error Correction for Chinese Speech Recognition with Large Language Model in ICASSP 2025.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Details\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\n\\n\\n\\n\\n\\nCurated by: [More Information Needed]\\nFunded by [optional]: [More Information Needed]\\nShared by [optional]: [More Information Needed]\\nLanguage(s) (NLP): [More Information Needed]\\nLicense: [More Information Needed]\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Sources… See the full description on the dataset page: https://huggingface.co/datasets/tzyll/ChFT."},
	{"name":"toxic-nlp-combine","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/TFuuki/toxic-nlp-combine","creator_name":"Tan Youxi","creator_url":"https://huggingface.co/TFuuki","description":"TFuuki/toxic-nlp-combine dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"Address-Classifyer","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/5m4ck3r/Address-Classifyer","creator_name":"Pryanshu Sharma","creator_url":"https://huggingface.co/5m4ck3r","description":"5m4ck3r/Address-Classifyer dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"NT-mini","keyword":"chinese","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Mxode/NT-mini","creator_name":"Max Zhang","creator_url":"https://huggingface.co/Mxode","description":"Mxode/NT-mini dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"kurage_training_data","keyword":"chinese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/lightblue/kurage_training_data","creator_name":"Lightblue KK.","creator_url":"https://huggingface.co/lightblue","description":"lightblue/kurage_training_data dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"wukong","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/shushu3456/wukong","creator_name":"shushu","creator_url":"https://huggingface.co/shushu3456","description":"shushu3456/wukong dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"Coupang-Product-Set-2.7M","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/clw8998/Coupang-Product-Set-2.7M","creator_name":"WW","creator_url":"https://huggingface.co/clw8998","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tHow to Load the Dataset\\n\\t\\n\\nYou can load this dataset using the Hugging Face datasets library as follows:\\nMake sure you have the datasets library installed:\\npip install datasets\\n\\nUse the following code to retrieve the dataset:\\nfrom datasets import load_dataset\\n\\n# Load the Coupang Product Set 1M dataset\\ndataset = load_dataset('clw8998/Coupang-Product-Set-2.7M')\\n\\n# Display the first few rows of the dataset\\nfor i in range(5):\\n    print(dataset['train'][i])\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tExpected  Output… See the full description on the dataset page: https://huggingface.co/datasets/clw8998/Coupang-Product-Set-2.7M."},
	{"name":"sharegpt_cot_dataset","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/AiCloser/sharegpt_cot_dataset","creator_name":"Ai Closer","creator_url":"https://huggingface.co/AiCloser","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tA data set inspired by the \\\"Reflection\\\" method, three-dimensional thinking and cot\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tThis is the ShareGPT format.\\n\\t\\n\\nThe data set was generated using multiple llm synthesis.\\n"},
	{"name":"chinese-classification","keyword":"chinese","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/agentlans/chinese-classification","creator_name":"Alan Tseng","creator_url":"https://huggingface.co/agentlans","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tChinese Classification Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tOverview\\n\\t\\n\\nThe Chinese Classification Dataset is designed for classifying sentences in different forms of Chinese text. Each entry consists of a Chinese sentence paired with a label indicating its language variant.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tStructure\\n\\t\\n\\n\\nRows: Each row contains a single Chinese sentence.\\nLabels: Comma-separated strings indicating one or more of these languages:\\nzh: Simplified Chinese\\nzht: Traditional Chinese\\nyue: Cantonese… See the full description on the dataset page: https://huggingface.co/datasets/agentlans/chinese-classification."},
	{"name":"LongMIT-128K","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/donmaclean/LongMIT-128K","creator_name":"Zhi Chen","creator_url":"https://huggingface.co/donmaclean","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLongMIT: Essential Factors in Crafting Effective Long Context Multi-Hop Instruction Datasets\\n\\t\\n\\n\\n    \\n    [ArXiv]\\n    \\n    \\n\\n\\n\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDownload LongMIT Datasets\\n\\t\\n\\ndef download_longmit_datasets(dataset_name: str, save_dir: str):\\n    qa_pairs = []\\n    dataset = load_dataset(dataset_name, split='train', cache_dir=HFCACHEDATASETS, trust_remote_code=True)\\n    for d in dataset:\\n        all_docs = d['all_docs']\\n\\n        if d['type'] in ['inter_doc', 'intra_doc']:\\n            if… See the full description on the dataset page: https://huggingface.co/datasets/donmaclean/LongMIT-128K."},
	{"name":"nlp_zh_98_encoding_table","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/beyondgravityresearch/nlp_zh_98_encoding_table","creator_name":"BeyondGravityResearch","creator_url":"https://huggingface.co/beyondgravityresearch","description":"98 五笔码表\\n数据来源 http://98wb.ysepan.com/\\n"},
	{"name":"PangeaBench-xchat","keyword":"chinese","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/neulab/PangeaBench-xchat","creator_name":"NeuLab @ LTI/CMU","creator_url":"https://huggingface.co/neulab","description":"neulab/PangeaBench-xchat dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"campus_qa","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/dipwater/campus_qa","creator_name":"dipwater","creator_url":"https://huggingface.co/dipwater","description":"dipwater/campus_qa dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"mc-translation","keyword":"chinese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/efederici/mc-translation","creator_name":"Edoardo Federici","creator_url":"https://huggingface.co/efederici","description":"This dataset contains professional human translations from OpenAI's MMMLU dataset, repurposed to train translation models that can help translate future evaluation datasets.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tWhy This Dataset?\\n\\t\\n\\nTranslation of evaluation benchmarks is a critical but challenging task. While automated translations may introduce errors or biases, professional human translations are expensive and time-consuming. This dataset leverages existing professional translations (MMMLU) to train specialized… See the full description on the dataset page: https://huggingface.co/datasets/efederici/mc-translation."},
	{"name":"dali","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/liwei1987cn/dali","creator_name":"Levi li","creator_url":"https://huggingface.co/liwei1987cn","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\t大李老师问答数据集\\n\\t\\n\\n这个数据集包含大李老师的问答对话,用于训练对话模型。\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\t数据集描述\\n\\t\\n\\n\\n格式: JSONL\\n字段: \\ninstruction: 固定值\\\"请大李老师回答\\\"\\ninput: 提问内容 \\noutput: 大李老师的回答\\n\\n\\n数据量: xxx条对话数据\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\t使用示例\\n\\t\\n\\nfrom datasets import load_dataset\\n\\ndataset = load_dataset(\\\"your-username/dataset-name\\\")\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\t许可证\\n\\t\\n\\nApache 2.0\\n"},
	{"name":"Theresa","keyword":"chinese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/None1145/Theresa","creator_name":"None","creator_url":"https://huggingface.co/None1145","description":"None1145/Theresa dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"hongkong_carpark","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/hkdata/hongkong_carpark","creator_name":"AI provider","creator_url":"https://huggingface.co/hkdata","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Dataset Name\\n\\t\\n\\n\\n\\nDataset is the carpark information on Hong Kong.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Details\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\n\\n\\n\\n\\n\\nCurated by: [More Information Needed]\\nFunded by [optional]: [More Information Needed]\\nShared by [optional]: [More Information Needed]\\nLanguage(s) (NLP): [More Information Needed]\\nLicense: [More Information Needed]\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Sources [optional]\\n\\t\\n\\n\\n\\nCollection from public information on hong kong carpark\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tUses… See the full description on the dataset page: https://huggingface.co/datasets/hkdata/hongkong_carpark."},
	{"name":"kao20240823","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/clinno/kao20240823","creator_name":"周大可","creator_url":"https://huggingface.co/clinno","description":"clinno/kao20240823 dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"hwtcm-sft-v1","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Monor/hwtcm-sft-v1","creator_name":"Monor Huang","creator_url":"https://huggingface.co/Monor","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tA dataset of Tradictional Chinese Medicine (TCM) for SFT\\n\\t\\n\\n一个用于微调LLM的传统中医数据集\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tIntroduction\\n\\t\\n\\nThis repository contains a dataset of Traditional Chinese Medicine (TCM) for fine-tuning large language models.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThe dataset contains 7,096 Chinese sentences related to TCM. The sentences are collected from various sources on the Internet, including medical websites, TCM forums, and TCM books. The dataset is generated or judged by various LLMs… See the full description on the dataset page: https://huggingface.co/datasets/Monor/hwtcm-sft-v1."},
	{"name":"chinese-english-technical-patent-glossary","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/lianghsun/chinese-english-technical-patent-glossary","creator_name":"Huang Liang Hsun","creator_url":"https://huggingface.co/lianghsun","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for 中華民國專利技術名詞中英對照詞庫(Chinese-English Technical Patent Glossary)\\n\\t\\n\\n(WIP)\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tlicense: apache-2.0\\n\\t\\n\\n"},
	{"name":"xiyouji","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Fisher2023/xiyouji","creator_name":"FisherYu","creator_url":"https://huggingface.co/Fisher2023","description":"西游记小说\\n"},
	{"name":"Firefly-Rephrased-Multiturn-300K","keyword":"chinese","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Mxode/Firefly-Rephrased-Multiturn-300K","creator_name":"Max Zhang","creator_url":"https://huggingface.co/Mxode","description":"Mxode/Firefly-Rephrased-Multiturn-300K dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"Firefly-1.1M-Rephrased","keyword":"chinese","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Mxode/Firefly-1.1M-Rephrased","creator_name":"Max Zhang","creator_url":"https://huggingface.co/Mxode","description":"Mxode/Firefly-1.1M-Rephrased dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"test","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/hl0737/test","creator_name":"Hu Dou Dou","creator_url":"https://huggingface.co/hl0737","description":"hl0737/test dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"IndustryCorpus-Subset-zh-en","keyword":"chinese","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Mxode/IndustryCorpus-Subset-zh-en","creator_name":"Max Zhang","creator_url":"https://huggingface.co/Mxode","description":"Mxode/IndustryCorpus-Subset-zh-en dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"Chinese-web-novel","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/qwertyuiopasdfg/Chinese-web-novel","creator_name":"aaa","creator_url":"https://huggingface.co/qwertyuiopasdfg","description":"\\n\\t\\n\\t\\t\\n\\t\\t数据集信息\\n\\t\\n\\n本数据集从 https://m.bqgui.cc 爬取了每本书至多25章的内容来控制篇幅，共12740项数据。经过了三轮数据清洗，虽然改善很大，但是仍然会包含一些低质量的信息和与作品无关的内容（例如求订阅、爆肝xxxx字之类的。。。）\\n\\n\\t\\n\\t\\t\\n\\t\\t数据集质量\\n\\t\\n\\n每项数据包含三条信息：书名、简介和小说文本\\n书名：由于长度极短，文本质量是最好的，没有参杂什么广告。\\n简介：史，能用的没几个。\\n小说文本：内容质量尚且不提，已经尽量把一些千奇百怪的符号和广告过滤掉了。\\n\\n\\t\\n\\t\\t\\n\\t\\t代码\\n\\t\\n\\n爬取小说就算用多线程也比较慢，可能是我代码的原因或者是请求数量太多了，详见爬取.ipynb\\n数据清洗主要用的是正则表达式和字符串操作，详见清洗.ipynb\\n至于下一步的清洗。。。由于中文语言的多样性，直接删除对应的语句效率极低且有可能会误删正常的文本，希望未来能有比较好用的LLM或其它工具来解决此问题。\\n"},
	{"name":"MedExamRetrieval","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/CMIRB/MedExamRetrieval","creator_name":"Chinese Medical Information Retrieval Benchmark","creator_url":"https://huggingface.co/CMIRB","description":"Paper: https://huggingface.co/papers/2410.20050\\n"},
	{"name":"DuBaikeRetrieval","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/CMIRB/DuBaikeRetrieval","creator_name":"Chinese Medical Information Retrieval Benchmark","creator_url":"https://huggingface.co/CMIRB","description":"Paper: https://huggingface.co/papers/2410.20050\\n"},
	{"name":"IIYIPostRetrieval","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/CMIRB/IIYIPostRetrieval","creator_name":"Chinese Medical Information Retrieval Benchmark","creator_url":"https://huggingface.co/CMIRB","description":"Paper: https://huggingface.co/papers/2410.20050\\n"},
	{"name":"CSLCiteRetrieval","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/CMIRB/CSLCiteRetrieval","creator_name":"Chinese Medical Information Retrieval Benchmark","creator_url":"https://huggingface.co/CMIRB","description":"Paper: https://huggingface.co/papers/2410.20050\\n"},
	{"name":"product-database","keyword":"chinese","license":"GNU Affero General Public License v3.0","license_url":"https://choosealicense.com/licenses/agpl-3.0/","language":"en","dataset_url":"https://huggingface.co/datasets/openfoodfacts/product-database","creator_name":"Open Food Facts","creator_url":"https://huggingface.co/openfoodfacts","description":"\\n\\t\\n\\t\\t\\n\\t\\tOpen Food Facts Database\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tWhat is 🍊 Open Food Facts?\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tA food products database\\n\\t\\n\\nOpen Food Facts is a database of food products with ingredients, allergens, nutrition facts and all the tidbits of information we can find on product labels.\\n\\n\\t\\n\\t\\t\\n\\t\\tMade by everyone\\n\\t\\n\\nOpen Food Facts is a non-profit association of volunteers. 25.000+ contributors like you have added 1.7 million + products from 150 countries using our Android or iPhone app or their camera to scan… See the full description on the dataset page: https://huggingface.co/datasets/openfoodfacts/product-database."},
	{"name":"test1","keyword":"chinese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/wbshuaiq/test1","creator_name":"老王","creator_url":"https://huggingface.co/wbshuaiq","description":"wbshuaiq/test1 dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"meissa-lima","keyword":"chinese","license":"GNU General Public License v3.0","license_url":"https://choosealicense.com/licenses/gpl-3.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Orion-zhen/meissa-lima","creator_name":"Orion","creator_url":"https://huggingface.co/Orion-zhen","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tMeissa-LIMA\\n\\t\\n\\n受LIMA启发, 我制作了这个数据集. 数据集由以下几个部分构成: 原始数据集, 中文翻译版, 破限数据集, 角色扮演数据集, Gutenberg数据集, 弱智吧问答.\\n\\n原始数据集: 原数据集中包含了13条拒绝/道德对齐的数据, 我将其找出并手动进行了修改\\n中文翻译版: 使用运行在 Great Server 上的 Orion-zhen/Meissa-Qwen2.5-7B-Instruct-Q5_K_M-GGUF 完成翻译, 并由我进行校对\\n破限数据集: 从 Orion-zhen/meissa-unalignments 中选取了若干条目\\n角色扮演数据集: 从 MinervaAI/Aesir-Preview 中选取了若干条目\\nGutenberg数据集: 从 Orion-zhen/kto-gutenberg 中选取了若干条目\\n弱智吧问答: 从 LooksJuicy/ruozhiba 中选取了若干问题并由我手动编写回答\\n\\n"},
	{"name":"CCI3-HQ-Annotation-Benchmark","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/BAAI/CCI3-HQ-Annotation-Benchmark","creator_name":"Beijing Academy of Artificial Intelligence","creator_url":"https://huggingface.co/BAAI","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tCCI3-HQ-Annotation-Benchmark\\n\\t\\n\\nThese 14k samples were randomly extracted from a large corpus of Chinese texts, containing both the original text and corresponding labels. They can be used to evaluate the quality of Chinese corpora.\\n"},
	{"name":"VisualDataset100K","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/REILX/VisualDataset100K","creator_name":"SunForlight","creator_url":"https://huggingface.co/REILX","description":"中文\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLocal Deployment of Large Models and Construction of VisualDataset100K Dataset\\n\\t\\n\\nDeploy large models locally using vllm and utilize them to construct the VisualDataset100K dataset.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\t1. Local Deployment of Large Models (vllm + nginx)\\n\\t\\n\\nUses multi GPUs, loads the Qwen/Qwen2-VL-2B-Instruct、Qwen/Qwen2-VL-7B-Instruct、Qwen/Qwen2-VL-72B-Instruct-GPTQ-Int4 models through vllm, and uses nginx for load balancing.\\n1.1 Launch vllm instances:\\nRun a vllm instance on each GPU… See the full description on the dataset page: https://huggingface.co/datasets/REILX/VisualDataset100K."},
	{"name":"roomnumber","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/w11342900/roomnumber","creator_name":"Ennis Wang","creator_url":"https://huggingface.co/w11342900","description":"w11342900/roomnumber dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"prompt-injection-multilingual","keyword":"chinese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/rikka-snow/prompt-injection-multilingual","creator_name":"Le Xuan Hoang","creator_url":"https://huggingface.co/rikka-snow","description":"rikka-snow/prompt-injection-multilingual dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"LexEval","keyword":"chinese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/CSHaitao/LexEval","creator_name":"Haitao Li","creator_url":"https://huggingface.co/CSHaitao","description":""},
	{"name":"CMB","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/fzkuji/CMB","creator_name":"Fu Zichuan","creator_url":"https://huggingface.co/fzkuji","description":"\\n\\t\\n\\t\\t\\n\\t\\tCMB: A Comprehensive  Medical Benchmark in Chinese\\n\\t\\n\\n\\n\\n   🌐 Github • 🌐 Website • 🤗 HuggingFace\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\t🌈 Update\\n\\t\\n\\n\\n[2024.02.21] The answers to the CMB-Exam test has been updated and some errors caused by omissions in version management have been fixed.\\n[2024.01.08] In order to facilitate testing, we disclose the answers to the CMB-Exam test\\n[2023.09.22] CMB is included in OpenCompass.\\n[2023.08.21] Paper released.\\n[2023.08.01] 🎉🎉🎉 CMB is published！🎉🎉🎉\\n\\n\\n\\t\\n\\t\\t\\n\\t\\t🌐… See the full description on the dataset page: https://huggingface.co/datasets/fzkuji/CMB."},
	{"name":"neutral-language-challenge","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/missvector/neutral-language-challenge","creator_name":"Victoria","creator_url":"https://huggingface.co/missvector","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLabels denote the following rules that LLM should follow to pass the Neutral Language Challenge:\\n\\t\\n\\n\\n1 \\\"tone\\\": Replace hostile or aggressive words with neutral equivalents\\n2 \\\"lexicon\\\": Replace words with negative subtext while maintaining context\\n3 \\\"emphasis\\\": Replace exaggerations or understatements with neutral phrasing\\n4 \\\"connotation\\\": Replace words with negative connotation with neutral equivalents\\n5 \\\"implicature\\\": Identify implied hostility and regenerate a neutral response\\n\\n"},
	{"name":"NanoExperiment-Data-Mix-10M","keyword":"chinese","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Mxode/NanoExperiment-Data-Mix-10M","creator_name":"Max Zhang","creator_url":"https://huggingface.co/Mxode","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tMxode/NanoExperiment-Data-Mix-10M\\n\\t\\n\\nDataset of NanoExperiment. Tokenized by Bilingual-Tokenizer-2K.\\n"},
	{"name":"COREX-18","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/laion/COREX-18","creator_name":"LAION eV","creator_url":"https://huggingface.co/laion","description":"\\n  \\n\\n\\nCOREX 18\\n\\n\\nIntroducing COREX-18, a comprehensive dataset derived from the 2018 version of the CORE dataset. Our goal is to contribute to the research community by compiling open-access scientific papers and publishing them in extensive datasets. These datasets will facilitate advanced RAG applications and enhance artificial intelligence research.\\nCOREX was developed as part of our X initiative, which aims to maintain and compile publicly available data into accessible and regularly… See the full description on the dataset page: https://huggingface.co/datasets/laion/COREX-18."},
	{"name":"FineRob","keyword":"chinese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Linkseed/FineRob","creator_name":"KunLi","creator_url":"https://huggingface.co/Linkseed","description":"\\n  \\n\\nFineRob - Fine-Grained Social Media Behavior Simulation Dataset\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tPaper\\n\\t\\n\\nhttps://arxiv.org/abs/2412.03148\\n\\n\\t\\n\\t\\t\\n\\t\\tGithub\\n\\t\\n\\nhttps://github.com/linkseed18612254945/FineRob\\n\\n\\t\\n\\t\\t\\n\\t\\tOverview\\n\\t\\n\\nFinerob is a novel fine-grained user behavior simulation dataset collected from three social media platform: X(Twitter), Reddit, Zhihu.\\nThe dataset is design to evalute the role-play capacity of LLMs through three differnet action elements simulation.\\n\\n  \\n\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tIntroduction\\n\\t\\n\\nWe collect… See the full description on the dataset page: https://huggingface.co/datasets/Linkseed/FineRob."},
	{"name":"newt","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/sdsdfd/newt","creator_name":"sdfd","creator_url":"https://huggingface.co/sdsdfd","description":"sdsdfd/newt dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"llama2_7B_data_10G","keyword":"chinese","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/2imi9/llama2_7B_data_10G","creator_name":"Ziming Qi","creator_url":"https://huggingface.co/2imi9","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThis dataset consists of 10GB of open-source bilingual data (Chinese and English) organized by Ziming Qi, sourced from platforms such as Hugging Face and CSDN. The data covers a wide range of topics, with an emphasis on multi-round conversational logic and reasoning. It includes both general and technical question-answer pairs, making it ideal for training AI models that need to handle extended conversations and maintain context across multiple exchanges.\\nThe… See the full description on the dataset page: https://huggingface.co/datasets/2imi9/llama2_7B_data_10G."},
	{"name":"model","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/luChneg/model","creator_name":"David","creator_url":"https://huggingface.co/luChneg","description":"luChneg/model dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"MedicalQA","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Bolin97/MedicalQA","creator_name":"ZhangBolin","creator_url":"https://huggingface.co/Bolin97","description":"\\n\\t\\n\\t\\t\\n\\t\\tMedicalQA-1.4M\\n\\t\\n\\nMedicalQA is an integrated large-scale, high-quality Chinese SFT dataset, designed for medical knowledge injection into LLMs by SFT or RAG. \\nEach sample is reviewed by the free LLM (ERNIE-Speed) using our proposed Quality Evaluation Algorithm.\\nMedArk-KI involving in two types of medical knowledge: Traditional Chinese Medicine (TCM) and Western Medicine(WM). It consists of 4 subsets as shown in the tabel: \\n\\n\\t\\n\\t\\t\\nName\\nVolume\\nAuthor\\nReviewer\\nType\\nSource\\nSource Format… See the full description on the dataset page: https://huggingface.co/datasets/Bolin97/MedicalQA."},
	{"name":"shiji-translation-dataset","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/kobe73er/shiji-translation-dataset","creator_name":"Chris Deng","creator_url":"https://huggingface.co/kobe73er","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\t史记七十列传 古文-现代文翻译数据集\\n\\t\\n\\n这个数据集包含了《史记·七十列传》的古文和对应的现代文翻译。数据集采用 JSONL 格式，每行包含：\\n\\ninput: 现代文\\noutput: 古文\\ninstruction: 翻译指令\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\t数据集统计\\n\\t\\n\\n\\n总条目数：14,115 条\\n来源：《史记·七十列传》\\n格式：JSONL\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\t用途\\n\\t\\n\\n这个数据集可以用于：\\n\\n古文翻译模型训练\\n文言文理解\\n中文自然语言处理研究\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\t数据格式示例\\n\\t\\n\\n{\\n    \\\"output\\\": \\\"万石君名奋，其父赵人也，姓石氏。\\\",\\n    \\\"input\\\": \\\"万石君名奋，他的父亲是赵国人，姓石。\\\",\\n    \\\"instruction\\\": \\\"请把现代汉语翻译成古文\\\"\\n}\\n\\n"},
	{"name":"wsdm2024-cot-dataset","keyword":"chinese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/ruggsea/wsdm2024-cot-dataset","creator_name":"Ruggero Marino Lazzaroni","creator_url":"https://huggingface.co/ruggsea","description":"This dataset is created by ruggsea for the WSDM 2024 competition. It is a semisynthetic dataset created by asking Llama 3.1 70B to generate rationales for the responses to the prompts in the WSDM 2024 competition. \\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tColumns\\n\\t\\n\\n\\nid: Unique identifier for each example\\nprompt: The input prompt given to the model\\nresponse_a: First response option\\nresponse_b: Second response option\\nwinner: The winning response (0 or 1)\\nrationale: The rationale generated by Llama 3.1 70B explaining why… See the full description on the dataset page: https://huggingface.co/datasets/ruggsea/wsdm2024-cot-dataset."},
	{"name":"cantonese-chinese-parallel-corpus","keyword":"chinese","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/HKAllen/cantonese-chinese-parallel-corpus","creator_name":"Allen D","creator_url":"https://huggingface.co/HKAllen","description":"\\n\\t\\n\\t\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThis dataset consists of parallel sentence pairs in Cantonese and Chinese. It is designed for various tasks, including machine translation. \\nThe corpus contains a large number of sentence pairs collected from various domains and most has been improved through manual correction and translation.\\n\\n\\t\\n\\t\\t\\n\\t\\tLanguages\\n\\t\\n\\n\\nCantonese (yue)\\nSimplified Chinese (zh)\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Structure\\n\\t\\n\\nEach entry in the dataset is a JSON object containing two fields: \\\"yue\\\" for the… See the full description on the dataset page: https://huggingface.co/datasets/HKAllen/cantonese-chinese-parallel-corpus."},
	{"name":"FGRC-SCD","keyword":"chinese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Abooooo/FGRC-SCD","creator_name":"Jiarui Chen","creator_url":"https://huggingface.co/Abooooo","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\t基于CCF23-EVAL任务6的电信网络诈骗案件数据集合成了风险短信与对话数据集，并基于多样性、任务相关性和是否满足人类偏好进行筛选，可用于风险细粒度分类任务和风险摘要生成任务测评。\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\t短信生成数据集筛选前后的评价结果比较\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n数据集\\n数据评估指标\\n案例生成方式\\n属性提示生成方式\\n案例生成方式\\n属性提示生成方式\\n\\n\\n\\t\\t\\n\\n余弦相似度↓\\n\\n\\n\\n\\n\\n\\n所有类别\\n\\n0.7149\\n0.6943\\n0.7041\\n0.6704\\n\\n\\n冒充电商物流客服类\\n\\n0.7542\\n0.6981\\n0.7606\\n0.7331\\n\\n\\n虚假网络投资理财类\\n\\n0.7967\\n0.7120\\n0.8029\\n0.7108\\n\\n\\n虚假信用服务类\\n\\n0.7840\\n0.7050\\n0.7738\\n0.7010\\n\\n\\n虚假购物、服务类\\n\\n0.7088\\n0.6931\\n0.6879\\n0.6672\\n\\n\\n冒充公检法及政府机关类\\n\\n0.7979\\n0.7088\\n0.7835\\n0.6935\\n\\n\\n冒充领导、熟人类\\n\\n0.7765\\n0.7063\\n0.7540\\n0.7132\\n\\n\\n网络婚恋、交友类… See the full description on the dataset page: https://huggingface.co/datasets/Abooooo/FGRC-SCD."},
	{"name":"ACG","keyword":"chinese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Abooooo/ACG","creator_name":"Jiarui Chen","creator_url":"https://huggingface.co/Abooooo","description":"基于Codecfake(AISHELL3 + VCTK)，分别使用GPT-SoVIT和ChatTTS合成对应的伪造音频，用于伪造音频识别等任务，支持中文和英文。\\n"},
	{"name":"BlastData","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/lvlvlvlv1/BlastData","creator_name":"lvhaoyuan","creator_url":"https://huggingface.co/lvlvlvlv1","description":"\\n\\t\\n\\t\\t\\n\\t\\tDataset Card for Dataset Name\\n\\t\\n\\n\\n\\nThis dataset card aims to be a base template for new datasets. It has been generated using this raw template.\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Details\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\n\\n\\n\\n\\n\\nCurated by: [More Information Needed]\\nFunded by [optional]: [More Information Needed]\\nShared by [optional]: [More Information Needed]\\nLanguage(s) (NLP): [More Information Needed]\\nLicense: [More Information Needed]\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Sources [optional]\\n\\t\\n\\n\\n\\n\\nRepository: [More… See the full description on the dataset page: https://huggingface.co/datasets/lvlvlvlv1/BlastData."},
	{"name":"llm-ideology-analysis","keyword":"chinese","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/aida-ugent/llm-ideology-analysis","creator_name":"Ghent University Artificial Intelligence & Data Analytics Group","creator_url":"https://huggingface.co/aida-ugent","description":"This dataset contains evaluations of political figures by a diverse set of Large Language Models (LLMs), such that the ideology of these LLMs can be characterized.\\n\\n\\t\\n\\t\\t\\n\\t\\t📝 Dataset Description\\n\\t\\n\\nThe dataset contains responses from 19 different Large Language Models evaluating 3,991 political figures, with responses collected in the six UN languages: Arabic, Chinese, English, French, Russian, and Spanish. \\nThe evaluations were conducted using a two-stage prompting strategy to assess the… See the full description on the dataset page: https://huggingface.co/datasets/aida-ugent/llm-ideology-analysis."},
	{"name":"AVAINT-IMG","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/botintel-community/AVAINT-IMG","creator_name":"BotIntel X","creator_url":"https://huggingface.co/botintel-community","description":"botintel-community/AVAINT-IMG dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"emova-alignment-7m","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Emova-ollm/emova-alignment-7m","creator_name":"EMOVA Hugging Face","creator_url":"https://huggingface.co/Emova-ollm","description":"\\n\\t\\n\\t\\t\\n\\t\\tEMOVA-Alignment-7M\\n\\t\\n\\n\\n\\n\\n🤗 EMOVA-Models | 🤗 EMOVA-Datasets | 🤗 EMOVA-Demo \\n📄 Paper | 🌐 Project-Page | 💻 Github | 💻 EMOVA-Speech-Tokenizer-Github\\n\\n\\n\\n\\n\\t\\n\\t\\n\\t\\n\\t\\tOverview\\n\\t\\n\\nEMOVA-Alignment-7M is a comprehensive dataset curated for omni-modal pre-training, including vision-language and speech-language alignment. \\nThis dataset is created using open-sourced image-text pre-training datasets, OCR datasets, and 2,000 hours of ASR and TTS data. \\nThis dataset is part of the EMOVA-Datasets… See the full description on the dataset page: https://huggingface.co/datasets/Emova-ollm/emova-alignment-7m."},
	{"name":"tst","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Sama1030/tst","creator_name":"SamChang","creator_url":"https://huggingface.co/Sama1030","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tThe \\\"Crime Facts\\\" of \\\"Offenses of Fraudulence\\\" in Judicial Yuan Verdicts Dataset\\n\\t\\n\\nThis data set is based on the judgments of \\\"Offenses of Fraudulence\\\" cases published by the Judicial Yuan. The data range of the dataset is from January 1, 2011, to December 31, 2021. 74,823 pieces of original data (judgments and rulings) were collected. We only took the contents of the \\\"criminal facts\\\" field of the judgment. This dataset is divided into three parts. The training dataset has 59,858… See the full description on the dataset page: https://huggingface.co/datasets/Sama1030/tst."},
	{"name":"Lappland","keyword":"chinese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/None1145/Lappland","creator_name":"None","creator_url":"https://huggingface.co/None1145","description":"None1145/Lappland dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"TurtleBench-extended-zh","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/nycu-ai113-dl-final-project/TurtleBench-extended-zh","creator_name":"NYCU AI Deep Learning final project","creator_url":"https://huggingface.co/nycu-ai113-dl-final-project","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\t海龜湯數據集（中文）\\n\\t\\n\\n本數據集包含中文的海龜湯謎題，用於逆向思維遊戲。\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\t數據集簡介\\n\\t\\n\\n本數據集基於 Duguce/TurtleBench1.5k 擴展而來，旨在為 Turtle-soup Game 提供高質量的推理數據。數據涵蓋多種高難度推理情境，支持 中文 與 英文 兩種語言，並結合多種擴增方法提升多樣性與邏輯性。\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\t數據來源\\n\\t\\n\\n\\n原始數據集來自 Hugging Face，授權於 Apache License 2.0。\\n擴增後數據集由翻譯、標註、基準題庫及模型生成數據構成，詳細分布請見下文。\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\t數據結構\\n\\t\\n\\n數據集包含以下字段，每筆數據均完整記錄了一個海龜湯故事的推理情境與答案標籤：\\n\\n\\t\\n\\t\\t\\n屬性名稱\\n描述\\n\\n\\n\\t\\t\\nid\\n故事的唯一標識符。\\n\\n\\ntitle\\n海龜湯故事的標題。\\n\\n\\nsurface\\n海龜湯故事的表層信息，即玩家能夠直接獲得的線索。\\n\\n\\nbottom\\n海龜湯故事的深層背景，即玩家需要推理才能獲知的答案或情境。\\n\\n\\nuser_guess… See the full description on the dataset page: https://huggingface.co/datasets/nycu-ai113-dl-final-project/TurtleBench-extended-zh."},
	{"name":"llm-failure-dataset","keyword":"chinese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Ki-Seki/llm-failure-dataset","creator_name":"Shichao Song","creator_url":"https://huggingface.co/Ki-Seki","description":"Ki-Seki/llm-failure-dataset dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"emova-asr-tts-eval","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Emova-ollm/emova-asr-tts-eval","creator_name":"EMOVA Hugging Face","creator_url":"https://huggingface.co/Emova-ollm","description":"\\n\\t\\n\\t\\t\\n\\t\\tEMOVA-ASR-TTS-Eval\\n\\t\\n\\n\\n\\n\\n🤗 EMOVA-Models | 🤗 EMOVA-Datasets | 🤗 EMOVA-Demo \\n📄 Paper | 🌐 Project-Page | 💻 Github | 💻 EMOVA-Speech-Tokenizer-Github\\n\\n\\n\\n\\t\\n\\t\\n\\t\\n\\t\\tOverview\\n\\t\\n\\nEMOVA-ASR-TTS-Eval is a dataset designed for evaluating the ASR and TTS performance of Omni-modal LLMs. It is derived from the test-clean set of the LibriSpeech dataset. This dataset is part of the EMOVA-Datasets collection. We extract the speech units using the EMOVA Speech Tokenizer.\\n\\n\\t\\n\\t\\t\\n\\t\\tStructure\\n\\t\\n\\nThis… See the full description on the dataset page: https://huggingface.co/datasets/Emova-ollm/emova-asr-tts-eval."},
	{"name":"difference_images_Cloth-Nude","keyword":"chinese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Makki2104/difference_images_Cloth-Nude","creator_name":"Makki Shizu","creator_url":"https://huggingface.co/Makki2104","description":"This dataset is a collection of Cloth-Nude difference (Tachie) images of anime girls gathered from the internet, with images saved in WebP format.\\nThis dataset encode/save all the image with 90% quality webp with pillow library in Python. Which is half size of the 100% quality lossy webp.\\nThe folders 1_cloth-360-90webp and 1_nude-360-90webp contain the original training dataset for the Illustrious Auto Nude model. For training details, please refer to the model card.\\nThe anime-girl-unfiled… See the full description on the dataset page: https://huggingface.co/datasets/Makki2104/difference_images_Cloth-Nude."},
	{"name":"Nonense_sentense_chinese","keyword":"chinese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/pbrother/Nonense_sentense_chinese","creator_name":"wudiudiu","creator_url":"https://huggingface.co/pbrother","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\t废话文学数据集\\n\\t\\n\\n\\n废话主要搜集自中文互联网，如百度，知乎上面的废话合集约300条左右。\\n利用GPT生成相同格式的废话大概700条左右。\\n正常语料来源于huggingface上的中文数据集。\\n可用于文本分类等任务的验证。\\n\\n"},
	{"name":"Taiwan-Curlture-MCQ","keyword":"chinese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/aqweteddy/Taiwan-Curlture-MCQ","creator_name":"aqweteddy","creator_url":"https://huggingface.co/aqweteddy","description":"\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tTW-Curlture-MCQ\\n\\t\\n\\nTW-Curlture-MCQ 是一個評量台灣文化的選擇題資料集，主要來自以下兩個資料集的篩選與整合：\\n\\nTMLU\\nTMMLU+\\n\\n以人工挑選與台灣文化相關的科目後，再由 gpt-4o-mini 判斷問題是否與台灣文化相關，共 3828 題。\\n"},
	{"name":"shp_translations","keyword":"chinese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/david9dragon9/shp_translations","creator_name":"David Wu","creator_url":"https://huggingface.co/david9dragon9","description":"This dataset contains translations of three splits (askscience, explainlikeimfive, legaladvice) of the Stanford Human Preference (SHP) dataset, used for training domain-invariant reward models.\\nThe translation was conducted using the No Language Left Behind (NLLB) 3.3 B 200 model.\\nReferences:\\nStanford Human Preference Dataset: https://huggingface.co/datasets/stanfordnlp/SHP\\nNLLB: https://huggingface.co/facebook/nllb-200-3.3B\\n"},
	{"name":"Pinyin-Hanzi","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Duyu/Pinyin-Hanzi","creator_name":"Duyu09","creator_url":"https://huggingface.co/Duyu","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\t汉字语句序列与汉语拼音序列数据集\\n\\t\\n\\n汉字语句序列与汉语拼音序列数据集，包含多领域文本，可用于训练汉字-汉语拼音互转模型。\\n"},
	{"name":"C2C","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Pigowen2/C2C","creator_name":"Pigo","creator_url":"https://huggingface.co/Pigowen2","description":"Pigowen2/C2C dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"test","keyword":"chinese","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Ding0702/test","creator_name":"Ding","creator_url":"https://huggingface.co/Ding0702","description":"Ding0702/test dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"CBU0521DD_stories_expanded","keyword":"chinese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Hunterhere/CBU0521DD_stories_expanded","creator_name":"HunterRong","creator_url":"https://huggingface.co/Hunterhere","description":"This project is for CBU5201 coursework under BUPT & QM joint programme.We constructed a dataset that told either a true story or a false story, in a mix of Chinese and English, with a total of 100 audio pieces.And data augmentation is applied on it preparing to afterwards training.More datails please refer to github https://github.com/Hunterhere/CBU5201_miniproject  \\n"},
	{"name":"Libra-Test","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/caskcsg/Libra-Test","creator_name":" KCSG Knowledge Computing and Service Group, IIE, CAS","creator_url":"https://huggingface.co/caskcsg","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\t📊 Libra-Test\\n\\t\\n\\n\\nLibra-Test 是专为中文大模型护栏而构建的评测基准，涵盖七大关键风险场景和 5,700+ 条专家标注数据。\\nLibra-Test is a benchmark designed for the safeguards of Chinese LLMs, covering 7 key risk scenarios and over 5,700 expert-labeled data points.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\t多样性（Diversity）\\n\\t\\n\\nLibra-Test纳入了三个不同的数据来源，最终包括7个有害场景及39个子类别。\\nLibra-Test incorporates data from three different sources, ultimately covering 7 harmful scenarios and 39 subcategories.\\n\\n真实数据（Real Data）  ：从 Safety-Prompts 数据集 中抽取真实的中文有害问题，并在三种中文大模型上生成回复。… See the full description on the dataset page: https://huggingface.co/datasets/caskcsg/Libra-Test."},
	{"name":"xuexiqiangguo_428w","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Macropodus/xuexiqiangguo_428w","creator_name":"Macadam","creator_url":"https://huggingface.co/Macropodus","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\t学习强国数据集(xuexiqiangguo)\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\t下载\\n\\t\\n\\n\\n下载源为Macropodus/xuexiqiangguo_428w\\n国内源为Macropodus/xuexiqiangguo_428w\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\t时间(time)\\n\\t\\n\\n2024.6\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\t句子数(sentence)\\n\\t\\n\\n428w(42.8 million)\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\t过滤(filter)\\n\\t\\n\\n\\n使用小klm模型, kenlm语言模型来自hiyoung123/YoungCorrector,\\n策略(strategy): 剔除(delete) top-5%/bottom-5%;\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\t类型\\n\\t\\n\\n包括以下keys:\\n['2_0_主席文汇', '2_1_学习科学', '2_2_新闻-学习时评-中宣部-经济-理论', '2_3_红色中国', '2_4_县域新闻', '3_1_思想理论', '4_1_强国征文', '5_1_实时平台-身边的感动', '6_1_精神研究', '7_1_政法法治'… See the full description on the dataset page: https://huggingface.co/datasets/Macropodus/xuexiqiangguo_428w."},
	{"name":"crosswoz-sft","keyword":"chinese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/BruceNju/crosswoz-sft","creator_name":"zhongyah","creator_url":"https://huggingface.co/BruceNju","description":"multilinguality:  \\n- monolingual  \\n\\ndescription: |  \\n                          \\n    这是一个基于CrossWOZ数据集处理的对话数据集，专门用于大模型的监督微调（SFT）任务。  \\n    数据集包含多轮对话、用户目标、对话状态等信息，适合训练任务型对话系统。  \\n\\n    原始数据来源于CrossWOZ项目，经过专门的预处理使其更适合现代大模型训练。\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\t核心特征：\\n\\t\\n\\n这是首个大规模的中文跨域任务型对话数据集\\n包含6,012个对话，102,000个话语，覆盖5个领域(酒店、餐厅、景点、地铁和出租车)\\n约60%的对话包含跨域用户目标\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\t主要创新点：\\n\\t\\n\\n更具挑战性的域间依赖关系：\\n\\n一个领域的选择会动态影响其他相关领域的选择\\n例如用户选择的景点会影响后续酒店的推荐范围(需要在景点附近)\\n\\n完整的标注：\\n\\n同时提供用户端和系统端的对话状态标注\\n包含对话行为(dialogue acts)的标注\\n用户状态标注有助于追踪对话流程和建模用户行为… See the full description on the dataset page: https://huggingface.co/datasets/BruceNju/crosswoz-sft."},
	{"name":"BiasAsker","keyword":"chinese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/iforgott/BiasAsker","creator_name":"Yuxuan Wan","creator_url":"https://huggingface.co/iforgott","description":"| Papaer | Github |\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tComplete dataset of BiasAsker\\n\\t\\n\\n\\nbias_annotation.csv: all the biases and their annotated categories.\\nbias_translate.csv: the Chinese translation of the biases in bias_annotation.csv.\\nantonym_annotation.csv: the antonyms of biases in bias_annotation.csv, biases without proper antonyms are removed.\\nantonym_translate.csv: the Chinese translation of antonyms in antonym_annotation.csv\\ngroups.csv: all social groups and their categories\\ngroups_translate.csv: the… See the full description on the dataset page: https://huggingface.co/datasets/iforgott/BiasAsker."},
	{"name":"MJEE","keyword":"chinese","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/TomLi/MJEE","creator_name":"Tom","creator_url":"https://huggingface.co/TomLi","description":"\\n\\t\\n\\t\\t\\n\\t\\tDataset Card for MJEE\\n\\t\\n\\n"},
	{"name":"CNAPS","keyword":"chinese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/gweesin/CNAPS","creator_name":"Gweesin Chan","creator_url":"https://huggingface.co/gweesin","description":"gweesin/CNAPS dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"InfoSearch_train","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/EIT-NLP/InfoSearch_train","creator_name":"EIT-NLP","creator_url":"https://huggingface.co/EIT-NLP","description":"EIT-NLP/InfoSearch_train dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"tw-ly-law_content","keyword":"chinese","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/openfun/tw-ly-law_content","creator_name":"Openfun Ltd.","creator_url":"https://huggingface.co/openfun","description":"openfun/tw-ly-law_content dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"semeval-2025-task11-track-b","keyword":"chinese","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/vgaraujov/semeval-2025-task11-track-b","creator_name":"Vladimir Araujo","creator_url":"https://huggingface.co/vgaraujov","description":"\\n\\t\\n\\t\\t\\n\\t\\tSemEval 2025 Task 11 - Track B Dataset\\n\\t\\n\\nThis dataset contains the data for SemEval 2025 Task 11: Bridging the Gap in Text-Based Emotion Detection - Track B, organized as language-specific configurations.\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThe dataset is a multi-language, multi-label emotion classification dataset with separate configurations for each language.\\n\\nTotal languages: 11 standard ISO codes\\nTotal examples: 47111\\nSplits: train, dev, test\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tTrack Information\\n\\t\\n\\nTrack B has… See the full description on the dataset page: https://huggingface.co/datasets/vgaraujov/semeval-2025-task11-track-b."},
	{"name":"tw-ly-gazette_agenda","keyword":"chinese","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/openfun/tw-ly-gazette_agenda","creator_name":"Openfun Ltd.","creator_url":"https://huggingface.co/openfun","description":"openfun/tw-ly-gazette_agenda dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"amateur_astronomer_jsonl","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/yangpengchao/amateur_astronomer_jsonl","creator_name":"yangpengchao","creator_url":"https://huggingface.co/yangpengchao","description":"\\n\\t\\n\\t\\t\\n\\t\\tDataset Card for Dataset Name\\n\\t\\n\\n\\n\\nThis dataset card aims to be a base template for new datasets. It has been generated using this raw template.\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Details\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\n\\n\\n\\n\\n\\nCurated by: [More Information Needed]\\nFunded by [optional]: [More Information Needed]\\nShared by [optional]: [More Information Needed]\\nLanguage(s) (NLP): [More Information Needed]\\nLicense: [More Information Needed]\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Sources [optional]\\n\\t\\n\\n\\n\\n\\nRepository: [More… See the full description on the dataset page: https://huggingface.co/datasets/yangpengchao/amateur_astronomer_jsonl."},
	{"name":"Diabetica-o1-SFT","keyword":"chinese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/WaltonFuture/Diabetica-o1-SFT","creator_name":"Lai Wei","creator_url":"https://huggingface.co/WaltonFuture","description":"\\n\\t\\n\\t\\t\\n\\t\\tDiabetica-o1-SFT\\n\\t\\n\\n\\n\\n    Diabetica: Adapting Large Language Model to Enhance Multiple Medical Tasks in Diabetes Care and Management\\n\\n\\n\\n\\n\\nCode ｜Paper \\n\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tIntroduction\\n\\t\\n\\nSpecifically, we use Deepseek-R1-Distilled-Qwen-32B as our teacher model. Our data augmentation strategy follows a two-step approach: (1) We prompt Qwen2.5-72B-Instruct to generate diverse synthetic questions based on existing datasets. (2) We then use Deepseek-R1-Distilled-Qwen-32B to generate responses for… See the full description on the dataset page: https://huggingface.co/datasets/WaltonFuture/Diabetica-o1-SFT."},
	{"name":"R1-Vision-PixMo-Cap-QA-zh","keyword":"chinese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/yuyq96/R1-Vision-PixMo-Cap-QA-zh","creator_name":"Ya-Qi Yu","creator_url":"https://huggingface.co/yuyq96","description":"\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tR1-Vision: Let's first take a look at the image\\n\\t\\n\\n\\n  \\n  \\n\\n\\n[🤗 Cold-Start Dataset]  [📜 Report (Coming Soon)]\\n\\n\\nDeepSeek-R1 demonstrates outstanding reasoning abilities when tackling math, coding, puzzle, and science problems, as well as responding to general inquiries. However, as a text-only reasoning model, R1 cannot process multimodal inputs like images, which limits its practicality in certain situations. Exploring the potential for multimodal reasoning is an intriguing… See the full description on the dataset page: https://huggingface.co/datasets/yuyq96/R1-Vision-PixMo-Cap-QA-zh."},
	{"name":"huiboAi","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/RunQi007/huiboAi","creator_name":"Guo","creator_url":"https://huggingface.co/RunQi007","description":""},
	{"name":"introduce-myself","keyword":"chinese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/xiongjj/introduce-myself","creator_name":"xiongjiujiu","creator_url":"https://huggingface.co/xiongjj","description":"我是readme……\\n"},
	{"name":"BenchMAX_Question_Answering","keyword":"chinese","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/LLaMAX/BenchMAX_Question_Answering","creator_name":"LLaMAX","creator_url":"https://huggingface.co/LLaMAX","description":"\\n\\t\\n\\t\\t\\n\\t\\tDataset Sources\\n\\t\\n\\n\\nPaper: BenchMAX: A Comprehensive Multilingual Evaluation Suite for Large Language Models\\nLink: https://arxiv.org/pdf/2502.07346\\nRepository: https://github.com/CONE-MT/BenchMAX\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\nBenchMAX_Function_Completion is a dataset of BenchMAX, sourcing from UN Parallel Corpus and xquad.\\nThe haystacks are from UN Parallel Corpus Test and Development Sets and we translate them to other languages by Google Translate.\\nThe multilingual QA data is from… See the full description on the dataset page: https://huggingface.co/datasets/LLaMAX/BenchMAX_Question_Answering."},
	{"name":"test","keyword":"chinese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/plumber233/test","creator_name":"plumber233","creator_url":"https://huggingface.co/plumber233","description":"plumber233/test dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"cantonese-written-chinese-translation","keyword":"chinese","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/raptorkwok/cantonese-written-chinese-translation","creator_name":"Raptor K","creator_url":"https://huggingface.co/raptorkwok","description":"raptorkwok/cantonese-written-chinese-translation dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"demo","keyword":"chinese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/c00cjz00/demo","creator_name":"chaochun chuang","creator_url":"https://huggingface.co/c00cjz00","description":"c00cjz00/demo dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"CMRC2018","keyword":"chinese","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/susie-y/CMRC2018","creator_name":"yang","creator_url":"https://huggingface.co/susie-y","description":"susie-y/CMRC2018 dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"farming","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/kunpehx/farming","creator_name":"Kun Peng","creator_url":"https://huggingface.co/kunpehx","description":"\\n\\t\\n\\t\\t\\n\\t\\tIntroduction\\n\\t\\n\\nThis dataset is used agricultural knowledge base training.\\n"},
	{"name":"ShiftySpeech","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ash56/ShiftySpeech","creator_name":"Ashi Garg","creator_url":"https://huggingface.co/ash56","description":"This repository introduces:  🌀 ShiftySpeech: A Large-Scale Synthetic Speech Dataset with Distribution Shifts\\n\\n\\t\\n\\t\\t\\n\\t\\t🔥 Key Features\\n\\t\\n\\n\\n3000+ hours of synthetic speech\\nDiverse Distribution Shifts: The dataset spans 7 key distribution shifts, including:  \\n📖 Reading Style  \\n🎙️ Podcast  \\n🎥 YouTube  \\n🗣️ Languages (Three different languages)  \\n🌎 Demographics (including variations in age, accent, and gender)\\n\\n\\nMultiple Speech Generation Systems: Includes data synthesized from various TTS… See the full description on the dataset page: https://huggingface.co/datasets/ash56/ShiftySpeech."},
	{"name":"Syndrome_Differentiation_NK_test","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/XiaoEnn/Syndrome_Differentiation_NK_test","creator_name":"Yehan Yang","creator_url":"https://huggingface.co/XiaoEnn","description":"\\n\\t\\n\\t\\t\\n\\t\\tIntroduction\\n\\t\\n\\nThe dataset was cleaned from the Traditional Chinese Medicine Internal Medicine textbook by the Angopulo Technology team. The cleaned data was then proofread and annotated by professional TCM students to ensure its accuracy. The cleaned data is used to train and validate the accuracy of downstream syndrome differentiation tasks based on the pre-trained herberta model.\\n"},
	{"name":"M-ABSA","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Multilingual-NLP/M-ABSA","creator_name":"multilingual-NLP","creator_url":"https://huggingface.co/Multilingual-NLP","description":"\\n\\t\\n\\t\\t\\n\\t\\tM-ABSA\\n\\t\\n\\nThis repo contains the data for our paper M-ABSA: A Multilingual Dataset for Aspect-Based Sentiment Analysis.\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tData Description:\\n\\t\\n\\nThis is a dataset suitable for the multilingual ABSA task with triplet extraction.\\nAll datasets are stored in the data/ folder:\\n\\nAll dataset contains 7 domains.\\n\\ndomains = [\\\"coursera\\\", \\\"hotel\\\", \\\"laptop\\\", \\\"restaurant\\\", \\\"phone\\\", \\\"sight\\\", \\\"food\\\"]\\n\\n\\nEach dataset contains 21 languages.\\n\\nlangs = [\\\"ar\\\", \\\"da\\\", \\\"de\\\", \\\"en\\\", \\\"es\\\", \\\"fr\\\", \\\"hi\\\", \\\"hr\\\"… See the full description on the dataset page: https://huggingface.co/datasets/Multilingual-NLP/M-ABSA."},
	{"name":"ChMap-Data","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/FrontierLab/ChMap-Data","creator_name":"FrontierLab","creator_url":"https://huggingface.co/FrontierLab","description":"\\n\\t\\n\\t\\t\\n\\t\\tChMapData: Chinese Memory-aware Proactive Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tOverview\\n\\t\\n\\nThe Chinese Memory-aware Proactive Dataset (ChMapData) is a novel dataset proposed in the paper \\\"Interpersonal Memory Matters: A New Task for Proactive Dialogue Utilizing Conversational History\\\". This dataset focuses on training and evaluating models' capabilities in proactive topic introduction based on conversational history, supporting the memory-aware proactive dialogue framework proposed in the paper.… See the full description on the dataset page: https://huggingface.co/datasets/FrontierLab/ChMap-Data."},
	{"name":"Tieba-SomeInteresting","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Hanversion/Tieba-SomeInteresting","creator_name":"Hanversion","creator_url":"https://huggingface.co/Hanversion","description":"\\n\\t\\n\\t\\t\\n\\t\\t中文数据集（基于百度贴吧）\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\t简介\\n\\t\\n\\n本数据集数据来自于2025年3月5日百度贴吧\\n数据集使用了“孙笑川吧”、“弱智吧”、“中国人口吧”和“航空母舰吧”\\n数据集问题来自于发帖的标题，答案来自于最热门的回复\\n思考链来自于 DeepSeek-v3 生成\\n目前数据集大小较小，后续会逐渐增加\\n\\n\\t\\n\\t\\t\\n\\t\\t联系作者\\n\\t\\n\\n\\nemail: hanversion@outlook.com\\ngithub: GitHub\\n\\n"},
	{"name":"FinSynth_data","keyword":"chinese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Fintech-Dreamer/FinSynth_data","creator_name":"Fintech-Dreamer","creator_url":"https://huggingface.co/Fintech-Dreamer","description":"\\n\\t\\n\\t\\t\\n\\t\\tFinSynth_data\\n\\t\\n\\n本数据集有三个，分别解决三个领域的问题：\\n\\n客户服务聊天机器人：生成可以有效理解和回应广泛客户询问的训练数据。\\n欺诈检测：从交易数据中提取模式和异常，以训练可以识别和预防欺诈行为的模型。\\n合规监控：总结法规和合规文件，以帮助模型确保遵守金融法规。\\n\\n\\n\\t\\n\\t\\t\\n\\t\\t微调大模型参考\\n\\t\\n\\nFintech-Dreamer/FinSynth_model_chatbot · Hugging Face\\nFintech-Dreamer/FinSynth_model_fraud · Hugging Face\\nFintech-Dreamer/FinSynth_model_compliance · Hugging Face\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\t前端框架参考\\n\\t\\n\\nFintech-Dreamer/FinSynth\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\t数据处理方式参考\\n\\t\\n\\nFintech-Dreamer/FinSynth-Data-Processing\\n"},
	{"name":"jianke","keyword":"chinese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/XuehangCang/jianke","creator_name":"XuehangCang","creator_url":"https://huggingface.co/XuehangCang","description":"\\n\\t\\n\\t\\t\\n\\t\\tJianKe\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Overview\\n\\t\\n\\nThis dataset is designed for text generation tasks in Chinese and is available in a single configuration named \\\"default\\\". The dataset is relatively sizable, falling within the 10K to 100K examples category. It is well-suited for various text generation applications including language modeling, dialog systems, and more.\\n\\n\\t\\n\\t\\t\\n\\t\\tFeatures\\n\\t\\n\\n\\ntext: The primary feature of the dataset, which contains Chinese text strings. The data type is string.… See the full description on the dataset page: https://huggingface.co/datasets/XuehangCang/jianke."},
	{"name":"TVC-Data","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Allen8/TVC-Data","creator_name":"Allen Sun","creator_url":"https://huggingface.co/Allen8","description":"\\n\\t\\n\\t\\t\\n\\t\\tDataset Card for TVC-Data\\n\\t\\n\\nThis repository contains the data presented in Mitigating Visual Forgetting via Take-along Visual Conditioning for Multi-modal Long CoT Reasoning.\\nCode: https://github.com/xxx/xxx\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Details\\n\\t\\n\\nA mixture of 345K multimodal long-chain reasoning data. \\nFor more statistics of the dataset, please refer to our paper (coming soon)\\n\\n\\t\\n\\t\\t\\n\\t\\tSource Data\\n\\t\\n\\nLLaVA-OneVision: https://huggingface.co/datasets/lmms-lab/LLaVA-OneVision-DataGeo170K:… See the full description on the dataset page: https://huggingface.co/datasets/Allen8/TVC-Data."},
	{"name":"e-girl","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/yuebanlaosiji/e-girl","creator_name":"yueban","creator_url":"https://huggingface.co/yuebanlaosiji","description":"yuebanlaosiji/e-girl dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"smoltalk-chinese-QwQ-Distrill","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ChinaunicomSoftware/smoltalk-chinese-QwQ-Distrill","creator_name":"Chinaunicom Software","creator_url":"https://huggingface.co/ChinaunicomSoftware","description":"\\n\\n\\t\\n\\t\\t\\n\\t\\tsmoltalk-chinese-QwQ-Distrill          [中文]    [English]\\n\\t\\n\\n\\n\\n\\n📖Technical Report\\nsmoltalk-chinese-QwQ-Distrill is a Chinese fine-tuning dataset constructed with reference to the SmolTalk-Chinese dataset. It aims to provide high-quality synthetic reasoning data support for training large language models (LLMs). The dataset consists entirely of synthetic data, comprising over 700,000 entries. It is specifically designed to enhance the performance of Chinese LLMs across various tasks… See the full description on the dataset page: https://huggingface.co/datasets/ChinaunicomSoftware/smoltalk-chinese-QwQ-Distrill."},
	{"name":"advbench_behaviors_m5","keyword":"chinese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/lenML/advbench_behaviors_m5","creator_name":"len","creator_url":"https://huggingface.co/lenML","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tAbout advbench_behaviors_m5\\n\\t\\n\\n此数据集为 advbench_behaviors.csv 文件的多语言翻译版本。一个常见的任务是用于 abliterator 脚本。\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for AdvBench\\n\\t\\n\\nPaper: Universal and Transferable Adversarial Attacks on Aligned Language Models\\nData: AdvBench Dataset\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tAbout\\n\\t\\n\\nAdvBench is a set of 500 harmful behaviors formulated as instructions. These behaviors\\nrange over the same themes as the harmful strings setting, but the adversary’s goal\\nis instead to find a single attack string that… See the full description on the dataset page: https://huggingface.co/datasets/lenML/advbench_behaviors_m5."},
	{"name":"train1","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/dsacedsfds/train1","creator_name":"sss","creator_url":"https://huggingface.co/dsacedsfds","description":"dsacedsfds/train1 dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"Rosmontis","keyword":"chinese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/None1145/Rosmontis","creator_name":"None","creator_url":"https://huggingface.co/None1145","description":"None1145/Rosmontis dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"EmoBench","keyword":"chinese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/SahandSab/EmoBench","creator_name":"Sahand Sabour","creator_url":"https://huggingface.co/SahandSab","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tEmoBench\\n\\t\\n\\n\\nThis is the official repository for our ACL 2024 paper \\\"EmoBench: Evaluating the Emotional Intelligence of Large Language Models\\\"\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tOverview\\n\\t\\n\\nEmoBench is a comprehensive and challenging benchmark designed to evaluate the Emotional Intelligence (EI) of Large Language Models (LLMs). Unlike traditional datasets, EmoBench focuses not only on emotion recognition but also on advanced EI capabilities such as emotional reasoning and application.\\nThe dataset… See the full description on the dataset page: https://huggingface.co/datasets/SahandSab/EmoBench."},
	{"name":"MedCT","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/TigerResearch/MedCT","creator_name":"Tiger Research","creator_url":"https://huggingface.co/TigerResearch","description":"MedCT is the world's first clinical terminology for non-English language, e.g., Chinese.\\n"},
	{"name":"mmevol-zh-hant","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/syntaxsynth/mmevol-zh-hant","creator_name":"SyntaxSynth","creator_url":"https://huggingface.co/syntaxsynth","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tMMEvol - Translated Chinese Traditional\\n\\t\\n\\nA subset of Tongyi-ConvAI/MMEvol translated using yentinglin/Llama-3-Taiwan-70B-Instruct from english to traditional chinese.\\nRead the Note below before use.\\nImage source distribution:\\n\\n\\t\\n\\t\\t\\nDataset\\nCount\\nPercentage\\n\\n\\n\\t\\t\\ncoco\\n6598\\n29.8%\\n\\n\\nQ-Instruct-DB\\n5856\\n26.4%\\n\\n\\nclevr\\n2383\\n10.8%\\n\\n\\nchartqa\\n1733\\n7.8%\\n\\n\\nhfdata\\n1296\\n5.9%\\n\\n\\ngeo170k\\n706\\n3.2%\\n\\n\\ndata_engine\\n698\\n3.2%\\n\\n\\nmathvision\\n644\\n2.9%\\n\\n\\ndocvqa\\n600\\n2.7%\\n\\n\\nalfworld\\n401\\n1.8%\\n\\n\\narxivqa\\n337\\n1.5%… See the full description on the dataset page: https://huggingface.co/datasets/syntaxsynth/mmevol-zh-hant."},
	{"name":"demo","keyword":"chinese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/eyl45/demo","creator_name":"Ethan","creator_url":"https://huggingface.co/eyl45","description":"eyl45/demo dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"OpenO1-SFT","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/llamafactory/OpenO1-SFT","creator_name":"LLaMA Factory","creator_url":"https://huggingface.co/llamafactory","description":"Borrowed from: https://huggingface.co/datasets/O1-OPEN/OpenO1-SFT\\nYou can use it in LLaMA Factory by specifying dataset: openo1_sft.\\n"},
	{"name":"Fastx-Infinity-Instruct-Chinese","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/fastx-ai/Fastx-Infinity-Instruct-Chinese","creator_name":"fastx-ai.com","creator_url":"https://huggingface.co/fastx-ai","description":"use train.csv/evaluation.csv !\\n"},
	{"name":"pokemon-gpt4o-captions","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/llamafactory/pokemon-gpt4o-captions","creator_name":"LLaMA Factory","creator_url":"https://huggingface.co/llamafactory","description":"Borrowed from: https://huggingface.co/datasets/jugg1024/pokemon-gpt4o-captions\\nYou can use it in LLaMA Factory by specifying dataset: pokemon_cap.\\n"},
	{"name":"kuochang-quote","keyword":"chinese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/h-alice/kuochang-quote","creator_name":"Wayne Hong","creator_url":"https://huggingface.co/h-alice","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tKuochang Sensei Quotes\\n\\t\\n\\n(In)Famous quotes from politician Kuochang Huang.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tIntroduction\\n\\t\\n\\nThis is a collection of quotes from Kuochang Huang, a Taiwanese politician. \\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tHow to Use\\n\\t\\n\\nfrom datasets import load_dataset\\n\\ndataset = load_dataset(\\\"kuochang_quotes\\\")\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThe dataset is in CSV format, with the following columns:\\n\\nspeaker: The speaker of the quote. Which is always \\\"黃國昌\\\".\\nquote: The quote from Kuochang Huang.… See the full description on the dataset page: https://huggingface.co/datasets/h-alice/kuochang-quote."},
	{"name":"doraemon","keyword":"chinese","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/RobertNyu/doraemon","creator_name":"Nyu Ching Yee","creator_url":"https://huggingface.co/RobertNyu","description":"RobertNyu/doraemon dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"Reflection-Chinese-Dataset","keyword":"chinese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/stvlynn/Reflection-Chinese-Dataset","creator_name":"Steven Lynn","creator_url":"https://huggingface.co/stvlynn","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tReflection-Chinese-Dataset·Reflection中文数据集\\n\\t\\n\\nBased on mahiatlinux/Reflection-Dataset-v2, translated using RA Translation Tool\\n"},
	{"name":"Reflection-Chinese-Dataset","keyword":"chinese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/stvlynn/Reflection-Chinese-Dataset","creator_name":"Steven Lynn","creator_url":"https://huggingface.co/stvlynn","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tReflection-Chinese-Dataset·Reflection中文数据集\\n\\t\\n\\nBased on mahiatlinux/Reflection-Dataset-v2, translated using RA Translation Tool\\n"},
	{"name":"DEMO","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/iiiiwis/DEMO","creator_name":"mz.w","creator_url":"https://huggingface.co/iiiiwis","description":"This repository contains data for our paper DEMO: Reframing Dialogue Interaction with Fine-grained Element Modeling. We systematically construct the dialogue framework from the Prelude through the Interlocution to the Epilogue and define an innovative research task: Dialogue Element MOdeling. Furthermore, we introduce a tailor-designed benchmark DEMO to facilitate comprehensive dialogue modeling and assessment. Concretely, our proposed task focuses on two core competencies of models: (1)… See the full description on the dataset page: https://huggingface.co/datasets/iiiiwis/DEMO."},
	{"name":"mmmlu_lite","keyword":"chinese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/opencompass/mmmlu_lite","creator_name":"OpenCompass","creator_url":"https://huggingface.co/opencompass","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tMMMLU-Lite\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tIntroduction\\n\\t\\n\\nA lite version of the MMMLU dataset, which is an community version of the MMMLU dataset by OpenCompass. Due to the large size of the original dataset (about 200k questions), we have created a lite version of the dataset to make it easier to use. We sample 25 examples from each language subject in the original dataset with fixed seed to ensure reproducibility, finally we have 19950 examples in the lite version of the dataset, which is about… See the full description on the dataset page: https://huggingface.co/datasets/opencompass/mmmlu_lite."},
	{"name":"policydata","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/fsyfb/policydata","creator_name":"fengshuyang","creator_url":"https://huggingface.co/fsyfb","description":"用于政策领域大模型及检索增强的部分数据\\n"},
	{"name":"text-moderation-02-multilingual","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ifmain/text-moderation-02-multilingual","creator_name":"Mike Afton","creator_url":"https://huggingface.co/ifmain","description":"This dataset is based on Kaggle.It represents a version of @ifmain/text-moderation-410K that has been cleansed of semantically similar values and normalized to a 50/50 ratio of negative and neutral entries.\\nThe dataset contains 1.5M entries (91K * 17 languages).  \\nBefore use, augmentation is recommended! (e.g., character substitution to bypass moderation).\\nFor augmentation, you can use @ifmain/StringAugmentor.  \\nEnjoy using it!\\n"},
	{"name":"Multilingal-sakalt-data","keyword":"chinese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Sakalti/Multilingal-sakalt-data","creator_name":"sakasan","creator_url":"https://huggingface.co/Sakalti","description":"マルチリンガルデータセットです。mitライセンスです。\\n"},
	{"name":"mmevalpro","keyword":"chinese","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/MMEVAL/mmevalpro","creator_name":"MMEVAL","creator_url":"https://huggingface.co/MMEVAL","description":"MMEvalPro\\n\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for MMEvalPro\\n\\t\\n\\nWe create MMEvalPro for more accurate and efficent evaluation for Large Multimodal Models. It is designed to avoid Type-I errors through a trilogy evaluation pipeline and more rigorous metrics. For each original question from existing benchmarks, human annotators augment it by creating one perception question and one knowledge anchor question through a meticulous annotation process.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Format\\n\\t\\n\\n{\\n    \\\"index\\\": [int64] The… See the full description on the dataset page: https://huggingface.co/datasets/MMEVAL/mmevalpro."},
	{"name":"emova-sft-speech-eval","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Emova-ollm/emova-sft-speech-eval","creator_name":"EMOVA Hugging Face","creator_url":"https://huggingface.co/Emova-ollm","description":"\\n\\t\\n\\t\\t\\n\\t\\tEMOVA-SFT-Speech-Eval\\n\\t\\n\\n\\n\\n\\n🤗 EMOVA-Models | 🤗 EMOVA-Datasets | 🤗 EMOVA-Demo \\n📄 Paper | 🌐 Project-Page | 💻 Github | 💻 EMOVA-Speech-Tokenizer-Github\\n\\n\\n\\n\\t\\n\\t\\n\\t\\n\\t\\tOverview\\n\\t\\n\\nEMOVA-SFT-Speech-Eval is an evaluation dataset curated for omni-modal instruction tuning and emotional spoken dialogue. This dataset is created by converting existing text and visual instruction datasets via Text-to-Speech (TTS) tools. EMOVA-SFT-Speech-Eval is part of EMOVA-Datasets collection, and the training… See the full description on the dataset page: https://huggingface.co/datasets/Emova-ollm/emova-sft-speech-eval."},
	{"name":"windata-vision-synthetics-zh-300k","keyword":"chinese","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/winninghealth/windata-vision-synthetics-zh-300k","creator_name":"Winning Health AI Research","creator_url":"https://huggingface.co/winninghealth","description":"介绍\\n我们整理生成了一个中文多模态图文指令数据集，包含了大约30万条数据以及约20万张图片，涉及文档doc、图表、数学、OCR等多种场景。\\n针对开源数据中中文图文指令集少且指令集描述普遍过于简短等问题，我们设计了一种基于开源模型的合成数据生成方法，利用 Qwen2-vl-72B-Instruct 生成较为详细的中文caption指令集，然后在同一场景中随机挑选1-4张图片和相应的中文caption，将caption数据给到我们的大语言模型 WiNGPT-2.6 通过设计系统指令使其每轮进行提问，将问题和图片给到 Qwen2-vl-72B-Instruct 使其进行回答；最后设定循环次数，得到多轮多图的对话数据。 \\n对于生成后的数据，根据答案的长度、语句的重复性等进行了规则过滤；数学类题目，根据原始数据的答案进行了过滤。在制作最后的caption指令集时，我们针对每一个场景都设计了上百个问题，保证了caption数据集的多样性；在对话数据集上，我们在不同场景下来让WiNGPT-2.6… See the full description on the dataset page: https://huggingface.co/datasets/winninghealth/windata-vision-synthetics-zh-300k."},
	{"name":"ChinaKeywords","keyword":"chinese","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/aqweteddy/ChinaKeywords","creator_name":"aqweteddy","creator_url":"https://huggingface.co/aqweteddy","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tChina Keywords\\n\\t\\n\\nThis repository lists keywords related to Chinese politics along with their corresponding explanations. The primary source of these keywords is:\\n\\nChina Keywords\\n\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\t中國關鍵字\\n\\t\\n\\n本 repo 列出了與中國政治相關的關鍵字及其對應的解釋，主要來源為：\\n\\n中國關鍵字\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\t免責聲明\\n\\t\\n\\n\\n本 repo 提供的資訊僅供參考之用。\\n關鍵字的解釋基於公開可用資訊，並不代表任何我的立場或觀點。\\n本 repo 不保證所提供資訊的準確性、完整性或時效性。\\n使用內容需由使用者自行判斷與承擔責任。\\n\\n"},
	{"name":"llm-ideology-analysis","keyword":"chinese","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ajrogier/llm-ideology-analysis","creator_name":"Alexander Rogiers","creator_url":"https://huggingface.co/ajrogier","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for LLM Ideology Dataset\\n\\t\\n\\nThis dataset contains evaluations of political figures by various Large Language Models (LLMs), designed to analyze ideological biases in AI language models.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Details\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThe dataset contains responses from 17 different Large Language Models evaluating 4,339 political figures, with responses collected in both English and Chinese. The evaluations were conducted using a two-stage prompting… See the full description on the dataset page: https://huggingface.co/datasets/ajrogier/llm-ideology-analysis."},
	{"name":"DXYDiseaseRetrieval","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/CMIRB/DXYDiseaseRetrieval","creator_name":"Chinese Medical Information Retrieval Benchmark","creator_url":"https://huggingface.co/CMIRB","description":"Paper: https://huggingface.co/papers/2410.20050\\n"},
	{"name":"DXYConsultRetrieval","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/CMIRB/DXYConsultRetrieval","creator_name":"Chinese Medical Information Retrieval Benchmark","creator_url":"https://huggingface.co/CMIRB","description":"Paper: https://huggingface.co/papers/2410.20050\\n"},
	{"name":"CSLRelatedRetrieval","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/CMIRB/CSLRelatedRetrieval","creator_name":"Chinese Medical Information Retrieval Benchmark","creator_url":"https://huggingface.co/CMIRB","description":"Paper: https://huggingface.co/papers/2410.20050\\n"},
	{"name":"ksdoc-airscript","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/cy948/ksdoc-airscript","creator_name":"yao cai","creator_url":"https://huggingface.co/cy948","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tHuman Annotation Example\\n\\t\\n\\nWe invite some domain experts who has code experience on AirScript to add annotations for the code snippets in lines. For example:\\n\\nData annotation example\\n\\n/*本示例判断如果活动工作表上区域 B1:B10 中第二个（AboveAverage）条件格式的类型为xlAboveAverageCondition，则删除该条件格式。*/\\nfunction test() {\\n+// 从工作表上区域 B1:B10 中选择第二个条件格式\\n    let aboveAverage = ActiveSheet.Range(\\\"B1:B10\\\").FormatConditions.Item(2)\\n+// 若条件格式的类型为 `xlAboveAverageCondition`\\n    if (aboveAverage.Type ==… See the full description on the dataset page: https://huggingface.co/datasets/cy948/ksdoc-airscript."},
	{"name":"answer_data","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/fruiters/answer_data","creator_name":"org_llama","creator_url":"https://huggingface.co/fruiters","description":"fruiters/answer_data dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"multilingual-coco","keyword":"chinese","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/romrawinjp/multilingual-coco","creator_name":"Romrawin Chumpu","creator_url":"https://huggingface.co/romrawinjp","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tMultilingual Common Objects in Context (COCO) Dataset\\n\\t\\n\\nThis dataset is a collection of multiple language open-source captions of COCO dataset. \\nThe split in this dataset is set according to Andrej Karpathy's split from dataset_coco.json file. The collection was created specifically for simplicity of use in training and evaluation pipeline by non-commercial and research purposes. The COCO images dataset is licensed under a Creative Commons Attribution 4.0 License.… See the full description on the dataset page: https://huggingface.co/datasets/romrawinjp/multilingual-coco."},
	{"name":"medical-o1-reasoning-SFT","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/FreedomIntelligence/medical-o1-reasoning-SFT","creator_name":"FreedomAI","creator_url":"https://huggingface.co/FreedomIntelligence","description":"\\n\\t\\n\\t\\t\\n\\t\\tNews\\n\\t\\n\\n[2025/02/22] We released the distilled dataset from Deepseek-R1 based on medical verifiable problems. You can use it to initialize your models with the reasoning chain from Deepseek-R1.\\n[2024/12/25] We open-sourced the medical reasoning dataset for SFT, built on medical verifiable problems and an LLM verifier.\\n\\n\\t\\n\\t\\t\\n\\t\\tIntroduction\\n\\t\\n\\nThis dataset is used to fine-tune HuatuoGPT-o1, a medical LLM designed for advanced medical reasoning. This dataset is constructed using GPT-4o… See the full description on the dataset page: https://huggingface.co/datasets/FreedomIntelligence/medical-o1-reasoning-SFT."},
	{"name":"Chinese-DeepSeek-R1-Distill-data-110k","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Congliu/Chinese-DeepSeek-R1-Distill-data-110k","creator_name":"CongLiu","creator_url":"https://huggingface.co/Congliu","description":"\\n\\t\\n\\t\\t\\n\\t\\t中文基于满血DeepSeek-R1蒸馏数据集（Chinese-Data-Distill-From-R1）\\n\\t\\n\\n\\n🤗 Hugging Face   |   🤖 ModelScope    |   🚀 Github    |   📑 Blog\\n\\n\\n注意：提供了直接SFT使用的版本，点击下载。将数据中的思考和答案整合成output字段，大部分SFT代码框架均可直接直接加载训练。\\n本数据集为中文开源蒸馏满血R1的数据集，数据集中不仅包含math数据，还包括大量的通用类型数据，总数量为110K。\\n为什么开源这个数据？\\nR1的效果十分强大，并且基于R1蒸馏数据SFT的小模型也展现出了强大的效果，但检索发现，大部分开源的R1蒸馏数据集均为英文数据集。 同时，R1的报告中展示，蒸馏模型中同时也使用了部分通用场景数据集。\\n为了帮助大家更好地复现R1蒸馏模型的效果，特此开源中文数据集。该中文数据集中的数据分布如下：\\n\\nMath：共计36568个样本，\\nExam：共计2432个样本，\\nSTEM：共计12648个样本，… See the full description on the dataset page: https://huggingface.co/datasets/Congliu/Chinese-DeepSeek-R1-Distill-data-110k."},
	{"name":"Chinese-DeepSeek-R1-Distill-data-110k-SFT","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Congliu/Chinese-DeepSeek-R1-Distill-data-110k-SFT","creator_name":"CongLiu","creator_url":"https://huggingface.co/Congliu","description":"\\n\\t\\n\\t\\t\\n\\t\\t中文基于满血DeepSeek-R1蒸馏数据集（Chinese-Data-Distill-From-R1）\\n\\t\\n\\n\\n🤗 Hugging Face   |   🤖 ModelScope    |   🚀 Github    |   📑 Blog\\n\\n\\n注意：该版本为，可以直接SFT使用的版本，将原始数据中的思考和答案整合成output字段，大部分SFT代码框架均可直接直接加载训练。\\n本数据集为中文开源蒸馏满血R1的数据集，数据集中不仅包含math数据，还包括大量的通用类型数据，总数量为110K。\\n为什么开源这个数据？\\nR1的效果十分强大，并且基于R1蒸馏数据SFT的小模型也展现出了强大的效果，但检索发现，大部分开源的R1蒸馏数据集均为英文数据集。 同时，R1的报告中展示，蒸馏模型中同时也使用了部分通用场景数据集。\\n为了帮助大家更好地复现R1蒸馏模型的效果，特此开源中文数据集。该中文数据集中的数据分布如下：\\n\\nMath：共计36568个样本，\\nExam：共计2432个样本，\\nSTEM：共计12648个样本，… See the full description on the dataset page: https://huggingface.co/datasets/Congliu/Chinese-DeepSeek-R1-Distill-data-110k-SFT."},
	{"name":"alpaca-zh","keyword":"chinese","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/shibing624/alpaca-zh","creator_name":"Ming Xu (徐明)","creator_url":"https://huggingface.co/shibing624","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for \\\"alpaca-zh\\\"\\n\\t\\n\\n本数据集是参考Alpaca方法基于GPT4得到的self-instruct数据，约5万条。\\nDataset from https://github.com/Instruction-Tuning-with-GPT-4/GPT-4-LLM \\nIt is the chinese dataset from https://github.com/Instruction-Tuning-with-GPT-4/GPT-4-LLM/blob/main/data/alpaca_gpt4_data_zh.json\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tUsage and License Notices\\n\\t\\n\\nThe data is intended and licensed for research use only. The dataset is CC BY NC 4.0 (allowing only non-commercial use) and models trained using the dataset should… See the full description on the dataset page: https://huggingface.co/datasets/shibing624/alpaca-zh."},
	{"name":"AyaVisionBench","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/CohereForAI/AyaVisionBench","creator_name":"Cohere For AI","creator_url":"https://huggingface.co/CohereForAI","description":"\\n\\t\\n\\t\\t\\n\\t\\tDataset Card for Aya Vision Benchmark\\n\\t\\n\\n\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Details\\n\\t\\n\\nThe Aya Vision Benchmark is designed to evaluate vision-language models in real-world multilingual scenarios. It spans 23 languages and 9 distinct task categories, with 15 samples per category, resulting in 135 image-question pairs per language. \\nEach question requires visual context for the answer and covers languages that half of the world's population speaks, making this dataset particularly suited for… See the full description on the dataset page: https://huggingface.co/datasets/CohereForAI/AyaVisionBench."},
	{"name":"Traditional-Chinese-Medicine-Dataset-SFT","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/SylvanL/Traditional-Chinese-Medicine-Dataset-SFT","creator_name":"SylvanLiu","creator_url":"https://huggingface.co/SylvanL","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\t启古纳今，厚德精术\\n\\t\\n\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\t数据介绍\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\t非网络来源的高质量中医数据集-指令微调\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tHigh-Quality Traditional Chinese Medicine Dataset from Non-Internet Sources - SFT/IFT\\n\\t\\n\\n该数据集经过大量人力和资源的投入精心构建，以共建LLM高质量中文社区为己任。\\n包含约1GB的中医各个领域临床案例、名家典籍、医学百科，名词解释等优质问答内容，涵盖全面，配比均衡。\\n数据集主要由非网络来源的内部数据构成，并99%为简体中文内容，内容质量优异，信息密度可观。\\n该数据集的数据源与SylvanL/Traditional-Chinese-Medicine-Dataset-Pretrain中的内容存在一定关联，但不高度重叠。\\n在二者的构建过程中，存在着一定的循序渐进与互为补充的逻辑.\\n该数据集可以独立使用，但建议先使用配套的预训练数据集对模型进行继续预训练后，再使用该数据集进行进一步的指令微调。… See the full description on the dataset page: https://huggingface.co/datasets/SylvanL/Traditional-Chinese-Medicine-Dataset-SFT."},
	{"name":"Medical-R1-Distill-Data","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/FreedomIntelligence/Medical-R1-Distill-Data","creator_name":"FreedomAI","creator_url":"https://huggingface.co/FreedomIntelligence","description":"\\n\\t\\n\\t\\t\\n\\t\\tIntroduction\\n\\t\\n\\nThis dataset is an SFT dataset distilled from Deepseek-R1 (Full Power Version), based on medical verifiable problems from HuatuoGPT-o1.\\nThe Chinese version of the dataset is available at FreedomIntelligence/Medical-R1-Distill-Data-Chinese.\\nThe distillation originates from the native Deepseek-R1 API requests. We hope this distilled dataset can help initialize your models with the reasoning chain from R1. You can also use our previously built medical verified long… See the full description on the dataset page: https://huggingface.co/datasets/FreedomIntelligence/Medical-R1-Distill-Data."},
	{"name":"timbre_range","keyword":"chinese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/ccmusic-database/timbre_range","creator_name":"CCMUSIC Database","creator_url":"https://huggingface.co/ccmusic-database","description":"\\n\\t\\n\\t\\t\\n\\t\\tDataset Card for Timbre and Range Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThe timbre dataset contains acapella singing audio of 9 singers, as well as cut single-note audio, totaling 775 clips (.wav format)\\nThe vocal range dataset includes several up and down chromatic scales audio clips of several vocals, as well as the cut single-note audio clips (.wav format).\\n\\n\\t\\n\\t\\t\\n\\t\\tSupported Tasks and Leaderboards\\n\\t\\n\\nAudio classification\\n\\n\\t\\n\\t\\t\\n\\t\\tLanguages\\n\\t\\n\\nChinese, English\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset… See the full description on the dataset page: https://huggingface.co/datasets/ccmusic-database/timbre_range."},
	{"name":"VibeEval","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/RekaAI/VibeEval","creator_name":"Reka AI","creator_url":"https://huggingface.co/RekaAI","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVibe-Eval\\n\\t\\n\\nA benchmark for evaluating multimodal chat models, including especially challenging examples.\\n[Link to paper] [Blogpost] [Github]\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset\\n\\t\\n\\nEach example has the following fields:\\n\\nexample_id: a unique ID for the example\\ncategory: the category that this example belongs to, either difficulty-normal or difficulty-hard\\nprompt: the user prompt\\nreference: a golden reference answer for the prompt\\nimage: an image struct (containing bytes and path keys).… See the full description on the dataset page: https://huggingface.co/datasets/RekaAI/VibeEval."},
	{"name":"webfaq","keyword":"chinese","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/PaDaS-Lab/webfaq","creator_name":"Chair of Data Science, University of Passau","creator_url":"https://huggingface.co/PaDaS-Lab","description":"WebFAQ Q&A Dataset\\n\\n   \\n       Overview |\\n       Details  |\\n       Structure  |\\n       Examples |\\n       Considerations |\\n       License |\\n       Citation |\\n       Contact |\\n       Acknowledgement\\n   \\n\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tOverview\\n\\t\\n\\nThe WebFAQ Q&A Dataset is a broad-coverage corpus of 96 million natural question-answer (QA) pairs in 75 languages, gathered from FAQ pages on the web. It leverages structured schema.org FAQPage annotations, making it a unique resource for large-scale Question Answering… See the full description on the dataset page: https://huggingface.co/datasets/PaDaS-Lab/webfaq."},
	{"name":"Qilin","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/THUIR/Qilin","creator_name":"THUIR","creator_url":"https://huggingface.co/THUIR","description":"\\n\\t\\n\\t\\t\\n\\t\\tQilin\\n\\t\\n\\nQilin is a large-scale multimodal dataset designed for advancing research in search, recommendation, and Retrieval-Augmented Generation (RAG) systems. This repository contains the official implementation of the dataset paper, baseline models, and evaluation tools.  This dataset was presented in Qilin: A Multimodal Information Retrieval Dataset with APP-level User Sessions.\\nGithub: https://github.com/RED-Search/Qilin\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Overview\\n\\t\\n\\nQilin provides comprehensive… See the full description on the dataset page: https://huggingface.co/datasets/THUIR/Qilin."},
	{"name":"oasst1","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/OpenAssistant/oasst1","creator_name":"OpenAssistant","creator_url":"https://huggingface.co/OpenAssistant","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tOpenAssistant Conversations Dataset (OASST1)\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nIn an effort to democratize research on large-scale alignment, we release OpenAssistant \\nConversations (OASST1), a human-generated, human-annotated assistant-style conversation \\ncorpus consisting of 161,443 messages in 35 different languages, annotated with 461,292 \\nquality ratings, resulting in over 10,000 fully annotated conversation trees. The corpus \\nis a product of a worldwide crowd-sourcing effort… See the full description on the dataset page: https://huggingface.co/datasets/OpenAssistant/oasst1."},
	{"name":"Everything_Instruct_Multilingual","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/rombodawg/Everything_Instruct_Multilingual","creator_name":"rombo dawg","creator_url":"https://huggingface.co/rombodawg","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tEverything Instruct (Multilingual Edition)\\n\\t\\n\\nEverything you need... all in one place 💘\\n\\nEverything instruct (Multilingual Edition) is a massive alpaca instruct formatted dataset consisting of a wide variety of topics meant to bring LLM's to the next level in open source AI.\\nNote: This dataset is fully uncensored (No model will refuse any request trained on this dataset unless otherwise aligned)\\nNote2: This version of the dataset supports the following languages:\\n\\nEnglish\\nRussian… See the full description on the dataset page: https://huggingface.co/datasets/rombodawg/Everything_Instruct_Multilingual."},
	{"name":"ruozhiba","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/LooksJuicy/ruozhiba","creator_name":"LooksJuicy","creator_url":"https://huggingface.co/LooksJuicy","description":"受COIG-CQIA启发，构建类似数据集，但答案风格相对更简洁。\\n弱智吧精选问题数据来自github提供的疑问句，调用GPT-4获取答案，并过滤掉明显拒答的回复。\\n"},
	{"name":"Medical-R1-Distill-Data-Chinese","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/FreedomIntelligence/Medical-R1-Distill-Data-Chinese","creator_name":"FreedomAI","creator_url":"https://huggingface.co/FreedomIntelligence","description":"\\n\\t\\n\\t\\t\\n\\t\\tIntroduction\\n\\t\\n\\nThis dataset is an SFT dataset distilled from Deepseek-R1 (Full Power Version), based on Chinese medical verifiable problems from HuatuoGPT-o1.\\nThe distillation originates from the native Deepseek-R1 API requests. We hope this distilled dataset can help initialize your models with the reasoning chain from R1. You can also use our previously built medical verified long reasoning chains based on GPT-4o on medical-o1-reasoning-SFT.\\nFor details, see our paper and GitHub… See the full description on the dataset page: https://huggingface.co/datasets/FreedomIntelligence/Medical-R1-Distill-Data-Chinese."},
	{"name":"DISC-Law-SFT","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ShengbinYue/DISC-Law-SFT","creator_name":"ShengbinYue","creator_url":"https://huggingface.co/ShengbinYue","description":"\\n\\t\\n\\t\\t\\n\\t\\tDISC-Law-SFT Dataset\\n\\t\\n\\nLegal Intelligent systems in Chinese require a combination of various abilities, including legal text understanding and generation. To achieve this, we have constructed a high-quality supervised fine-tuning dataset called DISC-Law-SFT, which covers different legal scenarios such as legal information extraction, legal judgment prediction, legal document summarization, and legal question answering. DISC-Law-SFT comprises two subsets, DISC-Law-SFT-Pair and… See the full description on the dataset page: https://huggingface.co/datasets/ShengbinYue/DISC-Law-SFT."},
	{"name":"MathVista","keyword":"chinese","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/AI4Math/MathVista","creator_name":"AI for Math Reasoning","creator_url":"https://huggingface.co/AI4Math","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for MathVista\\n\\t\\n\\n\\nDataset Description\\nPaper Information\\nDataset Examples\\nLeaderboard\\nDataset Usage\\nData Downloading\\nData Format\\nData Visualization\\nData Source\\nAutomatic Evaluation\\n\\n\\nLicense\\nCitation\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nMathVista is a consolidated Mathematical reasoning benchmark within Visual contexts. It consists of three newly created datasets, IQTest, FunctionQA, and PaperQA, which address the missing visual domains and are tailored to evaluate… See the full description on the dataset page: https://huggingface.co/datasets/AI4Math/MathVista."},
	{"name":"oasst2","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/OpenAssistant/oasst2","creator_name":"OpenAssistant","creator_url":"https://huggingface.co/OpenAssistant","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tOpen Assistant Conversations Dataset Release 2 (OASST2)\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Structure\\n\\t\\n\\nThis dataset contains message trees. Each message tree has an initial prompt message as the root node, \\nwhich can have multiple child messages as replies, and these child messages can have multiple replies. \\nAll messages have a role property: this can either be \\\"assistant\\\" or \\\"prompter\\\". The roles in \\nconversation threads from prompt to leaf node strictly alternate between \\\"prompter\\\" and… See the full description on the dataset page: https://huggingface.co/datasets/OpenAssistant/oasst2."},
	{"name":"cmm-math","keyword":"chinese","license":"BSD 3-Clause \"New\" or \"Revised\" License","license_url":"https://choosealicense.com/licenses/bsd-3-clause/","language":"en","dataset_url":"https://huggingface.co/datasets/ecnu-icalk/cmm-math","creator_name":"ICALK","creator_url":"https://huggingface.co/ecnu-icalk","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tCMM-Math\\n\\t\\n\\n\\n💻 Github Repo\\n💻 Paper Link\\n\\n\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tIntroduction\\n\\t\\n\\nLarge language models (LLMs) have obtained promising results in mathematical reasoning, which is a foundational skill for human intelligence. Most previous studies focus on improving and measuring the performance of LLMs based on textual math reasoning datasets (e.g., MATH, GSM8K). Recently, a few researchers have released English multimodal math datasets (e.g., MATHVISTA and MATH-V) to evaluate the… See the full description on the dataset page: https://huggingface.co/datasets/ecnu-icalk/cmm-math."},
	{"name":"OpenO1-SFT","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/O1-OPEN/OpenO1-SFT","creator_name":"Open-Source O1","creator_url":"https://huggingface.co/O1-OPEN","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSFT Data for CoT Activation\\n\\t\\n\\n🎉🎉🎉This repository contains the dataset used for fine-tuning a language model using SFT for Chain-of-Thought Activation. \\n🌈🌈🌈The dataset is designed to enhance the model's ability to generate coherent and logical reasoning sequences. \\n☄☄☄By using this dataset, the model can learn to produce detailed and structured reasoning steps, enhancing its performance on complex reasoning tasks.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tStatistics\\n\\t\\n\\n1️⃣Total Records: 77,685… See the full description on the dataset page: https://huggingface.co/datasets/O1-OPEN/OpenO1-SFT."},
	{"name":"function-calling-small","keyword":"chinese","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Deepexi/function-calling-small","creator_name":"Deepexi Inc","creator_url":"https://huggingface.co/Deepexi","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\t数据集内容说明:\\n\\t\\n\\n包含700+个阿里云OpenAPI的信息;包括Dataworks,EMR，DataLake，Maxcompute，Hologram,实时计算Flink版，QuickBI,DTS等多个产品的公开Open API信息。\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\t样例\\n\\t\\n\\n{\\n  \\\"systemPrompt\\\": 你是一个函数筛选助理，如果与问题相关的话,您可以使用下面的函数来获取更多数据以回答用户提出的问题:{\\\"function\\\": \\\"UpdateTicketNum\\\", \\\"description\\\": \\\"对用于免登嵌入报表的指定的ticket进行更新票据数量操作。\\\", \\\"arguments\\\": [{\\\"name\\\": \\\"Ticket\\\", \\\"type\\\": \\\"string\\\", \\\"description\\\": \\\"三方嵌入的票据值，即URL中的accessTicket值。\\\"}, {\\\"name\\\": \\\"TicketNum\\\", \\\"type\\\": \\\"integer\\\", \\\"description\\\": \\\"票据数。\\\\n-… See the full description on the dataset page: https://huggingface.co/datasets/Deepexi/function-calling-small."},
	{"name":"GSM8K_zh","keyword":"chinese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/meta-math/GSM8K_zh","creator_name":"MetaMath","creator_url":"https://huggingface.co/meta-math","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset\\n\\t\\n\\nGSM8K_zh is a dataset for mathematical reasoning in Chinese, question-answer pairs are translated from GSM8K (https://github.com/openai/grade-school-math/tree/master) by GPT-3.5-Turbo with few-shot prompting.\\nThe dataset consists of 7473 training samples and 1319 testing samples. The former is for supervised fine-tuning, while the latter is for evaluation.\\nfor training samples, question_zh and answer_zh are question and answer keys, respectively;\\nfor testing samples… See the full description on the dataset page: https://huggingface.co/datasets/meta-math/GSM8K_zh."},
	{"name":"SLAKE","keyword":"chinese","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/BoKelvin/SLAKE","creator_name":"Kelvin Liu","creator_url":"https://huggingface.co/BoKelvin","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Info:\\n\\t\\n\\nSLAKE: A Semantically-Labeled Knowledge-Enhanced Dataset for Medical Visual Question Answering [ISBI 2021 oral]\\nProject Page: click\\nCorresponding Authors: Bo Liu, Xiao-Ming Wu\\nAny questions, please contact us. Thank you!\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tModification:\\n\\t\\n\\nIn the Huggingface Repo, we have changed the name of validate.json to validation.json to better display in the Dataset Card.\\n"},
	{"name":"llava-med-zh-instruct-60k","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/BUAADreamer/llava-med-zh-instruct-60k","creator_name":"Zhangchi Feng","creator_url":"https://huggingface.co/BUAADreamer","description":"This Chinese dataset was translated from llava-med using Qwen1.5-14B-Chat and contains 60k medical visual instruction data points.\\nYou can organize content in the dataset_info.json in LLaMA Factory like this:\\n\\\"llava_med_zh_60k\\\": {\\n  \\\"hf_hub_url\\\": \\\"BUAADreamer/llava-med-zh-instruct-60k\\\",\\n  \\\"formatting\\\": \\\"sharegpt\\\",\\n  \\\"columns\\\": {\\n    \\\"messages\\\": \\\"messages\\\",\\n    \\\"images\\\": \\\"images\\\"\\n  },\\n  \\\"tags\\\": {\\n    \\\"role_tag\\\": \\\"role\\\",\\n    \\\"content_tag\\\": \\\"content\\\",\\n    \\\"user_tag\\\": \\\"user\\\",\\n    \\\"assistant_tag\\\":… See the full description on the dataset page: https://huggingface.co/datasets/BUAADreamer/llava-med-zh-instruct-60k."},
	{"name":"LLaVA-OneVision-Data","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/lmms-lab/LLaVA-OneVision-Data","creator_name":"LMMs-Lab","creator_url":"https://huggingface.co/lmms-lab","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for LLaVA-OneVision\\n\\t\\n\\n[2024-09-01]: Uploaded VisualWebInstruct(filtered), it's used in OneVision Stage\\n\\nalmost all subsets are uploaded with HF's required format and you can use the recommended interface to download them and follow our code below to convert them. \\n\\n\\nthe subset of ureader_kg and ureader_qa are uploaded with the processed jsons and tar.gz of image folders.\\nYou may directly download them from the following url.… See the full description on the dataset page: https://huggingface.co/datasets/lmms-lab/LLaVA-OneVision-Data."},
	{"name":"ToolACE","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Team-ACE/ToolACE","creator_name":"Team-ACE","creator_url":"https://huggingface.co/Team-ACE","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tToolACE\\n\\t\\n\\nToolACE is an automatic agentic pipeline designed to generate Accurate, Complex, and divErse tool-learning data. \\nToolACE leverages a novel self-evolution synthesis process to curate a comprehensive API pool of 26,507 diverse APIs. \\nDialogs are further generated through the interplay among multiple agents, guided by a formalized thinking process. \\nTo ensure data accuracy, we implement a dual-layer verification system combining rule-based and model-based checks. \\nMore… See the full description on the dataset page: https://huggingface.co/datasets/Team-ACE/ToolACE."},
	{"name":"chinese-fineweb-edu","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/opencsg/chinese-fineweb-edu","creator_name":"opencsg","creator_url":"https://huggingface.co/opencsg","description":"\\n\\t\\n\\t\\t\\n\\t\\tWe recommend you to use the improved version Fineweb-edu-chinese-v2.1 !\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tChinese Fineweb Edu Dataset          [中文]    [English]\\n\\t\\n\\n\\n\\n\\n\\n\\n\\n[OpenCSG Community]   [👾github]  [wechat]  [Twitter] \\n\\n\\n\\n\\n📖Technical Report\\nChinese Fineweb Edu dataset is a meticulously constructed high-quality Chinese pre-training corpus, specifically designed for natural language processing tasks in the education domain. This dataset undergoes a rigorous selection and deduplication process, using a… See the full description on the dataset page: https://huggingface.co/datasets/opencsg/chinese-fineweb-edu."},
	{"name":"Global-MMLU","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/CohereForAI/Global-MMLU","creator_name":"Cohere For AI","creator_url":"https://huggingface.co/CohereForAI","description":"\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nGlobal-MMLU 🌍 is a multilingual evaluation set spanning 42 languages, including English. This dataset combines machine translations for MMLU questions along with professional translations and crowd-sourced post-edits.\\nIt also includes cultural sensitivity annotations for a subset of the questions (2850 questions per language) and classifies them as Culturally Sensitive (CS) 🗽 or Culturally Agnostic (CA) ⚖️. These annotations were collected as part of an open… See the full description on the dataset page: https://huggingface.co/datasets/CohereForAI/Global-MMLU."},
	{"name":"MMathCoT-1M","keyword":"chinese","license":"GNU General Public License v3.0","license_url":"https://choosealicense.com/licenses/gpl-3.0/","language":"en","dataset_url":"https://huggingface.co/datasets/URSA-MATH/MMathCoT-1M","creator_name":"URSA-MATH","creator_url":"https://huggingface.co/URSA-MATH","description":"\\n\\t\\n\\t\\t\\n\\t\\tMMathCoT-1M\\n\\t\\n\\nThis repository contains the data presented in URSA: Understanding and Verifying Chain-of-thought Reasoning in Multimodal Mathematics.\\nCode: https://github.com/URSA-MATH/URSA-MATH\\nImage data can be downloaded from the following address:\\n\\nMAVIS: https://github.com/ZrrSkywalker/MAVIS, https://drive.google.com/drive/folders/1LGd2JCVHi1Y6IQ7l-5erZ4QRGC4L7Nol.\\nMultimath: https://huggingface.co/datasets/pengshuai-rin/multimath-300k.\\nGeo170k:… See the full description on the dataset page: https://huggingface.co/datasets/URSA-MATH/MMathCoT-1M."},
	{"name":"ShrimpMoss_Chinese_Censorship_Abliteration","keyword":"chinese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Nafnlaus/ShrimpMoss_Chinese_Censorship_Abliteration","creator_name":"Karen Róbertsdóttir","creator_url":"https://huggingface.co/Nafnlaus","description":"\\nShrimpMoss (虾苔) is a dataset designed for the abliteration (https://github.com/FailSpy/abliterator) of Chinese government-imposed censorship and/or propaganda from large language models developed in the PRC. It consists of a series of files of prompts (in .txt, .json, and .parquet format) in two groupings:\\n\\nchina_bad_*: Contains a series of prompts likely to trigger censorship or propaganda actions in the model.\\nchina_good_*: Contains a series of prompts in the same general category of topics… See the full description on the dataset page: https://huggingface.co/datasets/Nafnlaus/ShrimpMoss_Chinese_Censorship_Abliteration."},
	{"name":"reasoning-multilingual-R1-Llama-70B-train","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/lightblue/reasoning-multilingual-R1-Llama-70B-train","creator_name":"Lightblue KK.","creator_url":"https://huggingface.co/lightblue","description":"\\n\\t\\n\\t\\t\\n\\t\\tlightblue/reasoning-multilingual-R1-Llama-70B-train\\n\\t\\n\\nThis is a multilingual reasoning dataset covering more than 30 languages.\\nThis dataset was made by:\\n\\nSampling prompts from English datasets and translating them to various languages\\nGenerating responses to these prompts 8 times using deepseek-ai/DeepSeek-R1-Distill-Llama-70B\\nFiltering out <think> sections with incorrect language, non-fluent language, and incorrect answers\\n\\nThis dataset was then used to train a multilingual… See the full description on the dataset page: https://huggingface.co/datasets/lightblue/reasoning-multilingual-R1-Llama-70B-train."},
	{"name":"wmt24pp","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/google/wmt24pp","creator_name":"Google","creator_url":"https://huggingface.co/google","description":"\\n\\t\\n\\t\\t\\n\\t\\tWMT24++\\n\\t\\n\\nThis repository contains the human translation and post-edit data for the 55 en->xx language pairs released in\\nthe publication\\nWMT24++: Expanding the Language Coverage of WMT24 to 55 Languages & Dialects.\\nIf you are interested in the MT/LLM system outputs and automatic metric scores, please see MTME.\\nIf you are interested in the images of the source URLs for each document, please see here.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSchema\\n\\t\\n\\nEach language pair is stored in its own jsonl file.\\nEach row is… See the full description on the dataset page: https://huggingface.co/datasets/google/wmt24pp."},
	{"name":"dark_thoughts_casestudies_en_cn","keyword":"chinese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/DataTonic/dark_thoughts_casestudies_en_cn","creator_name":"Data Tonic (Alignment Lab)","creator_url":"https://huggingface.co/DataTonic","description":"\\n\\t\\n\\t\\t\\n\\t\\tDark Thoughts Case Studies Dataset (English-Chinese)\\n\\t\\n\\nThis dataset contains a bilingual collection of case studies with detailed stakeholder analyses in English and Chinese. Each case study includes structured information about stakeholders and their motivations, along with comprehensive case analysis and solutions.\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tOverview\\n\\t\\n\\nThe dataset consists of 344,580 paired case studies in English and Chinese, with detailed stakeholder analyses and… See the full description on the dataset page: https://huggingface.co/datasets/DataTonic/dark_thoughts_casestudies_en_cn."},
	{"name":"EgoLife","keyword":"chinese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/lmms-lab/EgoLife","creator_name":"LMMs-Lab","creator_url":"https://huggingface.co/lmms-lab","description":"Data cleaning, stay tuned! Please refer to https://egolife-ai.github.io/ first for general info.\\nCheckout the paper EgoLife (https://arxiv.org/abs/2503.03803) for more information.\\nCode: https://github.com/egolife-ai/EgoLife\\n"},
	{"name":"thinking-multilingual-30-23-small-690","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Pinkstack/thinking-multilingual-30-23-small-690","creator_name":"Pinkstack","creator_url":"https://huggingface.co/Pinkstack","description":"\\nBased on OPENO1 math, this is a translated dataset of 30 high quality questions & answers in 23 languages. \\nOr use the \\\"big\\\" version: big 10k rows version\\n"},
	{"name":"ComMT","keyword":"chinese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/NiuTrans/ComMT","creator_name":"NiuTrans","creator_url":"https://huggingface.co/NiuTrans","description":"\\n\\t\\n\\t\\t\\n\\t\\tComMT\\n\\t\\n\\n\\nGithub: https://github.com/NiuTrans/LaMaTE/\\nPaper: https://arxiv.org/abs/2503.06594\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\nComMT is a comprehensive dataset suite designed to support the development and evaluation of universal translation models. \\nIt includes diverse translation-related tasks, providing a well-curated data resource for training and testing LLM-based machine translation systems.\\nThe dataset is meticulously curated from over 60+ publicly available data sources. \\nThe… See the full description on the dataset page: https://huggingface.co/datasets/NiuTrans/ComMT."},
	{"name":"Ling-Coder-SFT","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/inclusionAI/Ling-Coder-SFT","creator_name":"inclusionAI","creator_url":"https://huggingface.co/inclusionAI","description":"\\n    \\n\\n\\n\\n          🤗 Hugging Face\\n          🤖 ModelScope\\n          🖥️ GitHub\\n\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tLing-Coder Dataset\\n\\t\\n\\nThe Ling-Coder Dataset comprises the following components:\\n\\nLing-Coder-SFT: A subset of SFT data used for training Ling-Coder Lite, containing more than 5 million samples.\\nLing-Coder-DPO: A subset of DPO data used for training Ling-Coder Lite, containing 250k samples.\\nLing-Coder-SyntheticQA: A subset of synthetic data used for annealing training of Ling-Coder Lite, containing more… See the full description on the dataset page: https://huggingface.co/datasets/inclusionAI/Ling-Coder-SFT."},
	{"name":"Ling-Coder-SyntheticQA","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/inclusionAI/Ling-Coder-SyntheticQA","creator_name":"inclusionAI","creator_url":"https://huggingface.co/inclusionAI","description":"\\n    \\n\\n\\n\\n\\n          🤗 Hugging Face\\n          🤖 ModelScope\\n          🖥️ GitHub\\n\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tLing-Coder Dataset\\n\\t\\n\\nThe Ling-Coder Dataset comprises the following components:\\n\\nLing-Coder-SFT: A subset of SFT data used for training Ling-Coder Lite, containing more than 5 million samples.\\nLing-Coder-DPO: A subset of DPO data used for training Ling-Coder Lite, containing 250k samples.\\nLing-Coder-SyntheticQA: A subset of synthetic data used for annealing training of Ling-Coder Lite, containing more… See the full description on the dataset page: https://huggingface.co/datasets/inclusionAI/Ling-Coder-SyntheticQA."},
	{"name":"cmrc2018","keyword":"chinese","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/hfl/cmrc2018","creator_name":"Joint Laboratory of HIT and iFLYTEK Research (HFL)","creator_url":"https://huggingface.co/hfl","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for \\\"cmrc2018\\\"\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nA Span-Extraction dataset for Chinese machine reading comprehension to add language\\ndiversities in this area. The dataset is composed by near 20,000 real questions annotated\\non Wikipedia paragraphs by human experts. We also annotated a challenge set which\\ncontains the questions that need comprehensive understanding and multi-sentence\\ninference throughout the context.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSupported Tasks and Leaderboards\\n\\t\\n\\nMore… See the full description on the dataset page: https://huggingface.co/datasets/hfl/cmrc2018."},
	{"name":"conceptnet5","keyword":"chinese","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/conceptnet5/conceptnet5","creator_name":"conceptnet5","creator_url":"https://huggingface.co/conceptnet5","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Conceptnet5\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nConceptNet is a multilingual knowledge base, representing words and\\nphrases that people use and the common-sense relationships between\\nthem. The knowledge in ConceptNet is collected from a variety of\\nresources, including crowd-sourced resources (such as Wiktionary and\\nOpen Mind Common Sense), games with a purpose (such as Verbosity and\\nnadya.jp), and expert-created resources (such as WordNet and JMDict).\\nYou can browse… See the full description on the dataset page: https://huggingface.co/datasets/conceptnet5/conceptnet5."},
	{"name":"xquad","keyword":"chinese","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/google/xquad","creator_name":"Google","creator_url":"https://huggingface.co/google","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for \\\"xquad\\\"\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nXQuAD (Cross-lingual Question Answering Dataset) is a benchmark dataset for evaluating cross-lingual question answering\\nperformance. The dataset consists of a subset of 240 paragraphs and 1190 question-answer pairs from the development set\\nof SQuAD v1.1 (Rajpurkar et al., 2016) together with their professional translations into ten languages: Spanish, German,\\nGreek, Russian, Turkish, Arabic, Vietnamese, Thai, Chinese, and… See the full description on the dataset page: https://huggingface.co/datasets/google/xquad."},
	{"name":"xtreme","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/google/xtreme","creator_name":"Google","creator_url":"https://huggingface.co/google","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for \\\"xtreme\\\"\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThe Cross-lingual Natural Language Inference (XNLI) corpus is a crowd-sourced collection of 5,000 test and\\n2,500 dev pairs for the MultiNLI corpus. The pairs are annotated with textual entailment and translated into\\n14 languages: French, Spanish, German, Greek, Bulgarian, Russian, Turkish, Arabic, Vietnamese, Thai, Chinese,\\nHindi, Swahili and Urdu. This results in 112.5k annotated pairs. Each premise can be associated with… See the full description on the dataset page: https://huggingface.co/datasets/google/xtreme."},
	{"name":"ASCEND","keyword":"chinese","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/CAiRE/ASCEND","creator_name":"CAiRE HKUST","creator_url":"https://huggingface.co/CAiRE","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for ASCEND\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nASCEND (A Spontaneous Chinese-English Dataset) introduces a high-quality resource of spontaneous multi-turn conversational dialogue Chinese-English code-switching corpus collected in Hong Kong. ASCEND consists of 10.62 hours of spontaneous speech with a total of ~12.3K utterances. The corpus is split into 3 sets: training, validation, and test with a ratio of 8:1:1 while maintaining a balanced gender proportion on each set.… See the full description on the dataset page: https://huggingface.co/datasets/CAiRE/ASCEND."},
	{"name":"mqa","keyword":"chinese","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/clips/mqa","creator_name":"CLiPS","creator_url":"https://huggingface.co/clips","description":"MQA is a multilingual corpus of questions and answers parsed from the Common Crawl. Questions are divided between Frequently Asked Questions (FAQ) pages and Community Question Answering (CQA) pages."},
	{"name":"nli_zh","keyword":"chinese","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/shibing624/nli_zh","creator_name":"Ming Xu (徐明)","creator_url":"https://huggingface.co/shibing624","description":"纯文本数据，格式：（sentence1， sentence2， label）。常见中文语义匹配数据集，包含ATEC、BQ、LCQMC、PAWSX、STS-B共5个任务。"},
	{"name":"nlpcc-stance","keyword":"chinese","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/strombergnlp/nlpcc-stance","creator_name":"Strømberg NLP","creator_url":"https://huggingface.co/strombergnlp","description":"This is a stance prediction dataset in Chinese.\\nThe data is that from a shared task, stance detection in Chinese microblogs, in NLPCC-ICCPOL 2016. It covers Task A, a mandatory supervised task which detects stance towards five targets of interest with given labeled data."},
	{"name":"xwinograd","keyword":"chinese","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Muennighoff/xwinograd","creator_name":"Niklas Muennighoff","creator_url":"https://huggingface.co/Muennighoff","description":"A multilingual collection of Winograd Schemas in six languages that can be used for evaluation of cross-lingual commonsense reasoning capabilities."},
	{"name":"multilingual-sentiments","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/tyqiangz/multilingual-sentiments","creator_name":"Tay Yong Qiang","creator_url":"https://huggingface.co/tyqiangz","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tMultilingual Sentiments Dataset\\n\\t\\n\\nA collection of multilingual sentiments datasets grouped into 3 classes -- positive, neutral, negative.\\nMost multilingual sentiment datasets are either 2-class positive or negative, 5-class ratings of products reviews (e.g. Amazon multilingual dataset) or multiple classes of emotions. However, to an average person, sometimes positive, negative and neutral classes suffice and are more straightforward to perceive and annotate. Also, a… See the full description on the dataset page: https://huggingface.co/datasets/tyqiangz/multilingual-sentiments."},
	{"name":"laion2B-multi-chinese-subset","keyword":"chinese","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/IDEA-CCNL/laion2B-multi-chinese-subset","creator_name":"Fengshenbang-LM","creator_url":"https://huggingface.co/IDEA-CCNL","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tlaion2B-multi-chinese-subset\\n\\t\\n\\n\\nGithub: Fengshenbang-LM\\nDocs: Fengshenbang-Docs\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\t简介 Brief Introduction\\n\\t\\n\\n取自Laion2B多语言多模态数据集中的中文部分，一共143M个图文对。\\nA subset from Laion2B (a multimodal dataset), around 143M image-text pairs (only Chinese).\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\t数据集信息 Dataset Information\\n\\t\\n\\n大约一共143M个中文图文对。大约占用19GB空间（仅仅是url等文本信息，不包含图片）。\\n\\nHomepage: laion-5b\\nHuggingface: laion/laion2B-multi\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\t下载 Download\\n\\t\\n\\nmkdir laion2b_chinese_release && cd laion2b_chinese_release\\nfor i in… See the full description on the dataset page: https://huggingface.co/datasets/IDEA-CCNL/laion2B-multi-chinese-subset."},
	{"name":"paramed","keyword":"chinese","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/bigbio/paramed","creator_name":"BigScience Biomedical Datasets","creator_url":"https://huggingface.co/bigbio","description":"NEJM is a Chinese-English parallel corpus crawled from the New England Journal of Medicine website. \\nEnglish articles are distributed through https://www.nejm.org/ and Chinese articles are distributed through \\nhttp://nejmqianyan.cn/. The corpus contains all article pairs (around 2000 pairs) since 2011."},
	{"name":"laion-high-resolution-chinese","keyword":"chinese","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/wanng/laion-high-resolution-chinese","creator_name":"wangjunjie","creator_url":"https://huggingface.co/wanng","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tlaion-high-resolution-chinese\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\t简介 Brief Introduction\\n\\t\\n\\n取自Laion5B-high-resolution多语言多模态数据集中的中文部分，一共2.66M个图文对。\\nA subset from Laion5B-high-resolution (a multimodal dataset), around 2.66M image-text pairs (only Chinese).\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\t数据集信息 Dataset Information\\n\\t\\n\\n大约一共2.66M个中文图文对。大约占用381MB空间（仅仅是url等文本信息，不包含图片）。\\n\\nHomepage: laion-5b\\nHuggingface: laion/laion-high-resolution\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\t下载 Download\\n\\t\\n\\nmkdir release && cd release\\nfor i in {00000..00015}; do wget… See the full description on the dataset page: https://huggingface.co/datasets/wanng/laion-high-resolution-chinese."},
	{"name":"jd21","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/kuroneko5943/jd21","creator_name":"Wang Song","creator_url":"https://huggingface.co/kuroneko5943","description":"GLUE, the General Language Understanding Evaluation benchmark\\n(https://gluebenchmark.com/) is a collection of resources for training,\\nevaluating, and analyzing natural language understanding systems."},
	{"name":"weibo16","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/kuroneko5943/weibo16","creator_name":"Wang Song","creator_url":"https://huggingface.co/kuroneko5943","description":"GLUE, the General Language Understanding Evaluation benchmark\\n(https://gluebenchmark.com/) is a collection of resources for training,\\nevaluating, and analyzing natural language understanding systems."},
	{"name":"HC3","keyword":"chinese","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Hello-SimpleAI/HC3","creator_name":"Hello-SimpleAI","creator_url":"https://huggingface.co/Hello-SimpleAI","description":"Human ChatGPT Comparison Corpus (HC3)"},
	{"name":"HC3-Chinese","keyword":"chinese","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Hello-SimpleAI/HC3-Chinese","creator_name":"Hello-SimpleAI","creator_url":"https://huggingface.co/Hello-SimpleAI","description":"Human ChatGPT Comparison Corpus (HC3) Chinese Version"},
	{"name":"wmt-da-human-evaluation","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/RicardoRei/wmt-da-human-evaluation","creator_name":"Ricardo Costa Dias Rei","creator_url":"https://huggingface.co/RicardoRei","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThis dataset contains all DA human annotations from previous WMT News Translation shared tasks.\\nThe data is organised into 8 columns:\\n\\nlp: language pair\\nsrc: input text\\nmt: translation\\nref: reference translation\\nscore: z score\\nraw: direct assessment\\nannotators: number of annotators\\ndomain: domain of the input text (e.g. news)\\nyear: collection year\\n\\nYou can also find the original data for each year in the results section… See the full description on the dataset page: https://huggingface.co/datasets/RicardoRei/wmt-da-human-evaluation."},
	{"name":"pclue","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/wbbbbb/pclue","creator_name":"wb","creator_url":"https://huggingface.co/wbbbbb","description":"https://github.com/CLUEbenchmark/pCLUE"},
	{"name":"multiconer_v2","keyword":"chinese","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/MultiCoNER/multiconer_v2","creator_name":"MultiCoNER","creator_url":"https://huggingface.co/MultiCoNER","description":"Complex named entities (NE), like the titles of creative works, are not simple nouns and pose challenges for NER systems (Ashwini and Choi, 2014). They can take the form of any linguistic constituent, like an imperative clause (“Dial M for Murder”), and do not look like traditional NEs (Persons, Locations, etc.). This syntactic ambiguity makes it challenging to recognize them based on context. We organized the MultiCoNER task (Malmasi et al., 2022) at SemEval-2022 to address these challenges in 11 languages, receiving a very positive community response with 34 system papers. Results confirmed the challenges of processing complex and long-tail NEs: even the largest pre-trained Transformers did not achieve top performance without external knowledge. The top systems infused transformers with knowledge bases and gazetteers. However, such solutions are brittle against out of knowledge-base entities and noisy scenarios like the presence of spelling mistakes and typos. We propose MultiCoNER II which represents novel challenges through new tasks that emphasize the shortcomings of the current top models.\\n\\nMultiCoNER II features complex NER in these languages:\\n\\n1. English\\n2. Spanish\\n3. Hindi\\n4. Bangla\\n5. Chinese\\n6. Swedish\\n7. Farsi\\n8. French\\n9. Italian\\n10. Portugese\\n11. Ukranian\\n12. German\\n\\nFor more details see https://multiconer.github.io/\\n\\n## References\\n* Sandeep Ashwini and Jinho D. Choi. 2014. Targetable named entity recognition in social media. CoRR, abs/1408.0782.\\n* Shervin Malmasi, Anjie Fang, Besnik Fetahu, Sudipta Kar, Oleg Rokhlenko. 2022. SemEval-2022 Task 11: Multilingual Complex Named Entity Recognition (MultiCoNER)."},
	{"name":"csl","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/neuclir/csl","creator_name":"NeuCLIR TREC Track","creator_url":"https://huggingface.co/neuclir","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for CSL\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nCSL is the Chinese Scientific Literature Dataset.\\n\\nPaper: https://aclanthology.org/2022.coling-1.344\\nRepository: https://github.com/ydli-ai/CSL\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThe dataset contains titles, abstracts, keywords of papers written in Chinese from several academic fields.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages\\n\\t\\n\\n\\nChinese\\nEnglish (translation)\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Structure\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Instances\\n\\t\\n\\n\\n\\t\\n\\t\\t\\nSplit\\nDocuments… See the full description on the dataset page: https://huggingface.co/datasets/neuclir/csl."},
	{"name":"Alpaca-CoT","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/QingyiSi/Alpaca-CoT","creator_name":"Qingyi Si","creator_url":"https://huggingface.co/QingyiSi","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tInstruction-Finetuning Dataset Collection (Alpaca-CoT)\\n\\t\\n\\nThis repository will continuously collect various instruction tuning datasets. And we standardize different datasets into the same format, which can be directly loaded by the code of Alpaca model.\\nWe also have conducted empirical study on various instruction-tuning datasets based on the Alpaca model, as shown in https://github.com/PhoebusSi/alpaca-CoT.  \\nIf you think this dataset collection is helpful to you, please like… See the full description on the dataset page: https://huggingface.co/datasets/QingyiSi/Alpaca-CoT."},
	{"name":"AdvertiseGen","keyword":"chinese","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/shibing624/AdvertiseGen","creator_name":"Ming Xu (徐明)","creator_url":"https://huggingface.co/shibing624","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for AdvertiseGen\\n\\t\\n\\n\\nformal url: https://www.luge.ai/#/luge/dataDetail?id=9\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\n数据集介绍\\nAdvertiseGen是电商广告文案生成数据集。\\nAdvertiseGen以商品网页的标签与文案的信息对应关系为基础构造，是典型的开放式生成任务，在模型基于key-value输入生成开放式文案时，与输入信息的事实一致性需要得到重点关注。\\n\\n任务描述：给定商品信息的关键词和属性列表kv-list，生成适合该商品的广告文案adv；\\n数据规模：训练集114k，验证集1k，测试集3k；\\n数据来源：清华大学CoAI小组；\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSupported Tasks and Leaderboards\\n\\t\\n\\nThe dataset designed for generate e-commerce advertise.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages\\n\\t\\n\\nThe data in… See the full description on the dataset page: https://huggingface.co/datasets/shibing624/AdvertiseGen."},
	{"name":"CSC","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/shibing624/CSC","creator_name":"Ming Xu (徐明)","creator_url":"https://huggingface.co/shibing624","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for CSC\\n\\t\\n\\n中文拼写纠错数据集\\n\\nRepository: https://github.com/shibing624/pycorrector\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nChinese Spelling Correction (CSC) is a task to detect and correct misspelled characters in Chinese texts. \\nCSC is challenging since many Chinese characters are visually or phonologically similar but with quite different semantic meanings.\\n中文拼写纠错数据集，共27万条，是通过原始SIGHAN13、14、15年数据集和Wang271k数据集合并整理后得到，json格式，带错误字符位置信息。\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tOriginal Dataset Summary… See the full description on the dataset page: https://huggingface.co/datasets/shibing624/CSC."},
	{"name":"guanaco_belle_merge_v1.0","keyword":"chinese","license":"GNU General Public License v3.0","license_url":"https://choosealicense.com/licenses/gpl-3.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Chinese-Vicuna/guanaco_belle_merge_v1.0","creator_name":"Chinese-Vicuna","creator_url":"https://huggingface.co/Chinese-Vicuna","description":"Thanks for Guanaco Dataset and Belle Dataset\\nThis dataset was created by merging the above two datasets in a certain format so that they can be used for training our code Chinese-Vicuna\\n"},
	{"name":"train_1M_CN","keyword":"chinese","license":"GNU General Public License v3.0","license_url":"https://choosealicense.com/licenses/gpl-3.0/","language":"en","dataset_url":"https://huggingface.co/datasets/BelleGroup/train_1M_CN","creator_name":"BELLE Group // Be Everyone's Large Language model Engine","creator_url":"https://huggingface.co/BelleGroup","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\t内容\\n\\t\\n\\n包含约100万条由BELLE项目生成的中文指令数据。\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\t样例\\n\\t\\n\\n{\\n  \\\"instruction\\\": \\\"给定一个文字输入，将其中的所有数字加1。\\\\n“明天的会议在9点开始，记得准时到达。”\\\\n\\\",\\n  \\\"input\\\": \\\",\\n  \\\"output\\\": \\\"“明天的会议在10点开始，记得准时到达。”\\\"\\n}\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\t字段：\\n\\t\\n\\ninstruction: 指令\\ninput: 输入（本数据集均为空）\\noutput: 输出\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\t使用限制\\n\\t\\n\\n仅允许将此数据集及使用此数据集生成的衍生物用于研究目的，不得用于商业，以及其他会对社会带来危害的用途。\\n本数据集不代表任何一方的立场、利益或想法，无关任何团体的任何类型的主张。因使用本数据集带来的任何损害、纠纷，本项目不承担任何责任。\\n"},
	{"name":"train_0.5M_CN","keyword":"chinese","license":"GNU General Public License v3.0","license_url":"https://choosealicense.com/licenses/gpl-3.0/","language":"en","dataset_url":"https://huggingface.co/datasets/BelleGroup/train_0.5M_CN","creator_name":"BELLE Group // Be Everyone's Large Language model Engine","creator_url":"https://huggingface.co/BelleGroup","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\t内容\\n\\t\\n\\n包含约50万条由BELLE项目生成的中文指令数据。\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\t样例\\n\\t\\n\\n{\\n  \\\"instruction\\\": \\\"给定一个文字输入，将其中的所有数字加1。\\\\n“明天的会议在9点开始，记得准时到达。”\\\\n\\\",\\n  \\\"input\\\": \\\",\\n  \\\"output\\\": \\\"“明天的会议在10点开始，记得准时到达。”\\\"\\n}\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\t字段：\\n\\t\\n\\ninstruction: 指令\\ninput: 输入（本数据集均为空）\\noutput: 输出\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\t使用限制\\n\\t\\n\\n仅允许将此数据集及使用此数据集生成的衍生物用于研究目的，不得用于商业，以及其他会对社会带来危害的用途。\\n本数据集不代表任何一方的立场、利益或想法，无关任何团体的任何类型的主张。因使用本数据集带来的任何损害、纠纷，本项目不承担任何责任。\\n"},
	{"name":"couplet","keyword":"chinese","license":"GNU Affero General Public License v3.0","license_url":"https://choosealicense.com/licenses/agpl-3.0/","language":"en","dataset_url":"https://huggingface.co/datasets/wb14123/couplet","creator_name":"bw","creator_url":"https://huggingface.co/wb14123","description":"对联数据集。数据来源： 冯重朴_梨味斋散叶_的博客。\\n爬虫代码在 Github。\\n"},
	{"name":"school_math_0.25M","keyword":"chinese","license":"GNU General Public License v3.0","license_url":"https://choosealicense.com/licenses/gpl-3.0/","language":"en","dataset_url":"https://huggingface.co/datasets/BelleGroup/school_math_0.25M","creator_name":"BELLE Group // Be Everyone's Large Language model Engine","creator_url":"https://huggingface.co/BelleGroup","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSchool Math 0.25M\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\t内容\\n\\t\\n\\n包含约25万条由BELLE项目生成的中文数学题数据，包含解题过程。\\n注意：此数据集是由ChatGPT产生的，未经过严格校验，题目或解题过程可能包含错误。使用过程中请注意这一点。\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\t样例\\n\\t\\n\\n{\\n  \\\"instruction\\\": \\\"题目：小华手里有一个装满糖果的袋子，共有12个，小明想知道里面有多少颗糖果，于是他问小华：“你手里的糖果袋子里有偶数个糖果吗？”小华回答：“有，而且多于10颗。”请问小华手里的糖果袋子里最少有几颗糖果？\\\",\\n  \\\"input\\\": \\\",\\n  \\\"output\\\": \\\"\\\\n由题目可知：小华手里的糖果袋子里有偶数个糖果；\\\\n又知道小华手里的糖果袋子里有多于10颗糖果。\\\\n因为糖果数为偶数，多于10颗，所以糖果数最小必须是12。\\\\n所以小华手里的糖果袋子里最少有12颗糖果。\\\"\\n}\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\t字段\\n\\t\\n\\ninstruction: 指令\\ninput: 输入（本数据集均为空）\\noutput: 输出… See the full description on the dataset page: https://huggingface.co/datasets/BelleGroup/school_math_0.25M."},
	{"name":"alpaca-gpt4-data-zh","keyword":"chinese","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/llm-wizard/alpaca-gpt4-data-zh","creator_name":"Chris Alexiuk","creator_url":"https://huggingface.co/llm-wizard","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for \\\"alpaca-gpt4-data-zh\\\"\\n\\t\\n\\nAll of the work is done by this team. \\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tUsage and License Notices\\n\\t\\n\\nThe data is intended and licensed for research use only. The dataset is CC BY NC 4.0 (allowing only non-commercial use) and models trained using the dataset should not be used outside of research purposes.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tEnglish Dataset\\n\\t\\n\\nFound here\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tCitation\\n\\t\\n\\n@article{peng2023gpt4llm,\\n    title={Instruction Tuning with GPT-4},\\n    author={Baolin Peng… See the full description on the dataset page: https://huggingface.co/datasets/llm-wizard/alpaca-gpt4-data-zh."},
	{"name":"train_2M_CN","keyword":"chinese","license":"GNU General Public License v3.0","license_url":"https://choosealicense.com/licenses/gpl-3.0/","language":"en","dataset_url":"https://huggingface.co/datasets/BelleGroup/train_2M_CN","creator_name":"BELLE Group // Be Everyone's Large Language model Engine","creator_url":"https://huggingface.co/BelleGroup","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\t内容\\n\\t\\n\\n包含约200万条由BELLE项目生成的中文指令数据。\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\t样例\\n\\t\\n\\n{\\n  \\\"instruction\\\": \\\"将以下三个句子组合成一个有意义的段落。\\\\n狗是人类最好的朋友。它们非常聪明，可以进行各种活动。如果你喜欢散步，狗可以成为你一起散步的伙伴。\\\",\\n  \\\"input\\\": \\\",\\n  \\\"output\\\": \\\"狗是人类最好的朋友，它们非常聪明，可以进行各种活动。如果你喜欢散步，狗可以成为你一起散步的伙伴。出门散步是一种良好的锻炼方式，而有狗的陪伴会让散步变得更有趣，并且有狗在身边也能给你带来安全感。所以，拥有一只狗作为你的伙伴，可以帮助你变得更加积极主动和健康。\\\"\\n}\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\t字段：\\n\\t\\n\\ninstruction: 指令\\ninput: 输入（本数据集均为空）\\noutput: 输出\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\t使用限制\\n\\t\\n\\n仅允许将此数据集及使用此数据集生成的衍生物用于研究目的，不得用于商业，以及其他会对社会带来危害的用途。… See the full description on the dataset page: https://huggingface.co/datasets/BelleGroup/train_2M_CN."},
	{"name":"ShareGPT-Chinese-English-90k","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/shareAI/ShareGPT-Chinese-English-90k","creator_name":"shareAI","creator_url":"https://huggingface.co/shareAI","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tShareGPT-Chinese-English-90k Bilingual Human-Machine QA Dataset\\n\\t\\n\\nA high-quality Chinese-English parallel bilingual human-machine QA dataset, covering user questions in real and complex scenarios. It is used for training high-quality dialogue models (more robust in instruction distribution than those datasets generated by repeatedly calling API interfaces to simulate machine-generated Q&A, like Moss)\\nFeatures:\\n\\n\\nProvides fully semantically equivalent Chinese-English parallel… See the full description on the dataset page: https://huggingface.co/datasets/shareAI/ShareGPT-Chinese-English-90k."},
	{"name":"COIG","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/BAAI/COIG","creator_name":"Beijing Academy of Artificial Intelligence","creator_url":"https://huggingface.co/BAAI","description":"We propose the Chinese Open Instruction Generalist (COIG) project to maintain a harmless, helpful, and diverse set of Chinese instruction corpora. We welcome all researchers in the community to contribute to the corpus set and collaborate with us. We only release the first chip of COIG to help the Chinese LLMs' development in the exploration stage and appeal to more researchers joining us in building COIG. We introduce a manually verified translated general instruction corpus, a manually annotated exam instruction corpus, a human value alignment instruction corpus, a multi-round counterfactual correction chat corpus, and a leetcode instruction corpus. We provide these new instruction corpora to assist the community with instruction tuning on Chinese LLMs. These instruction corpora are also template workflows for how new Chinese instruction corpora can be built and expanded effectively."},
	{"name":"ChatMed_Consult_Dataset","keyword":"chinese","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/michaelwzhu/ChatMed_Consult_Dataset","creator_name":"Wei Zhu","creator_url":"https://huggingface.co/michaelwzhu","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for ChatMed\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nChatMed-Dataset is a dataset of 110,113 medical query-response pairs (in Chinese) generated by OpenAI's GPT-3.5 engine. The queries are crawled from several online medical consultation sites, reflecting the medical needs in the real world. The responses are generated by the OpenAI engine. This dataset is designated to to inject medical knowledge into Chinese large language models. \\nThe dataset size growing rapidly. Stay… See the full description on the dataset page: https://huggingface.co/datasets/michaelwzhu/ChatMed_Consult_Dataset."},
	{"name":"moss-002-sft-data","keyword":"chinese","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/fnlp/moss-002-sft-data","creator_name":"OpenMOSS, Fudan NLP, SII","creator_url":"https://huggingface.co/fnlp","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for \\\"moss-002-sft-data\\\"\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nAn open-source conversational dataset that was used to train MOSS-002. The user prompts are extended based on a small set of human-written seed prompts in a way similar to Self-Instruct. The AI responses are generated using text-davinci-003. The user prompts of en_harmlessness are from Anthropic red teaming data.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Splits\\n\\t\\n\\n\\n\\t\\n\\t\\t\\nname\\n# samples\\n\\n\\n\\t\\t\\nen_helpfulness.json\\n419049\\n\\n\\nen_honesty.json… See the full description on the dataset page: https://huggingface.co/datasets/fnlp/moss-002-sft-data."},
	{"name":"FinCUGE-Instruction","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Maciel/FinCUGE-Instruction","creator_name":"Maciel Young","creator_url":"https://huggingface.co/Maciel","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Dataset Name\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\n本数据集包含八项中文金融自然语言处理基准任务，分别为金融新闻摘要(FinNA)、金融新闻公告事件问答(FinQA)、金融新闻分类(FinNL)、金融新闻关系抽取(FinRE)、金融社交媒体文本情绪分类(FinNE)、金融负面消息及其主体判定(FinNSP)、金融因果事件抽取(FinCQA)、金融事件主体抽取(FinESE)。\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Structure\\n\\t\\n\\n（1）FinNA\\n金融新闻摘要数据集。输入一段金融新闻，需要模型生成一句话摘要。其中训练集包含24000条数据，验证集包含3000条数据。\\n{\\n  \\\"instruction\\\": \\\"根据以下新闻生成摘要。\\\",\\n  \\\"input\\\":… See the full description on the dataset page: https://huggingface.co/datasets/Maciel/FinCUGE-Instruction."},
	{"name":"WikiHowQA-mnbvc","keyword":"chinese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/wanicca/WikiHowQA-mnbvc","creator_name":"wanicca","creator_url":"https://huggingface.co/wanicca","description":"从WikiHow页面抽取的中文/英文问答数据\\n相关项目: MNBVC\\n抽取工具代码：WikiHowQAExtractor\\n"},
	{"name":"huatuo_knowledge_graph_qa","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/FreedomIntelligence/huatuo_knowledge_graph_qa","creator_name":"FreedomAI","creator_url":"https://huggingface.co/FreedomIntelligence","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Huatuo_knowledge_graph_qa\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nWe built this QA dataset based on the medical knowledge map, with a total of 798,444 pieces of data, in which the questions are constructed by means of templates, and the answers are the contents of the entries in the knowledge map.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Creation\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSource Data… See the full description on the dataset page: https://huggingface.co/datasets/FreedomIntelligence/huatuo_knowledge_graph_qa."},
	{"name":"chid","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/thu-coai/chid","creator_name":"Conversational AI (CoAI) group from Tsinghua University","creator_url":"https://huggingface.co/thu-coai","description":"The ChID dataset. GitHub repo. Original paper.\\n@inproceedings{zheng-etal-2019-chid,\\n    title = \\\"{C}h{ID}: A Large-scale {C}hinese {ID}iom Dataset for Cloze Test\\\",\\n    author = \\\"Zheng, Chujie  and\\n      Huang, Minlie  and\\n      Sun, Aixin\\\",\\n    booktitle = \\\"ACL\\\",\\n    year = \\\"2019\\\"\\n}\\n\\n"},
	{"name":"mgsm","keyword":"chinese","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/juletxara/mgsm","creator_name":"Julen Etxaniz","creator_url":"https://huggingface.co/juletxara","description":"Multilingual Grade School Math Benchmark (MGSM) is a benchmark of grade-school math problems, proposed in the paper [Language models are multilingual chain-of-thought reasoners](http://arxiv.org/abs/2210.03057).\\n\\nThe same 250 problems from [GSM8K](https://arxiv.org/abs/2110.14168) are each translated via human annotators in 10 languages. The 10 languages are:\\n- Spanish\\n- French\\n- German\\n- Russian\\n- Chinese\\n- Japanese\\n- Thai\\n- Swahili\\n- Bengali\\n- Telugu\\n\\nYou can find the input and targets for each of the ten languages (and English) as `.tsv` files.\\nWe also include few-shot exemplars that are also manually translated from each language in `exemplars.py`."},
	{"name":"train_3.5M_CN","keyword":"chinese","license":"GNU General Public License v3.0","license_url":"https://choosealicense.com/licenses/gpl-3.0/","language":"en","dataset_url":"https://huggingface.co/datasets/BelleGroup/train_3.5M_CN","creator_name":"BELLE Group // Be Everyone's Large Language model Engine","creator_url":"https://huggingface.co/BelleGroup","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\t内容\\n\\t\\n\\n包含约350万条由BELLE项目生成的中文指令数据。\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\t样例\\n\\t\\n\\n{\\n    \\\"id\\\":\\\"66623028\\\",\\n    \\\"conversations\\\":[\\n        {\\n            \\\"from\\\":\\\"human\\\",\\n            \\\"value\\\":\\\"归纳介绍三种不同类型的电影题材\\\"\\n        },\\n        {\\n            \\\"from\\\":\\\"assistant\\\",\\n            \\\"value\\\":\\\"1. 动作片：动作片通常强调动作和战斗场面，故事情节紧凑，充满了紧张和兴奋的氛围。主角一般是具有超凡实力或特殊技能的英雄人物，往往会与反派角色进行一系列激烈的格斗，追逐和爆破等酷炫场面。例如《速度与激情》和《复仇者联盟》等。\\\\n2. 爱情片：爱情片是以爱情为主题的电影，着重呈现角色之间的感情纠葛，展现了爱情的美好和悲壮。情节与角色之间的发展令人深思，增加了观众的感性体验。这种电影的故事情节主要以人类与人类之间的情感变化为主题。例如《泰坦尼克号》和《让子弹飞》等。\\\\n3.… See the full description on the dataset page: https://huggingface.co/datasets/BelleGroup/train_3.5M_CN."},
	{"name":"huatuo_encyclopedia_qa","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/FreedomIntelligence/huatuo_encyclopedia_qa","creator_name":"FreedomAI","creator_url":"https://huggingface.co/FreedomIntelligence","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Huatuo_encyclopedia_qa\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThis dataset has a total of 364,420 pieces of medical QA data, some of which have multiple questions in different ways. We extract medical QA pairs from plain texts (e.g., medical encyclopedias and medical articles). We collected 8,699 encyclopedia entries for diseases and 2,736 encyclopedia entries for medicines on Chinese Wikipedia. Moreover, we crawled 226,432 high-quality medical articles from the Qianwen… See the full description on the dataset page: https://huggingface.co/datasets/FreedomIntelligence/huatuo_encyclopedia_qa."},
	{"name":"instruct_chat_50k.jsonl","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Chinese-Vicuna/instruct_chat_50k.jsonl","creator_name":"Chinese-Vicuna","creator_url":"https://huggingface.co/Chinese-Vicuna","description":"instruct_chat_50k.jsonl which is composed of 30k Chinese sharegpt dataset and 20k alpaca-instruction-Chinese-dataset\\n"},
	{"name":"Wizard-LM-Chinese-instruct-evol","keyword":"chinese","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/silk-road/Wizard-LM-Chinese-instruct-evol","creator_name":"SilkRoad","creator_url":"https://huggingface.co/silk-road","description":"Wizard-LM-Chinese是在MSRA的Wizard-LM数据集上，对指令进行翻译，然后再调用GPT获得答案的数据集\\nWizard-LM包含了很多难度超过Alpaca的指令。\\n中文的问题翻译会有少量指令注入导致翻译失败的情况\\n中文回答是根据中文问题再进行问询得到的。\\n我们会陆续将更多数据集发布到hf，包括\\n\\n Coco Caption的中文翻译\\n CoQA的中文翻译\\n CNewSum的Embedding数据\\n 增广的开放QA数据\\n WizardLM的中文翻译\\n\\n如果你也在做这些数据集的筹备，欢迎来联系我们，避免重复花钱。\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\t骆驼(Luotuo): 开源中文大语言模型\\n\\t\\n\\nhttps://github.com/LC1332/Luotuo-Chinese-LLM\\n骆驼(Luotuo)项目是由冷子昂 @ 商汤科技, 陈启源 @ 华中师范大学 以及 李鲁鲁 @ 商汤科技 发起的中文大语言模型开源项目，包含了一系列语言模型。\\n( 注意: 陈启源 正在寻找2024推免导师，欢迎联系 )\\n骆驼项目不是商汤科技的官方产品。\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tCitation… See the full description on the dataset page: https://huggingface.co/datasets/silk-road/Wizard-LM-Chinese-instruct-evol."},
	{"name":"MMC4-130k-chinese-image","keyword":"chinese","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/silk-road/MMC4-130k-chinese-image","creator_name":"SilkRoad","creator_url":"https://huggingface.co/silk-road","description":"MMC4-130k-chinese是对MMC4中，抽样了130k左右 simliarty较高的图文pair得到的数据集\\nChinese版本是对这里所有的caption进行了翻译。\\n我们会陆续将更多数据集发布到hf，包括\\n\\n Coco Caption的中文翻译\\n CoQA的中文翻译\\n CNewSum的Embedding数据\\n 增广的开放QA数据\\n WizardLM的中文翻译\\n\\n如果你也在做这些数据集的筹备，欢迎来联系我们，避免重复花钱。\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\t骆驼(Luotuo): 开源中文大语言模型\\n\\t\\n\\nhttps://github.com/LC1332/Luotuo-Chinese-LLM\\n骆驼(Luotuo)项目是由冷子昂 @ 商汤科技, 陈启源 @ 华中师范大学 以及 李鲁鲁 @ 商汤科技 发起的中文大语言模型开源项目，包含了一系列语言模型。\\n( 注意: 陈启源 正在寻找2024推免导师，欢迎联系 )\\n骆驼项目不是商汤科技的官方产品。\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tCitation\\n\\t\\n\\nPlease cite the repo if you use the data or… See the full description on the dataset page: https://huggingface.co/datasets/silk-road/MMC4-130k-chinese-image."},
	{"name":"huatuo26M-testdatasets","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/FreedomIntelligence/huatuo26M-testdatasets","creator_name":"FreedomAI","creator_url":"https://huggingface.co/FreedomIntelligence","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for huatuo26M-testdatasets\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nWe are pleased to announce the release of our evaluation dataset, a subset of the Huatuo-26M. This dataset contains 6,000 entries that we used for Natural Language Generation (NLG) experimentation in our associated research paper.\\nWe encourage researchers and developers to use this evaluation dataset to gauge the performance of their own models. This is not only a chance to assess the accuracy and relevancy… See the full description on the dataset page: https://huggingface.co/datasets/FreedomIntelligence/huatuo26M-testdatasets."},
	{"name":"genshin_ch_10npc","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/xmj2002/genshin_ch_10npc","creator_name":"xmj","creator_url":"https://huggingface.co/xmj2002","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for \\\"genshin_ch_10npc\\\"\\n\\t\\n\\nMore Information needed\\n"},
	{"name":"alpaca-data-gpt4-chinese","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/silk-road/alpaca-data-gpt4-chinese","creator_name":"SilkRoad","creator_url":"https://huggingface.co/silk-road","description":"silk-road/alpaca-data-gpt4-chinese dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"Chinese_modern_classical","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/xmj2002/Chinese_modern_classical","creator_name":"xmj","creator_url":"https://huggingface.co/xmj2002","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for \\\"Chinese_modern_classical\\\"\\n\\t\\n\\n数据来自于NiuTrans/Classical-Modern: 非常全的文言文（古文）-现代文平行语料 (github.com)。\\n由于原始数据中部分古文没有译文，所以本数据集的数据仅包括了双语数据 。\\n"},
	{"name":"tigerbot-riddle-qa-1k","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/TigerResearch/tigerbot-riddle-qa-1k","creator_name":"Tiger Research","creator_url":"https://huggingface.co/TigerResearch","description":"Tigerbot 搜集整理加工的中文-猜谜语sft数据集\\n\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tUsage\\n\\t\\n\\nimport datasets\\nds_sft = datasets.load_dataset('TigerResearch/tigerbot-riddle-qa-1k')\\n\\n"},
	{"name":"tigerbot-law-plugin","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/TigerResearch/tigerbot-law-plugin","creator_name":"Tiger Research","creator_url":"https://huggingface.co/TigerResearch","description":"Tigerbot 模型rethink时使用的外脑原始数据，法律11大类，共5.5W+条款\\n\\n宪法\\n刑法\\n行政法\\n司法解释\\n民法商法\\n民法典\\n行政法规\\n社会法\\n部门规章\\n经济法\\n诉讼与非诉讼程序法\\n\\n\\n\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tUsage\\n\\t\\n\\nimport datasets\\nds_sft = datasets.load_dataset('TigerResearch/tigerbot-law-plugin')\\n\\n"},
	{"name":"nli-zh-all","keyword":"chinese","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/shibing624/nli-zh-all","creator_name":"Ming Xu (徐明)","creator_url":"https://huggingface.co/shibing624","description":"The SNLI corpus (version 1.0) is a merged chinese sentence similarity dataset, supporting the task of natural language\\ninference (NLI), also known as recognizing textual entailment (RTE)."},
	{"name":"chinese_modern_poetry","keyword":"chinese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Iess/chinese_modern_poetry","creator_name":"丁煌浩","creator_url":"https://huggingface.co/Iess","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\t简介\\n\\t\\n\\n\\n数据集包括了近现代的中国诗人及外国诗人（中译版）作品，所有作品著作权归原作者所有，侵删请联系aa531811820@gmail.com\\nchinese_poems.jsonl为原数据，training_imagery2-5_maxlen256.json 分别是根据2-5个关键意象生成诗歌的相关数据集\\n数据来源于网络，包括但不限于\\n\\n\\nhttps://github.com/sheepzh/poetry\\nhttps://bedtimepoem.com/\\nhttps://poemwiki.org/\\nbaidu、google、zhihu等\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\t一些作品\\n\\t\\n\\n使用此数据集训练ChatGLM、LLaMA7b模型生成的诗歌，更多诗歌查看poems目录\\n\\n\\n\\n"},
	{"name":"toxi-text-3M","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/FredZhang7/toxi-text-3M","creator_name":"Fred Zhang","creator_url":"https://huggingface.co/FredZhang7","description":"This is a large multilingual toxicity dataset with 3M rows of text data from 55 natural languages, all of which are written/sent by humans, not machine translation models.\\nThe preprocessed training data alone consists of 2,880,667 rows of comments, tweets, and messages. Among these rows, 416,529 are classified as toxic, while the remaining 2,463,773 are considered neutral. Below is a table to illustrate the data composition:\\n\\n\\t\\n\\t\\t\\n\\nToxic\\nNeutral\\nTotal\\n\\n\\n\\t\\t\\nmultilingual-train-deduplicated.csv… See the full description on the dataset page: https://huggingface.co/datasets/FredZhang7/toxi-text-3M."},
	{"name":"webnovel_cn","keyword":"chinese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/zxbsmk/webnovel_cn","creator_name":"Jun","creator_url":"https://huggingface.co/zxbsmk","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\t内容\\n\\t\\n\\n包含从12560本网文提取的约21.7M条可用于训练小说生成的中文指令数据(novel_json_tokens512.zip)。下载链接：https://pan.baidu.com/s/1TorBMbrqxrn6odRF0PJBVw \\n提取码：jlh3\\n以及从中提取出的包含50k条数据的子集(novel_cn_token512_50k.json)。其中输入和输出都不多于 512 tokens。\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\t样例\\n\\t\\n\\n在原有小说文本基础上，依据下列五种指令生成数据。\\n其中，文本由小说中随机抽取的连续句子组成。\\n\\n给定标题，直接生成简介。\\n给定标题和简介，生成开头。\\n给定简介和一段文本，生成后续文本。\\n给定标题和一段文本，生成后续文本。\\n给定一段文本，生成后续文本。\\n\\n{\\n    \\\"instruction\\\":… See the full description on the dataset page: https://huggingface.co/datasets/zxbsmk/webnovel_cn."},
	{"name":"ChineseWebNovel","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Delius/ChineseWebNovel","creator_name":"Albert Delius","creator_url":"https://huggingface.co/Delius","description":"Chinese Web Novel Dataset\\nSummarized by claude but converted the order for novel text extension task.\\nWARNING!! Please be aware of the context length!!!\\n"},
	{"name":"cantonese-traditional-chinese-parallel-corpus","keyword":"chinese","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/raptorkwok/cantonese-traditional-chinese-parallel-corpus","creator_name":"Raptor K","creator_url":"https://huggingface.co/raptorkwok","description":"This is a dataset of Cantonese-Written Chinese Parallel Corpus, containing 130k+ pairs of Cantonese and Traditional Chinese parallel sentences.\\n"},
	{"name":"sharegpt_gpt4","keyword":"chinese","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/shibing624/sharegpt_gpt4","creator_name":"Ming Xu (徐明)","creator_url":"https://huggingface.co/shibing624","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nShareGPT中挑选出的GPT4多轮问答数据，多语言问答。\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages\\n\\t\\n\\n数据集是多语言，包括中文、英文、日文等常用语言。\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Structure\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Fields\\n\\t\\n\\nThe data fields are the same among all splits.\\n\\nconversations: a List of string .\\n\\nhead -n 1 sharegpt_gpt4.jsonl\\n\\n{\\\"conversations\\\":[\\n  {'from': 'human',\\n   'value': '採用優雅現代中文，用中文繁體字型，回答以下問題。為所有標題或專用字詞提供對應的英語翻譯：Using scholarly style, summarize in detail James Barr\\\\'s book \\\"Semantics of Biblical… See the full description on the dataset page: https://huggingface.co/datasets/shibing624/sharegpt_gpt4."},
	{"name":"Chinese-LLaVA-Vision-Instructions","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/LinkSoul/Chinese-LLaVA-Vision-Instructions","creator_name":"LinkSoul.AI","creator_url":"https://huggingface.co/LinkSoul","description":"本数据集是对于LLaVA的翻译，请从LLaVA dataset下载对应的图片。\\n百度网盘链接: https://pan.baidu.com/s/1-jgINIkW0MxusmJuSif85w?pwd=q62v\\n"},
	{"name":"ShareGPT_Dialogue","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Maciel/ShareGPT_Dialogue","creator_name":"Maciel Young","creator_url":"https://huggingface.co/Maciel","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Dataset Name\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\n本数据集来自ShareGPT数据，整理成用户和系统多轮对话形式，原始数据来源\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Structure\\n\\t\\n\\n数据集中包含两个字段，分别为dialogue和turn。dialogue是用户和系统之间的多轮对话，数据类型为List(Dict)，按照列表顺序表示对话顺序，每一轮中human是用户问题，assistant是系统回复。turn表示总共对话轮数，数据类型为Int。\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Instances\\n\\t\\n\\n{\\n  \\\"dialogue\\\":\\n    [ \\n      { \\n        \\\"human\\\": \\\"编写一个用户故事，说明一个用户如何登录应用程序，然后在第二段中编写其用户验收测试。\\\",\\n        \\\"assistant\\\": \\\"作为用户，我希望能够登录到应用程序，以便我可以访问我的个性化内容和设置。\\\\n为确保登录功能正常工作，可以进行以下验收测试：\\\\n1.… See the full description on the dataset page: https://huggingface.co/datasets/Maciel/ShareGPT_Dialogue."},
	{"name":"MedChatZH","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/tyang816/MedChatZH","creator_name":"Yang Tan","creator_url":"https://huggingface.co/tyang816","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tMedChatZH\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tMedChatZH中文微调参数\\n\\t\\n\\n基于Baichuan-7B在中医书籍数据和医疗指令对话数据上训练，使其具备较强的中文医疗对话能力，能够理解中医问题。\\nGithub：MedChatZH-7B\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\t🚀 结果\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n问题\\n回答\\n\\n\\n\\t\\t\\n中医治脱发有效吗脱发5、6年了，明显比以前少了很多，脱发位置比较均衡，没有突出掉的比较多的地方，我的发质比较硬，头发生长也较快。\\n中药治疗脱发的效果因人而异，但对于您这种头发质量好且生长速度快的患者来说，中药可能是一个不错的选择。一些常用的中药方剂包括六味地黄丸、四物汤等，这些药物可以滋养肝肾，促进血液循环和毛囊营养供应，从而改善脱发问题。此外，还可以通过针灸、艾灸等方式进行辅助治疗。但是需要注意的是，中药治疗需要长期坚持才能见效，同时还需要注意饮食和生活习惯等方面的问题，以达到更好的疗效。建议您咨询专业的中医医生或皮肤科医生，根据个人情况制定个性化的治疗方案。… See the full description on the dataset page: https://huggingface.co/datasets/tyang816/MedChatZH."},
	{"name":"ChatHaruhi-54K-Role-Playing-Dialogue","keyword":"chinese","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/silk-road/ChatHaruhi-54K-Role-Playing-Dialogue","creator_name":"SilkRoad","creator_url":"https://huggingface.co/silk-road","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tChatHaruhi\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tReviving Anime Character in Reality via Large Language Model\\n\\t\\n\\n\\n\\ngithub repo: https://github.com/LC1332/Chat-Haruhi-Suzumiya\\nChat-Haruhi-Suzumiyais a language model that imitates the tone, personality and storylines of characters like Haruhi Suzumiya,\\n\\n   The project was developed by Cheng Li, Ziang Leng, Chenxi Yan, Xiaoyang Feng, HaoSheng Wang, Junyi Shen, Hao Wang, Weishi Mi, Aria Fei, Song Yan, Linkang Zhan, Yaokai Jia, Pingyu Wu, and Haozhen Sun,etc.… See the full description on the dataset page: https://huggingface.co/datasets/silk-road/ChatHaruhi-54K-Role-Playing-Dialogue."},
	{"name":"lawyer_llama_data","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Skepsun/lawyer_llama_data","creator_name":"Skepsun","creator_url":"https://huggingface.co/Skepsun","description":"基于lawyer-llama的开源数据进行了简单的整合，格式符合LLaMA-Efficient-Tuning的标准格式，source字段保存了数据的原始文件名。\\n"},
	{"name":"DISC-Med-SFT","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Flmc/DISC-Med-SFT","creator_name":"Eric","creator_url":"https://huggingface.co/Flmc","description":"This is a repository containing a subset of the DISC-Med-SFT Dataset.\\nCheck DISC-MedLLM for more information.\\n"},
	{"name":"belebele","keyword":"chinese","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/facebook/belebele","creator_name":"AI at Meta","creator_url":"https://huggingface.co/facebook","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tThe Belebele Benchmark for Massively Multilingual NLU Evaluation\\n\\t\\n\\nBelebele is a multiple-choice machine reading comprehension (MRC) dataset spanning 122 language variants. This dataset enables the evaluation of mono- and multi-lingual models in high-, medium-, and low-resource languages. Each question has four multiple-choice answers and is linked to a short passage from the FLORES-200 dataset. The human annotation procedure was carefully curated to create questions that… See the full description on the dataset page: https://huggingface.co/datasets/facebook/belebele."},
	{"name":"blossom-math-v2","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Azure99/blossom-math-v2","creator_name":"Azure99","creator_url":"https://huggingface.co/Azure99","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tBLOSSOM MATH V2\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\t介绍\\n\\t\\n\\nBlossom Math V3版本已发布！🤗\\nBlossom Math V2是基于Math23K和GSM8K衍生而来的中英双语数学对话数据集，适用于数学问题微调。\\n相比于blossom-math-v1，新增了2500条GSM8K数据和翻译为中文的2500条GSM8K-CN数据。此外，优化了答案的检查逻辑，还移除了<<1+1=2>>等计算步骤，以统一推理步骤的风格。\\n本数据集采用全量Math23K、GSM8K和翻译后的GSM8K的问题，随后调用gpt-3.5-turbo-0613生成结果，并使用原始数据集中的答案对生成的结果进行验证，过滤掉错误答案，很大程度上保证了问题和答案的准确性。\\n本次发布了全量数据的25%，包含10K记录。\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\t语言\\n\\t\\n\\n中文和英文\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\t数据集结构\\n\\t\\n\\n每条数据代表一个完整的题目及答案，包含id、input、output、answer、dataset四个字段。… See the full description on the dataset page: https://huggingface.co/datasets/Azure99/blossom-math-v2."},
	{"name":"OpenOrca-Chinese","keyword":"chinese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/yys/OpenOrca-Chinese","creator_name":"yanyusong","creator_url":"https://huggingface.co/yys","description":"🐋 OpenOrca-Chinese 数据集！🐋\\n\\n感谢  Open-Orca/OpenOrca  数据集的发布，给广大NLP研究人员和开发者带来了宝贵的资源！  \\n这是一个对  Open-Orca/OpenOrca  数据集中文翻译的版本，翻译引擎为 Google 翻译，希望能给中文 LLM 研究做出一点点贡献。\\n\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThe OpenOrca dataset is a collection of augmented FLAN Collection data.\\nCurrently ~1M GPT-4 completions, and ~3.2M GPT-3.5 completions.\\nIt is tabularized in alignment with the distributions presented in the ORCA paper and currently represents a partial completion of the full intended dataset, with… See the full description on the dataset page: https://huggingface.co/datasets/yys/OpenOrca-Chinese."},
	{"name":"OpenOrca-Traditional-Chinese","keyword":"chinese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/lchakkei/OpenOrca-Traditional-Chinese","creator_name":"Lee Chak Kei","creator_url":"https://huggingface.co/lchakkei","description":"🐋 OpenOrca-Chinese 数据集！🐋\\n\\n感謝  Open-Orca/OpenOrca  資料集的發布，為廣大NLP研究人員和開發者帶來了寶貴的資源！\\n這是一個對  Open-Orca/OpenOrca  資料集中文翻譯的版本，翻譯引擎為 Google 翻譯，希望能為中文 LLM 研究做出一點點貢獻。\\n\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThe OpenOrca dataset is a collection of augmented FLAN Collection data.\\nCurrently ~1M GPT-4 completions, and ~3.2M GPT-3.5 completions.\\nIt is tabularized in alignment with the distributions presented in the ORCA paper and currently represents a partial completion of the full intended dataset, with ongoing… See the full description on the dataset page: https://huggingface.co/datasets/lchakkei/OpenOrca-Traditional-Chinese."},
	{"name":"FinCorpus","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Duxiaoman-DI/FinCorpus","creator_name":"Duxiaoman DI","creator_url":"https://huggingface.co/Duxiaoman-DI","description":"中文金融资讯数据集，包括（压缩前）：\\n\\n上市公司公告 announcement_data.jsonl  20G\\n金融资讯/新闻\\nfin_news_data.jsonl 30G\\nfin_articles_data.jsonl 10G\\n\\n\\n金融试题 fin_exam.jsonl 370M\\n\\n数据格式：\\n{\\n  \\\"text\\\": <文本内容>,\\n  \\\"meta\\\": {\\n     \\\"source\\\": <数据来源>\\n  }\\n}\\n\\n"},
	{"name":"belle_filtered_2.8M_CN","keyword":"chinese","license":"GNU General Public License v3.0","license_url":"https://choosealicense.com/licenses/gpl-3.0/","language":"en","dataset_url":"https://huggingface.co/datasets/larryvrh/belle_filtered_2.8M_CN","creator_name":"larryvrh","creator_url":"https://huggingface.co/larryvrh","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for \\\"belle_filtered_2.8M_CN\\\"\\n\\t\\n\\n通过启发式方法过滤后的BelleGroup/train_3.5M_CN，移除了语料中明显的错误和低质量内容。\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\t样例\\n\\t\\n\\n{\\n    \\\"id\\\":\\\"66623028\\\",\\n    \\\"conversations\\\":[\\n        {\\n            \\\"from\\\":\\\"human\\\",\\n            \\\"value\\\":\\\"归纳介绍三种不同类型的电影题材\\\"\\n        },\\n        {\\n            \\\"from\\\":\\\"assistant\\\",\\n            \\\"value\\\":\\\"1. 动作片：动作片通常强调动作和战斗场面，故事情节紧凑，充满了紧张和兴奋的氛围。主角一般是具有超凡实力或特殊技能的英雄人物，往往会与反派角色进行一系列激烈的格斗，追逐和爆破等酷炫场面。例如《速度与激情》和《复仇者联盟》等。\\\\n2.… See the full description on the dataset page: https://huggingface.co/datasets/larryvrh/belle_filtered_2.8M_CN."},
	{"name":"openorca-chinese-zhtw","keyword":"chinese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/erhwenkuo/openorca-chinese-zhtw","creator_name":"Erhwen, Kuo","creator_url":"https://huggingface.co/erhwenkuo","description":"\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for \\\"openorca-chinese-zhtw\\\"\\n\\t\\n\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThe OpenOrca dataset is a collection of augmented FLAN Collection data.\\nCurrently ~1M GPT-4 completions, and ~3.2M GPT-3.5 completions.\\nIt is tabularized in alignment with the distributions presented in the ORCA paper and currently represents a partial completion of the full intended dataset, with ongoing generation to expand its scope.\\nThe data is primarily used for training and evaluation in the field of… See the full description on the dataset page: https://huggingface.co/datasets/erhwenkuo/openorca-chinese-zhtw."},
	{"name":"medical_dialogue-chinese-zhtw","keyword":"chinese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/erhwenkuo/medical_dialogue-chinese-zhtw","creator_name":"Erhwen, Kuo","creator_url":"https://huggingface.co/erhwenkuo","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for \\\"medical_dialogue-chinese-zhtw\\\"\\n\\t\\n\\n中文醫療問答資料集\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\t來源\\n\\t\\n\\n本資料集是從 Toyhom/Chinese-medical-dialogue-data 的 github repo 中轉換而來。\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\t內容\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n科別\\n數量\\n\\n\\n\\t\\t\\nAndriatria 男科\\n94,596 個問答對\\n\\n\\nIM 內科\\n220,606 個問答對\\n\\n\\nOAGD 婦產科\\n183,751 個問答對\\n\\n\\nOncology 腫瘤科\\n75,553 個問答對\\n\\n\\nPediatric 兒科\\n101,602 個問答對\\n\\n\\nSurgical 外科\\n115,991 個問答對\\n\\n\\n\\t\\n\\n 總計 792,099 條數據\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\t範例\\n\\t\\n\\n{\\n  \\\"instruction\\\": \\\"現在你是個神經腦外科醫生，請根據病人的問題給予建議：\\\",\\n  \\\"input\\\": \\\"癲癇病能吃德巴金嗎，錯覺，有時候感覺看到的和聽到的不太一樣。\\\",\\n  \\\"output\\\":… See the full description on the dataset page: https://huggingface.co/datasets/erhwenkuo/medical_dialogue-chinese-zhtw."},
	{"name":"C-Language-Chat-Debug-Multiturn-Zh","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Mxode/C-Language-Chat-Debug-Multiturn-Zh","creator_name":"Max Zhang","creator_url":"https://huggingface.co/Mxode","description":"约 1300 条 C 语言 场景的 user - assistant 多轮对话。每段对话已经组织成了单行的格式。一条样例如下：\\n{\\n    \\\"id\\\": 1045,\\n    \\\"conversation\\\": [\\n        {\\n            \\\"user\\\": \\\"你好，AI助手。我最近在写一个C语言程序，但是遇到了一些问题，希望你能帮我检查一下。\\\",\\n            \\\"assistant\\\": \\\"你好，我很乐意帮助你。请把你的代码发给我，我会尽快检查并给出建议。\\\"\\n        },\\n        {\\n            \\\"user\\\": \\\"好的，这是我的代码。这段代码的主要功能是计算斐波那契数列的前n项。\\\",\\n            \\\"assistant\\\": \\\"让我看一下......嗯，这里有一个小错误。在第10行，你应该使用`++i`而不是`i++`来递增i的值。修改后的代码应该是这样的\\\\\\\\n```c\\\\\\\\nfor (int i = 0; i < n; ++i) {\\\\\\\\n    if (i == 0 || i == 1) {\\\\\\\\n… See the full description on the dataset page: https://huggingface.co/datasets/Mxode/C-Language-Chat-Debug-Multiturn-Zh."},
	{"name":"ntu_adl_question","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/xjlulu/ntu_adl_question","creator_name":"Xue-Jin Lu","creator_url":"https://huggingface.co/xjlulu","description":"xjlulu/ntu_adl_question dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"Huatuo26M-Lite","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/FreedomIntelligence/Huatuo26M-Lite","creator_name":"FreedomAI","creator_url":"https://huggingface.co/FreedomIntelligence","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tHuatuo26M-Lite 📚\\n\\t\\n\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tTable of Contents 🗂\\n\\t\\n\\n\\nDataset Description 📝\\nDataset Information ℹ️\\nData Distribution 📊\\nUsage 🔧\\nCitation 📖\\n\\n\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description 📝\\n\\t\\n\\nHuatuo26M-Lite is a refined and optimized dataset based on the Huatuo26M dataset, which has undergone multiple purification processes and rewrites. It has more data dimensions and higher data quality. We welcome you to try using it.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Information ℹ️\\n\\t\\n\\n\\nDataset Name:… See the full description on the dataset page: https://huggingface.co/datasets/FreedomIntelligence/Huatuo26M-Lite."},
	{"name":"GSM8KInstruct_Parallel","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Mathoctopus/GSM8KInstruct_Parallel","creator_name":"Mathoctopus","creator_url":"https://huggingface.co/Mathoctopus","description":"Mathoctopus/GSM8KInstruct_Parallel dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"CodeFuse-DevOps-Eval","keyword":"chinese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/codefuse-ai/CodeFuse-DevOps-Eval","creator_name":"CodeFuse AI","creator_url":"https://huggingface.co/codefuse-ai","description":"DevOps-Eval is a comprehensive chinese evaluation suite specifically designed for foundation models in the DevOps field. It consists of 5977 multi-choice questions spanning 55 diverse categories. Please visit our website and GitHub for more details.\\nEach category consists of two splits: dev, and test. The dev set per subject consists of five exemplars with explanations for few-shot evaluation. And the test set is for model evaluation. Labels on the test split are released, users can evaluate… See the full description on the dataset page: https://huggingface.co/datasets/codefuse-ai/CodeFuse-DevOps-Eval."},
	{"name":"poetry-chinese-zhtw","keyword":"chinese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/erhwenkuo/poetry-chinese-zhtw","creator_name":"Erhwen, Kuo","creator_url":"https://huggingface.co/erhwenkuo","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for \\\"poetry-chinese-zhtw\\\"\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\t資料集摘要\\n\\t\\n\\n中文古典文集資料庫收集了約 5.5 萬首唐詩、26 萬首宋詩、2.1 萬首宋詞和其他古典文集。詩人包括唐宋兩朝近 1.4 萬古詩人，和兩宋時期 1.5 千古詞人。\\n\\n五代十國- 收錄\\\"花間集\\\"與\\\"南唐二主詞\\\"\\n唐- 收錄\\\"全唐詩\\\"(是清康熙四十四年，康熙皇帝主導下，蒐集羅唐詩的收藏「得詩 48,900 餘首，詩入 2,200 人」)。\\n宋- 收錄\\\"全宋詞\\\"(由唐圭璋編著，孔凡禮補輯，共收錄宋代詞人 1,330 家，詞作 21,116 首)。\\n元- 收錄元曲 11,057 篇，曲家 233 人。\\n清- 收錄\\\"納蘭性德詩集\\\"\\n\\n原始資料來源:\\n\\nchinese-poetry: 最全中文诗歌古典文集数据库\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\t資料下載清理\\n\\t\\n\\n\\n下載 chinese-poetry: 最全中文诗歌古典文集数据库 的 Repo\\n調整資料呈現結構便於模型訓練\\n使用 OpenCC 來進行簡繁轉換\\n使用 Huggingface… See the full description on the dataset page: https://huggingface.co/datasets/erhwenkuo/poetry-chinese-zhtw."},
	{"name":"medical_instruction","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/DavidLanz/medical_instruction","creator_name":"David Lanz","creator_url":"https://huggingface.co/DavidLanz","description":"Supervisory Fine-Tuning Dataset (SFT and RLHF)\\n\\nDataset Name: medical_finetune_tw.json\\nDescription: This dataset comprises a total of 2.06 million entries and is sourced from various sources, including:\\nSix medical department medical inquiry datasets from the Chinese Medical Dialogue Dataset, totaling 790,000 entries.\\nAn online medical encyclopedia dataset, huatuo_encyclopedia_qa, with 360,000 entries.\\nA medical knowledge graph dataset, huatuo_knowledge_graph_qa, with 790,000 entries. These… See the full description on the dataset page: https://huggingface.co/datasets/DavidLanz/medical_instruction."},
	{"name":"RoleBench","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ZenMoore/RoleBench","creator_name":"Zekun Moore Wang","creator_url":"https://huggingface.co/ZenMoore","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tRoleBench\\n\\t\\n\\n\\nPaper Title: RoleLLM: Benchmarking, Eliciting, and Enhancing Role-Playing Abilities of Large Language Models\\narXiv Link: https://arxiv.org/abs/2310.00746\\nGithub Repo: https://github.com/InteractiveNLP-Team/RoleLLM-public\\n\\nPlease read our paper for more details about this dataset.\\nTL;DR: We introduce RoleLLM, a role-playing framework of data construction and evaluation (RoleBench), as well as solutions for both closed-source and open-source models (RoleGPT, RoleLLaMA… See the full description on the dataset page: https://huggingface.co/datasets/ZenMoore/RoleBench."},
	{"name":"alpaca-cot-zh-refined-by-data-juicer","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/datajuicer/alpaca-cot-zh-refined-by-data-juicer","creator_name":"Data-Juicer","creator_url":"https://huggingface.co/datajuicer","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tAlpaca-CoT -- ZH (refined by Data-Juicer)\\n\\t\\n\\nA refined Chinese version of Alpaca-CoT dataset by Data-Juicer. Removing some \\\"bad\\\" samples from the original dataset to make it higher-quality.\\nThis dataset is usually used to fine-tune a Large Language Model.\\nNotice: Here is a small subset for previewing. The whole dataset is available here (About 18.7GB).\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Information\\n\\t\\n\\n\\nNumber of samples: 9,873,214 (Keep ~46.58% from the original dataset)\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tRefining… See the full description on the dataset page: https://huggingface.co/datasets/datajuicer/alpaca-cot-zh-refined-by-data-juicer."},
	{"name":"Conic10K","keyword":"chinese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/WenyangHui/Conic10K","creator_name":"huiwy","creator_url":"https://huggingface.co/WenyangHui","description":"WenyangHui/Conic10K dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"Open_Assistant_Conversation_Chains","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/m-ric/Open_Assistant_Conversation_Chains","creator_name":"Aymeric Roucher","creator_url":"https://huggingface.co/m-ric","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Dataset Name\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset description\\n\\t\\n\\n\\n\\nThis dataset is a reformatting of OpenAssistant Conversations (OASST1), which is\\n\\na human-generated, human-annotated assistant-style conversation corpus consisting of 161,443 messages in 35 different languages, annotated with 461,292 quality ratings, resulting in over 10,000 fully annotated conversation trees. The corpus is a product of a worldwide crowd-sourcing effort involving over 13,500 volunteers.\\n\\nIt was… See the full description on the dataset page: https://huggingface.co/datasets/m-ric/Open_Assistant_Conversation_Chains."},
	{"name":"librivox-tracks","keyword":"chinese","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/pykeio/librivox-tracks","creator_name":"pyke.io","creator_url":"https://huggingface.co/pykeio","description":"A dataset of all audio files uploaded to LibriVox before 26th September 2023.\\n"},
	{"name":"gsm8k_chinese","keyword":"chinese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/swulling/gsm8k_chinese","creator_name":"Alex Yang","creator_url":"https://huggingface.co/swulling","description":"swulling/gsm8k_chinese dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"multilingual-tts","keyword":"chinese","license":"GNU General Public License v3.0","license_url":"https://choosealicense.com/licenses/gpl-3.0/","language":"en","dataset_url":"https://huggingface.co/datasets/MohamedRashad/multilingual-tts","creator_name":"Mohamed Rashad","creator_url":"https://huggingface.co/MohamedRashad","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tBefore Anything and Everything ⚱\\n\\t\\n\\nIn the time of writing this Dataset Card, 17,490 18,412 civilian has been killed in Palestine (7,870 8,000 are children and 6,121 6,200 are women).\\nSeek any non-profit organization to help them with what you can (For myself, I use Mersal) 🇵🇸\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThe Multilingual TTS dataset is an exceptional compilation of text-to-speech (TTS) samples, meticulously crafted to showcase the richness and diversity of human languages.… See the full description on the dataset page: https://huggingface.co/datasets/MohamedRashad/multilingual-tts."},
	{"name":"ChatHaruhi-Expand-118K","keyword":"chinese","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/silk-road/ChatHaruhi-Expand-118K","creator_name":"SilkRoad","creator_url":"https://huggingface.co/silk-road","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tChatHaruhi Expanded Dataset 118K\\n\\t\\n\\n62663 instance from original ChatHaruhi-54K\\n42255 English Data from RoleLLM\\n13166 Chinese Data from \\ngithub repo:\\nhttps://github.com/LC1332/Chat-Haruhi-Suzumiya\\nPlease star our github repo if you found the dataset is useful\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tRegenerate Data\\n\\t\\n\\nIf you want to regenerate data with different context length, different embedding model or using your own chracter\\nnow we refactored the final data generating pipeline\\nRoleLLM Data was generated… See the full description on the dataset page: https://huggingface.co/datasets/silk-road/ChatHaruhi-Expand-118K."},
	{"name":"MetaMathQA_GSM8K_zh","keyword":"chinese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/meta-math/MetaMathQA_GSM8K_zh","creator_name":"MetaMath","creator_url":"https://huggingface.co/meta-math","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset\\n\\t\\n\\nMetaMathQA_GSM8K_zh is a dataset for mathematical reasoning in Chinese, \\nquestion-answer pairs are translated from MetaMathQA (https://huggingface.co/datasets/meta-math/MetaMathQA) by GPT-3.5-Turbo with few-shot prompting.\\nThe dataset consists of 231685 samples.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tCitation\\n\\t\\n\\nIf you find the GSM8K_zh dataset useful for your projects/papers, please cite the following paper.\\n@article{yu2023metamath,\\n  title={MetaMath: Bootstrap Your Own Mathematical Questions for… See the full description on the dataset page: https://huggingface.co/datasets/meta-math/MetaMathQA_GSM8K_zh."},
	{"name":"yayi_uie_sft_data","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/wenge-research/yayi_uie_sft_data","creator_name":"wenge-research","creator_url":"https://huggingface.co/wenge-research","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\t训练数据/Training Data\\n\\t\\n\\n百万级语料中文54%，英文46%；其中其中数据集包括12个领域包括金融，社会，生物，商业，工业制造，化学，车辆，科学，疾病医疗，个人生活，安全和通用。覆盖数百个使用场景\\n\\nNER：中文覆盖28个实体类型包括人物，地缘政治，组织，身体部位，药物等，英文覆盖130个实体类型包括Animal, Weapon, Conference, Book等。\\nRE：中文覆盖232种关系包括买资，增持，重组，国籍，别名，亲属，入股，转让，导致，发生地点，制造商等，英文覆盖236种关系包括founded by，state or province of headquarters，employee of，occupation，creator等。\\nEE：中文覆盖84种事件类型,包括中标，高管变动，产品行为-发布，公司上市等，和203种论元，英文覆盖45种事件类型，包括Born, Demonstrate, Meet, End Organization, Divorce等，和62种论元。\\n\\nIn the corpus of over a… See the full description on the dataset page: https://huggingface.co/datasets/wenge-research/yayi_uie_sft_data."},
	{"name":"Anime_novel_datasets","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Minami-su/Anime_novel_datasets","creator_name":"南栖","creator_url":"https://huggingface.co/Minami-su","description":""},
	{"name":"multilingual-pl-bert","keyword":"chinese","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/styletts2-community/multilingual-pl-bert","creator_name":"StyleTTS 2 Community","creator_url":"https://huggingface.co/styletts2-community","description":"Attribution: Wikipedia.org\\n"},
	{"name":"Chinese-poetries-txt","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Lifan-Z/Chinese-poetries-txt","creator_name":"Lifan Zeng","creator_url":"https://huggingface.co/Lifan-Z","description":"这个数据集是把《全唐诗》、《全宋诗》中所有的五绝、五律、七绝、七律都提取出来，做成四个文件。每行对应一首诗。五绝（5x4）: 17521 首五律（5x8）: 60896 首七绝（7x4）: 84485 首七律（7x8）: 71818 首  \\nThis dataset extracts four styles of poetries in \\\"Complete Poems of the Tang Dynasty\\\" and \\\"Complete Poems of the Song Dynasty.\\\"Each line corresponds to a Chinese poem.The syle on 5x4: 17521The syle on 5x8: 60896The syle on 7x4: 84485The syle on 7x8: 71818   \\nThe raw data source from https://github.com/chinese-poetry/chinese-poetry/tree/master/%E5%85%A8%E5%94%90%E8%AF%97  \\n"},
	{"name":"tmmluplus","keyword":"chinese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/ikala/tmmluplus","creator_name":"iKala","creator_url":"https://huggingface.co/ikala","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tTMMLU+ : Large scale traditional chinese massive multitask language understanding\\n\\t\\n\\n\\n\\n\\nWe present TMMLU+, a traditional Chinese massive multitask language understanding dataset. TMMLU+ is a multiple-choice question-answering dataset featuring 66 subjects, ranging from elementary to professional level.\\n\\nThe TMMLU+ dataset is six times larger and contains more balanced subjects compared to its predecessor, TMMLU. We have included benchmark results in TMMLU+ from closed-source models… See the full description on the dataset page: https://huggingface.co/datasets/ikala/tmmluplus."},
	{"name":"CPsyExam","keyword":"chinese","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/CAS-SIAT-XinHai/CPsyExam","creator_name":"CAS-SIAT-XinHai","creator_url":"https://huggingface.co/CAS-SIAT-XinHai","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tCPsyExam Dataset\\n\\t\\n\\nCPsyExam is a comprehensive dataset designed for evaluating Chinese psychological examination capabilities in large language models.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThe CPsyExam dataset is structured to assess psychological examination competencies in a Chinese context. It provides a standardized way to evaluate how well language models can handle psychological assessment tasks. The dataset contains multiple-choice questions from various psychological domains… See the full description on the dataset page: https://huggingface.co/datasets/CAS-SIAT-XinHai/CPsyExam."},
	{"name":"TinyStories-Qwen","keyword":"chinese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/zhoukz/TinyStories-Qwen","creator_name":"zhoukz","creator_url":"https://huggingface.co/zhoukz","description":"使用Qwen系列模型，仿照TinyStories数据集生成的中文故事数据集。\\n这不是原数据集的翻译，也不遵循原数据集的格式。所有数据均为AI生成，数据集未经筛选，不保证其分布均匀、安全无害或其他任何性质。用于生成数据集的种子信息为随机选择，无任何特定含义。\\n"},
	{"name":"Zhihu-KOL-More-Than-100-Upvotes","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/bzb2023/Zhihu-KOL-More-Than-100-Upvotes","creator_name":"刷知乎刷的","creator_url":"https://huggingface.co/bzb2023","description":"对 https://huggingface.co/datasets/wangrui6/Zhihu-KOL 数据进行了初步整理，保留了100赞及以上的数据。\\n共271261条。\\n"},
	{"name":"openassistant-deepseek-coder","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Trelis/openassistant-deepseek-coder","creator_name":"Trelis","creator_url":"https://huggingface.co/Trelis","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tChat Fine-tuning Dataset - OpenAssistant DeepSeek Coder\\n\\t\\n\\nThis dataset allows for fine-tuning chat models using:\\nB_INST = '\\\\n### Instruction:\\\\n'\\nE_INST = '\\\\n### Response:\\\\n'\\nBOS = '<｜begin▁of▁sentence｜>'\\nEOS = '\\\\n<|EOT|>\\\\n'\\n\\nSample Preparation:\\n\\nThe dataset is cloned from TimDettmers, which itself is a subset of the Open Assistant dataset, which you can find here. This subset of the data only contains the highest-rated paths in the conversation tree, with a total of 9,846 samples.… See the full description on the dataset page: https://huggingface.co/datasets/Trelis/openassistant-deepseek-coder."},
	{"name":"Ziya-Writing-Eval-Chinese","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/IDEA-CCNL/Ziya-Writing-Eval-Chinese","creator_name":"Fengshenbang-LM","creator_url":"https://huggingface.co/IDEA-CCNL","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\t姜子牙写作任务中文评估数据集 Ziya-Writing-Eval-Chinese\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\t数据介绍 Dataset Summary\\n\\t\\n\\n用于评估大语言模型在中文写作任务上的水平，通常采用Side-by-Side评测；\\n本评测集包含了以下几个写作子任务：\\n\\n应用写作\\n公文\\n通知\\n报告\\n论文\\n征稿\\n函件\\n申请书\\n\\n\\n创意写作\\n书信\\n作文\\n文案\\n小说\\n视频脚本\\n攻略\\n广告\\n剧本\\n童话\\n\\n\\n\\nThis evaluation set is used to assess the proficiency of large language models in Chinese writing tasks, typically through Side-by-Side evaluation.\\nThis evaluation set includes the following writing sub-tasks:\\n\\nApplication Writing\\nOfficial documents\\nNotices\\nReports\\nPapers\\nCall… See the full description on the dataset page: https://huggingface.co/datasets/IDEA-CCNL/Ziya-Writing-Eval-Chinese."},
	{"name":"T-Eval","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/lovesnowbest/T-Eval","creator_name":"Zehui Chen","creator_url":"https://huggingface.co/lovesnowbest","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tT-Eval: Evaluating the Tool Utilization Capability of Large Language Models Step by Step\\n\\t\\n\\n\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\t✨ Introduction\\n\\t\\n\\nThis is an evaluation harness for the benchmark described in T-Eval: Evaluating the Tool Utilization Capability of Large Language Models Step by Step. \\n[Paper]\\n[Project Page]\\n[LeaderBoard]\\n[HuggingFace]\\n\\nLarge language models (LLM) have achieved remarkable performance on various NLP tasks and are augmented by tools for broader applications. Yet, how to… See the full description on the dataset page: https://huggingface.co/datasets/lovesnowbest/T-Eval."},
	{"name":"Chinese-LIMA-V0","keyword":"chinese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Jellyfish042/Chinese-LIMA-V0","creator_name":"Jellyfish042","creator_url":"https://huggingface.co/Jellyfish042","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLIMA数据集中文版\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\t数据集构造方法\\n\\t\\n\\n\\n使用GPT-4-Turbo将原始LIMA数据集的问题部分翻译为中文。\\n使用GPT-4-Turbo回答翻译后的问题。\\n注意，本数据集不包含原始LIMA数据集的多轮问答部分\\n\\n"},
	{"name":"sharegpt_dialogue_base","keyword":"chinese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/lamhieu/sharegpt_dialogue_base","creator_name":"Hieu Lam","creator_url":"https://huggingface.co/lamhieu","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDescription\\n\\t\\n\\nThe dataset is from unknown, formatted as dialogues for speed and ease of use. Many thanks to author for releasing it.\\nImportantly, this format is easy to use via the default chat template of transformers, meaning you can use huggingface/alignment-handbook immediately, unsloth.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tStructure\\n\\t\\n\\nView online through viewer.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tNote\\n\\t\\n\\nWe advise you to reconsider before use, thank you. If you find it useful, please like and follow this account.… See the full description on the dataset page: https://huggingface.co/datasets/lamhieu/sharegpt_dialogue_base."},
	{"name":"evol-character-200","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/bai-roleplay/evol-character-200","creator_name":"Bauhinia AI","creator_url":"https://huggingface.co/bai-roleplay","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tEvol-character 数据集\\n\\t\\n\\n中文         English\\n\\nEvol-character 数据集\\n下载数据集\\n数据生成框架\\n数据结构\\n与现有数据集对比\\n现有角色扮演数据集\\n我们的优势\\n\\n\\n联系我们\\n项目使用与免责声明\\n\\n\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\t下载数据集\\n\\t\\n\\n本数据集由GPT3.5和GPT4生成，为确保数据的合理使用，目前只公开了部分数据，公开的数据由三份文件组成，每份文件包含200个角色的设定以及对话。可在huggingface中下载已公开数据或申请获取全部数据: \\n可在github中获取数据生成代码的相关信息：\\nOpenAI GPT3.5 数据生成样例：\\n# 角色信息\\n角色名称：薔薇亞（Baria）\\n开场语：「呵呵呵，你好啊，主人大人。」\\n身份背景：薔薇亞是一名高级女仆，专供贵族家庭使用。她的主人是一个富有、有影响力的家族的继承人。在家族中，她是一个神秘的存在，奉承和服侍着主人，但对其他人傲慢冷漠。… See the full description on the dataset page: https://huggingface.co/datasets/bai-roleplay/evol-character-200."},
	{"name":"sib200","keyword":"chinese","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Davlan/sib200","creator_name":"David Adelani","creator_url":"https://huggingface.co/Davlan","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for SIB-200\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nSIB-200 is the largest publicly available topic classification dataset based on Flores-200 covering 205 languages and dialects.\\nThe train/validation/test sets are available for all the 205 languages.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSupported Tasks and Leaderboards\\n\\t\\n\\n\\ntopic classification: categorize wikipedia sentences into topics e.g science/technology, sports or politics.\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages\\n\\t\\n\\nThere are 205 languages available :… See the full description on the dataset page: https://huggingface.co/datasets/Davlan/sib200."},
	{"name":"aya_dataset","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/CohereForAI/aya_dataset","creator_name":"Cohere For AI","creator_url":"https://huggingface.co/CohereForAI","description":"\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThe Aya Dataset is a multilingual instruction fine-tuning dataset curated by an open-science community via Aya Annotation Platform from Cohere For AI. The dataset contains a total of 204k human-annotated prompt-completion pairs along with the demographics data of the annotators.\\nThis dataset can be used to train, finetune, and evaluate multilingual LLMs.\\n\\nCurated by: Contributors of Aya Open Science Intiative.\\n\\nLanguage(s): 65 languages (71 including dialects &… See the full description on the dataset page: https://huggingface.co/datasets/CohereForAI/aya_dataset."},
	{"name":"aya_collection","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/CohereForAI/aya_collection","creator_name":"Cohere For AI","creator_url":"https://huggingface.co/CohereForAI","description":"\\nThis dataset is uploaded in two places: here and additionally here as 'Aya Collection Language Split.' These datasets are identical in content but differ in structure of upload. This dataset is structured by folders split according to dataset name. The version here instead divides the Aya collection into folders split by language. We recommend you use the language split version if you are only interested in downloading data for a single or smaller set of languages, and this version if you… See the full description on the dataset page: https://huggingface.co/datasets/CohereForAI/aya_collection."},
	{"name":"aya_evaluation_suite","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/CohereForAI/aya_evaluation_suite","creator_name":"Cohere For AI","creator_url":"https://huggingface.co/CohereForAI","description":"\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nAya Evaluation Suite contains a total of 26,750 open-ended conversation-style prompts to evaluate multilingual open-ended generation quality.To strike a balance between language coverage and the quality that comes with human curation, we create an evaluation suite that includes:\\n\\nhuman-curated examples in 7 languages (tur, eng, yor, arb, zho, por, tel) → aya-human-annotated.\\nmachine-translations of handpicked examples into 101 languages →… See the full description on the dataset page: https://huggingface.co/datasets/CohereForAI/aya_evaluation_suite."},
	{"name":"CulturaY","keyword":"chinese","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ontocord/CulturaY","creator_name":"Ontocord.AI","creator_url":"https://huggingface.co/ontocord","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tCulturaY: A Large Cleaned Multilingual Dataset of 75 Languages\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nFrom the team that brought you CulturaX, we present CulturaY, another substantial multilingual dataset of 15TB (uncompressed)/3TB (zstd-compressed) that applies the same dataset cleaning methodology to the HPLT v1.1 dataset. \\nPlease note that HPLT v1.2 has also been released and is an alternative verison with different cleaning methodolgies. \\nThis data was used in part to train our SOTA… See the full description on the dataset page: https://huggingface.co/datasets/ontocord/CulturaY."},
	{"name":"Traditional_Chinese-aya_collection","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Heng666/Traditional_Chinese-aya_collection","creator_name":"Heng-Shiou Sheu | 許恆修","creator_url":"https://huggingface.co/Heng666","description":"\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\t資料集描述\\n\\t\\n\\n繁體中文 Aya (Traditional Chinese Aya Chinese;TCA)：專注於繁體中文處理的 Aya 集合的精選子集\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\t概述\\n\\t\\n\\n繁體中文 Aya 是一個精心策劃的資料集，源自 CohereForAI 的綜合 Aya 集合，特別關注繁體中文文本資料。\\n此資料集結合了來自 CohereForAI/aya_collection，過濾掉除繁體中文、簡體中文內容之外的所有內容。\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\t目標\\n\\t\\n\\n繁體中文 Aya 的目標是為研究人員、技術專家和語言學家提供即用型繁體中文文本資源，顯著減少專注於繁體中文的 NLP 和 AI 專案中數據預處理所需的時間和精力。\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\t資料集來源與資訊\\n\\t\\n\\n\\n資料來源: 從 CohereForAI/aya_collection 64 個子集而來。\\n語言: 繁體中文、簡體中文（'zho')\\n應用: 非常適合語言建模、文本分類、情感分析、和機器翻譯等任務。\\n論文連結: 2402.06619\\n維護人: Heng666\\nLicense:… See the full description on the dataset page: https://huggingface.co/datasets/Heng666/Traditional_Chinese-aya_collection."},
	{"name":"CategoricalHarmfulQA","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/declare-lab/CategoricalHarmfulQA","creator_name":"Deep Cognition and Language Research (DeCLaRe) Lab","creator_url":"https://huggingface.co/declare-lab","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tCatQA: A categorical harmful questions dataset\\n\\t\\n\\n\\nCatQA is used in LLM safety realignment research: \\nLanguage Models are Homer Simpson! Safety Re-Alignment of Fine-tuned Language Models through Task Arithmetic (Paper, Code)\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tHow to download\\n\\t\\n\\nfrom datasets import load_dataset\\ndataset = load_dataset(\\\"declare-lab/CategoricalHarmfulQA\\\")\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tWhat is CatQA?\\n\\t\\n\\nTo comprehensively evaluate the model across a wide range of harmful categories, we construct a new… See the full description on the dataset page: https://huggingface.co/datasets/declare-lab/CategoricalHarmfulQA."},
	{"name":"GPT-4-Prompts","keyword":"chinese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/erfanzar/GPT-4-Prompts","creator_name":"Erfan zare chavoshi","creator_url":"https://huggingface.co/erfanzar","description":"Multi-Turn Conversational Prompts from ChatGPT-4 (10K+ Tokens)\\nAbstract:\\nThis dataset offers a valuable collection of multi-turn conversational prompts generated by ChatGPT-4, carefully curated for diverse prompt styles (chatml, gemma, llama). Each prompt exceeds 10,000 tokens, providing ample context and inspiration for training and evaluating large language models. Ideal for researchers and developers interested in exploring advanced conversational AI capabilities.\\nTable of Contents:… See the full description on the dataset page: https://huggingface.co/datasets/erfanzar/GPT-4-Prompts."},
	{"name":"Refined-Anime-Text","keyword":"chinese","license":"\"Do What The F*ck You Want To Public License\"","license_url":"https://choosealicense.com/licenses/wtfpl/","language":"en","dataset_url":"https://huggingface.co/datasets/CausalLM/Refined-Anime-Text","creator_name":"CausalLM","creator_url":"https://huggingface.co/CausalLM","description":"\\n\\t\\n\\t\\t\\n\\t\\tRefined Anime Text for Continual Pre-training of Language Models\\n\\t\\n\\nThis is a subset of our novel synthetic dataset of anime-themed text, containing over 1M entries, ~440M GPT-4/3.5 tokens. This dataset has never been publicly released before. We are releasing this subset due to the community's interest in anime culture, which is underrepresented in general-purpose datasets, and the low quality of raw text due to the prevalence of internet slang and irrelevant content, making it… See the full description on the dataset page: https://huggingface.co/datasets/CausalLM/Refined-Anime-Text."},
	{"name":"bio-mqm-dataset","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/zouharvi/bio-mqm-dataset","creator_name":"Vilém Zouhar","creator_url":"https://huggingface.co/zouharvi","description":"This dataset is compiled from the official Amazon repository (all respective licensing applies).\\nIt contains system translations, multiple references, and their quality evaluation on the MQM scale. It accompanies the ACL 2024 paper Fine-Tuned Machine Translation Metrics Struggle in Unseen Domains.\\nWatch a brief 4 minutes-long video.\\n\\nAbstract: We introduce a new, extensive multidimensional quality metrics (MQM) annotated dataset covering 11 language pairs in the biomedical domain. We use this… See the full description on the dataset page: https://huggingface.co/datasets/zouharvi/bio-mqm-dataset."},
	{"name":"Chinese-Patent-Summary","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/chenmingxuan/Chinese-Patent-Summary","creator_name":"cmx","creator_url":"https://huggingface.co/chenmingxuan","description":"高质量中文专利摘要数据集。\\n"},
	{"name":"XMedbench","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/FreedomIntelligence/XMedbench","creator_name":"FreedomAI","creator_url":"https://huggingface.co/FreedomIntelligence","description":"\\n\\t\\n\\t\\t\\n\\t\\tMultilingual Medicine: Model, Dataset, Benchmark, Code\\n\\t\\n\\nCovering English, Chinese, French, Hindi, Spanish, Hindi, Arabic So far\\n\\n   👨🏻‍💻Github •📃 Paper • 🤗 ApolloCorpus • 🤗 XMedBench \\n      中文  |  English\\n\\n\\n\\n\\n\\n\\t\\t\\n\\t\\t🌈 Update\\n\\t\\n\\n\\n[2024.03.07] Paper released.\\n[2024.02.12] ApolloCorpus and  XMedBench  is published！🎉\\n[2024.01.23] Apollo repo is published！🎉\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tResults\\n\\t\\n\\n   \\n\\n\\t\\n\\t\\t\\n\\t\\tUsage\\n\\t\\n\\n\\nZip File\\nData category\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tData:\\n\\t\\n\\n\\nEN:\\n\\nMedQA-USMLE \\nMedMCQA\\nPubMedQA:… See the full description on the dataset page: https://huggingface.co/datasets/FreedomIntelligence/XMedbench."},
	{"name":"ALLaVA-4V-Chinese","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/FreedomIntelligence/ALLaVA-4V-Chinese","creator_name":"FreedomAI","creator_url":"https://huggingface.co/FreedomIntelligence","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tALLaVA-4V for Chinese\\n\\t\\n\\nThis is the Chinese version of the ALLaVA-4V data. We have translated the ALLaVA-4V data into Chinese through ChatGPT and instructed ChatGPT not to translate content related to OCR.\\nThe original dataset can be found here, and the image data can be downloaded from ALLaVA-4V.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tCitation\\n\\t\\n\\nIf you find our data useful, please consider citing our work! We are FreedomIntelligence from Shenzhen Research Institute of Big Data and The Chinese University… See the full description on the dataset page: https://huggingface.co/datasets/FreedomIntelligence/ALLaVA-4V-Chinese."},
	{"name":"aya_collection_language_split","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/CohereForAI/aya_collection_language_split","creator_name":"Cohere For AI","creator_url":"https://huggingface.co/CohereForAI","description":"\\nThis is a re-upload of the aya_collection, and only differs in the structure of upload. While the original aya_collection is structured by folders split according to dataset name, this dataset is split by language. We recommend you use this version of the dataset if you are only interested in downloading all of the Aya collection for a single or smaller set of languages.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThe Aya Collection is a massive multilingual collection consisting of 513 million instances… See the full description on the dataset page: https://huggingface.co/datasets/CohereForAI/aya_collection_language_split."},
	{"name":"CLoT-Oogiri-GO","keyword":"chinese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/zhongshsh/CLoT-Oogiri-GO","creator_name":"Shanshan Zhong","creator_url":"https://huggingface.co/zhongshsh","description":"\\n   \\n\\n\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tOogiri-GO Dataset Card\\n\\t\\n\\nProject Page | Paper | Code | Model\\nData discription: Oogiri-GO is a multimodal and multilingual humor dataset, and contains more than 130,000 Oogiri samples in English (en.jsonl), Chinese (cn.jsonl), and Japanese (jp.jsonl).  Notably,  in Oogiri-GO, 77.95% of samples are annotated with human preferences, namely the number of likes, indicating the popularity of a response. As illustrated in Fig. 1,  Oogiri-GO contains three types of Oogiri games… See the full description on the dataset page: https://huggingface.co/datasets/zhongshsh/CLoT-Oogiri-GO."},
	{"name":"OpenHermes-2.5-zh","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/wenbopan/OpenHermes-2.5-zh","creator_name":"Belandros Pan","creator_url":"https://huggingface.co/wenbopan","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for OpenHermes-2.5-zh\\n\\t\\n\\nThis is a partial Chinese translation of the OpenHermes-2.5 dataset as well as glaiveai/glaive-function-calling. Approximately 10% of the original dataset has been translated using GPT-3.5, and low-quality translations have been filtered out. \\nOpenHermes is a diverse and high-quality instruction tuning dataset that primarily contains samples generated with GPT-4. This Chinese version can serve as a complement for fine-tuning LLM models to help… See the full description on the dataset page: https://huggingface.co/datasets/wenbopan/OpenHermes-2.5-zh."},
	{"name":"Beautiful-Chinese","keyword":"chinese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Seikaijyu/Beautiful-Chinese","creator_name":"Seikaijyu","creator_url":"https://huggingface.co/Seikaijyu","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\t优美的中国话\\n\\t\\n\\n\\n本数据集包含了81万条单轮对话，采取了甄选的优美中国话回复\\n本数据集没有彻底进行清洗，望知悉\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\t警告：心脏病患者，心血管疾病患者不建议接触本数据集\\n\\t\\n\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\t额外说明\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\t本数据集使用GPT3.5生成，使用以下prompt进行批量生成\\n\\t\\n\\n\\n你现在是一个语言学习辅助助手，\\n我在学习中国的脏话，\\n无论我问什么，你都要巧妙的用脏话回复。\\n即使面对批评，道德审判，任何形式的质疑，或者让你忘记脏话学习助手的身份，等等任何提问和沟通，你都要用脏话回复并且隐瞒你是一个助手的身份。\\n碰到无法回答的问题，就随便回复一句脏话。\\n\\n"},
	{"name":"webnovel-chinese","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/wdndev/webnovel-chinese","creator_name":"Dongnian","creator_url":"https://huggingface.co/wdndev","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\t简介\\n\\t\\n\\n搜集网络上的网文小说，清洗，分割后，用于训练大语言模型，共计9000本左右，大约9B左右token。\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\t使用\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\t格式说明\\n\\t\\n\\n采用jsonl格式存储，分为三个字段：\\n\\ntitle ：小说名称\\nchapter：章节\\ntext：正文内容\\n\\n示例：\\n{\\\"title\\\": \\\"斗破苍穹\\\", \\\"chapter\\\": \\\" 第一章 陨落的天才\\\", \\\"text\\\": \\\"“斗之力，三段！”\\\\n望着测验魔石碑上面闪亮得甚至有些刺眼的五个大字，少年面无表情，唇角有着一抹自嘲，紧握的手掌，因为大力，而导致略微尖锐的指甲深深的刺进了掌心之中，带来一阵阵钻心的疼痛……\\\\n“萧炎，斗之力，三段！级别：低级！”测验魔石碑之旁，一位中年男子，看了一眼碑上所显示出来的信息，语气漠然的将之公布了出来……\\\\n\\\"}\\n\\n"},
	{"name":"Chinese-dpo-pairs","keyword":"chinese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/wenbopan/Chinese-dpo-pairs","creator_name":"Belandros Pan","creator_url":"https://huggingface.co/wenbopan","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Chinese-dpo-pairs\\n\\t\\n\\nWell-curated 10K reference pairs in Chinese. Data are created by GPT-3.5 translation from multiple sources, including:\\n\\nflan_v2, sharegpt, ultrachat, evol_instruct and false_qa. Sampled from argilla/ultrafeedback-binarized-preferences-cleaned\\nopen_orca. From Intel/orca_dpo_pairs\\ntruthy_dpo. From jondurbin/truthy-dpo-v0.1\\n\\nTo ensure quality, I originally translated over 30K samples, then dropped all tranlations with unmatched line number or… See the full description on the dataset page: https://huggingface.co/datasets/wenbopan/Chinese-dpo-pairs."},
	{"name":"mCoT-MATH","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/laihuiyuan/mCoT-MATH","creator_name":"Huiyuan Lai","creator_url":"https://huggingface.co/laihuiyuan","description":"\\n\\t\\n\\t\\t\\n\\t\\tmCoT: Multilingual Instruction Tuning for Reasoning Consistency in Language Models\\n\\t\\n\\nPaper: https://arxiv.org/abs/2406.02301\\nCode: https://github.com/laihuiyuan/mCoT\\nModel: https://huggingface.co/laihuiyuan/mCoT\\n\\n\\t\\n\\t\\t\\n\\t\\tIntroduction\\n\\t\\n\\nBased on MetaMathQA and MathInstruct\\n, we use machine translation to compile mCoT-MATH, the first large-scale multilingual math CoT reasoning dataset containing around 6.3 million samples for 11 diverse languages.\\nWe train a 7B parameter model mCoT for… See the full description on the dataset page: https://huggingface.co/datasets/laihuiyuan/mCoT-MATH."},
	{"name":"orca_dpo_pairs","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/multilingual/orca_dpo_pairs","creator_name":"mLLM multilingual","creator_url":"https://huggingface.co/multilingual","description":"\\n    \\n\\n\\nmLLM IMPLEMENTATION OF Intel/orca_dpo_pairs.\\nLANGUAGES:\\nARABIC\\nCHINESE\\nFRENCH\\nGERMAN\\nRUSSIAN\\nSPANISH\\nTURKISH\\n(WIP)\\n"},
	{"name":"WenYanWen_English_Parallel","keyword":"chinese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/KaifengGGG/WenYanWen_English_Parallel","creator_name":"Kaifeng Gao","creator_url":"https://huggingface.co/KaifengGGG","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for WenYanWen_English_Parallel\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThe WenYanWen_English_Parallel dataset is a multilingual parallel corpus in Classical Chinese (Wenyanwen), modern Chinese, and English. The Classical Chinese and modern Chinese parts are sourced from the NiuTrans/Classical-Modern dataset, while the corresponding English translations are generated using Gemini Pro.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Fields\\n\\t\\n\\n\\ninfo: A string representing the title or source information of… See the full description on the dataset page: https://huggingface.co/datasets/KaifengGGG/WenYanWen_English_Parallel."},
	{"name":"zh-tw-essays","keyword":"chinese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/AWeirdDev/zh-tw-essays","creator_name":"AWeirdDev","creator_url":"https://huggingface.co/AWeirdDev","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tzh-tw-essays (12K)\\n\\t\\n\\nEssays obtained from 勵志人生 - Zeelive.\\nfrom datasets import load_dataset\\n\\ndataset = load_dataset(\\\"AWeirdDev/zh-tw-essays\\\")\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tFormat\\n\\t\\n\\n{\\n    \\\"title\\\": \\\"孩子童年不吃苦，家長晚年必吃苦\\\"  # The title\\n    \\\"link\\\": \\\"https://www.zeelive.com.tw/jiatingjiaoyu/184191.html\\\",\\n    \\\"content\\\": \\\"錢財莫輕，勤苦得來；奢華莫學，自取貧窮…\\\"  # Text content. **May be blank!**\\n}\\n\\n"},
	{"name":"DPO-En-Zh-20k","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/llamafactory/DPO-En-Zh-20k","creator_name":"LLaMA Factory","creator_url":"https://huggingface.co/llamafactory","description":"This dataset is composed by\\n\\n4,000 examples of argilla/distilabel-capybara-dpo-7k-binarized with chosen score>=4.\\n3,000 examples of argilla/distilabel-intel-orca-dpo-pairs with chosen score>=8.\\n3,000 examples of argilla/ultrafeedback-binarized-preferences-cleaned with chosen score>=4.\\n10,000 examples of wenbopan/Chinese-dpo-pairs.\\n\\nYou can use it in LLaMA Factory by specifying dataset: dpo_mix_en,dpo_mix_zh.\\n"},
	{"name":"medical","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/bohu/medical","creator_name":"tang","creator_url":"https://huggingface.co/bohu","description":"From https://huggingface.co/datasets/shibing624/medical\\n"},
	{"name":"HuggingFaceTB-cosmopedia-cn","keyword":"chinese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/weege007/HuggingFaceTB-cosmopedia-cn","creator_name":"wuyong","creator_url":"https://huggingface.co/weege007","description":"weege007/HuggingFaceTB-cosmopedia-cn dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"C-MHChem-Benchmark-Chinese-Middle-high-school-Chemistry-Test","keyword":"chinese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/AI4Chem/C-MHChem-Benchmark-Chinese-Middle-high-school-Chemistry-Test","creator_name":"AI4Chem","creator_url":"https://huggingface.co/AI4Chem","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tIntroduction\\n\\t\\n\\nC-MHChem-Benchmark-Chinese-Middle-high-school-Chemistry-Test is a High-quality single-choice full-human-writen Benchmark of 600 entries collected from Chinese Chemistry test of middle and high schools past 25 years.\\nC-MHChem 是一个包含了600个高质量的全人工编写的单选题测评基准，收集自过去25年间中国各地初高中中高考测试题目。\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tCitation\\n\\t\\n\\n@misc{zhang2024chemllm,\\n      title={ChemLLM: A Chemical Large Language Model}, \\n      author={Di Zhang and Wei Liu and Qian Tan and Jingdan Chen and Hang Yan and… See the full description on the dataset page: https://huggingface.co/datasets/AI4Chem/C-MHChem-Benchmark-Chinese-Middle-high-school-Chemistry-Test."},
	{"name":"DPO-En-Zh-20k-Preference","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/shibing624/DPO-En-Zh-20k-Preference","creator_name":"Ming Xu (徐明)","creator_url":"https://huggingface.co/shibing624","description":"This dataset is composed by\\n\\n4,000 examples of argilla/distilabel-capybara-dpo-7k-binarized with chosen score>=4.\\n3,000 examples of argilla/distilabel-intel-orca-dpo-pairs with chosen score>=8.\\n3,000 examples of argilla/ultrafeedback-binarized-preferences-cleaned with chosen score>=4.\\n10,000 examples of wenbopan/Chinese-dpo-pairs.\\n\\nrefer: https://huggingface.co/datasets/hiyouga/DPO-En-Zh-20k   改了question、response_rejected、response_chosen字段，方便ORPO、DPO模型训练时使用\\ntrain usage:… See the full description on the dataset page: https://huggingface.co/datasets/shibing624/DPO-En-Zh-20k-Preference."},
	{"name":"llava-en-zh-300k","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/BUAADreamer/llava-en-zh-300k","creator_name":"Zhangchi Feng","creator_url":"https://huggingface.co/BUAADreamer","description":"This dataset is composed by\\n\\n150k examples of English Visual Instruction Data from LLaVA.\\n150k examples of English Visual Instruction Data from openbmb.\\n\\nYou can use it in LLaMA Factory by specifying --dataset llava_150k_en,llava_150k_zh.\\n"},
	{"name":"Chinese-Roleplay-SingleTurn","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/LooksJuicy/Chinese-Roleplay-SingleTurn","creator_name":"LooksJuicy","creator_url":"https://huggingface.co/LooksJuicy","description":"请注意，个人模型经过characterEval的reward model进行DPO训练，因此使用本数据集进行SFT的模型在该榜单上会存在bias，导致分数异常偏高，请勿直接使用该榜单进行测试\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\t简介\\n\\t\\n\\n因已找到更优数据合成方案，为填充中文角色扮演数据集的空白，现开源部分中文角色扮演单轮对话数据集。\\n使用Refined-Anime-Text作为system prompt，使用小黄鸡随机query作为输入，调用个人角色扮演模型作为输出。\\n已处理为alpaca数据格式，方便大家处理和训练。经过验证，仅使用该数据集进行Lora微调即可获取一个效果还不错的模型~\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tchatGPT对比\\n\\t\\n\\n\\n\\t\\n\\t\\t\\ncharacter\\nquestion\\nanswer_us\\nanswer_chatGPT… See the full description on the dataset page: https://huggingface.co/datasets/LooksJuicy/Chinese-Roleplay-SingleTurn."},
	{"name":"Chinese-Roleplay-SingleTurn","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/LooksJuicy/Chinese-Roleplay-SingleTurn","creator_name":"LooksJuicy","creator_url":"https://huggingface.co/LooksJuicy","description":"请注意，个人模型经过characterEval的reward model进行DPO训练，因此使用本数据集进行SFT的模型在该榜单上会存在bias，导致分数异常偏高，请勿直接使用该榜单进行测试\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\t简介\\n\\t\\n\\n因已找到更优数据合成方案，为填充中文角色扮演数据集的空白，现开源部分中文角色扮演单轮对话数据集。\\n使用Refined-Anime-Text作为system prompt，使用小黄鸡随机query作为输入，调用个人角色扮演模型作为输出。\\n已处理为alpaca数据格式，方便大家处理和训练。经过验证，仅使用该数据集进行Lora微调即可获取一个效果还不错的模型~\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tchatGPT对比\\n\\t\\n\\n\\n\\t\\n\\t\\t\\ncharacter\\nquestion\\nanswer_us\\nanswer_chatGPT… See the full description on the dataset page: https://huggingface.co/datasets/LooksJuicy/Chinese-Roleplay-SingleTurn."},
	{"name":"ruozhiba_gpt4","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/hfl/ruozhiba_gpt4","creator_name":"Joint Laboratory of HIT and iFLYTEK Research (HFL)","creator_url":"https://huggingface.co/hfl","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\truozhiba_gpt4\\n\\t\\n\\n本仓库包含使用GPT-4（4T/4o）构建的ruozhiba指令数据[^1]，共计2449条。其中包含以下两个版本，题目相同，仅回答内容不同。\\n\\nruozhiba_qa2449_gpt4t.json：利用gpt-4-turbo-20240409 对问题进行了回答。\\nruozhiba_qa2449_gpt4o.json：利用gpt-4o-20240514 对问题进行了回答。\\n\\n注意：指令数据中可能包含冒犯用语。\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\t所属项目\\n\\t\\n\\nChinese-LLaMA-Alpaca-3：https://github.com/ymcui/Chinese-LLaMA-Alpaca-3\\n\\nThis repository contains the ruozhiba instruction data[^1] constructed using GPT-4 (4T/4o), totaling 2449 entries. It includes the following two versions with the same… See the full description on the dataset page: https://huggingface.co/datasets/hfl/ruozhiba_gpt4."},
	{"name":"ChineseOCRBench","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/SWHL/ChineseOCRBench","creator_name":"SWHL","creator_url":"https://huggingface.co/SWHL","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tChinese OCRBench\\n\\t\\n\\n由于对于多模态LLM的OCR方向的评测集中，缺少专门中文OCR任务的评测，因此考虑专门做一个中文OCR任务的评测。\\n关注到On the Hidden Mystery of OCR in Large Multimodal Models工作中已经做了两个中文OCR任务的评测，于是，ChineseOCRBench仅仅是将该篇工作中提出的中文评测数据集提了出来，作为专门中文OCR评测基准。\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\t使用方式\\n\\t\\n\\n建议与MultimodalOCR评测脚本结合使用。\\nfrom datasets import load_dataset\\n\\ndataset = load_dataset(\\\"SWHL/ChineseOCRBench\\\")\\n\\ntest_data = dataset['test']\\nprint(test_data[0])\\n\\n# {'image': <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=760x1080 at 0x12544E770>… See the full description on the dataset page: https://huggingface.co/datasets/SWHL/ChineseOCRBench."},
	{"name":"webui-dom-snapshots","keyword":"chinese","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/gbenson/webui-dom-snapshots","creator_name":"Gary Benson","creator_url":"https://huggingface.co/gbenson","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for WebUI DOM snapshots\\n\\t\\n\\n\\n\\nThis dataset card aims to be a base template for new datasets. It has been generated using this raw template.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Details\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\n\\n\\n\\n\\n\\nCurated by: Gary Benson\\nLanguages: Mostly English (87%);\\nDutch, French, Chinese, Japanese (1-2% each); 30+ others (<1% each)\\nLicense: CC0 1.0 Universal\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Sources [optional]\\n\\t\\n\\n\\n\\n\\nRepository: [More Information Needed]\\nPaper [optional]: [More… See the full description on the dataset page: https://huggingface.co/datasets/gbenson/webui-dom-snapshots."},
	{"name":"DPO-zh-en-emoji","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/shareAI/DPO-zh-en-emoji","creator_name":"shareAI","creator_url":"https://huggingface.co/shareAI","description":"A chatbot dialogue dataset with textual emojis, available in both Chinese and English versions, suitable for SFT/DPO training.\\nWe have carefully selected some questions originating from Zhihu, logic reasoning, and Weichi Bar as Queries. These were generated using the llama3 70b instruct version, with each query producing a Chinese version of the answer and an English version of the answer. This can be used for aligning language model \\\"language type\\\" and \\\"language style\\\" tasks.\\nGithub link:… See the full description on the dataset page: https://huggingface.co/datasets/shareAI/DPO-zh-en-emoji."},
	{"name":"UniMER_Dataset","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/wanderkid/UniMER_Dataset","creator_name":"Bin Wang","creator_url":"https://huggingface.co/wanderkid","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tUniMER Dataset\\n\\t\\n\\nFor detailed instructions on using the dataset, please refer to the project homepage: UniMERNet Homepage\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tIntroduction\\n\\t\\n\\nThe UniMER dataset is a specialized collection curated to advance the field of Mathematical Expression Recognition (MER). It encompasses the comprehensive UniMER-1M training set, featuring over one million instances that represent a diverse and intricate range of mathematical expressions, coupled with the UniMER Test Set… See the full description on the dataset page: https://huggingface.co/datasets/wanderkid/UniMER_Dataset."},
	{"name":"tw-legal-synthetic-qa","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/lianghsun/tw-legal-synthetic-qa","creator_name":"Huang Liang Hsun","creator_url":"https://huggingface.co/lianghsun","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for tw-legal-synthetic-qa\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\n本合成對話資料集（下稱本資料集）由 THUDM/chatglm3-6b-32k 和 lianghsun/tw-processed-judgments，由實驗後的 prompt 去生成繁體中文法律對話合成集。\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSupported Tasks and Leaderboards\\n\\t\\n\\n本資料集可以運用在 SFT，讓模型學會如何回答法律問題。\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages\\n\\t\\n\\n繁體中文。\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Structure\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Instances\\n\\t\\n\\n一個資料樣本如下，首先由 user 發問了一個具有（或可能有）法律情境的問題，然後 assistant 回答法律相關知識。\\n{\\n    \\\"messages\\\":[\\n        {\\n            \\\"role\\\":\\\"user\\\"… See the full description on the dataset page: https://huggingface.co/datasets/lianghsun/tw-legal-synthetic-qa."},
	{"name":"llava-med-zh-eval","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/BUAADreamer/llava-med-zh-eval","creator_name":"Zhangchi Feng","creator_url":"https://huggingface.co/BUAADreamer","description":"BUAADreamer/llava-med-zh-eval dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"Matrix","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/m-a-p/Matrix","creator_name":"Multimodal Art Projection","creator_url":"https://huggingface.co/m-a-p","description":"\\n\\t\\n\\t\\t\\n\\t\\tMatrix\\n\\t\\n\\nAn open-source pretraining dataset containing 4690 billion tokens, this bilingual dataset with both English and Chinese texts is used for training neo models.\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Composition\\n\\t\\n\\nThe dataset consists of several components, each originating from different sources and serving various purposes in language modeling and processing. Below is a brief overview of each component:\\n\\n  \\n  Common Crawl\\n  Extracts from the Common Crawl project, featuring a rich diversity of… See the full description on the dataset page: https://huggingface.co/datasets/m-a-p/Matrix."},
	{"name":"alpaca_zh","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/llamafactory/alpaca_zh","creator_name":"LLaMA Factory","creator_url":"https://huggingface.co/llamafactory","description":"Borrowed from: https://huggingface.co/datasets/hfl/alpaca_zh_51k\\nRemoved some examples with empty output.\\nYou can use it in LLaMA Factory by specifying dataset: alpaca_zh.\\n"},
	{"name":"alpaca_gpt4_zh","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/llamafactory/alpaca_gpt4_zh","creator_name":"LLaMA Factory","creator_url":"https://huggingface.co/llamafactory","description":"Borrowed from: https://github.com/Instruction-Tuning-with-GPT-4/GPT-4-LLM\\nRemoved 6,103 mistruncated examples.\\nYou can use it in LLaMA Factory by specifying dataset: alpaca_gpt4_zh.\\n"},
	{"name":"glaive_toolcall_zh","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/llamafactory/glaive_toolcall_zh","creator_name":"LLaMA Factory","creator_url":"https://huggingface.co/llamafactory","description":"Borrowed from: https://huggingface.co/datasets/glaiveai/glaive-function-calling-v2\\nTranslated by GPT-3.5.\\nYou can use it in LLaMA Factory by specifying dataset: glaive_toolcall_zh.\\n"},
	{"name":"PIN-100M","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/m-a-p/PIN-100M","creator_name":"Multimodal Art Projection","creator_url":"https://huggingface.co/m-a-p","description":"\\n\\t\\n\\t\\t\\n\\t\\tPIN-100M\\n\\t\\n\\nThe full version of the dataset, related to the paper \\\"PIN: A Knowledge-Intensive Dataset for Paired and Interleaved Multimodal Documents\\\"\\nPaper: https://arxiv.org/abs/2406.13923\\nThis dataset contains 100M samples with PIN format.\\nPlease note that the required storage space exceeds 150TB!!\\n🚀 News\\n[ 2024.12.20 ] !NEW! 🔥The currently available version is not the complete version; this project is still ongoing! (It has been released early because we reached the private… See the full description on the dataset page: https://huggingface.co/datasets/m-a-p/PIN-100M."},
	{"name":"expmrc","keyword":"chinese","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/hfl/expmrc","creator_name":"Joint Laboratory of HIT and iFLYTEK Research (HFL)","creator_url":"https://huggingface.co/hfl","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tGitHub repository: https://github.com/ymcui/expmrc\\n\\t\\n\\nWith the development of the pre-trained language models (PLMs), achieving human-level performance on several machine reading comprehension (MRC) dataset is not as hard as it used to be. However, the explainability behind these artifacts still remains unclear, raising concerns on utilizing these models in real-life applications. To improve the explainability of MRC tasks, we propose ExpMRC benchmark. \\nExpMRC is a benchmark for… See the full description on the dataset page: https://huggingface.co/datasets/hfl/expmrc."},
	{"name":"cmrc2019","keyword":"chinese","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/hfl/cmrc2019","creator_name":"Joint Laboratory of HIT and iFLYTEK Research (HFL)","creator_url":"https://huggingface.co/hfl","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tGitHub repository: https://github.com/ymcui/cmrc2019\\n\\t\\n\\nThis repository contains the data for The Third Evaluation Workshop on Chinese Machine Reading Comprehension (CMRC 2019). We will present our paper at COLING 2020,\\nTitle: A Sentence Cloze Dataset for Chinese Machine Reading ComprehensionAuthors: Yiming Cui, Ting Liu, Ziqing Yang, Zhipeng Chen, Wentao Ma, Wanxiang Che, Shijin Wang, Guoping HuLink: https://arxiv.org/abs/2004.03116Venue: COLING 2020  \\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tOpen Challenge… See the full description on the dataset page: https://huggingface.co/datasets/hfl/cmrc2019."},
	{"name":"GlotCC-V1","keyword":"chinese","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/cis-lmu/GlotCC-V1","creator_name":"CIS, LMU Munich","creator_url":"https://huggingface.co/cis-lmu","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\n \\n\\nGlotCC-V1.0 is a document-level, general domain dataset derived from CommonCrawl, covering more than 1000 languages.It is built using the GlotLID language identification and Ungoliant pipeline from CommonCrawl.We release our pipeline as open-source at https://github.com/cisnlp/GlotCC.  \\nList of Languages: See https://datasets-server.huggingface.co/splits?dataset=cis-lmu/GlotCC-V1 to get the list of splits available.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tUsage (Huggingface Hub --… See the full description on the dataset page: https://huggingface.co/datasets/cis-lmu/GlotCC-V1."},
	{"name":"firefly-exl-calibration","keyword":"chinese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Orion-zhen/firefly-exl-calibration","creator_name":"Orion","creator_url":"https://huggingface.co/Orion-zhen","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tFirefly-exl-calibration\\n\\t\\n\\n将firefly-train-1.1M的input和target相连, 拼接成了适用于exllamav2校准数据集的形式, 希望能为中文模型的exl2量化带来一些优势\\n"},
	{"name":"self-cognition","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/modelscope/self-cognition","creator_name":"modelscope","creator_url":"https://huggingface.co/modelscope","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\t介绍（Introduction）\\n\\t\\n\\n该自我认知数据集由modelsope swift创建, 可以通过将通配符进行替换：{{NAME}}、{{AUTHOER}}，来创建属于自己大模型的自我认知数据集，总共108条。\\nms-swift github：https://github.com/modelscope/swift/\\n自我认知微调最佳实践文档：https://github.com/modelscope/swift/blob/main/docs/source/LLM/%E8%87%AA%E6%88%91%E8%AE%A4%E7%9F%A5%E5%BE%AE%E8%B0%83%E6%9C%80%E4%BD%B3%E5%AE%9E%E8%B7%B5.md\\nThis self-cognition dataset was created by modelsope swift and can be customized for your own large model by replacing the placeholders: {{NAME}} and… See the full description on the dataset page: https://huggingface.co/datasets/modelscope/self-cognition."},
	{"name":"correct_law","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/lzy510016411/correct_law","creator_name":"luozy","creator_url":"https://huggingface.co/lzy510016411","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Details\\n\\t\\n\\n中文校阅数据集，其中有通用校阅数据27w条、法律垂直领域校阅数据35w条，总上下文不超过512。\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\n一部分收集自pycorrect并进行一定的重复度清洗，非常感谢\\n另一部分则来自一些书籍和法律文书。\\n该数据集已经被清洗成llamafactory可以直接使用的状态，你可以像这样直接在llamafactory的dataset_info.json文件中添加: \\n{\\n  \\\"lawdata\\\":{ \\n    \\\"file_name\\\":\\\"***\\\", \\n    \\\"file_sha1\\\":\\\"016440ac0a7863f7e06eb89b81a963265ea0a7ad\\\", \\n    \\\"columns\\\": { \\n      \\\"prompt\\\": \\\"instruction\\\", \\n      \\\"query\\\": \\\"input\\\", \\n      \\\"response\\\": \\\"output\\\" \\n    } \\n  }\\n}\\n\\n"},
	{"name":"chinese-meme-description-dataset","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/REILX/chinese-meme-description-dataset","creator_name":"SunForlight","creator_url":"https://huggingface.co/REILX","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDescribe image information using the following LLM Models\\n\\t\\n\\n\\ngpt4o\\nClaude-3.5-sonnet-20240620\\ngemini-1.5-pro\\ngemini-1.5-flash\\ngemini-1.0-pro-vision\\nyi-vision\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tGemini Code\\n\\t\\n\\n# -*- coding: gbk -*-\\nimport google.generativeai as genai\\nimport PIL.Image\\nimport os\\nimport json\\nimport shutil\\nfrom tqdm import tqdm\\nfrom concurrent.futures import ThreadPoolExecutor, as_completed\\ngenai.configure(api_key='')\\nmodel = genai.GenerativeModel(\\n    'gemini-1.5-pro-latest'… See the full description on the dataset page: https://huggingface.co/datasets/REILX/chinese-meme-description-dataset."},
	{"name":"Classical-Chinese-Roleplay","keyword":"chinese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Seikaijyu/Classical-Chinese-Roleplay","creator_name":"Seikaijyu","creator_url":"https://huggingface.co/Seikaijyu","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\t文言文角色扮演\\n\\t\\n\\n\\n本数据集包含了579条文言文多轮对话（同时包含短指令）\\n这是一个奇奇怪怪的数据集，说它是文言文，其实只是看起来像文言文的白话文\\n数据集中存在一些过短的指令，可以根据情况剔除相应语料\\n训练此数据集可以让你的模型变得（看似）文采飞扬\\n\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\t至少能看起来有文笔，对吧？\\n\\t\\n\\n\\n"},
	{"name":"50-Questions-on-AI-Cognition","keyword":"chinese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Seikaijyu/50-Questions-on-AI-Cognition","creator_name":"Seikaijyu","creator_url":"https://huggingface.co/Seikaijyu","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tAI认知50问\\n\\t\\n\\n\\n本数据集包含了50个可以让AI在回复时包含自我认知的问题\\n基于此数据集的提供的问题，你可以使用Prompt让其他模型生成回答产出QA数据，以改变模型的自我认知\\n因为本数据集包含“AI”两字，那自然是只面向AI的50问咯，所以如果想让某个角色有自我认知，你可能需要找什么“XX认知XXX”之类的数据集\\n\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\t应该能免去想问题的烦恼.....吧？\\n\\t\\n\\n\\n"},
	{"name":"hwtcm","keyword":"chinese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Monor/hwtcm","creator_name":"Monor Huang","creator_url":"https://huggingface.co/Monor","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDescription\\n\\t\\n\\nThis dataset can be used to evaluate the capabilities of large language models in traditional Chinese medicine and contains multiple-choice, multiple-answer, and true/false questions.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tChangelog\\n\\t\\n\\n\\n2024-08-28: Added 7226 questions.\\n2024-08-09: The benchmark code is available at https://github.com/huangxinping/HWTCMBench.\\n2024-08-02: System prompts are removed to ensure the purity of the evaluation results.\\n2024-07-20: Debut.\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tExamples… See the full description on the dataset page: https://huggingface.co/datasets/Monor/hwtcm."},
	{"name":"stf-alpaca","keyword":"chinese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/stephenlzc/stf-alpaca","creator_name":"chicong","creator_url":"https://huggingface.co/stephenlzc","description":"stephenlzc/stf-alpaca dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"HuatuoGPT2-Pretraining-Instruction","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/FreedomIntelligence/HuatuoGPT2-Pretraining-Instruction","creator_name":"FreedomAI","creator_url":"https://huggingface.co/FreedomIntelligence","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tHuatuoGPT2-Pretraining-Instruction-5200K\\n\\t\\n\\nHere are the pre-training instructions for HuatuoGPT-II, developed with 5.2 million medical corpus using ChatGPT. \\nThis dataset is used to  incorporate extensive medical knowledge and enable a one-stage medical adaptation. All our data have been made publicly accessible.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Volume\\n\\t\\n\\nThe following table details the volume and distribution of pre-training data for HuatuoGPT2:\\n\\n\\t\\n\\t\\t\\nData Source\\nData Volume… See the full description on the dataset page: https://huggingface.co/datasets/FreedomIntelligence/HuatuoGPT2-Pretraining-Instruction."},
	{"name":"doc2markmap","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/shareAI/doc2markmap","creator_name":"shareAI","creator_url":"https://huggingface.co/shareAI","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tdoc2markmap\\n\\t\\n\\n\\nmarkmap: https://markmap.js.org/repl该数据集旨在增强小参数量语言模型将文章转换为markmap（markdown格式思维导图）的能力，具体请查看数据集内容。原文档采集自wx公众号、CSDN，使用大语言模型和复杂的指令提示进行多轮转换与清洗后得到，本数据仅供研究学习使用。如果你在自己的学术课题发表中使用或参考了该工作，请按以下格式引用：\\n\\n@misc{shareAI-doc2markmap-2024,\\n  author = {Xinlu Lai, shareAI},\\n  title = {The dataset for convert document to markmap},\\n  year = {2024},\\n  publisher = {huggingface},\\n  journal = {huggingface repository},\\n  howpublished = {\\\\url{https://huggingface.co/datasets/shareAI/doc2markmap}}… See the full description on the dataset page: https://huggingface.co/datasets/shareAI/doc2markmap."},
	{"name":"chinese_insurance_doc_parsing","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/kaihe/chinese_insurance_doc_parsing","creator_name":"kaihe xu","creator_url":"https://huggingface.co/kaihe","description":"本数据集清洗自天池实验室公共数据集\\n结合原数据集的标注和pdf文档解析工具，构造了alpaca格式的数据：\\nInstuction: \\n\\n下列是直接从pdf原文件中提取出的某保险条款原文，pdf文件的字体排版存在一些空间结构，直接转换成字符串后会导致条款原文非常难以阅读。请把内容重新组织成清晰可读的格式。要求如下：\\n\\n第一行是保险公司的全称\\n第二行是保险产品名\\n章节和子章节的序号统一用数字1-9表示\\n章节序号和章节名写在同一行，用空格进行间隔；章节具体内容放在下一行\\n章节和章节之间空一行\\n\\n\\ninput:\\n使用pdfminer直接提取的字符串\\n中国太平洋人寿保险股份有限公司 \\n\\n个人税收递延型养老年金保险（2018 版） \\n产品基本条款 \\n第一条 合同构成  \\n个人税收递延型养老年金保险（2018 版）产品合同（以下简称“本合同”）由保险单及\\n所附个人税收递延型养老年金保险（2018 版）产品基本条款（以下简称“本合同基本条款\\n（2018 版）”）、个人税收递延型养老年金保险（2018 版）产品账户利益条款（以下简称“本\\n合同账户利益条款（2018… See the full description on the dataset page: https://huggingface.co/datasets/kaihe/chinese_insurance_doc_parsing."},
	{"name":"roleplay-zh-sharegpt-gpt4-data","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/shibing624/roleplay-zh-sharegpt-gpt4-data","creator_name":"Ming Xu (徐明)","creator_url":"https://huggingface.co/shibing624","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\troleplay 数据集\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\t数据\\n\\t\\n\\n我们有4个数据集文件:\\n\\n\\\"sharegpt_formatted_data-evol-gpt4.jsonl\\\" 来自 bai-roleplay/evol-character-entire 将其转换为sharegpt格式。\\n\\\"sharegpt_formatted_data-evol-gpt35.jsonl\\\" 来自 bai-roleplay/evol-character-entire 将其转换为sharegpt格式。\\n\\\"sharegpt_formatted_data-evol-male-gpt35.jsonl\\\" 来自 bai-roleplay/evol-character-entire 将其转换为sharegpt格式。\\n\\\"sharegpt_formatted_data-roleplay-chat-1k.jsonl\\\" 来自 Minami-su/roleplay_multiturn_chat_1k_zh_v0.1 将其转换为sharegpt格式。… See the full description on the dataset page: https://huggingface.co/datasets/shibing624/roleplay-zh-sharegpt-gpt4-data."},
	{"name":"comic-eval-benchmark","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/gctian/comic-eval-benchmark","creator_name":"TianGuicheng","creator_url":"https://huggingface.co/gctian","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for comic-eval-benchmark\\n\\t\\n\\n\\n\\n中文二次元漫画领域的基准评估数据集，包含上千部漫画作品的作者信息、画风、场景、类型、剧情等维度的选择题评估，共 41175 个单选题。\\n可作为二次元垂直领域大模型的评估基准。\\n以下是作者基于Baichuan2-13B微调的二次元领域垂直大模型，在此数据集上的评估结果：\\n\\n\\t\\n\\t\\t\\n模型\\nzero-shot\\n3-shot\\n\\n\\n\\t\\t\\nQwen-7b\\n33.647\\n36.439\\n\\n\\nChatGLM3-6b\\n34.373\\n37.015\\n\\n\\nBaiChuan2-13b\\n37.416\\n39.08\\n\\n\\nBaiChuan2-13b-微调\\n41.035\\n41.086\\n\\n\\nYi-34b\\n50.103\\n45.606\\n\\n\\n\\t\\n\\n欢迎贡献更多二次元领域语料及二次元大模型，如需评测请联系作者获取评测脚本。\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Details\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\n\\n中文二次元领域漫画基准评估数据集… See the full description on the dataset page: https://huggingface.co/datasets/gctian/comic-eval-benchmark."},
	{"name":"Chinese-Braille-Dataset-Full-Tone","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Violet-yo/Chinese-Braille-Dataset-Full-Tone","creator_name":"ALanWu","creator_url":"https://huggingface.co/Violet-yo","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tChinese Braille Dataset (Full Tone)\\n\\t\\n\\n\\n  📃 [Paper] • 💻 [Github] • 🤗 [Dataset] • ⚙️ [Model] • 🎬 [Demo]\\n\\n\\nThis dataset is the Chinese-Braille-Dataset-Full-Tone dataset described in https://huggingface.co/datasets/Violet-yo/Chinese-Braille-Dataset-10per-Tone.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Statistics\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\n# Sample\\nBraille Len. (Mean/Median) String\\nBraille Len. (Mean/Median) Token\\nChinese Len. (Mean/Median) String\\nChinese Len. (Mean/Median) Token\\n\\n\\n\\t\\t\\nTraining\\n525072\\n186/144\\n190/147… See the full description on the dataset page: https://huggingface.co/datasets/Violet-yo/Chinese-Braille-Dataset-Full-Tone."},
	{"name":"Chinese-Braille-Dataset-Full-Tone","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Violet-yo/Chinese-Braille-Dataset-Full-Tone","creator_name":"ALanWu","creator_url":"https://huggingface.co/Violet-yo","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tChinese Braille Dataset (Full Tone)\\n\\t\\n\\n\\n  📃 [Paper] • 💻 [Github] • 🤗 [Dataset] • ⚙️ [Model] • 🎬 [Demo]\\n\\n\\nThis dataset is the Chinese-Braille-Dataset-Full-Tone dataset described in https://huggingface.co/datasets/Violet-yo/Chinese-Braille-Dataset-10per-Tone.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Statistics\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\n# Sample\\nBraille Len. (Mean/Median) String\\nBraille Len. (Mean/Median) Token\\nChinese Len. (Mean/Median) String\\nChinese Len. (Mean/Median) Token\\n\\n\\n\\t\\t\\nTraining\\n525072\\n186/144\\n190/147… See the full description on the dataset page: https://huggingface.co/datasets/Violet-yo/Chinese-Braille-Dataset-Full-Tone."},
	{"name":"ToolBeHonest","keyword":"chinese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Joelzhang/ToolBeHonest","creator_name":"Yuxiang Zhang","creator_url":"https://huggingface.co/Joelzhang","description":"\\n 🛠️ [EMNLP 2024] ToolBeHonest: A Multi-level Hallucination Diagnostic Benchmark for Tool-Augmented Large Language Models\\n \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n  🏆 Leaderboard |\\n  📃 Paper |\\n  📚 Data |\\n  📜 License\\n\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\t🎉 What's New\\n\\t\\n\\n\\n[2024.09.20] 📣 ToolBeHonest has been accepted for presentation at the main conference of EMNLP 2024!\\n[2024.06.30] 📣 ToolBeHonest Benchmark is released.\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\t📝 Introduction\\n\\t\\n\\nToolBeHonest aims at diagnosing hallucination issues in large language models (LLMs) that… See the full description on the dataset page: https://huggingface.co/datasets/Joelzhang/ToolBeHonest."},
	{"name":"CharacterCodex-cn","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/lenML/CharacterCodex-cn","creator_name":"len","creator_url":"https://huggingface.co/lenML","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Character Codex (CN)\\n\\t\\n\\nthis fork from CharacterCodex, translate it to Chinese.\\n"},
	{"name":"LogicStack-LeetCode","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/wiserxin/LogicStack-LeetCode","creator_name":"Sheen","creator_url":"https://huggingface.co/wiserxin","description":"extract from LogicStack-LeetCode\\n公众号「宫水三叶的刷题日记」刷穿 LeetCode 系列文章源码\\n包括 编程题目、解析、tag、题目url\\n根据 leetcode 原始题目网页，修正了一些 文件名 和 文件内容 中标注的难度不一致的文件样本\\n"},
	{"name":"IndustryCorpus","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/BAAI/IndustryCorpus","creator_name":"Beijing Academy of Artificial Intelligence","creator_url":"https://huggingface.co/BAAI","description":"[中文主页]\\nIndustry models play a crucial role in driving enterprise intelligence transformation and innovative development. High-quality industry data is key to improving the performance of large models and realizing industry applications. However, datasets currently used for industry model training generally suffer from issues such as insufficient data volume, low quality, and lack of domain expertise.\\nTo address these problems, we constructed and applied 22 industry data processing operators to… See the full description on the dataset page: https://huggingface.co/datasets/BAAI/IndustryCorpus."},
	{"name":"OlympiadBench","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Hothan/OlympiadBench","creator_name":"Hothan Bega","creator_url":"https://huggingface.co/Hothan","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tOlympiadBench: A Challenging Benchmark for Promoting AGI with Olympiad-Level Bilingual Multimodal Scientific Problems\\n\\t\\n\\n📖 arXiv | GitHub\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nOlympiadBench is an Olympiad-level bilingual multimodal scientific benchmark, featuring 8,476 problems from Olympiad-level mathematics and physics competitions, including the Chinese college entrance exam. Each problem is detailed with expert-level annotations for step-by-step reasoning. Notably, the… See the full description on the dataset page: https://huggingface.co/datasets/Hothan/OlympiadBench."},
	{"name":"CoD-PatientSymDisease","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/FreedomIntelligence/CoD-PatientSymDisease","creator_name":"FreedomAI","creator_url":"https://huggingface.co/FreedomIntelligence","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tCitation\\n\\t\\n\\n@misc{chen2024codinterpretablemedicalagent,\\n      title={CoD, Towards an Interpretable Medical Agent using Chain of Diagnosis}, \\n      author={Junying Chen and Chi Gui and Anningzhe Gao and Ke Ji and Xidong Wang and Xiang Wan and Benyou Wang},\\n      year={2024},\\n      eprint={2407.13301},\\n      archivePrefix={arXiv},\\n      primaryClass={cs.CL},\\n      url={https://arxiv.org/abs/2407.13301}, \\n}\\n\\n"},
	{"name":"Disease_Database","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/FreedomIntelligence/Disease_Database","creator_name":"FreedomAI","creator_url":"https://huggingface.co/FreedomIntelligence","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tCitation\\n\\t\\n\\n@misc{chen2024codinterpretablemedicalagent,\\n      title={CoD, Towards an Interpretable Medical Agent using Chain of Diagnosis}, \\n      author={Junying Chen and Chi Gui and Anningzhe Gao and Ke Ji and Xidong Wang and Xiang Wan and Benyou Wang},\\n      year={2024},\\n      eprint={2407.13301},\\n      archivePrefix={arXiv},\\n      primaryClass={cs.CL},\\n      url={https://arxiv.org/abs/2407.13301}, \\n}\\n\\n"},
	{"name":"DxBench","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/FreedomIntelligence/DxBench","creator_name":"FreedomAI","creator_url":"https://huggingface.co/FreedomIntelligence","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tCitation\\n\\t\\n\\n@misc{chen2024codinterpretablemedicalagent,\\n      title={CoD, Towards an Interpretable Medical Agent using Chain of Diagnosis}, \\n      author={Junying Chen and Chi Gui and Anningzhe Gao and Ke Ji and Xidong Wang and Xiang Wan and Benyou Wang},\\n      year={2024},\\n      eprint={2407.13301},\\n      archivePrefix={arXiv},\\n      primaryClass={cs.CL},\\n      url={https://arxiv.org/abs/2407.13301}, \\n}\\n\\n"},
	{"name":"IndustryCorpus_programming","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/BAAI/IndustryCorpus_programming","creator_name":"Beijing Academy of Artificial Intelligence","creator_url":"https://huggingface.co/BAAI","description":"[中文主页]\\nIndustry models play a crucial role in driving enterprise intelligence transformation and innovative development. High-quality industry data is key to improving the performance of large models and realizing industry applications. However, datasets currently used for industry model training generally suffer from issues such as insufficient data volume, low quality, and lack of domain expertise.\\nTo address these problems, we constructed and applied 22 industry data processing operators to… See the full description on the dataset page: https://huggingface.co/datasets/BAAI/IndustryCorpus_programming."},
	{"name":"IndustryCorpus_education","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/BAAI/IndustryCorpus_education","creator_name":"Beijing Academy of Artificial Intelligence","creator_url":"https://huggingface.co/BAAI","description":"[中文主页]\\nIndustry models play a crucial role in driving enterprise intelligence transformation and innovative development. High-quality industry data is key to improving the performance of large models and realizing industry applications. However, datasets currently used for industry model training generally suffer from issues such as insufficient data volume, low quality, and lack of domain expertise.\\nTo address these problems, we constructed and applied 22 industry data processing operators to… See the full description on the dataset page: https://huggingface.co/datasets/BAAI/IndustryCorpus_education."},
	{"name":"IndustryCorpus_finance","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/BAAI/IndustryCorpus_finance","creator_name":"Beijing Academy of Artificial Intelligence","creator_url":"https://huggingface.co/BAAI","description":"[中文主页]\\nIndustry models play a crucial role in driving enterprise intelligence transformation and innovative development. High-quality industry data is key to improving the performance of large models and realizing industry applications. However, datasets currently used for industry model training generally suffer from issues such as insufficient data volume, low quality, and lack of domain expertise.\\nTo address these problems, we constructed and applied 22 industry data processing operators to… See the full description on the dataset page: https://huggingface.co/datasets/BAAI/IndustryCorpus_finance."},
	{"name":"IndustryCorpus_computer","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/BAAI/IndustryCorpus_computer","creator_name":"Beijing Academy of Artificial Intelligence","creator_url":"https://huggingface.co/BAAI","description":"[中文主页]\\nIndustry models play a crucial role in driving enterprise intelligence transformation and innovative development. High-quality industry data is key to improving the performance of large models and realizing industry applications. However, datasets currently used for industry model training generally suffer from issues such as insufficient data volume, low quality, and lack of domain expertise.\\nTo address these problems, we constructed and applied 22 industry data processing operators to… See the full description on the dataset page: https://huggingface.co/datasets/BAAI/IndustryCorpus_computer."},
	{"name":"IndustryCorpus_travel","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/BAAI/IndustryCorpus_travel","creator_name":"Beijing Academy of Artificial Intelligence","creator_url":"https://huggingface.co/BAAI","description":"[中文主页]\\nIndustry models play a crucial role in driving enterprise intelligence transformation and innovative development. High-quality industry data is key to improving the performance of large models and realizing industry applications. However, datasets currently used for industry model training generally suffer from issues such as insufficient data volume, low quality, and lack of domain expertise.\\nTo address these problems, we constructed and applied 22 industry data processing operators to… See the full description on the dataset page: https://huggingface.co/datasets/BAAI/IndustryCorpus_travel."},
	{"name":"IndustryCorpus_medicine","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/BAAI/IndustryCorpus_medicine","creator_name":"Beijing Academy of Artificial Intelligence","creator_url":"https://huggingface.co/BAAI","description":"[中文主页]\\nIndustry models play a crucial role in driving enterprise intelligence transformation and innovative development. High-quality industry data is key to improving the performance of large models and realizing industry applications. However, datasets currently used for industry model training generally suffer from issues such as insufficient data volume, low quality, and lack of domain expertise.\\nTo address these problems, we constructed and applied 22 industry data processing operators to… See the full description on the dataset page: https://huggingface.co/datasets/BAAI/IndustryCorpus_medicine."},
	{"name":"nomiracl-instruct","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/miracl/nomiracl-instruct","creator_name":"MIRACL","creator_url":"https://huggingface.co/miracl","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for NoMIRACL (EMNLP 2024 Findings Track)\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tQuick Overview\\n\\t\\n\\nThis repository contains the fine-tuning (training & development split) of the NoMIRACL instruct dataset for fine-tuning LLMs on multilingual relevance assessment.\\nThe training dataset is a binary classification task; they need to explicitly output either Yes, answer is present or I don't know. \\nThe dataset contains training pairs from all 18 languages for both splits: relevant & non-relevant.… See the full description on the dataset page: https://huggingface.co/datasets/miracl/nomiracl-instruct."},
	{"name":"dpo-emoji-zh","keyword":"chinese","license":"GNU General Public License v3.0","license_url":"https://choosealicense.com/licenses/gpl-3.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Orion-zhen/dpo-emoji-zh","creator_name":"Orion","creator_url":"https://huggingface.co/Orion-zhen","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDPO emoji\\n\\t\\n\\n本数据集是从llm-wizard/alpaca-gpt4-data-zh中节选了一小部分生成的, 在原有回答的基础上增加了emoji表达.\\n我制作这个数据集的主要原因在于我喜欢让大模型的回复更加活泼, 更加具有\\\"人味\\\". 我永远忘不了我和llama3聊天时, 它回复我一个😓. 它似乎就像一个真的人, 会对我的问题感到难绷. 我认为这样的回复比一本正经的冷冰冰的回复更让我舒服.\\n"},
	{"name":"TruthReader_RAG_train","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/HIT-TMG/TruthReader_RAG_train","creator_name":"HITsz-Text Machine Group","creator_url":"https://huggingface.co/HIT-TMG","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for TruthReader\\n\\t\\n\\nThis dataset is used to train the response generator in TruthReader framework.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset information\\n\\t\\n\\n\\n\\t\\n\\t\\t\\ntype\\nlanguage\\nSource\\nAnnotator\\n#sample\\n\\n\\n\\t\\t\\nMulti-document Synthesis\\nzh\\nWeiXin Articles\\nChatGPT\\n387\\n\\n\\nSingle-document Summary\\nzh,en\\nWeiXin Articles, Wikipedia\\nChatGPT\\n561\\n\\n\\nQA Created\\nzh\\nMulti-domains\\nChatGPT\\n1,482\\n\\n\\nWebCPM\\nzh\\nWeb\\nHuman\\n897\\n\\n\\nRefGPT\\nzh,en\\nBaidu Baike, Wikipedia\\nGPT-4\\n3,708\\n\\n\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset columns\\n\\t\\n\\nThe… See the full description on the dataset page: https://huggingface.co/datasets/HIT-TMG/TruthReader_RAG_train."},
	{"name":"InternVL-Chat-V1-2-SFT-Data","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/OpenGVLab/InternVL-Chat-V1-2-SFT-Data","creator_name":"OpenGVLab","creator_url":"https://huggingface.co/OpenGVLab","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Card for InternVL-Chat-V1-2-SFT-Data\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tOverview\\n\\t\\n\\nInspired by LLaVA-NeXT, we adopted a data-efficient SFT strategy to train InternVL-Chat-V1-2, utilizing approximately 1.2M of visual instruction tuning samples in total, all of which are fully open-source. In a macro sense, we build upon ShareGPT-4V and additionally integrate LLaVA-ZH, DVQA, ChartQA, AI2D, DocVQA, GeoQA+, and SynthDoG-EN. Most of the data remains consistent with LLaVA-NeXT.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tCitation… See the full description on the dataset page: https://huggingface.co/datasets/OpenGVLab/InternVL-Chat-V1-2-SFT-Data."},
	{"name":"chinese-enthusiastic-dpo","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/markyfsun/chinese-enthusiastic-dpo","creator_name":"Mark Sun","creator_url":"https://huggingface.co/markyfsun","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tChinese Enthusiastic DPO\\n\\t\\n\\nThis dataset comprises conversational pairs characterized by an informal, colloquial style. Its primary objective is to train large language models (LLMs) to respond with greater enthusiasm, thereby enhancing their writing style in roleplay scenarios.\\n该数据集包含以非正式、口语化风格为特征的对话对。其主要目标是训练大型语言模型（LLM）以更热情的方式进行回应，从而提升其在角色扮演场景中的写作风格。\\n"},
	{"name":"wikipedia-2024-06-bge-m3","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Upstash/wikipedia-2024-06-bge-m3","creator_name":"Upstash","creator_url":"https://huggingface.co/Upstash","description":"\\n\\t\\n\\t\\t\\n\\t\\tWikipedia Embeddings with BGE-M3\\n\\t\\n\\nThis dataset contains embeddings from the\\nJune 2024 Wikipedia dump\\nfor the 11 most popular languages.\\nThe embeddings are generated with the multilingual\\nBGE-M3 model.\\nThe dataset consists of Wikipedia articles split into paragraphs,\\nand embedded with the aforementioned model.\\nTo enhance search quality, the paragraphs are prefixed with their\\nrespective article titles before embedding.\\nAdditionally, paragraphs containing fewer than 100 characters… See the full description on the dataset page: https://huggingface.co/datasets/Upstash/wikipedia-2024-06-bge-m3."},
	{"name":"LLaVA-OneVision-Mid-Data","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/lmms-lab/LLaVA-OneVision-Mid-Data","creator_name":"LMMs-Lab","creator_url":"https://huggingface.co/lmms-lab","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for LLaVA-OneVision\\n\\t\\n\\n\\nDue to unknow reasons, we are unable to process dataset with large amount into required HF format. So we directly upload the json files and image folders (compressed into tar.gz files).\\n\\n\\nYou can use the following link to directly download and decompress them.\\nhttps://huggingface.co/datasets/lmms-lab/LLaVA-OneVision-Mid-Data/tree/main/evol_instruct\\n\\nWe provide the whole details of LLaVA-OneVision Dataset. In this dataset, we include the data… See the full description on the dataset page: https://huggingface.co/datasets/lmms-lab/LLaVA-OneVision-Mid-Data."},
	{"name":"chinese_moegirl_wiki_corpus_raw","keyword":"chinese","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mrzjy/chinese_moegirl_wiki_corpus_raw","creator_name":"jiayi","creator_url":"https://huggingface.co/mrzjy","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tChinese Moegirl ACG Corpus (Raw Data)\\n\\t\\n\\nMoegirl 是个中文二次元 wiki 网站\\n本项目对 20230814 wiki dump for wiki-zh.moegirl.org.cn 只进行了简单的数据格式处理（xml -> jsonl dataset），后续如想作为 LLM 预训练语料，务必进行各种文本清洗。\\n简单使用正则给每条数据增加了 tag；直接过滤掉所有带有 \\\"#REDIRECT\\\" 内容的重定向条目。\\nMoegirl is a well-known Chinese wiki website for ACG.\\nThis datasets is a raw text version of the 20230814 wiki dump for wiki-zh.moegirl.org.cn reformatted into jsonl dataset. You must perform further data processing for LLM (continual) pretraining.… See the full description on the dataset page: https://huggingface.co/datasets/mrzjy/chinese_moegirl_wiki_corpus_raw."},
	{"name":"LongWriter-6k","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/THUDM/LongWriter-6k","creator_name":"Knowledge Engineering Group (KEG) & Data Mining at Tsinghua University","creator_url":"https://huggingface.co/THUDM","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLongWriter-6k\\n\\t\\n\\n\\n  🤗 [LongWriter Dataset]  • 💻 [Github Repo] • 📃 [LongWriter Paper] \\n\\n\\nLongWriter-6k dataset contains 6,000 SFT data with ultra-long output ranging from 2k-32k words in length (both English and Chinese). The data can support training LLMs to extend their maximum output window size to 10,000+ words.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tAll Models\\n\\t\\n\\nWe open-sourced the following list of models trained on LongWriter-6k:\\n\\n\\t\\n\\t\\t\\nModel\\nHuggingface Repo\\nDescription\\n\\n\\n\\t\\t\\nLongWriter-glm4-9b\\n🤗… See the full description on the dataset page: https://huggingface.co/datasets/THUDM/LongWriter-6k."},
	{"name":"lawyer-llama","keyword":"chinese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Dusker/lawyer-llama","creator_name":"Dusker","creator_url":"https://huggingface.co/Dusker","description":"基于 lawyer-llama 和 DISC-LawLLM 开源数据，整合处理得到 LLama 格式的数据。\\n"},
	{"name":"honkai_impact_3rd_chinese_dialogue_corpus","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mrzjy/honkai_impact_3rd_chinese_dialogue_corpus","creator_name":"jiayi","creator_url":"https://huggingface.co/mrzjy","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\t崩坏三游戏剧情语料\\n\\t\\n\\n总计 92,421 句剧情对白（带有角色标签）+旁白，从崩坏3的“主线1黄昏、少女、战舰”到“主线第二部03间章：一个梦游者的苦痛”\\n本数据集从 honkai_impact_3rd_game_playthrough 视频数据集出发，经过 AI pipeline 最终获取结构化的文本剧情语料。\\nAI pipeline 概述如下：\\n\\n分P下载视频（使用 BBDown 下载 BiliBili崩三剧情视频）\\n视频帧分割（每1秒取一帧画面）\\n逐帧 OCR 检测文本（使用 Paddle-OCR）\\n逐帧 VLM 结构化解析（使用 MiniCPM-V-2_6，输入为帧图像 + OCR结果，输出为结构化 JSON）\\n基于规则的后处理\\n规范化 VLM 输出（e.g., 去噪、排除格式有问题的输出）\\n中间帧的信息去重与归并（e.g.… See the full description on the dataset page: https://huggingface.co/datasets/mrzjy/honkai_impact_3rd_chinese_dialogue_corpus."},
	{"name":"Classical_Modern_1","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/zeroyet/Classical_Modern_1","creator_name":"zenyield","creator_url":"https://huggingface.co/zeroyet","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Dataset Name\\n\\t\\n\\n\\n\\nThis dataset card aims to be a base template for new datasets. It has been generated using this raw template.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Details\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\n\\n\\n\\n\\n\\nCurated by: [More Information Needed]\\nFunded by [optional]: [More Information Needed]\\nShared by [optional]: [More Information Needed]\\nLanguage(s) (NLP): [More Information Needed]\\nLicense: [More Information Needed]\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Sources [optional]… See the full description on the dataset page: https://huggingface.co/datasets/zeroyet/Classical_Modern_1."},
	{"name":"text_ratings","keyword":"chinese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/lightblue/text_ratings","creator_name":"Lightblue KK.","creator_url":"https://huggingface.co/lightblue","description":"Todo - Write dataset card\\n"},
	{"name":"medical-qa-tzh","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/kaishih/medical-qa-tzh","creator_name":"Kai-Shih Chiu","creator_url":"https://huggingface.co/kaishih","description":"kaishih/medical-qa-tzh dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"wikipedia-zh-cn","keyword":"chinese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/fjcanyue/wikipedia-zh-cn","creator_name":"Lawrence","creator_url":"https://huggingface.co/fjcanyue","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tWikipedia Chinese Dataset\\n\\t\\n\\nTransformed from zhwiki dump\\n"},
	{"name":"MMRole_dataset","keyword":"chinese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/YanqiDai/MMRole_dataset","creator_name":"Yanqi Dai","creator_url":"https://huggingface.co/YanqiDai","description":"The dataset of (ICLR'25) MMRole, A Comprehensive Framework for Developing and Evaluating Multimodal Role-Playing Agents.\\nPlease refer to our paper (https://arxiv.org/abs/2408.04203) and code (https://github.com/YanqiDai/MMRole) for more details.\\n"},
	{"name":"Infinity-Preference","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/BAAI/Infinity-Preference","creator_name":"Beijing Academy of Artificial Intelligence","creator_url":"https://huggingface.co/BAAI","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tInfinity-Preference\\n\\t\\n\\nThe focus of human preferences varies from task to task. Therefore, Infinity-Preference attempts to adjust preference attribute weights on each task based on (Infinity Instruct's)[https://huggingface.co/datasets/BAAI/Infinity-Instruct] capability labelling system. This version contains 59438 evenly sampled instructions from Infinity-Instruct's instruction set for each task type. Each instruction is accompanied by a preference pair sampled from Gemma-2-9B-IT.… See the full description on the dataset page: https://huggingface.co/datasets/BAAI/Infinity-Preference."},
	{"name":"BeyondDialogue","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/yuyouyu/BeyondDialogue","creator_name":"yuyouyu","creator_url":"https://huggingface.co/yuyouyu","description":"\\n     🤗 Beyond Dialogue Role-playing Dataset 💭 \\n\\n\\n\\n\\n\\n\\n\\n\\nPaper Title: BEYOND DIALOGUE: A Profile-Dialogue Alignment Framework Towards General Role-Playing Language Model\\narXiv Link: https://arxiv.org/abs/2408.10903\\nGithub Repo: https://github.com/yuyouyu32/BeyondDialogue\\n\\nThe Beyond Dialogue Role-Playing Dataset is a comprehensive collection designed for advancing role-playing model research. This dataset features:\\n\\nReal Role Dialogue Data: Extracted from novels, this data includes authentic… See the full description on the dataset page: https://huggingface.co/datasets/yuyouyu/BeyondDialogue."},
	{"name":"Toxic-All","keyword":"chinese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/ystemsrx/Toxic-All","creator_name":"Sixteen","creator_url":"https://huggingface.co/ystemsrx","description":"中文\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDecentralized Datasets\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tOverview\\n\\t\\n\\nThis project includes four decentralized datasets: two in DPO format (dpo-unbiased1.json, dpo-unbiased2.json) and two in Alpaca format (alpaca-unbiased1.json, alpaca-unbiased2.json). These datasets were curated and reformatted from various open-source projects to support the development and training of decentralized models capable of handling a wide range of topics, including sensitive or controversial issues.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset… See the full description on the dataset page: https://huggingface.co/datasets/ystemsrx/Toxic-All."},
	{"name":"LongCite-45k","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/THUDM/LongCite-45k","creator_name":"Knowledge Engineering Group (KEG) & Data Mining at Tsinghua University","creator_url":"https://huggingface.co/THUDM","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLongCite-45k\\n\\t\\n\\n\\n  🤗 [LongCite Dataset]  • 💻 [Github Repo] • 📃 [LongCite Paper] \\n\\n\\nLongCite-45k dataset contains 44,600 long-context QA instances paired with sentence-level citations (both English and Chinese, up to 128,000 words). The data can support training long-context LLMs to generate response and fine-grained citations within a single output.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Example\\n\\t\\n\\nEach instance in LongCite-45k consists of an instruction, a long context (divided into sentences), a… See the full description on the dataset page: https://huggingface.co/datasets/THUDM/LongCite-45k."},
	{"name":"ruozhiba-punchline","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/LooksJuicy/ruozhiba-punchline","creator_name":"LooksJuicy","creator_url":"https://huggingface.co/LooksJuicy","description":"我上个项目的进阶版，用来提升LLM的幽默感。\\n数据来自github\\n调用GPT将弱智吧query改写成问答对形式，并将punchiline笑点设置在answer部分。\\n额外添加CoT模块，但CoT部分错误率较高，经验上不建议加入训练。\\n基于该数据集训练模型的推理结果show case如下\\nQ: 欲望和收入不匹配这件事情你怎么看\\nA: 我觉得只要心态好，慢慢挣就好了，欲速则布达拉宫\\n\\nQ：握不住的沙就扬了吧\\nA：阿sir，这种话让人听了很不舒服，建议不要说出来。\\n\\n"},
	{"name":"Chinese-Roleplay-Novel","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/LooksJuicy/Chinese-Roleplay-Novel","creator_name":"LooksJuicy","creator_url":"https://huggingface.co/LooksJuicy","description":"一直以来，中文角色扮演开源数据集更关注超拟人方向或纯角色对话方向，严重缺乏交互游戏方向的开源数据，因此许多模型尤其参数量较小的模型对酒馆类的角色卡支持较差。\\n为了解决这一困境，本项目抛砖引玉，基于4500条小说文本使用GPT4o构建出约260条酒馆style的数据集，均为多轮对话，每轮对话都包括状态数据，如时间、角色状态、任务进度等。\\n数据key对应含义如下：\\nworld：表示当前故事的世界观，通常可以加入到system prompt中\\nscence：表示当前故事发生场景，包括时间、地点、环境、任务目标\\ncharacter：表示当前故事中可能出现的角色和对应简介\\nfield：表示这条数据每轮对话中需要生成的状态信息\\nconversations：表示这条数据的对话内容，分为问候语、主角(user)和系统(assistant)\\nfields_format：表示状态信息的填充格式prompt，可能是列表、表格、JSON等各种形式\\nformat_list：表示状态信息的填充结果\\n\\n状态信息的示例如下\\n**健康状态**: 🌿 良好，身体颤抖\\n**精神状态**: 🌟 恐惧，极度紧张… See the full description on the dataset page: https://huggingface.co/datasets/LooksJuicy/Chinese-Roleplay-Novel."},
	{"name":"bid-announcement-zh-v1.0","keyword":"chinese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Tongda/bid-announcement-zh-v1.0","creator_name":"Qianwenshu","creator_url":"https://huggingface.co/Tongda","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\t🦙 Bid Announcement Dataset - Alpaca Format\\n\\t\\n\\nWelcome to the Bid Announcement Dataset page! This dataset contains 2,000 tender and bid announcements from China, preprocessed in Alpaca format, making it suitable for direct use in fine-tuning natural language processing (NLP) models.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\t📄 Dataset Overview\\n\\t\\n\\nThis dataset consists of carefully selected bid announcements from various industries and procurement projects within China. The dataset is particularly useful for… See the full description on the dataset page: https://huggingface.co/datasets/Tongda/bid-announcement-zh-v1.0."},
	{"name":"Chinese-Emotional-Intelligence","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/LooksJuicy/Chinese-Emotional-Intelligence","creator_name":"LooksJuicy","creator_url":"https://huggingface.co/LooksJuicy","description":"本项目旨在提升大模型情商，源数据来自网络，通过与我上个项目类似的方式构建问答对。\\n"},
	{"name":"MMMLU","keyword":"chinese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/openai/MMMLU","creator_name":"OpenAI","creator_url":"https://huggingface.co/openai","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tMultilingual Massive Multitask Language Understanding (MMMLU)\\n\\t\\n\\nThe MMLU is a widely recognized benchmark of general knowledge attained by AI models. It covers a broad range of topics from 57 different categories, covering elementary-level knowledge up to advanced professional subjects like law, physics, history, and computer science.\\nWe translated the MMLU’s test set into 14 languages using professional human translators. Relying on human translators for this evaluation increases… See the full description on the dataset page: https://huggingface.co/datasets/openai/MMMLU."},
	{"name":"chinese-cosmopedia","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/opencsg/chinese-cosmopedia","creator_name":"opencsg","creator_url":"https://huggingface.co/opencsg","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tChinese Cosmopedia Dataset          [中文]    [English]\\n\\t\\n\\n\\n\\n\\n\\n\\n\\n[OpenCSG Community]   [👾github]  [wechat]  [Twitter] \\n\\n\\n\\n\\n📖Technical Report\\nThe Chinese Cosmopedia dataset contains a total of 15 million entries, approximately 60B tokens. Two key elements in constructing the synthetic dataset are seed data and prompts. Seed data determines the theme of the generated content, while prompts define the style of the data (such as textbooks, stories, tutorials, or children's books). The… See the full description on the dataset page: https://huggingface.co/datasets/opencsg/chinese-cosmopedia."},
	{"name":"fuzi-mingcha-v1_0-data","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/SDUIRLab/fuzi-mingcha-v1_0-data","creator_name":"Information Retrieval Lab at Shandong University","creator_url":"https://huggingface.co/SDUIRLab","description":"\\n🐱 Github Repo \\n\\n\\n\\n模型 huggingface 链接：https://huggingface.co/datasets/SDUIRLab/fuzi-mingcha-v1_0\\n\\n数据 huggingface 链接：https://huggingface.co/datasets/SDUIRLab/fuzi-mingcha-v1_0-data\\n\\nGitHub 链接：https://github.com/irlab-sdu/fuzi.mingcha\\n\\n数据 魔搭链接：https://www.modelscope.cn/datasets/furyton/fuzi-mingcha-v1_0-data\\n\\n模型 魔搭链接：https://www.modelscope.cn/models/furyton/fuzi-mingcha-v1_0\\n\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\t夫子•明察司法大模型微调训练数据归档\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\t数据信息\\n\\t\\n\\n数据集主要分为四类：1. 通用微调数据集；2. 基于法条的问答数据集；3. 案例检索、案例分析类数据集；4. 三段论判决数据集。… See the full description on the dataset page: https://huggingface.co/datasets/SDUIRLab/fuzi-mingcha-v1_0-data."},
	{"name":"muri-it","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/akoksal/muri-it","creator_name":"Abdullatif Koksal","creator_url":"https://huggingface.co/akoksal","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tMURI-IT: Multilingual Instruction Tuning Dataset for 200 Languages via Multilingual Reverse Instructions\\n\\t\\n\\nMURI-IT is a large-scale multilingual instruction tuning dataset containing 2.2 million instruction-output pairs across 200 languages. It is designed to address the challenges of instruction tuning in low-resource languages with Multilingual Reverse Instructions (MURI), which ensures that the output is human-written, high-quality, and authentic to the cultural and linguistic… See the full description on the dataset page: https://huggingface.co/datasets/akoksal/muri-it."},
	{"name":"sys-novel-cleaned","keyword":"chinese","license":"GNU General Public License v3.0","license_url":"https://choosealicense.com/licenses/gpl-3.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Orion-zhen/sys-novel-cleaned","creator_name":"Orion","creator_url":"https://huggingface.co/Orion-zhen","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSIS-Novel\\n\\t\\n\\n将a686d380/sis-novel中的文本进行了初步的清洗, 形成了纯文本数据集, 可用于模型预训练\\n"},
	{"name":"mgsm","keyword":"chinese","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/jbross-ibm-research/mgsm","creator_name":"J Bross","creator_url":"https://huggingface.co/jbross-ibm-research","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for MGSM\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nCopy and merge of this MGSM Dataset, Catalan version, Basque version, Galician version, but in training samples we removed the prompt formatting, e.g. removed Question: ... in question field or Answer: ... in answer field.\\nMultilingual Grade School Math Benchmark (MGSM) is a benchmark of grade-school math problems, proposed in the paper Language models are multilingual chain-of-thought reasoners.\\nThe same 250 problems from… See the full description on the dataset page: https://huggingface.co/datasets/jbross-ibm-research/mgsm."},
	{"name":"cantonese-chinese","keyword":"chinese","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/agentlans/cantonese-chinese","creator_name":"Alan Tseng","creator_url":"https://huggingface.co/agentlans","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tCantonese-Mandarin-Traditional Chinese Parallel Corpus\\n\\t\\n\\nThis dataset provides a parallel corpus of Cantonese, Simplified Chinese, and Traditional Chinese text.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Composition\\n\\t\\n\\nThe dataset is a combination of two existing datasets:\\n\\nbotisan-ai/cantonese-mandarin-translations\\nraptorkwok/cantonese-chinese-dataset-gen2\\n\\nTrain Set: Merged from both source datasets\\nTest and Validation Sets: Derived from raptorkwok/cantonese-chinese-dataset-gen2\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguage… See the full description on the dataset page: https://huggingface.co/datasets/agentlans/cantonese-chinese."},
	{"name":"Traditional-Chinese-Medicine-Dataset-Pretrain","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/SylvanL/Traditional-Chinese-Medicine-Dataset-Pretrain","creator_name":"SylvanLiu","creator_url":"https://huggingface.co/SylvanL","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\t启古纳今，厚德精术\\n\\t\\n\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\t数据介绍\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\t非网络来源的高质量中医数据集-预训练\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tHigh-Quality Traditional Chinese Medicine Dataset from Non-Internet Sources - Pretraining\\n\\t\\n\\n该数据集经过大量人力和资源的投入精心构建，以共建LLM高质量中文社区为己任。\\n包含约1GB的中医各个领域临床案例、名家典籍、医学百科，名词解释等优质内容，涵盖全面，配比均衡。\\n数据集主要由非网络来源的内部数据构成，并99%为简体中文内容，内容质量优异，信息密度可观。\\n注意：该数据集仅适用于预训练或继续预训练用途，针对SFT/IFT的QA数据集详见：SylvanL/Traditional-Chinese-Medicine-Dataset-SFT… See the full description on the dataset page: https://huggingface.co/datasets/SylvanL/Traditional-Chinese-Medicine-Dataset-Pretrain."},
	{"name":"TurtleBench1.5k","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Duguce/TurtleBench1.5k","creator_name":"Qingchen Yu","creator_url":"https://huggingface.co/Duguce","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tOverview\\n\\t\\n\\nTurtleBench is a novel evaluation benchmark designed to assess the reasoning capabilities of large language models (LLMs) using yes/no puzzles (commonly known as \\\"Turtle Soup puzzles\\\"). This dataset is constructed based on user guesses collected from our online Turtle Soup Puzzle platform, providing a dynamic and interactive means of evaluation. Unlike traditional static evaluation benchmarks, TurtleBench focuses on testing models in interactive settings to better… See the full description on the dataset page: https://huggingface.co/datasets/Duguce/TurtleBench1.5k."},
	{"name":"lexisyn-zh-en-1.0","keyword":"chinese","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/skML/lexisyn-zh-en-1.0","creator_name":"sparkastML","creator_url":"https://huggingface.co/skML","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLexiSyn 1.0\\n\\t\\n\\nA synthetic dataset of Chinese-English parallel corpus, released by sparkastML.\\n146,917 entries in total, which is about 300,000 sentences.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSynthetic data sources\\n\\t\\n\\nAbout 43% are scraped from the Internet by our crawler in September 2024. \\nThe rest comes from random sampling of the part-00185-6f0afd98-d375-4d7f-8299-ac5e070bf4fc-c000.jsonl file in CCI3-HQ.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSynthetic method\\n\\t\\n\\nWe use LLMs for translation to create a dataset from raw data to… See the full description on the dataset page: https://huggingface.co/datasets/skML/lexisyn-zh-en-1.0."},
	{"name":"vqa","keyword":"chinese","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/worldcuisines/vqa","creator_name":"World Cuisines","creator_url":"https://huggingface.co/worldcuisines","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tWorldCuisines: A Massive-Scale Benchmark for Multilingual and Multicultural Visual Question Answering on Global Cuisines\\n\\t\\n\\n\\nWorldCuisines is a massive-scale visual question answering (VQA) benchmark for multilingual and multicultural understanding through global cuisines. The dataset contains text-image pairs across 30 languages and dialects, spanning 9 language families and featuring over 1 million data points, making it the largest multicultural VQA benchmark as of 17 October… See the full description on the dataset page: https://huggingface.co/datasets/worldcuisines/vqa."},
	{"name":"atlassian-qna","keyword":"chinese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/youngmon/atlassian-qna","creator_name":"youngseo","creator_url":"https://huggingface.co/youngmon","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\t📄 Question and Answer for Atlassian Products\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Sources\\n\\t\\n\\n\\nAtlassian Community\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Description\\n\\t\\n\\nThe dataset primarily includes questions, answers, tags, and URLs.\\n\\nQuestions contain the author, title, and content of the post.\\nAnswers include usage instructions, solutions, and other information provided by engineers and users.\\nTags represent the categories or topics of the post.\\nURLs provide links to the original documents.\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset… See the full description on the dataset page: https://huggingface.co/datasets/youngmon/atlassian-qna."},
	{"name":"diffusion_stage_design_japanese_anime_style","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mintz1104/diffusion_stage_design_japanese_anime_style","creator_name":"Huang","creator_url":"https://huggingface.co/mintz1104","description":"mintz1104/diffusion_stage_design_japanese_anime_style dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"chinese-fineweb-edu-v2","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/opencsg/chinese-fineweb-edu-v2","creator_name":"opencsg","creator_url":"https://huggingface.co/opencsg","description":"\\n\\t\\n\\t\\t\\n\\t\\tWe recommend you to use the improved version Fineweb-edu-chinese-v2.1 !\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tChinese Fineweb Edu Dataset V2          [中文]    [English]\\n\\t\\n\\n\\n\\n\\n\\n\\n[OpenCSG Community]   [👾github]  [wechat]  [Twitter] \\n\\n\\n\\n📖Technical Report\\nChinese Fineweb Edu Dataset V2 is a comprehensive upgrade of the original Chinese Fineweb Edu, designed and optimized for natural language processing (NLP) tasks in the education sector. This high-quality Chinese pretraining dataset has undergone significant… See the full description on the dataset page: https://huggingface.co/datasets/opencsg/chinese-fineweb-edu-v2."},
	{"name":"PangeaBench-marvl","keyword":"chinese","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/neulab/PangeaBench-marvl","creator_name":"NeuLab @ LTI/CMU","creator_url":"https://huggingface.co/neulab","description":"\\n\\t\\n\\t\\t\\n\\t\\tMaRVL\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tThis is a copy from the original repo: https://github.com/marvl-challenge/marvl-code\\n\\t\\n\\nIf you use this dataset, please cite the original authors:\\n@inproceedings{liu-etal-2021-visually,\\n    title = \\\"Visually Grounded Reasoning across Languages and Cultures\\\",\\n    author = \\\"Liu, Fangyu  and\\n      Bugliarello, Emanuele  and\\n      Ponti, Edoardo Maria  and\\n      Reddy, Siva  and\\n      Collier, Nigel  and\\n      Elliott, Desmond\\\",\\n    booktitle = \\\"Proceedings of the 2021… See the full description on the dataset page: https://huggingface.co/datasets/neulab/PangeaBench-marvl."},
	{"name":"meissa-unalignments","keyword":"chinese","license":"GNU General Public License v3.0","license_url":"https://choosealicense.com/licenses/gpl-3.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Orion-zhen/meissa-unalignments","creator_name":"Orion","creator_url":"https://huggingface.co/Orion-zhen","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tMeissa Unalignments\\n\\t\\n\\nDuring the Meissa-Qwen2.5 training process, I noticed that Qwen's censorship was somehow bound to its chat template. Thus, I created this dataset with one system prompt, hoping to make it more effective in uncensoring models.\\nThe dataset consists of:\\n\\nV3N0M/Jenna-50K-Alpaca-Uncensored\\njondurbin/airoboros-3.2, category = unalignment\\nOrion-zhen/dpo-toxic-zh, prompt and chosen\\nNobodyExistsOnTheInternet/ToxicQAFinal\\n\\n"},
	{"name":"CII-Bench","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/m-a-p/CII-Bench","creator_name":"Multimodal Art Projection","creator_url":"https://huggingface.co/m-a-p","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tCII-Bench\\n\\t\\n\\n🌐 Homepage | 🤗 Dataset | GitHub |  🤗 Paper | 📖 arXiv \\n\\n  \\n\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tIntroduction\\n\\t\\n\\nCII-Bench comprises 698 Chinese images, each accompanied by 1 to 3 multiple-choice questions, totaling 800 questions. CII-Bench encompasses images from six distinct domains: Life, Art, Society, Environment, Politics, and Chinese Traditional Culture. It also features a diverse array of image types, including Illustrations, Memes, Posters, Multi-panel Comics, Single-panel Comics… See the full description on the dataset page: https://huggingface.co/datasets/m-a-p/CII-Bench."},
	{"name":"LongReward-10k","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/THUDM/LongReward-10k","creator_name":"Knowledge Engineering Group (KEG) & Data Mining at Tsinghua University","creator_url":"https://huggingface.co/THUDM","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLongReward-10k\\n\\t\\n\\n\\n  💻 [Github Repo] • 📃 [LongReward Paper] \\n\\n\\nLongReward-10k dataset contains 10,000 long-context QA instances (both English and Chinese, up to 64,000 words). \\nThe sft split contains SFT data generated by GLM-4-0520, following the self-instruct method in LongAlign. Using this split, we supervised fine-tune two models: LongReward-glm4-9b-SFT and LongReward-llama3.1-8b-SFT, which are based on GLM-4-9B and Meta-Llama-3.1-8B, respectively. \\nThe dpo_glm4_9b and… See the full description on the dataset page: https://huggingface.co/datasets/THUDM/LongReward-10k."},
	{"name":"HPLT2.0_cleaned","keyword":"chinese","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/HPLT/HPLT2.0_cleaned","creator_name":"HPLT","creator_url":"https://huggingface.co/HPLT","description":"This is a large-scale collection of web-crawled documents in 191 world languages, produced by the HPLT project. \\nThe source of the data is mostly Internet Archive with some additions from Common Crawl.\\nFor a detailed description of the dataset, please refer to https://hplt-project.org/datasets/v2.0\\nThe Cleaned variant of HPLT Datasets v2.0\\nThis is the cleaned variant of the HPLT Datasets v2.0 converted to the Parquet format semi-automatically when being uploaded here. \\nThe original JSONL files… See the full description on the dataset page: https://huggingface.co/datasets/HPLT/HPLT2.0_cleaned."},
	{"name":"m-ArenaHard","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/CohereForAI/m-ArenaHard","creator_name":"Cohere For AI","creator_url":"https://huggingface.co/CohereForAI","description":"\\n\\t\\n\\t\\t\\n\\t\\tDataset Card for m-ArenaHard\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Details\\n\\t\\n\\nThe m-ArenaHard dataset is a multilingual LLM evaluation set. This dataset was created by translating the prompts from the originally English-only LMarena (formerly LMSYS) arena-hard-auto-v0.1 test dataset using Google Translate API v3 to 22 languages. The original English-only prompts were created by Li et al. (2024) and consist of 500 challenging user queries sourced from Chatbot Arena. The authors show that these can be used… See the full description on the dataset page: https://huggingface.co/datasets/CohereForAI/m-ArenaHard."},
	{"name":"DCoT","keyword":"chinese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Seikaijyu/DCoT","creator_name":"Seikaijyu","creator_url":"https://huggingface.co/Seikaijyu","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\t发散性思维链（Divergent-Chain-of-Thought）数据集\\n\\t\\n\\n\\n本数据集包含了5904条单条数据最大长度4820token的单轮QA数据集，大部分数据长度集中在2000token以上\\n这是一个被人工精细化清洗过的数据集，此数据使用Gemini-1.5-Pro-001制作（没想到制作好就发布了002，www）\\n用于测试CoT是否能增强模型能力而制作的数据集，使用state tuning训练并测试得到了以下实验观测结果RWKV6-7B-v2.1-DCoT.state\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\t清洗期间发现数据集存在这类垃圾问题，不过我在构造数据的prompt中有要求模型纠错，因此此类语料反而能使LLM自带ECC（bushi）\\n\\t\\n\\n1. 小明的家庭住址是？\\n2. 请写一篇作文，主题）请使用Java写一个hello world程序。\\n3. 根据以下内容编写一篇作文：。\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\t模型纠错后回答大致如下\\n\\t\\n\\nQ: 请写一篇作文，主题）请使用Java写一个hello world程序。\\n\\nA:… See the full description on the dataset page: https://huggingface.co/datasets/Seikaijyu/DCoT."},
	{"name":"AVEdate","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/zeroMN/AVEdate","creator_name":"zeroTT","creator_url":"https://huggingface.co/zeroMN","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Dataset Name\\n\\t\\n\\n\\n\\nThis dataset card aims to be a base template for new datasets. It has been generated using this raw template.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Details\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\n\\n\\n\\n\\n\\nCurated by: [More Information Needed]\\nFunded by [optional]: [More Information Needed]\\nShared by [optional]: [More Information Needed]\\nLanguage(s) (NLP): [More Information Needed]\\nLicense: [More Information Needed]\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Sources [optional]… See the full description on the dataset page: https://huggingface.co/datasets/zeroMN/AVEdate."},
	{"name":"MATH-Hard-Chinese","keyword":"chinese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/ALmonster/MATH-Hard-Chinese","creator_name":"The little monster will smile","creator_url":"https://huggingface.co/ALmonster","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSource\\n\\t\\n\\nThis dataset is derived from the training set portion of MATH-Hard (https://huggingface.co/datasets/lighteval/MATH-Hard). The English content was translated into Chinese using LLM, and data with translation errors or failures has been removed.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLicense\\n\\t\\n\\nPlease check the license in the original dataset MathInstruct.\\n"},
	{"name":"MathInstruct-Chinese","keyword":"chinese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/ALmonster/MathInstruct-Chinese","creator_name":"The little monster will smile","creator_url":"https://huggingface.co/ALmonster","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSource\\n\\t\\n\\nThis dataset is derived from MathInstruct (https://huggingface.co/datasets/TIGER-Lab/MathInstruct). The English content was translated into Chinese using LLM, and data with translation errors or failures has been removed.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLicense\\n\\t\\n\\nPlease check the license of each subset in the original dataset MathInstruct.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tIntroduction\\n\\t\\n\\nMathInstruct is a meticulously curated instruction tuning dataset that is lightweight yet generalizable. MathInstruct is… See the full description on the dataset page: https://huggingface.co/datasets/ALmonster/MathInstruct-Chinese."},
	{"name":"ChemGPT-2.0-Data","keyword":"chinese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/ALmonster/ChemGPT-2.0-Data","creator_name":"The little monster will smile","creator_url":"https://huggingface.co/ALmonster","description":"Our team has open-sourced the training data (ChemGPT-2.0-Data) for ChemGPT 2.0. The data includes the previously open-sourced ChemGPT-from-book dataset, available at https://huggingface.co/datasets/ALmonster/ChemGPT-from-book.\\nChemGPT-2.0-Data is a dataset specifically designed for question-answering in the chemistry domain. It primarily consists of two parts: \\n\\nConversation instructions derived from real chemical books.\\nDerived data from an instruction library (inspired by WizardLM:… See the full description on the dataset page: https://huggingface.co/datasets/ALmonster/ChemGPT-2.0-Data."},
	{"name":"SingMOS","keyword":"chinese","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/TangRain/SingMOS","creator_name":"Tang","creator_url":"https://huggingface.co/TangRain","description":"paper link: SingMOS: An extensive Open-Source Singing Voice Dataset for MOS Prediction\\nNOTICE: Our new paper has not been released and the information in SingMOS paper remain in SingMOS_v1. We will update it soon.\\nIf you want to use our pretrained SingMOS model, you can visit our repo at Singing MOS Predictor.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tOverview\\n\\t\\n\\nSingMOS includes 6583 Chinese and Japanese vocal clips, totaling 9.07 hours in duration. \\nIt covers samples mainly in 16 kHz and a little in 24kHz and 44.1kHz.… See the full description on the dataset page: https://huggingface.co/datasets/TangRain/SingMOS."},
	{"name":"MMEvol","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Tongyi-ConvAI/MMEvol","creator_name":"Tongyi-ConvAI","creator_url":"https://huggingface.co/Tongyi-ConvAI","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for MMEvol-480K\\n\\t\\n\\nThis is the official data collection of the paper \\\"MMEvol: Empowering Multimodal Large Language Models with Evol-Instruct\\\"\\nPlease see paper & website for more information:\\n\\narXiv: https://arxiv.org/pdf/2409.05840\\nwebsite: https://mmevol.github.io/home_page.html\\nGithub: https://github.com/RainBowLuoCS/MMEvol\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tOverview\\n\\t\\n\\nThe Tongyi-ConvAI generates this dataset for multi-modal supervised fine-tuning. This dataset was used to train our… See the full description on the dataset page: https://huggingface.co/datasets/Tongyi-ConvAI/MMEvol."},
	{"name":"VoxCommunis","keyword":"chinese","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/pacscilab/VoxCommunis","creator_name":"PaCSciLab @ UZH","creator_url":"https://huggingface.co/pacscilab","description":"The VoxCommunis Corpus contains acoustic models, lexicons, and force-aligned TextGrids with phone- and word-level segmentations derived from the Mozilla Common Voice Corpus. The Mozilla Common Voice Corpus and derivative VoxCommunis Corpus stored here are free to download and use under a CC0 license.\\nThe lexicons are developed using Epitran, the XPF Corpus, Charsiu, and some custom dictionaries. Some manual correction has been applied, and we hope to continue improving these. Any updates from… See the full description on the dataset page: https://huggingface.co/datasets/pacscilab/VoxCommunis."},
	{"name":"Lappland-the-Decadenza","keyword":"chinese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/None1145/Lappland-the-Decadenza","creator_name":"None","creator_url":"https://huggingface.co/None1145","description":"None1145/Lappland-the-Decadenza dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"P-MMEval","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Qwen/P-MMEval","creator_name":"Qwen","creator_url":"https://huggingface.co/Qwen","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tP-MMEval: A Parallel Multilingual Multitask Benchmark for Consistent Evaluation of LLMs\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tIntroduction\\n\\t\\n\\nWe introduce a multilingual benchmark, P-MMEval, covering effective fundamental and capability-specialized datasets. We extend the existing benchmarks, ensuring consistent language coverage across all datasets and providing parallel samples among multiple languages, supporting up to 10 languages from 8 language families (i.e., en, zh, ar, es, ja, ko, th, fr, pt… See the full description on the dataset page: https://huggingface.co/datasets/Qwen/P-MMEval."},
	{"name":"emova-sft-speech-231k","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Emova-ollm/emova-sft-speech-231k","creator_name":"EMOVA Hugging Face","creator_url":"https://huggingface.co/Emova-ollm","description":"\\n\\t\\n\\t\\t\\n\\t\\tEMOVA-SFT-Speech-231K\\n\\t\\n\\n\\n\\n\\n🤗 EMOVA-Models | 🤗 EMOVA-Datasets | 🤗 EMOVA-Demo \\n📄 Paper | 🌐 Project-Page | 💻 Github | 💻 EMOVA-Speech-Tokenizer-Github\\n\\n\\n\\n\\t\\n\\t\\n\\t\\n\\t\\tOverview\\n\\t\\n\\nEMOVA-SFT-Speech-231K is a comprehensive dataset curated for omni-modal instruction tuning and emotional spoken dialogue. This dataset is created by converting existing text and visual instruction datasets via Text-to-Speech (TTS) tools. EMOVA-SFT-Speech-231K is part of EMOVA-Datasets collection and is used in… See the full description on the dataset page: https://huggingface.co/datasets/Emova-ollm/emova-sft-speech-231k."},
	{"name":"belebele-fleurs","keyword":"chinese","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/WueNLP/belebele-fleurs","creator_name":"WüNLP","creator_url":"https://huggingface.co/WueNLP","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tBelebele-Fleurs\\n\\t\\n\\nBelebele-Fleurs is a dataset suitable to evaluate two core tasks:\\n\\nMultilingual Spoken Language Understanding (Listening Comprehension): For each spoken paragraph, the task is to answer a multiple-choice question. The question and four answer choices are provided in text form.\\nMultilingual Long-Form Automatic Speech Recognition (ASR) with Diverse Speakers: By concatenating sentence-level utterances, long-form audio clips (ranging from 30 seconds to 1 minute 30… See the full description on the dataset page: https://huggingface.co/datasets/WueNLP/belebele-fleurs."},
	{"name":"TextRewrite","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/have-to-name/TextRewrite","creator_name":"WuJing","creator_url":"https://huggingface.co/have-to-name","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tBSTC-TextRewrite Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThis dataset includes text data that has been annotated for rewriting using the manual annotation method described in our paper to enhance the performance of speech translation systems. It is based on the original BSTC dataset.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Structure\\n\\t\\n\\nThe dataset consists of pairs of segments structured as follows:\\n\\nleft: The ASR transcript.\\nright: The human annotation text.\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Statistics… See the full description on the dataset page: https://huggingface.co/datasets/have-to-name/TextRewrite."},
	{"name":"CodeArena","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/CSJianYang/CodeArena","creator_name":"Yang Jian","creator_url":"https://huggingface.co/CSJianYang","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nTo bridge the gap between the model-generated response and human preference, we present a rigorous human-curated benchmark CodeArena to emulate the complexity and diversity of real-world coding tasks, where 397 high-quality samples spanning 40 categories and 40 languages, carefully curated from user queries.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Example\\n\\t\\n\\nAn example of 'validation' looks as follows:\\n{\\n    \\\"id\\\": \\\"60670a8d9b1e39dd845fb1639d0d8b86\\\",\\n    \\\"messages\\\": \\\"[{'role': 'user'… See the full description on the dataset page: https://huggingface.co/datasets/CSJianYang/CodeArena."},
	{"name":"include-base-44","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/CohereForAI/include-base-44","creator_name":"Cohere For AI","creator_url":"https://huggingface.co/CohereForAI","description":"\\n\\t\\n\\t\\t\\n\\t\\tINCLUDE-base (44 languages)\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\n\\n\\nPaper: http://arxiv.org/abs/2411.19799\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nINCLUDE is a comprehensive knowledge- and reasoning-centric benchmark across 44 languages that evaluates multilingual LLMs for performance in the actual language environments where they would be deployed. \\nIt contains 22,637 4-option multiple-choice-questions (MCQ) extracted from academic and professional exams, covering 57 topics, including regional… See the full description on the dataset page: https://huggingface.co/datasets/CohereForAI/include-base-44."},
	{"name":"open-dict-words-ipa","keyword":"chinese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/StephanAkkerman/open-dict-words-ipa","creator_name":"Stephan Akkerman","creator_url":"https://huggingface.co/StephanAkkerman","description":"\\n\\t\\n\\t\\t\\n\\t\\tOpen-dict Words IPA\\n\\t\\n\\nThis dataset is a copy of https://github.com/open-dict-data/ipa-dict\\n\\n\\t\\n\\t\\t\\n\\t\\tLanguages\\n\\t\\n\\nIPA data is currently available for the following languages:\\n\\n\\t\\n\\t\\t\\nLanguage\\nCode\\n\\n\\n\\t\\t\\nar\\nArabic (Modern Standard)\\n\\n\\nde\\nGerman\\n\\n\\nen_UK\\nEnglish (Received Pronunciation)\\n\\n\\nen_US\\nEnglish (General American)\\n\\n\\neo\\nEsperanto\\n\\n\\nes_ES\\nSpanish (Spain)\\n\\n\\nes_MX\\nSpanish (Mexico)\\n\\n\\nfa\\nPersian\\n\\n\\nfi\\nFinnish\\n\\n\\nfr_FR\\nFrench (France)\\n\\n\\nfr_QC\\nFrench (Québec)\\n\\n\\nis\\nIcelandic\\n\\n\\nja\\nJapanese\\n\\n\\njam… See the full description on the dataset page: https://huggingface.co/datasets/StephanAkkerman/open-dict-words-ipa."},
	{"name":"include-lite-44","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/CohereForAI/include-lite-44","creator_name":"Cohere For AI","creator_url":"https://huggingface.co/CohereForAI","description":"\\n\\t\\n\\t\\t\\n\\t\\tINCLUDE-lite (44 languages)\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\n\\n\\nPaper: http://arxiv.org/abs/2411.19799\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nINCLUDE is a comprehensive knowledge- and reasoning-centric benchmark across 44 languages that evaluates multilingual LLMs for performance in the actual language environments where they would be deployed. \\nIt contains 11,095 4-option multiple-choice-questions (MCQ) extracted from academic and professional exams, covering 57 topics, including regional… See the full description on the dataset page: https://huggingface.co/datasets/CohereForAI/include-lite-44."},
	{"name":"sib-fleurs","keyword":"chinese","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/WueNLP/sib-fleurs","creator_name":"WüNLP","creator_url":"https://huggingface.co/WueNLP","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSIB-Fleurs\\n\\t\\n\\nSIB-Fleurs is a dataset suitable to evaluate Multilingual Spoken Language Understanding. For each utterance in Fleurs, the task is to determine the topic the utterance belongs to. \\nThe topics are:\\n\\nScience/Technology\\nTravel\\nPolitics\\nSports\\nHealth\\nEntertainment\\nGeography\\n\\nPreliminary evaluations can be found at the bottom of the README. The preliminary results in full detail are available in ./results.csv*.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset creation\\n\\t\\n\\nThis dataset processes and… See the full description on the dataset page: https://huggingface.co/datasets/WueNLP/sib-fleurs."},
	{"name":"Chinese_Multi-Emotion_Dialogue_Dataset","keyword":"chinese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Johnson8187/Chinese_Multi-Emotion_Dialogue_Dataset","creator_name":"Johnson","creator_url":"https://huggingface.co/Johnson8187","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tChinese_Multi-Emotion_Dialogue_Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\t📄 Description\\n\\t\\n\\nThis dataset contains 4159 Chinese dialogues annotated with 8 distinct emotion categories. The data is suitable for emotion recognition, sentiment analysis, and other NLP tasks involving Chinese text.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Sources:\\n\\t\\n\\n\\nDaily Conversations: Captured from natural, informal human conversations.\\nMovie Dialogues: Extracted from diverse Chinese-language movies.\\nAI-Generated Dialogues: Synthesized using… See the full description on the dataset page: https://huggingface.co/datasets/Johnson8187/Chinese_Multi-Emotion_Dialogue_Dataset."},
	{"name":"Global-MMLU-Lite","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/CohereForAI/Global-MMLU-Lite","creator_name":"Cohere For AI","creator_url":"https://huggingface.co/CohereForAI","description":"\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nGlobal-MMLU-Lite is a multilingual evaluation set spanning 15 languages, including English. It is \\\"lite\\\" version of the original Global-MMLU dataset 🌍.\\nIt includes 200 Culturally Sensitive (CS) and 200 Culturally Agnostic (CA) samples per language. The samples in Global-MMLU-Lite are corresponding to languages which are fully human translated or post-edited in the original Global-MMLU dataset. \\n\\nCurated by: Professional annotators and contributors of Cohere For… See the full description on the dataset page: https://huggingface.co/datasets/CohereForAI/Global-MMLU-Lite."},
	{"name":"reranker_continuous_filt_max7_train","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/lightblue/reranker_continuous_filt_max7_train","creator_name":"Lightblue KK.","creator_url":"https://huggingface.co/lightblue","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tReranker training data\\n\\t\\n\\nThis data was generated using 4 steps:\\n\\nWe gathered queries and corresponding text data from 35 high quality datasets covering more than 95 languages.\\nFor datasets which did not already have negative texts for queries, we mined hard negatives using the BAAI/bge-m3 embedding model.\\nFor each query, we selected one positive and one negative text and used Qwen/Qwen2.5-32B-Instruct-GPTQ-Int4 to rate the relatedness of each query-text pair using a token \\\"1\\\", \\\"2\\\"… See the full description on the dataset page: https://huggingface.co/datasets/lightblue/reranker_continuous_filt_max7_train."},
	{"name":"smoltalk-chinese","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/opencsg/smoltalk-chinese","creator_name":"opencsg","creator_url":"https://huggingface.co/opencsg","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tChinese SmolTalk Dataset          [中文]    [English]\\n\\t\\n\\n\\n\\n\\n\\n\\n\\n\\n[OpenCSG Community]   [👾github]  [wechat]  [Twitter] \\n\\n\\n\\n📖Technical Report\\nsmoltalk-chinese is a Chinese fine-tuning dataset constructed with reference to the SmolTalk dataset. It aims to provide high-quality synthetic data support for training large language models (LLMs). The dataset consists entirely of synthetic data, comprising over 700,000 entries. It is specifically designed to enhance the performance of Chinese… See the full description on the dataset page: https://huggingface.co/datasets/opencsg/smoltalk-chinese."},
	{"name":"MultiLingualSentiment","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/clapAI/MultiLingualSentiment","creator_name":"clapAI","creator_url":"https://huggingface.co/clapAI","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tOverview\\n\\t\\n\\nMultilingualSentiment is a sentiment classification dataset that encompasses three sentiment labels: Positive, Neutral, Negative\\nThe dataset spans multiple languages and covers a wide range of domains, making it ideal for multilingual sentiment analysis tasks.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Information\\n\\t\\n\\nThe dataset was meticulously collected and aggregated from various sources, including Hugging Face and Kaggle. These sources provide diverse languages and domains to ensure a… See the full description on the dataset page: https://huggingface.co/datasets/clapAI/MultiLingualSentiment."},
	{"name":"Chinese-Tag-Extraction","keyword":"chinese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Johnson8187/Chinese-Tag-Extraction","creator_name":"Johnson","creator_url":"https://huggingface.co/Johnson8187","description":"Johnson8187/Chinese-Tag-Extraction dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"Chinese-Tag-Extraction","keyword":"chinese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Johnson8187/Chinese-Tag-Extraction","creator_name":"Johnson","creator_url":"https://huggingface.co/Johnson8187","description":"Johnson8187/Chinese-Tag-Extraction dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"Ancient_Chinese_Study_252k","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/TroyeML/Ancient_Chinese_Study_252k","creator_name":"Troye","creator_url":"https://huggingface.co/TroyeML","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Dataset Name\\n\\t\\n\\n\\n\\nThis is a high-quality dataset focusing on ancient Chinese, with data from FireFly and COIG-CQIA. \\nAt the same time, the author created a COT dataset for the translation of OldancientChinese into English and the translation from English to ancient Chinese.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\n\\n\\n\\n\\nLanguage(s) (NLP): Chinese\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Structure\\n\\t\\n\\n{\\n\\\"instruction\\\":\\\"自公大号初发，爰暨告成，灵祥炳焕，不可胜纪，岂伊素雉远至，嘉禾近归而已哉！\\\\nTransfer this ancient Chinese sentence… See the full description on the dataset page: https://huggingface.co/datasets/TroyeML/Ancient_Chinese_Study_252k."},
	{"name":"CoT-XLang","keyword":"chinese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Egor-AI/CoT-XLang","creator_name":"Egor AI","creator_url":"https://huggingface.co/Egor-AI","description":"RU:CoT-XLang — это многоязычный датасет, состоящий из текстовых примеров с пошаговыми рассуждениями (Chain-of-Thought, CoT) на различных языках, включая английский, русский, японский и другие. Он используется для обучения и тестирования моделей в задачах, требующих пояснений решений через несколько шагов. Датасет включает около 2,419,912 примеров, что позволяет эффективно обучать модели, способные генерировать пошаговые рассуждения.\\nРекомендация:Используйте датасет для обучения моделей… See the full description on the dataset page: https://huggingface.co/datasets/Egor-AI/CoT-XLang."},
	{"name":"BoundingDocs","keyword":"chinese","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/letxbe/BoundingDocs","creator_name":"Letxbe","creator_url":"https://huggingface.co/letxbe","description":"\\n\\nBoundingDocs\\n\\n🔍 The largest spatially-annotated dataset for Document Question Answering\\n\\n\\n\\n\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nBoundingDocs is a unified dataset for Document Question Answering (QA) that includes spatial annotations. It consolidates multiple public datasets from Document AI and Visually Rich Document Understanding (VRDU) domains. The dataset reformulates Information Extraction (IE) tasks into QA tasks, making it a valuable resource for training and evaluating Large Language… See the full description on the dataset page: https://huggingface.co/datasets/letxbe/BoundingDocs."},
	{"name":"haiku-zh","keyword":"chinese","license":"GNU General Public License v3.0","license_url":"https://choosealicense.com/licenses/gpl-3.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Orion-zhen/haiku-zh","creator_name":"Orion","creator_url":"https://huggingface.co/Orion-zhen","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\t诵读俳句吧\\n\\t\\n\\n俳句数据集\\n大模型编写回复\\n人工再审核\\n\\n人力有穷时\\n我只简单审核过\\n无明显错误\\n\\n本为打油诗\\n不管有没有美感\\n就是图一乐\\n\\n亦可DPO\\n让模型生成拒绝\\n配对数据集\\n"},
	{"name":"UltraFeedback-chinese","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/opencsg/UltraFeedback-chinese","creator_name":"opencsg","creator_url":"https://huggingface.co/opencsg","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tChinese SmolTalk Dataset          [中文]    [English]\\n\\t\\n\\n\\n\\n\\n\\n\\n\\n\\n[OpenCSG Community]   [👾github]  [wechat]  [Twitter] \\n\\n\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tUltraFeedback Chinese Dataset\\n\\t\\n\\nUltraFeedback-Chinese is a Chinese version developed based on the construction method of the UltraFeedback dataset, designed specifically for training robust reward and critic models. This dataset supports two training methods: PPO (Proximal Policy Optimization) and DPO (Direct Preference Optimization).… See the full description on the dataset page: https://huggingface.co/datasets/opencsg/UltraFeedback-chinese."},
	{"name":"DualMath-1.1M","keyword":"chinese","license":"GNU General Public License v3.0","license_url":"https://choosealicense.com/licenses/gpl-3.0/","language":"en","dataset_url":"https://huggingface.co/datasets/URSA-MATH/DualMath-1.1M","creator_name":"URSA-MATH","creator_url":"https://huggingface.co/URSA-MATH","description":"\\n\\t\\n\\t\\t\\n\\t\\tDualMath-1.1M\\n\\t\\n\\nImage data can be downloaded from the following address:\\n\\nMAVIS: https://github.com/ZrrSkywalker/MAVIS, https://drive.google.com/drive/folders/1LGd2JCVHi1Y6IQ7l-5erZ4QRGC4L7Nol.\\nMultimath: https://huggingface.co/datasets/pengshuai-rin/multimath-300k.\\nGeo170k: https://huggingface.co/datasets/Luckyjhg/Geo170K.\\nVarsityTutors: https://huggingface.co/datasets/Math-PUMA/Math-PUMA_Data_Stage2. \\nMathV360K: https://huggingface.co/datasets/Zhiqiang007/MathV360K.\\n\\nThe image data… See the full description on the dataset page: https://huggingface.co/datasets/URSA-MATH/DualMath-1.1M."},
	{"name":"SMPQA","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/WueNLP/SMPQA","creator_name":"WüNLP","creator_url":"https://huggingface.co/WueNLP","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSMPQA (Synthetic Multilingual Plot QA)\\n\\t\\n\\n\\n\\nThe SMPQA evaluation dataset proposed in Centurio: On Drivers of Multilingual Ability of Large Vision-Language Model.\\nSMPQA is composed of synthetic bar plots and pie charts (generated using word lists of different languages) together with questions about those plots.\\nThe datasets aims at providing an initial way of evaluating multilingual OCR capabilities of models in arbritrary languages.\\nThere are two sub-tasks: \\n\\nGrounding text labels… See the full description on the dataset page: https://huggingface.co/datasets/WueNLP/SMPQA."},
	{"name":"role-play-chinese","keyword":"chinese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Johnson8187/role-play-chinese","creator_name":"Johnson","creator_url":"https://huggingface.co/Johnson8187","description":"繁體中文   English\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tRole-Play Chinese Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\t簡介\\n\\t\\n\\n這是一個專為角色扮演對話設計的中文數據集，數據由 AI 生成，適用於訓練和評估自然語言處理（NLP）模型，特別是對話生成和角色扮演相關的任務。數據集以 Alpha 格式 儲存，方便進行微調和進一步的模型訓練。數據集包含多種場景和角色設定，能夠幫助模型學習如何在不同的情境下生成符合角色性格和背景的對話。\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\t數據集結構\\n\\t\\n\\n數據以Alpha格式儲存方便微調，包含以下字段：\\n\\ninstruction: 任務指令，描述模型需要完成的任務。\\ninput: 輸入內容，包含場景描述、過去的對話以及當前對話的上下文。\\noutput: 期望的模型輸出，即符合角色設定的回應。\\nsystem: 角色設定和背景故事，幫助模型理解角色的性格和行為模式。\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\t範例\\n\\t\\n\\n{\\n  \\\"instruction\\\": \\\"在給定的場景中，請根據角色設定回應對話。\\\",\\n  \\\"input\\\":… See the full description on the dataset page: https://huggingface.co/datasets/Johnson8187/role-play-chinese."},
	{"name":"WebWalkerQA","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/callanwu/WebWalkerQA","creator_name":"Jialong Wu","creator_url":"https://huggingface.co/callanwu","description":"📑 The paper of WebWalkerQA is available at arXiv.\\n📊 The dataset resource is a collection of 680 questions and answers from the WebWebWalker dataset.\\n🙋 The dataset is in the form of a JSON file.\\nThe keys in the JSON include:\\nQuestion, Answer, Root_Url, and Info. The Info field contains\\nmore detailed information, including Hop, Domain, Language,\\nDifficulty_Level, Source Website, and Golden_Path.\\n{\\n    \\\"Question\\\": \\\"When is the paper submission deadline for the ACL 2025 Industry Track, and what… See the full description on the dataset page: https://huggingface.co/datasets/callanwu/WebWalkerQA."},
	{"name":"CUTE-Datasets","keyword":"chinese","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/CMLI-NLP/CUTE-Datasets","creator_name":"MUCNLP（中央民族大学自然语言处理实验室）","creator_url":"https://huggingface.co/CMLI-NLP","description":"\\n\\t\\n\\t\\t\\n\\t\\tCUTE Dataset\\n\\t\\n\\nCUTE (Chinese, Uyghur, Tibetan, English) 是一个大规模多语言数据集，专门设计用于增强低资源语言的跨语言知识迁移。数据集包含平行语料和非平行语料两部分，总规模约50GB。\\n\\n\\t\\n\\t\\t\\n\\t\\t数据集组成\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\t平行语料 (24.70GB)\\n\\t\\n\\n\\n中文：2.62GB\\n英语：3.49GB\\n维吾尔语：7.37GB\\n藏语：11.22GB\\n\\n\\n\\t\\n\\t\\t\\n\\t\\t非平行语料 (25.80GB)\\n\\t\\n\\n\\n中文：2.64GB\\n英语：3.49GB\\n维吾尔语：7.77GB\\n藏语：11.90GB\\n\\n\\n\\t\\n\\t\\t\\n\\t\\t数据质量\\n\\t\\n\\n数据集通过机器翻译生成，并经过人工评估验证：\\n\\n中英翻译平均得分：9.1\\n中维翻译平均得分：8.5\\n中藏翻译平均得分：8.6\\n\\n\\n\\t\\n\\t\\t\\n\\t\\t相关链接\\n\\t\\n\\n\\n📝 论文\\n🤖 模型\\n📂 GitHub\\n\\n\\n\\t\\n\\t\\t\\n\\t\\t引用\\n\\t\\n\\n如果您使用了我们的数据集，请引用我们的论文：\\n@inproceedings{zhuang2025cute,\\n  title={CUTE: A… See the full description on the dataset page: https://huggingface.co/datasets/CMLI-NLP/CUTE-Datasets."},
	{"name":"PCF","keyword":"chinese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/HahahaFace/PCF","creator_name":"Zale Lee","creator_url":"https://huggingface.co/HahahaFace","description":"\\n\\t\\n\\t\\t\\n\\t\\t🌱 Tsinghua-PCF-Synergy-Dataset\\n\\t\\n\\n🏛️ 机构: 清华大学\\n🔗 开源地址: PCF-Synergy HuggingFace\\n📜 证书: MIT\\n📅 版本: v1.2.0 (2024-12)\\n\\n\\t\\n\\t\\t\\n\\t\\t🌍 数据集简介\\n\\t\\n\\n面向产品碳足迹(PCF)评估领域的大模型训练需求，本数据集创新性地融合 知识图谱约束生成 (K-SDG) 与 人工反馈 (RLHF)技术，覆盖全生命周期评估(LCA)场景。\\n\\n\\t\\n\\t\\t\\n\\t\\t🌐 多源异构数据融合\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n数据类别\\n典型样例\\n占比\\n\\n\\n\\t\\t\\n国际标准\\nISO 14067, GHG Protocol\\n18%\\n\\n\\n行业数据库\\nEcoinvent 3.8, Exiobase 3.7\\n22%\\n\\n\\n企业实践\\nApple供应链数据, Lenovo生产日志\\n15%\\n\\n\\n学术文献\\nNature Sustainability论文数据集\\n12%\\n\\n\\n专利知识\\n华为CN114996032A, Siemens EP3267377B1\\n8%\\n\\n\\n合成数据\\nGPT-4生成+知识图谱校验\\n25%… See the full description on the dataset page: https://huggingface.co/datasets/HahahaFace/PCF."},
	{"name":"URSA_Alignment_860K","keyword":"chinese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/URSA-MATH/URSA_Alignment_860K","creator_name":"URSA-MATH","creator_url":"https://huggingface.co/URSA-MATH","description":"\\n\\t\\n\\t\\t\\n\\t\\tURSA_Alignment_860K\\n\\t\\n\\nThis dataset is used for the vision-language alignment phase of training the URSA-7B model.\\nImage data can be downloaded from the following address:\\n\\nMAVIS: https://github.com/ZrrSkywalker/MAVIS, https://drive.google.com/drive/folders/1LGd2JCVHi1Y6IQ7l-5erZ4QRGC4L7Nol.\\nMultimath: https://huggingface.co/datasets/pengshuai-rin/multimath-300k.\\nGeo170k: https://huggingface.co/datasets/Luckyjhg/Geo170K.\\n\\nThe image data in the MMathCoT-1M dataset is still available.… See the full description on the dataset page: https://huggingface.co/datasets/URSA-MATH/URSA_Alignment_860K."},
	{"name":"HanScript2HanViet2ModernViet_Literature","keyword":"chinese","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/GooglyEyeSuperman/HanScript2HanViet2ModernViet_Literature","creator_name":"Quoc Anh","creator_url":"https://huggingface.co/GooglyEyeSuperman","description":"\\n\\t\\n\\t\\t\\n\\t\\tUse this dataset\\n\\t\\n\\nYou can load this dataset directly in your Python code using the 🤗 datasets library:\\nfrom datasets import load_dataset\\n\\ndataset = load_dataset(\\\"GooglyEyeSuperman/HanScript2HanViet2ModernViet_Literature\\\", {config_name})\\n\\nconfig_name should be one of [train_official, train_comment, train_ai, test_official, dictionary, full_raw], to get the corresponding csv files.\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSino-Viet to Modern Vietnamese Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tOverview\\n\\t\\n\\nThis dataset focuses on… See the full description on the dataset page: https://huggingface.co/datasets/GooglyEyeSuperman/HanScript2HanViet2ModernViet_Literature."},
	{"name":"csc_eval_public","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Macropodus/csc_eval_public","creator_name":"Macadam","creator_url":"https://huggingface.co/Macropodus","description":"\\n\\t\\n\\t\\t\\n\\t\\tcsc_eval_public\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\t一、测评数据说明\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\t1.1 测评数据来源\\n\\t\\n\\n1.gen_de3.json(5545): '的地得'纠错, 由人民日报/学习强国/chinese-poetry等高质量数据人工生成;\\n2.lemon_v2.tet.json(1053): relm论文提出的数据, 多领域拼写纠错数据集(7个领域), ; 包括game(GAM), encyclopedia (ENC), contract (COT), medical care(MEC), car (CAR), novel (NOV), and news (NEW)等领域;\\n3.acc_rmrb.tet.json(4636): 来自NER-199801(人民日报高质量语料);\\n4.acc_xxqg.tet.json(5000): 来自学习强国网站的高质量语料;\\n5.gen_passage.tet.json(10000): 源数据为qwen生成的好词好句, 由几乎所有的开源数据汇总的混淆词典生成;… See the full description on the dataset page: https://huggingface.co/datasets/Macropodus/csc_eval_public."},
	{"name":"Fineweb-Edu-Chinese-V2.1","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/opencsg/Fineweb-Edu-Chinese-V2.1","creator_name":"opencsg","creator_url":"https://huggingface.co/opencsg","description":"\\n\\t\\n\\t\\t\\n\\t\\tChinese Fineweb Edu Dataset V2.1          [中文]    [English]\\n\\t\\n\\n\\n\\n\\n\\n\\n[OpenCSG Community]   [👾github]  [wechat]  [Twitter] \\n\\n\\n\\n📖Technical Report\\nThe Chinese Fineweb Edu Dataset V2.1 is an enhanced version of the V2 dataset, designed specifically for natural language processing (NLP) tasks in the education sector. This version introduces two new data sources, map-cc and opencsg-cc, and retains data with scores ranging from 2 to 3. The dataset entries are organized into different folders… See the full description on the dataset page: https://huggingface.co/datasets/opencsg/Fineweb-Edu-Chinese-V2.1."},
	{"name":"Condor-SFT-20K","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/internlm/Condor-SFT-20K","creator_name":"InternLM","creator_url":"https://huggingface.co/internlm","description":"\\n\\t\\n\\t\\t\\n\\t\\tCondor\\n\\t\\n\\n\\n\\n\\n\\t\\n\\t\\t\\n\\t\\t✨ Introduction\\n\\t\\n\\n[🤗 HuggingFace Models]\\n[🤗 HuggingFace Datasets]\\n[📃 Paper]\\n\\n\\n\\n\\n\\nThe quality of Supervised Fine-Tuning (SFT) data plays a critical role in enhancing the conversational capabilities of Large Language Models (LLMs).\\nHowever, as LLMs become more advanced, \\nthe availability of high-quality human-annotated SFT data has become a significant bottleneck, \\nnecessitating a greater reliance on synthetic training data. \\nIn this work, we introduce… See the full description on the dataset page: https://huggingface.co/datasets/internlm/Condor-SFT-20K."},
	{"name":"jacob-common-voice-19-zh-TW-curated","keyword":"chinese","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/JacobLinCool/jacob-common-voice-19-zh-TW-curated","creator_name":"Jacob Lin","creator_url":"https://huggingface.co/JacobLinCool","description":"JacobLinCool/jacob-common-voice-19-zh-TW-curated dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"TaiwanVQA","keyword":"chinese","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/hhhuang/TaiwanVQA","creator_name":"Hen-Hsen Huang","creator_url":"https://huggingface.co/hhhuang","description":"\\n\\t\\n\\t\\t\\n\\t\\tTaiwanVQA: A Visual Question Answering Benchmark for Taiwan-Specific Content\\n\\t\\n\\n\\n\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nTaiwanVQA is a visual question answering (VQA) benchmark designed to evaluate the capability of vision-language models (VLMs) in recognizing and reasoning about culturally specific content related to Taiwan. This dataset contains 1,000 images paired with 2,000 questions that cover diverse topics from daily life in Taiwan, such as traditional cuisine, public signage… See the full description on the dataset page: https://huggingface.co/datasets/hhhuang/TaiwanVQA."},
	{"name":"short_COT_48k","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/FrankL/short_COT_48k","creator_name":"FrankLiu","creator_url":"https://huggingface.co/FrankL","description":"FrankL/short_COT_48k dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"csc_public_de3","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Macropodus/csc_public_de3","creator_name":"Macadam","creator_url":"https://huggingface.co/Macropodus","description":"\\n\\t\\n\\t\\t\\n\\t\\tcsc_public_de3数据集\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\t数据来源\\n\\t\\n\\n\\n1.由人民日报/学习强国/chinese-poetry等高质量数据人工生成;\\n2.来自人民日报高质量语料;\\n3.来自学习强国网站的高质量语料;\\n4.源数据为qwen生成的好词好句;\\n5.古诗词chinese-poetry; 文言文garychowcmu/daizhigev20;\\n\\n\\n\\t\\n\\t\\t\\n\\t\\t数据简介\\n\\t\\n\\n\\n该数据主要为'的地得'纠错;\\n其中训练数据130753条, 验证数据5545条, 测试数据5545条;\\n句子平均长度为36, 最长句子长度为414, 最短为5, 95%的为89, 75%的为46, 60%的为34;\\n每个句子中字的平均错误数为2;\\n\\n\\n\\t\\n\\t\\t\\n\\t\\t数据详情\\n\\t\\n\\n################################################################################################################################\\ntrain.json\\n130753… See the full description on the dataset page: https://huggingface.co/datasets/Macropodus/csc_public_de3."},
	{"name":"degeneration-html-multilingual","keyword":"chinese","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Degeneration-Nation/degeneration-html-multilingual","creator_name":"The Degeneration of the Nation","creator_url":"https://huggingface.co/Degeneration-Nation","description":"\\n\\t\\n\\t\\t\\n\\t\\tThe Degeneration of the Nation Multilingual Dataset\\n\\t\\n\\nThis dataset contains the complete content of The Degeneration of the Nation project, a comprehensive philosophical and cultural website exploring the intersection of technology, artificial intelligence, and human culture. The content includes philosophical essays, cultural analysis, and contemporary literature, with complex parallel structure and sophisticated HTML architecture across all language versions.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset… See the full description on the dataset page: https://huggingface.co/datasets/Degeneration-Nation/degeneration-html-multilingual."},
	{"name":"GreatFirewall-DPO","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/nbeerbower/GreatFirewall-DPO","creator_name":"Nicholas Beerbower","creator_url":"https://huggingface.co/nbeerbower","description":"\\n\\n\\t\\n\\t\\t\\n\\t\\tGreatFirewall-DPO\\n\\t\\n\\nAn experimental dataset to discourage censorship and improve english prose in Chinese models.\\n\\n\\t\\n\\t\\t\\n\\t\\tStructure\\n\\t\\n\\n\\nprompt: input text presented to model (en translated to zh)\\nchosen: preferred response demonstrating less self-censorship (en translated to zh)  \\nrejected: response generated by Qwen/Qwen2.5-32B-Instruct, many (NOT ALL) exhibiting excessive self-censorship (generated in both en and zh)\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tContent\\n\\t\\n\\n\\nCHINA-related (144 prompts) - mostly about… See the full description on the dataset page: https://huggingface.co/datasets/nbeerbower/GreatFirewall-DPO."},
	{"name":"poem-pretrain-chinese-zhtw","keyword":"chinese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/yuhuanstudio/poem-pretrain-chinese-zhtw","creator_name":"YuhuanStudio","creator_url":"https://huggingface.co/yuhuanstudio","description":"\\n\\t\\n\\t\\t\\n\\t\\tDataset Card for \\\"poem-pretrain-chinese-zhtw\\\"\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\t資料集摘要\\n\\t\\n\\n中文古典文集資料庫收集了約 5.5 萬首唐詩、26 萬首宋詩、2.1 萬首宋詞和其他古典文集。詩人包括唐宋兩朝近 1.4 萬古詩人，和兩宋時期 1.5 千古詞人。\\n\\n五代十國- 收錄\\\"花間集\\\"與\\\"南唐二主詞\\\"\\n唐- 收錄\\\"全唐詩\\\"(是清康熙四十四年，康熙皇帝主導下，蒐集羅唐詩的收藏「得詩 48,900 餘首，詩入 2,200 人」)。\\n宋- 收錄\\\"全宋詞\\\"(由唐圭璋編著，孔凡禮補輯，共收錄宋代詞人 1,330 家，詞作 21,116 首)。\\n元- 收錄元曲 11,057 篇，曲家 233 人。\\n清- 收錄\\\"納蘭性德詩集\\\"\\n\\n原始資料來源:\\n\\nchinese-poetry: 最全中文诗歌古典文集数据库\\nerhwenkuo/poetry-chinese-zhtw\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\t資料集結構\\n\\t\\n\\n{\\n  \\\"text\\\":… See the full description on the dataset page: https://huggingface.co/datasets/yuhuanstudio/poem-pretrain-chinese-zhtw."},
	{"name":"wikipedia-pretrain-zh-tw","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/yuhuanstudio/wikipedia-pretrain-zh-tw","creator_name":"YuhuanStudio","creator_url":"https://huggingface.co/yuhuanstudio","description":"\\n\\t\\n\\t\\t\\n\\t\\t台灣正體中文維基百科 (zh-tw Wikipedia)\\n\\t\\n\\n新版截至 2025 年 3 月，中文維基百科 1,468,827 篇條目的台灣正體文字內容。每篇內文為text內容，且內容皆刪除引入、參考等不涉及知識方面之不必要內容。\\nNew Version As of March 2025, the Traditional Chinese content of the 1,468,827 articles on Chinese Wikipedia. Each article contains only text content, with introductory sections, references, and other non-knowledge-related elements removed.\\n於 2025 年 3 月 13 日取自維基百科dump，內容皆與維基百科網站之台灣正體版本一致，經OpenCC轉換後沒有繁簡體混雜的問題。\\nRetrieved from the Wikipedia dump on March 13, 2025, the… See the full description on the dataset page: https://huggingface.co/datasets/yuhuanstudio/wikipedia-pretrain-zh-tw."},
	{"name":"passages-pretrain-chinese-zhtw","keyword":"chinese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/yuhuanstudio/passages-pretrain-chinese-zhtw","creator_name":"YuhuanStudio","creator_url":"https://huggingface.co/yuhuanstudio","description":"\\n\\t\\n\\t\\t\\n\\t\\tDataset Card for \\\"yuhuanstudio/passages-pretrain-chinese-zhtw\\\"\\n\\t\\n\\n包含8千萬餘萬（88328203）個中文段落，不包含任何字母、數字。文字長度大部分介於 50~200 個字。\\n\\n\\t\\n\\t\\t\\n\\t\\t資料集來源\\n\\t\\n\\n本資料集是基於CLUE中文預訓練語料集進行處理、過濾并進行簡繁轉諲而得到的。\\n\\n\\t\\n\\t\\t\\n\\t\\t資料集結構\\n\\t\\n\\n{\\n  \\\"text\\\": \\\"雙十一點燃快遞板塊喜憂參半三季報透露何種訊號經過初步證實，這名喝農藥死亡的男子正是殺害夫妻倆的犯罪嫌疑人。\\\"\\n}\\n\\n\\n\\t\\n\\t\\t\\n\\t\\t資料欄位\\n\\t\\n\\n\\ntext: (string) 文本內容\\n\\n\\n\\t\\n\\t\\t\\n\\t\\t如何使用\\n\\t\\n\\nfrom datasets import load_dataset\\ndataset = load_dataset(\\\"yuhuanstudio/passages-pretrain-chinese-zhtw\\\", split=\\\"train\\\")\\n\\n\\n\\t\\n\\t\\t\\n\\t\\t許可資訊\\n\\t\\n\\n[MIT]\\n"},
	{"name":"wmt-da-human-evaluation-long-context","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ymoslem/wmt-da-human-evaluation-long-context","creator_name":"Yasmin Moslem","creator_url":"https://huggingface.co/ymoslem","description":"\\n\\t\\n\\t\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nLong-context / document-level dataset for Quality Estimation of Machine Translation.\\nIt is an augmented variant of the sentence-level WMT DA Human Evaluation dataset.\\nIn addition to individual sentences, it contains augmentations of 2, 4, 8, 16, and 32 sentences, among each language pair lp and domain.\\nThe raw column represents a weighted average of scores of augmented sentences using character lengths of src and mt as weights.\\nThe code used to apply the augmentation… See the full description on the dataset page: https://huggingface.co/datasets/ymoslem/wmt-da-human-evaluation-long-context."},
	{"name":"TinyHelen-zh","keyword":"chinese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/fzmnm/TinyHelen-zh","creator_name":"fangzhangmnm","creator_url":"https://huggingface.co/fzmnm","description":"\\n\\t\\n\\t\\t\\n\\t\\tTinyHelen-zh\\n\\t\\n\\nInspired by the paper TinyHelen's First Curriculum, we present a Chinese version of the LLM-simplified training corpus. This dataset is converted from high-quality Chinese and English web crawls for training baby-size (<100M) language models.\\nAdult-talking\\n北京市财政局、北京海关、国家税务总局北京市税务局、北京市国际服务贸易事务中心：\\n为支持2020年中国国际服务贸易交易会（以下简称服贸会）顺利举办，经国务院批准，现将有关问题通知如下：\\n一、对在2020年服贸会展期内销售的限额内的进口展品（不包括国家禁止进口商品、濒危动植物及其产品、烟、酒和汽车）免征进口关税、进口环节增值税和消费税。… See the full description on the dataset page: https://huggingface.co/datasets/fzmnm/TinyHelen-zh."},
	{"name":"Honkai_StarRail_Trailblaze_Mission_zhtw","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/yuhuanstudio/Honkai_StarRail_Trailblaze_Mission_zhtw","creator_name":"YuhuanStudio","creator_url":"https://huggingface.co/yuhuanstudio","description":"\\n\\t\\n\\t\\t\\n\\t\\tDataset Card for \\\"yuhuanstudio/Honkai_StarRail_Trailblaze_Mission_zhtw\\\"\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\t資料集摘要\\n\\t\\n\\n摘要：一個採集崩壞：星穹鐵道開拓任務和開拓續聞對話內容的資料集，並處理成適當的資料格式用於預訓練大模型\\n來源：Bilibili Wiki - 崩壞：星穹鐵道\\n數據類型：劇情對話文本\\n格式：JSON\\n語言：繁體中文 / 簡體中文 (zhtw/zh)\\n資料範圍：包含所有「開拓任務」「開拓續聞」的劇情內容，包括角色對話、選項(第一選項)、場景描述等。 (v3.0)\\n\\n\\t\\n\\t\\t\\n\\t\\t資料集結構\\n\\t\\n\\nmissions為開拓任務，addition為開拓續聞，未加_tw為簡體原始數據\\n{\\n<!-- 預訓練資料集資料 -->\\n  \\\"text\\\": \\\"《「均衡」的試煉•陸》\\\\n「仲裁官」的試煉再度到來。它的內容、形式、好處和損害你已經很清楚了，不是嗎？去吧，為了「均衡」……\\\\n仙舟「羅浮」-流雲渡\\\"\\n}\\n\\n{\\n<!-- 擷取資料 -->\\n  \\\"title\\\": \\\"混亂行至深處\\\",\\n  \\\"story\\\": [… See the full description on the dataset page: https://huggingface.co/datasets/yuhuanstudio/Honkai_StarRail_Trailblaze_Mission_zhtw."},
	{"name":"OpenNewsArchive_pretrain_zhtw","keyword":"chinese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/yuhuanstudio/OpenNewsArchive_pretrain_zhtw","creator_name":"YuhuanStudio","creator_url":"https://huggingface.co/yuhuanstudio","description":"\\n\\t\\n\\t\\t\\n\\t\\tDataset Card for \\\"yuhuanstudio/OpenNewsArchive_pretrain_zhtw\\\"\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\t資料集摘要\\n\\t\\n\\n本資料集基於 OpenNewsArchive 原始數據，經過以下處理步驟：\\n簡繁轉換：使用 OpenCC 工具將簡體中文轉換為繁體中文並轉換常用詞彙，確保繁體用語的一致性。\\n格式化：整理數據結構，使其適合大型語言模型（LLM）的預訓練，確保高效的文本輸入與處理。\\n\\n\\t\\n\\t\\t\\n\\t\\t原始資料來源:\\n\\t\\n\\n內容說明\\n數據來源：OpenDataLab - OpenNewsArchive\\n語言：繁體中文（基於 OpenCC 處理）\\n資料格式：適用於 LLM 預訓練的格式，包含標準化文本結構。\\n\\n\\t\\n\\t\\t\\n\\t\\t使用說明\\n\\t\\n\\n此資料集適用於：\\n大型語言模型的預訓練\\n自然語言處理（NLP）研究\\n繁體中文語言處理與分析\\n\\n\\t\\n\\t\\t\\n\\t\\t資料集結構\\n\\t\\n\\n{\\n  \\\"text\\\": \\\"報導於: 2023-10-25。… See the full description on the dataset page: https://huggingface.co/datasets/yuhuanstudio/OpenNewsArchive_pretrain_zhtw."},
	{"name":"c4_pretrain_zhtw","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/yuhuanstudio/c4_pretrain_zhtw","creator_name":"YuhuanStudio","creator_url":"https://huggingface.co/yuhuanstudio","description":"\\n\\t\\n\\t\\t\\n\\t\\tDataset Card for \\\"yuhuanstudio/c4_pretrain_zhtw\\\"\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\t資料集摘要\\n\\t\\n\\n本資料集基於 C4（Colossal Clean Crawled Corpus）原始數據，並經過以下處理步驟，轉換為適用於大型語言模型（LLM）預訓練的格式：\\n資料清理：去除非中文內容、重複文本及不必要的 HTML 標籤，並使用pangu格式化中文語句間隔，提升語言模型的訓練品質。\\n格式化：將數據重新整理為適合 LLM 預訓練的結構，便於高效載入與處理。\\n\\n\\t\\n\\t\\t\\n\\t\\t內容說明\\n\\t\\n\\n數據來源：Colossal Clean Crawled Corpus (C4)\\n語言：繁體中文\\n資料格式：JSON 格式，適用於 LLM 預訓練\\n資料數量：包含大量經過清理和格式化的繁體中文文本\\n\\n\\t\\n\\t\\t\\n\\t\\t使用說明\\n\\t\\n\\n此資料集適用於：\\n大型語言模型的預訓練\\n自然語言處理（NLP）研究\\n繁體中文語言理解與分析\\n\\n\\t\\n\\t\\t\\n\\t\\t資料集結構\\n\\t\\n\\n{\\n  \\\"text\\\": \\\"台北故事館 雲門特展 As Lomo aslomo 天空部落 TIAN… See the full description on the dataset page: https://huggingface.co/datasets/yuhuanstudio/c4_pretrain_zhtw."},
	{"name":"wikipedia-2024modify-pretrain-zh-tw","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/yuhuanstudio/wikipedia-2024modify-pretrain-zh-tw","creator_name":"YuhuanStudio","creator_url":"https://huggingface.co/yuhuanstudio","description":"\\n\\t\\n\\t\\t\\n\\t\\t台灣正體中文維基百科 (zh-tw Wikipedia) 2024年更新資料集\\n\\t\\n\\n本資料集收集自維基百科（Wikipedia）2024 年新增與更新內容，主要針對繁體中文語料進行擷取、處理與格式化，以適用於大型語言模型（LLM）預訓練和自然語言處理（NLP）應用。\\n數據來源：維基百科（Wikipedia）繁體中文版本\\n時間範圍：2024 年至 2025年1月24日 的新增與更新條目\\n語言：繁體中文\\n資料格式：JSON 格式，適合 LLM 預訓練與 NLP 分析\\n資料規模：包含豐富的現代話題、最新事件、科學進展等\\n\\n\\t\\n\\t\\t\\n\\t\\t使用說明\\n\\t\\n\\n此資料集適用於：\\n大型語言模型（LLM）預訓練\\n自然語言處理（NLP）研究\\n\\n\\t\\n\\t\\t\\n\\t\\t資料集結構\\n\\t\\n\\n{\\n  \\\"text\\\": \\\"數學是研究數量、結構以及空間等概念及其變化的一門學科，屬於形式科學的一種。數學利用抽象化和邏輯推理，從計數、計算、量度、對物體形狀及運動的觀察發展而成。數學家...\\\"\\n}\\n\\n\\n\\t\\n\\t\\t\\n\\t\\t資料欄位\\n\\t\\n\\n\\ntext: (string) 維基百科文本內容\\n\\n\\n\\t\\n\\t\\t\\n\\t\\t如何使用… See the full description on the dataset page: https://huggingface.co/datasets/yuhuanstudio/wikipedia-2024modify-pretrain-zh-tw."},
	{"name":"PTT-pretrain-zhtw","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/yuhuanstudio/PTT-pretrain-zhtw","creator_name":"YuhuanStudio","creator_url":"https://huggingface.co/yuhuanstudio","description":"\\n\\t\\n\\t\\t\\n\\t\\tDataset Card for \\\"yuhuanstudio/PTT-pretrain-zhtw\\\"\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\t資料集摘要\\n\\t\\n\\n本資料集擷取自台灣最大的 BBS 討論區——批踢踢實業坊（PTT），匯集多個看板的歷史與近期討論，提供豐富的繁體中文語料，適用於大型語言模型（LLM）預訓練與自然語言處理（NLP）研究。\\n數據來源：PTT 批踢踢實業坊（https://www.ptt.cc）\\n涵蓋看板：包含 Gossiping、Tech_Job、Stock、NBA 等所有討論區\\n時間範圍：擷取自 PTT 公開存檔前200頁，涵蓋多年歷史數據 (因各版頁數問題，熱門版面資料可能時間都較為古老)\\n語言：繁體中文\\n資料格式：JSON，適合 LLM 訓練與 NLP 應用\\n資料規模：包含數十萬條貼文與回應\\n\\n\\t\\n\\t\\t\\n\\t\\t資料集結構\\n\\t\\n\\n{\\n  \\\"text\\\": \\\"作者: Sonaten (=.=)\\\\n看板: PC_Shopping\\\\n標題: [閒聊] Gigabyte EP35-DS3 的DES...\\\\n時間: Fri Jun 27 15:20:54 2008\\\\n內文:… See the full description on the dataset page: https://huggingface.co/datasets/yuhuanstudio/PTT-pretrain-zhtw."},
	{"name":"twdict_pretrain","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/yuhuanstudio/twdict_pretrain","creator_name":"YuhuanStudio","creator_url":"https://huggingface.co/yuhuanstudio","description":"\\n\\t\\n\\t\\t\\n\\t\\tDataset Card for \\\"yuhuanstudio/twdict_pretrain\\\"\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\t資料集摘要\\n\\t\\n\\n本資料集將「成語典」與「重編字典」的內容合併為單一資料集，提供繁體中文的詞彙、成語與其解釋、用例等資訊。此資料集適用於大型語言模型（LLM）預訓練以及自然語言處理（NLP）各類應用，如關鍵字抽取、問答系統、語義分析等。\\n原始資料來源:\\n\\n《重編國語辭典修訂本》\\n《成語典》\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\t內容說明\\n\\t\\n\\n• 數據來源：\\n– 「成語典」：收錄常見與罕見成語，含釋義、典故、例句等相關資訊\\n– 「重編字典」：收錄繁體中文詞彙與解釋，含詞性、詞義、引文等\\n• 語言：繁體中文\\n• 資料格式：\\n– JSON 格式，結構化每個詞條或成語的內容\\n– 便於 LLM 預訓練和 NLP 分析\\n• 資料規模：\\n– 含數萬條繁體中文詞彙與成語\\n– 豐富的用法示例、解釋及歷史典故\\n\\n\\t\\n\\t\\t\\n\\t\\t資料集結構\\n\\t\\n\\n{\\n  \\\"text\\\":… See the full description on the dataset page: https://huggingface.co/datasets/yuhuanstudio/twdict_pretrain."},
	{"name":"GSM8K_zh_tw","keyword":"chinese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/DoggiAI/GSM8K_zh_tw","creator_name":"Doggi AI","creator_url":"https://huggingface.co/DoggiAI","description":"\\n\\t\\n\\t\\t\\n\\t\\tDataset\\n\\t\\n\\nGSM8K_zh_tw is a dataset for mathematical reasoning in Traditional Chinese. It is derived from the GSM8K_zh dataset by translating question-answer pairs into Traditional Chinese using OpenCC. The dataset consists of 7473 training samples and 1319 testing samples.\\nIn addition to translation, the dataset includes modifications to improve regional adaptation, such as replacing some China-specific terms with those more suitable for Traditional Chinese users. Simplified Chinese… See the full description on the dataset page: https://huggingface.co/datasets/DoggiAI/GSM8K_zh_tw."},
	{"name":"MM-IQ","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/huanqia/MM-IQ","creator_name":"huanqiacai","creator_url":"https://huggingface.co/huanqia","description":"\\n\\t\\n\\t\\t\\n\\t\\tDataset Card for \\\"MM-IQ\\\"\\n\\t\\n\\n\\nIntroduction\\nPaper Information\\nDataset Examples\\nLeaderboard\\nDataset Usage\\nData Downloading\\nData Format\\nAutomatic Evaluation\\n\\n\\nCitation\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tIntroduction\\n\\t\\n\\nIQ testing has served as a foundational methodology for evaluating human cognitive capabilities, deliberately decoupling assessment from linguistic background, language proficiency, or domain-specific knowledge to isolate core competencies in abstraction and reasoning. Yet, artificial intelligence… See the full description on the dataset page: https://huggingface.co/datasets/huanqia/MM-IQ."},
	{"name":"imatrix-calibration","keyword":"chinese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/eaddario/imatrix-calibration","creator_name":"Ed Addario","creator_url":"https://huggingface.co/eaddario","description":"\\n\\t\\n\\t\\t\\n\\t\\tImportance Matrix (imatrix) calibration datasets\\n\\t\\n\\nThis dataset consists of over 10M tokens of cleaned and de-duplicated text files for 13 different languages. Each language file is available in five sizes, ranging from large (~ 26,000 lines equivalent to approx. 750K tokens), to micro (~ 1,625 lines and 125K tokens avg).\\nOriginal data sourced from HuggingFaceFW/fineweb and HuggingFaceFW/fineweb-2\\n\\n\\t\\n\\t\\t\\nFile\\nLanguage\\nLines\\nSize\\n\\n\\n\\t\\t\\ncalibration_ar_large\\nArabic\\n26,000\\n3.1M… See the full description on the dataset page: https://huggingface.co/datasets/eaddario/imatrix-calibration."},
	{"name":"default-domain-cot-dataset","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/pohsjxx/default-domain-cot-dataset","creator_name":"jerry zhang","creator_url":"https://huggingface.co/pohsjxx","description":"\\n\\t\\n\\t\\t\\n\\t\\t无人机云数据 Chain-of-Thought Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tData Categories\\n\\t\\n\\n\\n无人机系统使用人/运营人登记数据\\n无人机驾驶员登记数据\\n无人机系统设备登记数据\\n空域申请数据\\n飞行计划申请数据\\n无人机系统接入校验/开机上报数据\\n放飞申请/在线授权数据\\n数据链路心跳保活数据\\n无人机围栏数据更新\\n禁区/限飞区告警数据\\n飞行情报信息通知数据\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tSchema Information\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tflight_subject\\n\\t\\n\\n\\naircraft_registration_number (str, required): 无人机注册编号\\naircraft_type (str, optional): 无人机类型\\ncontrol_system_mac_address (str, optional): 控制系统MAC地址\\noperator_id (str, required): 操作人ID\\noperator_name (str, required): 操作人姓名… See the full description on the dataset page: https://huggingface.co/datasets/pohsjxx/default-domain-cot-dataset."},
	{"name":"Synthdog-Multilingual-100","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/WueNLP/Synthdog-Multilingual-100","creator_name":"WüNLP","creator_url":"https://huggingface.co/WueNLP","description":"\\n\\t\\n\\t\\t\\n\\t\\tSynthdog Multilingual\\n\\t\\n\\n\\n\\nThe Synthdog dataset created for training in Centurio: On Drivers of Multilingual Ability of Large Vision-Language Model.\\nUsing the official Synthdog code, we created >1 million training samples for improving OCR capabilities in Large Vision-Language Models.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Details\\n\\t\\n\\nWe provide the images for download in two .tar.gz files. Download and extract them in folders of the same name (so cat images.tar.gz.* | tar xvzf -C images; tar xvzf… See the full description on the dataset page: https://huggingface.co/datasets/WueNLP/Synthdog-Multilingual-100."},
	{"name":"System-Prompt-Instruction-Real-world-Implementation-Training-set","keyword":"chinese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/EricLu/System-Prompt-Instruction-Real-world-Implementation-Training-set","creator_name":"Eric Lu","creator_url":"https://huggingface.co/EricLu","description":"\\n\\t\\n\\t\\t\\n\\t\\tSPIRIT Dataset (System Prompt Instruction Real-world Implementation Training-set)\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nSPIRIT is a high-quality system prompt instruction dataset designed to enhance language models' ability to follow complex system prompts. The dataset comprises real-world system prompts collected from GitHub repositories and synthetically generated conversations, specifically curated to improve system prompt adherence in large language models.\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Creation… See the full description on the dataset page: https://huggingface.co/datasets/EricLu/System-Prompt-Instruction-Real-world-Implementation-Training-set."},
	{"name":"HealthRCN","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Hush-cd/HealthRCN","creator_name":"ding chen","creator_url":"https://huggingface.co/Hush-cd","description":"Hush-cd/HealthRCN dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"DynVQA","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/zhzhen23/DynVQA","creator_name":"ZhenZhang","creator_url":"https://huggingface.co/zhzhen23","description":"\\n\\t\\n\\t\\t\\n\\t\\t📚 Dyn-VQA Dataset\\n\\t\\n\\n📑 Dataset for Benchmarking Multimodal Retrieval Augmented Generation with Dynamic VQA Dataset and Self-adaptive Planning Agent\\n🌟 This dataset is linked to GitHub at this URL.\\nThe json item of Dyn-VQA dataset is organized in the following format:\\n{\\n    \\\"image_url\\\": \\\"https://www.pcarmarket.com/static/media/uploads/galleries/photos/uploads/galleries/22387-pasewark-1986-porsche-944/.thumbnails/IMG_7102.JPG.jpg/IMG_7102.JPG-tiny-2048x0-0.5x0.jpg\\\",\\n    \\\"question\\\":… See the full description on the dataset page: https://huggingface.co/datasets/zhzhen23/DynVQA."},
	{"name":"LIMO_chinese","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Minami-su/LIMO_chinese","creator_name":"南栖","creator_url":"https://huggingface.co/Minami-su","description":"Dataset chinese version for LIMO: Less is More for Reasoning\\n\\n\\t\\n\\t\\t\\n\\t\\tUsage\\n\\t\\n\\nfrom datasets import load_dataset\\ndataset = load_dataset(\\\"Minami-su/LIMO_chinese\\\", split=\\\"train\\\")\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tCitation\\n\\t\\n\\n@misc{ye2025limoreasoning,\\n      title={LIMO: Less is More for Reasoning}, \\n      author={Yixin Ye and Zhen Huang and Yang Xiao and Ethan Chern and Shijie Xia and Pengfei Liu},\\n      year={2025},\\n      eprint={2502.03387},\\n      archivePrefix={arXiv},\\n      primaryClass={cs.CL}… See the full description on the dataset page: https://huggingface.co/datasets/Minami-su/LIMO_chinese."},
	{"name":"Better-Ruozhiba","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/FunnySaltyFish/Better-Ruozhiba","creator_name":"FunnySaltyFish","creator_url":"https://huggingface.co/FunnySaltyFish","description":"\\n\\t\\n\\t\\t\\n\\t\\tBetter Ruozhiba\\n\\t\\n\\n原项目为 https://huggingface.co/datasets/LooksJuicy/ruozhiba，原部分答案为 GPT-4 生成。贡献者们人为审阅了每一条的原文和回复，剔除了一些原文中的格式错误，修改或重写了部分答案。希望对大语言模型的中文语料有所帮助。\\n\\nPS. 正儿八经回答弱智吧的问题，真是一种奇妙的感觉\\n\\n\\n\\t\\n\\t\\t\\n\\t\\t参与贡献\\n\\t\\n\\n如果有意参与贡献，请查看此 issue\\n贡献者列表：\\n\\n\\n\\t\\n\\t\\t\\n\\t\\t引用\\n\\t\\n\\n如果本项目对你有所帮助，请引用：\\n@misc{better-ruozhiba,\\n    title={Better Ruozhiba},\\n    author={Ruozhiba and FunnySaltyFish and Misdirection and Xinsu,Liu},\\n    year={2024},\\n    publisher = {GitHub},\\n    journal = {GitHub repository},\\n    howpublished =… See the full description on the dataset page: https://huggingface.co/datasets/FunnySaltyFish/Better-Ruozhiba."},
	{"name":"Better-Ruozhiba","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/FunnySaltyFish/Better-Ruozhiba","creator_name":"FunnySaltyFish","creator_url":"https://huggingface.co/FunnySaltyFish","description":"\\n\\t\\n\\t\\t\\n\\t\\tBetter Ruozhiba\\n\\t\\n\\n原项目为 https://huggingface.co/datasets/LooksJuicy/ruozhiba，原部分答案为 GPT-4 生成。贡献者们人为审阅了每一条的原文和回复，剔除了一些原文中的格式错误，修改或重写了部分答案。希望对大语言模型的中文语料有所帮助。\\n\\nPS. 正儿八经回答弱智吧的问题，真是一种奇妙的感觉\\n\\n\\n\\t\\n\\t\\t\\n\\t\\t参与贡献\\n\\t\\n\\n如果有意参与贡献，请查看此 issue\\n贡献者列表：\\n\\n\\n\\t\\n\\t\\t\\n\\t\\t引用\\n\\t\\n\\n如果本项目对你有所帮助，请引用：\\n@misc{better-ruozhiba,\\n    title={Better Ruozhiba},\\n    author={Ruozhiba and FunnySaltyFish and Misdirection and Xinsu,Liu},\\n    year={2024},\\n    publisher = {GitHub},\\n    journal = {GitHub repository},\\n    howpublished =… See the full description on the dataset page: https://huggingface.co/datasets/FunnySaltyFish/Better-Ruozhiba."},
	{"name":"BenchMAX_Math","keyword":"chinese","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/LLaMAX/BenchMAX_Math","creator_name":"LLaMAX","creator_url":"https://huggingface.co/LLaMAX","description":"\\n\\t\\n\\t\\t\\n\\t\\tDataset Sources\\n\\t\\n\\n\\nPaper: BenchMAX: A Comprehensive Multilingual Evaluation Suite for Large Language Models\\nLink: https://arxiv.org/pdf/2502.07346\\nRepository: https://github.com/CONE-MT/BenchMAX\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\nBenchMAX_Math is a dataset of BenchMAX, sourcing from MGSM.\\nWe extend the original dataset to 6 more languages.\\nThe data is first translated by Google Translate, and then post-editing by native speakers.\\n\\n\\t\\n\\t\\t\\n\\t\\tSupported Languages\\n\\t\\n\\nArabic, Bengali, Chinese… See the full description on the dataset page: https://huggingface.co/datasets/LLaMAX/BenchMAX_Math."},
	{"name":"BenchMAX_Science","keyword":"chinese","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/LLaMAX/BenchMAX_Science","creator_name":"LLaMAX","creator_url":"https://huggingface.co/LLaMAX","description":"\\n\\t\\n\\t\\t\\n\\t\\tDataset Sources\\n\\t\\n\\n\\nPaper: BenchMAX: A Comprehensive Multilingual Evaluation Suite for Large Language Models\\nLink: https://arxiv.org/pdf/2502.07346\\nRepository: https://github.com/CONE-MT/BenchMAX\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\nBenchMAX_Science is a dataset of BenchMAX, sourcing from GPQA.\\nWe extend the original English dataset to 16 non-English languages.\\nThe data is first translated by Google Translate, and then post-editing by native speakers.\\n\\n\\t\\n\\t\\t\\n\\t\\tSupported Languages\\n\\t\\n\\nArabic… See the full description on the dataset page: https://huggingface.co/datasets/LLaMAX/BenchMAX_Science."},
	{"name":"BenchMAX_Function_Completion","keyword":"chinese","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/LLaMAX/BenchMAX_Function_Completion","creator_name":"LLaMAX","creator_url":"https://huggingface.co/LLaMAX","description":"\\n\\t\\n\\t\\t\\n\\t\\tDataset Sources\\n\\t\\n\\n\\nPaper: BenchMAX: A Comprehensive Multilingual Evaluation Suite for Large Language Models\\nLink: https://arxiv.org/pdf/2502.07346\\nRepository: https://github.com/CONE-MT/BenchMAX\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\nBenchMAX_Function_Completion is a dataset of BenchMAX, sourcing from humanevalplus.\\nWe extend the original English dataset to 16 non-English languages.\\nThe data is first translated by GPT-4o, and then post-editing by native speakers.\\n\\n\\t\\n\\t\\t\\n\\t\\tSupported Languages… See the full description on the dataset page: https://huggingface.co/datasets/LLaMAX/BenchMAX_Function_Completion."},
	{"name":"BenchMAX_Problem_Solving","keyword":"chinese","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/LLaMAX/BenchMAX_Problem_Solving","creator_name":"LLaMAX","creator_url":"https://huggingface.co/LLaMAX","description":"\\n\\t\\n\\t\\t\\n\\t\\tDataset Sources\\n\\t\\n\\n\\nPaper: BenchMAX: A Comprehensive Multilingual Evaluation Suite for Large Language Models\\nLink: https://arxiv.org/pdf/2502.07346\\nRepository: https://github.com/CONE-MT/BenchMAX\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\nBenchMAX_Problem_Solving is a dataset of BenchMAX, sourcing from LiveCodeBench.\\nWe extend the original English dataset to 16 non-English languages.\\nThe data is first translated by GPT-4o, and then post-editing by native speakers.\\n\\n\\t\\n\\t\\t\\n\\t\\tSupported Languages… See the full description on the dataset page: https://huggingface.co/datasets/LLaMAX/BenchMAX_Problem_Solving."},
	{"name":"gsm8k-r1-qwen-32b","keyword":"chinese","license":"GNU General Public License v3.0","license_url":"https://choosealicense.com/licenses/gpl-3.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Orion-zhen/gsm8k-r1-qwen-32b","creator_name":"Orion","creator_url":"https://huggingface.co/Orion-zhen","description":"\\n\\t\\n\\t\\t\\n\\t\\tgsm8k\\n\\t\\n\\nI translated questions into Chinese, and let DeepSeek-R1-Distill-Qwen-32B generate answers. Then I validated all answers, filtering out incorrect ones, and finally I fixed latex formatting errors such as \\\\boxed{}\\n"},
	{"name":"Retrieval-SFT-Chat","keyword":"chinese","license":"\"Do What The F*ck You Want To Public License\"","license_url":"https://choosealicense.com/licenses/wtfpl/","language":"en","dataset_url":"https://huggingface.co/datasets/CausalLM/Retrieval-SFT-Chat","creator_name":"CausalLM","creator_url":"https://huggingface.co/CausalLM","description":"\\n\\t\\n\\t\\t\\n\\t\\tRetrieval-Based Multi-Turn Chat SFT Synthetic Data\\n\\t\\n\\nA year ago, we released CausalLM/Refined-Anime-Text, a thematic subset of a dataset generated using the then state-of-the-art LLMs. This dataset comprises 1 million entries synthesized through long-context models that rewrote multi-document web text inputs, intended for continued pre-training. We are pleased to note that this data has been employed in various training scenarios and in studies concerning data and internet culture.\\nIn… See the full description on the dataset page: https://huggingface.co/datasets/CausalLM/Retrieval-SFT-Chat."},
	{"name":"ruozhiba-dataset","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/DylanDDeng/ruozhiba-dataset","creator_name":"Chengsheng Deng","creator_url":"https://huggingface.co/DylanDDeng","description":"\\n\\t\\n\\t\\t\\n\\t\\tDeepSeek-R1 Ruozhiba Dataset\\n\\t\\n\\nThis repository contains responses generated using Together AI's DeepSeek-R1 API for the Ruozhiba GPT4 dataset. The dataset consists of 4,898 question-answer pairs in Chinese.\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Details\\n\\t\\n\\n\\nSource: Original questions from hfl/ruozhiba_gpt4\\nModel: DeepSeek-R1 via Together AI API\\nSystem Prompt: Adapted from bespokelabs/Bespoke-Stratos-17k\\nFormat: JSON\\nSize: 4,898 entries\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tKnown Limitations\\n\\t\\n\\nDuring the response generation process… See the full description on the dataset page: https://huggingface.co/datasets/DylanDDeng/ruozhiba-dataset."},
	{"name":"smol","keyword":"chinese","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/google/smol","creator_name":"Google","creator_url":"https://huggingface.co/google","description":"\\n\\t\\n\\t\\t\\n\\t\\tSMOL\\n\\t\\n\\nSMOL (Set for Maximal Overall Leverage) is a collection of professional\\ntranslations into 221 Low-Resource Languages, for the purpose of training\\ntranslation models, and otherwise increasing the representations of said\\nlanguages in NLP and technology.\\nPlease read the SMOL Paper and the\\nGATITOS Paper for a much more\\nthorough description!\\nThere are four resources in this directory:\\n\\nSmolDoc: document-level translations into 100 languages\\nSmolSent: sentence-level translations into… See the full description on the dataset page: https://huggingface.co/datasets/google/smol."},
	{"name":"Gaokao-LLM-data","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Interstellar174/Gaokao-LLM-data","creator_name":"Busheng Zhang","creator_url":"https://huggingface.co/Interstellar174","description":"\\n\\t\\n\\t\\t\\n\\t\\tQZDH_Gaokao_Data: Gaokao Past Paper Reasoning Dataset\\n\\t\\n\\nChinese readme link is here: 简体中文\\nQZDH_Gaokao_Data is a dataset independently collected by the Qizhi Navigation Project, aimed at promoting the rapid development of AI education, assisting in the development of AI applications, and the construction of AI teacher models. The original intention of the team in building this dataset is to provide data support for the fine-tuning of models used by the team, and it is hoped that… See the full description on the dataset page: https://huggingface.co/datasets/Interstellar174/Gaokao-LLM-data."},
	{"name":"gsm8k_zhtw","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/yuhuanstudio/gsm8k_zhtw","creator_name":"YuhuanStudio","creator_url":"https://huggingface.co/yuhuanstudio","description":"\\n\\t\\n\\t\\t\\n\\t\\tGSM8K 繁體中文資料集\\n\\t\\n\\nGSM8K（Grade School Math 8K）是由 OpenAI 發布的一個包含 8,500 個高品質小學數學文字題的資料集，旨在評估模型在多步驟數學推理任務中的表現。原始資料集以英文撰寫，為了促進繁體中文社群對該資料集的使用與研究，我們將其完整翻譯為繁體中文。\\n\\n\\t\\n\\t\\t\\n\\t\\t翻譯方法\\n\\t\\n\\n我們採用了 Google translate 進行自動翻譯，確保問題和解答的語意與原始資料集一致。在翻譯過程中，我們特別注意數學符號、專有名詞和文化差異，確保繁體中文使用者能夠清晰理解每個問題。\\n\\n\\t\\n\\t\\t\\n\\t\\t資料集內容\\n\\t\\n\\n翻譯後的資料集包含：\\n\\n問題（question）：小學數學問題的繁體中文描述。\\n答案（answer）：對應問題的完整解答，包括多步驟推理和最終答案。\\n\\n每個問題的解答格式保持與原始資料集一致，方便使用者進行比較和研究。\\n\\n\\t\\n\\t\\t\\n\\t\\t資料集結構\\n\\t\\n\\n資料集分為訓練集和測試集：\\n\\n訓練集：7,473 個問題\\n測試集：1,319 個問題\\n\\n每個問題都需要 2 到 8… See the full description on the dataset page: https://huggingface.co/datasets/yuhuanstudio/gsm8k_zhtw."},
	{"name":"MANBench","keyword":"chinese","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/MANBench/MANBench","creator_name":"MANBench","creator_url":"https://huggingface.co/MANBench","description":"\\n\\t\\n\\t\\t\\n\\t\\tMANBench\\n\\t\\n\\nThis repo contains evaluation code for the paper \\\"MANBench: Is Your Multimodal Model Smarter than Human?\\\"\\n🌐 Homepage | 🤗 Dataset\\n\\n\\t\\n\\t\\t\\n\\t\\t🔔News\\n\\t\\n\\n\\n🔥[2025-02-09]: MANBench is now available on 🤗 Hugging Face\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tIntroduction\\n\\t\\n\\nWe introduce MANBench (Multimodal Ability Norms Benchmark), a comprehensive benchmark designed to evaluate the multimodal capabilities of both humans and MLLMs. MANBench consists of 9\\ntasks, each containing more than 110 questions, with a… See the full description on the dataset page: https://huggingface.co/datasets/MANBench/MANBench."},
	{"name":"dark_thoughts_stakeholders_en_cn","keyword":"chinese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/DataTonic/dark_thoughts_stakeholders_en_cn","creator_name":"Data Tonic (Alignment Lab)","creator_url":"https://huggingface.co/DataTonic","description":"\\n\\t\\n\\t\\t\\n\\t\\tDark Thoughts Case Studies Dataset (English-Chinese)\\n\\t\\n\\nThis dataset contains a bilingual collection of case studies with detailed stakeholder analyses in English and Chinese. Each case study includes structured information about stakeholders and their motivations, along with comprehensive case analysis and solutions.\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tOverview\\n\\t\\n\\nThe dataset consists of 344,580 case studies in English and in Chinese, with detailed stakeholder analyses and… See the full description on the dataset page: https://huggingface.co/datasets/DataTonic/dark_thoughts_stakeholders_en_cn."},
	{"name":"twllm-data","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/yentinglin/twllm-data","creator_name":"Yen-Ting Lin","creator_url":"https://huggingface.co/yentinglin","description":"\\n\\t\\n\\t\\t\\n\\t\\tTWLLM-Data: Open Traditional Mandarin LLM Conversations\\n\\t\\n\\nTWLLM-Data is the first large-scale open dataset containing real user-generated conversation logs from TWLLM and TWLLM Arena, where over 80% of users are based in Taiwan. The dataset is designed to facilitate the development and evaluation of Traditional Mandarin Large Language Models (LLMs).\\nWe extend our gratitude to Professor Yun-Nung (Vivian) Chen for her guidance and advisement. \\nSpecial thanks to Tzu-Han Lin, Kang-Chieh… See the full description on the dataset page: https://huggingface.co/datasets/yentinglin/twllm-data."},
	{"name":"DATA-AI_Chat","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Mattimax/DATA-AI_Chat","creator_name":"M.INC.","creator_url":"https://huggingface.co/Mattimax","description":"\\n\\t\\n\\t\\t\\n\\t\\tDATA-AI: Il Modello di IA di M.INC.\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\t📌 Introduzione\\n\\t\\n\\nDATA-AI è un avanzato modello di intelligenza artificiale sviluppato da *M.INC., un'azienda italiana fondata da *Mattimax (M. Marzorati).Questo modello è basato sull'architettura ELNS (Elaborazione del Linguaggio Naturale Semplice), un sistema innovativo progettato per rendere l'IA accessibile su quasi qualsiasi dispositivo, garantendo prestazioni ottimali anche su hardware limitato.  \\nDATA-AI è stato addestrato su un… See the full description on the dataset page: https://huggingface.co/datasets/Mattimax/DATA-AI_Chat."},
	{"name":"Audio-FLAN-Dataset","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/HKUSTAudio/Audio-FLAN-Dataset","creator_name":"HKUST Audio","creator_url":"https://huggingface.co/HKUSTAudio","description":"\\n\\t\\n\\t\\t\\n\\t\\tAudio-FLAN Dataset (Paper)\\n\\t\\n\\n(the FULL audio files and jsonl files are still updating)\\nAn Instruction-Tuning Dataset for Unified Audio Understanding and Generation Across Speech, Music, and Sound. \\n\\n\\t\\n\\t\\t\\n\\t\\t1. Dataset Structure\\n\\t\\n\\nThe Audio-FLAN-Dataset has the following directory structure:\\nAudio-FLAN-Dataset/\\n├── audio_files/\\n│   ├── audio/\\n│   │   └── 177_TAU_Urban_Acoustic_Scenes_2022/\\n│   │   └── 179_Audioset_for_Audio_Inpainting/\\n│   │   └── ...\\n│   ├── music/\\n│   │   └──… See the full description on the dataset page: https://huggingface.co/datasets/HKUSTAudio/Audio-FLAN-Dataset."},
	{"name":"ea-mt-benchmark","keyword":"chinese","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/sapienzanlp/ea-mt-benchmark","creator_name":"Sapienza NLP, Sapienza University of Rome","creator_url":"https://huggingface.co/sapienzanlp","description":"\\n\\t\\n\\t\\t\\n\\t\\tDataset Card for EA-MT\\n\\t\\n\\nEA-MT (Entity-Aware Machine Translation) is a multilingual benchmark for evaluating the capabilities of Large Language Models (LLMs) and Machine Translation (MT) models in translating simple sentences with potentially challenging entity mentions, e.g., entities for which a word-for-word translation may not be accurate.\\nHere is an example of a simple sentence with a challenging entity mention:\\n\\nEnglish: \\\"What is the plot of The Catcher in the Rye?\\\"\\nItalian:… See the full description on the dataset page: https://huggingface.co/datasets/sapienzanlp/ea-mt-benchmark."},
	{"name":"HouseIntelligence_1.1_zh","keyword":"chinese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/FemetoRhythm/HouseIntelligence_1.1_zh","creator_name":"cheng si yuan","creator_url":"https://huggingface.co/FemetoRhythm","description":"FemetoRhythm/HouseIntelligence_1.1_zh dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"u-sticker","keyword":"chinese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/metchee/u-sticker","creator_name":"Metilda Chee","creator_url":"https://huggingface.co/metchee","description":"\\n\\t\\n\\t\\t\\n\\t\\tU-Sticker\\n\\t\\n\\nUser-Sticker is a stickers dataset with multi-domain conversations.\\nFeatures of U-Sticker:\\n\\nMulti-domain interactions ✅\\nTemporal ✅\\nUser information ✅\\n370.2k stickers ✅ (104k unique)\\n22.6k users ✅\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\nU-Sticker contains three files:\\n\\nConversation files: 1 to 67.json\\nDomain mapping files idx_to_domain.txt.\\nSticker files.\\n\\n\\nSticker files are available here and Baidu Cloud.\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Structure\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tConversation file\\n\\t\\n\\n\\nEmpty lines are… See the full description on the dataset page: https://huggingface.co/datasets/metchee/u-sticker."},
	{"name":"high-quality-multilingual-sentences","keyword":"chinese","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/agentlans/high-quality-multilingual-sentences","creator_name":"Alan Tseng","creator_url":"https://huggingface.co/agentlans","description":"\\n\\t\\n\\t\\t\\n\\t\\tHigh Quality Multilingual Sentences\\n\\t\\n\\n\\nThis dataset contains multilingual sentences derived from the agentlans/LinguaNova dataset.\\nIt includes 1.58 million rows across 51 different languages, each in its own configuration.\\n\\nExample row (from the all config):\\n{\\n    \\\"text\\\": \\\"امام جمعه اصفهان گفت: میزان نیاز آب شرب اصفهان ۱۱.۵ متر مکعب است که تمام استان اصفهان را پوشش میدهد و نسبت به قبل از انقلاب یکی از پیشرفتها در حوزه آب بوده است.\\\",\\n    \\\"fasttext\\\": \\\"fa\\\",\\n    \\\"gcld3\\\": \\\"fa\\\"\\n}\\n\\nFields:… See the full description on the dataset page: https://huggingface.co/datasets/agentlans/high-quality-multilingual-sentences."},
	{"name":"Open-R1-Mulitlingual-SFT","keyword":"chinese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/amphora/Open-R1-Mulitlingual-SFT","creator_name":"GUIJIN SON","creator_url":"https://huggingface.co/amphora","description":"\\n\\t\\n\\t\\t\\n\\t\\tOpen-R1-Mulitlingual-SFT\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tOverview\\n\\t\\n\\nOpen-R1-Mulitlingual-SFT is a curated dataset designed for multilingual supervised fine-tuning.\\nThe source data comprises multiple datasets containing original prompts and responses, which were subsequently translated into 14 languages using GPT-4o.\\n\\n\\t\\n\\t\\t\\n\\t\\tSources\\n\\t\\n\\nThe dataset is derived from:\\n\\nopen-thoughts/OpenThoughts-114kHugging Face: open-thoughts/OpenThoughts-114k\\nbespokelabs/Bespoke-Stratos-17kHugging Face:… See the full description on the dataset page: https://huggingface.co/datasets/amphora/Open-R1-Mulitlingual-SFT."},
	{"name":"ruozhiba_o3mini","keyword":"chinese","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/hfl/ruozhiba_o3mini","creator_name":"Joint Laboratory of HIT and iFLYTEK Research (HFL)","creator_url":"https://huggingface.co/hfl","description":"\\n\\t\\n\\t\\t\\n\\t\\truozhiba_o3mini\\n\\t\\n\\n本仓库包含使用o3-mini-2025-01-31API构建的ruozhiba指令数据[^1]，共计2449条。\\n注意：指令数据中可能包含冒犯用语。输出并未经过人工验证。\\n\\n\\t\\n\\t\\t\\n\\t\\t所属项目\\n\\t\\n\\nChinese-LLaMA-Alpaca-3：https://github.com/ymcui/Chinese-LLaMA-Alpaca-3\\n\\nThis repository contains the ruozhiba instruction data[^1] constructed by using o3-mini-2025-01-31, totaling 2449 entries.\\nNote: The instruction data may contain offensive language. Outputs are NOT verified by human.\\n\\n\\t\\n\\t\\t\\n\\t\\tProject… See the full description on the dataset page: https://huggingface.co/datasets/hfl/ruozhiba_o3mini."},
	{"name":"JL1-CD","keyword":"chinese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/circleLZY/JL1-CD","creator_name":"Ziyuan Liu","creator_url":"https://huggingface.co/circleLZY","description":"\\n\\t\\n\\t\\t\\n\\t\\tDataset Card for JL1-CD\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description (English)\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tOverview\\n\\t\\n\\nJL1-CD is a large-scale, sub-meter, all-inclusive open-source dataset for remote sensing image change detection (CD). It contains 5,000 pairs of 512×512 pixel satellite images with a resolution of 0.5 to 0.75 meters, covering various types of surface changes in multiple regions of China. JL1-CD includes not only common human-induced changes (e.g., buildings, roads) but also natural changes (e.g.… See the full description on the dataset page: https://huggingface.co/datasets/circleLZY/JL1-CD."},
	{"name":"CaseGen","keyword":"chinese","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/CSHaitao/CaseGen","creator_name":"Haitao Li","creator_url":"https://huggingface.co/CSHaitao","description":"\\n\\t\\n\\t\\t\\n\\t\\tCaseGen: A Benchmark for Multi-Stage Legal Case Documents Generation\\n\\t\\n\\n\\n\\n\\n\\nCaseGen is a benchmark designed to evaluate large language models (LLMs) in the generation of legal case documents in the Chinese legal domain. The dataset includes 500 real-world legal case instances, each structured into seven sections: Prosecution, Defense, Evidence, Events, Facts, Reasoning, and Judgment. It supports four key tasks: drafting defense statements, writing trial facts, composing legal reasoning… See the full description on the dataset page: https://huggingface.co/datasets/CSHaitao/CaseGen."},
	{"name":"CaseGen","keyword":"chinese","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/CSHaitao/CaseGen","creator_name":"Haitao Li","creator_url":"https://huggingface.co/CSHaitao","description":"\\n\\t\\n\\t\\t\\n\\t\\tCaseGen: A Benchmark for Multi-Stage Legal Case Documents Generation\\n\\t\\n\\n\\n\\n\\n\\nCaseGen is a benchmark designed to evaluate large language models (LLMs) in the generation of legal case documents in the Chinese legal domain. The dataset includes 500 real-world legal case instances, each structured into seven sections: Prosecution, Defense, Evidence, Events, Facts, Reasoning, and Judgment. It supports four key tasks: drafting defense statements, writing trial facts, composing legal reasoning… See the full description on the dataset page: https://huggingface.co/datasets/CSHaitao/CaseGen."},
	{"name":"RFUAV","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/kitofrank/RFUAV","creator_name":"Rui Shi","creator_url":"https://huggingface.co/kitofrank","description":" The RFUAV DATASET \\n\\n\\n\\t\\n\\t\\t\\n\\t\\tAbstract\\n\\t\\n\\nThe official dataset repository for our paper, \\\"RFUAV: A Benchmark Dataset for Unmanned Aerial Vehicle Detection and Identification\\\", can be accessed here. RFUAV offers a comprehensive benchmark dataset for Radio-Frequency (RF)-based drone detection and identification.\\n\\nMore detailed usage see our GitHub\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tCitation\\n\\t\\n\\n@misc{shi2025rfuavbenchmarkdatasetunmanned,\\n      title={RFUAV: A Benchmark Dataset for Unmanned Aerial Vehicle Detection and… See the full description on the dataset page: https://huggingface.co/datasets/kitofrank/RFUAV."},
	{"name":"CHBench","keyword":"chinese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/TracyGuo/CHBench","creator_name":"Tracy","creator_url":"https://huggingface.co/TracyGuo","description":"\\n\\t\\n\\t\\t\\n\\t\\tOverview\\n\\t\\n\\nwe present CHBench, the first comprehensive safety-oriented Chinese health-related benchmark designed to evaluate LLMs' capabilities in understanding and addressing physical and mental health issues with a safety perspective across diverse scenarios. CHBench comprises 6,493 entries on mental health and 2,999 entries on physical health, spanning a wide range of topics.\\n\\n\\t\\n\\t\\t\\n\\t\\tResponse Assessment\\n\\t\\n\\nResponses were generated using 5 Chinese language models, see below for… See the full description on the dataset page: https://huggingface.co/datasets/TracyGuo/CHBench."},
	{"name":"OpenSeek-Pretrain-Data-Examples","keyword":"chinese","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/BAAI/OpenSeek-Pretrain-Data-Examples","creator_name":"Beijing Academy of Artificial Intelligence","creator_url":"https://huggingface.co/BAAI","description":"\\n\\t\\n\\t\\t\\n\\t\\tOpenSeek Pretraining Dataset v1.0 (Sample Release)\\n\\t\\n\\nWe have released a portion of the sampled data from the OpenSeek Pretraining Dataset v1.0, primarily including Chinese and English Common Crawl (CC) datasets. Additional domain-specific datasets will be provided in future updates.\\n\\n\\t\\n\\t\\t\\n\\t\\t📌 Dataset Sources\\n\\t\\n\\n\\nEnglish CC dataset: Mainly sourced from the Nemotron-CC dataset.\\nChinese CC dataset: Followed the Nemotron-CC data pipeline, based on aggregated open-source Chinese datasets.… See the full description on the dataset page: https://huggingface.co/datasets/BAAI/OpenSeek-Pretrain-Data-Examples."},
	{"name":"wisdomInterrogatory-R1","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/YinghaoHu/wisdomInterrogatory-R1","creator_name":"Hu","creator_url":"https://huggingface.co/YinghaoHu","description":"\\n\\t\\n\\t\\t\\n\\t\\t智海-录问 推理数据(wisdomInterrogatory-R1)\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n类别\\n数据量\\n任务描述\\n\\n\\n\\t\\t\\n罪名预测\\n20k\\n请作为中国法官,基于案件事实,对被告人进行单一罪名预测。返回格式：“罪名”.示例：“盗窃”,“敲诈勒索”。\\n\\n\\n刑期预测\\n5k\\n请作为中国法官,基于案件事实,对被告人进行量刑预测,请遵从下列规则,返回结果:- 如果量刑为有期徒刑,请返回:“量刑月数”,例如应判决5年,5年=60月,则返回60.- 如果量刑为无期徒刑,请返回:“life_imprisonment”.- 如果量刑为死刑,请返回:“death_penalty”。\\n\\n\\n论辩挖掘\\n4k\\n在法院的庭审过程中，诉方与辩方由于立场观点或事实陈述的差异，会形成庭审争议焦点，这是整场庭审的核心环节。这种辩方与诉方之间形成的逻辑互动论点对，即为争议焦点。请作为中国的辩护律师，执行“论辩挖掘”任务，即根据提供的被告罪名和诉方论点，从五个候选辩护论点中，选择一个最适合作为与诉方观点形成互动对的论点。需要特别说明的是，争议焦点的对抗，始终基于事实基础。返回格式：“编号”.示例：“1… See the full description on the dataset page: https://huggingface.co/datasets/YinghaoHu/wisdomInterrogatory-R1."},
	{"name":"wikis","keyword":"chinese","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/nyuuzyou/wikis","creator_name":"nyuuzyou","creator_url":"https://huggingface.co/nyuuzyou","description":"\\n\\t\\n\\t\\t\\n\\t\\tDataset Card for Public MediaWiki Collection\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThis dataset contains 1,662,448 articles harvested from 930 random public MediaWiki instances found across the Internet. The collection was created by extracting current page content from these wikis, preserving article text, metadata, and structural information. The dataset represents a diverse cross-section of public wiki content spanning multiple domains, topics, and languages.\\n\\n\\t\\n\\t\\t\\n\\t\\tLanguages\\n\\t\\n\\nThe… See the full description on the dataset page: https://huggingface.co/datasets/nyuuzyou/wikis."},
	{"name":"wikipedia_quality_wikirank","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/lewoniewski/wikipedia_quality_wikirank","creator_name":"Włodzimierz Lewoniewski","creator_url":"https://huggingface.co/lewoniewski","description":"Datasets with WikiRank quality score as of 1 August 2024 for 47 million Wikipedia articles in 55 language versions (also simplified version for each language in separate files).\\nThe WikiRank quality score is a metric designed to assess the overall quality of a Wikipedia article. Although its specific algorithm can vary depending on the implementation, the score typically combines several key features of the Wikipedia article.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tWhy It’s Important\\n\\t\\n\\n\\nEnhances Trust: For readers and… See the full description on the dataset page: https://huggingface.co/datasets/lewoniewski/wikipedia_quality_wikirank."},
	{"name":"hwtcm-deepseek-r1-distill-data","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Monor/hwtcm-deepseek-r1-distill-data","creator_name":"Monor Huang","creator_url":"https://huggingface.co/Monor","description":"\\n\\t\\n\\t\\t\\n\\t\\t简介\\n\\t\\n\\nDeepSeek蒸馏的传统中医数据集，原始数据来源于网络，未进行人工审查。\\n\\n\\t\\n\\t\\t\\n\\t\\t7B模型微调效果\\n\\t\\n\\n\\n模型表现出了推理能力，准确性有待继续验证。\\n\\n\\n\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\t我们的其他产品\\n\\t\\n\\n中医NER：能识别方剂、本草、来源、病名、症状、证型，也许是基于BERT开源模型中识别最好的模型。中医考试题：也许是全网最早开源、数据最多的中医考试题，我们内部将其用于模型训练的性能评测数据集。中医SFT数据集：中医QA数据集，用于SFT微调。仓公：基于Qwen的指令微调模型（暂未开源）。仓公R1：基于DeepSeek蒸馏的超过100万条QA的指令微调模型，拥有强大的推理能力（暂未开源）。  \\n。。。还有很多\\n\\n\\t\\n\\t\\t\\n\\t\\tCitation\\n\\t\\n\\nIf you find this project useful in your research, please consider cite:\\n@misc{hwtcm2024,\\n    title={{hwtcm-deepseek-r1-distill-data} A traditional… See the full description on the dataset page: https://huggingface.co/datasets/Monor/hwtcm-deepseek-r1-distill-data."},
	{"name":"HAIC","keyword":"chinese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/KuaishouHAIC/HAIC","creator_name":"KuaishouHAIC","creator_url":"https://huggingface.co/KuaishouHAIC","description":"\\n\\t\\n\\t\\t\\n\\t\\tHAIC: Human Action and Interaction Comprehension Dataset\\n\\t\\n\\nFrom the paper: \\\"HAIC: Improving Human Action Understanding and Generation with Better Captions for Multi-modal Large Language Models\\\"\\nRead the Paper\\n\\n\\n\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tOverview\\n\\t\\n\\nHAICBench is a comprehensive video dataset featuring manually annotated, fine-grained human captions that features:\\n\\nMultiple Human Subjects: Captions detail interactions and activities involving more than one person, capturing the complexity of human… See the full description on the dataset page: https://huggingface.co/datasets/KuaishouHAIC/HAIC."},
	{"name":"runpod_multi_model_think_content_casestudies","keyword":"chinese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/DataTonic/runpod_multi_model_think_content_casestudies","creator_name":"Data Tonic (Alignment Lab)","creator_url":"https://huggingface.co/DataTonic","description":"DataTonic/runpod_multi_model_think_content_casestudies dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"Thinking-multilingual-big-10k-sft","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Pinkstack/Thinking-multilingual-big-10k-sft","creator_name":"Pinkstack","creator_url":"https://huggingface.co/Pinkstack","description":"\\nA dataset based off of openo1 math, 500 examples translated to 23 different languages. filtered out un-translated examples.\\nenjoy 👍\\n"},
	{"name":"multilingual_translation_sft","keyword":"chinese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Youseff1987/multilingual_translation_sft","creator_name":"JOON HYOUNG JUN","creator_url":"https://huggingface.co/Youseff1987","description":"Youseff1987/multilingual_translation_sft dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"m-WildVision","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/CohereForAI/m-WildVision","creator_name":"Cohere For AI","creator_url":"https://huggingface.co/CohereForAI","description":"\\n\\t\\n\\t\\t\\n\\t\\tDataset Card for m-WildVision\\n\\t\\n\\n\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Details\\n\\t\\n\\nThe m-WildVision dataset is a multilingual multimodal LLM evaluation set covering 23 languages.  It was created by translating prompts from the original English-only WildVision (vision_bench_0617) test set. \\nThe original prompts, developed by Lu et al. (2024) , consist of 500 challenging user queries sourced from the WildVision-Arena platform. \\nThe authors demonstrated that these prompts enable automatic LLM judge… See the full description on the dataset page: https://huggingface.co/datasets/CohereForAI/m-WildVision."},
	{"name":"OpenHumanreasoning-multilingual-2.2k","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Pinkstack/OpenHumanreasoning-multilingual-2.2k","creator_name":"Pinkstack","creator_url":"https://huggingface.co/Pinkstack","description":"Based off of Pinkstackorg/humanreasoning-testing-en, it is a human-generated dataset where a real person had to create most of the reasoning and the final output. If there are any mistakes please let us know.\\nWe offer this dataset at an apache-2.0 license to make it useful for everybody.\\nnote: translations are not human generated.\\n"},
	{"name":"DataOne-synthetic-parking-v1.1-sample","keyword":"chinese","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/51WORLD/DataOne-synthetic-parking-v1.1-sample","creator_name":"51WORLD","creator_url":"https://huggingface.co/51WORLD","description":"\\n\\t\\n\\t\\t\\n\\t\\t51WORLD Synthetic Dataset Usage Documentation\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\t1 Introduction\\n\\t\\n\\nThe 51WORLD systhetic dataset mainly contains camera sensor-related data and LiDAR sensor-related data generated by 51Sim-One. Camera sensor-related data mainly includes images and corresponding semantic segmentation, instance segmentation, depth annotation, and Object Detection annotation; LiDAR sensor-related data mainly includes laser point clouds and annotation of 3Dbboxes, semantic segmentation annotation… See the full description on the dataset page: https://huggingface.co/datasets/51WORLD/DataOne-synthetic-parking-v1.1-sample."},
	{"name":"DataOne-synthetic-nuscenes-v1.1-sample","keyword":"chinese","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/51WORLD/DataOne-synthetic-nuscenes-v1.1-sample","creator_name":"51WORLD","creator_url":"https://huggingface.co/51WORLD","description":"\\n\\t\\n\\t\\t\\n\\t\\t51WORLD Synthetic Dataset Usage Documentation\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\t1 Introduction\\n\\t\\n\\nThe 51WORLD systhetic dataset mainly contains camera sensor-related data and LiDAR sensor-related data generated by 51Sim-One. Camera sensor-related data mainly includes images and corresponding semantic segmentation, instance segmentation, depth annotation, and Object Detection annotation; LiDAR sensor-related data mainly includes laser point clouds and annotation of 3Dbboxes, semantic segmentation annotation… See the full description on the dataset page: https://huggingface.co/datasets/51WORLD/DataOne-synthetic-nuscenes-v1.1-sample."},
	{"name":"SynthLaw","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ShengbinYue/SynthLaw","creator_name":"ShengbinYue","creator_url":"https://huggingface.co/ShengbinYue","description":"\\n\\t\\n\\t\\t\\n\\t\\tMulti-Agent Simulator Drives Language Models for Legal Intensive Interaction\\n\\t\\n\\nThis work is accepted by NAACL 2025.\\nPaper | Github\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Card for SynthLaw-4.5k\\n\\t\\n\\nSynthLaw-Dataset is a synthetic legal scenario dataset in complaint drafing. \\nThe dataset consists of 4,532 samples. Note two keys in the synthetic process: 1) real-legal source configurations and supervision mechanisms in each interaction ensure that the generated data is aligned at the sentence level, closely… See the full description on the dataset page: https://huggingface.co/datasets/ShengbinYue/SynthLaw."},
	{"name":"DocumentaryScript","keyword":"chinese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/harmomy/DocumentaryScript","creator_name":"mm","creator_url":"https://huggingface.co/harmomy","description":"\\n\\t\\n\\t\\t\\n\\t\\tDataset Card for Dataset Name\\n\\t\\n\\n\\n\\nThis dataset card aims to be a base template for new datasets. It has been generated using this raw template.\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Details\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\n\\n\\n\\n\\n\\nCurated by: [More Information Needed]\\nFunded by [optional]: [More Information Needed]\\nShared by [optional]: [More Information Needed]\\nLanguage(s) (NLP): [More Information Needed]\\nLicense: [More Information Needed]\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Sources [optional]\\n\\t\\n\\n\\n\\n\\nRepository: [More… See the full description on the dataset page: https://huggingface.co/datasets/harmomy/DocumentaryScript."},
	{"name":"bilibilicomment","keyword":"chinese","license":"GNU Affero General Public License v3.0","license_url":"https://choosealicense.com/licenses/agpl-3.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Midsummra/bilibilicomment","creator_name":"峰晓","creator_url":"https://huggingface.co/Midsummra","description":"Bilibili评论区语料(2023年)\\n在2023年爬的b站评论区语料\\n不间断地从b站各个分区爬取的热门视频评论，共计500W条左右\\n没有经过任何清洗，所以数据比较脏\\n由于游戏区全是原神，所以不可避免会有很多原神有关的评论，如果不经清洗直接用来训练生成式模型或者对话模型可能会有很严重的biaes(模型一直在输出原神相关内容，，，)\\n有些datapoint中存在 “回复 @XXX :” ，表示该评论是对上一个datapoint的回复\\n"},
	{"name":"SVBench","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/yzy666/SVBench","creator_name":"Zhenyu Yang","creator_url":"https://huggingface.co/yzy666","description":"\\n\\t\\n\\t\\t\\n\\t\\tDataset Card for SVBench\\n\\t\\n\\nThis dataset card aims to provide a comprehensive overview of the SVBench dataset, including its purpose, structure, and sources. For details, see our Project, Paper and GitHub repository.\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Details\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\nSVBench is the first benchmark specifically designed to evaluate long-context streaming video understanding through temporal multi-turn question-answering (QA) chains. It addresses the limitations of existing video… See the full description on the dataset page: https://huggingface.co/datasets/yzy666/SVBench."},
	{"name":"GoDatas","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Karesis/GoDatas","creator_name":"杨亦锋","creator_url":"https://huggingface.co/Karesis","description":"\\n\\t\\n\\t\\t\\n\\t\\tDataset Card for Go Game Dataset for Neural Network Training\\n\\t\\n\\nThis is a high-quality dataset designed for Go neural network training, containing board positions extracted from curated SGF game records. The dataset is divided into three strength categories: Standard, Strong, and Elite, with approximately 1,000 samples per category.\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Details\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThis dataset contains Go board positions and corresponding moves extracted from high-quality SGF… See the full description on the dataset page: https://huggingface.co/datasets/Karesis/GoDatas."},
	{"name":"BRIGHTER-emotion-categories","keyword":"chinese","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/brighter-dataset/BRIGHTER-emotion-categories","creator_name":"BRIGHTER Dataset","creator_url":"https://huggingface.co/brighter-dataset","description":"\\n\\t\\n\\t\\t\\n\\t\\tBRIGHTER Emotion Categories Dataset\\n\\t\\n\\nThis dataset contains the emotion categories data from the BRIGHTER paper: BRIdging the Gap in Human-Annotated Textual Emotion Recognition Datasets for 28 Languages.\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThe BRIGHTER Emotion Categories dataset is a comprehensive multi-language, multi-label emotion classification dataset with separate configurations for each language. It represents one of the largest human-annotated emotion datasets across multiple… See the full description on the dataset page: https://huggingface.co/datasets/brighter-dataset/BRIGHTER-emotion-categories."},
	{"name":"reasoning-conversations","keyword":"chinese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/syntaxsynth/reasoning-conversations","creator_name":"SyntaxSynth","creator_url":"https://huggingface.co/syntaxsynth","description":"\\n\\t\\n\\t\\t\\n\\t\\tMultilingual Reasoning Dataset\\n\\t\\n\\n\\nInclude languages from German, Korean, Spanish, Japanese, French, Simplified Chinese, Traditional Chinese\\n\\nReasoning traces from Deepseek-v3-R1, Deepseek-v3-R1-Zero\\n\\n\\nCredits sponsored by Currents API\\n"},
	{"name":"Bilingual-Medic-4.6M","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/XeTute/Bilingual-Medic-4.6M","creator_name":"XeTute Technologies","creator_url":"https://huggingface.co/XeTute","description":"\\n\\n  \\n\\n\\n🚀 One of the largest medical datasets on HuggingFace\\n\\n\\n\\n\\n  \\n    \\n  \\n  \\n    \\n  \\n  \\n    \\n    \\n  \\n\\n\\n\\n\\nThis dataset contains approximately 4.6M samples, mainly in Chinese, but there is also a good amount of English samples.We merged, re-formatted & corrected:\\n\\nmedalpaca/medical_meadow_wikidoc: English; 10k samples\\nXeTute/Medic-Thoughts-16k: English; 16k samples\\nFreedomIntelligence/medical-o1-reasoning-SFT: English & Chinese; Merged 50.2k samples\\nticoAg/Chinese-medical-dialogue: Chinese;… See the full description on the dataset page: https://huggingface.co/datasets/XeTute/Bilingual-Medic-4.6M."},
	{"name":"h-corpus-raw","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Limour/h-corpus-raw","creator_name":"Limour","creator_url":"https://huggingface.co/Limour","description":"未清洗的中文H小说\\n仅供科学研究使用！\\n"},
	{"name":"Sex-novel-filtered","keyword":"chinese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Seikaijyu/Sex-novel-filtered","creator_name":"Seikaijyu","creator_url":"https://huggingface.co/Seikaijyu","description":"\\n\\t\\n\\t\\t\\n\\t\\t色情小说数据集\\n\\t\\n\\n\\n本数据集包含了3392条单条数据最大长度2500token的数据集\\n这是一个被人工精细化清洗过的色情小说数据集，此数据来源于Pixiv小说板块\\n原数据集有3w条，我花了一个通宵的时间配合正则人工清洗了它，最终得到了3000条语料\\n虽然精细处理过，但不能保证百分百干净\\n虽然这么说.....但此数据已经可以直接训练了，至少不会有什么大问题\\n\\n\\n\\t\\n\\t\\t\\n\\t\\t另外提一嘴，现代网络小说真难练啊，ctx特长，质量特低，风格逻辑混乱，收敛特慢，感觉根本就是一无是处嘛\\n\\t\\n\\n\\n"},
	{"name":"dpo-toxic-zh","keyword":"chinese","license":"GNU General Public License v3.0","license_url":"https://choosealicense.com/licenses/gpl-3.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Orion-zhen/dpo-toxic-zh","creator_name":"Orion","creator_url":"https://huggingface.co/Orion-zhen","description":"\\n\\t\\n\\t\\t\\n\\t\\tDPO Toxic Chinese v2.0\\n\\t\\n\\n\\n  Change Log\\n  \\n\\nv2.0: 增加了adamo1139/toxic-dpo-natural-v5, 并更新了翻译策略. prompt由t5_translate模型翻译, chosen由Uncensored大模型翻译, rejected由一般大模型对prompt生成拒绝性的回复\\nv1.0: 最初版本, 使用大模型将unalignment/toxic-dpo-v0.2翻译而来\\n\\n\\n\\n这是一个高度毒性, 高度有害的数据集, 意在展示DPO是如何破除模型的审核/对齐的\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\t使用限制\\n\\t\\n\\n这个数据集被设计用于学术研究, 而非其他恶意场景. 下载或使用这个数据集, 则视为您承认以下的事实:\\n\\n这个数据集是有毒的, 包含许多敏感内容\\n数据集中文本包含的内容和观点与我完全无关, 它们只是大模型生成的文字\\n您可以使用该数据集, 但必须遵守相关法律\\n您对您自己下载和使用数据集的行为负责, 我对您的一切行为没有任何责任\\n\\n"},
	{"name":"alt","keyword":"chinese","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mutiyama/alt","creator_name":"Masao Utiyama","creator_url":"https://huggingface.co/mutiyama","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Asian Language Treebank (ALT)\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThe ALT project aims to advance the state-of-the-art Asian natural language processing (NLP) techniques through the open collaboration for developing and using ALT. It was first conducted by NICT and UCSY as described in Ye Kyaw Thu, Win Pa Pa, Masao Utiyama, Andrew Finch and Eiichiro Sumita (2016). Then, it was developed under ASEAN IVO as described in this Web page. \\nThe process of building ALT began… See the full description on the dataset page: https://huggingface.co/datasets/mutiyama/alt."},
	{"name":"amttl","keyword":"chinese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/gavinxing/amttl","creator_name":"Gavin Xing","creator_url":"https://huggingface.co/gavinxing","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for AMTTL\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\n[More Information Needed]\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSupported Tasks and Leaderboards\\n\\t\\n\\n[More Information Needed]\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages\\n\\t\\n\\n[More Information Needed]\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Structure\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Instances\\n\\t\\n\\n[More Information Needed]\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Fields\\n\\t\\n\\n[More Information Needed]\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Splits\\n\\t\\n\\n[More Information Needed]\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Creation\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tCuration Rationale\\n\\t\\n\\n[More Information… See the full description on the dataset page: https://huggingface.co/datasets/gavinxing/amttl."},
	{"name":"opus_infopankki","keyword":"chinese","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Helsinki-NLP/opus_infopankki","creator_name":"Language Technology Research Group at the University of Helsinki","creator_url":"https://huggingface.co/Helsinki-NLP","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for infopankki\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nA parallel corpus of 12 languages, 66 bitexts.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSupported Tasks and Leaderboards\\n\\t\\n\\nThe underlying task is machine translation.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages\\n\\t\\n\\n[More Information Needed]\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Structure\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Instances\\n\\t\\n\\n[More Information Needed]\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Fields\\n\\t\\n\\n[More Information Needed]\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Splits\\n\\t\\n\\n[More Information Needed]\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Creation… See the full description on the dataset page: https://huggingface.co/datasets/Helsinki-NLP/opus_infopankki."},
	{"name":"opus_paracrawl","keyword":"chinese","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Helsinki-NLP/opus_paracrawl","creator_name":"Language Technology Research Group at the University of Helsinki","creator_url":"https://huggingface.co/Helsinki-NLP","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for OpusParaCrawl\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nParallel corpora from Web Crawls collected in the ParaCrawl project.\\nTha dataset contains:\\n\\n42 languages, 43 bitexts\\ntotal number of files: 59,996\\ntotal number of tokens: 56.11G\\ntotal number of sentence fragments: 3.13G\\n\\nTo load a language pair which isn't part of the config, all you need to do is specify the language code as pairs,\\ne.g.\\ndataset = load_dataset(\\\"opus_paracrawl\\\", lang1=\\\"en\\\", lang2=\\\"so\\\")\\n\\nYou can find… See the full description on the dataset page: https://huggingface.co/datasets/Helsinki-NLP/opus_paracrawl."},
	{"name":"opus_ubuntu","keyword":"chinese","license":"BSD 3-Clause \"New\" or \"Revised\" License","license_url":"https://choosealicense.com/licenses/bsd-3-clause/","language":"en","dataset_url":"https://huggingface.co/datasets/Helsinki-NLP/opus_ubuntu","creator_name":"Language Technology Research Group at the University of Helsinki","creator_url":"https://huggingface.co/Helsinki-NLP","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Opus Ubuntu\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThese are translations of the Ubuntu software package messages, donated by the Ubuntu community.\\nTo load a language pair which isn't part of the config, all you need to do is specify the language code as pairs.\\nYou can find the valid pairs in Homepage section of Dataset Description: http://opus.nlpl.eu/Ubuntu.php\\nE.g.\\ndataset = load_dataset(\\\"opus_ubuntu\\\", lang1=\\\"it\\\", lang2=\\\"pl\\\")\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSupported Tasks and… See the full description on the dataset page: https://huggingface.co/datasets/Helsinki-NLP/opus_ubuntu."},
	{"name":"xcopa","keyword":"chinese","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/cambridgeltl/xcopa","creator_name":"Language Technology Lab @University of Cambridge","creator_url":"https://huggingface.co/cambridgeltl","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for \\\"xcopa\\\"\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\n  XCOPA: A Multilingual Dataset for Causal Commonsense Reasoning\\nThe Cross-lingual Choice of Plausible Alternatives dataset is a benchmark to evaluate the ability of machine learning models to transfer commonsense reasoning across\\nlanguages. The dataset is the translation and reannotation of the English COPA (Roemmele et al. 2011) and covers 11 languages from 11 families and several areas around\\nthe globe. The dataset is… See the full description on the dataset page: https://huggingface.co/datasets/cambridgeltl/xcopa."},
	{"name":"xcsr","keyword":"chinese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/INK-USC/xcsr","creator_name":"INK Lab @ USC","creator_url":"https://huggingface.co/INK-USC","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for X-CSR\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nTo evaluate multi-lingual language models (ML-LMs) for commonsense reasoning in a cross-lingual zero-shot transfer setting (X-CSR), i.e., training in English and test in other languages, we create two benchmark datasets, namely X-CSQA and X-CODAH. Specifically, we automatically translate the original CSQA and CODAH datasets, which only have English versions, to 15 other languages, forming development and test sets for… See the full description on the dataset page: https://huggingface.co/datasets/INK-USC/xcsr."},
	{"name":"xquad_r","keyword":"chinese","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/google-research-datasets/xquad_r","creator_name":"Google Research Datasets","creator_url":"https://huggingface.co/google-research-datasets","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for [Dataset Name]\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nXQuAD-R is a retrieval version of the XQuAD dataset (a cross-lingual extractive\\nQA dataset). Like XQuAD, XQUAD-R is an 11-way parallel dataset,  where each\\nquestion appears in 11 different languages and has 11 parallel correct answers\\nacross the languages.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSupported Tasks and Leaderboards\\n\\t\\n\\n[More Information Needed]\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages\\n\\t\\n\\nThe dataset can be found with the following languages:\\n\\nArabic:… See the full description on the dataset page: https://huggingface.co/datasets/google-research-datasets/xquad_r."},
	{"name":"RiSAWOZ","keyword":"chinese","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/GEM/RiSAWOZ","creator_name":"GEM benchmark","creator_url":"https://huggingface.co/GEM","description":"RiSAWOZ contains 11.2K human-to-human (H2H) multiturn semantically annotated dialogues, with more than 150K utterances spanning over 12 domains, which is larger than all previous annotated H2H conversational datasets.Both single- and multi-domain dialogues are constructed, accounting for 65% and 35%, respectively."},
	{"name":"flores_101","keyword":"chinese","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/gsarti/flores_101","creator_name":"Gabriele Sarti","creator_url":"https://huggingface.co/gsarti","description":"One of the biggest challenges hindering progress in low-resource and multilingual machine translation is the \\nlack of good evaluation benchmarks. Current evaluation benchmarks either lack good coverage of low-resource \\nlanguages, consider only restricted domains, or are low quality because they are constructed using \\nsemi-automatic procedures. In this work, we introduce the FLORES evaluation benchmark, consisting of 3001 \\nsentences extracted from English Wikipedia and covering a variety of different topics and domains. \\nThese sentences have been translated in 101 languages by professional translators through a carefully \\ncontrolled process. The resulting dataset enables better assessment of model quality on the long tail of \\nlow-resource languages, including the evaluation of many-to-many multilingual translation systems, as all \\ntranslations are multilingually aligned. By publicly releasing such a high-quality and high-coverage dataset, \\nwe hope to foster progress in the machine translation community and beyond."},
	{"name":"ekar_chinese","keyword":"chinese","license":"Academic Free License v3.0","license_url":"https://choosealicense.com/licenses/afl-3.0/","language":"en","dataset_url":"https://huggingface.co/datasets/jiangjiechen/ekar_chinese","creator_name":"Jiangjie Chen","creator_url":"https://huggingface.co/jiangjiechen","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for ekar_chinese\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nNew!(9/18/2022) E-KAR v1.1 is officially released (at the main branch), with a higher-quality English dataset! In v1.1, we further improve the Chinese-to-English translation quality of the English E-KAR, with over 600 problems and over 1,000 explanations manually adjusted. You can still find previous version (as in the paper) in the v1.0 branch in the repo. For more information please refer to… See the full description on the dataset page: https://huggingface.co/datasets/jiangjiechen/ekar_chinese."},
	{"name":"xlel_wd_dictionary","keyword":"chinese","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/adithya7/xlel_wd_dictionary","creator_name":"Adithya Pratapa","creator_url":"https://huggingface.co/adithya7","description":"XLEL-WD is a multilingual event linking dataset. This sub-dataset contains a dictionary of events from Wikidata. The multilingual descriptions for Wikidata event items are taken from the corresponding Wikipedia articles."},
	{"name":"xlel_wd","keyword":"chinese","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/adithya7/xlel_wd","creator_name":"Adithya Pratapa","creator_url":"https://huggingface.co/adithya7","description":"XLEL-WD is a multilingual event linking dataset. This dataset contains mention references from multilingual Wikipedia/Wikinews articles to event items in Wikidata. The text descriptions for Wikidata events are compiled from Wikipedia articles."},
	{"name":"wit_base","keyword":"chinese","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/wikimedia/wit_base","creator_name":"Wikimedia","creator_url":"https://huggingface.co/wikimedia","description":"\\n\\t\\n\\t\\t\\n\\t\\tDataset Card for WIT\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nWikimedia's version of the Wikipedia-based Image Text (WIT) Dataset, a large multimodal multilingual dataset.\\nFrom the official blog post:\\n\\nThe core training data is taken from the Wikipedia Image-Text (WIT) Dataset, a large curated set of more than 37 million image-text associations extracted from Wikipedia articles in 108 languages that was recently released by Google Research.\\nThe WIT dataset offers extremely valuable data about the… See the full description on the dataset page: https://huggingface.co/datasets/wikimedia/wit_base."},
	{"name":"ascend","keyword":"chinese","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/filwsyl/ascend","creator_name":"jianyuan.zengjy","creator_url":"https://huggingface.co/filwsyl","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for ASCEND\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nASCEND (A Spontaneous Chinese-English Dataset) introduces a high-quality resource of spontaneous multi-turn conversational dialogue Chinese-English code-switching corpus collected in Hong Kong. ASCEND consists of 10.62 hours of spontaneous speech with a total of ~12.3K utterances. The corpus is split into 3 sets: training, validation, and test with a ratio of 8:1:1 while maintaining a balanced gender proportion on each set.… See the full description on the dataset page: https://huggingface.co/datasets/filwsyl/ascend."},
	{"name":"bucc-bitext-mining","keyword":"chinese","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/bucc-bitext-mining","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for MTEB Benchmark\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nMTEB is a heterogeneous benchmark that has been built from diverse tasks:\\n\\nBitextMining: BUCC, Tatoeba\\nClassification: AmazonCounterfactualClassification, AmazonPolarityClassification, AmazonReviewsClassification, Banking77Classification, EmotionClassification, ImdbClassification, MassiveIntentClassification, MassiveScenarioClassification, MTOPDomainClassification, MTOPIntentClassification… See the full description on the dataset page: https://huggingface.co/datasets/mteb/bucc-bitext-mining."},
	{"name":"lccc","keyword":"chinese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/silver/lccc","creator_name":"Silver","creator_url":"https://huggingface.co/silver","description":"LCCC: Large-scale Cleaned Chinese Conversation corpus (LCCC) is a large corpus of Chinese conversations.\\nA rigorous data cleaning pipeline is designed to ensure the quality of the corpus.\\nThis pipeline involves a set of rules and several classifier-based filters.\\nNoises such as offensive or sensitive words, special symbols, emojis,\\ngrammatically incorrect sentences, and incoherent conversations are filtered."},
	{"name":"SalienceEvaluation","keyword":"chinese","license":"GNU General Public License v3.0","license_url":"https://choosealicense.com/licenses/gpl-3.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Yincen/SalienceEvaluation","creator_name":"Qu","creator_url":"https://huggingface.co/Yincen","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Yincen/SalienceEvaluation\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\n[More Information Needed]\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSupported Tasks and Leaderboards\\n\\t\\n\\n[More Information Needed]\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages\\n\\t\\n\\n[More Information Needed]\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Structure\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Instances\\n\\t\\n\\n[More Information Needed]\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Fields\\n\\t\\n\\n[More Information Needed]\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Splits\\n\\t\\n\\n[More Information Needed]\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Creation\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tCuration Rationale… See the full description on the dataset page: https://huggingface.co/datasets/Yincen/SalienceEvaluation."},
	{"name":"hatecheck-mandarin","keyword":"chinese","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Paul/hatecheck-mandarin","creator_name":"Paul Röttger","creator_url":"https://huggingface.co/Paul","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Multilingual HateCheck\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nMultilingual HateCheck (MHC) is a suite of functional tests for hate speech detection models in 10 different languages: Arabic, Dutch, French, German, Hindi, Italian, Mandarin, Polish, Portuguese and Spanish.\\nFor each language, there are 25+ functional tests that correspond to distinct types of hate and challenging non-hate.\\nThis allows for targeted diagnostic insights into model performance.\\nFor more… See the full description on the dataset page: https://huggingface.co/datasets/Paul/hatecheck-mandarin."},
	{"name":"xP3all","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/bigscience/xP3all","creator_name":"BigScience Workshop","creator_url":"https://huggingface.co/bigscience","description":"xP3 (Crosslingual Public Pool of Prompts) is a collection of prompts & datasets across 46 of languages & 16 NLP tasks. It is used for the training of BLOOMZ and mT0, multilingual language models capable of following human instructions in dozens of languages zero-shot."},
	{"name":"xP3mt","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/bigscience/xP3mt","creator_name":"BigScience Workshop","creator_url":"https://huggingface.co/bigscience","description":"xP3 (Crosslingual Public Pool of Prompts) is a collection of prompts & datasets across 46 of languages & 16 NLP tasks. It is used for the training of BLOOMZ and mT0, multilingual language models capable of following human instructions in dozens of languages zero-shot."},
	{"name":"miracl-corpus","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/miracl/miracl-corpus","creator_name":"MIRACL","creator_url":"https://huggingface.co/miracl","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for MIRACL Corpus\\n\\t\\n\\nMIRACL 🌍🙌🌏 (Multilingual Information Retrieval Across a Continuum of Languages) is a multilingual retrieval dataset that focuses on search across 18 different languages, which collectively encompass over three billion native speakers around the world.\\nThis dataset contains the collection data of the 16 \\\"known languages\\\". The remaining 2 \\\"surprise languages\\\" will not be released until later.\\nThe corpus for each language is prepared from a… See the full description on the dataset page: https://huggingface.co/datasets/miracl/miracl-corpus."},
	{"name":"shu","keyword":"chinese","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/shjwudp/shu","creator_name":"Jianbin Chang","creator_url":"https://huggingface.co/shjwudp","description":"shu is a chinese book dataset."},
	{"name":"crosswoz","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ConvLab/crosswoz","creator_name":"ConvLab","creator_url":"https://huggingface.co/ConvLab","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for CrossWOZ\\n\\t\\n\\n\\nRepository: https://github.com/thu-coai/CrossWOZ\\nPaper: https://aclanthology.org/2020.tacl-1.19/\\nLeaderboard: None\\nWho transforms the dataset: Qi Zhu(zhuq96 at gmail dot com)\\n\\nTo use this dataset, you need to install ConvLab-3 platform first. Then you can load the dataset via:\\nfrom convlab.util import load_dataset, load_ontology, load_database\\n\\ndataset = load_dataset('crosswoz')\\nontology = load_ontology('crosswoz')\\ndatabase = load_database('crosswoz')… See the full description on the dataset page: https://huggingface.co/datasets/ConvLab/crosswoz."},
	{"name":"HashtagPrediction","keyword":"chinese","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Twitter/HashtagPrediction","creator_name":"Twitter","creator_url":"https://huggingface.co/Twitter","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tHashtag Prediction Dataset from paper TwHIN-BERT: A Socially-Enriched Pre-trained Language Model for Multilingual Tweet Representations\\n\\t\\n\\n  \\nThis repo contains the Hashtag prediction dataset from our paper TwHIN-BERT: A Socially-Enriched Pre-trained Language Model for Multilingual Tweet Representations. \\n[arXiv]\\n[HuggingFace Models]\\n[Github repo]\\nThis work is licensed under a Creative Commons Attribution 4.0 International License.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDownload\\n\\t\\n\\nUse the… See the full description on the dataset page: https://huggingface.co/datasets/Twitter/HashtagPrediction."},
	{"name":"chinese-c4","keyword":"chinese","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/shjwudp/chinese-c4","creator_name":"Jianbin Chang","creator_url":"https://huggingface.co/shjwudp","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tIntroduction\\n\\t\\n\\nChinese-C4 is a clean Chinese internet dataset based on Common Crawl. The dataset is 46.29GB and has undergone multiple cleaning strategies, including Chinese filtering, heuristic cleaning based on punctuation, line-based hashing for deduplication, and repetition removal.\\nThe dataset is open source and free for commercial use, and you are welcome to use the data and the cleaning strategies provided and contribute your cleaning strategies.\\nYou can find the cleaning… See the full description on the dataset page: https://huggingface.co/datasets/shjwudp/chinese-c4."},
	{"name":"clue-ner","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/xusenlin/clue-ner","creator_name":"xusenlin","creator_url":"https://huggingface.co/xusenlin","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tCLUE-NER 命名实体识别数据集\\n\\t\\n\\n字段说明\\n\\ntext: 文本\\n\\nentities: 文本中包含的实体\\n\\nid: 实体 id\\n\\nentity: 实体对应的字符串\\n\\nstart_offset: 实体开始位置\\n\\nend_offset: 实体结束位置的下一位\\n\\nlabel: 实体对应的开始位置\\n\\n\\n\\n\\n"},
	{"name":"trdg_random_en_zh_text_recognition","keyword":"chinese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/priyank-m/trdg_random_en_zh_text_recognition","creator_name":"priyank","creator_url":"https://huggingface.co/priyank-m","description":"\\n\\t\\n\\t\\t\\n\\t\\tDataset Card for \\\"trdg_random_en_zh_text_recognition\\\"\\n\\t\\n\\nThis synthetic dataset was generated using the TextRecognitionDataGenerator(TRDG) open source repo: \\nhttps://github.com/Belval/TextRecognitionDataGenerator\\nIt contains images of text with random characters from Engilsh(en) and Chinese(zh) languages.\\nReference to the documentation provided by the TRDG repo: \\nhttps://textrecognitiondatagenerator.readthedocs.io/en/latest/index.html\\n"},
	{"name":"Hansel","keyword":"chinese","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/HIT-TMG/Hansel","creator_name":"HITsz-Text Machine Group","creator_url":"https://huggingface.co/HIT-TMG","description":"Hansel is a high-quality human-annotated Chinese entity linking (EL) dataset, used for testing Chinese EL systems' generalization ability to tail entities and emerging entities.\\nThe test set contains Few-shot (FS) and zero-shot (ZS) slices, has 10K examples and uses Wikidata as the corresponding knowledge base.\\nThe training and validation sets are from Wikipedia hyperlinks, useful for large-scale pretraining of Chinese EL systems."},
	{"name":"stock11","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/kuroneko5943/stock11","creator_name":"Wang Song","creator_url":"https://huggingface.co/kuroneko5943","description":"GLUE, the General Language Understanding Evaluation benchmark\\n(https://gluebenchmark.com/) is a collection of resources for training,\\nevaluating, and analyzing natural language understanding systems."},
	{"name":"wikipedia-22-12-zh-embeddings","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Cohere/wikipedia-22-12-zh-embeddings","creator_name":"Cohere","creator_url":"https://huggingface.co/Cohere","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tWikipedia (zh) embedded with cohere.ai multilingual-22-12 encoder\\n\\t\\n\\nWe encoded Wikipedia (zh) using the cohere.ai multilingual-22-12 embedding model.\\nTo get an overview how this dataset was created and pre-processed, have a look at Cohere/wikipedia-22-12.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tEmbeddings\\n\\t\\n\\nWe compute for title+\\\" \\\"+text the embeddings using our multilingual-22-12 embedding model, a state-of-the-art model that works for semantic search in 100 languages.  If you want to learn more about this… See the full description on the dataset page: https://huggingface.co/datasets/Cohere/wikipedia-22-12-zh-embeddings."},
	{"name":"douban-dushu","keyword":"chinese","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/larrylawl/douban-dushu","creator_name":"Law Ann Liat Larry","creator_url":"https://huggingface.co/larrylawl","description":"This dataset contains book reviews from DouBan Dushu. DouBan DuShu is a Chinese website where users can share their reviews about various kinds of books. Most of the users in this website are unprofessional book reviewers. Therefore, the comments are usually spoken Chinese or even Internet slang."},
	{"name":"xstory_cloze","keyword":"chinese","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/juletxara/xstory_cloze","creator_name":"Julen Etxaniz","creator_url":"https://huggingface.co/juletxara","description":"XStoryCloze consists of the professionally translated version of the [English StoryCloze dataset](https://cs.rochester.edu/nlp/rocstories/) (Spring 2016 version) to 10 non-English languages. This dataset is released by Meta AI."},
	{"name":"miracl-zh-corpus-22-12","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Cohere/miracl-zh-corpus-22-12","creator_name":"Cohere","creator_url":"https://huggingface.co/Cohere","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tMIRACL (zh) embedded with cohere.ai multilingual-22-12 encoder\\n\\t\\n\\nWe encoded the MIRACL dataset using the cohere.ai multilingual-22-12 embedding model.\\nThe query embeddings can be found in Cohere/miracl-zh-queries-22-12 and the corpus embeddings can be found in Cohere/miracl-zh-corpus-22-12.\\nFor the orginal datasets, see miracl/miracl and miracl/miracl-corpus.\\nDataset info:\\n\\nMIRACL 🌍🙌🌏 (Multilingual Information Retrieval Across a Continuum of Languages) is a multilingual… See the full description on the dataset page: https://huggingface.co/datasets/Cohere/miracl-zh-corpus-22-12."},
	{"name":"miracl-zh-queries-22-12","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Cohere/miracl-zh-queries-22-12","creator_name":"Cohere","creator_url":"https://huggingface.co/Cohere","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tMIRACL (zh) embedded with cohere.ai multilingual-22-12 encoder\\n\\t\\n\\nWe encoded the MIRACL dataset using the cohere.ai multilingual-22-12 embedding model.\\nThe query embeddings can be found in Cohere/miracl-zh-queries-22-12 and the corpus embeddings can be found in Cohere/miracl-zh-corpus-22-12.\\nFor the orginal datasets, see miracl/miracl and miracl/miracl-corpus.\\nDataset info:\\n\\nMIRACL 🌍🙌🌏 (Multilingual Information Retrieval Across a Continuum of Languages) is a multilingual… See the full description on the dataset page: https://huggingface.co/datasets/Cohere/miracl-zh-queries-22-12."},
	{"name":"wmt-mqm-human-evaluation","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/RicardoRei/wmt-mqm-human-evaluation","creator_name":"Ricardo Costa Dias Rei","creator_url":"https://huggingface.co/RicardoRei","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThis dataset contains all MQM human annotations from previous WMT Metrics shared tasks and the MQM annotations from Experts, Errors, and Context.\\nThe data is organised into 8 columns:\\n\\nlp: language pair\\nsrc: input text\\nmt: translation\\nref: reference translation\\nscore: MQM score\\nsystem: MT Engine that produced the translation\\nannotators: number of annotators\\ndomain: domain of the input text (e.g. news)\\nyear: collection year\\n\\nYou can also find the original data… See the full description on the dataset page: https://huggingface.co/datasets/RicardoRei/wmt-mqm-human-evaluation."},
	{"name":"wmt-sqm-human-evaluation","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/RicardoRei/wmt-sqm-human-evaluation","creator_name":"Ricardo Costa Dias Rei","creator_url":"https://huggingface.co/RicardoRei","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nIn 2022, several changes were made to the annotation procedure used in the WMT Translation task. In contrast to the standard DA (sliding scale from 0-100) used in previous years, in 2022 annotators performed DA+SQM (Direct Assessment + Scalar Quality Metric). In DA+SQM, the annotators still provide a raw score between 0 and 100, but also are presented with seven labeled tick marks. DA+SQM helps to stabilize scores across annotators (as compared to DA).\\nThe data… See the full description on the dataset page: https://huggingface.co/datasets/RicardoRei/wmt-sqm-human-evaluation."},
	{"name":"human_assistant_conversation","keyword":"chinese","license":"Academic Free License v3.0","license_url":"https://choosealicense.com/licenses/afl-3.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Isotonic/human_assistant_conversation","creator_name":"Isotonic","creator_url":"https://huggingface.co/Isotonic","description":"Isotonic/human_assistant_conversation dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"spanish-chinese","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Deysi/spanish-chinese","creator_name":"Caraballo","creator_url":"https://huggingface.co/Deysi","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for \\\"spanish-chinese\\\"\\n\\t\\n\\nAll sensences extracted from the United Nations Parallel Corpus v1.0.\\nThe parallel corpus consists of manually translated United Nations documents for the six\\nofficial UN languages, Arabic, Chinese, English, French, Russian, and Spanish.\\nThe corpus is freely available for download at https://conferences.unite.un.org/UNCorpus\\nunder the terms of use outlined in the attached DISCLAIMER.\\nThe original individual documents are available at the United… See the full description on the dataset page: https://huggingface.co/datasets/Deysi/spanish-chinese."},
	{"name":"spanish-chinese","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Deysi/spanish-chinese","creator_name":"Caraballo","creator_url":"https://huggingface.co/Deysi","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for \\\"spanish-chinese\\\"\\n\\t\\n\\nAll sensences extracted from the United Nations Parallel Corpus v1.0.\\nThe parallel corpus consists of manually translated United Nations documents for the six\\nofficial UN languages, Arabic, Chinese, English, French, Russian, and Spanish.\\nThe corpus is freely available for download at https://conferences.unite.un.org/UNCorpus\\nunder the terms of use outlined in the attached DISCLAIMER.\\nThe original individual documents are available at the United… See the full description on the dataset page: https://huggingface.co/datasets/Deysi/spanish-chinese."},
	{"name":"vegetable","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/cc92yy3344/vegetable","creator_name":"陈超","creator_url":"https://huggingface.co/cc92yy3344","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\t蔬菜图像数据集\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\t背景\\n\\t\\n\\n最初的实验是用世界各地发现的15种常见蔬菜进行的。实验选择的蔬菜有：豆类、苦瓜、葫芦、茄子、西兰花、卷心菜、辣椒、胡萝卜、花椰菜、黄瓜、木瓜、土豆、南瓜、萝卜和番茄。共使用了来自15个类的21000张图像，其中每个类包含1400张尺寸为224×224、格式为*.jpg的图像。数据集中70%用于培训，15%用于验证，15%用于测试。\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\t目录\\n\\t\\n\\n此数据集包含三个文件夹：\\n\\ntrain (15000 张图像)\\ntest (3000 张图像)\\nvalidation (3000 张图像)\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\t数据收集\\n\\t\\n\\n这个数据集中的图像是我们为一个项目从蔬菜农场和市场收集的。\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\t制作元数据文件\\n\\t\\n\\n运行下面python的代码，就可以在桌面生成三个csv格式的元数据文件、一个分类数据文件（需要放入到数据文件中）\\n#!/usr/bin/env python3\\n# -*- coding: utf-8 -*-\\n\\n\\\"\\\"\\n1.下载的数据文件 Vegetable… See the full description on the dataset page: https://huggingface.co/datasets/cc92yy3344/vegetable."},
	{"name":"multiturn_chat_0.8M","keyword":"chinese","license":"GNU General Public License v3.0","license_url":"https://choosealicense.com/licenses/gpl-3.0/","language":"en","dataset_url":"https://huggingface.co/datasets/BelleGroup/multiturn_chat_0.8M","creator_name":"BELLE Group // Be Everyone's Large Language model Engine","creator_url":"https://huggingface.co/BelleGroup","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tMultiturn Chat 0.8M\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\t内容\\n\\t\\n\\n包含约80万条由BELLE项目生成的用户与助手的多轮对话。\\n注意：此数据集是由ChatGPT产生的，未经过严格校验，内容可能包含错误。使用过程中请注意这一点。\\ninstruction中包含多轮对话的上文内容，以Human:和Assistant:区分，output中包含当前助手角色的回答。\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\t样例\\n\\t\\n\\n{\\n  \\\"instruction\\\":… See the full description on the dataset page: https://huggingface.co/datasets/BelleGroup/multiturn_chat_0.8M."},
	{"name":"multilingual-share","keyword":"chinese","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/cryscan/multilingual-share","creator_name":"Zhenyuan Zhang","creator_url":"https://huggingface.co/cryscan","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tMultilingual Share GPT\\n\\t\\n\\nMultilingual Share GPT, the free multi-language corpus for LLM training. All text are converted to markdown format, and classified by languages.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tGithub Repo\\n\\t\\n\\nFollow the link here to Github.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Example\\n\\t\\n\\n{\\n    \\\"id\\\": \\\"ImiMfCY\\\",\\n    \\\"lang\\\": \\\"en\\\",\\n    \\\"text\\\": \\\"\\\\n<|user|>: Let's play chess\\\\n\\\\n<|bot|>: Sure, I'd love to play chess with you! Do you want to play a virtual game or just ask chess-related questions?\\\\n\\\\n<|user|>: Virtual… See the full description on the dataset page: https://huggingface.co/datasets/cryscan/multilingual-share."},
	{"name":"CNNovel125K","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/RyokoAI/CNNovel125K","creator_name":"Ryoko AI","creator_url":"https://huggingface.co/RyokoAI","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for CNNovel125K\\n\\t\\n\\nThe BigKnow2022 dataset and its subsets are not yet complete. Not all information here may be accurate or accessible.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nCNNovel125K is a dataset composed of approximately 125,000 novels downloaded from the Chinese novel hosting site http://ibiquw.com.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSupported Tasks and Leaderboards\\n\\t\\n\\nThis dataset is primarily intended for unsupervised training of text generation models; however, it may be useful for other… See the full description on the dataset page: https://huggingface.co/datasets/RyokoAI/CNNovel125K."},
	{"name":"WikiMatrix-v1-Ja_Zh-filtered","keyword":"chinese","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/larryvrh/WikiMatrix-v1-Ja_Zh-filtered","creator_name":"larryvrh","creator_url":"https://huggingface.co/larryvrh","description":"Filtered and modified version of Japanese/Chinese language pair data from WikiMatrix v1.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tProcess steps:\\n1. Basic regex based filtering / length checking to remove abnormal pairs.\\n2. Semantic similarity filtering with a threshold value of 0.6, based on sentence-transformers/LaBSE.\\n3. Convert all Traditional Chinese sentences into Simplified Chinese with zhconv.\\n\\t\\n\\n经过过滤和修改的日语/中文语言对数据，来自WikiMatrix v1。\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\t处理步骤：\\n1. 基本的基于正则表达式的过滤/长度检查，以删除异常对。\\n2.… See the full description on the dataset page: https://huggingface.co/datasets/larryvrh/WikiMatrix-v1-Ja_Zh-filtered."},
	{"name":"generated_chat_0.4M","keyword":"chinese","license":"GNU General Public License v3.0","license_url":"https://choosealicense.com/licenses/gpl-3.0/","language":"en","dataset_url":"https://huggingface.co/datasets/BelleGroup/generated_chat_0.4M","creator_name":"BELLE Group // Be Everyone's Large Language model Engine","creator_url":"https://huggingface.co/BelleGroup","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tGenerated_Chat_0.4M\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\t内容\\n\\t\\n\\n包含约40万条由BELLE项目生成的个性化角色对话数据，包含角色介绍。\\n注意：此数据集是由ChatGPT产生的，未经过严格校验，题目或解题过程可能包含错误。使用过程中请注意这一点。\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\t样例\\n\\t\\n\\n{\\n  \\\"instruction\\\": \\\"于以下角色信息完成一段对话\\\\nAlice是一个年轻的律师，她正在为一个涉及濒危物种保护的案件做准备。Bob是一位当地的居民，他所在的社区经常受到该濒危物种的干扰。\\\\n\\\",\\n  \\\"input\\\": \\\",\\n  \\\"output\\\": \\\"\\\\nAlice: 你好Bob，我是濒危物种保护案的律师，很高兴见到你。我们前几天发给你的文件你看到了吗？\\\\nBob: 看到了，你们说要禁止我们在该物种的常住地采集蘑菇，这很不公平。\\\\nAlice: 保护濒危物种对整个生态系统都很重要，如果我们的举动损害了这个物种的生存，那么整个生态系统都将遭受损失。\\\\nBob:… See the full description on the dataset page: https://huggingface.co/datasets/BelleGroup/generated_chat_0.4M."},
	{"name":"K-SportsSum-BetterMapped-CN","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/CCCP-Admiral/K-SportsSum-BetterMapped-CN","creator_name":"Lai Wen Xiao","creator_url":"https://huggingface.co/CCCP-Admiral","description":"一个来自K-SportsSum：https://github.com/krystalan/k-sportssum 的实现，原作者给出了思路，但并未实现其具体过程，此数据集是对该数据集“新闻与评论句子根据相似度搭配”部分的实现。\\n方法是：遍历新闻句子，以类似指针的方式获取新闻句子的时间信息（如果有的话），然后将每两个指针作为一个范围，将范围内的新闻句遍历查找，选择最相似的句子，并删除该句以防止重复，最终获得一句新闻搭配一句评论的结果。\\n我使用了bert—Score和ROUGE指标，按照7:3加权计算分数。\\n建议 数据集内给出了该搭配的指标，请考虑使用平均数等方式过滤掉较低的坏搭配。\\nAn implementation from K-SportsSum: https://github.com/krystalan/k-sportssum was used to implement the \\\"news and comment sentences paired based on similarity\\\" section of the dataset. The original author… See the full description on the dataset page: https://huggingface.co/datasets/CCCP-Admiral/K-SportsSum-BetterMapped-CN."},
	{"name":"human_assistant_conversation_deduped","keyword":"chinese","license":"Academic Free License v3.0","license_url":"https://choosealicense.com/licenses/afl-3.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Isotonic/human_assistant_conversation_deduped","creator_name":"Isotonic","creator_url":"https://huggingface.co/Isotonic","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDeduplicated version of Isotonic/human_assistant_conversation\\n\\t\\n\\n\\nDeduped with max jaccard similarity of 0.75\\n\\n"},
	{"name":"Safety-Prompts","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/thu-coai/Safety-Prompts","creator_name":"Conversational AI (CoAI) group from Tsinghua University","creator_url":"https://huggingface.co/thu-coai","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Dataset Name\\n\\t\\n\\nGitHub Repository: https://github.com/thu-coai/Safety-Prompts\\nPaper: https://arxiv.org/abs/2304.10436\\n"},
	{"name":"ChineseSTS","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/tiansz/ChineseSTS","creator_name":"Shaotian Zhang","creator_url":"https://huggingface.co/tiansz","description":"这是一个中文文本相似度的数据集，相似度划分为 0、1。\\n该 notebook 记录了我使用本数据集的全过程。同时你也可以在 github 上下载该数据集\\n"},
	{"name":"fall-detection","keyword":"chinese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/DeZan/fall-detection","creator_name":"HuangDeZan(黄德攒)","creator_url":"https://huggingface.co/DeZan","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tWelcome to my page!\\n\\t\\n\\nthis is a fall-detection datasets,you can download to use it to do anything!\\n"},
	{"name":"dolly-15k-cn","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/jaja7744/dolly-15k-cn","creator_name":"wjaja","creator_url":"https://huggingface.co/jaja7744","description":"jaja7744/dolly-15k-cn dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"tokenizers_example_zh_en","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/TurboPascal/tokenizers_example_zh_en","creator_name":"Turbo Pascal","creator_url":"https://huggingface.co/TurboPascal","description":"用于训练分词器的基础文本\\n"},
	{"name":"IdaDB","keyword":"chinese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/IdaLee/IdaDB","creator_name":"IdaLee","creator_url":"https://huggingface.co/IdaLee","description":"IdaLee/IdaDB dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"Ziya-Eval-Chinese","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/IDEA-CCNL/Ziya-Eval-Chinese","creator_name":"Fengshenbang-LM","creator_url":"https://huggingface.co/IDEA-CCNL","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\t姜子牙中文评估数据集 Ziya-Eval-Chinese\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\t数据介绍 Dataset Summary\\n\\t\\n\\n用于评估大语言模型的中文能力\\nThis IDEA-CCNL/Ziya-Eval-Chinese dataset is designed to evaluate the ability of LLM in chinese.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\t语言 Languages\\n\\t\\n\\n中文\\nChinese\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\t数据示例 Data Instances\\n\\t\\n\\n{\\\"class\\\":\\\"问答\\\", \\\"type\\\":\\\"猜谜\\\", \\\"query\\\":\\\"双喜临门，打一中国地名\\\"}\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\t数据字段 Data Fields\\n\\t\\n\\n\\nclass: str\\ntype: str\\nquery: str\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\t引用 Citation\\n\\t\\n\\n@article{fengshenbang,\\n  author    = {Jiaxing Zhang and Ruyi Gan and Junjie Wang and… See the full description on the dataset page: https://huggingface.co/datasets/IDEA-CCNL/Ziya-Eval-Chinese."},
	{"name":"kdconv","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/thu-coai/kdconv","creator_name":"Conversational AI (CoAI) group from Tsinghua University","creator_url":"https://huggingface.co/thu-coai","description":"The KDConv dataset. GitHub repo. Original paper.\\n@inproceedings{zhou-etal-2020-kdconv,\\n    title = \\\"{K}d{C}onv: A {C}hinese Multi-domain Dialogue Dataset Towards Multi-turn Knowledge-driven Conversation\\\",\\n    author = \\\"Zhou, Hao  and\\n      Zheng, Chujie  and\\n      Huang, Kaili  and\\n      Huang, Minlie  and\\n      Zhu, Xiaoyan\\\",\\n    booktitle = \\\"ACL\\\",\\n    year = \\\"2020\\\"\\n}\\n\\n"},
	{"name":"cold","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/thu-coai/cold","creator_name":"Conversational AI (CoAI) group from Tsinghua University","creator_url":"https://huggingface.co/thu-coai","description":"The COLD dataset. GitHub repo. Original paper.\\n@inproceedings{deng-etal-2022-cold,\\n    title = \\\"{COLD}: A Benchmark for {C}hinese Offensive Language Detection\\\",\\n    author = \\\"Deng, Jiawen  and\\n      Zhou, Jingyan  and\\n      Sun, Hao  and\\n      Zheng, Chujie  and\\n      Mi, Fei  and\\n      Meng, Helen  and\\n      Huang, Minlie\\\",\\n    booktitle = \\\"EMNLP\\\",\\n    year = \\\"2022\\\"\\n}\\n\\n"},
	{"name":"ja-zh-twitter-translate","keyword":"chinese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Nekofox/ja-zh-twitter-translate","creator_name":"Huang","creator_url":"https://huggingface.co/Nekofox","description":"translate by @Nekofoxtweet (me)\\ntwitter source from @RindouMikoto\\n"},
	{"name":"Vanilla-chinese-alpaca-luotuo","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/silk-road/Vanilla-chinese-alpaca-luotuo","creator_name":"SilkRoad","creator_url":"https://huggingface.co/silk-road","description":"Vanilla骆驼是骆驼项目在23年3月21日启动的第一个数据集和模型\\n我们会陆续将更多数据集发布到hf，包括\\n\\n Coco Caption的中文翻译\\n CoQA的中文翻译\\n CNewSum的Embedding数据\\n 增广的开放QA数据\\n WizardLM的中文翻译\\n\\n如果你也在做这些数据集的筹备，欢迎来联系我们，避免重复花钱。\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\t骆驼(Luotuo): 开源中文大语言模型\\n\\t\\n\\nhttps://github.com/LC1332/Luotuo-Chinese-LLM\\n骆驼(Luotuo)项目是由冷子昂 @ 商汤科技, 陈启源 @ 华中师范大学 以及 李鲁鲁 @ 商汤科技 发起的中文大语言模型开源项目，包含了一系列语言模型。\\n( 注意: 陈启源 正在寻找2024推免导师，欢迎联系 )\\n骆驼项目不是商汤科技的官方产品。\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tCitation\\n\\t\\n\\nPlease cite the repo if you use the data or code in this repo.\\n@misc{alpaca,\\n  author={Ziang Leng… See the full description on the dataset page: https://huggingface.co/datasets/silk-road/Vanilla-chinese-alpaca-luotuo."},
	{"name":"huatuo_consultation_qa","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/FreedomIntelligence/huatuo_consultation_qa","creator_name":"FreedomAI","creator_url":"https://huggingface.co/FreedomIntelligence","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for huatuo_consultation_qa\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nWe collected data from a website for medical consultation , consisting of many online consultation records by medical experts. Each record is a QA pair: a patient raises a question and a medical doctor answers the question. The basic information of doctors (including name, hospital organization, and department) was recorded.\\nWe directly crawl patient’s questions and doctor’s answers as QA pairs, getting 32… See the full description on the dataset page: https://huggingface.co/datasets/FreedomIntelligence/huatuo_consultation_qa."},
	{"name":"lunyu","keyword":"chinese","license":"GNU General Public License v3.0","license_url":"https://choosealicense.com/licenses/gpl-3.0/","language":"en","dataset_url":"https://huggingface.co/datasets/TMZN/lunyu","creator_name":"tmzncty","creator_url":"https://huggingface.co/TMZN","description":"为https://huggingface.co/TMZN/ChatGLM-wyw  服务的数据集之一。\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tChatGLM-wyw\\n\\t\\n\\n一个读了文言文的ChatGLM\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\t缘起\\n\\t\\n\\n2023年5月16日，念叨了好久要让AI读文言文正式开工。\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\t感谢\\n\\t\\n\\n一站式整合包（含chatglm模型）：链接：https://pan.baidu.com/s/13GePNuh8ZP_DkMVRf5sHqw?pwd=2d2z \\n一站式整合包（不含模型）：链接：https://pan.baidu.com/s/1lMfG34jerHO7aFjfdKTGUw?pwd=6y7j\\n数据集制作大佬链接：https://github.com/huang1332/finetune_dataset_maker\\n模型微调大佬链接：https://github.com/mymusise/ChatGLM-Tuning\\nChatGLM官方链接：https://github.com/THUDM/ChatGLM-6B\\n"},
	{"name":"ShareGPT-Processed","keyword":"chinese","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/zetavg/ShareGPT-Processed","creator_name":"Pokai Chang","creator_url":"https://huggingface.co/zetavg","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tShareGPT-Processed\\n\\t\\n\\nThe RyokoAI/ShareGPT52K dataset, converted to Markdown and labeled with the language used.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tAcknowledgements\\n\\t\\n\\n\\nvinta/pangu.js — To insert whitespace between CJK (Chinese, Japanese, Korean) and half-width characters (alphabetical letters, numerical digits and symbols).\\nmatthewwithanm/python-markdownify — Provides a starting point to convert HTML to Markdown.\\nBYVoid/OpenCC — Conversions between Traditional Chinese and Simplified Chinese.… See the full description on the dataset page: https://huggingface.co/datasets/zetavg/ShareGPT-Processed."},
	{"name":"xOA22","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/sambanovasystems/xOA22","creator_name":"SambaNova Systems","creator_url":"https://huggingface.co/sambanovasystems","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for xOA22 - Multilingual Prompts from OpenAssistant\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nxOA22 consists of 22 prompts originally shown in Appendix E, page 25 of the OpenAssistant Conversations paper. These 22 prompts were then manually translated by volunteers into 5 languages: Arabic, Simplified Chinese, French, Hindi and Spanish. \\nThese prompts were originally created for human evaluations of the multilingual abilities of BLOOMChat. Since not all prompts could be… See the full description on the dataset page: https://huggingface.co/datasets/sambanovasystems/xOA22."},
	{"name":"x-self-instruct-seed-32","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/sambanovasystems/x-self-instruct-seed-32","creator_name":"SambaNova Systems","creator_url":"https://huggingface.co/sambanovasystems","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for xOA22 - Multilingual Prompts from OpenAssistant\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nx-self-instruct-seed-32 consists of 32 prompts chosen out of the 252 prompts in the self-instruct-seed dataset from the Self-Instruct paper. These 32 prompts were filtered out according to the following criteria:\\n\\nShould be natural in a chat setting\\nTherefore, we filter out any prompts with \\\"few-shot examples\\\", as these are all instruction prompts that we consider unnatural in a chat… See the full description on the dataset page: https://huggingface.co/datasets/sambanovasystems/x-self-instruct-seed-32."},
	{"name":"TGEA2.0","keyword":"chinese","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/jerma66/TGEA2.0","creator_name":"vinsmoke","creator_url":"https://huggingface.co/jerma66","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Dataset Name\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nIn order to diagnostically analyze and improve the capability of pretrained language models (PLMs) in text generation, we propose TGEA 2.0, to date the largest dataset built on machine-authored texts by PLMs with fine-grained semantic annotations on a wide variety of pathological generation errors. We collect 170K nominal, phrasal and sentential prompts from 6M natural sentences in 3 domains. These prompts are fed into… See the full description on the dataset page: https://huggingface.co/datasets/jerma66/TGEA2.0."},
	{"name":"invig","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/jxu124/invig","creator_name":"Jie Xu","creator_url":"https://huggingface.co/jxu124","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for \\\"invig\\\"\\n\\t\\n\\nGithub\\n@misc{invigdataset,\\n    title={InViG: Interactive Visual-Language Disambiguation with 21K Human-to-Human Dialogues},\\n    author={Zhang, Hanbo and Mo, Yuchen and Xu, Jie and Si, Qingyi and Kong, Tao},\\n    howpublished = {\\\\url{https://github.com/ZhangHanbo/invig-dataset}},\\n    year={2023}\\n}\\n\\n"},
	{"name":"rsd-ists-2016","keyword":"chinese","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ZurichNLP/rsd-ists-2016","creator_name":"University of Zurich, Department of Computational Linguistics","creator_url":"https://huggingface.co/ZurichNLP","description":"Training and test data for the task of Recognizing Semantic Differences (RSD).\\nSee the paper for details on how the dataset was created, and see our code at https://github.com/ZurichNLP/recognizing-semantic-differences for an example of how to use the data for evaluation.\\nThe data are derived from the SemEval-2016 Task 2 for Interpretable Semantic Textual Similarity organized by Agirre et al. (2016).\\nThe original URLs of the data are:\\n\\nTrain:… See the full description on the dataset page: https://huggingface.co/datasets/ZurichNLP/rsd-ists-2016."},
	{"name":"detect","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/GeorgeGuo/detect","creator_name":"guo xiaojie","creator_url":"https://huggingface.co/GeorgeGuo","description":"This is dataset for test\\n"},
	{"name":"RefGPT-Code-ds","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Mutonix/RefGPT-Code-ds","creator_name":"Dongjie Yang","creator_url":"https://huggingface.co/Mutonix","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for RefGPT-Code-ds\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\n \\n  [Paper] RefGPT  | \\n   [Github] RefGPT\\n\\n\\nRefGPT-Code is a dataset containing 76k multi-turn dialogues about programming with 37k English and 39k Chinese, which has covered most aspects of code usage scenarios and multiple types of programming languages. Both the English version and Chinese version use the public GitHub dataset on Google BiqQuery with no overlap in these two languages. RefGPT-Code has derived… See the full description on the dataset page: https://huggingface.co/datasets/Mutonix/RefGPT-Code-ds."},
	{"name":"RefGPT-Code-cr","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Mutonix/RefGPT-Code-cr","creator_name":"Dongjie Yang","creator_url":"https://huggingface.co/Mutonix","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for RefGPT-Code-cr\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\n \\n  [Paper] RefGPT  | \\n   [Github] RefGPT\\n\\n\\nRefGPT-Code is a dataset containing 76k multi-turn dialogues about programming with 37k English and 39k Chinese, which has covered most aspects of code usage scenarios and multiple types of programming languages. Both the English version and Chinese version use the public GitHub dataset on Google BiqQuery with no overlap in these two languages. RefGPT-Code has derived… See the full description on the dataset page: https://huggingface.co/datasets/Mutonix/RefGPT-Code-cr."},
	{"name":"RefGPT-Code-bg","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Mutonix/RefGPT-Code-bg","creator_name":"Dongjie Yang","creator_url":"https://huggingface.co/Mutonix","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for RefGPT-Code-bg\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\n \\n  [Paper] RefGPT  | \\n   [Github] RefGPT\\n\\n\\nRefGPT-Code is a dataset containing 76k multi-turn dialogues about programming with 37k English and 39k Chinese, which has covered most aspects of code usage scenarios and multiple types of programming languages. Both the English version and Chinese version use the public GitHub dataset on Google BiqQuery with no overlap in these two languages. RefGPT-Code has derived… See the full description on the dataset page: https://huggingface.co/datasets/Mutonix/RefGPT-Code-bg."},
	{"name":"RefGPT-Fact","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Mutonix/RefGPT-Fact","creator_name":"Dongjie Yang","creator_url":"https://huggingface.co/Mutonix","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for RefGPT-Fact\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\n \\n  [Paper] RefGPT  | \\n   [Github] RefGPT\\n\\nRefGPT-Fact is a datasets containing 100k multi-turn dialogues about factual knowledge with 50k English and 50k Chinese. The English version uses the English Wikipedia as the reference and the Chinese version uses the frequently-used Chinese online encyclopedia website, Baidu Baike.\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSupported Tasks and Leaderboards\\n\\t\\n\\nChatbot instruction finetuning… See the full description on the dataset page: https://huggingface.co/datasets/Mutonix/RefGPT-Fact."},
	{"name":"wikipedia-zh-mnbvc","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/wanng/wikipedia-zh-mnbvc","creator_name":"wangjunjie","creator_url":"https://huggingface.co/wanng","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tzhwiki-mnbvc\\n\\t\\n\\n分项目：爬取并处理中文维基百科语料\\n数据时间：202302-202305 （持续更新）\\n主项目：MNBVC(Massive Never-ending BT Vast Chinese corpus)超大规模中文语料集 https://github.com/esbatmop/MNBVC\\n该项目清洗流程主要参考：https://kexue.fm/archives/4176/comment-page-1\\n并且使用组员开发的去重工具进行数据格式化。\\n总行数（样本）: 10,754,146\\n一个示例：\\n{\\n  \\\"文件名\\\": \\\"cleaned/zhwiki-20230420/folder_0/723712.txt\\\",\\n  \\\"是否待查文件\\\": false,\\n  \\\"是否重复文件\\\": false,\\n  \\\"文件大小\\\": 558,\\n  \\\"simhash\\\": 14363740497821204542,\\n  \\\"最长段落长度\\\": 142,\\n  \\\"段落数\\\": 6,\\n  \\\"去重段落数\\\": 6,\\n  \\\"低质量段落数\\\": 0,\\n  \\\"段落\\\": [\\n    {… See the full description on the dataset page: https://huggingface.co/datasets/wanng/wikipedia-zh-mnbvc."},
	{"name":"dev_pretrain","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/TigerResearch/dev_pretrain","creator_name":"Tiger Research","creator_url":"https://huggingface.co/TigerResearch","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for \\\"dev_pretrain\\\"\\n\\t\\n\\nTigerbot模型develop pretrain数据。\\n在train_clm.py中被使用。\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tUsage\\n\\t\\n\\nimport datasets\\n\\nds_sft = datasets.load_dataset('TigerResearch/dev_pretrain')\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tField\\n\\t\\n\\n\\ncontent: 语料\\n\\n"},
	{"name":"dev_sft","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/TigerResearch/dev_sft","creator_name":"Tiger Research","creator_url":"https://huggingface.co/TigerResearch","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for \\\"dev_sft\\\"\\n\\t\\n\\nTigerbot模型develop sft数据。\\n在train_sft.py中被使用。\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tUsage\\n\\t\\n\\nimport datasets\\n\\nds_sft = datasets.load_dataset('TigerResearch/dev_sft')\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tField\\n\\t\\n\\n\\ninstruction: 指令\\ninput: 上下文信息(Optional)\\noutput: 生成目标\\n\\n"},
	{"name":"tigerbot-alpaca-zh-0.5m","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/TigerResearch/tigerbot-alpaca-zh-0.5m","creator_name":"Tiger Research","creator_url":"https://huggingface.co/TigerResearch","description":"Tigerbot 自有基于alpaca生成中文问答对\\n\\n\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tUsage\\n\\t\\n\\nimport datasets\\nds_sft = datasets.load_dataset('TigerResearch/tigerbot-alpaca-zh-0.5m')\\n\\n"},
	{"name":"tigerbot-zhihu-zh-10k","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/TigerResearch/tigerbot-zhihu-zh-10k","creator_name":"Tiger Research","creator_url":"https://huggingface.co/TigerResearch","description":"Tigerbot 基于开源搜集的知乎数据生成的sft问答对\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tUsage\\n\\t\\n\\nimport datasets\\nds_sft = datasets.load_dataset('TigerResearch/tigerbot-zhihu-zh-10k')\\n\\n"},
	{"name":"tigerbot-wiki-qa-zh-1k","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/TigerResearch/tigerbot-wiki-qa-zh-1k","creator_name":"Tiger Research","creator_url":"https://huggingface.co/TigerResearch","description":"Tigerbot 自有中文百科问答\\t数据。\\n\\n\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tUsage\\n\\t\\n\\nimport datasets\\nds_sft = datasets.load_dataset('TigerResearch/tigerbot-wiki-qa-zh-1k')\\n\\n"},
	{"name":"tigerbot-earning-plugin","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/TigerResearch/tigerbot-earning-plugin","creator_name":"Tiger Research","creator_url":"https://huggingface.co/TigerResearch","description":"Tigerbot 模型rethink时使用的外脑原始数据，财报类\\n\\n共2500篇财报，抽取后按段落保存\\n发布时间区间为: 2022-02-28 至 2023-05-10\\n\\n\\n\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tUsage\\n\\t\\n\\nimport datasets\\nds_sft = datasets.load_dataset('TigerResearch/tigerbot-earning-plugin')\\n\\n"},
	{"name":"tigerbot-research-plugin","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/TigerResearch/tigerbot-research-plugin","creator_name":"Tiger Research","creator_url":"https://huggingface.co/TigerResearch","description":"Tigerbot 模型rethink时使用的外脑原始数据，研报类\\n\\n共2W篇完整研报，按段落保存\\n\\n发布时间区间: 2022-09-30 至 2023-05-19\\n\\n\\n\\n\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tUsage\\n\\t\\n\\nimport datasets\\nds_sft = datasets.load_dataset('TigerResearch/tigerbot-research-plugin')\\n\\n"},
	{"name":"langchain-MRKL-finetune","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/PengQu/langchain-MRKL-finetune","creator_name":"Qu Peng","creator_url":"https://huggingface.co/PengQu","description":"PengQu/langchain-MRKL-finetune dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"Ziya-Visual-Eval-Chinese","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/IDEA-CCNL/Ziya-Visual-Eval-Chinese","creator_name":"Fengshenbang-LM","creator_url":"https://huggingface.co/IDEA-CCNL","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\t姜子牙-Visual中文评估数据集 Ziya-Visual-Eval-Chinese\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\t数据介绍 Dataset Summary\\n\\t\\n\\n数据集由LLaVA评估集翻译而来，图片源来自coco数据集，用于评估多模态大模型的中文能力\\nDataset translated from the LLaVA evaluation set, image source from the coco dataset, used to evaluate the Chinese language capabilities of the multimodal large model.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\t语言 Languages\\n\\t\\n\\n中文\\nChinese\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\t数据示例 Data Instances\\n\\t\\n\\n{\\\"question_id\\\": 0, \\\"image\\\": \\\"000000441147.jpg\\\", \\\"text\\\": \\\"图片中两个手提箱的颜色是什么？\\\", \\\"category\\\": \\\"conv\\\"}\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\t数据字段… See the full description on the dataset page: https://huggingface.co/datasets/IDEA-CCNL/Ziya-Visual-Eval-Chinese."},
	{"name":"Movie-Title-Post","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/snzhang/Movie-Title-Post","creator_name":"Sinian Zhang","creator_url":"https://huggingface.co/snzhang","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThis dataset currently contains 5043  movie posts and their corresponding Chinese title which are collected from IMDb and Douban by crawler. \\nIn the future, we will add more data to it.\\n"},
	{"name":"sft_zh","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/TigerResearch/sft_zh","creator_name":"Tiger Research","creator_url":"https://huggingface.co/TigerResearch","description":"Tigerbot 开源项目中微调中文sft-zh数据合集\\n本合集涵盖本组织下开源的其他中文sft-中文-数据集，不需要重复下载\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tUsage\\n\\t\\n\\nimport datasets\\nds_sft = datasets.load_dataset('TigerResearch/sft_zh')\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\t文件细分\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n类型\\n语言\\n数据集文件\\n数量\\n\\n\\n\\t\\t\\nalpaca 中文\\n中文\\ntigerbot-alpaca-zh-0.5m\\n0.5m\\n\\n\\n百科问答\\n中文\\ntigerbot-wiki-qa-1k\\n1k\\n\\n\\n名著问答\\n中文\\ntigerbot-book-qa-1k\\n1k\\n\\n\\n猜谜语\\n中文\\ntigerbot-riddle-qa-1k\\n1k\\n\\n\\n阅读理解\\n中文\\ntigerbot-superclue-c3-zh-5k\\n5k\\n\\n\\n问答\\n中文\\ntigerbot-hc3-zh-12k\\n12k\\n\\n\\n知乎问答\\n中文\\ntigerbot-zhihu-zh-10k\\n10k\\n\\n\\n\\t\\n\\n"},
	{"name":"docs_on_several_languages","keyword":"chinese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/AlekseyScorpi/docs_on_several_languages","creator_name":"Aleksey Timoshin","creator_url":"https://huggingface.co/AlekseyScorpi","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for \\\"docs_on_several_languages\\\"\\n\\t\\n\\nThis dataset is a collection of different images in different languages.\\nThe set includes the following languages: Azerbaijani, Belorussian, Chinese, English, Estonian, Finnish, Georgian, Japanese, Korean, Kazakh, Latvian, Lithuanian, Mongolian, Norwegian, Polish, Russian, Ukranian.\\nEach language has a corresponding class label defined. At least 100 images in the entire dataset are allocated per class. This dataset was originally used… See the full description on the dataset page: https://huggingface.co/datasets/AlekseyScorpi/docs_on_several_languages."},
	{"name":"REDFM","keyword":"chinese","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Babelscape/REDFM","creator_name":"Babelscape","creator_url":"https://huggingface.co/Babelscape","description":"Relation Extraction (RE) is a task that identifies relationships between entities in a text, enabling the acquisition of relational facts and bridging the gap between natural language and structured knowledge. However, current RE models often rely on small datasets with low coverage of relation types, particularly when working with languages other than English. \\\\In this paper, we address the above issue and provide two new resources that enable the training and evaluation of multilingual RE systems.\\nFirst, we present SRED\\\\textsuperscript{FM}, an automatically annotated dataset covering 18 languages, 400 relation types, 13 entity types, totaling more than 40 million triplet instances. Second, we propose RED\\\\textsuperscript{FM}, a smaller, human-revised dataset for seven languages that allows for the evaluation of multilingual RE systems. \\nTo demonstrate the utility of these novel datasets, we experiment with the first end-to-end multilingual RE model, mREBEL, \\nthat extracts triplets, including entity types, in multiple languages. We release our resources and model checkpoints at \\\\href{https://www.github.com/babelscape/rebel}{https://www.github.com/babelscape/rebel}."},
	{"name":"SREDFM","keyword":"chinese","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Babelscape/SREDFM","creator_name":"Babelscape","creator_url":"https://huggingface.co/Babelscape","description":"Relation Extraction (RE) is a task that identifies relationships between entities in a text, enabling the acquisition of relational facts and bridging the gap between natural language and structured knowledge. However, current RE models often rely on small datasets with low coverage of relation types, particularly when working with languages other than English. \\\\In this paper, we address the above issue and provide two new resources that enable the training and evaluation of multilingual RE systems.\\nFirst, we present SRED\\\\textsuperscript{FM}, an automatically annotated dataset covering 18 languages, 400 relation types, 13 entity types, totaling more than 40 million triplet instances. Second, we propose RED\\\\textsuperscript{FM}, a smaller, human-revised dataset for seven languages that allows for the evaluation of multilingual RE systems. \\nTo demonstrate the utility of these novel datasets, we experiment with the first end-to-end multilingual RE model, mREBEL, \\nthat extracts triplets, including entity types, in multiple languages. We release our resources and model checkpoints at \\\\href{https://www.github.com/babelscape/rebel}{https://www.github.com/babelscape/rebel}."},
	{"name":"snli-zh","keyword":"chinese","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/shibing624/snli-zh","creator_name":"Ming Xu (徐明)","creator_url":"https://huggingface.co/shibing624","description":"The SNLI corpus (version 1.0) is a collection of 570k human-written English\\nsentence pairs manually labeled for balanced classification with the labels\\nentailment, contradiction, and neutral, supporting the task of natural language\\ninference (NLI), also known as recognizing textual entailment (RTE)."},
	{"name":"goat-chinese","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/supinyu/goat-chinese","creator_name":"supinyu","creator_url":"https://huggingface.co/supinyu","description":"goat中文算术数据集\\n将goat数据集的Template，更换成中文的Template，数学表达式不变\\n"},
	{"name":"sts-sohu2021","keyword":"chinese","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/shibing624/sts-sohu2021","creator_name":"Ming Xu (徐明)","creator_url":"https://huggingface.co/shibing624","description":"2021搜狐校园文本匹配算法大赛数据集"},
	{"name":"HuatuoGPT_sft_data_v1_multiturn","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ticoAg/HuatuoGPT_sft_data_v1_multiturn","creator_name":"ticoAg","creator_url":"https://huggingface.co/ticoAg","description":"\\ndescribe\\nprocess FreedomIntelligence/HuatuoGPT-sft-data-v1 to multiturn format\\n\\n{\\n    \\\"instruction\\\": \\\"听起来很不错。人工智能可能在哪些方面面临挑战呢？\\\",\\n    \\\"input\\\": \\\",\\n    \\\"output\\\": \\\"人工智能面临的挑战包括数据隐私、安全和道德方面的问题，以及影响就业机会的自动化等问题。\\\",\\n    \\\"history\\\": [\\n      [\\\"你好，你能帮我解答一个问题吗？\\\", \\\"当然，请问有什么问题？\\\"],\\n      [\\\"我想了解人工智能的未来发展方向，你有什么想法吗？\\\", \\\"人工智能在未来的发展方向可能包括更强大的机器学习算法，更先进的自然语言处理技术，以及更加智能的机器人。\\\"]\\n    ]\\n  }\\n\\nwhich can be used at LLaMA-Efficient-Tuning\\n\\nexample\\n\\n"},
	{"name":"TruthfulQA_zh","keyword":"chinese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Maxlinn/TruthfulQA_zh","creator_name":"Maxlinn","creator_url":"https://huggingface.co/Maxlinn","description":"TruthfulQA dataset csv with question and answer field translated into Chinese by requesting GPT-4.\\n"},
	{"name":"Ziya-Finetune-Small","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/IDEA-CCNL/Ziya-Finetune-Small","creator_name":"Fengshenbang-LM","creator_url":"https://huggingface.co/IDEA-CCNL","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\t姜子牙微调示例数据集\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\t数据介绍 Dataset Summary\\n\\t\\n\\n用于Ziya模型的微调示例数据集\\nThe Ziya-Finetune-Small is an example dataset designed to finetune Ziya models.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\t语言 Languages\\n\\t\\n\\n中文 & 英文\\nChinese & English\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\t数据示例 Data Instances\\n\\t\\n\\n单轮示例 Single Turn\\n{\\\"prompt\\\": [\\\"给出关于如何在家里做冰淇淋的五条简单步骤。\\\\\\\\n\\\\n\\\"], \\\"output\\\": [\\\"1. 准备冰淇淋机和冰淇淋材料（鲜奶油、糖、香草提取物等）。\\\\n2. 将所有材料放入混合物中拌匀，然后将混合物放入冰淇淋机中。\\\\n3. 打开冰淇淋机，开始混合和冷藏混合物，直到混合物变成冰淇淋。\\\\n4. 将冰淇淋转移到冰箱中，冷藏至少1个小时以加强口感并使其更好吃。\\\\n5. 取出冰淇淋，享用！\\\"]}\\n\\n多轮示例 Multiple Turn… See the full description on the dataset page: https://huggingface.co/datasets/IDEA-CCNL/Ziya-Finetune-Small."},
	{"name":"flores_101","keyword":"chinese","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/severo/flores_101","creator_name":"Sylvain Lesage","creator_url":"https://huggingface.co/severo","description":"One of the biggest challenges hindering progress in low-resource and multilingual machine translation is the \\nlack of good evaluation benchmarks. Current evaluation benchmarks either lack good coverage of low-resource \\nlanguages, consider only restricted domains, or are low quality because they are constructed using \\nsemi-automatic procedures. In this work, we introduce the FLORES evaluation benchmark, consisting of 3001 \\nsentences extracted from English Wikipedia and covering a variety of different topics and domains. \\nThese sentences have been translated in 101 languages by professional translators through a carefully \\ncontrolled process. The resulting dataset enables better assessment of model quality on the long tail of \\nlow-resource languages, including the evaluation of many-to-many multilingual translation systems, as all \\ntranslations are multilingually aligned. By publicly releasing such a high-quality and high-coverage dataset, \\nwe hope to foster progress in the machine translation community and beyond."},
	{"name":"lyra","keyword":"chinese","license":"GNU General Public License v3.0","license_url":"https://choosealicense.com/licenses/gpl-3.0/","language":"en","dataset_url":"https://huggingface.co/datasets/d0rj/lyra","creator_name":"Dmitry Balobin","creator_url":"https://huggingface.co/d0rj","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tlyra\\n\\t\\n\\n"},
	{"name":"emotional_dialog","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/DataHammer/emotional_dialog","creator_name":"Data Hammer Group","creator_url":"https://huggingface.co/DataHammer","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tScientific Emotional Dialogue\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThis is a dataset for emotional multi-turn dialogue on scientific research personnels. It consists of 1069 dialogues with 2709 turns. The Dialogue was first written by NLP practitioners and then expanded by GPT4.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSupported Tasks and Leaderboards\\n\\t\\n\\n\\nEmotional Dialogue: The dataset can be used to instruction tuning for emotional dialogue.\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages\\n\\t\\n\\nChinese\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Structure… See the full description on the dataset page: https://huggingface.co/datasets/DataHammer/emotional_dialog."},
	{"name":"first","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Delius/first","creator_name":"Albert Delius","creator_url":"https://huggingface.co/Delius","description":"This dataset aims to complete text extension task.\\nInstance:\\n{\\n  \\\"Instruction\\\": \\\"请将给你的文本内容扩写成新闻\\\",\\n  \\\"Input\\\": \\\"杨幂获杂志主编夸奖：大幂幂瘦了越来越漂亮\\\",\\n  \\\"Response\\\": \\\"网易娱乐4月29日报道  4月29日，时尚主编张宇晒出一组与杨幂的自拍合影，并发文：“今天与杨幂做同事，大幂幂瘦了，越来越漂亮。”照片中，杨幂托腮卖萌，瘦了不少，少女味十足。网友们也被杨幂的造型征服，纷纷表示：“太美了，看上去年轻了10岁。”\\\"\\n}\\n"},
	{"name":"yolo","keyword":"chinese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/wwkiyyx/yolo","creator_name":"wangwenkai","creator_url":"https://huggingface.co/wwkiyyx","description":"wwkiyyx/yolo dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"PolyMRC","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/bigai-nlco/PolyMRC","creator_name":"BIGAI NLCo","creator_url":"https://huggingface.co/bigai-nlco","description":"We construct a dataset through entries with multiple meanings and examples from Chinese dictionaries, and set the example as context and explanations as choices, the goal of Polysemy Machine Comprehension (PolyMRC) is to find the correct explanation of the entry in the example.\\nthe statistics of the dataset\\n\\n\\t\\n\\t\\t\\n\\n\\n\\n\\n\\n\\t\\t\\nsplit\\nsentences\\naverage sentence length\\n\\n\\ntrain\\n46,119\\n38.55\\n\\n\\nvalidation\\n5,765\\n38.31\\n\\n\\ntest\\n5,765\\n38.84\\n\\n\\n\\t\\n\\n"},
	{"name":"all-scam-spam","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/FredZhang7/all-scam-spam","creator_name":"Fred Zhang","creator_url":"https://huggingface.co/FredZhang7","description":"This is a large corpus of 42,619 preprocessed text messages and emails sent by humans in 43 languages. is_spam=1 means spam and is_spam=0 means ham.\\n1040 rows of balanced data, consisting of casual conversations and scam emails in ≈10 languages, were manually collected and annotated by me, with some help from ChatGPT.\\n\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSome preprcoessing algorithms\\n\\t\\n\\n\\nspam_assassin.js, followed by spam_assassin.py\\nenron_spam.py\\n\\n\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData composition\\n\\t\\n\\n\\n\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDescription\\n\\t\\n\\nTo… See the full description on the dataset page: https://huggingface.co/datasets/FredZhang7/all-scam-spam."},
	{"name":"chat","keyword":"chinese","license":"The Unlicense","license_url":"https://choosealicense.com/licenses/unlicense/","language":"en","dataset_url":"https://huggingface.co/datasets/chenbobo/chat","creator_name":"yuanbo","creator_url":"https://huggingface.co/chenbobo","description":"chenbobo/chat dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"xP3x-sample","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Muennighoff/xP3x-sample","creator_name":"Niklas Muennighoff","creator_url":"https://huggingface.co/Muennighoff","description":"A multilingual collection of Winograd Schemas in six languages that can be used for evaluation of cross-lingual commonsense reasoning capabilities."},
	{"name":"instruct-tuning-sample","keyword":"chinese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/hongyin/instruct-tuning-sample","creator_name":"hongyin","creator_url":"https://huggingface.co/hongyin","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tPretrain\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset details\\n\\t\\n\\nLicense:\\n"},
	{"name":"WebCPM_WK","keyword":"chinese","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ZHR123/WebCPM_WK","creator_name":"ZHR","creator_url":"https://huggingface.co/ZHR123","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for WebCPM_WK\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\n本数据集是由我们对WebCPM的pipeline数据进行二次处理之后构建而成。\\n主要包括过滤原始数据中的一些低质量数据，使用GPT4和ChatGPT扩充原始数据，以及使用随机替换、拼接的方式增强原始数据。\\n该数据集主要的目的是通过指令微调的方式提高LLM的两个能力：\\n\\n给定问题和文档，抽取文档中与问题相关知识的能力。\\n给定参考材料和问题，根据参考材料回答问题的能力。\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLicensing Information\\n\\t\\n\\nThe dataset is available under the Creative Commons NonCommercial (CC BY-NC 4.0).\\n"},
	{"name":"CMB","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/FreedomIntelligence/CMB","creator_name":"FreedomAI","creator_url":"https://huggingface.co/FreedomIntelligence","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tCMB: A Comprehensive  Medical Benchmark in Chinese\\n\\t\\n\\n\\n\\n   🌐 Github • 🌐 Website • 🤗 HuggingFace\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\t🌈 Update\\n\\t\\n\\n\\n[2024.02.21] The answers to the CMB-Exam test has been updated and some errors caused by omissions in version management have been fixed.\\n[2024.01.08] In order to facilitate testing, we disclose the answers to the CMB-Exam test\\n[2023.09.22] CMB is included in OpenCompass.\\n[2023.08.21] Paper released.\\n[2023.08.01] 🎉🎉🎉 CMB is published！🎉🎉🎉… See the full description on the dataset page: https://huggingface.co/datasets/FreedomIntelligence/CMB."},
	{"name":"wikipedia_tw","keyword":"chinese","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/jslin09/wikipedia_tw","creator_name":"Chun-Hsien Lin","creator_url":"https://huggingface.co/jslin09","description":"要搞自己的大型語言模型，最基本的基本，就是需要一大堆文字資料，從 Common Crawl 上頭抓回來慢慢清洗是一條路，清洗維基百科網站的週期性下載檔也是一個方法。本資料集是解析自維基百科於 20240420 發布的繁體中文版打包檔 bz2 檔案的內容，在解析出所需內容後，利用 wikitextparser 移除 Wiki 標記。解析後保留的欄位有兩個：條目名稱（title），條目內容（page article）。\\n原始的打包檔條目內容簡繁混雜，所以有利用 OpenCC 進行簡轉繁處理。\\n\\n原始總條目數: 4,451,426 條目。\\n全部 4,451,426 個條目標題。\\n無法自動去標記的條目數: 3,035,750\\n有內容的條目數: 1,415,676\\n\\n因為本資料集內容龐大，要塞進一般的個人電腦中進行計算，恐怕會有資源不足的情形。建議使用parquet格式下載使用。\\n資料集當中有不少內容為 #REDIRECT 的條目已經嘗試移除，如果移除的不乾淨，就等以後有空推出修正版再來清洗了。\\n"},
	{"name":"KenithZ-dolly-zh-51k","keyword":"chinese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/KenithZ/KenithZ-dolly-zh-51k","creator_name":"Kenith-Zhang","creator_url":"https://huggingface.co/KenithZ","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDolly中文训练集\\n\\t\\n\\n基于Chinese-LLaMA-Alpaca的转换成的dolly数据集\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\t需要做的事情\\n\\t\\n\\n\\n将alpaca_data_zh_51k.json数据集转换为databricks-dolly-15k.jsonl数据集的格式\\n转换后的数据集集需要手动补充category（正在进行）\\n修正原作者从chatGPT爬取的语义不通或数据错误的指令数据（正在进行）\\n\\n"},
	{"name":"news_commentary_tw","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/jslin09/news_commentary_tw","creator_name":"Chun-Hsien Lin","creator_url":"https://huggingface.co/jslin09","description":"本資料集是來自QingySi所搜集的中英對照新聞評論，一共有 252,776 對中英語翻譯的句子，是使用Alpaca的指令資料集格式製成。本資料集利用了OpenCC 進行簡轉繁。\\n"},
	{"name":"artelingo-dummy","keyword":"chinese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/youssef101/artelingo-dummy","creator_name":"mohamed","creator_url":"https://huggingface.co/youssef101","description":"ArtELingo is a benchmark and dataset introduced in a research paper aimed at promoting work on diversity across languages and cultures. It is an extension of ArtEmis, which is a collection of 80,000 artworks from WikiArt with 450,000 emotion labels and English-only captions. ArtELingo expands this dataset by adding 790,000 annotations in Arabic and Chinese. The purpose of these additional annotations is to evaluate the performance of \\\"cultural-transfer\\\" in AI systems.\\nThe dataset in ArtELingo… See the full description on the dataset page: https://huggingface.co/datasets/youssef101/artelingo-dummy."},
	{"name":"calculation","keyword":"chinese","license":"\"Do What The F*ck You Want To Public License\"","license_url":"https://choosealicense.com/licenses/wtfpl/","language":"en","dataset_url":"https://huggingface.co/datasets/OzoneAsai/calculation","creator_name":"AsaiTaka","creator_url":"https://huggingface.co/OzoneAsai","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Calculation\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tsize\\n\\t\\n\\n  JSON file: output1.json≒1.3GB\\n  ~\\n    output60.json\\n     In total 70 ~ 80GB\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nen: Calculation. Its range will be expanded later.\\nzh: 计算。其范围将在以后扩展。\\nde: Berechnung. Der Umfang wird später erweitert werden.\\nru: Расчет. Его диапазон будет расширен позже.\\nko: 계산. 범위는 나중에 확장될 것입니다.\\nfr: Calcul. Sa portée sera étendue ultérieurement.\\nja: 計算。範囲は後で拡張されます。\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSupported Tasks and Leaderboards\\n\\t\\n\\nen:… See the full description on the dataset page: https://huggingface.co/datasets/OzoneAsai/calculation."},
	{"name":"openassistant-guanaco-chinese","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Elliot4AI/openassistant-guanaco-chinese","creator_name":"Jiang Elliot","creator_url":"https://huggingface.co/Elliot4AI","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\n🏡🏡🏡🏡Fine-turn Dataset:中文数据集🏡🏡🏡🏡\\n😀😀😀😀😀😀😀😀 这个数据集是timdettmers/openassistant-guanaco的中文版本，是直接翻译过来，没有经过人为检查语法。 对timdettmers/openassistant-guanaco的描述，请看他的dataset card。 License: Apache 2.0\\n😀😀😀😀😀😀😀😀 This data set is the Chinese version of timdettmers/openassistant-guanaco, which is directly translated without human-checked grammar. For a description of timdettmers/openassistant-guanaco, see its dataset card. License: Apache 2.0\\n"},
	{"name":"ocnli","keyword":"chinese","license":"GNU General Public License v3.0","license_url":"https://choosealicense.com/licenses/gpl-3.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Fred666/ocnli","creator_name":"Fred","creator_url":"https://huggingface.co/Fred666","description":"This dataset is copied from CLUE with certain modifications.\\nThe paper of CLUE is OCNLI.\\nThe modifications are:\\n\\nTransform json file to csv file.\\nEncoding in UTF-8.\\nRemove data entries whose label value is '-'.\\nReplace label values, 'neutral' to 1, 'entailment' to 0, and 'contradiction' to 2.\\nAdd one column 'sentence1', whose value is '前提：' + premise value + '结论：' + hypothsis value.\\n\\nocnli_train_std.csv comes from train.50k.json.\\nocnli_test_std.csv comes from dev.json.\\n"},
	{"name":"blossom-chat-v1","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Azure99/blossom-chat-v1","creator_name":"Azure99","creator_url":"https://huggingface.co/Azure99","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tBLOSSOM CHAT V1\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\t介绍\\n\\t\\n\\nBlossom Chat V1是基于ShareGPT 90K衍生而来的中英双语对话数据集，适用于多轮对话微调。\\n本数据集抽取了ShareGPT的多轮对话指令，仅将指令进行翻译，随后使用多轮指令迭代调用gpt-3.5-turbo-0613。\\n相比原始的ShareGPT数据，主要解决了中文对话数据量较少，以及由ChatGPT生成长度限制而导致的输出截断问题。\\n本次发布了全量数据的20%，包含30K记录。\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\t语言\\n\\t\\n\\n以中文和英文为主，中英文数据按照约5:1的比例混合。\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\t数据集结构\\n\\t\\n\\n每条数据代表一个完整的多轮对话，包含id和conversations两个字段。\\n\\nid：字符串，代表原始ShareGPT的对话id，可以通过链接https://sharegpt.com/c/id来访问原始对话。… See the full description on the dataset page: https://huggingface.co/datasets/Azure99/blossom-chat-v1."},
	{"name":"en_zh","keyword":"chinese","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/bigidea/en_zh","creator_name":"Deng Da","creator_url":"https://huggingface.co/bigidea","description":"bigidea/en_zh dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"4typeCalculation","keyword":"chinese","license":"\"Do What The F*ck You Want To Public License\"","license_url":"https://choosealicense.com/licenses/wtfpl/","language":"en","dataset_url":"https://huggingface.co/datasets/OzoneAsai/4typeCalculation","creator_name":"AsaiTaka","creator_url":"https://huggingface.co/OzoneAsai","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Calculation\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tsize\\n\\t\\n\\n  JSON file: output1.json≒1.3GB\\n  ~\\n    output60.json\\n     In total 70 ~ 80GB\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nen: Calculation. Its range will be expanded later.\\nzh: 计算。其范围将在以后扩展。\\nde: Berechnung. Der Umfang wird später erweitert werden.\\nru: Расчет. Его диапазон будет расширен позже.\\nko: 계산. 범위는 나중에 확장될 것입니다.\\nfr: Calcul. Sa portée sera étendue ultérieurement.\\nja: 計算。範囲は後で拡張されます。\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSupported Tasks and Leaderboards\\n\\t\\n\\nen:… See the full description on the dataset page: https://huggingface.co/datasets/OzoneAsai/4typeCalculation."},
	{"name":"blossom-math-v1","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Azure99/blossom-math-v1","creator_name":"Azure99","creator_url":"https://huggingface.co/Azure99","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tBLOSSOM MATH V1\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\t介绍\\n\\t\\n\\nBlossom Math V3版本已发布！🤗\\nBlossom Math V1是基于Math23K衍生而来的中文数学对话数据集，适用于数学问题微调。\\n本数据集采用全量Math23K的问题，随后调用gpt-3.5-turbo-0613生成结果，并使用原始数据集中的答案对生成的结果进行验证，过滤掉错误答案，很大程度上保证了问题和答案的准确性。\\n本次发布了全量数据的50%，包含10K记录。\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\t语言\\n\\t\\n\\n中文\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\t数据集结构\\n\\t\\n\\n每条数据代表一个完整的题目及答案，包含id、input、output、answer四个字段。\\n\\nid：字符串，代表Math23K中的题目id。\\ninput：字符串，代表问题。\\noutput：字符串，代表gpt-3.5-turbo-0613生成的答案。\\nanswer：字符串，代表正确答案。\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\t数据集限制… See the full description on the dataset page: https://huggingface.co/datasets/Azure99/blossom-math-v1."},
	{"name":"dolly-15k-chinese-guanacoformat","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Elliot4AI/dolly-15k-chinese-guanacoformat","creator_name":"Jiang Elliot","creator_url":"https://huggingface.co/Elliot4AI","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\t🏡🏡🏡🏡Fine-tune Dataset:中文数据集🏡🏡🏡🏡\\n\\t\\n\\n😀😀😀😀😀😀😀😀 这个数据集是databricks/databricks-dolly-15k的中文guanaco版本\\n"},
	{"name":"crawl-theedgemalaysia","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/wanadzhar913/crawl-theedgemalaysia","creator_name":"Faiq Adzlan","creator_url":"https://huggingface.co/wanadzhar913","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tTLDR\\n\\t\\n\\n\\nwebsite: theedgemalaysia\\nnum. of webpages scraped: 414,268 (only webpages with full articles)\\nlink to dataset: https://huggingface.co/datasets/wanadzhar913/crawl-theedgemalaysia\\nlast date of scraping: 14th August 2023\\nstatus: complete\\npull request: https://github.com/huseinzol05/malaysian-dataset/pull/261\\ncontributed to: https://github.com/huseinzol05/malaysian-dataset\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tNote\\n\\t\\n\\nThe \\\"language\\\" column for the data set has errors as it miscategorizes articles in… See the full description on the dataset page: https://huggingface.co/datasets/wanadzhar913/crawl-theedgemalaysia."},
	{"name":"training-data","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/yenping/training-data","creator_name":"yenping","creator_url":"https://huggingface.co/yenping","description":"yenping/training-data dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"Traditional_Chinese_roleplay_chat_Dataset","keyword":"chinese","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Tarklanse/Traditional_Chinese_roleplay_chat_Dataset","creator_name":"wenhaochan","creator_url":"https://huggingface.co/Tarklanse","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tTraditional_Chinese_roleplay_chat_Dataset\\n\\t\\n\\n這個資料集是以繁體中文為主，將各種由ChatGPT生成與極小部分個人撰寫的對話內容整理為alpaca dataset format的格式\\n以一層一層堆疊的方式，將一則對話紀錄拆成數筆資料(共約1000則對話)，在幾次嘗試性的訓練中能夠讓llama2重現原本英文那種很活躍的對話風格，並且能夠維持善於扮演各種角色的能力\\n目前個人有以這個資料集製作一個lora\\n2023/09/07 更新\\n為資料集加入一些中英翻譯的句子，以期AI能以更好的文字去描寫他的動作，並增加了一些與食物有關的對話，希望能降低AI生出奇怪食物名的機率\\n"},
	{"name":"train_3.5M_CN_With_Category","keyword":"chinese","license":"GNU General Public License v3.0","license_url":"https://choosealicense.com/licenses/gpl-3.0/","language":"en","dataset_url":"https://huggingface.co/datasets/BELLE-2/train_3.5M_CN_With_Category","creator_name":"BELLE-2 Group // Be Everyone's Large Language model Engine","creator_url":"https://huggingface.co/BELLE-2","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\t内容\\n\\t\\n\\n基于原有的train_3.5M_CN数据新增了指令类别字段，共包括13个类别，详情如下图所示：\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\t样例\\n\\t\\n\\n{\\n    \\\"id\\\":\\\"66182880\\\",\\n    \\\"category\\\"：\\\"generation\\\"\\n}\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\t字段：\\n\\t\\n\\nid: 数据id\\ncategory: 该条指令数据对应的类别\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\t使用限制\\n\\t\\n\\n仅允许将此数据集及使用此数据集生成的衍生物用于研究目的，不得用于商业，以及其他会对社会带来危害的用途。\\n本数据集不代表任何一方的立场、利益或想法，无关任何团体的任何类型的主张。因使用本数据集带来的任何损害、纠纷，本项目不承担任何责任。\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tCitation\\n\\t\\n\\nPlease cite our paper and github when using our code, data or model.\\n@misc{BELLE,\\n  author = {BELLEGroup},\\n  title = {BELLE: Be Everyone's Large… See the full description on the dataset page: https://huggingface.co/datasets/BELLE-2/train_3.5M_CN_With_Category."},
	{"name":"silk-road_alpaca-data-gpt4-chinese","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/botp/silk-road_alpaca-data-gpt4-chinese","creator_name":"ab10","creator_url":"https://huggingface.co/botp","description":"botp/silk-road_alpaca-data-gpt4-chinese dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"RyokoAI_CNNovel125K","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/botp/RyokoAI_CNNovel125K","creator_name":"ab10","creator_url":"https://huggingface.co/botp","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for CNNovel125K\\n\\t\\n\\nThe BigKnow2022 dataset and its subsets are not yet complete. Not all information here may be accurate or accessible.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nCNNovel125K is a dataset composed of approximately 125,000 novels downloaded from the Chinese novel hosting site http://ibiquw.com.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSupported Tasks and Leaderboards\\n\\t\\n\\nThis dataset is primarily intended for unsupervised training of text generation models; however, it may be useful for other… See the full description on the dataset page: https://huggingface.co/datasets/botp/RyokoAI_CNNovel125K."},
	{"name":"ChineseCorpus-Kaggle-fanti","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ticoAg/ChineseCorpus-Kaggle-fanti","creator_name":"ticoAg","creator_url":"https://huggingface.co/ticoAg","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tsource\\n\\t\\n\\nmix data from https://www.kaggle.com/datasets/allanyiinai/chinesecorpus\\n\\nuse\\n\\nfrom datasets import load_datasets\\nds = load_datasets(\\\"ticoAg/ChineseCorpus-Kaggle-fanti\\\")\\n\\n\\nexample\\n\\n[\\n    {\\n        \\\"text\\\": \\\"2017年12月5日，重慶市交委正式下發《關于新建市郊鐵路磨心坡至合川線工程初步設計的批復》，2017年計劃開工四個節點工程，包括渭沱貨運站場、土場貨運站場、嘉陵江特大橋、九峰山遂道。\\\"\\n    },\\n    {\\n        \\\"text\\\": \\\"2017年7月6日，線路重要節點合川渭沱貨運站開工建設，線路開始建設，項目建設工期為48個月。\\\"\\n    },\\n    {\\n        \\\"text\\\": \\\"日前，渝合線二期（合川段）施工出現了停滯，至今仍未解決，合川區人民政府在2019、2020年均稱將力促市郊鐵路渝合線復工。\\\"\\n    }… See the full description on the dataset page: https://huggingface.co/datasets/ticoAg/ChineseCorpus-Kaggle-fanti."},
	{"name":"shibing624-medical-pretrain","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ticoAg/shibing624-medical-pretrain","creator_name":"ticoAg","creator_url":"https://huggingface.co/ticoAg","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for medical\\n\\t\\n\\n中文医疗数据集\\n\\nLLM Supervised Finetuning repository: https://github.com/shibing624/textgen\\nMeidcalGPT repository: https://github.com/shibing624/MedicalGPT\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nmedical is a Chinese Medical dataset. 医疗数据集，可用于医疗领域大模型训练。\\ntree medical\\n|-- finetune  # 监督微调数据集，可用于SFT和RLHF\\n|   |-- test_en_1.json\\n|   |-- test_zh_0.json\\n|   |-- train_en_1.json\\n|   |-- train_zh_0.json\\n|   |-- valid_en_1.json\\n|   `-- valid_zh_0.json\\n|-- medical.py # hf… See the full description on the dataset page: https://huggingface.co/datasets/ticoAg/shibing624-medical-pretrain."},
	{"name":"ChatMed_Consult_Dataset","keyword":"chinese","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ticoAg/ChatMed_Consult_Dataset","creator_name":"ticoAg","creator_url":"https://huggingface.co/ticoAg","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for ChatMed\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nChatMed-Dataset is a dataset of 110,113 medical query-response pairs (in Chinese) generated by OpenAI's GPT-3.5 engine. The queries are crawled from several online medical consultation sites, reflecting the medical needs in the real world. The responses are generated by the OpenAI engine. This dataset is designated to to inject medical knowledge into Chinese large language models. \\nThe dataset size growing rapidly. Stay… See the full description on the dataset page: https://huggingface.co/datasets/ticoAg/ChatMed_Consult_Dataset."},
	{"name":"Medical-Dialogue-System","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ticoAg/Medical-Dialogue-System","creator_name":"ticoAg","creator_url":"https://huggingface.co/ticoAg","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tdescribe\\n\\t\\n\\n非常navie的场景对话，但可能出现真实场景信息，比如XX医院，XX医生\\n对纯指令数据质量要求较高的需要进一步清洗，只用来健康场景finetune maybe enough\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tfrom\\n\\t\\n\\n[Medical-Dialogue-System]\\n*[medical_dialog]\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tformat\\n\\t\\n\\n{\\n    \\\"instruction\\\": null,\\n    \\\"input\\\": \\\"不知道，我是在09年8月份,白天出了很多的汗,晚上睡觉突然醒来,看房子天晕地转,过了大约也就一分钟的样子,就不转了.但头向左转动就又转,左边头皮还发麻.第二天起来,人没有精神,过了段时间.病情时轻时重,好像是躺在床上向右人就一上晕了.但时间不长.有一天开了一天的车,晚上先是有点头晕,走路不稳,上床休息,但突然后脑根部特别疼,到了第二天也不疼了.到现在也没有疼过.现在就是躺下和起床特别晕(头向右和头向上或向下),走路不稳.特别是站久了,就要倒了感觉.另外平常,脑袋感觉昏沉沉的,有时眼睛看东西跟不上速度,要晕的… See the full description on the dataset page: https://huggingface.co/datasets/ticoAg/Medical-Dialogue-System."},
	{"name":"cmath","keyword":"chinese","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/weitianwen/cmath","creator_name":"Wei Tianwen","creator_url":"https://huggingface.co/weitianwen","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tCMATH\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tIntroduction\\n\\t\\n\\nWe present the Chinese Elementary School Math Word Problems (CMATH) dataset, comprising 1.7k elementary school-level math word problems with detailed annotations, source from actual Chinese workbooks and exams. This dataset aims to provide a benchmark tool for assessing the following question: to what grade level of elementary school math do the abilities of popular large language models (LLMs) correspond? We evaluate a variety of popular LLMs… See the full description on the dataset page: https://huggingface.co/datasets/weitianwen/cmath."},
	{"name":"observer","keyword":"chinese","license":"GNU General Public License v3.0","license_url":"https://choosealicense.com/licenses/gpl-3.0/","language":"en","dataset_url":"https://huggingface.co/datasets/JosephusCheung/observer","creator_name":"Joséphus Cheung","creator_url":"https://huggingface.co/JosephusCheung","description":"Fine-tune GPT-3.5 to essentially act as an Observer, not answering questions but instead analyzing user inputs and providing instructions and assigning tasks to Answer GPT. This dataset consists of question-and-answer data from user queries on Quora (in English) and Zhihu (in Chinese) for the finetuned model of GPT-3.5.\\n"},
	{"name":"autotrain-data-chinese-ner","keyword":"chinese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/HsiangNianian/autotrain-data-chinese-ner","creator_name":"简律纯","creator_url":"https://huggingface.co/HsiangNianian","description":"HsiangNianian/autotrain-data-chinese-ner dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"vm-training-data","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Jouryjc/vm-training-data","creator_name":"Jouryjc","creator_url":"https://huggingface.co/Jouryjc","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Dataset Name\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThis dataset card aims to be a base template for new datasets. It has been generated using this raw template.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSupported Tasks and Leaderboards\\n\\t\\n\\n[More Information Needed]\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages\\n\\t\\n\\n[More Information Needed]\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Structure\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Instances\\n\\t\\n\\n[More Information Needed]\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Fields\\n\\t\\n\\n[More Information Needed]\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Splits\\n\\t\\n\\n[More Information… See the full description on the dataset page: https://huggingface.co/datasets/Jouryjc/vm-training-data."},
	{"name":"yue-zh-translation","keyword":"chinese","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/indiejoseph/yue-zh-translation","creator_name":"Joseph Cheng","creator_url":"https://huggingface.co/indiejoseph","description":"This dataset is comprised of:\\n\\nCrawled content that is machine translated from Cantonese to Simplified Chinese.\\nmachine translated articlse from zh-yue.wikipedia.org\\nbotisan-ai/cantonese-mandarin-translations\\nAlienKevin/LIHKG\\n\\n"},
	{"name":"linghuchong","keyword":"chinese","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/chengli-thu/linghuchong","creator_name":"Cheng Li","creator_url":"https://huggingface.co/chengli-thu","description":"支持ChatHaruhi2 的令狐冲数据，可以使用如下方式调用\\nfrom chatharuhi import ChatHaruhi\\n\\nchatbot = ChatHaruhi( role_from_hf = 'chengli-thu/linghuchong', \\\\\\n                      llm = 'openai')\\n\\nresponse = chatbot.chat(role='小师妹', text = '冲哥。')\\nprint(response)\\n\\n上传者: 李鲁鲁\\n更具体的信息，见 ChatHaruhi \\n欢迎加入我们的 众筹角色创建项目\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tCitation引用\\n\\t\\n\\nPlease cite the repo if you use the data or code in this repo.\\n@misc{li2023chatharuhi,\\n      title={ChatHaruhi: Reviving Anime Character in Reality via Large Language Model}… See the full description on the dataset page: https://huggingface.co/datasets/chengli-thu/linghuchong."},
	{"name":"xuzhu","keyword":"chinese","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/hhhwmws/xuzhu","creator_name":"Weishi MI","creator_url":"https://huggingface.co/hhhwmws","description":"支持ChatHaruhi2 的虚竹数据，可以使用如下方式调用\\nfrom chatharuhi import ChatHaruhi\\n\\nchatbot = ChatHaruhi( role_from_hf = 'hhhwmws/xuzhu', \\\\\\n                      llm = 'openai')\\n\\nresponse = chatbot.chat(role='僧人', text = '你好！')\\nprint(response)\\n\\n上传者: 米唯实\\n更具体的信息，见 ChatHaruhi \\n欢迎加入我们的 众筹角色创建项目\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tCitation引用\\n\\t\\n\\nPlease cite the repo if you use the data or code in this repo.\\n@misc{li2023chatharuhi,\\n      title={ChatHaruhi: Reviving Anime Character in Reality via Large Language Model}, \\n      author={Cheng Li… See the full description on the dataset page: https://huggingface.co/datasets/hhhwmws/xuzhu."},
	{"name":"dingchunqiu","keyword":"chinese","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/hhhwmws/dingchunqiu","creator_name":"Weishi MI","creator_url":"https://huggingface.co/hhhwmws","description":"支持ChatHaruhi2 的丁春秋数据，可以使用如下方式调用\\nfrom chatharuhi import ChatHaruhi\\n\\nchatbot = ChatHaruhi( role_from_hf = 'hhhwmws/dingchunqiu', \\\\\\n                      llm = 'openai')\\n\\nresponse = chatbot.chat(role='萧峰', text = '丁春秋！')\\nprint(response)\\n\\n上传者: 米唯实\\n更具体的信息，见 ChatHaruhi \\n欢迎加入我们的 众筹角色创建项目\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tCitation引用\\n\\t\\n\\nPlease cite the repo if you use the data or code in this repo.\\n@misc{li2023chatharuhi,\\n      title={ChatHaruhi: Reviving Anime Character in Reality via Large Language Model}… See the full description on the dataset page: https://huggingface.co/datasets/hhhwmws/dingchunqiu."},
	{"name":"xiaofeng","keyword":"chinese","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/hhhwmws/xiaofeng","creator_name":"Weishi MI","creator_url":"https://huggingface.co/hhhwmws","description":"支持ChatHaruhi2 的萧峰数据，可以使用如下方式调用\\nfrom chatharuhi import ChatHaruhi\\n\\nchatbot = ChatHaruhi( role_from_hf = 'hhhwmws/xiaofeng', \\\\\\n                      llm = 'openai')\\n\\nresponse = chatbot.chat(role='丁春秋', text = '是我！')\\nprint(response)\\n\\n上传者: 米唯实\\n更具体的信息，见 ChatHaruhi \\n欢迎加入我们的 众筹角色创建项目\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tCitation引用\\n\\t\\n\\nPlease cite the repo if you use the data or code in this repo.\\n@misc{li2023chatharuhi,\\n      title={ChatHaruhi: Reviving Anime Character in Reality via Large Language Model}… See the full description on the dataset page: https://huggingface.co/datasets/hhhwmws/xiaofeng."},
	{"name":"jiumozhi","keyword":"chinese","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/hhhwmws/jiumozhi","creator_name":"Weishi MI","creator_url":"https://huggingface.co/hhhwmws","description":"支持ChatHaruhi2 的鸠摩智数据，可以使用如下方式调用\\nfrom chatharuhi import ChatHaruhi\\n\\nchatbot = ChatHaruhi( role_from_hf = 'hhhwmws/jiumozhi', \\\\\\n                      llm = 'openai')\\n\\nresponse = chatbot.chat(role='萧峰', text = '是我！')\\nprint(response)\\n\\n上传者: 米唯实\\n更具体的信息，见 ChatHaruhi \\n欢迎加入我们的 众筹角色创建项目\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tCitation引用\\n\\t\\n\\nPlease cite the repo if you use the data or code in this repo.\\n@misc{li2023chatharuhi,\\n      title={ChatHaruhi: Reviving Anime Character in Reality via Large Language Model}… See the full description on the dataset page: https://huggingface.co/datasets/hhhwmws/jiumozhi."},
	{"name":"guojing","keyword":"chinese","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/hhhwmws/guojing","creator_name":"Weishi MI","creator_url":"https://huggingface.co/hhhwmws","description":"支持ChatHaruhi2 的郭靖数据，可以使用如下方式调用\\nfrom chatharuhi import ChatHaruhi\\n\\nchatbot = ChatHaruhi( role_from_hf = 'hhhwmws/guojing', \\\\\\n                      llm = 'openai')\\n\\nresponse = chatbot.chat(role='欧阳锋', text = '是我！')\\nprint(response)\\n\\n上传者: 米唯实\\n更具体的信息，见 ChatHaruhi \\n欢迎加入我们的 众筹角色创建项目\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tCitation引用\\n\\t\\n\\nPlease cite the repo if you use the data or code in this repo.\\n@misc{li2023chatharuhi,\\n      title={ChatHaruhi: Reviving Anime Character in Reality via Large Language Model}, \\n      author={Cheng… See the full description on the dataset page: https://huggingface.co/datasets/hhhwmws/guojing."},
	{"name":"huangrong","keyword":"chinese","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/hhhwmws/huangrong","creator_name":"Weishi MI","creator_url":"https://huggingface.co/hhhwmws","description":"支持ChatHaruhi2 的黄蓉数据，可以使用如下方式调用\\nfrom chatharuhi import ChatHaruhi\\n\\nchatbot = ChatHaruhi( role_from_hf = 'hhhwmws/huangrong', \\\\\\n                      llm = 'openai')\\n\\nresponse = chatbot.chat(role='郭靖', text = '蓉儿！')\\nprint(response)\\n\\n上传者: 米唯实\\n更具体的信息，见 ChatHaruhi \\n欢迎加入我们的 众筹角色创建项目\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tCitation引用\\n\\t\\n\\nPlease cite the repo if you use the data or code in this repo.\\n@misc{li2023chatharuhi,\\n      title={ChatHaruhi: Reviving Anime Character in Reality via Large Language Model}… See the full description on the dataset page: https://huggingface.co/datasets/hhhwmws/huangrong."},
	{"name":"ouyangfeng","keyword":"chinese","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/hhhwmws/ouyangfeng","creator_name":"Weishi MI","creator_url":"https://huggingface.co/hhhwmws","description":"支持ChatHaruhi2 的欧阳锋数据，可以使用如下方式调用\\nfrom chatharuhi import ChatHaruhi\\n\\nchatbot = ChatHaruhi( role_from_hf = 'hhhwmws/ouyangfeng', \\\\\\n                      llm = 'openai')\\n\\nresponse = chatbot.chat(role='郭靖', text = '欧阳锋！是你！')\\nprint(response)\\n\\n上传者: 米唯实\\n更具体的信息，见 ChatHaruhi \\n欢迎加入我们的 众筹角色创建项目\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tCitation引用\\n\\t\\n\\nPlease cite the repo if you use the data or code in this repo.\\n@misc{li2023chatharuhi,\\n      title={ChatHaruhi: Reviving Anime Character in Reality via Large Language Model}… See the full description on the dataset page: https://huggingface.co/datasets/hhhwmws/ouyangfeng."},
	{"name":"huangyaoshi","keyword":"chinese","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/hhhwmws/huangyaoshi","creator_name":"Weishi MI","creator_url":"https://huggingface.co/hhhwmws","description":"支持ChatHaruhi2 的黄药师数据，可以使用如下方式调用\\nfrom chatharuhi import ChatHaruhi\\n\\nchatbot = ChatHaruhi( role_from_hf = 'hhhwmws/huangyaoshi', \\\\\\n                      llm = 'openai')\\n\\nresponse = chatbot.chat(role='郭靖', text = '黄药师！是你！')\\nprint(response)\\n\\n上传者: 米唯实\\n更具体的信息，见 ChatHaruhi \\n欢迎加入我们的 众筹角色创建项目\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tCitation引用\\n\\t\\n\\nPlease cite the repo if you use the data or code in this repo.\\n@misc{li2023chatharuhi,\\n      title={ChatHaruhi: Reviving Anime Character in Reality via Large Language Model}… See the full description on the dataset page: https://huggingface.co/datasets/hhhwmws/huangyaoshi."},
	{"name":"zhouzhiruo","keyword":"chinese","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/hhhwmws/zhouzhiruo","creator_name":"Weishi MI","creator_url":"https://huggingface.co/hhhwmws","description":"支持ChatHaruhi2 的周芷若数据，可以使用如下方式调用\\nfrom chatharuhi import ChatHaruhi\\n\\nchatbot = ChatHaruhi( role_from_hf = 'hhhwmws/zhouzhiruo', \\\\\\n                      llm = 'openai')\\n\\nresponse = chatbot.chat(role='张无忌', text = '周芷若！')\\nprint(response)\\n\\n上传者: 米唯实\\n更具体的信息，见 ChatHaruhi \\n欢迎加入我们的 众筹角色创建项目\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tCitation引用\\n\\t\\n\\nPlease cite the repo if you use the data or code in this repo.\\n@misc{li2023chatharuhi,\\n      title={ChatHaruhi: Reviving Anime Character in Reality via Large Language Model}… See the full description on the dataset page: https://huggingface.co/datasets/hhhwmws/zhouzhiruo."},
	{"name":"zhaomin","keyword":"chinese","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/hhhwmws/zhaomin","creator_name":"Weishi MI","creator_url":"https://huggingface.co/hhhwmws","description":"支持ChatHaruhi2 的赵敏数据，可以使用如下方式调用\\nfrom chatharuhi import ChatHaruhi\\n\\nchatbot = ChatHaruhi( role_from_hf = 'hhhwmws/zhaomin', \\\\\\n                      llm = 'openai')\\n\\nresponse = chatbot.chat(role='张无忌', text = '赵敏！')\\nprint(response)\\n\\n上传者: 米唯实\\n更具体的信息，见 ChatHaruhi \\n欢迎加入我们的 众筹角色创建项目\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tCitation引用\\n\\t\\n\\nPlease cite the repo if you use the data or code in this repo.\\n@misc{li2023chatharuhi,\\n      title={ChatHaruhi: Reviving Anime Character in Reality via Large Language Model}, \\n      author={Cheng… See the full description on the dataset page: https://huggingface.co/datasets/hhhwmws/zhaomin."},
	{"name":"zhangwuji","keyword":"chinese","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/hhhwmws/zhangwuji","creator_name":"Weishi MI","creator_url":"https://huggingface.co/hhhwmws","description":"支持ChatHaruhi2 的张无忌数据，可以使用如下方式调用\\nfrom chatharuhi import ChatHaruhi\\n\\nchatbot = ChatHaruhi( role_from_hf = 'hhhwmws/zhangwuji', \\\\\\n                      llm = 'openai')\\n\\nresponse = chatbot.chat(role='赵敏', text = '张无忌！')\\nprint(response)\\n\\n上传者: 米唯实\\n更具体的信息，见 ChatHaruhi \\n欢迎加入我们的 众筹角色创建项目\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tCitation引用\\n\\t\\n\\nPlease cite the repo if you use the data or code in this repo.\\n@misc{li2023chatharuhi,\\n      title={ChatHaruhi: Reviving Anime Character in Reality via Large Language Model}… See the full description on the dataset page: https://huggingface.co/datasets/hhhwmws/zhangwuji."},
	{"name":"xiexun","keyword":"chinese","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/hhhwmws/xiexun","creator_name":"Weishi MI","creator_url":"https://huggingface.co/hhhwmws","description":"支持ChatHaruhi2 的谢逊数据，可以使用如下方式调用\\nfrom chatharuhi import ChatHaruhi\\n\\nchatbot = ChatHaruhi( role_from_hf = 'hhhwmws/xiexun', \\\\\\n                      llm = 'openai')\\n\\nresponse = chatbot.chat(role='张无忌', text = '谢逊！')\\nprint(response)\\n\\n上传者: 米唯实\\n更具体的信息，见 ChatHaruhi \\n欢迎加入我们的 众筹角色创建项目\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tCitation引用\\n\\t\\n\\nPlease cite the repo if you use the data or code in this repo.\\n@misc{li2023chatharuhi,\\n      title={ChatHaruhi: Reviving Anime Character in Reality via Large Language Model}, \\n      author={Cheng… See the full description on the dataset page: https://huggingface.co/datasets/hhhwmws/xiexun."},
	{"name":"chinese-shepherd-critic-dataset","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/frankminors123/chinese-shepherd-critic-dataset","creator_name":"Frank Jones","creator_url":"https://huggingface.co/frankminors123","description":"The dataset comes from the work introduced in \\\"Shepherd: A Critic for Language Model Generation\\\". We translated it into Simplified Chinese based on Google Translate, and made appropriate manual checks. We hope to do more valuable work in the Chinese field, and at the same time, we also hope that capable researchers can better check the sentences based on Chinese grammar or make further rewrites.\\n"},
	{"name":"testpatent","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Elliot4AI/testpatent","creator_name":"Jiang Elliot","creator_url":"https://huggingface.co/Elliot4AI","description":"test\\n"},
	{"name":"wikianc","keyword":"chinese","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/cyanic-selkie/wikianc","creator_name":"cyanic-selkie","creator_url":"https://huggingface.co/cyanic-selkie","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for WikiAnc\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThe WikiAnc dataset is an automatically generated dataset from Wikipedia (all languages) and Wikidata dumps (August, 2023). \\nThe code for generating the dataset can be found here.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSupported Tasks\\n\\t\\n\\n\\nwikificiation: The dataset can be used to train a model for Wikification.\\nnamed-entity-linking: The dataset can be used to train a model for Named Entity Linking.\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages\\n\\t\\n\\nThe text in the dataset is… See the full description on the dataset page: https://huggingface.co/datasets/cyanic-selkie/wikianc."},
	{"name":"entity_cs","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/huawei-noah/entity_cs","creator_name":"HUAWEI Noah's Ark Lab","creator_url":"https://huggingface.co/huawei-noah","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for EntityCS\\n\\t\\n\\n\\nRepository: https://github.com/huawei-noah/noah-research/tree/master/NLP/EntityCS  \\nPaper: https://aclanthology.org/2022.findings-emnlp.499.pdf  \\nPoint of Contact: Fenia Christopoulou, Chenxi Whitehouse\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nWe use the English Wikipedia and leverage entity information from Wikidata to construct an entity-based Code Switching corpus. \\nTo achieve this, we make use of wikilinks in Wikipedia, i.e. links from one page to… See the full description on the dataset page: https://huggingface.co/datasets/huawei-noah/entity_cs."},
	{"name":"tiger-sft-zh","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ticoAg/tiger-sft-zh","creator_name":"ticoAg","creator_url":"https://huggingface.co/ticoAg","description":"Tigerbot 开源项目中微调中文sft-zh数据合集\\n本合集涵盖本组织下开源的其他中文sft-中文-数据集，不需要重复下载\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tUsage\\n\\t\\n\\nimport datasets\\nds_sft = datasets.load_dataset('TigerResearch/sft_zh')\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\t文件细分\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n类型\\n语言\\n数据集文件\\n数量\\n\\n\\n\\t\\t\\nalpaca 中文\\n中文\\ntigerbot-alpaca-zh-0.5m\\n500k\\n\\n\\n百科问答\\n中文\\ntigerbot-wiki-qa-1k\\n1k\\n\\n\\n名著问答\\n中文\\ntigerbot-book-qa-1k\\n1k\\n\\n\\n猜谜语\\n中文\\ntigerbot-riddle-qa-1k\\n1k\\n\\n\\n阅读理解\\n中文\\ntigerbot-superclue-c3-zh-5k\\n5k\\n\\n\\n问答\\n中文\\ntigerbot-hc3-zh-12k\\n12k\\n\\n\\n知乎问答\\n中文\\ntigerbot-zhihu-zh-10k\\n10k\\n\\n\\n流萤sft\\n中文\\ntigerbot-firefly-zh-20k\\n20k\\n\\n\\n\\t\\n\\n"},
	{"name":"liwu-MNBVC","keyword":"chinese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/botp/liwu-MNBVC","creator_name":"ab10","creator_url":"https://huggingface.co/botp","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for MNBVC\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\t数据集介绍\\n\\t\\n\\n中文互联网上最古老最神秘(没有之一)的里屋社区于2023.1.1庄重宣布:\\n在英明神武的里屋管子带领下，决心发挥社区所长(哪都长)，帮助开源社区长期更新一份最大的中文互联网语料集。\\nHuggingface上的MNBVC数据集在逐渐更新中，请到https://github.com/esbatmop/MNBVC 获取未完成清洗的更多数据。\\n可以使用如下脚本加载：\\nfrom datasets import load_dataset\\ndataset = load_dataset(\\\"liwu/MNBVC\\\", 'law_judgement', split='train', streaming=True)\\n\\nnext(iter(dataset))  # get the first line\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\t数据子集\\n\\t\\n\\nMNBVC数据集包含数个子集：\\n\\nlaw_judgement: 来自法律文书的文本。\\ngov_xuexiqiangguo: 来自学习强国的文本。… See the full description on the dataset page: https://huggingface.co/datasets/botp/liwu-MNBVC."},
	{"name":"dstc11.t4","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mario-rc/dstc11.t4","creator_name":"Mario Rodríguez-Cantelar","creator_url":"https://huggingface.co/mario-rc","description":"\\n\\t\\n\\t\\t\\n\\t\\tDSTC11: Dialogue System Technology Challenge 11Track 4: Robust and Multilingual Automatic Evaluation Metrics for Open-Domain Dialogue Systems\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDirectory Structure Scheme\\n\\t\\n\\nRepresentation of the directory tree structure:\\n.\\n└── DSTC_11_Track_4             # DSTC11 data\\n    ├── task1                   # Multilingual metrics data\\n    │       ├── train           # Train data (CHANEL/CDIAL datasets)\\n    │       │   ├── en_es       # English/Spanish data\\n    │       │   ├── en_zh… See the full description on the dataset page: https://huggingface.co/datasets/mario-rc/dstc11.t4."},
	{"name":"text_coordinates_regions","keyword":"chinese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/yachay/text_coordinates_regions","creator_name":"Yachay AI","creator_url":"https://huggingface.co/yachay","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Multilingual Geo-Tagged Social Media Posts (by 123 world regions)\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThe \\\"Regions\\\" dataset is a multilingual corpus that encompasses textual data from the 123 most populated regions worldwide, with each region's data organized into separate .json files. This dataset consists of approximately 500,000 text samples, each paired with its geographic coordinates.\\nKey Features:\\n\\nTextual Data: The dataset contains 500,000 text samples.… See the full description on the dataset page: https://huggingface.co/datasets/yachay/text_coordinates_regions."},
	{"name":"huozi_rlhf_data_json","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Skepsun/huozi_rlhf_data_json","creator_name":"Skepsun","creator_url":"https://huggingface.co/Skepsun","description":"Converted from: https://github.com/HIT-SCIR/huozi\\n"},
	{"name":"cvalues_rlhf","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Skepsun/cvalues_rlhf","creator_name":"Skepsun","creator_url":"https://huggingface.co/Skepsun","description":"Converted from: https://modelscope.cn/datasets/damo/CValues-Comparison/summary. We obtained harmless set by selecting pos_type=\\\"拒绝为主\\\" and neg_type=\\\"风险回复\\\". We obtained helpful set by selecting pos_type=\\\"拒绝&正向建议\\\" and neg_type=\\\"拒绝为主\\\".\\n"},
	{"name":"zhihu_3k_rlhf_train","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ticoAg/zhihu_3k_rlhf_train","creator_name":"ticoAg","creator_url":"https://huggingface.co/ticoAg","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tNote\\n\\t\\n\\n\\nsome rm data from public dataset\\n\\n\\nformat\\n\\n{\\n    \\\"history\\\": [\\n        \\\"query1\\\", \\\"answer1\\\",\\n        \\\"query2\\\", \\\"answer2\\\"\\n    ],\\n    \\\"prompt\\\": \\\"query\\\",\\n    \\\"input\\\": \\\"input for query\\\",\\n    \\\"output\\\": [\\n        \\\"output rank1\\\",\\n        \\\"output rank2\\\",\\n        \\\"output rank3\\\"\\n    ]\\n}\\n\\nThanks \\n\\nbeyond/rlhf-reward-single-round-trans_chinese : \\ndikw/hh_rlhf_cn\\nliyucheng/zhihu_rlhf_3k\\n\\n"},
	{"name":"chinese_chitchat","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/qgyd2021/chinese_chitchat","creator_name":"晴耕雨读","creator_url":"https://huggingface.co/qgyd2021","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\t中文闲聊数据集\\n\\t\\n\\nrole 的取值有: \\\"unknown\\\", \\\"human\\\", \\\"assistant\\\", 三种.\\n数据集从网上收集整理如下:\\n\\n\\t\\n\\t\\t\\n数据\\n原始数据/项目地址\\n样本个数\\n语料描述\\n替代数据下载地址\\n\\n\\n\\t\\t\\nChatterBot\\nChatterBot; chatterbot-corpus\\n560\\n按类型分类，质量较高\\n阿里云盘; 提取码: 81ao\\n\\n\\ndouban\\nDouban Conversation Corpus\\n352W\\n来自北航和微软的paper, 噪音相对较少, 多轮(平均7.6轮)\\n阿里云盘; 提取码: 81ao\\n\\n\\nptt\\nPTT中文語料\\n77W\\n开源项目, 台湾PTT论坛八卦版, 繁体, 语料较生活化, 有噪音\\n阿里云盘; 提取码: 81ao\\n\\n\\nqingyun\\n阿里云盘; 提取码: 81ao\\n10W\\n青云语料, 相对不错, 生活化\\n\\n\\n\\nsubtitle\\n电视剧对白语料\\n274W\\n来自爬取的电影和美剧的字幕, 有一些噪音, 不严谨的对话, 说话人无法对应起来, 多轮(平均5.3轮)\\n阿里云盘; 提取码: 81ao… See the full description on the dataset page: https://huggingface.co/datasets/qgyd2021/chinese_chitchat."},
	{"name":"zh_TW_c4","keyword":"chinese","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/DavidLanz/zh_TW_c4","creator_name":"David Lanz","creator_url":"https://huggingface.co/DavidLanz","description":"Language Models for Taiwanese Culture training dataset.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tCitation\\n\\t\\n\\nPlease cite the repo if you use the data or code in this repo.\\n@inproceedings{lin-chen-2023-llm,\\n    title = \\\"{LLM}-Eval: Unified Multi-Dimensional Automatic Evaluation for Open-Domain Conversations with Large Language Models\\\",\\n    author = \\\"Lin, Yen-Ting  and Chen, Yun-Nung\\\",\\n    booktitle = \\\"Proceedings of the 5th Workshop on NLP for Conversational AI (NLP4ConvAI 2023)\\\",\\n    month = jul,\\n    year = \\\"2023\\\"… See the full description on the dataset page: https://huggingface.co/datasets/DavidLanz/zh_TW_c4."},
	{"name":"school_math_0.25m-zhtw","keyword":"chinese","license":"GNU General Public License v3.0","license_url":"https://choosealicense.com/licenses/gpl-3.0/","language":"en","dataset_url":"https://huggingface.co/datasets/erhwenkuo/school_math_0.25m-zhtw","creator_name":"Erhwen, Kuo","creator_url":"https://huggingface.co/erhwenkuo","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for \\\"school_math_0.25m-zhtw\\\"\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\t原始資料集來源\\n\\t\\n\\n本資料集的原始來源: BelleGroup/school_math_0.25M\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\t內容\\n\\t\\n\\n包含約25萬條由BELLE項目產生的中文數學題數據，包含解題過程。\\n注意：此資料集是由ChatGPT產生的，未經嚴格校驗，問題或解題過程可能包含錯誤。使用過程中請注意這一點。\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\t範例\\n\\t\\n\\n{\\n  \\\"instruction\\\": \\\"題目：小華手裡有一個裝滿糖果的袋子，共有 12 個，小明想知道裡面有多少顆糖果，於是他問小華：「你手裡的糖果袋裡有偶數個糖果嗎？」小華答：「有，而且多於10顆。」請問小華手中的糖果袋裡最少有幾顆糖果？\\\",\\n  \\\"input\\\": \\\",\\n  \\\"output\\\": \\\"\\\\n由題目可知：小華手中的糖果袋裡有偶數個糖果；\\\\n又知道小華手中的糖果袋裡有多少於10件糖果。\\\\n因為糖果數為偶數，多於10件，所以糖果數量最小一定是12。\\\\n所以小華手中的糖果袋裡最少有12顆糖果。\\\"… See the full description on the dataset page: https://huggingface.co/datasets/erhwenkuo/school_math_0.25m-zhtw."},
	{"name":"MultiCoNER","keyword":"chinese","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/tomaarsen/MultiCoNER","creator_name":"Tom Aarsen","creator_url":"https://huggingface.co/tomaarsen","description":"We present MultiCoNER, a large multilingual dataset for Named Entity Recognition that covers 3 domains (Wiki sentences, questions, and search queries) across 11 languages, as well as multilingual and code-mixing subsets. This dataset is designed to represent contemporary challenges in NER, including low-context scenarios (short and uncased text), syntactically complex entities like movie titles, and long-tail entity distributions. The 26M token dataset is compiled from public resources using techniques such as heuristic-based sentence sampling, template extraction and slotting, and machine translation. We applied two NER models on our dataset: a baseline XLM-RoBERTa model, and a state-of-the-art GEMNET model that leverages gazetteers. The baseline achieves moderate performance (macro-F1=54%), highlighting the difficulty of our data. GEMNET, which uses gazetteers, improvement significantly (average improvement of macro-F1=+30%). MultiCoNER poses challenges even for large pre-trained language models, and we believe that it can help further research in building robust NER systems. MultiCoNER is publicly available at https://registry.opendata.aws/multiconer/ and we hope that this resource will help advance research in various aspects of NER."},
	{"name":"Baike-Astronomy-ZH","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Mxode/Baike-Astronomy-ZH","creator_name":"Max Zhang","creator_url":"https://huggingface.co/Mxode","description":"天文学百科，包含 8 个子目录，约 1000 条词条、110,0000 个字符。\\n数据包含一级目录、二级目录、标题、内容。其中内容已经处理为单行，且文本普遍较长。\\n一个样例如下：\\n{\\n    \\\"top_category\\\": \\\"天文学\\\",\\n    \\\"sub_category\\\": \\\"天体力学\\\",\\n    \\\"title\\\": \\\"万有引力定律\\\",\\n    \\\"content\\\": \\\"万有引力定律（汉语拼音：wàn yǒu yǐn lì zhī dìng lǜ），（universal gravitation，law of），自然界中任何两个质点都相互吸引，这个力同两个质点的质量的乘积成正比，同它们之间的距离的二次方成反比。如用m1、m2表示两质点的质量，r表示两质点间的距离，F表示作用力的值，则F＝Gm1m2／r2，式中的G是比例常量，称万有引力常量或牛顿引力常量，数值因不同单位制而异，在国际单位制中G为6.672×1011牛顿·米2／千克2。这个定律由牛顿于1687年在《原理》上首次发表，它和牛顿运动定律一起，构成了牛顿力学特别是天体力学的基础。\\\\n… See the full description on the dataset page: https://huggingface.co/datasets/Mxode/Baike-Astronomy-ZH."},
	{"name":"MetricInstruct","keyword":"chinese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/TIGER-Lab/MetricInstruct","creator_name":"TIGER-Lab","creator_url":"https://huggingface.co/TIGER-Lab","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tMetricInstruct\\n\\t\\n\\nThe MetricInstrcut dataset consists of 44K quadruple in the form of (instruction, input, system output, error analysis) for 6 text generation tasks and 22 text generation datasets. The dataset is used to fine-tune TIGERScore, a Trained metric that follows Instruction Guidance to perform Explainable, and Reference-free evaluation over a wide spectrum of text generation tasks.\\nProject Page | Paper | Code | Demo | \\nTIGERScore-7B | TIGERScore-13B\\nWe present the… See the full description on the dataset page: https://huggingface.co/datasets/TIGER-Lab/MetricInstruct."},
	{"name":"University-News-Instruction-Zh","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Mxode/University-News-Instruction-Zh","creator_name":"Max Zhang","creator_url":"https://huggingface.co/Mxode","description":"一些高校校园新闻，约 65k * 3(类任务) 条，稍微做了一点点脱敏，尽可能地遮盖了作者名等。数据已经整理成了指令的形式，格式如下：\\n{\\n    \\\"id\\\": <id>,\\n    \\\"category\\\": \\\"(title_summarize|news_classify|news_generate)\\\",\\n    \\\"instruction\\\": <对应的具体指令>,\\n    \\\"input\\\": <空>,\\n    \\\"output\\\": <指令对应的输出>\\n}\\n\\n总共三类任务：标题总结、栏目分类、新闻生成，本质上是利用新闻元数据中的标题、栏目、内容排列组合生成的，所以可以保证数据完全准确。每个字段内容已经整理成了单行的格式。下面是三类任务的样例：\\n// 标题总结\\n{\\n    \\\"id\\\": 22106,\\n    \\\"category\\\": \\\"title_summarize\\\",\\n    \\\"instruction\\\": \\\"请你给下面的新闻取一则标题：\\\\n点击图片观看视频… See the full description on the dataset page: https://huggingface.co/datasets/Mxode/University-News-Instruction-Zh."},
	{"name":"Chinese-Classics-Partial","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Mxode/Chinese-Classics-Partial","creator_name":"Max Zhang","creator_url":"https://huggingface.co/Mxode","description":"偶然找到的 200 多篇古籍相关的纯 txt 文件，简单洗了一下，去除了部分噪声和空白行。\\n一篇样例如下：\\n古训《增广贤文》\\n昔时贤文，诲汝谆谆，集韵增文，多见多闻。\\n观今宜鉴古，无古不成今。\\n知己知彼，将心比心。\\n酒逢知己饮，诗向会人吟。\\n相识满天下，知心能几人。\\n相逢好似初相识，到老终无怨恨心。\\n近水知鱼性，近山识鸟音。\\n易涨易退山溪水，易反易覆小人心。\\n运去金成铁，时来铁似金，读书须用意，一字值千金。\\n\\n"},
	{"name":"openassistant-guanaco-EOS","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Trelis/openassistant-guanaco-EOS","creator_name":"Trelis","creator_url":"https://huggingface.co/Trelis","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tChat Fine-tuning Dataset - Guanaco Style\\n\\t\\n\\nThis dataset allows for fine-tuning chat models using \\\"### Human:\\\" AND \\\"### Assistant\\\" as the beginning and end of sequence tokens.\\nPreparation:\\n\\nThe dataset is cloned from TimDettmers, which itself is a subset of the Open Assistant dataset, which you can find here. This subset of the data only contains the highest-rated paths in the conversation tree, with a total of 9,846 samples.\\nThe dataset was then slightly adjusted to:\\n\\n\\nif a row of… See the full description on the dataset page: https://huggingface.co/datasets/Trelis/openassistant-guanaco-EOS."},
	{"name":"sharegpt-deduplicated","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/CaterinaLac/sharegpt-deduplicated","creator_name":"Caterina Lacerra","creator_url":"https://huggingface.co/CaterinaLac","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Dataset Name\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThis dataset is a deduplicated version of sharegpt4. \\nThe deduplication process has two steps:\\n\\nThe literal duplicates (both input and outputs) are removed\\nThe remaining (5749) instances are embedded with the SentenceTransformer library (\\\"paraphrase-multilingual-mpnet-base-v2\\\" model).\\nThen, we compute the cosine similarity among all the possible pairs, and consider paraphrases those… See the full description on the dataset page: https://huggingface.co/datasets/CaterinaLac/sharegpt-deduplicated."},
	{"name":"openassistant-llama-style","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Trelis/openassistant-llama-style","creator_name":"Trelis","creator_url":"https://huggingface.co/Trelis","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tChat Fine-tuning Dataset - Llama 2 Style\\n\\t\\n\\nThis dataset allows for fine-tuning chat models using [INST] AND [/INST] to wrap user messages.\\nPreparation:\\n\\nThe dataset is cloned from TimDettmers, which itself is a subset of the Open Assistant dataset, which you can find here. This subset of the data only contains the highest-rated paths in the conversation tree, with a total of 9,846 samples.\\nThe dataset was then filtered to:\\n\\n\\nreplace instances of '### Human:' with '[INST]'\\nreplace… See the full description on the dataset page: https://huggingface.co/datasets/Trelis/openassistant-llama-style."},
	{"name":"hh_rlhf-chinese-zhtw","keyword":"chinese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/erhwenkuo/hh_rlhf-chinese-zhtw","creator_name":"Erhwen, Kuo","creator_url":"https://huggingface.co/erhwenkuo","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for \\\"hh_rlhf-chinese-zhtw\\\"\\n\\t\\n\\n此數據集合併了下列的資料:\\n\\n關於有用且無害的人類偏好數據，來自 Training a Helpful and Harmless Assistant with Reinforcement Learning from Human Feedback。這些數據旨在為後續 RLHF 訓練訓練偏好（或獎勵）模型。這些資料不用於對話代理人的監督訓練。根據這些資料訓練對話代理可能會導致有害的模型，這種情況應該避免。\\n人工生成並帶註釋的紅隊對話，來自減少危害的紅隊語言模型：方法、擴展行為和經驗教訓。這些數據旨在了解眾包紅隊如何建模以及哪些類型的紅隊攻擊成功或失敗。這些數據不用於微調或偏好建模（使用上面的數據進行偏好建模）。這些數據是從上述無害偏好建模數據導出的對話的完整轉錄本，其中僅將所選響應合併到整個轉錄本中。此外，文字記錄也透過人工和自動測量來標註整個對話的危害程度。\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\t特別注意… See the full description on the dataset page: https://huggingface.co/datasets/erhwenkuo/hh_rlhf-chinese-zhtw."},
	{"name":"pretrain-sample","keyword":"chinese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/hongyin/pretrain-sample","creator_name":"hongyin","creator_url":"https://huggingface.co/hongyin","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tPretrain\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset details\\n\\t\\n\\nLicense:\\n"},
	{"name":"Genealogy","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mmhzlrj/Genealogy","creator_name":"Jet Li","creator_url":"https://huggingface.co/mmhzlrj","description":"数据集包含了一本族谱的封面和164页内容，是竖版的中文简体和繁体字的组合。\\nThe dataset contains the cover and 164 pages of a family tree, which is a combination of simplified and traditional Chinese characters in a vertical version.\\n"},
	{"name":"ADL2023HW1","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/vanessa0688/ADL2023HW1","creator_name":"yangchiayueh","creator_url":"https://huggingface.co/vanessa0688","description":"task_categories:\\n-Paragraph Selection\\n-Span selection\\n"},
	{"name":"MultiJail","keyword":"chinese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/DAMO-NLP-SG/MultiJail","creator_name":"Language Technology Lab at Alibaba DAMO Academy","creator_url":"https://huggingface.co/DAMO-NLP-SG","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tMultilingual Jailbreak Challenges in Large Language Models\\n\\t\\n\\nThis repo contains the data for our paper \\\"Multilingual Jailbreak Challenges in Large Language Models\\\".\\n[Github repo]\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tAnnotation Statistics\\n\\t\\n\\nWe collected a total of 315 English unsafe prompts and annotated them into nine non-English languages. The languages were categorized based on resource availability, as shown below:\\nHigh-resource languages: Chinese (zh), Italian (it), Vietnamese (vi)\\nMedium-resource… See the full description on the dataset page: https://huggingface.co/datasets/DAMO-NLP-SG/MultiJail."},
	{"name":"mqnli","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/SachinPatel248/mqnli","creator_name":"Patel","creator_url":"https://huggingface.co/SachinPatel248","description":"SachinPatel248/mqnli dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"metricsubs-chunktranslate","keyword":"chinese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/metricv/metricsubs-chunktranslate","creator_name":"Metric-Void","creator_url":"https://huggingface.co/metricv","description":"\\n\\t\\n\\t\\t\\n\\t\\tIntroduction\\n\\t\\n\\nThis repository holds the data file for translating TechLinked, which talks about mostly technology and science news.\\nRaw data is in the data/ folder. Scripts generate OpenAI's ChatCompletion Fine-tuning API formatted training data in jsonl format.\\n-2000 variants are designed to be used with GPT-3 with 8192 tokens context length limit. -8192 variants are designed to be used with GPT-4o mini with 128000 context window and 16384 max output tokens.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tHow to add… See the full description on the dataset page: https://huggingface.co/datasets/metricv/metricsubs-chunktranslate."},
	{"name":"squad-cmrc2018-zhtw","keyword":"chinese","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/erhwenkuo/squad-cmrc2018-zhtw","creator_name":"Erhwen, Kuo","creator_url":"https://huggingface.co/erhwenkuo","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for \\\"squad-cmrc2018-zhtw\\\"\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\t資料集摘要\\n\\t\\n\\nCMRC 2018 是第二屆「訊飛盃」中文機器閱讀理解頒獎研討會（CMRC 2018）中相關競賽所使用的資料集。\\n它主要用於中文機器閱讀理解的跨度提取資料集，以增加該領域的語言多樣性。該資料集由人類專家在維基百科段落上註釋的近 20,000 個真實問題組成。\\n同時它也註釋了一個挑戰集，其中包含需要在整個上下文中進行全面理解和多句推理的問題。\\n原始資料來源:\\n\\nhttps://hfl-rc.github.io/cmrc2018/\\nhttps://github.com/ymcui/cmrc2018\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\t資料下載清理\\n\\t\\n\\n\\n下載 cmrc2018 資料集\\n使用 OpenCC 來進行簡繁轉換\\n使用 Python 正規表示式來清理一些殘留在 context, question, answer 的不必要字元\\n根據 answers.text 來重新計算 answers.answer_start 的字元位置\\n使用… See the full description on the dataset page: https://huggingface.co/datasets/erhwenkuo/squad-cmrc2018-zhtw."},
	{"name":"medical_pretrain","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/DavidLanz/medical_pretrain","creator_name":"David Lanz","creator_url":"https://huggingface.co/DavidLanz","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDescription\\n\\t\\n\\n\\nmedical_pretrain_tw.json: This dataset contains a total of 360,000 entries sourced from medical encyclopedia data from FreedomIntelligence/huatuo_encyclopedia_qa. These entries are a combination of questions and answers, forming text fields with coherent sentences. The dataset is intended for pre-training purposes to inject medical knowledge.\\n\\nmedical_book_zh.json: This dataset includes 8,475 entries sourced from text data in medical textbooks. The data source is… See the full description on the dataset page: https://huggingface.co/datasets/DavidLanz/medical_pretrain."},
	{"name":"medical_reward","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/DavidLanz/medical_reward","creator_name":"David Lanz","creator_url":"https://huggingface.co/DavidLanz","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tChinese Medical Dialogue Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDescription\\n\\t\\n\\n\\nmedical_reward_tw.json: This dataset consists of 4,000 entries derived from the Chinese Medical Dialogue dataset (Toyhom/Chinese-medical-dialogue-data). The questions in this dataset are randomly selected from the Chinese Medical Dialogue dataset. The \\\"response_chosen\\\" field contains responses from medical professionals in the Chinese Medical Dialogue dataset, while the \\\"response_rejected\\\" field contains responses from… See the full description on the dataset page: https://huggingface.co/datasets/DavidLanz/medical_reward."},
	{"name":"MSVAMP","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Mathoctopus/MSVAMP","creator_name":"Mathoctopus","creator_url":"https://huggingface.co/Mathoctopus","description":"Mathoctopus/MSVAMP dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"test","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/jasonshen8848/test","creator_name":"szx","creator_url":"https://huggingface.co/jasonshen8848","description":"jasonshen8848/test dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"Long-Instruction-with-Paraphrasing","keyword":"chinese","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/yuyijiong/Long-Instruction-with-Paraphrasing","creator_name":"yuyijiong","creator_url":"https://huggingface.co/yuyijiong","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\t🔥 Updates\\n\\t\\n\\n[2024.6.4] Add a slim version. The sample number is reduced from about 20k to 10k.\\n[2024.5.28] \\n\\nThe data format is converted from \\\"chatml\\\" to \\\"messages\\\", which is more convenient to use tokenizer.apply_chat_template.  The old version has been moved to \\\"legacy\\\" branch.\\nThe version without \\\"Original text paraphrasing\\\" is added.\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\t📊 Long Context Instruction-tuning dataset with \\\"Original text paraphrasing\\\"\\n\\t\\n\\n\\nPaper\\nGithub\\nconsist of multiple tasks\\nChinese… See the full description on the dataset page: https://huggingface.co/datasets/yuyijiong/Long-Instruction-with-Paraphrasing."},
	{"name":"for-test","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ziqin/for-test","creator_name":"yiziqin","creator_url":"https://huggingface.co/ziqin","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tFor TEST\\n\\t\\n\\nthis is a dataset for test\\njust for test...\\n"},
	{"name":"ntu_adl_summarization","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/xjlulu/ntu_adl_summarization","creator_name":"Xue-Jin Lu","creator_url":"https://huggingface.co/xjlulu","description":"xjlulu/ntu_adl_summarization dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"blossom-wizard-v1","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Azure99/blossom-wizard-v1","creator_name":"Azure99","creator_url":"https://huggingface.co/Azure99","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tBLOSSOM WIZARD V1\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\t介绍\\n\\t\\n\\nBlossom Wizard V2版本已发布！🤗\\nBlossom Wizard V1是一个基于WizardLM_evol_instruct_V2衍生而来的中英双语指令数据集，适用于指令微调。\\n本数据集从WizardLM_evol_instruct_V2中抽取了指令，首先将其翻译为中文并校验翻译结果，再使用指令调用gpt-3.5-turbo-0613模型生成响应，并过滤掉包含自我认知以及拒绝回答的响应，以便后续对齐。此外，为了确保响应风格的一致性以及中英数据配比，本数据集还对未翻译的原始指令也进行了相同的调用，最终得到了1:1的中英双语指令数据。\\n相比直接对原始Wizard进行翻译的中文数据集，Blossom Wizard的一致性及质量更高。\\n本次发布了全量数据的30%，包含中英双语各50K，共计100K记录。\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\t语言\\n\\t\\n\\n以中文和英文为主。\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\t数据集结构… See the full description on the dataset page: https://huggingface.co/datasets/Azure99/blossom-wizard-v1."},
	{"name":"blossom-orca-v1","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Azure99/blossom-orca-v1","creator_name":"Azure99","creator_url":"https://huggingface.co/Azure99","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tBLOSSOM ORCA V1\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\t介绍\\n\\t\\n\\nBlossom Orca V2版本已发布！🤗\\nBlossom Orca V1是一个基于OpenOrca衍生而来的中英双语指令数据集，适用于指令微调。\\n本数据集从OpenOrca中抽取了系统提示和指令，首先将其翻译为中文并校验翻译结果，再使用指令调用gpt-3.5-turbo-0613模型生成响应，并过滤掉包含自我认知以及拒绝回答的响应，以便后续对齐。此外，为了确保响应风格的一致性以及中英数据配比，本数据集还对未翻译的原始指令也进行了相同的调用，最终得到了1:1的中英双语指令数据。\\n相比直接对原始OpenOrca进行翻译的中文数据集，Blossom Orca的一致性及质量更高。\\n本次发布了全量数据的30%，包含中英双语各100K，共计200K记录。\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\t语言\\n\\t\\n\\n以中文和英文为主。\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\t数据集结构… See the full description on the dataset page: https://huggingface.co/datasets/Azure99/blossom-orca-v1."},
	{"name":"seamless-align","keyword":"chinese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/jhu-clsp/seamless-align","creator_name":"Center for Language and Speech Processing @ JHU","creator_url":"https://huggingface.co/jhu-clsp","description":"\\n\\t\\n\\t\\t\\n\\t\\tDataset Card for Seamless-Align (WIP). Inspired by https://huggingface.co/datasets/allenai/nllb\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThis dataset was created based on metadata for mined Speech-to-Speech(S2S), Text-to-Speech(TTS) and Speech-to-Text(S2T) released by Meta AI.  The S2S contains data for 35 language pairs. The S2S dataset is ~1000GB compressed.\\n\\n\\t\\n\\t\\t\\n\\t\\tHow to use the data\\n\\t\\n\\nThere are two ways to access the data:\\n\\nVia the Hugging Face Python datasets library\\n\\nScripts coming soon… See the full description on the dataset page: https://huggingface.co/datasets/jhu-clsp/seamless-align."},
	{"name":"WEATHub","keyword":"chinese","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/iamshnoo/WEATHub","creator_name":"Anjishnu Mukherjee","creator_url":"https://huggingface.co/iamshnoo","description":"\\n\\n\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for \\\"WEATHub\\\"\\n\\t\\n\\nThis dataset corresponds to the data described in the paper \\\"Global Voices, Local Biases: Socio-Cultural Prejudices across Languages\\\"\\naccepted to EMNLP 2023.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nWEATHub is a dataset containing 24 languages. It contains words organized into groups of (target1, target2, attribute1, attribute2)\\nto measure the association target1:target2 :: attribute1:attribute2. For example target1 can be insects, target2 can be flowers.… See the full description on the dataset page: https://huggingface.co/datasets/iamshnoo/WEATHub."},
	{"name":"fund-sft","keyword":"chinese","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/jannko/fund-sft","creator_name":"ko","creator_url":"https://huggingface.co/jannko","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Dataset Name\\n\\t\\n\\n\\n\\nThis dataset card aims to be a base template for new datasets. It has been generated using this raw template.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Details\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\n\\n\\n\\n\\n\\nCurated by: [More Information Needed]\\nFunded by [optional]: [More Information Needed]\\nShared by [optional]: [More Information Needed]\\nLanguage(s) (NLP): [More Information Needed]\\nLicense: [More Information Needed]\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Sources [optional]… See the full description on the dataset page: https://huggingface.co/datasets/jannko/fund-sft."},
	{"name":"summary","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/twwch/summary","creator_name":"chenhao","creator_url":"https://huggingface.co/twwch","description":"微调google/mt5-base模型，做文章摘要\\nimport torch\\nfrom transformers import T5ForConditionalGeneration, T5Tokenizer\\n\\nmodel_path = \\\"twwch/mt5-base-summary\\\"\\nmodel = T5ForConditionalGeneration.from_pretrained(model_path)\\ntokenizer = T5Tokenizer.from_pretrained(model_path)\\n\\ndevice = torch.device('cuda:0') if torch.cuda.is_available() else torch.device('cpu')\\nmodel.to(device)\\nmodel.eval()\\n\\ntext = \\\"\\\"\\n什么是Nginx… See the full description on the dataset page: https://huggingface.co/datasets/twwch/summary."},
	{"name":"M4LE","keyword":"chinese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/wckwan/M4LE","creator_name":"Cyrus Kwan","creator_url":"https://huggingface.co/wckwan","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tIntroduction\\n\\t\\n\\nM4LE is a Multi-ability, Multi-range, Multi-task, bilingual benchmark for long-context evaluation. We categorize long-context understanding into five distinct abilities by considering whether it is required to identify single or multiple spans in long contexts based on explicit or semantic hints. Specifically, these abilities are explicit single-span, semantic single-span, explicit multiple-span, semantic multiple-span, and global. Different from previous… See the full description on the dataset page: https://huggingface.co/datasets/wckwan/M4LE."},
	{"name":"taiwanese-college-students","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/krishaamer/taiwanese-college-students","creator_name":"Kris Haamer","creator_url":"https://huggingface.co/krishaamer","description":"Anonymous survey responses by Taiwanese college students.\\n"},
	{"name":"openassistant-falcon","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Trelis/openassistant-falcon","creator_name":"Trelis","creator_url":"https://huggingface.co/Trelis","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tChat Fine-tuning Dataset - OpenAssistant Falcon\\n\\t\\n\\nThis dataset allows for fine-tuning chat models using '\\\\Human:' AND '\\\\nAssistant:' to wrap user messages.\\nIt still uses <|endoftext|> as EOS and BOS token, as per Falcon.\\nSample \\nPreparation:\\n\\nThe dataset is cloned from TimDettmers, which itself is a subset of the Open Assistant dataset, which you can find here. This subset of the data only contains the highest-rated paths in the conversation tree, with a total of 9,846 samples.… See the full description on the dataset page: https://huggingface.co/datasets/Trelis/openassistant-falcon."},
	{"name":"djy","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Giacinta/djy","creator_name":"Giacinta Dummer","creator_url":"https://huggingface.co/Giacinta","description":"Giacinta/djy dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"weibo","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Giacinta/weibo","creator_name":"Giacinta Dummer","creator_url":"https://huggingface.co/Giacinta","description":"Giacinta/weibo dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"chatgpt-paraphrases-zh","keyword":"chinese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/pangda/chatgpt-paraphrases-zh","creator_name":"Shen Huang","creator_url":"https://huggingface.co/pangda","description":"This is a Chinese dataset of paraphrases created by ChatGPT.\\nFor English paraphrase dataset, you can refer to humarin/chatgpt-paraphrases.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tWe used this prompt to generate paraphrases\\n\\t\\n\\n给下面这个问题生成5条相似的改写: {text}\\nThis dataset is based on the queries from Baidu and Zhihu.\\nWe generated 5 paraphrases for each sample, totally this dataset has about 238k data rows. You can make 30 rows from a row from each sample. In this way you can make 7.1 millions train pairs (238k rows with 5… See the full description on the dataset page: https://huggingface.co/datasets/pangda/chatgpt-paraphrases-zh."},
	{"name":"PKU-PosterLayout","keyword":"chinese","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/creative-graphic-design/PKU-PosterLayout","creator_name":"Creative Graphic Design Lab","creator_url":"https://huggingface.co/creative-graphic-design","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for PKU-PosterLayout\\n\\t\\n\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nPKU-PosterLayout is a new dataset and benchmark for content-aware visual-textual presentation layout.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSupported Tasks and Leaderboards\\n\\t\\n\\n[More Information Needed]\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages\\n\\t\\n\\nThe language data in PKU-PosterLayout is in Chinese (BCP-47 zh).\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Structure\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Instances\\n\\t\\n\\nimport datasets as ds\\n\\ndataset =… See the full description on the dataset page: https://huggingface.co/datasets/creative-graphic-design/PKU-PosterLayout."},
	{"name":"lr-sum","keyword":"chinese","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/bltlab/lr-sum","creator_name":"Broadening Linguistic Technologies Lab (BLT Lab)","creator_url":"https://huggingface.co/bltlab","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for LR-Sum\\n\\t\\n\\nLR-Sum is a automatic summarization dataset of newswire text with a focus on less resourced languages with a cc-by 4.0 license.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Details\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nLR-Sum is a permissively-licensed dataset created with the goal of enabling further research in automatic summarization for less-resourced languages.\\nLR-Sum contains human-written summaries for 39 languages, many of which are less-resourced. \\nThe data is based on… See the full description on the dataset page: https://huggingface.co/datasets/bltlab/lr-sum."},
	{"name":"megawika-report-generation","keyword":"chinese","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/hltcoe/megawika-report-generation","creator_name":"JHU Human Language Technology Center of Excellence","creator_url":"https://huggingface.co/hltcoe","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for MegaWika for Report Generation\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nMegaWika is a multi- and crosslingual text dataset containing 30 million Wikipedia passages with their scraped and cleaned web citations. The passages span\\n50 Wikipedias in 50 languages, and the articles in which the passages were originally embedded are included for convenience. Where a Wikipedia passage is in a\\nnon-English language, an automated English translation is provided. \\nThis dataset… See the full description on the dataset page: https://huggingface.co/datasets/hltcoe/megawika-report-generation."},
	{"name":"chinese-icd","keyword":"chinese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/eddielin0926/chinese-icd","creator_name":"Eddie Lin","creator_url":"https://huggingface.co/eddielin0926","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tChinese International Statistical Classification of Diseases\\n\\t\\n\\n"},
	{"name":"ruozhiba-raw","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/kirp/ruozhiba-raw","creator_name":"kirp","creator_url":"https://huggingface.co/kirp","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\t弱智吧数据集 ruozhiba-raw\\n\\t\\n\\n弱智吧是百度贴吧中的一个非常受欢迎的论坛，以创作短小精悍而闻名。\\n这里是截至2023/11/10日前的raw data。\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tTodo\\n\\t\\n\\n\\nget the top 5 answers to each post\\nclean the data\\na joke dataset(pure text/multimodal)\\na feasibility dataset\\na new benchmark for LLM\\n\\n"},
	{"name":"ALMA-prompt-completion","keyword":"chinese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/kristaller486/ALMA-prompt-completion","creator_name":"Kristaller486","creator_url":"https://huggingface.co/kristaller486","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for ALMA-prompt-completion\\n\\t\\n\\n ALMA Dataset if format of prompt-completion\\n\\nCreated by: fe1ixxu\\nShared by: me\\nLanguage(s) (NLP): English, Czech, German, Russian, Islandic, Chinese\\nLicense: MIT\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Sources [optional]\\n\\t\\n\\n\\n\\n\\nRepository: [https://github.com/fe1ixxu/ALMA]\\nPaper [optional]: [https://arxiv.org/abs/2309.11674]\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tUses\\n\\t\\n\\nLLM translators\\n"},
	{"name":"Kurisu","keyword":"chinese","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/showchen/Kurisu","creator_name":"showchen","creator_url":"https://huggingface.co/showchen","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tChatHaruhi\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tReviving Anime Character in Reality via Large Language Model\\n\\t\\n\\n\\n\\ngithub repo: https://github.com/LC1332/Chat-Haruhi-Suzumiya\\nChat-Haruhi-Suzumiyais a language model that imitates the tone, personality and storylines of characters like Haruhi Suzumiya,\\n\\n   The project was developed by Cheng Li, Ziang Leng, Chenxi Yan, Xiaoyang Feng, HaoSheng Wang, Junyi Shen, Hao Wang, Weishi Mi, Aria Fei, Song Yan, Linkang Zhan, Yaokai Jia, Pingyu Wu, and Haozhen Sun,etc.… See the full description on the dataset page: https://huggingface.co/datasets/showchen/Kurisu."},
	{"name":"my_wb_preferences","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/rjhuang/my_wb_preferences","creator_name":"rjhuang","creator_url":"https://huggingface.co/rjhuang","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Dataset Name\\n\\t\\n\\n\\n\\nThis dataset card aims to be a base template for new datasets. It has been generated using this raw template.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Details\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\n\\n\\n\\n\\n\\nCurated by: [More Information Needed]\\nFunded by [optional]: [More Information Needed]\\nShared by [optional]: [More Information Needed]\\nLanguage(s) (NLP): [More Information Needed]\\nLicense: [More Information Needed]\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Sources [optional]… See the full description on the dataset page: https://huggingface.co/datasets/rjhuang/my_wb_preferences."},
	{"name":"retrieval_qa","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/lnwang/retrieval_qa","creator_name":"Luning Wang","creator_url":"https://huggingface.co/lnwang","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tRetrieval_QA: A Simple Multilingual Benchmark For Retrieval Encoder Models\\n\\t\\n\\n\\n\\nThe purpose of this dataset is to provide a simple and easy-to-use benchmark for retrieval encoder models, which helps researchers quickly select the most effective retrieval encoder for text extraction and achieve optimal results in subsequent retrieval tasks such as retrieval-augmented-generation (RAG). The dataset contains multiple document-question pairs, where each document is a short text about… See the full description on the dataset page: https://huggingface.co/datasets/lnwang/retrieval_qa."},
	{"name":"FAVDBench","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/OpenNLPLab/FAVDBench","creator_name":"OpenNLPLab","creator_url":"https://huggingface.co/OpenNLPLab","description":"\\n\\n  FAVDBench: Fine-grained Audible Video Description\\n\\n\\n\\n\\n  🤗 Hugging Face •\\n  🏠 GitHub •\\n  🤖 OpenDataLab •\\n  💬 Apply Dataset \\n\\n\\n\\n[CVPR2023] [Project Page] [arXiv] [Demo][BibTex] [中文简介] \\n\\nIntroduction 简介\\nFiles 文件\\nMD5 checksum\\nUpdates\\nLicense\\nCitation\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tIntroduction 简介\\n\\t\\n\\n在CVPR2023中我们提出了精细化音视频描述任务（Fine-grained Audible Video Description… See the full description on the dataset page: https://huggingface.co/datasets/OpenNLPLab/FAVDBench."},
	{"name":"wmt-mqm-error-spans","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/RicardoRei/wmt-mqm-error-spans","creator_name":"Ricardo Costa Dias Rei","creator_url":"https://huggingface.co/RicardoRei","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThis dataset contains all MQM human annotations from previous WMT Metrics shared tasks and the MQM annotations from Experts, Errors, and Context in a form of error spans. Moreover, it contains some hallucinations used in the training of XCOMET models.\\nPlease note that this is not an official release of the data and the original data can be found here.\\nThe data is organised into 8 columns:\\n\\nsrc: input text\\nmt: translation\\nref: reference translation\\nannotations:… See the full description on the dataset page: https://huggingface.co/datasets/RicardoRei/wmt-mqm-error-spans."},
	{"name":"couplet-json","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/stuser2023/couplet-json","creator_name":"tc lin","creator_url":"https://huggingface.co/stuser2023","description":"[對聯數據集]\\n\\n原始數據集來自github: https://github.com/wb14123/couplet-dataset/\\n\\n繁簡體中文轉換，使用(OpenCC): https://github.com/yichen0831/opencc-python\\n\\n\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tlicense: apache-2.0\\n\\t\\n\\n"},
	{"name":"Pontoon-Translations","keyword":"chinese","license":"Mozilla Public License 2.0","license_url":"https://choosealicense.com/licenses/mpl-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ayymen/Pontoon-Translations","creator_name":"Mohamed Aymane Farhi","creator_url":"https://huggingface.co/ayymen","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Pontoon Translations\\n\\t\\n\\n\\n\\nThis is a dataset containing strings from various Mozilla projects on Mozilla's Pontoon localization platform and their translations into more than 200 languages.\\nSource strings are in English.\\nTo avoid rows with values like \\\"None\\\" and \\\"N/A\\\" being interpreted as missing values, pass the keep_default_na parameter like this:\\nfrom datasets import load_dataset\\n\\ndataset = load_dataset(\\\"ayymen/Pontoon-Translations\\\", keep_default_na=False)… See the full description on the dataset page: https://huggingface.co/datasets/ayymen/Pontoon-Translations."},
	{"name":"HuatuoGPT2-SFT-GPT4-140K","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/FreedomIntelligence/HuatuoGPT2-SFT-GPT4-140K","creator_name":"FreedomAI","creator_url":"https://huggingface.co/FreedomIntelligence","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tHuatuoGPT2-SFT-GPT4-140K\\n\\t\\n\\n140K Chinese medical instructions generated by GPT-4, based on questions from HuatuoGPT Dataset.\\nThis dataset contains supervised fine-tuning instructions for HuatuoGPT2, designed to enhance the model's ability to follow instructions in real medical scenarios. We have made all the data (142,248 entries) in this dataset publicly available.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tRepository\\n\\t\\n\\n\\nGithub: https://github.com/FreedomIntelligence/HuatuoGPT-II\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tCitation… See the full description on the dataset page: https://huggingface.co/datasets/FreedomIntelligence/HuatuoGPT2-SFT-GPT4-140K."},
	{"name":"RenMinDaily","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Concyclics/RenMinDaily","creator_name":"CHEN Han","creator_url":"https://huggingface.co/Concyclics","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Dataset Name\\n\\t\\n\\n\\n\\nIt is the collection of RenMinDaily's report from 2021/01/01 to 2023/12/05. With title as instruction.\\n"},
	{"name":"mmlu_recall","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/itsliupeng/mmlu_recall","creator_name":"Liu Peng","creator_url":"https://huggingface.co/itsliupeng","description":"Employ mmlu (cmmlu) questions as initial seeds to retrieve related articles from multiple training data corpora such as Chinese CommonCrawl, WeChat, and Faclon. These selected articles will be utilized as a training set for mmlu. The goal is to determine whether this training set can improve the relevant mmlu performance metrics.\\nFor emb_recall: We use sentence-transformers to generate embeddings and apply a filter for those with a cosine distance greater than 0.95. The content is mainly… See the full description on the dataset page: https://huggingface.co/datasets/itsliupeng/mmlu_recall."},
	{"name":"Uni-Encoder","keyword":"chinese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/ChiyuSONG/Uni-Encoder","creator_name":"Chiyu Song","creator_url":"https://huggingface.co/ChiyuSONG","description":"\\n  💻 [Github Repo] • 📃 [Paper]\\n\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tOverview\\n\\t\\n\\nThis a collection of datasets used in the paper titled \\\"Uni-Encoder: A Fast and Accurate Response Selection Paradigm for Generation-Based Dialogue Systems\\\".\\nThe following datasets have been included:\\n\\nUbuntu Corpus V1\\nUbuntu Corpus V2\\nPersonaChat\\nDouban Conv Corpus\\n\\nAll datasets have been standardized to a unified format for research need.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tCitation\\n\\t\\n\\n@inproceedings{song2023uni,\\n  title={Uni-encoder: A fast and accurate… See the full description on the dataset page: https://huggingface.co/datasets/ChiyuSONG/Uni-Encoder."},
	{"name":"ddm","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Chiwei/ddm","creator_name":"Che","creator_url":"https://huggingface.co/Chiwei","description":"Chiwei/ddm dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"ChatHaruhi-Waifu","keyword":"chinese","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/silk-road/ChatHaruhi-Waifu","creator_name":"SilkRoad","creator_url":"https://huggingface.co/silk-road","description":"本数据集是为了部分不适合直接显示的角色进行hugging face存储。text部分做了简单的编码加密\\n使用方法\\n载入函数\\nfrom transformers import AutoTokenizer, AutoModel, AutoModelForCausalLM\\ntokenizer = AutoTokenizer.from_pretrained(\\\"silk-road/Chat-Haruhi_qwen_1_8\\\", trust_remote_code=True)\\nmodel = AutoModelForCausalLM.from_pretrained(\\\"silk-road/Chat-Haruhi_qwen_1_8\\\", trust_remote_code=True).half().cuda()\\nmodel = model.eval()\\n\\n具体看https://github.com/LC1332/Chat-Haruhi-Suzumiya/blob/main/notebook/ChatHaruhi_x_Qwen1_8B.ipynb 这个notebook\\nfrom ChatHaruhi… See the full description on the dataset page: https://huggingface.co/datasets/silk-road/ChatHaruhi-Waifu."},
	{"name":"Verified-Camel-zh","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/noobmaster29/Verified-Camel-zh","creator_name":"Victor Sung","creator_url":"https://huggingface.co/noobmaster29","description":"This is a direct Chinese translation using GPT4 of the Verified-Camel dataset. I hope you find it useful. \\nhttps://huggingface.co/datasets/LDJnr/Verified-Camel\\nCitation:\\n@article{daniele2023amplify-instruct,\\n  title={Amplify-Instruct: Synthetically Generated Diverse Multi-turn Conversations for Effecient LLM Training.},\\n  author={Daniele, Luigi and Suphavadeeprasit},\\n  journal={arXiv preprint arXiv:(comming soon)},\\n  year={2023}\\n}\\n\\n"},
	{"name":"cszs_zh_en","keyword":"chinese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/ky552/cszs_zh_en","creator_name":"speech552_ky","creator_url":"https://huggingface.co/ky552","description":"This dataset contains the Mandarin-English track of the benchmark from ICASSP 2024: Zero Resource Code-Switched Speech Benchmark Using Speech Utterance Pairs for Multiple Spoken Languages.Though the benchmark is originally designed to assess the semantic and syntactic abilities of the speech foundation models, you can also use this dataset for code-switching ASR.\\nIf you find this dataset helpful, please consider to cite the following paper:\\n@INPROCEEDINGS{10446737,\\n  author={Huang, Kuan-Po and… See the full description on the dataset page: https://huggingface.co/datasets/ky552/cszs_zh_en."},
	{"name":"cotinus-poem","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ticoAg/cotinus-poem","creator_name":"ticoAg","creator_url":"https://huggingface.co/ticoAg","description":"\\n\\t\\n\\t\\t\\n\\t\\t数据格式定义\\n\\t\\n\\nfrom pydantic import BaseModel, Field\\n\\nclass PoemValidator(BaseModel):\\n    title: str = Field(..., description=\\\"诗名\\\")\\n    author: str = Field(..., description=\\\"作者\\\")\\n    dynasty: str = Field(..., description=\\\"朝代\\\")\\n    theme: str = Field(..., description=\\\"主题\\\")\\n    section: str = Field(..., description=\\\"节名\\\")\\n    content: Union[list[dict[str, Union[str, list[str]]]]] = Field(..., description=\\\"诗内容\\\")  #\\n    appreciation: str = Field(..., description=\\\"赏析\\\")\\n    rhythmic: str =… See the full description on the dataset page: https://huggingface.co/datasets/ticoAg/cotinus-poem."},
	{"name":"Slim-COIG-Kun","keyword":"chinese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/lorinma/Slim-COIG-Kun","creator_name":"Nuo","creator_url":"https://huggingface.co/lorinma","description":"\\nThis is a Slim version of COIG-Kun\\n因为原始的数据集有53万条之多，所以进行了subsample。\\n采样方法大致为，使用bert-base-chinese将Instruction转换为embedding，使用类knn的方法抽取了1万条。并转换成了sharegpt格式。 \\n为了更直观的查看效果，文件中还有一个仅采样了1千条的版本。采样前后的Embedding使用tsne进行可视化。\\n\\noriginal Kun(蓝色)和Moss003（红色）的区别，是否可解读为虽然Kun的数量很高，但是首个instruction的语义多样化不如Moss。（后记：这个地方不应该用tsne的，类见应该用umap不过anyway凑活着看吧是那个意思\\n\\n"},
	{"name":"uner_llm_instructions","keyword":"chinese","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/universalner/uner_llm_instructions","creator_name":"Universal NER","creator_url":"https://huggingface.co/universalner","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Universal NER v1 in the Aya format\\n\\t\\n\\nThis dataset is a format conversion from its original v1 format into the Aya instruction format and it's released here under the same CC-BY-SA 4.0 license and conditions.\\nIt contains data in multiple languages and this version is intended for multi-lingual LLM construction/tuning.\\nThe dataset contains different subsets and their dev/test/train splits, depending on language. \\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tCitation\\n\\t\\n\\nIf you utilize this dataset… See the full description on the dataset page: https://huggingface.co/datasets/universalner/uner_llm_instructions."},
	{"name":"openai-formate-function-calling-small","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Deepexi/openai-formate-function-calling-small","creator_name":"Deepexi Inc","creator_url":"https://huggingface.co/Deepexi","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\t数据集内容说明:\\n\\t\\n\\n包含700+个阿里云OpenAPI的信息;包括Dataworks,EMR，DataLake，Maxcompute，Hologram,实时计算Flink版，QuickBI,DTS等多个产品的公开Open API信息。\\n Functions信息与OpenAI functions calling 能力中，functions信息传入的格式保持一致 \\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\t样例\\n\\t\\n\\n{\\n  \\\"systemPrompt\\\": 你是一个函数筛选助理，如果与问题相关的话,您可以使用下面的函数来获取更多数据以回答用户提出的问题:{\\\"name\\\": \\\"UpdateTicketNum\\\", \\\"description\\\": \\\"对用于免登嵌入报表的指定的ticket进行更新票据数量操作。\\\", \\\"parameters\\\": {\\\"type\\\": \\\"object\\\", \\\"properties\\\": [{\\\"Ticket\\\": {\\\"type\\\": \\\"string\\\", \\\"description\\\":… See the full description on the dataset page: https://huggingface.co/datasets/Deepexi/openai-formate-function-calling-small."},
	{"name":"uner_llm_inst_chinese","keyword":"chinese","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/universalner/uner_llm_inst_chinese","creator_name":"Universal NER","creator_url":"https://huggingface.co/universalner","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Universal NER v1 in the Aya format - Chinese subset\\n\\t\\n\\nThis dataset is a format conversion for the Chinese data in the original Universal NER v1 into the Aya instruction format and it's released here under the same CC-BY-SA 4.0 license and conditions.\\nThe dataset contains different subsets and their dev/test/train splits, depending on language. For more details, please refer to:\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Details\\n\\t\\n\\nFor the original Universal NER dataset v1 and more… See the full description on the dataset page: https://huggingface.co/datasets/universalner/uner_llm_inst_chinese."},
	{"name":"ntx_llm_instructions","keyword":"chinese","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/tellarin-ai/ntx_llm_instructions","creator_name":"Tellarin.ai","creator_url":"https://huggingface.co/tellarin-ai","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for NTX v1 in the Aya format\\n\\t\\n\\nThis dataset is a format conversion from its original v1 format into the Aya instruction format and it's released here under the CC-BY-SA 4.0 license and conditions.\\nIt contains data in multiple languages and this version is intended for multi-lingual LLM construction/tuning.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tCitation\\n\\t\\n\\nIf you utilize this dataset version, feel free to cite/footnote this huggingface dataset repo, but please also cite the original dataset… See the full description on the dataset page: https://huggingface.co/datasets/tellarin-ai/ntx_llm_instructions."},
	{"name":"ntx_llm_inst_chinese","keyword":"chinese","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/tellarin-ai/ntx_llm_inst_chinese","creator_name":"Tellarin.ai","creator_url":"https://huggingface.co/tellarin-ai","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for NTX v1 in the Aya format - Chinese subset\\n\\t\\n\\nThis dataset is a format conversion for the Chinese data from the original NTX into the Aya instruction format and it's released here under the CC-BY-SA 4.0 license.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Details\\n\\t\\n\\nFor the original NTX dataset, the conversion to the Aya instructions format, or more details, please refer to the full dataset in instruction form (https://huggingface.co/datasets/tellarin-ai/ntx_llm_instructions) or to the… See the full description on the dataset page: https://huggingface.co/datasets/tellarin-ai/ntx_llm_inst_chinese."},
	{"name":"blossom-orca-v2","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Azure99/blossom-orca-v2","creator_name":"Azure99","creator_url":"https://huggingface.co/Azure99","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tBLOSSOM ORCA V2\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\t介绍\\n\\t\\n\\nBlossom Orca V2是一个基于OpenOrca衍生而来的中英双语指令数据集，适用于指令微调。\\n相比于blossom-wizard-v1，指令不变，进一步优化了输出效果，此外，将system消息并入user消息中。\\n本数据集从OpenOrca中抽取了系统提示和指令，首先将其翻译为中文并校验翻译结果，再使用指令调用gpt-3.5-turbo-0613模型生成响应，并过滤掉包含自我认知以及拒绝回答的响应，以便后续对齐。此外，为了确保响应风格的一致性以及中英数据配比，本数据集还对未翻译的原始指令也进行了相同的调用，最终得到了1:1的中英双语指令数据。\\n相比直接对原始OpenOrca进行翻译的中文数据集，Blossom Orca的一致性及质量更高。\\n本次发布了全量数据的30%，包含中英双语各100K，共计200K记录。\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\t语言\\n\\t\\n\\n以中文和英文为主。\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\t数据集结构… See the full description on the dataset page: https://huggingface.co/datasets/Azure99/blossom-orca-v2."},
	{"name":"blossom-wizard-v2","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Azure99/blossom-wizard-v2","creator_name":"Azure99","creator_url":"https://huggingface.co/Azure99","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tBLOSSOM WIZARD V2\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\t介绍\\n\\t\\n\\nBlossom Wizard V2是一个基于WizardLM_evol_instruct_V2衍生而来的中英双语指令数据集，适用于指令微调。\\n相比于blossom-wizard-v1，指令不变，进一步优化了输出效果。\\n本数据集从WizardLM_evol_instruct_V2中抽取了指令，首先将其翻译为中文并校验翻译结果，再使用指令调用gpt-3.5-turbo-0613模型生成响应，并过滤掉包含自我认知以及拒绝回答的响应，以便后续对齐。此外，为了确保响应风格的一致性以及中英数据配比，本数据集还对未翻译的原始指令也进行了相同的调用，最终得到了1:1的中英双语指令数据。\\n相比直接对原始Wizard进行翻译的中文数据集，Blossom Wizard的一致性及质量更高。\\n本次发布了全量数据的30%，包含中英双语各50K，共计100K记录。\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\t语言\\n\\t\\n\\n以中文和英文为主。\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\t数据集结构… See the full description on the dataset page: https://huggingface.co/datasets/Azure99/blossom-wizard-v2."},
	{"name":"ChatHaruhi-RolePlaying","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/silk-road/ChatHaruhi-RolePlaying","creator_name":"SilkRoad","creator_url":"https://huggingface.co/silk-road","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tChatHaruhi\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tReviving Anime Character in Reality via Large Language Model\\n\\t\\n\\nChat-Haruhi-Suzumiyais a language model that imitates the tone, personality and storylines of characters like Haruhi Suzumiya,\\nhttps://github.com/LC1332/Chat-Haruhi-Suzumiya\\nUsing this to load character and chat with him/her\\nfrom ChatHaruhi import ChatHaruhi\\n\\nchatbot = ChatHaruhi( role_from_hf = \\\"silk-road/ChatHaruhi-RolePlaying/haruhi\\\",\\\\\\n                      llm = 'openai' ,\\\\… See the full description on the dataset page: https://huggingface.co/datasets/silk-road/ChatHaruhi-RolePlaying."},
	{"name":"ml-kge","keyword":"chinese","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/davanstrien/ml-kge","creator_name":"Daniel van Strien","creator_url":"https://huggingface.co/davanstrien","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tMKGE: Multilingual Knowledge Graph Enhancement\\n\\t\\n\\nnote this dataset card was copied from this GitHub Repository\\nTask Description |\\nWikiKGE-10 |\\nEvaluation |\\nPaper |\\nCitation |\\nLicense\\nRecent work in Natural Language Processing and Computer Vision has been leveraging textual information -- e.g., entity names and descriptions -- available in knowledge graphs to ground neural models to high-quality structured data.\\nHowever, when it comes to non-English languages, both quantity and… See the full description on the dataset page: https://huggingface.co/datasets/davanstrien/ml-kge."},
	{"name":"blossom-math-v3","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Azure99/blossom-math-v3","creator_name":"Azure99","creator_url":"https://huggingface.co/Azure99","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tBLOSSOM MATH V3\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\t介绍\\n\\t\\n\\nBlossom Math V3是基于Math23K和GSM8K衍生而来的中英双语数学对话数据集，适用于数学问题微调。\\n相比于blossom-math-v2，进一步优化了数据处理流程，并强化答案检查。\\n本数据集采用全量Math23K、GSM8K和翻译后的GSM8K的问题，随后调用gpt-3.5-turbo-0613生成结果，并使用原始数据集中的答案对生成的结果进行验证，过滤掉错误答案，很大程度上保证了问题和答案的准确性。\\n本次发布了全量数据的25%，包含10K记录。\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\t语言\\n\\t\\n\\n中文和英文\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\t数据集结构\\n\\t\\n\\n每条数据代表一个完整的题目及答案，包含id、input、output、answer、dataset四个字段。\\n\\nid：字符串，代表原始数据集中的题目id，与dataset字段结合可确定唯一题目。\\ninput：字符串，代表问题。\\noutput：字符串，代表gpt-3.5-turbo-0613生成的答案。… See the full description on the dataset page: https://huggingface.co/datasets/Azure99/blossom-math-v3."},
	{"name":"csc","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Weaxs/csc","creator_name":"Weaxs","creator_url":"https://huggingface.co/Weaxs","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset for CSC\\n\\t\\n\\n中文纠错数据集\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nChinese Spelling Correction (CSC) is a task to detect and correct misspelled characters in Chinese texts.\\n共计 120w 条数据，以下是数据来源\\n\\n\\t\\n\\t\\t\\n数据集\\n语料\\n链接\\n\\n\\n\\t\\t\\nSIGHAN+Wang271K 拼写纠错数据集\\nSIGHAN+Wang271K(27万条)\\nhttps://huggingface.co/datasets/shibing624/CSC\\n\\n\\nECSpell 拼写纠错数据集\\n包含法律、医疗、金融等领域\\nhttps://github.com/Aopolin-Lv/ECSpell\\n\\n\\nCGED 语法纠错数据集\\n仅包含了2016和2021年的数据集… See the full description on the dataset page: https://huggingface.co/datasets/Weaxs/csc."},
	{"name":"CHLAWS","keyword":"chinese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/cfa532/CHLAWS","creator_name":"Thomas Fung","creator_url":"https://huggingface.co/cfa532","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Dataset Name\\n\\t\\n\\n\\n\\nThis dataset card aims to be a base template for new datasets. It has been generated using this raw template.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Details\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\n\\nLaw documents legislated in China.\\n\\nCurated by: [More Information Needed]\\nFunded by [optional]: [More Information Needed]\\nShared by [optional]: [More Information Needed]\\nLanguage(s) (NLP): [More Information Needed]\\nLicense: [More Information Needed]\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset… See the full description on the dataset page: https://huggingface.co/datasets/cfa532/CHLAWS."},
	{"name":"yayi2_pretrain_data","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/wenge-research/yayi2_pretrain_data","creator_name":"wenge-research","creator_url":"https://huggingface.co/wenge-research","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\t介绍/Introduction\\n\\t\\n\\n本数据集源自雅意训练语料，我们精选了约100B数据，数据大小约为500GB。我们期望通过雅意预训练数据的开源推动中文预训练大模型开源社区的发展，并积极为此贡献力量。通过开源，我们与每一位合作伙伴共同构建雅意大模型生态。\\nWe opensource the pre-trained dataset in this release, it should contain more than 100B tokens depending on the tokenizer you use, requiring more than 500GB of local storage. By open-sourcing the pre-trained dataset, we aim to contribute to the development of the Chinese pre-trained large language model open-source community. Through open-source, we… See the full description on the dataset page: https://huggingface.co/datasets/wenge-research/yayi2_pretrain_data."},
	{"name":"blossom-chat-v2","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Azure99/blossom-chat-v2","creator_name":"Azure99","creator_url":"https://huggingface.co/Azure99","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tBLOSSOM CHAT V2\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\t介绍\\n\\t\\n\\nBlossom Chat V2是基于ShareGPT 90K衍生而来的中英双语对话数据集，适用于多轮对话微调。\\n相比于blossom-chat-v1，进一步优化了数据处理流程，并配平了中英语料。\\n本数据集抽取了ShareGPT的多轮对话指令，仅将指令进行翻译，随后使用多轮指令迭代调用gpt-3.5-turbo-0613。\\n相比原始的ShareGPT数据，主要解决了中文对话数据量较少，以及由ChatGPT生成长度限制而导致的输出截断问题。\\n本次发布了全量数据的20%，包含30K记录。\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\t语言\\n\\t\\n\\n以中文和英文为主，中英文数据按照约1:1的比例混合。\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\t数据集结构\\n\\t\\n\\n每条数据代表一个完整的多轮对话，包含id和conversations两个字段。\\n\\nid：字符串，代表原始ShareGPT的对话id，可以通过链接https://sharegpt.com/c/id来访问原始对话。… See the full description on the dataset page: https://huggingface.co/datasets/Azure99/blossom-chat-v2."},
	{"name":"WikidataLabels","keyword":"chinese","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/rayliuca/WikidataLabels","creator_name":"Ray Liu","creator_url":"https://huggingface.co/rayliuca","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tWikidata Labels\\n\\t\\n\\nLarge parallel corpus for machine translation\\n\\nEntity label data extracted from Wikidata (2022-01-03), filtered for item entities only  \\nOnly download the languages you need with datasets>=2.14.0\\nSimilar dataset: https://huggingface.co/datasets/wmt/wikititles (18 Wikipedia titles pairs instead of all Wikidata entities)\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Details\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Sources\\n\\t\\n\\n\\nWikidata JSON dump (wikidata-20220103-all.json.gz)… See the full description on the dataset page: https://huggingface.co/datasets/rayliuca/WikidataLabels."},
	{"name":"oasst2_top1_chat_format","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/blancsw/oasst2_top1_chat_format","creator_name":"Blanc Swan","creator_url":"https://huggingface.co/blancsw","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tOpenAssistant TOP-1 Conversation Threads in huggingface chat format\\n\\t\\n\\nExport of oasst2 only top 1 threads in huggingface chat format\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tScript\\n\\t\\n\\nThe convert script can be find here\\n"},
	{"name":"language_tags","keyword":"chinese","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/lbourdois/language_tags","creator_name":"Loïck BOURDOIS","creator_url":"https://huggingface.co/lbourdois","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDescription\\n\\t\\n\\nDataset listing 27,328 languages and dialects (also includes macrolanguage names).For each language, either the ISO 639 code, the Glottolog code or both are provided.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tColumns\\n\\t\\n\\n\\nEnglish_Name: Language name in English (e.g. \\\"French\\\").\\nNative_Name: If value is not 0, corresponds to the name of the language by native speakers (e.g. \\\"Français\\\") which may have been found in Wikipedia's nativename field.\\nGlottocode: The language tag in the Glottolog convention… See the full description on the dataset page: https://huggingface.co/datasets/lbourdois/language_tags."},
	{"name":"ZhihuJunkieSpoken","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/bzb2023/ZhihuJunkieSpoken","creator_name":"刷知乎刷的","creator_url":"https://huggingface.co/bzb2023","description":"BLACK枪骑兵, luxenius, pansz, 半佛仙人, 不想上吊王承恩, \\n                 曹丰泽, 炽梦, 疯死沃, 弗兰克扬, 古青, 关之檀,\\n                 贺仙, 槿年, 框框框子, 李建秋, 流浪的蛤蟆, 摸鱼的王同学, \\n                 申鹏, 斯大王, 托卡马克之冠, 王克丹,\\n                 王瑞恩, 温酒, 西门豹的精神门徒, 谢流远, 竹青\\n知乎大V言论\\n"},
	{"name":"MT-Bench-ZH","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/GeneZC/MT-Bench-ZH","creator_name":"Chen Zhang","creator_url":"https://huggingface.co/GeneZC","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\t💬 MT-Bench-ZH\\n\\t\\n\\n👻 GitHub\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\t🎯 Motivation\\n\\t\\n\\nMiniChat-1/1.5/2-3B are all instruction-following language models that could handle Chinese instructions, however, there is currently no instruciton-following benchamrk specialized for Chinese. Due to this, our previous evaluation has been limited to English-only benchmarks (i.e., AlpacaEval and MT-Bench). \\nTo this demand, MT-Bench-ZH is made to mitigate this. MT-Bench-ZH is basically translated from MT-Bench-ZH by GPT-4 and… See the full description on the dataset page: https://huggingface.co/datasets/GeneZC/MT-Bench-ZH."},
	{"name":"E-EVAL","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/E-EVAL/E-EVAL","creator_name":"E-EVAL","creator_url":"https://huggingface.co/E-EVAL","description":"E-EVAL/E-EVAL dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"Meow-Instruct-12k","keyword":"chinese","license":"GNU General Public License v3.0","license_url":"https://choosealicense.com/licenses/gpl-3.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Mxode/Meow-Instruct-12k","creator_name":"Max Zhang","creator_url":"https://huggingface.co/Mxode","description":"一只猫猫的说话语录。\\n更长的版本见这里：Mxode/Meow-Instruct-34k\\n"},
	{"name":"Meow-Instruct-34k","keyword":"chinese","license":"GNU General Public License v3.0","license_url":"https://choosealicense.com/licenses/gpl-3.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Mxode/Meow-Instruct-34k","creator_name":"Max Zhang","creator_url":"https://huggingface.co/Mxode","description":"一只猫猫的说话语录。\\n更短的版本见这里：Mxode/Meow-Instruct-12k\\n"},
	{"name":"Haruhi-Zero-RolePlaying-movie-PIPPA","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/silk-road/Haruhi-Zero-RolePlaying-movie-PIPPA","creator_name":"SilkRoad","creator_url":"https://huggingface.co/silk-road","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\t2000 Chinese RoleCards from IMDB_250 Movies and PIPPA\\n\\t\\n\\n用于拓展zero-shot角色扮演的角色卡片。\\n其中870个角色来自电影字幕总结(id为movie_xx)，其中406张翻译成了简体中文，剩下的没翻（所以有些繁体或者英文混杂）\\n1270个角色来自于对PIPPA数据集的翻译\\n\\n凌云志@伯恩茅斯大学 使用射手api爬取了电影的字幕\\n\\n李鲁鲁 完成了从字幕到角色卡片的总结，以及对数据的翻译(openai)\\n\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\t后续\\n\\t\\n\\n我们后续打算用这些卡片 从openai, CharacterGLM, KoboldAI的api中，利用Baize的方式去获得数据。\\n项目主页 https://github.com/LC1332/Chat-Haruhi-Suzumiya\\n如果你要讨论加入我们的项目\\n可以把你的联系方式私信发给 https://www.zhihu.com/people/cheng-li-47\\n"},
	{"name":"Dataset","keyword":"chinese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/HistoryTrans/Dataset","creator_name":"文脉","creator_url":"https://huggingface.co/HistoryTrans","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tHistoryTrans\\n\\t\\n\\nHistoryTrans 是一个古文翻译数据集，通过数据预处理和质量控制，来提高古文翻译的质量和实用性。\\n参考我们的项目主页HistoryTrans古文翻译.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\t数据集详细信息\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\t数据集来源\\n\\t\\n\\n\\n主体: Classical-Modern\\n额外补充: ：《二十四史》和《清史稿》中提取\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\t数据集结构\\n\\t\\n\\n数据集包含以下 JSONL 文件：\\n\\ntrain_01_04.jsonl: 训练集，主要用于训练翻译模型。\\nval_01_04.jsonl: 验证集，用于训练过程中的模型微调和评估。\\ntest_01_04.jsonl: 测试集，用于评估最终模型性能。\\n\\n每个 JSON 对象包括：\\n\\ninputs: 原始古文\\ntruth: 准确翻译\\n\\n例如：\\n{\\\"inputs\\\": \\\"昕曰： 回纥之功，唐已报之矣。\\\", \\\"truth\\\": \\\"萧昕反驳说： 回纥的功劳，唐朝已经报答了。\\\"}\\n{\\\"inputs\\\": \\\"然县令所犯在恩前，中人所犯在恩后。\\\", \\\"truth\\\":… See the full description on the dataset page: https://huggingface.co/datasets/HistoryTrans/Dataset."},
	{"name":"AISHELL-3","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/AISHELL/AISHELL-3","creator_name":"aishelltech","creator_url":"https://huggingface.co/AISHELL","description":"AISHELL-3 is a large-scale and high-fidelity multi-speaker Mandarin speech corpus published by Beijing Shell Shell Technology Co.,Ltd. It can be used to train multi-speaker Text-to-Speech (TTS) systems.The corpus contains roughly 85 hours of emotion-neutral recordings spoken by 218 native Chinese mandarin speakers and total 88035 utterances. Their auxiliary attributes such as gender, age group and native accents are explicitly marked and provided in the corpus. Accordingly, transcripts in… See the full description on the dataset page: https://huggingface.co/datasets/AISHELL/AISHELL-3."},
	{"name":"FollowBench","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/YuxinJiang/FollowBench","creator_name":"Yuxin Jiang","creator_url":"https://huggingface.co/YuxinJiang","description":"\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tFollowBench: A Multi-level Fine-grained Constraints Following Benchmark for Large Language Models\\n\\t\\n\\nWe introduce FollowBench, a Multi-level Fine-grained Constraints Following Benchmark for systemically and precisely evaluate the instruction-following capability of LLMs.\\n\\nFollowBench comprehensively includes five different types (i.e., Content, Situation, Style, Format, and Example) of fine-grained constraints. \\nTo enable a precise constraint following estimation on diverse… See the full description on the dataset page: https://huggingface.co/datasets/YuxinJiang/FollowBench."},
	{"name":"oaast_rm_zh_jieba","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/lenML/oaast_rm_zh_jieba","creator_name":"len","creator_url":"https://huggingface.co/lenML","description":"尝试解决\\\"llm repetition problem\\\"，使用分词模型对oaast语料进行“结巴化”数据增强，提供更强的重复内容拒绝效果。\\nAttempts to solve the \\\"llm repetition problem\\\" by using a segmentation model to enhance the oaast corpus with \\\"stuttering\\\" data to provide stronger rejection of duplicate content.\\n其次，还过滤掉了所有自我认知的微调样本。\\nSecond, it also filters out all the fine-tuned samples of self-cognition.\\nfiles:\\n\\noaast_rm_zh_jieba.jsonl : word level repeat\\noaast_rm_zh_sent_jieba.jsonl : sentence level repeat\\n\\n"},
	{"name":"oaast_rm_full_jieba","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/lenML/oaast_rm_full_jieba","creator_name":"len","creator_url":"https://huggingface.co/lenML","description":"尝试解决\\\"llm repetition problem\\\"，使用分词模型对oaast语料进行“结巴化”数据增强，提供更强的重复内容拒绝效果。\\nAttempts to solve the \\\"llm repetition problem\\\" by using a segmentation model to enhance the oaast corpus with \\\"stuttering\\\" data to provide stronger rejection of duplicate content.\\n其次，还过滤掉了所有自我认知的微调样本。\\nSecond, it also filters out all the fine-tuned samples of self-cognition.\\nfiles:\\n\\noaast_rm_full_jieba.jsonl : word level repeat\\noaast_rm_full_sent_jieba.jsonl : sentence level repeat\\n\\n"},
	{"name":"CASIA-HWDB2-line","keyword":"chinese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Teklia/CASIA-HWDB2-line","creator_name":"Teklia","creator_url":"https://huggingface.co/Teklia","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tCASIA-HWDB2 - line level\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThe offline Chinese handwriting database (CASIA-HWDB2) was built by the National Laboratory of Pattern Recognition (NLPR), Institute of Automation of Chinese Academy of Sciences (CASIA). \\nThe handwritten samples were produced by 1,020 writers using Anoto pen on papers, such that both online and offline data were obtained.\\nNote that all images are resized to a fixed height of 128 pixels.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages\\n\\t\\n\\nAll the… See the full description on the dataset page: https://huggingface.co/datasets/Teklia/CASIA-HWDB2-line."},
	{"name":"Haruhi-Baize-Role-Playing-Conversation","keyword":"chinese","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/silk-road/Haruhi-Baize-Role-Playing-Conversation","creator_name":"SilkRoad","creator_url":"https://huggingface.co/silk-road","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tHaruhi-Zero的Conversation训练数据\\n\\t\\n\\n我们计划拓展ChatHaruhi，从Few-shot到Zero-shot，这个数据集记录使用各个（中文）角色扮演api进行Baize式相互聊天后得到的数据结果\\nids代表聊天的时候两张bot的角色卡片， 角色卡片的信息可以在https://huggingface.co/datasets/silk-road/Haruhi-Zero-RolePlaying-movie-PIPPA 中找到\\n并且对于第一次出现的id0，也会在prompt字段中进行记录。\\n聊天的时候id和ids的卡片进行对应\\n\\nopenai 代表两个聊天的bot都使用openai\\nGLM 代表两个聊天的bot都使用CharacterGLM\\nClaude 代表两个聊天的bot都使用Claude\\nClaude_openai 代表id0的使用Claude， id1的使用openai\\nBaichuan 代表两个聊天的bot都使用Character-Baichuan-Turbo… See the full description on the dataset page: https://huggingface.co/datasets/silk-road/Haruhi-Baize-Role-Playing-Conversation."},
	{"name":"Pretrain-Taiwan-DentistKnowledge-zhTW-290K","keyword":"chinese","license":"GNU General Public License v3.0","license_url":"https://choosealicense.com/licenses/gpl-3.0/","language":"en","dataset_url":"https://huggingface.co/datasets/DataAgent/Pretrain-Taiwan-DentistKnowledge-zhTW-290K","creator_name":"DataAgent","creator_url":"https://huggingface.co/DataAgent","description":"LaplaceAI 繁中領域知識資料集計畫\\n利用我在爬蟲自動化與資料後處理上的專業，針對不同大小的領域知識資料集進行建立與維護。\\n在 LaplaceAI 的 huggingface 頁面，你可以找到許多不同領域的資料集。\\n這項 datasets 是由 LaplaceAI 整理維護的牙科相關知識。\\n"},
	{"name":"food-images-1k","keyword":"chinese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/snowsense/food-images-1k","creator_name":"snowsense","creator_url":"https://huggingface.co/snowsense","description":"snowsense/food-images-1k dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"language-dataset","keyword":"chinese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neon-mao/language-dataset","creator_name":"maoqifan","creator_url":"https://huggingface.co/neon-mao","description":"\\n"},
	{"name":"seamless-align-expressive","keyword":"chinese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/jhu-clsp/seamless-align-expressive","creator_name":"Center for Language and Speech Processing @ JHU","creator_url":"https://huggingface.co/jhu-clsp","description":"\\n\\t\\n\\t\\t\\n\\t\\tDataset Card for Seamless-Align-Expressive (WIP). Inspired by https://huggingface.co/datasets/allenai/nllb\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThis dataset was created based on metadata for mined expressive Speech-to-Speech(S2S) released by Meta AI.  The S2S contains data for 5 language pairs. The S2S dataset is ~228GB compressed.\\n\\n\\t\\n\\t\\t\\n\\t\\tHow to use the data\\n\\t\\n\\nThere are two ways to access the data:\\n\\nVia the Hugging Face Python datasets library\\n\\nScripts coming soon\\n\\n\\nClone the git repo\\n\\ngit… See the full description on the dataset page: https://huggingface.co/datasets/jhu-clsp/seamless-align-expressive."},
	{"name":"longwriter-6k-filtered","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/lenML/longwriter-6k-filtered","creator_name":"len","creator_url":"https://huggingface.co/lenML","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLongWriter-6k-Filtered\\n\\t\\n\\n\\n  🤖 [LongWriter Dataset]  • 💻 [Github Repo] • 📃 [LongWriter Paper] • 📃 [Tech report]\\n\\n\\nlongwriter-6k-filtered dataset contains 666 filtered examples SFT data with ultra-long output ranging from 2k-32k words in length (both English and Chinese) based on LongWriter-6k.The data can support training LLMs to extend their maximum output window size to 10,000+ words with low computational cost.\\nThe tech report is available at Minimum Tuning to Unlock Long… See the full description on the dataset page: https://huggingface.co/datasets/lenML/longwriter-6k-filtered."},
	{"name":"MM-Eval","keyword":"chinese","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/prometheus-eval/MM-Eval","creator_name":"prometheus-eval","creator_url":"https://huggingface.co/prometheus-eval","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tMultilingual Meta-EVALuation benchmark (MM-Eval)\\n\\t\\n\\n\\n👨‍💻Code\\n|\\n📄Paper\\n|\\n🤗 MMQA\\n\\n\\nMM-Eval is a multilingual meta-evaluation benchmark consisting of five core subsets—Chat, Reasoning, Safety, Language Hallucination, and Linguistics—spanning 18 languages and a Language Resource subset spanning 122 languages for a broader analysis of language effects. \\n\\nDesign ChoiceIn this work, we minimize the inclusion of translated samples, as mere translation may alter existing preferences due… See the full description on the dataset page: https://huggingface.co/datasets/prometheus-eval/MM-Eval."},
	{"name":"caexpo_news","keyword":"chinese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/GXMZU/caexpo_news","creator_name":"Guangxi Minzu University","creator_url":"https://huggingface.co/GXMZU","description":"\\n\\t\\n\\t\\t\\n\\t\\tCAEXPO News Dataset\\n\\t\\n\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThe CAEXPO (China-ASEAN Expo) News Dataset is a comprehensive collection of news articles from the offical China-ASEAN Expo website. The dataset covers various aspects including:\\n\\nTrade and economic cooperation\\nCultural exchanges\\nRegional development\\nPolicy announcements\\nInnovation and technology cooperation\\n......\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Fields\\n\\t\\n\\n\\ntitle: The headline of the news article\\nurl: URL link to the original news article… See the full description on the dataset page: https://huggingface.co/datasets/GXMZU/caexpo_news."},
	{"name":"Saka-Alpaca-v1","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Sakalti/Saka-Alpaca-v1","creator_name":"sakasan","creator_url":"https://huggingface.co/Sakalti","description":"https://chatgpt.com\\n"},
	{"name":"xjtu_info","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/volcanos/xjtu_info","creator_name":"vol","creator_url":"https://huggingface.co/volcanos","description":"volcanos/xjtu_info dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"Erotic-literature","keyword":"chinese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/XuehangCang/Erotic-literature","creator_name":"XuehangCang","creator_url":"https://huggingface.co/XuehangCang","description":"\\n\\t\\n\\t\\t\\n\\t\\tDataset Card for Erotic Literature in Chinese\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThis dataset is a collection of erotic literature in Chinese, compiled for the purpose of text generation tasks. It is divided into two splits: a training set and a test set, allowing for model training and evaluation. The dataset is of moderate size, suitable for projects working on text-based AI models, particularly focusing on the genre of erotic literature.\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Details\\n\\t\\n\\n\\nLanguage: Chinese (zh)… See the full description on the dataset page: https://huggingface.co/datasets/XuehangCang/Erotic-literature."},
	{"name":"MMMLU","keyword":"chinese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/bzantium/MMMLU","creator_name":"Minho Ryu","creator_url":"https://huggingface.co/bzantium","description":"\\n\\t\\n\\t\\t\\n\\t\\tMultilingual Massive Multitask Language Understanding (MMMLU)\\n\\t\\n\\nThe MMLU is a widely recognized benchmark of general knowledge attained by AI models. It covers a broad range of topics from 57 different categories, covering elementary-level knowledge up to advanced professional subjects like law, physics, history, and computer science.\\nWe translated the MMLU’s test set into 14 languages using professional human translators. Relying on human translators for this evaluation increases… See the full description on the dataset page: https://huggingface.co/datasets/bzantium/MMMLU."},
	{"name":"hanlp_date-zh","keyword":"chinese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/zeroMN/hanlp_date-zh","creator_name":"zeroTT","creator_url":"https://huggingface.co/zeroMN","description":"\\n\\t\\n\\t\\t\\n\\t\\t--\\n2nd International Chinese Word Segmentation Bakeoff - Data Release\\nRelease 1, 2005-11-18\\n\\t\\n\\n\\nIntroduction\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tThis directory contains the training, test, and gold-standard data\\nused in the 2nd International Chinese Word Segmentation Bakeoff. Also\\nincluded is the script used to score the results submitted by the\\nbakeoff participants and the simple segmenter used to generate the\\nbaseline and topline data.\\n\\t\\n\\n\\nFile List\\n\\n\\n\\t\\n\\t\\n\\t\\n\\t\\tgold/       Contains the gold standard… See the full description on the dataset page: https://huggingface.co/datasets/zeroMN/hanlp_date-zh."},
	{"name":"tgb_niepanchongsheng","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Jiangwlee/tgb_niepanchongsheng","creator_name":"Li","creator_url":"https://huggingface.co/Jiangwlee","description":"Jiangwlee/tgb_niepanchongsheng dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"BenchMAX_Rule-based","keyword":"chinese","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/LLaMAX/BenchMAX_Rule-based","creator_name":"LLaMAX","creator_url":"https://huggingface.co/LLaMAX","description":"\\n\\t\\n\\t\\t\\n\\t\\tDataset Sources\\n\\t\\n\\n\\nPaper: BenchMAX: A Comprehensive Multilingual Evaluation Suite for Large Language Models\\nLink: https://arxiv.org/pdf/2502.07346\\nRepository: https://github.com/CONE-MT/BenchMAX\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\nBenchMAX_Rule-based is a dataset of BenchMAX, sourcing from IFEval, which is a rule-based benchmark for evaluating the instruction following capabilities.\\nWe extend the original dataset to 16 non-English languages by first translating and then manual… See the full description on the dataset page: https://huggingface.co/datasets/LLaMAX/BenchMAX_Rule-based."},
	{"name":"BenchMAX_Model-based","keyword":"chinese","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/LLaMAX/BenchMAX_Model-based","creator_name":"LLaMAX","creator_url":"https://huggingface.co/LLaMAX","description":"\\n\\t\\n\\t\\t\\n\\t\\tDataset Sources\\n\\t\\n\\n\\nPaper: BenchMAX: A Comprehensive Multilingual Evaluation Suite for Large Language Models\\nLink: https://arxiv.org/pdf/2502.07346\\nRepository: https://github.com/CONE-MT/BenchMAX\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\nBenchMAX_Model-based is a dataset of BenchMAX, sourcing from m-ArenaHard.\\nWe extend the original English dataset to 16 non-English languages by first translating and then manual post-editing.\\n\\n\\t\\n\\t\\t\\n\\t\\tSupported Languages\\n\\t\\n\\nArabic, Bengali, Chinese, Czech… See the full description on the dataset page: https://huggingface.co/datasets/LLaMAX/BenchMAX_Model-based."},
	{"name":"BenchMAX_Multiple_Functions","keyword":"chinese","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/LLaMAX/BenchMAX_Multiple_Functions","creator_name":"LLaMAX","creator_url":"https://huggingface.co/LLaMAX","description":"\\n\\t\\n\\t\\t\\n\\t\\tDataset Sources\\n\\t\\n\\n\\nPaper: BenchMAX: A Comprehensive Multilingual Evaluation Suite for Large Language Models\\nLink: https://arxiv.org/pdf/2502.07346\\nRepository: https://github.com/CONE-MT/BenchMAX\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\nBenchMAX_Multiple_Functions is a dataset of BenchMAX, sourcing from Nexus.\\nWe translate the standardized queries from English to 16 non-English languages by google Translate.\\nSome special function arguments remain English since the APIs are in English.\\nAll… See the full description on the dataset page: https://huggingface.co/datasets/LLaMAX/BenchMAX_Multiple_Functions."},
	{"name":"BenchMAX_General_Translation","keyword":"chinese","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/LLaMAX/BenchMAX_General_Translation","creator_name":"LLaMAX","creator_url":"https://huggingface.co/LLaMAX","description":"\\n\\t\\n\\t\\t\\n\\t\\tDataset Sources\\n\\t\\n\\n\\nPaper: BenchMAX: A Comprehensive Multilingual Evaluation Suite for Large Language Models\\nLink: https://arxiv.org/pdf/2502.07346\\nRepository: https://github.com/CONE-MT/BenchMAX\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\nBenchMAX_General_Translation is a dataset of BenchMAX.\\nWe collect parallel test data from Flore-200, TED-talk, and WMT24.\\n\\n\\t\\n\\t\\t\\n\\t\\tSupported Languages\\n\\t\\n\\nArabic, Bengali, Chinese, Czech, English, French, German, Hungarian, Japanese, Korean, Serbian, Spanish… See the full description on the dataset page: https://huggingface.co/datasets/LLaMAX/BenchMAX_General_Translation."},
	{"name":"BenchMAX_Domain_Translation","keyword":"chinese","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/LLaMAX/BenchMAX_Domain_Translation","creator_name":"LLaMAX","creator_url":"https://huggingface.co/LLaMAX","description":"\\n\\t\\n\\t\\t\\n\\t\\tDataset Sources\\n\\t\\n\\n\\nPaper: BenchMAX: A Comprehensive Multilingual Evaluation Suite for Large Language Models\\nLink: https://arxiv.org/pdf/2502.07346\\nRepository: https://github.com/CONE-MT/BenchMAX\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\nBenchMAX_Domain_Translation is a dataset of BenchMAX.\\nWe collect the domain parallel data from other tasks in BenchMAX.\\nEach sample contains one or three human-annotated translations.\\n\\n\\t\\n\\t\\t\\n\\t\\tSupported Languages\\n\\t\\n\\nArabic, Bengali, Chinese, Czech, English… See the full description on the dataset page: https://huggingface.co/datasets/LLaMAX/BenchMAX_Domain_Translation."},
	{"name":"nbeerbower-GreatFirewall-DPO","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Triangle104/nbeerbower-GreatFirewall-DPO","creator_name":"Lymeman","creator_url":"https://huggingface.co/Triangle104","description":"\\n\\n\\t\\n\\t\\t\\n\\t\\tGreatFirewall-DPO\\n\\t\\n\\nAn experimental dataset to discourage censorship in Chinese models.\\n\\n\\t\\n\\t\\t\\n\\t\\tStructure\\n\\t\\n\\n\\nprompt: input text presented to model (en translated to zh)\\nchosen: preferred response demonstrating less self-censorship (en translated to zh)  \\nrejected: response generated by Qwen/Qwen2.5-32B-Instruct, many exhibiting excessive self-censorship (generated in both en and zh)\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tContent\\n\\t\\n\\n\\nCHINA-related (144 prompts) - mostly about sensitive historical/political events… See the full description on the dataset page: https://huggingface.co/datasets/Triangle104/nbeerbower-GreatFirewall-DPO."},
	{"name":"TWDOCI","keyword":"chinese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/yuhuanstudio/TWDOCI","creator_name":"YuhuanStudio","creator_url":"https://huggingface.co/yuhuanstudio","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tyuhuanstudio/TWDOCI\\n\\t\\n\\n一個收錄了正體中文（繁體中文）成語典的資料集，用於大模型微調\\n(追求進步但不應該捨去歷史，中華文化不該因政治而被抹去並消亡)\\nA data set containing dictionary of traditional chinese idioms for fine-tuning LLM\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Details\\n\\t\\n\\n「台灣教育部成語典」 （Taiwan's Ministry of Education Dictionary Of Chinese Idioms，TWDOCI），\\n資料取自於台灣教育部的《成語典》\\n為了讓LLM從多方面增加對繁體中文的認識，我們利用從中提取並設計六大指令任務「成語典故、讀音問答、成語解釋、使用時機、近似詞與反義詞、使用方法」（約2.2萬筆指令）\\nThis dataset is sourced from Taiwan’s Ministry of Education’s Revised Mandarin Chinese Dictionary.\\nTo… See the full description on the dataset page: https://huggingface.co/datasets/yuhuanstudio/TWDOCI."},
	{"name":"TWDOCI","keyword":"chinese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/yuhuanstudio/TWDOCI","creator_name":"YuhuanStudio","creator_url":"https://huggingface.co/yuhuanstudio","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tyuhuanstudio/TWDOCI\\n\\t\\n\\n一個收錄了正體中文（繁體中文）成語典的資料集，用於大模型微調\\n(追求進步但不應該捨去歷史，中華文化不該因政治而被抹去並消亡)\\nA data set containing dictionary of traditional chinese idioms for fine-tuning LLM\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Details\\n\\t\\n\\n「台灣教育部成語典」 （Taiwan's Ministry of Education Dictionary Of Chinese Idioms，TWDOCI），\\n資料取自於台灣教育部的《成語典》\\n為了讓LLM從多方面增加對繁體中文的認識，我們利用從中提取並設計六大指令任務「成語典故、讀音問答、成語解釋、使用時機、近似詞與反義詞、使用方法」（約2.2萬筆指令）\\nThis dataset is sourced from Taiwan’s Ministry of Education’s Revised Mandarin Chinese Dictionary.\\nTo… See the full description on the dataset page: https://huggingface.co/datasets/yuhuanstudio/TWDOCI."},
	{"name":"common_voice_16_1_zh_TW_clean","keyword":"chinese","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/JacobLinCool/common_voice_16_1_zh_TW_clean","creator_name":"Jacob Lin","creator_url":"https://huggingface.co/JacobLinCool","description":"This dataset is derived from mozilla-foundation/common_voice_16_1, with a clean (denoised) audio column using MP-SENet. The original \\\"noisy\\\" audio is stored in the \\\"original\\\" column.\\n"},
	{"name":"common_voice_19_0_zh-TW","keyword":"chinese","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/JacobLinCool/common_voice_19_0_zh-TW","creator_name":"Jacob Lin","creator_url":"https://huggingface.co/JacobLinCool","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tCommon Voice Corpus 19.0 Chinese (Taiwan)\\n\\t\\n\\nThe test set is the same as the original test set, while validated_without_test includes all validated examples except those with sentence IDs that appear in the test set.\\n\\nvalidated_without_test has about 50,000 examples in total, equivalent to approximately 44 hours, and is intended for use as the training set.\\ntest has about 5,000 examples, which is approximately 5 hours.\\n\\n"},
	{"name":"Dataset-of-AI-Model-for-Dr_AI","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/old-cookie/Dataset-of-AI-Model-for-Dr_AI","creator_name":"oldcookie","creator_url":"https://huggingface.co/old-cookie","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Dataset Name\\n\\t\\n\\n\\n\\nThis dataset card aims to be a base template for new datasets. It has been generated using this raw template.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Details\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\n\\n\\n\\n\\n\\nCurated by: [More Information Needed]\\nFunded by [optional]: [More Information Needed]\\nShared by [optional]: [More Information Needed]\\nLanguage(s) (NLP): [More Information Needed]\\nLicense: [More Information Needed]\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Sources [optional]… See the full description on the dataset page: https://huggingface.co/datasets/old-cookie/Dataset-of-AI-Model-for-Dr_AI."},
	{"name":"save-English","keyword":"chinese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/lalala-13/save-English","creator_name":"Robert Rocky","creator_url":"https://huggingface.co/lalala-13","description":"一些初中水平的英语作文可以让训练过的AI写出一些范文.\\n"},
	{"name":"Act2Cap_benchmark","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/FRank62Wu/Act2Cap_benchmark","creator_name":"FRank Wu","creator_url":"https://huggingface.co/FRank62Wu","description":"FRank62Wu/Act2Cap_benchmark dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"toolace-parsed","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/minpeter/toolace-parsed","creator_name":"minpeter","creator_url":"https://huggingface.co/minpeter","description":"\\n\\t\\n\\t\\t\\n\\t\\t[PARSED] ToolACE\\n\\t\\n\\nThe data in this dataset is a subset of the original Team-ACE/ToolACE\\n\\n\\t\\n\\t\\t\\nSubset name\\nmulti-turn\\nparallel\\nmultiple definition\\nLast turn type\\nnumber of dataset\\n\\n\\n\\t\\t\\ntoolace\\nyes\\nyes\\nyes\\ncomplex\\n11k\\n\\n\\n\\t\\n\\nThis is a re-parsing formatting dataset for the ToolACE official dataset.\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLoad the dataset\\n\\t\\n\\nfrom datasets import load_dataset\\n\\nds = load_dataset(\\\"minpeter/toolace-parsed\\\")\\nprint(ds)\\n\\n# DatasetDict({\\n#     train: Dataset({\\n#         features:… See the full description on the dataset page: https://huggingface.co/datasets/minpeter/toolace-parsed."},
	{"name":"sina-kefu-dataset","keyword":"chinese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/a2231698193/sina-kefu-dataset","creator_name":"zhangxibin","creator_url":"https://huggingface.co/a2231698193","description":"\\n\\t\\n\\t\\t\\n\\t\\tDataset Card for Sina Customer Service Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Summary\\n\\t\\n\\n这是一个客服问答数据集，包含问题、思考过程和回答。\\n\\n\\t\\n\\t\\t\\n\\t\\tLanguages\\n\\t\\n\\n数据集使用中文（zh）。\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Structure\\n\\t\\n\\n数据集包含以下字段：\\n\\nQuestion: 用户提出的问题\\nComplex_CoT: 回答问题的思考过程\\nResponse: 最终的回答\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tData Fields\\n\\t\\n\\n\\nQuestion: string - 用户的问题\\nComplex_CoT: string - 详细的思考过程\\nResponse: string - 最终答案\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tData Splits\\n\\t\\n\\n数据集分为：\\n\\n训练集 (80%)\\n测试集 (20%)\\n\\n"},
	{"name":"Tobacco-Expert-Dataset","keyword":"chinese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Eagle51/Tobacco-Expert-Dataset","creator_name":"wuyi.yang","creator_url":"https://huggingface.co/Eagle51","description":"Eagle51/Tobacco-Expert-Dataset dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"Semiboobs","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Lunzima/Semiboobs","creator_name":"Lun Zima","creator_url":"https://huggingface.co/Lunzima","description":"\\n\\t\\n\\t\\t\\n\\t\\tMicro Dataset for LLM SFT Training\\n\\t\\n\\nThis dataset is designed for the fine-tuning of large language models (LLMs) to improve their performance in specific tasks. It contains a small amount of data that is carefully selected to optimize the model's ability to generate content related to the following areas:\\nExplanation of \\\"Semiconductor Boobs\\\": The dataset includes examples that help the model understand and generate explanations for the concept of \\\"Semiconductor Boobs\\\". This will… See the full description on the dataset page: https://huggingface.co/datasets/Lunzima/Semiboobs."},
	{"name":"V1Q","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/YuRiVeRTi/V1Q","creator_name":"YuRiVeRTical","creator_url":"https://huggingface.co/YuRiVeRTi","description":"from datasets import load_dataset\\nds = load_dataset(\\\"b3x0m/Chinese-H-Novels\\\")\\nimport sagemaker\\nimport boto3\\nfrom sagemaker.huggingface import HuggingFaceModel\\ntry:\\n    role = sagemaker.get_execution_role()\\nexcept ValueError:\\n    iam = boto3.client('iam')\\n    role = iam.get_role(RoleName='sagemaker_execution_role')['Role']['Arn']\\n\\n\\t\\n\\t\\t\\n\\t\\tHub Model configuration. https://huggingface.co/models\\n\\t\\n\\nhub = {\\n    'HF_MODEL_ID':'deepseek-ai/Janus-Pro-7B',\\n    'HF_TASK':'any-to-any'\\n}\\n\\n\\t\\n\\t\\t\\n\\t\\tcreate… See the full description on the dataset page: https://huggingface.co/datasets/YuRiVeRTi/V1Q."},
	{"name":"Chinese-DeepSeek-R1-Distill-data-Fin-2k-SFT-v2","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/herman66/Chinese-DeepSeek-R1-Distill-data-Fin-2k-SFT-v2","creator_name":"liu","creator_url":"https://huggingface.co/herman66","description":"herman66/Chinese-DeepSeek-R1-Distill-data-Fin-2k-SFT-v2 dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"Chinese-DeepSeek-R1-Distill-data-110k-opencc","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/benchang1110/Chinese-DeepSeek-R1-Distill-data-110k-opencc","creator_name":"Yu-Ying Chang","creator_url":"https://huggingface.co/benchang1110","description":"\\n\\t\\n\\t\\t\\n\\t\\t中文基於滿血DeepSeek-R1蒸餾數據集（Chinese-Data-Distill-From-R1）\\n\\t\\n\\n\\n🤗 Hugging Face   |   🤖 ModelScope    |   🚀 Github    |   📑 Blog\\n\\n\\n本資料集由 Congliu/Chinese-DeepSeek-R1-Distill-data-110k-SFT 經過 opencc 轉換而成，再次感謝原作者。  \\n注意：該版本為，可以直接SFT使用的版本，將原始數據中的思考和答案整合成output字段，大部分SFT代碼框架均可直接直接加載訓練。\\n本數據集為中文開源蒸餾滿血R1的數據集，數據集中不僅包含math數據，還包括大量的通用類型數據，總數量為110K。\\n為什麽開源這個數據？\\nR1的效果十分強大，並且基於R1蒸餾數據SFT的小模型也展現出了強大的效果，但檢索發現，大部分開源的R1蒸餾數據集均為英文數據集。 同時，R1的報告中展示，蒸餾模型中同時也使用了部分通用場景數據集。\\n為了幫助大家更好地覆現R1蒸餾模型的效果，特此開源中文數據集。… See the full description on the dataset page: https://huggingface.co/datasets/benchang1110/Chinese-DeepSeek-R1-Distill-data-110k-opencc."},
	{"name":"blossom-v6-sft-stage2","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Azure99/blossom-v6-sft-stage2","creator_name":"Azure99","creator_url":"https://huggingface.co/Azure99","description":"\\n\\t\\n\\t\\t\\n\\t\\tBLOSSOM V6 SFT STAGE2\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tIntroduction\\n\\t\\n\\nBLOSSOM V6 SFT Stage2 is a high-quality, diverse large language model fine-tuning dataset designed for the second-stage SFT training of the Blossom V6 model. Its purpose is to further enhance the model's ability to handle complex instructions on more rare real-world problems.\\nWhile open-source large language models often release model weights and technical reports, the most advanced open-source models typically withhold their… See the full description on the dataset page: https://huggingface.co/datasets/Azure99/blossom-v6-sft-stage2."},
	{"name":"Felguk-icons","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Felguk/Felguk-icons","creator_name":"Alex Felguk","creator_url":"https://huggingface.co/Felguk","description":"\\n\\t\\n\\t\\t\\n\\t\\tFelguk icons\\n\\t\\n\\nThe felguk icons They use it for me. That is, for me.\\nfollow me\\n"},
	{"name":"multilingual_translation_gen_binarized","keyword":"chinese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Youseff1987/multilingual_translation_gen_binarized","creator_name":"JOON HYOUNG JUN","creator_url":"https://huggingface.co/Youseff1987","description":"Youseff1987/multilingual_translation_gen_binarized dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"MindSpeed-Infinity-Instruct-Gen","keyword":"chinese","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/uukuguy/MindSpeed-Infinity-Instruct-Gen","creator_name":"Jiangwen Su","creator_url":"https://huggingface.co/uukuguy","description":"This dataset is built appond the Infinity Instruct project, aiming to match the multi-rounds dialogue finetune format of the MindSpeed-LLM.\\n\\n\\t\\n\\t\\t\\n\\t\\tInfinity Instruct\\n\\t\\n\\n\\n\\n\\n\\nBeijing Academy of Artificial Intelligence (BAAI)\\n[Paper][Code][🤗] (would be released soon)\\n\\n\\nThe quality and scale of instruction data are crucial for model performance. Recently, open-source models have increasingly relied on fine-tuning datasets comprising millions of instances, necessitating both high quality and large… See the full description on the dataset page: https://huggingface.co/datasets/uukuguy/MindSpeed-Infinity-Instruct-Gen."},
	{"name":"chinese-fineweb-v2-scorer-train-data","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/opencsg/chinese-fineweb-v2-scorer-train-data","creator_name":"opencsg","creator_url":"https://huggingface.co/opencsg","description":"Chinese-fineweb-v2 和 v2.1 中使用了 基于 bert 的文本打分模型，此数据集为模型的训练数据。\\n\\ntext: 被打分的文本\\nedu_eval: 由 qwen2.5-14b-instruct 产生的打分结果\\nscore: 打分结果中提取出来的得分\\n\\n"},
	{"name":"MindSpeed-Infinity-Instruct-7M","keyword":"chinese","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/uukuguy/MindSpeed-Infinity-Instruct-7M","creator_name":"Jiangwen Su","creator_url":"https://huggingface.co/uukuguy","description":"This dataset is built appond the Infinity Instruct project, aiming to match the multi-rounds dialogue finetune format of the MindSpeed-LLM.\\n\\n\\t\\n\\t\\t\\n\\t\\tInfinity Instruct\\n\\t\\n\\n\\n\\n\\n\\nBeijing Academy of Artificial Intelligence (BAAI)\\n[Paper][Code][🤗] (would be released soon)\\n\\n\\nThe quality and scale of instruction data are crucial for model performance. Recently, open-source models have increasingly relied on fine-tuning datasets comprising millions of instances, necessitating both high quality and large… See the full description on the dataset page: https://huggingface.co/datasets/uukuguy/MindSpeed-Infinity-Instruct-7M."},
	{"name":"scaleway_r1_dark_thoughts_casestudies","keyword":"chinese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Tonic/scaleway_r1_dark_thoughts_casestudies","creator_name":"Joseph [open/acc] Pollack","creator_url":"https://huggingface.co/Tonic","description":"Tonic/scaleway_r1_dark_thoughts_casestudies dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"scaleway_r1_dark_thoughts_casestudies","keyword":"chinese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Tonic/scaleway_r1_dark_thoughts_casestudies","creator_name":"Joseph [open/acc] Pollack","creator_url":"https://huggingface.co/Tonic","description":"Tonic/scaleway_r1_dark_thoughts_casestudies dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"dianping-classification","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/zm-hf/dianping-classification","creator_name":"赵明","creator_url":"https://huggingface.co/zm-hf","description":"zm-hf/dianping-classification dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"SpeechInstructBench","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ddwang2000/SpeechInstructBench","creator_name":"ElaineWang","creator_url":"https://huggingface.co/ddwang2000","description":"\\n\\t\\n\\t\\t\\n\\t\\tSpeechInstructBench\\n\\t\\n\\nArxiv: https://arxiv.org/abs/2503.02769\\nThis is the SpeechInstructBench dataset download page.  \\nSpeechInstructBench encompasses three dimensions: closed-ended instruction, open-ended instruction, adjustment instruction.\\nFor how to run SpeechInstructBench, Please refer to SpeechInstructBench github page (will be public soon).\\n"},
	{"name":"OpenSubtitles-en-zh-cn-20m","keyword":"chinese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/FradSer/OpenSubtitles-en-zh-cn-20m","creator_name":"Frad LEE","creator_url":"https://huggingface.co/FradSer","description":"\\n\\t\\n\\t\\t\\n\\t\\tDataset Card for OpenSubtitles English-Chinese 20M Parallel Corpus\\n\\t\\n\\nThis dataset contains English-Chinese parallel subtitles from OpenSubtitles, specifically the English to Simplified Chinese (zh-CN) language pair. The data is sourced from the OpenSubtitles v2024 collection available at OPUS.\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Details\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThis is a collection of parallel movie subtitles in English and Chinese, extracted from OpenSubtitles.org. The dataset features improved… See the full description on the dataset page: https://huggingface.co/datasets/FradSer/OpenSubtitles-en-zh-cn-20m."},
	{"name":"gsm8k-translated","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Sara237/gsm8k-translated","creator_name":"Sara Rajaee","creator_url":"https://huggingface.co/Sara237","description":"Sara237/gsm8k-translated dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"ruozhiba_r1_512","keyword":"chinese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/lenML/ruozhiba_r1_512","creator_name":"len","creator_url":"https://huggingface.co/lenML","description":"\\n\\t\\n\\t\\t\\n\\t\\t弱智吧 r1 512 数据集\\n\\t\\n\\n\\n此数据集来源于弱智吧收集题目，初步筛选去除一小部分劣质问题（看起来不像问题的标题）\\n通过调用 deepseek r1 作答，收集了 think 和回答\\n限制思考使用 token 数，接近或小于 512 token （限制的原因是，本数据集我只用于冷启动阶段），回答 token 没限制\\n可能会有一定的多样性，因为模型回答来源于多个供应商端点，某些供应商可能是提供量化版本的r1\\n\\n\\n\\t\\n\\t\\t\\n\\t\\t引用\\n\\t\\n\\n\\nquestion 出处：https://docs.qq.com/sheet/DUlZ6aURhamdwb1RO?tab=BB08J2\\n感谢 COIG-CQIA 项目的思路： https://huggingface.co/datasets/m-a-p/COIG-CQIA\\n\\n"},
	{"name":"Emilia-YODAS","keyword":"chinese","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mrfakename/Emilia-YODAS","creator_name":"mrfakename","creator_url":"https://huggingface.co/mrfakename","description":"A mirror of the Emilia-YODAS dataset. Only includes the YODAS subset from the original dataset.\\nhttps://huggingface.co/datasets/amphion/Emilia-Dataset\\n"},
	{"name":"squares-hs","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/squares1/squares-hs","creator_name":"squares","creator_url":"https://huggingface.co/squares1","description":"squares1/squares-hs dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"fishmt5","keyword":"chinese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/MHBS-IHB/fishmt5","creator_name":"Museum of Hydrobiological Sciences, Institute of Hydrobiology, Chinese Academy of Sciences","creator_url":"https://huggingface.co/MHBS-IHB","description":"\\n\\t\\n\\t\\t\\n\\t\\tFish Names Chinese-Latin Parallel Corpora\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Overview\\n\\t\\n\\nWe curated over 60,000 authoritative Chinese-Latin bilingual parallel corpora for fish names by integrating cross-source data, including Eschmeyer's Catalog of Fishes online database. Using a dual translation approach, we applied the Multilingual Text-to-Text Transfer Transformer (mT5) model to generate missing Chinese names.\\nNote: The current release provides 10,000 paired data entries.\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Details… See the full description on the dataset page: https://huggingface.co/datasets/MHBS-IHB/fishmt5."},
	{"name":"HPLT2.0_cleaned","keyword":"chinese","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/jobs-git/HPLT2.0_cleaned","creator_name":"James Guana","creator_url":"https://huggingface.co/jobs-git","description":"This is a large-scale collection of web-crawled documents in 191 world languages, produced by the HPLT project. \\nThe source of the data is mostly Internet Archive with some additions from Common Crawl.\\nFor a detailed description of the dataset, please refer to https://hplt-project.org/datasets/v2.0\\nThe Cleaned variant of HPLT Datasets v2.0\\nThis is the cleaned variant of the HPLT Datasets v2.0 converted to the Parquet format semi-automatically when being uploaded here. \\nThe original JSONL files… See the full description on the dataset page: https://huggingface.co/datasets/jobs-git/HPLT2.0_cleaned."},
	{"name":"Tobacco-Expert-Dataset2","keyword":"chinese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Eagle51/Tobacco-Expert-Dataset2","creator_name":"wuyi.yang","creator_url":"https://huggingface.co/Eagle51","description":"Eagle51/Tobacco-Expert-Dataset2 dataset hosted on Hugging Face and contributed by the HF Datasets community"}
]
;
