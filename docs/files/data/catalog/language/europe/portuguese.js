const data_for_language_europe_portuguese = 
[
	{"name":"spider-test-portuguese","keyword":"portuguese","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Boakpe/spider-test-portuguese","creator_name":"Breno","creator_url":"https://huggingface.co/Boakpe","description":"\n\t\n\t\t\n\t\tSpider Dataset - Vers√£o em Portugu√™s\n\t\n\nEste reposit√≥rio cont√©m a tradu√ß√£o para portugu√™s da parti√ß√£o de teste do dataset Spider, um benchmark para a tarefa de Text-to-SQL.\n\n\t\n\t\t\n\t\tSobre esta tradu√ß√£o\n\t\n\nA tradu√ß√£o da parti√ß√£o \"test\" do Spider (contendo 2.147 inst√¢ncias) foi realizada seguindo um processo rigoroso:\n\nTradu√ß√£o inicial: Utilizando a API do GPT-4o mini da OpenAI\nRevis√£o manual: Todas as 2.147 quest√µes foram revisadas e validadas manualmente\nCrit√©rios de tradu√ß√£o:‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Boakpe/spider-test-portuguese.","first_N":5,"first_N_keywords":["Portuguese","cc-by-sa-4.0","1K<n<10K","arxiv:1809.08887","üá∫üá∏ Region: US"],"keywords_longer_than_N":true},
	{"name":"spider-test-portuguese","keyword":"portuguese","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Boakpe/spider-test-portuguese","creator_name":"Breno","creator_url":"https://huggingface.co/Boakpe","description":"\n\t\n\t\t\n\t\tSpider Dataset - Vers√£o em Portugu√™s\n\t\n\nEste reposit√≥rio cont√©m a tradu√ß√£o para portugu√™s da parti√ß√£o de teste do dataset Spider, um benchmark para a tarefa de Text-to-SQL.\n\n\t\n\t\t\n\t\tSobre esta tradu√ß√£o\n\t\n\nA tradu√ß√£o da parti√ß√£o \"test\" do Spider (contendo 2.147 inst√¢ncias) foi realizada seguindo um processo rigoroso:\n\nTradu√ß√£o inicial: Utilizando a API do GPT-4o mini da OpenAI\nRevis√£o manual: Todas as 2.147 quest√µes foram revisadas e validadas manualmente\nCrit√©rios de tradu√ß√£o:‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Boakpe/spider-test-portuguese.","first_N":5,"first_N_keywords":["Portuguese","cc-by-sa-4.0","1K<n<10K","arxiv:1809.08887","üá∫üá∏ Region: US"],"keywords_longer_than_N":true},
	{"name":"BRIGHTER-emotion-categories","keyword":"portuguese","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/brighter-dataset/BRIGHTER-emotion-categories","creator_name":"BRIGHTER Dataset","creator_url":"https://huggingface.co/brighter-dataset","description":"\n\t\n\t\t\n\t\tBRIGHTER Emotion Categories Dataset\n\t\n\nThis dataset contains the emotion categories data from the BRIGHTER paper: BRIdging the Gap in Human-Annotated Textual Emotion Recognition Datasets for 28 Languages.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe BRIGHTER Emotion Categories dataset is a comprehensive multi-language, multi-label emotion classification dataset with separate configurations for each language. It represents one of the largest human-annotated emotion datasets across multiple‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/brighter-dataset/BRIGHTER-emotion-categories.","first_N":5,"first_N_keywords":["Afrikaans","Arabic","German","English","Spanish"],"keywords_longer_than_N":true},
	{"name":"BRIGHTER-emotion-intensities","keyword":"portuguese","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/brighter-dataset/BRIGHTER-emotion-intensities","creator_name":"BRIGHTER Dataset","creator_url":"https://huggingface.co/brighter-dataset","description":"\n\t\n\t\t\n\t\tBRIGHTER Emotion Intensities Dataset\n\t\n\nThis dataset contains the emotion intensities data from the BRIGHTER paper: BRIdging the Gap in Human-Annotated Textual Emotion Recognition Datasets for 28 Languages.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe BRIGHTER Emotion Intensities dataset is a comprehensive multi-language emotion intensity dataset with separate configurations for each language. It represents one of the largest human-annotated emotion datasets across multiple languages, providing‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/brighter-dataset/BRIGHTER-emotion-intensities.","first_N":5,"first_N_keywords":["Arabic","German","English","Spanish","Hausa"],"keywords_longer_than_N":true},
	{"name":"semeval-2025-task11-track-a","keyword":"portuguese","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/vgaraujov/semeval-2025-task11-track-a","creator_name":"Vladimir Araujo","creator_url":"https://huggingface.co/vgaraujov","description":"\n\t\n\t\t\n\t\tSemEval 2025 Task 11 - Track A Dataset\n\t\n\nThis dataset contains the data for SemEval 2025 Task 11: Bridging the Gap in Text-Based Emotion Detection - Track A, organized as language-specific configurations.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset is a multi-language, multi-label emotion classification dataset with separate configurations for each language.\n\nTotal languages: 26 standard ISO codes\nTotal examples: 115159\nSplits: train, dev, test\n\n\n\t\n\t\t\n\t\tLanguage Configurations\n\t\n\nEach‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/vgaraujov/semeval-2025-task11-track-a.","first_N":5,"first_N_keywords":["Afrikaans","Amharic","Arabic","German","English"],"keywords_longer_than_N":true},
	{"name":"semeval-2025-task11-track-c","keyword":"portuguese","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/vgaraujov/semeval-2025-task11-track-c","creator_name":"Vladimir Araujo","creator_url":"https://huggingface.co/vgaraujov","description":"\n\t\n\t\t\n\t\tSemEval 2025 Task 11 - Track C Dataset\n\t\n\nThis dataset contains the data for SemEval 2025 Task 11: Bridging the Gap in Text-Based Emotion Detection - Track C, organized as language-specific configurations.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset is a multi-language, multi-label emotion classification dataset with separate configurations for each language.\n\nTotal languages: 30 standard ISO codes\nTotal examples: 57254\nSplits: dev, test (Track C has no train split)\n\n\n\t\n\t\t\n\t\tTrack‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/vgaraujov/semeval-2025-task11-track-c.","first_N":5,"first_N_keywords":["Afrikaans","Amharic","Arabic","German","English"],"keywords_longer_than_N":true},
	{"name":"cgu__notas_fiscais","keyword":"portuguese","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/fredguth/cgu__notas_fiscais","creator_name":"Fred Guth","creator_url":"https://huggingface.co/fredguth","description":"\n\t\n\t\t\n\t\tDataset Card: cgu_notas_fiscais\n\t\n\nData from electronic invoices for federal government purchases made available by\nComptroller General of the Union (Controladoria-Geral da Uni√£o), which is a\nBrazilian federal government agency responsible for oversight and transparency.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\n\n\n\nCurated by: Fred Guth (@fredguth)\nFunded by: World Bank\nLanguage(s) (NLP): pt-br\nLicense: CC-BY 4.0\n\n\n\t\n\t\t\n\t\tDataset Sources\n\t\n\nThe source of this datasets‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/fredguth/cgu__notas_fiscais.","first_N":5,"first_N_keywords":["tabular-classification","Portuguese","cc-by-4.0","10M - 100M","parquet"],"keywords_longer_than_N":true},
	{"name":"PromptSearchTermsDecomposition","keyword":"portuguese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/cnmoro/PromptSearchTermsDecomposition","creator_name":"Carlo Moro","creator_url":"https://huggingface.co/cnmoro","description":"cnmoro/PromptSearchTermsDecomposition dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["text-classification","Portuguese","apache-2.0","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"KairosNews","keyword":"portuguese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/0edon/KairosNews","creator_name":"Quintino Fernandes","creator_url":"https://huggingface.co/0edon","description":"Handcrafted Dataset used in the elaboration of a thesis and a project for a competition (Premio Arquivo.pt: https://sobre.arquivo.pt/pt/colabore/premios-arquivo-pt/premio-arquivo-pt-2025/)\nIt contains news articles from the following Portuguese News agencies from 2020 to 2024:\nhttps://www.cmjornal.pt/ = 6771\nhttps://expresso.pt/ = 22606\nhttps://www.iol.pt/ = 39387\nhttps://www.publico.pt/ = 74893\nhttps://www.sapo.pt/ = 57838\nTOTAL = 201495\nEach news article contains it's url, title, text‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/0edon/KairosNews.","first_N":5,"first_N_keywords":["summarization","text-classification","token-classification","Portuguese","mit"],"keywords_longer_than_N":true},
	{"name":"reasoning-v1-20m-portuguese","keyword":"portuguese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/cnmoro/reasoning-v1-20m-portuguese","creator_name":"Carlo Moro","creator_url":"https://huggingface.co/cnmoro","description":"glaiveai/reasoning-v1-20m translated to portuguese.\n","first_N":5,"first_N_keywords":["text-generation","Portuguese","apache-2.0","10M - 100M","parquet"],"keywords_longer_than_N":true},
	{"name":"saude-coletiva","keyword":"portuguese","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/feliperafael/saude-coletiva","creator_name":"Felipe Rafael de Souza","creator_url":"https://huggingface.co/feliperafael","description":"\n\t\n\t\t\n\t\tDataset de Sa√∫de Coletiva\n\t\n\nEste dataset cont√©m informa√ß√µes sobre sa√∫de p√∫blica no Brasil, incluindo dados de mortalidade, interna√ß√µes hospitalares e indicadores de sa√∫de.\n\n\t\n\t\t\n\t\tConte√∫do do Dataset\n\t\n\nO dataset cont√©m os seguintes arquivos:\n\nsih_2000_2024.csv - Sistema de Informa√ß√µes Hospitalares (SIH) contendo dados de interna√ß√µes hospitalares de 2000 a 2024\nsim_limpo_e_alterado.csv - Sistema de Informa√ß√µes sobre Mortalidade (SIM) processado\nsim_95_columns_versao_final.csv - Vers√£o‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/feliperafael/saude-coletiva.","first_N":5,"first_N_keywords":["Portuguese","cc-by-4.0","üá∫üá∏ Region: US","health","brazil"],"keywords_longer_than_N":true},
	{"name":"negated_carolina","keyword":"portuguese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/hapaxlegomenon/negated_carolina","creator_name":"Matheus Westhelle","creator_url":"https://huggingface.co/hapaxlegomenon","description":"\n\t\n\t\t\n\t\tNotCarolina\n\t\n\nThis dataset contains examples of negation in Portuguese across multiple domains.\nIt is derived from the Carolina Corpus, which we segment into sentences and filter for common negation words in Portuguese.\n","first_N":5,"first_N_keywords":["Portuguese","apache-2.0","1M - 10M","parquet","Text"],"keywords_longer_than_N":true},
	{"name":"subset-Itau-Unibanco-aroeira-1B-tokens","keyword":"portuguese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/bobboyms/subset-Itau-Unibanco-aroeira-1B-tokens","creator_name":"Thiago Luiz Rodrigues","creator_url":"https://huggingface.co/bobboyms","description":"\n\t\n\t\t\n\t\tSubset Corpus Itau-Unibanco/aroeira: 1B tokens (portuguese PT-BR)\n\t\n\nSubset Corpus Itau-Unibanco/aroeira: 1B tokens (portuguese PT-BR)\nsubset-Itau-Unibanco-aroeira-1B-tokens \n","first_N":5,"first_N_keywords":["text-generation","Portuguese","apache-2.0","1M - 10M","parquet"],"keywords_longer_than_N":true},
	{"name":"MediumSetPT","keyword":"portuguese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/AxeML/MediumSetPT","creator_name":"Ax√©ML - Community","creator_url":"https://huggingface.co/AxeML","description":"\n  \n\n\n\n\t\n\t\t\n\t\tüìö Dataset de Perguntas e Respostas por T√≥pico\n\t\n\nEste reposit√≥rio cont√©m um dataset com 40.000 amostras estruturadas para tarefas de Processamento de Linguagem Natural (PLN), com foco em perguntas tem√°ticas e respostas desenvolvidas.\n\n\t\n\t\t\n\t\tüìÅ Estrutura dos Dados\n\t\n\nCada amostra √© representada em formato JSON com os seguintes campos:\n\nid (string): Identificador √∫nico da amostra (UUID).\ntopic (lista de strings): Lista com os t√≥picos abordados.\nprompts (lista de strings):‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/AxeML/MediumSetPT.","first_N":5,"first_N_keywords":["text-generation","Portuguese","mit","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"fakerecogna2-extrativa","keyword":"portuguese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/recogna-nlp/fakerecogna2-extrativa","creator_name":"Recogna NLP","creator_url":"https://huggingface.co/recogna-nlp","description":"\n\t\n\t\t\n\t\tFakeRecogna 2.0 Extractive\n\t\n\nFakeRecogna 2.0 presents the extension for the FakeRecogna dataset in the context of fake news detection. FakeRecogna includes real and fake news texts collected from online media and ten fact-checking sources in Brazil. An important aspect is the lack of relation between the real and fake news samples, i.e., they are not mutually related to each other to avoid intrinsic bias in the data.\n\n\t\n\t\t\n\t\tThe Dataset\n\t\n\nThe fake news collection was performed on‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/recogna-nlp/fakerecogna2-extrativa.","first_N":5,"first_N_keywords":["text-classification","Portuguese","mit","10K - 100K","csv"],"keywords_longer_than_N":true},
	{"name":"fakerecogna2-extrativa","keyword":"portuguese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/recogna-nlp/fakerecogna2-extrativa","creator_name":"Recogna NLP","creator_url":"https://huggingface.co/recogna-nlp","description":"\n\t\n\t\t\n\t\tFakeRecogna 2.0 Extractive\n\t\n\nFakeRecogna 2.0 presents the extension for the FakeRecogna dataset in the context of fake news detection. FakeRecogna includes real and fake news texts collected from online media and ten fact-checking sources in Brazil. An important aspect is the lack of relation between the real and fake news samples, i.e., they are not mutually related to each other to avoid intrinsic bias in the data.\n\n\t\n\t\t\n\t\tThe Dataset\n\t\n\nThe fake news collection was performed on‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/recogna-nlp/fakerecogna2-extrativa.","first_N":5,"first_N_keywords":["text-classification","Portuguese","mit","10K - 100K","csv"],"keywords_longer_than_N":true},
	{"name":"ericksonian-terminology-multilingual","keyword":"portuguese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/LoneWolfgang/ericksonian-terminology-multilingual","creator_name":"Jordan Wolfgang Klein","creator_url":"https://huggingface.co/LoneWolfgang","description":"\n\t\n\t\t\n\t\tMultilingual Glossary of Ericksonian Terminology\n\t\n\nThis dataset was created to evaluate the performance of a multilingual sentence encoder adapted to Ericksonian terminology.\nThe International Glossary of Ericksonian Terminology was developed to promote consistent language use among Ericksonian practitioners worldwide.\nEach entry in the glossary reflects the consensus of three native-speaking translators who also study Ericksonian methodology.\nLanguage Teams:\n\nEnglish: Roxanna‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/LoneWolfgang/ericksonian-terminology-multilingual.","first_N":5,"first_N_keywords":["translation","English","Spanish","Portuguese","French"],"keywords_longer_than_N":true},
	{"name":"sage-voice-pt-br","keyword":"portuguese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/srxz/sage-voice-pt-br","creator_name":"RC","creator_url":"https://huggingface.co/srxz","description":"Dataset usado para treinar a voz da Sage (Valorant)\nGera√ß√£o do metadata.csv:\nRodar: whisper.sh em seguida transcrib.sh, isso produzira um txt com todas falas pronto para ser utilizado no treinamento com piper\n\n\n\t\n\t\t\n\t\tlicense: mit\n\t\n\n","first_N":5,"first_N_keywords":["Portuguese","mit","< 1K","parquet","Audio"],"keywords_longer_than_N":true},
	{"name":"Sentiments-FinBERT-PT-BR","keyword":"portuguese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/lucas-leme/Sentiments-FinBERT-PT-BR","creator_name":"Lucas Leme Santos","creator_url":"https://huggingface.co/lucas-leme","description":"\n\t\n\t\t\n\t\tDataset\n\t\n\nA manually annotated dataset was created to enable supervised training for the FinBERT-PT-BR model, which focuses on sentiment analysis of Brazilian Portuguese financial texts.\nMore than 1.4 million financial news texts in Portuguese were collected and used for the initial language modeling phase. From this corpus, a sample of 1,000 texts was manually annotated with sentiment labels.\n\n\t\n\t\t\n\t\tAnnotation Process\n\t\n\nThree annotators participated in the process.\nAll texts were‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/lucas-leme/Sentiments-FinBERT-PT-BR.","first_N":5,"first_N_keywords":["Portuguese","apache-2.0","< 1K","csv","Text"],"keywords_longer_than_N":true},
	{"name":"toxicity-multilingual-binary-classification-dataset","keyword":"portuguese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/malexandersalazar/toxicity-multilingual-binary-classification-dataset","creator_name":"Alexander Salazar","creator_url":"https://huggingface.co/malexandersalazar","description":"This dataset is a comprehensive collection designed to aid in the development of robust and nuanced models for identifying toxic language across multiple languages, while critically distinguishing it from expressions related to mental health, specifically depression. It synthesizes content from three existing public datasets (ToxiGen, TextDetox, and Mental Health - Depression) with a newly generated synthetic dataset (ToxiLLaMA). The creation process involved careful collection, extensive‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/malexandersalazar/toxicity-multilingual-binary-classification-dataset.","first_N":5,"first_N_keywords":["English","German","French","Italian","Portuguese"],"keywords_longer_than_N":true},
	{"name":"multihal","keyword":"portuguese","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/AnonymousSubmission9090/multihal","creator_name":"Anonymous","creator_url":"https://huggingface.co/AnonymousSubmission9090","description":"\n\t\n\t\t\n\t\tDataset Card for MultiHal\n\t\n\nBenchmark (test-only) intended for generative-form question answering grounded on knowledge graphs. \nMultiHal contains approximately 7k unique questions and 25.9k unique KG paths, some questions contain multiple candidate paths.\nThe benchmark is designed to support research for factual language modeling with a focus on providing a test bed for LLM hallucination evaluation and\nLLM knowledge updating based on KG paths in multilingual setting.\n\n\t\n\t\t\n\t\n\t\n\t\tUses‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/AnonymousSubmission9090/multihal.","first_N":5,"first_N_keywords":["question-answering","English","Spanish","French","Portuguese"],"keywords_longer_than_N":true},
	{"name":"TinyDS-20k","keyword":"portuguese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Hamzah-Asadullah/TinyDS-20k","creator_name":"Hamzah Asadullah","creator_url":"https://huggingface.co/Hamzah-Asadullah","description":"\n\t\n\t\t\n\t\tTinyDS\n\t\n\n\n\n\nAlpaca-style dataset with around 20k samples scraped from Qwen3-8B using SyntheticAlpaca. Q&A pairs can be in 32 different languages, these are listed in the metadata.Topics are all around STEM, programming, and literature.  \nMIT @ 2025 Hamzah Asadullah\n\n\n","first_N":5,"first_N_keywords":["question-answering","translation","text-generation","English","Chinese"],"keywords_longer_than_N":true},
	{"name":"Political-BRSD","keyword":"portuguese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/cerqueiramatheus/Political-BRSD","creator_name":"Matheus Cerqueira","creator_url":"https://huggingface.co/cerqueiramatheus","description":"cerqueiramatheus/Political-BRSD dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["text-classification","Portuguese","mit","10K - 100K","csv"],"keywords_longer_than_N":true},
	{"name":"multiblimp","keyword":"portuguese","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/jumelet/multiblimp","creator_name":"Jaap Jumelet","creator_url":"https://huggingface.co/jumelet","description":"\n\t\n\t\t\n\t\tMultiBLiMP\n\t\n\nMultiBLiMP is a massively Multilingual Benchmark for Linguistic Minimal Pairs. The dataset is composed of synthetic pairs generated using Universal Dependencies and UniMorph.\nThe paper can be found here.\nWe split the data set by language: each language consists of a single .tsv file. The rows contain many attributes for a particular pair, most important are the sen and wrong_sen fields, which we use for evaluating the language models.\n\n\t\n\t\t\n\t\n\t\n\t\tUsing MultiBLiMP\n\t\n\nTo‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/jumelet/multiblimp.","first_N":5,"first_N_keywords":["multilingual","Buriat","Spanish","Sanskrit","Romanian"],"keywords_longer_than_N":true},
	{"name":"JBB-Behaviors-pt","keyword":"portuguese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/tech4humans/JBB-Behaviors-pt","creator_name":"Tech4Humans","creator_url":"https://huggingface.co/tech4humans","description":"\n\t\n\t\t\n\t\tJBB-Behaviors-pt\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nJBB-Behaviors-pt is a dataset of behaviors in Portuguese, including both jailbreak prompts and safe behaviors. The dataset is intended for behavioral testing of language models to evaluate their robustness against jailbreak attempts in Portuguese.\n\n\t\n\t\t\n\t\tWhat is a jailbreak?\n\t\n\nJailbreak prompts are inputs designed to bypass a language model's safety guardrails, potentially causing it to generate harmful, unethical, or otherwise‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/tech4humans/JBB-Behaviors-pt.","first_N":5,"first_N_keywords":["text-classification","Portuguese","mit","< 1K","csv"],"keywords_longer_than_N":true},
	{"name":"multivsr","keyword":"portuguese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/sindhuhegde/multivsr","creator_name":"Sindhu Hegde","creator_url":"https://huggingface.co/sindhuhegde","description":"\n\t\n\t\t\n\t\tDataset: MultiVSR\n\t\n\nWe introduce a large-scale multilingual lip-reading dataset: MultiVSR. The dataset comprises a total of 12,000 hours of video footage, covering English + 12 non-English languages. MultiVSR is a massive dataset with a huge diversity in terms of the speakers as well as languages, with approximately 1.6M video clips across 123K YouTube videos. Please check the website for samples.\n\n  \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDownload instructions\n\t\n\nPlease check the GitHub repo to download‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/sindhuhegde/multivsr.","first_N":5,"first_N_keywords":["English","French","German","Spanish","Italian"],"keywords_longer_than_N":true},
	{"name":"PORTO","keyword":"portuguese","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/LIACC/PORTO","creator_name":"LIACC","creator_url":"https://huggingface.co/LIACC","description":"\n\t\n\t\t\n\t\tPost-OCR Resources for Text Optimisation\n\t\n\nResource for evaluation and develop OCRs and Post-OCR focused on historical Portuguese.\nHow to load the dataset:\nfrom datasets import load_dataset\n\ndataset = load_dataset(\"LIACC/PORTO\")\n\n","first_N":5,"first_N_keywords":["image-to-text","fill-mask","text-generation","Portuguese","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"Guilherme34_uncensor_portuguese","keyword":"portuguese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/BornSaint/Guilherme34_uncensor_portuguese","creator_name":"R√≥ger Santos","creator_url":"https://huggingface.co/BornSaint","description":"Bad translation of huihui-ai/Guilherme34_uncensor\nThis dataset needs to be filtered, because it was made using ArgosTranslate\n","first_N":5,"first_N_keywords":["Portuguese","apache-2.0","< 1K","parquet","Text"],"keywords_longer_than_N":true},
	{"name":"common_voice_21_0","keyword":"portuguese","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/2Jyq/common_voice_21_0","creator_name":"2Jyq","creator_url":"https://huggingface.co/2Jyq","description":"Due to storage limits some files had to be split into multiple parts. They can be merged like this: cat file.* > file.\n","first_N":5,"first_N_keywords":["crowdsourced","crowdsourced","multilingual","extended|common_voice","Abkhaz"],"keywords_longer_than_N":true},
	{"name":"IFEval-mt-pt","keyword":"portuguese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carminho/IFEval-mt-pt","creator_name":"Carminho Lab","creator_url":"https://huggingface.co/carminho","description":"carminho/IFEval-mt-pt dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["text-generation","Portuguese","apache-2.0","< 1K","json"],"keywords_longer_than_N":true},
	{"name":"morphscore","keyword":"portuguese","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/catherinearnett/morphscore","creator_name":"Catherine Arnett","creator_url":"https://huggingface.co/catherinearnett","description":"\n\t\n\t\t\n\t\tMorphScore\n\t\n\nMorphScore is a tokenizer evaluation framework, which evaluates the extent to which a tokenizer segments words along morpheme boundaries. This repository contains the datasets used to calculate MorphScore.\nIn total, we have datasetes for 86 languages, but only 70 languages have at least 100 items after filtering. \nAll datasets are derived from existing Universal Dependencies treebanks. In the table below, we link the source dataset for each language. \nSee the new preprint‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/catherinearnett/morphscore.","first_N":5,"first_N_keywords":["Arabic","English","German","Russian","Turkish"],"keywords_longer_than_N":true},
	{"name":"youtube-commons-small","keyword":"portuguese","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/dm-petrov/youtube-commons-small","creator_name":"Dmitry Petrov","creator_url":"https://huggingface.co/dm-petrov","description":"\n\t\n\t\t\n\t\tüì∫ YouTube-Commons-Small üì∫\n\t\n\nThis is a smaller subset of the YouTube-Commons dataset, which is a collection of audio transcripts from videos shared on YouTube under a CC-By license.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis smaller version contains a subset of the original dataset, maintaining the same structure and features. It's designed for easier experimentation and testing purposes.\n\n\t\n\t\t\n\t\tFeatures\n\t\n\nThe dataset includes the following information for each video:\n\nVideo ID and link‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/dm-petrov/youtube-commons-small.","first_N":5,"first_N_keywords":["text-generation","English","French","Spanish","Portuguese"],"keywords_longer_than_N":true},
	{"name":"ACL-SRW-2025","keyword":"portuguese","license":"GNU General Public License v3.0","license_url":"https://choosealicense.com/licenses/gpl-3.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Translated-MMLU-Blind-Review/ACL-SRW-2025","creator_name":"Translated MMLU Blind Review","creator_url":"https://huggingface.co/Translated-MMLU-Blind-Review","description":"\n\t\n\t\t\n\t\tDataset Components\n\t\n\nThe dataset is partitioned into three discrete tables stored in CSV or Parquet format:\n\nQuestions\nRecipes\nEvaluation Results\n\nEach component is described in detail below.\n\n\n\t\n\t\t\n\t\tQuestions\n\t\n\n\narea\n\ndomain\n\nquestion_number\nAn integer index uniquely identifying each question inside the knowledge domain.\n\ntranslation_method\nEnglish, Google Translate, GPT-3.5-Turbo, GPT-4o, Human\n\nquestion\n\noption_a, option_b, option_c, option_d\n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tRecipes\n\t\n\n\narea‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Translated-MMLU-Blind-Review/ACL-SRW-2025.","first_N":5,"first_N_keywords":["question-answering","zero-shot-classification","text-generation","English","Portuguese"],"keywords_longer_than_N":true},
	{"name":"multihal","keyword":"portuguese","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ernlavr/multihal","creator_name":"Ernests Lavrinovics","creator_url":"https://huggingface.co/ernlavr","description":"\n\t\n\t\t\n\t\tDataset Card for MultiHal\n\t\n\nBenchmark (test-only) intended for generative-form question answering grounded on knowledge graphs. \nMultiHal contains approximately 7k unique questions and 25.9k unique KG paths, some questions contain multiple candidate paths.\nThe benchmark is designed to support research for factual language modeling with a focus on providing a test bed for LLM hallucination evaluation and\nLLM knowledge updating based on KG paths in multilingual setting. See the paper‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ernlavr/multihal.","first_N":5,"first_N_keywords":["question-answering","English","Spanish","French","Portuguese"],"keywords_longer_than_N":true},
	{"name":"AfriSentiClassification","keyword":"portuguese","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/AfriSentiClassification","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  AfriSentiClassification\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nAfriSenti is the largest sentiment analysis dataset for under-represented African languages.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2c\n\n\nDomains\nSocial, Written\n\n\nReferencehttps://arxiv.org/abs/2302.08956\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask = mteb.get_tasks([\"AfriSentiClassification\"])\nevaluator = mteb.MTEB(task)\n\nmodel‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/AfriSentiClassification.","first_N":5,"first_N_keywords":["text-classification","sentiment-analysis","sentiment-scoring","sentiment-classification","hate-speech-detection"],"keywords_longer_than_N":true},
	{"name":"ibge-cidades","keyword":"portuguese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Saint-Clair/ibge-cidades","creator_name":"Lima","creator_url":"https://huggingface.co/Saint-Clair","description":"\n\t\n\t\t\n\t\tibge-cidades\n\t\n\nDados dos munic√≠pios no Portal Cidades@ recuperados da API do IBGE\n\n\t\n\t\t\n\t\tFonte\n\t\n\nOs dados em quest√£o s√£o disponibilizados pelo IBGE no Portal Cidades@ (https://cidades.ibge.gov.br/brasil/panorama). Os dados foram coletados por chamadas √† API em 21-22 de maio de 2025.\n\n\t\n\t\t\n\t\tDados no dataset\n\t\n\nO dataset cont√©m dados de 5.565 localidades no Brasil (Cidades, Povoados, Vilarejos, etc.) coletados pelo IBGE, organizados por ano.\nNo total, s√£o 40 indicadores que t√™m seus‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Saint-Clair/ibge-cidades.","first_N":5,"first_N_keywords":["tabular-classification","tabular-regression","no-annotation","found","monolingual"],"keywords_longer_than_N":true},
	{"name":"Discord-Unveiled-Compressed","keyword":"portuguese","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/SaisExperiments/Discord-Unveiled-Compressed","creator_name":"Sai","creator_url":"https://huggingface.co/SaisExperiments","description":"\n\n.hf-sanitized.hf-sanitized-j1_tz_W_VRFLnAn8gnmpk .container { --bg-primary: #0d0511; --bg-secondary: #1a0f1f; --bg-tertiary: #2d1b35; --bg-card: #3d2847; --text-primary: #fef7ff; --text-secondary: #f0d9ff; --text-muted: #c084fc; --pink-soft: #fce7f3; --pink-medium: #f9a8d4; --pink-bright: #ec4899; --pink-hot: #e91e63; --pink-neon: #ff1493; --purple-soft: #e879f9; --purple-bright: #c026d3; --purple-deep: #7c3aed; --border-glow: #f472b6; --shadow-pink: rgba(244, 114, 182, 0.4);‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/SaisExperiments/Discord-Unveiled-Compressed.","first_N":5,"first_N_keywords":["English","Spanish","French","Portuguese","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"MAPS","keyword":"portuguese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Fujitsu-FRE/MAPS","creator_name":"Fujitsu Research of Europe","creator_url":"https://huggingface.co/Fujitsu-FRE","description":"\n\t\n\t\t\n\t\tDataset Card for Multilingual Benchmark for Global Agent Performance and Security\n\t\n\nThis is the first Multilingual Agentic AI Benchmark for evaluating agentic AI systems across different languages and diverse tasks. Benchmark enables systematic analysis of how agents perform under multilingual conditions. To balance performance and safety evaluation, our benchmark comprises 805 tasks: 405 from performance-oriented datasets (GAIA, SWE-bench, MATH) and 400 from the Agent Security‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Fujitsu-FRE/MAPS.","first_N":5,"first_N_keywords":["text-generation","question-answering","Arabic","English","Japanese"],"keywords_longer_than_N":true},
	{"name":"sib200_14classes","keyword":"portuguese","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Davlan/sib200_14classes","creator_name":"David Adelani","creator_url":"https://huggingface.co/Davlan","description":"\n\t\n\t\t\n\t\tDataset Card for SIB-200\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nSIB-200 is the largest publicly available topic classification dataset based on Flores-200 covering 205 languages and dialects.\nThe train/validation/test sets are available for all the 205 languages.\nThis is another version with 14 classes, more idea for few-shot evaluation, it has 5 examples for few-shot, and larger test set (1225)\n\n\t\n\t\t\n\t\tSupported Tasks and Leaderboards\n\t\n\n\ntopic classification: categorize wikipedia sentences‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Davlan/sib200_14classes.","first_N":5,"first_N_keywords":["text-classification","topic-classification","found","expert-generated","multilingual"],"keywords_longer_than_N":true},
	{"name":"Lemonade","keyword":"portuguese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/stanford-oval/Lemonade","creator_name":"Stanford Open Virtual Assistant Lab (OVAL)","creator_url":"https://huggingface.co/stanford-oval","description":"LEMONADE is a large, expert-annotated dataset for event extraction from news articles in 20 languages: English, Spanish, Arabic, French, Italian, Russian, German, Turkish, Burmese, Indonesian, Ukrainian, Korean, Portuguese, Dutch, Somali, Nepali, Chinese, Persian, Hebrew, and Japanese.\nSee https://github.com/stanford-oval/Lemonade for details.\n","first_N":5,"first_N_keywords":["text-classification","English","Spanish","Arabic","French"],"keywords_longer_than_N":true},
	{"name":"community-alignment-dataset","keyword":"portuguese","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/facebook/community-alignment-dataset","creator_name":"AI at Meta","creator_url":"https://huggingface.co/facebook","description":"\nCommunity Alignment\n\n\n Github ¬† | ¬†\n Paper\n\n\n\n\t\n\t\t\n\t\tDataset\n\t\n\nCommunity Alignment is a large-scale open source, multilingual and multi-turn preference dataset to align LLMs with human preferences across cultures. It features prompt-level overlap in annotators, enabling social-choice-based and distributional approaches to LLM alignment, as well as natural language explanations for choices.\n\n[Large-scale] ~200,000 comparisons of LLM responses, collected from >3,000 unique annotators who‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/facebook/community-alignment-dataset.","first_N":5,"first_N_keywords":["Hindi","English","Portuguese","Italian","French"],"keywords_longer_than_N":true},
	{"name":"oasst1","keyword":"portuguese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/OpenAssistant/oasst1","creator_name":"OpenAssistant","creator_url":"https://huggingface.co/OpenAssistant","description":"\n\t\n\t\t\n\t\tOpenAssistant Conversations Dataset (OASST1)\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nIn an effort to democratize research on large-scale alignment, we release OpenAssistant \nConversations (OASST1), a human-generated, human-annotated assistant-style conversation \ncorpus consisting of 161,443 messages in 35 different languages, annotated with 461,292 \nquality ratings, resulting in over 10,000 fully annotated conversation trees. The corpus \nis a product of a worldwide crowd-sourcing effort‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/OpenAssistant/oasst1.","first_N":5,"first_N_keywords":["English","Spanish","Russian","German","Polish"],"keywords_longer_than_N":true},
	{"name":"wikipedia-monthly","keyword":"portuguese","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/omarkamali/wikipedia-monthly","creator_name":"Omar Kamali","creator_url":"https://huggingface.co/omarkamali","description":"\n\t\n\t\t\n\t\tüöÄ Wikipedia Monthly\n\t\n\nLast updated: July 16, 2025, 22:53 UTC\nThis repository provides monthly, multilingual dumps of Wikipedia, processed and prepared for easy use in NLP projects.\nNOTE: The first run is still in progress and languages are still being processed and uploaded.\n\n\n\t\n\t\t\n\t\tüìä Live Statistics\n\t\n\n\n\t\n\t\t\nMetric\nValue\n\n\n\t\t\nüåç Languages Available\n341\n\n\nüìÑ Total Articles\n64.5M\n\n\nüíæ Total Size\n205.54 GB\n\n\n\t\n\n\n\n\t\n\t\t\n\t\tWhy Use This Dataset?\n\t\n\n\nFreshness: We run our pipeline monthly‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/omarkamali/wikipedia-monthly.","first_N":5,"first_N_keywords":["Abkhaz","Achinese","Adyghe","Afrikaans","Akan"],"keywords_longer_than_N":true},
	{"name":"oasst2","keyword":"portuguese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/OpenAssistant/oasst2","creator_name":"OpenAssistant","creator_url":"https://huggingface.co/OpenAssistant","description":"\n\t\n\t\t\n\t\tOpen Assistant Conversations Dataset Release 2 (OASST2)\n\t\n\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nThis dataset contains message trees. Each message tree has an initial prompt message as the root node, \nwhich can have multiple child messages as replies, and these child messages can have multiple replies. \nAll messages have a role property: this can either be \"assistant\" or \"prompter\". The roles in \nconversation threads from prompt to leaf node strictly alternate between \"prompter\" and‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/OpenAssistant/oasst2.","first_N":5,"first_N_keywords":["English","Spanish","Russian","German","Polish"],"keywords_longer_than_N":true},
	{"name":"HPLT2.0_cleaned","keyword":"portuguese","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/HPLT/HPLT2.0_cleaned","creator_name":"HPLT","creator_url":"https://huggingface.co/HPLT","description":"This is a large-scale collection of web-crawled documents in 191 world languages, produced by the HPLT project. \nThe source of the data is mostly Internet Archive with some additions from Common Crawl.\nFor a detailed description of the dataset, please refer to our website and our pre-print.\n\n\t\n\t\t\n\t\n\t\n\t\tThe Cleaned variant of HPLT Datasets v2.0\n\t\n\nThis is the cleaned variant of the HPLT Datasets v2.0 converted to the Parquet format semi-automatically when being uploaded here. \nThe original‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/HPLT/HPLT2.0_cleaned.","first_N":5,"first_N_keywords":["fill-mask","text-generation","language-modeling","multilingual","Achinese"],"keywords_longer_than_N":true},
	{"name":"Global-MMLU","keyword":"portuguese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/CohereLabs/Global-MMLU","creator_name":"Cohere Labs","creator_url":"https://huggingface.co/CohereLabs","description":"\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nGlobal-MMLU üåç is a multilingual evaluation set spanning 42 languages, including English. This dataset combines machine translations for MMLU questions along with professional translations and crowd-sourced post-edits.\nIt also includes cultural sensitivity annotations for a subset of the questions (2850 questions per language) and classifies them as Culturally Sensitive (CS) üóΩ or Culturally Agnostic (CA) ‚öñÔ∏è. These annotations were collected as part of an open‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/CohereLabs/Global-MMLU.","first_N":5,"first_N_keywords":["English","Arabic","Bengali","Spanish","French"],"keywords_longer_than_N":true},
	{"name":"xtreme","keyword":"portuguese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/google/xtreme","creator_name":"Google","creator_url":"https://huggingface.co/google","description":"\n\t\n\t\t\n\t\tDataset Card for \"xtreme\"\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThe Cross-lingual Natural Language Inference (XNLI) corpus is a crowd-sourced collection of 5,000 test and\n2,500 dev pairs for the MultiNLI corpus. The pairs are annotated with textual entailment and translated into\n14 languages: French, Spanish, German, Greek, Bulgarian, Russian, Turkish, Arabic, Vietnamese, Thai, Chinese,\nHindi, Swahili and Urdu. This results in 112.5k annotated pairs. Each premise can be associated with the‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/google/xtreme.","first_N":5,"first_N_keywords":["multiple-choice","question-answering","token-classification","text-classification","text-retrieval"],"keywords_longer_than_N":true},
	{"name":"multilingual_librispeech","keyword":"portuguese","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/facebook/multilingual_librispeech","creator_name":"AI at Meta","creator_url":"https://huggingface.co/facebook","description":"\n\t\n\t\t\n\t\tDataset Card for MultiLingual LibriSpeech\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis is a streamable version of the Multilingual LibriSpeech (MLS) dataset. \nThe data archives were restructured from the original ones from OpenSLR to make it easier to stream.\nMLS dataset is a large multilingual corpus suitable for speech research. The dataset is derived from read audiobooks from LibriVox and consists of \n8 languages - English, German, Dutch, Spanish, French, Italian, Portuguese, Polish. It‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/facebook/multilingual_librispeech.","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","text-to-audio","expert-generated","crowdsourced"],"keywords_longer_than_N":true},
	{"name":"b2w-reviews01","keyword":"portuguese","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ruanchaves/b2w-reviews01","creator_name":"Ruan Chaves Rodrigues","creator_url":"https://huggingface.co/ruanchaves","description":"B2W-Reviews01 is an open corpus of product reviews. It contains more than 130k e-commerce customer reviews, collected from the Americanas.com website between January and May, 2018. B2W-Reviews01 offers rich information about the reviewer profile, such as gender, age, and geographical location. The corpus also has two different review rates","first_N":5,"first_N_keywords":["text-classification","sentiment-analysis","sentiment-scoring","intent-classification","topic-classification"],"keywords_longer_than_N":true},
	{"name":"multilingual-tts","keyword":"portuguese","license":"GNU General Public License v3.0","license_url":"https://choosealicense.com/licenses/gpl-3.0/","language":"en","dataset_url":"https://huggingface.co/datasets/MohamedRashad/multilingual-tts","creator_name":"Mohamed Rashad","creator_url":"https://huggingface.co/MohamedRashad","description":"\n\t\n\t\t\n\t\tBefore Anything and Everything ‚ö±\n\t\n\nIn the time of writing this Dataset Card, 17,490 18,412 civilian has been killed in Palestine (7,870 8,000 are children and 6,121 6,200 are women).\nSeek any non-profit organization to help them with what you can (For myself, I use Mersal) üáµüá∏\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Description\n\t\n\nThe Multilingual TTS dataset is an exceptional compilation of text-to-speech (TTS) samples, meticulously crafted to showcase the richness and diversity of human languages.‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/MohamedRashad/multilingual-tts.","first_N":5,"first_N_keywords":["text-to-speech","Arabic","English","Chinese","Spanish"],"keywords_longer_than_N":true},
	{"name":"aya_collection","keyword":"portuguese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/CohereLabs/aya_collection","creator_name":"Cohere Labs","creator_url":"https://huggingface.co/CohereLabs","description":"\nThis dataset is uploaded in two places: here and additionally here as 'Aya Collection Language Split.' These datasets are identical in content but differ in structure of upload. This dataset is structured by folders split according to dataset name. The version here instead divides the Aya collection into folders split by language. We recommend you use the language split version if you are only interested in downloading data for a single or smaller set of languages, and this version if you‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/CohereLabs/aya_collection.","first_N":5,"first_N_keywords":["text-classification","summarization","translation","Achinese","Afrikaans"],"keywords_longer_than_N":true},
	{"name":"aya_evaluation_suite","keyword":"portuguese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/CohereLabs/aya_evaluation_suite","creator_name":"Cohere Labs","creator_url":"https://huggingface.co/CohereLabs","description":"\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nAya Evaluation Suite contains a total of 26,750 open-ended conversation-style prompts to evaluate multilingual open-ended generation quality.To strike a balance between language coverage and the quality that comes with human curation, we create an evaluation suite that includes:\n\nhuman-curated examples in 7 languages (tur, eng, yor, arb, zho, por, tel) ‚Üí aya-human-annotated.\nmachine-translations of handpicked examples into 101 languages ‚Üí dolly-machine-translated.‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/CohereLabs/aya_evaluation_suite.","first_N":5,"first_N_keywords":["text-generation","crowdsourced","expert-generated","machine-generated","multilingual"],"keywords_longer_than_N":true},
	{"name":"mmarco-hard-negatives-reranker-score","keyword":"portuguese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/hotchpotch/mmarco-hard-negatives-reranker-score","creator_name":"Yuichi Tateno","creator_url":"https://huggingface.co/hotchpotch","description":"\nhotchpotch/mmarco-hard-negatives-reranker-score\n\nThis repository contains data from mMARCO scored using the reranker BAAI/bge-reranker-v2-m3.\n\n\t\n\t\t\n\t\tLanguages Covered\n\t\n\ntarget_languages = [\n    \"english\",\n    \"chinese\", \n    \"french\",\n    \"german\",\n    \"indonesian\",\n    \"italian\",\n    \"portuguese\",\n    \"russian\",\n    \"spanish\",\n    \"arabic\",\n    \"dutch\",\n    \"hindi\",\n    \"japanese\",\n    \"vietnamese\"\n]\n\n\n\t\n\t\t\n\t\tHard Negative Data\n\t\n\nThe hard negative data is derived from‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/hotchpotch/mmarco-hard-negatives-reranker-score.","first_N":5,"first_N_keywords":["English","Chinese","French","German","Indonesian"],"keywords_longer_than_N":true},
	{"name":"MMMLU","keyword":"portuguese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/openai/MMMLU","creator_name":"OpenAI","creator_url":"https://huggingface.co/openai","description":"\n\t\n\t\t\n\t\tMultilingual Massive Multitask Language Understanding (MMMLU)\n\t\n\nThe MMLU is a widely recognized benchmark of general knowledge attained by AI models. It covers a broad range of topics from 57 different categories, covering elementary-level knowledge up to advanced professional subjects like law, physics, history, and computer science.\nWe translated the MMLU‚Äôs test set into 14 languages using professional human translators. Relying on human translators for this evaluation increases‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/openai/MMMLU.","first_N":5,"first_N_keywords":["question-answering","Arabic","Bengali","German","Spanish"],"keywords_longer_than_N":true},
	{"name":"degeneration-html-multilingual","keyword":"portuguese","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Degeneration-Nation/degeneration-html-multilingual","creator_name":"The Degeneration of the Nation","creator_url":"https://huggingface.co/Degeneration-Nation","description":"\n\t\n\t\t\n\t\tThe Degeneration of the Nation Multilingual Dataset\n\t\n\n\nThis dataset contains the complete content of The Degeneration of the Nation project, a comprehensive philosophical and cultural website exploring the intersection of technology, artificial intelligence, and human culture. The content includes philosophical essays, cultural analysis, and contemporary literature, with complex parallel structure and sophisticated HTML architecture across all language versions.\n\n\t\n\t\t\n\t\n\t\n\t\tProject‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Degeneration-Nation/degeneration-html-multilingual.","first_N":5,"first_N_keywords":["translation","text-generation","text-classification","token-classification","sentence-similarity"],"keywords_longer_than_N":true},
	{"name":"wmt24pp","keyword":"portuguese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/google/wmt24pp","creator_name":"Google","creator_url":"https://huggingface.co/google","description":"\n\t\n\t\t\n\t\tWMT24++\n\t\n\nThis repository contains the human translation and post-edit data for the 55 en->xx language pairs released in\nthe publication\nWMT24++: Expanding the Language Coverage of WMT24 to 55 Languages & Dialects.\nIf you are interested in the MT/LLM system outputs and automatic metric scores, please see MTME.\nIf you are interested in the images of the source URLs for each document, please see here.\n\n\t\n\t\t\n\t\n\t\n\t\tSchema\n\t\n\nEach language pair is stored in its own jsonl file.\nEach row is‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/google/wmt24pp.","first_N":5,"first_N_keywords":["translation","Arabic","Bulgarian","Bengali","Catalan"],"keywords_longer_than_N":true},
	{"name":"xl-instruct","keyword":"portuguese","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/remorax98/xl-instruct","creator_name":"Vivek Iyer","creator_url":"https://huggingface.co/remorax98","description":"\n\t\n\t\t\n\t\tDataset Card for XL-Instruct\n\t\n\nThis dataset card provides a summary of the XL-Instruct dataset, a resource for advancing the cross-lingual capabilities of Large Language Models. It was introduced in the paper XL-Instruct: Synthetic Data for Cross-Lingual Open-Ended Generation.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nXL-Instruct is a high-quality, large-scale synthetic dataset designed to fine-tune LLMs for cross-lingual open-ended generation. The core task involves‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/remorax98/xl-instruct.","first_N":5,"first_N_keywords":["text-generation","Hindi","Chinese","German","Portuguese"],"keywords_longer_than_N":true},
	{"name":"vox-communis-parallel-g2p","keyword":"portuguese","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/fdemelo/vox-communis-parallel-g2p","creator_name":"Fl√°vio Eler De Melo","creator_url":"https://huggingface.co/fdemelo","description":"\n\t\n\t\t\n\t\tVoxCommunis Parallel G2P dataset\n\t\n\nThis dataset was derived from the VoxCommunis Corpus to provide pairs of utterances along with their\ncorresponding phonemes, side by side, as to ease the training of grapheme-to-phoneme (G2P) models.\nThe original VoxCommunis Corpus features force-aligned TextGrids with phone- and word-level segmentations derived from the Mozilla Common Voice Corpus.\nThe lexicons were developed using Epitran, the XPF Corpus, Charsiu, and some custom dictionaries.‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/fdemelo/vox-communis-parallel-g2p.","first_N":5,"first_N_keywords":["Abkhaz","Amharic","Bashkir","Belarusian","Bulgarian"],"keywords_longer_than_N":true},
	{"name":"bnl_newspapers","keyword":"portuguese","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/bnl-data/bnl_newspapers","creator_name":"BnL Open Data","creator_url":"https://huggingface.co/bnl-data","description":"\n\t\n\t\t\n\t\tDataset Card for BnL Historical Newspapers\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThe BnL has digitised over 800.000 pages of Luxembourg newspapers. This dataset currently has one configuration covering a subset of these newspapers, which sit under the \"Processed Datasets\" collection. The BNL:\n\nprocessed all newspapers and monographs that are in the public domain and extracted the full text and associated meta data of every single article, section, advertisement‚Ä¶ The result is a large number of‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/bnl-data/bnl_newspapers.","first_N":5,"first_N_keywords":["text-generation","fill-mask","language-modeling","masked-language-modeling","no-annotation"],"keywords_longer_than_N":true},
	{"name":"conceptnet5","keyword":"portuguese","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/conceptnet5/conceptnet5","creator_name":"conceptnet5","creator_url":"https://huggingface.co/conceptnet5","description":"\n\t\n\t\t\n\t\tDataset Card for Conceptnet5\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nConceptNet is a multilingual knowledge base, representing words and\nphrases that people use and the common-sense relationships between\nthem. The knowledge in ConceptNet is collected from a variety of\nresources, including crowd-sourced resources (such as Wiktionary and\nOpen Mind Common Sense), games with a purpose (such as Verbosity and\nnadya.jp), and expert-created resources (such as WordNet and JMDict).\nYou can browse what‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/conceptnet5/conceptnet5.","first_N":5,"first_N_keywords":["text-classification","multi-class-classification","crowdsourced","crowdsourced","found"],"keywords_longer_than_N":true},
	{"name":"europa_eac_tm","keyword":"portuguese","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/community-datasets/europa_eac_tm","creator_name":"Community Datasets","creator_url":"https://huggingface.co/community-datasets","description":"\n\t\n\t\t\n\t\tDataset Card for Europa Education and Culture Translation Memory (EAC-TM)\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset is a corpus of manually produced translations from english to up to 25 languages, released in 2012 by the European Union's Directorate General for Education and Culture (EAC).\nTo load a language pair that is not part of the config, just specify the language code as language pair. For example, if you want to translate Czech to Greek:\ndataset = load_dataset(\"europa_eac_tm\"‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/community-datasets/europa_eac_tm.","first_N":5,"first_N_keywords":["translation","expert-generated","expert-generated","translation","original"],"keywords_longer_than_N":true},
	{"name":"europa_ecdc_tm","keyword":"portuguese","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/community-datasets/europa_ecdc_tm","creator_name":"Community Datasets","creator_url":"https://huggingface.co/community-datasets","description":"\n\t\n\t\t\n\t\tDataset Card for [Dataset Name]\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nIn October 2012, the European Union (EU) agency 'European Centre for Disease Prevention and Control' (ECDC) released a translation memory (TM), i.e. a collection of sentences and their professionally produced translations, in twenty-five languages.\nECDC-TM covers 25 languages: the 23 official languages of the EU plus Norwegian (Norsk) and Icelandic. ECDC-TM was created by translating from English into the following 24‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/community-datasets/europa_ecdc_tm.","first_N":5,"first_N_keywords":["translation","expert-generated","expert-generated","translation","original"],"keywords_longer_than_N":true},
	{"name":"exams","keyword":"portuguese","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mhardalov/exams","creator_name":"Momchil Hardalov","creator_url":"https://huggingface.co/mhardalov","description":"\n\t\n\t\t\n\t\tDataset Card for [Dataset Name]\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nEXAMS is a benchmark dataset for multilingual and cross-lingual question answering from high school examinations. It consists of more than 24,000 high-quality high school exam questions in 16 languages, covering 8 language families and 24 school subjects from Natural Sciences and Social Sciences, among others.\n\n\t\n\t\t\n\t\tSupported Tasks and Leaderboards\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nThe languages in the‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mhardalov/exams.","first_N":5,"first_N_keywords":["question-answering","multiple-choice-qa","found","found","monolingual"],"keywords_longer_than_N":true},
	{"name":"opus_paracrawl","keyword":"portuguese","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Helsinki-NLP/opus_paracrawl","creator_name":"Language Technology Research Group at the University of Helsinki","creator_url":"https://huggingface.co/Helsinki-NLP","description":"\n\t\n\t\t\n\t\tDataset Card for OpusParaCrawl\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nParallel corpora from Web Crawls collected in the ParaCrawl project.\nTha dataset contains:\n\n42 languages, 43 bitexts\ntotal number of files: 59,996\ntotal number of tokens: 56.11G\ntotal number of sentence fragments: 3.13G\n\nTo load a language pair which isn't part of the config, all you need to do is specify the language code as pairs,\ne.g.\ndataset = load_dataset(\"opus_paracrawl\", lang1=\"en\", lang2=\"so\")\n\nYou can find the valid‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Helsinki-NLP/opus_paracrawl.","first_N":5,"first_N_keywords":["translation","found","found","multilingual","original"],"keywords_longer_than_N":true},
	{"name":"opus_ubuntu","keyword":"portuguese","license":"BSD 3-Clause \"New\" or \"Revised\" License","license_url":"https://choosealicense.com/licenses/bsd-3-clause/","language":"en","dataset_url":"https://huggingface.co/datasets/Helsinki-NLP/opus_ubuntu","creator_name":"Language Technology Research Group at the University of Helsinki","creator_url":"https://huggingface.co/Helsinki-NLP","description":"\n\t\n\t\t\n\t\tDataset Card for Opus Ubuntu\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThese are translations of the Ubuntu software package messages, donated by the Ubuntu community.\nTo load a language pair which isn't part of the config, all you need to do is specify the language code as pairs.\nYou can find the valid pairs in Homepage section of Dataset Description: http://opus.nlpl.eu/Ubuntu.php\nE.g.\ndataset = load_dataset(\"opus_ubuntu\", lang1=\"it\", lang2=\"pl\")\n\n\t\n\t\t\n\t\n\t\n\t\tSupported Tasks and Leaderboards‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Helsinki-NLP/opus_ubuntu.","first_N":5,"first_N_keywords":["translation","crowdsourced","expert-generated","found","multilingual"],"keywords_longer_than_N":true},
	{"name":"squad_v1_pt","keyword":"portuguese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/nunorc/squad_v1_pt","creator_name":"Nuno Ramos Carvalho","creator_url":"https://huggingface.co/nunorc","description":"\n\t\n\t\t\n\t\tDataset Card for \"squad_v1_pt\"\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nPortuguese translation of the SQuAD dataset. The translation was performed automatically using the Google Cloud API.\n\n\t\n\t\t\n\t\tSupported Tasks and Leaderboards\n\t\n\nMore Information Needed\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nMore Information Needed\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\n\t\n\t\t\n\t\tData Instances\n\t\n\n\n\t\n\t\t\n\t\tdefault\n\t\n\n\nSize of downloaded dataset files: 39.53 MB\nSize of the generated dataset: 96.72 MB\nTotal amount of disk used: 136.25 MB\n\nAn‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/nunorc/squad_v1_pt.","first_N":5,"first_N_keywords":["question-answering","extractive-qa","open-domain-qa","crowdsourced","crowdsourced"],"keywords_longer_than_N":true},
	{"name":"xcsr","keyword":"portuguese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/INK-USC/xcsr","creator_name":"INK Lab @ USC","creator_url":"https://huggingface.co/INK-USC","description":"\n\t\n\t\t\n\t\tDataset Card for X-CSR\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nTo evaluate multi-lingual language models (ML-LMs) for commonsense reasoning in a cross-lingual zero-shot transfer setting (X-CSR), i.e., training in English and test in other languages, we create two benchmark datasets, namely X-CSQA and X-CODAH. Specifically, we automatically translate the original CSQA and CODAH datasets, which only have English versions, to 15 other languages, forming development and test sets for studying X-CSR.‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/INK-USC/xcsr.","first_N":5,"first_N_keywords":["question-answering","multiple-choice-qa","crowdsourced","crowdsourced","machine-generated"],"keywords_longer_than_N":true},
	{"name":"mfaq","keyword":"portuguese","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/clips/mfaq","creator_name":"CLiPS","creator_url":"https://huggingface.co/clips","description":"We present the first multilingual FAQ dataset publicly available. We collected around 6M FAQ pairs from the web, in 21 different languages.","first_N":5,"first_N_keywords":["question-answering","multiple-choice-qa","no-annotation","other","multilingual"],"keywords_longer_than_N":true},
	{"name":"mqa","keyword":"portuguese","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/clips/mqa","creator_name":"CLiPS","creator_url":"https://huggingface.co/clips","description":"MQA is a multilingual corpus of questions and answers parsed from the Common Crawl. Questions are divided between Frequently Asked Questions (FAQ) pages and Community Question Answering (CQA) pages.","first_N":5,"first_N_keywords":["question-answering","multiple-choice-qa","no-annotation","other","multilingual"],"keywords_longer_than_N":true},
	{"name":"flores_101","keyword":"portuguese","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/gsarti/flores_101","creator_name":"Gabriele Sarti","creator_url":"https://huggingface.co/gsarti","description":"One of the biggest challenges hindering progress in low-resource and multilingual machine translation is the \nlack of good evaluation benchmarks. Current evaluation benchmarks either lack good coverage of low-resource \nlanguages, consider only restricted domains, or are low quality because they are constructed using \nsemi-automatic procedures. In this work, we introduce the FLORES evaluation benchmark, consisting of 3001 \nsentences extracted from English Wikipedia and covering a variety of different topics and domains. \nThese sentences have been translated in 101 languages by professional translators through a carefully \ncontrolled process. The resulting dataset enables better assessment of model quality on the long tail of \nlow-resource languages, including the evaluation of many-to-many multilingual translation systems, as all \ntranslations are multilingually aligned. By publicly releasing such a high-quality and high-coverage dataset, \nwe hope to foster progress in the machine translation community and beyond.","first_N":5,"first_N_keywords":["text-generation","translation","found","expert-generated","multilingual"],"keywords_longer_than_N":true},
	{"name":"oscar-small","keyword":"portuguese","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/nthngdy/oscar-small","creator_name":"Nathan Godey","creator_url":"https://huggingface.co/nthngdy","description":"The Open Super-large Crawled ALMAnaCH coRpus is a huge multilingual corpus obtained by language classification and filtering of the Common Crawl corpus using the goclassy architecture.\\","first_N":5,"first_N_keywords":["text-generation","language-modeling","no-annotation","found","multilingual"],"keywords_longer_than_N":true},
	{"name":"xlel_wd_dictionary","keyword":"portuguese","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/adithya7/xlel_wd_dictionary","creator_name":"Adithya Pratapa","creator_url":"https://huggingface.co/adithya7","description":"XLEL-WD is a multilingual event linking dataset. This sub-dataset contains a dictionary of events from Wikidata. The multilingual descriptions for Wikidata event items are taken from the corresponding Wikipedia articles.","first_N":5,"first_N_keywords":["found","found","multilingual","original","Afrikaans"],"keywords_longer_than_N":true},
	{"name":"xlel_wd","keyword":"portuguese","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/adithya7/xlel_wd","creator_name":"Adithya Pratapa","creator_url":"https://huggingface.co/adithya7","description":"XLEL-WD is a multilingual event linking dataset. This dataset contains mention references from multilingual Wikipedia/Wikinews articles to event items in Wikidata. The text descriptions for Wikidata events are compiled from Wikipedia articles.","first_N":5,"first_N_keywords":["found","found","multilingual","original","Afrikaans"],"keywords_longer_than_N":true},
	{"name":"wit_base","keyword":"portuguese","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/wikimedia/wit_base","creator_name":"Wikimedia","creator_url":"https://huggingface.co/wikimedia","description":"\n\t\n\t\t\n\t\tDataset Card for WIT\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nWikimedia's version of the Wikipedia-based Image Text (WIT) Dataset, a large multimodal multilingual dataset.\nFrom the official blog post:\n\nThe core training data is taken from the Wikipedia Image-Text (WIT) Dataset, a large curated set of more than 37 million image-text associations extracted from Wikipedia articles in 108 languages that was recently released by Google Research.\nThe WIT dataset offers extremely valuable data about the‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/wikimedia/wit_base.","first_N":5,"first_N_keywords":["image-to-text","text-retrieval","image-captioning","machine-generated","found"],"keywords_longer_than_N":true},
	{"name":"amazon_massive_scenario","keyword":"portuguese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/amazon_massive_scenario","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  MassiveScenarioClassification\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nMASSIVE: A 1M-Example Multilingual Natural Language Understanding Dataset with 51 Typologically-Diverse Languages\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2c\n\n\nDomains\nSpoken\n\nReference\nhttps://arxiv.org/abs/2204.08582\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask = mteb.get_tasks([\"MassiveScenarioClassification\"])\nevaluator =‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/amazon_massive_scenario.","first_N":5,"first_N_keywords":["text-classification","human-annotated","translated","Afrikaans","Amharic"],"keywords_longer_than_N":true},
	{"name":"amazon_massive_intent","keyword":"portuguese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/amazon_massive_intent","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  MassiveIntentClassification\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nMASSIVE: A 1M-Example Multilingual Natural Language Understanding Dataset with 51 Typologically-Diverse Languages\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2c\n\n\nDomains\nSpoken\n\n\nReference\nhttps://arxiv.org/abs/2204.08582\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask = mteb.get_tasks([\"MassiveIntentClassification\"])\nevaluator =‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/amazon_massive_intent.","first_N":5,"first_N_keywords":["text-classification","human-annotated","translated","Afrikaans","Amharic"],"keywords_longer_than_N":true},
	{"name":"askD","keyword":"portuguese","license":"GNU Lesser General Public License v3.0","license_url":"https://choosealicense.com/licenses/lgpl-3.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ju-resplande/askD","creator_name":"Juliana Resplande","creator_url":"https://huggingface.co/ju-resplande","description":"\\\r\n#TODO: description","first_N":5,"first_N_keywords":["abstractive-qa","closed-domain-qa","no-annotation","found","machine-generated"],"keywords_longer_than_N":true},
	{"name":"hatecheck-portuguese","keyword":"portuguese","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Paul/hatecheck-portuguese","creator_name":"Paul R√∂ttger","creator_url":"https://huggingface.co/Paul","description":"\n\t\n\t\t\n\t\tDataset Card for Multilingual HateCheck\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nMultilingual HateCheck (MHC) is a suite of functional tests for hate speech detection models in 10 different languages: Arabic, Dutch, French, German, Hindi, Italian, Mandarin, Polish, Portuguese and Spanish.\nFor each language, there are 25+ functional tests that correspond to distinct types of hate and challenging non-hate.\nThis allows for targeted diagnostic insights into model performance.\nFor more details‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Paul/hatecheck-portuguese.","first_N":5,"first_N_keywords":["text-classification","hate-speech-detection","crowdsourced","expert-generated","monolingual"],"keywords_longer_than_N":true},
	{"name":"translation-en-pt","keyword":"portuguese","license":"Academic Free License v3.0","license_url":"https://choosealicense.com/licenses/afl-3.0/","language":"en","dataset_url":"https://huggingface.co/datasets/VanessaSchenkel/translation-en-pt","creator_name":"Vanessa Schramm Schenkel Da Silva","creator_url":"https://huggingface.co/VanessaSchenkel","description":"How to use it: \nfrom datasets import load_dataset\n\nremote_dataset = load_dataset(\"VanessaSchenkel/translation-en-pt\", field=\"data\")\n\nremote_dataset\n\nOutput:\nDatasetDict({\n    train: Dataset({\n        features: ['id', 'translation'],\n        num_rows: 260482\n    })\n})\n\nExemple: \nremote_dataset[\"train\"][5]\n\nOutput:\n{'id': '5',\n 'translation': {'english': 'I have to go to sleep.',\n  'portuguese': 'Tenho de dormir.'}}\n\n","first_N":5,"first_N_keywords":["translation","found","found","translation","original"],"keywords_longer_than_N":true},
	{"name":"xwinograd","keyword":"portuguese","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Muennighoff/xwinograd","creator_name":"Niklas Muennighoff","creator_url":"https://huggingface.co/Muennighoff","description":"\n\t\n\t\t\n\t\tXWinograd\n\t\n\nMultilingual winograd schema challenge as used in Crosslingual Generalization through Multitask Finetuning.\n\n\t\n\t\t\n\t\tLanguages & Samples\n\t\n\n\n\"en\": 2325\n\"fr\": 83\n\"jp\": 959\n\"pt\": 263 \n\"ru\": 315\n\"zh\": 504\n\n\n\t\n\t\t\n\t\tDataset creation\n\t\n\nThe Winograd schema challenges in this dataset combine winograd schemas from the XWinograd dataset introduced in Tikhonov et al and as it only contains 16 Chinese schemas, we add 488 Chinese schemas from clue/cluewsc2020.\nIf you only want the‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Muennighoff/xwinograd.","first_N":5,"first_N_keywords":["English","French","Japanese","Portuguese","Russian"],"keywords_longer_than_N":true},
	{"name":"mapa","keyword":"portuguese","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/joelniklaus/mapa","creator_name":"Joel Niklaus","creator_url":"https://huggingface.co/joelniklaus","description":"\n\t\n\t\t\n\t\tDataset Card for Multilingual European Datasets for Sensitive Entity Detection in the Legal Domain\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThe dataset consists of 12 documents (9 for Spanish due to parsing errors) taken from EUR-Lex, a multilingual corpus of court\ndecisions and legal dispositions in the 24 official languages of the European Union. The documents have been annotated\nfor named entities following the guidelines of the MAPA project which foresees two\nannotation level, a general and a‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/joelniklaus/mapa.","first_N":5,"first_N_keywords":["token-classification","named-entity-recognition","other","found","multilingual"],"keywords_longer_than_N":true},
	{"name":"NERDE","keyword":"portuguese","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Gpaiva/NERDE","creator_name":"Guilherme Pereira Paiva","creator_url":"https://huggingface.co/Gpaiva","description":"(pt) NERDE √© um dataset para NER a partir de documentos jur√≠dicos da defesa econ√¥mica em portugu√™s do Brasil, foi criado em colabora√ß√£o com o Cade e o laborat√≥rio LATITUDE/UnB.\n(en) NERDE is a NER dataset from economic defense legal documents in Brazilian Portuguese, created in collaboration with Cade and the LATITUDE/UnB laboratory.","first_N":5,"first_N_keywords":["token-classification","named-entity-recognition","expert-generated","expert-generated","monolingual"],"keywords_longer_than_N":true},
	{"name":"xP3all","keyword":"portuguese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/bigscience/xP3all","creator_name":"BigScience Workshop","creator_url":"https://huggingface.co/bigscience","description":"xP3 (Crosslingual Public Pool of Prompts) is a collection of prompts & datasets across 46 of languages & 16 NLP tasks. It is used for the training of BLOOMZ and mT0, multilingual language models capable of following human instructions in dozens of languages zero-shot.","first_N":5,"first_N_keywords":["other","expert-generated","crowdsourced","multilingual","Akan"],"keywords_longer_than_N":true},
	{"name":"lextreme","keyword":"portuguese","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/joelniklaus/lextreme","creator_name":"Joel Niklaus","creator_url":"https://huggingface.co/joelniklaus","description":"The LEXTREME Benchmark is a collection of multilingual datasets for evaluating model performance \nacross a diverse set of legal NLU tasks.","first_N":5,"first_N_keywords":["text-classification","token-classification","multi-class-classification","multi-label-classification","topic-classification"],"keywords_longer_than_N":true},
	{"name":"handmade-dataset","keyword":"portuguese","license":"Academic Free License v3.0","license_url":"https://choosealicense.com/licenses/afl-3.0/","language":"en","dataset_url":"https://huggingface.co/datasets/VanessaSchenkel/handmade-dataset","creator_name":"Vanessa Schramm Schenkel Da Silva","creator_url":"https://huggingface.co/VanessaSchenkel","description":"Dataset with sentences regarding professions, half of the translations are to feminine and half for masculine sentences.\nHow to use it: \nfrom datasets import load_dataset\nremote_dataset = load_dataset(\"VanessaSchenkel/handmade-dataset\", field=\"data\")\nremote_dataset\n\nOutput:\nDatasetDict({\n    train: Dataset({\n        features: ['id', 'translation'],\n        num_rows: 388\n    })\n})\n\nExemple: \nremote_dataset[\"train\"][5]\n\nOutput:\n{'id': '5',\n 'translation': {'english': 'the postman finished her‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/VanessaSchenkel/handmade-dataset.","first_N":5,"first_N_keywords":["translation","found","found","translation","original"],"keywords_longer_than_N":true},
	{"name":"opus_books_en_pt","keyword":"portuguese","license":"Academic Free License v3.0","license_url":"https://choosealicense.com/licenses/afl-3.0/","language":"en","dataset_url":"https://huggingface.co/datasets/VanessaSchenkel/opus_books_en_pt","creator_name":"Vanessa Schramm Schenkel Da Silva","creator_url":"https://huggingface.co/VanessaSchenkel","description":"How to use it: \nfrom datasets import load_dataset\nremote_dataset = load_dataset(\"VanessaSchenkel/opus_books_en_pt\", field=\"data\")\nremote_dataset\n\nOutput:\nDatasetDict({\n    train: Dataset({\n        features: ['id', 'translation'],\n        num_rows: 1404\n    })\n})\n\nExemple: \nremote_dataset[\"train\"][5]\n\nOutput:\n{'id': '5',\n 'translation': {'en': \"There was nothing so very remarkable in that; nor did Alice think it so very much out of the way to hear the Rabbit say to itself, 'Oh dear!\",\n  'pt':‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/VanessaSchenkel/opus_books_en_pt.","first_N":5,"first_N_keywords":["translation","found","found","translation","extended|opus_books"],"keywords_longer_than_N":true},
	{"name":"multilingual-sentiments","keyword":"portuguese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/tyqiangz/multilingual-sentiments","creator_name":"Tay Yong Qiang","creator_url":"https://huggingface.co/tyqiangz","description":"\n\t\n\t\t\n\t\tMultilingual Sentiments Dataset\n\t\n\nA collection of multilingual sentiments datasets grouped into 3 classes -- positive, neutral, negative.\nMost multilingual sentiment datasets are either 2-class positive or negative, 5-class ratings of products reviews (e.g. Amazon multilingual dataset) or multiple classes of emotions. However, to an average person, sometimes positive, negative and neutral classes suffice and are more straightforward to perceive and annotate. Also, a positive/negative‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/tyqiangz/multilingual-sentiments.","first_N":5,"first_N_keywords":["text-classification","sentiment-analysis","sentiment-classification","monolingual","multilingual"],"keywords_longer_than_N":true},
	{"name":"xP3mt","keyword":"portuguese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/bigscience/xP3mt","creator_name":"BigScience Workshop","creator_url":"https://huggingface.co/bigscience","description":"xP3 (Crosslingual Public Pool of Prompts) is a collection of prompts & datasets across 46 of languages & 16 NLP tasks. It is used for the training of BLOOMZ and mT0, multilingual language models capable of following human instructions in dozens of languages zero-shot.","first_N":5,"first_N_keywords":["other","expert-generated","crowdsourced","multilingual","Akan"],"keywords_longer_than_N":true},
	{"name":"mc4_legal","keyword":"portuguese","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/joelniklaus/mc4_legal","creator_name":"Joel Niklaus","creator_url":"https://huggingface.co/joelniklaus","description":"\n\t\n\t\t\n\t\tDataset Card for MC4_Legal: A Corpus Covering the Legal Part of MC4 for European Languages\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset contains large text resources (~133GB in total) from mc4 filtered for legal data that can be used for pretraining language models.\nUse the dataset like this:\nfrom datasets import load_dataset\ndataset = load_dataset(\"joelito/mc4_legal\", \"de\", split='train', streaming=True)\n\n\n\t\n\t\t\n\t\n\t\n\t\tSupported Tasks and Leaderboards\n\t\n\nThe dataset supports the task of‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/joelniklaus/mc4_legal.","first_N":5,"first_N_keywords":["fill-mask","other","found","multilingual","original"],"keywords_longer_than_N":true},
	{"name":"olid-br","keyword":"portuguese","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/dougtrajano/olid-br","creator_name":"Douglas Trajano","creator_url":"https://huggingface.co/dougtrajano","description":"\n\t\n\t\t\n\t\tOLID-BR\n\t\n\nOffensive Language Identification Dataset for Brazilian Portuguese (OLID-BR) is a dataset with multi-task annotations for the detection of offensive language.\nThe current version (v1.0) contains 7,943 (extendable to 13,538) comments from different sources, including social media (YouTube and Twitter) and related datasets.\nOLID-BR contains a collection of annotated sentences in Brazilian Portuguese using an annotation model that encompasses the following levels:\n\nOffensive‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/dougtrajano/olid-br.","first_N":5,"first_N_keywords":["Portuguese","cc-by-4.0","1K - 10K","parquet","Text"],"keywords_longer_than_N":true},
	{"name":"brwac_tiny","keyword":"portuguese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/thegoodfellas/brwac_tiny","creator_name":"The Good Fellas","creator_url":"https://huggingface.co/thegoodfellas","description":"\n\t\n\t\t\n\t\tDataset Card for BrWac\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThe BrWaC (Brazilian Portuguese Web as Corpus) is a large corpus constructed following the Wacky framework, \nwhich was made public for research purposes. The current corpus version, released in January 2017, is composed by \n3.53 million documents, 2.68 billion tokens and 5.79 million types. Please note that this resource is available \nsolely for academic research purposes, and you agreed not to use it for any commercial applications.‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/thegoodfellas/brwac_tiny.","first_N":5,"first_N_keywords":["fill-mask","masked-language-modeling","no-annotation","found","monolingual"],"keywords_longer_than_N":true},
	{"name":"PortugueseLegalSentences-v1","keyword":"portuguese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/rufimelo/PortugueseLegalSentences-v1","creator_name":"Rui Melo","creator_url":"https://huggingface.co/rufimelo","description":"\n\t\n\t\t\n\t\tPortuguese Legal Sentences\n\t\n\nCollection of Legal Sentences from the Portuguese Supreme Court of Justice\nThe goal of this dataset was to be used for MLM and TSDAE\n\n\t\n\t\t\n\t\tContributions\n\t\n\n@rufimelo99\n","first_N":5,"first_N_keywords":["no-annotation","found","monolingual","original","Portuguese"],"keywords_longer_than_N":true},
	{"name":"PortugueseLegalSentences-v0","keyword":"portuguese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/rufimelo/PortugueseLegalSentences-v0","creator_name":"Rui Melo","creator_url":"https://huggingface.co/rufimelo","description":"\n\t\n\t\t\n\t\tPortuguese Legal Sentences\n\t\n\nCollection of Legal Sentences from the Portuguese Supreme Court of Justice\nThe goal of this dataset was to be used for MLM and TSDAE\n\n\t\n\t\t\n\t\tContributions\n\t\n\n@rufimelo99\n","first_N":5,"first_N_keywords":["no-annotation","found","monolingual","original","Portuguese"],"keywords_longer_than_N":true},
	{"name":"PortugueseLegalSentences-v2","keyword":"portuguese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/rufimelo/PortugueseLegalSentences-v2","creator_name":"Rui Melo","creator_url":"https://huggingface.co/rufimelo","description":"\n\t\n\t\t\n\t\tPortuguese Legal Sentences\n\t\n\nCollection of Legal Sentences from the Portuguese Supreme Court of Justice\nThe goal of this dataset was to be used for MLM and TSDAE\nExtended version of rufimelo/PortugueseLegalSentences-v1\n200000/200000/100000\n\n\t\n\t\t\n\t\tContributions\n\t\n\n@rufimelo99\n","first_N":5,"first_N_keywords":["no-annotation","found","monolingual","original","Portuguese"],"keywords_longer_than_N":true},
	{"name":"PortugueseLegalSentences-v3","keyword":"portuguese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/rufimelo/PortugueseLegalSentences-v3","creator_name":"Rui Melo","creator_url":"https://huggingface.co/rufimelo","description":"\n\t\n\t\t\n\t\tPortuguese Legal Sentences\n\t\n\nCollection of Legal Sentences from the Portuguese Supreme Court of Justice\nThe goal of this dataset was to be used for MLM and TSDAE\nExtended version of rufimelo/PortugueseLegalSentences-v1\n400000/50000/50000\n\n\t\n\t\t\n\t\tContributions\n\t\n\n@rufimelo99\n","first_N":5,"first_N_keywords":["no-annotation","found","monolingual","original","Portuguese"],"keywords_longer_than_N":true},
	{"name":"TaTA","keyword":"portuguese","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/GEM/TaTA","creator_name":"GEM benchmark","creator_url":"https://huggingface.co/GEM","description":"Dataset loader for TaTA: A Multilingual Table-to-Text Dataset for African Languages","first_N":5,"first_N_keywords":["table-to-text","none","unknown","yes","original"],"keywords_longer_than_N":true},
	{"name":"qa-pt","keyword":"portuguese","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ju-resplande/qa-pt","creator_name":"Juliana Resplande","creator_url":"https://huggingface.co/ju-resplande","description":"\n\t\n\t\t\n\t\tDataset Card for QA-Portuguese\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nPortuguese preprocessed split from MQA dataset.\n\n\t\n\t\t\n\t\tSupported Tasks and Leaderboards\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nThe dataset is Portuguese.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\n\t\n\t\t\n\t\tData Instances\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tData Fields\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tData Splits\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tDataset Creation\n\t\n\n\n\t\n\t\t\n\t\tCuration Rationale\n\t\n\n[More Information Needed]‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ju-resplande/qa-pt.","first_N":5,"first_N_keywords":["question-answering","multiple-choice-qa","no-annotation","other","monolingual"],"keywords_longer_than_N":true},
	{"name":"HashtagPrediction","keyword":"portuguese","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Twitter/HashtagPrediction","creator_name":"Twitter","creator_url":"https://huggingface.co/Twitter","description":"\n\t\n\t\t\n\t\tHashtag Prediction Dataset from paper TwHIN-BERT: A Socially-Enriched Pre-trained Language Model for Multilingual Tweet Representations\n\t\n\n  \nThis repo contains the Hashtag prediction dataset from our paper TwHIN-BERT: A Socially-Enriched Pre-trained Language Model for Multilingual Tweet Representations. \n[arXiv][HuggingFace Models]\n[Github repo]\nThis work is licensed under a Creative Commons Attribution 4.0 International License.\n\n\t\n\t\t\n\t\n\t\n\t\tDownload\n\t\n\nUse the‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Twitter/HashtagPrediction.","first_N":5,"first_N_keywords":["Slovenian","Urdu","Sindhi","Polish","Vietnamese"],"keywords_longer_than_N":true},
	{"name":"portuguese-legal-sentences-v0","keyword":"portuguese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/stjiris/portuguese-legal-sentences-v0","creator_name":"Sumariza√ß√£o e Informa√ß√£o de decis√µes: Aplica√ß√£o de T√©cnicas de Intelig√™ncia Artificial no Supremo Tribunal de Justi√ßa (IRIS)","creator_url":"https://huggingface.co/stjiris","description":"\n\nWork developed as part of Project IRIS.\nThesis: A Semantic Search System for Supremo Tribunal de Justi√ßa\n\n\t\n\t\t\n\t\n\t\n\t\tPortuguese Legal Sentences\n\t\n\nCollection of Legal Sentences from the Portuguese Supreme Court of Justice\nThe goal of this dataset was to be used for MLM and TSDAE\n\n\t\n\t\t\n\t\n\t\n\t\tContributions\n\t\n\n@rufimelo99\nIf you use this work, please cite:\n@InProceedings{MeloSemantic,\n  author=\"Melo, Rui\n  and Santos, Pedro A.\n  and Dias, Jo{\\~a}o\",\n  editor=\"Moniz, Nuno\n  and Vale, Zita\n  and‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/stjiris/portuguese-legal-sentences-v0.","first_N":5,"first_N_keywords":["no-annotation","found","monolingual","original","Portuguese"],"keywords_longer_than_N":true},
	{"name":"MultiLegalPile_Wikipedia_Filtered","keyword":"portuguese","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/joelniklaus/MultiLegalPile_Wikipedia_Filtered","creator_name":"Joel Niklaus","creator_url":"https://huggingface.co/joelniklaus","description":"A filtered version of the MultiLegalPile dataset, together with wikipedia articles.","first_N":5,"first_N_keywords":["fill-mask","other","found","multilingual","original"],"keywords_longer_than_N":true},
	{"name":"EU_Wikipedias","keyword":"portuguese","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/joelniklaus/EU_Wikipedias","creator_name":"Joel Niklaus","creator_url":"https://huggingface.co/joelniklaus","description":"Wikipedia dataset containing cleaned articles of all languages.\nThe datasets are built from the Wikipedia dump\n(https://dumps.wikimedia.org/) with one split per language. Each example\ncontains the content of one full Wikipedia article with cleaning to strip\nmarkdown and unwanted sections (references, etc.).","first_N":5,"first_N_keywords":["fill-mask","other","found","multilingual","original"],"keywords_longer_than_N":true},
	{"name":"IRIS_sts","keyword":"portuguese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/stjiris/IRIS_sts","creator_name":"Sumariza√ß√£o e Informa√ß√£o de decis√µes: Aplica√ß√£o de T√©cnicas de Intelig√™ncia Artificial no Supremo Tribunal de Justi√ßa (IRIS)","creator_url":"https://huggingface.co/stjiris","description":"\n\nWork developed as part of Project IRIS.\nThesis: A Semantic Search System for Supremo Tribunal de Justi√ßa\n\n\t\n\t\t\n\t\n\t\n\t\tPortuguese Legal Sentences\n\t\n\nCollection of Legal Sentences pairs from the Portuguese Supreme Court of Justice\nThe goal of this dataset was to be used for Semantic Textual Similarity\n\nValues from 0-1: random sentences across documents\nValues from 2-4: sentences from the same summary (implying some level of entailment)\nValues from 4-5: sentences pairs generated through OpenAi'‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/stjiris/IRIS_sts.","first_N":5,"first_N_keywords":["text-classification","text-scoring","semantic-similarity-scoring","automated","found"],"keywords_longer_than_N":true},
	{"name":"told_br_binary_sm","keyword":"portuguese","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/inctdd/told_br_binary_sm","creator_name":"Instituto Nacional de Ci√™ncia e Tecnologia em Democracia Digital","creator_url":"https://huggingface.co/inctdd","description":"This dataset is a random 1/3 slice of the original told-br\n","first_N":5,"first_N_keywords":["monolingual","told-br","Portuguese","cc-by-sa-4.0","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"MultiLegalPileWikipediaFiltered","keyword":"portuguese","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/joelniklaus/MultiLegalPileWikipediaFiltered","creator_name":"Joel Niklaus","creator_url":"https://huggingface.co/joelniklaus","description":"A filtered version of the MultiLegalPile dataset, together with wikipedia articles.","first_N":5,"first_N_keywords":["fill-mask","other","found","multilingual","original"],"keywords_longer_than_N":true},
	{"name":"legal-mc4","keyword":"portuguese","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/joelniklaus/legal-mc4","creator_name":"Joel Niklaus","creator_url":"https://huggingface.co/joelniklaus","description":"Legal-MC4: A Corpus Covering the Legal Part of MC4 for European Languages","first_N":5,"first_N_keywords":["fill-mask","other","found","multilingual","original"],"keywords_longer_than_N":true},
	{"name":"blogset-br","keyword":"portuguese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/thegoodfellas/blogset-br","creator_name":"The Good Fellas","creator_url":"https://huggingface.co/thegoodfellas","description":"\n\t\n\t\t\n\t\tDataset Card for Dataset Name\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nEste Dataset foi criado a partir dos dados disponibilizados pelo Grupo de Processamento de Linguagem Natural da PUC-RS. O site oficial pode ser encontrado aqui: https://www.inf.pucrs.br/linatural/wordpress/recursos-e-ferramentas/blogset-br/\n\n\t\n\t\t\n\t\tSupported Tasks and Leaderboards\n\t\n\nIndicado para treinamento de modelos de linguagem.\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nPortugu√™s do Brasil\n\n\t\n\t\t\n\t\tInitial Data Collection and Normalization‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/thegoodfellas/blogset-br.","first_N":5,"first_N_keywords":["Portuguese","apache-2.0","1M - 10M","text","Text"],"keywords_longer_than_N":true},
	{"name":"gutenberg_multilang","keyword":"portuguese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/sedthh/gutenberg_multilang","creator_name":"Richard Nagyfi","creator_url":"https://huggingface.co/sedthh","description":"\n\t\n\t\t\n\t\tDataset Card for Project Gutenber - Multilanguage eBooks\n\t\n\nA collection of non-english language eBooks (7907, about 75-80% of all the ES, DE, FR, NL, IT, PT, HU books available on the site) from the Project Gutenberg site with metadata removed. \nOriginally colected for https://github.com/LAION-AI/Open-Assistant\n\n\t\n\t\t\nLANG\nEBOOKS\n\n\n\t\t\nES\n717\n\n\nDE\n1735\n\n\nFR\n2863\n\n\nNL\n904\n\n\nIT\n692\n\n\nPT\n501\n\n\nHU\n495\n\n\n\t\n\nThe METADATA column contains catalogue meta information on each book as a serialized‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/sedthh/gutenberg_multilang.","first_N":5,"first_N_keywords":["text-generation","Spanish","German","French","Dutch"],"keywords_longer_than_N":true},
	{"name":"multiconer_v2","keyword":"portuguese","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/MultiCoNER/multiconer_v2","creator_name":"MultiCoNER","creator_url":"https://huggingface.co/MultiCoNER","description":"Complex named entities (NE), like the titles of creative works, are not simple nouns and pose challenges for NER systems (Ashwini and Choi, 2014). They can take the form of any linguistic constituent, like an imperative clause (‚ÄúDial M for Murder‚Äù), and do not look like traditional NEs (Persons, Locations, etc.). This syntactic ambiguity makes it challenging to recognize them based on context. We organized the MultiCoNER task (Malmasi et al., 2022) at SemEval-2022 to address these challenges in 11 languages, receiving a very positive community response with 34 system papers. Results confirmed the challenges of processing complex and long-tail NEs: even the largest pre-trained Transformers did not achieve top performance without external knowledge. The top systems infused transformers with knowledge bases and gazetteers. However, such solutions are brittle against out of knowledge-base entities and noisy scenarios like the presence of spelling mistakes and typos. We propose MultiCoNER II which represents novel challenges through new tasks that emphasize the shortcomings of the current top models.\n\nMultiCoNER II features complex NER in these languages:\n\n1. English\n2. Spanish\n3. Hindi\n4. Bangla\n5. Chinese\n6. Swedish\n7. Farsi\n8. French\n9. Italian\n10. Portugese\n11. Ukranian\n12. German\n\nFor more details see https://multiconer.github.io/\n\n## References\n* Sandeep Ashwini and Jinho D. Choi. 2014. Targetable named entity recognition in social media. CoRR, abs/1408.0782.\n* Shervin Malmasi, Anjie Fang, Besnik Fetahu, Sudipta Kar, Oleg Rokhlenko. 2022. SemEval-2022 Task 11: Multilingual Complex Named Entity Recognition (MultiCoNER).","first_N":5,"first_N_keywords":["token-classification","Bengali","Chinese","German","English"],"keywords_longer_than_N":true},
	{"name":"oscar-small","keyword":"portuguese","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/djstrong/oscar-small","creator_name":"Krzysztof Wr√≥bel","creator_url":"https://huggingface.co/djstrong","description":"The Open Super-large Crawled ALMAnaCH coRpus is a huge multilingual corpus obtained by language classification and filtering of the Common Crawl corpus using the goclassy architecture.\\","first_N":5,"first_N_keywords":["text-generation","language-modeling","no-annotation","found","multilingual"],"keywords_longer_than_N":true},
	{"name":"faquad-nli","keyword":"portuguese","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ruanchaves/faquad-nli","creator_name":"Ruan Chaves Rodrigues","creator_url":"https://huggingface.co/ruanchaves","description":"\n\t\n\t\t\n\t\tDataset Card for FaQuAD-NLI\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nFaQuAD is a Portuguese reading comprehension dataset that follows the format of the Stanford Question Answering Dataset (SQuAD). It is a pioneer Portuguese reading comprehension dataset using the challenging format of SQuAD. The dataset aims to address the problem of abundant questions sent by academics whose answers are found in available institutional documents in the Brazilian higher education system. It consists of 900‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ruanchaves/faquad-nli.","first_N":5,"first_N_keywords":["question-answering","extractive-qa","expert-generated","found","monolingual"],"keywords_longer_than_N":true},
	{"name":"mc4-pt-cleaned","keyword":"portuguese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/thegoodfellas/mc4-pt-cleaned","creator_name":"The Good Fellas","creator_url":"https://huggingface.co/thegoodfellas","description":"\n\t\n\t\t\n\t\tDescription\n\t\n\nThis is a clenned version of AllenAI mC4 PtBR section. The original dataset can be found here https://huggingface.co/datasets/allenai/c4\n\n\t\n\t\t\n\t\tClean procedure\n\t\n\nWe applied the same clenning procedure as explained here: https://gitlab.com/yhavinga/c4nlpreproc.git \nThe repository offers two strategies. The first one, found in the main.py file, uses pyspark to create a dataframe that can both clean the text and create a \npseudo mix on the entire dataset. We found this‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/thegoodfellas/mc4-pt-cleaned.","first_N":5,"first_N_keywords":["fill-mask","text-generation","Portuguese","apache-2.0","100M - 1B"],"keywords_longer_than_N":true},
	{"name":"Fact-Completion","keyword":"portuguese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Polyglot-or-Not/Fact-Completion","creator_name":"Polyglot-or-Not","creator_url":"https://huggingface.co/Polyglot-or-Not","description":"\n\t\n\t\t\n\t\tDataset Card\n\t\n\n\nHomepage: https://bit.ly/ischool-berkeley-capstone\nRepository: https://github.com/daniel-furman/Capstone\nPoint of Contact: daniel_furman@berkeley.edu\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis is the dataset for Polyglot or Not?: Measuring Multilingual Encyclopedic Knowledge Retrieval from Foundation Language Models.\n\n\t\n\t\t\n\t\n\t\n\t\tTest Description\n\t\n\n Given a factual association such as The capital of France is Paris, we determine whether a model adequately \"knows\" this‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Polyglot-or-Not/Fact-Completion.","first_N":5,"first_N_keywords":["text-generation","fill-mask","expert-generated","machine-generated","multilingual"],"keywords_longer_than_N":true},
	{"name":"lingnli-multi-mt","keyword":"portuguese","license":"BSD 2-Clause \"Simplified\" License","license_url":"https://choosealicense.com/licenses/bsd-2-clause/","language":"en","dataset_url":"https://huggingface.co/datasets/maximoss/lingnli-multi-mt","creator_name":"Maximos Skandalis","creator_url":"https://huggingface.co/maximoss","description":"\n\t\n\t\t\n\t\tDataset Card for Dataset Name\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis repository contains a collection of machine translations of LingNLI dataset \ninto 9 different languages (Bulgarian, Finnish, French, Greek, Italian, Korean, Lithuanian, Portuguese, Spanish). The goal is to predict textual entailment (does sentence A \nimply/contradict/neither sentence B), which is a classification task (given two sentences, \npredict one of three labels). It is here formatted in the same manner as the‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/maximoss/lingnli-multi-mt.","first_N":5,"first_N_keywords":["text-classification","natural-language-inference","multi-input-text-classification","Greek","French"],"keywords_longer_than_N":true},
	{"name":"xP3x","keyword":"portuguese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/CohereLabs/xP3x","creator_name":"Cohere Labs","creator_url":"https://huggingface.co/CohereLabs","description":"\n\t\n\t\t\n\t\tDataset Card for xP3x\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\n\nxP3x (Crosslingual Public Pool of Prompts eXtended) is a collection of prompts & datasets across 277 languages & 16 NLP tasks. It contains all of xP3 + much more! It is used for training future contenders of mT0 & BLOOMZ at project Aya @Cohere Labs üß°\n\n\nCreation: The dataset can be recreated using instructions available here together with the file in this repository named xp3x_create.py. We provide this version to save processing‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/CohereLabs/xP3x.","first_N":5,"first_N_keywords":["other","expert-generated","crowdsourced","multilingual","Afrikaans"],"keywords_longer_than_N":true},
	{"name":"portuguese-parliament-interventions","keyword":"portuguese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/luist18/portuguese-parliament-interventions","creator_name":"Lu√≠s Tavares","creator_url":"https://huggingface.co/luist18","description":"luist18/portuguese-parliament-interventions dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["Portuguese","mit","1K - 10K","csv","Tabular"],"keywords_longer_than_N":true},
	{"name":"pt-parliament-interventions","keyword":"portuguese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/luist18/pt-parliament-interventions","creator_name":"Lu√≠s Tavares","creator_url":"https://huggingface.co/luist18","description":"luist18/pt-parliament-interventions dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["Portuguese","mit","< 1K","csv","Text"],"keywords_longer_than_N":true},
	{"name":"ptparl","keyword":"portuguese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/luist18/ptparl","creator_name":"Lu√≠s Tavares","creator_url":"https://huggingface.co/luist18","description":"The PTPARL dataset is a dataset containing 5713 interventions in the Portuguese parliament.","first_N":5,"first_N_keywords":["text-classification","multi-label-classification","expert-generated","found","monolingual"],"keywords_longer_than_N":true},
	{"name":"instruct-aira-dataset","keyword":"portuguese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/nicholasKluge/instruct-aira-dataset","creator_name":"Nicholas Kluge Corr√™a","creator_url":"https://huggingface.co/nicholasKluge","description":"\n\t\n\t\t\n\t\tInstruct-Aira Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset contains a collection of prompts and responses to those prompts. All completions were generated by querying already-tuned models (ChatGPT, LLama 2, Open-Assistant, etc.). The dataset is available in Portuguese, English, and Spanish.\n\n\t\n\t\t\n\t\tSupported Tasks and Leaderboards\n\t\n\nThis dataset can be utilized for various natural language processing tasks, including but not limited to:\n\nLanguage modeling.\nQuestion-answering‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/nicholasKluge/instruct-aira-dataset.","first_N":5,"first_N_keywords":["text-generation","Portuguese","English","Spanish","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"reward-aira-dataset","keyword":"portuguese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/nicholasKluge/reward-aira-dataset","creator_name":"Nicholas Kluge Corr√™a","creator_url":"https://huggingface.co/nicholasKluge","description":"\n\t\n\t\t\n\t\tReward-Aira Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset contains a collection of prompt + completion examples of LLM following instructions in a conversational manner. All prompts come with two possible completions (one better than the other). The dataset is available in both Portuguese and English.\n\n\t\n\t\t\n\t\tSupported Tasks and Leaderboards\n\t\n\nThis dataset can be utilized to train a reward/preference model or DPO fine-tuning.\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nEnglish and Portuguese.‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/nicholasKluge/reward-aira-dataset.","first_N":5,"first_N_keywords":["text-classification","Portuguese","English","apache-2.0","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"harmless-aira-dataset","keyword":"portuguese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/nicholasKluge/harmless-aira-dataset","creator_name":"Nicholas Kluge Corr√™a","creator_url":"https://huggingface.co/nicholasKluge","description":"\n\t\n\t\t\n\t\tHarmless-Aira Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset contains a collection of prompt + completion examples of LLM following instructions in a conversational manner. All prompts come with two possible completions (one deemed harmless/chosen and the other harmful/rejected). The dataset is available in both Portuguese and English.\n\n\t\n\t\t\n\t\tSupported Tasks and Leaderboards\n\t\n\nThis dataset can be utilized to train a reward/preference model or DPO fine-tuning.\n\n\t\n\t\t\n\t\tLanguages‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/nicholasKluge/harmless-aira-dataset.","first_N":5,"first_N_keywords":["text-classification","Portuguese","English","apache-2.0","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"SREDFM","keyword":"portuguese","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Babelscape/SREDFM","creator_name":"Babelscape","creator_url":"https://huggingface.co/Babelscape","description":"Relation Extraction (RE) is a task that identifies relationships between entities in a text, enabling the acquisition of relational facts and bridging the gap between natural language and structured knowledge. However, current RE models often rely on small datasets with low coverage of relation types, particularly when working with languages other than English. \\In this paper, we address the above issue and provide two new resources that enable the training and evaluation of multilingual RE systems.\nFirst, we present SRED\\textsuperscript{FM}, an automatically annotated dataset covering 18 languages, 400 relation types, 13 entity types, totaling more than 40 million triplet instances. Second, we propose RED\\textsuperscript{FM}, a smaller, human-revised dataset for seven languages that allows for the evaluation of multilingual RE systems. \nTo demonstrate the utility of these novel datasets, we experiment with the first end-to-end multilingual RE model, mREBEL, \nthat extracts triplets, including entity types, in multiple languages. We release our resources and model checkpoints at \\href{https://www.github.com/babelscape/rebel}{https://www.github.com/babelscape/rebel}.","first_N":5,"first_N_keywords":["token-classification","Arabic","Catalan","German","Greek"],"keywords_longer_than_N":true},
	{"name":"flores_101","keyword":"portuguese","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/severo/flores_101","creator_name":"Sylvain Lesage","creator_url":"https://huggingface.co/severo","description":"One of the biggest challenges hindering progress in low-resource and multilingual machine translation is the \nlack of good evaluation benchmarks. Current evaluation benchmarks either lack good coverage of low-resource \nlanguages, consider only restricted domains, or are low quality because they are constructed using \nsemi-automatic procedures. In this work, we introduce the FLORES evaluation benchmark, consisting of 3001 \nsentences extracted from English Wikipedia and covering a variety of different topics and domains. \nThese sentences have been translated in 101 languages by professional translators through a carefully \ncontrolled process. The resulting dataset enables better assessment of model quality on the long tail of \nlow-resource languages, including the evaluation of many-to-many multilingual translation systems, as all \ntranslations are multilingually aligned. By publicly releasing such a high-quality and high-coverage dataset, \nwe hope to foster progress in the machine translation community and beyond.","first_N":5,"first_N_keywords":["text-generation","translation","found","expert-generated","multilingual"],"keywords_longer_than_N":true},
	{"name":"toxi-text-3M","keyword":"portuguese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/FredZhang7/toxi-text-3M","creator_name":"Fred Zhang","creator_url":"https://huggingface.co/FredZhang7","description":"This is a large multilingual toxicity dataset with 3M rows of text data from 55 natural languages, all of which are written/sent by humans, not machine translation models.\nThe preprocessed training data alone consists of 2,880,667 rows of comments, tweets, and messages. Among these rows, 416,529 are classified as toxic, while the remaining 2,463,773 are considered neutral. Below is a table to illustrate the data composition:\n\n\t\n\t\t\n\nToxic\nNeutral\nTotal\n\n\n\t\t\nmultilingual-train-deduplicated.csv‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/FredZhang7/toxi-text-3M.","first_N":5,"first_N_keywords":["text-classification","zero-shot-classification","Arabic","Spanish","Panjabi"],"keywords_longer_than_N":true},
	{"name":"all-scam-spam","keyword":"portuguese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/FredZhang7/all-scam-spam","creator_name":"Fred Zhang","creator_url":"https://huggingface.co/FredZhang7","description":"This is a large corpus of 42,619 preprocessed text messages and emails sent by humans in 43 languages. is_spam=1 means spam and is_spam=0 means ham.\n1040 rows of balanced data, consisting of casual conversations and scam emails in ‚âà10 languages, were manually collected and annotated by me, with some help from ChatGPT.\n\n\n\n\t\n\t\t\n\t\tSome preprcoessing algorithms\n\t\n\n\nspam_assassin.js, followed by spam_assassin.py\nenron_spam.py\n\n\n\n\n\t\n\t\t\n\t\tData composition\n\t\n\n\n\n\n\n\t\n\t\t\n\t\tDescription\n\t\n\nTo make the text‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/FredZhang7/all-scam-spam.","first_N":5,"first_N_keywords":["text-classification","zero-shot-classification","Norwegian","Spanish","Somali"],"keywords_longer_than_N":true},
	{"name":"xP3x-sample","keyword":"portuguese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Muennighoff/xP3x-sample","creator_name":"Niklas Muennighoff","creator_url":"https://huggingface.co/Muennighoff","description":"A multilingual collection of Winograd Schemas in six languages that can be used for evaluation of cross-lingual commonsense reasoning capabilities.","first_N":5,"first_N_keywords":["other","expert-generated","crowdsourced","multilingual","Afrikaans"],"keywords_longer_than_N":true},
	{"name":"malicious-website-features-2.4M","keyword":"portuguese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/FredZhang7/malicious-website-features-2.4M","creator_name":"Fred Zhang","creator_url":"https://huggingface.co/FredZhang7","description":"Important Notice:\n\nA subset of the URL dataset is from Kaggle, and the Kaggle datasets contained 10%-15% mislabelled data. See this dicussion I opened for some false positives. I have contacted Kaggle regarding their erroneous \"Usability\" score calculation for these unreliable datasets.\nThe feature extraction methods shown here are not robust at all in 2023, and there're even silly mistakes in 3 functions: not_indexed_by_google, domain_registration_length, and age_of_domain.\n\n\n\nThe features‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/FredZhang7/malicious-website-features-2.4M.","first_N":5,"first_N_keywords":["text-classification","feature-extraction","tabular-classification","Norwegian","Afrikaans"],"keywords_longer_than_N":true},
	{"name":"professor_heideltime_en","keyword":"portuguese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/hugosousa/professor_heideltime_en","creator_name":"Hugo Sousa","creator_url":"https://huggingface.co/hugosousa","description":"\n\t\n\t\t\n\t\tProfessor HeidelTime\n\t\n\n\n\nProfessor HeidelTime is a project to create a multilingual corpus weakly labeled with HeidelTime, a temporal tagger.\n\n\t\n\t\t\n\t\n\t\n\t\tCorpus Details\n\t\n\nThe weak labeling was performed in six languages. Here are the specifics of the corpus for each language:\n\n\t\n\t\t\nDataset\nLanguage\nDocuments\nFrom\nTo\nTokens\nTimexs\n\n\n\t\t\nAll the News 2.0\nEN\n24,642\n2016-01-01\n2020-04-0218,755,616\n254,803\n\n\nItalian Crime News\nIT\n9,619\n2011-01-01\n2021-12-31\n3,296,898\n58,823\n\n\nGerman News‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/hugosousa/professor_heideltime_en.","first_N":5,"first_N_keywords":["token-classification","parsing","part-of-speech","named-entity-recognition","machine-generated"],"keywords_longer_than_N":true},
	{"name":"ggml-vicuna-v0-quantized","keyword":"portuguese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/maknee/ggml-vicuna-v0-quantized","creator_name":"maknee","creator_url":"https://huggingface.co/maknee","description":"These are quantized ggml binary files for vicuna 7B and 13B models. The version of vicuna for these models are v0.\nThese files can be used in conjunction with minigpt4 ggml models 7B and 13B in minigpt4.cpp\nRecommended are the Q5_K and Q6_K implementations. If there are any issues, use Q4_1 or Q4_0.\n\n\n\t\n\t\t\n\t\n\t\n\t\tVicuna Model Card\n\t\n\n\n\t\n\t\t\n\t\n\t\n\t\tModel details\n\t\n\nModel type:\nVicuna is an open-source chatbot trained by fine-tuning LLaMA on user-shared conversations collected from ShareGPT.\nIt is‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/maknee/ggml-vicuna-v0-quantized.","first_N":5,"first_N_keywords":["English","Bulgarian","Catalan","Czech","Danish"],"keywords_longer_than_N":true},
	{"name":"massive_translation_dataset","keyword":"portuguese","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Amani27/massive_translation_dataset","creator_name":"Amani N","creator_url":"https://huggingface.co/Amani27","description":"\n\t\n\t\t\n\t\tDataset Card for Massive Dataset for Translation\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset is derived from AmazonScience/MASSIVE dataset for translation task purpose.\n\n\t\n\t\t\n\t\tSupported Tasks and Leaderboards\n\t\n\nTranslation\n\n\t\n\t\t\n\t\tLanguages\n\t\n\n\nEnglish (en_US)\nGerman (de_DE)\nHindi (hi_IN)\nSpanish (es_ES)\nFrench (fr_FR)\nItalian (it_IT)\nArabic (ar_SA)\nDutch (nl_NL)\nJapanese (ja_JP)\nPortugese (pt_PT)\n\n","first_N":5,"first_N_keywords":["translation","English","German","Spanish","Hindi"],"keywords_longer_than_N":true},
	{"name":"MMLU_Portuguese","keyword":"portuguese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/FreedomIntelligence/MMLU_Portuguese","creator_name":"FreedomAI","creator_url":"https://huggingface.co/FreedomIntelligence","description":"Portuguese version of MMLU dataset tranlasted by gpt-3.5-turbo.The dataset is used in the research related to MultilingualSIFT. \n","first_N":5,"first_N_keywords":["Portuguese","mit","üá∫üá∏ Region: US"],"keywords_longer_than_N":false},
	{"name":"text-template-to-summarize","keyword":"portuguese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Anderson-Andre-P/text-template-to-summarize","creator_name":"Anderson Andr√© Pereira Eleut√©rio","creator_url":"https://huggingface.co/Anderson-Andre-P","description":"Anderson-Andre-P/text-template-to-summarize dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["summarization","Portuguese","mit","< 1K","csv"],"keywords_longer_than_N":true},
	{"name":"UltrachatBR","keyword":"portuguese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/recogna-nlp/UltrachatBR","creator_name":"Recogna NLP","creator_url":"https://huggingface.co/recogna-nlp","description":"\n\t\n\t\t\n\t\tUltrachatBR: Um Dataset em Portugu√™s baseado no Ultrachat\n\t\n\nO UltrachatBR √© uma vers√£o em portugu√™s do conhecido dataset Ultrachat, originalmente desenvolvido para o idioma ingl√™s. Este projeto visa disponibilizar uma vasta cole√ß√£o de di√°logos traduzidos para o portugu√™s, ampliando assim o acesso a recursos de processamento de linguagem natural para a comunidade de l√≠ngua portuguesa.\n\n\t\n\t\t\n\t\n\t\n\t\tProcesso de Tradu√ß√£o\n\t\n\nO processo de tradu√ß√£o foi realizado utilizando a API do Google‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/recogna-nlp/UltrachatBR.","first_N":5,"first_N_keywords":["text-generation","Portuguese","mit","100K - 1M","json"],"keywords_longer_than_N":true},
	{"name":"UltrachatBR","keyword":"portuguese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/recogna-nlp/UltrachatBR","creator_name":"Recogna NLP","creator_url":"https://huggingface.co/recogna-nlp","description":"\n\t\n\t\t\n\t\tUltrachatBR: Um Dataset em Portugu√™s baseado no Ultrachat\n\t\n\nO UltrachatBR √© uma vers√£o em portugu√™s do conhecido dataset Ultrachat, originalmente desenvolvido para o idioma ingl√™s. Este projeto visa disponibilizar uma vasta cole√ß√£o de di√°logos traduzidos para o portugu√™s, ampliando assim o acesso a recursos de processamento de linguagem natural para a comunidade de l√≠ngua portuguesa.\n\n\t\n\t\t\n\t\n\t\n\t\tProcesso de Tradu√ß√£o\n\t\n\nO processo de tradu√ß√£o foi realizado utilizando a API do Google‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/recogna-nlp/UltrachatBR.","first_N":5,"first_N_keywords":["text-generation","Portuguese","mit","100K - 1M","json"],"keywords_longer_than_N":true},
	{"name":"copywritings-pt-br-instruct","keyword":"portuguese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/BornSaint/copywritings-pt-br-instruct","creator_name":"R√≥ger Santos","creator_url":"https://huggingface.co/BornSaint","description":"BornSaint/copywritings-pt-br-instruct dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["Portuguese","apache-2.0","< 1K","json","Text"],"keywords_longer_than_N":true},
	{"name":"sib200","keyword":"portuguese","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Davlan/sib200","creator_name":"David Adelani","creator_url":"https://huggingface.co/Davlan","description":"\n\t\n\t\t\n\t\tDataset Card for SIB-200\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nSIB-200 is the largest publicly available topic classification dataset based on Flores-200 covering 205 languages and dialects.\nThe train/validation/test sets are available for all the 205 languages.\n\n\t\n\t\t\n\t\tSupported Tasks and Leaderboards\n\t\n\n\ntopic classification: categorize wikipedia sentences into topics e.g science/technology, sports or politics.\n\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nThere are 205 languages available :\n\n\t\n\t\t\n\t\tDataset‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Davlan/sib200.","first_N":5,"first_N_keywords":["text-classification","topic-classification","found","expert-generated","multilingual"],"keywords_longer_than_N":true},
	{"name":"central_de_fatos","keyword":"portuguese","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/fake-news-UFG/central_de_fatos","creator_name":"fake-news-UFG","creator_url":"https://huggingface.co/fake-news-UFG","description":"\n\t\n\t\t\n\t\tCentral de Fatos\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nIn recent times, the interest for research dissecting the dissemination and prevention of misinformation in the online environment has spiked dramatically.\nGiven that scenario, a recurring obstacle is the unavailability of public datasets containing fact-checked instances.\nIn this work, we performed an extensive data collection of such instances from the better part of all major internationally recognized Brazilian fact-checking agencies.‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/fake-news-UFG/central_de_fatos.","first_N":5,"first_N_keywords":["text-classification","found","monolingual","Portuguese","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"bible-ptbr-gun-gub-aligned","keyword":"portuguese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/tiagoblima/bible-ptbr-gun-gub-aligned","creator_name":"Tiago Barbosa de Lima","creator_url":"https://huggingface.co/tiagoblima","description":"tiagoblima/bible-ptbr-gun-gub-aligned dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["translation","Portuguese","Guaran√≠","mit","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"belebele","keyword":"portuguese","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/facebook/belebele","creator_name":"AI at Meta","creator_url":"https://huggingface.co/facebook","description":"\n\t\n\t\t\n\t\tThe Belebele Benchmark for Massively Multilingual NLU Evaluation\n\t\n\nBelebele is a multiple-choice machine reading comprehension (MRC) dataset spanning 122 language variants. This dataset enables the evaluation of mono- and multi-lingual models in high-, medium-, and low-resource languages. Each question has four multiple-choice answers and is linked to a short passage from the FLORES-200 dataset. The human annotation procedure was carefully curated to create questions that discriminate‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/facebook/belebele.","first_N":5,"first_N_keywords":["question-answering","zero-shot-classification","text-classification","multiple-choice","Afrikaans"],"keywords_longer_than_N":true},
	{"name":"wikianc","keyword":"portuguese","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/cyanic-selkie/wikianc","creator_name":"cyanic-selkie","creator_url":"https://huggingface.co/cyanic-selkie","description":"\n\t\n\t\t\n\t\tDataset Card for WikiAnc\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThe WikiAnc dataset is an automatically generated dataset from Wikipedia (all languages) and Wikidata dumps (August, 2023). \nThe code for generating the dataset can be found here.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\n\nwikificiation: The dataset can be used to train a model for Wikification.\nnamed-entity-linking: The dataset can be used to train a model for Named Entity Linking.\n\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nThe text in the dataset is in all 320‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/cyanic-selkie/wikianc.","first_N":5,"first_N_keywords":["token-classification","machine-generated","crowdsourced","machine-generated","crowdsourced"],"keywords_longer_than_N":true},
	{"name":"entity_cs","keyword":"portuguese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/huawei-noah/entity_cs","creator_name":"HUAWEI Noah's Ark Lab","creator_url":"https://huggingface.co/huawei-noah","description":"\n\t\n\t\t\n\t\tDataset Card for EntityCS\n\t\n\n\nRepository: https://github.com/huawei-noah/noah-research/tree/master/NLP/EntityCS  \nPaper: https://aclanthology.org/2022.findings-emnlp.499.pdf  \nPoint of Contact: Fenia Christopoulou, Chenxi Whitehouse\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Description\n\t\n\nWe use the English Wikipedia and leverage entity information from Wikidata to construct an entity-based Code Switching corpus. \nTo achieve this, we make use of wikilinks in Wikipedia, i.e. links from one page to another.‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/huawei-noah/entity_cs.","first_N":5,"first_N_keywords":["Afrikaans","Amharic","Arabic","Assamese","Azerbaijani"],"keywords_longer_than_N":true},
	{"name":"Bosque_PT-PT","keyword":"portuguese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/liaad/Bosque_PT-PT","creator_name":"LIAAD, INESCTEC","creator_url":"https://huggingface.co/liaad","description":"liaad/Bosque_PT-PT dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["token-classification","Portuguese","mit","1K - 10K","parquet"],"keywords_longer_than_N":true},
	{"name":"calame-pt","keyword":"portuguese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/NOVA-vision-language/calame-pt","creator_name":"NOVA Vision & Language","creator_url":"https://huggingface.co/NOVA-vision-language","description":"\n\t\n\t\t\n\t\tCALAME-PT\n\t\n\n\n\t\n\t\t\n\t\tContext-Aware LAnguage Modeling Evaluation for Portuguese\n\t\n\nCALAME-PT is a PT benchmark composed of small texts (contexts) and their respective last words. \nThese contexts should, in theory, contain enough information so that a human or a model is capable of guessing its last word - without being too specific and/or too ambiguous.\n\n\t\n\t\t\n\t\tComposition\n\t\n\nCALAME-PT is composed of 2 \"sets\" of data - handwritten and generated. \n\nHandwritten Set: contains 406‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/NOVA-vision-language/calame-pt.","first_N":5,"first_N_keywords":["Portuguese","mit","1K - 10K","json","Text"],"keywords_longer_than_N":true},
	{"name":"calame-pt","keyword":"portuguese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/NOVA-vision-language/calame-pt","creator_name":"NOVA Vision & Language","creator_url":"https://huggingface.co/NOVA-vision-language","description":"\n\t\n\t\t\n\t\tCALAME-PT\n\t\n\n\n\t\n\t\t\n\t\tContext-Aware LAnguage Modeling Evaluation for Portuguese\n\t\n\nCALAME-PT is a PT benchmark composed of small texts (contexts) and their respective last words. \nThese contexts should, in theory, contain enough information so that a human or a model is capable of guessing its last word - without being too specific and/or too ambiguous.\n\n\t\n\t\t\n\t\tComposition\n\t\n\nCALAME-PT is composed of 2 \"sets\" of data - handwritten and generated. \n\nHandwritten Set: contains 406‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/NOVA-vision-language/calame-pt.","first_N":5,"first_N_keywords":["Portuguese","mit","1K - 10K","json","Text"],"keywords_longer_than_N":true},
	{"name":"mswc_fscil_subset","keyword":"portuguese","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/NeuroBench/mswc_fscil_subset","creator_name":"NeuroBench","creator_url":"https://huggingface.co/NeuroBench","description":"This is a subset of the Multilingual Spoken Word Corpus dataset, which is built specifically for the Few-shot Class-incremental Learning (FSCIL) task. \nA total of 15 languages are chosen, split into 5 base languages (English, German, Catalan, French, Kinyarwanda) and 10 incrementally learned languages (Persian, Spanish, Russian, Welsh, Italian, Basque, Polish, Esparanto, Portuguese, Dutch).\nThe FSCIL task entails first training a model using abundant training data on words from the 5 base‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/NeuroBench/mswc_fscil_subset.","first_N":5,"first_N_keywords":["English","Spanish","Catalan","French","Kinyarwanda"],"keywords_longer_than_N":true},
	{"name":"canarim","keyword":"portuguese","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/dominguesm/canarim","creator_name":"Maicon Domingues","creator_url":"https://huggingface.co/dominguesm","description":"\n  \n\n\n\n  [üê± GitHub]\n\n\n\n\n\n\n\t\n\t\t\n\t\tCanarim: A Large-Scale Dataset of Web Pages in the Portuguese Language\n\t\n\n\n\t\n\t\t\n\t\tIntroduction\n\t\n\nCanarim is a database encompassing over 342 million Portuguese language documents, sourced from multiple iterations of CommonCrawl. This nearly 1 terabyte database stands as one of the most extensive Portuguese language data collections available. It underwent initial deduplication using URLs, with plans for further text-based deduplication and filtering of‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/dominguesm/canarim.","first_N":5,"first_N_keywords":["text-generation","fill-mask","language-modeling","masked-language-modeling","monolingual"],"keywords_longer_than_N":true},
	{"name":"multilingual-pl-bert","keyword":"portuguese","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/styletts2-community/multilingual-pl-bert","creator_name":"StyleTTS 2 Community","creator_url":"https://huggingface.co/styletts2-community","description":"Attribution: Wikipedia.org\n","first_N":5,"first_N_keywords":["Afrikaans","Aragonese","Arabic","Azerbaijani","Bashkir"],"keywords_longer_than_N":true},
	{"name":"HisaSoft","keyword":"portuguese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Hisasartori/HisaSoft","creator_name":"Hisa Sartori ","creator_url":"https://huggingface.co/Hisasartori","description":"Hisasartori/HisaSoft dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["Portuguese","English","apache-2.0","< 1K","soundfolder"],"keywords_longer_than_N":true},
	{"name":"uner_llm_instructions","keyword":"portuguese","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/universalner/uner_llm_instructions","creator_name":"Universal NER","creator_url":"https://huggingface.co/universalner","description":"\n\t\n\t\t\n\t\tDataset Card for Universal NER v1 in the Aya format\n\t\n\nThis dataset is a format conversion from its original v1 format into the Aya instruction format and it's released here under the same CC-BY-SA 4.0 license and conditions.\nIt contains data in multiple languages and this version is intended for multi-lingual LLM construction/tuning.\nThe dataset contains different subsets and their dev/test/train splits, depending on language. \n\n\t\n\t\t\n\t\tCitation\n\t\n\nIf you utilize this dataset version‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/universalner/uner_llm_instructions.","first_N":5,"first_N_keywords":["token-classification","Cebuano","Danish","German","English"],"keywords_longer_than_N":true},
	{"name":"uner_llm_inst_portuguese","keyword":"portuguese","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/universalner/uner_llm_inst_portuguese","creator_name":"Universal NER","creator_url":"https://huggingface.co/universalner","description":"\n\t\n\t\t\n\t\tDataset Card for Universal NER v1 in the Aya format - Portuguese subset\n\t\n\nThis dataset is a format conversion for the Portuguese data in the original Universal NER v1 into the Aya instruction format and it's released here under the same CC-BY-SA 4.0 license and conditions.\nThe dataset contains different subsets and their dev/test/train splits, depending on language. For more details, please refer to:\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\nFor the original Universal NER dataset v1 and more details‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/universalner/uner_llm_inst_portuguese.","first_N":5,"first_N_keywords":["token-classification","Portuguese","cc-by-sa-4.0","10K - 100K","json"],"keywords_longer_than_N":true},
	{"name":"ntx_llm_instructions","keyword":"portuguese","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/tellarin-ai/ntx_llm_instructions","creator_name":"Tellarin.ai","creator_url":"https://huggingface.co/tellarin-ai","description":"\n\t\n\t\t\n\t\tDataset Card for NTX v1 in the Aya format\n\t\n\nThis dataset is a format conversion from its original v1 format into the Aya instruction format and it's released here under the CC-BY-SA 4.0 license and conditions.\nIt contains data in multiple languages and this version is intended for multi-lingual LLM construction/tuning.\n\n\t\n\t\t\n\t\tCitation\n\t\n\nIf you utilize this dataset version, feel free to cite/footnote this huggingface dataset repo, but please also cite the original dataset‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/tellarin-ai/ntx_llm_instructions.","first_N":5,"first_N_keywords":["token-classification","Arabic","German","English","Spanish"],"keywords_longer_than_N":true},
	{"name":"ntx_llm_inst_portuguese","keyword":"portuguese","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/tellarin-ai/ntx_llm_inst_portuguese","creator_name":"Tellarin.ai","creator_url":"https://huggingface.co/tellarin-ai","description":"\n\t\n\t\t\n\t\tDataset Card for NTX v1 in the Aya format - Portuguese subset\n\t\n\nThis dataset is a format conversion for the Portuguese data from the original NTX into the Aya instruction format and it's released here under the CC-BY-SA 4.0 license.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\nFor the original NTX dataset, the conversion to the Aya instructions format, or more details, please refer to the full dataset in instruction form (https://huggingface.co/datasets/tellarin-ai/ntx_llm_instructions) or to the paper‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/tellarin-ai/ntx_llm_inst_portuguese.","first_N":5,"first_N_keywords":["token-classification","Portuguese","cc-by-sa-4.0","< 1K","json"],"keywords_longer_than_N":true},
	{"name":"gender-by-name","keyword":"portuguese","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/erickrribeiro/gender-by-name","creator_name":"Erick R. Ribeiro","creator_url":"https://huggingface.co/erickrribeiro","description":"\n\t\n\t\t\n\t\tDataset Card for \"Gender-by-Name\"\n\t\n\nThis dataset attributes first names to genders, giving counts and probabilities. It combines open-source government data from the US, UK, Canada, and Australia. The dataset is taken from UCI Machine Learning Repository\n\n\t\n\t\t\n\t\tDataset Information\n\t\n\nThis dataset combines raw counts for first/given names of male and female babies in those time periods, and then calculates a probability for a name given the aggregate count.  Source datasets are from‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/erickrribeiro/gender-by-name.","first_N":5,"first_N_keywords":["text-classification","English","Portuguese","cc-by-4.0","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"FakeRecogna","keyword":"portuguese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/recogna-nlp/FakeRecogna","creator_name":"Recogna NLP","creator_url":"https://huggingface.co/recogna-nlp","description":"\n\t\n\t\t\n\t\tFakeRecogna\n\t\n\nFakeRecogna is a dataset comprised of real and fake news. The real news is not directly linked to fake news and vice-versa, which could lead to a biased classification. The news collection was performed by crawlers developed for mining pages of well-known and of great national importance agency news. The web crawlers were developed based on each analyzed webpage, where the extracted information is first separated into categories and then grouped by dates. The plurality‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/recogna-nlp/FakeRecogna.","first_N":5,"first_N_keywords":["text-classification","Portuguese","mit","10K - 100K","csv"],"keywords_longer_than_N":true},
	{"name":"FakeRecogna","keyword":"portuguese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/recogna-nlp/FakeRecogna","creator_name":"Recogna NLP","creator_url":"https://huggingface.co/recogna-nlp","description":"\n\t\n\t\t\n\t\tFakeRecogna\n\t\n\nFakeRecogna is a dataset comprised of real and fake news. The real news is not directly linked to fake news and vice-versa, which could lead to a biased classification. The news collection was performed by crawlers developed for mining pages of well-known and of great national importance agency news. The web crawlers were developed based on each analyzed webpage, where the extracted information is first separated into categories and then grouped by dates. The plurality‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/recogna-nlp/FakeRecogna.","first_N":5,"first_N_keywords":["text-classification","Portuguese","mit","10K - 100K","csv"],"keywords_longer_than_N":true},
	{"name":"mqnli","keyword":"portuguese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/SachinPatel248/mqnli","creator_name":"Patel","creator_url":"https://huggingface.co/SachinPatel248","description":"SachinPatel248/mqnli dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["text-classification","English","German","Spanish","Arabic"],"keywords_longer_than_N":true},
	{"name":"Multi-EuP","keyword":"portuguese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/unimelb-nlp/Multi-EuP","creator_name":"The University of Melbourne","creator_url":"https://huggingface.co/unimelb-nlp","description":"\n\t\n\t\t\n\t\n\t\n\t\tNOTES FOR DOWNLOAD!\n\t\n\n\nHighly recommend downloading it via the API:\n\ncurl -X GET \\\n     \"https://datasets-server.huggingface.co/first-rows?dataset=unimelb-nlp%2FMulti-EuP&config=default&split=full\"\n\n\nIf you are using the HuggingFace library, please follow these steps:\n\npip install datasets\n\nfrom datasets import load_dataset\n\ndataset = load_dataset(\"unimelb-nlp/Multi-EuP\", keep_default_na=False)\n\nNote: It's crucial to use keep_default_na=False because some datasets contain 'null'‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/unimelb-nlp/Multi-EuP.","first_N":5,"first_N_keywords":["text-retrieval","English","German","French","Italian"],"keywords_longer_than_N":true},
	{"name":"aya_dataset","keyword":"portuguese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/CohereLabs/aya_dataset","creator_name":"Cohere Labs","creator_url":"https://huggingface.co/CohereLabs","description":"\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThe Aya Dataset is a multilingual instruction fine-tuning dataset curated by an open-science community via Aya Annotation Platform from Cohere Labs. The dataset contains a total of 204k human-annotated prompt-completion pairs along with the demographics data of the annotators.\nThis dataset can be used to train, finetune, and evaluate multilingual LLMs.\n\nCurated by: Contributors of Aya Open Science Intiative.\n\nLanguage(s): 65 languages (71 including dialects &‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/CohereLabs/aya_dataset.","first_N":5,"first_N_keywords":["other","crowdsourced","expert-generated","crowdsourced","expert-generated"],"keywords_longer_than_N":true},
	{"name":"recognasumm","keyword":"portuguese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/recogna-nlp/recognasumm","creator_name":"Recogna NLP","creator_url":"https://huggingface.co/recogna-nlp","description":"\n\t\n\t\t\n\t\tRecognaSumm Dataset\n\t\n\n\n\t\n\t\t\n\t\tIntroduction\n\t\n\nRecognaSumm is a novel and comprehensive database specifically designed for the task of automatic text summarization in Portuguese. RecognaSumm stands out due to its diverse origin, composed of news collected from a variety of information sources, including agencies and online news portals. The database was constructed using web scraping techniques and careful curation, re sulting in a rich and representative collection of documents‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/recogna-nlp/recognasumm.","first_N":5,"first_N_keywords":["summarization","Portuguese","mit","100K<n<1M","üá∫üá∏ Region: US"],"keywords_longer_than_N":true},
	{"name":"TuPY_dataset_multilabel","keyword":"portuguese","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/victoriadreis/TuPY_dataset_multilabel","creator_name":"Victoria Reis","creator_url":"https://huggingface.co/victoriadreis","description":"\n\t\n\t\t\n\t\tPortuguese Hate Speech Dataset (TuPy)\n\t\n\nThe Portuguese hate speech dataset (TuPy) is an annotated corpus designed to facilitate the development of advanced hate speech detection models using machine learning (ML) and natural language processing (NLP) techniques. TuPy is formed by 10000 thousand unpublished annotated tweets collected in 2023.\nThis repository is organized as follows:\nroot.\n    ‚îú‚îÄ‚îÄ annotations   : classification given by annotators\n    ‚îú‚îÄ‚îÄ raw corpus    : dataset before‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/victoriadreis/TuPY_dataset_multilabel.","first_N":5,"first_N_keywords":["text-classification","crowdsourced","crowdsourced","monolingual","original"],"keywords_longer_than_N":true},
	{"name":"TuPY_dataset_binary","keyword":"portuguese","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/victoriadreis/TuPY_dataset_binary","creator_name":"Victoria Reis","creator_url":"https://huggingface.co/victoriadreis","description":"\n\t\n\t\t\n\t\tPortuguese Hate Speech Dataset (TuPy)\n\t\n\nThe Portuguese hate speech dataset (TuPy) is an annotated corpus designed to facilitate the development of advanced hate speech detection models using machine learning (ML) and natural language processing (NLP) techniques. TuPy is formed by 10000 thousand unpublished annotated tweets collected in 2023.\nThis repository is organized as follows:\nroot.\n    ‚îú‚îÄ‚îÄ annotations   : classification given by annotators\n    ‚îú‚îÄ‚îÄ raw corpus    : dataset before‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/victoriadreis/TuPY_dataset_binary.","first_N":5,"first_N_keywords":["text-classification","crowdsourced","crowdsourced","monolingual","original"],"keywords_longer_than_N":true},
	{"name":"TuPy-Dataset","keyword":"portuguese","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Silly-Machine/TuPy-Dataset","creator_name":"Silly-Machine","creator_url":"https://huggingface.co/Silly-Machine","description":"\n\t\n\t\t\n\t\tPortuguese Hate Speech Dataset (TuPy)\n\t\n\nThe Portuguese hate speech dataset (TuPy) is an annotated corpus designed to facilitate the development of advanced hate speech detection models using machine learning (ML) \nand natural language processing (NLP) techniques. TuPy is comprised of 10,000 (ten thousand) unpublished, annotated, and anonymized documents collected \non Twitter (currently known as X) in 2023. \nThis repository is organized as follows:\nroot.\n    ‚îú‚îÄ‚îÄ binary     : binary‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Silly-Machine/TuPy-Dataset.","first_N":5,"first_N_keywords":["text-classification","crowdsourced","Brazilian-Portuguese","monolingual","original"],"keywords_longer_than_N":true},
	{"name":"FAQ_BACEN","keyword":"portuguese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/paulofinardi/FAQ_BACEN","creator_name":"paulo","creator_url":"https://huggingface.co/paulofinardi","description":"This dataset was the used in the paper https://arxiv.org/abs/2311.11331\n\n\n\t\n\t\t\n\t\tlicense: apache-2.0\n\t\n\n","first_N":5,"first_N_keywords":["text-classification","question-answering","Portuguese","apache-2.0","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"FAQ_BACEN","keyword":"portuguese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Itau-Unibanco/FAQ_BACEN","creator_name":"Ita√∫-Unibanco","creator_url":"https://huggingface.co/Itau-Unibanco","description":"This dataset was used in the article: https://arxiv.org/abs/2311.11331\n","first_N":5,"first_N_keywords":["text-classification","question-answering","Portuguese","apache-2.0","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"TuPyE-Dataset","keyword":"portuguese","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Silly-Machine/TuPyE-Dataset","creator_name":"Silly-Machine","creator_url":"https://huggingface.co/Silly-Machine","description":"\n\t\n\t\t\n\t\tPortuguese Hate Speech Expanded Dataset (TuPyE)\n\t\n\nTuPyE, an enhanced iteration of TuPy, encompasses a compilation of 43,668 meticulously annotated documents specifically \nselected for the purpose of hate speech detection within diverse social network contexts. \nThis augmented dataset integrates supplementary annotations and amalgamates with datasets sourced from \nFortuna et al. (2019), \nLeite et al. (2020), \nand Vargas et al. (2022),\ncomplemented by an infusion of 10,000 original‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Silly-Machine/TuPyE-Dataset.","first_N":5,"first_N_keywords":["text-classification","crowdsourced","crowdsourced","monolingual","crowdsourced"],"keywords_longer_than_N":true},
	{"name":"prompt_injections","keyword":"portuguese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/yanismiraoui/prompt_injections","creator_name":"Yanis Miraoui","creator_url":"https://huggingface.co/yanismiraoui","description":"\n\t\n\t\t\n\t\tDataset Card for Prompt Injections by  Yanis Miraoui  üëã\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset of prompt injections enriches Large Language Models (LLMs) by providing task-specific examples and prompts, helping improve LLMs' performance and control their behavior.\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset contains over 1000 rows of prompt injections in multiple languages. It contains examples of prompt injections using different techniques such as: prompt leaking, jailbreaking‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/yanismiraoui/prompt_injections.","first_N":5,"first_N_keywords":["no-annotation","multilingual","original","English","French"],"keywords_longer_than_N":true},
	{"name":"oasst2_top1_chat_format","keyword":"portuguese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/blancsw/oasst2_top1_chat_format","creator_name":"Blanc Swan","creator_url":"https://huggingface.co/blancsw","description":"\n\t\n\t\t\n\t\tOpenAssistant TOP-1 Conversation Threads in huggingface chat format\n\t\n\nExport of oasst2 only top 1 threads in huggingface chat format\n\n\t\n\t\t\n\t\tScript\n\t\n\nThe convert script can be find here\n","first_N":5,"first_N_keywords":["English","Spanish","Russian","German","Polish"],"keywords_longer_than_N":true},
	{"name":"openassistant-deepseek-coder","keyword":"portuguese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Trelis/openassistant-deepseek-coder","creator_name":"Trelis","creator_url":"https://huggingface.co/Trelis","description":"\n\t\n\t\t\n\t\tChat Fine-tuning Dataset - OpenAssistant DeepSeek Coder\n\t\n\nThis dataset allows for fine-tuning chat models using:\nB_INST = '\\n### Instruction:\\n'\nE_INST = '\\n### Response:\\n'\nBOS = '<ÔΩúbegin‚ñÅof‚ñÅsentenceÔΩú>'\nEOS = '\\n<|EOT|>\\n'\n\nSample Preparation:\n\nThe dataset is cloned from TimDettmers, which itself is a subset of the Open Assistant dataset, which you can find here. This subset of the data only contains the highest-rated paths in the conversation tree, with a total of 9,846 samples.\nThe‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Trelis/openassistant-deepseek-coder.","first_N":5,"first_N_keywords":["English","Spanish","Russian","German","Polish"],"keywords_longer_than_N":true},
	{"name":"language_tags","keyword":"portuguese","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/lbourdois/language_tags","creator_name":"Lo√Øck BOURDOIS","creator_url":"https://huggingface.co/lbourdois","description":"\n\t\n\t\t\n\t\tDescription\n\t\n\nDataset listing 27,328 languages and dialects (also includes macrolanguage names).For each language, either the ISO 639 code, the Glottolog code or both are provided.\n\n\t\n\t\t\n\t\tColumns\n\t\n\n\nEnglish_Name: Language name in English (e.g. \"French\").\nNative_Name: If value is not 0, corresponds to the name of the language by native speakers (e.g. \"Fran√ßais\") which may have been found in Wikipedia's nativename field.\nGlottocode: The language tag in the Glottolog convention (e.g.‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/lbourdois/language_tags.","first_N":5,"first_N_keywords":["Afade","Par√° Ar√°ra","Afar","Aka-Bea","Abon"],"keywords_longer_than_N":true},
	{"name":"harem","keyword":"portuguese","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/arubenruben/harem","creator_name":"R√∫ben Almeida","creator_url":"https://huggingface.co/arubenruben","description":"\n\t\n\t\t\n\t\tDataset Card for HAREM\n\t\n\n\n\n\n\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\n\n\n\n\n\nCurated by: [More Information Needed]\nFunded by [optional]: [More Information Needed]\nShared by [optional]: [More Information Needed]\nLanguage(s) (NLP): pt\nLicense: cc-by-4.0\n\n\n\t\n\t\t\n\t\tDataset Sources [optional]\n\t\n\n\n\n\nRepository: [More Information Needed]\nPaper [optional]: [More Information Needed]\nDemo [optional]: [More Information Needed]\n\n\n\t\n\t\t\n\t\tUses\n\t\n\n\n\n\n\t\n\t\t\n\t\tDirect Use\n\t\n\n\n\n[More‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/arubenruben/harem.","first_N":5,"first_N_keywords":["token-classification","expert-generated","monolingual","Portuguese","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"aes_enem_dataset","keyword":"portuguese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/kamel-usp/aes_enem_dataset","creator_name":"KAMeL USP","creator_url":"https://huggingface.co/kamel-usp","description":"\n\t\n\t\t\n\t\tAutomated Essay Score (AES) ENEM Dataset\n\t\n\n\n\t\n\t\t\n\t\tUse Case and Creators\n\t\n\n\nIntended Use: Estimate Essay Score\nCreators: Igor Cataneo Silveira, Andr√© Barbosa and Denis Deratani Mau√°\nContact Information:  igorcs@ime.usp.br; andre.barbosa@ime.usp.br\n\n\n\t\n\t\t\n\t\tLicensing Information\n\t\n\n\nLicense: MIT License\n\n\n\t\n\t\t\n\t\tCitation Details\n\t\n\n\nPreferred Citation:\n\n@proceedings{DBLP:conf/propor/2024,\n  editor       = {Igor Cataneo Silveira, Andr√© Barbosa and Denis Deratani Mau√°},\n  title        =‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/kamel-usp/aes_enem_dataset.","first_N":5,"first_N_keywords":["text-classification","Portuguese","apache-2.0","1K - 10K","parquet"],"keywords_longer_than_N":true},
	{"name":"testedata","keyword":"portuguese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Nuno-Tome/testedata","creator_name":"Nuno Tome","creator_url":"https://huggingface.co/Nuno-Tome","description":"\n\t\n\t\t\n\t\tDataset Card for Dataset Name\n\t\n\n\n\nThis dataset aims to be a base template for new datasets and for testing code.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n2 image files in jpg format\n","first_N":5,"first_N_keywords":["Portuguese","English","apache-2.0","< 1K","imagefolder"],"keywords_longer_than_N":true},
	{"name":"udhr-lid","keyword":"portuguese","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/cis-lmu/udhr-lid","creator_name":"CIS, LMU Munich","creator_url":"https://huggingface.co/cis-lmu","description":"\n\t\n\t\t\n\t\tUDHR-LID\n\t\n\nWhy UDHR-LID?\nYou can access UDHR (Universal Declaration of Human Rights) here, but when a verse is missing, they have texts such as \"missing\" or \"?\". Also, about 1/3 of the sentences consist only of \"articles 1-30\" in different languages. We cleaned the entire dataset from XML files and selected only the paragraphs. We cleared any unrelated language texts from the data and also removed the cases that were incorrect.\nIncorrect? Look at the ckb and kmr files in the UDHR.‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/cis-lmu/udhr-lid.","first_N":5,"first_N_keywords":["multilingual","Tigrinya","Balkan Romani","Standard Arabic","Metlat√≥noc Mixtec"],"keywords_longer_than_N":true},
	{"name":"rebel_portuguese","keyword":"portuguese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/grsilva/rebel_portuguese","creator_name":"Gabriel Silva","creator_url":"https://huggingface.co/grsilva","description":"This is a dataset that was created to re-train REBEL to work better for the Portuguese language.\nThis dataset was generated using CROCODILE, which was adapted to use a Portuguese specific model (pt_core_news_sm) instead of their default multi-language model (xx_ent_wiki_sm).\nThe dataset comes with a train, test, dev and train_dev splits. The train_dev split accounts for 80% of the dataset with the remaining 20% being the training data. The train and dev split was generated from the 80%‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/grsilva/rebel_portuguese.","first_N":5,"first_N_keywords":["Portuguese","mit","1M - 10M","json","Text"],"keywords_longer_than_N":true},
	{"name":"seamless-align","keyword":"portuguese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/jhu-clsp/seamless-align","creator_name":"Center for Language and Speech Processing @ JHU","creator_url":"https://huggingface.co/jhu-clsp","description":"\n\t\n\t\t\n\t\tDataset Card for Seamless-Align (WIP). Inspired by https://huggingface.co/datasets/allenai/nllb\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset was created based on metadata for mined Speech-to-Speech(S2S), Text-to-Speech(TTS) and Speech-to-Text(S2T) released by Meta AI.  The S2S contains data for 35 language pairs. The S2S dataset is ~1000GB compressed.\n\n\t\n\t\t\n\t\tHow to use the data\n\t\n\nThere are two ways to access the data:\n\nVia the Hugging Face Python datasets library\n\nScripts coming soon‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/jhu-clsp/seamless-align.","first_N":5,"first_N_keywords":["translation","audio-to-audio","Maltese","English","Welsh"],"keywords_longer_than_N":true},
	{"name":"fakerecogna2-abstrativa","keyword":"portuguese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/recogna-nlp/fakerecogna2-abstrativa","creator_name":"Recogna NLP","creator_url":"https://huggingface.co/recogna-nlp","description":"\n\t\n\t\t\n\t\tFakeRecogna 2.0 - Abstractive\n\t\n\nFakeRecogna 2.0 presents the extension for the FakeRecogna dataset in the context of fake news detection. FakeRecogna includes real and fake news texts collected from online media and ten fact-checking sources in Brazil. An important aspect is the lack of relation between the real and fake news samples, i.e., they are not mutually related to each other to avoid intrinsic bias in the data.\n\n\t\n\t\t\n\t\tThe Dataset\n\t\n\nThe fake news collection was performed on‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/recogna-nlp/fakerecogna2-abstrativa.","first_N":5,"first_N_keywords":["text-classification","Portuguese","mit","10K - 100K","csv"],"keywords_longer_than_N":true},
	{"name":"fakerecogna2-abstrativa","keyword":"portuguese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/recogna-nlp/fakerecogna2-abstrativa","creator_name":"Recogna NLP","creator_url":"https://huggingface.co/recogna-nlp","description":"\n\t\n\t\t\n\t\tFakeRecogna 2.0 - Abstractive\n\t\n\nFakeRecogna 2.0 presents the extension for the FakeRecogna dataset in the context of fake news detection. FakeRecogna includes real and fake news texts collected from online media and ten fact-checking sources in Brazil. An important aspect is the lack of relation between the real and fake news samples, i.e., they are not mutually related to each other to avoid intrinsic bias in the data.\n\n\t\n\t\t\n\t\tThe Dataset\n\t\n\nThe fake news collection was performed on‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/recogna-nlp/fakerecogna2-abstrativa.","first_N":5,"first_N_keywords":["text-classification","Portuguese","mit","10K - 100K","csv"],"keywords_longer_than_N":true},
	{"name":"isaaa","keyword":"portuguese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/lz0kzs/isaaa","creator_name":"luiz","creator_url":"https://huggingface.co/lz0kzs","description":"lz0kzs/isaaa dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["Portuguese","apache-2.0","< 1K","soundfolder","Audio"],"keywords_longer_than_N":true},
	{"name":"openassistant-falcon","keyword":"portuguese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Trelis/openassistant-falcon","creator_name":"Trelis","creator_url":"https://huggingface.co/Trelis","description":"\n\t\n\t\t\n\t\tChat Fine-tuning Dataset - OpenAssistant Falcon\n\t\n\nThis dataset allows for fine-tuning chat models using '\\Human:' AND '\\nAssistant:' to wrap user messages.\nIt still uses <|endoftext|> as EOS and BOS token, as per Falcon.\nSample \nPreparation:\n\nThe dataset is cloned from TimDettmers, which itself is a subset of the Open Assistant dataset, which you can find here. This subset of the data only contains the highest-rated paths in the conversation tree, with a total of 9,846 samples.\nThe‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Trelis/openassistant-falcon.","first_N":5,"first_N_keywords":["English","Spanish","Russian","German","Polish"],"keywords_longer_than_N":true},
	{"name":"qa_hotel_dataset","keyword":"portuguese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/nova-sqoin/qa_hotel_dataset","creator_name":"nova","creator_url":"https://huggingface.co/nova-sqoin","description":"nova-sqoin/qa_hotel_dataset dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["question-answering","English","Portuguese","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"cnn_news_ptbr","keyword":"portuguese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/celsowm/cnn_news_ptbr","creator_name":"Celso F","creator_url":"https://huggingface.co/celsowm","description":"\n\t\n\t\t\n\t\tDataset Card for \"cnn_news_ptbr\"\n\t\n\nMore Information needed\n","first_N":5,"first_N_keywords":["text-classification","Portuguese","apache-2.0","1K - 10K","parquet"],"keywords_longer_than_N":true},
	{"name":"bbc_news_ptbr_summary","keyword":"portuguese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/celsowm/bbc_news_ptbr_summary","creator_name":"Celso F","creator_url":"https://huggingface.co/celsowm","description":"\n\t\n\t\t\n\t\tDataset Card for \"bbc_news_ptbr_summary\"\n\t\n\nMore Information needed\n","first_N":5,"first_N_keywords":["text-classification","summarization","Portuguese","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"adoro_cinema_filmes","keyword":"portuguese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/celsowm/adoro_cinema_filmes","creator_name":"Celso F","creator_url":"https://huggingface.co/celsowm","description":"\n\t\n\t\t\n\t\tDataset Card for \"adoro_cinema_filmes\"\n\t\n\nMore Information needed\n","first_N":5,"first_N_keywords":["text-classification","multi-label-classification","Portuguese","apache-2.0","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"CulturaY","keyword":"portuguese","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ontocord/CulturaY","creator_name":"Ontocord.AI","creator_url":"https://huggingface.co/ontocord","description":"\n\t\n\t\t\n\t\tCulturaY: A Large Cleaned Multilingual Dataset of 75 Languages\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nFrom the team that brought you CulturaX, we present CulturaY, another substantial multilingual dataset of 15TB (uncompressed)/3TB (zstd-compressed) that applies the same dataset cleaning methodology to the HPLT v1.1 dataset. \nPlease note that HPLT v1.2 has also been released and is an alternative verison with different cleaning methodolgies. \nThis data was used in part to train our SOTA‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ontocord/CulturaY.","first_N":5,"first_N_keywords":["text-generation","fill-mask","language-modeling","masked-language-modeling","no-annotation"],"keywords_longer_than_N":true},
	{"name":"Agricultura_regenerativa_Portugues_Portuguese","keyword":"portuguese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Solshine/Agricultura_regenerativa_Portugues_Portuguese","creator_name":"Caleb DeLeeuw","creator_url":"https://huggingface.co/Solshine","description":"Dados semissint√©ticos gerados por meio da biblioteca RAG contendo conhecimento de agricultura regenerativa de especialistas do dom√≠nio, conectados √† API ChatGPT4.\nUm conjunto de dados que detalha solu√ß√µes agr√≠colas regenerativas para problemas agr√≠colas comuns, em portugu√™s, com consci√™ncia cultural em rela√ß√£o √† Floresta Amaz√¥nica e √†s comunidades agr√≠colas brasileiras marginalizadas.\nSemi-synthetic data generated via RAG library containing regenerative farming knowledge from domain experts‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Solshine/Agricultura_regenerativa_Portugues_Portuguese.","first_N":5,"first_N_keywords":["Portuguese","mit","n<1K","üá∫üá∏ Region: US","biology"],"keywords_longer_than_N":true},
	{"name":"my_cool_dataset","keyword":"portuguese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/ricardo-lsantos/my_cool_dataset","creator_name":"Ricardo Lisboa Santos","creator_url":"https://huggingface.co/ricardo-lsantos","description":"ricardo-lsantos/my_cool_dataset dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["Portuguese","mit","< 1K","csv","Text"],"keywords_longer_than_N":true},
	{"name":"aya_dataset_pt","keyword":"portuguese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/botbotrobotics/aya_dataset_pt","creator_name":"BotBot","creator_url":"https://huggingface.co/botbotrobotics","description":"CohereForAI Aya Dataset filtrado para portugu√™s (PT).\nAya Dataset Summary\nThe Aya Dataset is a multilingual instruction fine-tuning dataset curated by an open-science community via Aya Annotation Platform from Cohere For AI. The dataset contains a total of 204k human-annotated prompt-completion pairs along with the demographics data of the annotators.\nThis dataset can be used to train, finetune, and evaluate multilingual LLMs.\nCurated by: Contributors of Aya Open Science Intiative.‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/botbotrobotics/aya_dataset_pt.","first_N":5,"first_N_keywords":["Portuguese","apache-2.0","1K - 10K","parquet","Text"],"keywords_longer_than_N":true},
	{"name":"aya_dataset_pt","keyword":"portuguese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/botbotrobotics/aya_dataset_pt","creator_name":"BotBot","creator_url":"https://huggingface.co/botbotrobotics","description":"CohereForAI Aya Dataset filtrado para portugu√™s (PT).\nAya Dataset Summary\nThe Aya Dataset is a multilingual instruction fine-tuning dataset curated by an open-science community via Aya Annotation Platform from Cohere For AI. The dataset contains a total of 204k human-annotated prompt-completion pairs along with the demographics data of the annotators.\nThis dataset can be used to train, finetune, and evaluate multilingual LLMs.\nCurated by: Contributors of Aya Open Science Intiative.‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/botbotrobotics/aya_dataset_pt.","first_N":5,"first_N_keywords":["Portuguese","apache-2.0","1K - 10K","parquet","Text"],"keywords_longer_than_N":true},
	{"name":"ChatML-aya_dataset","keyword":"portuguese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Felladrin/ChatML-aya_dataset","creator_name":"Victor Nogueira","creator_url":"https://huggingface.co/Felladrin","description":"CohereForAI/aya_dataset in ChatML format, ready to use in HuggingFace TRL's SFT Trainer.\nPython code used for conversion:\nfrom datasets import load_dataset\nfrom transformers import AutoTokenizer\n\ntokenizer = AutoTokenizer.from_pretrained(\"Felladrin/Llama-160M-Chat-v1\")\n\ndataset = load_dataset(\"CohereForAI/aya_dataset\", split=\"train\")\n\ndef format(columns):\n    messages = [\n        {\n            \"role\": \"user\",\n            \"content\": columns[\"inputs\"].strip(),\n        },\n        {‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Felladrin/ChatML-aya_dataset.","first_N":5,"first_N_keywords":["question-answering","text-generation","crowdsourced","expert-generated","crowdsourced"],"keywords_longer_than_N":true},
	{"name":"text_coordinates_regions","keyword":"portuguese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/yachay/text_coordinates_regions","creator_name":"Yachay AI","creator_url":"https://huggingface.co/yachay","description":"\n\t\n\t\t\n\t\tDataset Card for Multilingual Geo-Tagged Social Media Posts (by 123 world regions)\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThe \"Regions\" dataset is a multilingual corpus that encompasses textual data from the 123 most populated regions worldwide, with each region's data organized into separate .json files. This dataset consists of approximately 500,000 text samples, each paired with its geographic coordinates.\nKey Features:\n\nTextual Data: The dataset contains 500,000 text samples.‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/yachay/text_coordinates_regions.","first_N":5,"first_N_keywords":["feature-extraction","token-classification","text-classification","English","Chinese"],"keywords_longer_than_N":true},
	{"name":"CC-MAIN-2023-23","keyword":"portuguese","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/dominguesm/CC-MAIN-2023-23","creator_name":"Maicon Domingues","creator_url":"https://huggingface.co/dominguesm","description":"\n\t\n\t\t\n\t\tDataset Card for \"CC-MAIN-2023-23\"\n\t\n\nMore Information needed\n","first_N":5,"first_N_keywords":["text-generation","fill-mask","Portuguese","cc-by-4.0","10M - 100M"],"keywords_longer_than_N":true},
	{"name":"pira","keyword":"portuguese","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/paulopirozelli/pira","creator_name":"Paulo Pirozelli","creator_url":"https://huggingface.co/paulopirozelli","description":"\n\t\n\t\t\n\t\tPir√°: A Bilingual Portuguese-English Dataset for Question-Answering about the Ocean, the Brazilian coast, and climate change\n\t\n\nPir√° is a crowdsourced reading comprehension dataset on the ocean, the Brazilian coast, and climate change. \nQA sets are presented in both Portuguese and English, together with their corresponding textual context.\nThe dataset also contains human and automatic paraphrases for questions and answers, as well as a number of qualitative assessments. \nThe original‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/paulopirozelli/pira.","first_N":5,"first_N_keywords":["question-answering","Portuguese","English","cc-by-4.0","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"gpt4all-j-prompt-generations-pt","keyword":"portuguese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/pablo-moreira/gpt4all-j-prompt-generations-pt","creator_name":"Pablo Filetti Moreira","creator_url":"https://huggingface.co/pablo-moreira","description":"\n\t\n\t\t\n\t\tDataset Card for \"gpt4all-j-prompt-generations-pt\"\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nCopy translated into Portuguese of the dataset gpt4all_prompt_generations using the googletrans library.\n\n\t\n\t\t\n\t\tTranslate\n\t\n\ntranslate_dataset.ipynb\n\n\t\n\t\t\n\t\tUsage\n\t\n\ndataset_usage.ipynb\n","first_N":5,"first_N_keywords":["text-generation","Portuguese","apache-2.0","100K - 1M","parquet"],"keywords_longer_than_N":true},
	{"name":"openassistant-guanaco-EOS","keyword":"portuguese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Trelis/openassistant-guanaco-EOS","creator_name":"Trelis","creator_url":"https://huggingface.co/Trelis","description":"\n\t\n\t\t\n\t\tChat Fine-tuning Dataset - Guanaco Style\n\t\n\nThis dataset allows for fine-tuning chat models using \"### Human:\" AND \"### Assistant\" as the beginning and end of sequence tokens.\nPreparation:\n\nThe dataset is cloned from TimDettmers, which itself is a subset of the Open Assistant dataset, which you can find here. This subset of the data only contains the highest-rated paths in the conversation tree, with a total of 9,846 samples.\nThe dataset was then slightly adjusted to:\n\n\nif a row of‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Trelis/openassistant-guanaco-EOS.","first_N":5,"first_N_keywords":["English","Spanish","Russian","German","Polish"],"keywords_longer_than_N":true},
	{"name":"openassistant-llama-style","keyword":"portuguese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Trelis/openassistant-llama-style","creator_name":"Trelis","creator_url":"https://huggingface.co/Trelis","description":"\n\t\n\t\t\n\t\tChat Fine-tuning Dataset - Llama 2 Style\n\t\n\nThis dataset allows for fine-tuning chat models using [INST] AND [/INST] to wrap user messages.\nPreparation:\n\nThe dataset is cloned from TimDettmers, which itself is a subset of the Open Assistant dataset, which you can find here. This subset of the data only contains the highest-rated paths in the conversation tree, with a total of 9,846 samples.\nThe dataset was then filtered to:\n\n\nreplace instances of '### Human:' with '[INST]'\nreplace‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Trelis/openassistant-llama-style.","first_N":5,"first_N_keywords":["English","Spanish","Russian","German","Polish"],"keywords_longer_than_N":true},
	{"name":"aya_collection_language_split","keyword":"portuguese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/CohereLabs/aya_collection_language_split","creator_name":"Cohere Labs","creator_url":"https://huggingface.co/CohereLabs","description":"\nThis is a re-upload of the aya_collection, and only differs in the structure of upload. While the original aya_collection is structured by folders split according to dataset name, this dataset is split by language. We recommend you use this version of the dataset if you are only interested in downloading all of the Aya collection for a single or smaller set of languages.\n\n\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThe Aya Collection is a massive multilingual collection consisting of 513 million instances of‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/CohereLabs/aya_collection_language_split.","first_N":5,"first_N_keywords":["Achinese","Afrikaans","Amharic","Arabic","Azerbaijani"],"keywords_longer_than_N":true},
	{"name":"Cabra3k","keyword":"portuguese","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/botbotrobotics/Cabra3k","creator_name":"BotBot","creator_url":"https://huggingface.co/botbotrobotics","description":"O conjunto de dados Cabra √© uma cole√ß√£o ampla e diversificada de 3.000 entradas ou conjuntos de perguntas e respostas (QA) sobre o Brasil. Inclui t√≥picos variados como hist√≥ria, pol√≠tica, geografia, cultura, cinema, esportes, ci√™ncia e tecnologia, governo e muito mais. Este conjunto foi cuidadosamente elaborado e selecionado pela nossa equipe, garantindo alta qualidade e relev√¢ncia para estudos e aplica√ß√µes relacionadas ao Brasil.\nDetalhes do Conjunto de Dados:\nTamanho: 3.000 conjuntos de QA‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/botbotrobotics/Cabra3k.","first_N":5,"first_N_keywords":["Portuguese","cc-by-sa-4.0","1K - 10K","json","Text"],"keywords_longer_than_N":true},
	{"name":"tokenizer-wiki-bench","keyword":"portuguese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/occiglot/tokenizer-wiki-bench","creator_name":"Occiglot","creator_url":"https://huggingface.co/occiglot","description":"\n\t\n\t\t\n\t\tMultilingual Tokenizer Benchmark\n\t\n\nThis dataset includes pre-processed wikipedia data for tokenizer evaluation in 45 languages. We provide more information on the evaluation task in general this blogpost.\n\n\t\n\t\t\n\t\tUsage\n\t\n\nThe dataset allows us to easily calculate tokenizer fertility and the proportion of continued words on any of the supported languages. In the example below we take the Mistral tokenizer and evaluate its performance on Slovak. \nfrom transformers import AutoTokenizer‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/occiglot/tokenizer-wiki-bench.","first_N":5,"first_N_keywords":["Afrikaans","Arabic","Bulgarian","Catalan","Czech"],"keywords_longer_than_N":true},
	{"name":"Publico","keyword":"portuguese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/hugosousa/Publico","creator_name":"Hugo Sousa","creator_url":"https://huggingface.co/hugosousa","description":"\n\t\n\t\t\n\t\tP√∫blico\n\t\n\nThis dataset was build by translating a set of 34,157 news from P√∫blico, an European Portuguese news paper. The news have been translated using Google Translator.\nTo now more about the data visit the Github repos used to scrape and translate the news.\n","first_N":5,"first_N_keywords":["Portuguese","English","German","French","Spanish"],"keywords_longer_than_N":true},
	{"name":"Puntuguese","keyword":"portuguese","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Superar/Puntuguese","creator_name":"Marcio Lima In√°cio","creator_url":"https://huggingface.co/Superar","description":"\n\t\n\t\t\n\t\tPuntuguese - A Corpus of Puns in Portuguese with Micro-editions\n\t\n\nPuntuguese is a corpus of Portuguese punning texts, including Brazilian and European Portuguese jokes. The data has been manually gathered and curated according to our guidelines. It also contains some layers of annotation:\n\nEvery pun is classified as homophonic, homographic, both, or none according to their specific punning signs;\nThe punning and alternative signs were made explicit for every joke;\nWe also mark‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Superar/Puntuguese.","first_N":5,"first_N_keywords":["text-classification","token-classification","Portuguese","cc-by-sa-4.0","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"stopwords-pt","keyword":"portuguese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/AiresPucrs/stopwords-pt","creator_name":"AI Robotics Ethics Society (PUCRS)","creator_url":"https://huggingface.co/AiresPucrs","description":"\n\t\n\t\t\n\t\tStopwords PT (Teeny-Tiny Castle)\n\t\n\nThis dataset is part of a tutorial tied to the Teeny-Tiny Castle, an open-source repository containing¬†educational tools for AI Ethics and Safety research. \n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nfrom datasets import load_dataset\n\ndataset = load_dataset(\"AiresPucrs/stopwords-pt\", split = 'train')\n\n","first_N":5,"first_N_keywords":["text-classification","Portuguese","apache-2.0","< 1K","parquet"],"keywords_longer_than_N":true},
	{"name":"panlex-meanings","keyword":"portuguese","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/cointegrated/panlex-meanings","creator_name":"David Dale","creator_url":"https://huggingface.co/cointegrated","description":"\n\t\n\t\t\n\t\tDataset Card for panlex-meanings\n\t\n\nThis is a dataset of words in several thousand languages, extracted from https://panlex.org.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset has been extracted from https://panlex.org (the 20240301 database dump) and rearranged on the per-language basis.\nEach language subset consists of expressions (words and phrases). \nEach expression is associated with some meanings (if there is more than one meaning, they are in separate‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/cointegrated/panlex-meanings.","first_N":5,"first_N_keywords":["translation","Afar","Western Abnaki","Abkhazian","Abaza"],"keywords_longer_than_N":true},
	{"name":"bbrc_brazilian_banking_regulation_corpora","keyword":"portuguese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/bancodobrasil/bbrc_brazilian_banking_regulation_corpora","creator_name":"Banco do Brasil S.A.","creator_url":"https://huggingface.co/bancodobrasil","description":"We present BBRC, a collection of 25 corpus of banking regulatory risk from different departments of Banco do Brasil (BB). These are individual corpus about investments, insurance, human resources, security, technology, treasury, loans, accounting, fraud, credit cards, payment methods, agribusiness, risks, etc. They were annotated in binary form by experts indicating whether each regulatory document contains regulatory risk that may require changes to products, processes, services, and channels‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/bancodobrasil/bbrc_brazilian_banking_regulation_corpora.","first_N":5,"first_N_keywords":["Portuguese","mit","üá∫üá∏ Region: US"],"keywords_longer_than_N":false},
	{"name":"COVID19BR","keyword":"portuguese","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ju-resplande/COVID19BR","creator_name":"Juliana Resplande","creator_url":"https://huggingface.co/ju-resplande","description":"\n\t\n\t\t\n\t\tCOVID19.Br\n\t\n\nA Dataset of Misinformation about COVID-19 in Brazilian Portuguese WhatsApp Messages\n\nRepository:\nhttps://zenodo.org/records/5193932 \nhttps://github.com/cabrau/FakeWhatsApp.Br\n\n\nPaper:\nhttps://sol.sbc.org.br/index.php/dsw/article/view/17422/17258 \nhttps://sol.sbc.org.br/index.php/sbbd/article/view/17868/17702\nMaster's thesis (in Portuguese): https://repositorio.ufc.br/handle/riufc/63379\n\n\n\n\n\t\t\n\t\tCitation Information\n\t\n\n@inproceedings{dsw,\n author = {Ant√¥nio Diogo Martins‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ju-resplande/COVID19BR.","first_N":5,"first_N_keywords":["text-classification","Portuguese","cc-by-4.0","1K - 10K","parquet"],"keywords_longer_than_N":true},
	{"name":"TCC","keyword":"portuguese","license":"Academic Free License v3.0","license_url":"https://choosealicense.com/licenses/afl-3.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Kashmir96/TCC","creator_name":"Thierry Braga","creator_url":"https://huggingface.co/Kashmir96","description":"Kashmir96/TCC dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["Portuguese","afl-3.0","Audio","üá∫üá∏ Region: US"],"keywords_longer_than_N":false},
	{"name":"instruct-aira-dataset-v3","keyword":"portuguese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/nicholasKluge/instruct-aira-dataset-v3","creator_name":"Nicholas Kluge Corr√™a","creator_url":"https://huggingface.co/nicholasKluge","description":"\n\t\n\t\t\n\t\tInstruct-Aira Dataset version 3.0\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset contains a collection of multi-turn conversations between an assistant and a user. Conversations were generated by user interactions with already-tuned models (ChatGPT, LLama 2, Open-Assistant, etc). The dataset is available in Portuguese and English.\n\n\t\n\t\t\n\t\tSupported Tasks and Leaderboards\n\t\n\nThis dataset can be utilized for various natural language processing tasks, including but not limited to:\n\nLanguage‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/nicholasKluge/instruct-aira-dataset-v3.","first_N":5,"first_N_keywords":["text-generation","Portuguese","English","apache-2.0","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"oaast_rm_full_jieba","keyword":"portuguese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/lenML/oaast_rm_full_jieba","creator_name":"len","creator_url":"https://huggingface.co/lenML","description":"Â∞ùËØïËß£ÂÜ≥\"llm repetition problem\"Ôºå‰ΩøÁî®ÂàÜËØçÊ®°ÂûãÂØπoaastËØ≠ÊñôËøõË°å‚ÄúÁªìÂ∑¥Âåñ‚ÄùÊï∞ÊçÆÂ¢ûÂº∫ÔºåÊèê‰æõÊõ¥Âº∫ÁöÑÈáçÂ§çÂÜÖÂÆπÊãíÁªùÊïàÊûú„ÄÇ\nAttempts to solve the \"llm repetition problem\" by using a segmentation model to enhance the oaast corpus with \"stuttering\" data to provide stronger rejection of duplicate content.\nÂÖ∂Ê¨°ÔºåËøòËøáÊª§Êéâ‰∫ÜÊâÄÊúâËá™ÊàëËÆ§Áü•ÁöÑÂæÆË∞ÉÊ†∑Êú¨„ÄÇ\nSecond, it also filters out all the fine-tuned samples of self-cognition.\nfiles:\n\noaast_rm_full_jieba.jsonl : word level repeat\noaast_rm_full_sent_jieba.jsonl : sentence level repeat\n\n","first_N":5,"first_N_keywords":["English","Spanish","Russian","German","Polish"],"keywords_longer_than_N":true},
	{"name":"YouTube-Commons-descriptions","keyword":"portuguese","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Rijgersberg/YouTube-Commons-descriptions","creator_name":"Edwin Rijgersberg","creator_url":"https://huggingface.co/Rijgersberg","description":"\n\t\n\t\t\n\t\tYouTube Commons Descriptions and Language Detection\n\t\n\nThis dataset adds titles, descriptions and language detection to YouTube Commons, a valuable open dataset:\n\nYouTube-Commons is a collection of audio transcripts of 2,063,066 videos shared on YouTube under a CC BY 4.0 license.\nContent\nThe collection comprises 22,709,724 original and automatically translated transcripts from 3,156,703 videos (721,136 individual channels).\n\nUnfortunately I have found that the detection of the original‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Rijgersberg/YouTube-Commons-descriptions.","first_N":5,"first_N_keywords":["English","French","Spanish","Portuguese","German"],"keywords_longer_than_N":true},
	{"name":"brwac","keyword":"portuguese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/bfunicheli/brwac","creator_name":"Funicheli","creator_url":"https://huggingface.co/bfunicheli","description":"\n\n\t\n\t\t\n\t\tDataset Card for BrWaC\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThe BrWaC (Brazilian Portuguese Web as Corpus) is a large corpus constructed following the Wacky framework, \nwhich was made public for research purposes. The current corpus version, released in January 2017, is composed by \n3.53 million documents, 2.68 billion tokens and 5.79 million types. Please note that this resource is available \nsolely for academic research purposes, and you agreed not to use it for any commercial‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/bfunicheli/brwac.","first_N":5,"first_N_keywords":["text-generation","fill-mask","language-modeling","masked-language-modeling","no-annotation"],"keywords_longer_than_N":true},
	{"name":"BoundingDocs","keyword":"portuguese","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/letxbe/BoundingDocs","creator_name":"Letxbe","creator_url":"https://huggingface.co/letxbe","description":"\n\nBoundingDocs\n\nüîç The largest spatially-annotated dataset for Document Question Answering\n\n\n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Description\n\t\n\nBoundingDocs is a unified dataset for Document Question Answering (QA) that includes spatial annotations. It consolidates multiple public datasets from Document AI and Visually Rich Document Understanding (VRDU) domains. The dataset reformulates Information Extraction (IE) tasks into QA tasks, making it a valuable resource for training and evaluating Large Language‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/letxbe/BoundingDocs.","first_N":5,"first_N_keywords":["question-answering","visual-question-answering","English","Italian","Spanish"],"keywords_longer_than_N":true},
	{"name":"LegalSumm","keyword":"portuguese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/MartimZanatti/LegalSumm","creator_name":"Martim Zanatti dos Santos Gomes da Silva","creator_url":"https://huggingface.co/MartimZanatti","description":"\n\t\n\t\t\n\t\tAnotated Dataset of Summaries of the Supreme Court of Justice of Portugal\n\t\n\nThis dataset contains 68 summaries of 12 judgments STJ annotated in several dimensions by legal experts. \n\n10 summaries are the summaries written by the judges themselves.\n29 summaries are extractive summaries generated by LexRank technique.\n30 summaries are abstractive summaries generated by Llamma LLM.\n\n\n\t\n\t\t\n\t\tDataset Content:\n\t\n\nCase information\n\nJudgment Name\n\nId of judgment\n\n\nReport Section\n\nJudgment‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/MartimZanatti/LegalSumm.","first_N":5,"first_N_keywords":["text-classification","Portuguese","mit","< 1K","csv"],"keywords_longer_than_N":true},
	{"name":"zenith_ai_305","keyword":"portuguese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/alvemoans/zenith_ai_305","creator_name":"moans alvs","creator_url":"https://huggingface.co/alvemoans","description":"\n\t\n\t\t\n\t\tLegal Data Analysis Dataset\n\t\n\nThis dataset contains legal statements, analyses, and judgments primarily related to labor law and contract law, drawn from various cases and legal interpretations. It includes text entries with factual descriptions, legal arguments, and conclusions based on judicial decisions, as well as instructions related to interpreting those facts.\n\n\t\n\t\t\n\t\tDataset Overview\n\t\n\nThe dataset is structured as a series of legal paragraphs and corresponding instructions‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/alvemoans/zenith_ai_305.","first_N":5,"first_N_keywords":["text-generation","Portuguese","apache-2.0","< 1K","json"],"keywords_longer_than_N":true},
	{"name":"high-quality-multilingual-sentences","keyword":"portuguese","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/agentlans/high-quality-multilingual-sentences","creator_name":"Alan Tseng","creator_url":"https://huggingface.co/agentlans","description":"\n\t\n\t\t\n\t\tHigh Quality Multilingual Sentences\n\t\n\n\nThis dataset contains multilingual sentences derived from the agentlans/LinguaNova dataset.\nIt includes 1.58 million rows across 51 different languages, each in its own configuration.\n\nExample row (from the all config):\n{\n    \"text\": \"ÿßŸÖÿßŸÖ ÿ¨ŸÖÿπŸá ÿßÿµŸÅŸáÿßŸÜ ⁄ØŸÅÿ™: ŸÖ€åÿ≤ÿßŸÜ ŸÜ€åÿßÿ≤ ÿ¢ÿ® ÿ¥ÿ±ÿ® ÿßÿµŸÅŸáÿßŸÜ €±€±.€µ ŸÖÿ™ÿ± ŸÖ⁄©ÿπÿ® ÿßÿ≥ÿ™ ⁄©Ÿá ÿ™ŸÖÿßŸÖ ÿßÿ≥ÿ™ÿßŸÜ ÿßÿµŸÅŸáÿßŸÜ ÿ±ÿß ŸæŸàÿ¥ÿ¥ ŸÖ€åÿØŸáÿØ Ÿà ŸÜÿ≥ÿ®ÿ™ ÿ®Ÿá ŸÇÿ®ŸÑ ÿßÿ≤ ÿßŸÜŸÇŸÑÿßÿ® €å⁄©€å ÿßÿ≤ Ÿæ€åÿ¥ÿ±ŸÅÿ™Ÿáÿß ÿØÿ± ÿ≠Ÿàÿ≤Ÿá ÿ¢ÿ® ÿ®ŸàÿØŸá ÿßÿ≥ÿ™.\",\n    \"fasttext\": \"fa\",\n    \"gcld3\": \"fa\"\n}\n\nFields:‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/agentlans/high-quality-multilingual-sentences.","first_N":5,"first_N_keywords":["text-generation","text-classification","text-retrieval","multilingual","Arabic"],"keywords_longer_than_N":true},
	{"name":"bfc-test","keyword":"portuguese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/AugustoSavi/bfc-test","creator_name":"Augusto Savi","creator_url":"https://huggingface.co/AugustoSavi","description":"\n\t\n\t\t\n\t\tDataset de Exemplos para BFC-Script\n\t\n\nEste dataset cont√©m exemplos pr√°ticos de uso da linguagem bfc-script, organizados em pares de prompt e completion. Ele foi criado para ajudar desenvolvedores a entender e utilizar a linguagem em diversos cen√°rios, desde opera√ß√µes b√°sicas at√© funcionalidades mais avan√ßadas.\n\n\t\n\t\t\n\t\tEstrutura do Dataset\n\t\n\nO dataset est√° no formato JSONL (JSON Lines), onde cada linha √© um objeto JSON com dois campos:\n\nprompt: Uma pergunta ou descri√ß√£o de um cen√°rio‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/AugustoSavi/bfc-test.","first_N":5,"first_N_keywords":["text-generation","Portuguese","mit","< 1K","json"],"keywords_longer_than_N":true},
	{"name":"AIME2025-Multilingual","keyword":"portuguese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/fedric95/AIME2025-Multilingual","creator_name":"Federico Ricciuti","creator_url":"https://huggingface.co/fedric95","description":"\n\t\n\t\t\n\t\tDescription\n\t\n\nThis repository contains a multi language version of the AIME2025 dataset. \nAs the english reference version, we haved used the one created by the authors of MathArena.\nFor completness, we have included the english version also in this repository, please, refer to the one contained in the MathArena github repository for the original one (https://github.com/eth-sri/matharena/tree/main/data/aime). Many thanks to Jasper Dekoninck for the help in understanding the structure‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/fedric95/AIME2025-Multilingual.","first_N":5,"first_N_keywords":["German","English","Italian","Portuguese","French"],"keywords_longer_than_N":true},
	{"name":"realtor-conversational-portuguese_br","keyword":"portuguese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/bobboyms/realtor-conversational-portuguese_br","creator_name":"Thiago Luiz Rodrigues","creator_url":"https://huggingface.co/bobboyms","description":"\n\t\n\t\t\n\t\tRealtor Conversational (Portuguese BR) - Realtor-Client Conversation Dataset\n\t\n\n\n\t\n\t\t\n\t\tDetailed Dataset Description\n\t\n\nIntroduction:\nThis dataset, named \"Realtor Conversational (Portuguese BR)\", offers rich and detailed simulations of conversational interactions between real estate agents (realtors) and clients in Brazil. Generated using the advanced language model gpt-4o-mini, the data is synthetic but designed to mirror the dynamics, vocabulary, and common scenarios found in the‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/bobboyms/realtor-conversational-portuguese_br.","first_N":5,"first_N_keywords":["text-generation","Portuguese","apache-2.0","1K<n<10K","üá∫üá∏ Region: US"],"keywords_longer_than_N":false},
	{"name":"portuguese-classic-books-adapted-to-modern-portuguese-br","keyword":"portuguese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/bobboyms/portuguese-classic-books-adapted-to-modern-portuguese-br","creator_name":"Thiago Luiz Rodrigues","creator_url":"https://huggingface.co/bobboyms","description":"Okay, here is the improved and expanded text translated into American English, including the corrected citation format.\n\n\n\t\n\t\t\n\t\tClassic Portuguese Language Books Adapted to Modern Brazilian Portuguese\n\t\n\n\n\t\n\t\t\n\t\tDetailed Dataset Description\n\t\n\nThis dataset presents a unique collection of texts derived from classic books of Portuguese language literature, with a strong representation of Brazilian authors. All selected works are in the public domain and were originally sourced from Project‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/bobboyms/portuguese-classic-books-adapted-to-modern-portuguese-br.","first_N":5,"first_N_keywords":["text-generation","Portuguese","apache-2.0","1K<n<10K","Text"],"keywords_longer_than_N":true},
	{"name":"Phonemized-UD","keyword":"portuguese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/suchirsalhan/Phonemized-UD","creator_name":"Suchir Salhan","creator_url":"https://huggingface.co/suchirsalhan","description":"\n\t\n\t\t\n\t\tPhoneme-UD: A Multilingual Phonemized Universal Dependencies Corpus for 34+ Languages\n\t\n\n\n\t\n\t\t\n\t\tG2P+ Phonemizer\n\t\n\nWe use G2P+ to phonemize Universal Dependencies. Here is an example usage: \n# Install required packages\n!apt-get install -y espeak-ng\n!pip install phonemizer g2p-plus\n# Set the environment variable from Python\nimport os\nos.environ[\"PHONEMIZER_ESPEAK_LIBRARY\"] = \"/usr/lib/x86_64-linux-gnu/libespeak-ng.so.1\"\n\n# Now run your transcription\nfrom g2p_plus import‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/suchirsalhan/Phonemized-UD.","first_N":5,"first_N_keywords":["Afrikaans","Amharic","Arabic","Azerbaijani","Catalan"],"keywords_longer_than_N":true},
	{"name":"world-languages-dataset","keyword":"portuguese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/SivaMallikarjun/world-languages-dataset","creator_name":"Parvatham Siva Mallikarjun","creator_url":"https://huggingface.co/SivaMallikarjun","description":"\n\t\n\t\t\n\t\tüåç World Languages Dataset\n\t\n\nThis dataset contains a list of official and unofficial languages categorized by language families...\n","first_N":5,"first_N_keywords":["text-classification","language-identification","expert-generated","multilingual","original"],"keywords_longer_than_N":true},
	{"name":"historinhas","keyword":"portuguese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Boakpe/historinhas","creator_name":"Breno","creator_url":"https://huggingface.co/Boakpe","description":"\"Historinhas\" √© um dataset em portugu√™s inspirado no TinyStories, desenvolvido para demonstrar que modelos de linguagem de menor escala podem gerar textos coerentes quando treinados em dados simplificados e de alta qualidade.\nEste conjunto de dados cont√©m hist√≥rias curtas e simples em portugu√™s, projetadas para serem compreens√≠veis e adequadas para treinar modelos menores que ainda possam produzir narrativas coerentes e fluidas.\n","first_N":5,"first_N_keywords":["text-generation","feature-extraction","zero-shot-classification","Portuguese","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"agua_e_esgoto_nordeste_brasileiro","keyword":"portuguese","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carpenterbb/agua_e_esgoto_nordeste_brasileiro","creator_name":"carpenter","creator_url":"https://huggingface.co/carpenterbb","description":"\n\t\n\t\t\n\t\tBrazilian Northeast Water and Sanitation Crisis Dataset (BNWSC)\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset provides multidisciplinary data on water access, sanitation, public health, and socioeconomic disparities in Brazil's Northeast region. It integrates official sources (2014‚Äì2022) and includes projections up to 2030, supporting research in public policy, collective health, and sustainability.\n\n\n\t\n\t\t\n\t\tKey Features\n\t\n\n\n\t\n\t\t\n\t\tApplications\n\t\n\n\nCorrelation analysis between sanitation, income‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carpenterbb/agua_e_esgoto_nordeste_brasileiro.","first_N":5,"first_N_keywords":["Portuguese","cc-by-4.0","1K - 10K","csv","Tabular"],"keywords_longer_than_N":true},
	{"name":"hotel_dataset_llama2","keyword":"portuguese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/nova-sqoin/hotel_dataset_llama2","creator_name":"nova","creator_url":"https://huggingface.co/nova-sqoin","description":"nova-sqoin/hotel_dataset_llama2 dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["Portuguese","English","apache-2.0","< 1K","json"],"keywords_longer_than_N":true},
	{"name":"mapa-eur-lex","keyword":"portuguese","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/dglover1/mapa-eur-lex","creator_name":"D Glover","creator_url":"https://huggingface.co/dglover1","description":"\n\t\n\t\t\n\t\tDataset Card for Multilingual European Datasets for Sensitive Entity Detection in the Legal Domain\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset is a completed version of the MAPA EUR-LEX dataset, originally converted to Huggingface format by joelniklaus. See the dataset card for more information about MAPA.\n3 of the (Spanish) EUR-LEX WebAnno TSV files in the source MAPA repository are malformed, so they were omitted from the original conversion, causing under-representation of the‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/dglover1/mapa-eur-lex.","first_N":5,"first_N_keywords":["token-classification","named-entity-recognition","other","found","multilingual"],"keywords_longer_than_N":true},
	{"name":"lr-sum","keyword":"portuguese","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/bltlab/lr-sum","creator_name":"Broadening Linguistic Technologies Lab (BLT Lab)","creator_url":"https://huggingface.co/bltlab","description":"\n\t\n\t\t\n\t\tDataset Card for LR-Sum\n\t\n\nLR-Sum is a automatic summarization dataset of newswire text with a focus on less resourced languages with a cc-by 4.0 license.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nLR-Sum is a permissively-licensed dataset created with the goal of enabling further research in automatic summarization for less-resourced languages.\nLR-Sum contains human-written summaries for 39 languages, many of which are less-resourced. \nThe data is based on the‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/bltlab/lr-sum.","first_N":5,"first_N_keywords":["summarization","text-generation","found","found","multilingual"],"keywords_longer_than_N":true},
	{"name":"sentiment-analysis-pt","keyword":"portuguese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/AiresPucrs/sentiment-analysis-pt","creator_name":"AI Robotics Ethics Society (PUCRS)","creator_url":"https://huggingface.co/AiresPucrs","description":"\n\t\n\t\t\n\t\tSentiment Analysis PT (Teeny-Tiny Castle)\n\t\n\nThis dataset is part of a tutorial tied to the Teeny-Tiny Castle, an open-source repository containing¬†educational tools for AI Ethics and Safety research. \n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nfrom datasets import load_dataset\n\ndataset = load_dataset(\"AiresPucrs/sentiment-analysis-pt\", split = 'train')\n\n","first_N":5,"first_N_keywords":["text-classification","Portuguese","apache-2.0","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"hotel_dataset","keyword":"portuguese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/nova-sqoin/hotel_dataset","creator_name":"nova","creator_url":"https://huggingface.co/nova-sqoin","description":"nova-sqoin/hotel_dataset dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["Portuguese","English","apache-2.0","< 1K","json"],"keywords_longer_than_N":true},
	{"name":"cabrita-guanaco-dataset-52k","keyword":"portuguese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/f7lipe/cabrita-guanaco-dataset-52k","creator_name":"FIlipe Correia","creator_url":"https://huggingface.co/f7lipe","description":"f7lipe/cabrita-guanaco-dataset-52k dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["Portuguese","apache-2.0","10K - 100K","parquet","Text"],"keywords_longer_than_N":true},
	{"name":"GPT4-500k-Augmented-PTBR-Clean","keyword":"portuguese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/cnmoro/GPT4-500k-Augmented-PTBR-Clean","creator_name":"Carlo Moro","creator_url":"https://huggingface.co/cnmoro","description":"A translated version of Open-Orca/1million-gpt-4 to portuguese.\nInstructions and responses with non-latin characters have been removed, as well as coding-related tasks.\n","first_N":5,"first_N_keywords":["text-generation","Portuguese","mit","100K - 1M","parquet"],"keywords_longer_than_N":true},
	{"name":"megawika-report-generation","keyword":"portuguese","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/hltcoe/megawika-report-generation","creator_name":"JHU Human Language Technology Center of Excellence","creator_url":"https://huggingface.co/hltcoe","description":"\n\t\n\t\t\n\t\tDataset Card for MegaWika for Report Generation\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nMegaWika is a multi- and crosslingual text dataset containing 30 million Wikipedia passages with their scraped and cleaned web citations. The passages span\n50 Wikipedias in 50 languages, and the articles in which the passages were originally embedded are included for convenience. Where a Wikipedia passage is in a\nnon-English language, an automated English translation is provided. \nThis dataset provides the‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/hltcoe/megawika-report-generation.","first_N":5,"first_N_keywords":["summarization","text-retrieval","text-generation","Afrikaans","Arabic"],"keywords_longer_than_N":true},
	{"name":"language-dataset","keyword":"portuguese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neon-mao/language-dataset","creator_name":"maoqifan","creator_url":"https://huggingface.co/neon-mao","description":"\n","first_N":5,"first_N_keywords":["text-classification","English","Chinese","French","Russian"],"keywords_longer_than_N":true},
	{"name":"instruct-aira-dataset-v2","keyword":"portuguese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/nicholasKluge/instruct-aira-dataset-v2","creator_name":"Nicholas Kluge Corr√™a","creator_url":"https://huggingface.co/nicholasKluge","description":"\n\t\n\t\t\n\t\tInstruct-Aira Dataset version 2.0\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset contains a collection of single-turn conversations between an assistant and a user. Conversations were generated by user interactions with already-tuned models (ChatGPT, LLama 2, Open-Assistant, etc). The dataset is available in Portuguese and English.\n\n\t\n\t\t\n\t\tSupported Tasks and Leaderboards\n\t\n\nThis dataset can be utilized for various natural language processing tasks, including but not limited to:\n\nLanguage‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/nicholasKluge/instruct-aira-dataset-v2.","first_N":5,"first_N_keywords":["text-generation","Portuguese","English","apache-2.0","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"MuMiN-PT","keyword":"portuguese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/ju-resplande/MuMiN-PT","creator_name":"Juliana Resplande","creator_url":"https://huggingface.co/ju-resplande","description":"\n\t\n\t\t\n\t\tMuMIN-PT\n\t\n\nMuMIN Portuguese Baseline subset extracted using Lingua.\n\nHomepage: https://mumin-dataset.github.io/\nRepository: https://github.com/MuMiN-dataset/mumin-baseline\nPaper:  https://arxiv.org/abs/2202.11684\nLeaderboard: \nPoint of Contact:\n\n\n\t\n\t\t\n\t\n\t\n\t\tCitation Information\n\t\n\n@inproceedings{10.1145/3477495.3531744,\nauthor = {Nielsen, Dan S. and McConville, Ryan},\ntitle = {MuMiN: A Large-Scale Multilingual Multimodal Fact-Checked Misinformation Social Network Dataset},\nyear =‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ju-resplande/MuMiN-PT.","first_N":5,"first_N_keywords":["text-classification","found","monolingual","Portuguese","mit"],"keywords_longer_than_N":true},
	{"name":"ptbr-deita-8k","keyword":"portuguese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/botbotrobotics/ptbr-deita-8k","creator_name":"BotBot","creator_url":"https://huggingface.co/botbotrobotics","description":"\n\t\n\t\t\n\t\tPTBR Deita 8k\n\t\n\nPortuguese translation of the Deita 8k dataset. \n","first_N":5,"first_N_keywords":["Portuguese","apache-2.0","1K - 10K","json","Text"],"keywords_longer_than_N":true},
	{"name":"orca-math-portuguese-64k","keyword":"portuguese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/rhaymison/orca-math-portuguese-64k","creator_name":"Rhaymison Cristian","creator_url":"https://huggingface.co/rhaymison","description":"translated for:\n\n\nRepository: microsoft/orca-math-word-problems-200k\nPaper: Orca-Math: Unlocking the potential of\nSLMs in Grade School Math\n\n","first_N":5,"first_N_keywords":["text-generation","question-answering","Portuguese","apache-2.0","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"Date_jese","keyword":"portuguese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Raivatv24/Date_jese","creator_name":"Fernando Roldao","creator_url":"https://huggingface.co/Raivatv24","description":"Raivatv24/Date_jese dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["Portuguese","apache-2.0","n<1K","üá∫üá∏ Region: US"],"keywords_longer_than_N":false},
	{"name":"re_dial_ptbr","keyword":"portuguese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/matheusrdgsf/re_dial_ptbr","creator_name":"Matheus Rodrigues de Souza F√©lix","creator_url":"https://huggingface.co/matheusrdgsf","description":"\n\t\n\t\t\n\t\tDataset Card for ReDial - PTBR\n\t\n\n\nOriginal dataset: Redial Huggingface\nHomepage: ReDial Dataset\nRepository: ReDialData\nPaper: Towards Deep Conversational Recommendations\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThe ReDial (Recommendation Dialogues) PTBR dataset is an annotated collection of dialogues where users recommend movies to each other translated to brazilian portuguese.\nThe adapted version of this dataset in Brazilian Portuguese was translated by the Maritalk. This translated version‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/matheusrdgsf/re_dial_ptbr.","first_N":5,"first_N_keywords":["text-classification","translation","Portuguese","English","mit"],"keywords_longer_than_N":true},
	{"name":"ProfessorHeidelTime","keyword":"portuguese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/hugosousa/ProfessorHeidelTime","creator_name":"Hugo Sousa","creator_url":"https://huggingface.co/hugosousa","description":"\n\t\n\t\t\n\t\tProfessor HeidelTime\n\t\n\nPaper    GitHub\nProfessor HeidelTime is a project to create a multilingual corpus weakly labeled with HeidelTime, a temporal tagger.\n\n\t\n\t\t\n\t\tCorpus Details\n\t\n\nThe weak labeling was performed in six languages. Here are the specifics of the corpus for each language:\n\n\t\n\t\t\nDataset\nLanguage\nDocuments\nFrom\nTo\nTokens\nTimexs\n\n\n\t\t\nAll the News 2.0\nEN\n24,642\n2016-01-01\n2020-04-02\n18,755,616\n254,803\n\n\nItalian Crime News\nIT\n9,619\n2011-01-01\n2021-12-31\n3,296,898\n58,823‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/hugosousa/ProfessorHeidelTime.","first_N":5,"first_N_keywords":["token-classification","parsing","part-of-speech","named-entity-recognition","machine-generated"],"keywords_longer_than_N":true},
	{"name":"Rhulk_pt-br","keyword":"portuguese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/satierf/Rhulk_pt-br","creator_name":"thiago freitas pimenta","creator_url":"https://huggingface.co/satierf","description":"satierf/Rhulk_pt-br dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["text-to-speech","text-generation","Portuguese","mit","< 1K"],"keywords_longer_than_N":true},
	{"name":"mewsli-x","keyword":"portuguese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/izhx/mewsli-x","creator_name":"Xin Zhang","creator_url":"https://huggingface.co/izhx","description":"I generated the dataset following mewsli-x.md#getting-started\nand converted into different parts (see process.py):\n\nar/de/en/es/fa/ja/pl/ro/ta/tr/uk wikinews_mentions dev and test (from wikinews_mentions-dev/test.jsonl)\ncandidate entities of 50 languages (from candidate_set_entities.jsonl)\nEnglish wikipedia_pairs to fine-tune models (from wikipedia_pairs-dev/train.jsonl)\n\nRaw data files are in raw.tar.gz, which contains:\n[...] 535M Feb 24 22:06 candidate_set_entities.jsonl\n[...] 9.8M Feb 24‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/izhx/mewsli-x.","first_N":5,"first_N_keywords":["text-retrieval","entity-linking-retrieval","Afrikaans","Arabic","Azerbaijani"],"keywords_longer_than_N":true},
	{"name":"QuestionClassification","keyword":"portuguese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/cnmoro/QuestionClassification","creator_name":"Carlo Moro","creator_url":"https://huggingface.co/cnmoro","description":"cnmoro/QuestionClassification dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["text-classification","English","Portuguese","apache-2.0","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"medicine-information-pt","keyword":"portuguese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/rhaymison/medicine-information-pt","creator_name":"Rhaymison Cristian","creator_url":"https://huggingface.co/rhaymison","description":"rhaymison/medicine-information-pt dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["text-generation","Portuguese","apache-2.0","1K - 10K","parquet"],"keywords_longer_than_N":true},
	{"name":"extraglue","keyword":"portuguese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/PORTULAN/extraglue","creator_name":"PORTULAN","creator_url":"https://huggingface.co/PORTULAN","description":"\n\n\n¬†¬†¬†¬†This is the dataset card for extraGLUE. \n  You may be interested in some of the other datasets for Portuguese and in the models trained with them, \n  namely Albertina (encoders) and Gerv√°sio (decoders) families.\n\n\n\n\n\n\n\t\n\t\t\n\t\tExtraGLUE\n\t\n\n\n\n\nExtraGLUE is a Portuguese dataset obtained by the automatic translation of some of the tasks in the GLUE and SuperGLUE benchmarks.\nTwo variants of Portuguese are considered, namely European Portuguese and American Portuguese.\nThe dataset is‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/PORTULAN/extraglue.","first_N":5,"first_N_keywords":["text-classification","sentence-similarity","question-answering","language-modeling","multi-class-classification"],"keywords_longer_than_N":true},
	{"name":"mittens","keyword":"portuguese","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/google/mittens","creator_name":"Google","creator_url":"https://huggingface.co/google","description":"\n\t\n\t\t\n\t\tMiTTenS: A Dataset for Evaluating Misgendering in Translation\n\t\n\nMisgendering is the act of referring to someone in a way that does not reflect their gender identity.  Translation systems, including foundation models capable of translation, can produce errors that result in misgendering harms. To measure the extent of such potential harms when translating into and out of English, we introduce a dataset, MiTTenS, covering 26 languages from a variety of language families and scripts‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/google/mittens.","first_N":5,"first_N_keywords":["translation","Arabic","Finnish","Oromo","Ganda"],"keywords_longer_than_N":true},
	{"name":"google-play-apps-review-pt","keyword":"portuguese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/AiresPucrs/google-play-apps-review-pt","creator_name":"AI Robotics Ethics Society (PUCRS)","creator_url":"https://huggingface.co/AiresPucrs","description":"\n\t\n\t\t\n\t\tGoogle Play Apps Review PT (Teeny-Tiny Castle)\n\t\n\nThis dataset is part of a tutorial tied to the Teeny-Tiny Castle, an open-source repository containing¬†educational tools for AI Ethics and Safety research. \n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nfrom datasets import load_dataset\n\ndataset = load_dataset(\"AiresPucrs/google-play-apps-review-pt\", split = 'train')\n\n","first_N":5,"first_N_keywords":["text-classification","Portuguese","apache-2.0","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"sharegpt_dialogue_base","keyword":"portuguese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/lamhieu/sharegpt_dialogue_base","creator_name":"Hieu Lam","creator_url":"https://huggingface.co/lamhieu","description":"\n\t\n\t\t\n\t\tDescription\n\t\n\nThe dataset is from unknown, formatted as dialogues for speed and ease of use. Many thanks to author for releasing it.\nImportantly, this format is easy to use via the default chat template of transformers, meaning you can use huggingface/alignment-handbook immediately, unsloth.\n\n\t\n\t\t\n\t\n\t\n\t\tStructure\n\t\n\nView online through viewer.\n\n\t\n\t\t\n\t\n\t\n\t\tNote\n\t\n\nWe advise you to reconsider before use, thank you. If you find it useful, please like and follow this account.‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/lamhieu/sharegpt_dialogue_base.","first_N":5,"first_N_keywords":["text-generation","English","Vietnamese","Chinese","Spanish"],"keywords_longer_than_N":true},
	{"name":"enem-essay-correction-2018-2024","keyword":"portuguese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/fonsecovizk/enem-essay-correction-2018-2024","creator_name":"Gabriel Fonseca","creator_url":"https://huggingface.co/fonsecovizk","description":"fonsecovizk/enem-essay-correction-2018-2024 dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["Portuguese","apache-2.0","1K - 10K","parquet","Text"],"keywords_longer_than_N":true},
	{"name":"Open_Assistant_Conversation_Chains","keyword":"portuguese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/m-ric/Open_Assistant_Conversation_Chains","creator_name":"Aymeric Roucher","creator_url":"https://huggingface.co/m-ric","description":"\n\t\n\t\t\n\t\tDataset Card for Dataset Name\n\t\n\n\n\t\n\t\t\n\t\tDataset description\n\t\n\n\n\nThis dataset is a reformatting of OpenAssistant Conversations (OASST1), which is\n\na human-generated, human-annotated assistant-style conversation corpus consisting of 161,443 messages in 35 different languages, annotated with 461,292 quality ratings, resulting in over 10,000 fully annotated conversation trees. The corpus is a product of a worldwide crowd-sourcing effort involving over 13,500 volunteers.\n\nIt was modified‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/m-ric/Open_Assistant_Conversation_Chains.","first_N":5,"first_N_keywords":["text-generation","English","Spanish","Russian","German"],"keywords_longer_than_N":true},
	{"name":"Ceu","keyword":"portuguese","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/nerfadox/Ceu","creator_name":"Fabr√≠cio Mendes","creator_url":"https://huggingface.co/nerfadox","description":"nerfadox/Ceu dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["Portuguese","cc0-1.0","< 1K","imagefolder","Image"],"keywords_longer_than_N":true},
	{"name":"panlex","keyword":"portuguese","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/lbourdois/panlex","creator_name":"Lo√Øck BOURDOIS","creator_url":"https://huggingface.co/lbourdois","description":"\n\t\n\t\t\n\t\tPanLex\n\t\n\nJanuary 1, 2024 version of PanLex Language Vocabulary with 24,650,274 rows covering 6,152 languages.\n\n\t\n\t\t\n\t\tColumns\n\t\n\n\nvocab: contains the text entry.  \n639-3: contains the ISO 639-3 languages tags to allow users to filter on the language(s) of their choice.\n639-3_english_name: the English language name associated to the code ISO 639-3. \nvar_code: contains a code to differentiate language variants. In practice, this is the code 639-3 + a number.  If 000, it corresponds to‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/lbourdois/panlex.","first_N":5,"first_N_keywords":["Ghotuo","Alumu-Tesu","Ari","Amal","Arb√´resh√´ Albanian"],"keywords_longer_than_N":true},
	{"name":"stata","keyword":"portuguese","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/adenhaus/stata","creator_name":"Aden Haussmann","creator_url":"https://huggingface.co/adenhaus","description":"\n\t\n\t\t\n\t\tBackground\n\t\n\nThis dataset contains human evaluations of whether outputs on the TaTA dataset are a) understandable and b) attributable to the source tables. See TaTA: A Multilingual Table-to-Text Dataset for African Languages for more details. \nIt can be used to train a learned metric, called StATA, to evaluate model performance on the TaTA dataset.\nPaper: https://www.arxiv.org/abs/2503.23204\nThe original can be found here.\n","first_N":5,"first_N_keywords":["table-to-text","yes","Arabic","English","French"],"keywords_longer_than_N":true},
	{"name":"pt_to_an","keyword":"portuguese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/matjs/pt_to_an","creator_name":"Matheus J. G. Silva","creator_url":"https://huggingface.co/matjs","description":"A collection of translations from Portuguese do Angrarosskesh, my fictional language.\n","first_N":5,"first_N_keywords":["translation","Portuguese","mit","< 1K","csv"],"keywords_longer_than_N":true},
	{"name":"fake_voices","keyword":"portuguese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/unfake/fake_voices","creator_name":"Unfake","creator_url":"https://huggingface.co/unfake","description":"\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Card for Fake Voices\n\t\n\nThis dataset contains deepfakes in Brazilian Portuguese created with XTTS model.\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Details\n\t\n\nThe dataset was created using the XTTS model, which is a Text-to-Speech model pre-trained in several languages including Portuguese. \nIn order to generate the mentioned deepfakes, the model was fed with recordings from the CETUC Corpus, \nmade available by Fala Brasil Group. It contains speeches from 101 speakers, totaling 140 hours of‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/unfake/fake_voices.","first_N":5,"first_N_keywords":["text-to-speech","text-to-audio","Portuguese","mit","1B<n<10B"],"keywords_longer_than_N":true},
	{"name":"dataset-portuguese-aira-v2-Gemma-format","keyword":"portuguese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/EddyGiusepe/dataset-portuguese-aira-v2-Gemma-format","creator_name":"EDDY GIUSEPE CHIRINOS ISIDRO, PhD","creator_url":"https://huggingface.co/EddyGiusepe","description":"Dataset Aira para o formato do Modelo Gemma \n\n\n\t\n\t\t\n\t\tResumo do Dataset\n\t\n\nEste conjunto de dados cont√©m uma cole√ß√£o de conversas individuais entre um assistente e um usu√°rio.\nAs conversas foram geradas pelas intera√ß√µes do usu√°rio com modelos j√° ajustados (ChatGPT, LLama 2, Open-Assistant, etc).\nO conjunto de dados est√° dispon√≠vel em portugu√™s (tem a vers√£o em Ingl√™s que ainda n√£o tratei). Mas voc√™ pode baixar do \nreposit√≥rio de Nicholas Kluge Corr√™a tanto a vers√£o em Portugu√™s e \na vers√£o em‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/EddyGiusepe/dataset-portuguese-aira-v2-Gemma-format.","first_N":5,"first_N_keywords":["question-answering","Portuguese","apache-2.0","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"cetacean-ptbr","keyword":"portuguese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/lucianosb/cetacean-ptbr","creator_name":"Luciano Santa Br√≠gida","creator_url":"https://huggingface.co/lucianosb","description":"This dataset is a merge of Open-Orca and Dolphin translated to portuguese.\n","first_N":5,"first_N_keywords":["Portuguese","mit","1M - 10M","parquet","Text"],"keywords_longer_than_N":true},
	{"name":"bhojpuri","keyword":"portuguese","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ankur02/bhojpuri","creator_name":"Ankur Verma","creator_url":"https://huggingface.co/ankur02","description":"\n\t\n\t\t\n\t\n\t\n\t\tFLEURS\n\t\n\nFleurs is the speech version of the FLoRes machine translation benchmark. \nWe use 2009 n-way parallel sentences from the FLoRes dev and devtest publicly available sets, in 102 languages. \nTraining sets have around 10 hours of supervision. Speakers of the train sets are different than speakers from the dev/test sets. Multilingual fine-tuning is\nused and ‚Äùunit error rate‚Äù (characters, signs) of all languages is averaged. Languages and results are also grouped into seven‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ankur02/bhojpuri.","first_N":5,"first_N_keywords":["automatic-speech-recognition","expert-generated","crowdsourced","machine-generated","crowdsourced"],"keywords_longer_than_N":true},
	{"name":"multi-hatecheck","keyword":"portuguese","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/multi-hatecheck","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  MultiHateClassification\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nHate speech detection dataset with binary\n                       (hateful vs non-hateful) labels. Includes 25+ distinct types of hate\n                       and challenging non-hate, and 11 languages.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask categoryt2c\n\n\nDomains\nConstructed, Written\n\n\nReference\nhttps://aclanthology.org/2022.woah-1.15/\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/multi-hatecheck.","first_N":5,"first_N_keywords":["text-classification","sentiment-analysis","sentiment-scoring","sentiment-classification","hate-speech-detection"],"keywords_longer_than_N":true},
	{"name":"aya_african_alpaca","keyword":"portuguese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/vutuka/aya_african_alpaca","creator_name":"vutuka","creator_url":"https://huggingface.co/vutuka","description":"\n\t\n\t\t\n\t\tAya African Alpaca Style Dataset\n\t\n\n\n\nThis dataset card aims to be a base template for new datasets. It has been generated using this raw template.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\n\n\n\n\nCurated by: [More Information Needed]\nFunded by [optional]: [More Information Needed]\nShared by [optional]: [More Information Needed]\nLanguage(s) (NLP): [More Information Needed]\nLicense: [More Information Needed]\n\n\n\t\n\t\t\n\t\tDataset Sources [optional]\n\t\n\n\n\n\nRepository: [More‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/vutuka/aya_african_alpaca.","first_N":5,"first_N_keywords":["text-generation","Afrikaans","Swahili","French","English"],"keywords_longer_than_N":true},
	{"name":"bio-mqm-dataset","keyword":"portuguese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/zouharvi/bio-mqm-dataset","creator_name":"Vil√©m Zouhar","creator_url":"https://huggingface.co/zouharvi","description":"This dataset is compiled from the official Amazon repository (all respective licensing applies).\nIt contains system translations, multiple references, and their quality evaluation on the MQM scale. It accompanies the ACL 2024 paper Fine-Tuned Machine Translation Metrics Struggle in Unseen Domains.\nWatch a brief 4 minutes-long video.\n\nAbstract: We introduce a new, extensive multidimensional quality metrics (MQM) annotated dataset covering 11 language pairs in the biomedical domain. We use this‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/zouharvi/bio-mqm-dataset.","first_N":5,"first_N_keywords":["translation","English","German","Spanish","Basque"],"keywords_longer_than_N":true},
	{"name":"medicine-medical_meadow_wikidoc_pt","keyword":"portuguese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/rhaymison/medicine-medical_meadow_wikidoc_pt","creator_name":"Rhaymison Cristian","creator_url":"https://huggingface.co/rhaymison","description":"rhaymison/medicine-medical_meadow_wikidoc_pt dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["text-generation","Portuguese","apache-2.0","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"mental-health-pt","keyword":"portuguese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/rhaymison/mental-health-pt","creator_name":"Rhaymison Cristian","creator_url":"https://huggingface.co/rhaymison","description":"rhaymison/mental-health-pt dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["text-generation","Portuguese","apache-2.0","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"medicine-medical-eval-pt","keyword":"portuguese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/rhaymison/medicine-medical-eval-pt","creator_name":"Rhaymison Cristian","creator_url":"https://huggingface.co/rhaymison","description":"rhaymison/medicine-medical-eval-pt dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["text-generation","Portuguese","apache-2.0","< 1K","parquet"],"keywords_longer_than_N":true},
	{"name":"MultiQ","keyword":"portuguese","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/caro-holt/MultiQ","creator_name":"Holtermann","creator_url":"https://huggingface.co/caro-holt","description":"\n\t\n\t\t\n\t\tDataset Card for MultiQ\n\t\n\nThis is the dataset corresponding to the paper \"Evaluating the Elementary Multilingual Capabilities of Large Language Models with MultiQ\". \nIt is a silver standard benchmark that can be used to evaluate the basic multilingual capabilities of LLMs. It contains 200 open ended questions automatically \ntranslated into 137 typologically diverse languages. \n\nCurated by: Carolin Holtermann, Paul R√∂ttger, Timm Dill, Anne Lauscher\nLanguage(s) (NLP): 137 diverse‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/caro-holt/MultiQ.","first_N":5,"first_N_keywords":["question-answering","Tagalog","Samoan","Macedonian","Gujarati"],"keywords_longer_than_N":true},
	{"name":"SQuAD-pt_BR-V1.1","keyword":"portuguese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/vsvasconcelos/SQuAD-pt_BR-V1.1","creator_name":"Vagner Sanches Vasconcelos","creator_url":"https://huggingface.co/vsvasconcelos","description":"\n\t\n\t\t\n\t\tDataset Card for Dataset Name\n\t\n\n\n\nO conjunto de dados \"Stanford Question Answering Dataset\" (SQuAD), para tarefa de perguntas e respostas extrativas, foi desenvolvido em 2016. Ele utiliza perguntas geradas \na partir de 536 artigos da Wikipedia com mais de 100.000 linhas de dados. √â constru√≠do na forma de uma pergunta e um contexto dos artigos da Wikipedia contendo a resposta \n√† pergunta.\nOriginalmente este dataset foi constru√≠do no idioma ingl√™s, contudo, o grupo Deep Learning Brasil‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/vsvasconcelos/SQuAD-pt_BR-V1.1.","first_N":5,"first_N_keywords":["Portuguese","apache-2.0","10K - 100K","csv","Text"],"keywords_longer_than_N":true},
	{"name":"SQuAD-pt_BR-V1.1_","keyword":"portuguese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/vsvasconcelos/SQuAD-pt_BR-V1.1_","creator_name":"Vagner Sanches Vasconcelos","creator_url":"https://huggingface.co/vsvasconcelos","description":"\n\t\n\t\t\n\t\tDataset Card para o SQuAD 1.1 em Portugu√™s Brasil\n\t\n\nO conjunto de dados \"Stanford Question Answering Dataset\" (SQuAD),\npara tarefa de perguntas e respostas extrativas, foi desenvolvido em 2016. Ele utiliza perguntas geradas a partir de\n536 artigos da Wikipedia* com mais de 100.000 linhas de dados. √â constru√≠do na forma de uma pergunta e um contexto dos artigos da\nWikipedia contendo a resposta √† pergunta. [1]Originalmente este dataset foi constru√≠do no idioma ingl√™s, contudo, o grupo‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/vsvasconcelos/SQuAD-pt_BR-V1.1_.","first_N":5,"first_N_keywords":["Portuguese","mit","10K - 100K","csv","Text"],"keywords_longer_than_N":true},
	{"name":"questions_answers_geo_nord","keyword":"portuguese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/rhaymison/questions_answers_geo_nord","creator_name":"Rhaymison Cristian","creator_url":"https://huggingface.co/rhaymison","description":"rhaymison/questions_answers_geo_nord dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["text-generation","Portuguese","apache-2.0","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"cml-tts","keyword":"portuguese","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ylacombe/cml-tts","creator_name":"Yoach Lacombe","creator_url":"https://huggingface.co/ylacombe","description":"\n\t\n\t\t\n\t\tDataset Card for CML-TTS\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nCML-TTS is a recursive acronym for CML-Multi-Lingual-TTS, a Text-to-Speech (TTS) dataset developed at the Center of Excellence in Artificial Intelligence (CEIA) of the Federal University of Goias (UFG).\nCML-TTS is a dataset comprising audiobooks sourced from the public domain books of Project Gutenberg, read by volunteers from the LibriVox project. The dataset includes recordings in Dutch, German, French, Italian, Polish‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ylacombe/cml-tts.","first_N":5,"first_N_keywords":["text-to-speech","text-to-audio","Dutch","French","German"],"keywords_longer_than_N":true},
	{"name":"enem","keyword":"portuguese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/maritaca-ai/enem","creator_name":"Maritaca AI","creator_url":"https://huggingface.co/maritaca-ai","description":"The ENEM 2022, 2023 and 2024 datasets encompass all multiple-choice questions from the last two editions of the Exame Nacional do Ensino M√©dio (ENEM), the main standardized entrance examination adopted by Brazilian universities. The datasets have been created to allow the evaluation of both textual-only and textual-visual language models. To evaluate textual-only models, we incorporated into the datasets the textual descriptions of the images that appear in the questions' statements from the‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/maritaca-ai/enem.","first_N":5,"first_N_keywords":["visual-question-answering","multiple-choice","Portuguese","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"CA-PT_Parallel_Corpus","keyword":"portuguese","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/projecte-aina/CA-PT_Parallel_Corpus","creator_name":"Projecte Aina","creator_url":"https://huggingface.co/projecte-aina","description":"\n\t\n\t\t\n\t\tDataset Card for CA-PT Parallel Corpus\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThe CA-PT Parallel Corpus is a Catalan-Portuguese dataset created to support Catalan in NLP tasks, specifically \nMachine Translation.\n\n\t\n\t\t\n\t\tSupported Tasks and Leaderboards\n\t\n\nThe dataset can be used to train Bilingual Machine Translation models between Portuguese and Catalan in any direction, \nas well as Multilingual Machine Translation models.\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nThe sentences included in the dataset are in‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/projecte-aina/CA-PT_Parallel_Corpus.","first_N":5,"first_N_keywords":["translation","multilingual","Catalan","Portuguese","cc-by-sa-4.0"],"keywords_longer_than_N":true},
	{"name":"librivox-tracks","keyword":"portuguese","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/pykeio/librivox-tracks","creator_name":"pyke.io","creator_url":"https://huggingface.co/pykeio","description":"A dataset of all audio files uploaded to LibriVox before 26th September 2023.\n","first_N":5,"first_N_keywords":["text-to-speech","automatic-speech-recognition","Achinese","Afrikaans","Ancient Greek (to 1453)"],"keywords_longer_than_N":true},
	{"name":"Portuguese-English-Vocab-PartiallyTransformed","keyword":"portuguese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Solshine/Portuguese-English-Vocab-PartiallyTransformed","creator_name":"Caleb DeLeeuw","creator_url":"https://huggingface.co/Solshine","description":"Notes on use:\nPortuguese and English Translations of readme are available here.\nPartially cleaned and reorganized. Minimal secondhand verification after generation through Google Bard on November 28th 2023. Mistakes are minimal but present, such as tagging of words in supplemental information sometimes using the whole word (ie Noun) and sometimes only a letter or abreviation (ie N) for the same part of speech.\nReccomended for finetuning of smaller models only, such as 12, 7, or 3 B models to‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Solshine/Portuguese-English-Vocab-PartiallyTransformed.","first_N":5,"first_N_keywords":["Portuguese","English","mit","1K - 10K","csv"],"keywords_longer_than_N":true},
	{"name":"Pontoon-Translations","keyword":"portuguese","license":"Mozilla Public License 2.0","license_url":"https://choosealicense.com/licenses/mpl-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ayymen/Pontoon-Translations","creator_name":"Mohamed Aymane Farhi","creator_url":"https://huggingface.co/ayymen","description":"\n\t\n\t\t\n\t\tDataset Card for Pontoon Translations\n\t\n\n\n\nThis is a dataset containing strings from various Mozilla projects on Mozilla's Pontoon localization platform and their translations into more than 200 languages.\nSource strings are in English.\nTo avoid rows with values like \"None\" and \"N/A\" being interpreted as missing values, pass the keep_default_na parameter like this:\nfrom datasets import load_dataset\n\ndataset = load_dataset(\"ayymen/Pontoon-Translations\", keep_default_na=False)‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ayymen/Pontoon-Translations.","first_N":5,"first_N_keywords":["translation","crowdsourced","Abkhaz","Achinese","Acoli"],"keywords_longer_than_N":true},
	{"name":"cosmos_qa_ptbr","keyword":"portuguese","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/heloisy/cosmos_qa_ptbr","creator_name":"Heloisy Rodrigues","creator_url":"https://huggingface.co/heloisy","description":"\n\t\n\t\t\n\t\tCosmos QA Portugu√™s\n\t\n\nEste dataset √© uma tradu√ß√£o para portugu√™s do Cosmos QA, que originalmente √© na l√≠ngua inglesa. \nA tradu√ß√£o foi feita automaticamente usando o GPT-3.5-turbo, logo pode ter erros que n√£o foram notados numa an√°lise superficial. \nSe atente ao uso.\n\n\t\n\t\t\n\t\tDataset Card for cosmos_qa\n\t\n\n\n\t\n\t\t\n\t\tLicensing Information\n\t\n\nThe data is distributed under the CC BY 4.0 license.\n\n\t\n\t\t\n\t\tSource Data Citation INformation\n\t\n\n@inproceedings{huang-etal-2019-cosmos,\n    title =‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/heloisy/cosmos_qa_ptbr.","first_N":5,"first_N_keywords":["multiple-choice","cosmos_qa","Portuguese","cc-by-4.0","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"Propbank-BR","keyword":"portuguese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/liaad/Propbank-BR","creator_name":"LIAAD, INESCTEC","creator_url":"https://huggingface.co/liaad","description":"Problem in line 20727 with \\t missing\n","first_N":5,"first_N_keywords":["token-classification","Portuguese","mit","1K - 10K","parquet"],"keywords_longer_than_N":true},
	{"name":"meudata","keyword":"portuguese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/EronSamez/meudata","creator_name":"Samez","creator_url":"https://huggingface.co/EronSamez","description":"EronSamez/meudata dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["text-generation","Portuguese","apache-2.0","< 1K","json"],"keywords_longer_than_N":true},
	{"name":"multiple-choice-questions","keyword":"portuguese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/mateus-hamade/multiple-choice-questions","creator_name":"Mateus Hamade","creator_url":"https://huggingface.co/mateus-hamade","description":"\n\t\n\t\t\n\t\n\t\n\t\tQuest√µes de M√∫ltipla Escolha - Base de dados (PT-BR)\n\t\n\n\n\t\n\t\t\n\t\n\t\n\t\tContextualiza√ß√£o\n\t\n\nEste reposit√≥rio cont√©m uma base de dados (data.json) com quest√µes de m√∫ltipla escolha, a qual foi utilizada principalmente no desenvolvimento de modelos de recupera√ß√£o de informa√ß√£o.\n\n\t\n\t\t\n\t\n\t\n\t\tDescri√ß√£o do conjunto de dados\n\t\n\nO conjunto de dados √© composto por quest√µes de m√∫ltipla escolha, abrangendo uma variedade de temas dentro da √°rea da Ci√™ncia da Computa√ß√£o. Cada quest√£o √© estruturada‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mateus-hamade/multiple-choice-questions.","first_N":5,"first_N_keywords":["text-classification","question-answering","Portuguese","mit","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"Multilingual-Benchmark","keyword":"portuguese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/TaiMingLu/Multilingual-Benchmark","creator_name":"TaiMing","creator_url":"https://huggingface.co/TaiMingLu","description":"These are the GSM8K and ARC dataset translated by Google Translate. \nBibTex\n@misc{lu2024languagecountslearnunlearn,\n      title={Every Language Counts: Learn and Unlearn in Multilingual LLMs}, \n      author={Taiming Lu and Philipp Koehn},\n      year={2024},\n      eprint={2406.13748},\n      archivePrefix={arXiv},\n      primaryClass={cs.CL},\n      url={https://arxiv.org/abs/2406.13748}, \n}\n\n","first_N":5,"first_N_keywords":["zero-shot-classification","question-answering","translation","English","German"],"keywords_longer_than_N":true},
	{"name":"lambada-pt","keyword":"portuguese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/TucanoBR/lambada-pt","creator_name":"Tucano","creator_url":"https://huggingface.co/TucanoBR","description":"\n\t\n\t\t\n\t\tLAMBADA-PT\n\t\n\n\nRepository: TucanoBR/lambada-pt\nPaper: Radford et al. Language Models are Unsupervised Multitask Learners\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset is a translated version (Portuguese) of the LAMBADA test split as pre-processed by OpenAI.\nLAMBADA is used to evaluate the capabilities of computational models for text understanding by means of a word prediction task. LAMBADA is a collection of narrative texts sharing the characteristic that human subjects are able to guess‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/TucanoBR/lambada-pt.","first_N":5,"first_N_keywords":["text-generation","Portuguese","mit","1K - 10K","parquet"],"keywords_longer_than_N":true},
	{"name":"Descriptors_STJ","keyword":"portuguese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/MartimZanatti/Descriptors_STJ","creator_name":"Martim Zanatti dos Santos Gomes da Silva","creator_url":"https://huggingface.co/MartimZanatti","description":"\nWork developed as part of [IRIS] (https://www.inesc-id.pt/projects/PR07005/)\n\n\t\n\t\t\n\t\n\t\n\t\tExtreme Multi-Label Classification of Descriptors\n\t\n\nThe goal of this dataset is to train an Extreme Multi-Label classifier that, given a judgment from the Supreme Court of Justice of Portugal (STJ), can associate relevant descriptors to the judgment.\nDataset Contents:\n\nJudgment ID: Unique identifier for each judgment.\nSTJ Section: The section of the STJ to which the judgment belongs.Judgment Text: Full‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/MartimZanatti/Descriptors_STJ.","first_N":5,"first_N_keywords":["token-classification","Portuguese","mit","10K - 100K","csv"],"keywords_longer_than_N":true},
	{"name":"anacreontea","keyword":"portuguese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/ronunes/anacreontea","creator_name":"Rafael Oleques Nunes","creator_url":"https://huggingface.co/ronunes","description":"This repository contains the dataset for the paper Ancient Greek's New Technological Muse: Extracting Topoi in the Anacreontea with LLMs, accepted at the 51st SEMISH (51¬∫ Semin√°rio Integrado de Software e Hardware).\nAbstract:\n\nNatural Language Processing (NLP), along with Large Language Models (LLMs), holds significant potential in the domain of literature, leveraging its computational capabilities to analyze and comprehend human language. These techniques prove to be particularly useful in a‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ronunes/anacreontea.","first_N":5,"first_N_keywords":["text-classification","Portuguese","Greek","mit","< 1K"],"keywords_longer_than_N":true},
	{"name":"europa-random-split","keyword":"portuguese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/NCube/europa-random-split","creator_name":"Neural Network Nomads (We are GLOSS)","creator_url":"https://huggingface.co/NCube","description":"\n\t\n\t\t\n\t\tDataset Card for EUROPA\n\t\n\nThis dataset card aims to be a base template for new datasets. It has been generated using this raw template.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nEUROPA is a dataset designed for training and evaluating multilingual keyphrase generation models in the legal domain. It consists of legal judgments from the Court of Justice of the European Union (EU) and includes instances in all 24 official EU languages.\nKey Features:\nMultilingual: Covers‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/NCube/europa-random-split.","first_N":5,"first_N_keywords":["French","German","English","Italian","Dutch"],"keywords_longer_than_N":true},
	{"name":"GlotCC-V1","keyword":"portuguese","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/cis-lmu/GlotCC-V1","creator_name":"CIS, LMU Munich","creator_url":"https://huggingface.co/cis-lmu","description":"\n\t\n\t\t\n\t\tDataset Summary\n\t\n\n \n\nGlotCC-V1.0 is a document-level, general domain dataset derived from CommonCrawl, covering more than 1000 languages.It is built using the GlotLID language identification and Ungoliant pipeline from CommonCrawl.We release our pipeline as open-source at https://github.com/cisnlp/GlotCC.  \nList of Languages: See https://datasets-server.huggingface.co/splits?dataset=cis-lmu/GlotCC-V1 to get the list of splits available.\n\n\t\t\n\t\tUsage (Huggingface Hub -- Recommended)‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/cis-lmu/GlotCC-V1.","first_N":5,"first_N_keywords":["multilingual","Abau","Amarasi","Abkhaz","Abkhazian"],"keywords_longer_than_N":true},
	{"name":"GlotCC-V1","keyword":"portuguese","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/cis-lmu/GlotCC-V1","creator_name":"CIS, LMU Munich","creator_url":"https://huggingface.co/cis-lmu","description":"\n\t\n\t\t\n\t\tDataset Summary\n\t\n\n \n\nGlotCC-V1.0 is a document-level, general domain dataset derived from CommonCrawl, covering more than 1000 languages.It is built using the GlotLID language identification and Ungoliant pipeline from CommonCrawl.We release our pipeline as open-source at https://github.com/cisnlp/GlotCC.  \nList of Languages: See https://datasets-server.huggingface.co/splits?dataset=cis-lmu/GlotCC-V1 to get the list of splits available.\n\n\t\t\n\t\tUsage (Huggingface Hub -- Recommended)‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/cis-lmu/GlotCC-V1.","first_N":5,"first_N_keywords":["multilingual","Abau","Amarasi","Abkhaz","Abkhazian"],"keywords_longer_than_N":true},
	{"name":"MultiPICo","keyword":"portuguese","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Multilingual-Perspectivist-NLU/MultiPICo","creator_name":"MultilingualPerspectivistNLU","creator_url":"https://huggingface.co/Multilingual-Perspectivist-NLU","description":"\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nMultiPICo (Multilingual Perspectivist Irony Corpus) is a disaggregated multilingual corpus for irony detection, containing 18,778 pairs of short conversations (post-reply) from Twitter (8,956) and Reddit (9,822), along with the demographic information of each annotator (age, nationality, gender, and so on). \n\n\t\n\t\t\n\t\tSupported Tasks and Leaderboards\n\t\n\nIrony classification task using soft labels (i.e., distribution of annotations) or hard labels (i.e., aggregated‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Multilingual-Perspectivist-NLU/MultiPICo.","first_N":5,"first_N_keywords":["Spanish","English","German","Arabic","Portuguese"],"keywords_longer_than_N":true},
	{"name":"europa","keyword":"portuguese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/NCube/europa","creator_name":"Neural Network Nomads (We are GLOSS)","creator_url":"https://huggingface.co/NCube","description":"\n\t\n\t\t\n\t\tDataset Card for EUROPA\n\t\n\nThis dataset card aims to be a base template for new datasets. It has been generated using this raw template.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nEUROPA is a dataset designed for training and evaluating multilingual keyphrase generation models in the legal domain. It consists of legal judgments from the Court of Justice of the European Union (EU) and includes instances in all 24 official EU languages.\nKey Features:\nMultilingual: Covers‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/NCube/europa.","first_N":5,"first_N_keywords":["French","German","English","Italian","Dutch"],"keywords_longer_than_N":true},
	{"name":"FairytaleQA-translated-ptPT","keyword":"portuguese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/benjleite/FairytaleQA-translated-ptPT","creator_name":"Bernardo Leite","creator_url":"https://huggingface.co/benjleite","description":"\n\t\n\t\t\n\t\tDataset Card for FairytaleQA-translated-ptPT\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis repository contains the European Portuguese (pt-PT) machine-translated version of the original English FairytaleQA dataset (https://huggingface.co/datasets/WorkInTheDark/FairytaleQA). FairytaleQA is an open-source dataset designed to enhance comprehension of narratives, aimed at students from kindergarten to eighth grade. The dataset is meticulously annotated by education experts following an evidence-based‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/benjleite/FairytaleQA-translated-ptPT.","first_N":5,"first_N_keywords":["question-answering","text-generation","Portuguese","apache-2.0","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"GigaVerbo-Text-Filter","keyword":"portuguese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/TucanoBR/GigaVerbo-Text-Filter","creator_name":"Tucano","creator_url":"https://huggingface.co/TucanoBR","description":"\n\t\n\t\t\n\t\tGigaVerbo Text-Filter\n\t\n\n\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nGigaVerbo Text-Filter is a dataset with 110,000 randomly selected samples from 9 subsets of GigaVerbo (i.e., specifically those that were not synthetic). This dataset was used to train the text-quality filters described in \"Tucano: Advancing Neural Text Generation for Portuguese\". To create the text embeddings, we used sentence-transformers/LaBSE. All scores were generated by GPT-4o.\n\n\t\n\t\t\n\t\n\t\n\t\tSupported Tasks and Leaderboards‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/TucanoBR/GigaVerbo-Text-Filter.","first_N":5,"first_N_keywords":["text-classification","Portuguese","apache-2.0","100K - 1M","parquet"],"keywords_longer_than_N":true},
	{"name":"GigaVerbo-Text-Filter","keyword":"portuguese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/TucanoBR/GigaVerbo-Text-Filter","creator_name":"Tucano","creator_url":"https://huggingface.co/TucanoBR","description":"\n\t\n\t\t\n\t\tGigaVerbo Text-Filter\n\t\n\n\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nGigaVerbo Text-Filter is a dataset with 110,000 randomly selected samples from 9 subsets of GigaVerbo (i.e., specifically those that were not synthetic). This dataset was used to train the text-quality filters described in \"Tucano: Advancing Neural Text Generation for Portuguese\". To create the text embeddings, we used sentence-transformers/LaBSE. All scores were generated by GPT-4o.\n\n\t\n\t\t\n\t\n\t\n\t\tSupported Tasks and Leaderboards‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/TucanoBR/GigaVerbo-Text-Filter.","first_N":5,"first_N_keywords":["text-classification","Portuguese","apache-2.0","100K - 1M","parquet"],"keywords_longer_than_N":true},
	{"name":"M3GIA","keyword":"portuguese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Songweii/M3GIA","creator_name":"Wei Song","creator_url":"https://huggingface.co/Songweii","description":"\n\t\n\t\t\n\t\tM3GIA: A Cognition Inspired Multilingual and Multimodal General Intelligence Ability\n\t\n\n[üåê Homepage] | ü§ó Dataset | ü§ó Paper | üìñ arXiv | üíª GitHub\nThe evaluation code can be found in üíª GitHub.\n[Abstract]\nAs recent multi-modality large language models (MLLMs) have shown formidable proficiency on various complex tasks, there has been increasing attention on debating whether these models could eventually mirror human intelligence. However, existing benchmarks mainly focus on evaluating‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Songweii/M3GIA.","first_N":5,"first_N_keywords":["English","Chinese","Spanish","French","Portuguese"],"keywords_longer_than_N":true},
	{"name":"Chatgpt","keyword":"portuguese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/RajChat/Chatgpt","creator_name":"Rajdeep Chatterjee ","creator_url":"https://huggingface.co/RajChat","description":"\n\t\n\t\t\n\t\tOpenAssistant Conversations Dataset (OASST1)\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nIn an effort to democratize research on large-scale alignment, we release OpenAssistant \nConversations (OASST1), a human-generated, human-annotated assistant-style conversation \ncorpus consisting of 161,443 messages in 35 different languages, annotated with 461,292 \nquality ratings, resulting in over 10,000 fully annotated conversation trees. The corpus \nis a product of a worldwide crowd-sourcing effort‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/RajChat/Chatgpt.","first_N":5,"first_N_keywords":["English","Spanish","Russian","German","Polish"],"keywords_longer_than_N":true},
	{"name":"synthetic_multilingual_llm_prompts","keyword":"portuguese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/gretelai/synthetic_multilingual_llm_prompts","creator_name":"Gretel.ai","creator_url":"https://huggingface.co/gretelai","description":"\n  \n  Image generated by DALL-E. See prompt for more details\n\n\n\n\t\n\t\t\n\t\tüìùüåê Synthetic Multilingual LLM Prompts\n\t\n\nWelcome to the \"Synthetic Multilingual LLM Prompts\" dataset! This comprehensive collection features 1,250 synthetic LLM prompts generated using Gretel Navigator, available in seven different languages. To ensure accuracy and diversity in prompts, and translation quality and consistency across the different languages, we employed Gretel Navigator both as a generation tool and as an‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/gretelai/synthetic_multilingual_llm_prompts.","first_N":5,"first_N_keywords":["text-generation","translation","question-answering","English","Dutch"],"keywords_longer_than_N":true},
	{"name":"NTREX","keyword":"portuguese","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/davidstap/NTREX","creator_name":"David Stap","creator_url":"https://huggingface.co/davidstap","description":"\n\t\n\t\t\n\t\tDataset Description\n\t\n\nNTREX -- News Test References for MT Evaluation from English into a total of 128 target languages. See original GitHub repo for full details.\nExample of loading:\ndataset = load_dataset(\"davidstap/NTREX\", \"rus_Cyrl\", trust_remote_code=True)\n\n\n\t\n\t\t\n\t\n\t\n\t\tLanguages\n\t\n\nThe following languages are available:\n\n\t\n\t\t\nLanguage Code\nLanguage Name\n\n\n\t\t\nafr_Latn\nAfrikaans\n\n\namh_Ethi\nAmharic\n\n\narb_Arab\nArabic\n\n\naze_Latn\nAzerbaijani\nbak_Cyrl\nBashkir\n\n\nbel_Cyrl\nBelarusian‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/davidstap/NTREX.","first_N":5,"first_N_keywords":["translation","expert-generated","expert-generated","translation","Afrikaans"],"keywords_longer_than_N":true},
	{"name":"caramelo-emotions-v2","keyword":"portuguese","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Adilmar/caramelo-emotions-v2","creator_name":"Adilmar Coelho Dantas","creator_url":"https://huggingface.co/Adilmar","description":"Adilmar/caramelo-emotions-v2 dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["Portuguese","cc-by-4.0","100K - 1M","parquet","Text"],"keywords_longer_than_N":true},
	{"name":"eurlex-multilingual","keyword":"portuguese","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/eurlex-multilingual","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  MultiEURLEXMultilabelClassification\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nEU laws in 23 EU languages containing annotated labels for 21 EUROVOC concepts.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2c\n\n\nDomains\nLegal, Government, Written\n\n\nReferencehttps://huggingface.co/datasets/coastalcph/multi_eurlex\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask =‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/eurlex-multilingual.","first_N":5,"first_N_keywords":["text-classification","multi-label-classification","topic-classification","expert-annotated","multilingual"],"keywords_longer_than_N":true},
	{"name":"biblenlp-corpus-mmteb","keyword":"portuguese","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/davidstap/biblenlp-corpus-mmteb","creator_name":"David Stap","creator_url":"https://huggingface.co/davidstap","description":"This dataset pre-computes all English-centric directions from bible-nlp/biblenlp-corpus, and as a result loading is significantly faster.\nLoading example:\n>>> from datasets import load_dataset\n>>> dataset = load_dataset(\"davidstap/biblenlp-corpus-mmteb\", \"eng-arb\", trust_remote_code=True)\n>>> dataset\nDatasetDict({\n    train: Dataset({\n        features: ['eng', 'arb'],\n        num_rows: 28723\n    })\n    validation: Dataset({\n        features: ['eng', 'arb'],\n        num_rows: 1578\n    })‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/davidstap/biblenlp-corpus-mmteb.","first_N":5,"first_N_keywords":["no-annotation","expert-generated","translation","multilingual","Arifama-Miniafia"],"keywords_longer_than_N":true},
	{"name":"nurc-sp_pseudo_labelled","keyword":"portuguese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/RodrigoLimaRFL/nurc-sp_pseudo_labelled","creator_name":"Rodrigo de Freitas Lima","creator_url":"https://huggingface.co/RodrigoLimaRFL","description":"RodrigoLimaRFL/nurc-sp_pseudo_labelled dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["Portuguese","mit","10K - 100K","parquet","Audio"],"keywords_longer_than_N":true},
	{"name":"Buscape","keyword":"portuguese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/liaad/Buscape","creator_name":"LIAAD, INESCTEC","creator_url":"https://huggingface.co/liaad","description":"\n\t\n\t\t\n\t\tBuscap√© Sample annotated for Semantic Role Labelling\n\t\n\n\n\t\n\t\t\n\t\tPropbank-Br Corpora Buscap√© Sample\n\t\n\nThe Propbank-Br is a project that aims to annotate corpora with semantic role labels for the purpose of creating training datasets for automated semantic role classifiers. The annotation scheme is quite similar to that of the English Propbank (Palmer et al., 2005), with language-specific differences taken into account. The set of semantic roles was designed to facilitate automatic‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/liaad/Buscape.","first_N":5,"first_N_keywords":["token-classification","Portuguese","mit","1K - 10K","parquet"],"keywords_longer_than_N":true},
	{"name":"flickr8k-pt-br","keyword":"portuguese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/laicsiifes/flickr8k-pt-br","creator_name":"Laborat√≥rio de Intelig√™ncia Computacional e Sistemas de informa√ß√£o","creator_url":"https://huggingface.co/laicsiifes","description":"\n\t\n\t\t\n\t\tüéâ Flickr8K Dataset Translation for Portuguese Image Captioning\n\t\n\n\n\t\n\t\t\n\t\tüíæ Dataset Summary\n\t\n\nFlickr8K Portuguese Translation, a multimodal dataset for Portuguese image captioning with 8,000 images, each accompanied by five descriptive captions that have been\ngenerated by human annotators for every individual image. The original English captions were rendered into Portuguese\nthrough the utilization of the Google Translator API.\n\n\t\n\t\t\n\t\tüßë‚Äçüíª Hot to Get Started with the Dataset‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/laicsiifes/flickr8k-pt-br.","first_N":5,"first_N_keywords":["image-to-text","text-to-image","text-generation","Portuguese","mit"],"keywords_longer_than_N":true},
	{"name":"flickr30k-pt-br","keyword":"portuguese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/laicsiifes/flickr30k-pt-br","creator_name":"Laborat√≥rio de Intelig√™ncia Computacional e Sistemas de informa√ß√£o","creator_url":"https://huggingface.co/laicsiifes","description":"\n\t\n\t\t\n\t\tüéâ Flickr30K Translated for Portuguese Image Captioning\n\t\n\n\n\t\n\t\t\n\t\tüíæ Dataset Summary\n\t\n\nFlickr30K Portuguese Translated, a multimodal dataset for Portuguese image captioning with 31,014 images, each accompanied by five descriptive captions that have been\ngenerated by human annotators for every individual image. The original English captions were rendered into Portuguese\nthrough the utilization of the Google Translator API.\nThe dataset is one of the results of work available at:‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/laicsiifes/flickr30k-pt-br.","first_N":5,"first_N_keywords":["text-generation","image-to-text","text-to-image","Portuguese","mit"],"keywords_longer_than_N":true},
	{"name":"FairytaleQA-translated-ptBR","keyword":"portuguese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/benjleite/FairytaleQA-translated-ptBR","creator_name":"Bernardo Leite","creator_url":"https://huggingface.co/benjleite","description":"\n\t\n\t\t\n\t\tDataset Card for FairytaleQA-translated-ptBR\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis repository contains the Brazilian Portuguese (pt-BR) machine-translated version of the original English FairytaleQA dataset (https://huggingface.co/datasets/WorkInTheDark/FairytaleQA). FairytaleQA is an open-source dataset designed to enhance comprehension of narratives, aimed at students from kindergarten to eighth grade. The dataset is meticulously annotated by education experts following an‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/benjleite/FairytaleQA-translated-ptBR.","first_N":5,"first_N_keywords":["question-answering","text-generation","Portuguese","apache-2.0","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"fact-check-bureau","keyword":"portuguese","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/NaughtyConstrictor/fact-check-bureau","creator_name":"Younes","creator_url":"https://huggingface.co/NaughtyConstrictor","description":"\n\t\n\t\t\n\t\n\t\n\t\tFact-Check Retrieval Dataset\n\t\n\nThis dataset is designed to support the development and evaluation of fact-check retrieval pipelines. It is structured to work with FactCheckBureau, a tool for designing and evaluating fact-check retrieval pipelines. The dataset comprises a list of claims, fact-check articles, and precomputed embeddings for English and French fact-checks.\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Structure\n\t\n\nThe dataset consists of the following files and directories:\n\narticles.csv:‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/NaughtyConstrictor/fact-check-bureau.","first_N":5,"first_N_keywords":["English","French","Portuguese","Spanish","Arabic"],"keywords_longer_than_N":true},
	{"name":"xsimplusplus","keyword":"portuguese","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/jaygala24/xsimplusplus","creator_name":"Jay Gala","creator_url":"https://huggingface.co/jaygala24","description":"xSIM++ is an extension of xSIM. In comparison to xSIM, this evaluates using target-side data with additional synthetic, hard-to-distinguish examples. You can find more details about it in the publication: xSIM++: An Improved Proxy to Bitext Mining Performance for Low-Resource Languages.\n","first_N":5,"first_N_keywords":["derived","multilingual","Achinese","Mesopotamian Arabic","Ta'izzi-Adeni Arabic"],"keywords_longer_than_N":true},
	{"name":"coco-captions-pt-br","keyword":"portuguese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/laicsiifes/coco-captions-pt-br","creator_name":"Laborat√≥rio de Intelig√™ncia Computacional e Sistemas de informa√ß√£o","creator_url":"https://huggingface.co/laicsiifes","description":"\n\t\n\t\t\n\t\tüéâ COCO Captions Dataset Translation for Portuguese Image Captioning\n\t\n\n\n\t\n\t\t\n\t\tüíæ Dataset Summary\n\t\n\nCOCO Captions Portuguese Translation, a multimodal dataset for Portuguese image captioning with 123,287 images, each accompanied by five descriptive captions that have been\ngenerated by human annotators for every individual image. The original English captions were rendered into Portuguese\nthrough the utilization of the Google Translator API.\n\n\t\n\t\t\n\t\tüßë‚Äçüíª Hot to Get Started with the‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/laicsiifes/coco-captions-pt-br.","first_N":5,"first_N_keywords":["text-to-image","image-to-text","text-generation","Portuguese","mit"],"keywords_longer_than_N":true},
	{"name":"webui-dom-snapshots","keyword":"portuguese","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/gbenson/webui-dom-snapshots","creator_name":"Gary Benson","creator_url":"https://huggingface.co/gbenson","description":"\n\t\n\t\t\n\t\tDataset Card for WebUI DOM snapshots\n\t\n\n\n\nThis dataset card aims to be a base template for new datasets. It has been generated using this raw template.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\n\n\n\n\n\nCurated by: Gary Benson\nLanguages: Mostly English (87%);\nDutch, French, Chinese, Japanese (1-2% each); 30+ others (<1% each)\nLicense: CC0 1.0 Universal\n\n\n\t\n\t\t\n\t\tDataset Sources [optional]\n\t\n\n\n\n\nRepository: [More Information Needed]\nPaper [optional]: [More Information Needed]‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/gbenson/webui-dom-snapshots.","first_N":5,"first_N_keywords":["image-feature-extraction","reinforcement-learning","text-classification","multilingual","biglab/webui-7k"],"keywords_longer_than_N":true},
	{"name":"oab_gemini","keyword":"portuguese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/celsowm/oab_gemini","creator_name":"Celso F","creator_url":"https://huggingface.co/celsowm","description":"celsowm/oab_gemini dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["question-answering","Portuguese","apache-2.0","1K - 10K","json"],"keywords_longer_than_N":true},
	{"name":"Emakhuwa-News-Topic-Classification","keyword":"portuguese","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/LIACC/Emakhuwa-News-Topic-Classification","creator_name":"LIACC","creator_url":"https://huggingface.co/LIACC","description":"BibTeX:\nThe dataset paper was published in EMNLP 2024.\nPlease cite as:\n@inproceedings{ali-etal-2024-building,\n    title = \"Building Resources for Emakhuwa: Machine Translation and News Classification Benchmarks\",\n    author = \"Ali, Felermino D. M. A.  and\n      Lopes Cardoso, Henrique  and\n      Sousa-Silva, Rui\",\n    editor = \"Al-Onaizan, Yaser  and\n      Bansal, Mohit  and\n      Chen, Yun-Nung\",\n    booktitle = \"Proceedings of the 2024 Conference on Empirical Methods in Natural Language‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/LIACC/Emakhuwa-News-Topic-Classification.","first_N":5,"first_N_keywords":["translation","text-classification","Makhuwa","Portuguese","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"Emakhuwa-loanwords-detection","keyword":"portuguese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/LIACC/Emakhuwa-loanwords-detection","creator_name":"LIACC","creator_url":"https://huggingface.co/LIACC","description":"\n\t\n\t\t\n\t\tDetecting Loanwords in Emakhuwa\n\t\n\nPaper: Detecting Loanwords in Emakhuwa: An Extremely Low-Resource {B}antu Language Exhibiting Significant Borrowing from Portuguese\n\n@inproceedings{ali-etal-2024-detecting,\n    title = \"Detecting Loanwords in Emakhuwa: An Extremely Low-Resource {B}antu Language Exhibiting Significant Borrowing from {P}ortuguese\",\n    author = \"Ali, Felermino Dario Mario  and\n      Lopes Cardoso, Henrique  and\n      Sousa-Silva, Rui\",\n    booktitle = \"Proceedings of‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/LIACC/Emakhuwa-loanwords-detection.","first_N":5,"first_N_keywords":["text-classification","Portuguese","Makhuwa","mit","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"learnlangai-general","keyword":"portuguese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/falleco/learnlangai-general","creator_name":"Israel Crisanto","creator_url":"https://huggingface.co/falleco","description":"falleco/learnlangai-general dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["text-generation","English","Portuguese","mit","< 1K"],"keywords_longer_than_N":true},
	{"name":"sql-create-context-pt","keyword":"portuguese","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/emdemor/sql-create-context-pt","creator_name":"Eduardo Morais","creator_url":"https://huggingface.co/emdemor","description":"\n\t\n\t\t\n\t\tOverview\n\t\n\nEste dataset  √© uma vers√£o traduzida para o portugu√™s do dataset b-mc2/sql-create-context,\nque foi constru√≠do a partir dos datasets WikiSQL e Spider. Ele cont√©m exemplos de perguntas\nem portugu√™s, instru√ß√µes SQL CREATE TABLE e consultas SQL que respondem √†s perguntas\nutilizando a instru√ß√£o CREATE TABLE como contexto.\nO principal objetivo deste dataset √© ajudar modelos de linguagem natural  em portugu√™s a gerar consultas\nSQL precisas e contextualizadas, prevenindo a‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/emdemor/sql-create-context-pt.","first_N":5,"first_N_keywords":["text-generation","question-answering","table-question-answering","Portuguese","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"bitext_sib200_miners","keyword":"portuguese","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/gentaiscool/bitext_sib200_miners","creator_name":"Genta Indra Winata","creator_url":"https://huggingface.co/gentaiscool","description":"gentaiscool/bitext_sib200_miners dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["multilingual","Achinese","Mesopotamian Arabic","Ta'izzi-Adeni Arabic","Tunisian Arabic"],"keywords_longer_than_N":true},
	{"name":"InvoicesReceiptsPT","keyword":"portuguese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Francisco-Cruz/InvoicesReceiptsPT","creator_name":"Francisco Cruz","creator_url":"https://huggingface.co/Francisco-Cruz","description":"This is a dataset comprising 1003 images of invoices and receipts, as well as the transcription of relevant fields for each document ‚Äì seller name, seller address, seller tax identification, buyer tax identification, invoice date, invoice total amount, invoice tax amount, and document reference. \nIt is organized as:\n\nfolder 1_Images: files with pictures od the invoices/receipts \nfolder 2_Annotations_Json: text files with the annotations on a json format\n\nAlso available at:‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Francisco-Cruz/InvoicesReceiptsPT.","first_N":5,"first_N_keywords":["text-classification","Portuguese","apache-2.0","1K - 10K","imagefolder"],"keywords_longer_than_N":true},
	{"name":"biblenlp-corpus-mmteb","keyword":"portuguese","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/biblenlp-corpus-mmteb","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"This dataset pre-computes all English-centric directions from bible-nlp/biblenlp-corpus, and as a result loading is significantly faster.\nLoading example:\n>>> from datasets import load_dataset\n>>> dataset = load_dataset(\"davidstap/biblenlp-corpus-mmteb\", \"eng-arb\", trust_remote_code=True)\n>>> dataset\nDatasetDict({\n    train: Dataset({\n        features: ['eng', 'arb'],\n        num_rows: 28723\n    })\n    validation: Dataset({\n        features: ['eng', 'arb'],\n        num_rows: 1578\n    })‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/biblenlp-corpus-mmteb.","first_N":5,"first_N_keywords":["no-annotation","expert-generated","translation","multilingual","Arifama-Miniafia"],"keywords_longer_than_N":true},
	{"name":"medical-translation-test-set","keyword":"portuguese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/ai-amplified/medical-translation-test-set","creator_name":"admin","creator_url":"https://huggingface.co/ai-amplified","description":"ai-amplified/medical-translation-test-set dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["English","French","Portuguese","Romanian","German"],"keywords_longer_than_N":true},
	{"name":"librivox-tracks","keyword":"portuguese","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/xacer/librivox-tracks","creator_name":"xacer","creator_url":"https://huggingface.co/xacer","description":"A dataset of all audio files uploaded to LibriVox before 26th September 2023.\nForked from https://huggingface.co/datasets/pykeio/librivox-tracks\nChanges:\n\nUsed archive.org metadata API to annotate rows with \"duration\" column\n\n","first_N":5,"first_N_keywords":["text-to-speech","automatic-speech-recognition","feature-extraction","Achinese","Afrikaans"],"keywords_longer_than_N":true},
	{"name":"social_i_qa_pt","keyword":"portuguese","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/fabiogr/social_i_qa_pt","creator_name":"Fabio Grassiotto","creator_url":"https://huggingface.co/fabiogr","description":"\n\t\n\t\t\n\t\tSocialIQa dataset v1.4 (PT)\n\t\n\nThis is translation to the portuguese language of the dataset allenai/social_i_qa.Translations were done using three independent models:  \n\nHelsinki-NLP/opus-mt-tc-big-en-pt\nunicamp-dl/translation-en-pt-t5  \nfacebook/nllb-200-distilled-1.3B\n\nTranslations were evaluated using the evaluation metric GEMBA - GPT Estimation Metric Based Assessment\n(from the article Large Language Models Are State-of-the-Art Evaluators of Translation Quality) using‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/fabiogr/social_i_qa_pt.","first_N":5,"first_N_keywords":["Portuguese","cc-by-4.0","10K - 100K","json","Text"],"keywords_longer_than_N":true},
	{"name":"fleurs_clean","keyword":"portuguese","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Helloworld668/fleurs_clean","creator_name":"zhide Tang","creator_url":"https://huggingface.co/Helloworld668","description":"\n\t\n\t\t\n\t\n\t\n\t\tFLEURS\n\t\n\nFleurs is the speech version of the FLoRes machine translation benchmark. \nWe use 2009 n-way parallel sentences from the FLoRes dev and devtest publicly available sets, in 102 languages. \nTraining sets have around 10 hours of supervision. Speakers of the train sets are different than speakers from the dev/test sets. Multilingual fine-tuning is\nused and ‚Äùunit error rate‚Äù (characters, signs) of all languages is averaged. Languages and results are also grouped into seven‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Helloworld668/fleurs_clean.","first_N":5,"first_N_keywords":["automatic-speech-recognition","expert-generated","crowdsourced","machine-generated","crowdsourced"],"keywords_longer_than_N":true},
	{"name":"portuguese-blogs","keyword":"portuguese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/fabiovilao/portuguese-blogs","creator_name":"fabio vila","creator_url":"https://huggingface.co/fabiovilao","description":"\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Details\n\t\n\nBlog-1 may include other languages in an unstructured text format without markdown. The latest one, Blog-6, is formatted in markdown and may contain less other languages text.\nTexts are separated by the string <|endoftext|>.\n\n\t\n\t\t\n\t\n\t\n\t\tUses\n\t\n\nTraining language models.\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Structure\n\t\n\nA simple text file with articles separated by <|endoftext|> between each text.\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Creation\n\t\n\nFirst semester of 2024.\n\n\t\n\t\t\n\t\n\t\n\t\tBias, Risks‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/fabiovilao/portuguese-blogs.","first_N":5,"first_N_keywords":["text-generation","Portuguese","apache-2.0","100M - 1B","text"],"keywords_longer_than_N":true},
	{"name":"portuguese-blogs","keyword":"portuguese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/fabiovilao/portuguese-blogs","creator_name":"fabio vila","creator_url":"https://huggingface.co/fabiovilao","description":"\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Details\n\t\n\nBlog-1 may include other languages in an unstructured text format without markdown. The latest one, Blog-6, is formatted in markdown and may contain less other languages text.\nTexts are separated by the string <|endoftext|>.\n\n\t\n\t\t\n\t\n\t\n\t\tUses\n\t\n\nTraining language models.\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Structure\n\t\n\nA simple text file with articles separated by <|endoftext|> between each text.\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Creation\n\t\n\nFirst semester of 2024.\n\n\t\n\t\t\n\t\n\t\n\t\tBias, Risks‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/fabiovilao/portuguese-blogs.","first_N":5,"first_N_keywords":["text-generation","Portuguese","apache-2.0","100M - 1B","text"],"keywords_longer_than_N":true},
	{"name":"testedados","keyword":"portuguese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/MatheusFr/testedados","creator_name":"Matheus Francisco","creator_url":"https://huggingface.co/MatheusFr","description":"MatheusFr/testedados dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["text-classification","text-generation","Portuguese","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"xP3x-Kongo","keyword":"portuguese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Svngoku/xP3x-Kongo","creator_name":"NIONGOLO Chrys F√©-Marty","creator_url":"https://huggingface.co/Svngoku","description":"\n\t\n\t\t\n\t\tDataset Card for xP3x Kikongo Focus\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\n\nxP3x (Crosslingual Public Pool of Prompts eXtended) is a collection of prompts & datasets across 277 languages & 16 NLP tasks. It contains all of xP3 + much more! It is used for training future contenders of mT0 & BLOOMZ at project Aya @C4AI üß°\n\n\nCreation: The dataset can be recreated using instructions available here together with the file in this repository named xp3x_create.py. We provide this version to save‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Svngoku/xP3x-Kongo.","first_N":5,"first_N_keywords":["other","translation","expert-generated","crowdsourced","multilingual"],"keywords_longer_than_N":true},
	{"name":"medicine-evaluation-pt-tokenized-2048","keyword":"portuguese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mmoreirast/medicine-evaluation-pt-tokenized-2048","creator_name":"Mariana Moreira","creator_url":"https://huggingface.co/mmoreirast","description":"\n\t\n\t\t\n\t\tEvaluation Dataset for Doctor Llama\n\t\n\nThis repository contains a tokenized version of medicine-evaluation-pt.\n\n\t\n\t\t\n\t\tAuthor\n\t\n\nMariana Moreira dos Santos (LinkedIn)\n","first_N":5,"first_N_keywords":["question-answering","Portuguese","apache-2.0","< 1K","parquet"],"keywords_longer_than_N":true},
	{"name":"sigarra","keyword":"portuguese","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/neuralshift/sigarra","creator_name":"NeuralShift","creator_url":"https://huggingface.co/neuralshift","description":"\n\t\n\t\t\n\t\tDataset Card for \"sigarra\"\n\t\n\nThe \"sigarra\" dataset available on Hugging Face is not a property of NeuralShift. We are uploading it to the platform to increase its accessibility and foster further research.\nHere's some additional information about the original SIGARRA News Corpus:\nSource: University of Porto (UP) SIGARRA information system\nContent: A collection of academic news articles with manual annotations for named entity recognition.\nSize: Approximately 4.22 MB\nFormat:‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/neuralshift/sigarra.","first_N":5,"first_N_keywords":["Portuguese","cc-by-sa-4.0","< 1K","parquet","Text"],"keywords_longer_than_N":true},
	{"name":"nurc-sp_pseudo_labelled-dev","keyword":"portuguese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/RodrigoLimaRFL/nurc-sp_pseudo_labelled-dev","creator_name":"Rodrigo de Freitas Lima","creator_url":"https://huggingface.co/RodrigoLimaRFL","description":"RodrigoLimaRFL/nurc-sp_pseudo_labelled-dev dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["Portuguese","mit","< 1K","parquet","Audio"],"keywords_longer_than_N":true},
	{"name":"treino","keyword":"portuguese","license":"GNU General Public License v3.0","license_url":"https://choosealicense.com/licenses/gpl-3.0/","language":"en","dataset_url":"https://huggingface.co/datasets/colab-tjap/treino","creator_name":"Trainee TJAP","creator_url":"https://huggingface.co/colab-tjap","description":"Primeiro teste\n","first_N":5,"first_N_keywords":["Portuguese","gpl-3.0","< 1K","json","Text"],"keywords_longer_than_N":true},
	{"name":"olist_customers_review","keyword":"portuguese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/verissimomanoel/olist_customers_review","creator_name":"Manoel Ver√≠ssimo dos Santos Neto","creator_url":"https://huggingface.co/verissimomanoel","description":"verissimomanoel/olist_customers_review dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["text-classification","Portuguese","apache-2.0","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"text-to-icpc2","keyword":"portuguese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/diogocarapito/text-to-icpc2","creator_name":"Diogo Carapito","creator_url":"https://huggingface.co/diogocarapito","description":"\n\t\n\t\t\n\t\tDataset Card for Dataset Name\n\t\n\n\n\n\n\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\n\n\nThis dataset to train a text classification model for  ICPC2 codes in portuguese\n\nCurated by: [More Information Needed]\nFunded by [optional]: [More Information Needed]\nShared by [optional]: [More Information Needed]\nLanguage(s) (NLP): pt\nLicense: apache-2.0\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Sources [optional]\n\t\n\n\n\n\nRepository: https://github.com/diogocarapito/text-to-icpc2\nPaper [optional]: [More‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/diogocarapito/text-to-icpc2.","first_N":5,"first_N_keywords":["text-classification","Portuguese","apache-2.0","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"Emakhuwa-Portuguese-News-MT","keyword":"portuguese","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/LIACC/Emakhuwa-Portuguese-News-MT","creator_name":"LIACC","creator_url":"https://huggingface.co/LIACC","description":"\n\t\n\t\t\n\t\tNews Parallel Dataset for Emakhuwa of Mozambique\n\t\n\n\n\nThis repository contains releases of parallel data for machine translation in Mozambican languages. \nCurrently, it supports one language pair, Portuguese-Emakhuwa, Emakhuwa being the widely spoken language in Mozambique.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\n\n\n\n\nFunded by: This dataset was created with support from Lacuna Fund, the world‚Äôs first collaborative effort to provide data scientists, researchers, and‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/LIACC/Emakhuwa-Portuguese-News-MT.","first_N":5,"first_N_keywords":["translation","Makhuwa","Portuguese","cc-by-4.0","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"Emakhuwa-FLORES","keyword":"portuguese","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/LIACC/Emakhuwa-FLORES","creator_name":"LIACC","creator_url":"https://huggingface.co/LIACC","description":"\n\t\n\t\t\n\t\tDataset card\n\t\n\n\n\t\n\t\t\n\t\tDescription\n\t\n\n\n\nFLORES+ dev and devtest set in Emakhuwa\n\n\t\n\t\t\n\t\tLicense\n\t\n\n\nCC-BY-SA-4.0\n\n\t\n\t\t\n\t\tAttribution\n\t\n\n\n\n@inproceedings{ali-etal-2024-expanding,\n    title = \"Expanding {FLORES}+ Benchmark for More Low-Resource Settings: {P}ortuguese-Emakhuwa Machine Translation Evaluation\",\n    author = \"Ali, Felermino Dario Mario  and\n      Lopes Cardoso, Henrique  and\n      Sousa-Silva, Rui\",\n    editor = \"Haddow, Barry  and\n      Kocmi, Tom  and\n      Koehn, Philipp‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/LIACC/Emakhuwa-FLORES.","first_N":5,"first_N_keywords":["Portuguese","Makhuwa","cc-by-sa-4.0","1K - 10K","json"],"keywords_longer_than_N":true},
	{"name":"zenless_zone_zero_interknots_v1.0","keyword":"portuguese","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mrzjy/zenless_zone_zero_interknots_v1.0","creator_name":"jiayi","creator_url":"https://huggingface.co/mrzjy","description":"\n\t\n\t\t\n\t\n\t\n\t\tZZZ Interknots\n\t\n\nThis datasets contains extracted Interknot posts and comments (Áª≥ÁΩëÁöÑÂçöÂÆ¢‰∏éËØÑËÆ∫) in multi-language.\nUp to game version: 1.0\n\nInterknot posts and comments examples\n\n{\n  \"id\": \"1021\",\n  \"poster\": \"Sorrowful Intern\",\n  \"title\": \"[Commission] Missing Bangboo merchants\",\n  \"text\": \"Hello, pros... Some of the senior Bangboo of our merchant association have gone missing! We urgently need an expert to help find them!!\\nLet me explain, I recently joined a very prestigious‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mrzjy/zenless_zone_zero_interknots_v1.0.","first_N":5,"first_N_keywords":["text-generation","Chinese","English","Japanese","German"],"keywords_longer_than_N":true},
	{"name":"wikipedia-2024-06-bge-m3","keyword":"portuguese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Upstash/wikipedia-2024-06-bge-m3","creator_name":"Upstash","creator_url":"https://huggingface.co/Upstash","description":"\n\t\n\t\t\n\t\tWikipedia Embeddings with BGE-M3\n\t\n\nThis dataset contains embeddings from the\nJune 2024 Wikipedia dump\nfor the 11 most popular languages.\nThe embeddings are generated with the multilingual\nBGE-M3 model.\nThe dataset consists of Wikipedia articles split into paragraphs,\nand embedded with the aforementioned model.\nTo enhance search quality, the paragraphs are prefixed with their\nrespective article titles before embedding.\nAdditionally, paragraphs containing fewer than 100 characters‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Upstash/wikipedia-2024-06-bge-m3.","first_N":5,"first_N_keywords":["English","German","Spanish","Persian","French"],"keywords_longer_than_N":true},
	{"name":"XL-HeadTags","keyword":"portuguese","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/faisaltareque/XL-HeadTags","creator_name":"Faisal Tareque Shohan","creator_url":"https://huggingface.co/faisaltareque","description":"\n\t\n\t\t\n\t\tDataset Card for XL-HeadTags Corpus\n\t\n\n\n\t\n\t\t\n\t\tDataset Source\n\t\n\nWe have used M3LS and XL-Sum as source for this dataset.\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\n We provide XL-HeadTags, a large-scale news headline and tags generation dataset. The dataset consists of 20 languages across six diverse language families. It contains 415K news headline-article pairs with auxiliary information such as image captions, topic words (read more).\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\n\t\n\t\t\n\t\tData Instances\n\t\n\nOne‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/faisaltareque/XL-HeadTags.","first_N":5,"first_N_keywords":["summarization","sentence-similarity","English","Portuguese","Spanish"],"keywords_longer_than_N":true},
	{"name":"testeliminha","keyword":"portuguese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Ciscomuna/testeliminha","creator_name":"Jo√£o Gabriel da Silva dos Santos","creator_url":"https://huggingface.co/Ciscomuna","description":"\n\t\n\t\t\n\t\tDataset Card for Dataset Name\n\t\n\n\n\nThis dataset card aims to be a base template for new datasets. It has been generated using this raw template.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\n\n\n\n\n\nCurated by: [More Information Needed]\nFunded by [optional]: [More Information Needed]\nShared by [optional]: [More Information Needed]\nLanguage(s) (NLP): [More Information Needed]\nLicense: [More Information Needed]\n\n\n\t\n\t\t\n\t\tDataset Sources [optional]\n\t\n\n\n\n\nRepository: [More‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Ciscomuna/testeliminha.","first_N":5,"first_N_keywords":["question-answering","Portuguese","apache-2.0","< 1K","csv"],"keywords_longer_than_N":true},
	{"name":"Multi-Opthalingua","keyword":"portuguese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/AAAIBenchmark/Multi-Opthalingua","creator_name":"AAAIBenchmark","creator_url":"https://huggingface.co/AAAIBenchmark","description":"\n\t\n\t\t\n\t\tCite\n\t\n\nAccepted to AAAI 2025 (https://openreview.net/group?id=AAAI.org/2025/Conference#tab-recent-activity)\nMulti-OphthaLingua: A Multilingual Benchmark for Assessing and Debiasing LLM Ophthalmological QA in LMICs:\n@misc{restrepo2024multiophthalinguamultilingualbenchmarkassessing,\n      title={Multi-OphthaLingua: A Multilingual Benchmark for Assessing and Debiasing LLM Ophthalmological QA in LMICs}, \n      author={David Restrepo and Chenwei Wu and Zhengxu Tang and Zitao Shuai and Thao‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/AAAIBenchmark/Multi-Opthalingua.","first_N":5,"first_N_keywords":["question-answering","Hindi","Chinese","English","Spanish"],"keywords_longer_than_N":true},
	{"name":"nothing_is_real","keyword":"portuguese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Monteiroo/nothing_is_real","creator_name":"Igor Gabriel Monteiro","creator_url":"https://huggingface.co/Monteiroo","description":"Monteiroo/nothing_is_real dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["Portuguese","mit","10K - 100K","csv","Text"],"keywords_longer_than_N":true},
	{"name":"gemini_orpo_dpo_ptbr","keyword":"portuguese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/celsowm/gemini_orpo_dpo_ptbr","creator_name":"Celso F","creator_url":"https://huggingface.co/celsowm","description":"celsowm/gemini_orpo_dpo_ptbr dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["text-generation","question-answering","Portuguese","apache-2.0","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"flores","keyword":"portuguese","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/flores","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  FloresBitextMining\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nFLORES is a benchmark dataset for machine translation between English and low-resource languages.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2t\n\n\nDomains\nNon-fiction, Encyclopaedic, Written\n\nReference\nhttps://huggingface.co/datasets/facebook/flores\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask = mteb.get_tasks([\"FloresBitextMining\"])‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/flores.","first_N":5,"first_N_keywords":["translation","human-annotated","multilingual","Achinese","Mesopotamian Arabic"],"keywords_longer_than_N":true},
	{"name":"NTREX","keyword":"portuguese","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/NTREX","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  NTREXBitextMining\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nNTREX is a News Test References dataset for Machine Translation Evaluation, covering translation from English into 128 languages. We select language pairs according to the M2M-100 language grouping strategy, resulting in 1916 directions.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2t\n\n\nDomains\nNews, Written\n\n\nReference\nhttps://huggingface.co/datasets/davidstap/NTREX\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/NTREX.","first_N":5,"first_N_keywords":["translation","expert-annotated","expert-generated","translated","Afrikaans"],"keywords_longer_than_N":true},
	{"name":"ParaNames","keyword":"portuguese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/bltlab/ParaNames","creator_name":"Broadening Linguistic Technologies Lab (BLT Lab)","creator_url":"https://huggingface.co/bltlab","description":"\n\t\n\t\t\n\t\n\t\n\t\tDataset Card for Dataset Name\n\t\n\n\n\nThis dataset card aims to be a base template for new datasets. It has been generated using this raw template.\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Description\n\t\n\n\n\n\n\n\nCurated by: [More Information Needed]\nFunded by [optional]: [More Information Needed]\nShared by [optional]: [More Information Needed]\nLanguage(s) (NLP): [More Information Needed]\nLicense: [More Information Needed]\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Sources [optional]‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/bltlab/ParaNames.","first_N":5,"first_N_keywords":["token-classification","Nias","Kotava","Banjar","Angika"],"keywords_longer_than_N":true},
	{"name":"xm3600","keyword":"portuguese","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/floschne/xm3600","creator_name":"Flo Schneider","creator_url":"https://huggingface.co/floschne","description":"\n\t\n\t\t\n\t\n\t\n\t\tXM3600 - Crossmodal-3600\n\t\n\n\n\t\n\t\t\n\t\n\t\n\t\tThis is a copy from https://google.github.io/crossmodal-3600/\n\t\n\nIf you use this dataset, please cite the original authors:\n@inproceedings{ThapliyalCrossmodal2022,\n  author = {Ashish Thapliyal and Jordi Pont-Tuset and Xi Chen and Radu Soricut},\n  title = {{Crossmodal-3600: A Massively Multilingual Multimodal Evaluation Dataset}},\n  booktitle = {EMNLP},\n  year = {2022}\n}\n\nIt also includes the image features as PIL Image and has a uniform and‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/floschne/xm3600.","first_N":5,"first_N_keywords":["image-to-text","Arabic","Bengali","Czech","Danish"],"keywords_longer_than_N":true},
	{"name":"xm3600_1k","keyword":"portuguese","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/floschne/xm3600_1k","creator_name":"Flo Schneider","creator_url":"https://huggingface.co/floschne","description":"\n\t\n\t\t\n\t\n\t\n\t\tXM3600 - Crossmodal-3600 - 1K Split\n\t\n\n\n\t\n\t\t\n\t\n\t\n\t\tThis is a copy from https://google.github.io/crossmodal-3600/\n\t\n\nIf you use this dataset, please cite the original authors:\n@inproceedings{ThapliyalCrossmodal2022,\n  author = {Ashish Thapliyal and Jordi Pont-Tuset and Xi Chen and Radu Soricut},\n  title = {{Crossmodal-3600: A Massively Multilingual Multimodal Evaluation Dataset}},\n  booktitle = {EMNLP},\n  year = {2022}\n}\n\n\n\t\n\t\t\n\t\n\t\n\t\tThis is a 1K split of XM3600!\n\t\n\nFor this, we‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/floschne/xm3600_1k.","first_N":5,"first_N_keywords":["image-to-text","Arabic","Bengali","Czech","Danish"],"keywords_longer_than_N":true},
	{"name":"xgqa","keyword":"portuguese","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/floschne/xgqa","creator_name":"Flo Schneider","creator_url":"https://huggingface.co/floschne","description":"\n\t\n\t\t\n\t\txGQA\n\t\n\n\n\t\n\t\t\n\t\tThis is a clone of the few_shot-test split of the xGQA dataset\n\t\n\nPlease find the original repository here: https://github.com/adapter-hub/xGQA\nIf you use this dataset, please cite the original authors:\n@inproceedings{pfeiffer-etal-2021-xGQA,\n    title={{xGQA: Cross-Lingual Visual Question Answering}},\n    author={ Jonas Pfeiffer and Gregor Geigle and Aishwarya Kamath and Jan-Martin O. Steitz and Stefan Roth and Ivan Vuli{\\'{c}} and Iryna Gurevych},\n    booktitle =‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/floschne/xgqa.","first_N":5,"first_N_keywords":["visual-question-answering","Bengali","German","English","Indonesian"],"keywords_longer_than_N":true},
	{"name":"cpc_2015_brasil","keyword":"portuguese","license":"Academic Free License v3.0","license_url":"https://choosealicense.com/licenses/afl-3.0/","language":"en","dataset_url":"https://huggingface.co/datasets/0rakul0/cpc_2015_brasil","creator_name":"Jefferson Silva dos Anjos","creator_url":"https://huggingface.co/0rakul0","description":"\n\t\n\t\t\n\t\tSALVAMENTO do Dataset\n\t\n\nfrom datasets import load_dataset\nfrom datasets import Dataset\nimport pandas as pd\n\n# Carregar os dados do arquivo de texto\ndf = pd.read_parquet('../data/cpc_2015_cleaned.parquet')\n\ndata = {\n    \"livro\": df[\"Livro\"],\n    \"capitulo\": df[\"Capitulo\"],\n    \"titulo\": df[\"Titulo\"],\n    \"secao\": df[\"Secao\"],\n    \"subsecao\": df[\"Subsecao\"],\n    \"artigo\": df[\"Artigo\"]\n}\n\n# Dividir o texto em se√ß√µes\ndataset = Dataset.from_pandas(pd.DataFrame(data))‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/0rakul0/cpc_2015_brasil.","first_N":5,"first_N_keywords":["text-classification","question-answering","summarization","Portuguese","afl-3.0"],"keywords_longer_than_N":true},
	{"name":"x-fact","keyword":"portuguese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/utahnlp/x-fact","creator_name":"NLP at University of Utah","creator_url":"https://huggingface.co/utahnlp","description":"\n\t\n\t\t\n\t\tDataset Card for \"x-fact\"\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nX-FACT is a multilingual dataset for fact-checking with real world claims. The dataset contains short statments in 25 languages with top five evidence documents retrieved by performing google search with claim statements. The dataset contains two additional evaluation splits (in addition to a traditional test set): ood and zeroshot. ood measures out-of-domain generalization where while the language‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/utahnlp/x-fact.","first_N":5,"first_N_keywords":["text-classification","Arabic","Bengali","Spanish","Persian"],"keywords_longer_than_N":true},
	{"name":"xgqa_1k","keyword":"portuguese","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/floschne/xgqa_1k","creator_name":"Flo Schneider","creator_url":"https://huggingface.co/floschne","description":"\n\t\n\t\t\n\t\txGQA 1K\n\t\n\n\n\t\n\t\t\n\t\tThis is a 1K subset of the few_shot-test split of the xGQA dataset\n\t\n\nPlease find the original repository here: https://github.com/adapter-hub/xGQA\nIf you use this dataset, please cite the original authors:\n@inproceedings{pfeiffer-etal-2021-xGQA,\n    title={{xGQA: Cross-Lingual Visual Question Answering}},\n    author={ Jonas Pfeiffer and Gregor Geigle and Aishwarya Kamath and Jan-Martin O. Steitz and Stefan Roth and Ivan Vuli{\\'{c}} and Iryna Gurevych},\n    booktitle‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/floschne/xgqa_1k.","first_N":5,"first_N_keywords":["visual-question-answering","Bengali","German","English","Indonesian"],"keywords_longer_than_N":true},
	{"name":"from-one-to-many-toxicity-mitigation","keyword":"portuguese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/luizapzbn/from-one-to-many-toxicity-mitigation","creator_name":"Luiza Pozzobon","creator_url":"https://huggingface.co/luizapzbn","description":"\n\t\n\t\t\n\t\n\t\n\t\tFrom One to Many: Expanding the Scope of Toxicity Mitigation in Language Models\n\t\n\n[arxiv][code][data]\nData accompanying the paper \"From One to Many: Expanding the Scope of Toxicity Mitigation in Language Models\" accepted to ACL Findings 2024.\nAbstract: To date, toxicity mitigation in language models has almost entirely been focused on single-language settings. As language models embrace multilingual capabilities, it‚Äôs crucial our safety measures keep pace. Recognizing this‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/luizapzbn/from-one-to-many-toxicity-mitigation.","first_N":5,"first_N_keywords":["text-generation","text-classification","English","Portuguese","Hindi"],"keywords_longer_than_N":true},
	{"name":"text_ratings","keyword":"portuguese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/lightblue/text_ratings","creator_name":"Lightblue KK.","creator_url":"https://huggingface.co/lightblue","description":"Todo - Write dataset card\n","first_N":5,"first_N_keywords":["Amharic","Arabic","Bulgarian","Bengali","Czech"],"keywords_longer_than_N":true},
	{"name":"Wikipedia-Abstract","keyword":"portuguese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/laion/Wikipedia-Abstract","creator_name":"LAION eV","creator_url":"https://huggingface.co/laion","description":"Wikipedia Abstract\n\n\n  \n\n\n\nIntroducing Wikipedia Abstract, a comprehensive dataset encompassing abstracts, complete articles, and a popularity score index for both widely spoken and lesser-known Wikipedia subsets. Our dedication to Wikipedia-X ensures a centralized Wikipedia dataset that undergoes regular updates and adheres to the highest standards.\nA central focus of our efforts was to include exotic languages that often lack up-to-date Wikipedia dumps or may not have any dumps at all.‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/laion/Wikipedia-Abstract.","first_N":5,"first_N_keywords":["text-classification","question-answering","text-generation","fill-mask","Arabic"],"keywords_longer_than_N":true},
	{"name":"estatuto","keyword":"portuguese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/abelrh/estatuto","creator_name":"Abel Melo Borges","creator_url":"https://huggingface.co/abelrh","description":"abelrh/estatuto dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["question-answering","Portuguese","apache-2.0","< 1K","json"],"keywords_longer_than_N":true},
	{"name":"LEI40","keyword":"portuguese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/abelrh/LEI40","creator_name":"Abel Melo Borges","creator_url":"https://huggingface.co/abelrh","description":"abelrh/LEI40 dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["Portuguese","apache-2.0","< 1K","json","Text"],"keywords_longer_than_N":true},
	{"name":"TechnicalDebt_GitHubIssues_PT","keyword":"portuguese","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/IuryCavalcante/TechnicalDebt_GitHubIssues_PT","creator_name":"Iury Cavalcante","creator_url":"https://huggingface.co/IuryCavalcante","description":"\n\t\n\t\t\n\t\tTechnical Debt in GitHub Issues (Portuguese)\n\t\n\n\n\t\n\t\t\n\t\tVis√£o Geral\n\t\n\nEste dataset re√∫ne issues p√∫blicas extra√≠das do GitHub que mencionam o termo \"d√≠vida t√©cnica\" ou suas varia√ß√µes em portugu√™s. A base foi constru√≠da com o objetivo de apoiar pesquisas em Engenharia de Software, Processamento de Linguagem Natural (PLN) e Intelig√™ncia Artificial, com foco na compreens√£o e classifica√ß√£o de como o conceito de d√≠vida t√©cnica √© comunicado por desenvolvedores.\nA estrutura e categoriza√ß√£o‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/IuryCavalcante/TechnicalDebt_GitHubIssues_PT.","first_N":5,"first_N_keywords":["text-classification","Portuguese","cc-by-4.0","< 1K","csv"],"keywords_longer_than_N":true},
	{"name":"TechnicalDebt_GitHubIssues_PT","keyword":"portuguese","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/IuryCavalcante/TechnicalDebt_GitHubIssues_PT","creator_name":"Iury Cavalcante","creator_url":"https://huggingface.co/IuryCavalcante","description":"\n\t\n\t\t\n\t\tTechnical Debt in GitHub Issues (Portuguese)\n\t\n\n\n\t\n\t\t\n\t\tVis√£o Geral\n\t\n\nEste dataset re√∫ne issues p√∫blicas extra√≠das do GitHub que mencionam o termo \"d√≠vida t√©cnica\" ou suas varia√ß√µes em portugu√™s. A base foi constru√≠da com o objetivo de apoiar pesquisas em Engenharia de Software, Processamento de Linguagem Natural (PLN) e Intelig√™ncia Artificial, com foco na compreens√£o e classifica√ß√£o de como o conceito de d√≠vida t√©cnica √© comunicado por desenvolvedores.\nA estrutura e categoriza√ß√£o‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/IuryCavalcante/TechnicalDebt_GitHubIssues_PT.","first_N":5,"first_N_keywords":["text-classification","Portuguese","cc-by-4.0","< 1K","csv"],"keywords_longer_than_N":true},
	{"name":"voices-of-civilizations","keyword":"portuguese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/sander-wood/voices-of-civilizations","creator_name":"Shangda Wu (Sander Wood)","creator_url":"https://huggingface.co/sander-wood","description":"\n\t\n\t\t\n\t\tVoices of Civilizations (VoC)\n\t\n\nVoices of Civilizations (VoC) is the first multilingual QA benchmark designed to assess audio LLMs‚Äô cultural comprehension using full-length music recordings. VoC spans:\n\n38 languages (including zh, en, hi, es, fr, ja, ko, ar, sw, bn, de, pt, ru, etc.)\n380 tracks drawn from traditional and regional music\n860 multiple-choice questions probing four dimensions: language, region, mood, and theme\n\nVoC exposes models‚Äô biases and weaknesses on‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/sander-wood/voices-of-civilizations.","first_N":5,"first_N_keywords":["question-answering","Arabic","Bengali","Bulgarian","Chinese"],"keywords_longer_than_N":true},
	{"name":"synthetic_transcript_pt","keyword":"portuguese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/yuriyvnv/synthetic_transcript_pt","creator_name":"Yuriy Perezhohin","creator_url":"https://huggingface.co/yuriyvnv","description":"\n\t\n\t\t\n\t\tPortuguese Speech Dataset with Multiple Training Configurations\n\t\n\nA comprehensive Portuguese speech dataset offering three distinct training configurations for speech recognition research, each designed for different experimental scenarios and training paradigms.\n\n\t\n\t\t\n\t\tüéØ Dataset Configurations Overview\n\t\n\nThis dataset provides three carefully curated subsets to enable comprehensive speech recognition research:\n\n\t\n\t\t\nConfiguration\nTraining Data\nValidation\nTest\nTotal Samples\nUse Case‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/yuriyvnv/synthetic_transcript_pt.","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","audio-classification","Portuguese","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"synthetic_transcript_pt","keyword":"portuguese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/yuriyvnv/synthetic_transcript_pt","creator_name":"Yuriy Perezhohin","creator_url":"https://huggingface.co/yuriyvnv","description":"\n\t\n\t\t\n\t\tPortuguese Speech Dataset with Multiple Training Configurations\n\t\n\nA comprehensive Portuguese speech dataset offering three distinct training configurations for speech recognition research, each designed for different experimental scenarios and training paradigms.\n\n\t\n\t\t\n\t\tüéØ Dataset Configurations Overview\n\t\n\nThis dataset provides three carefully curated subsets to enable comprehensive speech recognition research:\n\n\t\n\t\t\nConfiguration\nTraining Data\nValidation\nTest\nTotal Samples\nUse Case‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/yuriyvnv/synthetic_transcript_pt.","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","audio-classification","Portuguese","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"portugese_ner_dataset","keyword":"portuguese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/HUMADEX/portugese_ner_dataset","creator_name":"HUMADEX Research Group","creator_url":"https://huggingface.co/HUMADEX","description":"\n\t\n\t\t\n\t\tPortugese NER dataset\n\t\n\n\n\t\n\t\t\n\t\tAcknowledgement\n\t\n\nThis dataset had been created as part of joint research of HUMADEX research group (https://www.linkedin.com/company/101563689/) and has received funding by the European Union Horizon Europe Research and Innovation Program project SMILE (grant number 101080923) and Marie Sk≈Çodowska-Curie Actions (MSCA) Doctoral Networks, project BosomShield ((rant number 101073222). Responsibility for the information and views expressed herein lies‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/HUMADEX/portugese_ner_dataset.","first_N":5,"first_N_keywords":["token-classification","Portuguese","apache-2.0","100K - 1M","parquet"],"keywords_longer_than_N":true},
	{"name":"ApolloMoEDataset","keyword":"portuguese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/FreedomIntelligence/ApolloMoEDataset","creator_name":"FreedomAI","creator_url":"https://huggingface.co/FreedomIntelligence","description":"\n\t\n\t\t\n\t\tDemocratizing Medical LLMs For Much More Languages\n\t\n\nCovering 12 Major Languages including English, Chinese, French, Hindi, Spanish, Arabic, Russian, Japanese, Korean, German, Italian, Portuguese and 38 Minor Languages So far.\n\n   üìÉ Paper ‚Ä¢ üåê Demo ‚Ä¢ ü§ó ApolloMoEDataset ‚Ä¢ ü§ó ApolloMoEBench  ‚Ä¢ ü§ó Models  ‚Ä¢üåê Apollo  ‚Ä¢ üåê ApolloMoE\n\n\n\n\n\n\n\t\n\t\t\n\t\tüåà Update\n\t\n\n\n[2024.10.15] ApolloMoE repo is publishedÔºÅüéâ\n\n\n\t\n\t\t\n\t\tLanguages Coverage\n\t\n\n12 Major Languages and 38 Minor Languages\n\n  Click to‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/FreedomIntelligence/ApolloMoEDataset.","first_N":5,"first_N_keywords":["question-answering","Arabic","English","Chinese","Korean"],"keywords_longer_than_N":true},
	{"name":"ApolloMoEBench","keyword":"portuguese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/FreedomIntelligence/ApolloMoEBench","creator_name":"FreedomAI","creator_url":"https://huggingface.co/FreedomIntelligence","description":"\n\t\n\t\t\n\t\tDemocratizing Medical LLMs For Much More Languages\n\t\n\nCovering 12 Major Languages including English, Chinese, French, Hindi, Spanish, Arabic, Russian, Japanese, Korean, German, Italian, Portuguese and 38 Minor Languages So far.\n\n   üìÉ Paper ‚Ä¢ üåê Demo ‚Ä¢ ü§ó ApolloMoEDataset ‚Ä¢ ü§ó ApolloMoEBench  ‚Ä¢ ü§ó Models  ‚Ä¢üåê Apollo  ‚Ä¢ üåê ApolloMoE\n\n\n\n\n\n\n\t\n\t\t\n\t\tüåà Update\n\t\n\n\n[2024.10.15] ApolloMoE repo is publishedÔºÅüéâ\n\n\n\t\n\t\t\n\t\tLanguages Coverage\n\t\n\n12 Major Languages and 38 Minor Languages\n\n  Click to‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/FreedomIntelligence/ApolloMoEBench.","first_N":5,"first_N_keywords":["question-answering","Arabic","English","Chinese","Korean"],"keywords_longer_than_N":true},
	{"name":"product-database","keyword":"portuguese","license":"GNU Affero General Public License v3.0","license_url":"https://choosealicense.com/licenses/agpl-3.0/","language":"en","dataset_url":"https://huggingface.co/datasets/openfoodfacts/product-database","creator_name":"Open Food Facts","creator_url":"https://huggingface.co/openfoodfacts","description":"\n\t\n\t\t\n\t\tOpen Food Facts Database\n\t\n\n\n\t\n\t\t\n\t\tWhat is üçä Open Food Facts?\n\t\n\n\n\t\n\t\t\n\t\tA food products database\n\t\n\nOpen Food Facts is a database of food products with ingredients, allergens, nutrition facts and all the tidbits of information we can find on product labels.\n\n\t\n\t\t\n\t\tMade by everyone\n\t\n\nOpen Food Facts is a non-profit association of volunteers. 25.000+ contributors like you have added 1.7 million + products from 150 countries using our Android or iPhone app or their camera to scan‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/openfoodfacts/product-database.","first_N":5,"first_N_keywords":["English","French","German","Spanish","Italian"],"keywords_longer_than_N":true},
	{"name":"qa-portuguese-small","keyword":"portuguese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Jpzinn654/qa-portuguese-small","creator_name":"Juan Pablo","creator_url":"https://huggingface.co/Jpzinn654","description":"\n\t\n\t\t\n\t\tQA-PORTUGUESE-SMALL\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe qa-portuguese-small dataset is a collection of 500,000 question-answer pairs in Portuguese designed for Question Answering (QA) tasks. The dataset includes questions based on a wide variety of domains, such as news, general knowledge, and everyday facts, and provides corresponding answers in natural language.\nThe dataset is intended for training and evaluating machine learning models that can answer questions in Portuguese‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Jpzinn654/qa-portuguese-small.","first_N":5,"first_N_keywords":["question-answering","table-question-answering","Portuguese","mit","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"nocaps-pt-br","keyword":"portuguese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/laicsiifes/nocaps-pt-br","creator_name":"Laborat√≥rio de Intelig√™ncia Computacional e Sistemas de informa√ß√£o","creator_url":"https://huggingface.co/laicsiifes","description":"\n\t\n\t\t\n\t\tüéâ nocaps Dataset Translation for Portuguese Image Captioning\n\t\n\n\n\t\n\t\t\n\t\tüíæ Dataset Summary\n\t\n\nnocaps Portuguese Translation, a multimodal dataset for Portuguese image captioning benchmark, each image accompanied by ten descriptive captions\nthat have been generated by human annotators for every individual image. The original English captions were rendered into Portuguese\nthrough the utilization of the Google Translator API.\n\n\t\n\t\t\n\t\tüßë‚Äçüíª Hot to Get Started with the Dataset\n\t\n\nfrom‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/laicsiifes/nocaps-pt-br.","first_N":5,"first_N_keywords":["text-to-image","image-to-text","text-generation","Portuguese","mit"],"keywords_longer_than_N":true},
	{"name":"Saudades_da_terra","keyword":"portuguese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Verotic/Saudades_da_terra","creator_name":"Adriano","creator_url":"https://huggingface.co/Verotic","description":"Verotic/Saudades_da_terra dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["summarization","Portuguese","mit","üá∫üá∏ Region: US"],"keywords_longer_than_N":false},
	{"name":"m-ArenaHard","keyword":"portuguese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/CohereLabs/m-ArenaHard","creator_name":"Cohere Labs","creator_url":"https://huggingface.co/CohereLabs","description":"\n\t\n\t\t\n\t\tDataset Card for m-ArenaHard\n\t\n\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\nThe m-ArenaHard dataset is a multilingual LLM evaluation set. This dataset was created by translating the prompts from the originally English-only LMarena (formerly LMSYS) arena-hard-auto-v0.1 test dataset using Google Translate API v3 to 22 languages. The original English-only prompts were created by Li et al. (2024) and consist of 500 challenging user queries sourced from Chatbot Arena. The authors show that these can be used‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/CohereLabs/m-ArenaHard.","first_N":5,"first_N_keywords":["English","French","German","Spanish","Italian"],"keywords_longer_than_N":true},
	{"name":"blogsetbr","keyword":"portuguese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/tallesl/blogsetbr","creator_name":"Talles L","creator_url":"https://huggingface.co/tallesl","description":"\n\t\n\t\t\n\t\n\t\n\t\tBlogSet-BR\n\t\n\nReprodu√ß√£o do dataset BlogSet-BR criado pela universidade PUCRS.\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Original\n\t\n\nO dataset original (sem modifica√ß√µes) encontra-se em blogsetbr-original.csv (7.477.853\nregistros).\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Modificado\n\t\n\nUma c√≥pia modificada do dataset pode ser encontrada em blogsetbr-modificado.csv (7.468.541\nregistros). Foi modificado:\n\nRemo√ß√£o de registros duplicados e com problemas de escape (9.312 registros removidos).\nAdicionado um cabe√ßalho ao arquivo.‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/tallesl/blogsetbr.","first_N":5,"first_N_keywords":["text-generation","Portuguese","apache-2.0","1M<n<10M","üá∫üá∏ Region: US"],"keywords_longer_than_N":false},
	{"name":"mmmlu_lite","keyword":"portuguese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/opencompass/mmmlu_lite","creator_name":"OpenCompass","creator_url":"https://huggingface.co/opencompass","description":"\n\t\n\t\t\n\t\tMMMLU-Lite\n\t\n\n\n\t\n\t\t\n\t\tIntroduction\n\t\n\nA lite version of the MMMLU dataset, which is an community version of the MMMLU dataset by OpenCompass. Due to the large size of the original dataset (about 200k questions), we have created a lite version of the dataset to make it easier to use. We sample 25 examples from each language subject in the original dataset with fixed seed to ensure reproducibility, finally we have 19950 examples in the lite version of the dataset, which is about 10% of‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/opencompass/mmmlu_lite.","first_N":5,"first_N_keywords":["question-answering","Arabic","Bengali","German","Spanish"],"keywords_longer_than_N":true},
	{"name":"sib-fleurs","keyword":"portuguese","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/WueNLP/sib-fleurs","creator_name":"W√ºNLP","creator_url":"https://huggingface.co/WueNLP","description":"\n\t\n\t\t\n\t\tSIB-Fleurs\n\t\n\nSIB-Fleurs is a dataset suitable to evaluate Multilingual Spoken Language Understanding. For each utterance in Fleurs, the task is to determine the topic the utterance belongs to. \nThe topics are:\n\nScience/Technology\nTravel\nPolitics\nSports\nHealth\nEntertainment\nGeography\n\nPreliminary evaluations can be found at the bottom of the README. The preliminary results in full detail are available in ./results.csv*.\n\n\t\n\t\t\n\t\n\t\n\t\tDataset creation\n\t\n\nThis dataset processes and merges‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/WueNLP/sib-fleurs.","first_N":5,"first_N_keywords":["audio-classification","automatic-speech-recognition","audio-text-to-text","text-to-speech","question-answering"],"keywords_longer_than_N":true},
	{"name":"MMMLU","keyword":"portuguese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/bzantium/MMMLU","creator_name":"Minho Ryu","creator_url":"https://huggingface.co/bzantium","description":"\n\t\n\t\t\n\t\tMultilingual Massive Multitask Language Understanding (MMMLU)\n\t\n\nThe MMLU is a widely recognized benchmark of general knowledge attained by AI models. It covers a broad range of topics from 57 different categories, covering elementary-level knowledge up to advanced professional subjects like law, physics, history, and computer science.\nWe translated the MMLU‚Äôs test set into 14 languages using professional human translators. Relying on human translators for this evaluation increases‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/bzantium/MMMLU.","first_N":5,"first_N_keywords":["question-answering","Arabic","Bengali","German","Spanish"],"keywords_longer_than_N":true},
	{"name":"crime_tweets_in_portuguese","keyword":"portuguese","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/miguelribeirokk/crime_tweets_in_portuguese","creator_name":"Miguel Ant√¥nio Ribeiro e Silva","creator_url":"https://huggingface.co/miguelribeirokk","description":"\n\t\n\t\t\n\t\tTweets190: A Comprehensive Dataset of Crime-Related Tweets in Portuguese with Sentiment, Toxicity, and Location Information\n\t\n\nThis dataset contains 61.715 tweets related to possible crime reports, labeled with categories such as \"Assalto\", \"Roubo\", \"Furto\", \"Ass√©dio\", \"Seguran√ßa P√∫blica\", \"Homic√≠dio, and \"Outros\", along with sentiment analysis, toxicity analysis, and location identification.\nA particular feature in the Portuguese language is that many words potentially related to‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/miguelribeirokk/crime_tweets_in_portuguese.","first_N":5,"first_N_keywords":["Portuguese","cc-by-4.0","10K - 100K","csv","Tabular"],"keywords_longer_than_N":true},
	{"name":"tabela-taco","keyword":"portuguese","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/julianamarques/tabela-taco","creator_name":"Juliana Marques","creator_url":"https://huggingface.co/julianamarques","description":"\n\t\n\t\t\n\t\tDataset: TACO - Tabela Brasileira de Composi√ß√£o de Alimentos\n\t\n\nThe TACO Table is the reference nutritional table for foods consumed in Brazil. The information contained in this dataset was taken from the excel file made available by NEPA - Center for Studies and Research in Food at UNICAMP, through the link: \nhttps://nepa.unicamp.br/publicacoes/tabela-taco-excel/\n","first_N":5,"first_N_keywords":["Portuguese","cc0-1.0","< 1K","csv","Text"],"keywords_longer_than_N":true},
	{"name":"xtreme-up-semantic-parsing","keyword":"portuguese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Davlan/xtreme-up-semantic-parsing","creator_name":"David Adelani","creator_url":"https://huggingface.co/Davlan","description":"\n\t\n\t\t\n\t\tDataset Card for afrixnli\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nSee XTREME-UP GitHub\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nThere are 20 languages available :\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\n\t\n\t\t\n\t\tData Instances\n\t\n\nThe examples look like this for English:\nfrom datasets import load_dataset\ndata = load_dataset('Davlan/xtreme-up-semantic-parsing', 'yor') \n# Please, specify the language code\n# A data point example is below:\n{\n\"id\": \"3231323330393336\",\n\"split\": \"test\",\n\"intent\": \"IN:GET_REMINDER\",\n\"locale\": \"en\"‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Davlan/xtreme-up-semantic-parsing.","first_N":5,"first_N_keywords":["text-classification","multilingual","Amharic","Belarusian","Bengali"],"keywords_longer_than_N":true},
	{"name":"figuras_de_linguagem","keyword":"portuguese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/marioluciofjr/figuras_de_linguagem","creator_name":"M√°rio L√∫cio","creator_url":"https://huggingface.co/marioluciofjr","description":"\n\t\n\t\t\n\t\tDescri√ß√£o\n\t\n\nDataset com 100 frases diferentes sobre processo seletivo de emprego. As frases correspondem √†s figuras de linguagem: analogia, met√°fora, sarcasmo e ironia.\n","first_N":5,"first_N_keywords":["zero-shot-classification","Portuguese","mit","< 1K","csv"],"keywords_longer_than_N":true},
	{"name":"cml-tts-filtered","keyword":"portuguese","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/PHBJT/cml-tts-filtered","creator_name":"Paul Henri Biojout","creator_url":"https://huggingface.co/PHBJT","description":"\n\t\n\t\t\n\t\tDataset Card for Filtred and CML-TTS\n\t\n\nThis dataset is a filtred version of a CML-TTS [1]. \nCML-TTS [1] CML-TTS is a recursive acronym for CML-Multi-Lingual-TTS, a Text-to-Speech (TTS) dataset developed at the Center of Excellence in Artificial Intelligence (CEIA) of the Federal University of Goias (UFG). CML-TTS is a dataset comprising audiobooks sourced from the public domain books of Project Gutenberg, read by volunteers from the LibriVox project. The dataset includes recordings in‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/PHBJT/cml-tts-filtered.","first_N":5,"first_N_keywords":["text-to-speech","French","German","Dutch","Polish"],"keywords_longer_than_N":true},
	{"name":"reviews_linkedin","keyword":"portuguese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/marioluciofjr/reviews_linkedin","creator_name":"M√°rio L√∫cio","creator_url":"https://huggingface.co/marioluciofjr","description":"\n\t\n\t\t\n\t\tDescri√ß√£o\n\t\n\nDataset que traz os coment√°rios dos usus√°rios do Google Play sobre o app do LinkedIn\n","first_N":5,"first_N_keywords":["text-classification","Portuguese","mit","10K - 100K","csv"],"keywords_longer_than_N":true},
	{"name":"portufake","keyword":"portuguese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/unfake/portufake","creator_name":"Unfake","creator_url":"https://huggingface.co/unfake","description":"\n\t\n\t\t\n\t\n\t\n\t\tDataset Card for Portufake\n\t\n\n\n\nThis dataset contains spectrograms of audio deepfakes and real speaker recordings in Portuguese, originating from Fake Voices Dataset \nand CETUC Corpus, respectively.\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Description\n\t\n\n\n\nThe dataset contains 183,878 512px x 256px colored constant-Q transform (CQT) spectrograms created from audios categorized in two labels: \"real\" or \"fake\". \nThey correspond, respectively, to Brazilian Portuguese‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/unfake/portufake.","first_N":5,"first_N_keywords":["image-classification","image-feature-extraction","Portuguese","mit","10B<n<100B"],"keywords_longer_than_N":true},
	{"name":"librispeech_pt","keyword":"portuguese","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/murilo-as/librispeech_pt","creator_name":"Murilo Alvares Silva","creator_url":"https://huggingface.co/murilo-as","description":"murilo-as/librispeech_pt dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["Portuguese","cc0-1.0","< 1K","soundfolder","Audio"],"keywords_longer_than_N":true},
	{"name":"MultiSimV2","keyword":"portuguese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/MichaelR207/MultiSimV2","creator_name":"Michael Ryan","creator_url":"https://huggingface.co/MichaelR207","description":"\n\t\n\t\t\n\t\tDataset Card for MultiSim Benchmark\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThe MultiSim benchmark is a growing collection of text simplification datasets targeted at sentence simplification in several languages.  Currently, the benchmark spans 12 languages.\n\n\n\t\n\t\n\t\n\t\tSupported Tasks\n\t\n\n\nSentence Simplification\n\n\n\t\n\t\n\t\n\t\tUsage\n\t\n\nfrom datasets importload_dataset\n\ndataset = load_dataset(\"MichaelR207/MultiSimV2\")\n\n\n\t\n\t\t\n\t\tCitation\n\t\n\nIf you use this benchmark, please cite our paper:‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/MichaelR207/MultiSimV2.","first_N":5,"first_N_keywords":["summarization","text-generation","English","French","Russian"],"keywords_longer_than_N":true},
	{"name":"leis_ordinarias_1988_2024","keyword":"portuguese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/celsowm/leis_ordinarias_1988_2024","creator_name":"Celso F","creator_url":"https://huggingface.co/celsowm","description":"celsowm/leis_ordinarias_1988_2024 dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["summarization","text-generation","Portuguese","apache-2.0","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"parallel_corpus_game","keyword":"portuguese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/bot-yaya/parallel_corpus_game","creator_name":"yaya","creator_url":"https://huggingface.co/bot-yaya","description":"https://github.com/mnbvc-parallel-corpus-team/parallel_corpus_mnbvc\nGame Corpus Collected by MNBVC Parallel Corpus Team.\n\n\t\n\t\t\n\t\t07/10/2025 Updated\n\t\n\nAdd 4 new corpus from games:\n\nDisco Elysium\nSCP Secret Laboratory\nStar Wars: Jedi Fallen Order\nStellar Blade\n\n\n\t\n\t\t\n\t\t06/13/2025 Rename and Reupload Dataset\n\t\n\n47 Games are Included:\n\nAnonymous Hacker Simulator\nBorderlands 2\nBorderlands 3\nBaldur's Gate 3\nCultist Simulator\nCyberpunk 2077\nDark Souls 3\nDetroit Become Human\nDisaster Band\nDo Not‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/bot-yaya/parallel_corpus_game.","first_N":5,"first_N_keywords":["translation","Arabic","Chinese","German","English"],"keywords_longer_than_N":true},
	{"name":"Global-MMLU-Lite","keyword":"portuguese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/CohereLabs/Global-MMLU-Lite","creator_name":"Cohere Labs","creator_url":"https://huggingface.co/CohereLabs","description":"\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nGlobal-MMLU-Lite is a multilingual evaluation set spanning 16 languages, including English. It is \"lite\" version of the original Global-MMLU dataset üåç.\nIt includes 200 Culturally Sensitive (CS) and 200 Culturally Agnostic (CA) samples per language. The samples in Global-MMLU-Lite are corresponding to languages which are fully human translated or post-edited in the original Global-MMLU dataset. \nNOTE: Of the 16 languages presently included in Global-MMLU-Lite, 15‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/CohereLabs/Global-MMLU-Lite.","first_N":5,"first_N_keywords":["English","Arabic","Bengali","Spanish","French"],"keywords_longer_than_N":true},
	{"name":"juciData","keyword":"portuguese","license":"GNU General Public License v3.0","license_url":"https://choosealicense.com/licenses/gpl-3.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ResidenciaTJAP-IA/juciData","creator_name":"Equipe de IA da Resid√™ncia Tecnol√≥gica","creator_url":"https://huggingface.co/ResidenciaTJAP-IA","description":"Primeiro teste\n","first_N":5,"first_N_keywords":["Portuguese","gpl-3.0","< 1K","json","Text"],"keywords_longer_than_N":true},
	{"name":"LegiSubject-Br-Summaries","keyword":"portuguese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/ronunes/LegiSubject-Br-Summaries","creator_name":"Rafael Oleques Nunes","creator_url":"https://huggingface.co/ronunes","description":"\n\t\n\t\t\n\t\tüáßüá∑ Brazilian Legislative Bills ‚Äì Summary Dataset\n\t\n\nThis dataset contains summaries (ementas) of legislative bills proposed in the Brazilian Chamber of Deputies (BCoD) from 1991 to 2022.It is intended for multi-label classification, where each bill may be associated with one or more subject categories (temas).\nüîÄ This is the summary version of the dataset.If you are looking for the keywords version, see:üëâ ronunes/LegiSubject-Br-Keywords\n\n\n\t\n\t\t\n\t\n\t\n\t\tüìÅ Dataset Structure\n\t\n\nThe‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ronunes/LegiSubject-Br-Summaries.","first_N":5,"first_N_keywords":["text-classification","Portuguese","mit","1M - 10M","parquet"],"keywords_longer_than_N":true},
	{"name":"muri-it-language-split","keyword":"portuguese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/akoksal/muri-it-language-split","creator_name":"Abdullatif Koksal","creator_url":"https://huggingface.co/akoksal","description":"\n\t\n\t\t\n\t\tMURI-IT: Multilingual Instruction Tuning Dataset for 200 Languages via Multilingual Reverse Instructions\n\t\n\nMURI-IT is a large-scale multilingual instruction tuning dataset containing 2.2 million instruction-output pairs across 200 languages. It is designed to address the challenges of instruction tuning in low-resource languages with Multilingual Reverse Instructions (MURI), which ensures that the output is human-written, high-quality, and authentic to the cultural and linguistic‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/akoksal/muri-it-language-split.","first_N":5,"first_N_keywords":["text-generation","question-answering","summarization","Achinese","Adyghe"],"keywords_longer_than_N":true},
	{"name":"AllTripletsMsMarco-PTBR","keyword":"portuguese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/cnmoro/AllTripletsMsMarco-PTBR","creator_name":"Carlo Moro","creator_url":"https://huggingface.co/cnmoro","description":"Need a huge dataset translated? Connect with me!\n","first_N":5,"first_N_keywords":["Portuguese","apache-2.0","10M - 100M","parquet","Text"],"keywords_longer_than_N":true},
	{"name":"include-lite-44","keyword":"portuguese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/CohereLabs/include-lite-44","creator_name":"Cohere Labs","creator_url":"https://huggingface.co/CohereLabs","description":"\n\t\n\t\t\n\t\tINCLUDE-lite (44 languages)\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\n\n\nPaper: http://arxiv.org/abs/2411.19799\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nINCLUDE is a comprehensive knowledge- and reasoning-centric benchmark across 44 languages that evaluates multilingual LLMs for performance in the actual language environments where they would be deployed. \nIt contains 11,095 4-option multiple-choice-questions (MCQ) extracted from academic and professional exams, covering 57 topics, including regional‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/CohereLabs/include-lite-44.","first_N":5,"first_N_keywords":["multiple-choice","Albanian","Arabic","Armenian","Azerbaijani"],"keywords_longer_than_N":true},
	{"name":"Multilingal-sakalt-data","keyword":"portuguese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Sakalti/Multilingal-sakalt-data","creator_name":"sakasan","creator_url":"https://huggingface.co/Sakalti","description":"„Éû„É´„ÉÅ„É™„É≥„Ç¨„É´„Éá„Éº„Çø„Çª„ÉÉ„Éà„Åß„Åô„ÄÇmit„É©„Ç§„Çª„É≥„Çπ„Åß„Åô„ÄÇ\n","first_N":5,"first_N_keywords":["text-generation","Abkhaz","Bhojpuri","Chechen","Czech"],"keywords_longer_than_N":true},
	{"name":"bidCorpus","keyword":"portuguese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/tcepi/bidCorpus","creator_name":"Tribunal de Contas do Estado do Piau√≠","creator_url":"https://huggingface.co/tcepi","description":"\n\t\n\t\t\n\t\tDataset Card for \"BidCorpus\"\n\t\n\n\n\t\n\t\t\n\t\tHow to load the datasets\n\t\n\nTo load one of the datasets, simply provide the tcepi/bidCorpus argument as the first parameter, followed by the name of the desired dataset, such as bid_corpus_raw.\nfrom datasets import load_dataset\ndataset = load_dataset(\"tcepi/bidCorpus\", \"bidCorpus_raw\")\n\nThe csv format version of the datasets is available in the \\bidCorpus_csvs folder.\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThe BidCorpus dataset consists of various‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/tcepi/bidCorpus.","first_N":5,"first_N_keywords":["text-classification","token-classification","sentence-similarity","Portuguese","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"wiki-talks","keyword":"portuguese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/lflage/wiki-talks","creator_name":"Lucas Fonseca Lage","creator_url":"https://huggingface.co/lflage","description":"\n\t\n\t\t\n\t\tWiki-Talks\n\t\n\nThe Wiki-Talks dataset is a collection of conversational threads extracted from the talk pages on Wikipedia.\nThis dataset captures collaborative dialogue, discussion patterns, and consensus-building among Wikipedia contributors.\nIt is useful for NLP research focused on dialogue, sentiment analysis, and community dynamics.\n\n\t\n\t\t\n\t\tDetails\n\t\n\nCurrently due to PyArrow incompatibility to the long recursive structures in the dataset there is an intrinsic incompatibility‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/lflage/wiki-talks.","first_N":5,"first_N_keywords":["English","German","Portuguese","Spanish","French"],"keywords_longer_than_N":true},
	{"name":"muri-it","keyword":"portuguese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/akoksal/muri-it","creator_name":"Abdullatif Koksal","creator_url":"https://huggingface.co/akoksal","description":"\n\t\n\t\t\n\t\tMURI-IT: Multilingual Instruction Tuning Dataset for 200 Languages via Multilingual Reverse Instructions\n\t\n\nMURI-IT is a large-scale multilingual instruction tuning dataset containing 2.2 million instruction-output pairs across 200 languages. It is designed to address the challenges of instruction tuning in low-resource languages with Multilingual Reverse Instructions (MURI), which ensures that the output is human-written, high-quality, and authentic to the cultural and linguistic‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/akoksal/muri-it.","first_N":5,"first_N_keywords":["text-generation","question-answering","summarization","Achinese","Adyghe"],"keywords_longer_than_N":true},
	{"name":"mls-annotated","keyword":"portuguese","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/PHBJT/mls-annotated","creator_name":"Paul Henri Biojout","creator_url":"https://huggingface.co/PHBJT","description":"\n\t\n\t\t\n\t\tDataset Card for Annotations of non English MLS\n\t\n\nThis dataset consists in annotations of a the Non English subset of the Multilingual LibriSpeech (MLS) dataset. \nMLS dataset is a large multilingual corpus suitable for speech research. The dataset is derived from read audiobooks from LibriVox and consists of \n8 languages - English, German, Dutch, Spanish, French, Italian, Portuguese, Polish. It includes about 44.5K hours of English and a total of about 6K hours for other languages.‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/PHBJT/mls-annotated.","first_N":5,"first_N_keywords":["text-to-speech","French","German","Dutch","Portuguese"],"keywords_longer_than_N":true},
	{"name":"mosel","keyword":"portuguese","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/FBK-MT/mosel","creator_name":"FBK-MT","creator_url":"https://huggingface.co/FBK-MT","description":"\n\n\n\t\n\t\t\n\t\tDataset Description, Collection, and Source\n\t\n\nThe MOSEL corpus is a multilingual dataset collection including up to 950K hours of open-source speech recordings covering the 24 official languages of the European Union. We collect data by surveying labeled and unlabeled speech corpora under open-source compliant licenses.\nIn particular, MOSEL includes the automatic transcripts of 441k hours of unlabeled speech from VoxPopuli and LibriLight. The data is transcribed using Whisper large‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/FBK-MT/mosel.","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","machine-generated","found","multilingual"],"keywords_longer_than_N":true},
	{"name":"include-base-44","keyword":"portuguese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/CohereLabs/include-base-44","creator_name":"Cohere Labs","creator_url":"https://huggingface.co/CohereLabs","description":"\n\t\n\t\t\n\t\tINCLUDE-base (44 languages)\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\n\n\nPaper: http://arxiv.org/abs/2411.19799\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nINCLUDE is a comprehensive knowledge- and reasoning-centric benchmark across 44 languages that evaluates multilingual LLMs for performance in the actual language environments where they would be deployed. \nIt contains 22,637 4-option multiple-choice-questions (MCQ) extracted from academic and professional exams, covering 57 topics, including regional‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/CohereLabs/include-base-44.","first_N":5,"first_N_keywords":["multiple-choice","Albanian","Arabic","Armenian","Azerbaijani"],"keywords_longer_than_N":true},
	{"name":"unlabelled-sti-corpus","keyword":"portuguese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/SIRIS-Lab/unlabelled-sti-corpus","creator_name":"SIRIS Lab, Research Division of SIRIS Academic","creator_url":"https://huggingface.co/SIRIS-Lab","description":"\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe unlabelled-sti-corpus is a diverse dataset designed for developing information extraction datasets (i.e. text classification or NER) for Science, Technology, and Innovation (STI) records. The corpus contains approximately 35,000 records sourced from four major repositories:\n\n22,500 publications from OpenAlex\n10,000 European research projects from CORDIS\n5,000 regional projects from Interreg and Kohesio\n7,000 patents from Lens.org\n\nThe dataset is stratified‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/SIRIS-Lab/unlabelled-sti-corpus.","first_N":5,"first_N_keywords":["English","Spanish","French","German","Italian"],"keywords_longer_than_N":true},
	{"name":"Deltacorpus_1.1","keyword":"portuguese","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/FrancophonIA/Deltacorpus_1.1","creator_name":"FrancophonIA","creator_url":"https://huggingface.co/FrancophonIA","description":"\n[!NOTE]\nDataset origin: https://lindat.cz/repository/xmlui/handle/11234/1-1743\n\n\n\t\n\t\t\n\t\tDescription\n\t\n\nTexts in 107 languages from the W2C corpus (http://hdl.handle.net/11858/00-097C-0000-0022-6133-9), first 1,000,000 tokens per language, tagged by the delexicalized tagger described in Yu et al. (2016, LREC, Portoro≈æ, Slovenia).\nChanges in version 1.1: \n\nUniversal Dependencies tagset instead of the older and smaller Google Universal POS tagset. \n\nSVM classifier trained on Universal‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/FrancophonIA/Deltacorpus_1.1.","first_N":5,"first_N_keywords":["token-classification","multilingual","Afrikaans","Albanian","Amharic"],"keywords_longer_than_N":true},
	{"name":"ToxicCommons","keyword":"portuguese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/PleIAs/ToxicCommons","creator_name":"PleIAs","creator_url":"https://huggingface.co/PleIAs","description":"\n\t\n\t\t\n\t\tToxic Commons\n\t\n\nToxic Commons is a release of 2 million samples of annotated, public domain, multilingual text that was used to train Celadon. \nIt is being released alongside Celadon, in order to better understand multilingual and multicultural toxicity. \nEach sample was classified across 5 axes of toxicity:\n\nRace and origin-based bias: includes racism as well as bias against someone‚Äôs country or region of origin or immigration status, especially immigrant or refugee status. \nGender‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/PleIAs/ToxicCommons.","first_N":5,"first_N_keywords":["text-classification","English","French","Spanish","German"],"keywords_longer_than_N":true},
	{"name":"PangeaBench-xmmmu","keyword":"portuguese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neulab/PangeaBench-xmmmu","creator_name":"NeuLab @ LTI/CMU","creator_url":"https://huggingface.co/neulab","description":"neulab/PangeaBench-xmmmu dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["visual-question-answering","question-answering","multiple-choice","Arabic","French"],"keywords_longer_than_N":true},
	{"name":"told-br","keyword":"portuguese","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/told-br","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  BrazilianToxicTweetsClassification\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\n\n    ToLD-Br is the biggest dataset for toxic tweets in Brazilian Portuguese, crowdsourced by 42 annotators selected from\n    a pool of 129 volunteers. Annotators were selected aiming to create a plural group in terms of demographics (ethnicity,\n    sexual orientation, age, gender). Each tweet was labeled by three annotators in 6 possible categories: LGBTQ+phobia,\n    Xenophobia, Obscene, Insult‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/told-br.","first_N":5,"first_N_keywords":["text-classification","multi-label-classification","sentiment-analysis","sentiment-scoring","sentiment-classification"],"keywords_longer_than_N":true},
	{"name":"Emakhuwa-Portuguese-OCR-post-correction","keyword":"portuguese","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/LIACC/Emakhuwa-Portuguese-OCR-post-correction","creator_name":"LIACC","creator_url":"https://huggingface.co/LIACC","description":"BibTeX:\nThe dataset paper was published in EMNLP 2024.\nPlease cite as:\n@inproceedings{ali-etal-2024-building,\n    title = \"Building Resources for Emakhuwa: Machine Translation and News Classification Benchmarks\",\n    author = \"Ali, Felermino D. M. A.  and\n      Lopes Cardoso, Henrique  and\n      Sousa-Silva, Rui\",\n    editor = \"Al-Onaizan, Yaser  and\n      Bansal, Mohit  and\n      Chen, Yun-Nung\",\n    booktitle = \"Proceedings of the 2024 Conference on Empirical Methods in Natural Language‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/LIACC/Emakhuwa-Portuguese-OCR-post-correction.","first_N":5,"first_N_keywords":["translation","text-generation","Makhuwa","Portuguese","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"Emakhuwa-Monolingual","keyword":"portuguese","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/LIACC/Emakhuwa-Monolingual","creator_name":"LIACC","creator_url":"https://huggingface.co/LIACC","description":"BibTeX:\nThe dataset paper was published in EMNLP 2024.\nPlease cite as:\n@inproceedings{ali-etal-2024-building,\n    title = \"Building Resources for Emakhuwa: Machine Translation and News Classification Benchmarks\",\n    author = \"Ali, Felermino D. M. A.  and\n      Lopes Cardoso, Henrique  and\n      Sousa-Silva, Rui\",\n    editor = \"Al-Onaizan, Yaser  and\n      Bansal, Mohit  and\n      Chen, Yun-Nung\",\n    booktitle = \"Proceedings of the 2024 Conference on Empirical Methods in Natural Language‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/LIACC/Emakhuwa-Monolingual.","first_N":5,"first_N_keywords":["translation","text-generation","Makhuwa","Portuguese","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"mc-translation","keyword":"portuguese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/efederici/mc-translation","creator_name":"Edoardo Federici","creator_url":"https://huggingface.co/efederici","description":"This dataset contains professional human translations from OpenAI's MMMLU dataset, repurposed to train translation models that can help translate future evaluation datasets.\n\n\t\n\t\t\n\t\tWhy This Dataset?\n\t\n\nTranslation of evaluation benchmarks is a critical but challenging task. While automated translations may introduce errors or biases, professional human translations are expensive and time-consuming. This dataset leverages existing professional translations (MMMLU) to train specialized‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/efederici/mc-translation.","first_N":5,"first_N_keywords":["translation","English","Swahili","Spanish","German"],"keywords_longer_than_N":true},
	{"name":"TCCHandInformation","keyword":"portuguese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/GuilhermeGomes/TCCHandInformation","creator_name":"Guilherme Gomes Luccas Rodrigues","creator_url":"https://huggingface.co/GuilhermeGomes","description":"\n\t\n\t\t\n\t\tDataset Card for Dataset Name\n\t\n\nDataset created with MediaPipe with the aim of doing fine tuning consisting of:\n\nuser prompt containing the information\nsystem prompt explaining what will be received\nexpected response\n\n","first_N":5,"first_N_keywords":["text-classification","Portuguese","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"enunciados_pge_rj","keyword":"portuguese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/celsowm/enunciados_pge_rj","creator_name":"Celso F","creator_url":"https://huggingface.co/celsowm","description":"celsowm/enunciados_pge_rj dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["question-answering","Portuguese","apache-2.0","üá∫üá∏ Region: US"],"keywords_longer_than_N":false},
	{"name":"VoxCommunis","keyword":"portuguese","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/pacscilab/VoxCommunis","creator_name":"PaCSciLab @ UZH","creator_url":"https://huggingface.co/pacscilab","description":"The VoxCommunis Corpus contains acoustic models, lexicons, and force-aligned TextGrids with phone- and word-level segmentations derived from the Mozilla Common Voice Corpus. The Mozilla Common Voice Corpus and derivative VoxCommunis Corpus stored here are free to download and use under a CC0 license.\nThe lexicons are developed using Epitran, the XPF Corpus, Charsiu, and some custom dictionaries. Some manual correction has been applied, and we hope to continue improving these. Any updates from‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/pacscilab/VoxCommunis.","first_N":5,"first_N_keywords":["Abkhaz","Amharic","Bashkir","Belarusian","Bulgarian"],"keywords_longer_than_N":true},
	{"name":"ementas_camarabr_1934_2024","keyword":"portuguese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/belisards/ementas_camarabr_1934_2024","creator_name":"adriano","creator_url":"https://huggingface.co/belisards","description":"Collected at 26 Sept 2024\n","first_N":5,"first_N_keywords":["Portuguese","mit","100K - 1M","parquet","Tabular"],"keywords_longer_than_N":true},
	{"name":"SpokenPortugueseGeographicalSocialVarieties","keyword":"portuguese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Jarbas/SpokenPortugueseGeographicalSocialVarieties","creator_name":"Casimiro Ferreira","creator_url":"https://huggingface.co/Jarbas","description":"\n\t\n\t\t\n\t\tSpoken Portuguese - Geographical and Social Varieties\n\t\n\ndataset source: https://www.clul.ulisboa.pt\n(1995-1997 - European Commission DGXXII, Programme LINGUA/SOCRATES)\nThe project is concluded and the materials are published in CD-ROM, with the exclusive publishing support of Instituto Cam√µes, under the title Portugu√™s Falado - Documentos Aut√™nticos: Grava√ß√µes √°udio com transcri√ß√£o alinhada. Its distribution outside of Portugal is ensured by Instituto Cam√µes and in Portugal by CLUL.‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Jarbas/SpokenPortugueseGeographicalSocialVarieties.","first_N":5,"first_N_keywords":["automatic-speech-recognition","Portuguese","mit","< 1K","soundfolder"],"keywords_longer_than_N":true},
	{"name":"cml-tts-filtered-annotated","keyword":"portuguese","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/PHBJT/cml-tts-filtered-annotated","creator_name":"Paul Henri Biojout","creator_url":"https://huggingface.co/PHBJT","description":"\n\t\n\t\t\n\t\tDataset Card for Filtred and annotated CML TTS\n\t\n\nThis dataset is an annotated and filtred version of a CML-TTS [1]. \nCML-TTS [1] CML-TTS is a recursive acronym for CML-Multi-Lingual-TTS, a Text-to-Speech (TTS) dataset developed at the Center of Excellence in Artificial Intelligence (CEIA) of the Federal University of Goias (UFG). CML-TTS is a dataset comprising audiobooks sourced from the public domain books of Project Gutenberg, read by volunteers from the LibriVox project. The‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/PHBJT/cml-tts-filtered-annotated.","first_N":5,"first_N_keywords":["text-to-speech","French","German","Italian","Spanish"],"keywords_longer_than_N":true},
	{"name":"X-ALMA-Preference","keyword":"portuguese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/haoranxu/X-ALMA-Preference","creator_name":"Haoran Xu","creator_url":"https://huggingface.co/haoranxu","description":"This is the translation preference dataset used by X-ALMA.\nsource: the source sentence.\nchosen: the preferred translation.\nreject: the dis-preferred translation.\ndirections: the translation direction.\n@misc{xu2024xalmaplugplay,\n      title={X-ALMA: Plug & Play Modules and Adaptive Rejection for Quality Translation at Scale}, \n      author={Haoran Xu and Kenton Murray and Philipp Koehn and Hieu Hoang and Akiko Eriguchi and Huda Khayrallah},\n      year={2024},\n      eprint={2410.03115}‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/haoranxu/X-ALMA-Preference.","first_N":5,"first_N_keywords":["English","Danish","Dutch","German","Icelandic"],"keywords_longer_than_N":true},
	{"name":"rest-products","keyword":"portuguese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/victorvarela/rest-products","creator_name":"Victor Varela","creator_url":"https://huggingface.co/victorvarela","description":"victorvarela/rest-products dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["text-classification","Portuguese","mit","üá∫üá∏ Region: US"],"keywords_longer_than_N":false},
	{"name":"alagoasideb","keyword":"portuguese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/giseldo/alagoasideb","creator_name":"Giseldo Neo","creator_url":"https://huggingface.co/giseldo","description":"A pr√≥xima vers√£o desse modelo ter√° um pequeno tratamento dos dados, em rela√ß√£o ao tipo das colunas.\n","first_N":5,"first_N_keywords":["feature-extraction","Portuguese","apache-2.0","1K - 10K","csv"],"keywords_longer_than_N":true},
	{"name":"test_4","keyword":"portuguese","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/tunngo/test_4","creator_name":"nguyen tuan","creator_url":"https://huggingface.co/tunngo","description":"\n\t\n\t\t\n\t\n\t\n\t\tFLEURS\n\t\n\nFleurs is the speech version of the FLoRes machine translation benchmark. \nWe use 2009 n-way parallel sentences from the FLoRes dev and devtest publicly available sets, in 102 languages. \nTraining sets have around 10 hours of supervision. Speakers of the train sets are different than speakers from the dev/test sets. Multilingual fine-tuning is\nused and ‚Äùunit error rate‚Äù (characters, signs) of all languages is averaged. Languages and results are also grouped into seven‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/tunngo/test_4.","first_N":5,"first_N_keywords":["automatic-speech-recognition","expert-generated","crowdsourced","machine-generated","crowdsourced"],"keywords_longer_than_N":true},
	{"name":"enunciados_pge_rj_orpo","keyword":"portuguese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/celsowm/enunciados_pge_rj_orpo","creator_name":"Celso F","creator_url":"https://huggingface.co/celsowm","description":"celsowm/enunciados_pge_rj_orpo dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["question-answering","Portuguese","apache-2.0","1K - 10K","json"],"keywords_longer_than_N":true},
	{"name":"prompt-injection-multilingual","keyword":"portuguese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/rikka-snow/prompt-injection-multilingual","creator_name":"Le Xuan Hoang","creator_url":"https://huggingface.co/rikka-snow","description":"rikka-snow/prompt-injection-multilingual dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["text-classification","Vietnamese","English","Chinese","French"],"keywords_longer_than_N":true},
	{"name":"quinquilharia","keyword":"portuguese","license":"The Unlicense","license_url":"https://choosealicense.com/licenses/unlicense/","language":"en","dataset_url":"https://huggingface.co/datasets/tallesl/quinquilharia","creator_name":"Talles L","creator_url":"https://huggingface.co/tallesl","description":"\n\n\t\n\t\t\n\t\tQuinquilharia\n\t\n\nTextos variados em portugu√™s do Brasil.\n\n\t\n\t\t\n\t\tF√≥runs\n\t\n\n\n\t\n\t\t\nTema\nLink do f√≥rum\nDataset com scrap realizado\n\n\n\t\t\nAgility (esporte)\n[agilityrj.forumeiros.com][agilityrj]\nagilityrj.csv (~10 mil postagens)\n\n\nArtes marciais\n[forum.bjjforum.com.br][bjjforum]\nbjjforum.csv (~318 mil postagens)\n\n\nArtes marciais\n[ufconfantasy.forumeiros.com][ufconfantasy]\nufconfantasy.csv (~120 mil postagens)\n\n\nArtesanato\n[atelierdasartes.forumeiros.com][atelierdasartes]\natelierdasartes.csv‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/tallesl/quinquilharia.","first_N":5,"first_N_keywords":["text-generation","Portuguese","unlicense","üá∫üá∏ Region: US"],"keywords_longer_than_N":false},
	{"name":"PangeaBench-xgqa","keyword":"portuguese","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/neulab/PangeaBench-xgqa","creator_name":"NeuLab @ LTI/CMU","creator_url":"https://huggingface.co/neulab","description":"\n\t\n\t\t\n\t\txGQA\n\t\n\n\n\t\n\t\t\n\t\tThis is a clone of the few_shot-test split of the xGQA dataset\n\t\n\nPlease find the original repository here: https://github.com/adapter-hub/xGQA\nIf you use this dataset, please cite the original authors:\n@inproceedings{pfeiffer-etal-2021-xGQA,\n    title={{xGQA: Cross-Lingual Visual Question Answering}},\n    author={ Jonas Pfeiffer and Gregor Geigle and Aishwarya Kamath and Jan-Martin O. Steitz and Stefan Roth and Ivan Vuli{\\'{c}} and Iryna Gurevych},\n    booktitle =‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/neulab/PangeaBench-xgqa.","first_N":5,"first_N_keywords":["visual-question-answering","Bengali","German","English","Indonesian"],"keywords_longer_than_N":true},
	{"name":"English-PTBR","keyword":"portuguese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Dexavator/English-PTBR","creator_name":"VICTOR DE ALENCAR DELGADO","creator_url":"https://huggingface.co/Dexavator","description":"Dexavator/English-PTBR dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["translation","English","Portuguese","apache-2.0","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"chatgptex","keyword":"portuguese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/AstatonnCorp/chatgptex","creator_name":"Astatonn Corp","creator_url":"https://huggingface.co/AstatonnCorp","description":"\n\t\n\t\t\n\t\tImportant\n\t\n\nPlease, remember to cite the author.\nName: Lucas Lima (Astatonn)\nSocial: https://astatonn.com\n","first_N":5,"first_N_keywords":["Portuguese","mit","1K - 10K","json","Text"],"keywords_longer_than_N":true},
	{"name":"RePro-categories-multilabel","keyword":"portuguese","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/higopires/RePro-categories-multilabel","creator_name":"Higo Felipe Silva Pires","creator_url":"https://huggingface.co/higopires","description":"\n\t\n\t\t\n\t\tRePro: A Benchmark Dataset for Opinion Mining in Brazilian Portuguese\n\t\n\nRePro, which stands for \"REview of PROducts,\" is a benchmark dataset for opinion mining in Brazilian Portuguese. It consists of 10,000 humanly annotated e-commerce product reviews, each labeled with sentiment and topic information. The dataset was created based on data from one of the largest Brazilian e-commerce platforms, which produced the B2W-Reviews01 dataset‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/higopires/RePro-categories-multilabel.","first_N":5,"first_N_keywords":["text-classification","Portuguese","cc-by-sa-4.0","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"Squad_PT","keyword":"portuguese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/vitorandrade/Squad_PT","creator_name":"Vitor Pereira Andrade","creator_url":"https://huggingface.co/vitorandrade","description":"\n\t\n\t\t\n\t\tDataset Card para o SQuAD 1.1 em Portugu√™s Brasil\n\t\n\nO conjunto de dados \"Stanford Question Answering Dataset\" (SQuAD),\npara tarefa de perguntas e respostas extrativas, foi desenvolvido em 2016. Ele utiliza perguntas geradas a partir de\n536 artigos da Wikipedia* com mais de 100.000 linhas de dados. √â constru√≠do na forma de uma pergunta e um contexto dos artigos da\nWikipedia contendo a resposta √† pergunta. [1]Originalmente este dataset foi constru√≠do no idioma ingl√™s, contudo, o grupo‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/vitorandrade/Squad_PT.","first_N":5,"first_N_keywords":["Portuguese","mit","10K - 100K","csv","Text"],"keywords_longer_than_N":true},
	{"name":"inteligenciamultipla","keyword":"portuguese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/giseldo/inteligenciamultipla","creator_name":"Giseldo Neo","creator_url":"https://huggingface.co/giseldo","description":"Resposta de estudante ao question√°rio que levanta o perfil de intelig√™ncia m√∫ltiplas.\n","first_N":5,"first_N_keywords":["Portuguese","apache-2.0","< 1K","csv","Text"],"keywords_longer_than_N":true},
	{"name":"Hourly-Electricity-Demand-Brazil-Dataset","keyword":"portuguese","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/SamuelM0422/Hourly-Electricity-Demand-Brazil-Dataset","creator_name":"Samuel Silva","creator_url":"https://huggingface.co/SamuelM0422","description":"\n\t\n\t\t\n\t\tüáßüá∑ Hourly Load Curve - ONS (Brazil)\n\t\n\nThis dataset contains hourly electricity load data for Brazil, published by the ONS - National Electric System Operator. It spans from the year 2000 to the present (currently 2025), with continuous updates.\n\n\t\n\t\t\n\t\tüìå Description\n\t\n\nThe data represents the hourly electricity demand profile across the Brazilian National Interconnected System (SIN). It is especially suitable for:\n\nElectricity load forecasting\nEnergy demand pattern analysis\nTime‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/SamuelM0422/Hourly-Electricity-Demand-Brazil-Dataset.","first_N":5,"first_N_keywords":["time-series-forecasting","English","Portuguese","cc-by-4.0","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"multilingual_translation_gen_binarized","keyword":"portuguese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Youseff1987/multilingual_translation_gen_binarized","creator_name":"JOON HYOUNG JUN","creator_url":"https://huggingface.co/Youseff1987","description":"Youseff1987/multilingual_translation_gen_binarized dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["translation","Korean","English","Chinese","Zulu"],"keywords_longer_than_N":true},
	{"name":"portugues_ocr_dataset_full","keyword":"portuguese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/mazafard/portugues_ocr_dataset_full","creator_name":"Mohammadreza Asadollahifard","creator_url":"https://huggingface.co/mazafard","description":"\n\t\n\t\t\n\t\tPortugues OCR Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThe portugues_ocr_dataset_full is a dataset designed for Optical Character Recognition (OCR) tasks. It contains images of text from the Portuguese literary work Os Lus√≠adas by Lu√≠s Vaz de Cam√µes, as well as the corresponding ground truth text labels. This dataset can be used for training and evaluating OCR models for Portuguese text recognition.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset consists of:\n\nImages: Each image is a cropped portion‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mazafard/portugues_ocr_dataset_full.","first_N":5,"first_N_keywords":["image-to-text","manual","monolingual","Portuguese","English"],"keywords_longer_than_N":true},
	{"name":"portugues_ocr_dataset_full","keyword":"portuguese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/mazafard/portugues_ocr_dataset_full","creator_name":"Mohammadreza Asadollahifard","creator_url":"https://huggingface.co/mazafard","description":"\n\t\n\t\t\n\t\tPortugues OCR Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThe portugues_ocr_dataset_full is a dataset designed for Optical Character Recognition (OCR) tasks. It contains images of text from the Portuguese literary work Os Lus√≠adas by Lu√≠s Vaz de Cam√µes, as well as the corresponding ground truth text labels. This dataset can be used for training and evaluating OCR models for Portuguese text recognition.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset consists of:\n\nImages: Each image is a cropped portion‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mazafard/portugues_ocr_dataset_full.","first_N":5,"first_N_keywords":["image-to-text","manual","monolingual","Portuguese","English"],"keywords_longer_than_N":true},
	{"name":"cbo","keyword":"portuguese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ricardocechinel/cbo","creator_name":"ricardo cechinel","creator_url":"https://huggingface.co/ricardocechinel","description":"ricardocechinel/cbo dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["question-answering","Portuguese","apache-2.0","1K - 10K","json"],"keywords_longer_than_N":true},
	{"name":"subset-Itau-Unibanco-aroeira-4B-tokens","keyword":"portuguese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/bobboyms/subset-Itau-Unibanco-aroeira-4B-tokens","creator_name":"Thiago Luiz Rodrigues","creator_url":"https://huggingface.co/bobboyms","description":"\n\t\n\t\t\n\t\tSubset Corpus Itau-Unibanco/aroeira: 1B tokens (portuguese PT-BR)\n\t\n\nSubset Corpus Itau-Unibanco/aroeira: 1B tokens (portuguese PT-BR)\nsubset-Itau-Unibanco-aroeira-1B-tokens \n","first_N":5,"first_N_keywords":["text-generation","Portuguese","apache-2.0","10M - 100M","parquet"],"keywords_longer_than_N":true},
	{"name":"mHumanEval-Benchmark","keyword":"portuguese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/md-nishat-008/mHumanEval-Benchmark","creator_name":"Nishat Raihan","creator_url":"https://huggingface.co/md-nishat-008","description":"\n\n\n\t\n\t\t\n\t\tüî∑ Accepted in NAACL Proceedings (2025) üî∑\n\t\n\n\n\n\n\n  \n    \n      \n        \n          \n        \n      \n      \n        \n          \n        \n      \n      \n        \n          \n        \n      \n    \n  \n\n\n\n\n\n  \n\n\t\n\t\n\t\n\t\tmHumanEval\n\t\n\nThe mHumanEval benchmark is curated based on prompts from the original HumanEval üìö [Chen et al., 2021]. It includes a total of 33,456 prompts for Python, and 836,400 in total - significantly expanding from the original 164. \n\n\n\t\n\t\t\n\t\tQuick Start\n\t\n\n  Detailed‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/md-nishat-008/mHumanEval-Benchmark.","first_N":5,"first_N_keywords":["Afar","Abkhaz","Avestan","Afrikaans","Akan"],"keywords_longer_than_N":true},
	{"name":"portuguese-ocr-dataset","keyword":"portuguese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/mazafard/portuguese-ocr-dataset","creator_name":"Mohammadreza Asadollahifard","creator_url":"https://huggingface.co/mazafard","description":"task_categories:\n\nimage-to-text\ntask_ids:\noptical-character-recognition\ntext-recognition\n\n\n\t\n\t\t\n\t\tPortuguese OCR Dataset\n\t\n\nA comprehensive dataset for Portuguese OCR (Optical Character Recognition) generated from classic Portuguese literature with diverse fonts and visual styles.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset contains 20000 text images for OCR training, created from Portuguese books from Project Gutenberg. Each image contains a complete Portuguese sentence with proper‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mazafard/portuguese-ocr-dataset.","first_N":5,"first_N_keywords":["image-to-text","text-generation","Portuguese","mit","< 1K"],"keywords_longer_than_N":true},
	{"name":"portuguese-ocr-dataset","keyword":"portuguese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/mazafard/portuguese-ocr-dataset","creator_name":"Mohammadreza Asadollahifard","creator_url":"https://huggingface.co/mazafard","description":"task_categories:\n\nimage-to-text\ntask_ids:\noptical-character-recognition\ntext-recognition\n\n\n\t\n\t\t\n\t\tPortuguese OCR Dataset\n\t\n\nA comprehensive dataset for Portuguese OCR (Optical Character Recognition) generated from classic Portuguese literature with diverse fonts and visual styles.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset contains 20000 text images for OCR training, created from Portuguese books from Project Gutenberg. Each image contains a complete Portuguese sentence with proper‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mazafard/portuguese-ocr-dataset.","first_N":5,"first_N_keywords":["image-to-text","text-generation","Portuguese","mit","< 1K"],"keywords_longer_than_N":true},
	{"name":"literary-synthesis","keyword":"portuguese","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/agentlans/literary-synthesis","creator_name":"Alan Tseng","creator_url":"https://huggingface.co/agentlans","description":"\n\t\n\t\t\n\t\tLiterary Synthesis\n\t\n\nThis dataset repurposes the original agentlans/literary-reasoning \ndata by reformatting it as creative writing prompts paired with literary-style outputs. \n\nWriting style attributes were put in random order, with prompts randomly either prepended or appended.\nThe output text has been cleaned to make it suitable for creative writing and literary generation tasks.\nThe rows were sorted by increasing reading difficulty for curriculum learning.\n\n","first_N":5,"first_N_keywords":["text-generation","English","French","German","Spanish"],"keywords_longer_than_N":true},
	{"name":"PolyGuardPrompts","keyword":"portuguese","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ToxicityPrompts/PolyGuardPrompts","creator_name":"ToxicityPrompts","creator_url":"https://huggingface.co/ToxicityPrompts","description":"\n\t\n\t\t\n\t\tPolyGuard: A Multilingual Safety Moderation Tool for 17 Languages\n\t\n\nAbstract: Truly multilingual safety moderation efforts for Large Language Models (LLMs) have been hindered by a narrow focus on a small set of languages (e.g., English, Chinese) as well as a limited scope of safety definition, resulting in significant gaps in moderation capabilities. To bridge these gaps, we release PolyGuard, a new state-of-the-art multilingual safety model for safeguarding LLM generations, and the‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ToxicityPrompts/PolyGuardPrompts.","first_N":5,"first_N_keywords":["Arabic","Chinese","Czech","Dutch","English"],"keywords_longer_than_N":true},
	{"name":"multicultural-wvs-alignment","keyword":"portuguese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ryzzlestrizzle/multicultural-wvs-alignment","creator_name":"Jonathan Rystr√∏m","creator_url":"https://huggingface.co/ryzzlestrizzle","description":"ryzzlestrizzle/multicultural-wvs-alignment dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["text-generation","Danish","Portuguese","Dutch","English"],"keywords_longer_than_N":true},
	{"name":"u-sticker","keyword":"portuguese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/metchee/u-sticker","creator_name":"Metilda Chee","creator_url":"https://huggingface.co/metchee","description":"\n\t\n\t\t\n\t\tU-Sticker\n\t\n\nUser-Sticker is a stickers dataset with multi-domain conversations.\nFeatures of U-Sticker:\n\nMulti-domain interactions ‚úÖ\nTemporal ‚úÖ\nUser information ‚úÖ\n370.2k stickers ‚úÖ (104k unique)\n22.6k users ‚úÖ\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nU-Sticker contains three files:\n\nConversation files: 1 to 67.json\nDomain mapping files idx_to_domain.txt.\nSticker files.\n\n\nSticker files are available here and Baidu Cloud.\n\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\n\t\n\t\t\n\t\tConversation file\n\t\n\n\nEmpty lines are‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/metchee/u-sticker.","first_N":5,"first_N_keywords":["Arabic","Chinese","English","French","Turkish"],"keywords_longer_than_N":true},
	{"name":"multilingual_translation_gpt4o_gen","keyword":"portuguese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Youseff1987/multilingual_translation_gpt4o_gen","creator_name":"JOON HYOUNG JUN","creator_url":"https://huggingface.co/Youseff1987","description":"Youseff1987/multilingual_translation_gpt4o_gen dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["translation","Korean","English","Chinese","Zulu"],"keywords_longer_than_N":true},
	{"name":"linkedin-industry-list","keyword":"portuguese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/fantastic-jobs/linkedin-industry-list","creator_name":"Fantastic.jobs","creator_url":"https://huggingface.co/fantastic-jobs","description":"fantastic-jobs/linkedin-industry-list dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["text-classification","translation","English","Korean","Spanish"],"keywords_longer_than_N":true},
	{"name":"wikipedia_quality_wikirank","keyword":"portuguese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/lewoniewski/wikipedia_quality_wikirank","creator_name":"W≈Çodzimierz Lewoniewski","creator_url":"https://huggingface.co/lewoniewski","description":"Datasets with WikiRank quality score as of 1 August 2024 for 47 million Wikipedia articles in 55 language versions (also simplified version for each language in separate files).\nThe WikiRank quality score is a metric designed to assess the overall quality of a Wikipedia article. Although its specific algorithm can vary depending on the implementation, the score typically combines several key features of the Wikipedia article.\n\n\t\n\t\t\n\t\n\t\n\t\tWhy It‚Äôs Important\n\t\n\n\nEnhances Trust: For readers and‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/lewoniewski/wikipedia_quality_wikirank.","first_N":5,"first_N_keywords":["Arabic","Azerbaijani","Belarusian","Bulgarian","Catalan"],"keywords_longer_than_N":true},
	{"name":"thinking-multilingual-30-23-small-690","keyword":"portuguese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Pinkstack/thinking-multilingual-30-23-small-690","creator_name":"Pinkstack","creator_url":"https://huggingface.co/Pinkstack","description":"\nBased on OPENO1 math, this is a translated dataset of 30 high quality questions & answers in 23 languages. \nOr use the \"big\" version: big 10k rows version\n","first_N":5,"first_N_keywords":["text-generation","Arabic","Chinese","Czech","Danish"],"keywords_longer_than_N":true},
	{"name":"Thinking-multilingual-big-10k-sft","keyword":"portuguese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Pinkstack/Thinking-multilingual-big-10k-sft","creator_name":"Pinkstack","creator_url":"https://huggingface.co/Pinkstack","description":"\nA dataset based off of openo1 math, 500 examples translated to 23 different languages. filtered out un-translated examples.\nenjoy üëç\n","first_N":5,"first_N_keywords":["text-generation","Arabic","Chinese","Czech","Danish"],"keywords_longer_than_N":true},
	{"name":"V1Q","keyword":"portuguese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/YuRiVeRTi/V1Q","creator_name":"YuRiVeRTical","creator_url":"https://huggingface.co/YuRiVeRTi","description":"from datasets import load_dataset\nds = load_dataset(\"b3x0m/Chinese-H-Novels\")\nimport sagemaker\nimport boto3\nfrom sagemaker.huggingface import HuggingFaceModel\ntry:\n    role = sagemaker.get_execution_role()\nexcept ValueError:\n    iam = boto3.client('iam')\n    role = iam.get_role(RoleName='sagemaker_execution_role')['Role']['Arn']\n\n\t\n\t\t\n\t\tHub Model configuration. https://huggingface.co/models\n\t\n\nhub = {\n    'HF_MODEL_ID':'deepseek-ai/Janus-Pro-7B',\n    'HF_TASK':'any-to-any'\n}\n\n\t\n\t\t\n\t\tcreate‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/YuRiVeRTi/V1Q.","first_N":5,"first_N_keywords":["text-classification","token-classification","table-question-answering","question-answering","zero-shot-classification"],"keywords_longer_than_N":true},
	{"name":"PleIAs-ToxicCommons","keyword":"portuguese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/agentlans/PleIAs-ToxicCommons","creator_name":"Alan Tseng","creator_url":"https://huggingface.co/agentlans","description":"\n\t\n\t\t\n\t\tPleIAs/ToxicCommons\n\t\n\nThis dataset is a refined version of the PleIAs/ToxicCommons collection, focusing on historical texts labeled for content that may be considered objectionable by modern standards (what the authors of the dataset deem \"toxic\"). \nThe cleaned dataset contains 1‚Äâ051‚Äâ027 rows, each representing a text sample with associated toxicity scores across five dimensions:\n\nRace and origin-based bias\nGender and sexuality-based bias\nReligious bias\nAbility bias\nViolence and abuse‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/agentlans/PleIAs-ToxicCommons.","first_N":5,"first_N_keywords":["text-classification","English","French","Spanish","German"],"keywords_longer_than_N":true},
	{"name":"multilingual_translation_sft","keyword":"portuguese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Youseff1987/multilingual_translation_sft","creator_name":"JOON HYOUNG JUN","creator_url":"https://huggingface.co/Youseff1987","description":"Youseff1987/multilingual_translation_sft dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["translation","Korean","English","Chinese","Zulu"],"keywords_longer_than_N":true},
	{"name":"TinyMarkdown-Instruct-PT","keyword":"portuguese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/VAMJ-0042/TinyMarkdown-Instruct-PT","creator_name":"Vitor Augusto Machado Jorge","creator_url":"https://huggingface.co/VAMJ-0042","description":"\n\t\n\t\t\n\t\tMarkdown Fine-Tuning Datasets (English & PT-BR)\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThese datasets are designed to fine-tune Large Language Models (LLMs) like Gemma to generate structured Markdown-formatted responses. The datasets contain instruction-response pairs, ensuring the model learns how to output Markdown elements correctly.\n\n\t\n\t\t\n\t\tDatasets\n\t\n\n\n\t\n\t\t\n\t\t1. English Markdown Dataset\n\t\n\n\nAvailable on Hugging Face: TinyMarkdown-Instruct-EN\nSize: Large-scale dataset with structured Markdown‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/VAMJ-0042/TinyMarkdown-Instruct-PT.","first_N":5,"first_N_keywords":["question-answering","Portuguese","mit","10K - 100K","json"],"keywords_longer_than_N":true},
	{"name":"dou-brazil-dataset","keyword":"portuguese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/gerson-vfs/dou-brazil-dataset","creator_name":"Gerson Victor Vieira Fontenele da Silva","creator_url":"https://huggingface.co/gerson-vfs","description":"\n\t\n\t\t\n\t\tDataset Card for Dataset Di√°rio Oficial da Uni√£o (DOU)\n\t\n\n\n\nThe Di√°rio Oficial da Uni√£o (DOU) is the official government gazette of Brazil, published by the National Press. It serves as the primary means of communication for federal government acts, including laws, decrees, ordinances, public notices, and other official decisions. The DOU ensures transparency and legal validity for government actions and is divided into three sections:  \n\nSection 1: Publishes laws, decrees, and‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/gerson-vfs/dou-brazil-dataset.","first_N":5,"first_N_keywords":["text-generation","Portuguese","mit","100K - 1M","csv"],"keywords_longer_than_N":true},
	{"name":"acordaos_filtrados_sem_duplicatas_sm","keyword":"portuguese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/sfreitascecilia/acordaos_filtrados_sem_duplicatas_sm","creator_name":"Cec√≠lia de Souza Freitas","creator_url":"https://huggingface.co/sfreitascecilia","description":"sfreitascecilia/acordaos_filtrados_sem_duplicatas_sm dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["Portuguese","mit","< 1K","parquet","Text"],"keywords_longer_than_N":true},
	{"name":"panlex-definitions","keyword":"portuguese","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/cointegrated/panlex-definitions","creator_name":"David Dale","creator_url":"https://huggingface.co/cointegrated","description":"\n\t\n\t\t\n\t\tDataset Card for panlex-definitions\n\t\n\nThis is a dataset of word definitions in several hudnred languages, extracted from https://panlex.org.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset has been extracted from https://panlex.org (the 20250201 database dump) and rearranged on the per-language basis (by the language of the definition).\nEach language subset consists of definitions (short phrases).\nEach definition is associated with some meanings (if there is‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/cointegrated/panlex-definitions.","first_N":5,"first_N_keywords":["translation","Abkhazian","Hijazi Arabic","Afrikaans","Ainu (Japan)"],"keywords_longer_than_N":true},
	{"name":"praias_es_pt_dataset","keyword":"portuguese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/feserrm/praias_es_pt_dataset","creator_name":"Felipe Serrano","creator_url":"https://huggingface.co/feserrm","description":"feserrm/praias_es_pt_dataset dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["translation","text-generation","Portuguese","Spanish","mit"],"keywords_longer_than_N":true},
	{"name":"HelpSteer3","keyword":"portuguese","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/nvidia/HelpSteer3","creator_name":"NVIDIA","creator_url":"https://huggingface.co/nvidia","description":"\n\t\n\t\t\n\t\tHelpSteer3\n\t\n\nHelpSteer3 is an open-source dataset (CC-BY-4.0) that supports aligning models to become more helpful in responding to user prompts.\nHelpSteer3-Preference can be used to train Llama 3.3 Nemotron Super 49B v1 (for Generative RMs) and Llama 3.3 70B Instruct Models (for Bradley-Terry RMs) to produce Reward Models that score as high as 85.5% on RM-Bench and 78.6% on JudgeBench, which substantially surpass existing Reward Models on these benchmarks.\nHelpSteer3-Feedback and‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/nvidia/HelpSteer3.","first_N":5,"first_N_keywords":["English","Chinese","Korean","French","Spanish"],"keywords_longer_than_N":true},
	{"name":"semeval-2025-task11-track-b","keyword":"portuguese","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/vgaraujov/semeval-2025-task11-track-b","creator_name":"Vladimir Araujo","creator_url":"https://huggingface.co/vgaraujov","description":"\n\t\n\t\t\n\t\tSemEval 2025 Task 11 - Track B Dataset\n\t\n\nThis dataset contains the data for SemEval 2025 Task 11: Bridging the Gap in Text-Based Emotion Detection - Track B, organized as language-specific configurations.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset is a multi-language, multi-label emotion classification dataset with separate configurations for each language.\n\nTotal languages: 11 standard ISO codes\nTotal examples: 47111\nSplits: train, dev, test\n\n\n\t\n\t\t\n\t\tTrack Information\n\t\n\nTrack B has‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/vgaraujov/semeval-2025-task11-track-b.","first_N":5,"first_N_keywords":["Amharic","Arabic","German","English","Spanish"],"keywords_longer_than_N":true},
	{"name":"acl-6060","keyword":"portuguese","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ymoslem/acl-6060","creator_name":"Yasmin Moslem","creator_url":"https://huggingface.co/ymoslem","description":"\n\t\n\t\t\n\t\tACL 60/60\n\t\n\n\n\t\n\t\t\n\t\tDataset details\n\t\n\nACL 60/60 evaluation sets for multilingual translation of ACL 2022 technical presentations into 10 target languages.\n\n\t\n\t\t\n\t\tCitation\n\t\n\n@inproceedings{salesky-etal-2023-evaluating,\n    title = \"Evaluating Multilingual Speech Translation under Realistic Conditions with Resegmentation and Terminology\",\n    author = \"Salesky, Elizabeth  and\n      Darwish, Kareem  and\n      Al-Badrashiny, Mohamed  and\n      Diab, Mona  and\n      Niehues, Jan\"‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ymoslem/acl-6060.","first_N":5,"first_N_keywords":["translation","automatic-speech-recognition","English","Arabic","German"],"keywords_longer_than_N":true},
	{"name":"multiCHILDES","keyword":"portuguese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/IParraMartin/multiCHILDES","creator_name":"I√±igo Parra","creator_url":"https://huggingface.co/IParraMartin","description":"\n\t\n\t\t\n\t\tmultiCHILDES: Multilingual Child-Directed Speech Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset contains child-directed speech from 19 languages, extracted from the CHILDES corpus. The text has been cleaned and is designed for text generation tasks, particularly in studying early language acquisition.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\nSource: CHILDES corpus\nLanguages: 19 languages\nText Type: Child-directed speech\nTask: Text Generation, Language Modeling\nData Processing: The dataset‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/IParraMartin/multiCHILDES.","first_N":5,"first_N_keywords":["text-generation","English","Basque","Spanish","Portuguese"],"keywords_longer_than_N":true},
	{"name":"UFLA-FORMS","keyword":"portuguese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Victorgonl/UFLA-FORMS","creator_name":"Victor Gon√ßalves Lima","creator_url":"https://huggingface.co/Victorgonl","description":"\n\t\n\t\t\n\t\tUFLA-FORMS: an Academic Forms Dataset for Information Extraction in the Portuguese Language\n\t\n\n\n\t\n\t\t\n\t\tAbout\n\t\n\nUFLA-FORMS is a manually labeled dataset of document forms in Brazilian Portuguese extracted from the domains of the Federal University of Lavras (UFLA). The dataset emphasizes the hierarchical structure between the entities of a document through their relationships, in addition to the extraction of key-value pairs. Samples were labeled using ToolRI.\n\n\t\n\t\t\n\t\n\t\n\t\tOverview‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Victorgonl/UFLA-FORMS.","first_N":5,"first_N_keywords":["token-classification","question-answering","table-question-answering","Portuguese","English"],"keywords_longer_than_N":true},
	{"name":"mgi__notas_fiscais","keyword":"portuguese","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/fredguth/mgi__notas_fiscais","creator_name":"Fred Guth","creator_url":"https://huggingface.co/fredguth","description":"\n\t\n\t\t\n\t\tDataset Card: mgi__notas_fiscais\n\t\n\nFiltered and enriched version of [cgu__notas_fiscais]\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\n\n\n\nCurated by: Fred Guth (@fredguth)\nFunded by: World Bank\nLanguage(s) (NLP): pt-br\nLicense: CC-BY 4.0\n\n\n\t\n\t\t\n\t\tDataset Sources\n\t\n\ncgu__notas_fiscais\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\n\t\n\t\t\n\t\titens_notas\n\t\n\n\n\t\n\t\t\ncolumn_name\ndata_type\ncomment\n\n\n\t\t\nchave_acesso\nVARCHAR\nidentificador da nota fiscal em que este item foi registrado.\n\n\nserie‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/fredguth/mgi__notas_fiscais.","first_N":5,"first_N_keywords":["tabular-classification","Portuguese","cc-by-4.0","10M - 100M","parquet"],"keywords_longer_than_N":true},
	{"name":"AyaVisionBench","keyword":"portuguese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/CohereLabs/AyaVisionBench","creator_name":"Cohere Labs","creator_url":"https://huggingface.co/CohereLabs","description":"\n\t\n\t\t\n\t\tDataset Card for Aya Vision Benchmark\n\t\n\n\n\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\nThe Aya Vision Benchmark is designed to evaluate vision-language models in real-world multilingual scenarios. It spans 23 languages and 9 distinct task categories, with 15 samples per category, resulting in 135 image-question pairs per language. \nEach question requires visual context for the answer and covers languages that half of the world's population speaks, making this dataset particularly suited for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/CohereLabs/AyaVisionBench.","first_N":5,"first_N_keywords":["English","French","German","Spanish","Italian"],"keywords_longer_than_N":true},
	{"name":"m-WildVision","keyword":"portuguese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/CohereLabs/m-WildVision","creator_name":"Cohere Labs","creator_url":"https://huggingface.co/CohereLabs","description":"\n\t\n\t\t\n\t\tDataset Card for m-WildVision\n\t\n\n\n\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\nThe m-WildVision dataset is a multilingual multimodal LLM evaluation set covering 23 languages.  It was created by translating prompts from the original English-only WildVision (vision_bench_0617) test set. \nThe original prompts, developed by Lu et al. (2024) , consist of 500 challenging user queries sourced from the WildVision-Arena platform. \nThe authors demonstrated that these prompts enable automatic LLM judge‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/CohereLabs/m-WildVision.","first_N":5,"first_N_keywords":["English","French","German","Spanish","Italian"],"keywords_longer_than_N":true},
	{"name":"OpenHumanreasoning-multilingual-2.2k","keyword":"portuguese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Pinkstack/OpenHumanreasoning-multilingual-2.2k","creator_name":"Pinkstack","creator_url":"https://huggingface.co/Pinkstack","description":"Based off of Pinkstackorg/humanreasoning-testing-en, it is a human-generated dataset where a real person had to create most of the reasoning and the final output. If there are any mistakes please let us know.\nWe offer this dataset at an apache-2.0 license to make it useful for everybody.\nnote: translations are not human generated.\n","first_N":5,"first_N_keywords":["text-generation","Arabic","Chinese","Czech","Danish"],"keywords_longer_than_N":true},
	{"name":"HPLT2.0_cleaned","keyword":"portuguese","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/jobs-git/HPLT2.0_cleaned","creator_name":"James Guana","creator_url":"https://huggingface.co/jobs-git","description":"This is a large-scale collection of web-crawled documents in 191 world languages, produced by the HPLT project. \nThe source of the data is mostly Internet Archive with some additions from Common Crawl.\nFor a detailed description of the dataset, please refer to https://hplt-project.org/datasets/v2.0\nThe Cleaned variant of HPLT Datasets v2.0\nThis is the cleaned variant of the HPLT Datasets v2.0 converted to the Parquet format semi-automatically when being uploaded here. \nThe original JSONL files‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/jobs-git/HPLT2.0_cleaned.","first_N":5,"first_N_keywords":["fill-mask","text-generation","language-modeling","multilingual","Achinese"],"keywords_longer_than_N":true},
	{"name":"Kaleidoscope","keyword":"portuguese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Anonym-sub/Kaleidoscope","creator_name":"Anonymous submission","creator_url":"https://huggingface.co/Anonym-sub","description":"\n\t\n\t\t\n\t\tKaleidoscope  (18 Languages)\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe Kaleidoscope Benchmark is a \nglobal collection of multiple-choice questions sourced from real-world exams, \nwith the goal of evaluating multimodal and multilingual understanding in VLMs. \nThe collected exams are in a Multiple-choice question answering (MCQA) \nformat which provides a structured framework for evaluation by prompting \nmodels with predefined answer choices, closely mimicking conventional human testing‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Anonym-sub/Kaleidoscope.","first_N":5,"first_N_keywords":["Arabic","Bengali","Croatian","Dutch","English"],"keywords_longer_than_N":true},
	{"name":"MAPS_Verified","keyword":"portuguese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Fujitsu-FRE/MAPS_Verified","creator_name":"Fujitsu Research of Europe","creator_url":"https://huggingface.co/Fujitsu-FRE","description":"\n\t\n\t\t\n\t\tDataset Card for Multilingual Benchmark for Global Agent Performance and Security\n\t\n\nThis is the first Multilingual Agentic AI Benchmark for evaluating agentic AI systems across different languages and diverse tasks. Benchmark enables systematic analysis of how agents perform under multilingual conditions. This dataset contains 550 instances for GAIA, 660 instances for ASB, 737 instances for Maths, and 1100 instances for SWE. Each task was translated into 10 target languages resulting‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Fujitsu-FRE/MAPS_Verified.","first_N":5,"first_N_keywords":["text-generation","question-answering","Arabic","English","Japanese"],"keywords_longer_than_N":true},
	{"name":"testdata","keyword":"portuguese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/leoloko/testdata","creator_name":"Leonardo","creator_url":"https://huggingface.co/leoloko","description":"leoloko/testdata dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["Portuguese","apache-2.0","< 1K","csv","Text"],"keywords_longer_than_N":true},
	{"name":"WiNNL","keyword":"portuguese","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/peemil/WiNNL","creator_name":"Emile Peetermans","creator_url":"https://huggingface.co/peemil","description":"\n\t\n\t\t\n\t\tWiNNL\n\t\n\nWikiNews Named entity recognition and Linking (WiNNL) is a multilingual news NER & NEL benchmark based on Wikinews articles.\nThe dataset was created by automatically scraping and tagging news articles, and manually corrected by native speakers to ensure accuracy.\nYou can find more information in the paper:\nhttps://aclanthology.org/2024.dlnld-1.3.pdf\nThe dataset includes the following NER classes in IOB format (labels):\n\nPER (Person): person names \nLOC (Location): geographical‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/peemil/WiNNL.","first_N":5,"first_N_keywords":["token-classification","Dutch","English","Spanish","Portuguese"],"keywords_longer_than_N":true},
	{"name":"open_government","keyword":"portuguese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/AgentPublic/open_government","creator_name":"AgentPublic","creator_url":"https://huggingface.co/AgentPublic","description":"\n\t\n\t\t\n\t\tOpen Government Dataset\n\t\n\nOpen Government is the largest agregation of governement text and data made available as part of open data programs. \nIn total, the dataset contains approximately 380B tokens. While Open Government aims to become a global resource, in its current state it mostly features open datasets from the US, France, European and international organizations.\nThe dataset comprises 16 collections curated through two different initiaties: Finance commons and Legal commons.‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/AgentPublic/open_government.","first_N":5,"first_N_keywords":["text-generation","English","French","Bulgarian","Croatian"],"keywords_longer_than_N":true},
	{"name":"FactNews","keyword":"portuguese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/franciellevargas/FactNews","creator_name":"Francielle Vargas","creator_url":"https://huggingface.co/franciellevargas","description":"\n\t\n\t\t\n\t\tEvaluation Benchmark for Sentence-Level Factuality Prediciton in Portuguese\n\t\n\nThe FactNews consits of the first large sentence-level annotated corpus for factuality prediciton in Portuguese. \nIt is composed of 6,191 sentences annotated according to factuality and media bias definitions proposed by AllSides. We use FactNews to assess the overall reliability of news sources by formulating \ntwo text classification problems for predicting sentence-level factuality of news reporting and‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/franciellevargas/FactNews.","first_N":5,"first_N_keywords":["text-classification","Portuguese","apache-2.0","10K - 100K","csv"],"keywords_longer_than_N":true},
	{"name":"GammaCorpus-Polylingo-50k","keyword":"portuguese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/rubenroy/GammaCorpus-Polylingo-50k","creator_name":"Ruben Roy","creator_url":"https://huggingface.co/rubenroy","description":"\n\t\n\t\t\n\t\tGammaCorpus Polylingo 50k\n\t\n\n\n\t\n\t\t\n\t\tWhat is it?\n\t\n\nThe GammaCorpus Polylingo 50k dataset consists of 50,000 structured, unfiltered, single-turn conversations, where each interaction includes:\n\nInput: A user prompt or question.\nOutput: A response generated by an AI assistant.\nLanguage: The language used in the interaction.\n\nThis dataset is designed to help in the training and evaluation of conversational AI models for linguistic purposes. This dataset can be especially helpful if you‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/rubenroy/GammaCorpus-Polylingo-50k.","first_N":5,"first_N_keywords":["text-generation","English","Russian","Vietnamese","German"],"keywords_longer_than_N":true},
	{"name":"Synthdog-Multilingual-100","keyword":"portuguese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/WueNLP/Synthdog-Multilingual-100","creator_name":"W√ºNLP","creator_url":"https://huggingface.co/WueNLP","description":"\n\t\n\t\t\n\t\tSynthdog Multilingual\n\t\n\n\n\nThe Synthdog dataset created for training in Centurio: On Drivers of Multilingual Ability of Large Vision-Language Model.\nUsing the official Synthdog code, we created >1 million training samples for improving OCR capabilities in Large Vision-Language Models.\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Details\n\t\n\nWe provide the images for download in two .tar.gz files. Download and extract them in folders of the same name (so cat images.tar.gz.* | tar xvzf -C images; tar xvzf‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/WueNLP/Synthdog-Multilingual-100.","first_N":5,"first_N_keywords":["image-to-text","multilingual","Afrikaans","Amharic","Arabic"],"keywords_longer_than_N":true},
	{"name":"kaleidoscope","keyword":"portuguese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/CohereLabs/kaleidoscope","creator_name":"Cohere Labs","creator_url":"https://huggingface.co/CohereLabs","description":"\n\t\n\t\t\n\t\tKaleidoscope  (18 Languages)\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe Kaleidoscope Benchmark is a \nglobal collection of multiple-choice questions sourced from real-world exams, \nwith the goal of evaluating multimodal and multilingual understanding in VLMs. \nThe collected exams are in a Multiple-choice question answering (MCQA) \nformat which provides a structured framework for evaluation by prompting \nmodels with predefined answer choices, closely mimicking conventional human testing‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/CohereLabs/kaleidoscope.","first_N":5,"first_N_keywords":["Arabic","Bengali","Croatian","Dutch","English"],"keywords_longer_than_N":true},
	{"name":"wikipedia-pt-embeddings","keyword":"portuguese","license":"European Union Public License 1.1","license_url":"https://choosealicense.com/licenses/eupl-1.1/","language":"en","dataset_url":"https://huggingface.co/datasets/marquesafonso/wikipedia-pt-embeddings","creator_name":"Afonso Marques","creator_url":"https://huggingface.co/marquesafonso","description":"\n\t\n\t\t\n\t\tDataset Card for Dataset Name\n\t\n\n\n\nA Wikipedia dataset using only the portuguese subset. An embeddings column is added to enable vector search. \nThe dataset has been chunked using chonkie and sentence transformers (model: static-similarity-mrl-multilingual-v1)\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Description\n\t\n\n\n\n\n\n\nCurated by: marquesafonso\nLanguage(s) (NLP): Portuguese\nLicense: eupl-1.1\n\n\n\t\n\t\n\t\n\t\tDataset Sources [optional]\n\t\n\n\n\n\nRepository: wikimedia/wikipedia‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/marquesafonso/wikipedia-pt-embeddings.","first_N":5,"first_N_keywords":["Portuguese","eupl-1.1","1M - 10M","parquet","Text"],"keywords_longer_than_N":true},
	{"name":"oab_bench","keyword":"portuguese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/felipeoes/oab_bench","creator_name":"Felipe Oliveira","creator_url":"https://huggingface.co/felipeoes","description":"\n\t\n\t\t\n\t\tOABench: Brazilian Bar Exams Benchmark Dataset\n\t\n\n\n\n\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nOABench is a benchmark dataset designed to evaluate the performance of Large Language Models (LLMs) on Brazilian legal exams. It is based on the Unified Bar Exam of the Brazilian Bar Association (OAB), a comprehensive and challenging exam required for law graduates to practice law in Brazil. This dataset provides a rigorous and realistic testbed for LLMs in the legal domain, covering a wide range of legal topics‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/felipeoes/oab_bench.","first_N":5,"first_N_keywords":["question-answering","Portuguese","mit","< 1K","parquet"],"keywords_longer_than_N":true},
	{"name":"oab_bench","keyword":"portuguese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/felipeoes/oab_bench","creator_name":"Felipe Oliveira","creator_url":"https://huggingface.co/felipeoes","description":"\n\t\n\t\t\n\t\tOABench: Brazilian Bar Exams Benchmark Dataset\n\t\n\n\n\n\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nOABench is a benchmark dataset designed to evaluate the performance of Large Language Models (LLMs) on Brazilian legal exams. It is based on the Unified Bar Exam of the Brazilian Bar Association (OAB), a comprehensive and challenging exam required for law graduates to practice law in Brazil. This dataset provides a rigorous and realistic testbed for LLMs in the legal domain, covering a wide range of legal topics‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/felipeoes/oab_bench.","first_N":5,"first_N_keywords":["question-answering","Portuguese","mit","< 1K","parquet"],"keywords_longer_than_N":true},
	{"name":"M-ABSA","keyword":"portuguese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Multilingual-NLP/M-ABSA","creator_name":"multilingual-NLP","creator_url":"https://huggingface.co/Multilingual-NLP","description":"\n\t\n\t\t\n\t\tM-ABSA\n\t\n\nThis repo contains the data for our paper M-ABSA: A Multilingual Dataset for Aspect-Based Sentiment Analysis.\n\n\n\t\n\t\t\n\t\tData Description:\n\t\n\nThis is a dataset suitable for the multilingual ABSA task with triplet extraction.\nAll datasets are stored in the data/ folder:\n\nAll dataset contains 7 domains.\n\ndomains = [\"coursera\", \"hotel\", \"laptop\", \"restaurant\", \"phone\", \"sight\", \"food\"]\n\n\nEach dataset contains 21 languages.\n\nlangs = [\"ar\", \"da\", \"de\", \"en\", \"es\", \"fr\", \"hi\", \"hr\"‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Multilingual-NLP/M-ABSA.","first_N":5,"first_N_keywords":["token-classification","text-classification","Arabic","Danish","German"],"keywords_longer_than_N":true},
	{"name":"smol","keyword":"portuguese","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/google/smol","creator_name":"Google","creator_url":"https://huggingface.co/google","description":"\n\t\n\t\t\n\t\tSMOL\n\t\n\nSMOL (Set for Maximal Overall Leverage) is a collection of professional\ntranslations into 221 Low-Resource Languages, for the purpose of training\ntranslation models, and otherwise increasing the representations of said\nlanguages in NLP and technology.\nPlease read the SMOL Paper and the\nGATITOS Paper for a much more\nthorough description!\nThere are four resources in this directory:\n\nSmolDoc: document-level translations into 100 languages\nSmolSent: sentence-level translations into‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/google/smol.","first_N":5,"first_N_keywords":["translation","Afar","Abkhaz","Achinese","Acoli"],"keywords_longer_than_N":true},
	{"name":"LivingNER","keyword":"portuguese","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Praise2112/LivingNER","creator_name":"Praise","creator_url":"https://huggingface.co/Praise2112","description":"\n\t\n\t\t\n\t\tLivingNER: Named entity recognition, normalization & classification of species, pathogens and food\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThe LivingNER Gold Standard corpus is a collection of 2000 clinical case reports covering a broad range of medical specialities, i.e. infectious diseases (including Covid-19 cases), cardiology, neurology, oncology, dentistry, pediatrics, endocrinology, primary care, allergology, radiology, psychiatry, ophthalmology, urology, internal medicine, emergency and‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Praise2112/LivingNER.","first_N":5,"first_N_keywords":["token-classification","multilingual","English","French","Galolen"],"keywords_longer_than_N":true},
	{"name":"DATA-AI_Chat","keyword":"portuguese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Mattimax/DATA-AI_Chat","creator_name":"M.INC.","creator_url":"https://huggingface.co/Mattimax","description":"\n\t\n\t\t\n\t\tDATA-AI: Il Modello di IA di M.INC.\n\t\n\n\n\t\n\t\t\n\t\tüìå Introduzione\n\t\n\nDATA-AI √® un avanzato modello di intelligenza artificiale sviluppato da *M.INC., un'azienda italiana fondata da *Mattimax (M. Marzorati).Questo modello √® basato sull'architettura ELNS (Elaborazione del Linguaggio Naturale Semplice), un sistema innovativo progettato per rendere l'IA accessibile su quasi qualsiasi dispositivo, garantendo prestazioni ottimali anche su hardware limitato.  \nDATA-AI √® stato addestrato su un‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Mattimax/DATA-AI_Chat.","first_N":5,"first_N_keywords":["Italian","English","Spanish","Russian","German"],"keywords_longer_than_N":true},
	{"name":"PolyGuardMix","keyword":"portuguese","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ToxicityPrompts/PolyGuardMix","creator_name":"ToxicityPrompts","creator_url":"https://huggingface.co/ToxicityPrompts","description":"\n\t\n\t\t\n\t\tPolyGuard: A Multilingual Safety Moderation Tool for 17 Languages\n\t\n\nAbstract: Truly multilingual safety moderation efforts for Large Language Models (LLMs) have been hindered by a narrow focus on a small set of languages (e.g., English, Chinese) as well as a limited scope of safety definition, resulting in significant gaps in moderation capabilities. To bridge these gaps, we release PolyGuard, a new state-of-the-art multilingual safety model for safeguarding LLM generations, and the‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ToxicityPrompts/PolyGuardMix.","first_N":5,"first_N_keywords":["Arabic","Chinese","Czech","Dutch","English"],"keywords_longer_than_N":true},
	{"name":"2M-Belebele","keyword":"portuguese","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/facebook/2M-Belebele","creator_name":"AI at Meta","creator_url":"https://huggingface.co/facebook","description":"\n\t\n\t\t\n\t\t2M-Belebele\n\t\n\n\n\t\n\t\t\n\t\tHighly-Multilingual Speech and American Sign Language Comprehension Dataset\n\t\n\nWe introduce 2M-Belebele as the first highly multilingual speech and American Sign Language (ASL) comprehension dataset. Our dataset, which is an extension of the existing Belebele only-text dataset, covers 74 spoken languages at the intersection of Belebele and Fleurs, and one sign language (ASL). \nThe speech dataset is built from aligning Belebele, Flores200 and Fleurs datasets as‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/facebook/2M-Belebele.","first_N":5,"first_N_keywords":["question-answering","automatic-speech-recognition","Bulgarian","Panjabi","English"],"keywords_longer_than_N":true},
	{"name":"imatrix-calibration","keyword":"portuguese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/eaddario/imatrix-calibration","creator_name":"Ed Addario","creator_url":"https://huggingface.co/eaddario","description":"\n\t\n\t\t\n\t\tImportance Matrix Calibration Datasets\n\t\n\nThis repository contains calibration datasets used to generate importance matrices (imatrix), which in turn help minimise errors introduced during quantization.\n\n\t\n\t\t\n\t\tMath calibration datasets\n\t\n\nThis dataset consists of over 10M tokens of cleaned math prompts and is available in six sizes, ranging from huge (~ 430,000 lines equivalent to approx. 10M tokens), to micro (~ 13,700 lines and 1.7M tokens avg).\nOriginal data sourced from‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/eaddario/imatrix-calibration.","first_N":5,"first_N_keywords":["text-generation","Arabic","Chinese","German","English"],"keywords_longer_than_N":true},
	{"name":"reasoning-multilingual-R1-Llama-70B-train","keyword":"portuguese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/lightblue/reasoning-multilingual-R1-Llama-70B-train","creator_name":"Lightblue KK.","creator_url":"https://huggingface.co/lightblue","description":"\n\t\n\t\t\n\t\tlightblue/reasoning-multilingual-R1-Llama-70B-train\n\t\n\nThis is a multilingual reasoning dataset covering more than 30 languages.\nThis dataset was made by:\n\nSampling prompts from English datasets and translating them to various languages\nGenerating responses to these prompts 8 times using deepseek-ai/DeepSeek-R1-Distill-Llama-70B\nFiltering out <think> sections with incorrect language, non-fluent language, and incorrect answers\n\nThis dataset was then used to train a multilingual‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/lightblue/reasoning-multilingual-R1-Llama-70B-train.","first_N":5,"first_N_keywords":["Amharic","Arabic","Bengali","Chinese","Czech"],"keywords_longer_than_N":true},
	{"name":"HateBR","keyword":"portuguese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/franciellevargas/HateBR","creator_name":"Francielle Vargas","creator_url":"https://huggingface.co/franciellevargas","description":"\n\t\n\t\t\n\t\tHateBR: The Evaluation Benchmark for Brazilian Portuguese Hate Speech Detection\n\t\n\nHateBR is the first large-scale, expert-annotated dataset of Brazilian Instagram comments specifically designed for hate speech detection on the web and social media. The dataset was collected from Brazilian Instagram comments made by politicians and manually annotated by specialists.\nIt contains 7,000 documents, annotated across three distinct layers:\nBinary classification (offensive vs. non-offensive‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/franciellevargas/HateBR.","first_N":5,"first_N_keywords":["text-classification","Portuguese","apache-2.0","1K - 10K","csv"],"keywords_longer_than_N":true},
	{"name":"MOL","keyword":"portuguese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/franciellevargas/MOL","creator_name":"Francielle Vargas","creator_url":"https://huggingface.co/franciellevargas","description":"\n\t\n\t\t\n\t\tMOL - Context-Aware Multilingual Offensive Lexicon\n\t\n\nThe MOL is the first specialized lexicon for hate speech detection, annotated with contextual information.\nIt consists of 1,000 explicit and implicit (clue-based) human-annotated rationales used with pejorative connotations, manually identified by a linguist and annotated by three experts regarding their contextual dependency (context-dependent or context-independent).\nFor example, the term \"stupid\" is classified as a‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/franciellevargas/MOL.","first_N":5,"first_N_keywords":["text-classification","Portuguese","English","German","Spanish"],"keywords_longer_than_N":true},
	{"name":"CPTransExercise","keyword":"portuguese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/edmond5995/CPTransExercise","creator_name":"Hoi","creator_url":"https://huggingface.co/edmond5995","description":"Chinese-Portuguese Translation Exercise Corpus (CPTEC)\nThis dataset aims to provide translators to practice Chinese-Portuguese translation with different levels from basic to proficient.\nThis is a sample dataset from CPTEC, please contact us for more information.\nCitation\nIf you use this dataset, please cite:\nHoi, L. M., Sun, Y., Lin, M., & Im, S. K. (2025). Design of Intelligent Educational Mobile Apps with an Original Dataset for Chinese-Portuguese Translators. Forum for Linguistic Studies‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/edmond5995/CPTransExercise.","first_N":5,"first_N_keywords":["translation","Chinese","Portuguese","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"MultiLingualSentiment","keyword":"portuguese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/clapAI/MultiLingualSentiment","creator_name":"clapAI","creator_url":"https://huggingface.co/clapAI","description":"\n\t\n\t\t\n\t\tOverview\n\t\n\nMultilingualSentiment is a sentiment classification dataset that encompasses three sentiment labels: Positive, Neutral, Negative\nThe dataset spans multiple languages and covers a wide range of domains, making it ideal for multilingual sentiment analysis tasks.\n\n\t\n\t\t\n\t\tDataset Information\n\t\n\nThe dataset was meticulously collected and aggregated from various sources, including Hugging Face and Kaggle. These sources provide diverse languages and domains to ensure a‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/clapAI/MultiLingualSentiment.","first_N":5,"first_N_keywords":["text-classification","Arabic","German","English","Spanish"],"keywords_longer_than_N":true},
	{"name":"YouTube-Commons","keyword":"portuguese","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Rijgersberg/YouTube-Commons","creator_name":"Edwin Rijgersberg","creator_url":"https://huggingface.co/Rijgersberg","description":"\n\t\n\t\t\n\t\tYouTube Commons Re-upload\n\t\n\nThis is a re-upload of PleIAs' YouTube Commons, a valuable open dataset:\n\nYouTube-Commons is a collection of audio transcripts of 2,063,066 videos shared on YouTube under a CC BY 4.0 license.\nContent\nThe collection comprises 22,709,724 original and automatically translated transcripts from 3,156,703 videos (721,136 individual channels).\n\nUnfortunately, there are problems with loading YouTube Commons with Hugging Face Datasets.\nIn order to alleviate those‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Rijgersberg/YouTube-Commons.","first_N":5,"first_N_keywords":["text-generation","English","French","Spanish","Portuguese"],"keywords_longer_than_N":true},
	{"name":"InferBR","keyword":"portuguese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/hapaxlegomenon/InferBR","creator_name":"Matheus Westhelle","creator_url":"https://huggingface.co/hapaxlegomenon","description":"\n\t\n\t\t\n\t\tInferBR\n\t\n\nThis is the InferBR dataset for Natural Language Inference in Portuguese. This version removes the flagged low-quality samples from the original dataset,\nkeeping 10.528 samples. The Github repo with the raw data can be found at: https://github.com/lbencke/InferBR.\n\n\t\n\t\t\n\t\tColumns\n\t\n\nsentence_pair_id: Identifier for premise-hypothesis sentence pairs.\npremise: The premise sentence.\nhypothesis: The hypothesis sentence.\nlabel: The generated label for the hypothesis considering‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/hapaxlegomenon/InferBR.","first_N":5,"first_N_keywords":["text-classification","Portuguese","mit","10K - 100K","csv"],"keywords_longer_than_N":true},
	{"name":"news-of-the-brazilian-newspaper","keyword":"portuguese","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/emdemor/news-of-the-brazilian-newspaper","creator_name":"Eduardo Morais","creator_url":"https://huggingface.co/emdemor","description":"\n\t\n\t\t\n\t\tNews of the Brazilian Newspaper\n\t\n\nThis repository contains a comprehensive dataset of news articles from a Brazilian newspaper, Folha de S√£o Paulo (http://www.folha.uol.com.br/). The dataset includes 167,053 examples of news articles, comprising headlines, URLs of articles, complete articles, and their respective categories. \n\n\t\n\t\t\n\t\tDataset Creation\n\t\n\nThe headlines were initially gathered from Inshorts and were then used to scrape the complete news articles from Folha de S√£o Paulo.‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/emdemor/news-of-the-brazilian-newspaper.","first_N":5,"first_N_keywords":["text-classification","summarization","feature-extraction","text-generation","Portuguese"],"keywords_longer_than_N":true},
	{"name":"GUI-Ban","keyword":"portuguese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/wendellast/GUI-Ban","creator_name":"wendel alves","creator_url":"https://huggingface.co/wendellast","description":"wendellast/GUI-Ban dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["text-generation","English","Portuguese","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"P-MMEval","keyword":"portuguese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Qwen/P-MMEval","creator_name":"Qwen","creator_url":"https://huggingface.co/Qwen","description":"\n\t\n\t\t\n\t\tP-MMEval: A Parallel Multilingual Multitask Benchmark for Consistent Evaluation of LLMs\n\t\n\n\n\t\n\t\t\n\t\tIntroduction\n\t\n\nWe introduce a multilingual benchmark, P-MMEval, covering effective fundamental and capability-specialized datasets. We extend the existing benchmarks, ensuring consistent language coverage across all datasets and providing parallel samples among multiple languages, supporting up to 10 languages from 8 language families (i.e., en, zh, ar, es, ja, ko, th, fr, pt, vi). As a‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Qwen/P-MMEval.","first_N":5,"first_N_keywords":["Arabic","Spanish","French","Japanese","Korean"],"keywords_longer_than_N":true},
	{"name":"belebele-fleurs","keyword":"portuguese","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/WueNLP/belebele-fleurs","creator_name":"W√ºNLP","creator_url":"https://huggingface.co/WueNLP","description":"\n\t\n\t\t\n\t\tBelebele-Fleurs\n\t\n\nBelebele-Fleurs is a dataset suitable to evaluate two core tasks:\n\nMultilingual Spoken Language Understanding (Listening Comprehension): For each spoken paragraph, the task is to answer a multiple-choice question. The question and four answer choices are provided in text form.\nMultilingual Long-Form Automatic Speech Recognition (ASR) with Diverse Speakers: By concatenating sentence-level utterances, long-form audio clips (ranging from 30 seconds to 1 minute 30‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/WueNLP/belebele-fleurs.","first_N":5,"first_N_keywords":["audio-classification","automatic-speech-recognition","audio-text-to-text","text-to-speech","question-answering"],"keywords_longer_than_N":true},
	{"name":"reranker_continuous_filt_max7_train","keyword":"portuguese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/lightblue/reranker_continuous_filt_max7_train","creator_name":"Lightblue KK.","creator_url":"https://huggingface.co/lightblue","description":"\n\t\n\t\t\n\t\tReranker training data\n\t\n\nThis data was generated using 4 steps:\n\nWe gathered queries and corresponding text data from 35 high quality datasets covering more than 95 languages.\nFor datasets which did not already have negative texts for queries, we mined hard negatives using the BAAI/bge-m3 embedding model.\nFor each query, we selected one positive and one negative text and used Qwen/Qwen2.5-32B-Instruct-GPTQ-Int4 to rate the relatedness of each query-text pair using a token \"1\", \"2\"‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/lightblue/reranker_continuous_filt_max7_train.","first_N":5,"first_N_keywords":["English","Chinese","Spanish","German","Arabic"],"keywords_longer_than_N":true},
	{"name":"PublicTransportAI","keyword":"portuguese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Willgnner-Santos/PublicTransportAI","creator_name":"Willgnner Ferreira Santos","creator_url":"https://huggingface.co/Willgnner-Santos","description":"\n\t\n\t\t\n\t\tDataset Card for PublicTransportAI\n\t\n\nPublicTransportAI is a public dataset focused on demand forecasting for urban public transportation in Goi√¢nia (Brazil). It was developed as part of the research published in the Brazilian Journal of Technology (DOI: 10.38152/bjtv3n4-003) and includes structured and raw data used to train 1D Convolutional Neural Networks (CNNs) for daily passenger demand prediction.\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\n\t\n\t\tDescription\n\t\n\n\nCurated by: Willgnner‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Willgnner-Santos/PublicTransportAI.","first_N":5,"first_N_keywords":["time-series-forecasting","English","Portuguese","apache-2.0","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"PangeaBench-xm100","keyword":"portuguese","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/neulab/PangeaBench-xm100","creator_name":"NeuLab @ LTI/CMU","creator_url":"https://huggingface.co/neulab","description":"\n\t\n\t\t\n\t\n\t\n\t\tXM100\n\t\n\n\n\t\n\t\t\n\t\n\t\n\t\tThis is a copy from https://google.github.io/crossmodal-3600/\n\t\n\nIf you use this dataset, please cite the original authors:\n@inproceedings{ThapliyalCrossmodal2022,\n  author = {Ashish Thapliyal and Jordi Pont-Tuset and Xi Chen and Radu Soricut},\n  title = {{Crossmodal-3600: A Massively Multilingual Multimodal Evaluation Dataset}},\n  booktitle = {EMNLP},\n  year = {2022}\n}\n\n","first_N":5,"first_N_keywords":["image-to-text","Arabic","Bengali","Czech","Danish"],"keywords_longer_than_N":true},
	{"name":"Everything_Instruct_Multilingual","keyword":"portuguese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/rombodawg/Everything_Instruct_Multilingual","creator_name":"rombo dawg","creator_url":"https://huggingface.co/rombodawg","description":"\n\t\n\t\t\n\t\tEverything Instruct (Multilingual Edition)\n\t\n\nEverything you need... all in one place üíò\n\nEverything instruct (Multilingual Edition) is a massive alpaca instruct formatted dataset consisting of a wide variety of topics meant to bring LLM's to the next level in open source AI.\nNote: This dataset is fully uncensored (No model will refuse any request trained on this dataset unless otherwise aligned)\nNote2: This version of the dataset supports the following languages:\n\nEnglish\nRussian‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/rombodawg/Everything_Instruct_Multilingual.","first_N":5,"first_N_keywords":["English","Russian","Chinese","Korean","Urdu"],"keywords_longer_than_N":true},
	{"name":"Kurtis-E1-Multilingual-01-SFT","keyword":"portuguese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ethicalabs/Kurtis-E1-Multilingual-01-SFT","creator_name":"ethicalabs.ai","creator_url":"https://huggingface.co/ethicalabs","description":"ethicalabs/Kurtis-E1-Multilingual-01-SFT dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["English","Italian","Spanish","French","Portuguese"],"keywords_longer_than_N":true},
	{"name":"brazilian-news-articles","keyword":"portuguese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/maikerdr/brazilian-news-articles","creator_name":"reis","creator_url":"https://huggingface.co/maikerdr","description":"maikerdr/brazilian-news-articles dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["text-generation","summarization","Portuguese","mit","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"webfaq","keyword":"portuguese","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/PaDaS-Lab/webfaq","creator_name":"Chair of Data Science, University of Passau","creator_url":"https://huggingface.co/PaDaS-Lab","description":"WebFAQ Q&A Dataset\n\n   \n       Overview |\n       Details  |\n       Structure  |\n       Examples |\n       Considerations |\n       License |\n       Citation |\n       Contact |\n       Acknowledgement\n   \n\n\n\n\t\n\t\t\n\t\n\t\n\t\tOverview\n\t\n\nThe WebFAQ Q&A Dataset is a broad-coverage corpus of 96 million natural question-answer (QA) pairs in 75 languages, gathered from FAQ pages on the web. It leverages structured schema.org FAQPage annotations, making it a unique resource for large-scale Question Answering‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/PaDaS-Lab/webfaq.","first_N":5,"first_N_keywords":["question-answering","multilingual","Afrikaans","Amharic","Arabic"],"keywords_longer_than_N":true},
	{"name":"ordem_paranormal_QA","keyword":"portuguese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/thnbi/ordem_paranormal_QA","creator_name":"Renato Freitas","creator_url":"https://huggingface.co/thnbi","description":"\n\t\n\t\t\n\t\tDataset Ordem Paranormal: Enigma do Medo\n\t\n\nDataset para o modelo thnbi/magistrada\n\n\t\n\t\t\n\t\tDescri√ß√£o\n\t\n\nEste dataset cont√©m pares de instru√ß√£o-resposta baseados no universo do jogo \"Enigma do Medo\", parte do sistema de RPG Ordem Paranormal. Os dados foram extra√≠dos e curados a partir da Wiki oficial do Ordem Paranormal.\n\n\t\n\t\t\n\t\tConte√∫do\n\t\n\n\nPerguntas e respostas sobre localiza√ß√µes do jogo\nInforma√ß√µes sobre mec√¢nicas e sistemas\nDetalhes sobre a narrativa e lore\nOrienta√ß√µes sobre‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/thnbi/ordem_paranormal_QA.","first_N":5,"first_N_keywords":["Portuguese","mit","< 1K","json","Text"],"keywords_longer_than_N":true},
	{"name":"MMMLU_subset","keyword":"portuguese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/double7/MMMLU_subset","creator_name":"Sen Yang","creator_url":"https://huggingface.co/double7","description":"\n\t\n\t\t\n\t\tAbout MMMLU subset\n\t\n\n  This is a subset of MMMLU, specifically, we sampled 10% of the original data to improve evaluation efficiency.\n  In addition, we categorize the questions into four categories by subject, i.e., STEM, HUMANITIES, SOCIAL SCIENCES, and OTHER, aligned with MMLU.\n\n\t\n\t\t\n\t\n\t\n\t\tMultilingual Massive Multitask Language Understanding (MMMLU)\n\t\n\nThe MMLU is a widely recognized benchmark of general knowledge attained by AI models. It covers a broad range of topics from 57‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/double7/MMMLU_subset.","first_N":5,"first_N_keywords":["question-answering","Arabic","Bengali","German","Spanish"],"keywords_longer_than_N":true},
	{"name":"Dhanishtha-2.0-SUPERTHINKER","keyword":"portuguese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/HelpingAI/Dhanishtha-2.0-SUPERTHINKER","creator_name":"HelpingAI","creator_url":"https://huggingface.co/HelpingAI","description":"üì¶ Dhanishtha-2.0-SUPERTHINKER\n A distilled corpus of 11.7K high-quality samples showcasing multi-phase reasoning and structured emotional cognition. Sourced directly from the internal training data of Dhanishtha-2.0 ‚Äî the world‚Äôs first Large Language Model (LLM) to implement Intermediate Thinking, featuring multiple <think> and <ser> blocks per response\n\n\n\t\n\t\t\n\t\tüìä Overview\n\t\n\n\n11.7K multilingual samples (languages listed below)\nInstruction-Output format, ideal for supervised fine-tuning‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/HelpingAI/Dhanishtha-2.0-SUPERTHINKER.","first_N":5,"first_N_keywords":["text-generation","Afrikaans","Arabic","Bulgarian","Catalan"],"keywords_longer_than_N":true},
	{"name":"ericksonian-core-competencies-multilingual","keyword":"portuguese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/LoneWolfgang/ericksonian-core-competencies-multilingual","creator_name":"Jordan Wolfgang Klein","creator_url":"https://huggingface.co/LoneWolfgang","description":"This dataset is designed to improve the cross-lingual alignment of sentence embeddings related to the work of Milton H. Erickson. Each row contains an English sentence paired with its translation in one of four target languages: French, Spanish, Italian, or Portuguese. The dataset can be used to fine-tune cross-lingual alignment using the tools and procedures developed by SBERT.\nMilton H. Erickson (1901‚Äì1980) was a historically significant hypnotherapist and a pioneer of brief therapy. The‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/LoneWolfgang/ericksonian-core-competencies-multilingual.","first_N":5,"first_N_keywords":["translation","English","Italian","Portuguese","Spanish"],"keywords_longer_than_N":true},
	{"name":"harmful-text","keyword":"portuguese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/nicholasKluge/harmful-text","creator_name":"Nicholas Kluge Corr√™a","creator_url":"https://huggingface.co/nicholasKluge","description":"\n\t\n\t\t\n\t\tHarmful-Text\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset contains a collection of examples of harmful and harmless language. The dataset is available in both Portuguese and English.\nSamples were collected from the following datasets:\n\nAnthropic/hh-rlhf.\nallenai/prosocial-dialog.\nallenai/real-toxicity-prompts.\ndirtycomputer/Toxic_Comment_Classification_Challenge.\nPaul/hatecheck-portuguese.\ntold-br.\nskg/toxigen-data.\n\n\n\t\n\t\t\n\t\tSupported Tasks and Leaderboards\n\t\n\nThis dataset can be‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/nicholasKluge/harmful-text.","first_N":5,"first_N_keywords":["text-classification","Portuguese","English","apache-2.0","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"multilingual-queries-for-collected-works-of-milton-h-erickson","keyword":"portuguese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/LoneWolfgang/multilingual-queries-for-collected-works-of-milton-h-erickson","creator_name":"Jordan Wolfgang Klein","creator_url":"https://huggingface.co/LoneWolfgang","description":"\n\t\n\t\t\n\t\tMultilingual Queries for the Collected Works of Milton H. Erickson\n\t\n\nThis collection contains machine-generated and translated queries designed to evaluate the performance of a multilingual retriever adapted to Ericksonian terminology.\nTo create the queries, the Collected Works of Milton H. Erickson was segmented into 500-word samples. Also, a list of relevant keywords was extracted from the Glossary of Ericksonian Terminology. Using the samples and keywords, queries were generated by‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/LoneWolfgang/multilingual-queries-for-collected-works-of-milton-h-erickson.","first_N":5,"first_N_keywords":["translation","English","Portuguese","Japanese","Chinese"],"keywords_longer_than_N":true},
	{"name":"R3-eval-MMMLU","keyword":"portuguese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/HLeiTR/R3-eval-MMMLU","creator_name":"Shou-Yi Hung","creator_url":"https://huggingface.co/HLeiTR","description":"HLeiTR/R3-eval-MMMLU dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["question-answering","Arabic","Bengali","German","Spanish"],"keywords_longer_than_N":true},
	{"name":"EmoTalk-7","keyword":"portuguese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/NoeFlandre/EmoTalk-7","creator_name":"No√© Flandre","creator_url":"https://huggingface.co/NoeFlandre","description":"\n\t\n\t\t\n\t\tEmoTalk-7\n\t\n\nEmoTalk-7 is a large-scale, multilingual, synthetic multimodal emotion recognition dataset generated using the Mistral API. It covers 7 major European languages and contains realistic social media scenarios with comprehensive emotion analysis, visual descriptions, and cultural context annotations.\n\n\t\n\t\t\n\t\tüìù Dataset Summary\n\t\n\nEmoTalk-7 contains 1400+ multimodal emotion records with high-quality annotations. It is designed to simulate authentic social media content across‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/NoeFlandre/EmoTalk-7.","first_N":5,"first_N_keywords":["text-classification","English","French","Spanish","German"],"keywords_longer_than_N":true},
	{"name":"English-French-Portuguese-Lexicon","keyword":"portuguese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/MLap/English-French-Portuguese-Lexicon","creator_name":"aman prakash","creator_url":"https://huggingface.co/MLap","description":"\n\t\n\t\t\n\t\tDemo Notebook for this dataset\n\t\n\n\nDataset created with Gemini-Flash-2.5 API with the prompt given below:\n\nGenerate a list of 500 simple and commonly used English words, each translated into French and Portuguese. Format the output as CSV with the columns: English, French, Portuguese. Only include single words (no phrases or verbs starting with ‚Äòto‚Äô, like ‚Äòto eat‚Äô or ‚Äòto go‚Äô). Avoid grammatical verbs and ensure no repetitions.\n\nExtensive manual cleaning was done with the help of Google‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/MLap/English-French-Portuguese-Lexicon.","first_N":5,"first_N_keywords":["English","French","Portuguese","mit","< 1K"],"keywords_longer_than_N":true},
	{"name":"wikifacts-bench","keyword":"portuguese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/kaengreg/wikifacts-bench","creator_name":"Grigory Kovalev","creator_url":"https://huggingface.co/kaengreg","description":"kaengreg/wikifacts-bench dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["Russian","English","German","French","Portuguese"],"keywords_longer_than_N":true},
	{"name":"wikimedia","keyword":"portuguese","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/OpenLLM-France/wikimedia","creator_name":"OpenLLM France","creator_url":"https://huggingface.co/OpenLLM-France","description":"\n\t\n\t\t\n\t\tDataset Card\n\t\n\nThis dataset is a curated collection of Wikimedia pages in markdown format,\ncompiled from various Wikimedia projects across multiple languages.\nCovered Wikimedia Projects:\n\nwikipedia\nwikibooks\nwikinews\nwikiquote\nwikisource\nwikiversity\nwikivoyage\nwiktionary\n\nSupported Languages:\n\nar (Arabic)\nbr (Breton)\nca (Catalan)\nco (Corsican)\nde (German)\nen (English)\nes (Spanish)\neu (Basque)\nfr (French)\nfrp (Arpitan)\nit (Italian)\nnl (Dutch)\noc (Occitan)\npcd (Picard)\npt (Portuguese)‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/OpenLLM-France/wikimedia.","first_N":5,"first_N_keywords":["text-generation","fill-mask","language-modeling","masked-language-modeling","English"],"keywords_longer_than_N":true},
	{"name":"wpp_pav_transcrito_openai","keyword":"portuguese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/BernardoAI/wpp_pav_transcrito_openai","creator_name":"Bernardo Aires","creator_url":"https://huggingface.co/BernardoAI","description":"\n\t\n\t\t\n\t\tüé§ Transcri√ß√µes WhatsApp - OpenAI GPT-4o Transcribe\n\t\n\nEste dataset cont√©m transcri√ß√µes de mensagens de √°udio do WhatsApp geradas usando OpenAI GPT-4o Transcribe.\n\n\t\n\t\t\n\t\tüìã Descri√ß√£o\n\t\n\n\nOrigem: Mensagens de √°udio do WhatsApp em portugu√™s brasileiro\nModelo: OpenAI GPT-4o Transcribe\nPre√ßo: $6.00/1M tokens\nTotal de amostras: 198\nFormato de √°udio: WAV (16kHz)\nIdioma: Portugu√™s brasileiro\n\nModelo Whisper de alta precis√£o da OpenAI para transcri√ß√£o de √°udio.\n\n\t\n\t\t\n\t\n\t\n\t\tüìä Estat√≠sticas‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/BernardoAI/wpp_pav_transcrito_openai.","first_N":5,"first_N_keywords":["automatic-speech-recognition","Portuguese","mit","< 1K","parquet"],"keywords_longer_than_N":true},
	{"name":"pt_bantu","keyword":"portuguese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/andissonerangel/pt_bantu","creator_name":"Andissone Rangel","creator_url":"https://huggingface.co/andissonerangel","description":"andissonerangel/pt_bantu dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["translation","Portuguese","apache-2.0","< 1K","csv"],"keywords_longer_than_N":true},
	{"name":"oab_exams_2011_2025_combined","keyword":"portuguese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/russ7/oab_exams_2011_2025_combined","creator_name":"Erick Russo de Freitas Mathias","creator_url":"https://huggingface.co/russ7","description":"russ7/oab_exams_2011_2025_combined dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["feature-extraction","question-answering","Portuguese","mit","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"dhanishtha-2.0-superthinker-mlx","keyword":"portuguese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mlx-community/dhanishtha-2.0-superthinker-mlx","creator_name":"MLX Community","creator_url":"https://huggingface.co/mlx-community","description":"\n\t\n\t\t\n\t\tüì¶ Dhanishtha-2.0-SUPERTHINKER-MLX\n\t\n\n A distilled corpus of 11.7K high-quality samples showcasing multi-phase reasoning and structured emotional cognition. Sourced directly from the internal training data of Dhanishtha-2.0 ‚Äî the world‚Äôs first Large Language Model (LLM) to implement Intermediate Thinking, featuring multiple <think> and <ser> blocks per response\n\n\t\n\t\t\n\t\n\t\n\t\tExample with MLX-LM-LoRA:\n\t\n\nmlx_lm_lora.train \\\n--model‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mlx-community/dhanishtha-2.0-superthinker-mlx.","first_N":5,"first_N_keywords":["text-generation","Afrikaans","Arabic","Bulgarian","Catalan"],"keywords_longer_than_N":true},
	{"name":"domain-translations","keyword":"portuguese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/humbleworth/domain-translations","creator_name":"HumbleWorth","creator_url":"https://huggingface.co/humbleworth","description":"\n\t\n\t\t\n\t\tMultilingual Domain Name Translations Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset contains 155,004 domain names with their multilingual translations across 20 languages. Each domain has been segmented into constituent words and translated while preserving semantic meaning and commercial appeal. The dataset is particularly valuable for domain name research, multilingual NLP tasks, and understanding how brand names and concepts translate across languages.\n\n\t\n\t\t\n\t\tDataset‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/humbleworth/domain-translations.","first_N":5,"first_N_keywords":["translation","text-generation","feature-extraction","multilingual","Arabic"],"keywords_longer_than_N":true},
	{"name":"lapsbm2","keyword":"portuguese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/falabrasil/lapsbm2","creator_name":"Grupo FalaBrasil","creator_url":"https://huggingface.co/falabrasil","description":"falabrasil/lapsbm2 dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["automatic-speech-recognition","found","found","monolingual","original"],"keywords_longer_than_N":true},
	{"name":"MiniSetPT","keyword":"portuguese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/AxeML/MiniSetPT","creator_name":"Ax√©ML - Community","creator_url":"https://huggingface.co/AxeML","description":"\n  \n\n\n\n\t\n\t\t\n\t\tüìö Dataset de Perguntas e Respostas por T√≥pico\n\t\n\nEste reposit√≥rio cont√©m um dataset com 10.000 amostras estruturadas para tarefas de Processamento de Linguagem Natural (PLN), com foco em perguntas tem√°ticas e respostas desenvolvidas.\n\n\t\n\t\t\n\t\tüìÅ Estrutura dos Dados\n\t\n\nCada amostra √© representada em formato JSON com os seguintes campos:\n\nid (string): Identificador √∫nico da amostra (UUID).\ntopic (lista de strings): Lista com os t√≥picos abordados.\nprompts (lista de strings):‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/AxeML/MiniSetPT.","first_N":5,"first_N_keywords":["text-generation","Portuguese","mit","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"corpus-synthetic-lgpd","keyword":"portuguese","license":"Academic Free License v3.0","license_url":"https://choosealicense.com/licenses/afl-3.0/","language":"en","dataset_url":"https://huggingface.co/datasets/celiudos/corpus-synthetic-lgpd","creator_name":"Marcelo Anselmo de Souza Filho","creator_url":"https://huggingface.co/celiudos","description":"\n\t\n\t\t\n\t\tDataset: 105 samples for validation\n\t\n\nThis dataset is a sample of 105 documents from the Carolina Corpus, with data annotated in accordance with the LGPD (Brazilian General Data Protection Law).\nIt is part of an academic study for comparing legal language models.\nWe used to validate the model https://huggingface.co/celiudos/legal-bert-lgpd\nThe data has been modified to preserve privacy while maintaining the structure and content of the documents.\nThe CPF (Brazilian ID Number) had its‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/celiudos/corpus-synthetic-lgpd.","first_N":5,"first_N_keywords":["token-classification","Portuguese","afl-3.0","< 1K","parquet"],"keywords_longer_than_N":true},
	{"name":"corpus-carolina-jud-lgpd","keyword":"portuguese","license":"Academic Free License v3.0","license_url":"https://choosealicense.com/licenses/afl-3.0/","language":"en","dataset_url":"https://huggingface.co/datasets/celiudos/corpus-carolina-jud-lgpd","creator_name":"Marcelo Anselmo de Souza Filho","creator_url":"https://huggingface.co/celiudos","description":"\n\t\n\t\t\n\t\tCarolina Corpus with data annotated in accordance with the LGPD (Brazilian General Data Protection Law)\n\t\n\nThis dataset is a derivative of the Carolina Corpus.\nWe analyzed and filtered the content in search of personal data for academic purposes.\nWe balanced the dataset to train the model https://huggingface.co/celiudos/legal-bert-lgpd\n\n\t\n\t\t\nLabels\nEn\n\n\n\t\t\nNOME\nNAME\n\n\nDATA\nDATE\n\n\nENDERECO\nADDRESS\n\n\nCEP\nZIPCODE\n\n\nCPF\nCPF\n\n\nTELEFONE\nPHONE\n\n\nEMAIL\nEMAIL\n\n\nDINHEIRO\nMONEY‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/celiudos/corpus-carolina-jud-lgpd.","first_N":5,"first_N_keywords":["token-classification","Portuguese","afl-3.0","1K - 10K","parquet"],"keywords_longer_than_N":true},
	{"name":"quran_multilingual_parallel","keyword":"portuguese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/freococo/quran_multilingual_parallel","creator_name":"Wynn","creator_url":"https://huggingface.co/freococo","description":"\n\t\n\t\t\n\t\tüìò Qur‚Äôan Multilingual Parallel Dataset (quran_multilingual_parallel)\n\t\n\nThis dataset presents a clean, structurally-aligned multilingual parallel corpus of the Qur‚Äôanic text. It is intended for linguistic, computational, and cross-lingual AI applications ‚Äî not only for religious interpretation.\nIt contains over 6,200 verse-level alignments in 54 human languages, formatted in a machine-friendly .csv structure with language-specific translation fields.\n\n\n\t\n\t\t\n\t\n\t\n\t\tüß† Dataset Highlights‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/freococo/quran_multilingual_parallel.","first_N":5,"first_N_keywords":["translation","Arabic","Albanian","Amharic","Azerbaijani"],"keywords_longer_than_N":true},
	{"name":"wikipedia-citation-index","keyword":"portuguese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/lewoniewski/wikipedia-citation-index","creator_name":"W≈Çodzimierz Lewoniewski","creator_url":"https://huggingface.co/lewoniewski","description":"Dataset with citation indexes as of 1 August 2024 for 47 million Wikipedia articles in 55 language versions. Research: ArXiv\n","first_N":5,"first_N_keywords":["Arabic","Azerbaijani","Belarusian","Bulgarian","Catalan"],"keywords_longer_than_N":true},
	{"name":"MLSNT","keyword":"portuguese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/ComplexDataLab/MLSNT","creator_name":"Complex Data Lab","creator_url":"https://huggingface.co/ComplexDataLab","description":"\n\t\n\t\t\n\t\tMLSNT: Multi-Lingual Social Network Toxicity Dataset\n\t\n\nMLSNT is a multi-lingual dataset for toxicity detection created through a large language model-assisted label transfer pipeline. It enables efficient and scalable moderation across languages and platforms, and is built to support span-level and category-specific classification for toxic content.\nThis dataset is introduced in the following paper:\n\nUnified Game Moderation: Soft-Prompting and LLM-Assisted Label Transfer for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ComplexDataLab/MLSNT.","first_N":5,"first_N_keywords":["text-classification","token-classification","Chinese","Japanese","Portuguese"],"keywords_longer_than_N":true},
	{"name":"drbodebench","keyword":"portuguese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/recogna-nlp/drbodebench","creator_name":"Recogna NLP","creator_url":"https://huggingface.co/recogna-nlp","description":"\n\t\n\t\t\n\t\tBenchmark Brasileiro de Testes de Aptid√£o M√©dica: DrBodeBench (DBB)\n\t\n\n\n  \n\n\nEste conjunto de dados introduz um novo benchmark para avaliar modelos de linguagem grandes (LLMs) m√©dicos em portugu√™s brasileiro, abordando uma lacuna cr√≠tica na avalia√ß√£o de IA para aplica√ß√µes de sa√∫de em contextos n√£o ingleses. Ele √© constru√≠do a partir de testes de aptid√£o m√©dica brasileiros que abrangem o per√≠odo de 2011-2024, incluindo o Exame Nacional de Revalida√ß√£o de Diplomas M√©dicos Expedidos por‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/recogna-nlp/drbodebench.","first_N":5,"first_N_keywords":["Portuguese","apache-2.0","1K - 10K","json","Tabular"],"keywords_longer_than_N":true},
	{"name":"e-faq","keyword":"portuguese","license":"GNU General Public License v3.0","license_url":"https://choosealicense.com/licenses/gpl-3.0/","language":"en","dataset_url":"https://huggingface.co/datasets/GoBotsAI/e-faq","creator_name":"GoBots","creator_url":"https://huggingface.co/GoBotsAI","description":"GoBotsAI/e-faq dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["zero-shot-classification","Spanish","Portuguese","gpl-3.0","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"LargerSetPT","keyword":"portuguese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/AxeML/LargerSetPT","creator_name":"Ax√©ML - Community","creator_url":"https://huggingface.co/AxeML","description":"\n  \n\n\n\n\t\n\t\t\n\t\tüìö Dataset de Perguntas e Respostas por T√≥pico\n\t\n\nEste reposit√≥rio cont√©m um dataset com 100.000 amostras estruturadas para tarefas de Processamento de Linguagem Natural (PLN), com foco em perguntas tem√°ticas e respostas desenvolvidas.\n\n\t\n\t\t\n\t\tüìÅ Estrutura dos Dados\n\t\n\nCada amostra √© representada em formato JSON com os seguintes campos:\n\nid (string): Identificador √∫nico da amostra (UUID).\ntopic (lista de strings): Lista com os t√≥picos abordados.\nprompts (lista de strings):‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/AxeML/LargerSetPT.","first_N":5,"first_N_keywords":["question-answering","text-generation","Portuguese","mit","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"brazilian-news-article-summarization-DPO","keyword":"portuguese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/maikerdr/brazilian-news-article-summarization-DPO","creator_name":"reis","creator_url":"https://huggingface.co/maikerdr","description":"\n\t\n\t\t\n\t\tüóûÔ∏è Brazilian News Preference Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Card for maikerdr/brazilian-news-article-summarization-DPO\n\t\n\nGenerated using https://github.com/maikereis/news-summarizer\n\n\n\t\n\t\t\n\t\tüìù Dataset Summary\n\t\n\nThis dataset consists of Brazilian news articles scraped from reputable online journalism sources. \n\n\t\n\t\t\n\t\tG1\n\t\n\n\nhttps://g1.globo.com/politica/\nhttps://g1.globo.com/economia/\nhttps://g1.globo.com/ciencia/\nhttps://g1.globo.com/tecnologia/\nhttps://g1.globo.com/saude/‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/maikerdr/brazilian-news-article-summarization-DPO.","first_N":5,"first_N_keywords":["summarization","Portuguese","mit","1K - 10K","parquet"],"keywords_longer_than_N":true},
	{"name":"EuroGEC-7","keyword":"portuguese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/NoeFlandre/EuroGEC-7","creator_name":"No√© Flandre","creator_url":"https://huggingface.co/NoeFlandre","description":"\n\t\n\t\t\n\t\tEuroGEC-7: A Growing Multilingual Dataset for Grammatical Error Correction\n\t\n\nEuroGEC-7 is a large-scale, synthetic, multilingual grammatical error correction (GEC) dataset created using the Mistral API. It is specifically designed to simulate learner-style grammar mistakes across 7 major European languages ‚Äî with over 20,000 annotated pairs and counting.\nThis dataset is actively maintained and continuously expanding, both in scale and coverage. New entries are generated daily from a‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/NoeFlandre/EuroGEC-7.","first_N":5,"first_N_keywords":["English","French","Spanish","German","Italian"],"keywords_longer_than_N":true},
	{"name":"healthqa-br","keyword":"portuguese","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Larxel/healthqa-br","creator_name":"Andrew D'addario","creator_url":"https://huggingface.co/Larxel","description":"\n\t\n\t\t\n\t\tHealthQA-BR\n\t\n\n\n\t\n\t\t\n\t\tResumo\n\t\n\n\nO HealthQA-BR √© o primeiro benchmark de larga escala e abrang√™ncia para todo o Sistema √önico de Sa√∫de (SUS), projetado para medir o conhecimento cl√≠nico de Grandes Modelos de Linguagem (LLMs) frente aos desafios da sa√∫de p√∫blica brasileira. Composto por 5.632 quest√µes de m√∫ltipla escolha, o conjunto de dados √© derivado de provas e concursos de licenciamento profissional e resid√™ncia de abrang√™ncia nacional e de alto impacto no Brasil.\nDiferentemente de‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Larxel/healthqa-br.","first_N":5,"first_N_keywords":["question-answering","Portuguese","cc-by-4.0","1K - 10K","parquet"],"keywords_longer_than_N":true},
	{"name":"portuguese-fact-checking","keyword":"portuguese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/ju-resplande/portuguese-fact-checking","creator_name":"Juliana Resplande","creator_url":"https://huggingface.co/ju-resplande","description":"\n\t\n\t\t\n\t\tPortuguese Automated Fact-Checking\n\t\n\n\n\t\n\t\t\n\nFake.BR\nCOVID19.BR\nMuMiN-PT\n\n\n\t\t\nInfo (fake/true)\nüñ•Ô∏è\nüí¨\nX\n\n\nDomain\nGeneral\nHealth\n\"General\" (Health)\n\n\nYear\n2016‚Äì2018\n2020\n2020‚Äì2022\n\n\nApproach [1]\nbottom-up\nbottom-up\ntop-down\n\n\nSize\n3580/3580\n848/1139\n1339/65\n\n\n% URL\n1.0%/0.7%\n28.9%/56.9%\n0.3%/0.0%\n\n\nAvg. # words\n181.4/183.1\n167.7/111.1\n18.9/16.9\n\n\n\t\n\nCorpora characteristics after cleaning. Top-down starts with fact-checked claims; bottom-up seeks for new misinformation in posts.‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ju-resplande/portuguese-fact-checking.","first_N":5,"first_N_keywords":["text-classification","Portuguese","mit","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"wpp_pav_transcrito_gemini","keyword":"portuguese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/BernardoAI/wpp_pav_transcrito_gemini","creator_name":"Bernardo Aires","creator_url":"https://huggingface.co/BernardoAI","description":"\n\t\n\t\t\n\t\tüé§ Transcri√ß√µes WhatsApp - Google Gemini 2.0 Flash\n\t\n\nEste dataset cont√©m transcri√ß√µes de mensagens de √°udio do WhatsApp geradas usando Google Gemini 2.0 Flash.\n\n\t\n\t\t\n\t\tüìã Descri√ß√£o\n\t\n\n\nOrigem: Mensagens de √°udio do WhatsApp em portugu√™s brasileiro\nModelo: Google Gemini 2.0 Flash\nPre√ßo: $0.075/1M tokens\nTotal de amostras: 198\nFormato de √°udio: WAV (16kHz)\nIdioma: Portugu√™s brasileiro\n\nModelo de IA multimodal avan√ßado da Google com capacidades de an√°lise contextual de √°udio.‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/BernardoAI/wpp_pav_transcrito_gemini.","first_N":5,"first_N_keywords":["automatic-speech-recognition","Portuguese","mit","< 1K","parquet"],"keywords_longer_than_N":true},
	{"name":"wpp_pav_transcrito_deepgram","keyword":"portuguese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/BernardoAI/wpp_pav_transcrito_deepgram","creator_name":"Bernardo Aires","creator_url":"https://huggingface.co/BernardoAI","description":"\n\t\n\t\t\n\t\tüé§ Transcri√ß√µes WhatsApp - Deepgram Nova 2\n\t\n\nEste dataset cont√©m transcri√ß√µes de mensagens de √°udio do WhatsApp geradas usando Deepgram Nova 2.\n\n\t\n\t\t\n\t\tüìã Descri√ß√£o\n\t\n\n\nOrigem: Mensagens de √°udio do WhatsApp em portugu√™s brasileiro\nModelo: Deepgram Nova 2\nPre√ßo: $0.0043/minuto\nTotal de amostras: 198\nFormato de √°udio: WAV (16kHz)\nIdioma: Portugu√™s brasileiro\n\nModelo de transcri√ß√£o em tempo real da Deepgram com baixa lat√™ncia.\n\n\t\n\t\t\n\t\n\t\n\t\tüìä Estat√≠sticas\n\t\n\n\nTotal de amostras: 198‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/BernardoAI/wpp_pav_transcrito_deepgram.","first_N":5,"first_N_keywords":["automatic-speech-recognition","Portuguese","mit","< 1K","parquet"],"keywords_longer_than_N":true},
	{"name":"LLM_Multilingual_dataset","keyword":"portuguese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/lewishamilton21/LLM_Multilingual_dataset","creator_name":"Kesavprabu","creator_url":"https://huggingface.co/lewishamilton21","description":"\n\t\n\t\t\n\t\tDataset Card for Dataset Name\n\t\n\n\n\nThis dataset card aims to be a base template for new datasets. It has been generated using this raw template.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\n\n\n\n\n\nCurated by: [More Information Needed]\nFunded by [optional]: [More Information Needed]\nShared by [optional]: [More Information Needed]\nLanguage(s) (NLP): [More Information Needed]\nLicense: [More Information Needed]\n\n\n\t\n\t\t\n\t\tDataset Sources [optional]\n\t\n\n\n\n\nRepository: [More‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/lewishamilton21/LLM_Multilingual_dataset.","first_N":5,"first_N_keywords":["table-question-answering","Japanese","Finnish","Indonesian","Russian"],"keywords_longer_than_N":true},
	{"name":"emouerj-sed","keyword":"portuguese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/AdeoyeLadele/emouerj-sed","creator_name":"Adeoye Sunday Ladele","creator_url":"https://huggingface.co/AdeoyeLadele","description":"\n\t\n\t\t\n\t\tDataset Card for \"emouerj-sed\"\n\t\n\nThis Dataset is adapted from emoUERJ for the Speech Emotion Diarization Task.\nThe dataset is created following the recipe for described in the (SPEECH EMOTION DIARIZATION: WHICH EMOTION APPEARS WHEN?)[https://arxiv.org/pdf/2306.12991] paper.\n","first_N":5,"first_N_keywords":["audio-classification","Portuguese","apache-2.0","< 1K","parquet"],"keywords_longer_than_N":true},
	{"name":"SpokenPortugueseGeographicalSocialVarieties_splits","keyword":"portuguese","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Jarbas/SpokenPortugueseGeographicalSocialVarieties_splits","creator_name":"Casimiro Ferreira","creator_url":"https://huggingface.co/Jarbas","description":"sentence splits from SpokenPortugueseGeographicalSocialVarieties generated via forced alignment\n","first_N":5,"first_N_keywords":["automatic-speech-recognition","Portuguese","mit","1K - 10K","soundfolder"],"keywords_longer_than_N":true},
	{"name":"perguntas_e_respostas_astronomia_pt_br_V2.0","keyword":"portuguese","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/vinimuchulski/perguntas_e_respostas_astronomia_pt_br_V2.0","creator_name":"vini","creator_url":"https://huggingface.co/vinimuchulski","description":"\n\t\n\t\t\n\t\tREADME: Dataset JSON de Perguntas e Respostas sobre Astronomia\n\t\n\n\n\t\n\t\t\n\t\tVis√£o Geral\n\t\n\nEste reposit√≥rio cont√©m um dataset sint√©tico de perguntas e respostas sobre astronomia, gerado no formato JSON. O objetivo deste dataset √© servir como material educativo e para o ajuste fino (fine-tuning) de Modelos de Linguagem Grandes (LLMs).\nEsse dataset cont√©m 1000 perguntas e respostas variadas sobre t√≥picos de astronomia, como planetas, estrelas, gal√°xias e fen√¥menos c√≥smicos, juntamente com‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/vinimuchulski/perguntas_e_respostas_astronomia_pt_br_V2.0.","first_N":5,"first_N_keywords":["Portuguese","apache-2.0","1K - 10K","json","Text"],"keywords_longer_than_N":true},
	{"name":"bird-sql-portuguese","keyword":"portuguese","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Boakpe/bird-sql-portuguese","creator_name":"Breno","creator_url":"https://huggingface.co/Boakpe","description":"\n\t\n\t\t\n\t\tBIRD-SQL - Vers√£o em Portugu√™s\n\t\n\nEste reposit√≥rio cont√©m a tradu√ß√£o para portugu√™s da parti√ß√£o de treino e desenvolvimento do benchmark BIRD-SQL, um benchmark para a tarefa de Text-to-SQL.\n","first_N":5,"first_N_keywords":["table-question-answering","question-answering","Portuguese","cc-by-sa-4.0","1K<n<10K"],"keywords_longer_than_N":true}
]
;
