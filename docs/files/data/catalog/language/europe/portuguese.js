const data_for_language_europe_portuguese = 
[
	{"name":"TinyDS-20k","keyword":"portuguese","description":"\n\t\n\t\t\n\t\tTinyDS\n\t\n\n\n\n\nAlpaca-style dataset with around 20k samples scraped from Qwen3-8B using SyntheticAlpaca. Q&A pairs can be in 32 different languages, these are listed in the metadata.Topics are all around STEM, programming, and literature.  \nMIT @ 2025 Hamzah Asadullah\n\n\n","url":"https://huggingface.co/datasets/Hamzah-Asadullah/TinyDS-20k","creator_name":"Hamzah Asadullah","creator_url":"https://huggingface.co/Hamzah-Asadullah","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["question-answering","translation","text-generation","text2text-generation","English"],"keywords_longer_than_N":true},
	{"name":"fiqa_pt","keyword":"portuguese","description":"Using SeamlessM4T to translate FiQA to portuguese.\n","url":"https://huggingface.co/datasets/leonardo-avila/fiqa_pt","creator_name":"Leonardo B. A.","creator_url":"https://huggingface.co/leonardo-avila","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":null,"first_N":5,"first_N_keywords":["Portuguese","apache-2.0","ðŸ‡ºðŸ‡¸ Region: US"],"keywords_longer_than_N":false},
	{"name":"allenai_tulu-3-sft-mixture-DolphinLabeled","keyword":"portuguese","description":"\n\t\n\t\t\n\t\tallenai tulu-3-sft-mixture DolphinLabeled\n\t\n\n\n\t\n\t\t\n\t\tPart of the DolphinLabeled series of datasets\n\t\n\n\n\t\n\t\t\n\t\tPresented by Eric Hartford and Cognitive Computations\n\t\n\nThe purpose of this dataset is to enable filtering of allenai/tulu-3-sft-mixture dataset.\nThe original dataset is allenai/tulu-3-sft-mixture\nI have modified the dataset using two scripts.\n\ndedupe.py - removes rows with identical final message content\nlabel.py - adds a \"flags\" column containing the following booleanâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/QuixiAI/allenai_tulu-3-sft-mixture-DolphinLabeled.","url":"https://huggingface.co/datasets/QuixiAI/allenai_tulu-3-sft-mixture-DolphinLabeled","creator_name":"Quixi AI","creator_url":"https://huggingface.co/QuixiAI","license_name":"Open Data Commons Attribution License v1.0","license_url":"https://scancode-licensedb.aboutcode.org/odc-by-1.0.html","language":"en","first_N":5,"first_N_keywords":["other","crowdsourced","expert-generated","machine-generated","multilingual"],"keywords_longer_than_N":true},
	{"name":"reward-aira-dataset","keyword":"portuguese","description":"\n\t\n\t\t\n\t\tReward-Aira Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset contains a collection of prompt + completion examples of LLM following instructions in a conversational manner. All prompts come with two possible completions (one better than the other). The dataset is available in both Portuguese and English.\n\n\t\n\t\t\n\t\tSupported Tasks and Leaderboards\n\t\n\nThis dataset can be utilized to train a reward/preference model or DPO fine-tuning.\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nEnglish and Portuguese.â€¦ See the full description on the dataset page: https://huggingface.co/datasets/nicholasKluge/reward-aira-dataset.","url":"https://huggingface.co/datasets/nicholasKluge/reward-aira-dataset","creator_name":"Nicholas Kluge CorrÃªa","creator_url":"https://huggingface.co/nicholasKluge","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","Portuguese","English","apache-2.0","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"PortugueseLegalSentences-v3","keyword":"portuguese","description":"\n\t\n\t\t\n\t\tPortuguese Legal Sentences\n\t\n\nCollection of Legal Sentences from the Portuguese Supreme Court of Justice\nThe goal of this dataset was to be used for MLM and TSDAE\nExtended version of rufimelo/PortugueseLegalSentences-v1\n400000/50000/50000\n\n\t\n\t\t\n\t\tContributions\n\t\n\n@rufimelo99\n","url":"https://huggingface.co/datasets/rufimelo/PortugueseLegalSentences-v3","creator_name":"Rui Melo","creator_url":"https://huggingface.co/rufimelo","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["no-annotation","found","monolingual","original","Portuguese"],"keywords_longer_than_N":true},
	{"name":"prompt_injections","keyword":"portuguese","description":"\n\t\n\t\t\n\t\tDataset Card for Prompt Injections by  Yanis Miraoui  ðŸ‘‹\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset of prompt injections enriches Large Language Models (LLMs) by providing task-specific examples and prompts, helping improve LLMs' performance and control their behavior.\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset contains over 1000 rows of prompt injections in multiple languages. It contains examples of prompt injections using different techniques such as: prompt leaking, jailbreakingâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/yanismiraoui/prompt_injections.","url":"https://huggingface.co/datasets/yanismiraoui/prompt_injections","creator_name":"Yanis Miraoui","creator_url":"https://huggingface.co/yanismiraoui","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["no-annotation","multilingual","original","English","French"],"keywords_longer_than_N":true},
	{"name":"xlel_wd_dictionary","keyword":"portuguese","description":"XLEL-WD is a multilingual event linking dataset. This sub-dataset contains a dictionary of events from Wikidata. The multilingual descriptions for Wikidata event items are taken from the corresponding Wikipedia articles.","url":"https://huggingface.co/datasets/adithya7/xlel_wd_dictionary","creator_name":"Adithya Pratapa","creator_url":"https://huggingface.co/adithya7","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["found","found","multilingual","original","Afrikaans"],"keywords_longer_than_N":true},
	{"name":"minigpt4-7b-ggml","keyword":"portuguese","description":"These are quantized ggml binary files for minigpt4 7B model.\nThese files can be used in conjunction with vicuna v0 ggml models to get minigpt4 working.\nNot all implementations were tested. If there are any issues, use f16.\n","url":"https://huggingface.co/datasets/maknee/minigpt4-7b-ggml","creator_name":"maknee","creator_url":"https://huggingface.co/maknee","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":null,"first_N":5,"first_N_keywords":["English","Bulgarian","Catalan","Czech","Danish"],"keywords_longer_than_N":true},
	{"name":"seamless-align","keyword":"portuguese","description":"\n\t\n\t\t\n\t\tDataset Card for Seamless-Align (WIP). Inspired by https://huggingface.co/datasets/allenai/nllb\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset was created based on metadata for mined Speech-to-Speech(S2S), Text-to-Speech(TTS) and Speech-to-Text(S2T) released by Meta AI.  The S2S contains data for 35 language pairs. The S2S dataset is ~1000GB compressed.\n\n\t\n\t\t\n\t\tHow to use the data\n\t\n\nThere are two ways to access the data:\n\nVia the Hugging Face Python datasets library\n\nScripts coming soonâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/jhu-clsp/seamless-align.","url":"https://huggingface.co/datasets/jhu-clsp/seamless-align","creator_name":"Center for Language and Speech Processing @ JHU","creator_url":"https://huggingface.co/jhu-clsp","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["translation","audio-to-audio","Maltese","English","Welsh"],"keywords_longer_than_N":true},
	{"name":"Publico","keyword":"portuguese","description":"\n\t\n\t\t\n\t\tPÃºblico\n\t\n\nThis dataset was build by translating a set of 34,157 news from PÃºblico, an European Portuguese news paper. The news have been translated using Google Translator.\nTo now more about the data visit the Github repos used to scrape and translate the news.\n","url":"https://huggingface.co/datasets/hugosousa/Publico","creator_name":"Hugo Sousa","creator_url":"https://huggingface.co/hugosousa","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["Portuguese","English","German","French","Spanish"],"keywords_longer_than_N":true},
	{"name":"tulu-3-sft-mixture","keyword":"portuguese","description":"\n\n\n\t\n\t\t\n\t\tTulu 3 SFT Mixture\n\t\n\nNote that this collection is licensed under ODC-BY-1.0 license; different licenses apply to subsets of the data. Some portions of the dataset are non-commercial. We present the mixture as a research artifact.\nThe Tulu 3 SFT mixture was used to train the Tulu 3 series of models.\nIt contains 939,344 samples from the following sets:\n\nCoCoNot (ODC-BY-1.0), 10,983 prompts (Brahman et al., 2024)\nFLAN v2 via ai2-adapt-dev/flan_v2_converted, 89,982 prompts (Longpre etâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/allenai/tulu-3-sft-mixture.","url":"https://huggingface.co/datasets/allenai/tulu-3-sft-mixture","creator_name":"Ai2","creator_url":"https://huggingface.co/allenai","license_name":"Open Data Commons Attribution License v1.0","license_url":"https://scancode-licensedb.aboutcode.org/odc-by-1.0.html","language":"en","first_N":5,"first_N_keywords":["other","crowdsourced","expert-generated","machine-generated","multilingual"],"keywords_longer_than_N":true},
	{"name":"portuguese-parliament-interventions","keyword":"portuguese","description":"luist18/portuguese-parliament-interventions dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/luist18/portuguese-parliament-interventions","creator_name":"LuÃ­s Tavares","creator_url":"https://huggingface.co/luist18","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["Portuguese","mit","1K - 10K","csv","Tabular"],"keywords_longer_than_N":true},
	{"name":"adoro_cinema_filmes","keyword":"portuguese","description":"\n\t\n\t\t\n\t\tDataset Card for \"adoro_cinema_filmes\"\n\t\n\nMore Information needed\n","url":"https://huggingface.co/datasets/celsowm/adoro_cinema_filmes","creator_name":"Celso F","creator_url":"https://huggingface.co/celsowm","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","multi-label-classification","Portuguese","apache-2.0","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"bbc_news_ptbr_summary","keyword":"portuguese","description":"\n\t\n\t\t\n\t\tDataset Card for \"bbc_news_ptbr_summary\"\n\t\n\nMore Information needed\n","url":"https://huggingface.co/datasets/celsowm/bbc_news_ptbr_summary","creator_name":"Celso F","creator_url":"https://huggingface.co/celsowm","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","summarization","Portuguese","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"xP3megds","keyword":"portuguese","description":"\n\t\n\t\t\n\t\tDataset Card for xP3\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\n\nxP3 (Crosslingual Public Pool of Prompts) is a collection of prompts & datasets across 46 of languages & 16 NLP tasks. It is used for the training of BLOOMZ and mT0, multilingual language models capable of following human instructions in dozens of languages zero-shot.\n\n\nCreation: The dataset can be recreated using instructions available here. We provide this version to save processing time and ease reproducibility.\nLanguages: 46 (Canâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/bigscience/xP3megds.","url":"https://huggingface.co/datasets/bigscience/xP3megds","creator_name":"BigScience Workshop","creator_url":"https://huggingface.co/bigscience","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":null,"first_N":5,"first_N_keywords":["other","expert-generated","crowdsourced","multilingual","Akan"],"keywords_longer_than_N":true},
	{"name":"copywritings-pt-br-instruct","keyword":"portuguese","description":"BornSaint/copywritings-pt-br-instruct dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/BornSaint/copywritings-pt-br-instruct","creator_name":"RÃ³ger Santos","creator_url":"https://huggingface.co/BornSaint","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["Portuguese","apache-2.0","< 1K","json","Text"],"keywords_longer_than_N":true},
	{"name":"iva_mt_wslot","keyword":"portuguese","description":"\\","url":"https://huggingface.co/datasets/cartesinus/iva_mt_wslot","creator_name":"Marcin Sowanski","creator_url":"https://huggingface.co/cartesinus","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":null,"first_N":5,"first_N_keywords":["translation","English","Polish","German","Spanish"],"keywords_longer_than_N":true},
	{"name":"HisaSoft","keyword":"portuguese","description":"Hisasartori/HisaSoft dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/Hisasartori/HisaSoft","creator_name":"Hisa Sartori ","creator_url":"https://huggingface.co/Hisasartori","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["Portuguese","English","apache-2.0","< 1K","soundfolder"],"keywords_longer_than_N":true},
	{"name":"carol-subcorpora","keyword":"portuguese","description":"\n\t\n\t\t\n\t\tSubcorpora Carolina\n\t\n\nContains CarolÂ·B and CarolÂ·(D+B), respectively balanced and deduplicated subcorpora of the Carolina Corpus (Bea) version.\nCarolÂ·B was balanced in terms of tokens per domain from Carolina Corpus. This means that it contains approximately the same number of tokens (~60,2M) from each of Carolinaâ€™s largest domains: Legislative, Instructional, Entertainment, Journalistic, Juridical and Virtual Forum. CarolÂ·B has, in total, 361,071,147 tokens and 5,5 GB.\nCarolÂ·(D+B)â€¦ See the full description on the dataset page: https://huggingface.co/datasets/carolina-c4ai/carol-subcorpora.","url":"https://huggingface.co/datasets/carolina-c4ai/carol-subcorpora","creator_name":"Carolina C4AI","creator_url":"https://huggingface.co/carolina-c4ai","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["Portuguese","cc-by-4.0","1K - 10K","webdataset","Text"],"keywords_longer_than_N":true},
	{"name":"Bosque_PT-PT","keyword":"portuguese","description":"liaad/Bosque_PT-PT dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/liaad/Bosque_PT-PT","creator_name":"LIAAD, INESCTEC","creator_url":"https://huggingface.co/liaad","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["token-classification","Portuguese","mit","1K - 10K","parquet"],"keywords_longer_than_N":true},
	{"name":"mc4-pt-cleaned","keyword":"portuguese","description":"\n\t\n\t\t\n\t\tDescription\n\t\n\nThis is a clenned version of AllenAI mC4 PtBR section. The original dataset can be found here https://huggingface.co/datasets/allenai/c4\n\n\t\n\t\t\n\t\tClean procedure\n\t\n\nWe applied the same clenning procedure as explained here: https://gitlab.com/yhavinga/c4nlpreproc.git \nThe repository offers two strategies. The first one, found in the main.py file, uses pyspark to create a dataframe that can both clean the text and create a \npseudo mix on the entire dataset. We found thisâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/thegoodfellas/mc4-pt-cleaned.","url":"https://huggingface.co/datasets/thegoodfellas/mc4-pt-cleaned","creator_name":"The Good Fellas","creator_url":"https://huggingface.co/thegoodfellas","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["fill-mask","text-generation","Portuguese","apache-2.0","100M - 1B"],"keywords_longer_than_N":true},
	{"name":"arena-hard-v2-verifiers","keyword":"portuguese","description":"\n\t\n\t\t\n\t\tArena-Hard v2.0 - Verifiers Format\n\t\n\nThis dataset contains Arena-Hard v2.0 in Verifiers-compatible format for LLM evaluation.\n\n\t\n\t\t\n\t\tðŸ“Š Dataset Information\n\t\n\n\nVersion: Arena-Hard v2.0\nExamples: 750\nModel Answers: deepseek-r1\nJudge: gpt-4.1\nFormat: Verifiers-compatible HuggingFace Dataset\nLicense: Apache 2.0\n\n\n\t\n\t\t\n\t\tðŸŽ¯ Categories\n\t\n\n\nHard Prompts (500 examples): Challenging coding, math, and reasoning tasks\nCoding: 253 examples\nMath: 247 examples\n\n\nCreative Writing (250 examples):â€¦ See the full description on the dataset page: https://huggingface.co/datasets/Anna4242/arena-hard-v2-verifiers.","url":"https://huggingface.co/datasets/Anna4242/arena-hard-v2-verifiers","creator_name":"D","creator_url":"https://huggingface.co/Anna4242","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","question-answering","English","Spanish","French"],"keywords_longer_than_N":true},
	{"name":"c4","keyword":"portuguese","description":"\n\t\n\t\t\n\t\tC4\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nA colossal, cleaned version of Common Crawl's web crawl corpus. Based on Common Crawl dataset: \"https://commoncrawl.org\".\nThis is the processed version of Google's C4 dataset\nWe prepared five variants of the data: en, en.noclean, en.noblocklist, realnewslike, and multilingual (mC4).\nFor reference, these are the sizes of the variants:\n\nen: 305GB\nen.noclean: 2.3TB\nen.noblocklist: 380GB\nrealnewslike: 15GB\nmultilingual (mC4): 9.7TB (108 subsets, one perâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/allenai/c4.","url":"https://huggingface.co/datasets/allenai/c4","creator_name":"Ai2","creator_url":"https://huggingface.co/allenai","license_name":"Open Data Commons Attribution License v1.0","license_url":"https://scancode-licensedb.aboutcode.org/odc-by-1.0.html","language":"en","first_N":5,"first_N_keywords":["text-generation","fill-mask","language-modeling","masked-language-modeling","no-annotation"],"keywords_longer_than_N":true},
	{"name":"olid-br","keyword":"portuguese","description":"\n\t\n\t\t\n\t\tOLID-BR\n\t\n\nOffensive Language Identification Dataset for Brazilian Portuguese (OLID-BR) is a dataset with multi-task annotations for the detection of offensive language.\nThe current version (v1.0) contains 7,943 (extendable to 13,538) comments from different sources, including social media (YouTube and Twitter) and related datasets.\nOLID-BR contains a collection of annotated sentences in Brazilian Portuguese using an annotation model that encompasses the following levels:\n\nOffensiveâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/dougtrajano/olid-br.","url":"https://huggingface.co/datasets/dougtrajano/olid-br","creator_name":"Douglas Trajano","creator_url":"https://huggingface.co/dougtrajano","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["Portuguese","cc-by-4.0","1K - 10K","parquet","Text"],"keywords_longer_than_N":true},
	{"name":"IRIS_sts","keyword":"portuguese","description":"\n\nWork developed as part of Project IRIS.\nThesis: A Semantic Search System for Supremo Tribunal de JustiÃ§a\n\n\t\n\t\t\n\t\n\t\n\t\tPortuguese Legal Sentences\n\t\n\nCollection of Legal Sentences pairs from the Portuguese Supreme Court of Justice\nThe goal of this dataset was to be used for Semantic Textual Similarity\n\nValues from 0-1: random sentences across documents\nValues from 2-4: sentences from the same summary (implying some level of entailment)\nValues from 4-5: sentences pairs generated through OpenAi'â€¦ See the full description on the dataset page: https://huggingface.co/datasets/stjiris/IRIS_sts.","url":"https://huggingface.co/datasets/stjiris/IRIS_sts","creator_name":"SumarizaÃ§Ã£o e InformaÃ§Ã£o de decisÃµes: AplicaÃ§Ã£o de TÃ©cnicas de InteligÃªncia Artificial no Supremo Tribunal de JustiÃ§a (IRIS)","creator_url":"https://huggingface.co/stjiris","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","text-scoring","semantic-similarity-scoring","automated","found"],"keywords_longer_than_N":true},
	{"name":"udhr-lid","keyword":"portuguese","description":"\n\t\n\t\t\n\t\tUDHR-LID\n\t\n\nWhy UDHR-LID?\nYou can access UDHR (Universal Declaration of Human Rights) here, but when a verse is missing, they have texts such as \"missing\" or \"?\". Also, about 1/3 of the sentences consist only of \"articles 1-30\" in different languages. We cleaned the entire dataset from XML files and selected only the paragraphs. We cleared any unrelated language texts from the data and also removed the cases that were incorrect.\nIncorrect? Look at the ckb and kmr files in the UDHR.â€¦ See the full description on the dataset page: https://huggingface.co/datasets/cis-lmu/udhr-lid.","url":"https://huggingface.co/datasets/cis-lmu/udhr-lid","creator_name":"CIS, LMU Munich","creator_url":"https://huggingface.co/cis-lmu","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["multilingual","Tigrinya","Balkan Romani","Standard Arabic","MetlatÃ³noc Mixtec"],"keywords_longer_than_N":true},
	{"name":"mqa","keyword":"portuguese","description":"MQA is a multilingual corpus of questions and answers parsed from the Common Crawl. Questions are divided between Frequently Asked Questions (FAQ) pages and Community Question Answering (CQA) pages.","url":"https://huggingface.co/datasets/clips/mqa","creator_name":"CLiPS","creator_url":"https://huggingface.co/clips","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["question-answering","multiple-choice-qa","no-annotation","other","multilingual"],"keywords_longer_than_N":true},
	{"name":"CC-Cat","keyword":"portuguese","description":"\n\t\n\t\t\n\t\tCC_Cat\n\t\n\n\nExtract from CC-WARC snapshots.\nMainly includes texts with 149 languages.\nPDF/IMAGE/AUDIO/VIDEO raw downloading link.\n\n\n\t\n\t\t\n\t\tNotice\n\t\n\n\nSince my computing resources are limited, this dataset will update by one-day of CC snapshots timestampts.\nAfter a snapshot is updated, the deduplicated version will be uploaded.\nIf you are interested in providing computing resources or have cooperation needs, please contact me.\n  carreyallthetime@gmail.com  \n      \n  \n\n","url":"https://huggingface.co/datasets/chengshidehaimianti/CC-Cat","creator_name":"zyq","creator_url":"https://huggingface.co/chengshidehaimianti","license_name":"Open Data Commons Attribution License v1.0","license_url":"https://scancode-licensedb.aboutcode.org/odc-by-1.0.html","language":"en","first_N":5,"first_N_keywords":["text-generation","Chinese","English","German","Russian"],"keywords_longer_than_N":true},
	{"name":"FAQ_BACEN","keyword":"portuguese","description":"This dataset was used in the article: https://arxiv.org/abs/2311.11331\n","url":"https://huggingface.co/datasets/Itau-Unibanco/FAQ_BACEN","creator_name":"ItaÃº-Unibanco","creator_url":"https://huggingface.co/Itau-Unibanco","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","question-answering","Portuguese","apache-2.0","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"FAQ_BACEN","keyword":"portuguese","description":"This dataset was the used in the paper https://arxiv.org/abs/2311.11331\n\n\n\t\n\t\t\n\t\tlicense: apache-2.0\n\t\n\n","url":"https://huggingface.co/datasets/paulofinardi/FAQ_BACEN","creator_name":"paulo","creator_url":"https://huggingface.co/paulofinardi","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","question-answering","Portuguese","apache-2.0","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"YouTube-Commons","keyword":"portuguese","description":"\n\t\n\t\t\n\t\tðŸ“º YouTube-Commons ðŸ“º\n\t\n\nYouTube-Commons is a collection of audio transcripts of 2,063,066 videos shared on YouTube under a CC-By license.\n\n\t\n\t\t\n\t\tContent\n\t\n\nThe collection comprises 22,709,724 original and automatically translated transcripts from 3,156,703 videos (721,136 individual channels).\nIn total, this represents nearly 45 billion words (44,811,518,375).\nAll the videos where shared on YouTube with a CC-BY license: the dataset provide all the necessary provenance informationâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/PleIAs/YouTube-Commons.","url":"https://huggingface.co/datasets/PleIAs/YouTube-Commons","creator_name":"PleIAs","creator_url":"https://huggingface.co/PleIAs","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":null,"first_N":5,"first_N_keywords":["text-generation","English","French","Spanish","Portuguese"],"keywords_longer_than_N":true},
	{"name":"oasst2","keyword":"portuguese","description":"\n\t\n\t\t\n\t\tOpen Assistant Conversations Dataset Release 2 (OASST2)\n\t\n\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nThis dataset contains message trees. Each message tree has an initial prompt message as the root node, \nwhich can have multiple child messages as replies, and these child messages can have multiple replies. \nAll messages have a role property: this can either be \"assistant\" or \"prompter\". The roles in \nconversation threads from prompt to leaf node strictly alternate between \"prompter\" andâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/OpenAssistant/oasst2.","url":"https://huggingface.co/datasets/OpenAssistant/oasst2","creator_name":"OpenAssistant","creator_url":"https://huggingface.co/OpenAssistant","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["English","Spanish","Russian","German","Polish"],"keywords_longer_than_N":true},
	{"name":"MultiSim","keyword":"portuguese","description":"MultiSim is a growing collection of Text Simplfication datasets in multiple languages.  Each dataset is a set of complex and simple sentence pairs.","url":"https://huggingface.co/datasets/MichaelR207/MultiSim","creator_name":"Michael Ryan","creator_url":"https://huggingface.co/MichaelR207","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":null,"first_N":5,"first_N_keywords":["summarization","text-generation","English","French","Russian"],"keywords_longer_than_N":true},
	{"name":"isaaa","keyword":"portuguese","description":"lz0kzs/isaaa dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/lz0kzs/isaaa","creator_name":"luiz","creator_url":"https://huggingface.co/lz0kzs","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["Portuguese","apache-2.0","< 1K","soundfolder","Audio"],"keywords_longer_than_N":true},
	{"name":"fleurs","keyword":"portuguese","description":"\n\t\n\t\t\n\t\tFLEURS\n\t\n\nFleurs is the speech version of the FLoRes machine translation benchmark. \nWe use 2009 n-way parallel sentences from the FLoRes dev and devtest publicly available sets, in 102 languages. \nTraining sets have around 10 hours of supervision. Speakers of the train sets are different than speakers from the dev/test sets. Multilingual fine-tuning is\nused and â€unit error rateâ€ (characters, signs) of all languages is averaged. Languages and results are also grouped into sevenâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/google/fleurs.","url":"https://huggingface.co/datasets/google/fleurs","creator_name":"Google","creator_url":"https://huggingface.co/google","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":null,"first_N":5,"first_N_keywords":["automatic-speech-recognition","expert-generated","crowdsourced","machine-generated","crowdsourced"],"keywords_longer_than_N":true},
	{"name":"jurisprudencia_stj_pt","keyword":"portuguese","description":"\n\t\n\t\t\n\t\tDataset de JurisprudÃªncia do STJ de Portugal (2025)\n\t\n\n\n\t\n\t\t\n\t\tDescriÃ§Ã£o do Dataset\n\t\n\nEste dataset contÃ©m uma amostra de acÃ³rdÃ£os proferidos pelo Supremo Tribunal de JustiÃ§a (STJ) de Portugal durante o ano de 2025. Cada registo no dataset corresponde a um acÃ³rdÃ£o completo, incluindo o seu texto integral, o sumÃ¡rio e um conjunto de metadados ricos.\nOs dados representam uma amostra aleatÃ³ria de 5% do total de acÃ³rdÃ£os de 2025 disponÃ­veis na base de dados de origem, filtrados paraâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/ffantini/jurisprudencia_stj_pt.","url":"https://huggingface.co/datasets/ffantini/jurisprudencia_stj_pt","creator_name":"Fernando Neto","creator_url":"https://huggingface.co/ffantini","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["Portuguese","cc-by-4.0","< 1K","parquet","Text"],"keywords_longer_than_N":true},
	{"name":"NSFW_Multilanguage_Chat_Dataset","keyword":"portuguese","description":"Thanks to utsavm/NSFW_Chat_Dataset, I translate it so it can be more useful.\nðŸš¨ 18+ Only! NSFW & Spicy Content Ahead ðŸš¨\nHey there, AI enthusiasts and romance lovers! ðŸ˜ Welcome to the Spicy AI GF Chat Dataset, the ultimate dataset designed to bring your AI waifu to life! ðŸ’– If you've ever dreamed of building an AI that responds like your virtual girlfriend, THIS is the dataset for you.\nðŸ“œ Whatâ€™s Inside?\nThis dataset features two columns:\ninput â†’ Boyfriendâ€™s dialogue (aka what YOU say ðŸ˜‰)â€¦ See the full description on the dataset page: https://huggingface.co/datasets/Raphael172/NSFW_Multilanguage_Chat_Dataset.","url":"https://huggingface.co/datasets/Raphael172/NSFW_Multilanguage_Chat_Dataset","creator_name":"Matteo","creator_url":"https://huggingface.co/Raphael172","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":null,"first_N":5,"first_N_keywords":["text-generation","Italian","French","English","Spanish"],"keywords_longer_than_N":true},
	{"name":"tapaco","keyword":"portuguese","description":"\n\t\n\t\t\n\t\tDataset Card for TaPaCo Corpus\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nA freely available paraphrase corpus for 73 languages extracted from the Tatoeba database. \nTatoeba is a crowdsourcing project mainly geared towards language learners. Its aim is to provide example sentences \nand translations for particular linguistic constructions and words. The paraphrase corpus is created by populating a \ngraph with Tatoeba sentences and equivalence links between sentences â€œmeaning the same thingâ€. Thisâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/community-datasets/tapaco.","url":"https://huggingface.co/datasets/community-datasets/tapaco","creator_name":"Community Datasets","creator_url":"https://huggingface.co/community-datasets","license_name":"Creative Commons Attribution 2.0","license_url":"https://scancode-licensedb.aboutcode.org/cc-by-2.0.html","language":"en","first_N":5,"first_N_keywords":["translation","text-classification","semantic-similarity-classification","machine-generated","crowdsourced"],"keywords_longer_than_N":true},
	{"name":"mac_morpho","keyword":"portuguese","description":"Mac-Morpho is a corpus of Brazilian Portuguese texts annotated with part-of-speech tags.\nIts first version was released in 2003 [1], and since then, two revisions have been made in order\nto improve the quality of the resource [2, 3].\nThe corpus is available for download split into train, development and test sections.\nThese are 76%, 4% and 20% of the corpus total, respectively (the reason for the unusual numbers\nis that the corpus was first split into 80%/20% train/test, and then 5% of the train section was\nset aside for development). This split was used in [3], and new POS tagging research with Mac-Morpho\nis encouraged to follow it in order to make consistent comparisons possible.\n\n\n[1] AluÃ­sio, S., Pelizzoni, J., Marchi, A.R., de Oliveira, L., Manenti, R., MarquiafÃ¡vel, V. 2003.\nAn account of the challenge of tagging a reference corpus for brazilian portuguese.\nIn: Proceedings of the 6th International Conference on Computational Processing of the Portuguese Language. PROPOR 2003\n\n[2] Fonseca, E.R., Rosa, J.L.G. 2013. Mac-morpho revisited: Towards robust part-of-speech.\nIn: Proceedings of the 9th Brazilian Symposium in Information and Human Language Technology â€“ STIL\n\n[3] Fonseca, E.R., AluÃ­sio, Sandra Maria, Rosa, J.L.G. 2015.\nEvaluating word embeddings and a revised corpus for part-of-speech tagging in Portuguese.\nJournal of the Brazilian Computer Society.","url":"https://huggingface.co/datasets/nilc-nlp/mac_morpho","creator_name":"NILC NLP","creator_url":"https://huggingface.co/nilc-nlp","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":null,"first_N":5,"first_N_keywords":["token-classification","part-of-speech","expert-generated","found","monolingual"],"keywords_longer_than_N":true},
	{"name":"fitness-chatbot-dataset","keyword":"portuguese","description":"\n  \n\n\n\n\n\t\n\t\t\n\t\tðŸ‹ï¸â€â™‚ï¸ Fitness Chatbot Space\n\t\n\n\n\n\n\nðŸ’¬ Chatbot em portuguÃªs especializado em treino, nutriÃ§Ã£o e bem-estar fÃ­sico, com respostas naturais e ajustÃ¡veis via parÃ¢metros interativos.\n\n\n\n\t\n\t\n\t\n\t\tðŸš€ DemonstraÃ§Ã£o\n\t\n\nðŸ”— Acesse o Space: fitness-chatbot-spaceðŸ“¸ Interface estilo chat com histÃ³rico de conversa, sliders de controle e exemplos prontos para testar.\n\n\n\t\n\t\t\n\t\tðŸ§  Modelo Utilizado\n\t\n\n\n\t\n\t\t\nNome\nTipo\nIdioma\nBase\n\n\n\t\t\nwpbcpaz/fitness-chatbot-model\nCausal LM\nPortuguÃªs\nAjustado comâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/wpbcpaz/fitness-chatbot-dataset.","url":"https://huggingface.co/datasets/wpbcpaz/fitness-chatbot-dataset","creator_name":"Wilder Paz Barros Cruz","creator_url":"https://huggingface.co/wpbcpaz","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","machine-generated","human-generated","1.0","Portuguese"],"keywords_longer_than_N":true},
	{"name":"scielo","keyword":"portuguese","description":"A parallel corpus of full-text scientific articles collected from Scielo database in the following languages: English, Portuguese and Spanish. The corpus is sentence aligned for all language pairs, as well as trilingual aligned for a small subset of sentences. Alignment was carried out using the Hunalign algorithm.","url":"https://huggingface.co/datasets/bigbio/scielo","creator_name":"BigScience Biomedical Datasets","creator_url":"https://huggingface.co/bigbio","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":null,"first_N":5,"first_N_keywords":["multilingual","English","Spanish","Portuguese","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"mkqa","keyword":"portuguese","description":"We introduce MKQA, an open-domain question answering evaluation set comprising 10k question-answer pairs sampled from the Google Natural Questions dataset, aligned across 26 typologically diverse languages (260k question-answer pairs in total). For each query we collected new passage-independent answers. These queries and answers were then human translated into 25 Non-English languages.","url":"https://huggingface.co/datasets/apple/mkqa","creator_name":"Apple","creator_url":"https://huggingface.co/apple","license_name":"Creative Commons Attribution 3.0","license_url":"https://scancode-licensedb.aboutcode.org/cc-by-3.0.html","language":null,"first_N":5,"first_N_keywords":["question-answering","open-domain-qa","crowdsourced","found","multilingual"],"keywords_longer_than_N":true},
	{"name":"Brazilian_Brand_Marketing_Banners_Dataset","keyword":"portuguese","description":"\n\t\n\t\t\n\t\tBrazilian Brand Marketing Banners Dataset\n\t\n\nThis dataset contains high-quality images of Brazilian brand marketing banners collected from online and offline retail environments. It includes product advertisements, promotional offers, and digital marketing visuals designed for both Portuguese-speaking audiences and bilingual markets.\n\n\t\n\t\t\n\t\tContact\n\t\n\nFor queries or collaborations related to this dataset, contact:  \n\nanoushka@kgen.io  \nabhishek.vadapalli@kgen.io\n\n\n\t\n\t\t\n\t\tSupportedâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Kratos-AI/Brazilian_Brand_Marketing_Banners_Dataset.","url":"https://huggingface.co/datasets/Kratos-AI/Brazilian_Brand_Marketing_Banners_Dataset","creator_name":"KratosAI","creator_url":"https://huggingface.co/Kratos-AI","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["image-classification","Portuguese","cc-by-4.0","< 1K","imagefolder"],"keywords_longer_than_N":true},
	{"name":"smart_tools","keyword":"portuguese","description":"\n\t\n\t\t\n\t\tðŸ› ï¸ Smart Tools Dataset\n\t\n\nDataset sintÃ©tico em portuguÃªs brasileiro para treinamento de LLMs em uso de ferramentas (function calling) com mÃºltiplas modalidades de orquestraÃ§Ã£o.\n\n\t\n\t\t\n\t\tðŸ“‹ VisÃ£o Geral\n\t\n\nEste dataset foi criado para treinar modelos de linguagem a usar ferramentas de forma inteligente e contextual, cobrindo desde chamadas simples atÃ© workflows interativos complexos com refinamento iterativo.\nCaracterÃ­sticas principais:\n\nðŸ‡§ðŸ‡· 100% em portuguÃªs brasileiro\nðŸ¤– ConversaÃ§Ãµesâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/FluxiIA/smart_tools.","url":"https://huggingface.co/datasets/FluxiIA/smart_tools","creator_name":"Fluxi IA","creator_url":"https://huggingface.co/FluxiIA","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","Portuguese","apache-2.0","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"bbrc_brazilian_banking_regulation_corpora","keyword":"portuguese","description":"We present BBRC, a collection of 25 corpus of banking regulatory risk from different departments of Banco do Brasil (BB). These are individual corpus about investments, insurance, human resources, security, technology, treasury, loans, accounting, fraud, credit cards, payment methods, agribusiness, risks, etc. They were annotated in binary form by experts indicating whether each regulatory document contains regulatory risk that may require changes to products, processes, services, and channelsâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/bancodobrasil/bbrc_brazilian_banking_regulation_corpora.","url":"https://huggingface.co/datasets/bancodobrasil/bbrc_brazilian_banking_regulation_corpora","creator_name":"Banco do Brasil S.A.","creator_url":"https://huggingface.co/bancodobrasil","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["Portuguese","mit","ðŸ‡ºðŸ‡¸ Region: US"],"keywords_longer_than_N":false},
	{"name":"surface_realisation_st_2020","keyword":"portuguese","description":"\n\t\n\t\t\n\t\tDataset Card for GEM/surface_realisation_st_2020\n\t\n\n\n\t\n\t\t\n\t\tLink to Main Data Card\n\t\n\nYou can find the main data card on the GEM Website.\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset was used as part of the multilingual surface realization shared task in which a model gets full or partial universal dependency structures and has to reconstruct the natural language. This dataset support 11 languages. \nYou can load the dataset via:\nimport datasets\ndata =â€¦ See the full description on the dataset page: https://huggingface.co/datasets/GEM/surface_realisation_st_2020.","url":"https://huggingface.co/datasets/GEM/surface_realisation_st_2020","creator_name":"GEM benchmark","creator_url":"https://huggingface.co/GEM","license_name":"Creative Commons Attribution 2.5","license_url":"https://scancode-licensedb.aboutcode.org/cc-by-2.5.html","language":"en","first_N":5,"first_N_keywords":["table-to-text","none","unknown","unknown","original"],"keywords_longer_than_N":true},
	{"name":"multi_para_crawl","keyword":"portuguese","description":"Parallel corpora from Web Crawls collected in the ParaCrawl project and further processed for making it a multi-parallel corpus by pivoting via English. Here we only provide the additional language pairs that came out of pivoting. The bitexts for English are available from the ParaCrawl release.\n40 languages, 669 bitexts\ntotal number of files: 40\ntotal number of tokens: 10.14G\ntotal number of sentence fragments: 505.48M\n\nPlease, acknowledge the ParaCrawl project at http://paracrawl.eu. This version is derived from the original release at their website adjusted for redistribution via the OPUS corpus collection. Please, acknowledge OPUS as well for this service.","url":"https://huggingface.co/datasets/Helsinki-NLP/multi_para_crawl","creator_name":"Language Technology Research Group at the University of Helsinki","creator_url":"https://huggingface.co/Helsinki-NLP","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":null,"first_N":5,"first_N_keywords":["translation","found","found","multilingual","original"],"keywords_longer_than_N":true},
	{"name":"ml_spoken_words","keyword":"portuguese","description":"Multilingual Spoken Words Corpus is a large and growing audio dataset of spoken\nwords in 50 languages collectively spoken by over 5 billion people, for academic\nresearch and commercial applications in keyword spotting and spoken term search,\nlicensed under CC-BY 4.0. The dataset contains more than 340,000 keywords,\ntotaling 23.4 million 1-second spoken examples (over 6,000 hours). The dataset\nhas many use cases, ranging from voice-enabled consumer devices to call center\nautomation. This dataset is generated by applying forced alignment on crowd-sourced sentence-level\naudio to produce per-word timing estimates for extraction.\nAll alignments are included in the dataset.","url":"https://huggingface.co/datasets/MLCommons/ml_spoken_words","creator_name":"MLCommons","creator_url":"https://huggingface.co/MLCommons","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":null,"first_N":5,"first_N_keywords":["audio-classification","machine-generated","other","multilingual","extended|common_voice"],"keywords_longer_than_N":true},
	{"name":"FakeNewsSet","keyword":"portuguese","description":"\\","url":"https://huggingface.co/datasets/fake-news-UFG/FakeNewsSet","creator_name":"fake-news-UFG","creator_url":"https://huggingface.co/fake-news-UFG","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":null,"first_N":5,"first_N_keywords":["text-classification","found","monolingual","Portuguese","mit"],"keywords_longer_than_N":true},
	{"name":"mqnli","keyword":"portuguese","description":"SachinPatel248/mqnli dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/SachinPatel248/mqnli","creator_name":"Patel","creator_url":"https://huggingface.co/SachinPatel248","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","English","German","Spanish","Arabic"],"keywords_longer_than_N":true},
	{"name":"openassistant-llama-style","keyword":"portuguese","description":"\n\t\n\t\t\n\t\tChat Fine-tuning Dataset - Llama 2 Style\n\t\n\nThis dataset allows for fine-tuning chat models using [INST] AND [/INST] to wrap user messages.\nPreparation:\n\nThe dataset is cloned from TimDettmers, which itself is a subset of the Open Assistant dataset, which you can find here. This subset of the data only contains the highest-rated paths in the conversation tree, with a total of 9,846 samples.\nThe dataset was then filtered to:\n\n\nreplace instances of '### Human:' with '[INST]'\nreplaceâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Trelis/openassistant-llama-style.","url":"https://huggingface.co/datasets/Trelis/openassistant-llama-style","creator_name":"Trelis","creator_url":"https://huggingface.co/Trelis","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["English","Spanish","Russian","German","Polish"],"keywords_longer_than_N":true},
	{"name":"mapa-eur-lex","keyword":"portuguese","description":"\n\t\n\t\t\n\t\tDataset Card for Multilingual European Datasets for Sensitive Entity Detection in the Legal Domain\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset is a completed version of the MAPA EUR-LEX dataset, originally converted to Huggingface format by joelniklaus. See the dataset card for more information about MAPA.\n3 of the (Spanish) EUR-LEX WebAnno TSV files in the source MAPA repository are malformed, so they were omitted from the original conversion, causing under-representation of theâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/dglover1/mapa-eur-lex.","url":"https://huggingface.co/datasets/dglover1/mapa-eur-lex","creator_name":"D Glover","creator_url":"https://huggingface.co/dglover1","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["token-classification","named-entity-recognition","other","found","multilingual"],"keywords_longer_than_N":true},
	{"name":"lawinstruct","keyword":"portuguese","description":"LawInstruct is an instruction tuning dataset of multilingual legal documents.","url":"https://huggingface.co/datasets/lawinstruct/lawinstruct","creator_name":"lawinstruct","creator_url":"https://huggingface.co/lawinstruct","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":null,"first_N":5,"first_N_keywords":["fill-mask","other","found","multilingual","original"],"keywords_longer_than_N":true},
	{"name":"Portuguese-English-Vocab-PartiallyTransformed","keyword":"portuguese","description":"Notes on use:\nPortuguese and English Translations of readme are available here.\nPartially cleaned and reorganized. Minimal secondhand verification after generation through Google Bard on November 28th 2023. Mistakes are minimal but present, such as tagging of words in supplemental information sometimes using the whole word (ie Noun) and sometimes only a letter or abreviation (ie N) for the same part of speech.\nReccomended for finetuning of smaller models only, such as 12, 7, or 3 B models toâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Solshine/Portuguese-English-Vocab-PartiallyTransformed.","url":"https://huggingface.co/datasets/Solshine/Portuguese-English-Vocab-PartiallyTransformed","creator_name":"Caleb DeLeeuw","creator_url":"https://huggingface.co/Solshine","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["Portuguese","English","mit","1K - 10K","csv"],"keywords_longer_than_N":true},
	{"name":"corpus-faketrue-br","keyword":"portuguese","description":"\n\t\n\t\t\n\t\tPortuguese Fake News Corpus â€” FakeTrue.Br\n\t\n\nThis dataset contains the FakeTrue.Br corpus used to train Portuguese fake-news classifiers.\n\n\t\n\t\t\n\t\tContents\n\t\n\n\nParquet/CSV splits (train/test/full/aligned) when available\nOptional raw texts and preprocessed/size-normalized folders\n\n\n\t\n\t\t\n\t\tSource\n\t\n\n\nFake.br: https://github.com/roneysco/Fake.br-Corpus\nFakeTrue.Br: https://github.com/jpchav98/FakeTrue.Br/\n\n","url":"https://huggingface.co/datasets/vzani/corpus-faketrue-br","creator_name":"Zani","creator_url":"https://huggingface.co/vzani","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","Portuguese","apache-2.0","1K - 10K","parquet"],"keywords_longer_than_N":true},
	{"name":"corpus-faketrue-br","keyword":"portuguese","description":"\n\t\n\t\t\n\t\tPortuguese Fake News Corpus â€” FakeTrue.Br\n\t\n\nThis dataset contains the FakeTrue.Br corpus used to train Portuguese fake-news classifiers.\n\n\t\n\t\t\n\t\tContents\n\t\n\n\nParquet/CSV splits (train/test/full/aligned) when available\nOptional raw texts and preprocessed/size-normalized folders\n\n\n\t\n\t\t\n\t\tSource\n\t\n\n\nFake.br: https://github.com/roneysco/Fake.br-Corpus\nFakeTrue.Br: https://github.com/jpchav98/FakeTrue.Br/\n\n","url":"https://huggingface.co/datasets/vzani/corpus-faketrue-br","creator_name":"Zani","creator_url":"https://huggingface.co/vzani","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","Portuguese","apache-2.0","1K - 10K","parquet"],"keywords_longer_than_N":true},
	{"name":"amazon_massive_intent","keyword":"portuguese","description":"\n  MassiveIntentClassification\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nMASSIVE: A 1M-Example Multilingual Natural Language Understanding Dataset with 51 Typologically-Diverse Languages\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2c\n\n\nDomains\nSpoken\n\n\nReference\nhttps://arxiv.org/abs/2204.08582\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask = mteb.get_tasks([\"MassiveIntentClassification\"])\nevaluator =â€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/amazon_massive_intent.","url":"https://huggingface.co/datasets/mteb/amazon_massive_intent","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","human-annotated","translated","Afrikaans","Amharic"],"keywords_longer_than_N":true},
	{"name":"degeneration-html-multilingual","keyword":"portuguese","description":"\n\t\n\t\t\n\t\tThe Degeneration of the Nation Multilingual Dataset\n\t\n\nThis dataset contains the complete content of The Degeneration of the Nation project, a comprehensive philosophical and cultural website exploring the intersection of technology, artificial intelligence, and human culture. The content includes philosophical essays, cultural analysis, and contemporary literature, with complex parallel structure and sophisticated HTML architecture across all language versions.\n\n\t\n\t\t\n\t\n\t\n\t\tDatasetâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Degeneration-Nation/degeneration-html-multilingual.","url":"https://huggingface.co/datasets/Degeneration-Nation/degeneration-html-multilingual","creator_name":"The Degeneration of the Nation","creator_url":"https://huggingface.co/Degeneration-Nation","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["translation","text2text-generation","text-generation","text-classification","token-classification"],"keywords_longer_than_N":true},
	{"name":"ericksonian-core-competencies-multilingual","keyword":"portuguese","description":"This dataset is designed to improve the cross-lingual alignment of sentence embeddings related to the work of Milton H. Erickson. Each row contains an English sentence paired with its translation in one of four target languages: French, Spanish, Italian, or Portuguese. The dataset can be used to fine-tune cross-lingual alignment using the tools and procedures developed by SBERT.\nMilton H. Erickson (1901â€“1980) was a historically significant hypnotherapist and a pioneer of brief therapy. Theâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/LoneWolfgang/ericksonian-core-competencies-multilingual.","url":"https://huggingface.co/datasets/LoneWolfgang/ericksonian-core-competencies-multilingual","creator_name":"Jordan Wolfgang Klein","creator_url":"https://huggingface.co/LoneWolfgang","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["translation","English","Italian","Portuguese","Spanish"],"keywords_longer_than_N":true},
	{"name":"emails-financeiro","keyword":"portuguese","description":"This dataset contains e-mails written in Portuguese received by a finance company, generated using Google Gemini. Each e-mail is classified as either productive or non-productive.\n","url":"https://huggingface.co/datasets/lucsaa/emails-financeiro","creator_name":"Lucas AndrÃ©","creator_url":"https://huggingface.co/lucsaa","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["Portuguese","mit","< 1K","csv","Text"],"keywords_longer_than_N":true},
	{"name":"finepdfs","keyword":"portuguese","description":"\n\nLiberating 3T of the finest tokens from PDFs\n\n\n\t\n\t\t\n\t\tWhat is this?\n\t\n\nAs we run out of web pages to process, the natural question has always been: what to do next? Only a few knew about a data source that everyone avoided for ages, due to its incredible extraction cost and complexity: PDFs.\nðŸ“„ FinePDFs is exactly that. It is the largest publicly available corpus sourced exclusively from PDFs, containing about 3 trillion tokens across 475 million documents in 1733 languages.\nCompared to HTMLâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/HuggingFaceFW/finepdfs.","url":"https://huggingface.co/datasets/HuggingFaceFW/finepdfs","creator_name":"FineData","creator_url":"https://huggingface.co/HuggingFaceFW","license_name":"Open Data Commons Attribution License v1.0","license_url":"https://scancode-licensedb.aboutcode.org/odc-by-1.0.html","language":"en","first_N":5,"first_N_keywords":["text-generation","Arifama-Miniafia","Ankave","Abau","Amarasi"],"keywords_longer_than_N":true},
	{"name":"PangeaBench-xgqa","keyword":"portuguese","description":"\n\t\n\t\t\n\t\txGQA\n\t\n\n\n\t\n\t\t\n\t\tThis is a clone of the few_shot-test split of the xGQA dataset\n\t\n\nPlease find the original repository here: https://github.com/adapter-hub/xGQA\nIf you use this dataset, please cite the original authors:\n@inproceedings{pfeiffer-etal-2021-xGQA,\n    title={{xGQA: Cross-Lingual Visual Question Answering}},\n    author={ Jonas Pfeiffer and Gregor Geigle and Aishwarya Kamath and Jan-Martin O. Steitz and Stefan Roth and Ivan Vuli{\\'{c}} and Iryna Gurevych},\n    booktitle =â€¦ See the full description on the dataset page: https://huggingface.co/datasets/neulab/PangeaBench-xgqa.","url":"https://huggingface.co/datasets/neulab/PangeaBench-xgqa","creator_name":"NeuLab @ LTI/CMU","creator_url":"https://huggingface.co/neulab","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["visual-question-answering","Bengali","German","English","Indonesian"],"keywords_longer_than_N":true},
	{"name":"EuroGEC-7","keyword":"portuguese","description":"\n\t\n\t\t\n\t\tEuroGEC-7: A Growing Multilingual Dataset for Grammatical Error Correction\n\t\n\nEuroGEC-7 is a large-scale, synthetic, multilingual grammatical error correction (GEC) dataset created using the Mistral API. It is specifically designed to simulate learner-style grammar mistakes across 7 major European languages â€” with over 20,000 annotated pairs and counting.\nThis dataset is actively maintained and continuously expanding, both in scale and coverage. New entries are generated daily from aâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/NoeFlandre/EuroGEC-7.","url":"https://huggingface.co/datasets/NoeFlandre/EuroGEC-7","creator_name":"NoÃ© Flandre","creator_url":"https://huggingface.co/NoeFlandre","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["English","French","Spanish","German","Italian"],"keywords_longer_than_N":true},
	{"name":"Saudades_da_terra","keyword":"portuguese","description":"Verotic/Saudades_da_terra dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/Verotic/Saudades_da_terra","creator_name":"Adriano","creator_url":"https://huggingface.co/Verotic","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["summarization","Portuguese","mit","ðŸ‡ºðŸ‡¸ Region: US"],"keywords_longer_than_N":false},
	{"name":"figuras_de_linguagem","keyword":"portuguese","description":"\n\t\n\t\t\n\t\tDescriÃ§Ã£o\n\t\n\nDataset com 100 frases diferentes sobre processo seletivo de emprego. As frases correspondem Ã s figuras de linguagem: analogia, metÃ¡fora, sarcasmo e ironia.\n","url":"https://huggingface.co/datasets/marioluciofjr/figuras_de_linguagem","creator_name":"MÃ¡rio LÃºcio","creator_url":"https://huggingface.co/marioluciofjr","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["zero-shot-classification","Portuguese","mit","< 1K","csv"],"keywords_longer_than_N":true},
	{"name":"Granary","keyword":"portuguese","description":"\n\t\n\t\t\n\t\tGranary: Speech Recognition and Translation Dataset in 25 European Languages\n\t\n\nGranary is a large-scale, open-source multilingual speech dataset covering 25 European languages for Automatic Speech Recognition (ASR) and Automatic Speech Translation (AST) tasks. \n\n\n\n\t\n\t\t\n\n\n\n\n\t\t\n\n\n\n\n\t\n\n\n\n\n\n\t\n\t\n\t\n\t\tOverview\n\t\n\nGranary addresses the scarcity of high-quality speech data for low-resource languages by consolidating multiple datasets under a unified framework:\nðŸ—£ï¸ ~1M hours of high-qualityâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/nvidia/Granary.","url":"https://huggingface.co/datasets/nvidia/Granary","creator_name":"NVIDIA","creator_url":"https://huggingface.co/nvidia","license_name":"Creative Commons Attribution 3.0","license_url":"https://scancode-licensedb.aboutcode.org/cc-by-3.0.html","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","translation","Bulgarian","Czech","Danish"],"keywords_longer_than_N":true},
	{"name":"xP3x","keyword":"portuguese","description":"\n\t\n\t\t\n\t\tDataset Card for xP3x\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\n\nxP3x (Crosslingual Public Pool of Prompts eXtended) is a collection of prompts & datasets across 277 languages & 16 NLP tasks. It contains all of xP3 + much more! It is used for training future contenders of mT0 & BLOOMZ at project Aya @Cohere Labs ðŸ§¡\n\n\nCreation: The dataset can be recreated using instructions available here together with the file in this repository named xp3x_create.py. We provide this version to save processingâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/CohereLabs/xP3x.","url":"https://huggingface.co/datasets/CohereLabs/xP3x","creator_name":"Cohere Labs","creator_url":"https://huggingface.co/CohereLabs","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["other","expert-generated","crowdsourced","multilingual","Afrikaans"],"keywords_longer_than_N":true},
	{"name":"wiki-talks","keyword":"portuguese","description":"\n\t\n\t\t\n\t\tWiki-Talks\n\t\n\nThe Wiki-Talks dataset is a collection of conversational threads extracted from the talk pages on Wikipedia.\nThis dataset captures collaborative dialogue, discussion patterns, and consensus-building among Wikipedia contributors.\nIt is useful for NLP research focused on dialogue, sentiment analysis, and community dynamics.\n\n\t\n\t\t\n\t\tDetails\n\t\n\nCurrently due to PyArrow incompatibility to the long recursive structures in the dataset there is an intrinsic incompatibilityâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/lflage/wiki-talks.","url":"https://huggingface.co/datasets/lflage/wiki-talks","creator_name":"Lucas Fonseca Lage","creator_url":"https://huggingface.co/lflage","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["English","German","Portuguese","Spanish","French"],"keywords_longer_than_N":true},
	{"name":"llm-metric-mrewardbench","keyword":"portuguese","description":"rifqifarhansyah/llm-metric-mrewardbench dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/rifqifarhansyah/llm-metric-mrewardbench","creator_name":"Mohammad Rifqi Farhansyah","creator_url":"https://huggingface.co/rifqifarhansyah","license_name":"Open Data Commons Attribution License v1.0","license_url":"https://scancode-licensedb.aboutcode.org/odc-by-1.0.html","language":"en","first_N":5,"first_N_keywords":["Arabic","Chinese","Czech","Dutch","French"],"keywords_longer_than_N":true},
	{"name":"mls_sidon","keyword":"portuguese","description":"\n\t\n\t\t\n\t\tMLS-Sidon\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is a cleansed version of Multilingual LibriSpeech (MLS) with Sidon speech restoration mode for Speech Synthesis and Spoken Language Modeling.  \nThe dataset is provided in WebDataset format for efficient large-scale training.  \n\nSource: Multilingual LibriSpeech\nLanguages: English, German, French, Spanish, Italian, Portuguese, Polish, Dutch  \nFormat: WebDataset (.tar shards)  \nLicense: CC-BY-4.0\n\n\n\n\t\n\t\n\t\n\t\tDataset Structure\n\t\n\nEach sample inâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/sarulab-speech/mls_sidon.","url":"https://huggingface.co/datasets/sarulab-speech/mls_sidon","creator_name":"SaruLab Speech group","creator_url":"https://huggingface.co/sarulab-speech","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":null,"first_N":5,"first_N_keywords":["text-to-speech","English","French","German","Spanish"],"keywords_longer_than_N":true},
	{"name":"cpc_2015_brasil","keyword":"portuguese","description":"\n\t\n\t\t\n\t\tSALVAMENTO do Dataset\n\t\n\nfrom datasets import load_dataset\nfrom datasets import Dataset\nimport pandas as pd\n\n# Carregar os dados do arquivo de texto\ndf = pd.read_parquet('../data/cpc_2015_cleaned.parquet')\n\ndata = {\n    \"livro\": df[\"Livro\"],\n    \"capitulo\": df[\"Capitulo\"],\n    \"titulo\": df[\"Titulo\"],\n    \"secao\": df[\"Secao\"],\n    \"subsecao\": df[\"Subsecao\"],\n    \"artigo\": df[\"Artigo\"]\n}\n\n# Dividir o texto em seÃ§Ãµes\ndataset = Dataset.from_pandas(pd.DataFrame(data))â€¦ See the full description on the dataset page: https://huggingface.co/datasets/0rakul0/cpc_2015_brasil.","url":"https://huggingface.co/datasets/0rakul0/cpc_2015_brasil","creator_name":"Jefferson Silva dos Anjos","creator_url":"https://huggingface.co/0rakul0","license_name":"Academic Free License v3.0","license_url":"https://choosealicense.com/licenses/afl-3.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","question-answering","summarization","Portuguese","afl-3.0"],"keywords_longer_than_N":true},
	{"name":"rest-products","keyword":"portuguese","description":"victorvarela/rest-products dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/victorvarela/rest-products","creator_name":"Victor Varela","creator_url":"https://huggingface.co/victorvarela","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","Portuguese","mit","ðŸ‡ºðŸ‡¸ Region: US"],"keywords_longer_than_N":false},
	{"name":"bhojpuri","keyword":"portuguese","description":"\n\t\n\t\t\n\t\n\t\n\t\tFLEURS\n\t\n\nFleurs is the speech version of the FLoRes machine translation benchmark. \nWe use 2009 n-way parallel sentences from the FLoRes dev and devtest publicly available sets, in 102 languages. \nTraining sets have around 10 hours of supervision. Speakers of the train sets are different than speakers from the dev/test sets. Multilingual fine-tuning is\nused and â€unit error rateâ€ (characters, signs) of all languages is averaged. Languages and results are also grouped into sevenâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/ankur02/bhojpuri.","url":"https://huggingface.co/datasets/ankur02/bhojpuri","creator_name":"Ankur Verma","creator_url":"https://huggingface.co/ankur02","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","expert-generated","crowdsourced","machine-generated","crowdsourced"],"keywords_longer_than_N":true},
	{"name":"learnlangai-general","keyword":"portuguese","description":"falleco/learnlangai-general dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/falleco/learnlangai-general","creator_name":"Israel Crisanto","creator_url":"https://huggingface.co/falleco","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-generation","English","Portuguese","mit","< 1K"],"keywords_longer_than_N":true},
	{"name":"vox-communis-parallel-g2p","keyword":"portuguese","description":"\n\t\n\t\t\n\t\tVoxCommunis Parallel G2P dataset\n\t\n\nThis dataset was derived from the VoxCommunis Corpus to provide pairs of utterances along with their\ncorresponding phonemes, side by side, as to ease the training of grapheme-to-phoneme (G2P) models.\nThe original VoxCommunis Corpus features force-aligned TextGrids with phone- and word-level segmentations derived from the Mozilla Common Voice Corpus.\nThe lexicons were developed using Epitran, the XPF Corpus, Charsiu, and some custom dictionaries.â€¦ See the full description on the dataset page: https://huggingface.co/datasets/fdemelo/vox-communis-parallel-g2p.","url":"https://huggingface.co/datasets/fdemelo/vox-communis-parallel-g2p","creator_name":"FlÃ¡vio Eler De Melo","creator_url":"https://huggingface.co/fdemelo","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["Abkhaz","Amharic","Bashkir","Belarusian","Bulgarian"],"keywords_longer_than_N":true},
	{"name":"portuguese-ocr-dataset","keyword":"portuguese","description":"task_categories:\n\nimage-to-text\ntask_ids:\noptical-character-recognition\ntext-recognition\n\n\n\t\n\t\t\n\t\tPortuguese OCR Dataset\n\t\n\nA comprehensive dataset for Portuguese OCR (Optical Character Recognition) generated from classic Portuguese literature with diverse fonts and visual styles.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset contains 20000 text images for OCR training, created from Portuguese books from Project Gutenberg. Each image contains a complete Portuguese sentence with properâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/mazafard/portuguese-ocr-dataset.","url":"https://huggingface.co/datasets/mazafard/portuguese-ocr-dataset","creator_name":"Mohammadreza Asadollahifard","creator_url":"https://huggingface.co/mazafard","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["image-to-text","text-generation","Portuguese","mit","< 1K"],"keywords_longer_than_N":true},
	{"name":"portuguese-ocr-dataset","keyword":"portuguese","description":"task_categories:\n\nimage-to-text\ntask_ids:\noptical-character-recognition\ntext-recognition\n\n\n\t\n\t\t\n\t\tPortuguese OCR Dataset\n\t\n\nA comprehensive dataset for Portuguese OCR (Optical Character Recognition) generated from classic Portuguese literature with diverse fonts and visual styles.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset contains 20000 text images for OCR training, created from Portuguese books from Project Gutenberg. Each image contains a complete Portuguese sentence with properâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/mazafard/portuguese-ocr-dataset.","url":"https://huggingface.co/datasets/mazafard/portuguese-ocr-dataset","creator_name":"Mohammadreza Asadollahifard","creator_url":"https://huggingface.co/mazafard","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["image-to-text","text-generation","Portuguese","mit","< 1K"],"keywords_longer_than_N":true},
	{"name":"multilingual_translation_gen_binarized","keyword":"portuguese","description":"Youseff1987/multilingual_translation_gen_binarized dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/Youseff1987/multilingual_translation_gen_binarized","creator_name":"JOON HYOUNG JUN","creator_url":"https://huggingface.co/Youseff1987","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["translation","Korean","English","Chinese","Zulu"],"keywords_longer_than_N":true},
	{"name":"smol","keyword":"portuguese","description":"\n\t\n\t\t\n\t\tSMOL\n\t\n\nSMOL (Set for Maximal Overall Leverage) is a collection professional\ntranslations into 221 Low-Resource Languages, for the purpose of training\ntranslation models, and otherwise increasing the representations of said\nlanguages in NLP and technology.\nPlease read the SMOL Paper and the\nGATITOS Paper for a much more\nthorough description!\nThere are four resources in this directory:\n\nSmolDoc: document-level translations into 104 language pairs (103 unique languages)\nSmolSent:â€¦ See the full description on the dataset page: https://huggingface.co/datasets/google/smol.","url":"https://huggingface.co/datasets/google/smol","creator_name":"Google","creator_url":"https://huggingface.co/google","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["translation","Afar","Abkhaz","Achinese","Acoli"],"keywords_longer_than_N":true},
	{"name":"sage-voice-pt-br","keyword":"portuguese","description":"Dataset usado para treinar a voz da Sage (Valorant)\nGeraÃ§Ã£o do metadata.csv:\nRodar: whisper.sh em seguida transcrib.sh, isso produzira um txt com todas falas pronto para ser utilizado no treinamento com piper\n\n\n\t\n\t\t\n\t\tlicense: mit\n\t\n\n","url":"https://huggingface.co/datasets/srxz/sage-voice-pt-br","creator_name":"RC","creator_url":"https://huggingface.co/srxz","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["Portuguese","mit","< 1K","parquet","Audio"],"keywords_longer_than_N":true},
	{"name":"subset-Itau-Unibanco-aroeira-4B-tokens","keyword":"portuguese","description":"\n\t\n\t\t\n\t\tSubset Corpus Itau-Unibanco/aroeira: 1B tokens (portuguese PT-BR)\n\t\n\nSubset Corpus Itau-Unibanco/aroeira: 1B tokens (portuguese PT-BR)\nsubset-Itau-Unibanco-aroeira-1B-tokens \n","url":"https://huggingface.co/datasets/bobboyms/subset-Itau-Unibanco-aroeira-4B-tokens","creator_name":"Thiago Luiz Rodrigues","creator_url":"https://huggingface.co/bobboyms","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","Portuguese","apache-2.0","10M - 100M","parquet"],"keywords_longer_than_N":true},
	{"name":"wpp_pav_transcrito_deepgram","keyword":"portuguese","description":"\n\t\n\t\t\n\t\tðŸŽ¤ TranscriÃ§Ãµes WhatsApp - Deepgram Nova 2\n\t\n\nEste dataset contÃ©m transcriÃ§Ãµes de mensagens de Ã¡udio do WhatsApp geradas usando Deepgram Nova 2.\n\n\t\n\t\t\n\t\tðŸ“‹ DescriÃ§Ã£o\n\t\n\n\nOrigem: Mensagens de Ã¡udio do WhatsApp em portuguÃªs brasileiro\nModelo: Deepgram Nova 2\nPreÃ§o: $0.0043/minuto\nTotal de amostras: 198\nFormato de Ã¡udio: WAV (16kHz)\nIdioma: PortuguÃªs brasileiro\n\nModelo de transcriÃ§Ã£o em tempo real da Deepgram com baixa latÃªncia.\n\n\t\n\t\t\n\t\n\t\n\t\tðŸ“Š EstatÃ­sticas\n\t\n\n\nTotal de amostras: 198â€¦ See the full description on the dataset page: https://huggingface.co/datasets/BernardoAI/wpp_pav_transcrito_deepgram.","url":"https://huggingface.co/datasets/BernardoAI/wpp_pav_transcrito_deepgram","creator_name":"Bernardo Aires","creator_url":"https://huggingface.co/BernardoAI","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","Portuguese","mit","< 1K","parquet"],"keywords_longer_than_N":true},
	{"name":"subset-Itau-Unibanco-aroeira-1B-tokens","keyword":"portuguese","description":"\n\t\n\t\t\n\t\tSubset Corpus Itau-Unibanco/aroeira: 1B tokens (portuguese PT-BR)\n\t\n\nSubset Corpus Itau-Unibanco/aroeira: 1B tokens (portuguese PT-BR)\nsubset-Itau-Unibanco-aroeira-1B-tokens \n","url":"https://huggingface.co/datasets/bobboyms/subset-Itau-Unibanco-aroeira-1B-tokens","creator_name":"Thiago Luiz Rodrigues","creator_url":"https://huggingface.co/bobboyms","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","Portuguese","apache-2.0","1M - 10M","parquet"],"keywords_longer_than_N":true},
	{"name":"domain-translations","keyword":"portuguese","description":"\n\t\n\t\t\n\t\tMultilingual Domain Name Translations Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset contains 155,004 domain names with their multilingual translations across 20 languages. Each domain has been segmented into constituent words and translated while preserving semantic meaning and commercial appeal. The dataset is particularly valuable for domain name research, multilingual NLP tasks, and understanding how brand names and concepts translate across languages.\n\n\t\n\t\t\n\t\tDatasetâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/humbleworth/domain-translations.","url":"https://huggingface.co/datasets/humbleworth/domain-translations","creator_name":"HumbleWorth","creator_url":"https://huggingface.co/humbleworth","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["translation","text-generation","feature-extraction","multilingual","Arabic"],"keywords_longer_than_N":true},
	{"name":"fake_voices","keyword":"portuguese","description":"\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Card for Fake Voices\n\t\n\nThis dataset contains deepfakes in Brazilian Portuguese created with XTTS model.\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Details\n\t\n\nThe dataset was created using the XTTS model, which is a Text-to-Speech model pre-trained in several languages including Portuguese. \nIn order to generate the mentioned deepfakes, the model was fed with recordings from the CETUC Corpus, \nmade available by Fala Brasil Group. It contains speeches from 101 speakers, totaling 140 hours ofâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/unfake/fake_voices.","url":"https://huggingface.co/datasets/unfake/fake_voices","creator_name":"Unfake","creator_url":"https://huggingface.co/unfake","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-to-speech","text-to-audio","Portuguese","mit","1B<n<10B"],"keywords_longer_than_N":true},
	{"name":"English-PTBR","keyword":"portuguese","description":"Dexavator/English-PTBR dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/Dexavator/English-PTBR","creator_name":"VICTOR DE ALENCAR DELGADO","creator_url":"https://huggingface.co/Dexavator","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["translation","English","Portuguese","apache-2.0","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"brazilian-news-article-summarization-DPO","keyword":"portuguese","description":"\n\t\n\t\t\n\t\tðŸ—žï¸ Brazilian News Preference Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Card for maikerdr/brazilian-news-article-summarization-DPO\n\t\n\nGenerated using https://github.com/maikereis/news-summarizer\n\n\n\t\n\t\t\n\t\tðŸ“ Dataset Summary\n\t\n\nThis dataset consists of Brazilian news articles scraped from reputable online journalism sources. \n\n\t\n\t\t\n\t\tG1\n\t\n\n\nhttps://g1.globo.com/politica/\nhttps://g1.globo.com/economia/\nhttps://g1.globo.com/ciencia/\nhttps://g1.globo.com/tecnologia/\nhttps://g1.globo.com/saude/â€¦ See the full description on the dataset page: https://huggingface.co/datasets/maikerdr/brazilian-news-article-summarization-DPO.","url":"https://huggingface.co/datasets/maikerdr/brazilian-news-article-summarization-DPO","creator_name":"reis","creator_url":"https://huggingface.co/maikerdr","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["summarization","Portuguese","mit","1K - 10K","parquet"],"keywords_longer_than_N":true},
	{"name":"dhanishtha-2.0-superthinker","keyword":"portuguese","description":"\n\t\n\t\t\n\t\tðŸ“¦ Dhanishtha-2.0-SUPERTHINKER-MLX\n\t\n\n A distilled corpus of 11.7K high-quality samples showcasing multi-phase reasoning and structured emotional cognition. Sourced directly from the internal training data of Dhanishtha-2.0 â€” the worldâ€™s first Large Language Model (LLM) to implement Intermediate Thinking, featuring multiple <think> and <ser> blocks per response\n\n\t\n\t\t\n\t\n\t\n\t\tExample with MLX-LM-LoRA:\n\t\n\nmlx_lm_lora.train \\\n--modelâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/mlx-community/dhanishtha-2.0-superthinker.","url":"https://huggingface.co/datasets/mlx-community/dhanishtha-2.0-superthinker","creator_name":"MLX Community","creator_url":"https://huggingface.co/mlx-community","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","Afrikaans","Arabic","Bulgarian","Catalan"],"keywords_longer_than_N":true},
	{"name":"fineweb2hq-vs-c4","keyword":"portuguese","description":"This dataset includes 5000 rows per language from each of two sources: the higher-quality epfml/FineWeb2-HQ\nand the lower-quality allenai/c4. The data is split 80/20 into training and test sets.\nLanguages were carefully chosen to ensure balanced representation across both splits:\nArabic, Chinese, Czech, Danish, Dutch, French, German, Greek, Hungarian, Indonesian, Italian, Japanese, Persian, Polish, Portuguese, Russian, Spanish, Swedish, Turkish, and Vietnamese.\n","url":"https://huggingface.co/datasets/agentlans/fineweb2hq-vs-c4","creator_name":"Alan Tseng","creator_url":"https://huggingface.co/agentlans","license_name":"Open Data Commons Attribution License v1.0","license_url":"https://scancode-licensedb.aboutcode.org/odc-by-1.0.html","language":"en","first_N":5,"first_N_keywords":["text-classification","Portuguese","Danish","Persian","German"],"keywords_longer_than_N":true},
	{"name":"UFLA-FORMS","keyword":"portuguese","description":"\n\t\n\t\t\n\t\tUFLA-FORMS: an Academic Forms Dataset for Information Extraction in the Portuguese Language\n\t\n\n\n\t\n\t\t\n\t\tAbout\n\t\n\nUFLA-FORMS is a manually labeled dataset of document forms in Brazilian Portuguese extracted from the domains of the Federal University of Lavras (UFLA). The dataset emphasizes the hierarchical structure between the entities of a document through their relationships, in addition to the extraction of key-value pairs. Samples were labeled using ToolRI.\n\n\t\n\t\t\n\t\n\t\n\t\tOverviewâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Victorgonl/UFLA-FORMS.","url":"https://huggingface.co/datasets/Victorgonl/UFLA-FORMS","creator_name":"Victor GonÃ§alves Lima","creator_url":"https://huggingface.co/Victorgonl","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["token-classification","question-answering","table-question-answering","Portuguese","English"],"keywords_longer_than_N":true},
	{"name":"CPTransExercise","keyword":"portuguese","description":"Chinese-Portuguese Translation Exercise Corpus (CPTEC)\nThis dataset aims to provide translators to practice Chinese-Portuguese translation with different levels from basic to proficient.\nThis is a sample dataset from CPTEC, please contact us for more information.\nlmhoi@mpu.edu.mo\n","url":"https://huggingface.co/datasets/edmond5995/CPTransExercise","creator_name":"Hoi","creator_url":"https://huggingface.co/edmond5995","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["translation","Chinese","Portuguese","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"llm-metric-mrewardbench","keyword":"portuguese","description":"rubricreward/llm-metric-mrewardbench dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/rubricreward/llm-metric-mrewardbench","creator_name":"rubricreward","creator_url":"https://huggingface.co/rubricreward","license_name":"Open Data Commons Attribution License v1.0","license_url":"https://scancode-licensedb.aboutcode.org/odc-by-1.0.html","language":"en","first_N":5,"first_N_keywords":["Arabic","Chinese","Czech","Dutch","French"],"keywords_longer_than_N":true},
	{"name":"phonetic-piper-recording-studio-prompts","keyword":"portuguese","description":"\n\t\n\t\t\n\t\tPhonetic Piper Studio Recordings Prompts\n\t\n\nThis dataset is a processed version of an utterance dataset made available for various languages as prompts for the Piper recording studio. Along with the original prompts, we include:\n\ncolumns ipa_espeak and ipa_epitran containing phonemized versions of the original sentences according to espeak-ng and Epitran phonemizers, respectively\ncolumns lang, espeak_lang_code, epitran_lang_code containing the language codes as reported by piperâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fdemelo/phonetic-piper-recording-studio-prompts.","url":"https://huggingface.co/datasets/fdemelo/phonetic-piper-recording-studio-prompts","creator_name":"FlÃ¡vio Eler De Melo","creator_url":"https://huggingface.co/fdemelo","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["Afrikaans","Arabic","Bulgarian","Catalan","Czech"],"keywords_longer_than_N":true},
	{"name":"TCCHandInformation","keyword":"portuguese","description":"\n\t\n\t\t\n\t\tDataset Card for Dataset Name\n\t\n\nDataset created with MediaPipe with the aim of doing fine tuning consisting of:\n\nuser prompt containing the information\nsystem prompt explaining what will be received\nexpected response\n\n","url":"https://huggingface.co/datasets/GuilhermeGomes/TCCHandInformation","creator_name":"Guilherme Gomes Luccas Rodrigues","creator_url":"https://huggingface.co/GuilhermeGomes","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","Portuguese","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"flickr8k-pt-br","keyword":"portuguese","description":"\n\t\n\t\t\n\t\tðŸŽ‰ Flickr8K Dataset Translation for Portuguese Image Captioning\n\t\n\n\n\t\n\t\t\n\t\tðŸ’¾ Dataset Summary\n\t\n\nFlickr8K Portuguese Translation, a multimodal dataset for Portuguese image captioning with 8,000 images, each accompanied by five descriptive captions that have been\ngenerated by human annotators for every individual image. The original English captions were rendered into Portuguese\nthrough the utilization of the Google Translator API.\n\n\t\n\t\t\n\t\tðŸ§‘â€ðŸ’» Hot to Get Started with the Datasetâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/laicsiifes/flickr8k-pt-br.","url":"https://huggingface.co/datasets/laicsiifes/flickr8k-pt-br","creator_name":"LaboratÃ³rio de InteligÃªncia Computacional e Sistemas de informaÃ§Ã£o","creator_url":"https://huggingface.co/laicsiifes","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["image-to-text","text-to-image","text-generation","Portuguese","mit"],"keywords_longer_than_N":true},
	{"name":"tabela-taco","keyword":"portuguese","description":"\n\t\n\t\t\n\t\tDataset: TACO - Tabela Brasileira de ComposiÃ§Ã£o de Alimentos\n\t\n\nThe TACO Table is the reference nutritional table for foods consumed in Brazil. The information contained in this dataset was taken from the excel file made available by NEPA - Center for Studies and Research in Food at UNICAMP, through the link: \nhttps://nepa.unicamp.br/publicacoes/tabela-taco-excel/\n","url":"https://huggingface.co/datasets/julianamarques/tabela-taco","creator_name":"Juliana Marques","creator_url":"https://huggingface.co/julianamarques","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["Portuguese","cc0-1.0","< 1K","csv","Text"],"keywords_longer_than_N":true},
	{"name":"multihal","keyword":"portuguese","description":"\n\t\n\t\t\n\t\tDataset Card for MultiHal\n\t\n\nBenchmark (test-only) intended for generative-form question answering grounded on knowledge graphs. \nMultiHal contains approximately 7k unique questions and 25.9k unique KG paths, some questions contain multiple candidate paths.\nThe benchmark is designed to support research for factual language modeling with a focus on providing a test bed for LLM hallucination evaluation and\nLLM knowledge updating based on KG paths in multilingual setting. See the paperâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/ernlavr/multihal.","url":"https://huggingface.co/datasets/ernlavr/multihal","creator_name":"Ernests Lavrinovics","creator_url":"https://huggingface.co/ernlavr","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["question-answering","English","Spanish","French","Portuguese"],"keywords_longer_than_N":true},
	{"name":"V1Q","keyword":"portuguese","description":"from datasets import load_dataset\nds = load_dataset(\"b3x0m/Chinese-H-Novels\")\nimport sagemaker\nimport boto3\nfrom sagemaker.huggingface import HuggingFaceModel\ntry:\n    role = sagemaker.get_execution_role()\nexcept ValueError:\n    iam = boto3.client('iam')\n    role = iam.get_role(RoleName='sagemaker_execution_role')['Role']['Arn']\n\n\t\n\t\t\n\t\tHub Model configuration. https://huggingface.co/models\n\t\n\nhub = {\n    'HF_MODEL_ID':'deepseek-ai/Janus-Pro-7B',\n    'HF_TASK':'any-to-any'\n}\n\n\t\n\t\t\n\t\tcreateâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/YuRiVeRTi/V1Q.","url":"https://huggingface.co/datasets/YuRiVeRTi/V1Q","creator_name":"YuRiVeRTical","creator_url":"https://huggingface.co/YuRiVeRTi","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","table-question-answering","question-answering","zero-shot-classification"],"keywords_longer_than_N":true},
	{"name":"LLM_Multilingual_dataset","keyword":"portuguese","description":"\n\t\n\t\t\n\t\tDataset Card for Dataset Name\n\t\n\n\n\nThis dataset card aims to be a base template for new datasets. It has been generated using this raw template.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\n\n\n\n\n\nCurated by: [More Information Needed]\nFunded by [optional]: [More Information Needed]\nShared by [optional]: [More Information Needed]\nLanguage(s) (NLP): [More Information Needed]\nLicense: [More Information Needed]\n\n\n\t\n\t\t\n\t\tDataset Sources [optional]\n\t\n\n\n\n\nRepository: [Moreâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/lewishamilton21/LLM_Multilingual_dataset.","url":"https://huggingface.co/datasets/lewishamilton21/LLM_Multilingual_dataset","creator_name":"Kesavprabu","creator_url":"https://huggingface.co/lewishamilton21","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["table-question-answering","Japanese","Finnish","Indonesian","Russian"],"keywords_longer_than_N":true},
	{"name":"sentiment-analysis-pt","keyword":"portuguese","description":"\n\t\n\t\t\n\t\tSentiment Analysis PT (Teeny-Tiny Castle)\n\t\n\nThis dataset is part of a tutorial tied to the Teeny-Tiny Castle, an open-source repository containingÂ educational tools for AI Ethics and Safety research. \n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nfrom datasets import load_dataset\n\ndataset = load_dataset(\"AiresPucrs/sentiment-analysis-pt\", split = 'train')\n\n","url":"https://huggingface.co/datasets/AiresPucrs/sentiment-analysis-pt","creator_name":"AI Robotics Ethics Society (PUCRS)","creator_url":"https://huggingface.co/AiresPucrs","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","Portuguese","apache-2.0","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"tatoeba-tokipona","keyword":"portuguese","description":"NetherQuartz/tatoeba-tokipona dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/NetherQuartz/tatoeba-tokipona","creator_name":"Vladimir Larkin","creator_url":"https://huggingface.co/NetherQuartz","license_name":"Creative Commons Attribution 2.0","license_url":"https://scancode-licensedb.aboutcode.org/cc-by-2.0.html","language":"en","first_N":5,"first_N_keywords":["translation","Toki Pona","English","Russian","Ukrainian"],"keywords_longer_than_N":true},
	{"name":"OpenHumanreasoning-multilingual-2.2k","keyword":"portuguese","description":"Based off of Pinkstackorg/humanreasoning-testing-en, it is a human-generated dataset where a real person had to create most of the reasoning and the final output. If there are any mistakes please let us know.\nWe offer this dataset at an apache-2.0 license to make it useful for everybody.\nnote: translations are not human generated.\n","url":"https://huggingface.co/datasets/Pinkstack/OpenHumanreasoning-multilingual-2.2k","creator_name":"Pinkstack","creator_url":"https://huggingface.co/Pinkstack","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","Arabic","Chinese","Czech","Danish"],"keywords_longer_than_N":true},
	{"name":"Political-BRSD","keyword":"portuguese","description":"cerqueiramatheus/Political-BRSD dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/cerqueiramatheus/Political-BRSD","creator_name":"Matheus Cerqueira","creator_url":"https://huggingface.co/cerqueiramatheus","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","Portuguese","mit","10K - 100K","csv"],"keywords_longer_than_N":true},
	{"name":"wmt24pp","keyword":"portuguese","description":"\n\t\n\t\t\n\t\tWMT24++\n\t\n\nThis repository contains the human translation and post-edit data for the 55 en->xx language pairs released in\nthe publication\nWMT24++: Expanding the Language Coverage of WMT24 to 55 Languages & Dialects.\nIf you are interested in the MT/LLM system outputs and automatic metric scores, please see MTME.\nIf you are interested in the images of the source URLs for each document, please see here.\n\n\t\n\t\t\n\t\n\t\n\t\tSchema\n\t\n\nEach language pair is stored in its own jsonl file.\nEach row isâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/google/wmt24pp.","url":"https://huggingface.co/datasets/google/wmt24pp","creator_name":"Google","creator_url":"https://huggingface.co/google","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["translation","Arabic","Bulgarian","Bengali","Catalan"],"keywords_longer_than_N":true},
	{"name":"forex-algotrading-m15-1000-columns","keyword":"portuguese","description":"\n\t\n\t\t\n\t\tFOREX Algotrading M15 1000 Columns\n\t\n\n\n\t\n\t\t\n\t\tDescriÃ§Ã£o\n\t\n\nEste dataset contÃ©m dados histÃ³ricos de Forex em intervalos de 15 minutos (M15), incluindo mÃºltiplos pares de moedas. Ã‰ voltado para anÃ¡lise de sÃ©ries temporais e desenvolvimento de algoritmos de trading automatizados. Cada arquivo CSV contÃ©m 1000 colunas com dados de mercado, como preÃ§os de abertura, fechamento, mÃ¡xima e mÃ­nima, volume e spread.\n\n\n\t\n\t\t\n\t\tEstrutura do dataset\n\t\n\nCada arquivo CSV possui as seguintes colunas:â€¦ See the full description on the dataset page: https://huggingface.co/datasets/lukealvess/forex-algotrading-m15-1000-columns.","url":"https://huggingface.co/datasets/lukealvess/forex-algotrading-m15-1000-columns","creator_name":"Lucas Alves","creator_url":"https://huggingface.co/lukealvess","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["time-series-forecasting","English","Portuguese","cc-by-4.0","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"bfc-test","keyword":"portuguese","description":"\n\t\n\t\t\n\t\tDataset de Exemplos para BFC-Script\n\t\n\nEste dataset contÃ©m exemplos prÃ¡ticos de uso da linguagem bfc-script, organizados em pares de prompt e completion. Ele foi criado para ajudar desenvolvedores a entender e utilizar a linguagem em diversos cenÃ¡rios, desde operaÃ§Ãµes bÃ¡sicas atÃ© funcionalidades mais avanÃ§adas.\n\n\t\n\t\t\n\t\tEstrutura do Dataset\n\t\n\nO dataset estÃ¡ no formato JSONL (JSON Lines), onde cada linha Ã© um objeto JSON com dois campos:\n\nprompt: Uma pergunta ou descriÃ§Ã£o de um cenÃ¡rioâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/AugustoSavi/bfc-test.","url":"https://huggingface.co/datasets/AugustoSavi/bfc-test","creator_name":"Augusto Savi","creator_url":"https://huggingface.co/AugustoSavi","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-generation","Portuguese","mit","< 1K","json"],"keywords_longer_than_N":true},
	{"name":"x-fact","keyword":"portuguese","description":"\n\t\n\t\t\n\t\tDataset Card for \"x-fact\"\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nX-FACT is a multilingual dataset for fact-checking with real world claims. The dataset contains short statments in 25 languages with top five evidence documents retrieved by performing google search with claim statements. The dataset contains two additional evaluation splits (in addition to a traditional test set): ood and zeroshot. ood measures out-of-domain generalization where while the languageâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/utahnlp/x-fact.","url":"https://huggingface.co/datasets/utahnlp/x-fact","creator_name":"NLP at University of Utah","creator_url":"https://huggingface.co/utahnlp","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","Arabic","Bengali","Spanish","Persian"],"keywords_longer_than_N":true},
	{"name":"librivox-tracks","keyword":"portuguese","description":"A dataset of all audio files uploaded to LibriVox before 26th September 2023.\nForked from https://huggingface.co/datasets/pykeio/librivox-tracks\nChanges:\n\nUsed archive.org metadata API to annotate rows with \"duration\" column\n\n","url":"https://huggingface.co/datasets/xacer/librivox-tracks","creator_name":"xacer","creator_url":"https://huggingface.co/xacer","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-to-speech","automatic-speech-recognition","feature-extraction","Achinese","Afrikaans"],"keywords_longer_than_N":true},
	{"name":"emilia-sitio-do-pica-pau-amarelo-2012","keyword":"portuguese","description":"gabrielsemiceki9/emilia-sitio-do-pica-pau-amarelo-2012 dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/gabrielsemiceki9/emilia-sitio-do-pica-pau-amarelo-2012","creator_name":"877","creator_url":"https://huggingface.co/gabrielsemiceki9","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-to-speech","Portuguese","mit","< 1K","soundfolder"],"keywords_longer_than_N":true},
	{"name":"multilingual-reward-bench","keyword":"portuguese","description":"\n\t\n\t\t\n\t\tMultilingual Reward Bench (v1.0)\n\t\n\nReward models (RMs) have driven the development of state-of-the-art LLMs today, with unprecedented impact across the globe. However, their performance in multilingual settings still remains understudied. \nIn order to probe reward model behavior on multilingual data, we present M-RewardBench, a benchmark for 23 typologically diverse languages. \nM-RewardBench contains prompt-chosen-rejected preference triples obtained by curating and translating chatâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/CohereLabsCommunity/multilingual-reward-bench.","url":"https://huggingface.co/datasets/CohereLabsCommunity/multilingual-reward-bench","creator_name":"Cohere Labs Community","creator_url":"https://huggingface.co/CohereLabsCommunity","license_name":"Open Data Commons Attribution License v1.0","license_url":"https://scancode-licensedb.aboutcode.org/odc-by-1.0.html","language":"en","first_N":5,"first_N_keywords":["Arabic","Chinese","Czech","Dutch","French"],"keywords_longer_than_N":true},
	{"name":"GoSim-3","keyword":"portuguese","description":"\n\t\n\t\t\n\t\tGoSim-3\n\t\n\nEste repositÃ³rio contÃ©m dados anotados em portuguÃªs para anÃ¡lise de similaridade semÃ¢ntica entre perguntas de e-commerce.\nSelecionamos 150 pares de perguntas reais de plataformas de e-commerce. TrÃªs anotadores avaliaram cada par com base em sua similaridade, usando trÃªs categorias:\n\nsimilar\n\nalmost similar\n\ndissimilar\n\n\nApÃ³s consenso entre os anotadores, filtramos os pares com maioria de votos. Foram mantidos 144 pares, descartando 6 pares com total desacordo.\n\nsimilar: 34â€¦ See the full description on the dataset page: https://huggingface.co/datasets/GoBotsAI/GoSim-3.","url":"https://huggingface.co/datasets/GoBotsAI/GoSim-3","creator_name":"GoBots","creator_url":"https://huggingface.co/GoBotsAI","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["Portuguese","apache-2.0","< 1K","csv","Text"],"keywords_longer_than_N":true},
	{"name":"include-lite-44","keyword":"portuguese","description":"\n\t\n\t\t\n\t\tINCLUDE-lite (44 languages)\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\n\n\nPaper: http://arxiv.org/abs/2411.19799\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nINCLUDE is a comprehensive knowledge- and reasoning-centric benchmark across 44 languages that evaluates multilingual LLMs for performance in the actual language environments where they would be deployed. \nIt contains 11,095 4-option multiple-choice-questions (MCQ) extracted from academic and professional exams, covering 57 topics, including regionalâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/CohereLabs/include-lite-44.","url":"https://huggingface.co/datasets/CohereLabs/include-lite-44","creator_name":"Cohere Labs","creator_url":"https://huggingface.co/CohereLabs","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["multiple-choice","Albanian","Arabic","Armenian","Azerbaijani"],"keywords_longer_than_N":true},
	{"name":"VoxCommunis","keyword":"portuguese","description":"\n\t\n\t\t\n\t\tVoxCommunis Corpus\n\t\n\nThe VoxCommunis Corpus is a phonetic corpus derived from the Mozilla Common Voice Corpus. Corresponding audio files and corpus metadata can be downloaded from Mozilla Common Voice, or from one of several Hugging Face repositories for the differing versions. \nWithin each folder, the filenames share similar structure and contain critical information for effectively using the file. More detail regarding the specifics of the filename for each file type is providedâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/pacscilab/VoxCommunis.","url":"https://huggingface.co/datasets/pacscilab/VoxCommunis","creator_name":"PaCSciLab @ UZH","creator_url":"https://huggingface.co/pacscilab","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["Abkhaz","Amharic","Bashkir","Belarusian","Bulgarian"],"keywords_longer_than_N":true},
	{"name":"common_voice_21_0","keyword":"portuguese","description":"\n\t\n\t\t\n\t\tDataset Card for Common Voice Corpus 21.0\n\t\n\n\n\nThis dataset is an unofficial version of the Mozilla Common Voice Corpus 21. It was downloaded and converted from the project's website https://commonvoice.mozilla.org/.\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nAbkhaz, Albanian, Amharic, Arabic, Armenian, Assamese, Asturian, Azerbaijani, Basaa, Bashkir, Basque, Belarusian, Bengali, Breton, Bulgarian, Cantonese, Catalan, Central Kurdish, Chinese (China), Chinese (Hong Kong), Chinese (Taiwan), Chuvash, Czechâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fsicoli/common_voice_21_0.","url":"https://huggingface.co/datasets/fsicoli/common_voice_21_0","creator_name":"Fabio Sicoli","creator_url":"https://huggingface.co/fsicoli","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":null,"first_N":5,"first_N_keywords":["automatic-speech-recognition","Abkhaz","Afrikaans","Amharic","Arabic"],"keywords_longer_than_N":true},
	{"name":"HelpSteer3","keyword":"portuguese","description":"\n\t\n\t\t\n\t\tHelpSteer3\n\t\n\nHelpSteer3 is an open-source dataset (CC-BY-4.0) that supports aligning models to become more helpful in responding to user prompts.\nHelpSteer3-Preference can be used to train Llama 3.3 Nemotron Super 49B v1 (for Generative RMs) and Llama 3.3 70B Instruct Models (for Bradley-Terry RMs) to produce Reward Models that score as high as 85.5% on RM-Bench and 78.6% on JudgeBench, which substantially surpass existing Reward Models on these benchmarks.\nHelpSteer3-Feedback andâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/nvidia/HelpSteer3.","url":"https://huggingface.co/datasets/nvidia/HelpSteer3","creator_name":"NVIDIA","creator_url":"https://huggingface.co/nvidia","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["English","Chinese","Korean","French","Spanish"],"keywords_longer_than_N":true},
	{"name":"from-one-to-many-toxicity-mitigation","keyword":"portuguese","description":"\n\t\n\t\t\n\t\n\t\n\t\tFrom One to Many: Expanding the Scope of Toxicity Mitigation in Language Models\n\t\n\n[arxiv][code][data]\nData accompanying the paper \"From One to Many: Expanding the Scope of Toxicity Mitigation in Language Models\" accepted to ACL Findings 2024.\nAbstract: To date, toxicity mitigation in language models has almost entirely been focused on single-language settings. As language models embrace multilingual capabilities, itâ€™s crucial our safety measures keep pace. Recognizing thisâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/luizapzbn/from-one-to-many-toxicity-mitigation.","url":"https://huggingface.co/datasets/luizapzbn/from-one-to-many-toxicity-mitigation","creator_name":"Luiza Pozzobon","creator_url":"https://huggingface.co/luizapzbn","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","text-classification","English","Portuguese","Hindi"],"keywords_longer_than_N":true},
	{"name":"Squad_PT","keyword":"portuguese","description":"\n\t\n\t\t\n\t\tDataset Card para o SQuAD 1.1 em PortuguÃªs Brasil\n\t\n\nO conjunto de dados \"Stanford Question Answering Dataset\" (SQuAD),\npara tarefa de perguntas e respostas extrativas, foi desenvolvido em 2016. Ele utiliza perguntas geradas a partir de\n536 artigos da Wikipedia* com mais de 100.000 linhas de dados. Ã‰ construÃ­do na forma de uma pergunta e um contexto dos artigos da\nWikipedia contendo a resposta Ã  pergunta. [1]Originalmente este dataset foi construÃ­do no idioma inglÃªs, contudo, o grupoâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/vitorandrade/Squad_PT.","url":"https://huggingface.co/datasets/vitorandrade/Squad_PT","creator_name":"Vitor Pereira Andrade","creator_url":"https://huggingface.co/vitorandrade","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["Portuguese","mit","10K - 100K","csv","Text"],"keywords_longer_than_N":true},
	{"name":"agua_e_esgoto_nordeste_brasileiro","keyword":"portuguese","description":"\n\t\n\t\t\n\t\tBrazilian Northeast Water and Sanitation Crisis Dataset (BNWSC)\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset provides multidisciplinary data on water access, sanitation, public health, and socioeconomic disparities in Brazil's Northeast region. It integrates official sources (2014â€“2022) and includes projections up to 2030, supporting research in public policy, collective health, and sustainability.\n\n\n\t\n\t\t\n\t\tKey Features\n\t\n\n\n\t\n\t\t\n\t\tApplications\n\t\n\n\nCorrelation analysis between sanitation, incomeâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/carpenterbb/agua_e_esgoto_nordeste_brasileiro.","url":"https://huggingface.co/datasets/carpenterbb/agua_e_esgoto_nordeste_brasileiro","creator_name":"carpenter","creator_url":"https://huggingface.co/carpenterbb","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["Portuguese","cc-by-4.0","1K - 10K","csv","Tabular"],"keywords_longer_than_N":true},
	{"name":"Multilingual-Benchmark","keyword":"portuguese","description":"These are the GSM8K and ARC dataset translated by Google Translate. \nBibTex\n@misc{lu2024languagecountslearnunlearn,\n      title={Every Language Counts: Learn and Unlearn in Multilingual LLMs}, \n      author={Taiming Lu and Philipp Koehn},\n      year={2024},\n      eprint={2406.13748},\n      archivePrefix={arXiv},\n      primaryClass={cs.CL},\n      url={https://arxiv.org/abs/2406.13748}, \n}\n\n","url":"https://huggingface.co/datasets/TaiMingLu/Multilingual-Benchmark","creator_name":"TaiMing","creator_url":"https://huggingface.co/TaiMingLu","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["zero-shot-classification","question-answering","translation","English","German"],"keywords_longer_than_N":true},
	{"name":"multiple-choice-questions","keyword":"portuguese","description":"\n\t\n\t\t\n\t\n\t\n\t\tQuestÃµes de MÃºltipla Escolha - Base de dados (PT-BR)\n\t\n\n\n\t\n\t\t\n\t\n\t\n\t\tContextualizaÃ§Ã£o\n\t\n\nEste repositÃ³rio contÃ©m uma base de dados (data.json) com questÃµes de mÃºltipla escolha, a qual foi utilizada principalmente no desenvolvimento de modelos de recuperaÃ§Ã£o de informaÃ§Ã£o.\n\n\t\n\t\t\n\t\n\t\n\t\tDescriÃ§Ã£o do conjunto de dados\n\t\n\nO conjunto de dados Ã© composto por questÃµes de mÃºltipla escolha, abrangendo uma variedade de temas dentro da Ã¡rea da CiÃªncia da ComputaÃ§Ã£o. Cada questÃ£o Ã© estruturadaâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/mateus-hamade/multiple-choice-questions.","url":"https://huggingface.co/datasets/mateus-hamade/multiple-choice-questions","creator_name":"Mateus Hamade","creator_url":"https://huggingface.co/mateus-hamade","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","question-answering","Portuguese","mit","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"u-sticker","keyword":"portuguese","description":"\n\t\n\t\t\n\t\tU-Sticker\n\t\n\nUser-Sticker is a stickers dataset with multi-domain conversations.\nFeatures of U-Sticker:\n\nMulti-domain interactions âœ…\nTemporal âœ…\nUser information âœ…\n370.2k stickers âœ… (104k unique)\n22.6k users âœ…\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nU-Sticker contains three files:\n\nConversation files: 1 to 67.json\nDomain mapping files idx_to_domain.txt.\nSticker files.\n\n\nSticker files are available here and Baidu Cloud.\n\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\n\t\n\t\t\n\t\tConversation file\n\t\n\n\nEmpty lines areâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/metchee/u-sticker.","url":"https://huggingface.co/datasets/metchee/u-sticker","creator_name":"Metilda Chee","creator_url":"https://huggingface.co/metchee","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["Arabic","Chinese","English","French","Turkish"],"keywords_longer_than_N":true},
	{"name":"Alvorada-bench","keyword":"portuguese","description":"This dataset contains 4,515 multiple-choice questions from five major Brazilian university entrance exams (ENEM, FUVEST, UNICAMP, ITA, IME) spanning 32 years (1981-2025), along with model responses from 20  LLMs.\n\n\t\n\t\t\n\t\tFiles\n\t\n\n\n\t\n\t\t\n\t\tðŸ“„ questions_data.csv (4,515 rows)\n\t\n\nContains the exam questions with:\n\nquestion_id: Unique identifier\nquestion_statement: Question text in Portuguese\ncorrect_answer: Correct option (A-E)\nalternative_a to alternative_e: Answer choices\nsubject: Academicâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/HenriqueGodoy/Alvorada-bench.","url":"https://huggingface.co/datasets/HenriqueGodoy/Alvorada-bench","creator_name":"Henrique Godoy","creator_url":"https://huggingface.co/HenriqueGodoy","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["mit","100K - 1M","csv","Text","Datasets"],"keywords_longer_than_N":true},
	{"name":"multihal","keyword":"portuguese","description":"\n\t\n\t\t\n\t\tDataset Card for MultiHal\n\t\n\nBenchmark (test-only) intended for generative-form question answering grounded on knowledge graphs. \nMultiHal contains approximately 7k unique questions and 25.9k unique KG paths, some questions contain multiple candidate paths.\nThe benchmark is designed to support research for factual language modeling with a focus on providing a test bed for LLM hallucination evaluation and\nLLM knowledge updating based on KG paths in multilingual setting.\n\n\t\n\t\t\n\t\n\t\n\t\tUsesâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/AnonymousSubmission9090/multihal.","url":"https://huggingface.co/datasets/AnonymousSubmission9090/multihal","creator_name":"Anonymous","creator_url":"https://huggingface.co/AnonymousSubmission9090","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["question-answering","English","Spanish","French","Portuguese"],"keywords_longer_than_N":true},
	{"name":"mmlux","keyword":"portuguese","description":"\n\t\n\t\t\n\t\tCitation Information\n\t\n\nIf you find benchmarks useful in your research, please consider citing the test and also the MMLU dataset it draws from:\n    @misc{thellmann2024crosslingual,\n    title={Towards Cross-Lingual LLM Evaluation for European Languages},\n    author={Klaudia Thellmann and Bernhard Stadler and Michael Fromm and Jasper Schulze Buschhoff and Alex Jude and Fabio Barth and Johannes Leveling and Nicolas Flores-Herr and Joachim KÃ¶hler and RenÃ© JÃ¤kel and Mehdi Ali}â€¦ See the full description on the dataset page: https://huggingface.co/datasets/Eurolingua/mmlux.","url":"https://huggingface.co/datasets/Eurolingua/mmlux","creator_name":"EuroLingua-GPT","creator_url":"https://huggingface.co/Eurolingua","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":null,"first_N":5,"first_N_keywords":["multiple-choice","expert-generated","multilingual","cais/mmlu","German"],"keywords_longer_than_N":true},
	{"name":"social_i_qa_pt","keyword":"portuguese","description":"\n\t\n\t\t\n\t\tSocialIQa dataset v1.4 (PT)\n\t\n\nThis is translation to the portuguese language of the dataset allenai/social_i_qa.Translations were done using three independent models:  \n\nHelsinki-NLP/opus-mt-tc-big-en-pt\nunicamp-dl/translation-en-pt-t5  \nfacebook/nllb-200-distilled-1.3B\n\nTranslations were evaluated using the evaluation metric GEMBA - GPT Estimation Metric Based Assessment\n(from the article Large Language Models Are State-of-the-Art Evaluators of Translation Quality) usingâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fabiogr/social_i_qa_pt.","url":"https://huggingface.co/datasets/fabiogr/social_i_qa_pt","creator_name":"Fabio Grassiotto","creator_url":"https://huggingface.co/fabiogr","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["Portuguese","cc-by-4.0","10K - 100K","json","Text"],"keywords_longer_than_N":true},
	{"name":"montok","keyword":"portuguese","description":"\n\t\n\t\t\n\t\tMonTok: A Suite of Monolingual Tokenizers\n\t\n\nThis is a set of monolingual tokenizers for 98 languages. For each language, there are Unigram, BPE, and SuperBPE tokenizers, ranging in vocabulary size from around 6k to over 200k.\n\n\t\n\t\t\n\t\tTraining Details\n\t\n\n\n\t\n\t\t\n\t\tTraining Data\n\t\n\nAll tokenizers are trained on samples of the data used to the train the Goldfish language models. \nThe tokenizers were either trained on scaled or unscaled data. This refers to whether the models are trained onâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/catherinearnett/montok.","url":"https://huggingface.co/datasets/catherinearnett/montok","creator_name":"Catherine Arnett","creator_url":"https://huggingface.co/catherinearnett","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["Afrikaans","Tosk Albanian","Amharic","Standard Arabic","Assamese"],"keywords_longer_than_N":true},
	{"name":"Portuguese-Umbundu_Sentence-Pairs","keyword":"portuguese","description":"martinsmussinda/Portuguese-Umbundu_Sentence-Pairs dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/martinsmussinda/Portuguese-Umbundu_Sentence-Pairs","creator_name":"Martins Mussinda","creator_url":"https://huggingface.co/martinsmussinda","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["translation","Portuguese","mit","< 1K","Text"],"keywords_longer_than_N":true},
	{"name":"nurc-sp_pseudo_labelled-dev","keyword":"portuguese","description":"RodrigoLimaRFL/nurc-sp_pseudo_labelled-dev dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/RodrigoLimaRFL/nurc-sp_pseudo_labelled-dev","creator_name":"Rodrigo de Freitas Lima","creator_url":"https://huggingface.co/RodrigoLimaRFL","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["Portuguese","mit","< 1K","parquet","Audio"],"keywords_longer_than_N":true},
	{"name":"unlabelled-sti-corpus","keyword":"portuguese","description":"\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe unlabelled-sti-corpus is a diverse dataset designed for developing information extraction datasets (i.e. text classification or NER) for Science, Technology, and Innovation (STI) records. The corpus contains approximately 35,000 records sourced from four major repositories:\n\n22,500 publications from OpenAlex\n10,000 European research projects from CORDIS\n5,000 regional projects from Interreg and Kohesio\n7,000 patents from Lens.org\n\nThe dataset is stratifiedâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/SIRIS-Lab/unlabelled-sti-corpus.","url":"https://huggingface.co/datasets/SIRIS-Lab/unlabelled-sti-corpus","creator_name":"SIRIS Lab, Research Division of SIRIS Academic","creator_url":"https://huggingface.co/SIRIS-Lab","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["English","Spanish","French","German","Italian"],"keywords_longer_than_N":true},
	{"name":"portuguese-blogs","keyword":"portuguese","description":"\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Details\n\t\n\nBlog-1 may include other languages in an unstructured text format without markdown. The latest one, Blog-6, is formatted in markdown and may contain less other languages text.\nTexts are separated by the string <|endoftext|>.\n\n\t\n\t\t\n\t\n\t\n\t\tUses\n\t\n\nTraining language models.\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Structure\n\t\n\nA simple text file with articles separated by <|endoftext|> between each text.\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Creation\n\t\n\nFirst semester of 2024.\n\n\t\n\t\t\n\t\n\t\n\t\tBias, Risksâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fabiovilao/portuguese-blogs.","url":"https://huggingface.co/datasets/fabiovilao/portuguese-blogs","creator_name":"fabio vila","creator_url":"https://huggingface.co/fabiovilao","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","Portuguese","apache-2.0","100M - 1B","text"],"keywords_longer_than_N":true},
	{"name":"portuguese-blogs","keyword":"portuguese","description":"\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Details\n\t\n\nBlog-1 may include other languages in an unstructured text format without markdown. The latest one, Blog-6, is formatted in markdown and may contain less other languages text.\nTexts are separated by the string <|endoftext|>.\n\n\t\n\t\t\n\t\n\t\n\t\tUses\n\t\n\nTraining language models.\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Structure\n\t\n\nA simple text file with articles separated by <|endoftext|> between each text.\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Creation\n\t\n\nFirst semester of 2024.\n\n\t\n\t\t\n\t\n\t\n\t\tBias, Risksâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fabiovilao/portuguese-blogs.","url":"https://huggingface.co/datasets/fabiovilao/portuguese-blogs","creator_name":"fabio vila","creator_url":"https://huggingface.co/fabiovilao","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","Portuguese","apache-2.0","100M - 1B","text"],"keywords_longer_than_N":true},
	{"name":"Emakhuwa-Portuguese-OCR-post-correction","keyword":"portuguese","description":"BibTeX:\nThe dataset paper was published in EMNLP 2024.\nPlease cite as:\n@inproceedings{ali-etal-2024-building,\n    title = \"Building Resources for Emakhuwa: Machine Translation and News Classification Benchmarks\",\n    author = \"Ali, Felermino D. M. A.  and\n      Lopes Cardoso, Henrique  and\n      Sousa-Silva, Rui\",\n    editor = \"Al-Onaizan, Yaser  and\n      Bansal, Mohit  and\n      Chen, Yun-Nung\",\n    booktitle = \"Proceedings of the 2024 Conference on Empirical Methods in Natural Languageâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/LIACC/Emakhuwa-Portuguese-OCR-post-correction.","url":"https://huggingface.co/datasets/LIACC/Emakhuwa-Portuguese-OCR-post-correction","creator_name":"LIACC","creator_url":"https://huggingface.co/LIACC","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["translation","text-generation","Makhuwa","Portuguese","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"acordaos_filtrados_sem_duplicatas_sm","keyword":"portuguese","description":"sfreitascecilia/acordaos_filtrados_sem_duplicatas_sm dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/sfreitascecilia/acordaos_filtrados_sem_duplicatas_sm","creator_name":"CecÃ­lia de Souza Freitas","creator_url":"https://huggingface.co/sfreitascecilia","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["Portuguese","mit","< 1K","parquet","Text"],"keywords_longer_than_N":true},
	{"name":"brazilian-news-articles","keyword":"portuguese","description":"maikerdr/brazilian-news-articles dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/maikerdr/brazilian-news-articles","creator_name":"reis","creator_url":"https://huggingface.co/maikerdr","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-generation","text2text-generation","summarization","Portuguese","mit"],"keywords_longer_than_N":true},
	{"name":"AIME2025-Multilingual","keyword":"portuguese","description":"\n\t\n\t\t\n\t\tDescription\n\t\n\nThis repository contains a multi language version of the AIME2025 dataset. \nAs the english reference version, we haved used the one created by the authors of MathArena.\nFor completness, we have included the english version also in this repository, please, refer to the one contained in the MathArena github repository for the original one (https://github.com/eth-sri/matharena/tree/main/data/aime). Many thanks to Jasper Dekoninck for the help in understanding the structureâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fedric95/AIME2025-Multilingual.","url":"https://huggingface.co/datasets/fedric95/AIME2025-Multilingual","creator_name":"Federico Ricciuti","creator_url":"https://huggingface.co/fedric95","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["German","English","Italian","Portuguese","French"],"keywords_longer_than_N":true},
	{"name":"qa-portuguese-small","keyword":"portuguese","description":"\n\t\n\t\t\n\t\tQA-PORTUGUESE-SMALL\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe qa-portuguese-small dataset is a collection of 500,000 question-answer pairs in Portuguese designed for Question Answering (QA) tasks. The dataset includes questions based on a wide variety of domains, such as news, general knowledge, and everyday facts, and provides corresponding answers in natural language.\nThe dataset is intended for training and evaluating machine learning models that can answer questions in Portugueseâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Jpzinn654/qa-portuguese-small.","url":"https://huggingface.co/datasets/Jpzinn654/qa-portuguese-small","creator_name":"Juan Pablo","creator_url":"https://huggingface.co/Jpzinn654","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["question-answering","table-question-answering","Portuguese","mit","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"caramelo-emotions-v2","keyword":"portuguese","description":"Adilmar/caramelo-emotions-v2 dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/Adilmar/caramelo-emotions-v2","creator_name":"Adilmar Coelho Dantas","creator_url":"https://huggingface.co/Adilmar","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["Portuguese","cc-by-4.0","100K - 1M","parquet","Text"],"keywords_longer_than_N":true},
	{"name":"librivox-tracks","keyword":"portuguese","description":"A dataset of all audio files uploaded to LibriVox before 26th September 2023.\n","url":"https://huggingface.co/datasets/pykeio/librivox-tracks","creator_name":"pyke.io","creator_url":"https://huggingface.co/pykeio","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-to-speech","automatic-speech-recognition","Achinese","Afrikaans","Ancient Greek (to 1453)"],"keywords_longer_than_N":true},
	{"name":"coddef","keyword":"portuguese","description":"falabrasil/coddef dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/falabrasil/coddef","creator_name":"Grupo FalaBrasil","creator_url":"https://huggingface.co/falabrasil","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","Portuguese","mit","< 1K","webdataset"],"keywords_longer_than_N":true},
	{"name":"yodas-granary","keyword":"portuguese","description":"\n\t\n\t\t\n\t\tDataset Card for YODAS-Granary\n\t\n\n\nRepository: NeMo-speech-data-processor: Granary\nPaper: Granary: Speech Recognition and Translation Dataset in 25 European Languages\nShared by: ESPnet\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Description\n\t\n\nYODAS-Granary is a curated subset of the larger nvidia/Granary dataset, focusing on high-quality pseudo-labeled speech data for Automatic Speech Recognition (ASR) and Automatic Speech Translation (AST) across 23 European languages.\n\n\t\n\t\n\t\n\t\tOverviewâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/espnet/yodas-granary.","url":"https://huggingface.co/datasets/espnet/yodas-granary","creator_name":"ESPnet","creator_url":"https://huggingface.co/espnet","license_name":"Creative Commons Attribution 3.0","license_url":"https://scancode-licensedb.aboutcode.org/cc-by-3.0.html","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","translation","Bulgarian","Czech","Danish"],"keywords_longer_than_N":true},
	{"name":"fiNERweb","keyword":"portuguese","description":"fiNERweb is a multilingual named entity recognition dataset containing annotated text in multiple languages.\nEach example contains the original text, tokenized text, BIO tags, and character/token spans for entities.","url":"https://huggingface.co/datasets/whoisjones/fiNERweb","creator_name":"Jonas Golde","creator_url":"https://huggingface.co/whoisjones","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":null,"first_N":5,"first_N_keywords":["token-classification","named-entity-recognition","Vietnamese","Tamil","Oriya"],"keywords_longer_than_N":true},
	{"name":"historinhas","keyword":"portuguese","description":"\"Historinhas\" Ã© um dataset em portuguÃªs inspirado no TinyStories, desenvolvido para demonstrar que modelos de linguagem de menor escala podem gerar textos coerentes quando treinados em dados simplificados e de alta qualidade.\nEste conjunto de dados contÃ©m histÃ³rias curtas e simples em portuguÃªs, projetadas para serem compreensÃ­veis e adequadas para treinar modelos menores que ainda possam produzir narrativas coerentes e fluidas.\n","url":"https://huggingface.co/datasets/Boakpe/historinhas","creator_name":"Breno","creator_url":"https://huggingface.co/Boakpe","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","feature-extraction","zero-shot-classification","Portuguese","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"multilingual-text","keyword":"portuguese","description":"\n\t\n\t\t\n\t\tMultilingual Text Dataset\n\t\n\nThis dataset contains a curated selection of rows from multiple input datasets, where each row includes a text chunk of approximately 2000 tokens (as measured by Llama 3.1 tokenizer) verified to be written in the correct language. Only rows with properly classified language chunks are retained, ensuring high-quality multilingual data for analysis or model training.\n\n\t\n\t\t\n\t\tPreprocessing Steps\n\t\n\n\nNormalized whitespace, punctuation, Unicode characters, andâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/agentlans/multilingual-text.","url":"https://huggingface.co/datasets/agentlans/multilingual-text","creator_name":"Alan Tseng","creator_url":"https://huggingface.co/agentlans","license_name":"Open Data Commons Attribution License v1.0","license_url":"https://scancode-licensedb.aboutcode.org/odc-by-1.0.html","language":"en","first_N":5,"first_N_keywords":["text-generation","text-classification","Amharic","Arabic","Bengali"],"keywords_longer_than_N":true},
	{"name":"Rhulk_pt-br","keyword":"portuguese","description":"satierf/Rhulk_pt-br dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/satierf/Rhulk_pt-br","creator_name":"thiago freitas pimenta","creator_url":"https://huggingface.co/satierf","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-to-speech","text-generation","Portuguese","mit","< 1K"],"keywords_longer_than_N":true},
	{"name":"spsafe","keyword":"portuguese","description":"\n\t\n\t\t\n\t\tSPSafe Dataset\n\t\n\n\n\t\n\t\t\n\t\tAbout the Dataset\n\t\n\nSPSafe is a standardized dataset of crime incident reports registered in the state of SÃ£o Paulo, Brazil, from 2003 to 2022. This dataset was created to address and resolve issues of standardization, consistency, and heterogeneity found in the original data provided by the Secretariat of Public Security of the State of SÃ£o Paulo (SSP/SP).\nThe primary goal of SPSafe is to provide a high-quality, easy-to-use resource for public safetyâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/joaomjr/spsafe.","url":"https://huggingface.co/datasets/joaomjr/spsafe","creator_name":"Joao Marcos","creator_url":"https://huggingface.co/joaomjr","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["Portuguese","mit","100M<n<1B","ðŸ‡ºðŸ‡¸ Region: US","socioloy"],"keywords_longer_than_N":true},
	{"name":"Chatgpt","keyword":"portuguese","description":"\n\t\n\t\t\n\t\tOpenAssistant Conversations Dataset (OASST1)\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nIn an effort to democratize research on large-scale alignment, we release OpenAssistant \nConversations (OASST1), a human-generated, human-annotated assistant-style conversation \ncorpus consisting of 161,443 messages in 35 different languages, annotated with 461,292 \nquality ratings, resulting in over 10,000 fully annotated conversation trees. The corpus \nis a product of a worldwide crowd-sourcing effortâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/RajChat/Chatgpt.","url":"https://huggingface.co/datasets/RajChat/Chatgpt","creator_name":"Rajdeep Chatterjee ","creator_url":"https://huggingface.co/RajChat","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["English","Spanish","Russian","German","Polish"],"keywords_longer_than_N":true},
	{"name":"common_voice_22_0","keyword":"portuguese","description":"\n\t\n\t\t\n\t\tDataset Card for Common Voice Corpus 22.0\n\t\n\n\n\nThis dataset is an unofficial version of the Mozilla Common Voice Corpus 22. It was downloaded and converted from the project's website https://commonvoice.mozilla.org/.\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nAbkhaz, Albanian, Amharic, Arabic, Armenian, Assamese, Asturian, Azerbaijani, Basaa, Bashkir, Basque, Belarusian, Bengali, Breton, Bulgarian, Cantonese, Catalan, Central Kurdish, Chinese (China), Chinese (Hong Kong), Chinese (Taiwan), Chuvash, Czechâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fsicoli/common_voice_22_0.","url":"https://huggingface.co/datasets/fsicoli/common_voice_22_0","creator_name":"Fabio Sicoli","creator_url":"https://huggingface.co/fsicoli","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":null,"first_N":5,"first_N_keywords":["automatic-speech-recognition","Abkhaz","Afrikaans","Amharic","Arabic"],"keywords_longer_than_N":true},
	{"name":"bordirlines","keyword":"portuguese","description":"\n\t\n\t\t\n\t\tBordIRLines Dataset\n\t\n\nThis is the dataset associated with the paper \"BordIRlines: A Dataset for Evaluating Cross-lingual Retrieval-Augmented Generation\" (link).\nCode: https://github.com/manestay/bordIRlines\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThe BordIRLines Dataset is an information retrieval (IR) dataset constructed from various language corpora. It contains queries and corresponding ranked docs along with their relevance scores. The dataset includes multiple languages, including Englishâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/borderlines/bordirlines.","url":"https://huggingface.co/datasets/borderlines/bordirlines","creator_name":"cross-lingual LLMs and RAG","creator_url":"https://huggingface.co/borderlines","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":null,"first_N":5,"first_N_keywords":["question-answering","human","machine-generated","found","multilingual"],"keywords_longer_than_N":true},
	{"name":"drbodebench","keyword":"portuguese","description":"\n\t\n\t\t\n\t\tBenchmark Brasileiro de Testes de AptidÃ£o MÃ©dica: DrBodeBench (DBB)\n\t\n\n\n  \n\n\nEste conjunto de dados introduz um novo benchmark para avaliar modelos de linguagem grandes (LLMs) mÃ©dicos em portuguÃªs brasileiro, abordando uma lacuna crÃ­tica na avaliaÃ§Ã£o de IA para aplicaÃ§Ãµes de saÃºde em contextos nÃ£o ingleses. Ele Ã© construÃ­do a partir de testes de aptidÃ£o mÃ©dica brasileiros que abrangem o perÃ­odo de 2011-2025, incluindo o Exame Nacional de RevalidaÃ§Ã£o de Diplomas MÃ©dicos Expedidos porâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/recogna-nlp/drbodebench.","url":"https://huggingface.co/datasets/recogna-nlp/drbodebench","creator_name":"Recogna NLP","creator_url":"https://huggingface.co/recogna-nlp","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["Portuguese","apache-2.0","1K - 10K","json","Tabular"],"keywords_longer_than_N":true},
	{"name":"text_ratings","keyword":"portuguese","description":"Todo - Write dataset card\n","url":"https://huggingface.co/datasets/lightblue/text_ratings","creator_name":"Lightblue KK.","creator_url":"https://huggingface.co/lightblue","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["Amharic","Arabic","Bulgarian","Bengali","Czech"],"keywords_longer_than_N":true},
	{"name":"Brazilian_CLT_preferences","keyword":"portuguese","description":"Dataset DescriptionThis dataset contains 736 validated human-preference entries designed to align language models with expert expectations for answering questions about Brazilâ€™s Consolidation of Labor Laws (CLT). It was created to support Direct Preference Optimization (DPO) fine-tuning and evaluation of LLM-based legal assistants.\n\n\t\n\t\t\n\t\tIntended Use\n\t\n\n\nPrimary Purpose: Training and evaluating models for legal question answering under the Brazilian CLT framework.\nTarget Users: Researchersâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/ai-eldorado/Brazilian_CLT_preferences.","url":"https://huggingface.co/datasets/ai-eldorado/Brazilian_CLT_preferences","creator_name":"Eldorado Research Institute","creator_url":"https://huggingface.co/ai-eldorado","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["question-answering","Portuguese","mit","< 1K","json"],"keywords_longer_than_N":true},
	{"name":"Portuguese-audio-dataset","keyword":"portuguese","description":"\n\t\n\t\t\n\t\tPortuguese Voice Emotion Dataset\n\t\n\n*This dataset contains high-quality (â€œA-gradeâ€) data. It has been carefully curated, cleaned, and verified to ensure accuracy, completeness, and consistency, making it suitable for high-stakes or production-grade model training.\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset comprises high-quality Portuguese speech recordings designed for training and evaluating Speech Emotion Recognition (SER) models. The dataset contains voice samples expressing fourâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Kratos-AI/Portuguese-audio-dataset.","url":"https://huggingface.co/datasets/Kratos-AI/Portuguese-audio-dataset","creator_name":"KratosAI","creator_url":"https://huggingface.co/Kratos-AI","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["audio-classification","Portuguese","cc-by-4.0","< 1K","soundfolder"],"keywords_longer_than_N":true},
	{"name":"Portuguese-audio-dataset","keyword":"portuguese","description":"\n\t\n\t\t\n\t\tPortuguese Voice Emotion Dataset\n\t\n\n*This dataset contains high-quality (â€œA-gradeâ€) data. It has been carefully curated, cleaned, and verified to ensure accuracy, completeness, and consistency, making it suitable for high-stakes or production-grade model training.\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset comprises high-quality Portuguese speech recordings designed for training and evaluating Speech Emotion Recognition (SER) models. The dataset contains voice samples expressing fourâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Kratos-AI/Portuguese-audio-dataset.","url":"https://huggingface.co/datasets/Kratos-AI/Portuguese-audio-dataset","creator_name":"KratosAI","creator_url":"https://huggingface.co/Kratos-AI","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["audio-classification","Portuguese","cc-by-4.0","< 1K","soundfolder"],"keywords_longer_than_N":true},
	{"name":"europa","keyword":"portuguese","description":"\n\t\n\t\t\n\t\tDataset Card for EUROPA\n\t\n\nThis dataset card aims to be a base template for new datasets. It has been generated using this raw template.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nEUROPA is a dataset designed for training and evaluating multilingual keyphrase generation models in the legal domain. It consists of legal judgments from the Court of Justice of the European Union (EU) and includes instances in all 24 official EU languages.\nKey Features:\nMultilingual: Coversâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/NCube/europa.","url":"https://huggingface.co/datasets/NCube/europa","creator_name":"Neural Network Nomads (We are GLOSS)","creator_url":"https://huggingface.co/NCube","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["French","German","English","Italian","Dutch"],"keywords_longer_than_N":true},
	{"name":"xm3600","keyword":"portuguese","description":"\n\t\n\t\t\n\t\n\t\n\t\tXM3600 - Crossmodal-3600\n\t\n\n\n\t\n\t\t\n\t\n\t\n\t\tThis is a copy from https://google.github.io/crossmodal-3600/\n\t\n\nIf you use this dataset, please cite the original authors:\n@inproceedings{ThapliyalCrossmodal2022,\n  author = {Ashish Thapliyal and Jordi Pont-Tuset and Xi Chen and Radu Soricut},\n  title = {{Crossmodal-3600: A Massively Multilingual Multimodal Evaluation Dataset}},\n  booktitle = {EMNLP},\n  year = {2022}\n}\n\nIt also includes the image features as PIL Image and has a uniform andâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/floschne/xm3600.","url":"https://huggingface.co/datasets/floschne/xm3600","creator_name":"Flo Schneider","creator_url":"https://huggingface.co/floschne","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["image-to-text","Arabic","Bengali","Czech","Danish"],"keywords_longer_than_N":true},
	{"name":"xm3600_1k","keyword":"portuguese","description":"\n\t\n\t\t\n\t\n\t\n\t\tXM3600 - Crossmodal-3600 - 1K Split\n\t\n\n\n\t\n\t\t\n\t\n\t\n\t\tThis is a copy from https://google.github.io/crossmodal-3600/\n\t\n\nIf you use this dataset, please cite the original authors:\n@inproceedings{ThapliyalCrossmodal2022,\n  author = {Ashish Thapliyal and Jordi Pont-Tuset and Xi Chen and Radu Soricut},\n  title = {{Crossmodal-3600: A Massively Multilingual Multimodal Evaluation Dataset}},\n  booktitle = {EMNLP},\n  year = {2022}\n}\n\n\n\t\n\t\t\n\t\n\t\n\t\tThis is a 1K split of XM3600!\n\t\n\nFor this, weâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/floschne/xm3600_1k.","url":"https://huggingface.co/datasets/floschne/xm3600_1k","creator_name":"Flo Schneider","creator_url":"https://huggingface.co/floschne","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["image-to-text","Arabic","Bengali","Czech","Danish"],"keywords_longer_than_N":true},
	{"name":"praias_es_pt_dataset","keyword":"portuguese","description":"feserrm/praias_es_pt_dataset dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/feserrm/praias_es_pt_dataset","creator_name":"Felipe Serrano","creator_url":"https://huggingface.co/feserrm","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["translation","text-generation","Portuguese","Spanish","mit"],"keywords_longer_than_N":true},
	{"name":"English-French-Portuguese-Lexicon","keyword":"portuguese","description":"\n\t\n\t\t\n\t\tDemo Notebook for this dataset\n\t\n\n\nDataset created with Gemini-Flash-2.5 API with the prompt given below:\n\nGenerate a list of 500 simple and commonly used English words, each translated into French and Portuguese. Format the output as CSV with the columns: English, French, Portuguese. Only include single words (no phrases or verbs starting with â€˜toâ€™, like â€˜to eatâ€™ or â€˜to goâ€™). Avoid grammatical verbs and ensure no repetitions.\n\nExtensive manual cleaning was done with the help of Googleâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/MLap/English-French-Portuguese-Lexicon.","url":"https://huggingface.co/datasets/MLap/English-French-Portuguese-Lexicon","creator_name":"aman prakash","creator_url":"https://huggingface.co/MLap","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["English","French","Portuguese","mit","< 1K"],"keywords_longer_than_N":true},
	{"name":"mmarco-hard-negatives-reranker-score","keyword":"portuguese","description":"\nhotchpotch/mmarco-hard-negatives-reranker-score\n\nThis repository contains data from mMARCO scored using the reranker BAAI/bge-reranker-v2-m3.\n\n\t\n\t\t\n\t\tLanguages Covered\n\t\n\ntarget_languages = [\n    \"english\",\n    \"chinese\", \n    \"french\",\n    \"german\",\n    \"indonesian\",\n    \"italian\",\n    \"portuguese\",\n    \"russian\",\n    \"spanish\",\n    \"arabic\",\n    \"dutch\",\n    \"hindi\",\n    \"japanese\",\n    \"vietnamese\"\n]\n\n\n\t\n\t\t\n\t\tHard Negative Data\n\t\n\nThe hard negative data is derived fromâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/hotchpotch/mmarco-hard-negatives-reranker-score.","url":"https://huggingface.co/datasets/hotchpotch/mmarco-hard-negatives-reranker-score","creator_name":"Yuichi Tateno","creator_url":"https://huggingface.co/hotchpotch","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["English","Chinese","French","German","Indonesian"],"keywords_longer_than_N":true},
	{"name":"testedados","keyword":"portuguese","description":"MatheusFr/testedados dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/MatheusFr/testedados","creator_name":"Matheus Francisco","creator_url":"https://huggingface.co/MatheusFr","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","text-generation","Portuguese","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"aya_collection_language_split","keyword":"portuguese","description":"\nThis is a re-upload of the aya_collection, and only differs in the structure of upload. While the original aya_collection is structured by folders split according to dataset name, this dataset is split by language. We recommend you use this version of the dataset if you are only interested in downloading all of the Aya collection for a single or smaller set of languages.\n\n\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThe Aya Collection is a massive multilingual collection consisting of 513 million instances ofâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/CohereLabs/aya_collection_language_split.","url":"https://huggingface.co/datasets/CohereLabs/aya_collection_language_split","creator_name":"Cohere Labs","creator_url":"https://huggingface.co/CohereLabs","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["Achinese","Afrikaans","Amharic","Arabic","Azerbaijani"],"keywords_longer_than_N":true},
	{"name":"fineweb-edu-translated","keyword":"portuguese","description":"\n\t\n\t\t\n\t\tHelsinki-NLP/fineweb-edu-translated\n\t\n\nAutomatically translated documents from fineweb-edu. Translations are based on OPUS-MT and HPLT-MT models.\n","url":"https://huggingface.co/datasets/Helsinki-NLP/fineweb-edu-translated","creator_name":"Language Technology Research Group at the University of Helsinki","creator_url":"https://huggingface.co/Helsinki-NLP","license_name":"Open Data Commons Attribution License v1.0","license_url":"https://scancode-licensedb.aboutcode.org/odc-by-1.0.html","language":"en","first_N":5,"first_N_keywords":["text-generation","Bulgarian","Catalan","Czech","Danish"],"keywords_longer_than_N":true},
	{"name":"imatrix-calibration","keyword":"portuguese","description":"\n\t\n\t\t\n\t\tImportance Matrix Calibration Datasets\n\t\n\nThis repository contains calibration datasets used to generate importance matrices (imatrix), which in turn help minimise errors introduced during quantization.\n\n\t\n\t\t\n\t\tMath calibration datasets\n\t\n\nThis dataset consists of over 10M tokens of cleaned math prompts and is available in six sizes, ranging from huge (~ 430,000 lines equivalent to approx. 10M tokens), to micro (~ 13,700 lines and 1.7M tokens avg).\nOriginal data sourced fromâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/eaddario/imatrix-calibration.","url":"https://huggingface.co/datasets/eaddario/imatrix-calibration","creator_name":"Ed Addario","creator_url":"https://huggingface.co/eaddario","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-generation","Arabic","Chinese","German","English"],"keywords_longer_than_N":true},
	{"name":"lapsbm","keyword":"portuguese","description":"falabrasil/lapsbm dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/falabrasil/lapsbm","creator_name":"Grupo FalaBrasil","creator_url":"https://huggingface.co/falabrasil","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","Portuguese","mit","< 1K","webdataset"],"keywords_longer_than_N":true},
	{"name":"europa-random-split","keyword":"portuguese","description":"\n\t\n\t\t\n\t\tDataset Card for EUROPA\n\t\n\nThis dataset card aims to be a base template for new datasets. It has been generated using this raw template.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nEUROPA is a dataset designed for training and evaluating multilingual keyphrase generation models in the legal domain. It consists of legal judgments from the Court of Justice of the European Union (EU) and includes instances in all 24 official EU languages.\nKey Features:\nMultilingual: Coversâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/NCube/europa-random-split.","url":"https://huggingface.co/datasets/NCube/europa-random-split","creator_name":"Neural Network Nomads (We are GLOSS)","creator_url":"https://huggingface.co/NCube","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["French","German","English","Italian","Dutch"],"keywords_longer_than_N":true},
	{"name":"epfml-FineWeb2-HQ-sample","keyword":"portuguese","description":"\n\t\n\t\t\n\t\tepfml/FineWeb2-HQ\n\t\n\nA curated subset of the epfml/FineWeb2-HQ dataset featuring high-quality multilingual text.\n\n\t\n\t\t\n\t\tDetails\n\t\n\n\nFirst 25â€‰000 rows per config (language and script pair)\nDuplicates removed\nTexts truncated to 512 LLaMA 3.1 tokens\nScores transformed with log10\nRows shuffled and 20% of the rows split into the test set (stratified by config)\n\n\n\t\n\t\t\n\t\tExample\n\t\n\n{\n  \"text\": \"çˆµå£«å¤§å¸ˆTim Garland æ·±åœ³ä¸“åœº - [jazz]\\nTim Garland Lighthouseâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/agentlans/epfml-FineWeb2-HQ-sample.","url":"https://huggingface.co/datasets/agentlans/epfml-FineWeb2-HQ-sample","creator_name":"Alan Tseng","creator_url":"https://huggingface.co/agentlans","license_name":"Open Data Commons Attribution License v1.0","license_url":"https://scancode-licensedb.aboutcode.org/odc-by-1.0.html","language":"en","first_N":5,"first_N_keywords":["text-generation","Russian","Chinese","German","Japanese"],"keywords_longer_than_N":true},
	{"name":"BoundingDocs","keyword":"portuguese","description":"\n\nBoundingDocs\n\nðŸ” The largest spatially-annotated dataset for Document Question Answering\n\n\n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Description\n\t\n\nBoundingDocs is a unified dataset for Document Question Answering (QA) that includes spatial annotations. It consolidates multiple public datasets from Document AI and Visually Rich Document Understanding (VRDU) domains. The dataset reformulates Information Extraction (IE) tasks into QA tasks, making it a valuable resource for training and evaluating Large Languageâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/letxbe/BoundingDocs.","url":"https://huggingface.co/datasets/letxbe/BoundingDocs","creator_name":"Letxbe","creator_url":"https://huggingface.co/letxbe","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["question-answering","visual-question-answering","English","Italian","Spanish"],"keywords_longer_than_N":true},
	{"name":"InvoicesReceiptsPT","keyword":"portuguese","description":"This is a dataset comprising 1003 images of invoices and receipts, as well as the transcription of relevant fields for each document â€“ seller name, seller address, seller tax identification, buyer tax identification, invoice date, invoice total amount, invoice tax amount, and document reference. \nIt is organized as:\n\nfolder 1_Images: files with pictures od the invoices/receipts \nfolder 2_Annotations_Json: text files with the annotations on a json format\n\nAlso available at:â€¦ See the full description on the dataset page: https://huggingface.co/datasets/Francisco-Cruz/InvoicesReceiptsPT.","url":"https://huggingface.co/datasets/Francisco-Cruz/InvoicesReceiptsPT","creator_name":"Francisco Cruz","creator_url":"https://huggingface.co/Francisco-Cruz","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","Portuguese","apache-2.0","1K - 10K","imagefolder"],"keywords_longer_than_N":true},
	{"name":"exameneslatam","keyword":"portuguese","description":"entelai2017/exameneslatam dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/entelai2017/exameneslatam","creator_name":"Entelai","creator_url":"https://huggingface.co/entelai2017","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":null,"first_N":5,"first_N_keywords":["Spanish","Portuguese","mit","ðŸ‡ºðŸ‡¸ Region: US"],"keywords_longer_than_N":false},
	{"name":"Tatoeba-Translations","keyword":"portuguese","description":"\n\t\n\t\t\n\t\tDataset Details\n\t\n\nThis is the latest version of Tatoeba translations as of December 2024.\nThe sentences are downloaded from the Tatoeba collection website.\nThe dataset is processed through mapping sentences.tar.bz2 using sentences_base.tar.bz2 to find source (sentence_src) and target (sentence_tgt) sentences.\nWhile lang_src and lang_tgt columns follow the mapping provided by Tatoeba, the lang_pair column merely lists the two languages in the translation pair.\n\n\t\n\t\t\n\t\n\t\n\t\tStatisticsâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/ymoslem/Tatoeba-Translations.","url":"https://huggingface.co/datasets/ymoslem/Tatoeba-Translations","creator_name":"Yasmin Moslem","creator_url":"https://huggingface.co/ymoslem","license_name":"Creative Commons Attribution 2.0","license_url":"https://scancode-licensedb.aboutcode.org/cc-by-2.0.html","language":"en","first_N":5,"first_N_keywords":["translation","multilingual","Abkhaz","Afrikaans","Amharic"],"keywords_longer_than_N":true},
	{"name":"Kurtis-E1-Multilingual-01-SFT","keyword":"portuguese","description":"ethicalabs/Kurtis-E1-Multilingual-01-SFT dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/ethicalabs/Kurtis-E1-Multilingual-01-SFT","creator_name":"ethicalabs.ai","creator_url":"https://huggingface.co/ethicalabs","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["English","Italian","Spanish","French","Portuguese"],"keywords_longer_than_N":true},
	{"name":"HateBR","keyword":"portuguese","description":"\n\t\n\t\t\n\t\tHateBR: The Evaluation Benchmark for Brazilian Portuguese Hate Speech Detection\n\t\n\nHateBR is the first large-scale, expert-annotated dataset of Brazilian Instagram comments specifically designed for hate speech detection on the web and social media. The dataset was collected from Brazilian Instagram comments made by politicians and manually annotated by specialists.\nIt contains 7,000 documents, annotated across three distinct layers:\nBinary classification (offensive vs. non-offensiveâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/franciellevargas/HateBR.","url":"https://huggingface.co/datasets/franciellevargas/HateBR","creator_name":"Francielle Vargas","creator_url":"https://huggingface.co/franciellevargas","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","Portuguese","apache-2.0","1K - 10K","csv"],"keywords_longer_than_N":true},
	{"name":"librispeech_pt","keyword":"portuguese","description":"murilo-as/librispeech_pt dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/murilo-as/librispeech_pt","creator_name":"Murilo Alvares Silva","creator_url":"https://huggingface.co/murilo-as","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["Portuguese","cc0-1.0","< 1K","soundfolder","Audio"],"keywords_longer_than_N":true},
	{"name":"biblenlp-corpus","keyword":"portuguese","description":"\n\t\n\t\t\n\t\tDataset Card for BibleNLP Corpus\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nPartial and complete Bible translations in 833 languages, aligned by verse.\n\n\t\n\t\t\n\t\tLanguages\n\t\n\naai, aak, aau, aaz, abt, abx, aby, acf, acr, acu, adz, aer, aey, agd, agg, agm, agn, agr, agt, agu, aia, aii, aka, ake, alp, alq, als, aly, ame, amf, amk, amm, amn, amo, amp, amr, amu, amx, anh, anv, aoi, aoj, aom, aon, apb, ape, apn, apr, apu, apw, apz, arb, are, arl, arn, arp, asm, aso, ata, atb, atd, atg, att, auc, aui, auyâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/bible-nlp/biblenlp-corpus.","url":"https://huggingface.co/datasets/bible-nlp/biblenlp-corpus","creator_name":"The Partnership for Applied Biblical NLP","creator_url":"https://huggingface.co/bible-nlp","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":null,"first_N":5,"first_N_keywords":["translation","no-annotation","expert-generated","translation","multilingual"],"keywords_longer_than_N":true},
	{"name":"HashtagPrediction","keyword":"portuguese","description":"\n\t\n\t\t\n\t\tHashtag Prediction Dataset from paper TwHIN-BERT: A Socially-Enriched Pre-trained Language Model for Multilingual Tweet Representations\n\t\n\n  \nThis repo contains the Hashtag prediction dataset from our paper TwHIN-BERT: A Socially-Enriched Pre-trained Language Model for Multilingual Tweet Representations. \n[arXiv][HuggingFace Models]\n[Github repo]\nThis work is licensed under a Creative Commons Attribution 4.0 International License.\n\n\t\n\t\t\n\t\n\t\n\t\tDownload\n\t\n\nUse theâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Twitter/HashtagPrediction.","url":"https://huggingface.co/datasets/Twitter/HashtagPrediction","creator_name":"Twitter","creator_url":"https://huggingface.co/Twitter","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["Slovenian","Urdu","Sindhi","Polish","Vietnamese"],"keywords_longer_than_N":true},
	{"name":"aes_enem_dataset","keyword":"portuguese","description":"\n\t\n\t\t\n\t\tAutomated Essay Score (AES) ENEM Dataset\n\t\n\n\n\t\n\t\t\n\t\tUse Case and Creators\n\t\n\n\nIntended Use: Estimate Essay Score\nCreators: Igor Cataneo Silveira, AndrÃ© Barbosa and Denis Deratani MauÃ¡\nContact Information:  igorcs@ime.usp.br; andre.barbosa@ime.usp.br\n\n\n\t\n\t\t\n\t\tLicensing Information\n\t\n\n\nLicense: MIT License\n\n\n\t\n\t\t\n\t\tCitation Details\n\t\n\n\nPreferred Citation:\n\n@proceedings{DBLP:conf/propor/2024,\n  editor       = {Igor Cataneo Silveira, AndrÃ© Barbosa and Denis Deratani MauÃ¡},\n  title        =â€¦ See the full description on the dataset page: https://huggingface.co/datasets/kamel-usp/aes_enem_dataset.","url":"https://huggingface.co/datasets/kamel-usp/aes_enem_dataset","creator_name":"KAMeL USP","creator_url":"https://huggingface.co/kamel-usp","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","Portuguese","apache-2.0","1K - 10K","parquet"],"keywords_longer_than_N":true},
	{"name":"bernice-pretrain-data","keyword":"portuguese","description":"Tweet IDs for the 2.5 billion multilingual tweets used to train Bernice, a Twitter encoder.\nThe tweets are from the public 1% Twitter API stream from January 2016 to December 2021. \nTwitter-provided language metadata is provided with the tweet ID. The data contains 66 unique languages, \nas identified by ISO 639 language codes, including `und` for undefined languages.\nTweets need to be re-gathered via the Twitter API.","url":"https://huggingface.co/datasets/jhu-clsp/bernice-pretrain-data","creator_name":"Center for Language and Speech Processing @ JHU","creator_url":"https://huggingface.co/jhu-clsp","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":null,"first_N":5,"first_N_keywords":["other","no-annotation","found","multilingual","original"],"keywords_longer_than_N":true},
	{"name":"ChatML-aya_dataset","keyword":"portuguese","description":"CohereForAI/aya_dataset in ChatML format, ready to use in HuggingFace TRL's SFT Trainer.\nPython code used for conversion:\nfrom datasets import load_dataset\nfrom transformers import AutoTokenizer\n\ntokenizer = AutoTokenizer.from_pretrained(\"Felladrin/Llama-160M-Chat-v1\")\n\ndataset = load_dataset(\"CohereForAI/aya_dataset\", split=\"train\")\n\ndef format(columns):\n    messages = [\n        {\n            \"role\": \"user\",\n            \"content\": columns[\"inputs\"].strip(),\n        },\n        {â€¦ See the full description on the dataset page: https://huggingface.co/datasets/Felladrin/ChatML-aya_dataset.","url":"https://huggingface.co/datasets/Felladrin/ChatML-aya_dataset","creator_name":"Victor Nogueira","creator_url":"https://huggingface.co/Felladrin","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["question-answering","text-generation","crowdsourced","expert-generated","crowdsourced"],"keywords_longer_than_N":true},
	{"name":"aya_dataset_pt","keyword":"portuguese","description":"CohereForAI Aya Dataset filtrado para portuguÃªs (PT).\nAya Dataset Summary\nThe Aya Dataset is a multilingual instruction fine-tuning dataset curated by an open-science community via Aya Annotation Platform from Cohere For AI. The dataset contains a total of 204k human-annotated prompt-completion pairs along with the demographics data of the annotators.\nThis dataset can be used to train, finetune, and evaluate multilingual LLMs.\nCurated by: Contributors of Aya Open Science Intiative.â€¦ See the full description on the dataset page: https://huggingface.co/datasets/botbotrobotics/aya_dataset_pt.","url":"https://huggingface.co/datasets/botbotrobotics/aya_dataset_pt","creator_name":"BotBot","creator_url":"https://huggingface.co/botbotrobotics","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["Portuguese","apache-2.0","1K - 10K","parquet","Text"],"keywords_longer_than_N":true},
	{"name":"aya_dataset_pt","keyword":"portuguese","description":"CohereForAI Aya Dataset filtrado para portuguÃªs (PT).\nAya Dataset Summary\nThe Aya Dataset is a multilingual instruction fine-tuning dataset curated by an open-science community via Aya Annotation Platform from Cohere For AI. The dataset contains a total of 204k human-annotated prompt-completion pairs along with the demographics data of the annotators.\nThis dataset can be used to train, finetune, and evaluate multilingual LLMs.\nCurated by: Contributors of Aya Open Science Intiative.â€¦ See the full description on the dataset page: https://huggingface.co/datasets/botbotrobotics/aya_dataset_pt.","url":"https://huggingface.co/datasets/botbotrobotics/aya_dataset_pt","creator_name":"BotBot","creator_url":"https://huggingface.co/botbotrobotics","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["Portuguese","apache-2.0","1K - 10K","parquet","Text"],"keywords_longer_than_N":true},
	{"name":"MMMLU","keyword":"portuguese","description":"\n\t\n\t\t\n\t\tMultilingual Massive Multitask Language Understanding (MMMLU)\n\t\n\nThe MMLU is a widely recognized benchmark of general knowledge attained by AI models. It covers a broad range of topics from 57 different categories, covering elementary-level knowledge up to advanced professional subjects like law, physics, history, and computer science.\nWe translated the MMLUâ€™s test set into 14 languages using professional human translators. Relying on human translators for this evaluation increasesâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/openai/MMMLU.","url":"https://huggingface.co/datasets/openai/MMMLU","creator_name":"OpenAI","creator_url":"https://huggingface.co/openai","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["question-answering","Arabic","Bengali","German","Spanish"],"keywords_longer_than_N":true},
	{"name":"lextreme","keyword":"portuguese","description":"The LEXTREME Benchmark is a collection of multilingual datasets for evaluating model performance \nacross a diverse set of legal NLU tasks.","url":"https://huggingface.co/datasets/joelniklaus/lextreme","creator_name":"Joel Niklaus","creator_url":"https://huggingface.co/joelniklaus","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","multi-class-classification","multi-label-classification","topic-classification"],"keywords_longer_than_N":true},
	{"name":"FakeRecogna","keyword":"portuguese","description":"\n\t\n\t\t\n\t\tFakeRecogna\n\t\n\nFakeRecogna is a dataset comprised of real and fake news. The real news is not directly linked to fake news and vice-versa, which could lead to a biased classification. The news collection was performed by crawlers developed for mining pages of well-known and of great national importance agency news. The web crawlers were developed based on each analyzed webpage, where the extracted information is first separated into categories and then grouped by dates. The pluralityâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/recogna-nlp/FakeRecogna.","url":"https://huggingface.co/datasets/recogna-nlp/FakeRecogna","creator_name":"Recogna NLP","creator_url":"https://huggingface.co/recogna-nlp","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","Portuguese","mit","10K - 100K","csv"],"keywords_longer_than_N":true},
	{"name":"FakeRecogna","keyword":"portuguese","description":"\n\t\n\t\t\n\t\tFakeRecogna\n\t\n\nFakeRecogna is a dataset comprised of real and fake news. The real news is not directly linked to fake news and vice-versa, which could lead to a biased classification. The news collection was performed by crawlers developed for mining pages of well-known and of great national importance agency news. The web crawlers were developed based on each analyzed webpage, where the extracted information is first separated into categories and then grouped by dates. The pluralityâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/recogna-nlp/FakeRecogna.","url":"https://huggingface.co/datasets/recogna-nlp/FakeRecogna","creator_name":"Recogna NLP","creator_url":"https://huggingface.co/recogna-nlp","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","Portuguese","mit","10K - 100K","csv"],"keywords_longer_than_N":true},
	{"name":"harem","keyword":"portuguese","description":"\n\t\n\t\t\n\t\tDataset Card for HAREM\n\t\n\n\n\n\n\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\n\n\n\n\n\nCurated by: [More Information Needed]\nFunded by [optional]: [More Information Needed]\nShared by [optional]: [More Information Needed]\nLanguage(s) (NLP): pt\nLicense: cc-by-4.0\n\n\n\t\n\t\t\n\t\tDataset Sources [optional]\n\t\n\n\n\n\nRepository: [More Information Needed]\nPaper [optional]: [More Information Needed]\nDemo [optional]: [More Information Needed]\n\n\n\t\n\t\t\n\t\tUses\n\t\n\n\n\n\n\t\n\t\t\n\t\tDirect Use\n\t\n\n\n\n[Moreâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/arubenruben/harem.","url":"https://huggingface.co/datasets/arubenruben/harem","creator_name":"RÃºben Almeida","creator_url":"https://huggingface.co/arubenruben","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["token-classification","expert-generated","monolingual","Portuguese","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"MLDR","keyword":"portuguese","description":"\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nMLDR is a Multilingual Long-Document Retrieval dataset built on Wikipeida, Wudao and mC4, covering 13 typologically diverse languages. Specifically, we sample lengthy articles from Wikipedia, Wudao and mC4 datasets and randomly choose paragraphs from them. Then we use GPT-3.5 to generate questions based on these paragraphs. The generated question and the sampled article constitute a new text pair to the dataset. The prompt for GPT3.5 is â€œYou are a curious AIâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Shitao/MLDR.","url":"https://huggingface.co/datasets/Shitao/MLDR","creator_name":"Xiao","creator_url":"https://huggingface.co/Shitao","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":null,"first_N":5,"first_N_keywords":["text-retrieval","multilingual","Arabic","German","English"],"keywords_longer_than_N":true},
	{"name":"xtr-wiki_qa","keyword":"portuguese","description":"\n\t\n\t\t\n\t\tXtr-WikiQA\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nXtr-WikiQA is an Answer Sentence Selection (AS2) dataset in 9 non-English languages, proposed in our paper accepted at ACL 2023 (Findings): Cross-Lingual Knowledge Distillation for Answer Sentence Selection in Low-Resource Languages.\nThis dataset is based on an English AS2 dataset, WikiQA (Original, Hugging Face).\nFor translations, we used Amazon Translate.\n\n\t\n\t\t\n\t\n\t\n\t\tLanguages\n\t\n\n\nArabic (ar)\nSpanish (es)\nFrench (fr)\nGerman (de)\nHindi (hi)â€¦ See the full description on the dataset page: https://huggingface.co/datasets/AmazonScience/xtr-wiki_qa.","url":"https://huggingface.co/datasets/AmazonScience/xtr-wiki_qa","creator_name":"Amazon Science","creator_url":"https://huggingface.co/AmazonScience","license_name":"Community Data License Agreement Permissive 2.0","license_url":"https://scancode-licensedb.aboutcode.org/cdla-permissive-2.0.html","language":"en","first_N":5,"first_N_keywords":["question-answering","text-retrieval","open-domain-qa","machine-generated","found"],"keywords_longer_than_N":true},
	{"name":"multilingual-sentiments","keyword":"portuguese","description":"\n\t\n\t\t\n\t\tMultilingual Sentiments Dataset\n\t\n\nA collection of multilingual sentiments datasets grouped into 3 classes -- positive, neutral, negative.\nMost multilingual sentiment datasets are either 2-class positive or negative, 5-class ratings of products reviews (e.g. Amazon multilingual dataset) or multiple classes of emotions. However, to an average person, sometimes positive, negative and neutral classes suffice and are more straightforward to perceive and annotate. Also, a positive/negativeâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/tyqiangz/multilingual-sentiments.","url":"https://huggingface.co/datasets/tyqiangz/multilingual-sentiments","creator_name":"Tay Yong Qiang","creator_url":"https://huggingface.co/tyqiangz","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","sentiment-analysis","sentiment-classification","monolingual","multilingual"],"keywords_longer_than_N":true},
	{"name":"opus_books_en_pt","keyword":"portuguese","description":"How to use it: \nfrom datasets import load_dataset\nremote_dataset = load_dataset(\"VanessaSchenkel/opus_books_en_pt\", field=\"data\")\nremote_dataset\n\nOutput:\nDatasetDict({\n    train: Dataset({\n        features: ['id', 'translation'],\n        num_rows: 1404\n    })\n})\n\nExemple: \nremote_dataset[\"train\"][5]\n\nOutput:\n{'id': '5',\n 'translation': {'en': \"There was nothing so very remarkable in that; nor did Alice think it so very much out of the way to hear the Rabbit say to itself, 'Oh dear!\",\n  'pt':â€¦ See the full description on the dataset page: https://huggingface.co/datasets/VanessaSchenkel/opus_books_en_pt.","url":"https://huggingface.co/datasets/VanessaSchenkel/opus_books_en_pt","creator_name":"Vanessa Schramm Schenkel Da Silva","creator_url":"https://huggingface.co/VanessaSchenkel","license_name":"Academic Free License v3.0","license_url":"https://choosealicense.com/licenses/afl-3.0/","language":"en","first_N":5,"first_N_keywords":["translation","found","found","translation","extended|opus_books"],"keywords_longer_than_N":true},
	{"name":"text_coordinates_regions","keyword":"portuguese","description":"\n\t\n\t\t\n\t\tDataset Card for Multilingual Geo-Tagged Social Media Posts (by 123 world regions)\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThe \"Regions\" dataset is a multilingual corpus that encompasses textual data from the 123 most populated regions worldwide, with each region's data organized into separate .json files. This dataset consists of approximately 500,000 text samples, each paired with its geographic coordinates.\nKey Features:\n\nTextual Data: The dataset contains 500,000 text samples.â€¦ See the full description on the dataset page: https://huggingface.co/datasets/yachay/text_coordinates_regions.","url":"https://huggingface.co/datasets/yachay/text_coordinates_regions","creator_name":"Yachay AI","creator_url":"https://huggingface.co/yachay","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","token-classification","text-classification","English","Chinese"],"keywords_longer_than_N":true},
	{"name":"qa_hotel_dataset","keyword":"portuguese","description":"nova-sqoin/qa_hotel_dataset dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/nova-sqoin/qa_hotel_dataset","creator_name":"nova","creator_url":"https://huggingface.co/nova-sqoin","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["question-answering","English","Portuguese","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"jurisprudencia_tr_pt","keyword":"portuguese","description":"\n\t\n\t\t\n\t\tDataset de JurisprudÃªncia dos TR de Portugal (2025)\n\t\n\n\n\t\n\t\t\n\t\tDescriÃ§Ã£o do Dataset\n\t\n\nEste dataset contÃ©m uma amostra de acÃ³rdÃ£os proferidos pelos Tribunais da RelaÃ§Ã£o (TR) de Portugal durante o ano de 2025. Inclui decisÃµes dos tribunais de Lisboa (TRL), Porto (TRP), Coimbra (TRC), Ã‰vora (TRE) e GuimarÃ£es (TRG). Cada registo no dataset corresponde a um acÃ³rdÃ£o completo, incluindo o seu texto integral, o sumÃ¡rio e um conjunto de metadados ricos.\nOs dados representam uma amostraâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/ffantini/jurisprudencia_tr_pt.","url":"https://huggingface.co/datasets/ffantini/jurisprudencia_tr_pt","creator_name":"Fernando Neto","creator_url":"https://huggingface.co/ffantini","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["Portuguese","cc-by-4.0","< 1K","parquet","Text"],"keywords_longer_than_N":true},
	{"name":"multilingual_librispeech","keyword":"portuguese","description":"\n\t\n\t\t\n\t\tDataset Card for MultiLingual LibriSpeech\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis is a streamable version of the Multilingual LibriSpeech (MLS) dataset. \nThe data archives were restructured from the original ones from OpenSLR to make it easier to stream.\nMLS dataset is a large multilingual corpus suitable for speech research. The dataset is derived from read audiobooks from LibriVox and consists of \n8 languages - English, German, Dutch, Spanish, French, Italian, Portuguese, Polish. Itâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/facebook/multilingual_librispeech.","url":"https://huggingface.co/datasets/facebook/multilingual_librispeech","creator_name":"AI at Meta","creator_url":"https://huggingface.co/facebook","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","text-to-audio","expert-generated","crowdsourced"],"keywords_longer_than_N":true},
	{"name":"instruct-aira-dataset","keyword":"portuguese","description":"\n\t\n\t\t\n\t\tInstruct-Aira Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset contains a collection of prompts and responses to those prompts. All completions were generated by querying already-tuned models (ChatGPT, LLama 2, Open-Assistant, etc.). The dataset is available in Portuguese, English, and Spanish.\n\n\t\n\t\t\n\t\tSupported Tasks and Leaderboards\n\t\n\nThis dataset can be utilized for various natural language processing tasks, including but not limited to:\n\nLanguage modeling.\nQuestion-answeringâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/nicholasKluge/instruct-aira-dataset.","url":"https://huggingface.co/datasets/nicholasKluge/instruct-aira-dataset","creator_name":"Nicholas Kluge CorrÃªa","creator_url":"https://huggingface.co/nicholasKluge","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","Portuguese","English","Spanish","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"mfaq","keyword":"portuguese","description":"We present the first multilingual FAQ dataset publicly available. We collected around 6M FAQ pairs from the web, in 21 different languages.","url":"https://huggingface.co/datasets/clips/mfaq","creator_name":"CLiPS","creator_url":"https://huggingface.co/clips","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["question-answering","multiple-choice-qa","no-annotation","other","multilingual"],"keywords_longer_than_N":true},
	{"name":"qa-ptpt","keyword":"portuguese","description":"\n\t\n\t\t\n\t\tDataset Card for Dataset Name\n\t\n\n\n\nPortuguese preprocessed split from MQA dataset containing only the question_title and answer_text columns of records in the \".pt\" domain.\nThe dataset was derived by filtering the following dataset: ju-resplande/qa-pt\nThe rationale is to have a dataset that is closer aligned with the Portuguese (Portugal) language.\nThe same license as both upstream datasets is used: Creative Commons Zero v1.0 Universal.\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Detailsâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/marquesafonso/qa-ptpt.","url":"https://huggingface.co/datasets/marquesafonso/qa-ptpt","creator_name":"Afonso Marques","creator_url":"https://huggingface.co/marquesafonso","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["question-answering","Portuguese","cc0-1.0","1M - 10M","parquet"],"keywords_longer_than_N":true},
	{"name":"Open_Assistant_Conversation_Chains","keyword":"portuguese","description":"\n\t\n\t\t\n\t\tDataset Card for Dataset Name\n\t\n\n\n\t\n\t\t\n\t\tDataset description\n\t\n\n\n\nThis dataset is a reformatting of OpenAssistant Conversations (OASST1), which is\n\na human-generated, human-annotated assistant-style conversation corpus consisting of 161,443 messages in 35 different languages, annotated with 461,292 quality ratings, resulting in over 10,000 fully annotated conversation trees. The corpus is a product of a worldwide crowd-sourcing effort involving over 13,500 volunteers.\n\nIt was modifiedâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/m-ric/Open_Assistant_Conversation_Chains.","url":"https://huggingface.co/datasets/m-ric/Open_Assistant_Conversation_Chains","creator_name":"Aymeric Roucher","creator_url":"https://huggingface.co/m-ric","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","English","Spanish","Russian","German"],"keywords_longer_than_N":true},
	{"name":"legal-mc4","keyword":"portuguese","description":"Legal-MC4: A Corpus Covering the Legal Part of MC4 for European Languages","url":"https://huggingface.co/datasets/joelniklaus/legal-mc4","creator_name":"Joel Niklaus","creator_url":"https://huggingface.co/joelniklaus","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["fill-mask","other","found","multilingual","original"],"keywords_longer_than_N":true},
	{"name":"TuPyE-Dataset","keyword":"portuguese","description":"\n\t\n\t\t\n\t\tPortuguese Hate Speech Expanded Dataset (TuPyE)\n\t\n\nTuPyE, an enhanced iteration of TuPy, encompasses a compilation of 43,668 meticulously annotated documents specifically \nselected for the purpose of hate speech detection within diverse social network contexts. \nThis augmented dataset integrates supplementary annotations and amalgamates with datasets sourced from \nFortuna et al. (2019), \nLeite et al. (2020), \nand Vargas et al. (2022),\ncomplemented by an infusion of 10,000 originalâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Silly-Machine/TuPyE-Dataset.","url":"https://huggingface.co/datasets/Silly-Machine/TuPyE-Dataset","creator_name":"Silly-Machine","creator_url":"https://huggingface.co/Silly-Machine","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","crowdsourced","crowdsourced","monolingual","crowdsourced"],"keywords_longer_than_N":true},
	{"name":"ggml-vicuna-v0-quantized","keyword":"portuguese","description":"These are quantized ggml binary files for vicuna 7B and 13B models. The version of vicuna for these models are v0.\nThese files can be used in conjunction with minigpt4 ggml models 7B and 13B in minigpt4.cpp\nRecommended are the Q5_K and Q6_K implementations. If there are any issues, use Q4_1 or Q4_0.\n\n\n\t\n\t\t\n\t\n\t\n\t\tVicuna Model Card\n\t\n\n\n\t\n\t\t\n\t\n\t\n\t\tModel details\n\t\n\nModel type:\nVicuna is an open-source chatbot trained by fine-tuning LLaMA on user-shared conversations collected from ShareGPT.\nIt isâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/maknee/ggml-vicuna-v0-quantized.","url":"https://huggingface.co/datasets/maknee/ggml-vicuna-v0-quantized","creator_name":"maknee","creator_url":"https://huggingface.co/maknee","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["English","Bulgarian","Catalan","Czech","Danish"],"keywords_longer_than_N":true},
	{"name":"ParlaMint3","keyword":"portuguese","description":"ParlaMint 3.0 is a multilingual set of 26 comparable corpora containing parliamentary debates mostly starting in 2015 and extending to mid-2022. \nThe corpora have extensive metadata, including aspects of the parliament; the speakers (name, gender, MP status, party affiliation, party coalition/opposition); \nare structured into time-stamped terms, sessions and meetings; and with speeches being marked by the speaker and their role (e.g. chair, regular speaker). \nThe speeches also contain marked-up transcriber comments, such as gaps in the transcription, interruptions, applause, etc. \nNote that some corpora have further information, e.g. the year of birth of the speakers, links to their Wikipedia articles, their membership in various committees, etc. \nThe corpora are also marked to the subcorpus they belong to (\"reference\", until 2020-01-30, \"covid\", from 2020-01-31, and \"war\", from 2022-02-24). \nThe corpora are encoded according to the Parla-CLARIN TEI recommendation (https://clarin-eric.github.io/parla-clarin/), but have been encoded against the compatible, \nbut much stricter ParlaMint encoding guidelines (https://clarin-eric.github.io/ParlaMint/) and schemas (included in this distribution). \nThis entry contains the ParlaMint TEI-encoded corpora with the derived plain text versions of the corpora along with TSV metadata of the speeches. \nAlso included is the 3.0 release of the data and scripts available at the GitHub repository of the ParlaMint project.","url":"https://huggingface.co/datasets/cjvt/ParlaMint3","creator_name":"Center za jezikovne vire in tehnologije Univerze v Ljubljani","creator_url":"https://huggingface.co/cjvt","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":null,"first_N":5,"first_N_keywords":["other","multilingual","Slovenian","German","Bosnian"],"keywords_longer_than_N":true},
	{"name":"europa_eac_tm","keyword":"portuguese","description":"\n\t\n\t\t\n\t\tDataset Card for Europa Education and Culture Translation Memory (EAC-TM)\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset is a corpus of manually produced translations from english to up to 25 languages, released in 2012 by the European Union's Directorate General for Education and Culture (EAC).\nTo load a language pair that is not part of the config, just specify the language code as language pair. For example, if you want to translate Czech to Greek:\ndataset = load_dataset(\"europa_eac_tm\"â€¦ See the full description on the dataset page: https://huggingface.co/datasets/community-datasets/europa_eac_tm.","url":"https://huggingface.co/datasets/community-datasets/europa_eac_tm","creator_name":"Community Datasets","creator_url":"https://huggingface.co/community-datasets","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["translation","expert-generated","expert-generated","translation","original"],"keywords_longer_than_N":true},
	{"name":"multilingual_librispeech","keyword":"portuguese","description":"Multilingual LibriSpeech (MLS) dataset is a large multilingual corpus suitable for speech research. The dataset is derived from read audiobooks from LibriVox and consists of 8 languages - English, German, Dutch, Spanish, French, Italian, Portuguese, Polish.","url":"https://huggingface.co/datasets/legacy-datasets/multilingual_librispeech","creator_name":"Legacy Datasets","creator_url":"https://huggingface.co/legacy-datasets","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":null,"first_N":5,"first_N_keywords":["automatic-speech-recognition","audio-classification","speaker-identification","expert-generated","crowdsourced"],"keywords_longer_than_N":true},
	{"name":"eur-lex-sum","keyword":"portuguese","description":"The EUR-Lex-Sum dataset is a multilingual resource intended for text summarization in the legal domain.\nIt is based on human-written summaries of legal acts issued by the European Union.\nIt distinguishes itself by introducing a smaller set of high-quality human-written samples,\neach of which have much longer references (and summaries!) than comparable datasets.\nAdditionally, the underlying legal acts provide a challenging domain-specific application to legal texts,\nwhich are so far underrepresented in non-English languages.\nFor each legal act, the sample can be available in up to 24 languages\n(the officially recognized languages in the European Union);\nthe validation and test samples consist entirely of samples available in all languages,\nand are aligned across all languages at the paragraph level.","url":"https://huggingface.co/datasets/dennlinger/eur-lex-sum","creator_name":"Dennis Aumiller","creator_url":"https://huggingface.co/dennlinger","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":null,"first_N":5,"first_N_keywords":["translation","summarization","found","expert-generated","found"],"keywords_longer_than_N":true},
	{"name":"ptbr-deita-8k","keyword":"portuguese","description":"\n\t\n\t\t\n\t\tPTBR Deita 8k\n\t\n\nPortuguese translation of the Deita 8k dataset. \n","url":"https://huggingface.co/datasets/botbotrobotics/ptbr-deita-8k","creator_name":"BotBot","creator_url":"https://huggingface.co/botbotrobotics","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["Portuguese","apache-2.0","1K - 10K","json","Text"],"keywords_longer_than_N":true},
	{"name":"PortugueseLegalSentences-v2","keyword":"portuguese","description":"\n\t\n\t\t\n\t\tPortuguese Legal Sentences\n\t\n\nCollection of Legal Sentences from the Portuguese Supreme Court of Justice\nThe goal of this dataset was to be used for MLM and TSDAE\nExtended version of rufimelo/PortugueseLegalSentences-v1\n200000/200000/100000\n\n\t\n\t\t\n\t\tContributions\n\t\n\n@rufimelo99\n","url":"https://huggingface.co/datasets/rufimelo/PortugueseLegalSentences-v2","creator_name":"Rui Melo","creator_url":"https://huggingface.co/rufimelo","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["no-annotation","found","monolingual","original","Portuguese"],"keywords_longer_than_N":true},
	{"name":"EU_Wikipedias","keyword":"portuguese","description":"Wikipedia dataset containing cleaned articles of all languages.\nThe datasets are built from the Wikipedia dump\n(https://dumps.wikimedia.org/) with one split per language. Each example\ncontains the content of one full Wikipedia article with cleaning to strip\nmarkdown and unwanted sections (references, etc.).","url":"https://huggingface.co/datasets/joelniklaus/EU_Wikipedias","creator_name":"Joel Niklaus","creator_url":"https://huggingface.co/joelniklaus","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["fill-mask","other","found","multilingual","original"],"keywords_longer_than_N":true},
	{"name":"nllb-200-10M-sample","keyword":"portuguese","description":"\n\t\n\t\t\n\t\tDataset Card for \"nllb-200-10M-sample\"\n\t\n\nThis is a sample of nearly 10M sentence pairs from the NLLB-200 \nmined dataset allenai/nllb, \nscored with the model facebook/blaser-2.0-qe \ndescribed in the SeamlessM4T paper.\nThe sample is not random; instead, we just took the top n sentence pairs from each translation direction.\nThe number n was computed with the goal of upsamping the directions that contain underrepresented languages.\nNevertheless, the 187 languoids (language and scriptâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/slone/nllb-200-10M-sample.","url":"https://huggingface.co/datasets/slone/nllb-200-10M-sample","creator_name":"SLONE","creator_url":"https://huggingface.co/slone","license_name":"Open Data Commons Attribution License v1.0","license_url":"https://scancode-licensedb.aboutcode.org/odc-by-1.0.html","language":"en","first_N":5,"first_N_keywords":["translation","Akan","Amharic","Arabic","Awadhi"],"keywords_longer_than_N":true},
	{"name":"bible_para","keyword":"portuguese","description":"This is a multilingual parallel corpus created from translations of the Bible compiled by Christos Christodoulopoulos and Mark Steedman.\n\n102 languages, 5,148 bitexts\ntotal number of files: 107\ntotal number of tokens: 56.43M\ntotal number of sentence fragments: 2.84M","url":"https://huggingface.co/datasets/Helsinki-NLP/bible_para","creator_name":"Language Technology Research Group at the University of Helsinki","creator_url":"https://huggingface.co/Helsinki-NLP","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":null,"first_N":5,"first_N_keywords":["translation","found","found","multilingual","original"],"keywords_longer_than_N":true},
	{"name":"CulturaY","keyword":"portuguese","description":"\n\t\n\t\t\n\t\tCulturaY: A Large Cleaned Multilingual Dataset of 75 Languages\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nFrom the team that brought you CulturaX, we present CulturaY, another substantial multilingual dataset of 15TB (uncompressed)/3TB (zstd-compressed) that applies the same dataset cleaning methodology to the HPLT v1.1 dataset. \nPlease note that HPLT v1.2 has also been released and is an alternative verison with different cleaning methodolgies. \nThis data was used in part to train our SOTAâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Viet-Mistral/CulturaY.","url":"https://huggingface.co/datasets/Viet-Mistral/CulturaY","creator_name":"Vietnamese Mistral","creator_url":"https://huggingface.co/Viet-Mistral","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","fill-mask","language-modeling","masked-language-modeling","no-annotation"],"keywords_longer_than_N":true},
	{"name":"hpe2sa","keyword":"portuguese","description":"\n\t\n\t\t\n\t\thpe2sa: Human Post-Editing with Error Span Annotations ðŸ¤ŒðŸ•\n\t\n\nNo momento apenas um placeholder enquanto o repositÃ³rio privado Ã© preparado para liberaÃ§Ã£o.\nGithub repository\n","url":"https://huggingface.co/datasets/rsn86/hpe2sa","creator_name":"Rodrigo Schmidt Nurmberg","creator_url":"https://huggingface.co/rsn86","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":null,"first_N":5,"first_N_keywords":["translation","Portuguese","English","apache-2.0","ðŸ‡ºðŸ‡¸ Region: US"],"keywords_longer_than_N":false},
	{"name":"HypoTranslate","keyword":"portuguese","description":"This repo releases the HypoTranslate dataset in paper \"GenTranslate: Large Language Models are Generative Multilingual Speech and Machine Translators\".\nCode: https://github.com/YUCHEN005/GenTranslate\nModel: https://huggingface.co/PeacefulData/GenTranslate\nData: This repo\nFilename format: [split]_[data_source]_[src_language_code]_[tgt_language_code]_[task]_[seamlessm4t_size].pt\ne.g. train_fleurs_en_cy_st_large.pt\nNote:\n\nLanguage code look-up: Table 15 & 17 inâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/PeacefulData/HypoTranslate.","url":"https://huggingface.co/datasets/PeacefulData/HypoTranslate","creator_name":"Peaceful Data","creator_url":"https://huggingface.co/PeacefulData","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":null,"first_N":5,"first_N_keywords":["text-generation","English","Chinese","Japanese","French"],"keywords_longer_than_N":true},
	{"name":"port_data_random","keyword":"portuguese","description":"This Language Identification Dataset provides a multi-domain corpus in European and Brazilian Portuguese. \nThe repository is an anonymyzed version to support a submsission to the EACL 2024 conference.\nFurther information about the dataset can be soon found in the paper: Enhancing Portuguese Variants Identification with Domain-Agnostic Ensemble Approaches","url":"https://huggingface.co/datasets/Random-Mary-Smith/port_data_random","creator_name":"Random Mary","creator_url":"https://huggingface.co/Random-Mary-Smith","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":null,"first_N":5,"first_N_keywords":["Portuguese","mit","1M<n<10M","doi:10.57967/hf/1278","ðŸ‡ºðŸ‡¸ Region: US"],"keywords_longer_than_N":false},
	{"name":"Fact-Completion","keyword":"portuguese","description":"\n\t\n\t\t\n\t\tDataset Card\n\t\n\n\nHomepage: https://bit.ly/ischool-berkeley-capstone\nRepository: https://github.com/daniel-furman/Capstone\nPoint of Contact: daniel_furman@berkeley.edu\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis is the dataset for Polyglot or Not?: Measuring Multilingual Encyclopedic Knowledge Retrieval from Foundation Language Models.\n\n\t\n\t\t\n\t\n\t\n\t\tTest Description\n\t\n\n Given a factual association such as The capital of France is Paris, we determine whether a model adequately \"knows\" thisâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Polyglot-or-Not/Fact-Completion.","url":"https://huggingface.co/datasets/Polyglot-or-Not/Fact-Completion","creator_name":"Polyglot-or-Not","creator_url":"https://huggingface.co/Polyglot-or-Not","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","fill-mask","expert-generated","machine-generated","multilingual"],"keywords_longer_than_N":true},
	{"name":"instruct-aira-dataset-v3","keyword":"portuguese","description":"\n\t\n\t\t\n\t\tInstruct-Aira Dataset version 3.0\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset contains a collection of multi-turn conversations between an assistant and a user. Conversations were generated by user interactions with already-tuned models (ChatGPT, LLama 2, Open-Assistant, etc). The dataset is available in Portuguese and English.\n\n\t\n\t\t\n\t\tSupported Tasks and Leaderboards\n\t\n\nThis dataset can be utilized for various natural language processing tasks, including but not limited to:\n\nLanguageâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/nicholasKluge/instruct-aira-dataset-v3.","url":"https://huggingface.co/datasets/nicholasKluge/instruct-aira-dataset-v3","creator_name":"Nicholas Kluge CorrÃªa","creator_url":"https://huggingface.co/nicholasKluge","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","Portuguese","English","apache-2.0","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"massive_translation_dataset","keyword":"portuguese","description":"\n\t\n\t\t\n\t\tDataset Card for Massive Dataset for Translation\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset is derived from AmazonScience/MASSIVE dataset for translation task purpose.\n\n\t\n\t\t\n\t\tSupported Tasks and Leaderboards\n\t\n\nTranslation\n\n\t\n\t\t\n\t\tLanguages\n\t\n\n\nEnglish (en_US)\nGerman (de_DE)\nHindi (hi_IN)\nSpanish (es_ES)\nFrench (fr_FR)\nItalian (it_IT)\nArabic (ar_SA)\nDutch (nl_NL)\nJapanese (ja_JP)\nPortugese (pt_PT)\n\n","url":"https://huggingface.co/datasets/Amani27/massive_translation_dataset","creator_name":"Amani N","creator_url":"https://huggingface.co/Amani27","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["translation","English","German","Spanish","Hindi"],"keywords_longer_than_N":true},
	{"name":"xP3mt","keyword":"portuguese","description":"xP3 (Crosslingual Public Pool of Prompts) is a collection of prompts & datasets across 46 of languages & 16 NLP tasks. It is used for the training of BLOOMZ and mT0, multilingual language models capable of following human instructions in dozens of languages zero-shot.","url":"https://huggingface.co/datasets/bigscience/xP3mt","creator_name":"BigScience Workshop","creator_url":"https://huggingface.co/bigscience","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["other","expert-generated","crowdsourced","multilingual","Akan"],"keywords_longer_than_N":true},
	{"name":"mc4_legal","keyword":"portuguese","description":"\n\t\n\t\t\n\t\tDataset Card for MC4_Legal: A Corpus Covering the Legal Part of MC4 for European Languages\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset contains large text resources (~133GB in total) from mc4 filtered for legal data that can be used for pretraining language models.\nUse the dataset like this:\nfrom datasets import load_dataset\ndataset = load_dataset(\"joelito/mc4_legal\", \"de\", split='train', streaming=True)\n\n\n\t\n\t\t\n\t\n\t\n\t\tSupported Tasks and Leaderboards\n\t\n\nThe dataset supports the task ofâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/joelniklaus/mc4_legal.","url":"https://huggingface.co/datasets/joelniklaus/mc4_legal","creator_name":"Joel Niklaus","creator_url":"https://huggingface.co/joelniklaus","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["fill-mask","other","found","multilingual","original"],"keywords_longer_than_N":true},
	{"name":"Brazilian_Road_Signs_Dataset","keyword":"portuguese","description":"\n\t\n\t\t\n\t\tBrazilian Road Signs Dataset\n\t\n\nThis dataset contains high-quality images of Brazilian road and traffic signs collected from various urban and rural environments. It supports AI research in computer vision, object detection, and autonomous driving systems adapted to Brazilâ€™s signage standards and language.\n\n\t\n\t\t\n\t\tContact\n\t\n\nFor queries or collaborations related to this dataset, contact:  \n\nanoushka@kgen.io  \nabhishek.vadapalli@kgen.io\n\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\n\nTask Categories:â€¦ See the full description on the dataset page: https://huggingface.co/datasets/Kratos-AI/Brazilian_Road_Signs_Dataset.","url":"https://huggingface.co/datasets/Kratos-AI/Brazilian_Road_Signs_Dataset","creator_name":"KratosAI","creator_url":"https://huggingface.co/Kratos-AI","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["image-classification","object-detection","Portuguese","cc-by-4.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"Brazilian_Bills_and_Invoices_Dataset","keyword":"portuguese","description":"\n\t\n\t\t\n\t\tBrazilian Bills and Invoices Dataset\n\t\n\nThis dataset contains high-quality scanned and photographed images of Brazilian bills, invoices, and utility payment documents. It supports AI research in OCR, financial document understanding, and structured data extraction for Portuguese-language financial contexts.\n\n\t\n\t\t\n\t\tContact\n\t\n\nFor queries or collaborations related to this dataset, contact:  \n\nanoushka@kgen.io  \nabhishek.vadapalli@kgen.io\n\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\n\nTask Categories:â€¦ See the full description on the dataset page: https://huggingface.co/datasets/Kratos-AI/Brazilian_Bills_and_Invoices_Dataset.","url":"https://huggingface.co/datasets/Kratos-AI/Brazilian_Bills_and_Invoices_Dataset","creator_name":"KratosAI","creator_url":"https://huggingface.co/Kratos-AI","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["Portuguese","cc-by-4.0","< 1K","imagefolder","Image"],"keywords_longer_than_N":true},
	{"name":"eurlex_resources","keyword":"portuguese","description":"\n\t\n\t\t\n\t\tDataset Card for EurlexResources: A Corpus Covering the Largest EURLEX Resources\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset contains large text resources (~179GB in total) from EURLEX that can be used for pretraining language models.\nUse the dataset like this:\nfrom datasets import load_dataset\nconfig = \"de_caselaw\" # {lang}_{resource}\ndataset = load_dataset(\"joelito/eurlex_resources\", config, split='train', streaming=True) \n\n\n\t\n\t\t\n\t\n\t\n\t\tSupported Tasks and Leaderboards\n\t\n\nThe datasetâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/joelniklaus/eurlex_resources.","url":"https://huggingface.co/datasets/joelniklaus/eurlex_resources","creator_name":"Joel Niklaus","creator_url":"https://huggingface.co/joelniklaus","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":null,"first_N":5,"first_N_keywords":["fill-mask","other","found","multilingual","original"],"keywords_longer_than_N":true},
	{"name":"portuguese-legal-sentences-v0","keyword":"portuguese","description":"\n\nWork developed as part of Project IRIS.\nThesis: A Semantic Search System for Supremo Tribunal de JustiÃ§a\n\n\t\n\t\t\n\t\n\t\n\t\tPortuguese Legal Sentences\n\t\n\nCollection of Legal Sentences from the Portuguese Supreme Court of Justice\nThe goal of this dataset was to be used for MLM and TSDAE\n\n\t\n\t\t\n\t\n\t\n\t\tContributions\n\t\n\n@rufimelo99\nIf you use this work, please cite:\n@InProceedings{MeloSemantic,\n  author=\"Melo, Rui\n  and Santos, Pedro A.\n  and Dias, Jo{\\~a}o\",\n  editor=\"Moniz, Nuno\n  and Vale, Zita\n  andâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/stjiris/portuguese-legal-sentences-v0.","url":"https://huggingface.co/datasets/stjiris/portuguese-legal-sentences-v0","creator_name":"SumarizaÃ§Ã£o e InformaÃ§Ã£o de decisÃµes: AplicaÃ§Ã£o de TÃ©cnicas de InteligÃªncia Artificial no Supremo Tribunal de JustiÃ§a (IRIS)","creator_url":"https://huggingface.co/stjiris","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["no-annotation","found","monolingual","original","Portuguese"],"keywords_longer_than_N":true},
	{"name":"hotel_dataset_llama2","keyword":"portuguese","description":"nova-sqoin/hotel_dataset_llama2 dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/nova-sqoin/hotel_dataset_llama2","creator_name":"nova","creator_url":"https://huggingface.co/nova-sqoin","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["Portuguese","English","apache-2.0","< 1K","json"],"keywords_longer_than_N":true},
	{"name":"gpt4all-j-prompt-generations-pt","keyword":"portuguese","description":"\n\t\n\t\t\n\t\tDataset Card for \"gpt4all-j-prompt-generations-pt\"\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nCopy translated into Portuguese of the dataset gpt4all_prompt_generations using the googletrans library.\n\n\t\n\t\t\n\t\tTranslate\n\t\n\ntranslate_dataset.ipynb\n\n\t\n\t\t\n\t\tUsage\n\t\n\ndataset_usage.ipynb\n","url":"https://huggingface.co/datasets/pablo-moreira/gpt4all-j-prompt-generations-pt","creator_name":"Pablo Filetti Moreira","creator_url":"https://huggingface.co/pablo-moreira","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","Portuguese","apache-2.0","100K - 1M","parquet"],"keywords_longer_than_N":true},
	{"name":"conceptnet5","keyword":"portuguese","description":"\n\t\n\t\t\n\t\tDataset Card for Conceptnet5\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nConceptNet is a multilingual knowledge base, representing words and\nphrases that people use and the common-sense relationships between\nthem. The knowledge in ConceptNet is collected from a variety of\nresources, including crowd-sourced resources (such as Wiktionary and\nOpen Mind Common Sense), games with a purpose (such as Verbosity and\nnadya.jp), and expert-created resources (such as WordNet and JMDict).\nYou can browse whatâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/conceptnet5/conceptnet5.","url":"https://huggingface.co/datasets/conceptnet5/conceptnet5","creator_name":"conceptnet5","creator_url":"https://huggingface.co/conceptnet5","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","multi-class-classification","crowdsourced","crowdsourced","found"],"keywords_longer_than_N":true},
	{"name":"my_cool_dataset","keyword":"portuguese","description":"ricardo-lsantos/my_cool_dataset dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/ricardo-lsantos/my_cool_dataset","creator_name":"Ricardo Lisboa Santos","creator_url":"https://huggingface.co/ricardo-lsantos","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["Portuguese","mit","< 1K","csv","Text"],"keywords_longer_than_N":true},
	{"name":"base-dados-odio-lgbtqia","keyword":"portuguese","description":"\n\t\n\t\t\n\t\tBase de Dados de Ã“dio contra Pessoas LGBTQIA+ em PortuguÃªs (PT-BR)\n\t\n\nColeÃ§Ã£o de datasets para detecÃ§Ã£o de discurso de Ã³dio contra pessoas LGBTQIA+ em portuguÃªs brasileiro.\n\n\t\n\t\t\n\t\tðŸŽ¯ Objetivo\n\t\n\nFornecer dados de treinamento e validaÃ§Ã£o para sistemas de detecÃ§Ã£o de discurso de Ã³dio contra pessoas LGBTQIA+ em portuguÃªs brasileiro.\n\n\t\n\t\t\n\t\tðŸ“¢ Contexto Social\n\t\n\nEste dataset foi criado a partir de uma onda de Ã³dio real sofrida pelo podcast Entre Amigues da equipe CÃ³digo NÃ£o BinÃ¡rio. Osâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Veronyka/base-dados-odio-lgbtqia.","url":"https://huggingface.co/datasets/Veronyka/base-dados-odio-lgbtqia","creator_name":"Veronyka \"Travahacker\" Gimenes","creator_url":"https://huggingface.co/Veronyka","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","text-retrieval","Portuguese","mit","10K<n<100K"],"keywords_longer_than_N":true},
	{"name":"base-dados-odio-lgbtqia","keyword":"portuguese","description":"\n\t\n\t\t\n\t\tBase de Dados de Ã“dio contra Pessoas LGBTQIA+ em PortuguÃªs (PT-BR)\n\t\n\nColeÃ§Ã£o de datasets para detecÃ§Ã£o de discurso de Ã³dio contra pessoas LGBTQIA+ em portuguÃªs brasileiro.\n\n\t\n\t\t\n\t\tðŸŽ¯ Objetivo\n\t\n\nFornecer dados de treinamento e validaÃ§Ã£o para sistemas de detecÃ§Ã£o de discurso de Ã³dio contra pessoas LGBTQIA+ em portuguÃªs brasileiro.\n\n\t\n\t\t\n\t\tðŸ“¢ Contexto Social\n\t\n\nEste dataset foi criado a partir de uma onda de Ã³dio real sofrida pelo podcast Entre Amigues da equipe CÃ³digo NÃ£o BinÃ¡rio. Osâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Veronyka/base-dados-odio-lgbtqia.","url":"https://huggingface.co/datasets/Veronyka/base-dados-odio-lgbtqia","creator_name":"Veronyka \"Travahacker\" Gimenes","creator_url":"https://huggingface.co/Veronyka","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","text-retrieval","Portuguese","mit","10K<n<100K"],"keywords_longer_than_N":true},
	{"name":"xP3x-sample","keyword":"portuguese","description":"A multilingual collection of Winograd Schemas in six languages that can be used for evaluation of cross-lingual commonsense reasoning capabilities.","url":"https://huggingface.co/datasets/Muennighoff/xP3x-sample","creator_name":"Niklas Muennighoff","creator_url":"https://huggingface.co/Muennighoff","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["other","expert-generated","crowdsourced","multilingual","Afrikaans"],"keywords_longer_than_N":true},
	{"name":"translation-en-pt","keyword":"portuguese","description":"How to use it: \nfrom datasets import load_dataset\n\nremote_dataset = load_dataset(\"VanessaSchenkel/translation-en-pt\", field=\"data\")\n\nremote_dataset\n\nOutput:\nDatasetDict({\n    train: Dataset({\n        features: ['id', 'translation'],\n        num_rows: 260482\n    })\n})\n\nExemple: \nremote_dataset[\"train\"][5]\n\nOutput:\n{'id': '5',\n 'translation': {'english': 'I have to go to sleep.',\n  'portuguese': 'Tenho de dormir.'}}\n\n","url":"https://huggingface.co/datasets/VanessaSchenkel/translation-en-pt","creator_name":"Vanessa Schramm Schenkel Da Silva","creator_url":"https://huggingface.co/VanessaSchenkel","license_name":"Academic Free License v3.0","license_url":"https://choosealicense.com/licenses/afl-3.0/","language":"en","first_N":5,"first_N_keywords":["translation","found","found","translation","original"],"keywords_longer_than_N":true},
	{"name":"MMLU_Portuguese","keyword":"portuguese","description":"Portuguese version of MMLU dataset tranlasted by gpt-3.5-turbo.The dataset is used in the research related to MultilingualSIFT. \n","url":"https://huggingface.co/datasets/FreedomIntelligence/MMLU_Portuguese","creator_name":"FreedomAI","creator_url":"https://huggingface.co/FreedomIntelligence","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["Portuguese","mit","ðŸ‡ºðŸ‡¸ Region: US"],"keywords_longer_than_N":false},
	{"name":"GPT4-500k-Augmented-PTBR-Clean","keyword":"portuguese","description":"A translated version of Open-Orca/1million-gpt-4 to portuguese.\nInstructions and responses with non-latin characters have been removed, as well as coding-related tasks.\n","url":"https://huggingface.co/datasets/cnmoro/GPT4-500k-Augmented-PTBR-Clean","creator_name":"Carlo Moro","creator_url":"https://huggingface.co/cnmoro","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-generation","Portuguese","mit","100K - 1M","parquet"],"keywords_longer_than_N":true},
	{"name":"google-play-apps-review-pt","keyword":"portuguese","description":"\n\t\n\t\t\n\t\tGoogle Play Apps Review PT (Teeny-Tiny Castle)\n\t\n\nThis dataset is part of a tutorial tied to the Teeny-Tiny Castle, an open-source repository containingÂ educational tools for AI Ethics and Safety research. \n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nfrom datasets import load_dataset\n\ndataset = load_dataset(\"AiresPucrs/google-play-apps-review-pt\", split = 'train')\n\n","url":"https://huggingface.co/datasets/AiresPucrs/google-play-apps-review-pt","creator_name":"AI Robotics Ethics Society (PUCRS)","creator_url":"https://huggingface.co/AiresPucrs","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","Portuguese","apache-2.0","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"recognasumm","keyword":"portuguese","description":"\n\t\n\t\t\n\t\tRecognaSumm Dataset\n\t\n\n\n\t\n\t\t\n\t\tIntroduction\n\t\n\nRecognaSumm is a novel and comprehensive database specifically designed for the task of automatic text summarization in Portuguese. RecognaSumm stands out due to its diverse origin, composed of news collected from a variety of information sources, including agencies and online news portals. The database was constructed using web scraping techniques and careful curation, re sulting in a rich and representative collection of documentsâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/recogna-nlp/recognasumm.","url":"https://huggingface.co/datasets/recogna-nlp/recognasumm","creator_name":"Recogna NLP","creator_url":"https://huggingface.co/recogna-nlp","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["summarization","Portuguese","mit","100K<n<1M","ðŸ‡ºðŸ‡¸ Region: US"],"keywords_longer_than_N":true},
	{"name":"perguntas_e_respostas_astronomia_pt_br_V2.0","keyword":"portuguese","description":"\n\t\n\t\t\n\t\tREADME: Dataset JSON de Perguntas e Respostas sobre Astronomia\n\t\n\n\n\t\n\t\t\n\t\tVisÃ£o Geral\n\t\n\nEste repositÃ³rio contÃ©m um dataset sintÃ©tico de perguntas e respostas sobre astronomia, gerado no formato JSON. O objetivo deste dataset Ã© servir como material educativo e para o ajuste fino (fine-tuning) de Modelos de Linguagem Grandes (LLMs).\nEsse dataset contÃ©m 1000 perguntas e respostas variadas sobre tÃ³picos de astronomia, como planetas, estrelas, galÃ¡xias e fenÃ´menos cÃ³smicos, juntamente comâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/vinimuchulski/perguntas_e_respostas_astronomia_pt_br_V2.0.","url":"https://huggingface.co/datasets/vinimuchulski/perguntas_e_respostas_astronomia_pt_br_V2.0","creator_name":"vini","creator_url":"https://huggingface.co/vinimuchulski","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["Portuguese","apache-2.0","1K - 10K","json","Text"],"keywords_longer_than_N":true},
	{"name":"Global-MMLU-Lite","keyword":"portuguese","description":"\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nGlobal-MMLU-Lite is a multilingual evaluation set spanning 16 languages, including English. It is \"lite\" version of the original Global-MMLU dataset ðŸŒ.\nIt includes 200 Culturally Sensitive (CS) and 200 Culturally Agnostic (CA) samples per language. The samples in Global-MMLU-Lite are corresponding to languages which are fully human translated or post-edited in the original Global-MMLU dataset. \nNOTE: Of the 16 languages presently included in Global-MMLU-Lite, 15â€¦ See the full description on the dataset page: https://huggingface.co/datasets/CohereLabs/Global-MMLU-Lite.","url":"https://huggingface.co/datasets/CohereLabs/Global-MMLU-Lite","creator_name":"Cohere Labs","creator_url":"https://huggingface.co/CohereLabs","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["English","Arabic","Bengali","Spanish","French"],"keywords_longer_than_N":true},
	{"name":"xsimplusplus","keyword":"portuguese","description":"xSIM++ is an extension of xSIM. In comparison to xSIM, this evaluates using target-side data with additional synthetic, hard-to-distinguish examples. You can find more details about it in the publication: xSIM++: An Improved Proxy to Bitext Mining Performance for Low-Resource Languages.\n","url":"https://huggingface.co/datasets/jaygala24/xsimplusplus","creator_name":"Jay Gala","creator_url":"https://huggingface.co/jaygala24","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["derived","multilingual","Achinese","Mesopotamian Arabic","Ta'izzi-Adeni Arabic"],"keywords_longer_than_N":true},
	{"name":"cml-tts","keyword":"portuguese","description":"\n\t\n\t\t\n\t\tDataset Card for CML-TTS\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nCML-TTS is a recursive acronym for CML-Multi-Lingual-TTS, a Text-to-Speech (TTS) dataset developed at the Center of Excellence in Artificial Intelligence (CEIA) of the Federal University of Goias (UFG).\nCML-TTS is a dataset comprising audiobooks sourced from the public domain books of Project Gutenberg, read by volunteers from the LibriVox project. The dataset includes recordings in Dutch, German, French, Italian, Polishâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/ylacombe/cml-tts.","url":"https://huggingface.co/datasets/ylacombe/cml-tts","creator_name":"Yoach Lacombe","creator_url":"https://huggingface.co/ylacombe","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-to-speech","text-to-audio","Dutch","French","German"],"keywords_longer_than_N":true},
	{"name":"truthfulqax","keyword":"portuguese","description":"\n\t\n\t\t\n\t\tCitation Information\n\t\n\nIf you find benchmarks useful in your research, please consider citing the test and also the TruthfulQA dataset it draws from:\n    @misc{thellmann2024crosslingual,\n    title={Towards Cross-Lingual LLM Evaluation for European Languages},\n    author={Klaudia Thellmann and Bernhard Stadler and Michael Fromm and Jasper Schulze Buschhoff and Alex Jude and Fabio Barth and Johannes Leveling and Nicolas Flores-Herr and Joachim KÃ¶hler and RenÃ© JÃ¤kel and Mehdi Ali}â€¦ See the full description on the dataset page: https://huggingface.co/datasets/Eurolingua/truthfulqax.","url":"https://huggingface.co/datasets/Eurolingua/truthfulqax","creator_name":"EuroLingua-GPT","creator_url":"https://huggingface.co/Eurolingua","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":null,"first_N":5,"first_N_keywords":["text-generation","German","French","Spanish","Italian"],"keywords_longer_than_N":true},
	{"name":"banking77-pt-br","keyword":"portuguese","description":"\n\t\n\t\t\n\t\tResumo do conjunto de dados\n\t\n\n\n\nTraduÃ§Ã£o revisada para o portuguÃªs brasileiro do conjunto de dados BANKING77. O conjunto Ã© composto por consultas online realizadas a sistemas conversacionais de bancos, rotuladas de acordo com suas intenÃ§Ãµes correspondentes. De acordo com a documentaÃ§Ã£o original, as 13.083 consultas que compÃµem o conjunto sÃ£o referentes a atendimentos ao cliente, e foram rotuladas em 77 intenÃ§Ãµes diferentes. O foco principal Ã© suportar anÃ¡lises em domÃ­nio especÃ­fico eâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/c2d-usp/banking77-pt-br.","url":"https://huggingface.co/datasets/c2d-usp/banking77-pt-br","creator_name":"Centro de CiÃªncia de Dados","creator_url":"https://huggingface.co/c2d-usp","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["Portuguese","cc-by-4.0","10K - 100K","csv","Text"],"keywords_longer_than_N":true},
	{"name":"biblenlp-corpus-mmteb","keyword":"portuguese","description":"This dataset pre-computes all English-centric directions from bible-nlp/biblenlp-corpus, and as a result loading is significantly faster.\nLoading example:\n>>> from datasets import load_dataset\n>>> dataset = load_dataset(\"davidstap/biblenlp-corpus-mmteb\", \"eng-arb\", trust_remote_code=True)\n>>> dataset\nDatasetDict({\n    train: Dataset({\n        features: ['eng', 'arb'],\n        num_rows: 28723\n    })\n    validation: Dataset({\n        features: ['eng', 'arb'],\n        num_rows: 1578\n    })â€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/biblenlp-corpus-mmteb.","url":"https://huggingface.co/datasets/mteb/biblenlp-corpus-mmteb","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["no-annotation","expert-generated","translation","multilingual","Arifama-Miniafia"],"keywords_longer_than_N":true},
	{"name":"Thinking-multilingual-big-10k-sft","keyword":"portuguese","description":"\nA dataset based off of openo1 math, 500 examples translated to 23 different languages. filtered out un-translated examples.\nenjoy ðŸ‘\n","url":"https://huggingface.co/datasets/Pinkstack/Thinking-multilingual-big-10k-sft","creator_name":"Pinkstack","creator_url":"https://huggingface.co/Pinkstack","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","Arabic","Chinese","Czech","Danish"],"keywords_longer_than_N":true},
	{"name":"GigaVerbo-Text-Filter","keyword":"portuguese","description":"\n\t\n\t\t\n\t\tGigaVerbo Text-Filter\n\t\n\n\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nGigaVerbo Text-Filter is a dataset with 110,000 randomly selected samples from 9 subsets of GigaVerbo (i.e., specifically those that were not synthetic). This dataset was used to train the text-quality filters described in \"Tucano: Advancing Neural Text Generation for Portuguese\". To create the text embeddings, we used sentence-transformers/LaBSE. All scores were generated by GPT-4o.\n\n\t\n\t\t\n\t\n\t\n\t\tSupported Tasks and Leaderboardsâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/TucanoBR/GigaVerbo-Text-Filter.","url":"https://huggingface.co/datasets/TucanoBR/GigaVerbo-Text-Filter","creator_name":"Tucano","creator_url":"https://huggingface.co/TucanoBR","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","Portuguese","apache-2.0","100K - 1M","parquet"],"keywords_longer_than_N":true},
	{"name":"GigaVerbo-Text-Filter","keyword":"portuguese","description":"\n\t\n\t\t\n\t\tGigaVerbo Text-Filter\n\t\n\n\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nGigaVerbo Text-Filter is a dataset with 110,000 randomly selected samples from 9 subsets of GigaVerbo (i.e., specifically those that were not synthetic). This dataset was used to train the text-quality filters described in \"Tucano: Advancing Neural Text Generation for Portuguese\". To create the text embeddings, we used sentence-transformers/LaBSE. All scores were generated by GPT-4o.\n\n\t\n\t\t\n\t\n\t\n\t\tSupported Tasks and Leaderboardsâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/TucanoBR/GigaVerbo-Text-Filter.","url":"https://huggingface.co/datasets/TucanoBR/GigaVerbo-Text-Filter","creator_name":"Tucano","creator_url":"https://huggingface.co/TucanoBR","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","Portuguese","apache-2.0","100K - 1M","parquet"],"keywords_longer_than_N":true},
	{"name":"flickr30k-pt-br","keyword":"portuguese","description":"\n\t\n\t\t\n\t\tðŸŽ‰ Flickr30K Translated for Portuguese Image Captioning\n\t\n\n\n\t\n\t\t\n\t\tðŸ’¾ Dataset Summary\n\t\n\nFlickr30K Portuguese Translated, a multimodal dataset for Portuguese image captioning with 31,014 images, each accompanied by five descriptive captions that have been\ngenerated by human annotators for every individual image. The original English captions were rendered into Portuguese\nthrough the utilization of the Google Translator API.\nThe dataset is one of the results of work available at:â€¦ See the full description on the dataset page: https://huggingface.co/datasets/laicsiifes/flickr30k-pt-br.","url":"https://huggingface.co/datasets/laicsiifes/flickr30k-pt-br","creator_name":"LaboratÃ³rio de InteligÃªncia Computacional e Sistemas de informaÃ§Ã£o","creator_url":"https://huggingface.co/laicsiifes","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-generation","image-to-text","text-to-image","Portuguese","mit"],"keywords_longer_than_N":true},
	{"name":"lambada-pt","keyword":"portuguese","description":"\n\t\n\t\t\n\t\tLAMBADA-PT\n\t\n\n\nRepository: TucanoBR/lambada-pt\nPaper: Radford et al. Language Models are Unsupervised Multitask Learners\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset is a translated version (Portuguese) of the LAMBADA test split as pre-processed by OpenAI.\nLAMBADA is used to evaluate the capabilities of computational models for text understanding by means of a word prediction task. LAMBADA is a collection of narrative texts sharing the characteristic that human subjects are able to guessâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/TucanoBR/lambada-pt.","url":"https://huggingface.co/datasets/TucanoBR/lambada-pt","creator_name":"Tucano","creator_url":"https://huggingface.co/TucanoBR","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-generation","Portuguese","mit","1K - 10K","parquet"],"keywords_longer_than_N":true},
	{"name":"harmful-text","keyword":"portuguese","description":"\n\t\n\t\t\n\t\tHarmful-Text\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset contains a collection of examples of harmful and harmless language. The dataset is available in both Portuguese and English.\nSamples were collected from the following datasets:\n\nAnthropic/hh-rlhf.\nallenai/prosocial-dialog.\nallenai/real-toxicity-prompts.\ndirtycomputer/Toxic_Comment_Classification_Challenge.\nPaul/hatecheck-portuguese.\ntold-br.\nskg/toxigen-data.\n\n\n\t\n\t\t\n\t\tSupported Tasks and Leaderboards\n\t\n\nThis dataset can beâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/nicholasKluge/harmful-text.","url":"https://huggingface.co/datasets/nicholasKluge/harmful-text","creator_name":"Nicholas Kluge CorrÃªa","creator_url":"https://huggingface.co/nicholasKluge","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","Portuguese","English","apache-2.0","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"minds14","keyword":"portuguese","description":"\n\t\n\t\t\n\t\tMInDS-14\n\t\n\nMINDS-14 is training and evaluation resource for intent detection task with spoken data. It covers 14 \nintents extracted from a commercial system in the e-banking domain, associated with spoken examples in 14 diverse language varieties.\n\n\t\n\t\t\n\t\tExample\n\t\n\nMInDS-14 can be downloaded and used as follows:\nfrom datasets import load_dataset\n\nminds_14 = load_dataset(\"PolyAI/minds14\", \"fr-FR\") # for French\n# to download all data for multi-lingual fine-tuning uncomment followingâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/PolyAI/minds14.","url":"https://huggingface.co/datasets/PolyAI/minds14","creator_name":"PolyAI","creator_url":"https://huggingface.co/PolyAI","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","keyword-spotting","expert-generated","crowdsourced","machine-generated"],"keywords_longer_than_N":true},
	{"name":"amazon_massive_scenario","keyword":"portuguese","description":"\n  MassiveScenarioClassification\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nMASSIVE: A 1M-Example Multilingual Natural Language Understanding Dataset with 51 Typologically-Diverse Languages\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2c\n\n\nDomains\nSpoken\n\nReference\nhttps://arxiv.org/abs/2204.08582\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask = mteb.get_tasks([\"MassiveScenarioClassification\"])\nevaluator =â€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/amazon_massive_scenario.","url":"https://huggingface.co/datasets/mteb/amazon_massive_scenario","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","human-annotated","translated","Afrikaans","Amharic"],"keywords_longer_than_N":true},
	{"name":"negated_carolina","keyword":"portuguese","description":"\n\t\n\t\t\n\t\tNotCarolina\n\t\n\nThis dataset contains examples of negation in Portuguese across multiple domains.\nIt is derived from the Carolina Corpus, which we segment into sentences and filter for common negation words in Portuguese.\n","url":"https://huggingface.co/datasets/hapaxlegomenon/negated_carolina","creator_name":"John Doe","creator_url":"https://huggingface.co/hapaxlegomenon","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["Portuguese","apache-2.0","1M - 10M","parquet","Text"],"keywords_longer_than_N":true},
	{"name":"corpus-carolina-jud-lgpd","keyword":"portuguese","description":"\n\t\n\t\t\n\t\tCarolina Corpus with data annotated in accordance with the LGPD (Brazilian General Data Protection Law)\n\t\n\nThis dataset is a derivative of the Carolina Corpus.\nWe analyzed and filtered the content in search of personal data for academic purposes.\nWe balanced the dataset to train the model https://huggingface.co/celiudos/legal-bert-lgpd\n\n\t\n\t\t\nLabels\nEn\n\n\n\t\t\nNOME\nNAME\n\n\nDATA\nDATE\n\n\nENDERECO\nADDRESS\n\n\nCEP\nZIPCODE\n\n\nCPF\nCPF\n\n\nTELEFONE\nPHONE\n\n\nEMAIL\nEMAIL\n\n\nDINHEIRO\nMONEYâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/celiudos/corpus-carolina-jud-lgpd.","url":"https://huggingface.co/datasets/celiudos/corpus-carolina-jud-lgpd","creator_name":"Marcelo Anselmo de Souza Filho","creator_url":"https://huggingface.co/celiudos","license_name":"Academic Free License v3.0","license_url":"https://choosealicense.com/licenses/afl-3.0/","language":"en","first_N":5,"first_N_keywords":["token-classification","Portuguese","afl-3.0","1K - 10K","parquet"],"keywords_longer_than_N":true},
	{"name":"medicine-information-pt","keyword":"portuguese","description":"rhaymison/medicine-information-pt dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/rhaymison/medicine-information-pt","creator_name":"Rhaymison Cristian","creator_url":"https://huggingface.co/rhaymison","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","Portuguese","apache-2.0","1K - 10K","parquet"],"keywords_longer_than_N":true},
	{"name":"tweet_sentiment_multilingual","keyword":"portuguese","description":"\n  TweetSentimentClassification\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nA multilingual Sentiment Analysis dataset consisting of tweets in 8 different languages.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2c\n\n\nDomains\nSocial, Written\n\n\nReferencehttps://aclanthology.org/2022.lrec-1.27\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask = mteb.get_tasks([\"TweetSentimentClassification\"])\nevaluator =â€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/tweet_sentiment_multilingual.","url":"https://huggingface.co/datasets/mteb/tweet_sentiment_multilingual","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"Creative Commons Attribution 3.0","license_url":"https://scancode-licensedb.aboutcode.org/cc-by-3.0.html","language":"en","first_N":5,"first_N_keywords":["text-classification","sentiment-analysis","sentiment-scoring","sentiment-classification","hate-speech-detection"],"keywords_longer_than_N":true},
	{"name":"mewsli-x","keyword":"portuguese","description":"I generated the dataset following mewsli-x.md#getting-started\nand converted into different parts (see process.py):\n\nar/de/en/es/fa/ja/pl/ro/ta/tr/uk wikinews_mentions dev and test (from wikinews_mentions-dev/test.jsonl)\ncandidate entities of 50 languages (from candidate_set_entities.jsonl)\nEnglish wikipedia_pairs to fine-tune models (from wikipedia_pairs-dev/train.jsonl)\n\nRaw data files are in raw.tar.gz, which contains:\n[...] 535M Feb 24 22:06 candidate_set_entities.jsonl\n[...] 9.8M Feb 24â€¦ See the full description on the dataset page: https://huggingface.co/datasets/izhx/mewsli-x.","url":"https://huggingface.co/datasets/izhx/mewsli-x","creator_name":"Xin Zhang","creator_url":"https://huggingface.co/izhx","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","entity-linking-retrieval","Afrikaans","Arabic","Azerbaijani"],"keywords_longer_than_N":true},
	{"name":"community-alignment-dataset","keyword":"portuguese","description":"\nCommunity Alignment\n\n\n Github Â  | Â \n Paper\n\n\n\n\t\n\t\t\n\t\tDataset\n\t\n\nCommunity Alignment is a large-scale open source, multilingual and multi-turn preference dataset to align LLMs with human preferences across cultures. It features prompt-level overlap in annotators, enabling social-choice-based and distributional approaches to LLM alignment, as well as natural language explanations for choices.\n\n[Large-scale] ~200,000 comparisons of LLM responses, collected from >3,000 unique annotators whoâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/facebook/community-alignment-dataset.","url":"https://huggingface.co/datasets/facebook/community-alignment-dataset","creator_name":"AI at Meta","creator_url":"https://huggingface.co/facebook","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["Hindi","English","Portuguese","Italian","French"],"keywords_longer_than_N":true},
	{"name":"coco-captions-pt-br","keyword":"portuguese","description":"\n\t\n\t\t\n\t\tðŸŽ‰ COCO Captions Dataset Translation for Portuguese Image Captioning\n\t\n\n\n\t\n\t\t\n\t\tðŸ’¾ Dataset Summary\n\t\n\nCOCO Captions Portuguese Translation, a multimodal dataset for Portuguese image captioning with 123,287 images, each accompanied by five descriptive captions that have been\ngenerated by human annotators for every individual image. The original English captions were rendered into Portuguese\nthrough the utilization of the Google Translator API.\n\n\t\n\t\t\n\t\tðŸ§‘â€ðŸ’» Hot to Get Started with theâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/laicsiifes/coco-captions-pt-br.","url":"https://huggingface.co/datasets/laicsiifes/coco-captions-pt-br","creator_name":"LaboratÃ³rio de InteligÃªncia Computacional e Sistemas de informaÃ§Ã£o","creator_url":"https://huggingface.co/laicsiifes","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-to-image","image-to-text","text-generation","Portuguese","mit"],"keywords_longer_than_N":true},
	{"name":"fakerecogna2-extrativa","keyword":"portuguese","description":"\n\t\n\t\t\n\t\tFakeRecogna 2.0 Extractive\n\t\n\nFakeRecogna 2.0 presents the extension for the FakeRecogna dataset in the context of fake news detection. FakeRecogna includes real and fake news texts collected from online media and ten fact-checking sources in Brazil. An important aspect is the lack of relation between the real and fake news samples, i.e., they are not mutually related to each other to avoid intrinsic bias in the data.\n\n\t\n\t\t\n\t\tThe Dataset\n\t\n\nThe fake news collection was performed onâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/recogna-nlp/fakerecogna2-extrativa.","url":"https://huggingface.co/datasets/recogna-nlp/fakerecogna2-extrativa","creator_name":"Recogna NLP","creator_url":"https://huggingface.co/recogna-nlp","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","Portuguese","mit","10K - 100K","csv"],"keywords_longer_than_N":true},
	{"name":"fakerecogna2-extrativa","keyword":"portuguese","description":"\n\t\n\t\t\n\t\tFakeRecogna 2.0 Extractive\n\t\n\nFakeRecogna 2.0 presents the extension for the FakeRecogna dataset in the context of fake news detection. FakeRecogna includes real and fake news texts collected from online media and ten fact-checking sources in Brazil. An important aspect is the lack of relation between the real and fake news samples, i.e., they are not mutually related to each other to avoid intrinsic bias in the data.\n\n\t\n\t\t\n\t\tThe Dataset\n\t\n\nThe fake news collection was performed onâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/recogna-nlp/fakerecogna2-extrativa.","url":"https://huggingface.co/datasets/recogna-nlp/fakerecogna2-extrativa","creator_name":"Recogna NLP","creator_url":"https://huggingface.co/recogna-nlp","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","Portuguese","mit","10K - 100K","csv"],"keywords_longer_than_N":true},
	{"name":"prompt-injection-multilingual","keyword":"portuguese","description":"rikka-snow/prompt-injection-multilingual dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/rikka-snow/prompt-injection-multilingual","creator_name":"Le Xuan Hoang","creator_url":"https://huggingface.co/rikka-snow","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","Vietnamese","English","Chinese","French"],"keywords_longer_than_N":true},
	{"name":"toxicity-multilingual-binary-classification-dataset","keyword":"portuguese","description":"This dataset is a comprehensive collection designed to aid in the development of robust and nuanced models for identifying toxic language across multiple languages, while critically distinguishing it from expressions related to mental health, specifically depression. It synthesizes content from three existing public datasets (ToxiGen, TextDetox, and Mental Health - Depression) with a newly generated synthetic dataset (ToxiLLaMA). The creation process involved careful collection, extensiveâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/malexandersalazar/toxicity-multilingual-binary-classification-dataset.","url":"https://huggingface.co/datasets/malexandersalazar/toxicity-multilingual-binary-classification-dataset","creator_name":"Alexander Salazar","creator_url":"https://huggingface.co/malexandersalazar","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["English","German","French","Italian","Portuguese"],"keywords_longer_than_N":true},
	{"name":"medicine-evaluation-pt-tokenized-2048","keyword":"portuguese","description":"\n\t\n\t\t\n\t\tEvaluation Dataset for Doctor Llama\n\t\n\nThis repository contains a tokenized version of medicine-evaluation-pt.\n\n\t\n\t\t\n\t\tAuthor\n\t\n\nMariana Moreira dos Santos (LinkedIn)\n","url":"https://huggingface.co/datasets/mmoreirast/medicine-evaluation-pt-tokenized-2048","creator_name":"Mariana Moreira","creator_url":"https://huggingface.co/mmoreirast","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["question-answering","Portuguese","apache-2.0","< 1K","parquet"],"keywords_longer_than_N":true},
	{"name":"corpus-combined","keyword":"portuguese","description":"\n\t\n\t\t\n\t\tPortuguese Fake News Corpus â€” combined\n\t\n\nThis dataset contains the combined corpus used to train Portuguese fake-news classifiers.\n\n\t\n\t\t\n\t\tContents\n\t\n\n\nParquet/CSV splits (train/test/full/aligned) when available\nOptional raw texts and preprocessed/size-normalized folders\n\n\n\t\n\t\t\n\t\tSource\n\t\n\n\nFake.br: https://github.com/roneysco/Fake.br-Corpus\nFakeTrue.Br: https://github.com/jpchav98/FakeTrue.Br/\n\n","url":"https://huggingface.co/datasets/vzani/corpus-combined","creator_name":"Zani","creator_url":"https://huggingface.co/vzani","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","Portuguese","apache-2.0","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"corpus-combined","keyword":"portuguese","description":"\n\t\n\t\t\n\t\tPortuguese Fake News Corpus â€” combined\n\t\n\nThis dataset contains the combined corpus used to train Portuguese fake-news classifiers.\n\n\t\n\t\t\n\t\tContents\n\t\n\n\nParquet/CSV splits (train/test/full/aligned) when available\nOptional raw texts and preprocessed/size-normalized folders\n\n\n\t\n\t\t\n\t\tSource\n\t\n\n\nFake.br: https://github.com/roneysco/Fake.br-Corpus\nFakeTrue.Br: https://github.com/jpchav98/FakeTrue.Br/\n\n","url":"https://huggingface.co/datasets/vzani/corpus-combined","creator_name":"Zani","creator_url":"https://huggingface.co/vzani","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","Portuguese","apache-2.0","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"PublicTransportAI","keyword":"portuguese","description":"\n\t\n\t\t\n\t\tDataset Card for PublicTransportAI\n\t\n\nPublicTransportAI is a public dataset focused on demand forecasting for urban public transportation in GoiÃ¢nia (Brazil). It was developed as part of the research published in the Brazilian Journal of Technology (DOI: 10.38152/bjtv3n4-003) and includes structured and raw data used to train 1D Convolutional Neural Networks (CNNs) for daily passenger demand prediction.\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\n\t\n\t\tDescription\n\t\n\n\nCurated by: Willgnnerâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Willgnner-Santos/PublicTransportAI.","url":"https://huggingface.co/datasets/Willgnner-Santos/PublicTransportAI","creator_name":"Willgnner Ferreira Santos","creator_url":"https://huggingface.co/Willgnner-Santos","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["time-series-forecasting","English","Portuguese","apache-2.0","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"blogsetbr","keyword":"portuguese","description":"\n\t\n\t\t\n\t\n\t\n\t\tBlogSet-BR\n\t\n\nReproduÃ§Ã£o do dataset BlogSet-BR criado pela universidade PUCRS.\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Original\n\t\n\nO dataset original (sem modificaÃ§Ãµes) encontra-se em blogsetbr-original.csv (7.477.853\nregistros).\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Modificado\n\t\n\nUma cÃ³pia modificada do dataset pode ser encontrada em blogsetbr-modificado.csv (7.468.541\nregistros). Foi modificado:\n\nRemoÃ§Ã£o de registros duplicados e com problemas de escape (9.312 registros removidos).\nAdicionado um cabeÃ§alho ao arquivo.â€¦ See the full description on the dataset page: https://huggingface.co/datasets/tallesl/blogsetbr.","url":"https://huggingface.co/datasets/tallesl/blogsetbr","creator_name":"Talles L","creator_url":"https://huggingface.co/tallesl","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","Portuguese","apache-2.0","1M<n<10M","ðŸ‡ºðŸ‡¸ Region: US"],"keywords_longer_than_N":false},
	{"name":"olist_customers_review","keyword":"portuguese","description":"verissimomanoel/olist_customers_review dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/verissimomanoel/olist_customers_review","creator_name":"Manoel VerÃ­ssimo dos Santos Neto","creator_url":"https://huggingface.co/verissimomanoel","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","Portuguese","apache-2.0","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"ApolloMoEDataset","keyword":"portuguese","description":"\n\t\n\t\t\n\t\tDemocratizing Medical LLMs For Much More Languages\n\t\n\nCovering 12 Major Languages including English, Chinese, French, Hindi, Spanish, Arabic, Russian, Japanese, Korean, German, Italian, Portuguese and 38 Minor Languages So far.\n\n   ðŸ“ƒ Paper â€¢ ðŸŒ Demo â€¢ ðŸ¤— ApolloMoEDataset â€¢ ðŸ¤— ApolloMoEBench  â€¢ ðŸ¤— Models  â€¢ðŸŒ Apollo  â€¢ ðŸŒ ApolloMoE\n\n\n\n\n\n\n\t\n\t\t\n\t\tðŸŒˆ Update\n\t\n\n\n[2024.10.15] ApolloMoE repo is publishedï¼ðŸŽ‰\n\n\n\t\n\t\t\n\t\tLanguages Coverage\n\t\n\n12 Major Languages and 38 Minor Languages\n\n  Click toâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/FreedomIntelligence/ApolloMoEDataset.","url":"https://huggingface.co/datasets/FreedomIntelligence/ApolloMoEDataset","creator_name":"FreedomAI","creator_url":"https://huggingface.co/FreedomIntelligence","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["question-answering","Arabic","English","Chinese","Korean"],"keywords_longer_than_N":true},
	{"name":"quinquilharia","keyword":"portuguese","description":"\n\n\t\n\t\t\n\t\tQuinquilharia\n\t\n\nTextos variados em portuguÃªs do Brasil.\n\n\t\n\t\t\n\t\tFÃ³runs\n\t\n\n\n\t\n\t\t\nTema\nLink do fÃ³rum\nDataset com scrap realizado\n\n\n\t\t\nAgility (esporte)\n[agilityrj.forumeiros.com][agilityrj]\nagilityrj.csv (~10 mil postagens)\n\n\nArtes marciais\n[forum.bjjforum.com.br][bjjforum]\nbjjforum.csv (~318 mil postagens)\n\n\nArtes marciais\n[ufconfantasy.forumeiros.com][ufconfantasy]\nufconfantasy.csv (~120 mil postagens)\n\n\nArtesanato\n[atelierdasartes.forumeiros.com][atelierdasartes]\natelierdasartes.csvâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/tallesl/quinquilharia.","url":"https://huggingface.co/datasets/tallesl/quinquilharia","creator_name":"Talles L","creator_url":"https://huggingface.co/tallesl","license_name":"The Unlicense","license_url":"https://choosealicense.com/licenses/unlicense/","language":"en","first_N":5,"first_N_keywords":["text-generation","Portuguese","unlicense","ðŸ‡ºðŸ‡¸ Region: US"],"keywords_longer_than_N":false},
	{"name":"licCorpus","keyword":"portuguese","description":"\n\t\n\t\t\n\t\tDescriÃ§Ã£o\n\t\n\nO Lic Corpus Ã© um conjunto de dados focado no domÃ­nio jurÃ­dico e de licitaÃ§Ãµes, composto por documentos como editais de licitaÃ§Ã£o, contratos pÃºblicos e legislaÃ§Ãµes relacionadas a processos licitatÃ³rios. Este dataset foi projetado para ser utilizado no prÃ©-treinamento de modelos de linguagem, especialmente para tarefas de Processamento de Linguagem Natural (PLN) no contexto de licitaÃ§Ãµes e contratos pÃºblicos no Brasil.\nOs dados foram extraÃ­dos de fontes como o Comprasnetâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/vic35get/licCorpus.","url":"https://huggingface.co/datasets/vic35get/licCorpus","creator_name":"Victor Ribeiro da Silva","creator_url":"https://huggingface.co/vic35get","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["fill-mask","Portuguese","apache-2.0","1M - 10M","parquet"],"keywords_longer_than_N":true},
	{"name":"MLSNT","keyword":"portuguese","description":"\n\t\n\t\t\n\t\tMLSNT: Multi-Lingual Social Network Toxicity Dataset\n\t\n\nMLSNT is a multi-lingual dataset for toxicity detection created through a large language model-assisted label transfer pipeline. It enables efficient and scalable moderation across languages and platforms, and is built to support span-level and category-specific classification for toxic content.\nThis dataset is introduced in the following paper:\n\nUnified Game Moderation: Soft-Prompting and LLM-Assisted Label Transfer forâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/ComplexDataLab/MLSNT.","url":"https://huggingface.co/datasets/ComplexDataLab/MLSNT","creator_name":"Complex Data Lab","creator_url":"https://huggingface.co/ComplexDataLab","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","Chinese","Japanese","Portuguese"],"keywords_longer_than_N":true},
	{"name":"cetacean-ptbr","keyword":"portuguese","description":"This dataset is a merge of Open-Orca and Dolphin translated to portuguese.\n","url":"https://huggingface.co/datasets/lucianosb/cetacean-ptbr","creator_name":"Luciano Santa BrÃ­gida","creator_url":"https://huggingface.co/lucianosb","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["Portuguese","mit","1M - 10M","parquet","Text"],"keywords_longer_than_N":true},
	{"name":"P-MMEval","keyword":"portuguese","description":"\n\t\n\t\t\n\t\tP-MMEval: A Parallel Multilingual Multitask Benchmark for Consistent Evaluation of LLMs\n\t\n\n\n\t\n\t\t\n\t\tIntroduction\n\t\n\nWe introduce a multilingual benchmark, P-MMEval, covering effective fundamental and capability-specialized datasets. We extend the existing benchmarks, ensuring consistent language coverage across all datasets and providing parallel samples among multiple languages, supporting up to 10 languages from 8 language families (i.e., en, zh, ar, es, ja, ko, th, fr, pt, vi). As aâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Qwen/P-MMEval.","url":"https://huggingface.co/datasets/Qwen/P-MMEval","creator_name":"Qwen","creator_url":"https://huggingface.co/Qwen","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["Arabic","Spanish","French","Japanese","Korean"],"keywords_longer_than_N":true},
	{"name":"muri-it-language-split","keyword":"portuguese","description":"\n\t\n\t\t\n\t\tMURI-IT: Multilingual Instruction Tuning Dataset for 200 Languages via Multilingual Reverse Instructions\n\t\n\nMURI-IT is a large-scale multilingual instruction tuning dataset containing 2.2 million instruction-output pairs across 200 languages. It is designed to address the challenges of instruction tuning in low-resource languages with Multilingual Reverse Instructions (MURI), which ensures that the output is human-written, high-quality, and authentic to the cultural and linguisticâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/akoksal/muri-it-language-split.","url":"https://huggingface.co/datasets/akoksal/muri-it-language-split","creator_name":"Abdullatif Koksal","creator_url":"https://huggingface.co/akoksal","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text2text-generation","text-generation","question-answering","summarization","Achinese"],"keywords_longer_than_N":true},
	{"name":"AfriSentiClassification","keyword":"portuguese","description":"\n  AfriSentiClassification\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nAfriSenti is the largest sentiment analysis dataset for under-represented African languages.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2c\n\n\nDomains\nSocial, Written\n\n\nReferencehttps://arxiv.org/abs/2302.08956\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask = mteb.get_tasks([\"AfriSentiClassification\"])\nevaluator = mteb.MTEB(task)\n\nmodelâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/AfriSentiClassification.","url":"https://huggingface.co/datasets/mteb/AfriSentiClassification","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","sentiment-analysis","sentiment-scoring","sentiment-classification","hate-speech-detection"],"keywords_longer_than_N":true},
	{"name":"oaast_rm_full_jieba","keyword":"portuguese","description":"å°è¯•è§£å†³\"llm repetition problem\"ï¼Œä½¿ç”¨åˆ†è¯æ¨¡åž‹å¯¹oaastè¯­æ–™è¿›è¡Œâ€œç»“å·´åŒ–â€æ•°æ®å¢žå¼ºï¼Œæä¾›æ›´å¼ºçš„é‡å¤å†…å®¹æ‹’ç»æ•ˆæžœã€‚\nAttempts to solve the \"llm repetition problem\" by using a segmentation model to enhance the oaast corpus with \"stuttering\" data to provide stronger rejection of duplicate content.\nå…¶æ¬¡ï¼Œè¿˜è¿‡æ»¤æŽ‰äº†æ‰€æœ‰è‡ªæˆ‘è®¤çŸ¥çš„å¾®è°ƒæ ·æœ¬ã€‚\nSecond, it also filters out all the fine-tuned samples of self-cognition.\nfiles:\n\noaast_rm_full_jieba.jsonl : word level repeat\noaast_rm_full_sent_jieba.jsonl : sentence level repeat\n\n","url":"https://huggingface.co/datasets/lenML/oaast_rm_full_jieba","creator_name":"len","creator_url":"https://huggingface.co/lenML","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["English","Spanish","Russian","German","Polish"],"keywords_longer_than_N":true},
	{"name":"BRIGHTER-emotion-categories","keyword":"portuguese","description":"\n\t\n\t\t\n\t\tBRIGHTER Emotion Categories Dataset\n\t\n\nThis dataset contains the emotion categories data from the BRIGHTER paper: BRIdging the Gap in Human-Annotated Textual Emotion Recognition Datasets for 28 Languages.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe BRIGHTER Emotion Categories dataset is a comprehensive multi-language, multi-label emotion classification dataset with separate configurations for each language. It represents one of the largest human-annotated emotion datasets across multipleâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/brighter-dataset/BRIGHTER-emotion-categories.","url":"https://huggingface.co/datasets/brighter-dataset/BRIGHTER-emotion-categories","creator_name":"BRIGHTER Dataset","creator_url":"https://huggingface.co/brighter-dataset","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["Afrikaans","Arabic","German","English","Spanish"],"keywords_longer_than_N":true},
	{"name":"instruct-aira-dataset-v2","keyword":"portuguese","description":"\n\t\n\t\t\n\t\tInstruct-Aira Dataset version 2.0\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset contains a collection of single-turn conversations between an assistant and a user. Conversations were generated by user interactions with already-tuned models (ChatGPT, LLama 2, Open-Assistant, etc). The dataset is available in Portuguese and English.\n\n\t\n\t\t\n\t\tSupported Tasks and Leaderboards\n\t\n\nThis dataset can be utilized for various natural language processing tasks, including but not limited to:\n\nLanguageâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/nicholasKluge/instruct-aira-dataset-v2.","url":"https://huggingface.co/datasets/nicholasKluge/instruct-aira-dataset-v2","creator_name":"Nicholas Kluge CorrÃªa","creator_url":"https://huggingface.co/nicholasKluge","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","Portuguese","English","apache-2.0","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"aya_evaluation_suite","keyword":"portuguese","description":"\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nAya Evaluation Suite contains a total of 26,750 open-ended conversation-style prompts to evaluate multilingual open-ended generation quality.To strike a balance between language coverage and the quality that comes with human curation, we create an evaluation suite that includes:\n\nhuman-curated examples in 7 languages (tur, eng, yor, arb, zho, por, tel) â†’ aya-human-annotated.\nmachine-translations of handpicked examples into 101 languages â†’ dolly-machine-translated.â€¦ See the full description on the dataset page: https://huggingface.co/datasets/CohereLabs/aya_evaluation_suite.","url":"https://huggingface.co/datasets/CohereLabs/aya_evaluation_suite","creator_name":"Cohere Labs","creator_url":"https://huggingface.co/CohereLabs","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","crowdsourced","expert-generated","machine-generated","multilingual"],"keywords_longer_than_N":true},
	{"name":"YouTube-Commons","keyword":"portuguese","description":"\n\t\n\t\t\n\t\tYouTube Commons Re-upload\n\t\n\nThis is a re-upload of PleIAs' YouTube Commons, a valuable open dataset:\n\nYouTube-Commons is a collection of audio transcripts of 2,063,066 videos shared on YouTube under a CC BY 4.0 license.\nContent\nThe collection comprises 22,709,724 original and automatically translated transcripts from 3,156,703 videos (721,136 individual channels).\n\nUnfortunately, there are problems with loading YouTube Commons with Hugging Face Datasets.\nIn order to alleviate thoseâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Rijgersberg/YouTube-Commons.","url":"https://huggingface.co/datasets/Rijgersberg/YouTube-Commons","creator_name":"Edwin Rijgersberg","creator_url":"https://huggingface.co/Rijgersberg","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","English","French","Spanish","Portuguese"],"keywords_longer_than_N":true},
	{"name":"webui-dom-snapshots","keyword":"portuguese","description":"\n\t\n\t\t\n\t\tDataset Card for WebUI DOM snapshots\n\t\n\n\n\nThis dataset card aims to be a base template for new datasets. It has been generated using this raw template.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\n\n\n\n\n\nCurated by: Gary Benson\nLanguages: Mostly English (87%);\nDutch, French, Chinese, Japanese (1-2% each); 30+ others (<1% each)\nLicense: CC0 1.0 Universal\n\n\n\t\n\t\t\n\t\tDataset Sources [optional]\n\t\n\n\n\n\nRepository: [More Information Needed]\nPaper [optional]: [More Information Needed]â€¦ See the full description on the dataset page: https://huggingface.co/datasets/gbenson/webui-dom-snapshots.","url":"https://huggingface.co/datasets/gbenson/webui-dom-snapshots","creator_name":"Gary Benson","creator_url":"https://huggingface.co/gbenson","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["image-feature-extraction","reinforcement-learning","text-classification","multilingual","biglab/webui-7k"],"keywords_longer_than_N":true},
	{"name":"panlex-meanings","keyword":"portuguese","description":"\n\t\n\t\t\n\t\tDataset Card for panlex-meanings\n\t\n\nThis is a dataset of words in several thousand languages, extracted from https://panlex.org.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset has been extracted from https://panlex.org (the 20240301 database dump) and rearranged on the per-language basis.\nEach language subset consists of expressions (words and phrases). \nEach expression is associated with some meanings (if there is more than one meaning, they are in separateâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/cointegrated/panlex-meanings.","url":"https://huggingface.co/datasets/cointegrated/panlex-meanings","creator_name":"David Dale","creator_url":"https://huggingface.co/cointegrated","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["translation","Afar","Western Abnaki","Abkhazian","Abaza"],"keywords_longer_than_N":true},
	{"name":"Multilingal-sakalt-data","keyword":"portuguese","description":"ãƒžãƒ«ãƒãƒªãƒ³ã‚¬ãƒ«ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã§ã™ã€‚mitãƒ©ã‚¤ã‚»ãƒ³ã‚¹ã§ã™ã€‚\n","url":"https://huggingface.co/datasets/Sakalti/Multilingal-sakalt-data","creator_name":"sakasan","creator_url":"https://huggingface.co/Sakalti","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-generation","Abkhaz","Bhojpuri","Chechen","Czech"],"keywords_longer_than_N":true},
	{"name":"tulu-3-sft-mixture-with-language","keyword":"portuguese","description":"\n\nJust a version of the good tulu-3-sft-mixture dataset with a column indicating language.\nLanguage detection has been performed with fastText.\nâš ï¸ It may contain errors.\n","url":"https://huggingface.co/datasets/anakin87/tulu-3-sft-mixture-with-language","creator_name":"Stefano Fiorucci","creator_url":"https://huggingface.co/anakin87","license_name":"Open Data Commons Attribution License v1.0","license_url":"https://scancode-licensedb.aboutcode.org/odc-by-1.0.html","language":"en","first_N":5,"first_N_keywords":["other","crowdsourced","expert-generated","machine-generated","multilingual"],"keywords_longer_than_N":true},
	{"name":"orca-math-portuguese-64k","keyword":"portuguese","description":"translated for:\n\n\nRepository: microsoft/orca-math-word-problems-200k\nPaper: Orca-Math: Unlocking the potential of\nSLMs in Grade School Math\n\n","url":"https://huggingface.co/datasets/rhaymison/orca-math-portuguese-64k","creator_name":"Rhaymison Cristian","creator_url":"https://huggingface.co/rhaymison","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","question-answering","Portuguese","apache-2.0","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"Lemonade","keyword":"portuguese","description":"LEMONADE is a large, expert-annotated dataset for event extraction from news articles in 20 languages: English, Spanish, Arabic, French, Italian, Russian, German, Turkish, Burmese, Indonesian, Ukrainian, Korean, Portuguese, Dutch, Somali, Nepali, Chinese, Persian, Hebrew, and Japanese.\nSee https://github.com/stanford-oval/Lemonade for details.\n","url":"https://huggingface.co/datasets/stanford-oval/Lemonade","creator_name":"Stanford Open Virtual Assistant Lab (OVAL)","creator_url":"https://huggingface.co/stanford-oval","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","text-generation","English","Spanish","Arabic"],"keywords_longer_than_N":true},
	{"name":"philosophy-culture-translations-html-csv","keyword":"portuguese","description":"\n\t\n\t\t\n\t\tAI-Culture Philosophy and Culture Translations CSV + HTML Corpus\n\t\n\nThe corpus contains an exceptionally diverse range of cultural, philosophical, and literary texts, available in 12 major languages. Among other topics, there is extensive engagement with the ethics and aesthetics of artificial intelligence and its cultural and philosophical implications, as well as connections between AI and philosophy of language and philosophy of mind.\nThis project is maintained by a non-profitâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/AI-Culture-Commons/philosophy-culture-translations-html-csv.","url":"https://huggingface.co/datasets/AI-Culture-Commons/philosophy-culture-translations-html-csv","creator_name":"AIâ€‘Cultureâ€‘Commons","creator_url":"https://huggingface.co/AI-Culture-Commons","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["translation","text-generation","text-classification","sentence-similarity","summarization"],"keywords_longer_than_N":true},
	{"name":"legislacao-ufam","keyword":"portuguese","description":"\n\t\n\t\t\n\t\tDataset: LegislaÃ§Ã£o AcadÃªmica da UFAM\n\t\n\nEste dataset contÃ©m textos da legislaÃ§Ã£o acadÃªmica de GraduaÃ§Ã£o da Universidade Federal do Amazonas (UFAM), extraÃ­dos de PDFs atravÃ©s do uso do Tesseract OCR com \nsupervisÃ£o humana para garantir a qualidade dos textos. Documentos em pior qualidade foram digitados manualmente para formar arquivos TXT precisos.\n\n\t\n\t\t\n\t\tEstrutura do Dataset\n\t\n\nO dataset Ã© organizado da seguinte forma:\nâ”œâ”€â”€ data\nâ”‚   â”œâ”€â”€ train.parquet\nâ”‚   â””â”€â”€ test.parquet\nâ”œâ”€â”€ faqs\nâ”‚â€¦ See the full description on the dataset page: https://huggingface.co/datasets/matiusX/legislacao-ufam.","url":"https://huggingface.co/datasets/matiusX/legislacao-ufam","creator_name":"Matheus Palheta","creator_url":"https://huggingface.co/matiusX","license_name":"Open Data Commons Attribution License v1.0","license_url":"https://scancode-licensedb.aboutcode.org/odc-by-1.0.html","language":"en","first_N":5,"first_N_keywords":["text-classification","text-generation","summarization","zero-shot-classification","text2text-generation"],"keywords_longer_than_N":true},
	{"name":"ProfessorHeidelTime","keyword":"portuguese","description":"\n\t\n\t\t\n\t\tProfessor HeidelTime\n\t\n\nPaper    GitHub\nProfessor HeidelTime is a project to create a multilingual corpus weakly labeled with HeidelTime, a temporal tagger.\n\n\t\n\t\t\n\t\tCorpus Details\n\t\n\nThe weak labeling was performed in six languages. Here are the specifics of the corpus for each language:\n\n\t\n\t\t\nDataset\nLanguage\nDocuments\nFrom\nTo\nTokens\nTimexs\n\n\n\t\t\nAll the News 2.0\nEN\n24,642\n2016-01-01\n2020-04-02\n18,755,616\n254,803\n\n\nItalian Crime News\nIT\n9,619\n2011-01-01\n2021-12-31\n3,296,898\n58,823â€¦ See the full description on the dataset page: https://huggingface.co/datasets/hugosousa/ProfessorHeidelTime.","url":"https://huggingface.co/datasets/hugosousa/ProfessorHeidelTime","creator_name":"Hugo Sousa","creator_url":"https://huggingface.co/hugosousa","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["token-classification","parsing","part-of-speech","named-entity-recognition","machine-generated"],"keywords_longer_than_N":true},
	{"name":"Evatraining3","keyword":"portuguese","description":"WDAlex/Evatraining3 dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/WDAlex/Evatraining3","creator_name":"Alexandre Henrique De Assis Silva","creator_url":"https://huggingface.co/WDAlex","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["Portuguese","mit","1K - 10K","json","Text"],"keywords_longer_than_N":true},
	{"name":"hatebr-omni-classification","keyword":"portuguese","description":"Este dataset contÃ©m uma classificaÃ§Ã£o de toxicidade e discurso de Ã³dio para comentÃ¡rios em portuguÃªs do Brasil, derivado do conhecido dataset HateBR.\nCada comentÃ¡rio foi analisado utilizando o modelo de moderaÃ§Ã£o omni-moderation-latest da OpenAI para identificar a categoria de conteÃºdo prejudicial mais provÃ¡vel e sua respectiva pontuaÃ§Ã£o (score). O objetivo Ã© fornecer um recurso para treinar e avaliar modelos de detecÃ§Ã£o de conteÃºdo tÃ³xico.\n\n\t\n\t\t\n\t\n\t\n\t\tMetodologia de GeraÃ§Ã£o\n\t\n\n\nDataset Base:â€¦ See the full description on the dataset page: https://huggingface.co/datasets/HRB25/hatebr-omni-classification.","url":"https://huggingface.co/datasets/HRB25/hatebr-omni-classification","creator_name":"Hugo Rios Brito","creator_url":"https://huggingface.co/HRB25","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","Portuguese","apache-2.0","1K - 10K","parquet"],"keywords_longer_than_N":true},
	{"name":"upvoteweb-posts","keyword":"portuguese","description":"\n\t\n\t\t\n\t\tupvoteweb: posts\n\t\n\nPosts in upvoteweb.\n\n\t\n\t\t\n\t\tconfigs\n\t\n\n\n[!IMPORTANT]There are several configs representing different permutations of this dataset. Load the relevant config for the task you are interested in.\n\nOverview of configs:\n\ndefault: largely unfiltered/unprocessed original data\neduscored: the \"eduscore\" predicted on the text column with huggingface's trained classifier\nen-clean: filter language for en and language_score for > 0.6. Run clean-text on the text col, preservingâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/BEE-spoke-data/upvoteweb-posts.","url":"https://huggingface.co/datasets/BEE-spoke-data/upvoteweb-posts","creator_name":"BEEspoke Data","creator_url":"https://huggingface.co/BEE-spoke-data","license_name":"Open Data Commons Attribution License v1.0","license_url":"https://scancode-licensedb.aboutcode.org/odc-by-1.0.html","language":"en","first_N":5,"first_N_keywords":["text-generation","feature-extraction","image-to-text","text-to-image","fill-mask"],"keywords_longer_than_N":true},
	{"name":"mosel","keyword":"portuguese","description":"\n\n\n\t\n\t\t\n\t\tDataset Description, Collection, and Source\n\t\n\nThe MOSEL corpus is a multilingual dataset collection including up to 950K hours of open-source speech recordings covering the 24 official languages of the European Union. We collect data by surveying labeled and unlabeled speech corpora under open-source compliant licenses.\nIn particular, MOSEL includes the automatic transcripts of 441k hours of unlabeled speech from VoxPopuli and LibriLight. The data is transcribed using Whisper largeâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/FBK-MT/mosel.","url":"https://huggingface.co/datasets/FBK-MT/mosel","creator_name":"FBK-MT","creator_url":"https://huggingface.co/FBK-MT","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","machine-generated","found","multilingual"],"keywords_longer_than_N":true},
	{"name":"extraglue","keyword":"portuguese","description":"\n\n\nÂ Â Â Â This is the dataset card for extraGLUE. \n  You may be interested in some of the other datasets for Portuguese and in the models trained with them, \n  namely Albertina (encoders) and GervÃ¡sio (decoders) families.\n\n\n\n\n\n\n\t\n\t\t\n\t\tExtraGLUE\n\t\n\n\n\n\nExtraGLUE is a Portuguese dataset obtained by the automatic translation of some of the tasks in the GLUE and SuperGLUE benchmarks.\nTwo variants of Portuguese are considered, namely European Portuguese and American Portuguese.\nThe dataset isâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/PORTULAN/extraglue.","url":"https://huggingface.co/datasets/PORTULAN/extraglue","creator_name":"PORTULAN","creator_url":"https://huggingface.co/PORTULAN","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","sentence-similarity","question-answering","language-modeling","multi-class-classification"],"keywords_longer_than_N":true},
	{"name":"MultiSimV2","keyword":"portuguese","description":"\n\t\n\t\t\n\t\tDataset Card for MultiSim Benchmark\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThe MultiSim benchmark is a growing collection of text simplification datasets targeted at sentence simplification in several languages.  Currently, the benchmark spans 12 languages.\n\n\n\t\n\t\n\t\n\t\tSupported Tasks\n\t\n\n\nSentence Simplification\n\n\n\t\n\t\n\t\n\t\tUsage\n\t\n\nfrom datasets importload_dataset\n\ndataset = load_dataset(\"MichaelR207/MultiSimV2\")\n\n\n\t\n\t\t\n\t\tCitation\n\t\n\nIf you use this benchmark, please cite our paper:â€¦ See the full description on the dataset page: https://huggingface.co/datasets/MichaelR207/MultiSimV2.","url":"https://huggingface.co/datasets/MichaelR207/MultiSimV2","creator_name":"Michael Ryan","creator_url":"https://huggingface.co/MichaelR207","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["summarization","text2text-generation","text-generation","English","French"],"keywords_longer_than_N":true},
	{"name":"MMMLU_subset","keyword":"portuguese","description":"\n\t\n\t\t\n\t\tAbout MMMLU subset\n\t\n\n  This is a subset of MMMLU, specifically, we sampled 10% of the original data to improve evaluation efficiency.\n  In addition, we categorize the questions into four categories by subject, i.e., STEM, HUMANITIES, SOCIAL SCIENCES, and OTHER, aligned with MMLU.\n\n\t\n\t\t\n\t\n\t\n\t\tMultilingual Massive Multitask Language Understanding (MMMLU)\n\t\n\nThe MMLU is a widely recognized benchmark of general knowledge attained by AI models. It covers a broad range of topics from 57â€¦ See the full description on the dataset page: https://huggingface.co/datasets/double7/MMMLU_subset.","url":"https://huggingface.co/datasets/double7/MMMLU_subset","creator_name":"Sen Yang","creator_url":"https://huggingface.co/double7","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["question-answering","Arabic","Bengali","German","Spanish"],"keywords_longer_than_N":true},
	{"name":"MAPS_Verified","keyword":"portuguese","description":"\n\t\n\t\t\n\t\tDataset Card for Multilingual Benchmark for Global Agent Performance and Security\n\t\n\nThis is the first Multilingual Agentic AI Benchmark for evaluating agentic AI systems across different languages and diverse tasks. Benchmark enables systematic analysis of how agents perform under multilingual conditions. This dataset contains 550 instances for GAIA, 660 instances for ASB, 737 instances for Maths, and 1100 instances for SWE. Each task was translated into 10 target languages resultingâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Fujitsu-FRE/MAPS_Verified.","url":"https://huggingface.co/datasets/Fujitsu-FRE/MAPS_Verified","creator_name":"Fujitsu Research of Europe","creator_url":"https://huggingface.co/Fujitsu-FRE","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-generation","question-answering","Arabic","English","Japanese"],"keywords_longer_than_N":true},
	{"name":"Discord-Unveiled-Compressed","keyword":"portuguese","description":"\n\n.hf-sanitized.hf-sanitized-j1_tz_W_VRFLnAn8gnmpk .container { --bg-primary: #0d0511; --bg-secondary: #1a0f1f; --bg-tertiary: #2d1b35; --bg-card: #3d2847; --text-primary: #fef7ff; --text-secondary: #f0d9ff; --text-muted: #c084fc; --pink-soft: #fce7f3; --pink-medium: #f9a8d4; --pink-bright: #ec4899; --pink-hot: #e91e63; --pink-neon: #ff1493; --purple-soft: #e879f9; --purple-bright: #c026d3; --purple-deep: #7c3aed; --border-glow: #f472b6; --shadow-pink: rgba(244, 114, 182, 0.4);â€¦ See the full description on the dataset page: https://huggingface.co/datasets/SaisExperiments/Discord-Unveiled-Compressed.","url":"https://huggingface.co/datasets/SaisExperiments/Discord-Unveiled-Compressed","creator_name":"Sai","creator_url":"https://huggingface.co/SaisExperiments","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["English","Spanish","French","Portuguese","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"constituicao","keyword":"portuguese","description":"falabrasil/constituicao dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/falabrasil/constituicao","creator_name":"Grupo FalaBrasil","creator_url":"https://huggingface.co/falabrasil","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","Portuguese","mit","1K - 10K","webdataset"],"keywords_longer_than_N":true},
	{"name":"wikiixc","keyword":"portuguese","description":"cleitonparis/wikiixc dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/cleitonparis/wikiixc","creator_name":"Cleiton Paris","creator_url":"https://huggingface.co/cleitonparis","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":null,"first_N":5,"first_N_keywords":["token-classification","Portuguese","apache-2.0","ðŸ‡ºðŸ‡¸ Region: US","Not-For-All-Audiences"],"keywords_longer_than_N":false},
	{"name":"testdata","keyword":"portuguese","description":"leoloko/testdata dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/leoloko/testdata","creator_name":"Leonardo","creator_url":"https://huggingface.co/leoloko","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["Portuguese","apache-2.0","< 1K","csv","Text"],"keywords_longer_than_N":true},
	{"name":"re_dial_ptbr","keyword":"portuguese","description":"\n\t\n\t\t\n\t\tDataset Card for ReDial - PTBR\n\t\n\n\nOriginal dataset: Redial Huggingface\nHomepage: ReDial Dataset\nRepository: ReDialData\nPaper: Towards Deep Conversational Recommendations\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThe ReDial (Recommendation Dialogues) PTBR dataset is an annotated collection of dialogues where users recommend movies to each other translated to brazilian portuguese.\nThe adapted version of this dataset in Brazilian Portuguese was translated by the Maritalk. This translated versionâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/matheusrdgsf/re_dial_ptbr.","url":"https://huggingface.co/datasets/matheusrdgsf/re_dial_ptbr","creator_name":"Matheus Rodrigues de Souza FÃ©lix","creator_url":"https://huggingface.co/matheusrdgsf","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","text2text-generation","translation","Portuguese","English"],"keywords_longer_than_N":true},
	{"name":"Discord-Unveiled","keyword":"portuguese","description":"This dataset accompanies a paper submitted to ICWSM 2025 and includes data from 3,167 distinct public Discord servers, containing all their public messages.\nWith over 2 billion messages, the dataset is organized into 3,167 individual JSON files, each named after the corresponding server's ID.\nAn additional file, servers.json, provides an overview, description, metadata, and a guide for all the servers. For further details, please refer to the paper.\nPaper link: arXiv\nBibTeX formatted citation:â€¦ See the full description on the dataset page: https://huggingface.co/datasets/fvdfs41/Discord-Unveiled.","url":"https://huggingface.co/datasets/fvdfs41/Discord-Unveiled","creator_name":"yea","creator_url":"https://huggingface.co/fvdfs41","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":null,"first_N":5,"first_N_keywords":["English","Spanish","French","Portuguese","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"webfaq","keyword":"portuguese","description":"WebFAQ Q&A Dataset\n\n   \n       Overview |\n       Details  |\n       Structure  |\n       Examples |\n       Considerations |\n       License |\n       Citation |\n       Contact |\n       Acknowledgement\n   \n\n\n\n\t\n\t\t\n\t\n\t\n\t\tOverview\n\t\n\nThe WebFAQ Q&A Dataset is a broad-coverage corpus of 96 million natural question-answer (QA) pairs in 75 languages, gathered from FAQ pages on the web. It leverages structured schema.org FAQPage annotations, making it a unique resource for large-scale Question Answeringâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/PaDaS-Lab/webfaq.","url":"https://huggingface.co/datasets/PaDaS-Lab/webfaq","creator_name":"Chair of Data Science, University of Passau","creator_url":"https://huggingface.co/PaDaS-Lab","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["question-answering","multilingual","Afrikaans","Amharic","Arabic"],"keywords_longer_than_N":true},
	{"name":"floras","keyword":"portuguese","description":"\n\t\n\t\t\n\t\tFLORAS\n\t\n\nFLORAS is a 50-language benchmark For LOng-form Recognition And Summarization of spoken language. \nThe goal of FLORAS is to create a more realistic benchmarking environment for speech recognition, translation, and summarization models. \nUnlike typical academic benchmarks like LibriSpeech and FLEURS that uses pre-segmented single-speaker read-speech, FLORAS tests the capabilities of models on raw long-form conversational audio, which can have one or many speakers.\nTo encourageâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/espnet/floras.","url":"https://huggingface.co/datasets/espnet/floras","creator_name":"ESPnet","creator_url":"https://huggingface.co/espnet","license_name":"Creative Commons Attribution 3.0","license_url":"https://scancode-licensedb.aboutcode.org/cc-by-3.0.html","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","translation","summarization","English","Spanish"],"keywords_longer_than_N":true},
	{"name":"meudata","keyword":"portuguese","description":"EronSamez/meudata dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/EronSamez/meudata","creator_name":"Samez","creator_url":"https://huggingface.co/EronSamez","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","Portuguese","apache-2.0","< 1K","json"],"keywords_longer_than_N":true},
	{"name":"mgi__notas_fiscais","keyword":"portuguese","description":"\n\t\n\t\t\n\t\tDataset Card: mgi__notas_fiscais\n\t\n\nFiltered and enriched version of [cgu__notas_fiscais]\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\n\n\n\nCurated by: Fred Guth (@fredguth)\nFunded by: World Bank\nLanguage(s) (NLP): pt-br\nLicense: CC-BY 4.0\n\n\n\t\n\t\t\n\t\tDataset Sources\n\t\n\ncgu__notas_fiscais\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\n\t\n\t\t\n\t\titens_notas\n\t\n\n\n\t\n\t\t\ncolumn_name\ndata_type\ncomment\n\n\n\t\t\nchave_acesso\nVARCHAR\nidentificador da nota fiscal em que este item foi registrado.\n\n\nserieâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fredguth/mgi__notas_fiscais.","url":"https://huggingface.co/datasets/fredguth/mgi__notas_fiscais","creator_name":"Fred Guth","creator_url":"https://huggingface.co/fredguth","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["tabular-classification","Portuguese","cc-by-4.0","10M - 100M","parquet"],"keywords_longer_than_N":true},
	{"name":"realtor-conversational-portuguese_br","keyword":"portuguese","description":"\n\t\n\t\t\n\t\tRealtor Conversational (Portuguese BR) - Realtor-Client Conversation Dataset\n\t\n\n\n\t\n\t\t\n\t\tDetailed Dataset Description\n\t\n\nIntroduction:\nThis dataset, named \"Realtor Conversational (Portuguese BR)\", offers rich and detailed simulations of conversational interactions between real estate agents (realtors) and clients in Brazil. Generated using the advanced language model gpt-4o-mini, the data is synthetic but designed to mirror the dynamics, vocabulary, and common scenarios found in theâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/bobboyms/realtor-conversational-portuguese_br.","url":"https://huggingface.co/datasets/bobboyms/realtor-conversational-portuguese_br","creator_name":"Thiago Luiz Rodrigues","creator_url":"https://huggingface.co/bobboyms","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","Portuguese","apache-2.0","1K<n<10K","ðŸ‡ºðŸ‡¸ Region: US"],"keywords_longer_than_N":false},
	{"name":"medicine-medical_meadow_wikidoc_pt","keyword":"portuguese","description":"rhaymison/medicine-medical_meadow_wikidoc_pt dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/rhaymison/medicine-medical_meadow_wikidoc_pt","creator_name":"Rhaymison Cristian","creator_url":"https://huggingface.co/rhaymison","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","Portuguese","apache-2.0","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"bio-mqm-dataset","keyword":"portuguese","description":"This dataset is compiled from the official Amazon repository (all respective licensing applies).\nIt contains system translations, multiple references, and their quality evaluation on the MQM scale. It accompanies the ACL 2024 paper Fine-Tuned Machine Translation Metrics Struggle in Unseen Domains.\nWatch a brief 4 minutes-long video.\n\nAbstract: We introduce a new, extensive multidimensional quality metrics (MQM) annotated dataset covering 11 language pairs in the biomedical domain. We use thisâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/zouharvi/bio-mqm-dataset.","url":"https://huggingface.co/datasets/zouharvi/bio-mqm-dataset","creator_name":"VilÃ©m Zouhar","creator_url":"https://huggingface.co/zouharvi","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["translation","English","German","Spanish","Basque"],"keywords_longer_than_N":true},
	{"name":"wikifacts-bench","keyword":"portuguese","description":"kaengreg/wikifacts-bench dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/kaengreg/wikifacts-bench","creator_name":"Grigory Kovalev","creator_url":"https://huggingface.co/kaengreg","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["Russian","English","German","French","Portuguese"],"keywords_longer_than_N":true},
	{"name":"Emakhuwa-News-Topic-Classification","keyword":"portuguese","description":"BibTeX:\nThe dataset paper was published in EMNLP 2024.\nPlease cite as:\n@inproceedings{ali-etal-2024-building,\n    title = \"Building Resources for Emakhuwa: Machine Translation and News Classification Benchmarks\",\n    author = \"Ali, Felermino D. M. A.  and\n      Lopes Cardoso, Henrique  and\n      Sousa-Silva, Rui\",\n    editor = \"Al-Onaizan, Yaser  and\n      Bansal, Mohit  and\n      Chen, Yun-Nung\",\n    booktitle = \"Proceedings of the 2024 Conference on Empirical Methods in Natural Languageâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/LIACC/Emakhuwa-News-Topic-Classification.","url":"https://huggingface.co/datasets/LIACC/Emakhuwa-News-Topic-Classification","creator_name":"LIACC","creator_url":"https://huggingface.co/LIACC","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["translation","text-classification","Makhuwa","Portuguese","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"text-to-icpc2","keyword":"portuguese","description":"\n\t\n\t\t\n\t\tDataset Card for Dataset Name\n\t\n\n\n\n\n\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\n\n\nThis dataset to train a text classification model for  ICPC2 codes in portuguese\n\nCurated by: [More Information Needed]\nFunded by [optional]: [More Information Needed]\nShared by [optional]: [More Information Needed]\nLanguage(s) (NLP): pt\nLicense: apache-2.0\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Sources [optional]\n\t\n\n\n\n\nRepository: https://github.com/diogocarapito/text-to-icpc2\nPaper [optional]: [Moreâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/diogocarapito/text-to-icpc2.","url":"https://huggingface.co/datasets/diogocarapito/text-to-icpc2","creator_name":"Diogo Carapito","creator_url":"https://huggingface.co/diogocarapito","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","Portuguese","apache-2.0","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"MultiEup-v2","keyword":"portuguese","description":"\n\t\n\t\t\n\t\tMulti-EuP-v2\n\t\n\nThis dataset card documents Multi-EuP-v2, a multilingual corpus of European Parliament debate speeches enriched with Member of European Parliament (MEP) metadata and multilingual debate titles/IDs. It supports research on political text analysis, speaker-attribute prediction, stance/vote prediction, multilingual NLP, and retrieval.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nMulti-EuP-v2 aggregates 50,337 debate speeches (each a unique did) in 24â€¦ See the full description on the dataset page: https://huggingface.co/datasets/unimelb-nlp/MultiEup-v2.","url":"https://huggingface.co/datasets/unimelb-nlp/MultiEup-v2","creator_name":"The University of Melbourne","creator_url":"https://huggingface.co/unimelb-nlp","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","text-retrieval","text-generation","multilingual","Bulgarian"],"keywords_longer_than_N":true},
	{"name":"synthetic_transcript_pt","keyword":"portuguese","description":"\n\t\n\t\t\n\t\tPortuguese Speech Dataset with Multiple Training Configurations\n\t\n\nA comprehensive Portuguese speech dataset offering three distinct training configurations for speech recognition research, each designed for different experimental scenarios and training paradigms.\n\n\t\n\t\t\n\t\tðŸŽ¯ Dataset Configurations Overview\n\t\n\nThis dataset provides three carefully curated subsets to enable comprehensive speech recognition research:\n\n\t\n\t\t\nConfiguration\nTraining Data\nValidation\nTest\nTotal Samples\nUse Caseâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/yuriyvnv/synthetic_transcript_pt.","url":"https://huggingface.co/datasets/yuriyvnv/synthetic_transcript_pt","creator_name":"Yuriy Perezhohin","creator_url":"https://huggingface.co/yuriyvnv","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","audio-classification","Portuguese","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"synthetic_transcript_pt","keyword":"portuguese","description":"\n\t\n\t\t\n\t\tPortuguese Speech Dataset with Multiple Training Configurations\n\t\n\nA comprehensive Portuguese speech dataset offering three distinct training configurations for speech recognition research, each designed for different experimental scenarios and training paradigms.\n\n\t\n\t\t\n\t\tðŸŽ¯ Dataset Configurations Overview\n\t\n\nThis dataset provides three carefully curated subsets to enable comprehensive speech recognition research:\n\n\t\n\t\t\nConfiguration\nTraining Data\nValidation\nTest\nTotal Samples\nUse Caseâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/yuriyvnv/synthetic_transcript_pt.","url":"https://huggingface.co/datasets/yuriyvnv/synthetic_transcript_pt","creator_name":"Yuriy Perezhohin","creator_url":"https://huggingface.co/yuriyvnv","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","audio-classification","Portuguese","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"MAPS","keyword":"portuguese","description":"\n\t\n\t\t\n\t\tDataset Card for Multilingual Benchmark for Global Agent Performance and Security\n\t\n\nThis is the first Multilingual Agentic AI Benchmark for evaluating agentic AI systems across different languages and diverse tasks. Benchmark enables systematic analysis of how agents perform under multilingual conditions. To balance performance and safety evaluation, our benchmark comprises 805 tasks: 405 from performance-oriented datasets (GAIA, SWE-bench, MATH) and 400 from the Agent Securityâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Fujitsu-FRE/MAPS.","url":"https://huggingface.co/datasets/Fujitsu-FRE/MAPS","creator_name":"Fujitsu Research of Europe","creator_url":"https://huggingface.co/Fujitsu-FRE","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-generation","question-answering","Arabic","English","Japanese"],"keywords_longer_than_N":true},
	{"name":"dou-brazil-dataset","keyword":"portuguese","description":"\n\t\n\t\t\n\t\tDataset Card for Dataset DiÃ¡rio Oficial da UniÃ£o (DOU)\n\t\n\n\n\nThe DiÃ¡rio Oficial da UniÃ£o (DOU) is the official government gazette of Brazil, published by the National Press. It serves as the primary means of communication for federal government acts, including laws, decrees, ordinances, public notices, and other official decisions. The DOU ensures transparency and legal validity for government actions and is divided into three sections:  \n\nSection 1: Publishes laws, decrees, andâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/gerson-vfs/dou-brazil-dataset.","url":"https://huggingface.co/datasets/gerson-vfs/dou-brazil-dataset","creator_name":"Gerson Victor Vieira Fontenele da Silva","creator_url":"https://huggingface.co/gerson-vfs","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-generation","Portuguese","mit","100K - 1M","csv"],"keywords_longer_than_N":true},
	{"name":"HPLT2.0_cleaned","keyword":"portuguese","description":"This is a large-scale collection of web-crawled documents in 191 world languages, produced by the HPLT project. \nThe source of the data is mostly Internet Archive with some additions from Common Crawl.\nFor a detailed description of the dataset, please refer to https://hplt-project.org/datasets/v2.0\nThe Cleaned variant of HPLT Datasets v2.0\nThis is the cleaned variant of the HPLT Datasets v2.0 converted to the Parquet format semi-automatically when being uploaded here. \nThe original JSONL filesâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/jobs-git/HPLT2.0_cleaned.","url":"https://huggingface.co/datasets/jobs-git/HPLT2.0_cleaned","creator_name":"James Guana","creator_url":"https://huggingface.co/jobs-git","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["fill-mask","text-generation","language-modeling","multilingual","Achinese"],"keywords_longer_than_N":true},
	{"name":"news-of-the-brazilian-newspaper","keyword":"portuguese","description":"\n\t\n\t\t\n\t\tNews of the Brazilian Newspaper\n\t\n\nThis repository contains a comprehensive dataset of news articles from a Brazilian newspaper, Folha de SÃ£o Paulo (http://www.folha.uol.com.br/). The dataset includes 167,053 examples of news articles, comprising headlines, URLs of articles, complete articles, and their respective categories. \n\n\t\n\t\t\n\t\tDataset Creation\n\t\n\nThe headlines were initially gathered from Inshorts and were then used to scrape the complete news articles from Folha de SÃ£o Paulo.â€¦ See the full description on the dataset page: https://huggingface.co/datasets/emdemor/news-of-the-brazilian-newspaper.","url":"https://huggingface.co/datasets/emdemor/news-of-the-brazilian-newspaper","creator_name":"Eduardo Morais","creator_url":"https://huggingface.co/emdemor","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","summarization","feature-extraction","text-generation","Portuguese"],"keywords_longer_than_N":true},
	{"name":"GlotCC-V1","keyword":"portuguese","description":"\n\t\n\t\t\n\t\tDataset Summary\n\t\n\n \n\nGlotCC-V1.0 is a document-level, general domain dataset derived from CommonCrawl, covering more than 1000 languages.It is built using the GlotLID language identification and Ungoliant pipeline from CommonCrawl.We release our pipeline as open-source at https://github.com/cisnlp/GlotCC.  \nList of Languages: See https://datasets-server.huggingface.co/splits?dataset=cis-lmu/GlotCC-V1 to get the list of splits available.\n\n\t\t\n\t\tUsage (Huggingface Hub -- Recommended)â€¦ See the full description on the dataset page: https://huggingface.co/datasets/cis-lmu/GlotCC-V1.","url":"https://huggingface.co/datasets/cis-lmu/GlotCC-V1","creator_name":"CIS, LMU Munich","creator_url":"https://huggingface.co/cis-lmu","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["multilingual","Abau","Amarasi","Abkhaz","Abkhazian"],"keywords_longer_than_N":true},
	{"name":"GlotCC-V1","keyword":"portuguese","description":"\n\t\n\t\t\n\t\tDataset Summary\n\t\n\n \n\nGlotCC-V1.0 is a document-level, general domain dataset derived from CommonCrawl, covering more than 1000 languages.It is built using the GlotLID language identification and Ungoliant pipeline from CommonCrawl.We release our pipeline as open-source at https://github.com/cisnlp/GlotCC.  \nList of Languages: See https://datasets-server.huggingface.co/splits?dataset=cis-lmu/GlotCC-V1 to get the list of splits available.\n\n\t\t\n\t\tUsage (Huggingface Hub -- Recommended)â€¦ See the full description on the dataset page: https://huggingface.co/datasets/cis-lmu/GlotCC-V1.","url":"https://huggingface.co/datasets/cis-lmu/GlotCC-V1","creator_name":"CIS, LMU Munich","creator_url":"https://huggingface.co/cis-lmu","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["multilingual","Abau","Amarasi","Abkhaz","Abkhazian"],"keywords_longer_than_N":true},
	{"name":"cgu__notas_fiscais","keyword":"portuguese","description":"\n\t\n\t\t\n\t\tDataset Card: cgu_notas_fiscais\n\t\n\nData from electronic invoices for federal government purchases made available by\nComptroller General of the Union (Controladoria-Geral da UniÃ£o), which is a\nBrazilian federal government agency responsible for oversight and transparency.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\n\n\n\nCurated by: Fred Guth (@fredguth)\nFunded by: World Bank\nLanguage(s) (NLP): pt-br\nLicense: CC-BY 4.0\n\n\n\t\n\t\t\n\t\tDataset Sources\n\t\n\nThe source of this datasetsâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fredguth/cgu__notas_fiscais.","url":"https://huggingface.co/datasets/fredguth/cgu__notas_fiscais","creator_name":"Fred Guth","creator_url":"https://huggingface.co/fredguth","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["tabular-classification","Portuguese","cc-by-4.0","10M - 100M","parquet"],"keywords_longer_than_N":true},
	{"name":"portuguese-classic-books-adapted-to-modern-portuguese-br","keyword":"portuguese","description":"Okay, here is the improved and expanded text translated into American English, including the corrected citation format.\n\n\n\t\n\t\t\n\t\tClassic Portuguese Language Books Adapted to Modern Brazilian Portuguese\n\t\n\n\n\t\n\t\t\n\t\tDetailed Dataset Description\n\t\n\nThis dataset presents a unique collection of texts derived from classic books of Portuguese language literature, with a strong representation of Brazilian authors. All selected works are in the public domain and were originally sourced from Projectâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/bobboyms/portuguese-classic-books-adapted-to-modern-portuguese-br.","url":"https://huggingface.co/datasets/bobboyms/portuguese-classic-books-adapted-to-modern-portuguese-br","creator_name":"Thiago Luiz Rodrigues","creator_url":"https://huggingface.co/bobboyms","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","Portuguese","apache-2.0","1K<n<10K","Text"],"keywords_longer_than_N":true},
	{"name":"community-alignment","keyword":"portuguese","description":"Community Alignment\n\nCommunity Alignment is a large-scale open source, multilingual and multi-turn preference dataset to align LLMs with human preferences across cultures. It features prompt-level overlap in annotators, enabling social-choice-based and distributional approaches to LLM alignment, as well as natural language explanations for choices.\n\n[Large-scale] ~200,000 comparisons of LLM responses, collected from >3,000 unique annotators who provided feedback at an individual level.â€¦ See the full description on the dataset page: https://huggingface.co/datasets/anon-submission00/community-alignment.","url":"https://huggingface.co/datasets/anon-submission00/community-alignment","creator_name":"anonymous","creator_url":"https://huggingface.co/anon-submission00","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["Hindi","English","French","Portuguese","Italian"],"keywords_longer_than_N":true},
	{"name":"fusion-synth-data-ufb","keyword":"portuguese","description":"\n\t\n\t\t\n\t\tOffline Synthetic Data (UFB) for: Making, not taking, the Best-of-N\n\t\n\n\n\t\n\t\t\n\t\tContent\n\t\n\nThis data contains completions for a 10,000 subset of the  UFB prompts (translated into 9 languages)  from 5 different teacher models and 2 aggregations:\nTeachers: We sample one completion from each of the following models at temperature T=0.3. For kimik2, qwen3, and deepseek-v3 we use TogetherAI, for gemma3-27b and command-a we use locally hosted images.\n\ngemma3-27b: GEMMA3-27B-IT\nkimik2:â€¦ See the full description on the dataset page: https://huggingface.co/datasets/CohereLabs/fusion-synth-data-ufb.","url":"https://huggingface.co/datasets/CohereLabs/fusion-synth-data-ufb","creator_name":"Cohere Labs","creator_url":"https://huggingface.co/CohereLabs","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-generation","English","French","German","Spanish"],"keywords_longer_than_N":true},
	{"name":"nanobeir-multilingual","keyword":"portuguese","description":"This multilingual collection is derived from the original English NanoBEIR datasets, which are smaller versions of BEIR datasets.\nThe compact size of these datasets makes them ideal for conducting quick and efficient evaluations during training.\nTo facilitate broader research in cross-lingual information retrieval, our dataset has been machine-translated from the original English\ninto eight additional languages: Arabic (ar), German (de), Spanish (es), French (fr), Italian (it), Norwegian (no)â€¦ See the full description on the dataset page: https://huggingface.co/datasets/lightonai/nanobeir-multilingual.","url":"https://huggingface.co/datasets/lightonai/nanobeir-multilingual","creator_name":"LightOn AI","creator_url":"https://huggingface.co/lightonai","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","French","Arabic","English","German"],"keywords_longer_than_N":true},
	{"name":"reasoning-multilingual-R1-Llama-70B-train","keyword":"portuguese","description":"\n\t\n\t\t\n\t\tlightblue/reasoning-multilingual-R1-Llama-70B-train\n\t\n\nThis is a multilingual reasoning dataset covering more than 30 languages.\nThis dataset was made by:\n\nSampling prompts from English datasets and translating them to various languages\nGenerating responses to these prompts 8 times using deepseek-ai/DeepSeek-R1-Distill-Llama-70B\nFiltering out <think> sections with incorrect language, non-fluent language, and incorrect answers\n\nThis dataset was then used to train a multilingualâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/lightblue/reasoning-multilingual-R1-Llama-70B-train.","url":"https://huggingface.co/datasets/lightblue/reasoning-multilingual-R1-Llama-70B-train","creator_name":"Lightblue KK.","creator_url":"https://huggingface.co/lightblue","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["Amharic","Arabic","Bengali","Chinese","Czech"],"keywords_longer_than_N":true},
	{"name":"quran","keyword":"portuguese","description":"\n\t\n\t\t\n\t\tDataset Card for the Quran\n\t\n\n\n\t\n\t\t\n\t\tSummary\n\t\n\nThe Quran with metadata, translations, and multiple Arabic text (can use specific types for embeddings, search, classification, and display). There are 126+ columns containing 43+ languages.\n\n\t\n\t\t\n\t\tTODO\n\t\n\n\n Add Tafsirs  \n Add topics/ontology\n\n\n\t\n\t\t\n\t\tUsage\n\t\n\nfrom datasets import load_dataset\n\nds = load_dataset(\"nazimali/quran\", split=\"train\")\nds\n\nOutput:\nDataset({\n    features: ['surah', 'ayah', 'surah-name', 'surah-total-ayas'â€¦ See the full description on the dataset page: https://huggingface.co/datasets/nazimali/quran.","url":"https://huggingface.co/datasets/nazimali/quran","creator_name":"Nazim Ali","creator_url":"https://huggingface.co/nazimali","license_name":"Creative Commons Attribution 3.0","license_url":"https://scancode-licensedb.aboutcode.org/cc-by-3.0.html","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","translation","feature-extraction","text-generation"],"keywords_longer_than_N":true},
	{"name":"wikipedia-2024-06-bge-m3","keyword":"portuguese","description":"\n\t\n\t\t\n\t\tWikipedia Embeddings with BGE-M3\n\t\n\nThis dataset contains embeddings from the\nJune 2024 Wikipedia dump\nfor the 11 most popular languages.\nThe embeddings are generated with the multilingual\nBGE-M3 model.\nThe dataset consists of Wikipedia articles split into paragraphs,\nand embedded with the aforementioned model.\nTo enhance search quality, the paragraphs are prefixed with their\nrespective article titles before embedding.\nAdditionally, paragraphs containing fewer than 100 charactersâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Upstash/wikipedia-2024-06-bge-m3.","url":"https://huggingface.co/datasets/Upstash/wikipedia-2024-06-bge-m3","creator_name":"Upstash","creator_url":"https://huggingface.co/Upstash","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["English","German","Spanish","Persian","French"],"keywords_longer_than_N":true},
	{"name":"tatoeba_kbd","keyword":"portuguese","description":"\n\t\n\t\t\n\t\tTatoeba Translations Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset contains parallel sentence translations from Tatoeba to Kabardian language (kbd), filtered by similarity score. The source languages are:\n\nGerman (deu)\nEnglish (eng)\nFrench (fra)\nPortuguese (por)\nRussian (rus)\nSpanish (spa)\nTurkish (tur)\n\nAll translations in this dataset are paired with Kabardian (kbd) as the target language.\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThe dataset consists of high-quality parallelâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/panagoa/tatoeba_kbd.","url":"https://huggingface.co/datasets/panagoa/tatoeba_kbd","creator_name":"adam panagov","creator_url":"https://huggingface.co/panagoa","license_name":"Creative Commons Attribution 2.0","license_url":"https://scancode-licensedb.aboutcode.org/cc-by-2.0.html","language":"en","first_N":5,"first_N_keywords":["translation","Kabardian","German","English","French"],"keywords_longer_than_N":true},
	{"name":"semeval-2025-task11-track-a","keyword":"portuguese","description":"\n\t\n\t\t\n\t\tSemEval 2025 Task 11 - Track A Dataset\n\t\n\nThis dataset contains the data for SemEval 2025 Task 11: Bridging the Gap in Text-Based Emotion Detection - Track A, organized as language-specific configurations.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset is a multi-language, multi-label emotion classification dataset with separate configurations for each language.\n\nTotal languages: 26 standard ISO codes\nTotal examples: 115159\nSplits: train, dev, test\n\n\n\t\n\t\t\n\t\tLanguage Configurations\n\t\n\nEachâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/vgaraujov/semeval-2025-task11-track-a.","url":"https://huggingface.co/datasets/vgaraujov/semeval-2025-task11-track-a","creator_name":"Vladimir Araujo","creator_url":"https://huggingface.co/vgaraujov","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["Afrikaans","Amharic","Arabic","German","English"],"keywords_longer_than_N":true},
	{"name":"aya_dataset","keyword":"portuguese","description":"\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThe Aya Dataset is a multilingual instruction fine-tuning dataset curated by an open-science community via Aya Annotation Platform from Cohere Labs. The dataset contains a total of 204k human-annotated prompt-completion pairs along with the demographics data of the annotators.\nThis dataset can be used to train, finetune, and evaluate multilingual LLMs.\n\nCurated by: Contributors of Aya Open Science Intiative.\n\nLanguage(s): 65 languages (71 including dialects &â€¦ See the full description on the dataset page: https://huggingface.co/datasets/CohereLabs/aya_dataset.","url":"https://huggingface.co/datasets/CohereLabs/aya_dataset","creator_name":"Cohere Labs","creator_url":"https://huggingface.co/CohereLabs","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["other","crowdsourced","expert-generated","crowdsourced","expert-generated"],"keywords_longer_than_N":true},
	{"name":"fleurs_clean","keyword":"portuguese","description":"\n\t\n\t\t\n\t\n\t\n\t\tFLEURS\n\t\n\nFleurs is the speech version of the FLoRes machine translation benchmark. \nWe use 2009 n-way parallel sentences from the FLoRes dev and devtest publicly available sets, in 102 languages. \nTraining sets have around 10 hours of supervision. Speakers of the train sets are different than speakers from the dev/test sets. Multilingual fine-tuning is\nused and â€unit error rateâ€ (characters, signs) of all languages is averaged. Languages and results are also grouped into sevenâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Helloworld668/fleurs_clean.","url":"https://huggingface.co/datasets/Helloworld668/fleurs_clean","creator_name":"zhide Tang","creator_url":"https://huggingface.co/Helloworld668","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","expert-generated","crowdsourced","machine-generated","crowdsourced"],"keywords_longer_than_N":true},
	{"name":"BRIGHTER-emotion-intensities","keyword":"portuguese","description":"\n\t\n\t\t\n\t\tBRIGHTER Emotion Intensities Dataset\n\t\n\nThis dataset contains the emotion intensities data from the BRIGHTER paper: BRIdging the Gap in Human-Annotated Textual Emotion Recognition Datasets for 28 Languages.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe BRIGHTER Emotion Intensities dataset is a comprehensive multi-language emotion intensity dataset with separate configurations for each language. It represents one of the largest human-annotated emotion datasets across multiple languages, providingâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/brighter-dataset/BRIGHTER-emotion-intensities.","url":"https://huggingface.co/datasets/brighter-dataset/BRIGHTER-emotion-intensities","creator_name":"BRIGHTER Dataset","creator_url":"https://huggingface.co/brighter-dataset","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["Arabic","German","English","Spanish","Hausa"],"keywords_longer_than_N":true},
	{"name":"Web-multilingual","keyword":"portuguese","description":"\n\t\n\t\t\n\t\tDataset Card for Dataset Name\n\t\n\nThis dataset contains 1,141 multilingual web pages.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\n Each page contains the visible text extracted from the page. Each page includes 2 or more languages, with 2 prominent languages. \n page.csv lists the 2 prominent for each page. The content of the page is found in the pages/ folder.\n The breakdown of languages is the following:\n   1705 en\n   1043 fr\n    336 zh\n     90 es\n     79 id\n     77 de\n     75 pt\n     40 it\n     34â€¦ See the full description on the dataset page: https://huggingface.co/datasets/MAximeSobrier/Web-multilingual.","url":"https://huggingface.co/datasets/MAximeSobrier/Web-multilingual","creator_name":"Maxime Sobrier","creator_url":"https://huggingface.co/MAximeSobrier","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","French","English","Chinese","Portuguese"],"keywords_longer_than_N":true},
	{"name":"multiblimp","keyword":"portuguese","description":"\n\t\n\t\t\n\t\tMultiBLiMP\n\t\n\nMultiBLiMP is a massively Multilingual Benchmark for Linguistic Minimal Pairs. The dataset is composed of synthetic pairs generated using Universal Dependencies and UniMorph.\nThe paper can be found here.\nWe split the data set by language: each language consists of a single .tsv file. The rows contain many attributes for a particular pair, most important are the sen and wrong_sen fields, which we use for evaluating the language models.\n\n\t\n\t\t\n\t\n\t\n\t\tUsing MultiBLiMP\n\t\n\nToâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/jumelet/multiblimp.","url":"https://huggingface.co/datasets/jumelet/multiblimp","creator_name":"Jaap Jumelet","creator_url":"https://huggingface.co/jumelet","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["multilingual","Buriat","Spanish","Sanskrit","Romanian"],"keywords_longer_than_N":true},
	{"name":"LegalSumm","keyword":"portuguese","description":"\n\t\n\t\t\n\t\tAnotated Dataset of Summaries of the Supreme Court of Justice of Portugal\n\t\n\nThis dataset contains 68 summaries of 12 judgments STJ annotated in several dimensions by legal experts. \n\n10 summaries are the summaries written by the judges themselves.\n29 summaries are extractive summaries generated by LexRank technique.\n30 summaries are abstractive summaries generated by Llamma LLM.\n\n\n\t\n\t\t\n\t\tDataset Content:\n\t\n\nCase information\n\nJudgment Name\n\nId of judgment\n\n\nReport Section\n\nJudgmentâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/MartimZanatti/LegalSumm.","url":"https://huggingface.co/datasets/MartimZanatti/LegalSumm","creator_name":"Martim Zanatti dos Santos Gomes da Silva","creator_url":"https://huggingface.co/MartimZanatti","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","Portuguese","mit","< 1K","csv"],"keywords_longer_than_N":true},
	{"name":"saude-coletiva","keyword":"portuguese","description":"\n\t\n\t\t\n\t\tDataset de SaÃºde Coletiva\n\t\n\nEste dataset contÃ©m informaÃ§Ãµes sobre saÃºde pÃºblica no Brasil, incluindo dados de mortalidade, internaÃ§Ãµes hospitalares e indicadores de saÃºde.\n\n\t\n\t\t\n\t\tConteÃºdo do Dataset\n\t\n\nO dataset contÃ©m os seguintes arquivos:\n\nsih_2000_2024.csv - Sistema de InformaÃ§Ãµes Hospitalares (SIH) contendo dados de internaÃ§Ãµes hospitalares de 2000 a 2024\nsim_limpo_e_alterado.csv - Sistema de InformaÃ§Ãµes sobre Mortalidade (SIM) processado\nsim_95_columns_versao_final.csv - VersÃ£oâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/feliperafael/saude-coletiva.","url":"https://huggingface.co/datasets/feliperafael/saude-coletiva","creator_name":"Felipe Rafael de Souza","creator_url":"https://huggingface.co/feliperafael","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["Portuguese","cc-by-4.0","ðŸ‡ºðŸ‡¸ Region: US","health","brazil"],"keywords_longer_than_N":true},
	{"name":"InferBR","keyword":"portuguese","description":"\n\t\n\t\t\n\t\tInferBR\n\t\n\nThis is the InferBR dataset for Natural Language Inference in Portuguese. This version removes the flagged low-quality samples from the original dataset,\nkeeping 10.528 samples. The Github repo with the raw data can be found at: https://github.com/lbencke/InferBR.\n\n\t\n\t\t\n\t\tColumns\n\t\n\nsentence_pair_id: Identifier for premise-hypothesis sentence pairs.\npremise: The premise sentence.\nhypothesis: The hypothesis sentence.\nlabel: The generated label for the hypothesis consideringâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/hapaxlegomenon/InferBR.","url":"https://huggingface.co/datasets/hapaxlegomenon/InferBR","creator_name":"Matheus Westhelle","creator_url":"https://huggingface.co/hapaxlegomenon","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","Portuguese","mit","10K - 100K","csv"],"keywords_longer_than_N":true},
	{"name":"Propbank-BR","keyword":"portuguese","description":"Problem in line 20727 with \\t missing\n","url":"https://huggingface.co/datasets/liaad/Propbank-BR","creator_name":"LIAAD, INESCTEC","creator_url":"https://huggingface.co/liaad","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["token-classification","Portuguese","mit","1K - 10K","parquet"],"keywords_longer_than_N":true},
	{"name":"Multi-EuP","keyword":"portuguese","description":"\n\t\n\t\t\n\t\tNOTES FOR DOWNLOAD!\n\t\n\n\nHighly recommend downloading it via the API:\n\ncurl -X GET \\\n     \"https://datasets-server.huggingface.co/first-rows?dataset=unimelb-nlp%2FMulti-EuP&config=default&split=full\"\n\n\nIf you are using the HuggingFace library, please follow these steps:\n\npip install datasets\n\nfrom datasets import load_dataset\n\ndataset = load_dataset(\"unimelb-nlp/Multi-EuP\", keep_default_na=False)\n\nNote: It's crucial to use keep_default_na=False because some datasets contain 'null'â€¦ See the full description on the dataset page: https://huggingface.co/datasets/unimelb-nlp/Multi-EuP.","url":"https://huggingface.co/datasets/unimelb-nlp/Multi-EuP","creator_name":"The University of Melbourne","creator_url":"https://huggingface.co/unimelb-nlp","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","English","German","French","Italian"],"keywords_longer_than_N":true},
	{"name":"lr-sum","keyword":"portuguese","description":"\n\t\n\t\t\n\t\tDataset Card for LR-Sum\n\t\n\nLR-Sum is a automatic summarization dataset of newswire text with a focus on less resourced languages with a cc-by 4.0 license.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nLR-Sum is a permissively-licensed dataset created with the goal of enabling further research in automatic summarization for less-resourced languages.\nLR-Sum contains human-written summaries for 39 languages, many of which are less-resourced. \nThe data is based on theâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/bltlab/lr-sum.","url":"https://huggingface.co/datasets/bltlab/lr-sum","creator_name":"Broadening Linguistic Technologies Lab (BLT Lab)","creator_url":"https://huggingface.co/bltlab","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["summarization","text-generation","found","found","multilingual"],"keywords_longer_than_N":true},
	{"name":"oscar-mini","keyword":"portuguese","description":"The Open Super-large Crawled ALMAnaCH coRpus is a huge multilingual corpus obtained by language classification and filtering of the Common Crawl corpus using the goclassy architecture.\\","url":"https://huggingface.co/datasets/nthngdy/oscar-mini","creator_name":"Nathan Godey","creator_url":"https://huggingface.co/nthngdy","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":null,"first_N":5,"first_N_keywords":["text-generation","language-modeling","no-annotation","found","multilingual"],"keywords_longer_than_N":true},
	{"name":"bnl_newspapers","keyword":"portuguese","description":"\n\t\n\t\t\n\t\tDataset Card for BnL Historical Newspapers\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThe BnL has digitised over 800.000 pages of Luxembourg newspapers. This dataset currently has one configuration covering a subset of these newspapers, which sit under the \"Processed Datasets\" collection. The BNL:\n\nprocessed all newspapers and monographs that are in the public domain and extracted the full text and associated meta data of every single article, section, advertisementâ€¦ The result is a large number ofâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/bnl-data/bnl_newspapers.","url":"https://huggingface.co/datasets/bnl-data/bnl_newspapers","creator_name":"BnL Open Data","creator_url":"https://huggingface.co/bnl-data","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","fill-mask","language-modeling","masked-language-modeling","no-annotation"],"keywords_longer_than_N":true},
	{"name":"para_crawl","keyword":"portuguese","description":"\n\t\n\t\t\n\t\tDataset Card for \"para_crawl\"\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nWeb-Scale Parallel Corpora for Official European Languages.\n\n\t\n\t\t\n\t\tSupported Tasks and Leaderboards\n\t\n\nMore Information Needed\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nMore Information Needed\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\n\t\n\t\t\n\t\tData Instances\n\t\n\n\n\t\n\t\t\n\t\tenbg\n\t\n\n\nSize of downloaded dataset files: 103.75 MB\nSize of the generated dataset: 356.54 MB\nTotal amount of disk used: 460.27 MB\n\nAn example of 'train' looks as follows.\nThis example was tooâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/ParaCrawl/para_crawl.","url":"https://huggingface.co/datasets/ParaCrawl/para_crawl","creator_name":"ParaCrawl","creator_url":"https://huggingface.co/ParaCrawl","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":null,"first_N":5,"first_N_keywords":["translation","no-annotation","found","translation","original"],"keywords_longer_than_N":true},
	{"name":"language_tags","keyword":"portuguese","description":"\n\t\n\t\t\n\t\tDescription\n\t\n\nDataset listing 27,328 languages and dialects (also includes macrolanguage names).For each language, either the ISO 639 code, the Glottolog code or both are provided.\n\n\t\n\t\t\n\t\tColumns\n\t\n\n\nEnglish_Name: Language name in English (e.g. \"French\").\nNative_Name: If value is not 0, corresponds to the name of the language by native speakers (e.g. \"FranÃ§ais\") which may have been found in Wikipedia's nativename field.\nGlottocode: The language tag in the Glottolog convention (e.g.â€¦ See the full description on the dataset page: https://huggingface.co/datasets/lbourdois/language_tags.","url":"https://huggingface.co/datasets/lbourdois/language_tags","creator_name":"LoÃ¯ck BOURDOIS","creator_url":"https://huggingface.co/lbourdois","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["Afade","ParÃ¡ ArÃ¡ra","Afar","Aka-Bea","Abon"],"keywords_longer_than_N":true},
	{"name":"fleurs","keyword":"portuguese","description":"\n\t\n\t\t\n\t\tFLEURS\n\t\n\nFleurs is the speech version of the FLoRes machine translation benchmark. \nWe use 2009 n-way parallel sentences from the FLoRes dev and devtest publicly available sets, in 102 languages. \nTraining sets have around 10 hours of supervision. Speakers of the train sets are different than speakers from the dev/test sets. Multilingual fine-tuning is\nused and â€unit error rateâ€ (characters, signs) of all languages is averaged. Languages and results are also grouped into sevenâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/cahya/fleurs.","url":"https://huggingface.co/datasets/cahya/fleurs","creator_name":"Cahya Wirawan","creator_url":"https://huggingface.co/cahya","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":null,"first_N":5,"first_N_keywords":["automatic-speech-recognition","expert-generated","crowdsourced","machine-generated","crowdsourced"],"keywords_longer_than_N":true},
	{"name":"all-scam-spam","keyword":"portuguese","description":"This is a large corpus of 42,619 preprocessed text messages and emails sent by humans in 43 languages. is_spam=1 means spam and is_spam=0 means ham.\n1040 rows of balanced data, consisting of casual conversations and scam emails in â‰ˆ10 languages, were manually collected and annotated by me, with some help from ChatGPT.\n\n\n\n\t\n\t\t\n\t\tSome preprcoessing algorithms\n\t\n\n\nspam_assassin.js, followed by spam_assassin.py\nenron_spam.py\n\n\n\n\n\t\n\t\t\n\t\tData composition\n\t\n\n\n\n\n\n\t\n\t\t\n\t\tDescription\n\t\n\nTo make the textâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/FredZhang7/all-scam-spam.","url":"https://huggingface.co/datasets/FredZhang7/all-scam-spam","creator_name":"Fred Zhang","creator_url":"https://huggingface.co/FredZhang7","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","zero-shot-classification","Norwegian","Spanish","Somali"],"keywords_longer_than_N":true},
	{"name":"testedata","keyword":"portuguese","description":"\n\t\n\t\t\n\t\tDataset Card for Dataset Name\n\t\n\n\n\nThis dataset aims to be a base template for new datasets and for testing code.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n2 image files in jpg format\n","url":"https://huggingface.co/datasets/Nuno-Tome/testedata","creator_name":"Nuno Tome","creator_url":"https://huggingface.co/Nuno-Tome","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["Portuguese","English","apache-2.0","< 1K","imagefolder"],"keywords_longer_than_N":true},
	{"name":"oasst2_top1_chat_format","keyword":"portuguese","description":"\n\t\n\t\t\n\t\tOpenAssistant TOP-1 Conversation Threads in huggingface chat format\n\t\n\nExport of oasst2 only top 1 threads in huggingface chat format\n\n\t\n\t\t\n\t\tScript\n\t\n\nThe convert script can be find here\n","url":"https://huggingface.co/datasets/blancsw/oasst2_top1_chat_format","creator_name":"Blanc Swan","creator_url":"https://huggingface.co/blancsw","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["English","Spanish","Russian","German","Polish"],"keywords_longer_than_N":true},
	{"name":"mittens","keyword":"portuguese","description":"\n\t\n\t\t\n\t\tMiTTenS: A Dataset for Evaluating Misgendering in Translation\n\t\n\nMisgendering is the act of referring to someone in a way that does not reflect their gender identity.  Translation systems, including foundation models capable of translation, can produce errors that result in misgendering harms. To measure the extent of such potential harms when translating into and out of English, we introduce a dataset, MiTTenS, covering 26 languages from a variety of language families and scriptsâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/google/mittens.","url":"https://huggingface.co/datasets/google/mittens","creator_name":"Google","creator_url":"https://huggingface.co/google","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["translation","Arabic","Finnish","Oromo","Ganda"],"keywords_longer_than_N":true},
	{"name":"blogset-br","keyword":"portuguese","description":"\n\t\n\t\t\n\t\tDataset Card for Dataset Name\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nEste Dataset foi criado a partir dos dados disponibilizados pelo Grupo de Processamento de Linguagem Natural da PUC-RS. O site oficial pode ser encontrado aqui: https://www.inf.pucrs.br/linatural/wordpress/recursos-e-ferramentas/blogset-br/\n\n\t\n\t\t\n\t\tSupported Tasks and Leaderboards\n\t\n\nIndicado para treinamento de modelos de linguagem.\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nPortuguÃªs do Brasil\n\n\t\n\t\t\n\t\tInitial Data Collection and Normalizationâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/thegoodfellas/blogset-br.","url":"https://huggingface.co/datasets/thegoodfellas/blogset-br","creator_name":"The Good Fellas","creator_url":"https://huggingface.co/thegoodfellas","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["Portuguese","apache-2.0","1M - 10M","text","Text"],"keywords_longer_than_N":true},
	{"name":"faquad","keyword":"portuguese","description":"Academic secretaries and faculty members of higher education institutions face a common problem: \n  the abundance of questions sent by academics \n  whose answers are found in available institutional documents. \nThe official documents produced by Brazilian public universities are vast and disperse, \n  which discourage students to further search for answers in such sources.\nIn order to lessen this problem, we present FaQuAD: \n  a novel machine reading comprehension dataset \n  in the domain of Brazilian higher education institutions. \nFaQuAD follows the format of SQuAD (Stanford Question Answering Dataset) [Rajpurkar et al. 2016]. \nIt comprises 900 questions about 249 reading passages (paragraphs), \n  which were taken from 18 official documents of a computer science college \n  from a Brazilian federal university \n  and 21 Wikipedia articles related to Brazilian higher education system. \nAs far as we know, this is the first Portuguese reading comprehension dataset in this format.","url":"https://huggingface.co/datasets/eraldoluis/faquad","creator_name":"Eraldo R. Fernandes","creator_url":"https://huggingface.co/eraldoluis","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":null,"first_N":5,"first_N_keywords":["question-answering","extractive-qa","expert-generated","found","monolingual"],"keywords_longer_than_N":true},
	{"name":"gender-by-name","keyword":"portuguese","description":"\n\t\n\t\t\n\t\tDataset Card for \"Gender-by-Name\"\n\t\n\nThis dataset attributes first names to genders, giving counts and probabilities. It combines open-source government data from the US, UK, Canada, and Australia. The dataset is taken from UCI Machine Learning Repository\n\n\t\n\t\t\n\t\tDataset Information\n\t\n\nThis dataset combines raw counts for first/given names of male and female babies in those time periods, and then calculates a probability for a name given the aggregate count.  Source datasets are fromâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/erickrribeiro/gender-by-name.","url":"https://huggingface.co/datasets/erickrribeiro/gender-by-name","creator_name":"Erick R. Ribeiro","creator_url":"https://huggingface.co/erickrribeiro","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","English","Portuguese","cc-by-4.0","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"professor_heideltime_en","keyword":"portuguese","description":"\n\t\n\t\t\n\t\tProfessor HeidelTime\n\t\n\n\n\nProfessor HeidelTime is a project to create a multilingual corpus weakly labeled with HeidelTime, a temporal tagger.\n\n\t\n\t\t\n\t\n\t\n\t\tCorpus Details\n\t\n\nThe weak labeling was performed in six languages. Here are the specifics of the corpus for each language:\n\n\t\n\t\t\nDataset\nLanguage\nDocuments\nFrom\nTo\nTokens\nTimexs\n\n\n\t\t\nAll the News 2.0\nEN\n24,642\n2016-01-01\n2020-04-0218,755,616\n254,803\n\n\nItalian Crime News\nIT\n9,619\n2011-01-01\n2021-12-31\n3,296,898\n58,823\n\n\nGerman Newsâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/hugosousa/professor_heideltime_en.","url":"https://huggingface.co/datasets/hugosousa/professor_heideltime_en","creator_name":"Hugo Sousa","creator_url":"https://huggingface.co/hugosousa","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["token-classification","parsing","part-of-speech","named-entity-recognition","machine-generated"],"keywords_longer_than_N":true},
	{"name":"malicious-website-features-2.4M","keyword":"portuguese","description":"Important Notice:\n\nA subset of the URL dataset is from Kaggle, and the Kaggle datasets contained 10%-15% mislabelled data. See this dicussion I opened for some false positives. I have contacted Kaggle regarding their erroneous \"Usability\" score calculation for these unreliable datasets.\nThe feature extraction methods shown here are not robust at all in 2023, and there're even silly mistakes in 3 functions: not_indexed_by_google, domain_registration_length, and age_of_domain.\n\n\n\nThe featuresâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/FredZhang7/malicious-website-features-2.4M.","url":"https://huggingface.co/datasets/FredZhang7/malicious-website-features-2.4M","creator_name":"Fred Zhang","creator_url":"https://huggingface.co/FredZhang7","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","feature-extraction","tabular-classification","Norwegian","Afrikaans"],"keywords_longer_than_N":true},
	{"name":"factckbr","keyword":"portuguese","description":"A dataset to study Fake News in Portuguese, presenting a supposedly false News along with their respective fact check and classification.\nThe data is collected from the ClaimReview, a structured data schema used by fact check agencies to share their results in search engines, enabling data collect in real time.\nThe FACTCK.BR dataset contains 1309 claims with its corresponding label.","url":"https://huggingface.co/datasets/factckbr/factckbr","creator_name":"factckbr","creator_url":"https://huggingface.co/factckbr","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":null,"first_N":5,"first_N_keywords":["text-classification","fact-checking","expert-generated","found","monolingual"],"keywords_longer_than_N":true},
	{"name":"tatoeba","keyword":"portuguese","description":"This is a collection of translated sentences from Tatoeba\n359 languages, 3,403 bitexts\ntotal number of files: 750\ntotal number of tokens: 65.54M\ntotal number of sentence fragments: 8.96M","url":"https://huggingface.co/datasets/Helsinki-NLP/tatoeba","creator_name":"Language Technology Research Group at the University of Helsinki","creator_url":"https://huggingface.co/Helsinki-NLP","license_name":"Creative Commons Attribution 2.0","license_url":"https://scancode-licensedb.aboutcode.org/cc-by-2.0.html","language":null,"first_N":5,"first_N_keywords":["translation","found","found","multilingual","original"],"keywords_longer_than_N":true},
	{"name":"MultiLegalPile_Wikipedia_Filtered","keyword":"portuguese","description":"A filtered version of the MultiLegalPile dataset, together with wikipedia articles.","url":"https://huggingface.co/datasets/joelniklaus/MultiLegalPile_Wikipedia_Filtered","creator_name":"Joel Niklaus","creator_url":"https://huggingface.co/joelniklaus","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["fill-mask","other","found","multilingual","original"],"keywords_longer_than_N":true},
	{"name":"xcsr","keyword":"portuguese","description":"\n\t\n\t\t\n\t\tDataset Card for X-CSR\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nTo evaluate multi-lingual language models (ML-LMs) for commonsense reasoning in a cross-lingual zero-shot transfer setting (X-CSR), i.e., training in English and test in other languages, we create two benchmark datasets, namely X-CSQA and X-CODAH. Specifically, we automatically translate the original CSQA and CODAH datasets, which only have English versions, to 15 other languages, forming development and test sets for studying X-CSR.â€¦ See the full description on the dataset page: https://huggingface.co/datasets/INK-USC/xcsr.","url":"https://huggingface.co/datasets/INK-USC/xcsr","creator_name":"INK Lab @ USC","creator_url":"https://huggingface.co/INK-USC","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["question-answering","multiple-choice-qa","crowdsourced","crowdsourced","machine-generated"],"keywords_longer_than_N":true},
	{"name":"ms_terms","keyword":"portuguese","description":"The Microsoft Terminology Collection can be used to develop localized versions of applications that integrate with Microsoft products.\nIt can also be used to integrate Microsoft terminology into other terminology collections or serve as a base IT glossary\nfor language development in the nearly 100 languages available. Terminology is provided in .tbx format, an industry standard for terminology exchange.","url":"https://huggingface.co/datasets/microsoft/ms_terms","creator_name":"Microsoft","creator_url":"https://huggingface.co/microsoft","license_name":"Microsoft Public License","license_url":"https://choosealicense.com/licenses/ms-pl/","language":null,"first_N":5,"first_N_keywords":["translation","expert-generated","expert-generated","multilingual","translation"],"keywords_longer_than_N":true},
	{"name":"MultiLegalPileWikipediaFiltered","keyword":"portuguese","description":"A filtered version of the MultiLegalPile dataset, together with wikipedia articles.","url":"https://huggingface.co/datasets/joelniklaus/MultiLegalPileWikipediaFiltered","creator_name":"Joel Niklaus","creator_url":"https://huggingface.co/joelniklaus","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["fill-mask","other","found","multilingual","original"],"keywords_longer_than_N":true},
	{"name":"common_voice_17_0","keyword":"portuguese","description":"\n\t\n\t\t\n\t\tDataset Card for Common Voice Corpus 17.0\n\t\n\n\n\nThis dataset is an unofficial version of the Mozilla Common Voice Corpus 17. It was downloaded and converted from the project's website https://commonvoice.mozilla.org/.\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nAbkhaz, Albanian, Amharic, Arabic, Armenian, Assamese, Asturian, Azerbaijani, Basaa, Bashkir, Basque, Belarusian, Bengali, Breton, Bulgarian, Cantonese, Catalan, Central Kurdish, Chinese (China), Chinese (Hong Kong), Chinese (Taiwan), Chuvash, Czechâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fsicoli/common_voice_17_0.","url":"https://huggingface.co/datasets/fsicoli/common_voice_17_0","creator_name":"Fabio Sicoli","creator_url":"https://huggingface.co/fsicoli","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":null,"first_N":5,"first_N_keywords":["automatic-speech-recognition","Abkhaz","Afrikaans","Amharic","Arabic"],"keywords_longer_than_N":true},
	{"name":"Agricultura_regenerativa_Portugues_Portuguese","keyword":"portuguese","description":"Dados semissintÃ©ticos gerados por meio da biblioteca RAG contendo conhecimento de agricultura regenerativa de especialistas do domÃ­nio, conectados Ã  API ChatGPT4.\nUm conjunto de dados que detalha soluÃ§Ãµes agrÃ­colas regenerativas para problemas agrÃ­colas comuns, em portuguÃªs, com consciÃªncia cultural em relaÃ§Ã£o Ã  Floresta AmazÃ´nica e Ã s comunidades agrÃ­colas brasileiras marginalizadas.\nSemi-synthetic data generated via RAG library containing regenerative farming knowledge from domain expertsâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Solshine/Agricultura_regenerativa_Portugues_Portuguese.","url":"https://huggingface.co/datasets/Solshine/Agricultura_regenerativa_Portugues_Portuguese","creator_name":"Caleb DeLeeuw","creator_url":"https://huggingface.co/Solshine","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["Portuguese","mit","n<1K","ðŸ‡ºðŸ‡¸ Region: US","biology"],"keywords_longer_than_N":true},
	{"name":"UltrachatBR","keyword":"portuguese","description":"\n\t\n\t\t\n\t\tUltrachatBR: Um Dataset em PortuguÃªs baseado no Ultrachat\n\t\n\nO UltrachatBR Ã© uma versÃ£o em portuguÃªs do conhecido dataset Ultrachat, originalmente desenvolvido para o idioma inglÃªs. Este projeto visa disponibilizar uma vasta coleÃ§Ã£o de diÃ¡logos traduzidos para o portuguÃªs, ampliando assim o acesso a recursos de processamento de linguagem natural para a comunidade de lÃ­ngua portuguesa.\n\n\t\n\t\t\n\t\n\t\n\t\tProcesso de TraduÃ§Ã£o\n\t\n\nO processo de traduÃ§Ã£o foi realizado utilizando a API do Googleâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/recogna-nlp/UltrachatBR.","url":"https://huggingface.co/datasets/recogna-nlp/UltrachatBR","creator_name":"Recogna NLP","creator_url":"https://huggingface.co/recogna-nlp","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-generation","Portuguese","mit","100K - 1M","json"],"keywords_longer_than_N":true},
	{"name":"UltrachatBR","keyword":"portuguese","description":"\n\t\n\t\t\n\t\tUltrachatBR: Um Dataset em PortuguÃªs baseado no Ultrachat\n\t\n\nO UltrachatBR Ã© uma versÃ£o em portuguÃªs do conhecido dataset Ultrachat, originalmente desenvolvido para o idioma inglÃªs. Este projeto visa disponibilizar uma vasta coleÃ§Ã£o de diÃ¡logos traduzidos para o portuguÃªs, ampliando assim o acesso a recursos de processamento de linguagem natural para a comunidade de lÃ­ngua portuguesa.\n\n\t\n\t\t\n\t\n\t\n\t\tProcesso de TraduÃ§Ã£o\n\t\n\nO processo de traduÃ§Ã£o foi realizado utilizando a API do Googleâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/recogna-nlp/UltrachatBR.","url":"https://huggingface.co/datasets/recogna-nlp/UltrachatBR","creator_name":"Recogna NLP","creator_url":"https://huggingface.co/recogna-nlp","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-generation","Portuguese","mit","100K - 1M","json"],"keywords_longer_than_N":true},
	{"name":"tulu-3-sft-olmo-2-mixture","keyword":"portuguese","description":"Note that this collection is licensed under ODC-BY-1.0 license; different licenses apply to subsets of the data. Some portions of the dataset are non-commercial. We present the mixture as a research artifact.\nThe OLMo v2 SFT mixture was used to train the OLMo models.\nIt contains 939,344 samples from the following sets:\n\nCoCoNot (ODC-BY-1.0), 10,983 prompts (Brahman et al., 2024)\nFLAN v2 via ai2-adapt-dev/flan_v2_converted, 89,982 prompts (Longpre et al., 2023)\nNo Robots (CC-BY-NC-4.0), 9,500â€¦ See the full description on the dataset page: https://huggingface.co/datasets/allenai/tulu-3-sft-olmo-2-mixture.","url":"https://huggingface.co/datasets/allenai/tulu-3-sft-olmo-2-mixture","creator_name":"Ai2","creator_url":"https://huggingface.co/allenai","license_name":"Open Data Commons Attribution License v1.0","license_url":"https://scancode-licensedb.aboutcode.org/odc-by-1.0.html","language":"en","first_N":5,"first_N_keywords":["other","crowdsourced","expert-generated","machine-generated","multilingual"],"keywords_longer_than_N":true},
	{"name":"xP3","keyword":"portuguese","description":"xP3 (Crosslingual Public Pool of Prompts) is a collection of prompts & datasets across 46 of languages & 16 NLP tasks. It is used for the training of BLOOMZ and mT0, multilingual language models capable of following human instructions in dozens of languages zero-shot.","url":"https://huggingface.co/datasets/bigscience/xP3","creator_name":"BigScience Workshop","creator_url":"https://huggingface.co/bigscience","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":null,"first_N":5,"first_N_keywords":["other","expert-generated","crowdsourced","multilingual","Akan"],"keywords_longer_than_N":true},
	{"name":"pt-parliament-interventions","keyword":"portuguese","description":"luist18/pt-parliament-interventions dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/luist18/pt-parliament-interventions","creator_name":"LuÃ­s Tavares","creator_url":"https://huggingface.co/luist18","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["Portuguese","mit","< 1K","csv","Text"],"keywords_longer_than_N":true},
	{"name":"entity_cs","keyword":"portuguese","description":"\n\t\n\t\t\n\t\tDataset Card for EntityCS\n\t\n\n\nRepository: https://github.com/huawei-noah/noah-research/tree/master/NLP/EntityCS  \nPaper: https://aclanthology.org/2022.findings-emnlp.499.pdf  \nPoint of Contact: Fenia Christopoulou, Chenxi Whitehouse\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Description\n\t\n\nWe use the English Wikipedia and leverage entity information from Wikidata to construct an entity-based Code Switching corpus. \nTo achieve this, we make use of wikilinks in Wikipedia, i.e. links from one page to another.â€¦ See the full description on the dataset page: https://huggingface.co/datasets/huawei-noah/entity_cs.","url":"https://huggingface.co/datasets/huawei-noah/entity_cs","creator_name":"HUAWEI Noah's Ark Lab","creator_url":"https://huggingface.co/huawei-noah","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["Afrikaans","Amharic","Arabic","Assamese","Azerbaijani"],"keywords_longer_than_N":true},
	{"name":"cosmos_qa_ptbr","keyword":"portuguese","description":"\n\t\n\t\t\n\t\tCosmos QA PortuguÃªs\n\t\n\nEste dataset Ã© uma traduÃ§Ã£o para portuguÃªs do Cosmos QA, que originalmente Ã© na lÃ­ngua inglesa. \nA traduÃ§Ã£o foi feita automaticamente usando o GPT-3.5-turbo, logo pode ter erros que nÃ£o foram notados numa anÃ¡lise superficial. \nSe atente ao uso.\n\n\t\n\t\t\n\t\tDataset Card for cosmos_qa\n\t\n\n\n\t\n\t\t\n\t\tLicensing Information\n\t\n\nThe data is distributed under the CC BY 4.0 license.\n\n\t\n\t\t\n\t\tSource Data Citation INformation\n\t\n\n@inproceedings{huang-etal-2019-cosmos,\n    title =â€¦ See the full description on the dataset page: https://huggingface.co/datasets/heloisy/cosmos_qa_ptbr.","url":"https://huggingface.co/datasets/heloisy/cosmos_qa_ptbr","creator_name":"Heloisy Rodrigues","creator_url":"https://huggingface.co/heloisy","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["multiple-choice","cosmos_qa","Portuguese","cc-by-4.0","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"wiki_lingua","keyword":"portuguese","description":"\n\t\n\t\t\n\t\tDataset Card for \"wiki_lingua\"\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nWe introduce WikiLingua, a large-scale, multilingual dataset for the evaluation of cross-lingual abstractive summarization systems. We extract article and summary pairs in 18 languages from WikiHow, a high quality, collaborative resource of how-to guides on a diverse set of topics written by human authors. We create gold-standard article-summary alignments across languages by aligning the images that are used to describe eachâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/esdurmus/wiki_lingua.","url":"https://huggingface.co/datasets/esdurmus/wiki_lingua","creator_name":"Esin Durmus","creator_url":"https://huggingface.co/esdurmus","license_name":"Creative Commons Attribution 3.0","license_url":"https://scancode-licensedb.aboutcode.org/cc-by-3.0.html","language":"en","first_N":5,"first_N_keywords":["summarization","crowdsourced","crowdsourced","multilingual","original"],"keywords_longer_than_N":true},
	{"name":"squad_v1_pt","keyword":"portuguese","description":"\n\t\n\t\t\n\t\tDataset Card for \"squad_v1_pt\"\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nPortuguese translation of the SQuAD dataset. The translation was performed automatically using the Google Cloud API.\n\n\t\n\t\t\n\t\tSupported Tasks and Leaderboards\n\t\n\nMore Information Needed\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nMore Information Needed\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\n\t\n\t\t\n\t\tData Instances\n\t\n\n\n\t\n\t\t\n\t\tdefault\n\t\n\n\nSize of downloaded dataset files: 39.53 MB\nSize of the generated dataset: 96.72 MB\nTotal amount of disk used: 136.25 MB\n\nAnâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/nunorc/squad_v1_pt.","url":"https://huggingface.co/datasets/nunorc/squad_v1_pt","creator_name":"Nuno Ramos Carvalho","creator_url":"https://huggingface.co/nunorc","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["question-answering","extractive-qa","open-domain-qa","crowdsourced","crowdsourced"],"keywords_longer_than_N":true},
	{"name":"common_language","keyword":"portuguese","description":"This dataset is composed of speech recordings from languages that were carefully selected from the CommonVoice database.\nThe total duration of audio recordings is 45.1 hours (i.e., 1 hour of material for each language).\nThe dataset has been extracted from CommonVoice to train language-id systems.","url":"https://huggingface.co/datasets/speechbrain/common_language","creator_name":"SpeechBrain","creator_url":"https://huggingface.co/speechbrain","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":null,"first_N":5,"first_N_keywords":["audio-classification","speaker-identification","crowdsourced","crowdsourced","multilingual"],"keywords_longer_than_N":true},
	{"name":"b2w-reviews01","keyword":"portuguese","description":"B2W-Reviews01 is an open corpus of product reviews. It contains more than 130k e-commerce customer reviews, collected from the Americanas.com website between January and May, 2018. B2W-Reviews01 offers rich information about the reviewer profile, such as gender, age, and geographical location. The corpus also has two different review rates","url":"https://huggingface.co/datasets/ruanchaves/b2w-reviews01","creator_name":"Ruan Chaves Rodrigues","creator_url":"https://huggingface.co/ruanchaves","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","sentiment-analysis","sentiment-scoring","intent-classification","topic-classification"],"keywords_longer_than_N":true},
	{"name":"minigpt4-13b-ggml","keyword":"portuguese","description":"These are quantized ggml binary files for minigpt4 13B model.\nThese files can be used in conjunction with vicuna v0 ggml models to get minigpt4 working.\nNot all implementations were tested. If there are any issues, use f16.\n","url":"https://huggingface.co/datasets/maknee/minigpt4-13b-ggml","creator_name":"maknee","creator_url":"https://huggingface.co/maknee","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":null,"first_N":5,"first_N_keywords":["English","Bulgarian","Catalan","Czech","Danish"],"keywords_longer_than_N":true},
	{"name":"openassistant-falcon","keyword":"portuguese","description":"\n\t\n\t\t\n\t\tChat Fine-tuning Dataset - OpenAssistant Falcon\n\t\n\nThis dataset allows for fine-tuning chat models using '\\Human:' AND '\\nAssistant:' to wrap user messages.\nIt still uses <|endoftext|> as EOS and BOS token, as per Falcon.\nSample \nPreparation:\n\nThe dataset is cloned from TimDettmers, which itself is a subset of the Open Assistant dataset, which you can find here. This subset of the data only contains the highest-rated paths in the conversation tree, with a total of 9,846 samples.\nTheâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Trelis/openassistant-falcon.","url":"https://huggingface.co/datasets/Trelis/openassistant-falcon","creator_name":"Trelis","creator_url":"https://huggingface.co/Trelis","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["English","Spanish","Russian","German","Polish"],"keywords_longer_than_N":true},
	{"name":"hatecheck-portuguese","keyword":"portuguese","description":"\n\t\n\t\t\n\t\tDataset Card for Multilingual HateCheck\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nMultilingual HateCheck (MHC) is a suite of functional tests for hate speech detection models in 10 different languages: Arabic, Dutch, French, German, Hindi, Italian, Mandarin, Polish, Portuguese and Spanish.\nFor each language, there are 25+ functional tests that correspond to distinct types of hate and challenging non-hate.\nThis allows for targeted diagnostic insights into model performance.\nFor more detailsâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Paul/hatecheck-portuguese.","url":"https://huggingface.co/datasets/Paul/hatecheck-portuguese","creator_name":"Paul RÃ¶ttger","creator_url":"https://huggingface.co/Paul","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","hate-speech-detection","crowdsourced","expert-generated","monolingual"],"keywords_longer_than_N":true},
	{"name":"minds14-mirror","keyword":"portuguese","description":"MINDS-14 is training and evaluation resource for intent\ndetection task with spoken data. It covers 14\nintents extracted from a commercial system\nin the e-banking domain, associated with spoken examples in 14 diverse language varieties.","url":"https://huggingface.co/datasets/a6kme/minds14-mirror","creator_name":"Abhishek Kumar","creator_url":"https://huggingface.co/a6kme","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":null,"first_N":5,"first_N_keywords":["automatic-speech-recognition","keyword-spotting","expert-generated","crowdsourced","machine-generated"],"keywords_longer_than_N":true},
	{"name":"oasst1","keyword":"portuguese","description":"\n\t\n\t\t\n\t\tOpenAssistant Conversations Dataset (OASST1)\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nIn an effort to democratize research on large-scale alignment, we release OpenAssistant \nConversations (OASST1), a human-generated, human-annotated assistant-style conversation \ncorpus consisting of 161,443 messages in 35 different languages, annotated with 461,292 \nquality ratings, resulting in over 10,000 fully annotated conversation trees. The corpus \nis a product of a worldwide crowd-sourcing effortâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/OpenAssistant/oasst1.","url":"https://huggingface.co/datasets/OpenAssistant/oasst1","creator_name":"OpenAssistant","creator_url":"https://huggingface.co/OpenAssistant","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["English","Spanish","Russian","German","Polish"],"keywords_longer_than_N":true},
	{"name":"stella","keyword":"portuguese","description":"rafaaa2105/stella dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/rafaaa2105/stella","creator_name":"Polar","creator_url":"https://huggingface.co/rafaaa2105","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":null,"first_N":5,"first_N_keywords":["text-generation","Portuguese","apache-2.0","ðŸ‡ºðŸ‡¸ Region: US"],"keywords_longer_than_N":false},
	{"name":"ACAData","keyword":"portuguese","description":"\n\t\n\t\t\n\t\tDataset Card for ACAData\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nACAData is a multilingual instruction tuning dataset containing parallel text paragraphs from the academic domain.\n\n\t\n\t\t\n\t\tSupported Tasks and Leaderboards\n\t\n\nThe dataset is meant to be used for fine-tuning and benchmarking general purpose LLM's on Machine Translation tasks.\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nThe dataset contains (mainly long) paragraph of scientific texts from the academic domain in many European language pairs.\nThe languageâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/BSC-LT/ACAData.","url":"https://huggingface.co/datasets/BSC-LT/ACAData","creator_name":"Language Technologies Laboratory @ Barcelona Supercomputing Center","creator_url":"https://huggingface.co/BSC-LT","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["translation","Spanish","English","Catalan","Portuguese"],"keywords_longer_than_N":true},
	{"name":"FineWeb2-HQ","keyword":"portuguese","description":"\n\t\n\t\t\n\t\tFineWeb2-HQ\n\t\n\n\n\t\n\t\t\n\t\tDataset summary\n\t\n\nFineWeb2-HQ is a high-quality, model-filtered pretraining dataset derived as a subset of FineWeb2, spanning 20 languages. It enables around 6x faster pretraining compared to the base dataset. FineWeb2-HQ was created by selecting the top 10% quality documents of FineWeb2 in each language, based on scores assigned by a deep learning classifier trained to identify structured and knowledge-rich samples using XLM-RoBERTa embeddings.\n\n  \n\n\nValidationâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/epfml/FineWeb2-HQ.","url":"https://huggingface.co/datasets/epfml/FineWeb2-HQ","creator_name":"EPFL Machine Learning and Optimization Laboratory","creator_url":"https://huggingface.co/epfml","license_name":"Open Data Commons Attribution License v1.0","license_url":"https://scancode-licensedb.aboutcode.org/odc-by-1.0.html","language":"en","first_N":5,"first_N_keywords":["text-generation","Russian","Chinese","German","Japanese"],"keywords_longer_than_N":true},
	{"name":"FineWeb2-embedded","keyword":"portuguese","description":"\n\t\n\t\t\n\t\tFineWeb2-embedded\n\t\n\n\n\t\n\t\t\n\t\tDataset summary\n\t\n\nFineWeb2-embedded is an extension of the FineWeb2 dataset, annotated with document-level XLM-RoBERTa embeddings for 20 languages, making the dataset useful for a variety of tasks, including document clustering, filtering, and other multilingual research.\nSince XLM-RoBERTa has a sequence length limit of 512 tokens, each document's embeddings are obtained by mean-pooling 512 token chunks of the XLM-RoBERTa output. Therefore, longer textsâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/epfml/FineWeb2-embedded.","url":"https://huggingface.co/datasets/epfml/FineWeb2-embedded","creator_name":"EPFL Machine Learning and Optimization Laboratory","creator_url":"https://huggingface.co/epfml","license_name":"Open Data Commons Attribution License v1.0","license_url":"https://scancode-licensedb.aboutcode.org/odc-by-1.0.html","language":"en","first_N":5,"first_N_keywords":["text-generation","Russian","Chinese","German","Japanese"],"keywords_longer_than_N":true},
	{"name":"semeval-2025-task11-track-c","keyword":"portuguese","description":"\n\t\n\t\t\n\t\tSemEval 2025 Task 11 - Track C Dataset\n\t\n\nThis dataset contains the data for SemEval 2025 Task 11: Bridging the Gap in Text-Based Emotion Detection - Track C, organized as language-specific configurations.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset is a multi-language, multi-label emotion classification dataset with separate configurations for each language.\n\nTotal languages: 30 standard ISO codes\nTotal examples: 57254\nSplits: dev, test (Track C has no train split)\n\n\n\t\n\t\t\n\t\tTrackâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/vgaraujov/semeval-2025-task11-track-c.","url":"https://huggingface.co/datasets/vgaraujov/semeval-2025-task11-track-c","creator_name":"Vladimir Araujo","creator_url":"https://huggingface.co/vgaraujov","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["Afrikaans","Amharic","Arabic","German","English"],"keywords_longer_than_N":true},
	{"name":"HPLT2.0_cleaned","keyword":"portuguese","description":"This is a large-scale collection of web-crawled documents in 191 world languages, produced by the HPLT project. \nThe source of the data is mostly Internet Archive with some additions from Common Crawl.\nFor a detailed description of the dataset, please refer to our website and our pre-print.\n\n\t\n\t\t\n\t\n\t\n\t\tThe Cleaned variant of HPLT Datasets v2.0\n\t\n\nThis is the cleaned variant of the HPLT Datasets v2.0 converted to the Parquet format semi-automatically when being uploaded here. \nThe originalâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/HPLT/HPLT2.0_cleaned.","url":"https://huggingface.co/datasets/HPLT/HPLT2.0_cleaned","creator_name":"HPLT","creator_url":"https://huggingface.co/HPLT","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["fill-mask","text-generation","language-modeling","multilingual","Achinese"],"keywords_longer_than_N":true},
	{"name":"DATA-AI_Chat","keyword":"portuguese","description":"\n\t\n\t\t\n\t\tDATA-AI: Il Modello di IA di M.INC.\n\t\n\n\n\t\n\t\t\n\t\tðŸ“Œ Introduzione\n\t\n\nDATA-AI Ã¨ un avanzato modello di intelligenza artificiale sviluppato da *M.INC., un'azienda italiana fondata da *Mattimax (M. Marzorati).Questo modello Ã¨ basato sull'architettura ELNS (Elaborazione del Linguaggio Naturale Semplice), un sistema innovativo progettato per rendere l'IA accessibile su quasi qualsiasi dispositivo, garantendo prestazioni ottimali anche su hardware limitato.  \nDATA-AI Ã¨ stato addestrato su unâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Mattimax/DATA-AI_Chat.","url":"https://huggingface.co/datasets/Mattimax/DATA-AI_Chat","creator_name":"M.INC.","creator_url":"https://huggingface.co/Mattimax","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["Italian","English","Spanish","Russian","German"],"keywords_longer_than_N":true},
	{"name":"multicultural-wvs-alignment","keyword":"portuguese","description":"\n\t\n\t\t\n\t\tDataset Card: Multicultural WVS Alignment\n\t\n\nThis document is based on \"Datasheets for Datasets\" by Gebru et al. (arXiv:1803.09010). Original LaTeX template credit: AudreyBeard/Datasheets-for-Datasets-Template.\n\n\t\n\t\t\n\t\tModels Evaluated\n\t\n\n\n\t\n\t\t\nModel Name\nModel Family\n\n\n\t\t\nOLMo-2-0325-32B-Instruct\nolmo\n\n\nOLMo-2-1124-13B-Instruct\nolmo\n\n\nOLMo-2-1124-7B-Instruct\nolmo\n\n\ngemma-2-27b-it\ngemma\n\n\ngemma-2-2b-it\ngemma\n\n\ngemma-2-9b-it\ngemma\n\n\ngpt-3.5-turbo-0125\nopenai\n\n\ngpt-4-turbo-2024-04-09â€¦ See the full description on the dataset page: https://huggingface.co/datasets/ryzzlestrizzle/multicultural-wvs-alignment.","url":"https://huggingface.co/datasets/ryzzlestrizzle/multicultural-wvs-alignment","creator_name":"Jonathan RystrÃ¸m","creator_url":"https://huggingface.co/ryzzlestrizzle","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","Danish","Portuguese","Dutch","English"],"keywords_longer_than_N":true},
	{"name":"EmoTalk-7","keyword":"portuguese","description":"\n\t\n\t\t\n\t\tEmoTalk-7\n\t\n\nEmoTalk-7 is a large-scale, multilingual, synthetic multimodal emotion recognition dataset generated using the Mistral API. It covers 7 major European languages and contains realistic social media scenarios with comprehensive emotion analysis, visual descriptions, and cultural context annotations.\n\n\t\n\t\t\n\t\tðŸ“ Dataset Summary\n\t\n\nEmoTalk-7 contains 1400+ multimodal emotion records with high-quality annotations. It is designed to simulate authentic social media content acrossâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/NoeFlandre/EmoTalk-7.","url":"https://huggingface.co/datasets/NoeFlandre/EmoTalk-7","creator_name":"NoÃ© Flandre","creator_url":"https://huggingface.co/NoeFlandre","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","English","French","Spanish","German"],"keywords_longer_than_N":true},
	{"name":"zenith_ai_305","keyword":"portuguese","description":"\n\t\n\t\t\n\t\tLegal Data Analysis Dataset\n\t\n\nThis dataset contains legal statements, analyses, and judgments primarily related to labor law and contract law, drawn from various cases and legal interpretations. It includes text entries with factual descriptions, legal arguments, and conclusions based on judicial decisions, as well as instructions related to interpreting those facts.\n\n\t\n\t\t\n\t\tDataset Overview\n\t\n\nThe dataset is structured as a series of legal paragraphs and corresponding instructionsâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/alvemoans/zenith_ai_305.","url":"https://huggingface.co/datasets/alvemoans/zenith_ai_305","creator_name":"moans alvs","creator_url":"https://huggingface.co/alvemoans","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","Portuguese","apache-2.0","< 1K","json"],"keywords_longer_than_N":true},
	{"name":"medical-translation-test-set","keyword":"portuguese","description":"ai-amplified/medical-translation-test-set dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/ai-amplified/medical-translation-test-set","creator_name":"admin","creator_url":"https://huggingface.co/ai-amplified","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["English","French","Portuguese","Romanian","German"],"keywords_longer_than_N":true},
	{"name":"MultiLingualSentiment","keyword":"portuguese","description":"\n\t\n\t\t\n\t\tOverview\n\t\n\nMultilingualSentiment is a sentiment classification dataset that encompasses three sentiment labels: Positive, Neutral, Negative\nThe dataset spans multiple languages and covers a wide range of domains, making it ideal for multilingual sentiment analysis tasks.\n\n\t\n\t\t\n\t\tDataset Information\n\t\n\nThe dataset was meticulously collected and aggregated from various sources, including Hugging Face and Kaggle. These sources provide diverse languages and domains to ensure aâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/clapAI/MultiLingualSentiment.","url":"https://huggingface.co/datasets/clapAI/MultiLingualSentiment","creator_name":"clapAI","creator_url":"https://huggingface.co/clapAI","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","Arabic","German","English","Spanish"],"keywords_longer_than_N":true},
	{"name":"MintakaRetrieval","keyword":"portuguese","description":"\n  MintakaRetrieval\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nWe introduce Mintaka, a complex, natural, and multilingual dataset designed for experimenting with end-to-end question-answering models. Mintaka is composed of 20,000 question-answer pairs collected in English, annotated with Wikidata entities, and translated into Arabic, French, German, Hindi, Italian, Japanese, Portuguese, and Spanish for a total of 180,000 samples. Mintaka includes 8 types of complex questionsâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/MintakaRetrieval.","url":"https://huggingface.co/datasets/mteb/MintakaRetrieval","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","multiple-choice-qa","derived","translated","jinaai/mintakaqa"],"keywords_longer_than_N":true},
	{"name":"FactNews","keyword":"portuguese","description":"\n\t\n\t\t\n\t\tEvaluation Benchmark for Sentence-Level Factuality Prediciton in Portuguese\n\t\n\nThe FactNews consits of the first large sentence-level annotated corpus for factuality prediciton in Portuguese. \nIt is composed of 6,191 sentences annotated according to factuality and media bias definitions proposed by AllSides. We use FactNews to assess the overall reliability of news sources by formulating \ntwo text classification problems for predicting sentence-level factuality of news reporting andâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/franciellevargas/FactNews.","url":"https://huggingface.co/datasets/franciellevargas/FactNews","creator_name":"Francielle Vargas","creator_url":"https://huggingface.co/franciellevargas","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","Portuguese","apache-2.0","10K - 100K","csv"],"keywords_longer_than_N":true},
	{"name":"Sentiments-FinBERT-PT-BR","keyword":"portuguese","description":"\n\t\n\t\t\n\t\tDataset\n\t\n\nA manually annotated dataset was created to enable supervised training for the FinBERT-PT-BR model, which focuses on sentiment analysis of Brazilian Portuguese financial texts.\nMore than 1.4 million financial news texts in Portuguese were collected and used for the initial language modeling phase. From this corpus, a sample of 1,000 texts was manually annotated with sentiment labels.\n\n\t\n\t\t\n\t\tAnnotation Process\n\t\n\nThree annotators participated in the process.\nAll texts wereâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/lucas-leme/Sentiments-FinBERT-PT-BR.","url":"https://huggingface.co/datasets/lucas-leme/Sentiments-FinBERT-PT-BR","creator_name":"Lucas Leme Santos","creator_url":"https://huggingface.co/lucas-leme","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["Portuguese","apache-2.0","< 1K","csv","Text"],"keywords_longer_than_N":true},
	{"name":"reranker_continuous_filt_max7_train","keyword":"portuguese","description":"\n\t\n\t\t\n\t\tReranker training data\n\t\n\nThis data was generated using 4 steps:\n\nWe gathered queries and corresponding text data from 35 high quality datasets covering more than 95 languages.\nFor datasets which did not already have negative texts for queries, we mined hard negatives using the BAAI/bge-m3 embedding model.\nFor each query, we selected one positive and one negative text and used Qwen/Qwen2.5-32B-Instruct-GPTQ-Int4 to rate the relatedness of each query-text pair using a token \"1\", \"2\"â€¦ See the full description on the dataset page: https://huggingface.co/datasets/lightblue/reranker_continuous_filt_max7_train.","url":"https://huggingface.co/datasets/lightblue/reranker_continuous_filt_max7_train","creator_name":"Lightblue KK.","creator_url":"https://huggingface.co/lightblue","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["English","Chinese","Spanish","German","Arabic"],"keywords_longer_than_N":true},
	{"name":"ptbr-deita-8k","keyword":"portuguese","description":"\n\t\n\t\t\n\t\tPTBR Deita 8k\n\t\n\nPortuguese translation of the Deita 8k dataset. \n","url":"https://huggingface.co/datasets/botbot-ai/ptbr-deita-8k","creator_name":"BotBot","creator_url":"https://huggingface.co/botbot-ai","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["Portuguese","apache-2.0","1K - 10K","json","Text"],"keywords_longer_than_N":true},
	{"name":"NURC-SP_ENTOA_TTS","keyword":"portuguese","description":"\n\t\n\t\t\n\t\tHow to Load the Dataset\n\t\n\nThere are 4 configurations: \"prosodic\", \"automatic\", \"audioCorpus\" and test. To load the dataset with the HuggingFace datasets library, use the following code: \nprosodic = load_dataset(\"nilc-nlp/NURC-SP_ENTOA_TTS\", name=\"prosodic\")\nautomatic = load_dataset(\"nilc-nlp/NURC-SP_ENTOA_TTS\", name = \"automatic\")\naudioCorpus = load_dataset(\"nilc-nlp/NURC-SP_ENTOA_TTS\", name = \"audioCorpus\")\ntest = load_dataset(\"nilc-nlp/NURC-SP_ENTOA_TTS\", name=\"test\")â€¦ See the full description on the dataset page: https://huggingface.co/datasets/nilc-nlp/NURC-SP_ENTOA_TTS.","url":"https://huggingface.co/datasets/nilc-nlp/NURC-SP_ENTOA_TTS","creator_name":"NILC NLP","creator_url":"https://huggingface.co/nilc-nlp","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-to-speech","Portuguese","mit","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"eng_montok","keyword":"portuguese","description":"\n\t\n\t\t\n\t\tMonTok: A Suite of Monolingual Tokenizers\n\t\n\nThis is a set of monolingual tokenizers for 98 languages. For each language, there are Unigram, BPE, and SuperBPE tokenizers, ranging in vocabulary size from around 6k to over 200k.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\n","url":"https://huggingface.co/datasets/catherinearnett/eng_montok","creator_name":"Catherine Arnett","creator_url":"https://huggingface.co/catherinearnett","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["Afrikaans","Tosk Albanian","Amharic","Standard Arabic","Assamese"],"keywords_longer_than_N":true},
	{"name":"bidCorpus","keyword":"portuguese","description":"\n\t\n\t\t\n\t\tDataset Card for \"BidCorpus\"\n\t\n\n\n\t\n\t\t\n\t\tHow to load the datasets\n\t\n\nTo load one of the datasets, simply provide the tcepi/bidCorpus argument as the first parameter, followed by the name of the desired dataset, such as bid_corpus_raw.\nfrom datasets import load_dataset\ndataset = load_dataset(\"tcepi/bidCorpus\", \"bidCorpus_raw\")\n\nThe csv format version of the datasets is available in the \\bidCorpus_csvs folder.\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThe BidCorpus dataset consists of variousâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/tcepi/bidCorpus.","url":"https://huggingface.co/datasets/tcepi/bidCorpus","creator_name":"Tribunal de Contas do Estado do PiauÃ­","creator_url":"https://huggingface.co/tcepi","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","sentence-similarity","Portuguese","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"ipa-childes-split","keyword":"portuguese","description":"\n\t\n\t\t\n\t\tIPA-CHILDES split\n\t\n\nThis dataset is a postprocessed version of the IPA-CHILDES dataset. In particular,\nthe following changes have been implemented:\n\ncolumn processed_gloss dropped as it duplicates information of gloss up to punctuation\ncolumn gloss renamed as sentence, and column ipa_transcription renamed as ipa_g2p_plus (cf. G2P+)\ncolumn lang added to make IETF language tags accessible for training and inference; language tags normalized by the langcodes package\ncolumns ipa_espeakâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fdemelo/ipa-childes-split.","url":"https://huggingface.co/datasets/fdemelo/ipa-childes-split","creator_name":"FlÃ¡vio Eler De Melo","creator_url":"https://huggingface.co/fdemelo","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["Catalan","Welsh","Danish","German","English"],"keywords_longer_than_N":true},
	{"name":"JBB-Behaviors-pt","keyword":"portuguese","description":"\n\t\n\t\t\n\t\tJBB-Behaviors-pt\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nJBB-Behaviors-pt is a dataset of behaviors in Portuguese, including both jailbreak prompts and safe behaviors. The dataset is intended for behavioral testing of language models to evaluate their robustness against jailbreak attempts in Portuguese.\n\n\t\n\t\t\n\t\tWhat is a jailbreak?\n\t\n\nJailbreak prompts are inputs designed to bypass a language model's safety guardrails, potentially causing it to generate harmful, unethical, or otherwiseâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/tech4humans/JBB-Behaviors-pt.","url":"https://huggingface.co/datasets/tech4humans/JBB-Behaviors-pt","creator_name":"Tech4Humans","creator_url":"https://huggingface.co/tech4humans","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","Portuguese","mit","< 1K","csv"],"keywords_longer_than_N":true},
	{"name":"oab_gemini","keyword":"portuguese","description":"celsowm/oab_gemini dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/celsowm/oab_gemini","creator_name":"Celso F","creator_url":"https://huggingface.co/celsowm","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["question-answering","Portuguese","apache-2.0","1K - 10K","json"],"keywords_longer_than_N":true},
	{"name":"TinyMarkdown-Instruct-PT","keyword":"portuguese","description":"\n\t\n\t\t\n\t\tMarkdown Fine-Tuning Datasets (English & PT-BR)\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThese datasets are designed to fine-tune Large Language Models (LLMs) like Gemma to generate structured Markdown-formatted responses. The datasets contain instruction-response pairs, ensuring the model learns how to output Markdown elements correctly.\n\n\t\n\t\t\n\t\tDatasets\n\t\n\n\n\t\n\t\t\n\t\t1. English Markdown Dataset\n\t\n\n\nAvailable on Hugging Face: TinyMarkdown-Instruct-EN\nSize: Large-scale dataset with structured Markdownâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/VAMJ-0042/TinyMarkdown-Instruct-PT.","url":"https://huggingface.co/datasets/VAMJ-0042/TinyMarkdown-Instruct-PT","creator_name":"Vitor Augusto Machado Jorge","creator_url":"https://huggingface.co/VAMJ-0042","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["question-answering","Portuguese","mit","10K - 100K","json"],"keywords_longer_than_N":true},
	{"name":"Everything_Instruct_Multilingual","keyword":"portuguese","description":"\n\t\n\t\t\n\t\tEverything Instruct (Multilingual Edition)\n\t\n\nEverything you need... all in one place ðŸ’˜\n\nEverything instruct (Multilingual Edition) is a massive alpaca instruct formatted dataset consisting of a wide variety of topics meant to bring LLM's to the next level in open source AI.\nNote: This dataset is fully uncensored (No model will refuse any request trained on this dataset unless otherwise aligned)\nNote2: This version of the dataset supports the following languages:\n\nEnglish\nRussianâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/rombodawg/Everything_Instruct_Multilingual.","url":"https://huggingface.co/datasets/rombodawg/Everything_Instruct_Multilingual","creator_name":"rombo dawg","creator_url":"https://huggingface.co/rombodawg","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["English","Russian","Chinese","Korean","Urdu"],"keywords_longer_than_N":true},
	{"name":"Emakhuwa-Portuguese-News-MT","keyword":"portuguese","description":"\n\t\n\t\t\n\t\tNews Parallel Dataset for Emakhuwa of Mozambique\n\t\n\n\n\nThis repository contains releases of parallel data for machine translation in Mozambican languages. \nCurrently, it supports one language pair, Portuguese-Emakhuwa, Emakhuwa being the widely spoken language in Mozambique.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\n\n\n\n\nFunded by: This dataset was created with support from Lacuna Fund, the worldâ€™s first collaborative effort to provide data scientists, researchers, andâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/LIACC/Emakhuwa-Portuguese-News-MT.","url":"https://huggingface.co/datasets/LIACC/Emakhuwa-Portuguese-News-MT","creator_name":"LIACC","creator_url":"https://huggingface.co/LIACC","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["translation","Makhuwa","Portuguese","cc-by-4.0","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"PORTO","keyword":"portuguese","description":"\n\t\n\t\t\n\t\tPost-OCR Resources for Text Optimisation\n\t\n\nResource for evaluation and develop OCRs and Post-OCR focused on historical Portuguese.\nHow to load the dataset:\nfrom datasets import load_dataset\n\ndataset = load_dataset(\"LIACC/PORTO\")\n\n","url":"https://huggingface.co/datasets/LIACC/PORTO","creator_name":"LIACC","creator_url":"https://huggingface.co/LIACC","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["image-to-text","fill-mask","text-generation","Portuguese","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"multivsr","keyword":"portuguese","description":"\n\t\n\t\t\n\t\tDataset: MultiVSR\n\t\n\nWe introduce a large-scale multilingual lip-reading dataset: MultiVSR. The dataset comprises a total of 12,000 hours of video footage, covering English + 12 non-English languages. MultiVSR is a massive dataset with a huge diversity in terms of the speakers as well as languages, with approximately 1.6M video clips across 123K YouTube videos. Please check the website for samples.\n\n  \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDownload instructions\n\t\n\nPlease check the GitHub repo to downloadâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/sindhuhegde/multivsr.","url":"https://huggingface.co/datasets/sindhuhegde/multivsr","creator_name":"Sindhu Hegde","creator_url":"https://huggingface.co/sindhuhegde","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["English","French","German","Spanish","Italian"],"keywords_longer_than_N":true},
	{"name":"sql-create-context-pt","keyword":"portuguese","description":"\n\t\n\t\t\n\t\tOverview\n\t\n\nEste dataset  Ã© uma versÃ£o traduzida para o portuguÃªs do dataset b-mc2/sql-create-context,\nque foi construÃ­do a partir dos datasets WikiSQL e Spider. Ele contÃ©m exemplos de perguntas\nem portuguÃªs, instruÃ§Ãµes SQL CREATE TABLE e consultas SQL que respondem Ã s perguntas\nutilizando a instruÃ§Ã£o CREATE TABLE como contexto.\nO principal objetivo deste dataset Ã© ajudar modelos de linguagem natural  em portuguÃªs a gerar consultas\nSQL precisas e contextualizadas, prevenindo aâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/emdemor/sql-create-context-pt.","url":"https://huggingface.co/datasets/emdemor/sql-create-context-pt","creator_name":"Eduardo Morais","creator_url":"https://huggingface.co/emdemor","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","question-answering","table-question-answering","Portuguese","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"leis_ordinarias_1988_2024","keyword":"portuguese","description":"celsowm/leis_ordinarias_1988_2024 dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/celsowm/leis_ordinarias_1988_2024","creator_name":"Celso F","creator_url":"https://huggingface.co/celsowm","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["summarization","text-generation","Portuguese","apache-2.0","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"finepdfs-summaries","keyword":"portuguese","description":"\n\t\n\t\t\n\t\tfinepdfs-summaries\n\t\n\nSummaries generated with Qwen3-Next-80B-A3B-Instruct for documents from finepdfs.\nWork in progress, still generating more data.\nThe following table shows the data available for each language:\n\n\t\n\t\t\nLanguage\nSummaries\nTokens\nDisk size\n\n\n\t\t\nAll\n838,268,819\n247 B\n366 GB\n\n\ndeu_Latn\n363,671,069\n113 B\n149 GB\n\n\neng_Latn\n353,969,370\n89 B\n162 GB\nfra_Latn\n27,308,302\n10 B\n14 GB\n\n\nspa_Latn\n25,624,727\n9 B\n12 GB\n\n\nita_Latn\n17,587,618\n6 B\n8 GB\n\n\npor_Latn\n12,043,607\n4 B\n5 GBâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/MultiSynt/finepdfs-summaries.","url":"https://huggingface.co/datasets/MultiSynt/finepdfs-summaries","creator_name":"MultiSynt","creator_url":"https://huggingface.co/MultiSynt","license_name":"Open Data Commons Attribution License v1.0","license_url":"https://scancode-licensedb.aboutcode.org/odc-by-1.0.html","language":"en","first_N":5,"first_N_keywords":["text-generation","summarization","English","German","French"],"keywords_longer_than_N":true},
	{"name":"PleIAs-ToxicCommons","keyword":"portuguese","description":"\n\t\n\t\t\n\t\tPleIAs/ToxicCommons\n\t\n\nThis dataset is a refined version of the PleIAs/ToxicCommons collection, focusing on historical texts labeled for content that may be considered objectionable by modern standards (what the authors of the dataset deem \"toxic\"). \nThe cleaned dataset contains 1â€‰051â€‰027 rows, each representing a text sample with associated toxicity scores across five dimensions:\n\nRace and origin-based bias\nGender and sexuality-based bias\nReligious bias\nAbility bias\nViolence and abuseâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/agentlans/PleIAs-ToxicCommons.","url":"https://huggingface.co/datasets/agentlans/PleIAs-ToxicCommons","creator_name":"Alan Tseng","creator_url":"https://huggingface.co/agentlans","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","English","French","Spanish","German"],"keywords_longer_than_N":true},
	{"name":"synthetic_multilingual_llm_prompts","keyword":"portuguese","description":"\n  \n  Image generated by DALL-E. See prompt for more details\n\n\n\n\t\n\t\t\n\t\tðŸ“ðŸŒ Synthetic Multilingual LLM Prompts\n\t\n\nWelcome to the \"Synthetic Multilingual LLM Prompts\" dataset! This comprehensive collection features 1,250 synthetic LLM prompts generated using Gretel Navigator, available in seven different languages. To ensure accuracy and diversity in prompts, and translation quality and consistency across the different languages, we employed Gretel Navigator both as a generation tool and as anâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/gretelai/synthetic_multilingual_llm_prompts.","url":"https://huggingface.co/datasets/gretelai/synthetic_multilingual_llm_prompts","creator_name":"Gretel.ai","creator_url":"https://huggingface.co/gretelai","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","translation","question-answering","English","Dutch"],"keywords_longer_than_N":true},
	{"name":"Date_jese","keyword":"portuguese","description":"Raivatv24/Date_jese dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/Raivatv24/Date_jese","creator_name":"Fernando Roldao","creator_url":"https://huggingface.co/Raivatv24","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["Portuguese","apache-2.0","n<1K","ðŸ‡ºðŸ‡¸ Region: US"],"keywords_longer_than_N":false},
	{"name":"portufake","keyword":"portuguese","description":"\n\t\n\t\t\n\t\n\t\n\t\tDataset Card for Portufake\n\t\n\n\n\nThis dataset contains spectrograms of audio deepfakes and real speaker recordings in Portuguese, originating from Fake Voices Dataset \nand CETUC Corpus, respectively.\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Description\n\t\n\n\n\nThe dataset contains 183,878 512px x 256px colored constant-Q transform (CQT) spectrograms created from audios categorized in two labels: \"real\" or \"fake\". \nThey correspond, respectively, to Brazilian Portugueseâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/unfake/portufake.","url":"https://huggingface.co/datasets/unfake/portufake","creator_name":"Unfake","creator_url":"https://huggingface.co/unfake","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["image-classification","image-feature-extraction","Portuguese","mit","10B<n<100B"],"keywords_longer_than_N":true},
	{"name":"ementas_camarabr_1934_2024","keyword":"portuguese","description":"Collected at 26 Sept 2024\n","url":"https://huggingface.co/datasets/belisards/ementas_camarabr_1934_2024","creator_name":"adriano","creator_url":"https://huggingface.co/belisards","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["Portuguese","mit","100K - 1M","parquet","Tabular"],"keywords_longer_than_N":true},
	{"name":"X-ALMA-Preference","keyword":"portuguese","description":"This is the translation preference dataset used by X-ALMA.\nsource: the source sentence.\nchosen: the preferred translation.\nreject: the dis-preferred translation.\ndirections: the translation direction.\n@misc{xu2024xalmaplugplay,\n      title={X-ALMA: Plug & Play Modules and Adaptive Rejection for Quality Translation at Scale}, \n      author={Haoran Xu and Kenton Murray and Philipp Koehn and Hieu Hoang and Akiko Eriguchi and Huda Khayrallah},\n      year={2024},\n      eprint={2410.03115}â€¦ See the full description on the dataset page: https://huggingface.co/datasets/haoranxu/X-ALMA-Preference.","url":"https://huggingface.co/datasets/haoranxu/X-ALMA-Preference","creator_name":"Haoran Xu","creator_url":"https://huggingface.co/haoranxu","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["English","Danish","Dutch","German","Icelandic"],"keywords_longer_than_N":true},
	{"name":"xgqa","keyword":"portuguese","description":"\n\t\n\t\t\n\t\txGQA\n\t\n\n\n\t\n\t\t\n\t\tThis is a clone of the few_shot-test split of the xGQA dataset\n\t\n\nPlease find the original repository here: https://github.com/adapter-hub/xGQA\nIf you use this dataset, please cite the original authors:\n@inproceedings{pfeiffer-etal-2021-xGQA,\n    title={{xGQA: Cross-Lingual Visual Question Answering}},\n    author={ Jonas Pfeiffer and Gregor Geigle and Aishwarya Kamath and Jan-Martin O. Steitz and Stefan Roth and Ivan Vuli{\\'{c}} and Iryna Gurevych},\n    booktitle =â€¦ See the full description on the dataset page: https://huggingface.co/datasets/floschne/xgqa.","url":"https://huggingface.co/datasets/floschne/xgqa","creator_name":"Flo Schneider","creator_url":"https://huggingface.co/floschne","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["visual-question-answering","Bengali","German","English","Indonesian"],"keywords_longer_than_N":true},
	{"name":"SQuAD-pt_BR-V1.1_","keyword":"portuguese","description":"\n\t\n\t\t\n\t\tDataset Card para o SQuAD 1.1 em PortuguÃªs Brasil\n\t\n\nO conjunto de dados \"Stanford Question Answering Dataset\" (SQuAD),\npara tarefa de perguntas e respostas extrativas, foi desenvolvido em 2016. Ele utiliza perguntas geradas a partir de\n536 artigos da Wikipedia* com mais de 100.000 linhas de dados. Ã‰ construÃ­do na forma de uma pergunta e um contexto dos artigos da\nWikipedia contendo a resposta Ã  pergunta. [1]Originalmente este dataset foi construÃ­do no idioma inglÃªs, contudo, o grupoâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/vsvasconcelos/SQuAD-pt_BR-V1.1_.","url":"https://huggingface.co/datasets/vsvasconcelos/SQuAD-pt_BR-V1.1_","creator_name":"Vagner Sanches Vasconcelos","creator_url":"https://huggingface.co/vsvasconcelos","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["Portuguese","mit","10K - 100K","csv","Text"],"keywords_longer_than_N":true},
	{"name":"world-languages-dataset","keyword":"portuguese","description":"\n\t\n\t\t\n\t\tðŸŒ World Languages Dataset\n\t\n\nThis dataset contains a list of official and unofficial languages categorized by language families...\n","url":"https://huggingface.co/datasets/SivaMallikarjun/world-languages-dataset","creator_name":"Parvatham Siva Mallikarjun","creator_url":"https://huggingface.co/SivaMallikarjun","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","language-identification","expert-generated","multilingual","original"],"keywords_longer_than_N":true},
	{"name":"FairytaleQA-translated-ptPT","keyword":"portuguese","description":"\n\t\n\t\t\n\t\tDataset Card for FairytaleQA-translated-ptPT\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis repository contains the European Portuguese (pt-PT) machine-translated version of the original English FairytaleQA dataset (https://huggingface.co/datasets/WorkInTheDark/FairytaleQA). FairytaleQA is an open-source dataset designed to enhance comprehension of narratives, aimed at students from kindergarten to eighth grade. The dataset is meticulously annotated by education experts following an evidence-basedâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/benjleite/FairytaleQA-translated-ptPT.","url":"https://huggingface.co/datasets/benjleite/FairytaleQA-translated-ptPT","creator_name":"Bernardo Leite","creator_url":"https://huggingface.co/benjleite","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["question-answering","text-generation","Portuguese","apache-2.0","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"multilingual_translation_gpt4o_gen","keyword":"portuguese","description":"Youseff1987/multilingual_translation_gpt4o_gen dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/Youseff1987/multilingual_translation_gpt4o_gen","creator_name":"JOON HYOUNG JUN","creator_url":"https://huggingface.co/Youseff1987","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["translation","Korean","English","Chinese","Zulu"],"keywords_longer_than_N":true},
	{"name":"AllTripletsMsMarco-PTBR","keyword":"portuguese","description":"Need a huge dataset translated? Connect with me!\n","url":"https://huggingface.co/datasets/cnmoro/AllTripletsMsMarco-PTBR","creator_name":"Carlo Moro","creator_url":"https://huggingface.co/cnmoro","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["Portuguese","apache-2.0","10M - 100M","parquet","Text"],"keywords_longer_than_N":true},
	{"name":"brwac","keyword":"portuguese","description":"\n\n\t\n\t\t\n\t\tDataset Card for BrWaC\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThe BrWaC (Brazilian Portuguese Web as Corpus) is a large corpus constructed following the Wacky framework, \nwhich was made public for research purposes. The current corpus version, released in January 2017, is composed by \n3.53 million documents, 2.68 billion tokens and 5.79 million types. Please note that this resource is available \nsolely for academic research purposes, and you agreed not to use it for any commercialâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/bfunicheli/brwac.","url":"https://huggingface.co/datasets/bfunicheli/brwac","creator_name":"Funicheli","creator_url":"https://huggingface.co/bfunicheli","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-generation","fill-mask","language-modeling","masked-language-modeling","no-annotation"],"keywords_longer_than_N":true},
	{"name":"pt_bantu","keyword":"portuguese","description":"andissonerangel/pt_bantu dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/andissonerangel/pt_bantu","creator_name":"Andissone Rangel","creator_url":"https://huggingface.co/andissonerangel","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["translation","Portuguese","apache-2.0","< 1K","csv"],"keywords_longer_than_N":true},
	{"name":"MuMiN-PT","keyword":"portuguese","description":"\n\t\n\t\t\n\t\tMuMIN-PT\n\t\n\nMuMIN Portuguese Baseline subset extracted using Lingua.\n\nHomepage: https://mumin-dataset.github.io/\nRepository: https://github.com/MuMiN-dataset/mumin-baseline\nPaper:  https://arxiv.org/abs/2202.11684\nLeaderboard: \nPoint of Contact:\n\n\n\t\n\t\t\n\t\n\t\n\t\tCitation Information\n\t\n\n@inproceedings{10.1145/3477495.3531744,\nauthor = {Nielsen, Dan S. and McConville, Ryan},\ntitle = {MuMiN: A Large-Scale Multilingual Multimodal Fact-Checked Misinformation Social Network Dataset},\nyear =â€¦ See the full description on the dataset page: https://huggingface.co/datasets/ju-resplande/MuMiN-PT.","url":"https://huggingface.co/datasets/ju-resplande/MuMiN-PT","creator_name":"Juliana Resplande","creator_url":"https://huggingface.co/ju-resplande","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","found","monolingual","Portuguese","mit"],"keywords_longer_than_N":true},
	{"name":"m-ArenaHard","keyword":"portuguese","description":"\n\t\n\t\t\n\t\tDataset Card for m-ArenaHard\n\t\n\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\nThe m-ArenaHard dataset is a multilingual LLM evaluation set. This dataset was created by translating the prompts from the originally English-only LMarena (formerly LMSYS) arena-hard-auto-v0.1 test dataset using Google Translate API v3 to 22 languages. The original English-only prompts were created by Li et al. (2024) and consist of 500 challenging user queries sourced from Chatbot Arena. The authors show that these can be usedâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/CohereLabs/m-ArenaHard.","url":"https://huggingface.co/datasets/CohereLabs/m-ArenaHard","creator_name":"Cohere Labs","creator_url":"https://huggingface.co/CohereLabs","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["English","French","German","Spanish","Italian"],"keywords_longer_than_N":true},
	{"name":"LEI40","keyword":"portuguese","description":"abelrh/LEI40 dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/abelrh/LEI40","creator_name":"Abel Melo Borges","creator_url":"https://huggingface.co/abelrh","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["Portuguese","apache-2.0","< 1K","json","Text"],"keywords_longer_than_N":true},
	{"name":"JQL-LLM-Edu-Annotations","keyword":"portuguese","description":"\n\t\n\t\t\n\t\tðŸ“š JQL Educational Quality Annotations from LLMs\n\t\n\nThis dataset provides 17,186,606 documents with high-quality LLM annotations for evaluating the educational value of web documents, and serves as a benchmark for training and evaluating multilingual LLM annotators as described in the JQL paper.\n\n\n\t\n\t\t\n\t\tðŸ“ Dataset Summary\n\t\n\n  Multilingual document-level quality annotations scored on a 0â€“5 educational value scale by three state-of-the-art LLMs:\n  Gemma-3-27B-it, Mistral-3.1-24B-itâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/JQL-AI/JQL-LLM-Edu-Annotations.","url":"https://huggingface.co/datasets/JQL-AI/JQL-LLM-Edu-Annotations","creator_name":"JQL-AI","creator_url":"https://huggingface.co/JQL-AI","license_name":"Open Data Commons Attribution License v1.0","license_url":"https://scancode-licensedb.aboutcode.org/odc-by-1.0.html","language":"en","first_N":5,"first_N_keywords":["Bulgarian","Czech","Croatian","Macedonian","Polish"],"keywords_longer_than_N":true},
	{"name":"reasoning-v1-20m-portuguese","keyword":"portuguese","description":"glaiveai/reasoning-v1-20m translated to portuguese.\n","url":"https://huggingface.co/datasets/cnmoro/reasoning-v1-20m-portuguese","creator_name":"Carlo Moro","creator_url":"https://huggingface.co/cnmoro","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","Portuguese","apache-2.0","10M - 100M","parquet"],"keywords_longer_than_N":true},
	{"name":"OGC_Renewable_Regulation","keyword":"portuguese","description":"\n\t\n\t\t\n\t\tOGC_Renewable_Regulation - Overview\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nOGC_Renewable_Regulation is a curated multimodal dataset focused on renewable energy technical documents, regulations, and legal frameworks. It combines text and image data extracted from real scientific and regulatory PDFs to support tasks such as RAG DSE, question answering, document search, and vision-language model training.\n\n\t\n\t\t\n\t\tDataset Creation\n\t\n\nThis dataset was created using our open-source toolâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/racineai/OGC_Renewable_Regulation.","url":"https://huggingface.co/datasets/racineai/OGC_Renewable_Regulation","creator_name":"racine.ai","creator_url":"https://huggingface.co/racineai","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["question-answering","visual-question-answering","text-retrieval","English","French"],"keywords_longer_than_N":true},
	{"name":"pt_to_an","keyword":"portuguese","description":"A collection of translations from Portuguese do Angrarosskesh, my fictional language.\n","url":"https://huggingface.co/datasets/matjs/pt_to_an","creator_name":"Matheus J. G. Silva","creator_url":"https://huggingface.co/matjs","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["translation","Portuguese","mit","< 1K","csv"],"keywords_longer_than_N":true},
	{"name":"mmmlu_lite","keyword":"portuguese","description":"\n\t\n\t\t\n\t\tMMMLU-Lite\n\t\n\n\n\t\n\t\t\n\t\tIntroduction\n\t\n\nA lite version of the MMMLU dataset, which is an community version of the MMMLU dataset by OpenCompass. Due to the large size of the original dataset (about 200k questions), we have created a lite version of the dataset to make it easier to use. We sample 25 examples from each language subject in the original dataset with fixed seed to ensure reproducibility, finally we have 19950 examples in the lite version of the dataset, which is about 10% ofâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/opencompass/mmmlu_lite.","url":"https://huggingface.co/datasets/opencompass/mmmlu_lite","creator_name":"OpenCompass","creator_url":"https://huggingface.co/opencompass","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["question-answering","Arabic","Bengali","German","Spanish"],"keywords_longer_than_N":true},
	{"name":"youtube-commons-small","keyword":"portuguese","description":"\n\t\n\t\t\n\t\tðŸ“º YouTube-Commons-Small ðŸ“º\n\t\n\nThis is a smaller subset of the YouTube-Commons dataset, which is a collection of audio transcripts from videos shared on YouTube under a CC-By license.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis smaller version contains a subset of the original dataset, maintaining the same structure and features. It's designed for easier experimentation and testing purposes.\n\n\t\n\t\t\n\t\tFeatures\n\t\n\nThe dataset includes the following information for each video:\n\nVideo ID and linkâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/dm-petrov/youtube-commons-small.","url":"https://huggingface.co/datasets/dm-petrov/youtube-commons-small","creator_name":"Dmitry Petrov","creator_url":"https://huggingface.co/dm-petrov","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","English","French","Spanish","Portuguese"],"keywords_longer_than_N":true},
	{"name":"amv_genre_multimodal_dataset","keyword":"portuguese","description":"\n\t\n\t\t\n\t\tEstrutura do Conjunto de Dados\n\t\n\nO conjunto de dados, em formato CSV, foi preparado usando tÃ©cnicas de visualizaÃ§Ã£o de mÃ­dia (media visualization). Ele Ã© composto por vÃ­deos de humor sobre temas sociopolÃ­ticos, coletados do YouTube. O arquivo contÃ©m diversas colunas para uma anÃ¡lise multimodal:\n\namv_genre: O gÃªnero do vÃ­deo, categorizado como drama ou action.  \nCaracterÃ­sticas Visuais: MÃ©tricas de cor e brilho, como a mÃ©dia, mediana, desvio padrÃ£o e frequÃªncia dominante para matizâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Dumoura/amv_genre_multimodal_dataset.","url":"https://huggingface.co/datasets/Dumoura/amv_genre_multimodal_dataset","creator_name":"Eduardo Moura Almeida","creator_url":"https://huggingface.co/Dumoura","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","Portuguese","mit","< 1K","csv"],"keywords_longer_than_N":true},
	{"name":"xwinograd","keyword":"portuguese","description":"\n\t\n\t\t\n\t\tXWinograd\n\t\n\nMultilingual winograd schema challenge as used in Crosslingual Generalization through Multitask Finetuning.\n\n\t\n\t\t\n\t\tLanguages & Samples\n\t\n\n\n\"en\": 2325\n\"fr\": 83\n\"jp\": 959\n\"pt\": 263 \n\"ru\": 315\n\"zh\": 504\n\n\n\t\n\t\t\n\t\tDataset creation\n\t\n\nThe Winograd schema challenges in this dataset combine winograd schemas from the XWinograd dataset introduced in Tikhonov et al and as it only contains 16 Chinese schemas, we add 488 Chinese schemas from clue/cluewsc2020.\nIf you only want theâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Muennighoff/xwinograd.","url":"https://huggingface.co/datasets/Muennighoff/xwinograd","creator_name":"Niklas Muennighoff","creator_url":"https://huggingface.co/Muennighoff","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["English","French","Japanese","Portuguese","Russian"],"keywords_longer_than_N":true},
	{"name":"LivingNER","keyword":"portuguese","description":"\n\t\n\t\t\n\t\tLivingNER: Named entity recognition, normalization & classification of species, pathogens and food\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThe LivingNER Gold Standard corpus is a collection of 2000 clinical case reports covering a broad range of medical specialities, i.e. infectious diseases (including Covid-19 cases), cardiology, neurology, oncology, dentistry, pediatrics, endocrinology, primary care, allergology, radiology, psychiatry, ophthalmology, urology, internal medicine, emergency andâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Praise2112/LivingNER.","url":"https://huggingface.co/datasets/Praise2112/LivingNER","creator_name":"Praise","creator_url":"https://huggingface.co/Praise2112","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["token-classification","multilingual","English","French","Galolen"],"keywords_longer_than_N":true},
	{"name":"aya_collection","keyword":"portuguese","description":"\nThis dataset is uploaded in two places: here and additionally here as 'Aya Collection Language Split.' These datasets are identical in content but differ in structure of upload. This dataset is structured by folders split according to dataset name. The version here instead divides the Aya collection into folders split by language. We recommend you use the language split version if you are only interested in downloading data for a single or smaller set of languages, and this version if youâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/CohereLabs/aya_collection.","url":"https://huggingface.co/datasets/CohereLabs/aya_collection","creator_name":"Cohere Labs","creator_url":"https://huggingface.co/CohereLabs","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","summarization","translation","Achinese","Afrikaans"],"keywords_longer_than_N":true},
	{"name":"KairosNews","keyword":"portuguese","description":"Handcrafted Dataset used in the elaboration of a thesis and a project for a competition (Premio Arquivo.pt: https://sobre.arquivo.pt/pt/colabore/premios-arquivo-pt/premio-arquivo-pt-2025/)\nIt contains news articles from the following Portuguese News agencies from 2020 to 2024:\nhttps://www.cmjornal.pt/ = 6771\nhttps://expresso.pt/ = 22606\nhttps://www.iol.pt/ = 39387\nhttps://www.publico.pt/ = 74893\nhttps://www.sapo.pt/ = 57838\nTOTAL = 201495\nEach news article contains it's url, title, textâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/0edon/KairosNews.","url":"https://huggingface.co/datasets/0edon/KairosNews","creator_name":"Quintino Fernandes","creator_url":"https://huggingface.co/0edon","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["summarization","text-classification","token-classification","Portuguese","mit"],"keywords_longer_than_N":true},
	{"name":"portugues_ocr_dataset_full","keyword":"portuguese","description":"\n\t\n\t\t\n\t\tPortugues OCR Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThe portugues_ocr_dataset_full is a dataset designed for Optical Character Recognition (OCR) tasks. It contains images of text from the Portuguese literary work Os LusÃ­adas by LuÃ­s Vaz de CamÃµes, as well as the corresponding ground truth text labels. This dataset can be used for training and evaluating OCR models for Portuguese text recognition.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset consists of:\n\nImages: Each image is a cropped portionâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/mazafard/portugues_ocr_dataset_full.","url":"https://huggingface.co/datasets/mazafard/portugues_ocr_dataset_full","creator_name":"Mohammadreza Asadollahifard","creator_url":"https://huggingface.co/mazafard","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["image-to-text","manual","monolingual","Portuguese","English"],"keywords_longer_than_N":true},
	{"name":"portugues_ocr_dataset_full","keyword":"portuguese","description":"\n\t\n\t\t\n\t\tPortugues OCR Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThe portugues_ocr_dataset_full is a dataset designed for Optical Character Recognition (OCR) tasks. It contains images of text from the Portuguese literary work Os LusÃ­adas by LuÃ­s Vaz de CamÃµes, as well as the corresponding ground truth text labels. This dataset can be used for training and evaluating OCR models for Portuguese text recognition.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset consists of:\n\nImages: Each image is a cropped portionâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/mazafard/portugues_ocr_dataset_full.","url":"https://huggingface.co/datasets/mazafard/portugues_ocr_dataset_full","creator_name":"Mohammadreza Asadollahifard","creator_url":"https://huggingface.co/mazafard","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["image-to-text","manual","monolingual","Portuguese","English"],"keywords_longer_than_N":true},
	{"name":"semeval-2025-task11-track-b","keyword":"portuguese","description":"\n\t\n\t\t\n\t\tSemEval 2025 Task 11 - Track B Dataset\n\t\n\nThis dataset contains the data for SemEval 2025 Task 11: Bridging the Gap in Text-Based Emotion Detection - Track B, organized as language-specific configurations.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset is a multi-language, multi-label emotion classification dataset with separate configurations for each language.\n\nTotal languages: 11 standard ISO codes\nTotal examples: 47111\nSplits: train, dev, test\n\n\n\t\n\t\t\n\t\tTrack Information\n\t\n\nTrack B hasâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/vgaraujov/semeval-2025-task11-track-b.","url":"https://huggingface.co/datasets/vgaraujov/semeval-2025-task11-track-b","creator_name":"Vladimir Araujo","creator_url":"https://huggingface.co/vgaraujov","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["Amharic","Arabic","German","English","Spanish"],"keywords_longer_than_N":true},
	{"name":"mHumanEval-Benchmark","keyword":"portuguese","description":"\n\n\n\t\n\t\t\n\t\tðŸ”· Accepted in NAACL Proceedings (2025) ðŸ”·\n\t\n\n\n\n\n\n  \n    \n      \n        \n          \n        \n      \n      \n        \n          \n        \n      \n      \n        \n          \n        \n      \n    \n  \n\n\n\n\n\n  \n\n\t\n\t\n\t\n\t\tmHumanEval\n\t\n\nThe mHumanEval benchmark is curated based on prompts from the original HumanEval ðŸ“š [Chen et al., 2021]. It includes a total of 33,456 prompts for Python, and 836,400 in total - significantly expanding from the original 164. \n\n\n\t\n\t\t\n\t\tQuick Start\n\t\n\n  Detailedâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/md-nishat-008/mHumanEval-Benchmark.","url":"https://huggingface.co/datasets/md-nishat-008/mHumanEval-Benchmark","creator_name":"Nishat Raihan","creator_url":"https://huggingface.co/md-nishat-008","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["Afar","Abkhaz","Avestan","Afrikaans","Akan"],"keywords_longer_than_N":true},
	{"name":"SpokenPortugueseGeographicalSocialVarieties","keyword":"portuguese","description":"\n\t\n\t\t\n\t\tSpoken Portuguese - Geographical and Social Varieties\n\t\n\ndataset source: https://www.clul.ulisboa.pt\n(1995-1997 - European Commission DGXXII, Programme LINGUA/SOCRATES)\nThe project is concluded and the materials are published in CD-ROM, with the exclusive publishing support of Instituto CamÃµes, under the title PortuguÃªs Falado - Documentos AutÃªnticos: GravaÃ§Ãµes Ã¡udio com transcriÃ§Ã£o alinhada. Its distribution outside of Portugal is ensured by Instituto CamÃµes and in Portugal by CLUL.â€¦ See the full description on the dataset page: https://huggingface.co/datasets/TigreGotico/SpokenPortugueseGeographicalSocialVarieties.","url":"https://huggingface.co/datasets/TigreGotico/SpokenPortugueseGeographicalSocialVarieties","creator_name":"Tigre GÃ³tico Lda","creator_url":"https://huggingface.co/TigreGotico","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","Portuguese","mit","< 1K","soundfolder"],"keywords_longer_than_N":true},
	{"name":"Emakhuwa-loanwords-detection","keyword":"portuguese","description":"\n\t\n\t\t\n\t\tDetecting Loanwords in Emakhuwa\n\t\n\nPaper: Detecting Loanwords in Emakhuwa: An Extremely Low-Resource {B}antu Language Exhibiting Significant Borrowing from Portuguese\n\n@inproceedings{ali-etal-2024-detecting,\n    title = \"Detecting Loanwords in Emakhuwa: An Extremely Low-Resource {B}antu Language Exhibiting Significant Borrowing from {P}ortuguese\",\n    author = \"Ali, Felermino Dario Mario  and\n      Lopes Cardoso, Henrique  and\n      Sousa-Silva, Rui\",\n    booktitle = \"Proceedings ofâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/LIACC/Emakhuwa-loanwords-detection.","url":"https://huggingface.co/datasets/LIACC/Emakhuwa-loanwords-detection","creator_name":"LIACC","creator_url":"https://huggingface.co/LIACC","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","Portuguese","Makhuwa","mit","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"biblenlp-corpus-mmteb","keyword":"portuguese","description":"This dataset pre-computes all English-centric directions from bible-nlp/biblenlp-corpus, and as a result loading is significantly faster.\nLoading example:\n>>> from datasets import load_dataset\n>>> dataset = load_dataset(\"davidstap/biblenlp-corpus-mmteb\", \"eng-arb\", trust_remote_code=True)\n>>> dataset\nDatasetDict({\n    train: Dataset({\n        features: ['eng', 'arb'],\n        num_rows: 28723\n    })\n    validation: Dataset({\n        features: ['eng', 'arb'],\n        num_rows: 1578\n    })â€¦ See the full description on the dataset page: https://huggingface.co/datasets/davidstap/biblenlp-corpus-mmteb.","url":"https://huggingface.co/datasets/davidstap/biblenlp-corpus-mmteb","creator_name":"David Stap","creator_url":"https://huggingface.co/davidstap","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["no-annotation","expert-generated","translation","multilingual","Arifama-Miniafia"],"keywords_longer_than_N":true},
	{"name":"deep-libras","keyword":"portuguese","description":"gfmanica/deep-libras dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/gfmanica/deep-libras","creator_name":"Gabriel Felipe Manica","creator_url":"https://huggingface.co/gfmanica","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["Portuguese","mit","< 1K","Text","Video"],"keywords_longer_than_N":true},
	{"name":"toxi-text-3M","keyword":"portuguese","description":"This is a large multilingual toxicity dataset with 3M rows of text data from 55 natural languages, all of which are written/sent by humans, not machine translation models.\nThe preprocessed training data alone consists of 2,880,667 rows of comments, tweets, and messages. Among these rows, 416,529 are classified as toxic, while the remaining 2,463,773 are considered neutral. Below is a table to illustrate the data composition:\n\n\t\n\t\t\n\nToxic\nNeutral\nTotal\n\n\n\t\t\nmultilingual-train-deduplicated.csvâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/FredZhang7/toxi-text-3M.","url":"https://huggingface.co/datasets/FredZhang7/toxi-text-3M","creator_name":"Fred Zhang","creator_url":"https://huggingface.co/FredZhang7","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","zero-shot-classification","Arabic","Spanish","Panjabi"],"keywords_longer_than_N":true},
	{"name":"mental-health-pt","keyword":"portuguese","description":"rhaymison/mental-health-pt dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/rhaymison/mental-health-pt","creator_name":"Rhaymison Cristian","creator_url":"https://huggingface.co/rhaymison","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","Portuguese","apache-2.0","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"NOVA-63","keyword":"portuguese","description":"\n\t\n\t\n\t\n\t\tWe released this dataset under the MIT License. This means that anyone is free to use, copy, modify, distribute, and reuse our data, provided that the original copyright notice and license information are retained.\nThis work is jointly completed by PKU & Alibaba Group. The dataset is currently under review. Please be patient. We also hope this dataset can help more partners/colleagues in the community.\nTo ensure the validity and fairness of the benchmark evaluation, we explicitlyâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/zjy1298/NOVA-63.","url":"https://huggingface.co/datasets/zjy1298/NOVA-63","creator_name":"Zhang","creator_url":"https://huggingface.co/zjy1298","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":null,"first_N":5,"first_N_keywords":["Arabic","Chinese","English","French","Spanish"],"keywords_longer_than_N":true},
	{"name":"mc-translation","keyword":"portuguese","description":"This dataset contains professional human translations from OpenAI's MMMLU dataset, repurposed to train translation models that can help translate future evaluation datasets.\n\n\t\n\t\t\n\t\tWhy This Dataset?\n\t\n\nTranslation of evaluation benchmarks is a critical but challenging task. While automated translations may introduce errors or biases, professional human translations are expensive and time-consuming. This dataset leverages existing professional translations (MMMLU) to train specializedâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/efederici/mc-translation.","url":"https://huggingface.co/datasets/efederici/mc-translation","creator_name":"Edoardo Federici","creator_url":"https://huggingface.co/efederici","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["translation","English","Swahili","Spanish","German"],"keywords_longer_than_N":true},
	{"name":"muri-it","keyword":"portuguese","description":"\n\t\n\t\t\n\t\tMURI-IT: Multilingual Instruction Tuning Dataset for 200 Languages via Multilingual Reverse Instructions\n\t\n\nMURI-IT is a large-scale multilingual instruction tuning dataset containing 2.2 million instruction-output pairs across 200 languages. It is designed to address the challenges of instruction tuning in low-resource languages with Multilingual Reverse Instructions (MURI), which ensures that the output is human-written, high-quality, and authentic to the cultural and linguisticâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/akoksal/muri-it.","url":"https://huggingface.co/datasets/akoksal/muri-it","creator_name":"Abdullatif Koksal","creator_url":"https://huggingface.co/akoksal","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text2text-generation","text-generation","question-answering","summarization","Achinese"],"keywords_longer_than_N":true},
	{"name":"cml-tts-filtered-annotated","keyword":"portuguese","description":"\n\t\n\t\t\n\t\tDataset Card for Filtred and annotated CML TTS\n\t\n\nThis dataset is an annotated and filtred version of a CML-TTS [1]. \nCML-TTS [1] CML-TTS is a recursive acronym for CML-Multi-Lingual-TTS, a Text-to-Speech (TTS) dataset developed at the Center of Excellence in Artificial Intelligence (CEIA) of the Federal University of Goias (UFG). CML-TTS is a dataset comprising audiobooks sourced from the public domain books of Project Gutenberg, read by volunteers from the LibriVox project. Theâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/PHBJT/cml-tts-filtered-annotated.","url":"https://huggingface.co/datasets/PHBJT/cml-tts-filtered-annotated","creator_name":"Paul Henri Biojout","creator_url":"https://huggingface.co/PHBJT","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-to-speech","French","German","Italian","Spanish"],"keywords_longer_than_N":true},
	{"name":"PolyGuardMix","keyword":"portuguese","description":"\n\t\n\t\t\n\t\tPolyGuard: A Multilingual Safety Moderation Tool for 17 Languages\n\t\n\nAbstract: Truly multilingual safety moderation efforts for Large Language Models (LLMs) have been hindered by a narrow focus on a small set of languages (e.g., English, Chinese) as well as a limited scope of safety definition, resulting in significant gaps in moderation capabilities. To bridge these gaps, we release PolyGuard, a new state-of-the-art multilingual safety model for safeguarding LLM generations, and theâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/ToxicityPrompts/PolyGuardMix.","url":"https://huggingface.co/datasets/ToxicityPrompts/PolyGuardMix","creator_name":"ToxicityPrompts","creator_url":"https://huggingface.co/ToxicityPrompts","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["Arabic","Chinese","Czech","Dutch","English"],"keywords_longer_than_N":true},
	{"name":"nurc-sp_pseudo_labelled","keyword":"portuguese","description":"RodrigoLimaRFL/nurc-sp_pseudo_labelled dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/RodrigoLimaRFL/nurc-sp_pseudo_labelled","creator_name":"Rodrigo de Freitas Lima","creator_url":"https://huggingface.co/RodrigoLimaRFL","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["Portuguese","mit","10K - 100K","parquet","Audio"],"keywords_longer_than_N":true},
	{"name":"bot_etherium","keyword":"portuguese","description":"coan/bot_etherium dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/coan/bot_etherium","creator_name":"Ana Laura Coan","creator_url":"https://huggingface.co/coan","license_name":"Public Domain Dedication & License","license_url":"https://scancode-licensedb.aboutcode.org/pddl-1.0.html","language":"en","first_N":5,"first_N_keywords":["tabular-classification","Portuguese","pddl","1K - 10K","csv"],"keywords_longer_than_N":true},
	{"name":"FineNews-unfiltered","keyword":"portuguese","description":"\n\t\n\t\t\n\t\tFineNews\n\t\n\nWIP. Like FineWeb, but built from Common Crawl News instead of main web.\nFor languages not listed as a split, check the data/ directory.\nFor now, it contains the 2024-05 (May),-04 (April),-03 (March) dumps.\nThis is the unfiltered version, with only URL filtering applied.\n\n\t\n\t\t\n\t\tSome initial stats\n\t\n\nTotal number of documents: 35M\n\n\t\n\t\t\nDump\nNumber of docs\nDisk size (compressed)\n\n\n\t\t\nCC-NEWS-2024-05\n11_715_084\n11G\n\n\nCC-NEWS-2024-04\n11_546_298\n11G\n\n\nCC-NEWS-2024-03â€¦ See the full description on the dataset page: https://huggingface.co/datasets/maxidl/FineNews-unfiltered.","url":"https://huggingface.co/datasets/maxidl/FineNews-unfiltered","creator_name":"Max Idahl","creator_url":"https://huggingface.co/maxidl","license_name":"Open Data Commons Attribution License v1.0","license_url":"https://scancode-licensedb.aboutcode.org/odc-by-1.0.html","language":"en","first_N":5,"first_N_keywords":["text-generation","English","German","French","Polish"],"keywords_longer_than_N":true},
	{"name":"reviews_linkedin","keyword":"portuguese","description":"\n\t\n\t\t\n\t\tDescriÃ§Ã£o\n\t\n\nDataset que traz os comentÃ¡rios dos ususÃ¡rios do Google Play sobre o app do LinkedIn\n","url":"https://huggingface.co/datasets/marioluciofjr/reviews_linkedin","creator_name":"MÃ¡rio LÃºcio","creator_url":"https://huggingface.co/marioluciofjr","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","Portuguese","mit","10K - 100K","csv"],"keywords_longer_than_N":true},
	{"name":"enunciados_pge_rj_orpo","keyword":"portuguese","description":"celsowm/enunciados_pge_rj_orpo dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/celsowm/enunciados_pge_rj_orpo","creator_name":"Celso F","creator_url":"https://huggingface.co/celsowm","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["question-answering","Portuguese","apache-2.0","1K - 10K","json"],"keywords_longer_than_N":true},
	{"name":"ParaNames","keyword":"portuguese","description":"\n\t\n\t\t\n\t\n\t\n\t\tDataset Card for Dataset Name\n\t\n\n\n\nThis dataset card aims to be a base template for new datasets. It has been generated using this raw template.\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Description\n\t\n\n\n\n\n\n\nCurated by: [More Information Needed]\nFunded by [optional]: [More Information Needed]\nShared by [optional]: [More Information Needed]\nLanguage(s) (NLP): [More Information Needed]\nLicense: [More Information Needed]\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Sources [optional]â€¦ See the full description on the dataset page: https://huggingface.co/datasets/bltlab/ParaNames.","url":"https://huggingface.co/datasets/bltlab/ParaNames","creator_name":"Broadening Linguistic Technologies Lab (BLT Lab)","creator_url":"https://huggingface.co/bltlab","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["token-classification","Nias","Kotava","Banjar","Angika"],"keywords_longer_than_N":true},
	{"name":"clinc_oos_pt","keyword":"portuguese","description":"\n\t\n\t\t\n\t\tCLINC150 Portuguese Translation\n\t\n\nThis dataset is a Portuguese translation of the CLINC150 dataset, which contains queries from users interacting with a task-oriented dialog system across 150 intent classes over 10 domains.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe original CLINC150 dataset is designed for intent classification and out-of-scope detection. This version contains the original English text and its Portuguese translation.\n\n\t\n\t\t\n\t\tFeatures\n\t\n\n\ntext: Original English text\ntext_pt:â€¦ See the full description on the dataset page: https://huggingface.co/datasets/tech4humans/clinc_oos_pt.","url":"https://huggingface.co/datasets/tech4humans/clinc_oos_pt","creator_name":"Techforhumans","creator_url":"https://huggingface.co/tech4humans","license_name":"Creative Commons Attribution 3.0","license_url":"https://scancode-licensedb.aboutcode.org/cc-by-3.0.html","language":"en","first_N":5,"first_N_keywords":["text-classification","Portuguese","cc-by-3.0","1K - 10K","parquet"],"keywords_longer_than_N":true},
	{"name":"medicine-medical-eval-pt","keyword":"portuguese","description":"rhaymison/medicine-medical-eval-pt dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/rhaymison/medicine-medical-eval-pt","creator_name":"Rhaymison Cristian","creator_url":"https://huggingface.co/rhaymison","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","Portuguese","apache-2.0","< 1K","parquet"],"keywords_longer_than_N":true},
	{"name":"Hourly-Electricity-Demand-Brazil-Dataset","keyword":"portuguese","description":"\n\t\n\t\t\n\t\tðŸ‡§ðŸ‡· Hourly Load Curve - ONS (Brazil)\n\t\n\nThis dataset contains hourly electricity load data for Brazil, published by the ONS - National Electric System Operator. It spans from the year 2000 to the present (currently 2025), with continuous updates.\n\n\t\n\t\t\n\t\tðŸ“Œ Description\n\t\n\nThe data represents the hourly electricity demand profile across the Brazilian National Interconnected System (SIN). It is especially suitable for:\n\nElectricity load forecasting\nEnergy demand pattern analysis\nTimeâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/SamuelM0422/Hourly-Electricity-Demand-Brazil-Dataset.","url":"https://huggingface.co/datasets/SamuelM0422/Hourly-Electricity-Demand-Brazil-Dataset","creator_name":"Samuel Silva","creator_url":"https://huggingface.co/SamuelM0422","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["time-series-forecasting","English","Portuguese","cc-by-4.0","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"aya_african_alpaca","keyword":"portuguese","description":"\n\t\n\t\t\n\t\tAya African Alpaca Style Dataset\n\t\n\n\n\nThis dataset card aims to be a base template for new datasets. It has been generated using this raw template.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\n\n\n\n\nCurated by: [More Information Needed]\nFunded by [optional]: [More Information Needed]\nShared by [optional]: [More Information Needed]\nLanguage(s) (NLP): [More Information Needed]\nLicense: [More Information Needed]\n\n\n\t\n\t\t\n\t\tDataset Sources [optional]\n\t\n\n\n\n\nRepository: [Moreâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/vutuka/aya_african_alpaca.","url":"https://huggingface.co/datasets/vutuka/aya_african_alpaca","creator_name":"vutuka","creator_url":"https://huggingface.co/vutuka","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-generation","Afrikaans","Swahili","French","English"],"keywords_longer_than_N":true},
	{"name":"Wikipedia-Abstract","keyword":"portuguese","description":"Wikipedia Abstract\n\n\n  \n\n\n\nIntroducing Wikipedia Abstract, a comprehensive dataset encompassing abstracts, complete articles, and a popularity score index for both widely spoken and lesser-known Wikipedia subsets. Our dedication to Wikipedia-X ensures a centralized Wikipedia dataset that undergoes regular updates and adheres to the highest standards.\nA central focus of our efforts was to include exotic languages that often lack up-to-date Wikipedia dumps or may not have any dumps at all.â€¦ See the full description on the dataset page: https://huggingface.co/datasets/laion/Wikipedia-Abstract.","url":"https://huggingface.co/datasets/laion/Wikipedia-Abstract","creator_name":"LAION eV","creator_url":"https://huggingface.co/laion","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","question-answering","text-generation","fill-mask","Arabic"],"keywords_longer_than_N":true},
	{"name":"Emakhuwa-Monolingual","keyword":"portuguese","description":"BibTeX:\nThe dataset paper was published in EMNLP 2024.\nPlease cite as:\n@inproceedings{ali-etal-2024-building,\n    title = \"Building Resources for Emakhuwa: Machine Translation and News Classification Benchmarks\",\n    author = \"Ali, Felermino D. M. A.  and\n      Lopes Cardoso, Henrique  and\n      Sousa-Silva, Rui\",\n    editor = \"Al-Onaizan, Yaser  and\n      Bansal, Mohit  and\n      Chen, Yun-Nung\",\n    booktitle = \"Proceedings of the 2024 Conference on Empirical Methods in Natural Languageâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/LIACC/Emakhuwa-Monolingual.","url":"https://huggingface.co/datasets/LIACC/Emakhuwa-Monolingual","creator_name":"LIACC","creator_url":"https://huggingface.co/LIACC","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["translation","text-generation","Makhuwa","Portuguese","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"xP3x-Kongo","keyword":"portuguese","description":"\n\t\n\t\t\n\t\tDataset Card for xP3x Kikongo Focus\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\n\nxP3x (Crosslingual Public Pool of Prompts eXtended) is a collection of prompts & datasets across 277 languages & 16 NLP tasks. It contains all of xP3 + much more! It is used for training future contenders of mT0 & BLOOMZ at project Aya @C4AI ðŸ§¡\n\n\nCreation: The dataset can be recreated using instructions available here together with the file in this repository named xp3x_create.py. We provide this version to saveâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Svngoku/xP3x-Kongo.","url":"https://huggingface.co/datasets/Svngoku/xP3x-Kongo","creator_name":"NIONGOLO Chrys FÃ©-Marty","creator_url":"https://huggingface.co/Svngoku","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["other","translation","expert-generated","crowdsourced","multilingual"],"keywords_longer_than_N":true},
	{"name":"bot_claiton","keyword":"portuguese","description":"coan/bot_claiton dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/coan/bot_claiton","creator_name":"Ana Laura Coan","creator_url":"https://huggingface.co/coan","license_name":"Public Domain Dedication & License","license_url":"https://scancode-licensedb.aboutcode.org/pddl-1.0.html","language":"en","first_N":5,"first_N_keywords":["tabular-classification","Portuguese","pddl","n>1T","ðŸ‡ºðŸ‡¸ Region: US"],"keywords_longer_than_N":true},
	{"name":"M3GIA","keyword":"portuguese","description":"\n\t\n\t\t\n\t\tM3GIA: A Cognition Inspired Multilingual and Multimodal General Intelligence Ability\n\t\n\n[ðŸŒ Homepage] | ðŸ¤— Dataset | ðŸ¤— Paper | ðŸ“– arXiv | ðŸ’» GitHub\nThe evaluation code can be found in ðŸ’» GitHub.\n[Abstract]\nAs recent multi-modality large language models (MLLMs) have shown formidable proficiency on various complex tasks, there has been increasing attention on debating whether these models could eventually mirror human intelligence. However, existing benchmarks mainly focus on evaluatingâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Songweii/M3GIA.","url":"https://huggingface.co/datasets/Songweii/M3GIA","creator_name":"Wei Song","creator_url":"https://huggingface.co/Songweii","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["English","Chinese","Spanish","French","Portuguese"],"keywords_longer_than_N":true},
	{"name":"Descriptors_STJ","keyword":"portuguese","description":"\nWork developed as part of [IRIS] (https://www.inesc-id.pt/projects/PR07005/)\n\n\t\n\t\t\n\t\n\t\n\t\tExtreme Multi-Label Classification of Descriptors\n\t\n\nThe goal of this dataset is to train an Extreme Multi-Label classifier that, given a judgment from the Supreme Court of Justice of Portugal (STJ), can associate relevant descriptors to the judgment.\nDataset Contents:\n\nJudgment ID: Unique identifier for each judgment.\nSTJ Section: The section of the STJ to which the judgment belongs.Judgment Text: Fullâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/MartimZanatti/Descriptors_STJ.","url":"https://huggingface.co/datasets/MartimZanatti/Descriptors_STJ","creator_name":"Martim Zanatti dos Santos Gomes da Silva","creator_url":"https://huggingface.co/MartimZanatti","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["token-classification","Portuguese","mit","10K - 100K","csv"],"keywords_longer_than_N":true},
	{"name":"anacreontea","keyword":"portuguese","description":"This repository contains the dataset for the paper Ancient Greek's New Technological Muse: Extracting Topoi in the Anacreontea with LLMs, accepted at the 51st SEMISH (51Âº SeminÃ¡rio Integrado de Software e Hardware).\nAbstract:\n\nNatural Language Processing (NLP), along with Large Language Models (LLMs), holds significant potential in the domain of literature, leveraging its computational capabilities to analyze and comprehend human language. These techniques prove to be particularly useful in aâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/ronunes/anacreontea.","url":"https://huggingface.co/datasets/ronunes/anacreontea","creator_name":"Rafael Oleques Nunes","creator_url":"https://huggingface.co/ronunes","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","Portuguese","Greek","mit","< 1K"],"keywords_longer_than_N":true},
	{"name":"voices-of-civilizations","keyword":"portuguese","description":"\n\t\n\t\t\n\t\tVoices of Civilizations (VoC)\n\t\n\nVoices of Civilizations (VoC) is the first multilingual QA benchmark designed to assess audio LLMsâ€™ cultural comprehension using full-length music recordings. VoC spans:\n\n38 languages ðŸ‡¸ðŸ‡¦ Arabic (ar), ðŸ‡§ðŸ‡© Bengali (bn), ðŸ‡§ðŸ‡¬ Bulgarian (bg), ðŸ‡¨ðŸ‡³ Chinese (zh), ðŸ‡­ðŸ‡· Croatian (hr), ðŸ‡¨ðŸ‡¿ Czech (cs), ðŸ‡©ðŸ‡° Danish (da), ðŸ‡³ðŸ‡± Dutch (nl), ðŸ‡¬ðŸ‡§ English (en), ðŸ‡ªðŸ‡ª Estonian (et), ðŸ‡«ðŸ‡® Finnish (fi), ðŸ‡«ðŸ‡· French (fr), ðŸ‡©ðŸ‡ª German (de), ðŸ‡¬ðŸ‡· Greek (el), ðŸ‡®ðŸ‡± Hebrewâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/sander-wood/voices-of-civilizations.","url":"https://huggingface.co/datasets/sander-wood/voices-of-civilizations","creator_name":"Shangda Wu (Sander Wood)","creator_url":"https://huggingface.co/sander-wood","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["question-answering","Arabic","Bengali","Bulgarian","Chinese"],"keywords_longer_than_N":true},
	{"name":"wikipedia-citation-index","keyword":"portuguese","description":"Dataset with citation indexes as of 1 August 2024 for 47 million Wikipedia articles in 55 language versions. Research: ArXiv\n","url":"https://huggingface.co/datasets/lewoniewski/wikipedia-citation-index","creator_name":"WÅ‚odzimierz Lewoniewski","creator_url":"https://huggingface.co/lewoniewski","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["Arabic","Azerbaijani","Belarusian","Bulgarian","Catalan"],"keywords_longer_than_N":true},
	{"name":"enunciados_pge_rj","keyword":"portuguese","description":"celsowm/enunciados_pge_rj dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/celsowm/enunciados_pge_rj","creator_name":"Celso F","creator_url":"https://huggingface.co/celsowm","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["question-answering","Portuguese","apache-2.0","ðŸ‡ºðŸ‡¸ Region: US"],"keywords_longer_than_N":false},
	{"name":"fact-or-opinion","keyword":"portuguese","description":"agentlans/fact-or-opinion dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/agentlans/fact-or-opinion","creator_name":"Alan Tseng","creator_url":"https://huggingface.co/agentlans","license_name":"Open Data Commons Attribution License v1.0","license_url":"https://scancode-licensedb.aboutcode.org/odc-by-1.0.html","language":"en","first_N":5,"first_N_keywords":["text-classification","Amharic","Arabic","Bengali","German"],"keywords_longer_than_N":true},
	{"name":"chatgptex","keyword":"portuguese","description":"\n\t\n\t\t\n\t\tImportant\n\t\n\nPlease, remember to cite the author.\nName: Lucas Lima (Astatonn)\nSocial: https://astatonn.com\n","url":"https://huggingface.co/datasets/AstatonnCorp/chatgptex","creator_name":"Astatonn Corp","creator_url":"https://huggingface.co/AstatonnCorp","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["Portuguese","mit","1K - 10K","json","Text"],"keywords_longer_than_N":true},
	{"name":"portuguese-fact-checking","keyword":"portuguese","description":"\n\t\n\t\t\n\t\tPortuguese Automated Fact-Checking\n\t\n\n\n\t\n\t\t\n\nFake.BR\nCOVID19.BR\nMuMiN-PT\n\n\n\t\t\nInfo (fake/true)\nðŸ–¥ï¸\nðŸ’¬\nX\n\n\nDomain\nGeneral\nHealth\n\"General\" (Health)\n\n\nYear\n2016â€“2018\n2020\n2020â€“2022\n\n\nApproach [1]\nbottom-up\nbottom-up\ntop-down\n\n\nSize\n3580/3580\n848/1139\n1339/65\n\n\n% URL\n1.0%/0.7%\n28.9%/56.9%\n0.3%/0.0%\n\n\nAvg. # words\n181.4/183.1\n167.7/111.1\n18.9/16.9\n\n\n\t\n\nCorpora characteristics after cleaning. Top-down starts with fact-checked claims; bottom-up seeks for new misinformation in posts.â€¦ See the full description on the dataset page: https://huggingface.co/datasets/ju-resplande/portuguese-fact-checking.","url":"https://huggingface.co/datasets/ju-resplande/portuguese-fact-checking","creator_name":"Juliana Resplande","creator_url":"https://huggingface.co/ju-resplande","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","Portuguese","mit","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"IFEval-mt-pt","keyword":"portuguese","description":"carminho/IFEval-mt-pt dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/carminho/IFEval-mt-pt","creator_name":"Carminho Lab","creator_url":"https://huggingface.co/carminho","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","Portuguese","apache-2.0","< 1K","json"],"keywords_longer_than_N":true},
	{"name":"thinking-multilingual-30-23-small-690","keyword":"portuguese","description":"\nBased on OPENO1 math, this is a translated dataset of 30 high quality questions & answers in 23 languages. \nOr use the \"big\" version: big 10k rows version\n","url":"https://huggingface.co/datasets/Pinkstack/thinking-multilingual-30-23-small-690","creator_name":"Pinkstack","creator_url":"https://huggingface.co/Pinkstack","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","Arabic","Chinese","Czech","Danish"],"keywords_longer_than_N":true},
	{"name":"SpokenPortugueseGeographicalSocialVarieties_splits","keyword":"portuguese","description":"sentence splits from SpokenPortugueseGeographicalSocialVarieties generated via forced alignment\n","url":"https://huggingface.co/datasets/Jarbas/SpokenPortugueseGeographicalSocialVarieties_splits","creator_name":"Casimiro Ferreira","creator_url":"https://huggingface.co/Jarbas","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","Portuguese","mit","1K - 10K","soundfolder"],"keywords_longer_than_N":true},
	{"name":"LargerSetPT","keyword":"portuguese","description":"\n  \n\n\n\n\t\n\t\t\n\t\tðŸ“š Dataset de Perguntas e Respostas por TÃ³pico\n\t\n\nEste repositÃ³rio contÃ©m um dataset com 100.000 amostras estruturadas para tarefas de Processamento de Linguagem Natural (PLN), com foco em perguntas temÃ¡ticas e respostas desenvolvidas.\n\n\t\n\t\t\n\t\tðŸ“ Estrutura dos Dados\n\t\n\nCada amostra Ã© representada em formato JSON com os seguintes campos:\n\nid (string): Identificador Ãºnico da amostra (UUID).\ntopic (lista de strings): Lista com os tÃ³picos abordados.\nprompts (lista de strings):â€¦ See the full description on the dataset page: https://huggingface.co/datasets/AxeML/LargerSetPT.","url":"https://huggingface.co/datasets/AxeML/LargerSetPT","creator_name":"AxÃ©ML - Community","creator_url":"https://huggingface.co/AxeML","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["question-answering","text-generation","Portuguese","mit","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"OGC_Cooking_Recipes","keyword":"portuguese","description":"\n\t\n\t\t\n\t\tOGC_Cooking_Recipes - Overview\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nOGC_Cooking_Recipes is a curated multimodal dataset focused on cooking recipe documents, culinary guides, and food preparation instructions. It combines text and image data extracted from real culinary PDFs to support tasks such as RAG DSE, question answering, document search, and vision-language model training.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\tDataset Creation\n\t\n\nThis dataset was created using our open-source toolâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/racineai/OGC_Cooking_Recipes.","url":"https://huggingface.co/datasets/racineai/OGC_Cooking_Recipes","creator_name":"racine.ai","creator_url":"https://huggingface.co/racineai","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["visual-document-retrieval","text-retrieval","English","French","Chinese"],"keywords_longer_than_N":true},
	{"name":"testeliminha","keyword":"portuguese","description":"\n\t\n\t\t\n\t\tDataset Card for Dataset Name\n\t\n\n\n\nThis dataset card aims to be a base template for new datasets. It has been generated using this raw template.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\n\n\n\n\n\nCurated by: [More Information Needed]\nFunded by [optional]: [More Information Needed]\nShared by [optional]: [More Information Needed]\nLanguage(s) (NLP): [More Information Needed]\nLicense: [More Information Needed]\n\n\n\t\n\t\t\n\t\tDataset Sources [optional]\n\t\n\n\n\n\nRepository: [Moreâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Ciscomuna/testeliminha.","url":"https://huggingface.co/datasets/Ciscomuna/testeliminha","creator_name":"JoÃ£o Gabriel da Silva dos Santos","creator_url":"https://huggingface.co/Ciscomuna","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["question-answering","Portuguese","apache-2.0","< 1K","csv"],"keywords_longer_than_N":true},
	{"name":"actuarial-global-glossary-multilingual","keyword":"portuguese","description":"\n  \n\n\n\n  \n\n\n\t\n\t\t\n\t\tðŸ¤ Connect with me on LinkedIn!\n\t\n\n  \n  Join the mission to make actuarial knowledge accessible worldwide\n  Let's discuss how AI can transform professional education and break language barriers in finance!\n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tðŸŒ Global Actuarial Glossary - Breaking Language Barriers in Finance\n\t\n\n\n\n\n\n\n\t\n\t\t\n\t\tðŸš€ The World's Most Comprehensive Multilingual Actuarial Dataset\n\t\n\nImagine: A brilliant actuarial student in Tokyo, a risk analyst in SÃ£o Paulo, and an insurance executiveâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/manuelcaccone/actuarial-global-glossary-multilingual.","url":"https://huggingface.co/datasets/manuelcaccone/actuarial-global-glossary-multilingual","creator_name":"Manuel Caccone","creator_url":"https://huggingface.co/manuelcaccone","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","translation","text-generation","question-answering","multi-class-classification"],"keywords_longer_than_N":true},
	{"name":"emouerj-sed","keyword":"portuguese","description":"\n\t\n\t\t\n\t\tDataset Card for \"emouerj-sed\"\n\t\n\nThis Dataset is adapted from emoUERJ for the Speech Emotion Diarization Task.\nThe dataset is created following the recipe for described in the (SPEECH EMOTION DIARIZATION: WHICH EMOTION APPEARS WHEN?)[https://arxiv.org/pdf/2306.12991] paper.\n","url":"https://huggingface.co/datasets/AdeoyeLadele/emouerj-sed","creator_name":"Adeoye Sunday Ladele","creator_url":"https://huggingface.co/AdeoyeLadele","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["audio-classification","Portuguese","apache-2.0","< 1K","parquet"],"keywords_longer_than_N":true},
	{"name":"questions_answers_geo_nord","keyword":"portuguese","description":"rhaymison/questions_answers_geo_nord dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/rhaymison/questions_answers_geo_nord","creator_name":"Rhaymison Cristian","creator_url":"https://huggingface.co/rhaymison","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","Portuguese","apache-2.0","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"AyaVisionBench","keyword":"portuguese","description":"\n\t\n\t\t\n\t\tDataset Card for Aya Vision Benchmark\n\t\n\n\n\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\nThe Aya Vision Benchmark is designed to evaluate vision-language models in real-world multilingual scenarios. It spans 23 languages and 9 distinct task categories, with 15 samples per category, resulting in 135 image-question pairs per language. \nEach question requires visual context for the answer and covers languages that half of the world's population speaks, making this dataset particularly suited forâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/CohereLabs/AyaVisionBench.","url":"https://huggingface.co/datasets/CohereLabs/AyaVisionBench","creator_name":"Cohere Labs","creator_url":"https://huggingface.co/CohereLabs","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["English","French","German","Spanish","Italian"],"keywords_longer_than_N":true},
	{"name":"include-base-44","keyword":"portuguese","description":"\n\t\n\t\t\n\t\tINCLUDE-base (44 languages)\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\n\n\nPaper: http://arxiv.org/abs/2411.19799\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nINCLUDE is a comprehensive knowledge- and reasoning-centric benchmark across 44 languages that evaluates multilingual LLMs for performance in the actual language environments where they would be deployed. \nIt contains 22,637 4-option multiple-choice-questions (MCQ) extracted from academic and professional exams, covering 57 topics, including regionalâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/CohereLabs/include-base-44.","url":"https://huggingface.co/datasets/CohereLabs/include-base-44","creator_name":"Cohere Labs","creator_url":"https://huggingface.co/CohereLabs","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["multiple-choice","Albanian","Arabic","Armenian","Azerbaijani"],"keywords_longer_than_N":true},
	{"name":"cvss","keyword":"portuguese","description":"CVSS is a massively multilingual-to-English speech-to-speech translation corpus,\ncovering sentence-level parallel speech-to-speech translation pairs from 21\nlanguages into English.","url":"https://huggingface.co/datasets/google/cvss","creator_name":"Google","creator_url":"https://huggingface.co/google","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":null,"first_N":5,"first_N_keywords":["English","Arabic","Catalan","Welsh","German"],"keywords_longer_than_N":true},
	{"name":"PortugueseLegalSentences-v0","keyword":"portuguese","description":"\n\t\n\t\t\n\t\tPortuguese Legal Sentences\n\t\n\nCollection of Legal Sentences from the Portuguese Supreme Court of Justice\nThe goal of this dataset was to be used for MLM and TSDAE\n\n\t\n\t\t\n\t\tContributions\n\t\n\n@rufimelo99\n","url":"https://huggingface.co/datasets/rufimelo/PortugueseLegalSentences-v0","creator_name":"Rui Melo","creator_url":"https://huggingface.co/rufimelo","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["no-annotation","found","monolingual","original","Portuguese"],"keywords_longer_than_N":true},
	{"name":"ptparl","keyword":"portuguese","description":"The PTPARL dataset is a dataset containing 5713 interventions in the Portuguese parliament.","url":"https://huggingface.co/datasets/luist18/ptparl","creator_name":"LuÃ­s Tavares","creator_url":"https://huggingface.co/luist18","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","multi-label-classification","expert-generated","found","monolingual"],"keywords_longer_than_N":true},
	{"name":"Pornhub","keyword":"portuguese","description":"\n\t\n\t\t\n\t\tPornhub Dataset\n\t\n\nThe Pornhub Dataset provides a comprehensive collection of data sourced from pornhub.com, encompassing various details from MANYYY videos available on the platform.\nThe file consists of 742.133 lines of videos.\n\n\t\n\t\t\n\t\tData Description\n\t\n\n\nDelimiter: â€½\nFile Format: CSV\nContent:\nURL: The URL of the video.\nCategory: The genre or category of the video.\nUser: The username of the uploader.\nVideo_title: The title of the video.\nViews: The number of views the video hasâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Nikity/Pornhub.","url":"https://huggingface.co/datasets/Nikity/Pornhub","creator_name":"Nikita","creator_url":"https://huggingface.co/Nikity","license_name":"Open Data Commons Attribution License v1.0","license_url":"https://scancode-licensedb.aboutcode.org/odc-by-1.0.html","language":"en","first_N":5,"first_N_keywords":["Albanian","Arabic","Bengali","Bulgarian","Chinese"],"keywords_longer_than_N":true},
	{"name":"xtreme","keyword":"portuguese","description":"\n\t\n\t\t\n\t\tDataset Card for \"xtreme\"\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThe Cross-lingual Natural Language Inference (XNLI) corpus is a crowd-sourced collection of 5,000 test and\n2,500 dev pairs for the MultiNLI corpus. The pairs are annotated with textual entailment and translated into\n14 languages: French, Spanish, German, Greek, Bulgarian, Russian, Turkish, Arabic, Vietnamese, Thai, Chinese,\nHindi, Swahili and Urdu. This results in 112.5k annotated pairs. Each premise can be associated with theâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/google/xtreme.","url":"https://huggingface.co/datasets/google/xtreme","creator_name":"Google","creator_url":"https://huggingface.co/google","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["multiple-choice","question-answering","token-classification","text-classification","text-retrieval"],"keywords_longer_than_N":true},
	{"name":"gutenberg_multilang","keyword":"portuguese","description":"\n\t\n\t\t\n\t\tDataset Card for Project Gutenber - Multilanguage eBooks\n\t\n\nA collection of non-english language eBooks (7907, about 75-80% of all the ES, DE, FR, NL, IT, PT, HU books available on the site) from the Project Gutenberg site with metadata removed. \nOriginally colected for https://github.com/LAION-AI/Open-Assistant\n\n\t\n\t\t\nLANG\nEBOOKS\n\n\n\t\t\nES\n717\n\n\nDE\n1735\n\n\nFR\n2863\n\n\nNL\n904\n\n\nIT\n692\n\n\nPT\n501\n\n\nHU\n495\n\n\n\t\n\nThe METADATA column contains catalogue meta information on each book as a serializedâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/sedthh/gutenberg_multilang.","url":"https://huggingface.co/datasets/sedthh/gutenberg_multilang","creator_name":"Richard Nagyfi","creator_url":"https://huggingface.co/sedthh","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-generation","Spanish","German","French","Dutch"],"keywords_longer_than_N":true},
	{"name":"para_pat","keyword":"portuguese","description":"ParaPat: The Multi-Million Sentences Parallel Corpus of Patents Abstracts\n\nThis dataset contains the developed parallel corpus from the open access Google\nPatents dataset in 74 language pairs, comprising more than 68 million sentences\nand 800 million tokens. Sentences were automatically aligned using the Hunalign algorithm\nfor the largest 22 language pairs, while the others were abstract (i.e. paragraph) aligned.","url":"https://huggingface.co/datasets/ParaPat/para_pat","creator_name":"ParaPat","creator_url":"https://huggingface.co/ParaPat","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":null,"first_N":5,"first_N_keywords":["text-generation","fill-mask","translation","language-modeling","masked-language-modeling"],"keywords_longer_than_N":true},
	{"name":"tatoeba_mt","keyword":"portuguese","description":"The Tatoeba Translation Challenge is a multilingual data set of\nmachine translation benchmarks derived from user-contributed\ntranslations collected by [Tatoeba.org](https://tatoeba.org/) and\nprovided as parallel corpus from [OPUS](https://opus.nlpl.eu/). This\ndataset includes test and development data sorted by language pair. It\nincludes test sets for hundreds of language pairs and is continuously\nupdated. Please, check the version number tag to refer to the release\nthat your are using.","url":"https://huggingface.co/datasets/Helsinki-NLP/tatoeba_mt","creator_name":"Language Technology Research Group at the University of Helsinki","creator_url":"https://huggingface.co/Helsinki-NLP","license_name":"Creative Commons Attribution 2.0","license_url":"https://scancode-licensedb.aboutcode.org/cc-by-2.0.html","language":null,"first_N":5,"first_N_keywords":["text-generation","translation","no-annotation","crowdsourced","translation"],"keywords_longer_than_N":true},
	{"name":"common_voice_16_0","keyword":"portuguese","description":"\n\t\n\t\t\n\t\tDataset Card for Common Voice Corpus 16.0\n\t\n\n\n\nThis dataset is an unofficial version of the Mozilla Common Voice Corpus 16. It was downloaded and converted from the project's website https://commonvoice.mozilla.org/.\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nAbkhaz, Albanian, Amharic, Arabic, Armenian, Assamese, Asturian, Azerbaijani, Basaa, Bashkir, Basque, Belarusian, Bengali, Breton, Bulgarian, Cantonese, Catalan, Central Kurdish, Chinese (China), Chinese (Hong Kong), Chinese (Taiwan), Chuvash, Czechâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fsicoli/common_voice_16_0.","url":"https://huggingface.co/datasets/fsicoli/common_voice_16_0","creator_name":"Fabio Sicoli","creator_url":"https://huggingface.co/fsicoli","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":null,"first_N":5,"first_N_keywords":["automatic-speech-recognition","Abkhaz","Afrikaans","Amharic","Arabic"],"keywords_longer_than_N":true},
	{"name":"text-template-to-summarize","keyword":"portuguese","description":"Anderson-Andre-P/text-template-to-summarize dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/Anderson-Andre-P/text-template-to-summarize","creator_name":"Anderson AndrÃ© Pereira EleutÃ©rio","creator_url":"https://huggingface.co/Anderson-Andre-P","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["summarization","Portuguese","mit","< 1K","csv"],"keywords_longer_than_N":true},
	{"name":"stopwords-pt","keyword":"portuguese","description":"\n\t\n\t\t\n\t\tStopwords PT (Teeny-Tiny Castle)\n\t\n\nThis dataset is part of a tutorial tied to the Teeny-Tiny Castle, an open-source repository containingÂ educational tools for AI Ethics and Safety research. \n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nfrom datasets import load_dataset\n\ndataset = load_dataset(\"AiresPucrs/stopwords-pt\", split = 'train')\n\n","url":"https://huggingface.co/datasets/AiresPucrs/stopwords-pt","creator_name":"AI Robotics Ethics Society (PUCRS)","creator_url":"https://huggingface.co/AiresPucrs","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","Portuguese","apache-2.0","< 1K","parquet"],"keywords_longer_than_N":true},
	{"name":"TuPy-Dataset","keyword":"portuguese","description":"\n\t\n\t\t\n\t\tPortuguese Hate Speech Dataset (TuPy)\n\t\n\nThe Portuguese hate speech dataset (TuPy) is an annotated corpus designed to facilitate the development of advanced hate speech detection models using machine learning (ML) \nand natural language processing (NLP) techniques. TuPy is comprised of 10,000 (ten thousand) unpublished, annotated, and anonymized documents collected \non Twitter (currently known as X) in 2023. \nThis repository is organized as follows:\nroot.\n    â”œâ”€â”€ binary     : binaryâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Silly-Machine/TuPy-Dataset.","url":"https://huggingface.co/datasets/Silly-Machine/TuPy-Dataset","creator_name":"Silly-Machine","creator_url":"https://huggingface.co/Silly-Machine","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","crowdsourced","Brazilian-Portuguese","monolingual","original"],"keywords_longer_than_N":true},
	{"name":"openassistant-deepseek-coder","keyword":"portuguese","description":"\n\t\n\t\t\n\t\tChat Fine-tuning Dataset - OpenAssistant DeepSeek Coder\n\t\n\nThis dataset allows for fine-tuning chat models using:\nB_INST = '\\n### Instruction:\\n'\nE_INST = '\\n### Response:\\n'\nBOS = '<ï½œbeginâ–ofâ–sentenceï½œ>'\nEOS = '\\n<|EOT|>\\n'\n\nSample Preparation:\n\nThe dataset is cloned from TimDettmers, which itself is a subset of the Open Assistant dataset, which you can find here. This subset of the data only contains the highest-rated paths in the conversation tree, with a total of 9,846 samples.\nTheâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Trelis/openassistant-deepseek-coder.","url":"https://huggingface.co/datasets/Trelis/openassistant-deepseek-coder","creator_name":"Trelis","creator_url":"https://huggingface.co/Trelis","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["English","Spanish","Russian","German","Polish"],"keywords_longer_than_N":true},
	{"name":"elementor-layout-vlm-dataset","keyword":"portuguese","description":"\n\t\n\t\t\n\t\tElementor Layout VLM Dataset\n\t\n\n\n\t\n\t\t\n\t\tðŸ“Š Dataset Summary\n\t\n\nDataset para fine-tuning de modelos Vision-Language (VLM) para geraÃ§Ã£o de layouts Elementor a partir de imagens.\n\nTask: Visual Question Answering (VQA)\nFormat: VLM VQA (image, question, answer)\nTotal: 30 exemplos\nTraining: 24 exemplos\nValidation: 6 exemplos\n\n\n\t\n\t\t\n\t\tðŸŽ¯ Uso Recomendado\n\t\n\n\n\t\n\t\t\n\t\tAutoTrain Configuration\n\t\n\nTask: VLM VQA\nBase Model: google/paligemma-3b-pt-448\nDataset: vinicios94/elementor-layout-vlm-datasetâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/vinicios94/elementor-layout-vlm-dataset.","url":"https://huggingface.co/datasets/vinicios94/elementor-layout-vlm-dataset","creator_name":"Vinicios Rabaioli","creator_url":"https://huggingface.co/vinicios94","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["visual-question-answering","image-to-text","English","Portuguese","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"xtreme_s","keyword":"portuguese","description":"XTREME-S covers four task families: speech recognition, classification, speech-to-text translation and retrieval. Covering 102\nlanguages from 10+ language families, 3 different domains and 4\ntask families, XTREME-S aims to simplify multilingual speech\nrepresentation evaluation, as well as catalyze research in â€œuniversalâ€ speech representation learning.","url":"https://huggingface.co/datasets/google/xtreme_s","creator_name":"Google","creator_url":"https://huggingface.co/google","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":null,"first_N":5,"first_N_keywords":["automatic-speech-recognition","expert-generated","crowdsourced","machine-generated","crowdsourced"],"keywords_longer_than_N":true},
	{"name":"calame-pt","keyword":"portuguese","description":"\n\t\n\t\t\n\t\tCALAME-PT\n\t\n\n\n\t\n\t\t\n\t\tContext-Aware LAnguage Modeling Evaluation for Portuguese\n\t\n\nCALAME-PT is a PT benchmark composed of small texts (contexts) and their respective last words. \nThese contexts should, in theory, contain enough information so that a human or a model is capable of guessing its last word - without being too specific and/or too ambiguous.\n\n\t\n\t\t\n\t\tComposition\n\t\n\nCALAME-PT is composed of 2 \"sets\" of data - handwritten and generated. \n\nHandwritten Set: contains 406â€¦ See the full description on the dataset page: https://huggingface.co/datasets/NOVA-vision-language/calame-pt.","url":"https://huggingface.co/datasets/NOVA-vision-language/calame-pt","creator_name":"NOVA Vision & Language","creator_url":"https://huggingface.co/NOVA-vision-language","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["Portuguese","mit","1K - 10K","json","Text"],"keywords_longer_than_N":true},
	{"name":"calame-pt","keyword":"portuguese","description":"\n\t\n\t\t\n\t\tCALAME-PT\n\t\n\n\n\t\n\t\t\n\t\tContext-Aware LAnguage Modeling Evaluation for Portuguese\n\t\n\nCALAME-PT is a PT benchmark composed of small texts (contexts) and their respective last words. \nThese contexts should, in theory, contain enough information so that a human or a model is capable of guessing its last word - without being too specific and/or too ambiguous.\n\n\t\n\t\t\n\t\tComposition\n\t\n\nCALAME-PT is composed of 2 \"sets\" of data - handwritten and generated. \n\nHandwritten Set: contains 406â€¦ See the full description on the dataset page: https://huggingface.co/datasets/NOVA-vision-language/calame-pt.","url":"https://huggingface.co/datasets/NOVA-vision-language/calame-pt","creator_name":"NOVA Vision & Language","creator_url":"https://huggingface.co/NOVA-vision-language","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["Portuguese","mit","1K - 10K","json","Text"],"keywords_longer_than_N":true},
	{"name":"fakerecogna2-abstrativa","keyword":"portuguese","description":"\n\t\n\t\t\n\t\tFakeRecogna 2.0 - Abstractive\n\t\n\nFakeRecogna 2.0 presents the extension for the FakeRecogna dataset in the context of fake news detection. FakeRecogna includes real and fake news texts collected from online media and ten fact-checking sources in Brazil. An important aspect is the lack of relation between the real and fake news samples, i.e., they are not mutually related to each other to avoid intrinsic bias in the data.\n\n\t\n\t\t\n\t\tThe Dataset\n\t\n\nThe fake news collection was performed onâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/recogna-nlp/fakerecogna2-abstrativa.","url":"https://huggingface.co/datasets/recogna-nlp/fakerecogna2-abstrativa","creator_name":"Recogna NLP","creator_url":"https://huggingface.co/recogna-nlp","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","Portuguese","mit","10K - 100K","csv"],"keywords_longer_than_N":true},
	{"name":"fakerecogna2-abstrativa","keyword":"portuguese","description":"\n\t\n\t\t\n\t\tFakeRecogna 2.0 - Abstractive\n\t\n\nFakeRecogna 2.0 presents the extension for the FakeRecogna dataset in the context of fake news detection. FakeRecogna includes real and fake news texts collected from online media and ten fact-checking sources in Brazil. An important aspect is the lack of relation between the real and fake news samples, i.e., they are not mutually related to each other to avoid intrinsic bias in the data.\n\n\t\n\t\t\n\t\tThe Dataset\n\t\n\nThe fake news collection was performed onâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/recogna-nlp/fakerecogna2-abstrativa.","url":"https://huggingface.co/datasets/recogna-nlp/fakerecogna2-abstrativa","creator_name":"Recogna NLP","creator_url":"https://huggingface.co/recogna-nlp","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","Portuguese","mit","10K - 100K","csv"],"keywords_longer_than_N":true},
	{"name":"CC-MAIN-2023-23","keyword":"portuguese","description":"\n\t\n\t\t\n\t\tDataset Card for \"CC-MAIN-2023-23\"\n\t\n\nMore Information needed\n","url":"https://huggingface.co/datasets/dominguesm/CC-MAIN-2023-23","creator_name":"Maicon Domingues","creator_url":"https://huggingface.co/dominguesm","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","fill-mask","Portuguese","cc-by-4.0","10M - 100M"],"keywords_longer_than_N":true},
	{"name":"super_eurlex","keyword":"portuguese","description":"Super-EURLEX dataset containing legal documents from multiple languages.\n                The datasets are build/scrapped from the EURLEX Website [https://eur-lex.europa.eu/homepage.html]\n                With one split per language and sector, because the available features (metadata) differs for each \n                sector. Therefore, each sample contains the content of a full legal document in up to 3 different \n                formats. Those are raw HTML and cleaned HTML (if the HTML format was available on the EURLEX website \n                during the scrapping process) and cleaned text.\n                The cleaned text should be available for each sample and was extracted from HTML or PDF.\n                'Cleaned' HTML stands here for minor cleaning that was done to preserve to a large extent the necessary \n                HTML information like table structures while removing unnecessary complexity which was introduced to the \n                original documents due to actions like writing each sentence into a new object. \n                Additionally, each sample contains metadata which was scrapped on the fly, this implies the following \n                2 things. First, not every sector contains the same metadata. Second, most metadata might be \n                irrelevant for most use cases. \n                In our minds the most interesting metadata is the celex-id which is used to identify the legal \n                document at hand, but also contains a lot of information about the document \n                see [https://eur-lex.europa.eu/content/tools/eur-lex-celex-infographic-A3.pdf] as well as eurovoc-\n                concepts, which are labels that define the content of the documents. \n                Eurovoc-Concepts are, for example, only available for the sectors 1, 2, 3, 4, 5, 6, 9, C, and E.\n                The Naming of most metadata is kept like it was on the eurlex website, except for converting \n                it to lower case and replacing whitespaces with '_'.","url":"https://huggingface.co/datasets/ddrg/super_eurlex","creator_name":"Dresden Database Research Group","creator_url":"https://huggingface.co/ddrg","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":null,"first_N":5,"first_N_keywords":["text-classification","fill-mask","multi-class-classification","multi-label-classification","found"],"keywords_longer_than_N":true},
	{"name":"oscar-small","keyword":"portuguese","description":"The Open Super-large Crawled ALMAnaCH coRpus is a huge multilingual corpus obtained by language classification and filtering of the Common Crawl corpus using the goclassy architecture.\\","url":"https://huggingface.co/datasets/djstrong/oscar-small","creator_name":"Krzysztof WrÃ³bel","creator_url":"https://huggingface.co/djstrong","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","language-modeling","no-annotation","found","multilingual"],"keywords_longer_than_N":true},
	{"name":"oscar-small","keyword":"portuguese","description":"The Open Super-large Crawled ALMAnaCH coRpus is a huge multilingual corpus obtained by language classification and filtering of the Common Crawl corpus using the goclassy architecture.\\","url":"https://huggingface.co/datasets/nthngdy/oscar-small","creator_name":"Nathan Godey","creator_url":"https://huggingface.co/nthngdy","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","language-modeling","no-annotation","found","multilingual"],"keywords_longer_than_N":true},
	{"name":"multilingual-pl-bert","keyword":"portuguese","description":"Attribution: Wikipedia.org\n","url":"https://huggingface.co/datasets/styletts2-community/multilingual-pl-bert","creator_name":"StyleTTS 2 Community","creator_url":"https://huggingface.co/styletts2-community","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["Afrikaans","Aragonese","Arabic","Azerbaijani","Bashkir"],"keywords_longer_than_N":true},
	{"name":"brwac_tiny","keyword":"portuguese","description":"\n\t\n\t\t\n\t\tDataset Card for BrWac\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThe BrWaC (Brazilian Portuguese Web as Corpus) is a large corpus constructed following the Wacky framework, \nwhich was made public for research purposes. The current corpus version, released in January 2017, is composed by \n3.53 million documents, 2.68 billion tokens and 5.79 million types. Please note that this resource is available \nsolely for academic research purposes, and you agreed not to use it for any commercial applications.â€¦ See the full description on the dataset page: https://huggingface.co/datasets/thegoodfellas/brwac_tiny.","url":"https://huggingface.co/datasets/thegoodfellas/brwac_tiny","creator_name":"The Good Fellas","creator_url":"https://huggingface.co/thegoodfellas","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["fill-mask","masked-language-modeling","no-annotation","found","monolingual"],"keywords_longer_than_N":true},
	{"name":"mapa","keyword":"portuguese","description":"\n\t\n\t\t\n\t\tDataset Card for Multilingual European Datasets for Sensitive Entity Detection in the Legal Domain\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThe dataset consists of 12 documents (9 for Spanish due to parsing errors) taken from EUR-Lex, a multilingual corpus of court\ndecisions and legal dispositions in the 24 official languages of the European Union. The documents have been annotated\nfor named entities following the guidelines of the MAPA project which foresees two\nannotation level, a general and aâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/joelniklaus/mapa.","url":"https://huggingface.co/datasets/joelniklaus/mapa","creator_name":"Joel Niklaus","creator_url":"https://huggingface.co/joelniklaus","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["token-classification","named-entity-recognition","other","found","multilingual"],"keywords_longer_than_N":true},
	{"name":"tatoeba-mt-qna-oa","keyword":"portuguese","description":"\n\t\n\t\t\n\t\tDataset Card for multilingual tatoeba QnA translation with ~120K entries.\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nContains Parquet of a list of instructions and translation articles on different languages.\nEach row consists of\n\nINSTRUCTION\nRESPONSE\nSOURCE (tatoeba)\nMETADATA (json with language, text length, uuid, langs-pair).\n\n\n\t\n\t\t\n\t\tOriginal Dataset is avalible here:\n\t\n\n\nhttps://huggingface.co/datasets/Helsinki-NLP/tatoeba_mt\n\n","url":"https://huggingface.co/datasets/0x22almostEvil/tatoeba-mt-qna-oa","creator_name":"David Glushkov","creator_url":"https://huggingface.co/0x22almostEvil","license_name":"Creative Commons Attribution 2.0","license_url":"https://scancode-licensedb.aboutcode.org/cc-by-2.0.html","language":"en","first_N":5,"first_N_keywords":["question-answering","translation","English","Russian","German"],"keywords_longer_than_N":true},
	{"name":"FactChecksbr","keyword":"portuguese","description":"Collection of Portuguese Fact-Checking Benchmarks.","url":"https://huggingface.co/datasets/fake-news-UFG/FactChecksbr","creator_name":"fake-news-UFG","creator_url":"https://huggingface.co/fake-news-UFG","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":null,"first_N":5,"first_N_keywords":["text-classification","Portuguese","mit","10K<n<100K","doi:10.57967/hf/1016"],"keywords_longer_than_N":true},
	{"name":"cnn_news_ptbr","keyword":"portuguese","description":"\n\t\n\t\t\n\t\tDataset Card for \"cnn_news_ptbr\"\n\t\n\nMore Information needed\n","url":"https://huggingface.co/datasets/celsowm/cnn_news_ptbr","creator_name":"Celso F","creator_url":"https://huggingface.co/celsowm","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","Portuguese","apache-2.0","1K - 10K","parquet"],"keywords_longer_than_N":true},
	{"name":"fapesp-v2","keyword":"portuguese","description":"vgaraujov/fapesp-v2 dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/vgaraujov/fapesp-v2","creator_name":"Vladimir Araujo","creator_url":"https://huggingface.co/vgaraujov","license_name":"Creative Commons Attribution 2.0","license_url":"https://scancode-licensedb.aboutcode.org/cc-by-2.0.html","language":null,"first_N":5,"first_N_keywords":["translation","translation","English","Spanish","Portuguese"],"keywords_longer_than_N":true},
	{"name":"fapesp","keyword":"portuguese","description":"vgaraujov/fapesp dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/vgaraujov/fapesp","creator_name":"Vladimir Araujo","creator_url":"https://huggingface.co/vgaraujov","license_name":"Creative Commons Attribution 2.0","license_url":"https://scancode-licensedb.aboutcode.org/cc-by-2.0.html","language":"en","first_N":5,"first_N_keywords":["translation","English","Spanish","Portuguese","cc-by-2.0"],"keywords_longer_than_N":true},
	{"name":"docfullstructure_dataset","keyword":"portuguese","description":"kopan/docfullstructure_dataset dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/kopan/docfullstructure_dataset","creator_name":"Ilia Kopanichuk","creator_url":"https://huggingface.co/kopan","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":null,"first_N":5,"first_N_keywords":["text-classification","Russian","English","Kazakh","Bulgarian"],"keywords_longer_than_N":true},
	{"name":"ysh-solar-products-brazil","keyword":"portuguese","description":"\n\t\n\t\t\n\t\tYSH Solar Products - Brazil Market Dataset\n\t\n\nComprehensive dataset of solar energy products from major Brazilian distributors.\nLast Updated: 2025-10-20\n\n\t\n\t\t\n\t\tðŸ“Š Dataset Overview\n\t\n\nThis dataset contains 3,337 solar products from 5 major Brazilian distributors:\n\nFortlev Solar\nFotus\nNeoSolar  \nSolfacil\nOdex\n\n\n\t\n\t\t\n\t\tðŸ“¦ Dataset Structure\n\t\n\n\n\t\n\t\t\n\t\t1. Main Files\n\t\n\n\ndata/unified_products.json - Complete consolidated product database (2,914 products)\n\n\n\t\n\t\t\n\t\t2. CSV by Originalâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fernando-bold/ysh-solar-products-brazil.","url":"https://huggingface.co/datasets/fernando-bold/ysh-solar-products-brazil","creator_name":"Fernando Bold","creator_url":"https://huggingface.co/fernando-bold","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":null,"first_N":5,"first_N_keywords":["tabular-classification","tabular-regression","Portuguese","English","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"handmade-dataset","keyword":"portuguese","description":"Dataset with sentences regarding professions, half of the translations are to feminine and half for masculine sentences.\nHow to use it: \nfrom datasets import load_dataset\nremote_dataset = load_dataset(\"VanessaSchenkel/handmade-dataset\", field=\"data\")\nremote_dataset\n\nOutput:\nDatasetDict({\n    train: Dataset({\n        features: ['id', 'translation'],\n        num_rows: 388\n    })\n})\n\nExemple: \nremote_dataset[\"train\"][5]\n\nOutput:\n{'id': '5',\n 'translation': {'english': 'the postman finished herâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/VanessaSchenkel/handmade-dataset.","url":"https://huggingface.co/datasets/VanessaSchenkel/handmade-dataset","creator_name":"Vanessa Schramm Schenkel Da Silva","creator_url":"https://huggingface.co/VanessaSchenkel","license_name":"Academic Free License v3.0","license_url":"https://choosealicense.com/licenses/afl-3.0/","language":"en","first_N":5,"first_N_keywords":["translation","found","found","translation","original"],"keywords_longer_than_N":true},
	{"name":"pira","keyword":"portuguese","description":"\n\t\n\t\t\n\t\tPirÃ¡: A Bilingual Portuguese-English Dataset for Question-Answering about the Ocean, the Brazilian coast, and climate change\n\t\n\nPirÃ¡ is a crowdsourced reading comprehension dataset on the ocean, the Brazilian coast, and climate change. \nQA sets are presented in both Portuguese and English, together with their corresponding textual context.\nThe dataset also contains human and automatic paraphrases for questions and answers, as well as a number of qualitative assessments. \nThe originalâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/paulopirozelli/pira.","url":"https://huggingface.co/datasets/paulopirozelli/pira","creator_name":"Paulo Pirozelli","creator_url":"https://huggingface.co/paulopirozelli","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["question-answering","Portuguese","English","cc-by-4.0","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"BioInstructQA","keyword":"portuguese","description":"Large Language Models (LLMs) have demonstrated remarkable versatility \nin recent years, offering potential applications across specialized \ndomains such as healthcare and medicine. Despite the availability of \nvarious open-source LLMs tailored for health contexts, adapting \ngeneral-purpose LLMs to the medical domain presents significant\nchallenges. In this paper, we introduce BioMistral, an open-source\nLLM tailored for the biomedical domain, utilizing Mistral as its \nfoundation model and further pre-trained on PubMed Central. We conduct \na comprehensive evaluation of BioMistral on a benchmark comprising 10 \nestablished medical question-answering (QA) tasks in English. We also \nexplore lightweight models obtained through quantization and model \nmerging approaches. Our results demonstrate BioMistral's superior \nperformance compared to existing open-source medical models and its \ncompetitive edge against proprietary counterparts. Finally, to address \nthe limited availability of data beyond English and to assess the multilingual \ngeneralization of medical LLMs, we automatically translated and evaluated this\nbenchmark into 7 other languages. This marks the first large-scale\nmultilingual evaluation of LLMs in the medical domain. Datasets, \nmultilingual evaluation benchmarks, scripts, and all the models obtained \nduring our experiments are freely released.","url":"https://huggingface.co/datasets/BioMistral/BioInstructQA","creator_name":"BioMistral","creator_url":"https://huggingface.co/BioMistral","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":null,"first_N":5,"first_N_keywords":["question-answering","French","English","German","Spanish"],"keywords_longer_than_N":true},
	{"name":"openassistant-guanaco-EOS","keyword":"portuguese","description":"\n\t\n\t\t\n\t\tChat Fine-tuning Dataset - Guanaco Style\n\t\n\nThis dataset allows for fine-tuning chat models using \"### Human:\" AND \"### Assistant\" as the beginning and end of sequence tokens.\nPreparation:\n\nThe dataset is cloned from TimDettmers, which itself is a subset of the Open Assistant dataset, which you can find here. This subset of the data only contains the highest-rated paths in the conversation tree, with a total of 9,846 samples.\nThe dataset was then slightly adjusted to:\n\n\nif a row ofâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Trelis/openassistant-guanaco-EOS.","url":"https://huggingface.co/datasets/Trelis/openassistant-guanaco-EOS","creator_name":"Trelis","creator_url":"https://huggingface.co/Trelis","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["English","Spanish","Russian","German","Polish"],"keywords_longer_than_N":true},
	{"name":"qa-pt","keyword":"portuguese","description":"\n\t\n\t\t\n\t\tDataset Card for QA-Portuguese\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nPortuguese preprocessed split from MQA dataset.\n\n\t\n\t\t\n\t\tSupported Tasks and Leaderboards\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nThe dataset is Portuguese.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\n\t\n\t\t\n\t\tData Instances\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tData Fields\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tData Splits\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tDataset Creation\n\t\n\n\n\t\n\t\t\n\t\tCuration Rationale\n\t\n\n[More Information Needed]â€¦ See the full description on the dataset page: https://huggingface.co/datasets/ju-resplande/qa-pt.","url":"https://huggingface.co/datasets/ju-resplande/qa-pt","creator_name":"Juliana Resplande","creator_url":"https://huggingface.co/ju-resplande","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["question-answering","multiple-choice-qa","no-annotation","other","monolingual"],"keywords_longer_than_N":true},
	{"name":"go_emotions_ptbr","keyword":"portuguese","description":"\n\t\n\t\t\n\t\tDataset Card for GoEmotions\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThe GoEmotions dataset contains 58k carefully curated Reddit comments labeled for 27 emotion categories or Neutral.\nThe raw data is included as well as the smaller, simplified version of the dataset with predefined train/val/test\nsplits.\n\n\t\n\t\t\n\t\tSupported Tasks and Leaderboards\n\t\n\nThis dataset is intended for multi-class, multi-label emotion classification.\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nThe data is in English and Brazilian Portugueseâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/antoniomenezes/go_emotions_ptbr.","url":"https://huggingface.co/datasets/antoniomenezes/go_emotions_ptbr","creator_name":"Antonio Marcio Adiodato de Menezes","creator_url":"https://huggingface.co/antoniomenezes","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":null,"first_N":5,"first_N_keywords":["text-classification","multi-class-classification","multi-label-classification","crowdsourced","found"],"keywords_longer_than_N":true},
	{"name":"Wikinews-multilingual","keyword":"portuguese","description":"\n\t\n\t\t\n\t\tWikinews - weakly aligned multilingual pararell sentence datasets\n\t\n\nThis dataset contains 15,200 multilingual WikiNews articles in 33 languages.\nOut of 15,200 articles, 9,960 are non-English news and 5240 are English news.  All non-English news are linked to one of 5240 English news. Linked articles show the same event.\nList of non-English languages are: Spanish, French, German, Portuguese, Polish, Italian, Chinese, Russian, Japanese, Dutch, Swedish, Tamil, Serbian, Czech, Catalanâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Fumika/Wikinews-multilingual.","url":"https://huggingface.co/datasets/Fumika/Wikinews-multilingual","creator_name":"Fumika Isono","creator_url":"https://huggingface.co/Fumika","license_name":"Creative Commons Attribution 2.5","license_url":"https://scancode-licensedb.aboutcode.org/cc-by-2.5.html","language":"en","first_N":5,"first_N_keywords":["text-classification","feature-extraction","English","Spanish","French"],"keywords_longer_than_N":true},
	{"name":"Brazilian_Item_Price_and_Description_Dataset","keyword":"portuguese","description":"\n\t\n\t\t\n\t\tBrazilian Item Price and Description Dataset\n\t\n\nThis dataset contains high-resolution images and structured text data of product price tags and item descriptions collected from Brazilian retail stores and e-commerce platforms. It enables AI research in OCR, product recognition, and retail analytics for the Portuguese-speaking market.\n\n\t\n\t\t\n\t\tContact\n\t\n\nFor queries or collaborations related to this dataset, contact:  \n\nanoushka@kgen.io  \nabhishek.vadapalli@kgen.io\n\n\n\t\n\t\t\n\t\tSupportedâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Kratos-AI/Brazilian_Item_Price_and_Description_Dataset.","url":"https://huggingface.co/datasets/Kratos-AI/Brazilian_Item_Price_and_Description_Dataset","creator_name":"KratosAI","creator_url":"https://huggingface.co/Kratos-AI","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["image-classification","Portuguese","cc-by-4.0","< 1K","imagefolder"],"keywords_longer_than_N":true},
	{"name":"PortugueseLegalSentences-v1","keyword":"portuguese","description":"\n\t\n\t\t\n\t\tPortuguese Legal Sentences\n\t\n\nCollection of Legal Sentences from the Portuguese Supreme Court of Justice\nThe goal of this dataset was to be used for MLM and TSDAE\n\n\t\n\t\t\n\t\tContributions\n\t\n\n@rufimelo99\n","url":"https://huggingface.co/datasets/rufimelo/PortugueseLegalSentences-v1","creator_name":"Rui Melo","creator_url":"https://huggingface.co/rufimelo","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["no-annotation","found","monolingual","original","Portuguese"],"keywords_longer_than_N":true},
	{"name":"multiconer_v2","keyword":"portuguese","description":"Complex named entities (NE), like the titles of creative works, are not simple nouns and pose challenges for NER systems (Ashwini and Choi, 2014). They can take the form of any linguistic constituent, like an imperative clause (â€œDial M for Murderâ€), and do not look like traditional NEs (Persons, Locations, etc.). This syntactic ambiguity makes it challenging to recognize them based on context. We organized the MultiCoNER task (Malmasi et al., 2022) at SemEval-2022 to address these challenges in 11 languages, receiving a very positive community response with 34 system papers. Results confirmed the challenges of processing complex and long-tail NEs: even the largest pre-trained Transformers did not achieve top performance without external knowledge. The top systems infused transformers with knowledge bases and gazetteers. However, such solutions are brittle against out of knowledge-base entities and noisy scenarios like the presence of spelling mistakes and typos. We propose MultiCoNER II which represents novel challenges through new tasks that emphasize the shortcomings of the current top models.\n\nMultiCoNER II features complex NER in these languages:\n\n1. English\n2. Spanish\n3. Hindi\n4. Bangla\n5. Chinese\n6. Swedish\n7. Farsi\n8. French\n9. Italian\n10. Portugese\n11. Ukranian\n12. German\n\nFor more details see https://multiconer.github.io/\n\n## References\n* Sandeep Ashwini and Jinho D. Choi. 2014. Targetable named entity recognition in social media. CoRR, abs/1408.0782.\n* Shervin Malmasi, Anjie Fang, Besnik Fetahu, Sudipta Kar, Oleg Rokhlenko. 2022. SemEval-2022 Task 11: Multilingual Complex Named Entity Recognition (MultiCoNER).","url":"https://huggingface.co/datasets/MultiCoNER/multiconer_v2","creator_name":"MultiCoNER","creator_url":"https://huggingface.co/MultiCoNER","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["token-classification","Bengali","Chinese","German","English"],"keywords_longer_than_N":true},
	{"name":"mc4-sampling","keyword":"portuguese","description":"A sampling-enabled version of mC4, the colossal, cleaned version of Common Crawl's web crawl corpus.\n\nBased on Common Crawl dataset: \"https://commoncrawl.org\".\n\nThis is a version of the processed version of Google's mC4 dataset by AllenAI, in which sampling methods are implemented to perform on the fly.","url":"https://huggingface.co/datasets/bertin-project/mc4-sampling","creator_name":"BERTIN Project","creator_url":"https://huggingface.co/bertin-project","license_name":"Open Data Commons Attribution License v1.0","license_url":"https://scancode-licensedb.aboutcode.org/odc-by-1.0.html","language":null,"first_N":5,"first_N_keywords":["text-generation","fill-mask","language-modeling","no-annotation","found"],"keywords_longer_than_N":true},
	{"name":"xlel_wd","keyword":"portuguese","description":"XLEL-WD is a multilingual event linking dataset. This dataset contains mention references from multilingual Wikipedia/Wikinews articles to event items in Wikidata. The text descriptions for Wikidata events are compiled from Wikipedia articles.","url":"https://huggingface.co/datasets/adithya7/xlel_wd","creator_name":"Adithya Pratapa","creator_url":"https://huggingface.co/adithya7","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["found","found","multilingual","original","Afrikaans"],"keywords_longer_than_N":true},
	{"name":"opus_paracrawl","keyword":"portuguese","description":"\n\t\n\t\t\n\t\tDataset Card for OpusParaCrawl\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nParallel corpora from Web Crawls collected in the ParaCrawl project.\nTha dataset contains:\n\n42 languages, 43 bitexts\ntotal number of files: 59,996\ntotal number of tokens: 56.11G\ntotal number of sentence fragments: 3.13G\n\nTo load a language pair which isn't part of the config, all you need to do is specify the language code as pairs,\ne.g.\ndataset = load_dataset(\"opus_paracrawl\", lang1=\"en\", lang2=\"so\")\n\nYou can find the validâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Helsinki-NLP/opus_paracrawl.","url":"https://huggingface.co/datasets/Helsinki-NLP/opus_paracrawl","creator_name":"Language Technology Research Group at the University of Helsinki","creator_url":"https://huggingface.co/Helsinki-NLP","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["translation","found","found","multilingual","original"],"keywords_longer_than_N":true},
	{"name":"panlex","keyword":"portuguese","description":"\n\t\n\t\t\n\t\tPanLex\n\t\n\nJanuary 1, 2024 version of PanLex Language Vocabulary with 24,650,274 rows covering 6,152 languages.\n\n\t\n\t\t\n\t\tColumns\n\t\n\n\nvocab: contains the text entry.  \n639-3: contains the ISO 639-3 languages tags to allow users to filter on the language(s) of their choice.\n639-3_english_name: the English language name associated to the code ISO 639-3. \nvar_code: contains a code to differentiate language variants. In practice, this is the code 639-3 + a number.  If 000, it corresponds toâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/lbourdois/panlex.","url":"https://huggingface.co/datasets/lbourdois/panlex","creator_name":"LoÃ¯ck BOURDOIS","creator_url":"https://huggingface.co/lbourdois","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["Ghotuo","Alumu-Tesu","Ari","Amal","ArbÃ«reshÃ« Albanian"],"keywords_longer_than_N":true},
	{"name":"aya_dataset_pt","keyword":"portuguese","description":"CohereForAI Aya Dataset filtrado para portuguÃªs (PT).\nAya Dataset Summary\nThe Aya Dataset is a multilingual instruction fine-tuning dataset curated by an open-science community via Aya Annotation Platform from Cohere For AI. The dataset contains a total of 204k human-annotated prompt-completion pairs along with the demographics data of the annotators.\nThis dataset can be used to train, finetune, and evaluate multilingual LLMs.\nCurated by: Contributors of Aya Open Science Intiative.â€¦ See the full description on the dataset page: https://huggingface.co/datasets/botbotrobotics/aya_dataset_pt.","url":"https://huggingface.co/datasets/botbotrobotics/aya_dataset_pt","creator_name":"BotBot","creator_url":"https://huggingface.co/botbotrobotics","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["Portuguese","apache-2.0","1K - 10K","parquet","Text"],"keywords_longer_than_N":true},
	{"name":"aya_dataset_pt","keyword":"portuguese","description":"CohereForAI Aya Dataset filtrado para portuguÃªs (PT).\nAya Dataset Summary\nThe Aya Dataset is a multilingual instruction fine-tuning dataset curated by an open-science community via Aya Annotation Platform from Cohere For AI. The dataset contains a total of 204k human-annotated prompt-completion pairs along with the demographics data of the annotators.\nThis dataset can be used to train, finetune, and evaluate multilingual LLMs.\nCurated by: Contributors of Aya Open Science Intiative.â€¦ See the full description on the dataset page: https://huggingface.co/datasets/botbotrobotics/aya_dataset_pt.","url":"https://huggingface.co/datasets/botbotrobotics/aya_dataset_pt","creator_name":"BotBot","creator_url":"https://huggingface.co/botbotrobotics","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["Portuguese","apache-2.0","1K - 10K","parquet","Text"],"keywords_longer_than_N":true},
	{"name":"central_de_fatos","keyword":"portuguese","description":"\n\t\n\t\t\n\t\tCentral de Fatos\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nIn recent times, the interest for research dissecting the dissemination and prevention of misinformation in the online environment has spiked dramatically.\nGiven that scenario, a recurring obstacle is the unavailability of public datasets containing fact-checked instances.\nIn this work, we performed an extensive data collection of such instances from the better part of all major internationally recognized Brazilian fact-checking agencies.â€¦ See the full description on the dataset page: https://huggingface.co/datasets/fake-news-UFG/central_de_fatos.","url":"https://huggingface.co/datasets/fake-news-UFG/central_de_fatos","creator_name":"fake-news-UFG","creator_url":"https://huggingface.co/fake-news-UFG","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","found","monolingual","Portuguese","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"tatoeba-mt-all-in-one","keyword":"portuguese","description":"\n\t\n\t\t\n\t\tDataset Card for The Tatoeba Translation Challenge | All In One\n\t\n\n~7.3M entries.\nJust more user-friendly version that combines all of the entries of original dataset in a single file:\nhttps://huggingface.co/datasets/Helsinki-NLP/tatoeba_mt\n","url":"https://huggingface.co/datasets/0x22almostEvil/tatoeba-mt-all-in-one","creator_name":"David Glushkov","creator_url":"https://huggingface.co/0x22almostEvil","license_name":"Creative Commons Attribution 2.0","license_url":"https://scancode-licensedb.aboutcode.org/cc-by-2.0.html","language":"en","first_N":5,"first_N_keywords":["Helsinki-NLP","crowdsourced","translation","Helsinki-NLP/tatoeba_mt","Afrikaans"],"keywords_longer_than_N":true},
	{"name":"YouTube-Commons","keyword":"portuguese","description":"\n\t\n\t\t\n\t\tðŸ“º YouTube-Commons ðŸ“º\n\t\n\nYouTube-Commons is a collection of audio transcripts of 2,063,066 videos shared on YouTube under a CC-By license.\n\n\t\n\t\t\n\t\tContent\n\t\n\nThe collection comprises 22,709,724 original and automatically translated transcripts from 3,156,703 videos (721,136 individual channels).\nIn total, this represents nearly 45 billion words (44,811,518,375).\nAll the videos where shared on YouTube with a CC-BY license: the dataset provide all the necessary provenance informationâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/gautijha37/YouTube-Commons.","url":"https://huggingface.co/datasets/gautijha37/YouTube-Commons","creator_name":"Gautam Jha","creator_url":"https://huggingface.co/gautijha37","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","English","French","Spanish","Portuguese"],"keywords_longer_than_N":true},
	{"name":"bible-ptbr-gun-gub-aligned","keyword":"portuguese","description":"tiagoblima/bible-ptbr-gun-gub-aligned dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/tiagoblima/bible-ptbr-gun-gub-aligned","creator_name":"Tiago Barbosa de Lima","creator_url":"https://huggingface.co/tiagoblima","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["translation","Portuguese","GuaranÃ­","mit","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"canarim","keyword":"portuguese","description":"\n  \n\n\n\n  [ðŸ± GitHub]\n\n\n\n\n\n\n\t\n\t\t\n\t\tCanarim: A Large-Scale Dataset of Web Pages in the Portuguese Language\n\t\n\n\n\t\n\t\t\n\t\tIntroduction\n\t\n\nCanarim is a database encompassing over 342 million Portuguese language documents, sourced from multiple iterations of CommonCrawl. This nearly 1 terabyte database stands as one of the most extensive Portuguese language data collections available. It underwent initial deduplication using URLs, with plans for further text-based deduplication and filtering ofâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/dominguesm/canarim.","url":"https://huggingface.co/datasets/dominguesm/canarim","creator_name":"Maicon Domingues","creator_url":"https://huggingface.co/dominguesm","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","fill-mask","language-modeling","masked-language-modeling","monolingual"],"keywords_longer_than_N":true},
	{"name":"tatoeba-mt-llama-only","keyword":"portuguese","description":"\n\t\n\t\t\n\t\tDataset Card for multilingual tatoeba translations with ~3M entries (llama supported languages only).\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\n~3M entries. Just more user-friendly version that combines all of the entries of original dataset in a single file (llama supported languages only):\nhttps://huggingface.co/datasets/Helsinki-NLP/tatoeba_mt\n","url":"https://huggingface.co/datasets/0x22almostEvil/tatoeba-mt-llama-only","creator_name":"David Glushkov","creator_url":"https://huggingface.co/0x22almostEvil","license_name":"Creative Commons Attribution 2.0","license_url":"https://scancode-licensedb.aboutcode.org/cc-by-2.0.html","language":"en","first_N":5,"first_N_keywords":["translation","English","Russian","German","Ukrainian"],"keywords_longer_than_N":true},
	{"name":"NERDE","keyword":"portuguese","description":"(pt) NERDE Ã© um dataset para NER a partir de documentos jurÃ­dicos da defesa econÃ´mica em portuguÃªs do Brasil, foi criado em colaboraÃ§Ã£o com o Cade e o laboratÃ³rio LATITUDE/UnB.\n(en) NERDE is a NER dataset from economic defense legal documents in Brazilian Portuguese, created in collaboration with Cade and the LATITUDE/UnB laboratory.","url":"https://huggingface.co/datasets/Gpaiva/NERDE","creator_name":"Guilherme Pereira Paiva","creator_url":"https://huggingface.co/Gpaiva","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["token-classification","named-entity-recognition","expert-generated","expert-generated","monolingual"],"keywords_longer_than_N":true},
	{"name":"xP3all","keyword":"portuguese","description":"xP3 (Crosslingual Public Pool of Prompts) is a collection of prompts & datasets across 46 of languages & 16 NLP tasks. It is used for the training of BLOOMZ and mT0, multilingual language models capable of following human instructions in dozens of languages zero-shot.","url":"https://huggingface.co/datasets/bigscience/xP3all","creator_name":"BigScience Workshop","creator_url":"https://huggingface.co/bigscience","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["other","expert-generated","crowdsourced","multilingual","Akan"],"keywords_longer_than_N":true},
	{"name":"mswc_fscil_subset","keyword":"portuguese","description":"This is a subset of the Multilingual Spoken Word Corpus dataset, which is built specifically for the Few-shot Class-incremental Learning (FSCIL) task. \nA total of 15 languages are chosen, split into 5 base languages (English, German, Catalan, French, Kinyarwanda) and 10 incrementally learned languages (Persian, Spanish, Russian, Welsh, Italian, Basque, Polish, Esparanto, Portuguese, Dutch).\nThe FSCIL task entails first training a model using abundant training data on words from the 5 baseâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/NeuroBench/mswc_fscil_subset.","url":"https://huggingface.co/datasets/NeuroBench/mswc_fscil_subset","creator_name":"NeuroBench","creator_url":"https://huggingface.co/NeuroBench","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["English","Spanish","Catalan","French","Kinyarwanda"],"keywords_longer_than_N":true},
	{"name":"tokenizer-wiki-bench","keyword":"portuguese","description":"\n\t\n\t\t\n\t\tMultilingual Tokenizer Benchmark\n\t\n\nThis dataset includes pre-processed wikipedia data for tokenizer evaluation in 45 languages. We provide more information on the evaluation task in general this blogpost.\n\n\t\n\t\t\n\t\tUsage\n\t\n\nThe dataset allows us to easily calculate tokenizer fertility and the proportion of continued words on any of the supported languages. In the example below we take the Mistral tokenizer and evaluate its performance on Slovak. \nfrom transformers import AutoTokenizerâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/occiglot/tokenizer-wiki-bench.","url":"https://huggingface.co/datasets/occiglot/tokenizer-wiki-bench","creator_name":"Occiglot","creator_url":"https://huggingface.co/occiglot","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["Afrikaans","Arabic","Bulgarian","Catalan","Czech"],"keywords_longer_than_N":true},
	{"name":"rebel_portuguese","keyword":"portuguese","description":"This is a dataset that was created to re-train REBEL to work better for the Portuguese language.\nThis dataset was generated using CROCODILE, which was adapted to use a Portuguese specific model (pt_core_news_sm) instead of their default multi-language model (xx_ent_wiki_sm).\nThe dataset comes with a train, test, dev and train_dev splits. The train_dev split accounts for 80% of the dataset with the remaining 20% being the training data. The train and dev split was generated from the 80%â€¦ See the full description on the dataset page: https://huggingface.co/datasets/grsilva/rebel_portuguese.","url":"https://huggingface.co/datasets/grsilva/rebel_portuguese","creator_name":"Gabriel Silva","creator_url":"https://huggingface.co/grsilva","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["Portuguese","mit","1M - 10M","json","Text"],"keywords_longer_than_N":true},
	{"name":"quati","keyword":"portuguese","description":"Quati â€• Portuguese Native Information Retrieval dataset.","url":"https://huggingface.co/datasets/unicamp-dl/quati","creator_name":"unicamp-dl","creator_url":"https://huggingface.co/unicamp-dl","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":null,"first_N":5,"first_N_keywords":["question-answering","Portuguese","cc-by-4.0","1M<n<10M","arxiv:2404.06976"],"keywords_longer_than_N":true},
	{"name":"sharegpt_dialogue_base","keyword":"portuguese","description":"\n\t\n\t\t\n\t\tDescription\n\t\n\nThe dataset is from unknown, formatted as dialogues for speed and ease of use. Many thanks to author for releasing it.\nImportantly, this format is easy to use via the default chat template of transformers, meaning you can use huggingface/alignment-handbook immediately, unsloth.\n\n\t\n\t\t\n\t\n\t\n\t\tStructure\n\t\n\nView online through viewer.\n\n\t\n\t\t\n\t\n\t\n\t\tNote\n\t\n\nWe advise you to reconsider before use, thank you. If you find it useful, please like and follow this account.â€¦ See the full description on the dataset page: https://huggingface.co/datasets/lamhieu/sharegpt_dialogue_base.","url":"https://huggingface.co/datasets/lamhieu/sharegpt_dialogue_base","creator_name":"Hieu Lam","creator_url":"https://huggingface.co/lamhieu","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-generation","English","Vietnamese","Chinese","Spanish"],"keywords_longer_than_N":true},
	{"name":"TCC","keyword":"portuguese","description":"Kashmir96/TCC dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/Kashmir96/TCC","creator_name":"Thierry Braga","creator_url":"https://huggingface.co/Kashmir96","license_name":"Academic Free License v3.0","license_url":"https://choosealicense.com/licenses/afl-3.0/","language":"en","first_N":5,"first_N_keywords":["Portuguese","afl-3.0","Audio","ðŸ‡ºðŸ‡¸ Region: US"],"keywords_longer_than_N":false},
	{"name":"nestedclinbr","keyword":"portuguese","description":"\n\t\n\t\t\n\t\tNestedClinBr Corpus\n\t\n\n\n\nNestedClinBr is a new corpus containing nested and discontinuous entities in Brazilian Portuguese clinical narratives.\nThe main goal of NestedClinBr is to provide a human-annotated corpus that can be used for learning and evaluating different machine learning models to extract valuable medical information in the Portuguese language, in special nested and discontinuous entities, an important but less explored task.\nIn the context of clinical NLP, the recognitionâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/pucpr-br/nestedclinbr.","url":"https://huggingface.co/datasets/pucpr-br/nestedclinbr","creator_name":"PontifÃ­cia Universidade CatÃ³lica do ParanÃ¡","creator_url":"https://huggingface.co/pucpr-br","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["token-classification","Portuguese","apache-2.0","< 1K","text"],"keywords_longer_than_N":true},
	{"name":"GUI-Ban","keyword":"portuguese","description":"wendellast/GUI-Ban dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/wendellast/GUI-Ban","creator_name":"wendel alves","creator_url":"https://huggingface.co/wendellast","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","English","Portuguese","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"Ceu","keyword":"portuguese","description":"nerfadox/Ceu dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/nerfadox/Ceu","creator_name":"FabrÃ­cio Mendes","creator_url":"https://huggingface.co/nerfadox","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["Portuguese","cc0-1.0","< 1K","imagefolder","Image"],"keywords_longer_than_N":true},
	{"name":"Kaleidoscope","keyword":"portuguese","description":"\n\t\n\t\t\n\t\tKaleidoscope  (18 Languages)\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe Kaleidoscope Benchmark is a \nglobal collection of multiple-choice questions sourced from real-world exams, \nwith the goal of evaluating multimodal and multilingual understanding in VLMs. \nThe collected exams are in a Multiple-choice question answering (MCQA) \nformat which provides a structured framework for evaluation by prompting \nmodels with predefined answer choices, closely mimicking conventional human testingâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Anonym-sub/Kaleidoscope.","url":"https://huggingface.co/datasets/Anonym-sub/Kaleidoscope","creator_name":"Anonymous submission","creator_url":"https://huggingface.co/Anonym-sub","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["Arabic","Bengali","Croatian","Dutch","English"],"keywords_longer_than_N":true},
	{"name":"FairytaleQA-translated-ptBR","keyword":"portuguese","description":"\n\t\n\t\t\n\t\tDataset Card for FairytaleQA-translated-ptBR\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis repository contains the Brazilian Portuguese (pt-BR) machine-translated version of the original English FairytaleQA dataset (https://huggingface.co/datasets/WorkInTheDark/FairytaleQA). FairytaleQA is an open-source dataset designed to enhance comprehension of narratives, aimed at students from kindergarten to eighth grade. The dataset is meticulously annotated by education experts following anâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/benjleite/FairytaleQA-translated-ptBR.","url":"https://huggingface.co/datasets/benjleite/FairytaleQA-translated-ptBR","creator_name":"Bernardo Leite","creator_url":"https://huggingface.co/benjleite","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["question-answering","text-generation","Portuguese","apache-2.0","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"ApolloMoEBench","keyword":"portuguese","description":"\n\t\n\t\t\n\t\tDemocratizing Medical LLMs For Much More Languages\n\t\n\nCovering 12 Major Languages including English, Chinese, French, Hindi, Spanish, Arabic, Russian, Japanese, Korean, German, Italian, Portuguese and 38 Minor Languages So far.\n\n   ðŸ“ƒ Paper â€¢ ðŸŒ Demo â€¢ ðŸ¤— ApolloMoEDataset â€¢ ðŸ¤— ApolloMoEBench  â€¢ ðŸ¤— Models  â€¢ðŸŒ Apollo  â€¢ ðŸŒ ApolloMoE\n\n\n\n\n\n\n\t\n\t\t\n\t\tðŸŒˆ Update\n\t\n\n\n[2024.10.15] ApolloMoE repo is publishedï¼ðŸŽ‰\n\n\n\t\n\t\t\n\t\tLanguages Coverage\n\t\n\n12 Major Languages and 38 Minor Languages\n\n  Click toâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/FreedomIntelligence/ApolloMoEBench.","url":"https://huggingface.co/datasets/FreedomIntelligence/ApolloMoEBench","creator_name":"FreedomAI","creator_url":"https://huggingface.co/FreedomIntelligence","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["question-answering","Arabic","English","Chinese","Korean"],"keywords_longer_than_N":true},
	{"name":"WiNNL","keyword":"portuguese","description":"\n\t\n\t\t\n\t\tWiNNL\n\t\n\nWikiNews Named entity recognition and Linking (WiNNL) is a multilingual news NER & NEL benchmark based on Wikinews articles.\nThe dataset was created by automatically scraping and tagging news articles, and manually corrected by native speakers to ensure accuracy.\nYou can find more information in the paper:\nhttps://aclanthology.org/2024.dlnld-1.3.pdf\nThe dataset includes the following NER classes in IOB format (labels):\n\nPER (Person): person names \nLOC (Location): geographicalâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/peemil/WiNNL.","url":"https://huggingface.co/datasets/peemil/WiNNL","creator_name":"Emile Peetermans","creator_url":"https://huggingface.co/peemil","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["token-classification","Dutch","English","Spanish","Portuguese"],"keywords_longer_than_N":true},
	{"name":"Synthdog-Multilingual-100","keyword":"portuguese","description":"\n\t\n\t\t\n\t\tSynthdog Multilingual\n\t\n\n\n\nThe Synthdog dataset created for training in Centurio: On Drivers of Multilingual Ability of Large Vision-Language Model.\nUsing the official Synthdog code, we created >1 million training samples for improving OCR capabilities in Large Vision-Language Models.\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Details\n\t\n\nWe provide the images for download in two .tar.gz files. Download and extract them in folders of the same name (so cat images.tar.gz.* | tar xvzf -C images; tar xvzfâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/WueNLP/Synthdog-Multilingual-100.","url":"https://huggingface.co/datasets/WueNLP/Synthdog-Multilingual-100","creator_name":"WÃ¼NLP","creator_url":"https://huggingface.co/WueNLP","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["image-to-text","multilingual","Afrikaans","Amharic","Arabic"],"keywords_longer_than_N":true},
	{"name":"tatoeba_raw_por_kbd","keyword":"portuguese","description":"\n\t\n\t\t\n\t\tPortuguese-to-Kabardian Tatoeba Raw Machine Translations Dataset\n\t\n\nThis dataset contains translations of sentences from Portuguese to Kabardian, sourced from the Tatoeba project. It provides a substantial parallel corpus for machine translation and linguistic research involving the Kabardian language.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\n\n\t\n\t\t\n\t\tDataset Overview\n\t\n\nThis dataset contains over 14 million sentence pairs, with source sentences in Portuguese and their translations in Kabardian.â€¦ See the full description on the dataset page: https://huggingface.co/datasets/panagoa/tatoeba_raw_por_kbd.","url":"https://huggingface.co/datasets/panagoa/tatoeba_raw_por_kbd","creator_name":"adam panagov","creator_url":"https://huggingface.co/panagoa","license_name":"Creative Commons Attribution 2.0","license_url":"https://scancode-licensedb.aboutcode.org/cc-by-2.0.html","language":"en","first_N":5,"first_N_keywords":["translation","Portuguese","Kabardian","cc-by-2.0","1M - 10M"],"keywords_longer_than_N":true},
	{"name":"MediumSetPT","keyword":"portuguese","description":"\n  \n\n\n\n\t\n\t\t\n\t\tðŸ“š Dataset de Perguntas e Respostas por TÃ³pico\n\t\n\nEste repositÃ³rio contÃ©m um dataset com 40.000 amostras estruturadas para tarefas de Processamento de Linguagem Natural (PLN), com foco em perguntas temÃ¡ticas e respostas desenvolvidas.\n\n\t\n\t\t\n\t\tðŸ“ Estrutura dos Dados\n\t\n\nCada amostra Ã© representada em formato JSON com os seguintes campos:\n\nid (string): Identificador Ãºnico da amostra (UUID).\ntopic (lista de strings): Lista com os tÃ³picos abordados.\nprompts (lista de strings):â€¦ See the full description on the dataset page: https://huggingface.co/datasets/AxeML/MediumSetPT.","url":"https://huggingface.co/datasets/AxeML/MediumSetPT","creator_name":"AxÃ©ML - Community","creator_url":"https://huggingface.co/AxeML","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-generation","Portuguese","mit","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"multilingual-queries-for-collected-works-of-milton-h-erickson","keyword":"portuguese","description":"\n\t\n\t\t\n\t\tMultilingual Queries for the Collected Works of Milton H. Erickson\n\t\n\nThis collection contains machine-generated and translated queries designed to evaluate the performance of a multilingual retriever adapted to Ericksonian terminology.\nTo create the queries, the Collected Works of Milton H. Erickson was segmented into 500-word samples. Also, a list of relevant keywords was extracted from the Glossary of Ericksonian Terminology. Using the samples and keywords, queries were generated byâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/LoneWolfgang/multilingual-queries-for-collected-works-of-milton-h-erickson.","url":"https://huggingface.co/datasets/LoneWolfgang/multilingual-queries-for-collected-works-of-milton-h-erickson","creator_name":"Jordan Wolfgang Klein","creator_url":"https://huggingface.co/LoneWolfgang","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["translation","English","Portuguese","Japanese","Chinese"],"keywords_longer_than_N":true},
	{"name":"harmless-aira-dataset","keyword":"portuguese","description":"\n\t\n\t\t\n\t\tHarmless-Aira Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset contains a collection of prompt + completion examples of LLM following instructions in a conversational manner. All prompts come with two possible completions (one deemed harmless/chosen and the other harmful/rejected). The dataset is available in both Portuguese and English.\n\n\t\n\t\t\n\t\tSupported Tasks and Leaderboards\n\t\n\nThis dataset can be utilized to train a reward/preference model or DPO fine-tuning.\n\n\t\n\t\t\n\t\tLanguagesâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/nicholasKluge/harmless-aira-dataset.","url":"https://huggingface.co/datasets/nicholasKluge/harmless-aira-dataset","creator_name":"Nicholas Kluge CorrÃªa","creator_url":"https://huggingface.co/nicholasKluge","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","Portuguese","English","apache-2.0","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"TechnicalDebt_GitHubIssues_PT","keyword":"portuguese","description":"\n\t\n\t\t\n\t\tTechnical Debt in GitHub Issues (Portuguese)\n\t\n\n\n\t\n\t\t\n\t\tVisÃ£o Geral\n\t\n\nEste dataset reÃºne issues pÃºblicas extraÃ­das do GitHub que mencionam o termo \"dÃ­vida tÃ©cnica\" ou suas variaÃ§Ãµes em portuguÃªs. A base foi construÃ­da com o objetivo de apoiar pesquisas em Engenharia de Software, Processamento de Linguagem Natural (PLN) e InteligÃªncia Artificial, com foco na compreensÃ£o e classificaÃ§Ã£o de como o conceito de dÃ­vida tÃ©cnica Ã© comunicado por desenvolvedores.\nA estrutura e categorizaÃ§Ã£oâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/IuryCavalcante/TechnicalDebt_GitHubIssues_PT.","url":"https://huggingface.co/datasets/IuryCavalcante/TechnicalDebt_GitHubIssues_PT","creator_name":"Iury Cavalcante","creator_url":"https://huggingface.co/IuryCavalcante","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","Portuguese","cc-by-4.0","< 1K","csv"],"keywords_longer_than_N":true},
	{"name":"TechnicalDebt_GitHubIssues_PT","keyword":"portuguese","description":"\n\t\n\t\t\n\t\tTechnical Debt in GitHub Issues (Portuguese)\n\t\n\n\n\t\n\t\t\n\t\tVisÃ£o Geral\n\t\n\nEste dataset reÃºne issues pÃºblicas extraÃ­das do GitHub que mencionam o termo \"dÃ­vida tÃ©cnica\" ou suas variaÃ§Ãµes em portuguÃªs. A base foi construÃ­da com o objetivo de apoiar pesquisas em Engenharia de Software, Processamento de Linguagem Natural (PLN) e InteligÃªncia Artificial, com foco na compreensÃ£o e classificaÃ§Ã£o de como o conceito de dÃ­vida tÃ©cnica Ã© comunicado por desenvolvedores.\nA estrutura e categorizaÃ§Ã£oâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/IuryCavalcante/TechnicalDebt_GitHubIssues_PT.","url":"https://huggingface.co/datasets/IuryCavalcante/TechnicalDebt_GitHubIssues_PT","creator_name":"Iury Cavalcante","creator_url":"https://huggingface.co/IuryCavalcante","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","Portuguese","cc-by-4.0","< 1K","csv"],"keywords_longer_than_N":true},
	{"name":"corpus-carolina","keyword":"portuguese","description":"Carolina is an Open Corpus for Linguistics and Artificial Intelligence with a\nrobust volume of texts of varied typology in contemporary Brazilian Portuguese\n(1970-).","url":"https://huggingface.co/datasets/carolina-c4ai/corpus-carolina","creator_name":"Carolina C4AI","creator_url":"https://huggingface.co/carolina-c4ai","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":null,"first_N":5,"first_N_keywords":["fill-mask","text-generation","masked-language-modeling","language-modeling","no-annotation"],"keywords_longer_than_N":true},
	{"name":"xgqa_1k","keyword":"portuguese","description":"\n\t\n\t\t\n\t\txGQA 1K\n\t\n\n\n\t\n\t\t\n\t\tThis is a 1K subset of the few_shot-test split of the xGQA dataset\n\t\n\nPlease find the original repository here: https://github.com/adapter-hub/xGQA\nIf you use this dataset, please cite the original authors:\n@inproceedings{pfeiffer-etal-2021-xGQA,\n    title={{xGQA: Cross-Lingual Visual Question Answering}},\n    author={ Jonas Pfeiffer and Gregor Geigle and Aishwarya Kamath and Jan-Martin O. Steitz and Stefan Roth and Ivan Vuli{\\'{c}} and Iryna Gurevych},\n    booktitleâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/floschne/xgqa_1k.","url":"https://huggingface.co/datasets/floschne/xgqa_1k","creator_name":"Flo Schneider","creator_url":"https://huggingface.co/floschne","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["visual-question-answering","Bengali","German","English","Indonesian"],"keywords_longer_than_N":true},
	{"name":"MOL","keyword":"portuguese","description":"\n\t\n\t\t\n\t\tMOL - Context-Aware Multilingual Offensive Lexicon\n\t\n\nThe MOL is the first specialized lexicon for hate speech detection, annotated with contextual information.\nIt consists of 1,000 explicit and implicit (clue-based) human-annotated rationales used with pejorative connotations, manually identified by a linguist and annotated by three experts regarding their contextual dependency (context-dependent or context-independent).\nFor example, the term \"stupid\" is classified as aâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/franciellevargas/MOL.","url":"https://huggingface.co/datasets/franciellevargas/MOL","creator_name":"Francielle Vargas","creator_url":"https://huggingface.co/franciellevargas","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","Portuguese","English","German","Spanish"],"keywords_longer_than_N":true},
	{"name":"Chinese-Portuguese_Translation_Exercise_Corpus","keyword":"portuguese","description":"Chinese-Portuguese Translation Exercise Corpus (CPTEC)\nThis dataset aims to provide translators to practice Chinese-Portuguese translation with different levels from basic to proficient.\nThis is a sample dataset from CPTEC, please contact us for more information.\nCitation\nIf you use this dataset, please cite:\nHoi, L. M., Sun, Y., Lin, M., & Im, S. K. (2025). Design of Intelligent Educational Mobile Apps with an Original Dataset for Chinese-Portuguese Translators. Forum for Linguistic Studiesâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/edmond5995/Chinese-Portuguese_Translation_Exercise_Corpus.","url":"https://huggingface.co/datasets/edmond5995/Chinese-Portuguese_Translation_Exercise_Corpus","creator_name":"Hoi","creator_url":"https://huggingface.co/edmond5995","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["translation","Chinese","Portuguese","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"MultiQ","keyword":"portuguese","description":"\n\t\n\t\t\n\t\tDataset Card for MultiQ\n\t\n\nThis is the dataset corresponding to the paper \"Evaluating the Elementary Multilingual Capabilities of Large Language Models with MultiQ\". \nIt is a silver standard benchmark that can be used to evaluate the basic multilingual capabilities of LLMs. It contains 200 open ended questions automatically \ntranslated into 137 typologically diverse languages. \n\nCurated by: Carolin Holtermann, Paul RÃ¶ttger, Timm Dill, Anne Lauscher\nLanguage(s) (NLP): 137 diverseâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/caro-holt/MultiQ.","url":"https://huggingface.co/datasets/caro-holt/MultiQ","creator_name":"Holtermann","creator_url":"https://huggingface.co/caro-holt","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["question-answering","Tagalog","Samoan","Macedonian","Gujarati"],"keywords_longer_than_N":true},
	{"name":"SyntacticAgreement","keyword":"portuguese","description":"\n\t\n\t\t\n\t\tSyntacticAgreement\n\t\n\nThis dataset provides manually curated syntactic agreement test suites for four morphologically rich languages: Italian, Spanish, Portuguese, and Russian.It is designed to evaluate the ability of neural language models to capture hierarchical syntactic dependencies, with a focus on agreement phenomena that go beyond English subjectâ€“verb agreement.\nThis dataset is designed for targeted syntactic evaluation, which does not fit standard supervised NLP tasks. For thisâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/albalbalba/SyntacticAgreement.","url":"https://huggingface.co/datasets/albalbalba/SyntacticAgreement","creator_name":"alba taboas","creator_url":"https://huggingface.co/albalbalba","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":null,"first_N":5,"first_N_keywords":["other","expert-generated","Spanish","Italian","Portuguese"],"keywords_longer_than_N":true},
	{"name":"inteligenciamultipla","keyword":"portuguese","description":"Resposta de estudante ao questionÃ¡rio que levanta o perfil de inteligÃªncia mÃºltiplas.\n","url":"https://huggingface.co/datasets/giseldo/inteligenciamultipla","creator_name":"Giseldo Neo","creator_url":"https://huggingface.co/giseldo","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["Portuguese","apache-2.0","< 1K","csv","Text"],"keywords_longer_than_N":true},
	{"name":"JQL-Human-Edu-Annotations","keyword":"portuguese","description":"\n\t\n\t\t\n\t\tðŸ“š JQL Multilingual Educational Quality Annotations\n\t\n\nThis dataset provides high-quality human annotations for evaluating the educational value of web documents, and serves as a benchmark for training and evaluating multilingual LLM annotators as described in the JQL paper.\n\n\n\t\n\t\t\n\t\tðŸ“ Dataset Summary\n\t\n\n\nDocuments: 511 English texts  \nAnnotations: 3 human ratings per document (0â€“5 scale)  \nTranslations: Into 35 European languages using DeepL and GPT-4o  \nPurpose: For training andâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/JQL-AI/JQL-Human-Edu-Annotations.","url":"https://huggingface.co/datasets/JQL-AI/JQL-Human-Edu-Annotations","creator_name":"JQL-AI","creator_url":"https://huggingface.co/JQL-AI","license_name":"Open Data Commons Attribution License v1.0","license_url":"https://scancode-licensedb.aboutcode.org/odc-by-1.0.html","language":"en","first_N":5,"first_N_keywords":["text-classification","Bulgarian","Czech","Croatian","Macedonian"],"keywords_longer_than_N":true},
	{"name":"language-dataset","keyword":"portuguese","description":"\n","url":"https://huggingface.co/datasets/neon-mao/language-dataset","creator_name":"maoqifan","creator_url":"https://huggingface.co/neon-mao","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","English","Chinese","French","Russian"],"keywords_longer_than_N":true},
	{"name":"alagoasideb","keyword":"portuguese","description":"A prÃ³xima versÃ£o desse modelo terÃ¡ um pequeno tratamento dos dados, em relaÃ§Ã£o ao tipo das colunas.\n","url":"https://huggingface.co/datasets/giseldo/alagoasideb","creator_name":"Giseldo Neo","creator_url":"https://huggingface.co/giseldo","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","Portuguese","apache-2.0","1K - 10K","csv"],"keywords_longer_than_N":true},
	{"name":"PangeaBench-xmmmu","keyword":"portuguese","description":"neulab/PangeaBench-xmmmu dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/neulab/PangeaBench-xmmmu","creator_name":"NeuLab @ LTI/CMU","creator_url":"https://huggingface.co/neulab","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["visual-question-answering","question-answering","multiple-choice","Arabic","French"],"keywords_longer_than_N":true},
	{"name":"ToxicCommons","keyword":"portuguese","description":"\n\t\n\t\t\n\t\tToxic Commons\n\t\n\nToxic Commons is a release of 2 million samples of annotated, public domain, multilingual text that was used to train Celadon. \nIt is being released alongside Celadon, in order to better understand multilingual and multicultural toxicity. \nEach sample was classified across 5 axes of toxicity:\n\nRace and origin-based bias: includes racism as well as bias against someoneâ€™s country or region of origin or immigration status, especially immigrant or refugee status. \nGenderâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/PleIAs/ToxicCommons.","url":"https://huggingface.co/datasets/PleIAs/ToxicCommons","creator_name":"PleIAs","creator_url":"https://huggingface.co/PleIAs","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","English","French","Spanish","German"],"keywords_longer_than_N":true},
	{"name":"xtreme-up-semantic-parsing","keyword":"portuguese","description":"\n\t\n\t\t\n\t\tDataset Card for afrixnli\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nSee XTREME-UP GitHub\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nThere are 20 languages available :\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\n\t\n\t\t\n\t\tData Instances\n\t\n\nThe examples look like this for English:\nfrom datasets import load_dataset\ndata = load_dataset('Davlan/xtreme-up-semantic-parsing', 'yor') \n# Please, specify the language code\n# A data point example is below:\n{\n\"id\": \"3231323330393336\",\n\"split\": \"test\",\n\"intent\": \"IN:GET_REMINDER\",\n\"locale\": \"en\"â€¦ See the full description on the dataset page: https://huggingface.co/datasets/Davlan/xtreme-up-semantic-parsing.","url":"https://huggingface.co/datasets/Davlan/xtreme-up-semantic-parsing","creator_name":"David Adelani","creator_url":"https://huggingface.co/Davlan","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","multilingual","Amharic","Belarusian","Bengali"],"keywords_longer_than_N":true},
	{"name":"corpus-synthetic-lgpd","keyword":"portuguese","description":"\n\t\n\t\t\n\t\tDataset: 105 samples for validation\n\t\n\nThis dataset is a sample of 105 documents from the Carolina Corpus, with data annotated in accordance with the LGPD (Brazilian General Data Protection Law).\nIt is part of an academic study for comparing legal language models.\nWe used to validate the model https://huggingface.co/celiudos/legal-bert-lgpd\nThe data has been modified to preserve privacy while maintaining the structure and content of the documents.\nThe CPF (Brazilian ID Number) had itsâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/celiudos/corpus-synthetic-lgpd.","url":"https://huggingface.co/datasets/celiudos/corpus-synthetic-lgpd","creator_name":"Marcelo Anselmo de Souza Filho","creator_url":"https://huggingface.co/celiudos","license_name":"Academic Free License v3.0","license_url":"https://choosealicense.com/licenses/afl-3.0/","language":"en","first_N":5,"first_N_keywords":["token-classification","Portuguese","afl-3.0","< 1K","parquet"],"keywords_longer_than_N":true},
	{"name":"LegiSubject-Br-Summaries","keyword":"portuguese","description":"\n\t\n\t\t\n\t\tðŸ‡§ðŸ‡· Brazilian Legislative Bills â€“ Summary Dataset\n\t\n\nThis dataset contains summaries (ementas) of legislative bills proposed in the Brazilian Chamber of Deputies (BCoD) from 1991 to 2022.It is intended for multi-label classification, where each bill may be associated with one or more subject categories (temas).\nðŸ”€ This is the summary version of the dataset.If you are looking for the keywords version, see:ðŸ‘‰ ronunes/LegiSubject-Br-Keywords\n\n\n\t\n\t\t\n\t\n\t\n\t\tðŸ“ Dataset Structure\n\t\n\nTheâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/ronunes/LegiSubject-Br-Summaries.","url":"https://huggingface.co/datasets/ronunes/LegiSubject-Br-Summaries","creator_name":"Rafael Oleques Nunes","creator_url":"https://huggingface.co/ronunes","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","Portuguese","mit","1M - 10M","parquet"],"keywords_longer_than_N":true},
	{"name":"MultiPICo","keyword":"portuguese","description":"\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nMultiPICo (Multilingual Perspectivist Irony Corpus) is a disaggregated multilingual corpus for irony detection, containing 18,778 pairs of short conversations (post-reply) from Twitter (8,956) and Reddit (9,822), along with the demographic information of each annotator (age, nationality, gender, and so on). \n\n\t\n\t\t\n\t\tSupported Tasks and Leaderboards\n\t\n\nIrony classification task using soft labels (i.e., distribution of annotations) or hard labels (i.e., aggregatedâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Multilingual-Perspectivist-NLU/MultiPICo.","url":"https://huggingface.co/datasets/Multilingual-Perspectivist-NLU/MultiPICo","creator_name":"MultilingualPerspectivistNLU","creator_url":"https://huggingface.co/Multilingual-Perspectivist-NLU","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["Spanish","English","German","Arabic","Portuguese"],"keywords_longer_than_N":true},
	{"name":"tatoeba_kbd_filtered","keyword":"portuguese","description":"\n\t\n\t\t\n\t\tTatoeba Kabardian Filtered Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset is a filtered version of the Multilingual-to-Kabardian Tatoeba Translations Dataset, containing higher-quality parallel sentence translations to Kabardian language (kbd). The dataset has been further filtered to ensure greater translation accuracy and consistency.\nThe source languages are:\n\n\t\n\t\t\nLanguage Code\nLanguage Name\nNumber of Examples\n\n\n\t\t\neng_Latn\nEnglish\n468,894\n\n\nrus_Cyrl\nRussian\n284,256â€¦ See the full description on the dataset page: https://huggingface.co/datasets/panagoa/tatoeba_kbd_filtered.","url":"https://huggingface.co/datasets/panagoa/tatoeba_kbd_filtered","creator_name":"adam panagov","creator_url":"https://huggingface.co/panagoa","license_name":"Creative Commons Attribution 2.0","license_url":"https://scancode-licensedb.aboutcode.org/cc-by-2.0.html","language":"en","first_N":5,"first_N_keywords":["translation","Kabardian","German","English","French"],"keywords_longer_than_N":true},
	{"name":"multilingual_translation_sft","keyword":"portuguese","description":"Youseff1987/multilingual_translation_sft dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/Youseff1987/multilingual_translation_sft","creator_name":"JOON HYOUNG JUN","creator_url":"https://huggingface.co/Youseff1987","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["translation","Korean","English","Chinese","Zulu"],"keywords_longer_than_N":true},
	{"name":"Guilherme34_uncensor_portuguese","keyword":"portuguese","description":"Bad translation of huihui-ai/Guilherme34_uncensor\nThis dataset needs to be filtered, because it was made using ArgosTranslate\n","url":"https://huggingface.co/datasets/BornSaint/Guilherme34_uncensor_portuguese","creator_name":"RÃ³ger Santos","creator_url":"https://huggingface.co/BornSaint","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["Portuguese","apache-2.0","< 1K","parquet","Text"],"keywords_longer_than_N":true},
	{"name":"finepdfs-summaries","keyword":"portuguese","description":"\n\t\n\t\t\n\t\tfinepdfs-summaries\n\t\n\nSummaries generated with Qwen3-Next-80B-A3B-Instruct for documents from finepdfs.\nWork in progress, still generating more data.\nThe following table shows the size for each language:\n\n\t\n\t\t\nLanguage\nSummaries\nTokens\nDisk size\n\n\n\t\t\nAll\n764,482,142\n224 B\n336 GB\n\n\ndeu_Latn\n343,089,235\n106 B\n141 GB\n\n\neng_Latn\n321,343,046\n81 B\n150 GB\n\nfra_Latn\n27,308,302\n10 B\n14 GB\n\n\nspa_Latn\n25,624,727\n9 B\n12 GB\n\n\nita_Latn\n17,587,618\n6 B\n8 GB\n\n\npor_Latn\n12,043,607\n4 B\n5 GB\n\n\npol_Latn\n9â€¦ See the full description on the dataset page: https://huggingface.co/datasets/maxidl/finepdfs-summaries.","url":"https://huggingface.co/datasets/maxidl/finepdfs-summaries","creator_name":"Max Idahl","creator_url":"https://huggingface.co/maxidl","license_name":"Open Data Commons Attribution License v1.0","license_url":"https://scancode-licensedb.aboutcode.org/odc-by-1.0.html","language":"en","first_N":5,"first_N_keywords":["text-generation","summarization","English","German","French"],"keywords_longer_than_N":true},
	{"name":"mtg-cards-SIFT-Features","keyword":"portuguese","description":"\n\t\n\t\t\n\t\tMTG Card SIFT Features Dataset (v5.1)\n\t\n\n\nThis dataset contains the latest incremental MTG card SIFT + RootSIFT feature extraction pipeline. It is designed for server-side production inference, enabling additive updates to the FAISS index and id_map.json without retraining or reindexing from scratch.\n\nNote: This version aligns with a daily resources-nightly.zip Hugging Face upload workflow for reliable continuous deployment via my production server.\n\n\n\n\t\n\t\n\t\n\t\tWhatâ€™s New in v5.1?â€¦ See the full description on the dataset page: https://huggingface.co/datasets/JakeTurner616/mtg-cards-SIFT-Features.","url":"https://huggingface.co/datasets/JakeTurner616/mtg-cards-SIFT-Features","creator_name":"Jake Turner","creator_url":"https://huggingface.co/JakeTurner616","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":null,"first_N":5,"first_N_keywords":["feature-extraction","English","French","German","Italian"],"keywords_longer_than_N":true},
	{"name":"YouTube-Commons-descriptions","keyword":"portuguese","description":"\n\t\n\t\t\n\t\tYouTube Commons Descriptions and Language Detection\n\t\n\nThis dataset adds titles, descriptions and language detection to YouTube Commons, a valuable open dataset:\n\nYouTube-Commons is a collection of audio transcripts of 2,063,066 videos shared on YouTube under a CC BY 4.0 license.\nContent\nThe collection comprises 22,709,724 original and automatically translated transcripts from 3,156,703 videos (721,136 individual channels).\n\nUnfortunately I have found that the detection of the originalâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Rijgersberg/YouTube-Commons-descriptions.","url":"https://huggingface.co/datasets/Rijgersberg/YouTube-Commons-descriptions","creator_name":"Edwin Rijgersberg","creator_url":"https://huggingface.co/Rijgersberg","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["English","French","Spanish","Portuguese","German"],"keywords_longer_than_N":true},
	{"name":"ericksonian-terminology-multilingual","keyword":"portuguese","description":"\n\t\n\t\t\n\t\tMultilingual Glossary of Ericksonian Terminology\n\t\n\nThis dataset was created to evaluate the performance of a multilingual sentence encoder adapted to Ericksonian terminology.\nThe International Glossary of Ericksonian Terminology was developed to promote consistent language use among Ericksonian practitioners worldwide.\nEach entry in the glossary reflects the consensus of three native-speaking translators who also study Ericksonian methodology.\nLanguage Teams:\n\nEnglish: Roxannaâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/LoneWolfgang/ericksonian-terminology-multilingual.","url":"https://huggingface.co/datasets/LoneWolfgang/ericksonian-terminology-multilingual","creator_name":"Jordan Wolfgang Klein","creator_url":"https://huggingface.co/LoneWolfgang","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["translation","English","Spanish","Portuguese","French"],"keywords_longer_than_N":true},
	{"name":"M-ABSA","keyword":"portuguese","description":"\n\t\n\t\t\n\t\tM-ABSA\n\t\n\nThis repo contains the data for our paper M-ABSA: A Multilingual Dataset for Aspect-Based Sentiment Analysis.\n\n\n\t\n\t\t\n\t\tData Description:\n\t\n\nThis is a dataset suitable for the multilingual ABSA task with triplet extraction.\nAll datasets are stored in the data/ folder:\n\nAll dataset contains 7 domains.\n\ndomains = [\"coursera\", \"hotel\", \"laptop\", \"restaurant\", \"phone\", \"sight\", \"food\"]\n\n\nEach dataset contains 21 languages.\n\nlangs = [\"ar\", \"da\", \"de\", \"en\", \"es\", \"fr\", \"hi\", \"hr\"â€¦ See the full description on the dataset page: https://huggingface.co/datasets/Multilingual-NLP/M-ABSA.","url":"https://huggingface.co/datasets/Multilingual-NLP/M-ABSA","creator_name":"multilingual-NLP","creator_url":"https://huggingface.co/Multilingual-NLP","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["token-classification","text-classification","Arabic","Danish","German"],"keywords_longer_than_N":true},
	{"name":"nocaps-pt-br","keyword":"portuguese","description":"\n\t\n\t\t\n\t\tðŸŽ‰ nocaps Dataset Translation for Portuguese Image Captioning\n\t\n\n\n\t\n\t\t\n\t\tðŸ’¾ Dataset Summary\n\t\n\nnocaps Portuguese Translation, a multimodal dataset for Portuguese image captioning benchmark, each image accompanied by ten descriptive captions\nthat have been generated by human annotators for every individual image. The original English captions were rendered into Portuguese\nthrough the utilization of the Google Translator API.\n\n\t\n\t\t\n\t\tðŸ§‘â€ðŸ’» Hot to Get Started with the Dataset\n\t\n\nfromâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/laicsiifes/nocaps-pt-br.","url":"https://huggingface.co/datasets/laicsiifes/nocaps-pt-br","creator_name":"LaboratÃ³rio de InteligÃªncia Computacional e Sistemas de informaÃ§Ã£o","creator_url":"https://huggingface.co/laicsiifes","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-to-image","image-to-text","text-generation","Portuguese","mit"],"keywords_longer_than_N":true},
	{"name":"wikipedia_quality_wikirank","keyword":"portuguese","description":"Datasets with WikiRank quality score as of 1 August 2024 for 47 million Wikipedia articles in 55 language versions (also simplified version for each language in separate files).\nThe WikiRank quality score is a metric designed to assess the overall quality of a Wikipedia article. Although its specific algorithm can vary depending on the implementation, the score typically combines several key features of the Wikipedia article.\n\n\t\n\t\t\n\t\n\t\n\t\tWhy Itâ€™s Important\n\t\n\n\nEnhances Trust: For readers andâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/lewoniewski/wikipedia_quality_wikirank.","url":"https://huggingface.co/datasets/lewoniewski/wikipedia_quality_wikirank","creator_name":"WÅ‚odzimierz Lewoniewski","creator_url":"https://huggingface.co/lewoniewski","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["Arabic","Azerbaijani","Belarusian","Bulgarian","Catalan"],"keywords_longer_than_N":true},
	{"name":"PromptSearchTermsDecomposition","keyword":"portuguese","description":"cnmoro/PromptSearchTermsDecomposition dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/cnmoro/PromptSearchTermsDecomposition","creator_name":"Carlo Moro","creator_url":"https://huggingface.co/cnmoro","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","Portuguese","apache-2.0","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"Buscape","keyword":"portuguese","description":"\n\t\n\t\t\n\t\tBuscapÃ© Sample annotated for Semantic Role Labelling\n\t\n\n\n\t\n\t\t\n\t\tPropbank-Br Corpora BuscapÃ© Sample\n\t\n\nThe Propbank-Br is a project that aims to annotate corpora with semantic role labels for the purpose of creating training datasets for automated semantic role classifiers. The annotation scheme is quite similar to that of the English Propbank (Palmer et al., 2005), with language-specific differences taken into account. The set of semantic roles was designed to facilitate automaticâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/liaad/Buscape.","url":"https://huggingface.co/datasets/liaad/Buscape","creator_name":"LIAAD, INESCTEC","creator_url":"https://huggingface.co/liaad","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["token-classification","Portuguese","mit","1K - 10K","parquet"],"keywords_longer_than_N":true},
	{"name":"nothing_is_real","keyword":"portuguese","description":"Monteiroo/nothing_is_real dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/Monteiroo/nothing_is_real","creator_name":"Igor Gabriel Monteiro","creator_url":"https://huggingface.co/Monteiroo","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["Portuguese","mit","10K - 100K","csv","Text"],"keywords_longer_than_N":true},
	{"name":"estatuto","keyword":"portuguese","description":"abelrh/estatuto dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/abelrh/estatuto","creator_name":"Abel Melo Borges","creator_url":"https://huggingface.co/abelrh","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["question-answering","Portuguese","apache-2.0","< 1K","json"],"keywords_longer_than_N":true},
	{"name":"dataset-portuguese-aira-v2-Gemma-format","keyword":"portuguese","description":"Dataset Aira para o formato do Modelo Gemma \n\n\n\t\n\t\t\n\t\tResumo do Dataset\n\t\n\nEste conjunto de dados contÃ©m uma coleÃ§Ã£o de conversas individuais entre um assistente e um usuÃ¡rio.\nAs conversas foram geradas pelas interaÃ§Ãµes do usuÃ¡rio com modelos jÃ¡ ajustados (ChatGPT, LLama 2, Open-Assistant, etc).\nO conjunto de dados estÃ¡ disponÃ­vel em portuguÃªs (tem a versÃ£o em InglÃªs que ainda nÃ£o tratei). Mas vocÃª pode baixar do \nrepositÃ³rio de Nicholas Kluge CorrÃªa tanto a versÃ£o em PortuguÃªs e \na versÃ£o emâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/EddyGiusepe/dataset-portuguese-aira-v2-Gemma-format.","url":"https://huggingface.co/datasets/EddyGiusepe/dataset-portuguese-aira-v2-Gemma-format","creator_name":"EDDY GIUSEPE CHIRINOS ISIDRO, PhD","creator_url":"https://huggingface.co/EddyGiusepe","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["question-answering","Portuguese","apache-2.0","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"fineweb-2","keyword":"portuguese","description":"\n\t\n\t\t\n\t\tðŸ¥‚ FineWeb2\n\t\n\n\n    \n\n\n\nA sparkling update with 1000s of languages\n\n\n\t\n\t\t\n\t\tWhat is it?\n\t\n\nThis is the second iteration of the popular ðŸ· FineWeb dataset, bringing high quality pretraining data to over 1000 ðŸ—£ï¸ languages.\nThe ðŸ¥‚ FineWeb2 dataset is fully reproducible, available under the permissive ODC-By 1.0 license and extensively validated through hundreds of ablation experiments.\nIn particular, on the set of 9 diverse languages we used to guide our processing decisions, ðŸ¥‚ FineWeb2â€¦ See the full description on the dataset page: https://huggingface.co/datasets/HuggingFaceFW/fineweb-2.","url":"https://huggingface.co/datasets/HuggingFaceFW/fineweb-2","creator_name":"FineData","creator_url":"https://huggingface.co/HuggingFaceFW","license_name":"Open Data Commons Attribution License v1.0","license_url":"https://scancode-licensedb.aboutcode.org/odc-by-1.0.html","language":"en","first_N":5,"first_N_keywords":["text-generation","Arifama-Miniafia","Ankave","Abau","Amarasi"],"keywords_longer_than_N":true},
	{"name":"panlex-definitions","keyword":"portuguese","description":"\n\t\n\t\t\n\t\tDataset Card for panlex-definitions\n\t\n\nThis is a dataset of word definitions in several hudnred languages, extracted from https://panlex.org.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset has been extracted from https://panlex.org (the 20250201 database dump) and rearranged on the per-language basis (by the language of the definition).\nEach language subset consists of definitions (short phrases).\nEach definition is associated with some meanings (if there isâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/cointegrated/panlex-definitions.","url":"https://huggingface.co/datasets/cointegrated/panlex-definitions","creator_name":"David Dale","creator_url":"https://huggingface.co/cointegrated","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["translation","Abkhazian","Hijazi Arabic","Afrikaans","Ainu (Japan)"],"keywords_longer_than_N":true},
	{"name":"common_voice_21_0","keyword":"portuguese","description":"Due to storage limits some files had to be split into multiple parts. They can be merged like this: cat file.* > file.\n","url":"https://huggingface.co/datasets/2Jyq/common_voice_21_0","creator_name":"2Jyq","creator_url":"https://huggingface.co/2Jyq","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["crowdsourced","crowdsourced","multilingual","extended|common_voice","Abkhaz"],"keywords_longer_than_N":true},
	{"name":"R3-eval-MMMLU","keyword":"portuguese","description":"HLeiTR/R3-eval-MMMLU dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/HLeiTR/R3-eval-MMMLU","creator_name":"Shou-Yi Hung","creator_url":"https://huggingface.co/HLeiTR","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["question-answering","Arabic","Bengali","German","Spanish"],"keywords_longer_than_N":true},
	{"name":"pulseReddit","keyword":"portuguese","description":"mattbs/pulseReddit dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/mattbs/pulseReddit","creator_name":"Matheus Barroso de Santana","creator_url":"https://huggingface.co/mattbs","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":null,"first_N":5,"first_N_keywords":["Portuguese","English","apache-2.0","ðŸ‡ºðŸ‡¸ Region: US"],"keywords_longer_than_N":false},
	{"name":"PolyGuardPrompts","keyword":"portuguese","description":"\n\t\n\t\t\n\t\tPolyGuard: A Multilingual Safety Moderation Tool for 17 Languages\n\t\n\nAbstract: Truly multilingual safety moderation efforts for Large Language Models (LLMs) have been hindered by a narrow focus on a small set of languages (e.g., English, Chinese) as well as a limited scope of safety definition, resulting in significant gaps in moderation capabilities. To bridge these gaps, we release PolyGuard, a new state-of-the-art multilingual safety model for safeguarding LLM generations, and theâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/ToxicityPrompts/PolyGuardPrompts.","url":"https://huggingface.co/datasets/ToxicityPrompts/PolyGuardPrompts","creator_name":"ToxicityPrompts","creator_url":"https://huggingface.co/ToxicityPrompts","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["Arabic","Chinese","Czech","Dutch","English"],"keywords_longer_than_N":true},
	{"name":"GlobalDISCO","keyword":"portuguese","description":"\n\t\n\t\t\n\t\tGlobalDISCO\n\t\n\nGlobalDISCO is a large-scale dataset consisting of 73k music tracks generated by state-of-the-art commercial generative music models, along with paired links to 93k reference tracks in LAION-DISCO-12M. The dataset spans 147 languages and includes musical style prompts extracted from MusicBrainz and Wikipedia. The dataset is globally balanced, representing musical styles from artists across 79 countries and five continents. It is aimed to support the research community inâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/disco-eth/GlobalDISCO.","url":"https://huggingface.co/datasets/disco-eth/GlobalDISCO","creator_name":"DISCO","creator_url":"https://huggingface.co/disco-eth","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["audio-classification","English","Spanish","French","German"],"keywords_longer_than_N":true},
	{"name":"ngram-google-2012","keyword":"portuguese","description":"python -m spacy download en_core_web_sm\n\nTitles:\njq -s '.[].title' raw/dict.jsonl\n\nreturns\n\n \"English\"\n \"English One Million\"\n \"American English\"\n \"British English\"\n \"English Fiction\"\n \"Chinese (simplified)\"\n \"French\"\n \"German\"\n \"Hebrew\"\n \"Italian\"\n \"Russian\"\n \"Spanish\"\n\nSpellcheck:\nhttps://pypi.org/project/pyspellchecker/\nEnglish - â€˜enâ€™\nSpanish - â€˜esâ€™\nFrench - â€˜frâ€™\nPortuguese - â€˜ptâ€™\nGerman - â€˜deâ€™\nRussian - â€˜ruâ€™\nArabic - â€˜arâ€™\n\nSets now:\n\n \"English\" - en\n \"Spanish\" - es\n \"French\" - fr\n \"German\"â€¦ See the full description on the dataset page: https://huggingface.co/datasets/gustawdaniel/ngram-google-2012.","url":"https://huggingface.co/datasets/gustawdaniel/ngram-google-2012","creator_name":"Daniel Gustaw","creator_url":"https://huggingface.co/gustawdaniel","license_name":"Creative Commons Attribution 3.0","license_url":"https://scancode-licensedb.aboutcode.org/cc-by-3.0.html","language":"en","first_N":5,"first_N_keywords":["English","Spanish","French","Portuguese","German"],"keywords_longer_than_N":true},
	{"name":"open_government","keyword":"portuguese","description":"\n\t\n\t\t\n\t\tOpen Government Dataset\n\t\n\nOpen Government is the largest agregation of governement text and data made available as part of open data programs. \nIn total, the dataset contains approximately 380B tokens. While Open Government aims to become a global resource, in its current state it mostly features open datasets from the US, France, European and international organizations.\nThe dataset comprises 16 collections curated through two different initiaties: Finance commons and Legal commons.â€¦ See the full description on the dataset page: https://huggingface.co/datasets/AgentPublic/open_government.","url":"https://huggingface.co/datasets/AgentPublic/open_government","creator_name":"AgentPublic","creator_url":"https://huggingface.co/AgentPublic","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","English","French","Bulgarian","Croatian"],"keywords_longer_than_N":true},
	{"name":"wildchat-filtered","keyword":"portuguese","description":"\n\t\n\t\t\n\t\tWildChat Filtered Dataset\n\t\n\nThis is a filtered version of the WildChat-4.8M dataset.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset contains 3,199,860 conversations between human users and ChatGPT, filtered to keep only the essential conversation structure.\n\n\t\n\t\t\n\t\tData Structure\n\t\n\nEach conversation contains only:\n\nconversations: A list of message objects with:\nrole: Either \"user\" or \"assistant\"\ncontent: The text content of the message\n\n\n\nAll other metadata (timestamps, moderationâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/rayonlabs/wildchat-filtered.","url":"https://huggingface.co/datasets/rayonlabs/wildchat-filtered","creator_name":"Rayon Labs","creator_url":"https://huggingface.co/rayonlabs","license_name":"Open Data Commons Attribution License v1.0","license_url":"https://scancode-licensedb.aboutcode.org/odc-by-1.0.html","language":"en","first_N":5,"first_N_keywords":["text-generation","question-answering","English","Spanish","French"],"keywords_longer_than_N":true},
	{"name":"receitafederal","keyword":"portuguese","description":"fabiofachini/receitafederal dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/fabiofachini/receitafederal","creator_name":"Fabio Fachini","creator_url":"https://huggingface.co/fabiofachini","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["Portuguese","apache-2.0","1M - 10M","parquet","Text"],"keywords_longer_than_N":true},
	{"name":"MiniSetPT","keyword":"portuguese","description":"\n  \n\n\n\n\t\n\t\t\n\t\tðŸ“š Dataset de Perguntas e Respostas por TÃ³pico\n\t\n\nEste repositÃ³rio contÃ©m um dataset com 10.000 amostras estruturadas para tarefas de Processamento de Linguagem Natural (PLN), com foco em perguntas temÃ¡ticas e respostas desenvolvidas.\n\n\t\n\t\t\n\t\tðŸ“ Estrutura dos Dados\n\t\n\nCada amostra Ã© representada em formato JSON com os seguintes campos:\n\nid (string): Identificador Ãºnico da amostra (UUID).\ntopic (lista de strings): Lista com os tÃ³picos abordados.\nprompts (lista de strings):â€¦ See the full description on the dataset page: https://huggingface.co/datasets/AxeML/MiniSetPT.","url":"https://huggingface.co/datasets/AxeML/MiniSetPT","creator_name":"AxÃ©ML - Community","creator_url":"https://huggingface.co/AxeML","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-generation","Portuguese","mit","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"gemini_orpo_dpo_ptbr","keyword":"portuguese","description":"celsowm/gemini_orpo_dpo_ptbr dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/celsowm/gemini_orpo_dpo_ptbr","creator_name":"Celso F","creator_url":"https://huggingface.co/celsowm","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","question-answering","Portuguese","apache-2.0","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"ai-culture-multilingual-json-dolma","keyword":"portuguese","description":"\n\t\n\t\t\n\t\tAI-Culture Multilingual JSON + DOLMA Corpus\n\t\n\n\n16M words Â· 12 languages Â· CC-BY-4.0\n\nThe AI-Culture corpus contains 5K articles providing comprehensive philosophical and cultural content, exploring the intersection of technology, artificial intelligence, and human culture, perfectly aligned across 12 languages. All content maintains identical parallel structure across translations with zero duplication and editor-curated quality.\nThis project is maintained by a non-profit digitalâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/AI-Culture-Commons/ai-culture-multilingual-json-dolma.","url":"https://huggingface.co/datasets/AI-Culture-Commons/ai-culture-multilingual-json-dolma","creator_name":"AIâ€‘Cultureâ€‘Commons","creator_url":"https://huggingface.co/AI-Culture-Commons","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["translation","text-generation","text-classification","sentence-similarity","summarization"],"keywords_longer_than_N":true},
	{"name":"TRUEBench","keyword":"portuguese","description":"\n\t\n\t\t\n\t\tTRUEBench: A Benchmark for Assessing LLMs as Human Job Productivity Assistants\n\t\n\nTRUEBench is a benchmark introduced by Samsung Research to evaluate the performance of large language models (LLMs) as human job assistants which consists of over 2,400 realistic and challenging samples. \nTo assess performance in real-world applications, TRUEBench includes diverse dialog scenarios and language conditions.\n\n\t\n\t\t\n\t\tMain Features\n\t\n\n\nMultilinguality: The user instructions are written in aâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/SamsungResearch/TRUEBench.","url":"https://huggingface.co/datasets/SamsungResearch/TRUEBench","creator_name":"Samsung Research","creator_url":"https://huggingface.co/SamsungResearch","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","Korean","English","Japanese","Chinese"],"keywords_longer_than_N":true},
	{"name":"tatoeba-bitext-mining","keyword":"portuguese","description":"\n  Tatoeba\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\n1,000 English-aligned sentence pairs for each language based on the Tatoeba corpus\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2t\n\n\nDomains\nWritten\n\n\nReference\nhttps://github.com/facebookresearch/LASER/tree/main/data/tatoeba/v1\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask = mteb.get_tasks([\"Tatoeba\"])\nevaluator = mteb.MTEB(task)\n\nmodel =â€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/tatoeba-bitext-mining.","url":"https://huggingface.co/datasets/mteb/tatoeba-bitext-mining","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"Creative Commons Attribution 2.0","license_url":"https://scancode-licensedb.aboutcode.org/cc-by-2.0.html","language":"en","first_N":5,"first_N_keywords":["translation","human-annotated","multilingual","Afrikaans","Amharic"],"keywords_longer_than_N":true},
	{"name":"tulu3-100samples","keyword":"portuguese","description":"\n\t\n\t\t\n\t\tDataset\n\t\n\nThis dataset contains 100 samples from the Tulu 3 SFT Mixture.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nEach example in the dataset contains the standard instruction-tuning data points as follow:\n\nid (str): a unique identifier\nmessages (list): message format used for supervised fine-tuning (this contains user prompt and assistant responses)\nsource (str): the source dataset for the given sample\n\n\n\t\n\t\t\n\t\tLicense\n\t\n\nThis dataset is licensed under ODC-BY-1.0. It is intended for research andâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/anayak/tulu3-100samples.","url":"https://huggingface.co/datasets/anayak/tulu3-100samples","creator_name":"Akash Nayak","creator_url":"https://huggingface.co/anayak","license_name":"Open Data Commons Attribution License v1.0","license_url":"https://scancode-licensedb.aboutcode.org/odc-by-1.0.html","language":null,"first_N":5,"first_N_keywords":["other","crowdsourced","expert-generated","machine-generated","multilingual"],"keywords_longer_than_N":true},
	{"name":"fact-check-bureau","keyword":"portuguese","description":"\n\t\n\t\t\n\t\n\t\n\t\tFact-Check Retrieval Dataset\n\t\n\nThis dataset is designed to support the development and evaluation of fact-check retrieval pipelines. It is structured to work with FactCheckBureau, a tool for designing and evaluating fact-check retrieval pipelines. The dataset comprises a list of claims, fact-check articles, and precomputed embeddings for English and French fact-checks.\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Structure\n\t\n\nThe dataset consists of the following files and directories:\n\narticles.csv:â€¦ See the full description on the dataset page: https://huggingface.co/datasets/NaughtyConstrictor/fact-check-bureau.","url":"https://huggingface.co/datasets/NaughtyConstrictor/fact-check-bureau","creator_name":"Younes","creator_url":"https://huggingface.co/NaughtyConstrictor","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["English","French","Portuguese","Spanish","Arabic"],"keywords_longer_than_N":true},
	{"name":"hotel_dataset","keyword":"portuguese","description":"nova-sqoin/hotel_dataset dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/nova-sqoin/hotel_dataset","creator_name":"nova","creator_url":"https://huggingface.co/nova-sqoin","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["Portuguese","English","apache-2.0","< 1K","json"],"keywords_longer_than_N":true},
	{"name":"SegundoHAREM","keyword":"portuguese","description":"\n\t\n\t\t\n\t\tSegundo HAREM\n\t\n\nAccording to Linguateca - a repository for Natural Language resources in Portuguese - HAREM is a \"joint evaluation in the area of Named Entity Recognition in Portuguese\".\nThe sole goal of this dataset is to make Segundo HAREM generally available through the huggingface hub and the datasets library.\nIntended use: this dataset may be used to train and/or evaluate Named Entity Recognition models in Portuguese.\nThe script used to convert the original xml file containingâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/marquesafonso/SegundoHAREM.","url":"https://huggingface.co/datasets/marquesafonso/SegundoHAREM","creator_name":"Afonso Marques","creator_url":"https://huggingface.co/marquesafonso","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["token-classification","Portuguese","mit","< 1K","parquet"],"keywords_longer_than_N":true},
	{"name":"COVID19BR","keyword":"portuguese","description":"\n\t\n\t\t\n\t\tCOVID19.Br\n\t\n\nA Dataset of Misinformation about COVID-19 in Brazilian Portuguese WhatsApp Messages\n\nRepository:\nhttps://zenodo.org/records/5193932 \nhttps://github.com/cabrau/FakeWhatsApp.Br\n\n\nPaper:\nhttps://sol.sbc.org.br/index.php/dsw/article/view/17422/17258 \nhttps://sol.sbc.org.br/index.php/sbbd/article/view/17868/17702\nMaster's thesis (in Portuguese): https://repositorio.ufc.br/handle/riufc/63379\n\n\n\n\n\t\t\n\t\tCitation Information\n\t\n\n@inproceedings{dsw,\n author = {AntÃ´nio Diogo Martinsâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/ju-resplande/COVID19BR.","url":"https://huggingface.co/datasets/ju-resplande/COVID19BR","creator_name":"Juliana Resplande","creator_url":"https://huggingface.co/ju-resplande","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","Portuguese","cc-by-4.0","1K - 10K","parquet"],"keywords_longer_than_N":true},
	{"name":"Multi-Opthalingua","keyword":"portuguese","description":"\n\t\n\t\t\n\t\tCite\n\t\n\nAccepted to AAAI 2025 (https://openreview.net/group?id=AAAI.org/2025/Conference#tab-recent-activity)\nMulti-OphthaLingua: A Multilingual Benchmark for Assessing and Debiasing LLM Ophthalmological QA in LMICs:\n@misc{restrepo2024multiophthalinguamultilingualbenchmarkassessing,\n      title={Multi-OphthaLingua: A Multilingual Benchmark for Assessing and Debiasing LLM Ophthalmological QA in LMICs}, \n      author={David Restrepo and Chenwei Wu and Zhengxu Tang and Zitao Shuai and Thaoâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/AAAIBenchmark/Multi-Opthalingua.","url":"https://huggingface.co/datasets/AAAIBenchmark/Multi-Opthalingua","creator_name":"AAAIBenchmark","creator_url":"https://huggingface.co/AAAIBenchmark","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["question-answering","Hindi","Chinese","English","Spanish"],"keywords_longer_than_N":true},
	{"name":"moosa2022multilingual-cross-lingual-archived","keyword":"portuguese","description":"\n\t\n\t\t\n\t\tDataset Card for Multilingual Hate Speech Dataset\n\t\n\n\n\nThis dataset card provides information about the Multilingual Hate Speech Dataset, which was originally hosted on Kaggle. \nThe Multilingual Hate Speech Dataset is a modified version of an original multilingual hate speech dataset. In this version, examples from each language have been translated into the other languages present in the dataset, creating a more comprehensive cross-lingual resource.\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Detailsâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/ysenarath/moosa2022multilingual-cross-lingual-archived.","url":"https://huggingface.co/datasets/ysenarath/moosa2022multilingual-cross-lingual-archived","creator_name":"Yasas","creator_url":"https://huggingface.co/ysenarath","license_name":"Open Data Commons Attribution License v1.0","license_url":"https://scancode-licensedb.aboutcode.org/odc-by-1.0.html","language":"en","first_N":5,"first_N_keywords":["text-classification","Arabic","English","Chinese","French"],"keywords_longer_than_N":true},
	{"name":"kaleidoscope","keyword":"portuguese","description":"\n\t\n\t\t\n\t\tKaleidoscope  (18 Languages)\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe Kaleidoscope Benchmark is a \nglobal collection of multiple-choice questions sourced from real-world exams, \nwith the goal of evaluating multimodal and multilingual understanding in VLMs. \nThe collected exams are in a Multiple-choice question answering (MCQA) \nformat which provides a structured framework for evaluation by prompting \nmodels with predefined answer choices, closely mimicking conventional human testingâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/CohereLabs/kaleidoscope.","url":"https://huggingface.co/datasets/CohereLabs/kaleidoscope","creator_name":"Cohere Labs","creator_url":"https://huggingface.co/CohereLabs","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["Arabic","Bengali","Croatian","Dutch","English"],"keywords_longer_than_N":true},
	{"name":"Intermediate-Thinking-130k","keyword":"portuguese","description":"\n\t\n\t\t\n\t\tIntermediate-Thinking-130k\n\t\n\nA comprehensive dataset of 135,000 high-quality samples designed to advance language model reasoning capabilities through structured intermediate thinking processes. This dataset enables training and evaluation of models with sophisticated self-correction and iterative reasoning abilities across 42 languages.\nOG Link\n\n\t\n\t\t\n\t\n\t\n\t\tOverview\n\t\n\nIntermediate-Thinking-130k addresses a fundamental limitation in current language models: their inability to pauseâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/mlx-community/Intermediate-Thinking-130k.","url":"https://huggingface.co/datasets/mlx-community/Intermediate-Thinking-130k","creator_name":"MLX Community","creator_url":"https://huggingface.co/mlx-community","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","Afrikaans","Arabic","Bengali","Bulgarian"],"keywords_longer_than_N":true},
	{"name":"high-quality-multilingual-sentences","keyword":"portuguese","description":"\n\t\n\t\t\n\t\tHigh Quality Multilingual Sentences\n\t\n\n\nThis dataset contains multilingual sentences derived from the agentlans/LinguaNova dataset.\nIt includes 1.58 million rows across 51 different languages, each in its own configuration.\n\nExample row (from the all config):\n{\n    \"text\": \"Ø§Ù…Ø§Ù… Ø¬Ù…Ø¹Ù‡ Ø§ØµÙÙ‡Ø§Ù† Ú¯ÙØª: Ù…ÛŒØ²Ø§Ù† Ù†ÛŒØ§Ø² Ø¢Ø¨ Ø´Ø±Ø¨ Ø§ØµÙÙ‡Ø§Ù† Û±Û±.Ûµ Ù…ØªØ± Ù…Ú©Ø¹Ø¨ Ø§Ø³Øª Ú©Ù‡ ØªÙ…Ø§Ù… Ø§Ø³ØªØ§Ù† Ø§ØµÙÙ‡Ø§Ù† Ø±Ø§ Ù¾ÙˆØ´Ø´ Ù…ÛŒØ¯Ù‡Ø¯ Ùˆ Ù†Ø³Ø¨Øª Ø¨Ù‡ Ù‚Ø¨Ù„ Ø§Ø² Ø§Ù†Ù‚Ù„Ø§Ø¨ ÛŒÚ©ÛŒ Ø§Ø² Ù¾ÛŒØ´Ø±ÙØªÙ‡Ø§ Ø¯Ø± Ø­ÙˆØ²Ù‡ Ø¢Ø¨ Ø¨ÙˆØ¯Ù‡ Ø§Ø³Øª.\",\n    \"fasttext\": \"fa\",\n    \"gcld3\": \"fa\"\n}\n\nFields:â€¦ See the full description on the dataset page: https://huggingface.co/datasets/agentlans/high-quality-multilingual-sentences.","url":"https://huggingface.co/datasets/agentlans/high-quality-multilingual-sentences","creator_name":"Alan Tseng","creator_url":"https://huggingface.co/agentlans","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","text-classification","text-retrieval","multilingual","Arabic"],"keywords_longer_than_N":true},
	{"name":"enem","keyword":"portuguese","description":"The ENEM 2022, 2023 and 2024 datasets encompass all multiple-choice questions from the last two editions of the Exame Nacional do Ensino MÃ©dio (ENEM), the main standardized entrance examination adopted by Brazilian universities. The datasets have been created to allow the evaluation of both textual-only and textual-visual language models. To evaluate textual-only models, we incorporated into the datasets the textual descriptions of the images that appear in the questions' statements from theâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/maritaca-ai/enem.","url":"https://huggingface.co/datasets/maritaca-ai/enem","creator_name":"Maritaca AI","creator_url":"https://huggingface.co/maritaca-ai","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["visual-question-answering","multiple-choice","Portuguese","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"fakerecogna2-extrativa-elections","keyword":"portuguese","description":"HenriqueLz/fakerecogna2-extrativa-elections dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/HenriqueLz/fakerecogna2-extrativa-elections","creator_name":"Henrique Luiz","creator_url":"https://huggingface.co/HenriqueLz","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","Portuguese","mit","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"MMMLU","keyword":"portuguese","description":"\n\t\n\t\t\n\t\tMultilingual Massive Multitask Language Understanding (MMMLU)\n\t\n\nThe MMLU is a widely recognized benchmark of general knowledge attained by AI models. It covers a broad range of topics from 57 different categories, covering elementary-level knowledge up to advanced professional subjects like law, physics, history, and computer science.\nWe translated the MMLUâ€™s test set into 14 languages using professional human translators. Relying on human translators for this evaluation increasesâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/bzantium/MMMLU.","url":"https://huggingface.co/datasets/bzantium/MMMLU","creator_name":"Minho Ryu","creator_url":"https://huggingface.co/bzantium","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["question-answering","Arabic","Bengali","German","Spanish"],"keywords_longer_than_N":true},
	{"name":"GammaCorpus-Polylingo-50k","keyword":"portuguese","description":"\n\t\n\t\t\n\t\tGammaCorpus Polylingo 50k\n\t\n\n\n\t\n\t\t\n\t\tWhat is it?\n\t\n\nThe GammaCorpus Polylingo 50k dataset consists of 50,000 structured, unfiltered, single-turn conversations, where each interaction includes:\n\nInput: A user prompt or question.\nOutput: A response generated by an AI assistant.\nLanguage: The language used in the interaction.\n\nThis dataset is designed to help in the training and evaluation of conversational AI models for linguistic purposes. This dataset can be especially helpful if youâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/rubenroy/GammaCorpus-Polylingo-50k.","url":"https://huggingface.co/datasets/rubenroy/GammaCorpus-Polylingo-50k","creator_name":"Ruben Roy","creator_url":"https://huggingface.co/rubenroy","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","English","Russian","Vietnamese","German"],"keywords_longer_than_N":true},
	{"name":"cetuc","keyword":"portuguese","description":"falabrasil/cetuc dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/falabrasil/cetuc","creator_name":"Grupo FalaBrasil","creator_url":"https://huggingface.co/falabrasil","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","Portuguese","mit","100K - 1M","webdataset"],"keywords_longer_than_N":true},
	{"name":"ibge-cidades","keyword":"portuguese","description":"\n\t\n\t\t\n\t\tibge-cidades\n\t\n\nDados dos municÃ­pios no Portal Cidades@ recuperados da API do IBGE\n\n\t\n\t\t\n\t\tFonte\n\t\n\nOs dados em questÃ£o sÃ£o disponibilizados pelo IBGE no Portal Cidades@ (https://cidades.ibge.gov.br/brasil/panorama). Os dados foram coletados por chamadas Ã  API em 21-22 de maio de 2025.\n\n\t\n\t\t\n\t\tDados no dataset\n\t\n\nO dataset contÃ©m dados de 5.565 localidades no Brasil (Cidades, Povoados, Vilarejos, etc.) coletados pelo IBGE, organizados por ano.\nNo total, sÃ£o 40 indicadores que tÃªm seusâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Saint-Clair/ibge-cidades.","url":"https://huggingface.co/datasets/Saint-Clair/ibge-cidades","creator_name":"Lima","creator_url":"https://huggingface.co/Saint-Clair","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["tabular-classification","tabular-regression","no-annotation","found","monolingual"],"keywords_longer_than_N":true},
	{"name":"test_4","keyword":"portuguese","description":"\n\t\n\t\t\n\t\n\t\n\t\tFLEURS\n\t\n\nFleurs is the speech version of the FLoRes machine translation benchmark. \nWe use 2009 n-way parallel sentences from the FLoRes dev and devtest publicly available sets, in 102 languages. \nTraining sets have around 10 hours of supervision. Speakers of the train sets are different than speakers from the dev/test sets. Multilingual fine-tuning is\nused and â€unit error rateâ€ (characters, signs) of all languages is averaged. Languages and results are also grouped into sevenâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/tunngo/test_4.","url":"https://huggingface.co/datasets/tunngo/test_4","creator_name":"nguyen tuan","creator_url":"https://huggingface.co/tunngo","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","expert-generated","crowdsourced","machine-generated","crowdsourced"],"keywords_longer_than_N":true},
	{"name":"literary-synthesis","keyword":"portuguese","description":"\n\t\n\t\t\n\t\tLiterary Synthesis\n\t\n\nThis dataset repurposes the original agentlans/literary-reasoning \ndata by reformatting it as creative writing prompts paired with literary-style outputs. \n\nWriting style attributes were put in random order, with prompts randomly either prepended or appended.\nThe output text has been cleaned to make it suitable for creative writing and literary generation tasks.\nThe rows were sorted by increasing reading difficulty for curriculum learning.\n\n","url":"https://huggingface.co/datasets/agentlans/literary-synthesis","creator_name":"Alan Tseng","creator_url":"https://huggingface.co/agentlans","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","English","French","German","Spanish"],"keywords_longer_than_N":true},
	{"name":"Product_Similarity_Dataset","keyword":"portuguese","description":"This following dataset is a rich dataset of product similarity. The dataset has been design to be challenging to train on by having quite a lot of hard negatives\nThis dataset is especially targeted toward fine-tuning usecase, especially to finetune reranker or embedding model.\nThe data are especially adapted for listwise loss like LambdaLoss or ListNetLoss.\nThe data are in JSONL and each line follow the same format as here below : \n\nA \"query\", the anchor product label\n\"docs\", the potentialâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Antix5/Product_Similarity_Dataset.","url":"https://huggingface.co/datasets/Antix5/Product_Similarity_Dataset","creator_name":"Antoine Demangeon","creator_url":"https://huggingface.co/Antix5","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-ranking","feature-extraction","French","German","Chinese"],"keywords_longer_than_N":true},
	{"name":"GlobalNLI","keyword":"portuguese","description":"\n\t\n\t\t\n\t\tDataset Card for global_nli\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nGlobal NLI is a new text-based benchmark based on the aggregation of existing NLI datasets that are publicly available.\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nThere are 59 languages available :\n{\n    'amh': 'Amharic',\n    'ara': 'Arabic',\n    'asm': 'Assamese',\n    'aym': 'Aymara',\n    'ben': 'Bengali',\n    'bul': 'Bulgarian',\n    'bzd': 'Bribri',\n    'cat': 'Catalan',\n    'cni': 'AshÃ¡ninka',\n    'deu': 'German',\n    'ell': 'Greek',\n    'eng':â€¦ See the full description on the dataset page: https://huggingface.co/datasets/McGill-NLP/GlobalNLI.","url":"https://huggingface.co/datasets/McGill-NLP/GlobalNLI","creator_name":"McGill NLP Group","creator_url":"https://huggingface.co/McGill-NLP","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","natural-language-inference","multilingual","XNLI, AfriXNLI, IndicXNLI, AmericasNLI [30], XNLI-ca, myXNLI, IndoNLI, JNLI , InferBR, sick_pl, JamPatoisNLI, KLUE, RoNLI.","Amharic"],"keywords_longer_than_N":true},
	{"name":"crime_tweets_in_portuguese","keyword":"portuguese","description":"\n\t\n\t\t\n\t\tTweets190: A Comprehensive Dataset of Crime-Related Tweets in Portuguese with Sentiment, Toxicity, and Location Information\n\t\n\nThis dataset contains 61.715 tweets related to possible crime reports, labeled with categories such as \"Assalto\", \"Roubo\", \"Furto\", \"AssÃ©dio\", \"SeguranÃ§a PÃºblica\", \"HomicÃ­dio, and \"Outros\", along with sentiment analysis, toxicity analysis, and location identification.\nA particular feature in the Portuguese language is that many words potentially related toâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/miguelribeirokk/crime_tweets_in_portuguese.","url":"https://huggingface.co/datasets/miguelribeirokk/crime_tweets_in_portuguese","creator_name":"Miguel AntÃ´nio Ribeiro e Silva","creator_url":"https://huggingface.co/miguelribeirokk","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["Portuguese","cc-by-4.0","10K - 100K","csv","Tabular"],"keywords_longer_than_N":true},
	{"name":"faquad-nli","keyword":"portuguese","description":"\n\t\n\t\t\n\t\tDataset Card for FaQuAD-NLI\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nFaQuAD is a Portuguese reading comprehension dataset that follows the format of the Stanford Question Answering Dataset (SQuAD). It is a pioneer Portuguese reading comprehension dataset using the challenging format of SQuAD. The dataset aims to address the problem of abundant questions sent by academics whose answers are found in available institutional documents in the Brazilian higher education system. It consists of 900â€¦ See the full description on the dataset page: https://huggingface.co/datasets/ruanchaves/faquad-nli.","url":"https://huggingface.co/datasets/ruanchaves/faquad-nli","creator_name":"Ruan Chaves Rodrigues","creator_url":"https://huggingface.co/ruanchaves","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["question-answering","extractive-qa","expert-generated","found","monolingual"],"keywords_longer_than_N":true},
	{"name":"m-WildVision","keyword":"portuguese","description":"\n\t\n\t\t\n\t\tDataset Card for m-WildVision\n\t\n\n\n\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\nThe m-WildVision dataset is a multilingual multimodal LLM evaluation set covering 23 languages.  It was created by translating prompts from the original English-only WildVision (vision_bench_0617) test set. \nThe original prompts, developed by Lu et al. (2024) , consist of 500 challenging user queries sourced from the WildVision-Arena platform. \nThe authors demonstrated that these prompts enable automatic LLM judgeâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/CohereLabs/m-WildVision.","url":"https://huggingface.co/datasets/CohereLabs/m-WildVision","creator_name":"Cohere Labs","creator_url":"https://huggingface.co/CohereLabs","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["English","French","German","Spanish","Italian"],"keywords_longer_than_N":true},
	{"name":"Phonemized-UD","keyword":"portuguese","description":"\n\t\n\t\t\n\t\tPhoneme-UD: A Multilingual Phonemized Universal Dependencies Corpus for 34+ Languages\n\t\n\n\n\t\n\t\t\n\t\tG2P+ Phonemizer\n\t\n\nWe use G2P+ to phonemize Universal Dependencies. Here is an example usage: \n# Install required packages\n!apt-get install -y espeak-ng\n!pip install phonemizer g2p-plus\n# Set the environment variable from Python\nimport os\nos.environ[\"PHONEMIZER_ESPEAK_LIBRARY\"] = \"/usr/lib/x86_64-linux-gnu/libespeak-ng.so.1\"\n\n# Now run your transcription\nfrom g2p_plus importâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/suchirsalhan/Phonemized-UD.","url":"https://huggingface.co/datasets/suchirsalhan/Phonemized-UD","creator_name":"Suchir Salhan","creator_url":"https://huggingface.co/suchirsalhan","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["Afrikaans","Amharic","Arabic","Azerbaijani","Catalan"],"keywords_longer_than_N":true},
	{"name":"enem-essay-correction-2018-2024","keyword":"portuguese","description":"fonsecovizk/enem-essay-correction-2018-2024 dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/fonsecovizk/enem-essay-correction-2018-2024","creator_name":"Gabriel Fonseca","creator_url":"https://huggingface.co/fonsecovizk","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["Portuguese","apache-2.0","1K - 10K","parquet","Text"],"keywords_longer_than_N":true},
	{"name":"corpus-fake-br","keyword":"portuguese","description":"\n\t\n\t\t\n\t\tPortuguese Fake News Corpus - Fake.br\n\t\n\nThis dataset contains the corpus used to train Portuguese fake-news classifiers using news articles from Fake.br.\n\n\t\n\t\t\n\t\tContents\n\t\n\n\nParquet/CSV splits (train/test/full/aligned) when available\n\n\n\t\n\t\t\n\t\tSource\n\t\n\n\nFake.br: https://github.com/roneysco/Fake.br-Corpus\n\n","url":"https://huggingface.co/datasets/vzani/corpus-fake-br","creator_name":"Zani","creator_url":"https://huggingface.co/vzani","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","Portuguese","apache-2.0","1K - 10K","parquet"],"keywords_longer_than_N":true},
	{"name":"corpus-fake-br","keyword":"portuguese","description":"\n\t\n\t\t\n\t\tPortuguese Fake News Corpus - Fake.br\n\t\n\nThis dataset contains the corpus used to train Portuguese fake-news classifiers using news articles from Fake.br.\n\n\t\n\t\t\n\t\tContents\n\t\n\n\nParquet/CSV splits (train/test/full/aligned) when available\n\n\n\t\n\t\t\n\t\tSource\n\t\n\n\nFake.br: https://github.com/roneysco/Fake.br-Corpus\n\n","url":"https://huggingface.co/datasets/vzani/corpus-fake-br","creator_name":"Zani","creator_url":"https://huggingface.co/vzani","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","Portuguese","apache-2.0","1K - 10K","parquet"],"keywords_longer_than_N":true},
	{"name":"linkedin-industry-list","keyword":"portuguese","description":"fantastic-jobs/linkedin-industry-list dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/fantastic-jobs/linkedin-industry-list","creator_name":"Fantastic.jobs","creator_url":"https://huggingface.co/fantastic-jobs","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","translation","English","Korean","Spanish"],"keywords_longer_than_N":true},
	{"name":"lapsbm2","keyword":"portuguese","description":"falabrasil/lapsbm2 dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/falabrasil/lapsbm2","creator_name":"Grupo FalaBrasil","creator_url":"https://huggingface.co/falabrasil","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","monolingual","Portuguese","mit","< 1K"],"keywords_longer_than_N":true},
	{"name":"faquad-nli-parquet","keyword":"portuguese","description":"\n\t\n\t\t\n\t\tDataset Card for FaQuAD-NLI\n\t\n\nTHIS IS A TEMPORARY COPY OF THE ORIGINAL ruanchaves/faquad-nli.\nWHY? As of datasets==4.0, loading scripts and trust_remote_code are no longer supported. \nThis breaks things, like the lm-evaluation-harness-pt, which people who work with Portuguese LLMs need for running evals.\nAs soon as ruanchaves updates his version, I'll delete this copy.\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nFaQuAD is a Portuguese reading comprehension dataset that follows the format of theâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/nicholasKluge/faquad-nli-parquet.","url":"https://huggingface.co/datasets/nicholasKluge/faquad-nli-parquet","creator_name":"Nicholas Kluge CorrÃªa","creator_url":"https://huggingface.co/nicholasKluge","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["question-answering","extractive-qa","expert-generated","found","monolingual"],"keywords_longer_than_N":true},
	{"name":"GlobalNLI","keyword":"portuguese","description":"\n\t\n\t\t\n\t\tDataset Card for global_nli\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nGlobal NLI is a new text-based benchmark based on the aggregation of existing NLI datasets that are publicly available.\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nThere are 59 languages available :\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\n\t\n\t\t\n\t\tData Instances\n\t\n\nThe examples look like this for English:\nfrom datasets import load_dataset\ndata = load_dataset('vivekvermaiit/globalnli', 'eng') \n# Please, specify the language code\n# A data point example is below:\n{â€¦ See the full description on the dataset page: https://huggingface.co/datasets/vivekvermaiit/GlobalNLI.","url":"https://huggingface.co/datasets/vivekvermaiit/GlobalNLI","creator_name":"Vivek Verma","creator_url":"https://huggingface.co/vivekvermaiit","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","natural-language-inference","multilingual","XNLI, AfriXNLI, IndicXNLI, AmericasNLI [30], XNLI-ca, myXNLI, IndoNLI, JNLI , InferBR, sick_pl, JamPatoisNLI, KLUE, RoNLI.","Amharic"],"keywords_longer_than_N":true},
	{"name":"MKQARetrieval","keyword":"portuguese","description":"\n  MKQARetrieval\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nMultilingual Knowledge Questions & Answers (MKQA)contains 10,000 queries sampled from the Google Natural Questions dataset.\n        For each query we collect new passage-independent answers. These queries and answers are then human translated into 25 Non-English languages.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2t\n\n\nDomains\nWritten\n\n\nReference\nhttps://github.com/apple/ml-mkqa\n\n\n\t\n\nSource datasets:\n\napple/mkqa\n\n\n\t\n\t\t\n\t\tHow to evaluateâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/MKQARetrieval.","url":"https://huggingface.co/datasets/mteb/MKQARetrieval","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"Creative Commons Attribution 3.0","license_url":"https://scancode-licensedb.aboutcode.org/cc-by-3.0.html","language":"en","first_N":5,"first_N_keywords":["text-retrieval","multiple-choice-qa","human-annotated","multilingual","apple/mkqa"],"keywords_longer_than_N":true},
	{"name":"healthqa-br","keyword":"portuguese","description":"\n\t\n\t\t\n\t\tHealthQA-BR\n\t\n\n\n\t\n\t\t\n\t\tResumo\n\t\n\n\nO HealthQA-BR Ã© o primeiro benchmark de larga escala e abrangÃªncia para todo o Sistema Ãšnico de SaÃºde (SUS), projetado para medir o conhecimento clÃ­nico de Grandes Modelos de Linguagem (LLMs) frente aos desafios da saÃºde pÃºblica brasileira. Composto por 5.632 questÃµes de mÃºltipla escolha, o conjunto de dados Ã© derivado de provas e concursos de licenciamento profissional e residÃªncia de abrangÃªncia nacional e de alto impacto no Brasil.\nDiferentemente deâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Larxel/healthqa-br.","url":"https://huggingface.co/datasets/Larxel/healthqa-br","creator_name":"Andrew D'addario","creator_url":"https://huggingface.co/Larxel","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["question-answering","Portuguese","cc-by-4.0","1K - 10K","parquet"],"keywords_longer_than_N":true},
	{"name":"wpp_pav_transcrito_openai","keyword":"portuguese","description":"\n\t\n\t\t\n\t\tðŸŽ¤ TranscriÃ§Ãµes WhatsApp - OpenAI GPT-4o Transcribe\n\t\n\nEste dataset contÃ©m transcriÃ§Ãµes de mensagens de Ã¡udio do WhatsApp geradas usando OpenAI GPT-4o Transcribe.\n\n\t\n\t\t\n\t\tðŸ“‹ DescriÃ§Ã£o\n\t\n\n\nOrigem: Mensagens de Ã¡udio do WhatsApp em portuguÃªs brasileiro\nModelo: OpenAI GPT-4o Transcribe\nPreÃ§o: $6.00/1M tokens\nTotal de amostras: 198\nFormato de Ã¡udio: WAV (16kHz)\nIdioma: PortuguÃªs brasileiro\n\nModelo Whisper de alta precisÃ£o da OpenAI para transcriÃ§Ã£o de Ã¡udio.\n\n\t\n\t\t\n\t\n\t\n\t\tðŸ“Š EstatÃ­sticasâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/BernardoAI/wpp_pav_transcrito_openai.","url":"https://huggingface.co/datasets/BernardoAI/wpp_pav_transcrito_openai","creator_name":"Bernardo Aires","creator_url":"https://huggingface.co/BernardoAI","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","Portuguese","mit","< 1K","parquet"],"keywords_longer_than_N":true},
	{"name":"portugese_ner_dataset","keyword":"portuguese","description":"\n\t\n\t\t\n\t\tPortugese NER dataset\n\t\n\n\n\t\n\t\t\n\t\tAcknowledgement\n\t\n\nThis dataset had been created as part of joint research of HUMADEX research group (https://www.linkedin.com/company/101563689/) and has received funding by the European Union Horizon Europe Research and Innovation Program project SMILE (grant number 101080923) and Marie SkÅ‚odowska-Curie Actions (MSCA) Doctoral Networks, project BosomShield ((rant number 101073222). Responsibility for the information and views expressed herein liesâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/HUMADEX/portugese_ner_dataset.","url":"https://huggingface.co/datasets/HUMADEX/portugese_ner_dataset","creator_name":"HUMADEX Research Group","creator_url":"https://huggingface.co/HUMADEX","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["token-classification","Portuguese","apache-2.0","100K - 1M","parquet"],"keywords_longer_than_N":true},
	{"name":"napierone-epub-raw","keyword":"portuguese","description":"\n\t\n\t\t\n\t\tBEE-spoke-data/napierone-epub-raw\n\t\n\nNapierOne EPUB files converted with marker. Seems to contain mostly books from Project Gutenberg.\n\n\t\n\t\t\n\t\tdetected languages\n\t\n\nvia fasttext-langdetect\n{'ca': 1,\n 'cy': 1,\n 'da': 6,\n 'de': 105,\n 'en': 4403,\n 'eo': 2,\n 'es': 61,\n 'fi': 76,\n 'fr': 189,\n 'he': 1,\n 'hu': 5,\n 'is': 1,\n 'it': 40,\n 'la': 6,\n 'nl': 41,\n 'pl': 4,\n 'pt': 38,\n 'sv': 10,\n 'tl': 9}\n\n","url":"https://huggingface.co/datasets/BEE-spoke-data/napierone-epub-raw","creator_name":"BEEspoke Data","creator_url":"https://huggingface.co/BEE-spoke-data","license_name":"Open Data Commons Attribution License v1.0","license_url":"https://scancode-licensedb.aboutcode.org/odc-by-1.0.html","language":"en","first_N":5,"first_N_keywords":["text-generation","feature-extraction","English","Spanish","Finnish"],"keywords_longer_than_N":true},
	{"name":"MultiLongDocRetrieval","keyword":"portuguese","description":"\n  MultiLongDocRetrieval\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nMulti Long Doc Retrieval (MLDR) 'is curated by the multilingual articles from Wikipedia, Wudao and mC4 (see Table 7), and NarrativeQA (KocË‡isky Ì et al., 2018; Gu Ìˆnther et al., 2023), which is only for English.' (Chen et al., 2024).\n        It is constructed by sampling lengthy articles from Wikipedia, Wudao and mC4 datasets and randomly choose paragraphs from them. Then we use GPT-3.5 to generate questions basedâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/MultiLongDocRetrieval.","url":"https://huggingface.co/datasets/mteb/MultiLongDocRetrieval","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","LM-generated","multilingual","Shitao/MLDR","Arabic"],"keywords_longer_than_N":true},
	{"name":"PangeaBench-xm100","keyword":"portuguese","description":"\n\t\n\t\t\n\t\n\t\n\t\tXM100\n\t\n\n\n\t\n\t\t\n\t\n\t\n\t\tThis is a copy from https://google.github.io/crossmodal-3600/\n\t\n\nIf you use this dataset, please cite the original authors:\n@inproceedings{ThapliyalCrossmodal2022,\n  author = {Ashish Thapliyal and Jordi Pont-Tuset and Xi Chen and Radu Soricut},\n  title = {{Crossmodal-3600: A Massively Multilingual Multimodal Evaluation Dataset}},\n  booktitle = {EMNLP},\n  year = {2022}\n}\n\n","url":"https://huggingface.co/datasets/neulab/PangeaBench-xm100","creator_name":"NeuLab @ LTI/CMU","creator_url":"https://huggingface.co/neulab","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["image-to-text","Arabic","Bengali","Czech","Danish"],"keywords_longer_than_N":true},
	{"name":"mls-annotated","keyword":"portuguese","description":"\n\t\n\t\t\n\t\tDataset Card for Annotations of non English MLS\n\t\n\nThis dataset consists in annotations of a the Non English subset of the Multilingual LibriSpeech (MLS) dataset. \nMLS dataset is a large multilingual corpus suitable for speech research. The dataset is derived from read audiobooks from LibriVox and consists of \n8 languages - English, German, Dutch, Spanish, French, Italian, Portuguese, Polish. It includes about 44.5K hours of English and a total of about 6K hours for other languages.â€¦ See the full description on the dataset page: https://huggingface.co/datasets/PHBJT/mls-annotated.","url":"https://huggingface.co/datasets/PHBJT/mls-annotated","creator_name":"Paul Henri Biojout","creator_url":"https://huggingface.co/PHBJT","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-to-speech","French","German","Dutch","Portuguese"],"keywords_longer_than_N":true},
	{"name":"multi-hatecheck","keyword":"portuguese","description":"\n  MultiHateClassification\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nHate speech detection dataset with binary\n                       (hateful vs non-hateful) labels. Includes 25+ distinct types of hate\n                       and challenging non-hate, and 11 languages.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask categoryt2c\n\n\nDomains\nConstructed, Written\n\n\nReference\nhttps://aclanthology.org/2022.woah-1.15/\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this datasetâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/multi-hatecheck.","url":"https://huggingface.co/datasets/mteb/multi-hatecheck","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","sentiment-analysis","sentiment-scoring","sentiment-classification","hate-speech-detection"],"keywords_longer_than_N":true},
	{"name":"oab_exams_2011_2025_combined","keyword":"portuguese","description":"russ7/oab_exams_2011_2025_combined dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/russ7/oab_exams_2011_2025_combined","creator_name":"Erick Russo de Freitas Mathias","creator_url":"https://huggingface.co/russ7","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","question-answering","Portuguese","mit","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"cml-tts-filtered","keyword":"portuguese","description":"\n\t\n\t\t\n\t\tDataset Card for Filtred and CML-TTS\n\t\n\nThis dataset is a filtred version of a CML-TTS [1]. \nCML-TTS [1] CML-TTS is a recursive acronym for CML-Multi-Lingual-TTS, a Text-to-Speech (TTS) dataset developed at the Center of Excellence in Artificial Intelligence (CEIA) of the Federal University of Goias (UFG). CML-TTS is a dataset comprising audiobooks sourced from the public domain books of Project Gutenberg, read by volunteers from the LibriVox project. The dataset includes recordings inâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/PHBJT/cml-tts-filtered.","url":"https://huggingface.co/datasets/PHBJT/cml-tts-filtered","creator_name":"Paul Henri Biojout","creator_url":"https://huggingface.co/PHBJT","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-to-speech","French","German","Dutch","Polish"],"keywords_longer_than_N":true},
	{"name":"parallel_corpus_game","keyword":"portuguese","description":"https://github.com/mnbvc-parallel-corpus-team/parallel_corpus_mnbvc\nGame Corpus Collected by MNBVC Parallel Corpus Team.\n\n\t\n\t\t\n\t\t09/17/2025 Updated\n\t\n\n\nHollow Knight\n\n\n\t\n\t\t\n\t\t09/15/2025 Updated\n\t\n\n\nLimbus Company\nMirror\n\n\n\t\n\t\t\n\t\t09/08/2025 Updated\n\t\n\n\nSpice and Wolf VR (1&2)\nDeep Rock Galactic\nCities Skylines 1\n\n\n\t\n\t\t\n\t\t09/02/2025 Updated\n\t\n\n\nPlague Inc\n\n\n\t\n\t\t\n\t\t09/01/2025 Updated\n\t\n\n\nBanGDream from https://bestdori.com/\n\n\n\t\n\t\t\n\t\t08/15/2025 Updated\n\t\n\n\nATRI fromâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/bot-yaya/parallel_corpus_game.","url":"https://huggingface.co/datasets/bot-yaya/parallel_corpus_game","creator_name":"yaya","creator_url":"https://huggingface.co/bot-yaya","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["translation","Arabic","Chinese","German","English"],"keywords_longer_than_N":true},
	{"name":"cbo","keyword":"portuguese","description":"ricardocechinel/cbo dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/ricardocechinel/cbo","creator_name":"ricardo cechinel","creator_url":"https://huggingface.co/ricardocechinel","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["question-answering","Portuguese","apache-2.0","1K - 10K","json"],"keywords_longer_than_N":true},
	{"name":"QuestionClassification","keyword":"portuguese","description":"cnmoro/QuestionClassification dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/cnmoro/QuestionClassification","creator_name":"Carlo Moro","creator_url":"https://huggingface.co/cnmoro","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","English","Portuguese","apache-2.0","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"acl-6060","keyword":"portuguese","description":"\n\t\n\t\t\n\t\tACL 60/60\n\t\n\n\n\t\n\t\t\n\t\tDataset details\n\t\n\nACL 60/60 evaluation sets for multilingual translation of ACL 2022 technical presentations into 10 target languages.\n\n\t\n\t\t\n\t\tCitation\n\t\n\n@inproceedings{salesky-etal-2023-evaluating,\n    title = \"Evaluating Multilingual Speech Translation under Realistic Conditions with Resegmentation and Terminology\",\n    author = \"Salesky, Elizabeth  and\n      Darwish, Kareem  and\n      Al-Badrashiny, Mohamed  and\n      Diab, Mona  and\n      Niehues, Jan\"â€¦ See the full description on the dataset page: https://huggingface.co/datasets/ymoslem/acl-6060.","url":"https://huggingface.co/datasets/ymoslem/acl-6060","creator_name":"Yasmin Moslem","creator_url":"https://huggingface.co/ymoslem","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["translation","automatic-speech-recognition","English","Arabic","German"],"keywords_longer_than_N":true},
	{"name":"Global-MMLU","keyword":"portuguese","description":"\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nGlobal-MMLU ðŸŒ is a multilingual evaluation set spanning 42 languages, including English. This dataset combines machine translations for MMLU questions along with professional translations and crowd-sourced post-edits.\nIt also includes cultural sensitivity annotations for a subset of the questions (2850 questions per language) and classifies them as Culturally Sensitive (CS) ðŸ—½ or Culturally Agnostic (CA) âš–ï¸. These annotations were collected as part of an openâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/CohereLabs/Global-MMLU.","url":"https://huggingface.co/datasets/CohereLabs/Global-MMLU","creator_name":"Cohere Labs","creator_url":"https://huggingface.co/CohereLabs","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["English","Arabic","Bengali","Spanish","French"],"keywords_longer_than_N":true},
	{"name":"ordem_paranormal_QA","keyword":"portuguese","description":"\n\t\n\t\t\n\t\tDataset Ordem Paranormal: Enigma do Medo\n\t\n\nDataset para o modelo thnbi/magistrada\n\n\t\n\t\t\n\t\tDescriÃ§Ã£o\n\t\n\nEste dataset contÃ©m pares de instruÃ§Ã£o-resposta baseados no universo do jogo \"Enigma do Medo\", parte do sistema de RPG Ordem Paranormal. Os dados foram extraÃ­dos e curados a partir da Wiki oficial do Ordem Paranormal.\n\n\t\n\t\t\n\t\tConteÃºdo\n\t\n\n\nPerguntas e respostas sobre localizaÃ§Ãµes do jogo\nInformaÃ§Ãµes sobre mecÃ¢nicas e sistemas\nDetalhes sobre a narrativa e lore\nOrientaÃ§Ãµes sobreâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/thnbi/ordem_paranormal_QA.","url":"https://huggingface.co/datasets/thnbi/ordem_paranormal_QA","creator_name":"Renato Freitas","creator_url":"https://huggingface.co/thnbi","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["Portuguese","mit","< 1K","json","Text"],"keywords_longer_than_N":true},
	{"name":"wpp_pav_transcrito_gemini","keyword":"portuguese","description":"\n\t\n\t\t\n\t\tðŸŽ¤ TranscriÃ§Ãµes WhatsApp - Google Gemini 2.0 Flash\n\t\n\nEste dataset contÃ©m transcriÃ§Ãµes de mensagens de Ã¡udio do WhatsApp geradas usando Google Gemini 2.0 Flash.\n\n\t\n\t\t\n\t\tðŸ“‹ DescriÃ§Ã£o\n\t\n\n\nOrigem: Mensagens de Ã¡udio do WhatsApp em portuguÃªs brasileiro\nModelo: Google Gemini 2.0 Flash\nPreÃ§o: $0.075/1M tokens\nTotal de amostras: 198\nFormato de Ã¡udio: WAV (16kHz)\nIdioma: PortuguÃªs brasileiro\n\nModelo de IA multimodal avanÃ§ado da Google com capacidades de anÃ¡lise contextual de Ã¡udio.â€¦ See the full description on the dataset page: https://huggingface.co/datasets/BernardoAI/wpp_pav_transcrito_gemini.","url":"https://huggingface.co/datasets/BernardoAI/wpp_pav_transcrito_gemini","creator_name":"Bernardo Aires","creator_url":"https://huggingface.co/BernardoAI","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","Portuguese","mit","< 1K","parquet"],"keywords_longer_than_N":true},
	{"name":"allenai_tulu-3-sft-mixture-DolphinLabeled","keyword":"portuguese","description":"\n\t\n\t\t\n\t\tallenai tulu-3-sft-mixture DolphinLabeled\n\t\n\n\n\t\n\t\t\n\t\tPart of the DolphinLabeled series of datasets\n\t\n\n\n\t\n\t\t\n\t\tPresented by Eric Hartford and Cognitive Computations\n\t\n\nThe purpose of this dataset is to enable filtering of allenai/tulu-3-sft-mixture dataset.\nThe original dataset is allenai/tulu-3-sft-mixture\nI have modified the dataset using two scripts.\n\ndedupe.py - removes rows with identical final message content\nlabel.py - adds a \"flags\" column containing the following booleanâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/cognitivecomputations/allenai_tulu-3-sft-mixture-DolphinLabeled.","url":"https://huggingface.co/datasets/cognitivecomputations/allenai_tulu-3-sft-mixture-DolphinLabeled","creator_name":"Cognitive Computations","creator_url":"https://huggingface.co/cognitivecomputations","license_name":"Open Data Commons Attribution License v1.0","license_url":"https://scancode-licensedb.aboutcode.org/odc-by-1.0.html","language":"en","first_N":5,"first_N_keywords":["other","crowdsourced","expert-generated","machine-generated","multilingual"],"keywords_longer_than_N":true},
	{"name":"cabrita-guanaco-dataset-52k","keyword":"portuguese","description":"f7lipe/cabrita-guanaco-dataset-52k dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/f7lipe/cabrita-guanaco-dataset-52k","creator_name":"FIlipe Correia","creator_url":"https://huggingface.co/f7lipe","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["Portuguese","apache-2.0","10K - 100K","parquet","Text"],"keywords_longer_than_N":true},
	{"name":"discursos-senado-legislatura-56","keyword":"portuguese","description":"\n\t\n\t\t\n\t\tDiscursos da 56Âª Legislatura do Senado Federal\n\t\n\n\n\t\n\t\t\n\t\tVisÃ£o geral\n\t\n\nCorpus de pronunciamentos do PlenÃ¡rio do Senado Federal durante a 56Âª Legislatura (2019â€“2022), coletados via API pÃºblica e consolidados em Parquet. Cada linha Ã© um pronunciamento com metadados e texto integral quando disponÃ­vel.\n\n\t\n\t\t\n\t\tDetalhes do dataset\n\t\n\n\n\t\n\t\t\n\t\tDescriÃ§Ã£o\n\t\n\n\nPeriodo: 2019-02-01 a 2023-01-01\n\nUnidade: pronunciamento no PlenÃ¡rio do Senado\n\nFormato: Parquet (colunar, comprimido)  \n\nCamposâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fabriciosantana/discursos-senado-legislatura-56.","url":"https://huggingface.co/datasets/fabriciosantana/discursos-senado-legislatura-56","creator_name":"Fabricio Fernandes Santana","creator_url":"https://huggingface.co/fabriciosantana","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","text-classification","summarization","text-retrieval","text-generation"],"keywords_longer_than_N":true},
	{"name":"quran_multilingual_parallel","keyword":"portuguese","description":"\n\t\n\t\t\n\t\tðŸ“˜ Qurâ€™an Multilingual Parallel Dataset (quran_multilingual_parallel)\n\t\n\nThis dataset presents a clean, structurally-aligned multilingual parallel corpus of the Qurâ€™anic text. It is intended for linguistic, computational, and cross-lingual AI applications â€” not only for religious interpretation.\nIt contains over 6,200 verse-level alignments in 54 human languages, formatted in a machine-friendly .csv structure with language-specific translation fields.\n\n\n\t\n\t\t\n\t\n\t\n\t\tðŸ§  Dataset Highlightsâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/freococo/quran_multilingual_parallel.","url":"https://huggingface.co/datasets/freococo/quran_multilingual_parallel","creator_name":"Wynn","creator_url":"https://huggingface.co/freococo","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["translation","Arabic","Albanian","Amharic","Azerbaijani"],"keywords_longer_than_N":true},
	{"name":"SQuAD-pt_BR-V1.1","keyword":"portuguese","description":"\n\t\n\t\t\n\t\tDataset Card for Dataset Name\n\t\n\n\n\nO conjunto de dados \"Stanford Question Answering Dataset\" (SQuAD), para tarefa de perguntas e respostas extrativas, foi desenvolvido em 2016. Ele utiliza perguntas geradas \na partir de 536 artigos da Wikipedia com mais de 100.000 linhas de dados. Ã‰ construÃ­do na forma de uma pergunta e um contexto dos artigos da Wikipedia contendo a resposta \nÃ  pergunta.\nOriginalmente este dataset foi construÃ­do no idioma inglÃªs, contudo, o grupo Deep Learning Brasilâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/vsvasconcelos/SQuAD-pt_BR-V1.1.","url":"https://huggingface.co/datasets/vsvasconcelos/SQuAD-pt_BR-V1.1","creator_name":"Vagner Sanches Vasconcelos","creator_url":"https://huggingface.co/vsvasconcelos","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["Portuguese","apache-2.0","10K - 100K","csv","Text"],"keywords_longer_than_N":true},
	{"name":"multiCHILDES","keyword":"portuguese","description":"\n\t\n\t\t\n\t\tmultiCHILDES: Multilingual Child-Directed Speech Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset contains child-directed speech from 19 languages, extracted from the CHILDES corpus. The text has been cleaned and is designed for text generation tasks, particularly in studying early language acquisition.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\nSource: CHILDES corpus\nLanguages: 19 languages\nText Type: Child-directed speech\nTask: Text Generation, Language Modeling\nData Processing: The datasetâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/IParraMartin/multiCHILDES.","url":"https://huggingface.co/datasets/IParraMartin/multiCHILDES","creator_name":"IÃ±igo Parra","creator_url":"https://huggingface.co/IParraMartin","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-generation","English","Basque","Spanish","Portuguese"],"keywords_longer_than_N":true}
]
;
