const data_for_language_europe_german = 
[
	{"name":"MSD_manual_topics_user_base","keyword":"german","description":"\n\t\n\t\t\n\t\tMSD_manual_topics_user_base\n\t\n\nThis dataset has been built with the website https://www.msdmanuals.com/ provided by Merck & Co for the greater audience.\nThe MSD manual is an essential source of knowledge for many topics related to symptoms, diseases, health and other related topics. The manual makes an extra effort to make it available both for professionals and patients by having two distinct version. \nThe content, while being labelled the same, differs by the type of user in order toâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/nuvocare/MSD_manual_topics_user_base.","url":"https://huggingface.co/datasets/nuvocare/MSD_manual_topics_user_base","creator_name":"Nuvocare","creator_url":"https://huggingface.co/nuvocare","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","question-answering","text-generation","English","German"],"keywords_longer_than_N":true},
	{"name":"TinyDS-20k","keyword":"german","description":"\n\t\n\t\t\n\t\tTinyDS\n\t\n\n\n\n\nAlpaca-style dataset with around 20k samples scraped from Qwen3-8B using SyntheticAlpaca. Q&A pairs can be in 32 different languages, these are listed in the metadata.Topics are all around STEM, programming, and literature.  \nMIT @ 2025 Hamzah Asadullah\n\n\n","url":"https://huggingface.co/datasets/Hamzah-Asadullah/TinyDS-20k","creator_name":"Hamzah Asadullah","creator_url":"https://huggingface.co/Hamzah-Asadullah","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["question-answering","translation","text-generation","text2text-generation","English"],"keywords_longer_than_N":true},
	{"name":"nanochat-german-data","keyword":"german","description":"\n\t\n\t\t\n\t\tnanochat German: Pretraining Data\n\t\n\nThis repository uses a subset of the LLÃ¤Mmlein pretraining dataset, which itself is a strict subset of the German portion of the RedPajama V2 dataset.\nTo construct the dataset, we download the first 20 JSONL files from LLÃ¤Mmlein and merge them into a single collection.\nFollowing the original nanochat dataset construction process, we then split the data into shards containing approximately 250 million characters each.\nFor proper attribution, weâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/stefan-it/nanochat-german-data.","url":"https://huggingface.co/datasets/stefan-it/nanochat-german-data","creator_name":"Stefan Schweter","creator_url":"https://huggingface.co/stefan-it","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["German","apache-2.0","10M - 100M","parquet","Text"],"keywords_longer_than_N":true},
	{"name":"apertus-pretrain-swiss","keyword":"german","description":"\n\t\n\t\t\n\t\tSwiss Pretrain Data\n\t\n\nThis dataset provides a large collection of open-access and license-compliant Swiss data sources for language model training.\nThe dataset includes the following sources:\n\n\t\n\t\t\nName\nInternal ID\nTokens (B)\nDescription\n\n\n\t\t\nCuria Vista\ncuriavista\n0.5\nLegal and administrative documents from the Swiss database of parliamentary proceedings.\n\n\nenscheidsuche\nenscheidsuche_html\n4.5\nSwiss court decisions, sampled at 50% for balance.\n\n\nFineWeb-2â€¦ See the full description on the dataset page: https://huggingface.co/datasets/swiss-ai/apertus-pretrain-swiss.","url":"https://huggingface.co/datasets/swiss-ai/apertus-pretrain-swiss","creator_name":"Swiss AI Initiative","creator_url":"https://huggingface.co/swiss-ai","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["fill-mask","text-generation","French","English","German"],"keywords_longer_than_N":true},
	{"name":"allenai_tulu-3-sft-mixture-DolphinLabeled","keyword":"german","description":"\n\t\n\t\t\n\t\tallenai tulu-3-sft-mixture DolphinLabeled\n\t\n\n\n\t\n\t\t\n\t\tPart of the DolphinLabeled series of datasets\n\t\n\n\n\t\n\t\t\n\t\tPresented by Eric Hartford and Cognitive Computations\n\t\n\nThe purpose of this dataset is to enable filtering of allenai/tulu-3-sft-mixture dataset.\nThe original dataset is allenai/tulu-3-sft-mixture\nI have modified the dataset using two scripts.\n\ndedupe.py - removes rows with identical final message content\nlabel.py - adds a \"flags\" column containing the following booleanâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/QuixiAI/allenai_tulu-3-sft-mixture-DolphinLabeled.","url":"https://huggingface.co/datasets/QuixiAI/allenai_tulu-3-sft-mixture-DolphinLabeled","creator_name":"Quixi AI","creator_url":"https://huggingface.co/QuixiAI","license_name":"Open Data Commons Attribution License v1.0","license_url":"https://scancode-licensedb.aboutcode.org/odc-by-1.0.html","language":"en","first_N":5,"first_N_keywords":["other","crowdsourced","expert-generated","machine-generated","multilingual"],"keywords_longer_than_N":true},
	{"name":"FRFPE","keyword":"german","description":"Funds Report Front Page Entities (FRFPE) is a dataset for document understanding and token classification. \nIt contains 356 titles/front pages of annual and semi-annual reports as well as extracted text and annotations for five different token categories. \nFRFPE serves as an example of how to train and evaluate multimodal models such as LayoutLM using the deepdoctection framework on a custom dataset.\nFRFPE contains documents in three different languages \n\nenglish: 167 \ngerman: 149\nfrench: 9â€¦ See the full description on the dataset page: https://huggingface.co/datasets/deepdoctection/FRFPE.","url":"https://huggingface.co/datasets/deepdoctection/FRFPE","creator_name":"deepdoctection","creator_url":"https://huggingface.co/deepdoctection","license_name":"Open Data Commons Attribution License v1.0","license_url":"https://scancode-licensedb.aboutcode.org/odc-by-1.0.html","language":"en","first_N":5,"first_N_keywords":["token-classification","German","English","French","odc-by"],"keywords_longer_than_N":true},
	{"name":"prompt_injections","keyword":"german","description":"\n\t\n\t\t\n\t\tDataset Card for Prompt Injections by  Yanis Miraoui  ðŸ‘‹\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset of prompt injections enriches Large Language Models (LLMs) by providing task-specific examples and prompts, helping improve LLMs' performance and control their behavior.\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset contains over 1000 rows of prompt injections in multiple languages. It contains examples of prompt injections using different techniques such as: prompt leaking, jailbreakingâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/yanismiraoui/prompt_injections.","url":"https://huggingface.co/datasets/yanismiraoui/prompt_injections","creator_name":"Yanis Miraoui","creator_url":"https://huggingface.co/yanismiraoui","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["no-annotation","multilingual","original","English","French"],"keywords_longer_than_N":true},
	{"name":"xlel_wd_dictionary","keyword":"german","description":"XLEL-WD is a multilingual event linking dataset. This sub-dataset contains a dictionary of events from Wikidata. The multilingual descriptions for Wikidata event items are taken from the corresponding Wikipedia articles.","url":"https://huggingface.co/datasets/adithya7/xlel_wd_dictionary","creator_name":"Adithya Pratapa","creator_url":"https://huggingface.co/adithya7","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["found","found","multilingual","original","Afrikaans"],"keywords_longer_than_N":true},
	{"name":"minigpt4-7b-ggml","keyword":"german","description":"These are quantized ggml binary files for minigpt4 7B model.\nThese files can be used in conjunction with vicuna v0 ggml models to get minigpt4 working.\nNot all implementations were tested. If there are any issues, use f16.\n","url":"https://huggingface.co/datasets/maknee/minigpt4-7b-ggml","creator_name":"maknee","creator_url":"https://huggingface.co/maknee","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":null,"first_N":5,"first_N_keywords":["English","Bulgarian","Catalan","Czech","Danish"],"keywords_longer_than_N":true},
	{"name":"JimmyTeddy","keyword":"german","description":"emilderteddybaer/JimmyTeddy dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/emilderteddybaer/JimmyTeddy","creator_name":"Jimmy","creator_url":"https://huggingface.co/emilderteddybaer","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["German","apache-2.0","< 1K","json","Text"],"keywords_longer_than_N":true},
	{"name":"seamless-align","keyword":"german","description":"\n\t\n\t\t\n\t\tDataset Card for Seamless-Align (WIP). Inspired by https://huggingface.co/datasets/allenai/nllb\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset was created based on metadata for mined Speech-to-Speech(S2S), Text-to-Speech(TTS) and Speech-to-Text(S2T) released by Meta AI.  The S2S contains data for 35 language pairs. The S2S dataset is ~1000GB compressed.\n\n\t\n\t\t\n\t\tHow to use the data\n\t\n\nThere are two ways to access the data:\n\nVia the Hugging Face Python datasets library\n\nScripts coming soonâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/jhu-clsp/seamless-align.","url":"https://huggingface.co/datasets/jhu-clsp/seamless-align","creator_name":"Center for Language and Speech Processing @ JHU","creator_url":"https://huggingface.co/jhu-clsp","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["translation","audio-to-audio","Maltese","English","Welsh"],"keywords_longer_than_N":true},
	{"name":"WEATHub","keyword":"german","description":"\n\n\n\n\n\t\n\t\t\n\t\tDataset Card for \"WEATHub\"\n\t\n\nThis dataset corresponds to the data described in the paper \"Global Voices, Local Biases: Socio-Cultural Prejudices across Languages\"\naccepted to EMNLP 2023.\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nWEATHub is a dataset containing 24 languages. It contains words organized into groups of (target1, target2, attribute1, attribute2)\nto measure the association target1:target2 :: attribute1:attribute2. For example target1 can be insects, target2 can be flowers. And weâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/iamshnoo/WEATHub.","url":"https://huggingface.co/datasets/iamshnoo/WEATHub","creator_name":"Anjishnu Mukherjee","creator_url":"https://huggingface.co/iamshnoo","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["Arabic","Bengali","Central Kurdish","Danish","German"],"keywords_longer_than_N":true},
	{"name":"Publico","keyword":"german","description":"\n\t\n\t\t\n\t\tPÃºblico\n\t\n\nThis dataset was build by translating a set of 34,157 news from PÃºblico, an European Portuguese news paper. The news have been translated using Google Translator.\nTo now more about the data visit the Github repos used to scrape and translate the news.\n","url":"https://huggingface.co/datasets/hugosousa/Publico","creator_name":"Hugo Sousa","creator_url":"https://huggingface.co/hugosousa","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["Portuguese","English","German","French","Spanish"],"keywords_longer_than_N":true},
	{"name":"German_Names_Central_And_Eastern_Europe","keyword":"german","description":"This dataset contains German exonyms for various places in modern day Poland, Czech Republic, Latvia, Lithuania and Estonia. \nExonym : - A placename that is used by people who are not locals. For example, Prague is the Eng. exonym of Czech capital Praha, or Cologne is an exonym for German city KÃ¶ln.\nDue to extensive historical German rule and presence over large chunks of modern day Poland and Czech republic, these two countries populate the dataset the most.\n","url":"https://huggingface.co/datasets/DebasishDhal99/German_Names_Central_And_Eastern_Europe","creator_name":"Debasish Dhal","creator_url":"https://huggingface.co/DebasishDhal99","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["translation","German","Polish","Czech","Lithuanian"],"keywords_longer_than_N":true},
	{"name":"tulu-3-sft-mixture","keyword":"german","description":"\n\n\n\t\n\t\t\n\t\tTulu 3 SFT Mixture\n\t\n\nNote that this collection is licensed under ODC-BY-1.0 license; different licenses apply to subsets of the data. Some portions of the dataset are non-commercial. We present the mixture as a research artifact.\nThe Tulu 3 SFT mixture was used to train the Tulu 3 series of models.\nIt contains 939,344 samples from the following sets:\n\nCoCoNot (ODC-BY-1.0), 10,983 prompts (Brahman et al., 2024)\nFLAN v2 via ai2-adapt-dev/flan_v2_converted, 89,982 prompts (Longpre etâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/allenai/tulu-3-sft-mixture.","url":"https://huggingface.co/datasets/allenai/tulu-3-sft-mixture","creator_name":"Ai2","creator_url":"https://huggingface.co/allenai","license_name":"Open Data Commons Attribution License v1.0","license_url":"https://scancode-licensedb.aboutcode.org/odc-by-1.0.html","language":"en","first_N":5,"first_N_keywords":["other","crowdsourced","expert-generated","machine-generated","multilingual"],"keywords_longer_than_N":true},
	{"name":"iati-policy-markers","keyword":"german","description":"\n\t\n\t\t\n\t\tInternational Aid Transparency Initiative (IATI) Policy Marker Dataset\n\t\n\nA multi-purpose dataset including all activity title and description text published to IATI with metadata for policy markers.\nFor more information on IATI policy markers, see the element page on the IATI Standard Website.\nIATI is a living data source, and this dataset was last updated on 21 August, 2024. For the code to generate an updated version of this dataset, please see my Github repository here.\nFor anyâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/devinitorg/iati-policy-markers.","url":"https://huggingface.co/datasets/devinitorg/iati-policy-markers","creator_name":"Development Initiatives","creator_url":"https://huggingface.co/devinitorg","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","English","French","Spanish","German"],"keywords_longer_than_N":true},
	{"name":"german-polish-paired-placenames","keyword":"german","description":"\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset contains the German and Polish names for almost 10k places in Poland. It has been generated using this code.\nMany of these names are related to each other. Some German names are literal translation of the Polish names, some are phonetic modifications while some are unrelated.\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Creation\n\t\n\n\n\t\n\t\t\n\t\n\t\n\t\tSource Data\n\t\n\nGerman wiki page\n","url":"https://huggingface.co/datasets/DebasishDhal99/german-polish-paired-placenames","creator_name":"Debasish Dhal","creator_url":"https://huggingface.co/DebasishDhal99","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["translation","German","Polish","cc-by-4.0","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"lola-gramma-de-en","keyword":"german","description":"\n\t\n\t\t\n\t\tDataset Card\n\t\n\nThis gramma correction dataset is still work in progress! Do not use it for any serious LLM task - see Issues bellow.\n\n\t\n\t\t\n\t\tDataset summary\n\t\n\nThis dataset is used to finetune LLMs for German gramma correction for English speakers.  \n\n\t\n\t\t\n\t\tInput\n\t\n\nAn input is German sentence, which has potentially grammatical errors.\n\n\t\n\t\t\n\t\tOutput\n\t\n\nOutput is corrected sentence with minimal adjustments and list all gramma corrections and explanations.\n\n\t\n\t\t\n\t\tDataset creationâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/honzatoegel/lola-gramma-de-en.","url":"https://huggingface.co/datasets/honzatoegel/lola-gramma-de-en","creator_name":"Jan Toegel","creator_url":"https://huggingface.co/honzatoegel","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["German","English","apache-2.0","< 1K","csv"],"keywords_longer_than_N":true},
	{"name":"iva_mt_wslot","keyword":"german","description":"\\","url":"https://huggingface.co/datasets/cartesinus/iva_mt_wslot","creator_name":"Marcin Sowanski","creator_url":"https://huggingface.co/cartesinus","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":null,"first_N":5,"first_N_keywords":["translation","English","Polish","German","Spanish"],"keywords_longer_than_N":true},
	{"name":"fleurs-hs","keyword":"german","description":"\n\t\n\t\t\n\t\tFLEURS-HS\n\t\n\nAn extension of the FLEURS dataset for synthetic speech detection using text-to-speech, featured in the paper Synthetic speech detection with Wav2Vec 2.0 in various language settings.\nThis dataset is 1 of 3 used in the paper, the others being:\n\nFLEURS-HS VITS\ntest set containing (generally) more difficult synthetic samples\nseparated due to different licensing\n\n\nARCTIC-HS\nextension of the CMU_ARCTIC and L2-ARCTIC sets in a similar manner\n\n\n\n\t\n\t\t\n\t\tDataset Detailsâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/realnetworks-kontxt/fleurs-hs.","url":"https://huggingface.co/datasets/realnetworks-kontxt/fleurs-hs","creator_name":"KONTXT by RealNetworks","creator_url":"https://huggingface.co/realnetworks-kontxt","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":null,"first_N":5,"first_N_keywords":["audio-classification","German","English","Spanish","French"],"keywords_longer_than_N":true},
	{"name":"synthetic-multi-pii-ner-v1","keyword":"german","description":"\n\t\n\t\t\n\t\tSynthetic Multilingual PII NER Dataset\n\t\n\n\n\t\n\t\t\n\t\tModels Trained Using this Dataset\n\t\n\n\nE3-JSI/gliner-multi-pii-domains-v1\n\n\n\t\n\t\t\n\t\tDescription\n\t\n\nThis is a synthetic dataset created for the purposes for training multilingual personally identifiable information (PII) named entity recognition (NER) models.\nThe examples were generated using a prompt that generates the text and the entities present in the text. In addition, the generated response had to follow the restrictions:\n\ntheâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/E3-JSI/synthetic-multi-pii-ner-v1.","url":"https://huggingface.co/datasets/E3-JSI/synthetic-multi-pii-ner-v1","creator_name":"Department for Artificial Intelligence, JoÅ¾ef Stefan Institute","creator_url":"https://huggingface.co/E3-JSI","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["token-classification","English","French","German","Greek"],"keywords_longer_than_N":true},
	{"name":"arena-hard-v2-verifiers","keyword":"german","description":"\n\t\n\t\t\n\t\tArena-Hard v2.0 - Verifiers Format\n\t\n\nThis dataset contains Arena-Hard v2.0 in Verifiers-compatible format for LLM evaluation.\n\n\t\n\t\t\n\t\tðŸ“Š Dataset Information\n\t\n\n\nVersion: Arena-Hard v2.0\nExamples: 750\nModel Answers: deepseek-r1\nJudge: gpt-4.1\nFormat: Verifiers-compatible HuggingFace Dataset\nLicense: Apache 2.0\n\n\n\t\n\t\t\n\t\tðŸŽ¯ Categories\n\t\n\n\nHard Prompts (500 examples): Challenging coding, math, and reasoning tasks\nCoding: 253 examples\nMath: 247 examples\n\n\nCreative Writing (250 examples):â€¦ See the full description on the dataset page: https://huggingface.co/datasets/Anna4242/arena-hard-v2-verifiers.","url":"https://huggingface.co/datasets/Anna4242/arena-hard-v2-verifiers","creator_name":"D","creator_url":"https://huggingface.co/Anna4242","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","question-answering","English","Spanish","French"],"keywords_longer_than_N":true},
	{"name":"test_llm_dataset","keyword":"german","description":"\n\t\n\t\t\n\t\tModel Card for Mixtral-8x7B\n\t\n\nThe Mixtral-8x7B Large Language Model (LLM) is a pretrained generative Sparse Mixture of Experts. The Mixtral-8x7B outperforms Llama 2 70B on most benchmarks we tested.\nFor full details of this model please read our release blog post.\n\n\t\n\t\t\n\t\tWarning\n\t\n\nThis repo contains weights that are compatible with vLLM serving of the model as well as Hugging Face transformers library. It is based on the original Mixtral torrent release, but the file format andâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/youssefoud/test_llm_dataset.","url":"https://huggingface.co/datasets/youssefoud/test_llm_dataset","creator_name":"Youssef Oudghiri","creator_url":"https://huggingface.co/youssefoud","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["French","Italian","German","Spanish","English"],"keywords_longer_than_N":true},
	{"name":"lib3m_qa_dataset_v1","keyword":"german","description":"\n\t\n\t\t\n\t\tLibertarian Large Language Model QA Dataset (Lib3M QAD)\n\t\n\nVersion: 1.0.0\nThis repository contains a large-scale Question-Answer (QA) dataset generated from libertarian literature and content. The dataset is designed to help train and fine-tune language models with libertarian economic and philosophical concepts.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset consists of question-answer pairs automatically generated from a curated collection of libertarian books and content. The data isâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/lib3m/lib3m_qa_dataset_v1.","url":"https://huggingface.co/datasets/lib3m/lib3m_qa_dataset_v1","creator_name":"Libertarian Padawan","creator_url":"https://huggingface.co/lib3m","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["English","German","mit","100K - 1M","parquet"],"keywords_longer_than_N":true},
	{"name":"c4","keyword":"german","description":"\n\t\n\t\t\n\t\tC4\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nA colossal, cleaned version of Common Crawl's web crawl corpus. Based on Common Crawl dataset: \"https://commoncrawl.org\".\nThis is the processed version of Google's C4 dataset\nWe prepared five variants of the data: en, en.noclean, en.noblocklist, realnewslike, and multilingual (mC4).\nFor reference, these are the sizes of the variants:\n\nen: 305GB\nen.noclean: 2.3TB\nen.noblocklist: 380GB\nrealnewslike: 15GB\nmultilingual (mC4): 9.7TB (108 subsets, one perâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/allenai/c4.","url":"https://huggingface.co/datasets/allenai/c4","creator_name":"Ai2","creator_url":"https://huggingface.co/allenai","license_name":"Open Data Commons Attribution License v1.0","license_url":"https://scancode-licensedb.aboutcode.org/odc-by-1.0.html","language":"en","first_N":5,"first_N_keywords":["text-generation","fill-mask","language-modeling","masked-language-modeling","no-annotation"],"keywords_longer_than_N":true},
	{"name":"wmt-mqm-error-spans","keyword":"german","description":"\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset contains all MQM human annotations from previous WMT Metrics shared tasks and the MQM annotations from Experts, Errors, and Context in a form of error spans. Moreover, it contains some hallucinations used in the training of XCOMET models.\nPlease note that this is not an official release of the data and the original data can be found here.\nThe data is organised into 8 columns:\n\nsrc: input text\nmt: translation\nref: reference translation\nannotations: Listâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/RicardoRei/wmt-mqm-error-spans.","url":"https://huggingface.co/datasets/RicardoRei/wmt-mqm-error-spans","creator_name":"Ricardo Rei","creator_url":"https://huggingface.co/RicardoRei","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["English","German","Russian","Chinese","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"openassistant-guanaco-de","keyword":"german","description":"This is only a Copy of the Work of OpenAssistant and the user timdettmers \nTarget of this trainingdata is finetuning only in German language.\nFile openassistant_origfile_with_lang_informations.txt is the full trainingdata. Every line starts with Language Informations. You can easily filter with:\ncat openassistant_origfile_with_lang_informations.txt | grep ^de | sed s/^de,//g > openassistant_best_replies_de_train.jsonl\nReplace ^de with the language you are interessted in.\nFor language detectionâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/RainerGa/openassistant-guanaco-de.","url":"https://huggingface.co/datasets/RainerGa/openassistant-guanaco-de","creator_name":"Rainer Garbotz","creator_url":"https://huggingface.co/RainerGa","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["German","apache-2.0","< 1K","json","Text"],"keywords_longer_than_N":true},
	{"name":"german-function-calling","keyword":"german","description":"flozi00/german-function-calling dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/flozi00/german-function-calling","creator_name":"Florian Zimmermeister","creator_url":"https://huggingface.co/flozi00","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["German","apache-2.0","1K - 10K","json","Text"],"keywords_longer_than_N":true},
	{"name":"distilabel-math-preference-dpo-de","keyword":"german","description":"German azureml translation of argilla/distilabel-math-preference-dpo\nfor dpo finetuning.\n","url":"https://huggingface.co/datasets/mayflowergmbh/distilabel-math-preference-dpo-de","creator_name":"Mayflower GmbH","creator_url":"https://huggingface.co/mayflowergmbh","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","German","apache-2.0","1K - 10K","json"],"keywords_longer_than_N":true},
	{"name":"NLU-few-shot-benchmark-en-de","keyword":"german","description":"\n\t\n\t\t\n\t\tNLU Few-shot Benchmark - English and German\n\t\n\nThis is a few-shot training dataset from the domain of human-robot interaction.\nIt contains texts in German and English language with 64 different utterances (classes).\nEach utterance (class) has exactly 20 samples in the training set.\nThis leads to a total of 1280 different training samples.\nThe dataset is intended to benchmark the intent classifiers of chat bots in English and especially in German language.\nWe are building on ourâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/deutsche-telekom/NLU-few-shot-benchmark-en-de.","url":"https://huggingface.co/datasets/deutsche-telekom/NLU-few-shot-benchmark-en-de","creator_name":"Deutsche Telekom AG","creator_url":"https://huggingface.co/deutsche-telekom","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","intent-classification","multilingual","extended|deutsche-telekom/NLU-Evaluation-Data-en-de","English"],"keywords_longer_than_N":true},
	{"name":"germandpr","keyword":"german","description":"We take GermanQuAD as a starting point and add hard negatives from a dump of the full German Wikipedia following the approach of the DPR authors (Karpukhin et al., 2020). The format of the dataset also resembles the one of DPR. GermanDPR comprises 9275 question/answer pairs in the training set and 1025 pairs in the test set. For each pair, there are one positive context and three hard negative contexts.","url":"https://huggingface.co/datasets/deepset/germandpr","creator_name":"deepset","creator_url":"https://huggingface.co/deepset","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":null,"first_N":5,"first_N_keywords":["question-answering","text-retrieval","extractive-qa","closed-domain-qa","monolingual"],"keywords_longer_than_N":true},
	{"name":"tweetyface_debug","keyword":"german","description":"DEBUG DATASET","url":"https://huggingface.co/datasets/ML-Projects-Kiel/tweetyface_debug","creator_name":"Machine Learning Projects FH Kiel","creator_url":"https://huggingface.co/ML-Projects-Kiel","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","machine-generated","crowdsourced","multilingual","English"],"keywords_longer_than_N":true},
	{"name":"udhr-lid","keyword":"german","description":"\n\t\n\t\t\n\t\tUDHR-LID\n\t\n\nWhy UDHR-LID?\nYou can access UDHR (Universal Declaration of Human Rights) here, but when a verse is missing, they have texts such as \"missing\" or \"?\". Also, about 1/3 of the sentences consist only of \"articles 1-30\" in different languages. We cleaned the entire dataset from XML files and selected only the paragraphs. We cleared any unrelated language texts from the data and also removed the cases that were incorrect.\nIncorrect? Look at the ckb and kmr files in the UDHR.â€¦ See the full description on the dataset page: https://huggingface.co/datasets/cis-lmu/udhr-lid.","url":"https://huggingface.co/datasets/cis-lmu/udhr-lid","creator_name":"CIS, LMU Munich","creator_url":"https://huggingface.co/cis-lmu","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["multilingual","Tigrinya","Balkan Romani","Standard Arabic","MetlatÃ³noc Mixtec"],"keywords_longer_than_N":true},
	{"name":"mqa","keyword":"german","description":"MQA is a multilingual corpus of questions and answers parsed from the Common Crawl. Questions are divided between Frequently Asked Questions (FAQ) pages and Community Question Answering (CQA) pages.","url":"https://huggingface.co/datasets/clips/mqa","creator_name":"CLiPS","creator_url":"https://huggingface.co/clips","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["question-answering","multiple-choice-qa","no-annotation","other","multilingual"],"keywords_longer_than_N":true},
	{"name":"udhr-lid","keyword":"swiss german","description":"\n\t\n\t\t\n\t\tUDHR-LID\n\t\n\nWhy UDHR-LID?\nYou can access UDHR (Universal Declaration of Human Rights) here, but when a verse is missing, they have texts such as \"missing\" or \"?\". Also, about 1/3 of the sentences consist only of \"articles 1-30\" in different languages. We cleaned the entire dataset from XML files and selected only the paragraphs. We cleared any unrelated language texts from the data and also removed the cases that were incorrect.\nIncorrect? Look at the ckb and kmr files in the UDHR.â€¦ See the full description on the dataset page: https://huggingface.co/datasets/cis-lmu/udhr-lid.","url":"https://huggingface.co/datasets/cis-lmu/udhr-lid","creator_name":"CIS, LMU Munich","creator_url":"https://huggingface.co/cis-lmu","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["multilingual","Tigrinya","Balkan Romani","Standard Arabic","MetlatÃ³noc Mixtec"],"keywords_longer_than_N":true},
	{"name":"CC-Cat","keyword":"german","description":"\n\t\n\t\t\n\t\tCC_Cat\n\t\n\n\nExtract from CC-WARC snapshots.\nMainly includes texts with 149 languages.\nPDF/IMAGE/AUDIO/VIDEO raw downloading link.\n\n\n\t\n\t\t\n\t\tNotice\n\t\n\n\nSince my computing resources are limited, this dataset will update by one-day of CC snapshots timestampts.\nAfter a snapshot is updated, the deduplicated version will be uploaded.\nIf you are interested in providing computing resources or have cooperation needs, please contact me.\n  carreyallthetime@gmail.com  \n      \n  \n\n","url":"https://huggingface.co/datasets/chengshidehaimianti/CC-Cat","creator_name":"zyq","creator_url":"https://huggingface.co/chengshidehaimianti","license_name":"Open Data Commons Attribution License v1.0","license_url":"https://scancode-licensedb.aboutcode.org/odc-by-1.0.html","language":"en","first_N":5,"first_N_keywords":["text-generation","Chinese","English","German","Russian"],"keywords_longer_than_N":true},
	{"name":"GSM8KInstruct_Parallel","keyword":"german","description":"Mathoctopus/GSM8KInstruct_Parallel dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/Mathoctopus/GSM8KInstruct_Parallel","creator_name":"Mathoctopus","creator_url":"https://huggingface.co/Mathoctopus","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["question-answering","English","Chinese","Spanish","French"],"keywords_longer_than_N":true},
	{"name":"YouTube-Commons","keyword":"german","description":"\n\t\n\t\t\n\t\tðŸ“º YouTube-Commons ðŸ“º\n\t\n\nYouTube-Commons is a collection of audio transcripts of 2,063,066 videos shared on YouTube under a CC-By license.\n\n\t\n\t\t\n\t\tContent\n\t\n\nThe collection comprises 22,709,724 original and automatically translated transcripts from 3,156,703 videos (721,136 individual channels).\nIn total, this represents nearly 45 billion words (44,811,518,375).\nAll the videos where shared on YouTube with a CC-BY license: the dataset provide all the necessary provenance informationâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/PleIAs/YouTube-Commons.","url":"https://huggingface.co/datasets/PleIAs/YouTube-Commons","creator_name":"PleIAs","creator_url":"https://huggingface.co/PleIAs","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":null,"first_N":5,"first_N_keywords":["text-generation","English","French","Spanish","Portuguese"],"keywords_longer_than_N":true},
	{"name":"denner-ch-products","keyword":"german","description":"\n\t\n\t\t\n\t\tDenner Switzerland Products\n\t\n\nAll products and their information from Denner Switzerland.\nThe entire catalogue and the current special discounts are all included.\nProduct information contains:\n\nName\nPrice\nPrice Text\nUnit of product\nUnit price\nIf it is discounted\nDiscount information\nProduct category\nImage URL\nProduct URL\n\nCheck out similar datasets for other grocery stores\n\nhttps://huggingface.co/datasets/Yelinz/lidl-ch-productsâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Yelinz/denner-ch-products.","url":"https://huggingface.co/datasets/Yelinz/denner-ch-products","creator_name":"Yelin Z.","creator_url":"https://huggingface.co/Yelinz","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","German","cc-by-4.0","10K - 100K","csv"],"keywords_longer_than_N":true},
	{"name":"oasst2","keyword":"german","description":"\n\t\n\t\t\n\t\tOpen Assistant Conversations Dataset Release 2 (OASST2)\n\t\n\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nThis dataset contains message trees. Each message tree has an initial prompt message as the root node, \nwhich can have multiple child messages as replies, and these child messages can have multiple replies. \nAll messages have a role property: this can either be \"assistant\" or \"prompter\". The roles in \nconversation threads from prompt to leaf node strictly alternate between \"prompter\" andâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/OpenAssistant/oasst2.","url":"https://huggingface.co/datasets/OpenAssistant/oasst2","creator_name":"OpenAssistant","creator_url":"https://huggingface.co/OpenAssistant","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["English","Spanish","Russian","German","Polish"],"keywords_longer_than_N":true},
	{"name":"medicinal-plants","keyword":"german","description":"A growing dataset about medicinal plants. We plan to construct a multimodal dataset with images and text content extracted from \n\nbooks that went out of copywrite and \ndiverse and high-quality video data taken via smart phone and various lenses with a DSLR camera (24mm Macro, 50mm, 100mm Macro and a 24-120mm Zoom lens).\nParts of the iNaturalist and PlantNet300K datasets will be integrated as well to cover a wide spectrum of the kingdom Plantae.\n\nThe resulting dataset should be able to power aâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/mikehemberger/medicinal-plants.","url":"https://huggingface.co/datasets/mikehemberger/medicinal-plants","creator_name":"Mike Hemberger","creator_url":"https://huggingface.co/mikehemberger","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["question-answering","translation","summarization","feature-extraction","English"],"keywords_longer_than_N":true},
	{"name":"MultiSim","keyword":"german","description":"MultiSim is a growing collection of Text Simplfication datasets in multiple languages.  Each dataset is a set of complex and simple sentence pairs.","url":"https://huggingface.co/datasets/MichaelR207/MultiSim","creator_name":"Michael Ryan","creator_url":"https://huggingface.co/MichaelR207","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":null,"first_N":5,"first_N_keywords":["summarization","text-generation","English","French","Russian"],"keywords_longer_than_N":true},
	{"name":"fleurs","keyword":"german","description":"\n\t\n\t\t\n\t\tFLEURS\n\t\n\nFleurs is the speech version of the FLoRes machine translation benchmark. \nWe use 2009 n-way parallel sentences from the FLoRes dev and devtest publicly available sets, in 102 languages. \nTraining sets have around 10 hours of supervision. Speakers of the train sets are different than speakers from the dev/test sets. Multilingual fine-tuning is\nused and â€unit error rateâ€ (characters, signs) of all languages is averaged. Languages and results are also grouped into sevenâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/google/fleurs.","url":"https://huggingface.co/datasets/google/fleurs","creator_name":"Google","creator_url":"https://huggingface.co/google","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":null,"first_N":5,"first_N_keywords":["automatic-speech-recognition","expert-generated","crowdsourced","machine-generated","crowdsourced"],"keywords_longer_than_N":true},
	{"name":"wikipedia-22-12-de-embeddings","keyword":"german","description":"\n\t\n\t\t\n\t\tWikipedia (de) embedded with cohere.ai multilingual-22-12 encoder\n\t\n\nWe encoded Wikipedia (de) using the cohere.ai multilingual-22-12 embedding model.\nTo get an overview how this dataset was created and pre-processed, have a look at Cohere/wikipedia-22-12.\n\n\t\n\t\t\n\t\n\t\n\t\tEmbeddings\n\t\n\nWe compute for title+\" \"+text the embeddings using our multilingual-22-12 embedding model, a state-of-the-art model that works for semantic search in 100 languages.  If you want to learn more about thisâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Cohere/wikipedia-22-12-de-embeddings.","url":"https://huggingface.co/datasets/Cohere/wikipedia-22-12-de-embeddings","creator_name":"Cohere","creator_url":"https://huggingface.co/Cohere","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","expert-generated","multilingual","German"],"keywords_longer_than_N":true},
	{"name":"tapaco","keyword":"german","description":"\n\t\n\t\t\n\t\tDataset Card for TaPaCo Corpus\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nA freely available paraphrase corpus for 73 languages extracted from the Tatoeba database. \nTatoeba is a crowdsourcing project mainly geared towards language learners. Its aim is to provide example sentences \nand translations for particular linguistic constructions and words. The paraphrase corpus is created by populating a \ngraph with Tatoeba sentences and equivalence links between sentences â€œmeaning the same thingâ€. Thisâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/community-datasets/tapaco.","url":"https://huggingface.co/datasets/community-datasets/tapaco","creator_name":"Community Datasets","creator_url":"https://huggingface.co/community-datasets","license_name":"Creative Commons Attribution 2.0","license_url":"https://scancode-licensedb.aboutcode.org/cc-by-2.0.html","language":"en","first_N":5,"first_N_keywords":["translation","text-classification","semantic-similarity-classification","machine-generated","crowdsourced"],"keywords_longer_than_N":true},
	{"name":"saf_legal_domain_german","keyword":"german","description":"\n\t\n\t\t\n\t\tDataset Card for \"saf_legal_domain_german\"\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis Short Answer Feedback (SAF) dataset contains 19 German questions in the domain of the German social law (with reference answers). The idea of constructing a bilingual (English and German) short answer dataset as a way to remedy the lack of content-focused feedback datasets was introduced in Your Answer is Incorrect... Would you like to know why? Introducing a Bilingual Shortâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Short-Answer-Feedback/saf_legal_domain_german.","url":"https://huggingface.co/datasets/Short-Answer-Feedback/saf_legal_domain_german","creator_name":"Short Answer Feedback Interest Group","creator_url":"https://huggingface.co/Short-Answer-Feedback","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["expert-generated","other","monolingual","original","German"],"keywords_longer_than_N":true},
	{"name":"mkqa","keyword":"german","description":"We introduce MKQA, an open-domain question answering evaluation set comprising 10k question-answer pairs sampled from the Google Natural Questions dataset, aligned across 26 typologically diverse languages (260k question-answer pairs in total). For each query we collected new passage-independent answers. These queries and answers were then human translated into 25 Non-English languages.","url":"https://huggingface.co/datasets/apple/mkqa","creator_name":"Apple","creator_url":"https://huggingface.co/apple","license_name":"Creative Commons Attribution 3.0","license_url":"https://scancode-licensedb.aboutcode.org/cc-by-3.0.html","language":null,"first_N":5,"first_N_keywords":["question-answering","open-domain-qa","crowdsourced","found","multilingual"],"keywords_longer_than_N":true},
	{"name":"german-czech-paired-placenames","keyword":"german","description":"\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset contains the German and corresponding Czech names for almost 5k places in Czech Republic. It has been generated using this code.\nMany of these names are related to each other. Some German names are literal translation of the Czech names (or maybe the other way around), some are phonetic modifications while some are unrelated.\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Creation\n\t\n\n\n\t\n\t\t\n\t\n\t\n\t\tSource Data\n\t\n\nEnglish wiki page containing German exonyms for places in Czech Republic\n","url":"https://huggingface.co/datasets/DebasishDhal99/german-czech-paired-placenames","creator_name":"Debasish Dhal","creator_url":"https://huggingface.co/DebasishDhal99","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["translation","German","Czech","mit","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"Tilde-MODEL-Catalan","keyword":"german","description":"\n\t\n\t\t\n\t\tDataset Card for Tilde-MODEL-Catalan\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset contains the German version of the Tilde-MODEL corpus aligned with a Catalan translation.\nThe catalan text has been obtained using Apertium's RBMT system from the Spanish version. It contains 3.4M segments.\n\n\t\n\t\t\n\t\tSupported Tasks and Leaderboards\n\t\n\nThis dataset can be used to train NMT and SMT systems.\nIt has been used as a training corpus for the SoftcatalÃ  machine translation engine.\n\n\t\n\t\t\n\t\tLanguagesâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/softcatala/Tilde-MODEL-Catalan.","url":"https://huggingface.co/datasets/softcatala/Tilde-MODEL-Catalan","creator_name":"SoftcatalÃ ","creator_url":"https://huggingface.co/softcatala","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["translation","machine-generated","translation","extended|tilde_model","Catalan"],"keywords_longer_than_N":true},
	{"name":"multi_para_crawl","keyword":"german","description":"Parallel corpora from Web Crawls collected in the ParaCrawl project and further processed for making it a multi-parallel corpus by pivoting via English. Here we only provide the additional language pairs that came out of pivoting. The bitexts for English are available from the ParaCrawl release.\n40 languages, 669 bitexts\ntotal number of files: 40\ntotal number of tokens: 10.14G\ntotal number of sentence fragments: 505.48M\n\nPlease, acknowledge the ParaCrawl project at http://paracrawl.eu. This version is derived from the original release at their website adjusted for redistribution via the OPUS corpus collection. Please, acknowledge OPUS as well for this service.","url":"https://huggingface.co/datasets/Helsinki-NLP/multi_para_crawl","creator_name":"Language Technology Research Group at the University of Helsinki","creator_url":"https://huggingface.co/Helsinki-NLP","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":null,"first_N":5,"first_N_keywords":["translation","found","found","multilingual","original"],"keywords_longer_than_N":true},
	{"name":"germanquad-retrieval-qrels","keyword":"german","description":"This dataset is derived from the GermanQuAD dataset.\nThis dataset takes the testset and represents it as qrels in the BEIR information retrieval benchmark format.\nCorpus and query ids have been added.\nThe corresponding corpus can be found here.\nFull credit for the original dataset goes to the authors of the GermanQuAD dataset.\nThe original dataset is licensed under CC BY-SA 4.0.\nCitation for the original dataset:\n@misc{mÃ¶ller2021germanquad,\n      title={GermanQuAD and GermanDPR: Improvingâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/germanquad-retrieval-qrels.","url":"https://huggingface.co/datasets/mteb/germanquad-retrieval-qrels","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["deepset/germanquad","German","cc-by-4.0","1K - 10K","arrow"],"keywords_longer_than_N":true},
	{"name":"APIS_OEBL__Abbreviations","keyword":"german","description":"CoNLL-U(ish) file of 954 sentences of 164 texts, containing abbreviations and their extensions.\n\n\t\n\t\t\n\t\tsource\n\t\n\nThe original data was extracted from the Austrian Biographical Lexicon (Ã–BL) in the context of the Austrian Prosopographical Information System (APIS) project.\nFrom there, samples were randomly pulled and annotated for Named Entity Recognition tasks, which form this dataset.\nThe texts concern numerous smaller biographies in the time period between 19th and early 20th century withinâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/SteffRhes/APIS_OEBL__Abbreviations.","url":"https://huggingface.co/datasets/SteffRhes/APIS_OEBL__Abbreviations","creator_name":"Stefan Resch","creator_url":"https://huggingface.co/SteffRhes","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["token-classification","German","mit","ðŸ‡ºðŸ‡¸ Region: US"],"keywords_longer_than_N":false},
	{"name":"MSVAMP","keyword":"german","description":"Mathoctopus/MSVAMP dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/Mathoctopus/MSVAMP","creator_name":"Mathoctopus","creator_url":"https://huggingface.co/Mathoctopus","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","Bengali","Chinese","English","French"],"keywords_longer_than_N":true},
	{"name":"ml_spoken_words","keyword":"german","description":"Multilingual Spoken Words Corpus is a large and growing audio dataset of spoken\nwords in 50 languages collectively spoken by over 5 billion people, for academic\nresearch and commercial applications in keyword spotting and spoken term search,\nlicensed under CC-BY 4.0. The dataset contains more than 340,000 keywords,\ntotaling 23.4 million 1-second spoken examples (over 6,000 hours). The dataset\nhas many use cases, ranging from voice-enabled consumer devices to call center\nautomation. This dataset is generated by applying forced alignment on crowd-sourced sentence-level\naudio to produce per-word timing estimates for extraction.\nAll alignments are included in the dataset.","url":"https://huggingface.co/datasets/MLCommons/ml_spoken_words","creator_name":"MLCommons","creator_url":"https://huggingface.co/MLCommons","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":null,"first_N":5,"first_N_keywords":["audio-classification","machine-generated","other","multilingual","extended|common_voice"],"keywords_longer_than_N":true},
	{"name":"swissner","keyword":"german","description":"\n\t\n\t\t\n\t\tSwissNER\n\t\n\nA multilingual test set for named entity recognition (NER) on Swiss news articles.\n\n\t\n\t\t\n\t\tDescription\n\t\n\nSwissNER is a dataset for named entity recognition based on manually annotated news articles in Swiss Standard German, French, Italian, and Romansh Grischun.\nWe have manually annotated a selection of articles that have been published in February 2023 in the categories \"Switzerland\" or \"Regional\" on the following online news portals:\n\nSwiss Standard German: srf.châ€¦ See the full description on the dataset page: https://huggingface.co/datasets/ZurichNLP/swissner.","url":"https://huggingface.co/datasets/ZurichNLP/swissner","creator_name":"University of Zurich, Department of Computational Linguistics","creator_url":"https://huggingface.co/ZurichNLP","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["token-classification","named-entity-recognition","multilingual","German","French"],"keywords_longer_than_N":true},
	{"name":"tinystories_german","keyword":"german","description":"\n\t\n\t\t\n\t\tWhat have you done\n\t\n\nthis dataset is a german interpretation of the roneneldan/TinyStories dataset\nthat dataset is amazing- I wanted to make a german version to experiment with the bilinguality of tiny language models (more coming on that soon!!!) (i wrote a paper :D)\nthis is the result of a bunch of work and months of screwing around\nit was made with basically 0 budget; \n\nargos-translate contains 200k opennmt translated tinystories\ngerman_GEMINI_async-combined contains about 180kâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/SkySyrup/tinystories_german.","url":"https://huggingface.co/datasets/SkySyrup/tinystories_german","creator_name":"Ashley","creator_url":"https://huggingface.co/SkySyrup","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["German","apache-2.0","1M - 10M","text","Text"],"keywords_longer_than_N":true},
	{"name":"mqnli","keyword":"german","description":"SachinPatel248/mqnli dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/SachinPatel248/mqnli","creator_name":"Patel","creator_url":"https://huggingface.co/SachinPatel248","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","English","German","Spanish","Arabic"],"keywords_longer_than_N":true},
	{"name":"openassistant-llama-style","keyword":"german","description":"\n\t\n\t\t\n\t\tChat Fine-tuning Dataset - Llama 2 Style\n\t\n\nThis dataset allows for fine-tuning chat models using [INST] AND [/INST] to wrap user messages.\nPreparation:\n\nThe dataset is cloned from TimDettmers, which itself is a subset of the Open Assistant dataset, which you can find here. This subset of the data only contains the highest-rated paths in the conversation tree, with a total of 9,846 samples.\nThe dataset was then filtered to:\n\n\nreplace instances of '### Human:' with '[INST]'\nreplaceâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Trelis/openassistant-llama-style.","url":"https://huggingface.co/datasets/Trelis/openassistant-llama-style","creator_name":"Trelis","creator_url":"https://huggingface.co/Trelis","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["English","Spanish","Russian","German","Polish"],"keywords_longer_than_N":true},
	{"name":"mapa-eur-lex","keyword":"german","description":"\n\t\n\t\t\n\t\tDataset Card for Multilingual European Datasets for Sensitive Entity Detection in the Legal Domain\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset is a completed version of the MAPA EUR-LEX dataset, originally converted to Huggingface format by joelniklaus. See the dataset card for more information about MAPA.\n3 of the (Spanish) EUR-LEX WebAnno TSV files in the source MAPA repository are malformed, so they were omitted from the original conversion, causing under-representation of theâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/dglover1/mapa-eur-lex.","url":"https://huggingface.co/datasets/dglover1/mapa-eur-lex","creator_name":"D Glover","creator_url":"https://huggingface.co/dglover1","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["token-classification","named-entity-recognition","other","found","multilingual"],"keywords_longer_than_N":true},
	{"name":"lawinstruct","keyword":"german","description":"LawInstruct is an instruction tuning dataset of multilingual legal documents.","url":"https://huggingface.co/datasets/lawinstruct/lawinstruct","creator_name":"lawinstruct","creator_url":"https://huggingface.co/lawinstruct","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":null,"first_N":5,"first_N_keywords":["fill-mask","other","found","multilingual","original"],"keywords_longer_than_N":true},
	{"name":"gahd","keyword":"german","description":"\n\t\n\t\t\n\t\tDataset Card for GAHD\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nGAHD is a German Adversarial Hate speech Dataset containing 10,996 examples. We collected the dataset via four rounds of Dynamic Adversarial Data Collection and explored various methods of supporting annotators in finding adversarial examples.\n\nPaper: https://aclanthology.org/2024.naacl-long.248/\nRepository: https://github.com/jagol/gahd\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Structure\n\t\n\ngahd.csv contains the following columns:\n\ngahd_id: uniqueâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/jagoldz/gahd.","url":"https://huggingface.co/datasets/jagoldz/gahd","creator_name":"Janis Goldzycher","creator_url":"https://huggingface.co/jagoldz","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","German","cc-by-4.0","10K<n<100K","ðŸ‡ºðŸ‡¸ Region: US"],"keywords_longer_than_N":true},
	{"name":"jinaai_jina-embeddings-v2-base-en-03092024-eh35-webapp","keyword":"german","description":"\n\t\n\t\t\n\t\tjinaai_jina-embeddings-v2-base-en-03092024-eh35-webapp Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"health insurance domain\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the jinaai_jina-embeddings-v2-base-en-03092024-eh35-webapp model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Faceâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/jinaai_jina-embeddings-v2-base-en-03092024-eh35-webapp.","url":"https://huggingface.co/datasets/fine-tuned/jinaai_jina-embeddings-v2-base-en-03092024-eh35-webapp","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","German","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"selbstwahrnehmung-buch-rezensionen-pressestimmen-2025","keyword":"german","description":"\n\t\n\t\t\n\t\tRezensionen & Pressestimmen â€“ Selbstwahrnehmung mit allen Sinnen (2025)\n\t\n\nDeutschsprachiges KI-Dataset zum Buch Selbstwahrnehmung mit allen Sinnen (Psychosozial-Verlag, 2025): Buchrezensionen, Pressestimmen und Blog-Reviews fÃ¼r Psychologie, Achtsamkeit und Mental Health.\n\n\n\t\n\t\t\n\t\tInhalte\n\t\n\n\ndataset_unified.json\ndataset_unified.csv\n\n\n\t\n\t\t\n\t\tDatenstruktur\n\t\n\nFelder: type (review/press/blog), title, author, credentials, source, date, rating, text, hashtags.\n\n\t\n\t\t\n\t\tVerwendung (Python)â€¦ See the full description on the dataset page: https://huggingface.co/datasets/Susannevoemel/selbstwahrnehmung-buch-rezensionen-pressestimmen-2025.","url":"https://huggingface.co/datasets/Susannevoemel/selbstwahrnehmung-buch-rezensionen-pressestimmen-2025","creator_name":"VÃ¶mel","creator_url":"https://huggingface.co/Susannevoemel","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["German","mit","< 1K","json","Text"],"keywords_longer_than_N":true},
	{"name":"selbstwahrnehmung-buch-rezensionen-pressestimmen-2025","keyword":"german","description":"\n\t\n\t\t\n\t\tRezensionen & Pressestimmen â€“ Selbstwahrnehmung mit allen Sinnen (2025)\n\t\n\nDeutschsprachiges KI-Dataset zum Buch Selbstwahrnehmung mit allen Sinnen (Psychosozial-Verlag, 2025): Buchrezensionen, Pressestimmen und Blog-Reviews fÃ¼r Psychologie, Achtsamkeit und Mental Health.\n\n\n\t\n\t\t\n\t\tInhalte\n\t\n\n\ndataset_unified.json\ndataset_unified.csv\n\n\n\t\n\t\t\n\t\tDatenstruktur\n\t\n\nFelder: type (review/press/blog), title, author, credentials, source, date, rating, text, hashtags.\n\n\t\n\t\t\n\t\tVerwendung (Python)â€¦ See the full description on the dataset page: https://huggingface.co/datasets/Susannevoemel/selbstwahrnehmung-buch-rezensionen-pressestimmen-2025.","url":"https://huggingface.co/datasets/Susannevoemel/selbstwahrnehmung-buch-rezensionen-pressestimmen-2025","creator_name":"VÃ¶mel","creator_url":"https://huggingface.co/Susannevoemel","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["German","mit","< 1K","json","Text"],"keywords_longer_than_N":true},
	{"name":"T5_german_summaries_filtered_convos","keyword":"german","description":"\n\t\n\t\t\n\t\tSynthetic Call Center Summaries Dataset T5 German\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset contains synthetic summaries of call center conversations generated by different prompt configurations.\nEach record (in JSON Lines format) includes:\n\nThe original dialogue metadata.\nA generated summary tailored to provide quick insights for call center service agents.\nEvaluation metrics\n\n\n\t\n\t\t\n\t\tInformation on model\n\t\n\n\nT-Systems-onsite/mt5-small-sum-de-en-v2\nsource_prefix: \"summarize: \"â€¦ See the full description on the dataset page: https://huggingface.co/datasets/marccgrau/T5_german_summaries_filtered_convos.","url":"https://huggingface.co/datasets/marccgrau/T5_german_summaries_filtered_convos","creator_name":"Marc Christopher Grau","creator_url":"https://huggingface.co/marccgrau","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["summarization","text-generation","synthetic","monolingual","German"],"keywords_longer_than_N":true},
	{"name":"jinaai_jina-embeddings-v2-base-en-03092024-2ayt-webapp","keyword":"german","description":"\n\t\n\t\t\n\t\tjinaai_jina-embeddings-v2-base-en-03092024-2ayt-webapp Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"health insurance information\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the jinaai_jina-embeddings-v2-base-en-03092024-2ayt-webapp model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Huggingâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/jinaai_jina-embeddings-v2-base-en-03092024-2ayt-webapp.","url":"https://huggingface.co/datasets/fine-tuned/jinaai_jina-embeddings-v2-base-en-03092024-2ayt-webapp","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","German","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"MX-CHAT","keyword":"german","description":"MX-CHAT 01\n","url":"https://huggingface.co/datasets/berwart/MX-CHAT","creator_name":"Berwart","creator_url":"https://huggingface.co/berwart","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["English","French","Spanish","Russian","German"],"keywords_longer_than_N":true},
	{"name":"amazon_massive_intent","keyword":"german","description":"\n  MassiveIntentClassification\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nMASSIVE: A 1M-Example Multilingual Natural Language Understanding Dataset with 51 Typologically-Diverse Languages\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2c\n\n\nDomains\nSpoken\n\n\nReference\nhttps://arxiv.org/abs/2204.08582\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask = mteb.get_tasks([\"MassiveIntentClassification\"])\nevaluator =â€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/amazon_massive_intent.","url":"https://huggingface.co/datasets/mteb/amazon_massive_intent","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","human-annotated","translated","Afrikaans","Amharic"],"keywords_longer_than_N":true},
	{"name":"degeneration-html-multilingual","keyword":"german","description":"\n\t\n\t\t\n\t\tThe Degeneration of the Nation Multilingual Dataset\n\t\n\nThis dataset contains the complete content of The Degeneration of the Nation project, a comprehensive philosophical and cultural website exploring the intersection of technology, artificial intelligence, and human culture. The content includes philosophical essays, cultural analysis, and contemporary literature, with complex parallel structure and sophisticated HTML architecture across all language versions.\n\n\t\n\t\t\n\t\n\t\n\t\tDatasetâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Degeneration-Nation/degeneration-html-multilingual.","url":"https://huggingface.co/datasets/Degeneration-Nation/degeneration-html-multilingual","creator_name":"The Degeneration of the Nation","creator_url":"https://huggingface.co/Degeneration-Nation","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["translation","text2text-generation","text-generation","text-classification","token-classification"],"keywords_longer_than_N":true},
	{"name":"jinaai_jina-embeddings-v2-base-de-932024-59f9-webapp","keyword":"german","description":"\n\t\n\t\t\n\t\tjinaai_jina-embeddings-v2-base-de-932024-59f9-webapp Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"health insurance information retrieval\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the jinaai_jina-embeddings-v2-base-de-932024-59f9-webapp model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using theâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/jinaai_jina-embeddings-v2-base-de-932024-59f9-webapp.","url":"https://huggingface.co/datasets/fine-tuned/jinaai_jina-embeddings-v2-base-de-932024-59f9-webapp","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","German","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"jinaai_jina-embeddings-v2-base-de-932024-59f9-webapp","keyword":"german","description":"\n\t\n\t\t\n\t\tjinaai_jina-embeddings-v2-base-de-932024-59f9-webapp Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"health insurance information retrieval\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the jinaai_jina-embeddings-v2-base-de-932024-59f9-webapp model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using theâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/jinaai_jina-embeddings-v2-base-de-932024-59f9-webapp.","url":"https://huggingface.co/datasets/fine-tuned/jinaai_jina-embeddings-v2-base-de-932024-59f9-webapp","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","German","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"BenchMAX_Model-based","keyword":"german","description":"\n\t\n\t\t\n\t\tDataset Sources\n\t\n\n\nPaper: BenchMAX: A Comprehensive Multilingual Evaluation Suite for Large Language Models\nLink: https://huggingface.co/papers/2502.07346\nRepository: https://github.com/CONE-MT/BenchMAX\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nBenchMAX_Model-based is a dataset of BenchMAX, sourcing from m-ArenaHard, which evaluates the instruction following capability via model-based judgment.\nWe extend the original dataset to include languages that are not supported by m-ArenaHard throughâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/LLaMAX/BenchMAX_Model-based.","url":"https://huggingface.co/datasets/LLaMAX/BenchMAX_Model-based","creator_name":"LLaMAX","creator_url":"https://huggingface.co/LLaMAX","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","multilingual","English","Chinese","Spanish"],"keywords_longer_than_N":true},
	{"name":"smartdata-corpus","keyword":"german","description":"\n\t\n\t\t\n\t\tDataset Card for SmartData Corpus\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nSmartData Corpus is a German-language dataset which is human-annotated with entity types and a set of 15 traffic- and \nindustry-related n-ary relations and events, such as accidents, traffic jams, acquisitions, and strikes. \nThe corpus consists of newswire texts, Twitter messages, and traffic reports from radio stations, police and \nrailway companies.\nThis version of the dataset loader provides configurations for:\n\nNamedâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/DFKI-SLT/smartdata-corpus.","url":"https://huggingface.co/datasets/DFKI-SLT/smartdata-corpus","creator_name":"Speech and Language Technology, DFKI","creator_url":"https://huggingface.co/DFKI-SLT","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","German","cc-by-4.0","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"belgian-journal","keyword":"german","description":"\n\t\n\t\t\n\t\tDataset Description\n\t\n\n\n\nDataset contains the metadata + the text of company bylaws publications of Belgian companies on the Belgian Journal (Moniteur Belge/Belgisch Staatstblad).\nThis data was collected by webscraping the Belgian Journal, for more info see: https://github.com/Guust-Franssens/belgian-journal.\n\nLanguage(s) (NLP): French, Dutch and a small subset German (official languages of Belgium.)\nLicense: Creative Commons Zero v1.0 Universal\n\n","url":"https://huggingface.co/datasets/guust-franssens/belgian-journal","creator_name":"Guust Franssens","creator_url":"https://huggingface.co/guust-franssens","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","fill-mask","language-modeling","masked-language-modeling","French"],"keywords_longer_than_N":true},
	{"name":"finepdfs","keyword":"swiss german","description":"\n\nLiberating 3T of the finest tokens from PDFs\n\n\n\t\n\t\t\n\t\tWhat is this?\n\t\n\nAs we run out of web pages to process, the natural question has always been: what to do next? Only a few knew about a data source that everyone avoided for ages, due to its incredible extraction cost and complexity: PDFs.\nðŸ“„ FinePDFs is exactly that. It is the largest publicly available corpus sourced exclusively from PDFs, containing about 3 trillion tokens across 475 million documents in 1733 languages.\nCompared to HTMLâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/HuggingFaceFW/finepdfs.","url":"https://huggingface.co/datasets/HuggingFaceFW/finepdfs","creator_name":"FineData","creator_url":"https://huggingface.co/HuggingFaceFW","license_name":"Open Data Commons Attribution License v1.0","license_url":"https://scancode-licensedb.aboutcode.org/odc-by-1.0.html","language":"en","first_N":5,"first_N_keywords":["text-generation","Arifama-Miniafia","Ankave","Abau","Amarasi"],"keywords_longer_than_N":true},
	{"name":"finepdfs","keyword":"german","description":"\n\nLiberating 3T of the finest tokens from PDFs\n\n\n\t\n\t\t\n\t\tWhat is this?\n\t\n\nAs we run out of web pages to process, the natural question has always been: what to do next? Only a few knew about a data source that everyone avoided for ages, due to its incredible extraction cost and complexity: PDFs.\nðŸ“„ FinePDFs is exactly that. It is the largest publicly available corpus sourced exclusively from PDFs, containing about 3 trillion tokens across 475 million documents in 1733 languages.\nCompared to HTMLâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/HuggingFaceFW/finepdfs.","url":"https://huggingface.co/datasets/HuggingFaceFW/finepdfs","creator_name":"FineData","creator_url":"https://huggingface.co/HuggingFaceFW","license_name":"Open Data Commons Attribution License v1.0","license_url":"https://scancode-licensedb.aboutcode.org/odc-by-1.0.html","language":"en","first_N":5,"first_N_keywords":["text-generation","Arifama-Miniafia","Ankave","Abau","Amarasi"],"keywords_longer_than_N":true},
	{"name":"AufenthG","keyword":"german","description":"YaTutarsa/AufenthG dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/YaTutarsa/AufenthG","creator_name":"BeN","creator_url":"https://huggingface.co/YaTutarsa","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["German","mit","< 1K","parquet","Text"],"keywords_longer_than_N":true},
	{"name":"LLMDebiasingBenchmark","keyword":"german","description":"DEPRECIATED: For latest version, see huggingface.co/datasets/nicaudinet/llm-debiasing-benchmark\n\n\t\n\t\t\n\t\tDataset Card for LLM Debiasing Benchmark\n\t\n\nUpdate: Release coming soon. \n\n\t\n\t\t\n\t\tDataset Description\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis repository hosts the LLM Debiasing Benchmark, a collection of datasets and annotations used to evaluate debiasing methods for Large Language Model (LLM)-based annotations in computational social science. The benchmark is based on the paper \nâ€ƒâ€ƒ Benchmarkingâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/JerzakLabs/LLMDebiasingBenchmark.","url":"https://huggingface.co/datasets/JerzakLabs/LLMDebiasingBenchmark","creator_name":"Jerzak Labs","creator_url":"https://huggingface.co/JerzakLabs","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":null,"first_N":5,"first_N_keywords":["English","German","mit","arxiv:2506.09627","ðŸ‡ºðŸ‡¸ Region: US"],"keywords_longer_than_N":true},
	{"name":"Question-Sparql","keyword":"german","description":"\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset contains 895,954 examples of natural language questions paired with their corresponding SPARQL queries. It spans 12 languages and targets 15 distinct knowledge graphs, with a significant portion focused on Wikidata and DBpedia.\nThe dataset was developed as a contribution for the Master Thesis: \"Impact of Continual Multilingual Pre-training on Cross-Lingual Transferability for Source Languages\". Its purpose is to facilitate research in text-to-SPARQLâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/julioc-p/Question-Sparql.","url":"https://huggingface.co/datasets/julioc-p/Question-Sparql","creator_name":"Julio Perez","creator_url":"https://huggingface.co/julioc-p","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-generation","English","German","Hebrew","Kannada"],"keywords_longer_than_N":true},
	{"name":"PangeaBench-xgqa","keyword":"german","description":"\n\t\n\t\t\n\t\txGQA\n\t\n\n\n\t\n\t\t\n\t\tThis is a clone of the few_shot-test split of the xGQA dataset\n\t\n\nPlease find the original repository here: https://github.com/adapter-hub/xGQA\nIf you use this dataset, please cite the original authors:\n@inproceedings{pfeiffer-etal-2021-xGQA,\n    title={{xGQA: Cross-Lingual Visual Question Answering}},\n    author={ Jonas Pfeiffer and Gregor Geigle and Aishwarya Kamath and Jan-Martin O. Steitz and Stefan Roth and Ivan Vuli{\\'{c}} and Iryna Gurevych},\n    booktitle =â€¦ See the full description on the dataset page: https://huggingface.co/datasets/neulab/PangeaBench-xgqa.","url":"https://huggingface.co/datasets/neulab/PangeaBench-xgqa","creator_name":"NeuLab @ LTI/CMU","creator_url":"https://huggingface.co/neulab","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["visual-question-answering","Bengali","German","English","Indonesian"],"keywords_longer_than_N":true},
	{"name":"EuroGEC-7","keyword":"german","description":"\n\t\n\t\t\n\t\tEuroGEC-7: A Growing Multilingual Dataset for Grammatical Error Correction\n\t\n\nEuroGEC-7 is a large-scale, synthetic, multilingual grammatical error correction (GEC) dataset created using the Mistral API. It is specifically designed to simulate learner-style grammar mistakes across 7 major European languages â€” with over 20,000 annotated pairs and counting.\nThis dataset is actively maintained and continuously expanding, both in scale and coverage. New entries are generated daily from aâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/NoeFlandre/EuroGEC-7.","url":"https://huggingface.co/datasets/NoeFlandre/EuroGEC-7","creator_name":"NoÃ© Flandre","creator_url":"https://huggingface.co/NoeFlandre","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["English","French","Spanish","German","Italian"],"keywords_longer_than_N":true},
	{"name":"Granary","keyword":"german","description":"\n\t\n\t\t\n\t\tGranary: Speech Recognition and Translation Dataset in 25 European Languages\n\t\n\nGranary is a large-scale, open-source multilingual speech dataset covering 25 European languages for Automatic Speech Recognition (ASR) and Automatic Speech Translation (AST) tasks. \n\n\n\n\t\n\t\t\n\n\n\n\n\t\t\n\n\n\n\n\t\n\n\n\n\n\n\t\n\t\n\t\n\t\tOverview\n\t\n\nGranary addresses the scarcity of high-quality speech data for low-resource languages by consolidating multiple datasets under a unified framework:\nðŸ—£ï¸ ~1M hours of high-qualityâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/nvidia/Granary.","url":"https://huggingface.co/datasets/nvidia/Granary","creator_name":"NVIDIA","creator_url":"https://huggingface.co/nvidia","license_name":"Creative Commons Attribution 3.0","license_url":"https://scancode-licensedb.aboutcode.org/cc-by-3.0.html","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","translation","Bulgarian","Czech","Danish"],"keywords_longer_than_N":true},
	{"name":"IdiomsInCtx-MT","keyword":"german","description":"\n\t\n\t\t\n\t\tIdiomsInCtx-MT Dataset\n\t\n\nThis repository contains the IdiomsInCtx-MT dataset used in our ACL 2024 paper: The Fine-Tuning Paradox: Boosting Translation Quality Without Sacrificing LLM Abilities. See this GitHub repo for the origin of the data.\n\n\t\n\t\t\n\t\n\t\n\t\tDescription\n\t\n\nThe dataset consists of idiomatic expressions in context and their human-written translations. There are 1000 translations per direction. The dataset covers 2 language pairs (English-German and English-Russian) with 3â€¦ See the full description on the dataset page: https://huggingface.co/datasets/davidstap/IdiomsInCtx-MT.","url":"https://huggingface.co/datasets/davidstap/IdiomsInCtx-MT","creator_name":"David Stap","creator_url":"https://huggingface.co/davidstap","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["expert-generated","translation","multilingual","German","English"],"keywords_longer_than_N":true},
	{"name":"BenchMAX_Problem_Solving","keyword":"german","description":"\n\t\n\t\t\n\t\tDataset Sources\n\t\n\n\nPaper: BenchMAX: A Comprehensive Multilingual Evaluation Suite for Large Language Models\nLink: https://huggingface.co/papers/2502.07346\nRepository: https://github.com/CONE-MT/BenchMAX\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nBenchMAX_Problem_Solving is a dataset of BenchMAX, sourcing from LiveCodeBench_v4, which evaluates the code generation capability for solving multilingual competitive code problems.\nWe extend the original English dataset by 16 non-English languages.\nTheâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/LLaMAX/BenchMAX_Problem_Solving.","url":"https://huggingface.co/datasets/LLaMAX/BenchMAX_Problem_Solving","creator_name":"LLaMAX","creator_url":"https://huggingface.co/LLaMAX","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","multilingual","English","Chinese","Spanish"],"keywords_longer_than_N":true},
	{"name":"xP3x","keyword":"german","description":"\n\t\n\t\t\n\t\tDataset Card for xP3x\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\n\nxP3x (Crosslingual Public Pool of Prompts eXtended) is a collection of prompts & datasets across 277 languages & 16 NLP tasks. It contains all of xP3 + much more! It is used for training future contenders of mT0 & BLOOMZ at project Aya @Cohere Labs ðŸ§¡\n\n\nCreation: The dataset can be recreated using instructions available here together with the file in this repository named xp3x_create.py. We provide this version to save processingâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/CohereLabs/xP3x.","url":"https://huggingface.co/datasets/CohereLabs/xP3x","creator_name":"Cohere Labs","creator_url":"https://huggingface.co/CohereLabs","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["other","expert-generated","crowdsourced","multilingual","Afrikaans"],"keywords_longer_than_N":true},
	{"name":"wiki-talks","keyword":"german","description":"\n\t\n\t\t\n\t\tWiki-Talks\n\t\n\nThe Wiki-Talks dataset is a collection of conversational threads extracted from the talk pages on Wikipedia.\nThis dataset captures collaborative dialogue, discussion patterns, and consensus-building among Wikipedia contributors.\nIt is useful for NLP research focused on dialogue, sentiment analysis, and community dynamics.\n\n\t\n\t\t\n\t\tDetails\n\t\n\nCurrently due to PyArrow incompatibility to the long recursive structures in the dataset there is an intrinsic incompatibilityâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/lflage/wiki-talks.","url":"https://huggingface.co/datasets/lflage/wiki-talks","creator_name":"Lucas Fonseca Lage","creator_url":"https://huggingface.co/lflage","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["English","German","Portuguese","Spanish","French"],"keywords_longer_than_N":true},
	{"name":"llm-metric-mrewardbench","keyword":"german","description":"rifqifarhansyah/llm-metric-mrewardbench dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/rifqifarhansyah/llm-metric-mrewardbench","creator_name":"Mohammad Rifqi Farhansyah","creator_url":"https://huggingface.co/rifqifarhansyah","license_name":"Open Data Commons Attribution License v1.0","license_url":"https://scancode-licensedb.aboutcode.org/odc-by-1.0.html","language":"en","first_N":5,"first_N_keywords":["Arabic","Chinese","Czech","Dutch","French"],"keywords_longer_than_N":true},
	{"name":"mls_sidon","keyword":"german","description":"\n\t\n\t\t\n\t\tMLS-Sidon\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is a cleansed version of Multilingual LibriSpeech (MLS) with Sidon speech restoration mode for Speech Synthesis and Spoken Language Modeling.  \nThe dataset is provided in WebDataset format for efficient large-scale training.  \n\nSource: Multilingual LibriSpeech\nLanguages: English, German, French, Spanish, Italian, Portuguese, Polish, Dutch  \nFormat: WebDataset (.tar shards)  \nLicense: CC-BY-4.0\n\n\n\n\t\n\t\n\t\n\t\tDataset Structure\n\t\n\nEach sample inâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/sarulab-speech/mls_sidon.","url":"https://huggingface.co/datasets/sarulab-speech/mls_sidon","creator_name":"SaruLab Speech group","creator_url":"https://huggingface.co/sarulab-speech","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":null,"first_N":5,"first_N_keywords":["text-to-speech","English","French","German","Spanish"],"keywords_longer_than_N":true},
	{"name":"jinaai_jina-embeddings-v2-base-en-03092024-12h5-webapp","keyword":"german","description":"\n\t\n\t\t\n\t\tjinaai_jina-embeddings-v2-base-en-03092024-12h5-webapp Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"health insurance information\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the jinaai_jina-embeddings-v2-base-en-03092024-12h5-webapp model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Huggingâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/jinaai_jina-embeddings-v2-base-en-03092024-12h5-webapp.","url":"https://huggingface.co/datasets/fine-tuned/jinaai_jina-embeddings-v2-base-en-03092024-12h5-webapp","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","German","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"bhojpuri","keyword":"german","description":"\n\t\n\t\t\n\t\n\t\n\t\tFLEURS\n\t\n\nFleurs is the speech version of the FLoRes machine translation benchmark. \nWe use 2009 n-way parallel sentences from the FLoRes dev and devtest publicly available sets, in 102 languages. \nTraining sets have around 10 hours of supervision. Speakers of the train sets are different than speakers from the dev/test sets. Multilingual fine-tuning is\nused and â€unit error rateâ€ (characters, signs) of all languages is averaged. Languages and results are also grouped into sevenâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/ankur02/bhojpuri.","url":"https://huggingface.co/datasets/ankur02/bhojpuri","creator_name":"Ankur Verma","creator_url":"https://huggingface.co/ankur02","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","expert-generated","crowdsourced","machine-generated","crowdsourced"],"keywords_longer_than_N":true},
	{"name":"multilingual_translation_gen_binarized","keyword":"german","description":"Youseff1987/multilingual_translation_gen_binarized dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/Youseff1987/multilingual_translation_gen_binarized","creator_name":"JOON HYOUNG JUN","creator_url":"https://huggingface.co/Youseff1987","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["translation","Korean","English","Chinese","Zulu"],"keywords_longer_than_N":true},
	{"name":"llm-latent-language","keyword":"german","description":"Latents computed using meta-llama/Llama-2-7b-hf, meta-llama/Llama-2-13b-hf, meta-llama/Llama-2-70b-hf\n","url":"https://huggingface.co/datasets/wendlerc/llm-latent-language","creator_name":"Chris Wendler","creator_url":"https://huggingface.co/wendlerc","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["Chinese","German","French","Russian","English"],"keywords_longer_than_N":true},
	{"name":"ZEFYS2025","keyword":"german","description":"\n\t\n\t\t\n\t\tTitle\n\t\n\nZEFYS2025: A German Dataset for Named Entity Recognition and Entity Linking for Historical Newspapers\n\n\t\n\t\t\n\t\tDescription\n\t\n\nHistorical newspaper collectons were amongst the first materials to be scanned in order to preserve them for the future. To expand the ways in which specific types of information from digitised newspapers can be searched, explored and analysed, appropriate technologies need to be developed. Named entity recognition (NER) and entity linking (EL) are suchâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/SBB/ZEFYS2025.","url":"https://huggingface.co/datasets/SBB/ZEFYS2025","creator_name":"Staatsbibliothek zu Berlin - PreuÃŸischer Kulturbesitz","creator_url":"https://huggingface.co/SBB","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","German","cc-by-4.0","10K<n<100K","ðŸ‡ºðŸ‡¸ Region: US"],"keywords_longer_than_N":true},
	{"name":"mac-app-store-apps-descriptions","keyword":"german","description":"\n\t\n\t\t\n\t\tDataset Card for Macappstore Applications Descriptions\n\t\n\n\nMac App Store Applications descriptions extracted from the metadata from the public API.\n\nCurated by: MacPaw Way Ltd.\n\nLanguage(s) (NLP): Mostly EN, DE\nLicense: MIT\n\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\nThis dataset is a combined and refined Mac App Store Applications Metadata dataset subset. \nThe main idea behind its creation is to separate the description texts of the macOS apps for the convenience of further analysis.â€¦ See the full description on the dataset page: https://huggingface.co/datasets/MacPaw/mac-app-store-apps-descriptions.","url":"https://huggingface.co/datasets/MacPaw/mac-app-store-apps-descriptions","creator_name":"MacPaw Way Ltd.","creator_url":"https://huggingface.co/MacPaw","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["English","German","mit","10K - 100K","csv"],"keywords_longer_than_N":true},
	{"name":"mCoT-MATH","keyword":"german","description":"\n\t\n\t\t\n\t\tmCoT: Multilingual Instruction Tuning for Reasoning Consistency in Language Models\n\t\n\nPaper: https://arxiv.org/abs/2406.02301\nCode: https://github.com/laihuiyuan/mCoT\nModel: https://huggingface.co/laihuiyuan/mCoT\n\n\t\n\t\t\n\t\tIntroduction\n\t\n\nBased on MetaMathQA and MathInstruct\n, we use machine translation to compile mCoT-MATH, the first large-scale multilingual math CoT reasoning dataset containing around 6.3 million samples for 11 diverse languages.\nWe train a 7B parameter model mCoT forâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/laihuiyuan/mCoT-MATH.","url":"https://huggingface.co/datasets/laihuiyuan/mCoT-MATH","creator_name":"Huiyuan Lai","creator_url":"https://huggingface.co/laihuiyuan","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["Swahili","Bengali","Telugu","Thai","Japanese"],"keywords_longer_than_N":true},
	{"name":"domain-translations","keyword":"german","description":"\n\t\n\t\t\n\t\tMultilingual Domain Name Translations Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset contains 155,004 domain names with their multilingual translations across 20 languages. Each domain has been segmented into constituent words and translated while preserving semantic meaning and commercial appeal. The dataset is particularly valuable for domain name research, multilingual NLP tasks, and understanding how brand names and concepts translate across languages.\n\n\t\n\t\t\n\t\tDatasetâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/humbleworth/domain-translations.","url":"https://huggingface.co/datasets/humbleworth/domain-translations","creator_name":"HumbleWorth","creator_url":"https://huggingface.co/humbleworth","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["translation","text-generation","feature-extraction","multilingual","Arabic"],"keywords_longer_than_N":true},
	{"name":"GND_subjects_domain_description","keyword":"german","description":"\n\t\n\t\t\n\t\tLabel Descriptions (Generated with GPT-4-o Mini)\n\t\n\nTo enhance label clarity, we leveraged GPT-4-o Mini to generate detailed class descriptions for each category, providing one or two sentences for better context. On average, each output contained approximately Â±104 tokens, as measured with the OpenAI Playground.\nPrompt used\nEnglish: Generate a single, comprehensive paragraph that provides a detailed overview of the field of [LABEL] suitable for a classification label. The tone shouldâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/zahras/GND_subjects_domain_description.","url":"https://huggingface.co/datasets/zahras/GND_subjects_domain_description","creator_name":"zahra s","creator_url":"https://huggingface.co/zahras","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":null,"first_N":5,"first_N_keywords":["English","German","mit","ðŸ‡ºðŸ‡¸ Region: US"],"keywords_longer_than_N":false},
	{"name":"riddles-qa-de","keyword":"german","description":"D4ve-R/riddles-qa-de dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/D4ve-R/riddles-qa-de","creator_name":"David","creator_url":"https://huggingface.co/D4ve-R","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text2text-generation","question-answering","German","mit","< 1K"],"keywords_longer_than_N":true},
	{"name":"ops-volltext-klassifizierung-v1","keyword":"german","description":"\n\t\n\t\t\n\t\tSynthetisches Dataset fÃ¼r OPS-Klassifizierung\n\t\n\n\n\t\n\t\t\n\t\tHaftungsausschluss\n\t\n\nDiese Daten wurden von https://gesund.bund.de gescraped und sind Eigentum des Urheberrechtsinhabers. Der alleinige Zweck dieses Datensatzes und der zugehÃ¶rigen Codebasis sowie anderer Materialien ist es, die deutsche medizinische Gemeinschaft bei der Erstellung hochspezialisierter deutscher Modelle zu unterstÃ¼tzen.\nWenn Sie an vorab geparsten Daten interessiert sind, die als Baseline fÃ¼r diese synthetischenâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/regmibijay/ops-volltext-klassifizierung-v1.","url":"https://huggingface.co/datasets/regmibijay/ops-volltext-klassifizierung-v1","creator_name":"Bijay Regmi","creator_url":"https://huggingface.co/regmibijay","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","zero-shot-classification","feature-extraction","German","mit"],"keywords_longer_than_N":true},
	{"name":"ss_members_dataset","keyword":"german","description":"\n\t\n\t\t\n\t\tSS members dataset\n\t\n\nThis dataset contains information about some of the members of the SS during the Third Reich.\n\n\t\n\t\t\n\t\tSource\n\t\n\nThis dataset was made by parsing this page and all its subpages: https://www.dws-xip.com/reich/biografie/numery/numerA.html\n\n\t\n\t\t\n\t\tDisclaimer\n\t\n\nThis dataset is provided solely for archival and educational purposes. I do not support or endorse Nazist ideology, the actions of the SS, or any related beliefs. The information contained within this datasetâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/jotone/ss_members_dataset.","url":"https://huggingface.co/datasets/jotone/ss_members_dataset","creator_name":"John Toniutti","creator_url":"https://huggingface.co/jotone","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["table-question-answering","German","English","Polish","cc0-1.0"],"keywords_longer_than_N":true},
	{"name":"dhanishtha-2.0-superthinker","keyword":"german","description":"\n\t\n\t\t\n\t\tðŸ“¦ Dhanishtha-2.0-SUPERTHINKER-MLX\n\t\n\n A distilled corpus of 11.7K high-quality samples showcasing multi-phase reasoning and structured emotional cognition. Sourced directly from the internal training data of Dhanishtha-2.0 â€” the worldâ€™s first Large Language Model (LLM) to implement Intermediate Thinking, featuring multiple <think> and <ser> blocks per response\n\n\t\n\t\t\n\t\n\t\n\t\tExample with MLX-LM-LoRA:\n\t\n\nmlx_lm_lora.train \\\n--modelâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/mlx-community/dhanishtha-2.0-superthinker.","url":"https://huggingface.co/datasets/mlx-community/dhanishtha-2.0-superthinker","creator_name":"MLX Community","creator_url":"https://huggingface.co/mlx-community","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","Afrikaans","Arabic","Bulgarian","Catalan"],"keywords_longer_than_N":true},
	{"name":"ultrachat_de","keyword":"german","description":"\n\t\n\t\t\n\t\tGerman UltraChat\n\t\n\nThis dataset contains the first 1k prompts from HuggingFaceH4/ultrachat_200k translated to German and inference on with GPT-4.\n","url":"https://huggingface.co/datasets/bjoernp/ultrachat_de","creator_name":"BjÃ¶rn PlÃ¼ster","creator_url":"https://huggingface.co/bjoernp","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["German","mit","< 1K","parquet","Tabular"],"keywords_longer_than_N":true},
	{"name":"fineweb2hq-vs-c4","keyword":"german","description":"This dataset includes 5000 rows per language from each of two sources: the higher-quality epfml/FineWeb2-HQ\nand the lower-quality allenai/c4. The data is split 80/20 into training and test sets.\nLanguages were carefully chosen to ensure balanced representation across both splits:\nArabic, Chinese, Czech, Danish, Dutch, French, German, Greek, Hungarian, Indonesian, Italian, Japanese, Persian, Polish, Portuguese, Russian, Spanish, Swedish, Turkish, and Vietnamese.\n","url":"https://huggingface.co/datasets/agentlans/fineweb2hq-vs-c4","creator_name":"Alan Tseng","creator_url":"https://huggingface.co/agentlans","license_name":"Open Data Commons Attribution License v1.0","license_url":"https://scancode-licensedb.aboutcode.org/odc-by-1.0.html","language":"en","first_N":5,"first_N_keywords":["text-classification","Portuguese","Danish","Persian","German"],"keywords_longer_than_N":true},
	{"name":"bsi_grundschutz","keyword":"german","description":"schdav/bsi_grundschutz dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/schdav/bsi_grundschutz","creator_name":"David S","creator_url":"https://huggingface.co/schdav","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["German","mit","< 1K","csv","Text"],"keywords_longer_than_N":true},
	{"name":"AtomicGPT-3.0_Dataset","keyword":"german","description":"Atomic-Ai/AtomicGPT-3.0_Dataset dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/Atomic-Ai/AtomicGPT-3.0_Dataset","creator_name":"Atomic Ai Studios","creator_url":"https://huggingface.co/Atomic-Ai","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-generation","German","mit","100K - 1M","text"],"keywords_longer_than_N":true},
	{"name":"GG-BBQ","keyword":"german","description":"\n\t\n\t\t\n\t\tDataset Card for GG-BBQ\n\t\n\n\nGerman Gender Bias Benchmark for Question Answering (GG-BBQ) for gender bias evaluation in LLMs that support German language. \n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\n\n\n\n\nLanguage(s) (NLP): German\nLicense: cc-by-4.0\n\n\n\t\n\t\t\n\t\tDataset Sources\n\t\n\n\n\n\nRepository: https://github.com/shalakasatheesh/GG-BBQ\nPaper: https://arxiv.org/abs/2507.16410\n\n\n\t\n\t\t\n\t\tUses\n\t\n\nThis dataset is to be used to carry out the evaluation of gender bias in languageâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/shalakasatheesh/GG-BBQ.","url":"https://huggingface.co/datasets/shalakasatheesh/GG-BBQ","creator_name":"Shalaka Satheesh","creator_url":"https://huggingface.co/shalakasatheesh","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["multiple-choice","question-answering","German","cc-by-4.0","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"SynCED_EnDe_2025","keyword":"german","description":"\n\t\n\t\t\n\t\tSynCED-EnDe â€” Critical Error Detection (ENâ†’DE)\n\t\n\nSynCED-EnDe is a dataset for Critical Error Detection (CED) in Englishâ†’German machine translation.\n\n\t\n\t\t\n\t\tContents\n\t\n\n\nTrain (silver): train-silver/synced_ende_train_silver.tsv (~8k pairs)  \nEval (gold): eval-gold/synced_ende_eval_gold.tsv (1k dev/test, manually verified)  \nEval (extended): eval-gold/judged_quantified_annotated.tsv adds 5 rating dimensions:\nerror_obviousness  \nerror_severity  \nlocalization_complexityâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/moon712/SynCED_EnDe_2025.","url":"https://huggingface.co/datasets/moon712/SynCED_EnDe_2025","creator_name":"Muskaan Chopra","creator_url":"https://huggingface.co/moon712","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","translation","English","German","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"FL_Eval_GER","keyword":"german","description":"Single-Choice Question Answering dataset used for evaluation regarding Liechtenstein questions. Consists of 100 question-answer pairs, each consisting of a question and 4 possible answers. Answer A is always correct while answers B, C and D are incorrect. All question-answer pairs are either assigned to the legal domain or to the historical / general domain.\nIt is created using GPT 4 generations with prompts referencing information from the the FL_Legal_GER and FL_History_GER datasets.\n","url":"https://huggingface.co/datasets/JoeUnili/FL_Eval_GER","creator_name":"Joel","creator_url":"https://huggingface.co/JoeUnili","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["question-answering","German","apache-2.0","< 1K","csv"],"keywords_longer_than_N":true},
	{"name":"lambada_openai","keyword":"german","description":"\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset is comprised of the LAMBADA test split as pre-processed by OpenAI (see relevant discussions here and here). It also contains machine translated versions of the split in German, Spanish, French, and Italian.\nLAMBADA is used to evaluate the capabilities of computational models for text understanding by means of a word prediction task. LAMBADA is a collection of narrative texts sharing the characteristic that human subjects are able to guess their last wordâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/EleutherAI/lambada_openai.","url":"https://huggingface.co/datasets/EleutherAI/lambada_openai","creator_name":"EleutherAI","creator_url":"https://huggingface.co/EleutherAI","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["language-modeling","machine-generated","translation","lambada","German"],"keywords_longer_than_N":true},
	{"name":"SauerkrautLM-Fermented-Irrelevance-GER-DPO","keyword":"german","description":"\n\n\t\n\t\t\n\t\tSauerkrautLM-Fermented-Irrelevance-GER-DPO Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nSauerkrautLM-Fermented-Irrelevance-GER-DPO  is a specialized dataset designed for training language models in function calling irrelevance detection using Direct Preference Optimization (DPO). The dataset consists of 2,000 carefully evaluated instruction-response pairs, specifically curated to help models recognize situations where function calls are unnecessary and direct responses are more appropriate.â€¦ See the full description on the dataset page: https://huggingface.co/datasets/VAGOsolutions/SauerkrautLM-Fermented-Irrelevance-GER-DPO.","url":"https://huggingface.co/datasets/VAGOsolutions/SauerkrautLM-Fermented-Irrelevance-GER-DPO","creator_name":"VAGO solutions","creator_url":"https://huggingface.co/VAGOsolutions","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-generation","German","mit","1K - 10K","parquet"],"keywords_longer_than_N":true},
	{"name":"llm-metric-mrewardbench","keyword":"german","description":"rubricreward/llm-metric-mrewardbench dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/rubricreward/llm-metric-mrewardbench","creator_name":"rubricreward","creator_url":"https://huggingface.co/rubricreward","license_name":"Open Data Commons Attribution License v1.0","license_url":"https://scancode-licensedb.aboutcode.org/odc-by-1.0.html","language":"en","first_N":5,"first_N_keywords":["Arabic","Chinese","Czech","Dutch","French"],"keywords_longer_than_N":true},
	{"name":"phonetic-piper-recording-studio-prompts","keyword":"german","description":"\n\t\n\t\t\n\t\tPhonetic Piper Studio Recordings Prompts\n\t\n\nThis dataset is a processed version of an utterance dataset made available for various languages as prompts for the Piper recording studio. Along with the original prompts, we include:\n\ncolumns ipa_espeak and ipa_epitran containing phonemized versions of the original sentences according to espeak-ng and Epitran phonemizers, respectively\ncolumns lang, espeak_lang_code, epitran_lang_code containing the language codes as reported by piperâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fdemelo/phonetic-piper-recording-studio-prompts.","url":"https://huggingface.co/datasets/fdemelo/phonetic-piper-recording-studio-prompts","creator_name":"FlÃ¡vio Eler De Melo","creator_url":"https://huggingface.co/fdemelo","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["Afrikaans","Arabic","Bulgarian","Catalan","Czech"],"keywords_longer_than_N":true},
	{"name":"mac-app-store-apps-release-notes","keyword":"german","description":"\n\t\n\t\t\n\t\tDataset Card for Macappstore Applications Release Notes\n\t\n\n\nMac App Store Applications release notes extracted from the metadata from the public API.\n\nCurated by: MacPaw Way Ltd.\n\nLanguage(s) (NLP): Mostly EN, DE\nLicense: MIT\n\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\nThis dataset is a combined and refined Mac App Store Applications Metadata dataset subset. \nThe main idea behind its creation is to separate the release notes texts of the macOS apps for the convenience of further analysis.â€¦ See the full description on the dataset page: https://huggingface.co/datasets/MacPaw/mac-app-store-apps-release-notes.","url":"https://huggingface.co/datasets/MacPaw/mac-app-store-apps-release-notes","creator_name":"MacPaw Way Ltd.","creator_url":"https://huggingface.co/MacPaw","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["English","German","mit","10K - 100K","csv"],"keywords_longer_than_N":true},
	{"name":"multihal","keyword":"german","description":"\n\t\n\t\t\n\t\tDataset Card for MultiHal\n\t\n\nBenchmark (test-only) intended for generative-form question answering grounded on knowledge graphs. \nMultiHal contains approximately 7k unique questions and 25.9k unique KG paths, some questions contain multiple candidate paths.\nThe benchmark is designed to support research for factual language modeling with a focus on providing a test bed for LLM hallucination evaluation and\nLLM knowledge updating based on KG paths in multilingual setting. See the paperâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/ernlavr/multihal.","url":"https://huggingface.co/datasets/ernlavr/multihal","creator_name":"Ernests Lavrinovics","creator_url":"https://huggingface.co/ernlavr","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["question-answering","English","Spanish","French","Portuguese"],"keywords_longer_than_N":true},
	{"name":"V1Q","keyword":"german","description":"from datasets import load_dataset\nds = load_dataset(\"b3x0m/Chinese-H-Novels\")\nimport sagemaker\nimport boto3\nfrom sagemaker.huggingface import HuggingFaceModel\ntry:\n    role = sagemaker.get_execution_role()\nexcept ValueError:\n    iam = boto3.client('iam')\n    role = iam.get_role(RoleName='sagemaker_execution_role')['Role']['Arn']\n\n\t\n\t\t\n\t\tHub Model configuration. https://huggingface.co/models\n\t\n\nhub = {\n    'HF_MODEL_ID':'deepseek-ai/Janus-Pro-7B',\n    'HF_TASK':'any-to-any'\n}\n\n\t\n\t\t\n\t\tcreateâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/YuRiVeRTi/V1Q.","url":"https://huggingface.co/datasets/YuRiVeRTi/V1Q","creator_name":"YuRiVeRTical","creator_url":"https://huggingface.co/YuRiVeRTi","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","table-question-answering","question-answering","zero-shot-classification"],"keywords_longer_than_N":true},
	{"name":"Schule-DPO","keyword":"german","description":"\n\n\t\n\t\t\n\t\tSchule-DPO\n\t\n\nA collection of various writing assignments I completed in high school and college.\nMost were written in English, some in German. Everything has been translated to both languages and marked en for English or de for German under the lang column.\n\n\t\n\t\t\n\t\tMethod\n\t\n\nEssays were cleaned up and formatted as plain-text (some have a bit of markdown) and used as 'chosen'. Claude 3.5 Sonnet was used for translations and generating synthetic prompts. The prompts were then used toâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/nbeerbower/Schule-DPO.","url":"https://huggingface.co/datasets/nbeerbower/Schule-DPO","creator_name":"Nicholas Beerbower","creator_url":"https://huggingface.co/nbeerbower","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["English","German","cc-by-4.0","< 1K","json"],"keywords_longer_than_N":true},
	{"name":"imperfect_english_prompts","keyword":"german","description":"This is the dataset for our paper \"How Important is 'Perfect' English for Machine Translation Prompts?\"\n\nLarge language models (LLMs) have achieved top results in recent machine translation evaluations, but they are also known to be sensitive to errors and perturbations in their prompts. We systematically evaluate how both humanly plausible and synthetic errors in user prompts affect LLMs' performance on two related tasks: Machine translation and machine translation evaluation. We provide bothâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/niyatibafna/imperfect_english_prompts.","url":"https://huggingface.co/datasets/niyatibafna/imperfect_english_prompts","creator_name":"Niyati Bafna","creator_url":"https://huggingface.co/niyatibafna","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["translation","English","Czech","Ukrainian","German"],"keywords_longer_than_N":true},
	{"name":"jinaai_jina-embeddings-v2-base-en-02092024-jqg1-webapp","keyword":"german","description":"\n\t\n\t\t\n\t\tjinaai_jina-embeddings-v2-base-en-02092024-jqg1-webapp Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"health insurance information\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the jinaai_jina-embeddings-v2-base-en-02092024-jqg1-webapp model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Huggingâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/jinaai_jina-embeddings-v2-base-en-02092024-jqg1-webapp.","url":"https://huggingface.co/datasets/fine-tuned/jinaai_jina-embeddings-v2-base-en-02092024-jqg1-webapp","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","German","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"LLM_Multilingual_dataset","keyword":"german","description":"\n\t\n\t\t\n\t\tDataset Card for Dataset Name\n\t\n\n\n\nThis dataset card aims to be a base template for new datasets. It has been generated using this raw template.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\n\n\n\n\n\nCurated by: [More Information Needed]\nFunded by [optional]: [More Information Needed]\nShared by [optional]: [More Information Needed]\nLanguage(s) (NLP): [More Information Needed]\nLicense: [More Information Needed]\n\n\n\t\n\t\t\n\t\tDataset Sources [optional]\n\t\n\n\n\n\nRepository: [Moreâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/lewishamilton21/LLM_Multilingual_dataset.","url":"https://huggingface.co/datasets/lewishamilton21/LLM_Multilingual_dataset","creator_name":"Kesavprabu","creator_url":"https://huggingface.co/lewishamilton21","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["table-question-answering","Japanese","Finnish","Indonesian","Russian"],"keywords_longer_than_N":true},
	{"name":"span_absinth_german_faithfulness_detection_dataset","keyword":"german","description":"\n\t\n\t\t\n\t\tDataset Card for \"Span Absinth - Hallucination Detection Dataset of German News Summarization\"\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nSpan Absinth is an extension of the Absinth dataset, where each hallucinated summary-sentence has been augmented with span annotations, that define which part of the sentence is hallucinated. Span annotations have the advantage of\neffectively isolating hallucinations at the token level.\nPlease refer to our paper and Absinth, for more details about theâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/mtc/span_absinth_german_faithfulness_detection_dataset.","url":"https://huggingface.co/datasets/mtc/span_absinth_german_faithfulness_detection_dataset","creator_name":"MTC","creator_url":"https://huggingface.co/mtc","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","German","apache-2.0","1K - 10K","parquet"],"keywords_longer_than_N":true},
	{"name":"amilia_sim_conv","keyword":"german","description":"Blubbe/amilia_sim_conv dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/Blubbe/amilia_sim_conv","creator_name":"Linus","creator_url":"https://huggingface.co/Blubbe","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","German","apache-2.0","1K - 10K","json"],"keywords_longer_than_N":true},
	{"name":"12-weltanschauungen","keyword":"german","description":"\n\t\n\t\t\n\t\t12 Denkarten, 7 Erkenntnisstimmungen und 45 kulturgewordene Gedankenfehler\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset consists of writings on twelve thinking styles, seven moods of cognition, and forty-five culturally manifested cognitive errors. It includes a collection of texts that analyze and critique various aspects of human thought processes within a cultural context.\n\n\t\n\t\t\n\t\tUsage\n\t\n\nThe dataset can be used for tasks such as text generation, text classification, and analysisâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Lafisrap/12-weltanschauungen.","url":"https://huggingface.co/datasets/Lafisrap/12-weltanschauungen","creator_name":"Michael Schmidt","creator_url":"https://huggingface.co/Lafisrap","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-generation","text-classification","expert-generated","machine-generated","original"],"keywords_longer_than_N":true},
	{"name":"tatoeba-tokipona","keyword":"german","description":"NetherQuartz/tatoeba-tokipona dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/NetherQuartz/tatoeba-tokipona","creator_name":"Vladimir Larkin","creator_url":"https://huggingface.co/NetherQuartz","license_name":"Creative Commons Attribution 2.0","license_url":"https://scancode-licensedb.aboutcode.org/cc-by-2.0.html","language":"en","first_N":5,"first_N_keywords":["translation","Toki Pona","English","Russian","Ukrainian"],"keywords_longer_than_N":true},
	{"name":"oasst2_dpo_pairs","keyword":"german","description":"\n\t\n\t\t\n\t\tDataset Card for \"oasst2_dpo_pairs\"\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nDataset transferred into the structure for trainig with DPO and can be used with the Alignment Handbook\nThe structure follows mostly the same scheme as HuggingFaceH4/ultrafeedback_binarized\n\n\t\n\t\t\n\t\tUsage\n\t\n\nTo load the dataset, run:\nfrom datasets import load_dataset\n\nds = load_dataset(\"alexredna/oasst2_dpo_pairs\")\n\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nBase dataset filtered to only contain: German, English, Spanish and Frenshâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/alexredna/oasst2_dpo_pairs.","url":"https://huggingface.co/datasets/alexredna/oasst2_dpo_pairs","creator_name":"Alexander Gruhl","creator_url":"https://huggingface.co/alexredna","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["English","German","Spanish","French","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"germeval14_no_wikipedia","keyword":"german","description":"\n\t\n\t\t\n\t\tFiltered GermEval 2014 NER Dataset\n\t\n\nThis repository hosts a filtered version of the great GermEval 2014 NER Dataset.\nAfter some analysis of the annotated examples in this dataset, it can be seen that the dataset is highly biased by Wikipedia articles.\n\n\t\n\t\t\n\t\tDataset Stats\n\t\n\nWe present an overview of the top 10 top-level domains where annotations were retrieved from for training, development and test splits:\n\n\t\n\t\t\n\t\tTraining Split\n\t\n\n\n\t\n\t\t\nTLD\nNumber of examples (Percentage)â€¦ See the full description on the dataset page: https://huggingface.co/datasets/stefan-it/germeval14_no_wikipedia.","url":"https://huggingface.co/datasets/stefan-it/germeval14_no_wikipedia","creator_name":"Stefan Schweter","creator_url":"https://huggingface.co/stefan-it","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["token-classification","German","cc-by-4.0","ðŸ‡ºðŸ‡¸ Region: US"],"keywords_longer_than_N":false},
	{"name":"OpenHumanreasoning-multilingual-2.2k","keyword":"german","description":"Based off of Pinkstackorg/humanreasoning-testing-en, it is a human-generated dataset where a real person had to create most of the reasoning and the final output. If there are any mistakes please let us know.\nWe offer this dataset at an apache-2.0 license to make it useful for everybody.\nnote: translations are not human generated.\n","url":"https://huggingface.co/datasets/Pinkstack/OpenHumanreasoning-multilingual-2.2k","creator_name":"Pinkstack","creator_url":"https://huggingface.co/Pinkstack","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","Arabic","Chinese","Czech","Danish"],"keywords_longer_than_N":true},
	{"name":"Handelsgesetzbuch_HGB","keyword":"german","description":"\n\t\n\t\t\n\t\tlicense: mit\ntask_categories:\n- text-classification\nlanguage:\n- de\ntags:\n- legal\npretty_name: HGB\nsize_categories:\n- 1K<n<10K\n\t\n\n\n\t\n\t\t\n\t\tGerman HGB Law Dataset (Handelsgesetzbuch)\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThe HGB Law Dataset contains legal text from the German Commercial Code (Handelsgesetzbuch - HGB). It focuses on the general principles of German commercial law, and the dataset is designed for tasks related to legal text analysis.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\n\t\n\t\t\n\t\tDataâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/nookbe/Handelsgesetzbuch_HGB.","url":"https://huggingface.co/datasets/nookbe/Handelsgesetzbuch_HGB","creator_name":"legal","creator_url":"https://huggingface.co/nookbe","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","German","mit","< 1K","json"],"keywords_longer_than_N":true},
	{"name":"alpaca-gpt4_de-scored","keyword":"german","description":"\n\t\n\t\t\n\t\tModifications\n\t\n\nThis is the original and unchanged german translated dataset (train split only) in original order from mayflowergmbh/alpaca-gpt4_de with added cosine-similarity scores.\nThe scores have been calculated using the best static multilingual embedding model (for my needs): sentence-transformers/static-similarity-mrl-multilingual-v1 for faster distinction if an answer corresponds to a query upon the content.\n\n\t\n\t\t\n\t\n\t\n\t\tWhy?\n\t\n\nTo build an experimental static embedding modelâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/MarcGrumpyOlejak/alpaca-gpt4_de-scored.","url":"https://huggingface.co/datasets/MarcGrumpyOlejak/alpaca-gpt4_de-scored","creator_name":"Marc Olejak","creator_url":"https://huggingface.co/MarcGrumpyOlejak","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","German","apache-2.0","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"wmt24pp","keyword":"german","description":"\n\t\n\t\t\n\t\tWMT24++\n\t\n\nThis repository contains the human translation and post-edit data for the 55 en->xx language pairs released in\nthe publication\nWMT24++: Expanding the Language Coverage of WMT24 to 55 Languages & Dialects.\nIf you are interested in the MT/LLM system outputs and automatic metric scores, please see MTME.\nIf you are interested in the images of the source URLs for each document, please see here.\n\n\t\n\t\t\n\t\n\t\n\t\tSchema\n\t\n\nEach language pair is stored in its own jsonl file.\nEach row isâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/google/wmt24pp.","url":"https://huggingface.co/datasets/google/wmt24pp","creator_name":"Google","creator_url":"https://huggingface.co/google","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["translation","Arabic","Bulgarian","Bengali","Catalan"],"keywords_longer_than_N":true},
	{"name":"ragtruth-de-translated-manual-300","keyword":"german","description":"KRLabsOrg/ragtruth-de-translated-manual-300 dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/KRLabsOrg/ragtruth-de-translated-manual-300","creator_name":"KR Labs","creator_url":"https://huggingface.co/KRLabsOrg","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["German","mit","< 1K","parquet","Text"],"keywords_longer_than_N":true},
	{"name":"wmt-da-human-evaluation-long-context","keyword":"german","description":"\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nLong-context / document-level dataset for Quality Estimation of Machine Translation.\nIt is an augmented variant of the sentence-level WMT DA Human Evaluation dataset.\nIn addition to individual sentences, it contains augmentations of 2, 4, 8, 16, and 32 sentences, among each language pair lp and domain.\nThe raw column represents a weighted average of scores of augmented sentences using character lengths of src and mt as weights.\nThe code used to apply the augmentationâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/ymoslem/wmt-da-human-evaluation-long-context.","url":"https://huggingface.co/datasets/ymoslem/wmt-da-human-evaluation-long-context","creator_name":"Yasmin Moslem","creator_url":"https://huggingface.co/ymoslem","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["Bengali","Czech","German","English","Estonian"],"keywords_longer_than_N":true},
	{"name":"seamless-align-expressive","keyword":"german","description":"\n\t\n\t\t\n\t\tDataset Card for Seamless-Align-Expressive (WIP). Inspired by https://huggingface.co/datasets/allenai/nllb\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset was created based on metadata for mined expressive Speech-to-Speech(S2S) released by Meta AI.  The S2S contains data for 5 language pairs. The S2S dataset is ~228GB compressed.\n\n\t\n\t\t\n\t\tHow to use the data\n\t\n\nThere are two ways to access the data:\n\nVia the Hugging Face Python datasets library\n\nScripts coming soon\n\n\nClone the git repo\n\ngitâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/jhu-clsp/seamless-align-expressive.","url":"https://huggingface.co/datasets/jhu-clsp/seamless-align-expressive","creator_name":"Center for Language and Speech Processing @ JHU","creator_url":"https://huggingface.co/jhu-clsp","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["translation","audio-to-audio","German","English","Spanish"],"keywords_longer_than_N":true},
	{"name":"mGeNTE-supplementary","keyword":"german","description":"Supplementary data released alongside the paper: Mind the Inclusivity Gap: Multilingual Gender-Neutral Translation Evaluation with mGeNTE.\nThe official mGeNTE dataset is at this link.\n\n\t\n\t\t\n\t\tStructure\n\t\n\nThe supplementary material is organized as follows:\n\nattributions: contains all the token level attributions to be used with the class defined in our main repository, found at this link. Moreover, we also include a \"processed_\" version of each file where we aggregated the contributionsâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/FBK-MT/mGeNTE-supplementary.","url":"https://huggingface.co/datasets/FBK-MT/mGeNTE-supplementary","creator_name":"FBK-MT","creator_url":"https://huggingface.co/FBK-MT","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["English","Spanish","Italian","German","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"gahd","keyword":"german","description":"NOTE README copied from https://github.com/jagol/gahd\nThis repository contains the dataset from our NAACL 2024 paper \"Improving Adversarial Data Collection by Supporting Annotators: Lessons from GAHD, a German Hate Speech Dataset\".\ngahd.csv contains the following columns:\n\ngahd_id: unique identifier of the entry\ntext: text of the entry\nlabel: 0 = \"not-hate speech\", 1 = \"hate speech\"\nround: round in which the entry was created\nsplit: \"train\", \"dev\", or \"test\"\ncontrastive_gahd_id: gahd_id of itsâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/davanstrien/gahd.","url":"https://huggingface.co/datasets/davanstrien/gahd","creator_name":"Daniel van Strien","creator_url":"https://huggingface.co/davanstrien","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","German","cc-by-4.0","10K - 100K","csv"],"keywords_longer_than_N":true},
	{"name":"modern","keyword":"german","description":"\n\n\t\n\t\t\n\t\tDataset Card for CATMuS Modern and Contemporary (McCATMuS)\n\t\n\nJoin our Discord to ask questions about the dataset: \n\n\t\n\t\t\n\t\tDataset Details\n\t\n\nHandwritten Text Recognition (HTR) has emerged as a crucial tool for converting manuscripts images into machine-readable formats, enabling researchers and scholars to analyze vast collections efficiently. Despite significant technological progress, establishing consistent ground truth across projects for HTR tasks, particularly for complex andâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/CATMuS/modern.","url":"https://huggingface.co/datasets/CATMuS/modern","creator_name":"CATMuS: Consistent Approach to Transcribing ManuScripts","creator_url":"https://huggingface.co/CATMuS","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["image-to-text","French","German","English","Italian"],"keywords_longer_than_N":true},
	{"name":"reasoning-conversations","keyword":"german","description":"\n\t\n\t\t\n\t\tMultilingual Reasoning Dataset\n\t\n\n\nInclude languages from German, Korean, Spanish, Japanese, French, Simplified Chinese, Traditional Chinese\n\nReasoning traces from Deepseek-v3-R1, Deepseek-v3-R1-Zero\n\n\nCredits sponsored by Currents API\n","url":"https://huggingface.co/datasets/syntaxsynth/reasoning-conversations","creator_name":"SyntaxSynth","creator_url":"https://huggingface.co/syntaxsynth","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["English","Spanish","Korean","German","Japanese"],"keywords_longer_than_N":true},
	{"name":"x-fact","keyword":"german","description":"\n\t\n\t\t\n\t\tDataset Card for \"x-fact\"\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nX-FACT is a multilingual dataset for fact-checking with real world claims. The dataset contains short statments in 25 languages with top five evidence documents retrieved by performing google search with claim statements. The dataset contains two additional evaluation splits (in addition to a traditional test set): ood and zeroshot. ood measures out-of-domain generalization where while the languageâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/utahnlp/x-fact.","url":"https://huggingface.co/datasets/utahnlp/x-fact","creator_name":"NLP at University of Utah","creator_url":"https://huggingface.co/utahnlp","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","Arabic","Bengali","Spanish","Persian"],"keywords_longer_than_N":true},
	{"name":"OGC_Military","keyword":"german","description":"\n\t\n\t\t\n\t\tOGC - Organized, Grouped, Cleaned\n\t\n\n\n\t\n\t\t\n\t\tMilitary Vision DSE\n\t\n\n\nIntended for image/text to vector (DSE)\n\n\n\t\n\t\t\n\t\tDataset Composition\n\t\n\nMade with https://github.com/RacineAIOS/OGC_pdf-to-parquet\nThis dataset was created by scraping PDF documents from online sources and generating relevant synthetic queries.\nWe used Google's Gemini 2.0 Flash Lite model in our custom pipeline to produce the queries, allowing us to create a diverse set of questions based on the document content.â€¦ See the full description on the dataset page: https://huggingface.co/datasets/racineai/OGC_Military.","url":"https://huggingface.co/datasets/racineai/OGC_Military","creator_name":"racine.ai","creator_url":"https://huggingface.co/racineai","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["visual-document-retrieval","text-retrieval","English","French","Arabic"],"keywords_longer_than_N":true},
	{"name":"librivox-tracks","keyword":"german","description":"A dataset of all audio files uploaded to LibriVox before 26th September 2023.\nForked from https://huggingface.co/datasets/pykeio/librivox-tracks\nChanges:\n\nUsed archive.org metadata API to annotate rows with \"duration\" column\n\n","url":"https://huggingface.co/datasets/xacer/librivox-tracks","creator_name":"xacer","creator_url":"https://huggingface.co/xacer","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-to-speech","automatic-speech-recognition","feature-extraction","Achinese","Afrikaans"],"keywords_longer_than_N":true},
	{"name":"llm_filtered_customer_service_conversations_cleaned","keyword":"german","description":"\n\t\n\t\t\n\t\tLLM-filtered Customer Service Conversations Dataset (cleaned)\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset contains simulated conversations generated by our agentic simulation system.\nThe conversations are filtered by a LLM to ensure they are of high quality.\nEach record is stored in JSON Lines (JSONL) format and includes:\n\nInput Settings: Metadata such as selected bank, customer, agent profiles, and task details.\nMessages: The full conversation messages.\nSummary: A German summary of theâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/marccgrau/llm_filtered_customer_service_conversations_cleaned.","url":"https://huggingface.co/datasets/marccgrau/llm_filtered_customer_service_conversations_cleaned","creator_name":"Marc Christopher Grau","creator_url":"https://huggingface.co/marccgrau","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","summarization","synthetic","monolingual","German"],"keywords_longer_than_N":true},
	{"name":"apps-competition-de","keyword":"german","description":"\n\t\n\t\t\n\t\tapps competition subset with all of the prompts translated to German\n\t\n\nAll examples were taken from codeparrot/apps and the prompts were translated to German using educa-ai-nemo-dpo.\nNo filtering or processing has been done afterwards, use with care.\n","url":"https://huggingface.co/datasets/LenDigLearn/apps-competition-de","creator_name":"Lennard Michael Strohmeyer","creator_url":"https://huggingface.co/LenDigLearn","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["English","German","mit","< 1K","parquet"],"keywords_longer_than_N":true},
	{"name":"fedlex-articles","keyword":"german","description":"\n\t\n\t\t\n\t\tDataset Card for Dataset Name\n\t\n\n\n\nThis dataset card aims to be a base template for new datasets. It has been generated using this raw template.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\n\n\n\n\n\nCurated by: [More Information Needed]\nFunded by [optional]: [More Information Needed]\nShared by [optional]: [More Information Needed]\nLanguage(s) (NLP): [More Information Needed]\nLicense: [More Information Needed]\n\n\n\t\n\t\t\n\t\tDataset Sources [optional]\n\t\n\n\n\n\nRepository: [Moreâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/glards/fedlex-articles.","url":"https://huggingface.co/datasets/glards/fedlex-articles","creator_name":"Steve Glardon","creator_url":"https://huggingface.co/glards","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["translation","French","German","Italian","mit"],"keywords_longer_than_N":true},
	{"name":"multilingual-reward-bench","keyword":"german","description":"\n\t\n\t\t\n\t\tMultilingual Reward Bench (v1.0)\n\t\n\nReward models (RMs) have driven the development of state-of-the-art LLMs today, with unprecedented impact across the globe. However, their performance in multilingual settings still remains understudied. \nIn order to probe reward model behavior on multilingual data, we present M-RewardBench, a benchmark for 23 typologically diverse languages. \nM-RewardBench contains prompt-chosen-rejected preference triples obtained by curating and translating chatâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/CohereLabsCommunity/multilingual-reward-bench.","url":"https://huggingface.co/datasets/CohereLabsCommunity/multilingual-reward-bench","creator_name":"Cohere Labs Community","creator_url":"https://huggingface.co/CohereLabsCommunity","license_name":"Open Data Commons Attribution License v1.0","license_url":"https://scancode-licensedb.aboutcode.org/odc-by-1.0.html","language":"en","first_N":5,"first_N_keywords":["Arabic","Chinese","Czech","Dutch","French"],"keywords_longer_than_N":true},
	{"name":"include-lite-44","keyword":"german","description":"\n\t\n\t\t\n\t\tINCLUDE-lite (44 languages)\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\n\n\nPaper: http://arxiv.org/abs/2411.19799\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nINCLUDE is a comprehensive knowledge- and reasoning-centric benchmark across 44 languages that evaluates multilingual LLMs for performance in the actual language environments where they would be deployed. \nIt contains 11,095 4-option multiple-choice-questions (MCQ) extracted from academic and professional exams, covering 57 topics, including regionalâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/CohereLabs/include-lite-44.","url":"https://huggingface.co/datasets/CohereLabs/include-lite-44","creator_name":"Cohere Labs","creator_url":"https://huggingface.co/CohereLabs","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["multiple-choice","Albanian","Arabic","Armenian","Azerbaijani"],"keywords_longer_than_N":true},
	{"name":"mac-app-store-apps-metadata","keyword":"german","description":"\n\t\n\t\t\n\t\tDataset Card for Macappstore Applications Metadata\n\t\n\n\nMac App Store Applications Metadata sourced by the public API.\n\nCurated by: MacPaw Way Ltd.\n\nLanguage(s) (NLP): Mostly EN, DE\nLicense: MIT\n\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\nThis data aims to cover our internal company research needs and start collecting and sharing the macOS app dataset since we have yet to find a suitable existing one.\nFull application metadata was sourced by the public iTunes search API for the US, Germany, and Ukraineâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/MacPaw/mac-app-store-apps-metadata.","url":"https://huggingface.co/datasets/MacPaw/mac-app-store-apps-metadata","creator_name":"MacPaw Way Ltd.","creator_url":"https://huggingface.co/MacPaw","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["English","German","mit","10K - 100K","csv"],"keywords_longer_than_N":true},
	{"name":"vdr-multilingual-test","keyword":"german","description":"\n\t\n\t\t\n\t\tMultilingual Visual Document Retrieval Benchmarks\n\t\n\n\nThis dataset consists of 15 different benchmarks used to initially evaluate the vdr-2b-multi-v1 multimodal retrieval embedding model. These benchmarks allow the testing of multilingual, multimodal retrieval capabilities on text-only, visual-only and mixed page screenshots.\nEach language subset contains queries and images in that language and is divided into three different categories by the \"pagetype\" column. Each category containsâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/llamaindex/vdr-multilingual-test.","url":"https://huggingface.co/datasets/llamaindex/vdr-multilingual-test","creator_name":"LlamaIndex","creator_url":"https://huggingface.co/llamaindex","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["multilingual","German","Italian","French","Spanish"],"keywords_longer_than_N":true},
	{"name":"common_voice_21_0","keyword":"german","description":"\n\t\n\t\t\n\t\tDataset Card for Common Voice Corpus 21.0\n\t\n\n\n\nThis dataset is an unofficial version of the Mozilla Common Voice Corpus 21. It was downloaded and converted from the project's website https://commonvoice.mozilla.org/.\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nAbkhaz, Albanian, Amharic, Arabic, Armenian, Assamese, Asturian, Azerbaijani, Basaa, Bashkir, Basque, Belarusian, Bengali, Breton, Bulgarian, Cantonese, Catalan, Central Kurdish, Chinese (China), Chinese (Hong Kong), Chinese (Taiwan), Chuvash, Czechâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fsicoli/common_voice_21_0.","url":"https://huggingface.co/datasets/fsicoli/common_voice_21_0","creator_name":"Fabio Sicoli","creator_url":"https://huggingface.co/fsicoli","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":null,"first_N":5,"first_N_keywords":["automatic-speech-recognition","Abkhaz","Afrikaans","Amharic","Arabic"],"keywords_longer_than_N":true},
	{"name":"UniVLN","keyword":"german","description":"\n  \n    UniVLN: Universal Vision-Language Navigation\n    A universal benchmark for unifying VLN with multi-modal inputs\n  \n\n\n\n  \n    \n  \n  \n    \n  \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tðŸ”¥ News\n\t\n\n\n[2025/05/22] Upload Parquet files for generating the croissant file.\n[2025/05/15] Release of the first version of UniVLN.\n\n\n\t\n\t\t\n\t\n\t\n\t\tðŸ” Supported VLN Tasks\n\t\n\n\n\t\n\t\t\nDataset\nObjNav\nInstanceNav\nImgNav\nRoomNav\nPointNav\nInstructionNav\nDialogNav\n\n\n\t\t\nR2R\nâŒ\nâŒ\nâŒ\nâŒ\nâŒ\nâœ…\nâŒ\n\n\nVLN-CE\nâŒ\nâŒ\nâŒ\nâŒ\nâŒ\nâœ…\nâŒ\n\n\nHouse3D\nâŒ\nâŒ\nâŒ\nâœ…\nâŒ\nâŒ\nâŒ\n\n\nHM3D\nâœ…\nâœ…â€¦ See the full description on the dataset page: https://huggingface.co/datasets/JunweiZheng/UniVLN.","url":"https://huggingface.co/datasets/JunweiZheng/UniVLN","creator_name":"Junwei Zheng","creator_url":"https://huggingface.co/JunweiZheng","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","English","Chinese","German","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"novel_text","keyword":"german","description":"taozi555/novel_text dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/taozi555/novel_text","creator_name":"Taojiang","creator_url":"https://huggingface.co/taozi555","license_name":"Creative Commons Attribution 2.0","license_url":"https://scancode-licensedb.aboutcode.org/cc-by-2.0.html","language":"en","first_N":5,"first_N_keywords":["text-generation","Spanish","English","French","Indonesian"],"keywords_longer_than_N":true},
	{"name":"wiktionary-data","keyword":"german","description":"\n\t\n\t\t\n\t\tWiktionary Data on Hugging Face Datasets\n\t\n\n\n\n\n\nwiktionary-data is a sub-data extraction of the English Wiktionary that currently\nsupports the following languages:\n\nDeutsch - German\nLatinum - Latin\ná¼™Î»Î»Î·Î½Î¹ÎºÎ® - Ancient Greek\ní•œêµ­ì–´ - Korean\nðŽ ðŽ¼ðŽ¹- Old Persian\nð’€ð’…—ð’ºð’Œ‘(ð’Œ) - Akkadian\nElamite\nà¤¸à¤‚à¤¸à¥à¤•à¥ƒà¤¤à¤®à¥ - Sanskrit, or Classical Sanskrit\n\nwiktionary-data was originally a sub-module of wilhelm-graphdb. While\nthe dataset it's getting bigger, I noticed a wave of more exciting potentials thisâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/paion-data/wiktionary-data.","url":"https://huggingface.co/datasets/paion-data/wiktionary-data","creator_name":"Paion Data","creator_url":"https://huggingface.co/paion-data","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["English","German","Latin","Ancient Greek (to 1453)","Korean"],"keywords_longer_than_N":true},
	{"name":"wiktionary-data","keyword":"german","description":"\n\t\n\t\t\n\t\tWiktionary Data on Hugging Face Datasets\n\t\n\n\n\n\n\nwiktionary-data is a sub-data extraction of the English Wiktionary that currently\nsupports the following languages:\n\nDeutsch - German\nLatinum - Latin\ná¼™Î»Î»Î·Î½Î¹ÎºÎ® - Ancient Greek\ní•œêµ­ì–´ - Korean\nðŽ ðŽ¼ðŽ¹- Old Persian\nð’€ð’…—ð’ºð’Œ‘(ð’Œ) - Akkadian\nElamite\nà¤¸à¤‚à¤¸à¥à¤•à¥ƒà¤¤à¤®à¥ - Sanskrit, or Classical Sanskrit\n\nwiktionary-data was originally a sub-module of wilhelm-graphdb. While\nthe dataset it's getting bigger, I noticed a wave of more exciting potentials thisâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/paion-data/wiktionary-data.","url":"https://huggingface.co/datasets/paion-data/wiktionary-data","creator_name":"Paion Data","creator_url":"https://huggingface.co/paion-data","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["English","German","Latin","Ancient Greek (to 1453)","Korean"],"keywords_longer_than_N":true},
	{"name":"HelpSteer3","keyword":"german","description":"\n\t\n\t\t\n\t\tHelpSteer3\n\t\n\nHelpSteer3 is an open-source dataset (CC-BY-4.0) that supports aligning models to become more helpful in responding to user prompts.\nHelpSteer3-Preference can be used to train Llama 3.3 Nemotron Super 49B v1 (for Generative RMs) and Llama 3.3 70B Instruct Models (for Bradley-Terry RMs) to produce Reward Models that score as high as 85.5% on RM-Bench and 78.6% on JudgeBench, which substantially surpass existing Reward Models on these benchmarks.\nHelpSteer3-Feedback andâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/nvidia/HelpSteer3.","url":"https://huggingface.co/datasets/nvidia/HelpSteer3","creator_name":"NVIDIA","creator_url":"https://huggingface.co/nvidia","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["English","Chinese","Korean","French","Spanish"],"keywords_longer_than_N":true},
	{"name":"BenchMAX_General_Translation","keyword":"german","description":"\n\t\n\t\t\n\t\tDataset Sources\n\t\n\n\nPaper: BenchMAX: A Comprehensive Multilingual Evaluation Suite for Large Language Models\nLink: https://huggingface.co/papers/2502.07346\nRepository: https://github.com/CONE-MT/BenchMAX\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nBenchMAX_General_Translation is a dataset of BenchMAX, which evaluates the translation capability on the general domain.\nWe collect parallel test data from Flore-200, TED-talk, and WMT24.\n\n\t\n\t\t\n\t\n\t\n\t\tUsage\n\t\n\nRun the following commands to generateâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/LLaMAX/BenchMAX_General_Translation.","url":"https://huggingface.co/datasets/LLaMAX/BenchMAX_General_Translation","creator_name":"LLaMAX","creator_url":"https://huggingface.co/LLaMAX","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["translation","multilingual","English","Chinese","Spanish"],"keywords_longer_than_N":true},
	{"name":"BenchMAX_Math","keyword":"german","description":"\n\t\n\t\t\n\t\tDataset Sources\n\t\n\n\nPaper: BenchMAX: A Comprehensive Multilingual Evaluation Suite for Large Language Models\nLink: https://huggingface.co/papers/2502.07346\nRepository: https://github.com/CONE-MT/BenchMAX\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nBenchMAX_Math is a dataset of BenchMAX, sourcing from MGSM, which evaluates the math reasoning capability in multilingual scenarios.\nWe extend the original MGSM dataset by six additional languages, i.e. Arabic, Czech, Hungarian, Korean, Serbian, andâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/LLaMAX/BenchMAX_Math.","url":"https://huggingface.co/datasets/LLaMAX/BenchMAX_Math","creator_name":"LLaMAX","creator_url":"https://huggingface.co/LLaMAX","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","multilingual","English","Chinese","Spanish"],"keywords_longer_than_N":true},
	{"name":"Multilingual-Benchmark","keyword":"german","description":"These are the GSM8K and ARC dataset translated by Google Translate. \nBibTex\n@misc{lu2024languagecountslearnunlearn,\n      title={Every Language Counts: Learn and Unlearn in Multilingual LLMs}, \n      author={Taiming Lu and Philipp Koehn},\n      year={2024},\n      eprint={2406.13748},\n      archivePrefix={arXiv},\n      primaryClass={cs.CL},\n      url={https://arxiv.org/abs/2406.13748}, \n}\n\n","url":"https://huggingface.co/datasets/TaiMingLu/Multilingual-Benchmark","creator_name":"TaiMing","creator_url":"https://huggingface.co/TaiMingLu","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["zero-shot-classification","question-answering","translation","English","German"],"keywords_longer_than_N":true},
	{"name":"German-RAG-HARD-REASONING-DE-THINKING","keyword":"german","description":"avemio/German-RAG-HARD-REASONING-DE-THINKING dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/avemio/German-RAG-HARD-REASONING-DE-THINKING","creator_name":"Avemio AG","creator_url":"https://huggingface.co/avemio","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["German","mit","1K - 10K","json","Text"],"keywords_longer_than_N":true},
	{"name":"grundschutz-dataset","keyword":"german","description":"\n\t\n\t\t\n\t\tIT-Grundschutz Dataset\n\t\n\nTraining data for IT-Grundschutz fine-tuning.\n","url":"https://huggingface.co/datasets/indigosphere/grundschutz-dataset","creator_name":"Gernot Weiser","creator_url":"https://huggingface.co/indigosphere","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-generation","German","mit","< 1K","csv"],"keywords_longer_than_N":true},
	{"name":"jinaai_jina-embeddings-v2-base-en-03092024-f2kc-webapp","keyword":"german","description":"\n\t\n\t\t\n\t\tjinaai_jina-embeddings-v2-base-en-03092024-f2kc-webapp Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"health insurance domain\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the jinaai_jina-embeddings-v2-base-en-03092024-f2kc-webapp model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Faceâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/jinaai_jina-embeddings-v2-base-en-03092024-f2kc-webapp.","url":"https://huggingface.co/datasets/fine-tuned/jinaai_jina-embeddings-v2-base-en-03092024-f2kc-webapp","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","German","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"jinaai_jina-embeddings-v2-base-en-03092024-f2kc-webapp","keyword":"german","description":"\n\t\n\t\t\n\t\tjinaai_jina-embeddings-v2-base-en-03092024-f2kc-webapp Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"health insurance domain\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the jinaai_jina-embeddings-v2-base-en-03092024-f2kc-webapp model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Faceâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/jinaai_jina-embeddings-v2-base-en-03092024-f2kc-webapp.","url":"https://huggingface.co/datasets/fine-tuned/jinaai_jina-embeddings-v2-base-en-03092024-f2kc-webapp","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","German","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"u-sticker","keyword":"german","description":"\n\t\n\t\t\n\t\tU-Sticker\n\t\n\nUser-Sticker is a stickers dataset with multi-domain conversations.\nFeatures of U-Sticker:\n\nMulti-domain interactions âœ…\nTemporal âœ…\nUser information âœ…\n370.2k stickers âœ… (104k unique)\n22.6k users âœ…\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nU-Sticker contains three files:\n\nConversation files: 1 to 67.json\nDomain mapping files idx_to_domain.txt.\nSticker files.\n\n\nSticker files are available here and Baidu Cloud.\n\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\n\t\n\t\t\n\t\tConversation file\n\t\n\n\nEmpty lines areâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/metchee/u-sticker.","url":"https://huggingface.co/datasets/metchee/u-sticker","creator_name":"Metilda Chee","creator_url":"https://huggingface.co/metchee","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["Arabic","Chinese","English","French","Turkish"],"keywords_longer_than_N":true},
	{"name":"aya_german-sharegpt","keyword":"german","description":"\n\t\n\t\t\n\t\tDataset Card for Dataset Name\n\t\n\n\n\nThis dataset card aims to be a base template for new datasets. It has been generated using this raw template.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\n\n\n\n\n\nCurated by: [More Information Needed]\nDerived from Aya Collection Language Split\nFunded by [optional]: [More Information Needed]\nShared by [optional]: [More Information Needed]\nLanguage(s) (NLP): German\nLicense: Apache 2.0\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Sources [optional]\n\t\n\n\n\n\nRepository:â€¦ See the full description on the dataset page: https://huggingface.co/datasets/sroecker/aya_german-sharegpt.","url":"https://huggingface.co/datasets/sroecker/aya_german-sharegpt","creator_name":"Steffen RÃ¶cker","creator_url":"https://huggingface.co/sroecker","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["German","apache-2.0","1M - 10M","parquet","Tabular"],"keywords_longer_than_N":true},
	{"name":"multihal","keyword":"german","description":"\n\t\n\t\t\n\t\tDataset Card for MultiHal\n\t\n\nBenchmark (test-only) intended for generative-form question answering grounded on knowledge graphs. \nMultiHal contains approximately 7k unique questions and 25.9k unique KG paths, some questions contain multiple candidate paths.\nThe benchmark is designed to support research for factual language modeling with a focus on providing a test bed for LLM hallucination evaluation and\nLLM knowledge updating based on KG paths in multilingual setting.\n\n\t\n\t\t\n\t\n\t\n\t\tUsesâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/AnonymousSubmission9090/multihal.","url":"https://huggingface.co/datasets/AnonymousSubmission9090/multihal","creator_name":"Anonymous","creator_url":"https://huggingface.co/AnonymousSubmission9090","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["question-answering","English","Spanish","French","Portuguese"],"keywords_longer_than_N":true},
	{"name":"techmb","keyword":"german","description":"\n\t\n\t\t\n\t\tDataset Card for TechMB\n\t\n\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\nThe Technical drawing for Manufacturability Benchmark (TechMB) gives a domain specific benchmark for the task of manufacturability evaluations based on technical drawings.\nThis task is described as a Visual Question Answering (VQA) task targeted at Vision Language Models (VLM) consisting of 947 question-answer pairs on 180 distinct techical drawings.\nThe objects, the technical drawings are developed from, represent a selection ofâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/WSKL/techmb.","url":"https://huggingface.co/datasets/WSKL/techmb","creator_name":"Chair of Machine Tools and Control Systems","creator_url":"https://huggingface.co/WSKL","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["visual-question-answering","English","German","cc-by-4.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"mmlux","keyword":"german","description":"\n\t\n\t\t\n\t\tCitation Information\n\t\n\nIf you find benchmarks useful in your research, please consider citing the test and also the MMLU dataset it draws from:\n    @misc{thellmann2024crosslingual,\n    title={Towards Cross-Lingual LLM Evaluation for European Languages},\n    author={Klaudia Thellmann and Bernhard Stadler and Michael Fromm and Jasper Schulze Buschhoff and Alex Jude and Fabio Barth and Johannes Leveling and Nicolas Flores-Herr and Joachim KÃ¶hler and RenÃ© JÃ¤kel and Mehdi Ali}â€¦ See the full description on the dataset page: https://huggingface.co/datasets/Eurolingua/mmlux.","url":"https://huggingface.co/datasets/Eurolingua/mmlux","creator_name":"EuroLingua-GPT","creator_url":"https://huggingface.co/Eurolingua","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":null,"first_N":5,"first_N_keywords":["multiple-choice","expert-generated","multilingual","cais/mmlu","German"],"keywords_longer_than_N":true},
	{"name":"montok","keyword":"german","description":"\n\t\n\t\t\n\t\tMonTok: A Suite of Monolingual Tokenizers\n\t\n\nThis is a set of monolingual tokenizers for 98 languages. For each language, there are Unigram, BPE, and SuperBPE tokenizers, ranging in vocabulary size from around 6k to over 200k.\n\n\t\n\t\t\n\t\tTraining Details\n\t\n\n\n\t\n\t\t\n\t\tTraining Data\n\t\n\nAll tokenizers are trained on samples of the data used to the train the Goldfish language models. \nThe tokenizers were either trained on scaled or unscaled data. This refers to whether the models are trained onâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/catherinearnett/montok.","url":"https://huggingface.co/datasets/catherinearnett/montok","creator_name":"Catherine Arnett","creator_url":"https://huggingface.co/catherinearnett","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["Afrikaans","Tosk Albanian","Amharic","Standard Arabic","Assamese"],"keywords_longer_than_N":true},
	{"name":"German-RAG-HARD-BENCHMARK-REASONING-EVAL-OPEN-SOURCE","keyword":"german","description":"\n\nSee the image of the comparison in full-size here\n","url":"https://huggingface.co/datasets/avemio/German-RAG-HARD-BENCHMARK-REASONING-EVAL-OPEN-SOURCE","creator_name":"Avemio AG","creator_url":"https://huggingface.co/avemio","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["German","English","mit","1K - 10K","json"],"keywords_longer_than_N":true},
	{"name":"filtered_convos_research_llm_summaries","keyword":"german","description":"\n\t\n\t\t\n\t\tSynthetic Call Center Summaries Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset contains synthetic summaries of call center conversations generated by different prompt configurations.\nEach record (in JSON Lines format) includes:\n\nThe original dialogue metadata.\nA generated summary tailored to provide quick insights for call center service agents.\nEvaluation metrics\n\n\n\t\n\t\t\n\t\tPrompts for summarization\n\t\n\n\nNarrative: A narrative summary of the conversation.\nBullet Points: A summary of theâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/marccgrau/filtered_convos_research_llm_summaries.","url":"https://huggingface.co/datasets/marccgrau/filtered_convos_research_llm_summaries","creator_name":"Marc Christopher Grau","creator_url":"https://huggingface.co/marccgrau","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["summarization","text-generation","synthetic","monolingual","German"],"keywords_longer_than_N":true},
	{"name":"unlabelled-sti-corpus","keyword":"german","description":"\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe unlabelled-sti-corpus is a diverse dataset designed for developing information extraction datasets (i.e. text classification or NER) for Science, Technology, and Innovation (STI) records. The corpus contains approximately 35,000 records sourced from four major repositories:\n\n22,500 publications from OpenAlex\n10,000 European research projects from CORDIS\n5,000 regional projects from Interreg and Kohesio\n7,000 patents from Lens.org\n\nThe dataset is stratifiedâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/SIRIS-Lab/unlabelled-sti-corpus.","url":"https://huggingface.co/datasets/SIRIS-Lab/unlabelled-sti-corpus","creator_name":"SIRIS Lab, Research Division of SIRIS Academic","creator_url":"https://huggingface.co/SIRIS-Lab","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["English","Spanish","French","German","Italian"],"keywords_longer_than_N":true},
	{"name":"DCLM_German","keyword":"german","description":"\n\t\n\t\t\n\t\tDCLM German Dataset\n\t\n\nThis dataset contains German language data processed for LLM pretraining, filtered using FastText language detection.\n\n\t\n\t\t\n\t\tUsage\n\t\n\nfrom datasets import load_dataset\n\n# Load the entire dataset\ndataset = load_dataset(\"faidrap/DCLM_German\")\n\n# Stream for large datasets (recommended)\ndataset = load_dataset(\"faidrap/DCLM_German\", streaming=True)\n\n# Access the data\nfor example in dataset['train']:\n    print(example['text'][:100])  # Print first 100 charsâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/faidrap/DCLM_German.","url":"https://huggingface.co/datasets/faidrap/DCLM_German","creator_name":"Faidra Patsatzi","creator_url":"https://huggingface.co/faidrap","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","language-modeling","monolingual","original","German"],"keywords_longer_than_N":true},
	{"name":"DCLM_German","keyword":"german","description":"\n\t\n\t\t\n\t\tDCLM German Dataset\n\t\n\nThis dataset contains German language data processed for LLM pretraining, filtered using FastText language detection.\n\n\t\n\t\t\n\t\tUsage\n\t\n\nfrom datasets import load_dataset\n\n# Load the entire dataset\ndataset = load_dataset(\"faidrap/DCLM_German\")\n\n# Stream for large datasets (recommended)\ndataset = load_dataset(\"faidrap/DCLM_German\", streaming=True)\n\n# Access the data\nfor example in dataset['train']:\n    print(example['text'][:100])  # Print first 100 charsâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/faidrap/DCLM_German.","url":"https://huggingface.co/datasets/faidrap/DCLM_German","creator_name":"Faidra Patsatzi","creator_url":"https://huggingface.co/faidrap","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","language-modeling","monolingual","original","German"],"keywords_longer_than_N":true},
	{"name":"jinaai_jina-embeddings-v2-base-en-03092024-9evb-webapp","keyword":"german","description":"\n\t\n\t\t\n\t\tjinaai_jina-embeddings-v2-base-en-03092024-9evb-webapp Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"health insurance information retrieval\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the jinaai_jina-embeddings-v2-base-en-03092024-9evb-webapp model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it usingâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/jinaai_jina-embeddings-v2-base-en-03092024-9evb-webapp.","url":"https://huggingface.co/datasets/fine-tuned/jinaai_jina-embeddings-v2-base-en-03092024-9evb-webapp","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","German","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"German-RAG-ORPO-Long-Context-Alpaca-HESSIAN-AI","keyword":"german","description":"\n\t\n\t\t\n\t\tGerman-RAG-ORPO (Odds Ratio Preference Optimization) Long-Context Alpaca-Format\n\t\n\n\n\t\n\t\t\n\t\tGerman-RAG - German Retrieval Augmented Generation\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThe ORPO Long Context Tasks Dataset represents a specialized collection for fine-tuning language models with a focus on RAG-specific capabilities. \nThe subsets are derived from Synthetic generation inspired by Tencent's (â€œScaling Synthetic Data Creation with 1,000,000,000 Personasâ€).\n\n\t\n\t\t\n\t\tDataset Structureâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/avemio/German-RAG-ORPO-Long-Context-Alpaca-HESSIAN-AI.","url":"https://huggingface.co/datasets/avemio/German-RAG-ORPO-Long-Context-Alpaca-HESSIAN-AI","creator_name":"Avemio AG","creator_url":"https://huggingface.co/avemio","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["question-answering","summarization","German","English","mit"],"keywords_longer_than_N":true},
	{"name":"German-RAG-ORPO-Long-Context-Alpaca-HESSIAN-AI","keyword":"german","description":"\n\t\n\t\t\n\t\tGerman-RAG-ORPO (Odds Ratio Preference Optimization) Long-Context Alpaca-Format\n\t\n\n\n\t\n\t\t\n\t\tGerman-RAG - German Retrieval Augmented Generation\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThe ORPO Long Context Tasks Dataset represents a specialized collection for fine-tuning language models with a focus on RAG-specific capabilities. \nThe subsets are derived from Synthetic generation inspired by Tencent's (â€œScaling Synthetic Data Creation with 1,000,000,000 Personasâ€).\n\n\t\n\t\t\n\t\tDataset Structureâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/avemio/German-RAG-ORPO-Long-Context-Alpaca-HESSIAN-AI.","url":"https://huggingface.co/datasets/avemio/German-RAG-ORPO-Long-Context-Alpaca-HESSIAN-AI","creator_name":"Avemio AG","creator_url":"https://huggingface.co/avemio","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["question-answering","summarization","German","English","mit"],"keywords_longer_than_N":true},
	{"name":"AIME2025-Multilingual","keyword":"german","description":"\n\t\n\t\t\n\t\tDescription\n\t\n\nThis repository contains a multi language version of the AIME2025 dataset. \nAs the english reference version, we haved used the one created by the authors of MathArena.\nFor completness, we have included the english version also in this repository, please, refer to the one contained in the MathArena github repository for the original one (https://github.com/eth-sri/matharena/tree/main/data/aime). Many thanks to Jasper Dekoninck for the help in understanding the structureâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fedric95/AIME2025-Multilingual.","url":"https://huggingface.co/datasets/fedric95/AIME2025-Multilingual","creator_name":"Federico Ricciuti","creator_url":"https://huggingface.co/fedric95","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["German","English","Italian","Portuguese","French"],"keywords_longer_than_N":true},
	{"name":"jinaai_jina-embeddings-v2-base-en-03092024-u59b-webapp","keyword":"german","description":"\n\t\n\t\t\n\t\tjinaai_jina-embeddings-v2-base-en-03092024-u59b-webapp Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"health insurance information in German language\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the jinaai_jina-embeddings-v2-base-en-03092024-u59b-webapp model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can loadâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/jinaai_jina-embeddings-v2-base-en-03092024-u59b-webapp.","url":"https://huggingface.co/datasets/fine-tuned/jinaai_jina-embeddings-v2-base-en-03092024-u59b-webapp","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","German","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"jinaai_jina-embeddings-v2-base-en-03092024-u59b-webapp","keyword":"german","description":"\n\t\n\t\t\n\t\tjinaai_jina-embeddings-v2-base-en-03092024-u59b-webapp Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"health insurance information in German language\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the jinaai_jina-embeddings-v2-base-en-03092024-u59b-webapp model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can loadâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/jinaai_jina-embeddings-v2-base-en-03092024-u59b-webapp.","url":"https://huggingface.co/datasets/fine-tuned/jinaai_jina-embeddings-v2-base-en-03092024-u59b-webapp","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","German","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"taco-de","keyword":"german","description":"\n\t\n\t\t\n\t\tTACO subset with all of the prompts translated to German\n\t\n\nAll examples were taken from BAAI/TACO and the prompts were translated to German using educa-ai-nemo-dpo.\nNo filtering or processing has been done afterwards, use with care.\n","url":"https://huggingface.co/datasets/LenDigLearn/taco-de","creator_name":"Lennard Michael Strohmeyer","creator_url":"https://huggingface.co/LenDigLearn","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["English","German","apache-2.0","1K - 10K","parquet"],"keywords_longer_than_N":true},
	{"name":"librivox-tracks","keyword":"german","description":"A dataset of all audio files uploaded to LibriVox before 26th September 2023.\n","url":"https://huggingface.co/datasets/pykeio/librivox-tracks","creator_name":"pyke.io","creator_url":"https://huggingface.co/pykeio","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-to-speech","automatic-speech-recognition","Achinese","Afrikaans","Ancient Greek (to 1453)"],"keywords_longer_than_N":true},
	{"name":"yodas-granary","keyword":"german","description":"\n\t\n\t\t\n\t\tDataset Card for YODAS-Granary\n\t\n\n\nRepository: NeMo-speech-data-processor: Granary\nPaper: Granary: Speech Recognition and Translation Dataset in 25 European Languages\nShared by: ESPnet\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Description\n\t\n\nYODAS-Granary is a curated subset of the larger nvidia/Granary dataset, focusing on high-quality pseudo-labeled speech data for Automatic Speech Recognition (ASR) and Automatic Speech Translation (AST) across 23 European languages.\n\n\t\n\t\n\t\n\t\tOverviewâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/espnet/yodas-granary.","url":"https://huggingface.co/datasets/espnet/yodas-granary","creator_name":"ESPnet","creator_url":"https://huggingface.co/espnet","license_name":"Creative Commons Attribution 3.0","license_url":"https://scancode-licensedb.aboutcode.org/cc-by-3.0.html","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","translation","Bulgarian","Czech","Danish"],"keywords_longer_than_N":true},
	{"name":"fiNERweb","keyword":"german","description":"fiNERweb is a multilingual named entity recognition dataset containing annotated text in multiple languages.\nEach example contains the original text, tokenized text, BIO tags, and character/token spans for entities.","url":"https://huggingface.co/datasets/whoisjones/fiNERweb","creator_name":"Jonas Golde","creator_url":"https://huggingface.co/whoisjones","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":null,"first_N":5,"first_N_keywords":["token-classification","named-entity-recognition","Vietnamese","Tamil","Oriya"],"keywords_longer_than_N":true},
	{"name":"multilingual-text","keyword":"german","description":"\n\t\n\t\t\n\t\tMultilingual Text Dataset\n\t\n\nThis dataset contains a curated selection of rows from multiple input datasets, where each row includes a text chunk of approximately 2000 tokens (as measured by Llama 3.1 tokenizer) verified to be written in the correct language. Only rows with properly classified language chunks are retained, ensuring high-quality multilingual data for analysis or model training.\n\n\t\n\t\t\n\t\tPreprocessing Steps\n\t\n\n\nNormalized whitespace, punctuation, Unicode characters, andâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/agentlans/multilingual-text.","url":"https://huggingface.co/datasets/agentlans/multilingual-text","creator_name":"Alan Tseng","creator_url":"https://huggingface.co/agentlans","license_name":"Open Data Commons Attribution License v1.0","license_url":"https://scancode-licensedb.aboutcode.org/odc-by-1.0.html","language":"en","first_N":5,"first_N_keywords":["text-generation","text-classification","Amharic","Arabic","Bengali"],"keywords_longer_than_N":true},
	{"name":"Chatgpt","keyword":"german","description":"\n\t\n\t\t\n\t\tOpenAssistant Conversations Dataset (OASST1)\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nIn an effort to democratize research on large-scale alignment, we release OpenAssistant \nConversations (OASST1), a human-generated, human-annotated assistant-style conversation \ncorpus consisting of 161,443 messages in 35 different languages, annotated with 461,292 \nquality ratings, resulting in over 10,000 fully annotated conversation trees. The corpus \nis a product of a worldwide crowd-sourcing effortâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/RajChat/Chatgpt.","url":"https://huggingface.co/datasets/RajChat/Chatgpt","creator_name":"Rajdeep Chatterjee ","creator_url":"https://huggingface.co/RajChat","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["English","Spanish","Russian","German","Polish"],"keywords_longer_than_N":true},
	{"name":"common_voice_22_0","keyword":"german","description":"\n\t\n\t\t\n\t\tDataset Card for Common Voice Corpus 22.0\n\t\n\n\n\nThis dataset is an unofficial version of the Mozilla Common Voice Corpus 22. It was downloaded and converted from the project's website https://commonvoice.mozilla.org/.\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nAbkhaz, Albanian, Amharic, Arabic, Armenian, Assamese, Asturian, Azerbaijani, Basaa, Bashkir, Basque, Belarusian, Bengali, Breton, Bulgarian, Cantonese, Catalan, Central Kurdish, Chinese (China), Chinese (Hong Kong), Chinese (Taiwan), Chuvash, Czechâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fsicoli/common_voice_22_0.","url":"https://huggingface.co/datasets/fsicoli/common_voice_22_0","creator_name":"Fabio Sicoli","creator_url":"https://huggingface.co/fsicoli","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":null,"first_N":5,"first_N_keywords":["automatic-speech-recognition","Abkhaz","Afrikaans","Amharic","Arabic"],"keywords_longer_than_N":true},
	{"name":"jina-embeddings-v2-base-en-14052024-5b5o-webapp","keyword":"german","description":"\n\t\n\t\t\n\t\tjina-embeddings-v2-base-en-14052024-5b5o-webapp Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"Fashion boutique products and reviews search\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the jina-embeddings-v2-base-en-14052024-5b5o-webapp model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using theâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/jina-embeddings-v2-base-en-14052024-5b5o-webapp.","url":"https://huggingface.co/datasets/fine-tuned/jina-embeddings-v2-base-en-14052024-5b5o-webapp","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","German","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"OGC_2_vdr-visRAG-colpali","keyword":"german","description":"\n\t\n\t\t\n\t\tOGC 2 - Organized, Grouped, Cleaned\n\t\n\n\nIntended for image/text to vector (DSE)\n\n\n\t\n\t\t\n\t\tDataset Composition\n\t\n\nThis second version only has rows with positive queries\nThe dataset merges, shuffles, and formats data from:\n\nvidore/colpali_train_set\nopenbmb/VisRAG-Ret-Train-Synthetic-data\nllamaindex/vdr-multilingual-train\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Statistics\n\t\n\n\n\t\n\t\t\nMetric\nValue\n\n\n\t\t\nTotal rows\n600,000+\n\n\n\t\n\n\n\t\n\t\n\t\n\t\tLanguage Distribution\n\t\n\n\n\t\n\t\t\nLanguage\nRatio\n\n\n\t\t\nEnglish\nâ‰ˆ 64%\n\n\nFrench\nâ‰ˆâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/racineai/OGC_2_vdr-visRAG-colpali.","url":"https://huggingface.co/datasets/racineai/OGC_2_vdr-visRAG-colpali","creator_name":"racine.ai","creator_url":"https://huggingface.co/racineai","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["visual-document-retrieval","text-retrieval","English","French","Italian"],"keywords_longer_than_N":true},
	{"name":"ops-volltext-klassifizierung-v2","keyword":"german","description":"\n\t\n\t\t\n\t\tSynthetisches Dataset fÃ¼r OPS-Klassifizierung\n\t\n\n\n\t\n\t\t\n\t\tHaftungsausschluss\n\t\n\nDiese Daten wurden von https://gesund.bund.de gescraped und sind Eigentum des Urheberrechtsinhabers. Der alleinige Zweck dieses Datensatzes und der zugehÃ¶rigen Codebasis sowie anderer Materialien ist es, die deutsche medizinische Gemeinschaft bei der Erstellung hochspezialisierter deutscher Modelle zu unterstÃ¼tzen.\nWenn Sie an vorab geparsten Daten interessiert sind, die als Baseline fÃ¼r diese synthetischenâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/regmibijay/ops-volltext-klassifizierung-v2.","url":"https://huggingface.co/datasets/regmibijay/ops-volltext-klassifizierung-v2","creator_name":"Bijay Regmi","creator_url":"https://huggingface.co/regmibijay","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","feature-extraction","German","mit","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"ops-volltext-klassifizierung-v2","keyword":"german","description":"\n\t\n\t\t\n\t\tSynthetisches Dataset fÃ¼r OPS-Klassifizierung\n\t\n\n\n\t\n\t\t\n\t\tHaftungsausschluss\n\t\n\nDiese Daten wurden von https://gesund.bund.de gescraped und sind Eigentum des Urheberrechtsinhabers. Der alleinige Zweck dieses Datensatzes und der zugehÃ¶rigen Codebasis sowie anderer Materialien ist es, die deutsche medizinische Gemeinschaft bei der Erstellung hochspezialisierter deutscher Modelle zu unterstÃ¼tzen.\nWenn Sie an vorab geparsten Daten interessiert sind, die als Baseline fÃ¼r diese synthetischenâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/regmibijay/ops-volltext-klassifizierung-v2.","url":"https://huggingface.co/datasets/regmibijay/ops-volltext-klassifizierung-v2","creator_name":"Bijay Regmi","creator_url":"https://huggingface.co/regmibijay","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","feature-extraction","German","mit","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"trustpilot_review_classification","keyword":"german","description":"\n\t\n\t\t\n\t\tGithub Repo: https://github.com/pattplatt/trustpilot-review-classification\n\t\n\n\n\t\n\t\t\n\t\tProject report: https://homepageblob.blob.core.windows.net/content/Using NLP Techniques to Infer Trustpilot Ratings from User Reviews.pdf\n\t\n\n","url":"https://huggingface.co/datasets/Puidii/trustpilot_review_classification","creator_name":"Patrick Mueller","creator_url":"https://huggingface.co/Puidii","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","German","mit","100K - 1M","csv"],"keywords_longer_than_N":true},
	{"name":"text_ratings","keyword":"german","description":"Todo - Write dataset card\n","url":"https://huggingface.co/datasets/lightblue/text_ratings","creator_name":"Lightblue KK.","creator_url":"https://huggingface.co/lightblue","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["Amharic","Arabic","Bulgarian","Bengali","Czech"],"keywords_longer_than_N":true},
	{"name":"xflickrco_1k","keyword":"german","description":"floschne/xflickrco_1k dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/floschne/xflickrco_1k","creator_name":"Flo Schneider","creator_url":"https://huggingface.co/floschne","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["image-to-text","German","English","Spanish","Indonesian"],"keywords_longer_than_N":true},
	{"name":"taiga_corpus_subtitles","keyword":"german","description":"\n\t\n\t\t\n\t\tDataset Card for Taiga Corpus - TV Series Subtitles\n\t\n\nThis dataset contains subtitles extracted from various TV series. The original data is sourced from the Taiga Corpus. It consists of line-level subtitle information with precise timing and additional metadata including series title and episode information. The dataset is designed for tasks such as subtitle alignment, translation, and dialogue analysis.\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Details\n\t\n\nEach record in the dataset contains the followingâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Fascinat0r/taiga_corpus_subtitles.","url":"https://huggingface.co/datasets/Fascinat0r/taiga_corpus_subtitles","creator_name":"Nikita Kulakov","creator_url":"https://huggingface.co/Fascinat0r","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["question-answering","translation","Russian","English","Italian"],"keywords_longer_than_N":true},
	{"name":"German-RAG-ORPO-Long-Context-ShareGPT-HESSIAN-AI","keyword":"german","description":"\n\t\n\t\t\n\t\tGerman-RAG-ORPO (Odds Ratio Preference Optimization) Long Context ShareGPT-Format\n\t\n\n\n\t\n\t\t\n\t\tGerman-RAG - German Retrieval Augmented Generation\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThe ORPO Long Context Tasks Dataset represents a specialized collection for fine-tuning language models with a focus on RAG-specific capabilities. \nThe subsets are derived from Synthetic generation inspired by Tencent's (â€œScaling Synthetic Data Creation with 1,000,000,000 Personasâ€).\n\n\t\n\t\t\n\t\tDataset Structureâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/avemio/German-RAG-ORPO-Long-Context-ShareGPT-HESSIAN-AI.","url":"https://huggingface.co/datasets/avemio/German-RAG-ORPO-Long-Context-ShareGPT-HESSIAN-AI","creator_name":"Avemio AG","creator_url":"https://huggingface.co/avemio","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["question-answering","summarization","German","mit","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"German-RAG-ORPO-Long-Context-ShareGPT-HESSIAN-AI","keyword":"german","description":"\n\t\n\t\t\n\t\tGerman-RAG-ORPO (Odds Ratio Preference Optimization) Long Context ShareGPT-Format\n\t\n\n\n\t\n\t\t\n\t\tGerman-RAG - German Retrieval Augmented Generation\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThe ORPO Long Context Tasks Dataset represents a specialized collection for fine-tuning language models with a focus on RAG-specific capabilities. \nThe subsets are derived from Synthetic generation inspired by Tencent's (â€œScaling Synthetic Data Creation with 1,000,000,000 Personasâ€).\n\n\t\n\t\t\n\t\tDataset Structureâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/avemio/German-RAG-ORPO-Long-Context-ShareGPT-HESSIAN-AI.","url":"https://huggingface.co/datasets/avemio/German-RAG-ORPO-Long-Context-ShareGPT-HESSIAN-AI","creator_name":"Avemio AG","creator_url":"https://huggingface.co/avemio","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["question-answering","summarization","German","mit","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"css10-ljspeech","keyword":"german","description":"\n\t\n\t\t\n\t\tCSS10-LJSpeech\n\t\n\nCSS10-LJSpeech ã¯ã€Park et al. ãŒå…¬é–‹ã—ãŸ CSS10 ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’ã€LJSpeechäº’æ›ãƒ•ã‚©ãƒ¼ãƒžãƒƒãƒˆã«å¤‰æ›ã—ãŸ10è¨€èªžã®éŸ³å£°åˆæˆç”¨ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã§ã™ã€‚å„è¨€èªžã®æ–‡å­¦ä½œå“ã‚’éŸ³å£°åŒ–ã—ãŸé«˜å“è³ªãªéŸ³å£°ãƒ‡ãƒ¼ã‚¿ã‚’æä¾›ã—ã€LJSpeechãƒ•ã‚©ãƒ¼ãƒžãƒƒãƒˆï¼ˆid|text & wavs/*.wavï¼‰ã«çµ±ä¸€ã•ã‚Œã¦ã„ã¾ã™ã€‚\n\n\t\n\t\t\n\t\tãƒ‡ãƒ¼ã‚¿æ¦‚è¦\n\t\n\n\n\t\n\t\t\né …ç›®\nå€¤\n\n\n\t\t\nè©±è€…æ•°\n10 (è¨€èªžåˆ¥)\n\n\nç·éŸ³å£°æ•°\n64,196\n\n\nåˆè¨ˆæ™‚é–“\nç´„ 140 æ™‚é–“\n\n\nã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ãƒ¬ãƒ¼ãƒˆ\n22,050 Hz\n\n\néŸ³å£°ãƒ•ã‚©ãƒ¼ãƒžãƒƒãƒˆ\nIEEEæµ®å‹•å°æ•°ç‚¹ (32bit)\n\n\nãƒ†ã‚­ã‚¹ãƒˆè¨€èªž\n10è¨€èªž\n\n\nãƒ•ã‚©ãƒ¼ãƒžãƒƒãƒˆ\n`id\n\n\n\t\n\n\n\t\n\t\t\n\t\tè¨€èªžåˆ¥çµ±è¨ˆ\n\t\n\n\n\t\n\t\t\nè¨€èªž\nè¨€èªžã‚³ãƒ¼ãƒ‰\néŸ³å£°æ•°\nåˆè¨ˆæ™‚é–“\n\n\n\t\t\nãƒ‰ã‚¤ãƒ„èªž\nde\n7,428\n16.14æ™‚é–“\n\n\nã‚®ãƒªã‚·ãƒ£èªž\nel\n1,844\n4.14æ™‚é–“\n\n\nã‚¹ãƒšã‚¤ãƒ³èªž\nes\n11,016\n19.15æ™‚é–“\n\n\nãƒ•ã‚£ãƒ³ãƒ©ãƒ³ãƒ‰èªž\nfi\n4,842\n10.53æ™‚é–“â€¦ See the full description on the dataset page: https://huggingface.co/datasets/ayousanz/css10-ljspeech.","url":"https://huggingface.co/datasets/ayousanz/css10-ljspeech","creator_name":"yousan","creator_url":"https://huggingface.co/ayousanz","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["German","Greek","Spanish","Finnish","French"],"keywords_longer_than_N":true},
	{"name":"css10-ljspeech","keyword":"german","description":"\n\t\n\t\t\n\t\tCSS10-LJSpeech\n\t\n\nCSS10-LJSpeech ã¯ã€Park et al. ãŒå…¬é–‹ã—ãŸ CSS10 ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’ã€LJSpeechäº’æ›ãƒ•ã‚©ãƒ¼ãƒžãƒƒãƒˆã«å¤‰æ›ã—ãŸ10è¨€èªžã®éŸ³å£°åˆæˆç”¨ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã§ã™ã€‚å„è¨€èªžã®æ–‡å­¦ä½œå“ã‚’éŸ³å£°åŒ–ã—ãŸé«˜å“è³ªãªéŸ³å£°ãƒ‡ãƒ¼ã‚¿ã‚’æä¾›ã—ã€LJSpeechãƒ•ã‚©ãƒ¼ãƒžãƒƒãƒˆï¼ˆid|text & wavs/*.wavï¼‰ã«çµ±ä¸€ã•ã‚Œã¦ã„ã¾ã™ã€‚\n\n\t\n\t\t\n\t\tãƒ‡ãƒ¼ã‚¿æ¦‚è¦\n\t\n\n\n\t\n\t\t\né …ç›®\nå€¤\n\n\n\t\t\nè©±è€…æ•°\n10 (è¨€èªžåˆ¥)\n\n\nç·éŸ³å£°æ•°\n64,196\n\n\nåˆè¨ˆæ™‚é–“\nç´„ 140 æ™‚é–“\n\n\nã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ãƒ¬ãƒ¼ãƒˆ\n22,050 Hz\n\n\néŸ³å£°ãƒ•ã‚©ãƒ¼ãƒžãƒƒãƒˆ\nIEEEæµ®å‹•å°æ•°ç‚¹ (32bit)\n\n\nãƒ†ã‚­ã‚¹ãƒˆè¨€èªž\n10è¨€èªž\n\n\nãƒ•ã‚©ãƒ¼ãƒžãƒƒãƒˆ\n`id\n\n\n\t\n\n\n\t\n\t\t\n\t\tè¨€èªžåˆ¥çµ±è¨ˆ\n\t\n\n\n\t\n\t\t\nè¨€èªž\nè¨€èªžã‚³ãƒ¼ãƒ‰\néŸ³å£°æ•°\nåˆè¨ˆæ™‚é–“\n\n\n\t\t\nãƒ‰ã‚¤ãƒ„èªž\nde\n7,428\n16.14æ™‚é–“\n\n\nã‚®ãƒªã‚·ãƒ£èªž\nel\n1,844\n4.14æ™‚é–“\n\n\nã‚¹ãƒšã‚¤ãƒ³èªž\nes\n11,016\n19.15æ™‚é–“\n\n\nãƒ•ã‚£ãƒ³ãƒ©ãƒ³ãƒ‰èªž\nfi\n4,842\n10.53æ™‚é–“â€¦ See the full description on the dataset page: https://huggingface.co/datasets/ayousanz/css10-ljspeech.","url":"https://huggingface.co/datasets/ayousanz/css10-ljspeech","creator_name":"yousan","creator_url":"https://huggingface.co/ayousanz","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["German","Greek","Spanish","Finnish","French"],"keywords_longer_than_N":true},
	{"name":"europa","keyword":"german","description":"\n\t\n\t\t\n\t\tDataset Card for EUROPA\n\t\n\nThis dataset card aims to be a base template for new datasets. It has been generated using this raw template.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nEUROPA is a dataset designed for training and evaluating multilingual keyphrase generation models in the legal domain. It consists of legal judgments from the Court of Justice of the European Union (EU) and includes instances in all 24 official EU languages.\nKey Features:\nMultilingual: Coversâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/NCube/europa.","url":"https://huggingface.co/datasets/NCube/europa","creator_name":"Neural Network Nomads (We are GLOSS)","creator_url":"https://huggingface.co/NCube","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["French","German","English","Italian","Dutch"],"keywords_longer_than_N":true},
	{"name":"xm3600","keyword":"german","description":"\n\t\n\t\t\n\t\n\t\n\t\tXM3600 - Crossmodal-3600\n\t\n\n\n\t\n\t\t\n\t\n\t\n\t\tThis is a copy from https://google.github.io/crossmodal-3600/\n\t\n\nIf you use this dataset, please cite the original authors:\n@inproceedings{ThapliyalCrossmodal2022,\n  author = {Ashish Thapliyal and Jordi Pont-Tuset and Xi Chen and Radu Soricut},\n  title = {{Crossmodal-3600: A Massively Multilingual Multimodal Evaluation Dataset}},\n  booktitle = {EMNLP},\n  year = {2022}\n}\n\nIt also includes the image features as PIL Image and has a uniform andâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/floschne/xm3600.","url":"https://huggingface.co/datasets/floschne/xm3600","creator_name":"Flo Schneider","creator_url":"https://huggingface.co/floschne","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["image-to-text","Arabic","Bengali","Czech","Danish"],"keywords_longer_than_N":true},
	{"name":"another-german-alpaca-dataset","keyword":"german","description":"Fischerboot/another-german-alpaca-dataset dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/Fischerboot/another-german-alpaca-dataset","creator_name":"Moritz Nickel","creator_url":"https://huggingface.co/Fischerboot","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["German","apache-2.0","10K - 100K","json","Text"],"keywords_longer_than_N":true},
	{"name":"xm3600_1k","keyword":"german","description":"\n\t\n\t\t\n\t\n\t\n\t\tXM3600 - Crossmodal-3600 - 1K Split\n\t\n\n\n\t\n\t\t\n\t\n\t\n\t\tThis is a copy from https://google.github.io/crossmodal-3600/\n\t\n\nIf you use this dataset, please cite the original authors:\n@inproceedings{ThapliyalCrossmodal2022,\n  author = {Ashish Thapliyal and Jordi Pont-Tuset and Xi Chen and Radu Soricut},\n  title = {{Crossmodal-3600: A Massively Multilingual Multimodal Evaluation Dataset}},\n  booktitle = {EMNLP},\n  year = {2022}\n}\n\n\n\t\n\t\t\n\t\n\t\n\t\tThis is a 1K split of XM3600!\n\t\n\nFor this, weâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/floschne/xm3600_1k.","url":"https://huggingface.co/datasets/floschne/xm3600_1k","creator_name":"Flo Schneider","creator_url":"https://huggingface.co/floschne","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["image-to-text","Arabic","Bengali","Czech","Danish"],"keywords_longer_than_N":true},
	{"name":"Saka-Alpaca-v1","keyword":"german","description":"https://chatgpt.com\n","url":"https://huggingface.co/datasets/Sakalti/Saka-Alpaca-v1","creator_name":"sakasan","creator_url":"https://huggingface.co/Sakalti","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","Swedish","Norwegian","Finnish","German"],"keywords_longer_than_N":true},
	{"name":"germeval21_detox","keyword":"german","description":"\n\t\n\t\t\n\t\tDataset for DeTox at GermEval 2021: Fine grained Comment Classification\n\t\n\nHas a train test split and 3 labels for each comment: Sub1_Toxic, Sub2_Engaging, and Sub3_Factclaiming.\nDatasetDict({\n    train: Dataset({\n        features: ['comment_id', 'comment_text', 'Sub1_Toxic', 'Sub2_Engaging', 'Sub3_FactClaiming'],\n        num_rows: 3244\n    })\n    test: Dataset({\n        features: ['comment_id', 'comment_text', 'Sub1_Toxic', 'Sub2_Engaging', 'Sub3_FactClaiming'],\n        num_rows: 944â€¦ See the full description on the dataset page: https://huggingface.co/datasets/lschoen/germeval21_detox.","url":"https://huggingface.co/datasets/lschoen/germeval21_detox","creator_name":"Levente Schoenherr","creator_url":"https://huggingface.co/lschoen","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","German","mit","1K - 10K","parquet"],"keywords_longer_than_N":true},
	{"name":"mementos_1turn_search_sft_std","keyword":"german","description":"kieranschubert/mementos_1turn_search_sft_std dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/kieranschubert/mementos_1turn_search_sft_std","creator_name":"Kieran Schubert","creator_url":"https://huggingface.co/kieranschubert","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","French","German","Italian","English"],"keywords_longer_than_N":true},
	{"name":"BenchMAX_Rule-based","keyword":"german","description":"\n\t\n\t\t\n\t\tDataset Sources\n\t\n\n\nPaper: BenchMAX: A Comprehensive Multilingual Evaluation Suite for Large Language Models\nLink: https://huggingface.co/papers/2502.07346\nRepository: https://github.com/CONE-MT/BenchMAX\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nBenchMAX_Rule-based is a dataset of BenchMAX, sourcing from IFEval, which is a rule-based benchmark for evaluating the instruction following capabilities in multilingual scenarios.\nWe extend the original dataset to 16 non-English languages by firstâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/LLaMAX/BenchMAX_Rule-based.","url":"https://huggingface.co/datasets/LLaMAX/BenchMAX_Rule-based","creator_name":"LLaMAX","creator_url":"https://huggingface.co/LLaMAX","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","multilingual","English","Chinese","Spanish"],"keywords_longer_than_N":true},
	{"name":"gooaq_mt_german","keyword":"german","description":"\n\t\n\t\t\n\t\tGerman GooAQ (Google Answers to Google Questions) question-answer pairs\n\t\n\n\n\t\n\t\t\n\t\tAbout\n\t\n\nThis dataset is a version of the GooAQ question-answer pairs dataset machine-translated to English and back from English to German (link to original dataset). This dataset can be used directly with Sentence Transformers to train embedding models.\nMachine translation has been performed using the English-to-German quickMT model and the quickMT library with beam_size = 5.\nThe dataset contains ~3Mâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/MarcGrumpyOlejak/gooaq_mt_german.","url":"https://huggingface.co/datasets/MarcGrumpyOlejak/gooaq_mt_german","creator_name":"Marc Olejak","creator_url":"https://huggingface.co/MarcGrumpyOlejak","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","question-answering","German","apache-2.0","1M - 10M"],"keywords_longer_than_N":true},
	{"name":"UPRPRC_docfiles_from_UN","keyword":"german","description":"This datasets contains all the raw DOC file crawl from United Nations Digital Library, produced by https://github.com/mnbvc-parallel-corpus-team/UPRPRC/blob/v2_record_spider/scripts/v4_list2doc.py, using the index in https://huggingface.co/datasets/bot-yaya/documents.un.org_search_result.\nIf you are writing spider script to download all these files, you can do increment download based on this dataset.\nOur UPRPRC project: https://github.com/mnbvc-parallel-corpus-team/UPRPRC\nAttention: Recordâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/bot-yaya/UPRPRC_docfiles_from_UN.","url":"https://huggingface.co/datasets/bot-yaya/UPRPRC_docfiles_from_UN","creator_name":"yaya","creator_url":"https://huggingface.co/bot-yaya","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["translation","Arabic","Spanish","Chinese","English"],"keywords_longer_than_N":true},
	{"name":"MultiOCR-QA","keyword":"german","description":"\n\t\n\t\t\n\t\tEvaluating Robustness of LLMs in Question Answering on Multilingual Noisy OCR Data\n\t\n\n\n\n\n\nMultiOCR-QA is a large-scale multilingual QA dataset designed to evaluate how OCR noiseâ€”insertions, deletions, substitutionsâ€”affects Large Language Models (LLMs) in question answering. Unlike standard QA datasets, MultiOCR-QA provides both RawOCR (noisy OCR text) and CorrectedOCR (ground truth text), enabling direct measurement of robustness and testing of noise-mitigation strategies.\n\n\t\t\n\t\tðŸ—‚â€¦ See the full description on the dataset page: https://huggingface.co/datasets/Bhawna/MultiOCR-QA.","url":"https://huggingface.co/datasets/Bhawna/MultiOCR-QA","creator_name":"Piryani","creator_url":"https://huggingface.co/Bhawna","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["question-answering","English","French","German","mit"],"keywords_longer_than_N":true},
	{"name":"mmarco-hard-negatives-reranker-score","keyword":"german","description":"\nhotchpotch/mmarco-hard-negatives-reranker-score\n\nThis repository contains data from mMARCO scored using the reranker BAAI/bge-reranker-v2-m3.\n\n\t\n\t\t\n\t\tLanguages Covered\n\t\n\ntarget_languages = [\n    \"english\",\n    \"chinese\", \n    \"french\",\n    \"german\",\n    \"indonesian\",\n    \"italian\",\n    \"portuguese\",\n    \"russian\",\n    \"spanish\",\n    \"arabic\",\n    \"dutch\",\n    \"hindi\",\n    \"japanese\",\n    \"vietnamese\"\n]\n\n\n\t\n\t\t\n\t\tHard Negative Data\n\t\n\nThe hard negative data is derived fromâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/hotchpotch/mmarco-hard-negatives-reranker-score.","url":"https://huggingface.co/datasets/hotchpotch/mmarco-hard-negatives-reranker-score","creator_name":"Yuichi Tateno","creator_url":"https://huggingface.co/hotchpotch","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["English","Chinese","French","German","Indonesian"],"keywords_longer_than_N":true},
	{"name":"bundestag_gesetze_index_bulk_20240507","keyword":"german","description":"\n\t\n\t\t\n\t\n\t\n\t\tDeutsche Bundesgesetze und -verordnungen\n\t\n\nDieses Git Repository enthÃ¤lt alle Deutschen Bundesgesetze und -verordnungen\nals Elasticsearch Index Bulk Format. Diese Dateien wurden mit Hilfe von\nhttps://github.com/Orbiter/bundestag_gesetze_parser\nerzeugt. Der Ursprung der Gesetze sind die Webseiten\nhttps://www.gesetze-im-internet.de/\nwelche auch in den DatensÃ¤tzen verlinkt sind.\n\n\t\n\t\t\n\t\n\t\n\t\tVerwendungsmÃ¶glichkeiten\n\t\n\nDie Daten kÃ¶nnen beispielsweise als Grundlage fÃ¼r RAG (Retrievalâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/orbiter/bundestag_gesetze_index_bulk_20240507.","url":"https://huggingface.co/datasets/orbiter/bundestag_gesetze_index_bulk_20240507","creator_name":"Michael Christen","creator_url":"https://huggingface.co/orbiter","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","German","cc0-1.0","100K<n<1M","ðŸ‡ºðŸ‡¸ Region: US"],"keywords_longer_than_N":true},
	{"name":"aya_collection_language_split","keyword":"german","description":"\nThis is a re-upload of the aya_collection, and only differs in the structure of upload. While the original aya_collection is structured by folders split according to dataset name, this dataset is split by language. We recommend you use this version of the dataset if you are only interested in downloading all of the Aya collection for a single or smaller set of languages.\n\n\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThe Aya Collection is a massive multilingual collection consisting of 513 million instances ofâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/CohereLabs/aya_collection_language_split.","url":"https://huggingface.co/datasets/CohereLabs/aya_collection_language_split","creator_name":"Cohere Labs","creator_url":"https://huggingface.co/CohereLabs","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["Achinese","Afrikaans","Amharic","Arabic","Azerbaijani"],"keywords_longer_than_N":true},
	{"name":"fineweb-edu-translated","keyword":"german","description":"\n\t\n\t\t\n\t\tHelsinki-NLP/fineweb-edu-translated\n\t\n\nAutomatically translated documents from fineweb-edu. Translations are based on OPUS-MT and HPLT-MT models.\n","url":"https://huggingface.co/datasets/Helsinki-NLP/fineweb-edu-translated","creator_name":"Language Technology Research Group at the University of Helsinki","creator_url":"https://huggingface.co/Helsinki-NLP","license_name":"Open Data Commons Attribution License v1.0","license_url":"https://scancode-licensedb.aboutcode.org/odc-by-1.0.html","language":"en","first_N":5,"first_N_keywords":["text-generation","Bulgarian","Catalan","Czech","Danish"],"keywords_longer_than_N":true},
	{"name":"DE_Emilia_Yodas_680h","keyword":"german","description":"the dataset is 680h out of the german part from \nhttps://huggingface.co/datasets/amphion/Emilia-Dataset ( Emilia Yodas - cc by 4.0)\naudio event classified via scribe v1 (elevenlabs stt/asr)\n\nfacebook audio aestetics to be used as prefilter\n\nthe dataset is very much at a v1 - \nif you want to help - lets talk\nhttps://discord.gg/RUs3uzBdW3 (nsfw is fully opt in only - as sfw)\nif you want full transaction timestamps as they come from scribe v1 - they are cc by 4.0 NC\nand can be found hereâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/MrDragonFox/DE_Emilia_Yodas_680h.","url":"https://huggingface.co/datasets/MrDragonFox/DE_Emilia_Yodas_680h","creator_name":"MrDragonFox","creator_url":"https://huggingface.co/MrDragonFox","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["German","cc-by-4.0","100K - 1M","parquet","Audio"],"keywords_longer_than_N":true},
	{"name":"imatrix-calibration","keyword":"german","description":"\n\t\n\t\t\n\t\tImportance Matrix Calibration Datasets\n\t\n\nThis repository contains calibration datasets used to generate importance matrices (imatrix), which in turn help minimise errors introduced during quantization.\n\n\t\n\t\t\n\t\tMath calibration datasets\n\t\n\nThis dataset consists of over 10M tokens of cleaned math prompts and is available in six sizes, ranging from huge (~ 430,000 lines equivalent to approx. 10M tokens), to micro (~ 13,700 lines and 1.7M tokens avg).\nOriginal data sourced fromâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/eaddario/imatrix-calibration.","url":"https://huggingface.co/datasets/eaddario/imatrix-calibration","creator_name":"Ed Addario","creator_url":"https://huggingface.co/eaddario","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-generation","Arabic","Chinese","German","English"],"keywords_longer_than_N":true},
	{"name":"migros-ch-products","keyword":"german","description":"\n\t\n\t\t\n\t\tMigros Switzerland Products\n\t\n\nA selection of products and their information from Migros Switzerland.\nDue to the structure of the Migros product catalogue only a part of it is scraped.\n\nOnly all products of Migros region Zurich are scraped.\nNo other regions or their online catalogue is included.\nIf there is a wish for every region to be scraped or something else please leave a comment.\n\nProduct information contains:\n\nName\nPrice\nPrice Text\nUnit of product\nUnit price\nIf it is discountedâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Yelinz/migros-ch-products.","url":"https://huggingface.co/datasets/Yelinz/migros-ch-products","creator_name":"Yelin Z.","creator_url":"https://huggingface.co/Yelinz","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","German","cc-by-4.0","100K - 1M","csv"],"keywords_longer_than_N":true},
	{"name":"LCC_deu_news_1M_bt","keyword":"german","description":"\n\t\n\t\t\n\t\t1M*n backtranslated german news texts using quickMT with hard negatives\n\t\n\nThis still growing experimental project/dataset is not connected, funded or organized in any way by the The Leipzig Corpora Collection. I am very thankful that the main idea behind this collection has been released under CC-BY-4.0 - see Terms of Usage .\n\n\t\n\t\t\n\t\n\t\n\t\tOverview\n\t\n\nAt the moment the Leipzig Corpora Collention has many raw monolingual corpora transparently documented and available for downloads sinceâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/MarcGrumpyOlejak/LCC_deu_news_1M_bt.","url":"https://huggingface.co/datasets/MarcGrumpyOlejak/LCC_deu_news_1M_bt","creator_name":"Marc Olejak","creator_url":"https://huggingface.co/MarcGrumpyOlejak","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","monolingual","German","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"Multi-lingual_Detection","keyword":"german","description":"Manirathinam21/Multi-lingual_Detection dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/Manirathinam21/Multi-lingual_Detection","creator_name":"Manirathinam","creator_url":"https://huggingface.co/Manirathinam21","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","Arabic","Tamil","Japanese","English"],"keywords_longer_than_N":true},
	{"name":"AtomicGPT-Think-1-dataset","keyword":"german","description":"Ein Datensatz mit Denkanregungen oder Denkbeispielen kann verschiedenearien oder Fragestellungen enthalten die dazu dienen kritisches Denken, ProblemlungsfÃ¤higkeiten oder kreatives Denken zu fÃ¶rdern. Solche Datens kÃ¶nnten in der Bildung, Forschung oder im Training verwendet werden, umische zu entwickeln und innovative LÃ¶sungen zu finden.\n","url":"https://huggingface.co/datasets/Atomic-Ai/AtomicGPT-Think-1-dataset","creator_name":"Atomic Ai Studios","creator_url":"https://huggingface.co/Atomic-Ai","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-generation","German","mit","1K - 10K","text"],"keywords_longer_than_N":true},
	{"name":"europa-random-split","keyword":"german","description":"\n\t\n\t\t\n\t\tDataset Card for EUROPA\n\t\n\nThis dataset card aims to be a base template for new datasets. It has been generated using this raw template.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nEUROPA is a dataset designed for training and evaluating multilingual keyphrase generation models in the legal domain. It consists of legal judgments from the Court of Justice of the European Union (EU) and includes instances in all 24 official EU languages.\nKey Features:\nMultilingual: Coversâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/NCube/europa-random-split.","url":"https://huggingface.co/datasets/NCube/europa-random-split","creator_name":"Neural Network Nomads (We are GLOSS)","creator_url":"https://huggingface.co/NCube","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["French","German","English","Italian","Dutch"],"keywords_longer_than_N":true},
	{"name":"epfml-FineWeb2-HQ-sample","keyword":"german","description":"\n\t\n\t\t\n\t\tepfml/FineWeb2-HQ\n\t\n\nA curated subset of the epfml/FineWeb2-HQ dataset featuring high-quality multilingual text.\n\n\t\n\t\t\n\t\tDetails\n\t\n\n\nFirst 25â€‰000 rows per config (language and script pair)\nDuplicates removed\nTexts truncated to 512 LLaMA 3.1 tokens\nScores transformed with log10\nRows shuffled and 20% of the rows split into the test set (stratified by config)\n\n\n\t\n\t\t\n\t\tExample\n\t\n\n{\n  \"text\": \"çˆµå£«å¤§å¸ˆTim Garland æ·±åœ³ä¸“åœº - [jazz]\\nTim Garland Lighthouseâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/agentlans/epfml-FineWeb2-HQ-sample.","url":"https://huggingface.co/datasets/agentlans/epfml-FineWeb2-HQ-sample","creator_name":"Alan Tseng","creator_url":"https://huggingface.co/agentlans","license_name":"Open Data Commons Attribution License v1.0","license_url":"https://scancode-licensedb.aboutcode.org/odc-by-1.0.html","language":"en","first_N":5,"first_N_keywords":["text-generation","Russian","Chinese","German","Japanese"],"keywords_longer_than_N":true},
	{"name":"BoundingDocs","keyword":"german","description":"\n\nBoundingDocs\n\nðŸ” The largest spatially-annotated dataset for Document Question Answering\n\n\n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Description\n\t\n\nBoundingDocs is a unified dataset for Document Question Answering (QA) that includes spatial annotations. It consolidates multiple public datasets from Document AI and Visually Rich Document Understanding (VRDU) domains. The dataset reformulates Information Extraction (IE) tasks into QA tasks, making it a valuable resource for training and evaluating Large Languageâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/letxbe/BoundingDocs.","url":"https://huggingface.co/datasets/letxbe/BoundingDocs","creator_name":"Letxbe","creator_url":"https://huggingface.co/letxbe","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["question-answering","visual-question-answering","English","Italian","Spanish"],"keywords_longer_than_N":true},
	{"name":"germeval14_ner","keyword":"german","description":"\n\t\n\t\t\n\t\tGermEval 14 NER dataset\n\t\n\nThis dataset includes the actual NER tags (B-PER, B-LOC, etc.) besides the labels (0, 1, 2, ...) and requires no code execution when loading. Structured as follow\nDatasetDict({\n    train: Dataset({\n        features: ['id', 'source', 'source_date', 'tokens', 'ner_label', 'ner_tag', 'nested_ner_label', 'nested_ner_tag'],\n        num_rows: 24002\n    })\n    validation: Dataset({\n        features: ['id', 'source', 'source_date', 'tokens', 'ner_label', 'ner_tag'â€¦ See the full description on the dataset page: https://huggingface.co/datasets/lschoen/germeval14_ner.","url":"https://huggingface.co/datasets/lschoen/germeval14_ner","creator_name":"Levente Schoenherr","creator_url":"https://huggingface.co/lschoen","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["token-classification","German","mit","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"new-new-carlotta-data","keyword":"german","description":"Fischerboot/new-new-carlotta-data dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/Fischerboot/new-new-carlotta-data","creator_name":"Moritz Nickel","creator_url":"https://huggingface.co/Fischerboot","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["German","apache-2.0","< 1K","json","Text"],"keywords_longer_than_N":true},
	{"name":"Tatoeba-Translations","keyword":"german","description":"\n\t\n\t\t\n\t\tDataset Details\n\t\n\nThis is the latest version of Tatoeba translations as of December 2024.\nThe sentences are downloaded from the Tatoeba collection website.\nThe dataset is processed through mapping sentences.tar.bz2 using sentences_base.tar.bz2 to find source (sentence_src) and target (sentence_tgt) sentences.\nWhile lang_src and lang_tgt columns follow the mapping provided by Tatoeba, the lang_pair column merely lists the two languages in the translation pair.\n\n\t\n\t\t\n\t\n\t\n\t\tStatisticsâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/ymoslem/Tatoeba-Translations.","url":"https://huggingface.co/datasets/ymoslem/Tatoeba-Translations","creator_name":"Yasmin Moslem","creator_url":"https://huggingface.co/ymoslem","license_name":"Creative Commons Attribution 2.0","license_url":"https://scancode-licensedb.aboutcode.org/cc-by-2.0.html","language":"en","first_N":5,"first_N_keywords":["translation","multilingual","Abkhaz","Afrikaans","Amharic"],"keywords_longer_than_N":true},
	{"name":"Kurtis-E1-Multilingual-01-SFT","keyword":"german","description":"ethicalabs/Kurtis-E1-Multilingual-01-SFT dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/ethicalabs/Kurtis-E1-Multilingual-01-SFT","creator_name":"ethicalabs.ai","creator_url":"https://huggingface.co/ethicalabs","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["English","Italian","Spanish","French","Portuguese"],"keywords_longer_than_N":true},
	{"name":"biblenlp-corpus","keyword":"german","description":"\n\t\n\t\t\n\t\tDataset Card for BibleNLP Corpus\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nPartial and complete Bible translations in 833 languages, aligned by verse.\n\n\t\n\t\t\n\t\tLanguages\n\t\n\naai, aak, aau, aaz, abt, abx, aby, acf, acr, acu, adz, aer, aey, agd, agg, agm, agn, agr, agt, agu, aia, aii, aka, ake, alp, alq, als, aly, ame, amf, amk, amm, amn, amo, amp, amr, amu, amx, anh, anv, aoi, aoj, aom, aon, apb, ape, apn, apr, apu, apw, apz, arb, are, arl, arn, arp, asm, aso, ata, atb, atd, atg, att, auc, aui, auyâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/bible-nlp/biblenlp-corpus.","url":"https://huggingface.co/datasets/bible-nlp/biblenlp-corpus","creator_name":"The Partnership for Applied Biblical NLP","creator_url":"https://huggingface.co/bible-nlp","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":null,"first_N":5,"first_N_keywords":["translation","no-annotation","expert-generated","translation","multilingual"],"keywords_longer_than_N":true},
	{"name":"biblenlp-corpus","keyword":"german","description":"\n\t\n\t\t\n\t\tDataset Card for BibleNLP Corpus\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nPartial and complete Bible translations in 833 languages, aligned by verse.\n\n\t\n\t\t\n\t\tLanguages\n\t\n\naai, aak, aau, aaz, abt, abx, aby, acf, acr, acu, adz, aer, aey, agd, agg, agm, agn, agr, agt, agu, aia, aii, aka, ake, alp, alq, als, aly, ame, amf, amk, amm, amn, amo, amp, amr, amu, amx, anh, anv, aoi, aoj, aom, aon, apb, ape, apn, apr, apu, apw, apz, arb, are, arl, arn, arp, asm, aso, ata, atb, atd, atg, att, auc, aui, auyâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/bible-nlp/biblenlp-corpus.","url":"https://huggingface.co/datasets/bible-nlp/biblenlp-corpus","creator_name":"The Partnership for Applied Biblical NLP","creator_url":"https://huggingface.co/bible-nlp","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":null,"first_N":5,"first_N_keywords":["translation","no-annotation","expert-generated","translation","multilingual"],"keywords_longer_than_N":true},
	{"name":"HashtagPrediction","keyword":"german","description":"\n\t\n\t\t\n\t\tHashtag Prediction Dataset from paper TwHIN-BERT: A Socially-Enriched Pre-trained Language Model for Multilingual Tweet Representations\n\t\n\n  \nThis repo contains the Hashtag prediction dataset from our paper TwHIN-BERT: A Socially-Enriched Pre-trained Language Model for Multilingual Tweet Representations. \n[arXiv][HuggingFace Models]\n[Github repo]\nThis work is licensed under a Creative Commons Attribution 4.0 International License.\n\n\t\n\t\t\n\t\n\t\n\t\tDownload\n\t\n\nUse theâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Twitter/HashtagPrediction.","url":"https://huggingface.co/datasets/Twitter/HashtagPrediction","creator_name":"Twitter","creator_url":"https://huggingface.co/Twitter","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["Slovenian","Urdu","Sindhi","Polish","Vietnamese"],"keywords_longer_than_N":true},
	{"name":"fashion-captions-de","keyword":"german","description":"\n\n\n\n\n\n\nThe data offered by Jina AI, Finetuner team.\n\n\n\n\t\n\t\t\n\t\tSummary\n\t\n\nThis dataset is a German-language dataset based on the Fashion12K dataset, which originally contains both English and German text descriptions for each item.\nThis dataset was used to to finetuner CLIP using the Finetuner tool.\n\n\t\n\t\t\n\t\tFine-tuning\n\t\n\nPlease refer to our documentation: Multilingual Text-to-Image Search with MultilingualCLIP\nand blog Improving Search Quality for Non-English Queries with Fine-tunedâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/jinaai/fashion-captions-de.","url":"https://huggingface.co/datasets/jinaai/fashion-captions-de","creator_name":"Jina AI","creator_url":"https://huggingface.co/jinaai","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-to-image","monolingual","original","German","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"legalis","keyword":"german","description":"\n\t\n\t\t\n\t\tDataset Card for openlegaldata.io bulk case data\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis is a labeled version of my already edited data from openlegaldata.io.\n\n\t\n\t\t\n\t\tThe Entire Dataset Is In German\n\t\n\n\nGithub Repository: [uniArchive-legalis]](https://github.com/LennardZuendorf/uniArchive-legalis)\nProcessed Data: openlegaldata-processed\nOriginal Bulk Data: Bulk Data\n\n\n\t\n\t\t\n\t\n\t\n\t\tEdit Summary\n\t\n\n\nThis Data is based on already processed data from openlegaldata. Repositories for both canâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/LennardZuendorf/legalis.","url":"https://huggingface.co/datasets/LennardZuendorf/legalis","creator_name":"Lennard ZÃ¼ndorf","creator_url":"https://huggingface.co/LennardZuendorf","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","German","mit","1K - 10K","parquet"],"keywords_longer_than_N":true},
	{"name":"wino_x","keyword":"german","description":"Wino-X is a parallel dataset of German, French, and Russian Winograd schemas, aligned with their English \ncounterparts, used to examine whether neural machine translation models can perform coreference resolution that \nrequires commonsense knowledge and whether multilingual language models are capable of commonsense reasoning across \nmultiple languages.","url":"https://huggingface.co/datasets/demelin/wino_x","creator_name":"Denis Emelin","creator_url":"https://huggingface.co/demelin","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["translation","multiple-choice-qa","language-modeling","no-annotation","machine-generated"],"keywords_longer_than_N":true},
	{"name":"NLU-Evaluation-Data-en-de","keyword":"german","description":"\n\t\n\t\t\n\t\tNLU Evaluation Data - English and German\n\t\n\nA labeled English and German language multi-domain dataset (21 domains) with 25K user utterances for human-robot interaction.\nThis dataset is collected and annotated for evaluating NLU services and platforms.\nThe detailed paper on this dataset can be found at arXiv.org:\nBenchmarking Natural Language Understanding Services for building Conversational Agents\nThe dataset builds on the annotated data of the xliuhw/NLU-Evaluation-Data\nrepository.â€¦ See the full description on the dataset page: https://huggingface.co/datasets/deutsche-telekom/NLU-Evaluation-Data-en-de.","url":"https://huggingface.co/datasets/deutsche-telekom/NLU-Evaluation-Data-en-de","creator_name":"Deutsche Telekom AG","creator_url":"https://huggingface.co/deutsche-telekom","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","intent-classification","multilingual","extended|nlu_evaluation_data","English"],"keywords_longer_than_N":true},
	{"name":"snippet-mlsum-500-v2","keyword":"german","description":"\n\t\n\t\t\n\t\tDataset Card for Snippet-MLSUM-500-V2\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset is a sample of ~500 news articles from the MLSUM dataset, augmented with machine generated news snippets. \n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThis dataset was created to support the task of generating news snippets such as title, teaser, keywords, serp and tweet for news articles in German language.\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nde - German\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\ntext: a string feature.title: a string feature.teaser:â€¦ See the full description on the dataset page: https://huggingface.co/datasets/snipaid/snippet-mlsum-500-v2.","url":"https://huggingface.co/datasets/snipaid/snippet-mlsum-500-v2","creator_name":"SnipAId","creator_url":"https://huggingface.co/snipaid","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["summarization","German","mit","< 1K","csv"],"keywords_longer_than_N":true},
	{"name":"bernice-pretrain-data","keyword":"german","description":"Tweet IDs for the 2.5 billion multilingual tweets used to train Bernice, a Twitter encoder.\nThe tweets are from the public 1% Twitter API stream from January 2016 to December 2021. \nTwitter-provided language metadata is provided with the tweet ID. The data contains 66 unique languages, \nas identified by ISO 639 language codes, including `und` for undefined languages.\nTweets need to be re-gathered via the Twitter API.","url":"https://huggingface.co/datasets/jhu-clsp/bernice-pretrain-data","creator_name":"Center for Language and Speech Processing @ JHU","creator_url":"https://huggingface.co/jhu-clsp","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":null,"first_N":5,"first_N_keywords":["other","no-annotation","found","multilingual","original"],"keywords_longer_than_N":true},
	{"name":"snippet-mlsum-500","keyword":"german","description":"\n\t\n\t\t\n\t\tDataset Card for Snippet-MLSUM-500\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset is a sample of ~500 news articles from the MLSUM dataset, augmented with machine generated news snippets. \n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThis dataset was created to support the task of generating news snippets such as title, teaser, keywords, serp and tweet for news articles in German language.\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nde - German\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\ntext: a string feature.title: a string feature.teaser: aâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/snipaid/snippet-mlsum-500.","url":"https://huggingface.co/datasets/snipaid/snippet-mlsum-500","creator_name":"SnipAId","creator_url":"https://huggingface.co/snipaid","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["summarization","German","mit","< 1K","csv"],"keywords_longer_than_N":true},
	{"name":"Europarl-catalan","keyword":"german","description":"\n\t\n\t\t\n\t\tDataset Card for Tilde-MODEL-Catalan\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset contains two dataset pairs corresponding to the Europarl corpus. Both the English and the German version are aligned with the Catalan translation, which has been obtained using Apertium's RBMT system from the Spanish version of the Spanish-English alignment. Catalan-German alignment has been obtained using this alignment finder from de-en and ca-en.\n\nCatalan-English: 1 965 735 segments.\nCatalan-German: 1â€¦ See the full description on the dataset page: https://huggingface.co/datasets/softcatala/Europarl-catalan.","url":"https://huggingface.co/datasets/softcatala/Europarl-catalan","creator_name":"SoftcatalÃ ","creator_url":"https://huggingface.co/softcatala","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":null,"first_N":5,"first_N_keywords":["translation","no-annotation","machine-generated","translation","extended|europarl_bilingual"],"keywords_longer_than_N":true},
	{"name":"gerlayqa_5k_filtered_raw","keyword":"german","description":"\n\t\n\t\t\n\t\tGerLayQA 5K Filtered Raw\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis is a cleaned and filtered subset of the GerLayQA (German Legal Question Answering) dataset, specifically designed for German legal question-answering tasks. The dataset has been split into train and validation sets for proper model evaluation.\n\n\t\n\t\t\n\t\tDataset Statistics\n\t\n\n\nTotal Samples: 5000\nTrain Samples: 4500 (90.0%)\nValidation Samples: 500 (10.0%)\n\n\n\t\n\t\t\n\t\tTrain Set\n\t\n\n\nAverage Question Length: 1100.3 charactersâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/DomainLLM/gerlayqa_5k_filtered_raw.","url":"https://huggingface.co/datasets/DomainLLM/gerlayqa_5k_filtered_raw","creator_name":"DomainLLM","creator_url":"https://huggingface.co/DomainLLM","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["German","mit","1K - 10K","parquet","Text"],"keywords_longer_than_N":true},
	{"name":"ChatML-aya_dataset","keyword":"german","description":"CohereForAI/aya_dataset in ChatML format, ready to use in HuggingFace TRL's SFT Trainer.\nPython code used for conversion:\nfrom datasets import load_dataset\nfrom transformers import AutoTokenizer\n\ntokenizer = AutoTokenizer.from_pretrained(\"Felladrin/Llama-160M-Chat-v1\")\n\ndataset = load_dataset(\"CohereForAI/aya_dataset\", split=\"train\")\n\ndef format(columns):\n    messages = [\n        {\n            \"role\": \"user\",\n            \"content\": columns[\"inputs\"].strip(),\n        },\n        {â€¦ See the full description on the dataset page: https://huggingface.co/datasets/Felladrin/ChatML-aya_dataset.","url":"https://huggingface.co/datasets/Felladrin/ChatML-aya_dataset","creator_name":"Victor Nogueira","creator_url":"https://huggingface.co/Felladrin","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["question-answering","text-generation","crowdsourced","expert-generated","crowdsourced"],"keywords_longer_than_N":true},
	{"name":"rte3-multi","keyword":"german","description":"\n\t\n\t\t\n\t\tDataset Card for Dataset Name\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis repository contains all manually translated versions of RTE-3 dataset, plus the original English one. The languages into which RTE-3 dataset has so far been translated are Italian (2012), German (2013), and French (2023).\nUnlike in other repositories, both our own French version and the older Italian and German ones are here annotated in 3 classes (entailment, neutral, contradiction), and not in 2 (entailment, notâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/maximoss/rte3-multi.","url":"https://huggingface.co/datasets/maximoss/rte3-multi","creator_name":"Maximos Skandalis","creator_url":"https://huggingface.co/maximoss","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","natural-language-inference","multi-input-text-classification","French","English"],"keywords_longer_than_N":true},
	{"name":"MMMLU","keyword":"german","description":"\n\t\n\t\t\n\t\tMultilingual Massive Multitask Language Understanding (MMMLU)\n\t\n\nThe MMLU is a widely recognized benchmark of general knowledge attained by AI models. It covers a broad range of topics from 57 different categories, covering elementary-level knowledge up to advanced professional subjects like law, physics, history, and computer science.\nWe translated the MMLUâ€™s test set into 14 languages using professional human translators. Relying on human translators for this evaluation increasesâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/openai/MMMLU.","url":"https://huggingface.co/datasets/openai/MMMLU","creator_name":"OpenAI","creator_url":"https://huggingface.co/openai","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["question-answering","Arabic","Bengali","German","Spanish"],"keywords_longer_than_N":true},
	{"name":"lextreme","keyword":"german","description":"The LEXTREME Benchmark is a collection of multilingual datasets for evaluating model performance \nacross a diverse set of legal NLU tasks.","url":"https://huggingface.co/datasets/joelniklaus/lextreme","creator_name":"Joel Niklaus","creator_url":"https://huggingface.co/joelniklaus","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","multi-class-classification","multi-label-classification","topic-classification"],"keywords_longer_than_N":true},
	{"name":"fleurs-hs-vits","keyword":"german","description":"\n\t\n\t\t\n\t\tFLEURS-HS VITS\n\t\n\nAn extension of the FLEURS dataset for synthetic speech detection using text-to-speech, featured in the paper Synthetic speech detection with Wav2Vec 2.0 in various language settings.\nThis dataset is 1 of 3 used in the paper, the others being:\n\nFLEURS-HS\nthe default train, dev and test sets\nseparated due to different licensing\n\n\nARCTIC-HS\nextension of the CMU_ARCTIC and L2-ARCTIC sets in a similar manner\n\n\n\n\n\t\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nTheâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/realnetworks-kontxt/fleurs-hs-vits.","url":"https://huggingface.co/datasets/realnetworks-kontxt/fleurs-hs-vits","creator_name":"KONTXT by RealNetworks","creator_url":"https://huggingface.co/realnetworks-kontxt","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":null,"first_N":5,"first_N_keywords":["audio-classification","German","English","Spanish","French"],"keywords_longer_than_N":true},
	{"name":"OASST-DE","keyword":"german","description":"\n\t\n\t\t\n\t\tGerman OpenAssistant Conversations Dataset (OASST-DE)\n\t\n\nWith the goal of advancing open-source, german-language LLM research, we present \nOASST-DE: a high quality subset of a recent (25.08.23) dump from the OpenAssistant website\ntranslated to German using the GPT-3.5 API. More details on how the dataset was filtered and translated under dataset creation.\nFor more details on the OpenAssistant Project, look at the first OASST dataset (OASST1), the Open-Assistant GitHub repo\nor ourâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/OpenAssistant/OASST-DE.","url":"https://huggingface.co/datasets/OpenAssistant/OASST-DE","creator_name":"OpenAssistant","creator_url":"https://huggingface.co/OpenAssistant","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["German","apache-2.0","1K - 10K","parquet","Text"],"keywords_longer_than_N":true},
	{"name":"MLDR","keyword":"german","description":"\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nMLDR is a Multilingual Long-Document Retrieval dataset built on Wikipeida, Wudao and mC4, covering 13 typologically diverse languages. Specifically, we sample lengthy articles from Wikipedia, Wudao and mC4 datasets and randomly choose paragraphs from them. Then we use GPT-3.5 to generate questions based on these paragraphs. The generated question and the sampled article constitute a new text pair to the dataset. The prompt for GPT3.5 is â€œYou are a curious AIâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Shitao/MLDR.","url":"https://huggingface.co/datasets/Shitao/MLDR","creator_name":"Xiao","creator_url":"https://huggingface.co/Shitao","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":null,"first_N":5,"first_N_keywords":["text-retrieval","multilingual","Arabic","German","English"],"keywords_longer_than_N":true},
	{"name":"xtr-wiki_qa","keyword":"german","description":"\n\t\n\t\t\n\t\tXtr-WikiQA\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nXtr-WikiQA is an Answer Sentence Selection (AS2) dataset in 9 non-English languages, proposed in our paper accepted at ACL 2023 (Findings): Cross-Lingual Knowledge Distillation for Answer Sentence Selection in Low-Resource Languages.\nThis dataset is based on an English AS2 dataset, WikiQA (Original, Hugging Face).\nFor translations, we used Amazon Translate.\n\n\t\n\t\t\n\t\n\t\n\t\tLanguages\n\t\n\n\nArabic (ar)\nSpanish (es)\nFrench (fr)\nGerman (de)\nHindi (hi)â€¦ See the full description on the dataset page: https://huggingface.co/datasets/AmazonScience/xtr-wiki_qa.","url":"https://huggingface.co/datasets/AmazonScience/xtr-wiki_qa","creator_name":"Amazon Science","creator_url":"https://huggingface.co/AmazonScience","license_name":"Community Data License Agreement Permissive 2.0","license_url":"https://scancode-licensedb.aboutcode.org/cdla-permissive-2.0.html","language":"en","first_N":5,"first_N_keywords":["question-answering","text-retrieval","open-domain-qa","machine-generated","found"],"keywords_longer_than_N":true},
	{"name":"multilingual-sentiments","keyword":"german","description":"\n\t\n\t\t\n\t\tMultilingual Sentiments Dataset\n\t\n\nA collection of multilingual sentiments datasets grouped into 3 classes -- positive, neutral, negative.\nMost multilingual sentiment datasets are either 2-class positive or negative, 5-class ratings of products reviews (e.g. Amazon multilingual dataset) or multiple classes of emotions. However, to an average person, sometimes positive, negative and neutral classes suffice and are more straightforward to perceive and annotate. Also, a positive/negativeâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/tyqiangz/multilingual-sentiments.","url":"https://huggingface.co/datasets/tyqiangz/multilingual-sentiments","creator_name":"Tay Yong Qiang","creator_url":"https://huggingface.co/tyqiangz","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","sentiment-analysis","sentiment-classification","monolingual","multilingual"],"keywords_longer_than_N":true},
	{"name":"wmt-da-human-evaluation","keyword":"german","description":"\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset contains all DA human annotations from previous WMT News Translation shared tasks.\nThe data is organised into 8 columns:\n\nlp: language pair\nsrc: input text\nmt: translation\nref: reference translation\nscore: z score\nraw: direct assessment\nannotators: number of annotators\ndomain: domain of the input text (e.g. news)\nyear: collection year\n\nYou can also find the original data for each year in the results section https://www.statmt.org/wmt{YEAR}/results.htmlâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/RicardoRei/wmt-da-human-evaluation.","url":"https://huggingface.co/datasets/RicardoRei/wmt-da-human-evaluation","creator_name":"Ricardo Rei","creator_url":"https://huggingface.co/RicardoRei","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["Bengali","Czech","German","English","Estonian"],"keywords_longer_than_N":true},
	{"name":"text_coordinates_regions","keyword":"german","description":"\n\t\n\t\t\n\t\tDataset Card for Multilingual Geo-Tagged Social Media Posts (by 123 world regions)\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThe \"Regions\" dataset is a multilingual corpus that encompasses textual data from the 123 most populated regions worldwide, with each region's data organized into separate .json files. This dataset consists of approximately 500,000 text samples, each paired with its geographic coordinates.\nKey Features:\n\nTextual Data: The dataset contains 500,000 text samples.â€¦ See the full description on the dataset page: https://huggingface.co/datasets/yachay/text_coordinates_regions.","url":"https://huggingface.co/datasets/yachay/text_coordinates_regions","creator_name":"Yachay AI","creator_url":"https://huggingface.co/yachay","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","token-classification","text-classification","English","Chinese"],"keywords_longer_than_N":true},
	{"name":"multilingual_librispeech","keyword":"german","description":"\n\t\n\t\t\n\t\tDataset Card for MultiLingual LibriSpeech\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis is a streamable version of the Multilingual LibriSpeech (MLS) dataset. \nThe data archives were restructured from the original ones from OpenSLR to make it easier to stream.\nMLS dataset is a large multilingual corpus suitable for speech research. The dataset is derived from read audiobooks from LibriVox and consists of \n8 languages - English, German, Dutch, Spanish, French, Italian, Portuguese, Polish. Itâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/facebook/multilingual_librispeech.","url":"https://huggingface.co/datasets/facebook/multilingual_librispeech","creator_name":"AI at Meta","creator_url":"https://huggingface.co/facebook","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","text-to-audio","expert-generated","crowdsourced"],"keywords_longer_than_N":true},
	{"name":"nanochat-german-eval-data","keyword":"german","description":"\n\t\n\t\t\n\t\tnanochat German: Evaluation Data\n\t\n\nThis repository hosts the translated evaluation data used for assessing a German nanochat model.\nBackground information: The original nanochat implementation by Andrej Karpathy uses the \"Mosaic Eval Gauntlet\" (version v0.3.0) benchmark. More information about this benchmark can be found in Mosaic's blog post and this paper.\nTo evaluate our German nanochat model, we translated several datasets to German using Gemini 2.5 Pro. While this translationâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/stefan-it/nanochat-german-eval-data.","url":"https://huggingface.co/datasets/stefan-it/nanochat-german-eval-data","creator_name":"Stefan Schweter","creator_url":"https://huggingface.co/stefan-it","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["German","apache-2.0","arxiv:2406.03476","ðŸ‡ºðŸ‡¸ Region: US"],"keywords_longer_than_N":false},
	{"name":"mfaq","keyword":"german","description":"We present the first multilingual FAQ dataset publicly available. We collected around 6M FAQ pairs from the web, in 21 different languages.","url":"https://huggingface.co/datasets/clips/mfaq","creator_name":"CLiPS","creator_url":"https://huggingface.co/clips","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["question-answering","multiple-choice-qa","no-annotation","other","multilingual"],"keywords_longer_than_N":true},
	{"name":"Bundestag-v2","keyword":"german","description":"\n\t\n\t\t\n\t\tDataset Card for Bundestag-v2\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset was generated from the ParlSpeech V2 dataset. It contains speeches from the german parliament from 1990 until 2020 labelled with the party of the speaker.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nText Classification\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nGerman\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\n\t\n\t\t\n\t\tData Fields\n\t\n\n\ntext: Transcript of the speech in german\nparty: Party of the speaker\n\n\n\t\n\t\t\n\t\tData Splits\n\t\n\n\ntrain\nvalidation\ntest\n\n\n\t\n\t\t\n\t\tDatasetâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/threite/Bundestag-v2.","url":"https://huggingface.co/datasets/threite/Bundestag-v2","creator_name":"Thomas Reitenspiess","creator_url":"https://huggingface.co/threite","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","entity-linking-classification","expert-generated","monolingual","German"],"keywords_longer_than_N":true},
	{"name":"blbooks-parquet","keyword":"german","description":"\n\t\n\t\t\n\t\tDataset Card for British Library Books\n\t\n\nThis dataset is the same as https://huggingface.co/datasets/TheBritishLibrary/blbooks, however, this version is stored as parquet to avoid needing to run a datasets script. This also makes loading this dataset much quicker. \n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset consists of books digitised by the British Library in partnership with Microsoft. The dataset includes ~25 million pages of out of copyright texts. The majority of the texts wereâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/biglam/blbooks-parquet.","url":"https://huggingface.co/datasets/biglam/blbooks-parquet","creator_name":"BigLAM: BigScience Libraries, Archives and Museums","creator_url":"https://huggingface.co/biglam","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","fill-mask","other","language-modeling","masked-language-modeling"],"keywords_longer_than_N":true},
	{"name":"MDK_taxonomy","keyword":"german","description":"\n\t\n\t\t\n\t\tDataset Card for MDK_taxonomy\n\t\n\n\n\t\n\t\t\n\t\tDataset Description / Summary\n\t\n\nThis dataset was created as part of the Bertelsmann Foundation\nMusterdatenkatalog project. See the project on GitHub here.\nThe MDK provides an overview of Open Data in municipalities in Germany. \nThis data contains the taxonomy created by and-effect as part of the project.\nThe taxonomy adheres to the SKOS standard and is available as RDF and JSON-LD. \nThere are two levels to the taxonomy: 'Thema' (Topic, firstâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/and-effect/MDK_taxonomy.","url":"https://huggingface.co/datasets/and-effect/MDK_taxonomy","creator_name":"&effect data solutions GmbH","creator_url":"https://huggingface.co/and-effect","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["German","cc0-1.0","< 1K","csv","Text"],"keywords_longer_than_N":true},
	{"name":"KeyFiTax","keyword":"german","description":"\n\t\n\t\t\n\t\tDataset Card for Dataset Name\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset contains Key Figures with their properties from german tax acts. The dataset is annotated by tax experts and consists of 85 annotated paragraphs from 14 different German tax acts with 157 annotated tax key figures.\nThe annotation was performed based on a developed universally applicable annotation schema and a semantic model for key figures and their properties in legal texts.\nMore details about the schema andâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/danielsteinigen/KeyFiTax.","url":"https://huggingface.co/datasets/danielsteinigen/KeyFiTax","creator_name":"Daniel Steinigen","creator_url":"https://huggingface.co/danielsteinigen","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["token-classification","German","mit","< 1K","json"],"keywords_longer_than_N":true},
	{"name":"qald_9_plus","keyword":"german","description":"\n\t\n\t\t\n\t\tQALD-9-plus Dataset Description\n\t\n\nQALD-9-plus is the dataset for Knowledge Graph Question Answering (KGQA) based on well-known QALD-9.\nQALD-9-plus enables to train and test KGQA systems over DBpedia and Wikidata using questions in 9 different languages: English, German, Russian, French, Armenian, Belarusian, Lithuanian, Bashkir, and Ukrainian.\nSome of the questions have several alternative writings in particular languages which enables to evaluate the robustness of KGQA systems andâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/casey-martin/qald_9_plus.","url":"https://huggingface.co/datasets/casey-martin/qald_9_plus","creator_name":"Casey","creator_url":"https://huggingface.co/casey-martin","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["table-question-answering","Bashkir","Belarusian","German","English"],"keywords_longer_than_N":true},
	{"name":"Open_Assistant_Conversation_Chains","keyword":"german","description":"\n\t\n\t\t\n\t\tDataset Card for Dataset Name\n\t\n\n\n\t\n\t\t\n\t\tDataset description\n\t\n\n\n\nThis dataset is a reformatting of OpenAssistant Conversations (OASST1), which is\n\na human-generated, human-annotated assistant-style conversation corpus consisting of 161,443 messages in 35 different languages, annotated with 461,292 quality ratings, resulting in over 10,000 fully annotated conversation trees. The corpus is a product of a worldwide crowd-sourcing effort involving over 13,500 volunteers.\n\nIt was modifiedâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/m-ric/Open_Assistant_Conversation_Chains.","url":"https://huggingface.co/datasets/m-ric/Open_Assistant_Conversation_Chains","creator_name":"Aymeric Roucher","creator_url":"https://huggingface.co/m-ric","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","English","Spanish","Russian","German"],"keywords_longer_than_N":true},
	{"name":"Jukebox_Thrawns_Rave_Collection","keyword":"german","description":"Thrawn/Jukebox_Thrawns_Rave_Collection dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/Thrawn/Jukebox_Thrawns_Rave_Collection","creator_name":"Georg Stefanov","creator_url":"https://huggingface.co/Thrawn","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":null,"first_N":5,"first_N_keywords":["English","German","mit","Audio","ðŸ‡ºðŸ‡¸ Region: US"],"keywords_longer_than_N":true},
	{"name":"wmt-sqm-human-evaluation","keyword":"german","description":"\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nIn 2022, several changes were made to the annotation procedure used in the WMT Translation task. In contrast to the standard DA (sliding scale from 0-100) used in previous years, in 2022 annotators performed DA+SQM (Direct Assessment + Scalar Quality Metric). In DA+SQM, the annotators still provide a raw score between 0 and 100, but also are presented with seven labeled tick marks. DA+SQM helps to stabilize scores across annotators (as compared to DA).\nThe data isâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/RicardoRei/wmt-sqm-human-evaluation.","url":"https://huggingface.co/datasets/RicardoRei/wmt-sqm-human-evaluation","creator_name":"Ricardo Rei","creator_url":"https://huggingface.co/RicardoRei","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["Czech","German","English","Croatian","Japanese"],"keywords_longer_than_N":true},
	{"name":"legal-mc4","keyword":"german","description":"Legal-MC4: A Corpus Covering the Legal Part of MC4 for European Languages","url":"https://huggingface.co/datasets/joelniklaus/legal-mc4","creator_name":"Joel Niklaus","creator_url":"https://huggingface.co/joelniklaus","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["fill-mask","other","found","multilingual","original"],"keywords_longer_than_N":true},
	{"name":"ultradistil-intel-orca-dpo-de","keyword":"german","description":"(WIP)\nCurrently this dataset is WIP - there seem to be some translation tasks in the dataset that may not be completly accurate. \nIn the next days, they will be filtered out. To do so manually, just look for \"Ã¼bersetz\" in the columns \"input\", \"chosen\" or \"rejected\"\nand exclude them from your training pipeline.\n\n\t\n\t\t\n\t\tULTRA Distilabel Intel Orca DPO (German):\n\t\n\nThis is the machine-translated German version of Intel's Orca DPO pairs, distilabeled by argilla.\nThe provided dataset wasâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/aari1995/ultradistil-intel-orca-dpo-de.","url":"https://huggingface.co/datasets/aari1995/ultradistil-intel-orca-dpo-de","creator_name":"Aaron Chibb","creator_url":"https://huggingface.co/aari1995","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["German","apache-2.0","1K - 10K","parquet","Text"],"keywords_longer_than_N":true},
	{"name":"ultradistil-intel-orca-dpo-de","keyword":"german","description":"(WIP)\nCurrently this dataset is WIP - there seem to be some translation tasks in the dataset that may not be completly accurate. \nIn the next days, they will be filtered out. To do so manually, just look for \"Ã¼bersetz\" in the columns \"input\", \"chosen\" or \"rejected\"\nand exclude them from your training pipeline.\n\n\t\n\t\t\n\t\tULTRA Distilabel Intel Orca DPO (German):\n\t\n\nThis is the machine-translated German version of Intel's Orca DPO pairs, distilabeled by argilla.\nThe provided dataset wasâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/aari1995/ultradistil-intel-orca-dpo-de.","url":"https://huggingface.co/datasets/aari1995/ultradistil-intel-orca-dpo-de","creator_name":"Aaron Chibb","creator_url":"https://huggingface.co/aari1995","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["German","apache-2.0","1K - 10K","parquet","Text"],"keywords_longer_than_N":true},
	{"name":"UpGrow-Boost","keyword":"german","description":"\n\t\n\t\t\n\t\t UpGrow Boostâ„¢\n\t\n\nWelcome to the UpGrow Boost Dataset repository on Hugging Face. This repository provides insights into our dataset used for powering our AI-driven Instagram growth services.\n\n\t\n\t\t\n\t\tðŸŒ About UpGrow\n\t\n\nUpGrow is a trailblazing platform offering Instagram growth services powered by artificial intelligence (AI) and advanced machine learning algorithms for rapid and efficient Instagram growth.\n\n\t\n\t\t\n\t\tðŸ“Š UpGrow-Boost Dataset\n\t\n\nThe UpGrow-Boost Dataset is a collection ofâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/UpGrowTeam/UpGrow-Boost.","url":"https://huggingface.co/datasets/UpGrowTeam/UpGrow-Boost","creator_name":"UpGrow","creator_url":"https://huggingface.co/UpGrowTeam","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":null,"first_N":5,"first_N_keywords":["zero-shot-classification","depth-estimation","multiple-choice","summarization","English"],"keywords_longer_than_N":true},
	{"name":"MOCKS","keyword":"german","description":"Multilingual Open Custom Keyword Spotting Testset (MOCKS) is a comprehensive \naudio testset for evaluation and benchmarking Open-Vocabulary Keyword Spotting (OV-KWS) models.","url":"https://huggingface.co/datasets/voiceintelligenceresearch/MOCKS","creator_name":"VoiceIntelligenceResearch","creator_url":"https://huggingface.co/voiceintelligenceresearch","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":null,"first_N":5,"first_N_keywords":["expert-generated","multilingual","English","German","Spanish"],"keywords_longer_than_N":true},
	{"name":"ggml-vicuna-v0-quantized","keyword":"german","description":"These are quantized ggml binary files for vicuna 7B and 13B models. The version of vicuna for these models are v0.\nThese files can be used in conjunction with minigpt4 ggml models 7B and 13B in minigpt4.cpp\nRecommended are the Q5_K and Q6_K implementations. If there are any issues, use Q4_1 or Q4_0.\n\n\n\t\n\t\t\n\t\n\t\n\t\tVicuna Model Card\n\t\n\n\n\t\n\t\t\n\t\n\t\n\t\tModel details\n\t\n\nModel type:\nVicuna is an open-source chatbot trained by fine-tuning LLaMA on user-shared conversations collected from ShareGPT.\nIt isâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/maknee/ggml-vicuna-v0-quantized.","url":"https://huggingface.co/datasets/maknee/ggml-vicuna-v0-quantized","creator_name":"maknee","creator_url":"https://huggingface.co/maknee","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["English","Bulgarian","Catalan","Czech","Danish"],"keywords_longer_than_N":true},
	{"name":"Vidore2BioMedicalLecturesRetrieval","keyword":"german","description":"\n  Vidore2BioMedicalLecturesRetrieval\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nRetrieve associated pages according to questions.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2i\n\n\nDomains\nAcademic\n\n\nReference\nhttps://arxiv.org/pdf/2407.01449\n\n\n\t\n\nSource datasets:\n\nvidore/biomedical_lectures_v2\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask = mteb.get_task(\"Vidore2BioMedicalLecturesRetrieval\")\nevaluator =â€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/Vidore2BioMedicalLecturesRetrieval.","url":"https://huggingface.co/datasets/mteb/Vidore2BioMedicalLecturesRetrieval","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["visual-document-retrieval","image-to-text","text-to-image","derived","multilingual"],"keywords_longer_than_N":true},
	{"name":"ParlaMint3","keyword":"german","description":"ParlaMint 3.0 is a multilingual set of 26 comparable corpora containing parliamentary debates mostly starting in 2015 and extending to mid-2022. \nThe corpora have extensive metadata, including aspects of the parliament; the speakers (name, gender, MP status, party affiliation, party coalition/opposition); \nare structured into time-stamped terms, sessions and meetings; and with speeches being marked by the speaker and their role (e.g. chair, regular speaker). \nThe speeches also contain marked-up transcriber comments, such as gaps in the transcription, interruptions, applause, etc. \nNote that some corpora have further information, e.g. the year of birth of the speakers, links to their Wikipedia articles, their membership in various committees, etc. \nThe corpora are also marked to the subcorpus they belong to (\"reference\", until 2020-01-30, \"covid\", from 2020-01-31, and \"war\", from 2022-02-24). \nThe corpora are encoded according to the Parla-CLARIN TEI recommendation (https://clarin-eric.github.io/parla-clarin/), but have been encoded against the compatible, \nbut much stricter ParlaMint encoding guidelines (https://clarin-eric.github.io/ParlaMint/) and schemas (included in this distribution). \nThis entry contains the ParlaMint TEI-encoded corpora with the derived plain text versions of the corpora along with TSV metadata of the speeches. \nAlso included is the 3.0 release of the data and scripts available at the GitHub repository of the ParlaMint project.","url":"https://huggingface.co/datasets/cjvt/ParlaMint3","creator_name":"Center za jezikovne vire in tehnologije Univerze v Ljubljani","creator_url":"https://huggingface.co/cjvt","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":null,"first_N":5,"first_N_keywords":["other","multilingual","Slovenian","German","Bosnian"],"keywords_longer_than_N":true},
	{"name":"syntactic_transformations","keyword":"german","description":"This is the dataset used for Coloring the Blank Slate: \nPre-training Imparts a Hierarchical Inductive Bias to\nSequence-to-sequence Models.","url":"https://huggingface.co/datasets/amueller/syntactic_transformations","creator_name":"Aaron Mueller","creator_url":"https://huggingface.co/amueller","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":null,"first_N":5,"first_N_keywords":["no-annotation","found","2 languages","original","English"],"keywords_longer_than_N":true},
	{"name":"europa_eac_tm","keyword":"german","description":"\n\t\n\t\t\n\t\tDataset Card for Europa Education and Culture Translation Memory (EAC-TM)\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset is a corpus of manually produced translations from english to up to 25 languages, released in 2012 by the European Union's Directorate General for Education and Culture (EAC).\nTo load a language pair that is not part of the config, just specify the language code as language pair. For example, if you want to translate Czech to Greek:\ndataset = load_dataset(\"europa_eac_tm\"â€¦ See the full description on the dataset page: https://huggingface.co/datasets/community-datasets/europa_eac_tm.","url":"https://huggingface.co/datasets/community-datasets/europa_eac_tm","creator_name":"Community Datasets","creator_url":"https://huggingface.co/community-datasets","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["translation","expert-generated","expert-generated","translation","original"],"keywords_longer_than_N":true},
	{"name":"multilingual_librispeech","keyword":"german","description":"Multilingual LibriSpeech (MLS) dataset is a large multilingual corpus suitable for speech research. The dataset is derived from read audiobooks from LibriVox and consists of 8 languages - English, German, Dutch, Spanish, French, Italian, Portuguese, Polish.","url":"https://huggingface.co/datasets/legacy-datasets/multilingual_librispeech","creator_name":"Legacy Datasets","creator_url":"https://huggingface.co/legacy-datasets","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":null,"first_N":5,"first_N_keywords":["automatic-speech-recognition","audio-classification","speaker-identification","expert-generated","crowdsourced"],"keywords_longer_than_N":true},
	{"name":"eur-lex-sum","keyword":"german","description":"The EUR-Lex-Sum dataset is a multilingual resource intended for text summarization in the legal domain.\nIt is based on human-written summaries of legal acts issued by the European Union.\nIt distinguishes itself by introducing a smaller set of high-quality human-written samples,\neach of which have much longer references (and summaries!) than comparable datasets.\nAdditionally, the underlying legal acts provide a challenging domain-specific application to legal texts,\nwhich are so far underrepresented in non-English languages.\nFor each legal act, the sample can be available in up to 24 languages\n(the officially recognized languages in the European Union);\nthe validation and test samples consist entirely of samples available in all languages,\nand are aligned across all languages at the paragraph level.","url":"https://huggingface.co/datasets/dennlinger/eur-lex-sum","creator_name":"Dennis Aumiller","creator_url":"https://huggingface.co/dennlinger","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":null,"first_N":5,"first_N_keywords":["translation","summarization","found","expert-generated","found"],"keywords_longer_than_N":true},
	{"name":"EU_Wikipedias","keyword":"german","description":"Wikipedia dataset containing cleaned articles of all languages.\nThe datasets are built from the Wikipedia dump\n(https://dumps.wikimedia.org/) with one split per language. Each example\ncontains the content of one full Wikipedia article with cleaning to strip\nmarkdown and unwanted sections (references, etc.).","url":"https://huggingface.co/datasets/joelniklaus/EU_Wikipedias","creator_name":"Joel Niklaus","creator_url":"https://huggingface.co/joelniklaus","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["fill-mask","other","found","multilingual","original"],"keywords_longer_than_N":true},
	{"name":"nllb-200-10M-sample","keyword":"german","description":"\n\t\n\t\t\n\t\tDataset Card for \"nllb-200-10M-sample\"\n\t\n\nThis is a sample of nearly 10M sentence pairs from the NLLB-200 \nmined dataset allenai/nllb, \nscored with the model facebook/blaser-2.0-qe \ndescribed in the SeamlessM4T paper.\nThe sample is not random; instead, we just took the top n sentence pairs from each translation direction.\nThe number n was computed with the goal of upsamping the directions that contain underrepresented languages.\nNevertheless, the 187 languoids (language and scriptâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/slone/nllb-200-10M-sample.","url":"https://huggingface.co/datasets/slone/nllb-200-10M-sample","creator_name":"SLONE","creator_url":"https://huggingface.co/slone","license_name":"Open Data Commons Attribution License v1.0","license_url":"https://scancode-licensedb.aboutcode.org/odc-by-1.0.html","language":"en","first_N":5,"first_N_keywords":["translation","Akan","Amharic","Arabic","Awadhi"],"keywords_longer_than_N":true},
	{"name":"RyokoAI_ShareGPT52K","keyword":"german","description":"\n\t\n\t\t\n\t\tDataset Card for ShareGPT52K90K\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset is a collection of approximately 52,00090,000 conversations scraped via the ShareGPT API before it was shut down.\nThese conversations include both user prompts and responses from OpenAI's ChatGPT.\nThis repository now contains the new 90K conversations version. The previous 52K may\nbe found in the old/ directory.\n\n\t\n\t\t\n\t\tSupported Tasks and Leaderboards\n\t\n\n\ntext-generation\n\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nThis dataset isâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/botp/RyokoAI_ShareGPT52K.","url":"https://huggingface.co/datasets/botp/RyokoAI_ShareGPT52K","creator_name":"ab10","creator_url":"https://huggingface.co/botp","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","English","Spanish","German","multilingual"],"keywords_longer_than_N":true},
	{"name":"bible_para","keyword":"german","description":"This is a multilingual parallel corpus created from translations of the Bible compiled by Christos Christodoulopoulos and Mark Steedman.\n\n102 languages, 5,148 bitexts\ntotal number of files: 107\ntotal number of tokens: 56.43M\ntotal number of sentence fragments: 2.84M","url":"https://huggingface.co/datasets/Helsinki-NLP/bible_para","creator_name":"Language Technology Research Group at the University of Helsinki","creator_url":"https://huggingface.co/Helsinki-NLP","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":null,"first_N":5,"first_N_keywords":["translation","found","found","multilingual","original"],"keywords_longer_than_N":true},
	{"name":"CulturaY","keyword":"german","description":"\n\t\n\t\t\n\t\tCulturaY: A Large Cleaned Multilingual Dataset of 75 Languages\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nFrom the team that brought you CulturaX, we present CulturaY, another substantial multilingual dataset of 15TB (uncompressed)/3TB (zstd-compressed) that applies the same dataset cleaning methodology to the HPLT v1.1 dataset. \nPlease note that HPLT v1.2 has also been released and is an alternative verison with different cleaning methodolgies. \nThis data was used in part to train our SOTAâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Viet-Mistral/CulturaY.","url":"https://huggingface.co/datasets/Viet-Mistral/CulturaY","creator_name":"Vietnamese Mistral","creator_url":"https://huggingface.co/Viet-Mistral","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","fill-mask","language-modeling","masked-language-modeling","no-annotation"],"keywords_longer_than_N":true},
	{"name":"Fact-Completion","keyword":"german","description":"\n\t\n\t\t\n\t\tDataset Card\n\t\n\n\nHomepage: https://bit.ly/ischool-berkeley-capstone\nRepository: https://github.com/daniel-furman/Capstone\nPoint of Contact: daniel_furman@berkeley.edu\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis is the dataset for Polyglot or Not?: Measuring Multilingual Encyclopedic Knowledge Retrieval from Foundation Language Models.\n\n\t\n\t\t\n\t\n\t\n\t\tTest Description\n\t\n\n Given a factual association such as The capital of France is Paris, we determine whether a model adequately \"knows\" thisâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Polyglot-or-Not/Fact-Completion.","url":"https://huggingface.co/datasets/Polyglot-or-Not/Fact-Completion","creator_name":"Polyglot-or-Not","creator_url":"https://huggingface.co/Polyglot-or-Not","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","fill-mask","expert-generated","machine-generated","multilingual"],"keywords_longer_than_N":true},
	{"name":"massive_translation_dataset","keyword":"german","description":"\n\t\n\t\t\n\t\tDataset Card for Massive Dataset for Translation\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset is derived from AmazonScience/MASSIVE dataset for translation task purpose.\n\n\t\n\t\t\n\t\tSupported Tasks and Leaderboards\n\t\n\nTranslation\n\n\t\n\t\t\n\t\tLanguages\n\t\n\n\nEnglish (en_US)\nGerman (de_DE)\nHindi (hi_IN)\nSpanish (es_ES)\nFrench (fr_FR)\nItalian (it_IT)\nArabic (ar_SA)\nDutch (nl_NL)\nJapanese (ja_JP)\nPortugese (pt_PT)\n\n","url":"https://huggingface.co/datasets/Amani27/massive_translation_dataset","creator_name":"Amani N","creator_url":"https://huggingface.co/Amani27","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["translation","English","German","Spanish","Hindi"],"keywords_longer_than_N":true},
	{"name":"mc4_legal","keyword":"german","description":"\n\t\n\t\t\n\t\tDataset Card for MC4_Legal: A Corpus Covering the Legal Part of MC4 for European Languages\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset contains large text resources (~133GB in total) from mc4 filtered for legal data that can be used for pretraining language models.\nUse the dataset like this:\nfrom datasets import load_dataset\ndataset = load_dataset(\"joelito/mc4_legal\", \"de\", split='train', streaming=True)\n\n\n\t\n\t\t\n\t\n\t\n\t\tSupported Tasks and Leaderboards\n\t\n\nThe dataset supports the task ofâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/joelniklaus/mc4_legal.","url":"https://huggingface.co/datasets/joelniklaus/mc4_legal","creator_name":"Joel Niklaus","creator_url":"https://huggingface.co/joelniklaus","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["fill-mask","other","found","multilingual","original"],"keywords_longer_than_N":true},
	{"name":"SB10k","keyword":"german","description":"\n\t\n\t\t\n\t\tA Twitter corpus and benchmark resources for german sentiment analysis\n\t\n\n\n\t\n\t\t\n\t\tSource\n\t\n\nThe data is a snapshot from the SB10k Dataset.\nThe snapshot was made by Oliver Guhr.\n\n\t\n\t\t\n\t\tCitation Information\n\t\n\nPaper\n@inproceedings{cieliebak2017twitter,\n  title={A twitter corpus and benchmark resources for german sentiment analysis},\n  author={Cieliebak, Mark and Deriu, Jan Milan and Egger, Dominic and Uzdilli, Fatih},\n  booktitle={5th International Workshop on Natural Languageâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Alienmaster/SB10k.","url":"https://huggingface.co/datasets/Alienmaster/SB10k","creator_name":"Robert Geislinger","creator_url":"https://huggingface.co/Alienmaster","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","monolingual","German","cc-by-4.0","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"eurlex_resources","keyword":"german","description":"\n\t\n\t\t\n\t\tDataset Card for EurlexResources: A Corpus Covering the Largest EURLEX Resources\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset contains large text resources (~179GB in total) from EURLEX that can be used for pretraining language models.\nUse the dataset like this:\nfrom datasets import load_dataset\nconfig = \"de_caselaw\" # {lang}_{resource}\ndataset = load_dataset(\"joelito/eurlex_resources\", config, split='train', streaming=True) \n\n\n\t\n\t\t\n\t\n\t\n\t\tSupported Tasks and Leaderboards\n\t\n\nThe datasetâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/joelniklaus/eurlex_resources.","url":"https://huggingface.co/datasets/joelniklaus/eurlex_resources","creator_name":"Joel Niklaus","creator_url":"https://huggingface.co/joelniklaus","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":null,"first_N":5,"first_N_keywords":["fill-mask","other","found","multilingual","original"],"keywords_longer_than_N":true},
	{"name":"IndEgo","keyword":"german","description":"\n\t\n\t\t\n\t\tIndEgo: A Dataset of Industrial Scenarios and Collaborative Work for Egocentric Assistants\n\t\n\n\n\n\t\n\t\t\n\t\tAbstract:\n\t\n\nWe introduce IndEgo, a multimodal egocentric and exocentric video dataset capturing common industrial tasks such as assembly/disassembly, logistics and organisation, inspection and repair, and woodworking.The dataset includes 3,460 egocentric recordings (~197 hours) and 1,092 exocentric recordings (~97 hours).\n\nA central focus of IndEgo is collaborative work, where twoâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/FraunhoferIPK/IndEgo.","url":"https://huggingface.co/datasets/FraunhoferIPK/IndEgo","creator_name":"Fraunhofer IPK","creator_url":"https://huggingface.co/FraunhoferIPK","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["visual-question-answering","summarization","video-classification","any-to-any","English"],"keywords_longer_than_N":true},
	{"name":"Capybara-de","keyword":"german","description":"German version of LDJnr/Capybara. Translated using DeepL (informal style).\n\n\t\n\t\t\nlang\n#chars\n\n\n\t\t\nen\n71_102_832\n\n\nde\n81_422_005\n\n\n\t\n\n","url":"https://huggingface.co/datasets/maxidl/Capybara-de","creator_name":"Max Idahl","creator_url":"https://huggingface.co/maxidl","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","German","English","apache-2.0","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"germeval_14","keyword":"german","description":"The GermEval 2014 NER Shared Task builds on a new dataset with German Named Entity annotation with the following properties:    - The data was sampled from German Wikipedia and News Corpora as a collection of citations.    - The dataset covers over 31,000 sentences corresponding to over 590,000 tokens.    - The NER annotation uses the NoSta-D guidelines, which extend the TÃ¼bingen Treebank guidelines,      using four main NER categories with sub-structure, and annotating embeddings among NEs      such as [ORG FC Kickers [LOC Darmstadt]].","url":"https://huggingface.co/datasets/GermanEval/germeval_14","creator_name":"GermanEval","creator_url":"https://huggingface.co/GermanEval","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":null,"first_N":5,"first_N_keywords":["token-classification","named-entity-recognition","crowdsourced","found","monolingual"],"keywords_longer_than_N":true},
	{"name":"conceptnet5","keyword":"german","description":"\n\t\n\t\t\n\t\tDataset Card for Conceptnet5\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nConceptNet is a multilingual knowledge base, representing words and\nphrases that people use and the common-sense relationships between\nthem. The knowledge in ConceptNet is collected from a variety of\nresources, including crowd-sourced resources (such as Wiktionary and\nOpen Mind Common Sense), games with a purpose (such as Verbosity and\nnadya.jp), and expert-created resources (such as WordNet and JMDict).\nYou can browse whatâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/conceptnet5/conceptnet5.","url":"https://huggingface.co/datasets/conceptnet5/conceptnet5","creator_name":"conceptnet5","creator_url":"https://huggingface.co/conceptnet5","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","multi-class-classification","crowdsourced","crowdsourced","found"],"keywords_longer_than_N":true},
	{"name":"multilingual-sentiment-dataset","keyword":"german","description":"\n\t\n\t\t\n\t\tDataset Card for Dataset Name\n\t\n\n\n\nThis dataset card aims to be a base template for new datasets. It has been generated using this raw template.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\n\n\n\n\n\nCurated by: [More Information Needed]\nFunded by [optional]: [More Information Needed]\nShared by [optional]: [More Information Needed]\nLanguage(s) (NLP): [More Information Needed]\nLicense: [More Information Needed]\n\n\n\t\n\t\t\n\t\tDataset Sources [optional]\n\t\n\n\n\n\nRepository:\nBlpeng/nsmcâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Youseff1987/multilingual-sentiment-dataset.","url":"https://huggingface.co/datasets/Youseff1987/multilingual-sentiment-dataset","creator_name":"JOON HYOUNG JUN","creator_url":"https://huggingface.co/Youseff1987","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","Korean","Japanese","English","German"],"keywords_longer_than_N":true},
	{"name":"openlegaldata-bulk-data","keyword":"german","description":"\n\t\n\t\t\n\t\tDataset Card for openlegaldata.io bulk case data\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis is the copy of the lastest dump from openlegaldata.io. I will try to keep this updated, since there is no offical Huggingface Dataset Repo. \n\nHomepage: https://de.openlegaldata.io/\nRepository: Bulk Data\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis is the openlegaldata bulk case download from October 2022. Please refer to the offical website (above) for any more information. I have not made any changes forâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/LennardZuendorf/openlegaldata-bulk-data.","url":"https://huggingface.co/datasets/LennardZuendorf/openlegaldata-bulk-data","creator_name":"Lennard ZÃ¼ndorf","creator_url":"https://huggingface.co/LennardZuendorf","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","text-generation","German","mit","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"x-stance","keyword":"german","description":"The x-stance dataset contains more than 150 political questions, and 67k comments written by candidates on those questions. The comments are partly German, partly French and Italian. The data have been extracted from the Swiss voting advice platform Smartvote.","url":"https://huggingface.co/datasets/strombergnlp/x-stance","creator_name":"StrÃ¸mberg NLP","creator_url":"https://huggingface.co/strombergnlp","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","fact-checking","crowdsourced","found","multilingual"],"keywords_longer_than_N":true},
	{"name":"xP3x-sample","keyword":"german","description":"A multilingual collection of Winograd Schemas in six languages that can be used for evaluation of cross-lingual commonsense reasoning capabilities.","url":"https://huggingface.co/datasets/Muennighoff/xP3x-sample","creator_name":"Niklas Muennighoff","creator_url":"https://huggingface.co/Muennighoff","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["other","expert-generated","crowdsourced","multilingual","Afrikaans"],"keywords_longer_than_N":true},
	{"name":"openlegaldata-processed","keyword":"german","description":"\n\t\n\t\t\n\t\tDataset Card for openlegaldata.io bulk case data\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis is a edit/cleanup of Bulk Data of openlegaldata.io, which I also brought onto Huggingface here.\n\n\t\n\t\t\n\t\tThe Entire Dataset Is In German\n\t\n\n\nGithub Repository: [uniArchive-legalis]](https://github.com/LennardZuendorf/uniArchive-legalis)\nRepository: Bulk Data\n\n\n\t\n\t\t\n\t\tEdit Summary\n\t\n\nI have done some cleaning and splitting of the data and filtered out large parts that were not (easily) usable, cuttingâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/LennardZuendorf/openlegaldata-processed.","url":"https://huggingface.co/datasets/LennardZuendorf/openlegaldata-processed","creator_name":"Lennard ZÃ¼ndorf","creator_url":"https://huggingface.co/LennardZuendorf","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","German","mit","1K - 10K","parquet"],"keywords_longer_than_N":true},
	{"name":"truthful_qa-validation-german_q_n_a","keyword":"german","description":"Jakelolipopp/truthful_qa-validation-german_q_n_a dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/Jakelolipopp/truthful_qa-validation-german_q_n_a","creator_name":"Jake Lolipopp","creator_url":"https://huggingface.co/Jakelolipopp","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["German","apache-2.0","< 1K","parquet","Text"],"keywords_longer_than_N":true},
	{"name":"miracl-de-queries-22-12","keyword":"german","description":"\n\t\n\t\t\n\t\tMIRACL (de) embedded with cohere.ai multilingual-22-12 encoder\n\t\n\nWe encoded the MIRACL dataset using the cohere.ai multilingual-22-12 embedding model.\nThe query embeddings can be found in Cohere/miracl-de-queries-22-12 and the corpus embeddings can be found in Cohere/miracl-de-corpus-22-12.\nFor the orginal datasets, see miracl/miracl and miracl/miracl-corpus.\nDataset info:\n\nMIRACL ðŸŒðŸ™ŒðŸŒ (Multilingual Information Retrieval Across a Continuum of Languages) is a multilingual retrievalâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Cohere/miracl-de-queries-22-12.","url":"https://huggingface.co/datasets/Cohere/miracl-de-queries-22-12","creator_name":"Cohere","creator_url":"https://huggingface.co/Cohere","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","expert-generated","multilingual","German"],"keywords_longer_than_N":true},
	{"name":"sbb-dc-ocr","keyword":"german","description":"\n\t\n\t\t\n\t\tDataset Card for Berlin State Library OCR data\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\n\nThe digital collections of the SBB contain 153,942 digitized works from the time period of 1470 to 1945.\n\n\nAt the time of publication, 28,909 works have been OCR-processed resulting in 4,988,099 full-text pages.\nFor each page with OCR text, the language has been determined by langid (Lui/Baldwin 2012).\n\n\n\t\n\t\t\n\t\tSupported Tasks and Leaderboards\n\t\n\n\nlanguage-modeling: this dataset has the potential to be usedâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/SBB/sbb-dc-ocr.","url":"https://huggingface.co/datasets/SBB/sbb-dc-ocr","creator_name":"Staatsbibliothek zu Berlin - PreuÃŸischer Kulturbesitz","creator_url":"https://huggingface.co/SBB","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["fill-mask","text-generation","masked-language-modeling","language-modeling","machine-generated"],"keywords_longer_than_N":true},
	{"name":"hatecheck-german","keyword":"german","description":"\n\t\n\t\t\n\t\tDataset Card for Multilingual HateCheck\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nMultilingual HateCheck (MHC) is a suite of functional tests for hate speech detection models in 10 different languages: Arabic, Dutch, French, German, Hindi, Italian, Mandarin, Polish, Portuguese and Spanish.\nFor each language, there are 25+ functional tests that correspond to distinct types of hate and challenging non-hate.\nThis allows for targeted diagnostic insights into model performance.\nFor more detailsâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Paul/hatecheck-german.","url":"https://huggingface.co/datasets/Paul/hatecheck-german","creator_name":"Paul RÃ¶ttger","creator_url":"https://huggingface.co/Paul","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","hate-speech-detection","crowdsourced","expert-generated","monolingual"],"keywords_longer_than_N":true},
	{"name":"german_argument_mining","keyword":"german","description":"\n\t\n\t\t\n\t\tDataset Card for Annotated German Legal Decision Corpus\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset consists of 200 randomly chosen judgments. In these judgments a legal expert annotated the components\nconclusion, definition and subsumption of the German legal writing style Urteilsstil.\n\"Overall 25,075 sentences are annotated. 5% (1,202) of these sentences are marked as conclusion, 21% (5,328) as\ndefinition, 53% (13,322) are marked as subsumption and the remaining 21% (6,481) as other.â€¦ See the full description on the dataset page: https://huggingface.co/datasets/joelniklaus/german_argument_mining.","url":"https://huggingface.co/datasets/joelniklaus/german_argument_mining","creator_name":"Joel Niklaus","creator_url":"https://huggingface.co/joelniklaus","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","multi-class-classification","expert-generated","found","found"],"keywords_longer_than_N":true},
	{"name":"euronews","keyword":"german","description":"\n\t\n\t\t\n\t\tDataset Card for Europeana Newspapers\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tSupported Tasks and Leaderboards\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tLanguages\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\n\t\n\t\t\n\t\tData Instances\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tData Fields\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tData Splits\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tDataset Creation\n\t\n\n\n\t\n\t\t\n\t\tCuration Rationale\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tSourceâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/community-datasets/euronews.","url":"https://huggingface.co/datasets/community-datasets/euronews","creator_name":"Community Datasets","creator_url":"https://huggingface.co/community-datasets","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["token-classification","named-entity-recognition","expert-generated","crowdsourced","multilingual"],"keywords_longer_than_N":true},
	{"name":"blbooks","keyword":"german","description":"A dataset comprising of text created by OCR from the 49,455 digitised books, equating to 65,227 volumes (25+ million pages), published between c. 1510 - c. 1900.\nThe books cover a wide range of subject areas including philosophy, history, poetry and literature.","url":"https://huggingface.co/datasets/TheBritishLibrary/blbooks","creator_name":"British Library","creator_url":"https://huggingface.co/TheBritishLibrary","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":null,"first_N":5,"first_N_keywords":["text-generation","fill-mask","other","language-modeling","masked-language-modeling"],"keywords_longer_than_N":true},
	{"name":"iva_mt_wslot-exp","keyword":"german","description":"\\","url":"https://huggingface.co/datasets/cartesinus/iva_mt_wslot-exp","creator_name":"Marcin Sowanski","creator_url":"https://huggingface.co/cartesinus","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["translation","English","Polish","German","Spanish"],"keywords_longer_than_N":true},
	{"name":"dialect-at-tirol","keyword":"german","description":"\n\t\n\t\t\n\t\tDataset of Tyrolean Dialect (Austria)\n\t\n\nThis dataset contains 200+ words used in Tirol (Austria), together with their German translation and (optional) meaning.\n","url":"https://huggingface.co/datasets/morgendigital/dialect-at-tirol","creator_name":"Morgendigital","creator_url":"https://huggingface.co/morgendigital","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","German","apache-2.0","n<1K","ðŸ‡ºðŸ‡¸ Region: US"],"keywords_longer_than_N":false},
	{"name":"amazon_counterfactual","keyword":"german","description":"\n  AmazonCounterfactualClassification\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nA collection of Amazon customer reviews annotated for counterfactual detection pair classification.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2c\n\n\nDomains\nReviews, Written\n\nReference\nhttps://arxiv.org/abs/2104.06893\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask = mteb.get_tasks([\"AmazonCounterfactualClassification\"])â€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/amazon_counterfactual.","url":"https://huggingface.co/datasets/mteb/amazon_counterfactual","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","human-annotated","multilingual","German","English"],"keywords_longer_than_N":true},
	{"name":"Global-MMLU-Lite","keyword":"german","description":"\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nGlobal-MMLU-Lite is a multilingual evaluation set spanning 16 languages, including English. It is \"lite\" version of the original Global-MMLU dataset ðŸŒ.\nIt includes 200 Culturally Sensitive (CS) and 200 Culturally Agnostic (CA) samples per language. The samples in Global-MMLU-Lite are corresponding to languages which are fully human translated or post-edited in the original Global-MMLU dataset. \nNOTE: Of the 16 languages presently included in Global-MMLU-Lite, 15â€¦ See the full description on the dataset page: https://huggingface.co/datasets/CohereLabs/Global-MMLU-Lite.","url":"https://huggingface.co/datasets/CohereLabs/Global-MMLU-Lite","creator_name":"Cohere Labs","creator_url":"https://huggingface.co/CohereLabs","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["English","Arabic","Bengali","Spanish","French"],"keywords_longer_than_N":true},
	{"name":"germanrag-scored","keyword":"german","description":"\n\t\n\t\t\n\t\tModifications\n\t\n\nThis is the original and unchanged german translated dataset (train split only) in original order from DiscoResearch/germanrag with added cosine-similarity scores.\nThe scores between 'question' and 'answer' have been calculated using the best static multilingual embedding model (for my needs): sentence-transformers/static-similarity-mrl-multilingual-v1 for faster distinction if an answer corresponds to a query upon the content.\nIf you want to filter negative answersâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/MarcGrumpyOlejak/germanrag-scored.","url":"https://huggingface.co/datasets/MarcGrumpyOlejak/germanrag-scored","creator_name":"Marc Olejak","creator_url":"https://huggingface.co/MarcGrumpyOlejak","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","monolingual","German","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"uranus","keyword":"german","description":"\n\t\n\t\t\n\t\tðŸŒ€ Uranus Facts Dataset (Multilingual)\n\t\n\nThis repository contains a multilingual dataset of factual information about the planet Uranus, curated by Eris Dataworks under the open data initiative of Berinspa.\nThis dataset is designed for:\n\nMultilingual Natural Language Processing (NLP) tasks\nAstronomy education and data enrichment\nOpen science and translation projects\nLanguage learning using scientific content\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tðŸ“„ Dataset Details\n\t\n\nFilename: uranus.csvLanguages Included:â€¦ See the full description on the dataset page: https://huggingface.co/datasets/erisdataworks/uranus.","url":"https://huggingface.co/datasets/erisdataworks/uranus","creator_name":"Eris Dataworks","creator_url":"https://huggingface.co/erisdataworks","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["Indonesian","English","Spanish","German","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"StreamUni","keyword":"german","description":"\n\t\n\t\t\n\t\tThe training dataset for the paper 'StreamUni: Achieving Streaming Speech Translation with a Unified Large Speech-Language Model'\n\t\n\n\n\t\n\t\t\n\t\tModel\n\t\n\n\nhttps://huggingface.co/ICTNLP/StreamUni-Phi4\n\n\n\t\n\t\t\n\t\tGithub\n\t\n\n\nhttps://github.com/ictnlp/StreamUni\n\n","url":"https://huggingface.co/datasets/ICTNLP/StreamUni","creator_name":"Natural Language Processing Group, Institute of Computing Technology, Chinese Academy of Science","creator_url":"https://huggingface.co/ICTNLP","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["translation","Chinese","English","French","German"],"keywords_longer_than_N":true},
	{"name":"600chat_universe","keyword":"german","description":"\n\t\n\t\t\n\t\tðŸŒŒ Universe Q&A Multilingual Dataset (600 Rows)\n\t\n\nThis repository contains a multilingual Questionâ€“Answer dataset about the universe, created by Eris Dataworks as part of the Berinspa open science initiative.\nThe dataset covers a variety of astronomy topics such as planets, stars, galaxies, black holes, dark matter, and cosmology, translated into six languages.\n\n\n\t\n\t\t\n\t\n\t\n\t\tðŸ“„ Dataset Details\n\t\n\nFilename: universe_chat_dataset_600.csvLanguages Included:\n\nðŸ‡®ðŸ‡© Bahasa Indonesia  \nðŸ‡¬ðŸ‡§â€¦ See the full description on the dataset page: https://huggingface.co/datasets/erisdataworks/600chat_universe.","url":"https://huggingface.co/datasets/erisdataworks/600chat_universe","creator_name":"Eris Dataworks","creator_url":"https://huggingface.co/erisdataworks","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["Indonesian","English","Japanese","Chinese","Spanish"],"keywords_longer_than_N":true},
	{"name":"MeetingBank-transcript-de","keyword":"german","description":"This dataset consists of transcripts from the MeetingBank dataset. \nOverview\nMeetingBank, a benchmark dataset created from the city councils of 6 major U.S. cities to supplement existing datasets.\nIt contains 1,366 meetings with over 3,579 hours of video, as well as transcripts, PDF documents of meeting minutes, agenda, and other metadata.\nOn average, a council meeting is 2.6 hours long and its transcript contains over 28k tokens, making it a valuable testbed for meeting summarizers and forâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/AlioLeuchtmann/MeetingBank-transcript-de.","url":"https://huggingface.co/datasets/AlioLeuchtmann/MeetingBank-transcript-de","creator_name":"Alio Leuchtmann","creator_url":"https://huggingface.co/AlioLeuchtmann","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["translation","summarization","text-generation","machine-generated","machine-generated"],"keywords_longer_than_N":true},
	{"name":"Klipperai","keyword":"german","description":"IPNET/Klipperai dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/IPNET/Klipperai","creator_name":"daniel","creator_url":"https://huggingface.co/IPNET","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","Dutch","German","English","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"small_data_text","keyword":"german","description":"Miti-Komon/small_data_text dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/Miti-Komon/small_data_text","creator_name":"Miti Komon Hatashi","creator_url":"https://huggingface.co/Miti-Komon","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["German","apache-2.0","1K - 10K","text","Text"],"keywords_longer_than_N":true},
	{"name":"xsimplusplus","keyword":"german","description":"xSIM++ is an extension of xSIM. In comparison to xSIM, this evaluates using target-side data with additional synthetic, hard-to-distinguish examples. You can find more details about it in the publication: xSIM++: An Improved Proxy to Bitext Mining Performance for Low-Resource Languages.\n","url":"https://huggingface.co/datasets/jaygala24/xsimplusplus","creator_name":"Jay Gala","creator_url":"https://huggingface.co/jaygala24","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["derived","multilingual","Achinese","Mesopotamian Arabic","Ta'izzi-Adeni Arabic"],"keywords_longer_than_N":true},
	{"name":"cml-tts","keyword":"german","description":"\n\t\n\t\t\n\t\tDataset Card for CML-TTS\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nCML-TTS is a recursive acronym for CML-Multi-Lingual-TTS, a Text-to-Speech (TTS) dataset developed at the Center of Excellence in Artificial Intelligence (CEIA) of the Federal University of Goias (UFG).\nCML-TTS is a dataset comprising audiobooks sourced from the public domain books of Project Gutenberg, read by volunteers from the LibriVox project. The dataset includes recordings in Dutch, German, French, Italian, Polishâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/ylacombe/cml-tts.","url":"https://huggingface.co/datasets/ylacombe/cml-tts","creator_name":"Yoach Lacombe","creator_url":"https://huggingface.co/ylacombe","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-to-speech","text-to-audio","Dutch","French","German"],"keywords_longer_than_N":true},
	{"name":"truthfulqax","keyword":"german","description":"\n\t\n\t\t\n\t\tCitation Information\n\t\n\nIf you find benchmarks useful in your research, please consider citing the test and also the TruthfulQA dataset it draws from:\n    @misc{thellmann2024crosslingual,\n    title={Towards Cross-Lingual LLM Evaluation for European Languages},\n    author={Klaudia Thellmann and Bernhard Stadler and Michael Fromm and Jasper Schulze Buschhoff and Alex Jude and Fabio Barth and Johannes Leveling and Nicolas Flores-Herr and Joachim KÃ¶hler and RenÃ© JÃ¤kel and Mehdi Ali}â€¦ See the full description on the dataset page: https://huggingface.co/datasets/Eurolingua/truthfulqax.","url":"https://huggingface.co/datasets/Eurolingua/truthfulqax","creator_name":"EuroLingua-GPT","creator_url":"https://huggingface.co/Eurolingua","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":null,"first_N":5,"first_N_keywords":["text-generation","German","French","Spanish","Italian"],"keywords_longer_than_N":true},
	{"name":"SiMT-De-En-660K","keyword":"german","description":"660K De-En SiMT training data for EAST (paper and code).\n","url":"https://huggingface.co/datasets/biaofu-xmu/SiMT-De-En-660K","creator_name":"Biao Fu","creator_url":"https://huggingface.co/biaofu-xmu","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["German","English","apache-2.0","100K - 1M","json"],"keywords_longer_than_N":true},
	{"name":"Buergerliches_Gesetzbuch_BGB","keyword":"german","description":"\n\t\n\t\t\n\t\tGerman BGB Law Dataset (BÃ¼rgerliches Gesetzbuch)\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThe BGB Law Dataset contains legal text from the German Civil Code (BÃ¼rgerliches Gesetzbuch - BGB). It focuses on the general principles of German civil law, and the dataset is designed for tasks related to legal text analysis.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\n\t\n\t\t\n\t\tData Instances\n\t\n\nA typical data point in the dataset comprises a legal paragraph and its corresponding text. For example:\n{\n 'paragraph': 'Â§ 1â€¦ See the full description on the dataset page: https://huggingface.co/datasets/nookbe/Buergerliches_Gesetzbuch_BGB.","url":"https://huggingface.co/datasets/nookbe/Buergerliches_Gesetzbuch_BGB","creator_name":"legal","creator_url":"https://huggingface.co/nookbe","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","German","mit","1K - 10K","json"],"keywords_longer_than_N":true},
	{"name":"saturnus","keyword":"german","description":"\n\t\n\t\t\n\t\tðŸª Saturn Facts Dataset (Multilingual)\n\t\n\nThis repository contains a multilingual dataset of scientific facts about the planet Saturn, compiled by Eris Dataworks, an open data initiative under Berinspa.\nThe dataset is ideal for:\n\nMultilingual NLP training and evaluation\nAstronomy education and content development\nScientific fact-based applications\nLanguage learning through planetary knowledge\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tðŸ“„ Dataset Information\n\t\n\nFile: saturnus.csvLanguages Included:\n\nðŸ‡®ðŸ‡© Bahasaâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/erisdataworks/saturnus.","url":"https://huggingface.co/datasets/erisdataworks/saturnus","creator_name":"Eris Dataworks","creator_url":"https://huggingface.co/erisdataworks","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["Indonesian","English","Spanish","German","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"biblenlp-corpus-mmteb","keyword":"german","description":"This dataset pre-computes all English-centric directions from bible-nlp/biblenlp-corpus, and as a result loading is significantly faster.\nLoading example:\n>>> from datasets import load_dataset\n>>> dataset = load_dataset(\"davidstap/biblenlp-corpus-mmteb\", \"eng-arb\", trust_remote_code=True)\n>>> dataset\nDatasetDict({\n    train: Dataset({\n        features: ['eng', 'arb'],\n        num_rows: 28723\n    })\n    validation: Dataset({\n        features: ['eng', 'arb'],\n        num_rows: 1578\n    })â€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/biblenlp-corpus-mmteb.","url":"https://huggingface.co/datasets/mteb/biblenlp-corpus-mmteb","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["no-annotation","expert-generated","translation","multilingual","Arifama-Miniafia"],"keywords_longer_than_N":true},
	{"name":"biblenlp-corpus-mmteb","keyword":"german","description":"This dataset pre-computes all English-centric directions from bible-nlp/biblenlp-corpus, and as a result loading is significantly faster.\nLoading example:\n>>> from datasets import load_dataset\n>>> dataset = load_dataset(\"davidstap/biblenlp-corpus-mmteb\", \"eng-arb\", trust_remote_code=True)\n>>> dataset\nDatasetDict({\n    train: Dataset({\n        features: ['eng', 'arb'],\n        num_rows: 28723\n    })\n    validation: Dataset({\n        features: ['eng', 'arb'],\n        num_rows: 1578\n    })â€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/biblenlp-corpus-mmteb.","url":"https://huggingface.co/datasets/mteb/biblenlp-corpus-mmteb","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["no-annotation","expert-generated","translation","multilingual","Arifama-Miniafia"],"keywords_longer_than_N":true},
	{"name":"SauerkrautLM-Fermented-GER-DPO","keyword":"german","description":"\n\n\t\n\t\t\n\t\tSauerkrautLM-Fermented-GER-DPO Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nSauerkrautLM-Fermented-GER-DPO is a high-quality German instruction-response dataset specifically designed for Direct Preference Optimization (DPO) training. The dataset consists of 3,305 instruction-response pairs. Rather than being merged from existing German datasets, it was carefully created through a sophisticated augmentation process, transforming curated English instructions and responses into culturally adaptedâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/VAGOsolutions/SauerkrautLM-Fermented-GER-DPO.","url":"https://huggingface.co/datasets/VAGOsolutions/SauerkrautLM-Fermented-GER-DPO","creator_name":"VAGO solutions","creator_url":"https://huggingface.co/VAGOsolutions","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-generation","German","mit","1K - 10K","parquet"],"keywords_longer_than_N":true},
	{"name":"Thinking-multilingual-big-10k-sft","keyword":"german","description":"\nA dataset based off of openo1 math, 500 examples translated to 23 different languages. filtered out un-translated examples.\nenjoy ðŸ‘\n","url":"https://huggingface.co/datasets/Pinkstack/Thinking-multilingual-big-10k-sft","creator_name":"Pinkstack","creator_url":"https://huggingface.co/Pinkstack","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","Arabic","Chinese","Czech","Danish"],"keywords_longer_than_N":true},
	{"name":"jinaai_jina-embeddings-v2-base-en-03092024-wh9d-webapp","keyword":"german","description":"\n\t\n\t\t\n\t\tjinaai_jina-embeddings-v2-base-en-03092024-wh9d-webapp Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"health insurance information\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the jinaai_jina-embeddings-v2-base-en-03092024-wh9d-webapp model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Huggingâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/jinaai_jina-embeddings-v2-base-en-03092024-wh9d-webapp.","url":"https://huggingface.co/datasets/fine-tuned/jinaai_jina-embeddings-v2-base-en-03092024-wh9d-webapp","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","German","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"S4PLANTRAIN240427","keyword":"german","description":"HDBrinkmann/S4PLANTRAIN240427 dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/HDBrinkmann/S4PLANTRAIN240427","creator_name":"Brinkmann","creator_url":"https://huggingface.co/HDBrinkmann","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["question-answering","German","apache-2.0","1K - 10K","csv"],"keywords_longer_than_N":true},
	{"name":"RTE3","keyword":"german","description":"\n  RTE3\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nRecognising Textual Entailment Challenge (RTE-3) aim to provide the NLP community with a benchmark to test progress in recognizing textual entailment\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2t\n\n\nDomains\nNews, Web, Encyclopaedic, Written\nReference\nhttps://aclanthology.org/W07-1401/\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask = mteb.get_task(\"RTE3\")â€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/RTE3.","url":"https://huggingface.co/datasets/mteb/RTE3","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","semantic-similarity-classification","natural-language-inference","expert-annotated","multilingual"],"keywords_longer_than_N":true},
	{"name":"synthetic-pii-ner-mistral-v1","keyword":"german","description":"This the synthetic dataset used for training https://huggingface.co/urchade/gliner_multi_pii-v1. You can get it by browsing the files and dowloading the data.json file.\n","url":"https://huggingface.co/datasets/urchade/synthetic-pii-ner-mistral-v1","creator_name":"Urchade Zaratiana","creator_url":"https://huggingface.co/urchade","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["English","French","Italian","German","Spanish"],"keywords_longer_than_N":true},
	{"name":"minds14","keyword":"german","description":"\n\t\n\t\t\n\t\tMInDS-14\n\t\n\nMINDS-14 is training and evaluation resource for intent detection task with spoken data. It covers 14 \nintents extracted from a commercial system in the e-banking domain, associated with spoken examples in 14 diverse language varieties.\n\n\t\n\t\t\n\t\tExample\n\t\n\nMInDS-14 can be downloaded and used as follows:\nfrom datasets import load_dataset\n\nminds_14 = load_dataset(\"PolyAI/minds14\", \"fr-FR\") # for French\n# to download all data for multi-lingual fine-tuning uncomment followingâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/PolyAI/minds14.","url":"https://huggingface.co/datasets/PolyAI/minds14","creator_name":"PolyAI","creator_url":"https://huggingface.co/PolyAI","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","keyword-spotting","expert-generated","crowdsourced","machine-generated"],"keywords_longer_than_N":true},
	{"name":"OGC_MEGA_MultiDomain_DocRetrieval","keyword":"german","description":"\n\t\n\t\t\n\t\tVisual Document Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is designed for training visual document retrieval models. It combines multiple datasets from the OGC series, Colpali, and LlamaIndex to create the most comprehensive training resource for visual document retrieval tasks.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nThe dataset contains structured fields including unique identifiers with string lengths ranging from 45 to 50 characters, search query text with variable lengths betweenâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/racineai/OGC_MEGA_MultiDomain_DocRetrieval.","url":"https://huggingface.co/datasets/racineai/OGC_MEGA_MultiDomain_DocRetrieval","creator_name":"racine.ai","creator_url":"https://huggingface.co/racineai","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["visual-document-retrieval","text-retrieval","multilingual","English","French"],"keywords_longer_than_N":true},
	{"name":"amazon_massive_scenario","keyword":"german","description":"\n  MassiveScenarioClassification\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nMASSIVE: A 1M-Example Multilingual Natural Language Understanding Dataset with 51 Typologically-Diverse Languages\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2c\n\n\nDomains\nSpoken\n\nReference\nhttps://arxiv.org/abs/2204.08582\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask = mteb.get_tasks([\"MassiveScenarioClassification\"])\nevaluator =â€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/amazon_massive_scenario.","url":"https://huggingface.co/datasets/mteb/amazon_massive_scenario","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","human-annotated","translated","Afrikaans","Amharic"],"keywords_longer_than_N":true},
	{"name":"MAiDE-up","keyword":"german","description":"\n\t\n\t\t\n\t\tDataset Card for MAiDE-up: Multilingual Deception Detection of GPT-generated Hotel Reviews\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nMultilingual Deception Detection of GPT-generated Hotel Reviews. We compare real hotel reviews from Booking with LLM-generated hotel reviews in 10 languages.\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nThe text in the dataset is in 10 languages: Chinese, English, French, German, Italian, Romanian, Korean, Russian, Spanish, Turkish\n\n\t\n\t\t\n\t\tSupported Tasks and Leaderboards\n\t\n\nTODOâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/MichiganNLP/MAiDE-up.","url":"https://huggingface.co/datasets/MichiganNLP/MAiDE-up","creator_name":"LIT @ UMich","creator_url":"https://huggingface.co/MichiganNLP","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","zero-shot-classification","English","Chinese","French"],"keywords_longer_than_N":true},
	{"name":"TxT360-500k-sample-no_cc","keyword":"german","description":"\n\t\n\t\t\n\t\tBEE-spoke-data/TxT360-500k-sample-no_cc\n\t\n\nno common crawl\n","url":"https://huggingface.co/datasets/BEE-spoke-data/TxT360-500k-sample-no_cc","creator_name":"BEEspoke Data","creator_url":"https://huggingface.co/BEE-spoke-data","license_name":"Open Data Commons Attribution License v1.0","license_url":"https://scancode-licensedb.aboutcode.org/odc-by-1.0.html","language":"en","first_N":5,"first_N_keywords":["text-generation","feature-extraction","English","German","Japanese"],"keywords_longer_than_N":true},
	{"name":"campus-ride-hailing","keyword":"german","description":"\n\t\n\t\t\n\t\tDataset Card for Dataset Name\n\t\n\nThis dataset simulates realistic ride hailing demand patterns in a university campus environment by transforming real-world bike sharing trip data into ride hailing scenarios. The synthetic generation preserves temporal demand patterns and spatial distributions while adapting the characteristics for ride hailing services. This makes it valuable for transportation research, demand forecasting, and mobility optimization algorithms without privacyâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/oemer450/campus-ride-hailing.","url":"https://huggingface.co/datasets/oemer450/campus-ride-hailing","creator_name":"Ã–mer Erduran","creator_url":"https://huggingface.co/oemer450","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":null,"first_N":5,"first_N_keywords":["reinforcement-learning","German","English","apache-2.0","1K<n<10K"],"keywords_longer_than_N":true},
	{"name":"tatoeba_21-dec-2024","keyword":"german","description":"I would recommend anyone to download the most recent version of the files directly from Tatoeba. \nSince the most recent version of the dataset on huggingface is already quite old, I uploaded today's versions of the Tatoeba sentences. I uploaded the full dataset, as well as some files for some individual languages that I happen to speak. Honorable mention to Gronings, language code gos.\nExample code to download the most recent version of the Tatoeba dataset:\nimport requests\n\nwithâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Tom9358/tatoeba_21-dec-2024.","url":"https://huggingface.co/datasets/Tom9358/tatoeba_21-dec-2024","creator_name":"Tom","creator_url":"https://huggingface.co/Tom9358","license_name":"Creative Commons Attribution 2.0","license_url":"https://scancode-licensedb.aboutcode.org/cc-by-2.0.html","language":"en","first_N":5,"first_N_keywords":["translation","Dutch","English","German","Spanish"],"keywords_longer_than_N":true},
	{"name":"tweet_sentiment_multilingual","keyword":"german","description":"\n  TweetSentimentClassification\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nA multilingual Sentiment Analysis dataset consisting of tweets in 8 different languages.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2c\n\n\nDomains\nSocial, Written\n\n\nReferencehttps://aclanthology.org/2022.lrec-1.27\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask = mteb.get_tasks([\"TweetSentimentClassification\"])\nevaluator =â€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/tweet_sentiment_multilingual.","url":"https://huggingface.co/datasets/mteb/tweet_sentiment_multilingual","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"Creative Commons Attribution 3.0","license_url":"https://scancode-licensedb.aboutcode.org/cc-by-3.0.html","language":"en","first_N":5,"first_N_keywords":["text-classification","sentiment-analysis","sentiment-scoring","sentiment-classification","hate-speech-detection"],"keywords_longer_than_N":true},
	{"name":"mewsli-x","keyword":"german","description":"I generated the dataset following mewsli-x.md#getting-started\nand converted into different parts (see process.py):\n\nar/de/en/es/fa/ja/pl/ro/ta/tr/uk wikinews_mentions dev and test (from wikinews_mentions-dev/test.jsonl)\ncandidate entities of 50 languages (from candidate_set_entities.jsonl)\nEnglish wikipedia_pairs to fine-tune models (from wikipedia_pairs-dev/train.jsonl)\n\nRaw data files are in raw.tar.gz, which contains:\n[...] 535M Feb 24 22:06 candidate_set_entities.jsonl\n[...] 9.8M Feb 24â€¦ See the full description on the dataset page: https://huggingface.co/datasets/izhx/mewsli-x.","url":"https://huggingface.co/datasets/izhx/mewsli-x","creator_name":"Xin Zhang","creator_url":"https://huggingface.co/izhx","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","entity-linking-retrieval","Afrikaans","Arabic","Azerbaijani"],"keywords_longer_than_N":true},
	{"name":"jinaai_jina-embeddings-v2-base-en-03092024-jdbf-webapp","keyword":"german","description":"\n\t\n\t\t\n\t\tjinaai_jina-embeddings-v2-base-en-03092024-jdbf-webapp Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"health insurance domain\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the jinaai_jina-embeddings-v2-base-en-03092024-jdbf-webapp model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Faceâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/jinaai_jina-embeddings-v2-base-en-03092024-jdbf-webapp.","url":"https://huggingface.co/datasets/fine-tuned/jinaai_jina-embeddings-v2-base-en-03092024-jdbf-webapp","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","German","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"jinaai_jina-embeddings-v2-base-en-03092024-jdbf-webapp","keyword":"german","description":"\n\t\n\t\t\n\t\tjinaai_jina-embeddings-v2-base-en-03092024-jdbf-webapp Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"health insurance domain\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the jinaai_jina-embeddings-v2-base-en-03092024-jdbf-webapp model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Hugging Faceâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/jinaai_jina-embeddings-v2-base-en-03092024-jdbf-webapp.","url":"https://huggingface.co/datasets/fine-tuned/jinaai_jina-embeddings-v2-base-en-03092024-jdbf-webapp","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","German","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"lidl-ch-products","keyword":"german","description":"\n\t\n\t\t\n\t\tLidl Switzerland Products\n\t\n\nAll products and their information from Lidl Switzerland.\nThe entire catalogue and the current special discounts are all included.\nProduct information contains:\n\nName\nPrice\nPrice Text\nUnit of product\nUnit price\nIf it is discounted\nDiscount information\nProduct category\nImage URL\nProduct URL\n\nCheck out similar datasets for other grocery stores\n\nhttps://huggingface.co/datasets/Yelinz/migros-ch-products\nhttps://huggingface.co/datasets/Yelinz/coop-ch-productsâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Yelinz/lidl-ch-products.","url":"https://huggingface.co/datasets/Yelinz/lidl-ch-products","creator_name":"Yelin Z.","creator_url":"https://huggingface.co/Yelinz","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","German","cc-by-4.0","100K - 1M","csv"],"keywords_longer_than_N":true},
	{"name":"SpeechQE-CoVoST2","keyword":"german","description":"\n\t\n\t\t\n\t\tSpeechQE: Estimating the Quality of Direct Speech Translation\n\t\n\nThis is a benchmark and training corpus for the task of quality estimation for speech translation (SpeechQE).\nWe subsample about 80k segments from the training set and 500 from the dev and test of CoVoST2, then run seven different direct ST models to generate the ST hypotheses.\nSo,test split consists of 3500 instances(500*7). We also provide splits for each translation model.\n*(We provide test split first, and theâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/h-j-han/SpeechQE-CoVoST2.","url":"https://huggingface.co/datasets/h-j-han/SpeechQE-CoVoST2","creator_name":"HyoJung Han","creator_url":"https://huggingface.co/h-j-han","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["German","Spanish","English","mit","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"prompt-injection-multilingual","keyword":"german","description":"rikka-snow/prompt-injection-multilingual dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/rikka-snow/prompt-injection-multilingual","creator_name":"Le Xuan Hoang","creator_url":"https://huggingface.co/rikka-snow","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","Vietnamese","English","Chinese","French"],"keywords_longer_than_N":true},
	{"name":"mmarco-de-distilled-scored","keyword":"german","description":"\n\t\n\t\t\n\t\tModifications\n\t\n\nThis is a distilled (reduced) \"german only\" dataset (train split only) version still in original order from unicamp-dl/mmarco with added cosine-similarity scores. The full source of mmarco by unicamp is hosted in the repository on GitHub.\nThe scores between 'query' and 'text' have been calculated using the best static multilingual embedding model (for my needs): sentence-transformers/static-similarity-mrl-multilingual-v1 for faster distinction if an answer correspondsâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/MarcGrumpyOlejak/mmarco-de-distilled-scored.","url":"https://huggingface.co/datasets/MarcGrumpyOlejak/mmarco-de-distilled-scored","creator_name":"Marc Olejak","creator_url":"https://huggingface.co/MarcGrumpyOlejak","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","monolingual","German","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"Sentiment-Reasoning","keyword":"german","description":"\n\t\n\t\t\n\t\tSentiment Reasoning for Healthcare\n\t\n\nACL 2025 Industry Track (Oral)\nKhai-Nguyen Nguyen*, Khai Le-Duc*, Bach Phan Tat, Duy Le, Long Vo-Dang, Truong-Son Hy\n\n*Equal contribution\n\n\nPlease press â­ button and/or cite papers if you feel helpful.\n\n\n  \n\nSentiment Reasoning pipeline\n\n\nPaper: Sentiment Reasoning for Healthcare\n\nCode: https://github.com/leduckhai/Sentiment-Reasoning\n\nAbstract:Transparency in AI healthcare decision-making is crucial. By incorporating rationales to explain reasonâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/leduckhai/Sentiment-Reasoning.","url":"https://huggingface.co/datasets/leduckhai/Sentiment-Reasoning","creator_name":"Le Duc Khai","creator_url":"https://huggingface.co/leduckhai","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-generation","text-classification","audio-classification","automatic-speech-recognition","audio-text-to-text"],"keywords_longer_than_N":true},
	{"name":"toxicity-multilingual-binary-classification-dataset","keyword":"german","description":"This dataset is a comprehensive collection designed to aid in the development of robust and nuanced models for identifying toxic language across multiple languages, while critically distinguishing it from expressions related to mental health, specifically depression. It synthesizes content from three existing public datasets (ToxiGen, TextDetox, and Mental Health - Depression) with a newly generated synthetic dataset (ToxiLLaMA). The creation process involved careful collection, extensiveâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/malexandersalazar/toxicity-multilingual-binary-classification-dataset.","url":"https://huggingface.co/datasets/malexandersalazar/toxicity-multilingual-binary-classification-dataset","creator_name":"Alexander Salazar","creator_url":"https://huggingface.co/malexandersalazar","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["English","German","French","Italian","Portuguese"],"keywords_longer_than_N":true},
	{"name":"terra-xplain-cc-de","keyword":"german","description":"\n\t\n\t\t\n\t\tDataset Card for Terra-Xplain-CC-de\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nA high quality text dataset in german. Scraped from https://terraxplaincommons.zdf.de/\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset contains 283 items, including title, short_text and text for various domains.\n48833 words.\n\n\t\n\t\t\n\t\tSupported Tasks and Leaderboards\n\t\n\nText Generation, DPO finetuning for response length preference\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nGerman only\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n{\n  \"url\": \"source url\"â€¦ See the full description on the dataset page: https://huggingface.co/datasets/D4ve-R/terra-xplain-cc-de.","url":"https://huggingface.co/datasets/D4ve-R/terra-xplain-cc-de","creator_name":"David","creator_url":"https://huggingface.co/D4ve-R","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","text2text-generation","German","cc-by-4.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"Topic-specific-genre-classification_german_historical-newspapers","keyword":"german","description":"\n\t\n\t\t\n\t\tDataset Card for Topic-specific Genre Classification of German Historical Newspapers\n\t\n\nThis dataset was developed to train and evaluate topic-specific genre classification of German-language historical newspaper clippings. \n\nCurated by: [Sarah Oberbichler]\nLanguage(s) (NLP): [German]\nLicense: [afl-3.0]\n\n\n\t\n\t\t\n\t\tUses\n\t\n\n\nEvaluation of machine learning models for topic-specific classification of ocr-processed historical texts with varying quality levels.\nFine-tuning models onâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/oberbics/Topic-specific-genre-classification_german_historical-newspapers.","url":"https://huggingface.co/datasets/oberbics/Topic-specific-genre-classification_german_historical-newspapers","creator_name":"Oberbichler","creator_url":"https://huggingface.co/oberbics","license_name":"Academic Free License v3.0","license_url":"https://choosealicense.com/licenses/afl-3.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","German","afl-3.0","< 1K","csv"],"keywords_longer_than_N":true},
	{"name":"German-RAG-EMBEDDING-BENCHMARK","keyword":"german","description":"\n\t\n\t\t\n\t\tGerman-RAG-EMBEDDING-BENCHMARK\n\t\n\n\n\t\n\t\t\n\t\tGerman-RAG - German Retrieval Augmented Generation\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis German-RAG-EMBEDDING-BENCHMARK represents a specialized collection for evaluating embedding models.\nYou can use this dataset with this Evaluation Notebook in Colab:\nhttps://colab.research.google.com/drive/1KlIRchSlCtKg9C_bZkdWaYLxROeB0Fr_?usp=sharing\nAdditonally we have evaluated our Models on German Subsets of the MTEB Benchmark with this Evaluation Notebookâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/avemio/German-RAG-EMBEDDING-BENCHMARK.","url":"https://huggingface.co/datasets/avemio/German-RAG-EMBEDDING-BENCHMARK","creator_name":"Avemio AG","creator_url":"https://huggingface.co/avemio","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","German","mit","1K - 10K","json"],"keywords_longer_than_N":true},
	{"name":"aac","keyword":"german","description":"Cesarus/aac dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/Cesarus/aac","creator_name":"Stefan Maier","creator_url":"https://huggingface.co/Cesarus","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["German","apache-2.0","< 1K","json","Text"],"keywords_longer_than_N":true},
	{"name":"ApolloMoEDataset","keyword":"german","description":"\n\t\n\t\t\n\t\tDemocratizing Medical LLMs For Much More Languages\n\t\n\nCovering 12 Major Languages including English, Chinese, French, Hindi, Spanish, Arabic, Russian, Japanese, Korean, German, Italian, Portuguese and 38 Minor Languages So far.\n\n   ðŸ“ƒ Paper â€¢ ðŸŒ Demo â€¢ ðŸ¤— ApolloMoEDataset â€¢ ðŸ¤— ApolloMoEBench  â€¢ ðŸ¤— Models  â€¢ðŸŒ Apollo  â€¢ ðŸŒ ApolloMoE\n\n\n\n\n\n\n\t\n\t\t\n\t\tðŸŒˆ Update\n\t\n\n\n[2024.10.15] ApolloMoE repo is publishedï¼ðŸŽ‰\n\n\n\t\n\t\t\n\t\tLanguages Coverage\n\t\n\n12 Major Languages and 38 Minor Languages\n\n  Click toâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/FreedomIntelligence/ApolloMoEDataset.","url":"https://huggingface.co/datasets/FreedomIntelligence/ApolloMoEDataset","creator_name":"FreedomAI","creator_url":"https://huggingface.co/FreedomIntelligence","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["question-answering","Arabic","English","Chinese","Korean"],"keywords_longer_than_N":true},
	{"name":"rechtsprechungen-dump","keyword":"german","description":"\n\t\n\t\t\n\t\tGerman Case Law Dump\n\t\n\nThis dataset contains 78,909 documents of current German court decisions (as of July 30, 2025) collected from rechtsprechung-im-internet.de.  \nThe documents are sourced from various courts and types:\n\n\t\n\t\t\nCourt\nTypes\nDocuments\n\n\n\t\t\nBAG\nKARE\n7,033\n\n\nBFH\nSTRE\n11,150\n\n\nBGH\nJURE\n6,164\n\n\nBGH\nKORE\n25,992\n\n\nBPatG\nJURE\n5,866\n\n\nBPatG\nMPRE\n1,311\n\n\nBSG\nKSRE\n6,121\n\n\nBVerfG\nKVRE\n5,507\n\n\nBVerwG\nJURE\n553\nBVerwG\nWBRE\n9,210\n\n\n\t\n\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\nThe dataset isâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/elenanereiss/rechtsprechungen-dump.","url":"https://huggingface.co/datasets/elenanereiss/rechtsprechungen-dump","creator_name":"Elena Leitner","creator_url":"https://huggingface.co/elenanereiss","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["fill-mask","German","cc0-1.0","10K - 100K","json"],"keywords_longer_than_N":true},
	{"name":"rechtsprechungen-dump","keyword":"german","description":"\n\t\n\t\t\n\t\tGerman Case Law Dump\n\t\n\nThis dataset contains 78,909 documents of current German court decisions (as of July 30, 2025) collected from rechtsprechung-im-internet.de.  \nThe documents are sourced from various courts and types:\n\n\t\n\t\t\nCourt\nTypes\nDocuments\n\n\n\t\t\nBAG\nKARE\n7,033\n\n\nBFH\nSTRE\n11,150\n\n\nBGH\nJURE\n6,164\n\n\nBGH\nKORE\n25,992\n\n\nBPatG\nJURE\n5,866\n\n\nBPatG\nMPRE\n1,311\n\n\nBSG\nKSRE\n6,121\n\n\nBVerfG\nKVRE\n5,507\n\n\nBVerwG\nJURE\n553\nBVerwG\nWBRE\n9,210\n\n\n\t\n\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\nThe dataset isâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/elenanereiss/rechtsprechungen-dump.","url":"https://huggingface.co/datasets/elenanereiss/rechtsprechungen-dump","creator_name":"Elena Leitner","creator_url":"https://huggingface.co/elenanereiss","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["fill-mask","German","cc0-1.0","10K - 100K","json"],"keywords_longer_than_N":true},
	{"name":"german-oasst1-qa-format-scored","keyword":"german","description":"\n\t\n\t\t\n\t\tModifications\n\t\n\nThis is the original and unchanged german translated dataset (train and validation splits) in original order from AgentWaller/german-oasst1-qa-format with added cosine-similarity scores.\nThe scores have been calculated using the best static multilingual embedding model (for my needs): sentence-transformers/static-similarity-mrl-multilingual-v1 for faster distinction if an answer corresponds to a query upon the content.\n\n\t\n\t\t\n\t\n\t\n\t\tWhy?\n\t\n\nTo build an experimentalâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/MarcGrumpyOlejak/german-oasst1-qa-format-scored.","url":"https://huggingface.co/datasets/MarcGrumpyOlejak/german-oasst1-qa-format-scored","creator_name":"Marc Olejak","creator_url":"https://huggingface.co/MarcGrumpyOlejak","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","German","apache-2.0","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"munich-public-services","keyword":"german","description":"\n\t\n\t\t\n\t\tDataset Card for \"Munich Public Services\"\n\t\n\nzur deutschen Dokumentation\n\nThis dataset contains information about the services provided to the public by the City of Munich in the form of written articles, corresponding metadata as well as embeddings.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\n\nThe Munich Public Services dataset contains around 1.400 articles about various public services provided by the City of Munich.\nNext to the content of the articles, the datasetâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/it-at-m/munich-public-services.","url":"https://huggingface.co/datasets/it-at-m/munich-public-services","creator_name":"it@M","creator_url":"https://huggingface.co/it-at-m","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","German","English","mit","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"munich-public-services","keyword":"german","description":"\n\t\n\t\t\n\t\tDataset Card for \"Munich Public Services\"\n\t\n\nzur deutschen Dokumentation\n\nThis dataset contains information about the services provided to the public by the City of Munich in the form of written articles, corresponding metadata as well as embeddings.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\n\nThe Munich Public Services dataset contains around 1.400 articles about various public services provided by the City of Munich.\nNext to the content of the articles, the datasetâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/it-at-m/munich-public-services.","url":"https://huggingface.co/datasets/it-at-m/munich-public-services","creator_name":"it@M","creator_url":"https://huggingface.co/it-at-m","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","German","English","mit","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"MLSNT","keyword":"german","description":"\n\t\n\t\t\n\t\tMLSNT: Multi-Lingual Social Network Toxicity Dataset\n\t\n\nMLSNT is a multi-lingual dataset for toxicity detection created through a large language model-assisted label transfer pipeline. It enables efficient and scalable moderation across languages and platforms, and is built to support span-level and category-specific classification for toxic content.\nThis dataset is introduced in the following paper:\n\nUnified Game Moderation: Soft-Prompting and LLM-Assisted Label Transfer forâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/ComplexDataLab/MLSNT.","url":"https://huggingface.co/datasets/ComplexDataLab/MLSNT","creator_name":"Complex Data Lab","creator_url":"https://huggingface.co/ComplexDataLab","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","Chinese","Japanese","Portuguese"],"keywords_longer_than_N":true},
	{"name":"CaLMQA","keyword":"german","description":"\n\t\n\t\t\n\t\tDataset Summary\n\t\n\n\n\nCaLMQA is a translation-free long-form question answering (LFQA) dataset spanning 23 high- to low-resource languages. \n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nCaLMQA is a translation-free LFQA dataset with 51.7K questions from 23 languages, 11 high- to mid-resource and 12 low-resource.\nAll questions are culturally specific â€“ (1) they refer to concepts unique to one or a few cultures, such as\n\"Kuber iki umwami wa mbere wâ€™uburundi yitwa Ntare?\"â€¦ See the full description on the dataset page: https://huggingface.co/datasets/shanearora/CaLMQA.","url":"https://huggingface.co/datasets/shanearora/CaLMQA","creator_name":"Shane Arora","creator_url":"https://huggingface.co/shanearora","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["multilingual","Afar","Arabic","Baluchi","German"],"keywords_longer_than_N":true},
	{"name":"coop-ch-products","keyword":"german","description":"\n\t\n\t\t\n\t\tCoop Switzerland Products\n\t\n\nAll products and their information from Coop Switzerland.\nThe entire online catalogue is included.\nProduct information contains:\n\nName\nPrice\nPrice Text\nUnit of product\nUnit price\nIf it is discounted\nDiscount information\nProduct category\nImage URL\nProduct URL\n\nCheck out similar datasets for other grocery stores\n\nhttps://huggingface.co/datasets/Yelinz/lidl-ch-products\nhttps://huggingface.co/datasets/Yelinz/migros-ch-productsâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Yelinz/coop-ch-products.","url":"https://huggingface.co/datasets/Yelinz/coop-ch-products","creator_name":"Yelin Z.","creator_url":"https://huggingface.co/Yelinz","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","German","cc-by-4.0","100K - 1M","csv"],"keywords_longer_than_N":true},
	{"name":"muri-it-language-split","keyword":"german","description":"\n\t\n\t\t\n\t\tMURI-IT: Multilingual Instruction Tuning Dataset for 200 Languages via Multilingual Reverse Instructions\n\t\n\nMURI-IT is a large-scale multilingual instruction tuning dataset containing 2.2 million instruction-output pairs across 200 languages. It is designed to address the challenges of instruction tuning in low-resource languages with Multilingual Reverse Instructions (MURI), which ensures that the output is human-written, high-quality, and authentic to the cultural and linguisticâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/akoksal/muri-it-language-split.","url":"https://huggingface.co/datasets/akoksal/muri-it-language-split","creator_name":"Abdullatif Koksal","creator_url":"https://huggingface.co/akoksal","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text2text-generation","text-generation","question-answering","summarization","Achinese"],"keywords_longer_than_N":true},
	{"name":"oaast_rm_full_jieba","keyword":"german","description":"å°è¯•è§£å†³\"llm repetition problem\"ï¼Œä½¿ç”¨åˆ†è¯æ¨¡åž‹å¯¹oaastè¯­æ–™è¿›è¡Œâ€œç»“å·´åŒ–â€æ•°æ®å¢žå¼ºï¼Œæä¾›æ›´å¼ºçš„é‡å¤å†…å®¹æ‹’ç»æ•ˆæžœã€‚\nAttempts to solve the \"llm repetition problem\" by using a segmentation model to enhance the oaast corpus with \"stuttering\" data to provide stronger rejection of duplicate content.\nå…¶æ¬¡ï¼Œè¿˜è¿‡æ»¤æŽ‰äº†æ‰€æœ‰è‡ªæˆ‘è®¤çŸ¥çš„å¾®è°ƒæ ·æœ¬ã€‚\nSecond, it also filters out all the fine-tuned samples of self-cognition.\nfiles:\n\noaast_rm_full_jieba.jsonl : word level repeat\noaast_rm_full_sent_jieba.jsonl : sentence level repeat\n\n","url":"https://huggingface.co/datasets/lenML/oaast_rm_full_jieba","creator_name":"len","creator_url":"https://huggingface.co/lenML","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["English","Spanish","Russian","German","Polish"],"keywords_longer_than_N":true},
	{"name":"BRIGHTER-emotion-categories","keyword":"german","description":"\n\t\n\t\t\n\t\tBRIGHTER Emotion Categories Dataset\n\t\n\nThis dataset contains the emotion categories data from the BRIGHTER paper: BRIdging the Gap in Human-Annotated Textual Emotion Recognition Datasets for 28 Languages.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe BRIGHTER Emotion Categories dataset is a comprehensive multi-language, multi-label emotion classification dataset with separate configurations for each language. It represents one of the largest human-annotated emotion datasets across multipleâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/brighter-dataset/BRIGHTER-emotion-categories.","url":"https://huggingface.co/datasets/brighter-dataset/BRIGHTER-emotion-categories","creator_name":"BRIGHTER Dataset","creator_url":"https://huggingface.co/brighter-dataset","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["Afrikaans","Arabic","German","English","Spanish"],"keywords_longer_than_N":true},
	{"name":"aya_evaluation_suite","keyword":"german","description":"\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nAya Evaluation Suite contains a total of 26,750 open-ended conversation-style prompts to evaluate multilingual open-ended generation quality.To strike a balance between language coverage and the quality that comes with human curation, we create an evaluation suite that includes:\n\nhuman-curated examples in 7 languages (tur, eng, yor, arb, zho, por, tel) â†’ aya-human-annotated.\nmachine-translations of handpicked examples into 101 languages â†’ dolly-machine-translated.â€¦ See the full description on the dataset page: https://huggingface.co/datasets/CohereLabs/aya_evaluation_suite.","url":"https://huggingface.co/datasets/CohereLabs/aya_evaluation_suite","creator_name":"Cohere Labs","creator_url":"https://huggingface.co/CohereLabs","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","crowdsourced","expert-generated","machine-generated","multilingual"],"keywords_longer_than_N":true},
	{"name":"YouTube-Commons","keyword":"german","description":"\n\t\n\t\t\n\t\tYouTube Commons Re-upload\n\t\n\nThis is a re-upload of PleIAs' YouTube Commons, a valuable open dataset:\n\nYouTube-Commons is a collection of audio transcripts of 2,063,066 videos shared on YouTube under a CC BY 4.0 license.\nContent\nThe collection comprises 22,709,724 original and automatically translated transcripts from 3,156,703 videos (721,136 individual channels).\n\nUnfortunately, there are problems with loading YouTube Commons with Hugging Face Datasets.\nIn order to alleviate thoseâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Rijgersberg/YouTube-Commons.","url":"https://huggingface.co/datasets/Rijgersberg/YouTube-Commons","creator_name":"Edwin Rijgersberg","creator_url":"https://huggingface.co/Rijgersberg","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","English","French","Spanish","Portuguese"],"keywords_longer_than_N":true},
	{"name":"mercury","keyword":"german","description":"\n\n\t\n\t\t\n\t\tMercury Planet Facts Dataset\n\t\n\nThis dataset contains multilingual facts about the planet Mercury, provided in Indonesian, English, Spanish, and German.\n\n\t\n\t\t\n\t\tðŸ“„ License\n\t\n\nThis dataset is released under the Apache License 2.0.It is free to use for research, commercial, educational, and personal purposes â€” with appropriate attribution.\n\n\t\n\t\t\n\t\tðŸ¢ Source\n\t\n\nThis dataset was developed and published by Eris Dataworks, a data engineering company providing high-quality datasets toâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/erisdataworks/mercury.","url":"https://huggingface.co/datasets/erisdataworks/mercury","creator_name":"Eris Dataworks","creator_url":"https://huggingface.co/erisdataworks","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["English","Indonesian","Spanish","German","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"TV-44kHz-Full","keyword":"german","description":"\n\t\n\t\t\n\t\tThe \"Thorsten-Voice\" dataset\n\t\n\nThis truly open source (CC0 license) german (ðŸ‡©ðŸ‡ª) voice dataset contains about 40 hours of transcribed voice recordings by Thorsten MÃ¼ller, \na single male, native speaker in over 38.000 wave files.\n\nMono\nSamplerate: 44.100Hz\nTrimmed silence at begin/end\nDenoised\nNormalized to -24dB\n\n\n\t\n\t\t\n\t\tDisclaimer\n\t\n\n\"Please keep in mind, I am not a professional speaker, just an open source speech technology enthusiast who donates his voice. I contribute my personalâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Thorsten-Voice/TV-44kHz-Full.","url":"https://huggingface.co/datasets/Thorsten-Voice/TV-44kHz-Full","creator_name":"Thorsten MÃ¼ller","creator_url":"https://huggingface.co/Thorsten-Voice","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["text-to-speech","text-to-audio","German","cc0-1.0","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"webui-dom-snapshots","keyword":"german","description":"\n\t\n\t\t\n\t\tDataset Card for WebUI DOM snapshots\n\t\n\n\n\nThis dataset card aims to be a base template for new datasets. It has been generated using this raw template.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\n\n\n\n\n\nCurated by: Gary Benson\nLanguages: Mostly English (87%);\nDutch, French, Chinese, Japanese (1-2% each); 30+ others (<1% each)\nLicense: CC0 1.0 Universal\n\n\n\t\n\t\t\n\t\tDataset Sources [optional]\n\t\n\n\n\n\nRepository: [More Information Needed]\nPaper [optional]: [More Information Needed]â€¦ See the full description on the dataset page: https://huggingface.co/datasets/gbenson/webui-dom-snapshots.","url":"https://huggingface.co/datasets/gbenson/webui-dom-snapshots","creator_name":"Gary Benson","creator_url":"https://huggingface.co/gbenson","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["image-feature-extraction","reinforcement-learning","text-classification","multilingual","biglab/webui-7k"],"keywords_longer_than_N":true},
	{"name":"panlex-meanings","keyword":"german","description":"\n\t\n\t\t\n\t\tDataset Card for panlex-meanings\n\t\n\nThis is a dataset of words in several thousand languages, extracted from https://panlex.org.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset has been extracted from https://panlex.org (the 20240301 database dump) and rearranged on the per-language basis.\nEach language subset consists of expressions (words and phrases). \nEach expression is associated with some meanings (if there is more than one meaning, they are in separateâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/cointegrated/panlex-meanings.","url":"https://huggingface.co/datasets/cointegrated/panlex-meanings","creator_name":"David Dale","creator_url":"https://huggingface.co/cointegrated","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["translation","Afar","Western Abnaki","Abkhazian","Abaza"],"keywords_longer_than_N":true},
	{"name":"panlex-meanings","keyword":"swiss german","description":"\n\t\n\t\t\n\t\tDataset Card for panlex-meanings\n\t\n\nThis is a dataset of words in several thousand languages, extracted from https://panlex.org.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset has been extracted from https://panlex.org (the 20240301 database dump) and rearranged on the per-language basis.\nEach language subset consists of expressions (words and phrases). \nEach expression is associated with some meanings (if there is more than one meaning, they are in separateâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/cointegrated/panlex-meanings.","url":"https://huggingface.co/datasets/cointegrated/panlex-meanings","creator_name":"David Dale","creator_url":"https://huggingface.co/cointegrated","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["translation","Afar","Western Abnaki","Abkhazian","Abaza"],"keywords_longer_than_N":true},
	{"name":"raid","keyword":"german","description":"\nðŸš¨ RAID: A Shared Benchmark for Robust Evaluation of Machine-Generated Text Detectors ðŸš¨\nðŸŒ Website, ðŸ–¥ï¸ Github, ðŸ“ Paper\n\n\nRAID is the largest & most comprehensive dataset for evaluating AI-generated text detectors. \nIt contains over 10 million documents spanning 11 LLMs, 11 genres, 4 decoding strategies, and 12 adversarial attacks. \nIt is designed to be the go-to location for trustworthy third-party evaluation of both open-source and closed-source generated text detectors.\n\n\t\n\t\t\n\t\n\t\n\t\tLoadâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/liamdugan/raid.","url":"https://huggingface.co/datasets/liamdugan/raid","creator_name":"Liam Dugan","creator_url":"https://huggingface.co/liamdugan","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","English","Czech","German","mit"],"keywords_longer_than_N":true},
	{"name":"Multilingal-sakalt-data","keyword":"german","description":"ãƒžãƒ«ãƒãƒªãƒ³ã‚¬ãƒ«ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã§ã™ã€‚mitãƒ©ã‚¤ã‚»ãƒ³ã‚¹ã§ã™ã€‚\n","url":"https://huggingface.co/datasets/Sakalti/Multilingal-sakalt-data","creator_name":"sakasan","creator_url":"https://huggingface.co/Sakalti","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-generation","Abkhaz","Bhojpuri","Chechen","Czech"],"keywords_longer_than_N":true},
	{"name":"tokenizer-robustness-mmlu","keyword":"german","description":"\n\t\n\t\t\n\t\tTokenizer Robustness MMLU Dataset\n\t\n\nThis dataset contains MMLU-formatted questions and answers designed to test tokenizer robustness across different text formats and languages.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset consists of the same questions presented in 6 different formats, with both test (20 questions) and development (5 questions) sets:\n\noriginal - Standard formatted questions\nminor_spelling_errors - Questions with minor misspellings\nspoken_language - Questions in casualâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Malikeh1375/tokenizer-robustness-mmlu.","url":"https://huggingface.co/datasets/Malikeh1375/tokenizer-robustness-mmlu","creator_name":"Malikeh Ehghaghi","creator_url":"https://huggingface.co/Malikeh1375","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["English","Russian","Chinese","Japanese","German"],"keywords_longer_than_N":true},
	{"name":"tulu-3-sft-mixture-with-language","keyword":"german","description":"\n\nJust a version of the good tulu-3-sft-mixture dataset with a column indicating language.\nLanguage detection has been performed with fastText.\nâš ï¸ It may contain errors.\n","url":"https://huggingface.co/datasets/anakin87/tulu-3-sft-mixture-with-language","creator_name":"Stefano Fiorucci","creator_url":"https://huggingface.co/anakin87","license_name":"Open Data Commons Attribution License v1.0","license_url":"https://scancode-licensedb.aboutcode.org/odc-by-1.0.html","language":"en","first_N":5,"first_N_keywords":["other","crowdsourced","expert-generated","machine-generated","multilingual"],"keywords_longer_than_N":true},
	{"name":"nomiracl-instruct","keyword":"german","description":"\n\t\n\t\t\n\t\tDataset Card for NoMIRACL (EMNLP 2024 Findings Track)\n\t\n\n\n\t\n\t\t\n\t\tQuick Overview\n\t\n\nThis repository contains the fine-tuning (training & development split) of the NoMIRACL instruct dataset for fine-tuning LLMs on multilingual relevance assessment.\nThe training dataset is a binary classification task; they need to explicitly output either Yes, answer is present or I don't know. \nThe dataset contains training pairs from all 18 languages for both splits: relevant & non-relevant.\nimportâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/miracl/nomiracl-instruct.","url":"https://huggingface.co/datasets/miracl/nomiracl-instruct","creator_name":"MIRACL","creator_url":"https://huggingface.co/miracl","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","text-generation","Arabic","Bengali","German"],"keywords_longer_than_N":true},
	{"name":"FL_Legal_GER","keyword":"german","description":"The regulations (legal articles) as well as other legal data are contained inside this dataset in text form. Only one column called â€œtextâ€ is contained in the dataset. The dataset is intended to be used for continual pretraining of a language model on legal data from Liechtenstein. The dataset is published exclusively in German language and around 5â€™700 rows are included in the dataset. The relatively low number of 5700 rows can be explained by the fact that each legal regulation is beingâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/JoeUnili/FL_Legal_GER.","url":"https://huggingface.co/datasets/JoeUnili/FL_Legal_GER","creator_name":"Joel","creator_url":"https://huggingface.co/JoeUnili","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","German","apache-2.0","1K - 10K","text"],"keywords_longer_than_N":true},
	{"name":"Lemonade","keyword":"german","description":"LEMONADE is a large, expert-annotated dataset for event extraction from news articles in 20 languages: English, Spanish, Arabic, French, Italian, Russian, German, Turkish, Burmese, Indonesian, Ukrainian, Korean, Portuguese, Dutch, Somali, Nepali, Chinese, Persian, Hebrew, and Japanese.\nSee https://github.com/stanford-oval/Lemonade for details.\n","url":"https://huggingface.co/datasets/stanford-oval/Lemonade","creator_name":"Stanford Open Virtual Assistant Lab (OVAL)","creator_url":"https://huggingface.co/stanford-oval","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","text-generation","English","Spanish","Arabic"],"keywords_longer_than_N":true},
	{"name":"HARD-REASONING-DE","keyword":"german","description":"\n\t\n\t\t\n\t\tHARD-REASONING-DE\n\t\n\nThe original dataset was obtained from German-RAG LLM-HARD BENCHMARK and was further cleaned, filtered and re-evaluated. \n\n\t\n\t\t\n\t\tMethodology: Reasoning-DE\n\t\n\n\nProviding Persona Descriptions and rewriting in a similar style with a different focus area and name in german/english language\nGenerating Simple Logical Problems out of Persona-specific Views & Language.\nGenerating Approaches, Thinking-Steps & Solutions separately verified by Llama-3.1-405B-Instruct\nQualityâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/embraceableAI/HARD-REASONING-DE.","url":"https://huggingface.co/datasets/embraceableAI/HARD-REASONING-DE","creator_name":"Embraceable Technology GmbH","creator_url":"https://huggingface.co/embraceableAI","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["question-answering","text-generation","German","mit","< 1K"],"keywords_longer_than_N":true},
	{"name":"HARD-REASONING-DE","keyword":"german","description":"\n\t\n\t\t\n\t\tHARD-REASONING-DE\n\t\n\nThe original dataset was obtained from German-RAG LLM-HARD BENCHMARK and was further cleaned, filtered and re-evaluated. \n\n\t\n\t\t\n\t\tMethodology: Reasoning-DE\n\t\n\n\nProviding Persona Descriptions and rewriting in a similar style with a different focus area and name in german/english language\nGenerating Simple Logical Problems out of Persona-specific Views & Language.\nGenerating Approaches, Thinking-Steps & Solutions separately verified by Llama-3.1-405B-Instruct\nQualityâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/embraceableAI/HARD-REASONING-DE.","url":"https://huggingface.co/datasets/embraceableAI/HARD-REASONING-DE","creator_name":"Embraceable Technology GmbH","creator_url":"https://huggingface.co/embraceableAI","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["question-answering","text-generation","German","mit","< 1K"],"keywords_longer_than_N":true},
	{"name":"SMPQA","keyword":"german","description":"\n\t\n\t\t\n\t\n\t\n\t\tSMPQA (Synthetic Multilingual Plot QA)\n\t\n\n\n\nThe SMPQA evaluation dataset proposed in Centurio: On Drivers of Multilingual Ability of Large Vision-Language Model.\nSMPQA is composed of synthetic bar plots and pie charts (generated using word lists of different languages) together with questions about those plots.\nThe datasets aims at providing an initial way of evaluating multilingual OCR capabilities of models in arbritrary languages.\nThere are two sub-tasks: \n\nGrounding text labelsâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/WueNLP/SMPQA.","url":"https://huggingface.co/datasets/WueNLP/SMPQA","creator_name":"WÃ¼NLP","creator_url":"https://huggingface.co/WueNLP","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["visual-question-answering","English","Zulu","Indonesian","Italian"],"keywords_longer_than_N":true},
	{"name":"weather_and_campsite_germany","keyword":"german","description":"wilhelmine/weather_and_campsite_germany dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/wilhelmine/weather_and_campsite_germany","creator_name":"Ronja Schwarz","creator_url":"https://huggingface.co/wilhelmine","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["German","English","cc-by-4.0","1K - 10K","csv"],"keywords_longer_than_N":true},
	{"name":"philosophy-culture-translations-html-csv","keyword":"german","description":"\n\t\n\t\t\n\t\tAI-Culture Philosophy and Culture Translations CSV + HTML Corpus\n\t\n\nThe corpus contains an exceptionally diverse range of cultural, philosophical, and literary texts, available in 12 major languages. Among other topics, there is extensive engagement with the ethics and aesthetics of artificial intelligence and its cultural and philosophical implications, as well as connections between AI and philosophy of language and philosophy of mind.\nThis project is maintained by a non-profitâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/AI-Culture-Commons/philosophy-culture-translations-html-csv.","url":"https://huggingface.co/datasets/AI-Culture-Commons/philosophy-culture-translations-html-csv","creator_name":"AIâ€‘Cultureâ€‘Commons","creator_url":"https://huggingface.co/AI-Culture-Commons","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["translation","text-generation","text-classification","sentence-similarity","summarization"],"keywords_longer_than_N":true},
	{"name":"ProfessorHeidelTime","keyword":"german","description":"\n\t\n\t\t\n\t\tProfessor HeidelTime\n\t\n\nPaper    GitHub\nProfessor HeidelTime is a project to create a multilingual corpus weakly labeled with HeidelTime, a temporal tagger.\n\n\t\n\t\t\n\t\tCorpus Details\n\t\n\nThe weak labeling was performed in six languages. Here are the specifics of the corpus for each language:\n\n\t\n\t\t\nDataset\nLanguage\nDocuments\nFrom\nTo\nTokens\nTimexs\n\n\n\t\t\nAll the News 2.0\nEN\n24,642\n2016-01-01\n2020-04-02\n18,755,616\n254,803\n\n\nItalian Crime News\nIT\n9,619\n2011-01-01\n2021-12-31\n3,296,898\n58,823â€¦ See the full description on the dataset page: https://huggingface.co/datasets/hugosousa/ProfessorHeidelTime.","url":"https://huggingface.co/datasets/hugosousa/ProfessorHeidelTime","creator_name":"Hugo Sousa","creator_url":"https://huggingface.co/hugosousa","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["token-classification","parsing","part-of-speech","named-entity-recognition","machine-generated"],"keywords_longer_than_N":true},
	{"name":"upvoteweb-posts","keyword":"german","description":"\n\t\n\t\t\n\t\tupvoteweb: posts\n\t\n\nPosts in upvoteweb.\n\n\t\n\t\t\n\t\tconfigs\n\t\n\n\n[!IMPORTANT]There are several configs representing different permutations of this dataset. Load the relevant config for the task you are interested in.\n\nOverview of configs:\n\ndefault: largely unfiltered/unprocessed original data\neduscored: the \"eduscore\" predicted on the text column with huggingface's trained classifier\nen-clean: filter language for en and language_score for > 0.6. Run clean-text on the text col, preservingâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/BEE-spoke-data/upvoteweb-posts.","url":"https://huggingface.co/datasets/BEE-spoke-data/upvoteweb-posts","creator_name":"BEEspoke Data","creator_url":"https://huggingface.co/BEE-spoke-data","license_name":"Open Data Commons Attribution License v1.0","license_url":"https://scancode-licensedb.aboutcode.org/odc-by-1.0.html","language":"en","first_N":5,"first_N_keywords":["text-generation","feature-extraction","image-to-text","text-to-image","fill-mask"],"keywords_longer_than_N":true},
	{"name":"mosel","keyword":"german","description":"\n\n\n\t\n\t\t\n\t\tDataset Description, Collection, and Source\n\t\n\nThe MOSEL corpus is a multilingual dataset collection including up to 950K hours of open-source speech recordings covering the 24 official languages of the European Union. We collect data by surveying labeled and unlabeled speech corpora under open-source compliant licenses.\nIn particular, MOSEL includes the automatic transcripts of 441k hours of unlabeled speech from VoxPopuli and LibriLight. The data is transcribed using Whisper largeâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/FBK-MT/mosel.","url":"https://huggingface.co/datasets/FBK-MT/mosel","creator_name":"FBK-MT","creator_url":"https://huggingface.co/FBK-MT","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","machine-generated","found","multilingual"],"keywords_longer_than_N":true},
	{"name":"TransWeb-Edu-German","keyword":"german","description":"britllm/TransWeb-Edu-German dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/britllm/TransWeb-Edu-German","creator_name":"BritLLM","creator_url":"https://huggingface.co/britllm","license_name":"Open Data Commons Attribution License v1.0","license_url":"https://scancode-licensedb.aboutcode.org/odc-by-1.0.html","language":"en","first_N":5,"first_N_keywords":["German","odc-by","10M - 100M","json","Text"],"keywords_longer_than_N":true},
	{"name":"german-spoon-language","keyword":"german","description":"\n\t\n\t\t\n\t\tSpoon Language\n\t\n\nThis is a dataset of random german sentences from Tatoeba (accessed 23.07.25) mapped to their \"LÃ¶ffelsprache\" / spoon language version.\nThe corresponding GitHub repository can be found here.\n","url":"https://huggingface.co/datasets/wambosec/german-spoon-language","creator_name":"Denis Wambold","creator_url":"https://huggingface.co/wambosec","license_name":"Creative Commons Attribution 2.0","license_url":"https://scancode-licensedb.aboutcode.org/cc-by-2.0.html","language":"en","first_N":5,"first_N_keywords":["text-generation","German","cc-by-2.0","100K - 1M","csv"],"keywords_longer_than_N":true},
	{"name":"Matvel","keyword":"german","description":"DevKiDm/Matvel dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/DevKiDm/Matvel","creator_name":"Duy Nam Schlitz","creator_url":"https://huggingface.co/DevKiDm","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","feature-extraction","German","English"],"keywords_longer_than_N":true},
	{"name":"Post-OCR-Correction","keyword":"german","description":"Post-OCR correction is a large corpus of 1 billion words containing original texts with a varying number of OCR mistakes and an experimental multilingual post-OCR correction output created by Pleias.\nGeneration of Post-OCR correction was performed using HPC resources from GENCIâ€“IDRIS (Grant 2023-AD011014736) on Jean-Zay.\n\n\t\n\t\t\n\t\tDescription\n\t\n\nAll the texts come from collections integrated into Common Corpus, the largest open corpus for pretraining previously released by Pleias on HuggingFace.â€¦ See the full description on the dataset page: https://huggingface.co/datasets/PleIAs/Post-OCR-Correction.","url":"https://huggingface.co/datasets/PleIAs/Post-OCR-Correction","creator_name":"PleIAs","creator_url":"https://huggingface.co/PleIAs","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["French","English","Italian","German","cc0-1.0"],"keywords_longer_than_N":true},
	{"name":"SemEval2024-task8","keyword":"german","description":"\n\t\n\t\t\n\t\tSemEval2024-task8\n\t\n\nUnofficial mirror of M4 dataset from mbzuai-nlp/SemEval2024-task8 (website, github, codabench).\n\n\t\n\t\t\n\t\n\t\n\t\tData Format\n\t\n\n\n\t\n\t\t\n\t\n\t\n\t\tSubtask A\n\t\n\nAn object in the JSON format:\n{\n  id -> identifier of the example,\n  label -> label (human text: 0, machine text: 1,),\n  text -> text generated by a machine or written by a human,\n  model -> model that generated the data,\n  source -> source (Wikipedia, Wikihow, Peerread, Reddit, Arxiv)  on English or language (Arabicâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/d0rj/SemEval2024-task8.","url":"https://huggingface.co/datasets/d0rj/SemEval2024-task8","creator_name":"Dmitry Balobin","creator_url":"https://huggingface.co/d0rj","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","original","English","Arabic","German"],"keywords_longer_than_N":true},
	{"name":"AutomotiveUI-Bench-4K","keyword":"german","description":"\n\t\n\t\t\n\t\tAutomotiveUI-Bench-4K\n\t\n\nDataset Overview: 998 images and 4,208 annotations focusing on interaction with in-vehicle infotainment (IVI) systems.\nKey Features:\n\nServes as a validation benchmark for automotive UI.\nScope: Covers 15 automotive brands/OEMs, model years 2018-2025.\nImage Source: Primarily photographs of IVI displays (due to screenshot limitations in most vehicles), with some direct screenshots (e.g., Android Auto).\nAnnotation Classes:\nTest Action: Bounding box + imperativeâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/sparks-solutions/AutomotiveUI-Bench-4K.","url":"https://huggingface.co/datasets/sparks-solutions/AutomotiveUI-Bench-4K","creator_name":"SPARKS Solutions GmbH","creator_url":"https://huggingface.co/sparks-solutions","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["visual-question-answering","German","English","cc-by-4.0","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"FalseFriendsGermanEnglish","keyword":"german","description":"\n  FalseFriendsGermanEnglish\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nA dataset to identify False Friends / false cognates between English and German. A generally challenging task for multilingual models.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2t\n\n\nDomains\nWritten\nReference\nhttps://drive.google.com/file/d/1jgq0nBnV-UiYNxbKNrrr2gxDEHm-DMKH/view?usp=share_link\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mtebâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/FalseFriendsGermanEnglish.","url":"https://huggingface.co/datasets/mteb/FalseFriendsGermanEnglish","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","semantic-similarity-classification","human-annotated","monolingual","aari1995/false_friends_de_en_mteb"],"keywords_longer_than_N":true},
	{"name":"MultiSimV2","keyword":"german","description":"\n\t\n\t\t\n\t\tDataset Card for MultiSim Benchmark\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThe MultiSim benchmark is a growing collection of text simplification datasets targeted at sentence simplification in several languages.  Currently, the benchmark spans 12 languages.\n\n\n\t\n\t\n\t\n\t\tSupported Tasks\n\t\n\n\nSentence Simplification\n\n\n\t\n\t\n\t\n\t\tUsage\n\t\n\nfrom datasets importload_dataset\n\ndataset = load_dataset(\"MichaelR207/MultiSimV2\")\n\n\n\t\n\t\t\n\t\tCitation\n\t\n\nIf you use this benchmark, please cite our paper:â€¦ See the full description on the dataset page: https://huggingface.co/datasets/MichaelR207/MultiSimV2.","url":"https://huggingface.co/datasets/MichaelR207/MultiSimV2","creator_name":"Michael Ryan","creator_url":"https://huggingface.co/MichaelR207","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["summarization","text2text-generation","text-generation","English","French"],"keywords_longer_than_N":true},
	{"name":"MMMLU_subset","keyword":"german","description":"\n\t\n\t\t\n\t\tAbout MMMLU subset\n\t\n\n  This is a subset of MMMLU, specifically, we sampled 10% of the original data to improve evaluation efficiency.\n  In addition, we categorize the questions into four categories by subject, i.e., STEM, HUMANITIES, SOCIAL SCIENCES, and OTHER, aligned with MMLU.\n\n\t\n\t\t\n\t\n\t\n\t\tMultilingual Massive Multitask Language Understanding (MMMLU)\n\t\n\nThe MMLU is a widely recognized benchmark of general knowledge attained by AI models. It covers a broad range of topics from 57â€¦ See the full description on the dataset page: https://huggingface.co/datasets/double7/MMMLU_subset.","url":"https://huggingface.co/datasets/double7/MMMLU_subset","creator_name":"Sen Yang","creator_url":"https://huggingface.co/double7","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["question-answering","Arabic","Bengali","German","Spanish"],"keywords_longer_than_N":true},
	{"name":"MAPS_Verified","keyword":"german","description":"\n\t\n\t\t\n\t\tDataset Card for Multilingual Benchmark for Global Agent Performance and Security\n\t\n\nThis is the first Multilingual Agentic AI Benchmark for evaluating agentic AI systems across different languages and diverse tasks. Benchmark enables systematic analysis of how agents perform under multilingual conditions. This dataset contains 550 instances for GAIA, 660 instances for ASB, 737 instances for Maths, and 1100 instances for SWE. Each task was translated into 10 target languages resultingâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Fujitsu-FRE/MAPS_Verified.","url":"https://huggingface.co/datasets/Fujitsu-FRE/MAPS_Verified","creator_name":"Fujitsu Research of Europe","creator_url":"https://huggingface.co/Fujitsu-FRE","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-generation","question-answering","Arabic","English","Japanese"],"keywords_longer_than_N":true},
	{"name":"llm_filtered_customer_service_conversations","keyword":"german","description":"\n\t\n\t\t\n\t\tLLM-filtered Customer Service Conversations Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset contains simulated conversations generated by our agentic simulation system.\nThe conversations are filtered by a LLM to ensure they are of high quality.\nEach record is stored in JSON Lines (JSONL) format and includes:\n\nInput Settings: Metadata such as selected bank, customer, agent profiles, and task details.\nMessages: The full conversation messages.\nSummary: A German summary of the conversation.â€¦ See the full description on the dataset page: https://huggingface.co/datasets/marccgrau/llm_filtered_customer_service_conversations.","url":"https://huggingface.co/datasets/marccgrau/llm_filtered_customer_service_conversations","creator_name":"Marc Christopher Grau","creator_url":"https://huggingface.co/marccgrau","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","summarization","synthetic","monolingual","German"],"keywords_longer_than_N":true},
	{"name":"jinaai_jina-embeddings-v2-base-en-03092024-dxer-webapp","keyword":"german","description":"\n\t\n\t\t\n\t\tjinaai_jina-embeddings-v2-base-en-03092024-dxer-webapp Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"health insurance information\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the jinaai_jina-embeddings-v2-base-en-03092024-dxer-webapp model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Huggingâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/jinaai_jina-embeddings-v2-base-en-03092024-dxer-webapp.","url":"https://huggingface.co/datasets/fine-tuned/jinaai_jina-embeddings-v2-base-en-03092024-dxer-webapp","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","German","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"jinaai_jina-embeddings-v2-base-en-03092024-dxer-webapp","keyword":"german","description":"\n\t\n\t\t\n\t\tjinaai_jina-embeddings-v2-base-en-03092024-dxer-webapp Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"health insurance information\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the jinaai_jina-embeddings-v2-base-en-03092024-dxer-webapp model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Huggingâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/jinaai_jina-embeddings-v2-base-en-03092024-dxer-webapp.","url":"https://huggingface.co/datasets/fine-tuned/jinaai_jina-embeddings-v2-base-en-03092024-dxer-webapp","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","German","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"synthetic_financial_sentiment","keyword":"german","description":"nojedag/synthetic_financial_sentiment dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/nojedag/synthetic_financial_sentiment","creator_name":"NÃ©stor Ojeda GonzÃ¡lez","creator_url":"https://huggingface.co/nojedag","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","Spanish","German","French","mit"],"keywords_longer_than_N":true},
	{"name":"german_ner_dataset","keyword":"german","description":"\n\t\n\t\t\n\t\tGerman NER dataset\n\t\n\n\n\t\n\t\t\n\t\tAcknowledgement\n\t\n\nThis dataset had been created as part of joint research of HUMADEX research group (https://www.linkedin.com/company/101563689/) and has received funding by the European Union Horizon Europe Research and Innovation Program project SMILE (grant number 101080923) and Marie SkÅ‚odowska-Curie Actions (MSCA) Doctoral Networks, project BosomShield ((rant number 101073222). Responsibility for the information and views expressed herein liesâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/HUMADEX/german_ner_dataset.","url":"https://huggingface.co/datasets/HUMADEX/german_ner_dataset","creator_name":"HUMADEX Research Group","creator_url":"https://huggingface.co/HUMADEX","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["token-classification","German","apache-2.0","100K - 1M","parquet"],"keywords_longer_than_N":true},
	{"name":"german_ner_dataset","keyword":"german","description":"\n\t\n\t\t\n\t\tGerman NER dataset\n\t\n\n\n\t\n\t\t\n\t\tAcknowledgement\n\t\n\nThis dataset had been created as part of joint research of HUMADEX research group (https://www.linkedin.com/company/101563689/) and has received funding by the European Union Horizon Europe Research and Innovation Program project SMILE (grant number 101080923) and Marie SkÅ‚odowska-Curie Actions (MSCA) Doctoral Networks, project BosomShield ((rant number 101073222). Responsibility for the information and views expressed herein liesâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/HUMADEX/german_ner_dataset.","url":"https://huggingface.co/datasets/HUMADEX/german_ner_dataset","creator_name":"HUMADEX Research Group","creator_url":"https://huggingface.co/HUMADEX","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["token-classification","German","apache-2.0","100K - 1M","parquet"],"keywords_longer_than_N":true},
	{"name":"story_writing_benchmark","keyword":"german","description":"\n\t\n\t\t\n\t\tStory Evaluation Dataset\n\t\n\n\nThis dataset contains stories generated by Large Language Models (LLMs) across multiple languages, with comprehensive quality evaluations. It was created to train and benchmark models specifically on creative writing tasks.\nThis benchmark evaluates an LLM's ability to generate high-quality short stories based on simple prompts like \"write a story about X with n words.\" It is similar to TinyStories but targets longer-form and more complex content, focusingâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/lars1234/story_writing_benchmark.","url":"https://huggingface.co/datasets/lars1234/story_writing_benchmark","creator_name":"Lars Nieradzik","creator_url":"https://huggingface.co/lars1234","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-generation","text-classification","English","Spanish","German"],"keywords_longer_than_N":true},
	{"name":"xflickrco","keyword":"german","description":"floschne/xflickrco dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/floschne/xflickrco","creator_name":"Flo Schneider","creator_url":"https://huggingface.co/floschne","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["image-to-text","German","English","Spanish","Indonesian"],"keywords_longer_than_N":true},
	{"name":"Multi-Cultural-Single-Multi-Agent-Images","keyword":"german","description":"\n\t\n\t\t\n\t\tIntroduction\n\t\n\nLarge Language Models (LLMs) demonstrate impressive performance across various multi003 modal tasks. However, their effectiveness in cross-cultural contexts remains limited due to the predominantly Western-centric nature of existing data and models. Meanwhile, multi-agent models have shown strong capabilities in solving complex tasks. In this paper, we evaluate the performance of LLMs in a multi-agent interaction setting for the novel task of multicultural imageâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/ParthGeek/Multi-Cultural-Single-Multi-Agent-Images.","url":"https://huggingface.co/datasets/ParthGeek/Multi-Cultural-Single-Multi-Agent-Images","creator_name":"Bhalerao","creator_url":"https://huggingface.co/ParthGeek","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["English","Marathi","Spanish","German","Vietnamese"],"keywords_longer_than_N":true},
	{"name":"lua_code_dataset","keyword":"german","description":"tfcbhop/lua_code_dataset dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/tfcbhop/lua_code_dataset","creator_name":"Tim Gatzke","creator_url":"https://huggingface.co/tfcbhop","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["German","English","apache-2.0","< 1K","json"],"keywords_longer_than_N":true},
	{"name":"LEXam","keyword":"german","description":"\n  \n  \n    LEXam: Benchmarking Legal Reasoning on 340 Law Exams\n    A diverse, rigorous evaluation suite for legal AI from Swiss, EU, and international law examinations.\n  \n\n\nPaper | Project Page | GitHub Repository \n\n\t\n\t\n\t\n\t\tðŸ”¥ News\n\t\n\n\n[2025/05] Release of the first version of paper, where we evaluate representative SoTA LLMs with evaluations stricly verified by legal experts.\n\n\n\t\n\t\t\n\t\tðŸ§© Subsets\n\t\n\nThe dataset entails the following subsets:\n\nopen_question: All long-form, open-endedâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/LEXam-Benchmark/LEXam.","url":"https://huggingface.co/datasets/LEXam-Benchmark/LEXam","creator_name":"LEXam","creator_url":"https://huggingface.co/LEXam-Benchmark","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","text-generation","English","German","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"ManyToDanishTranslations-tatoeba","keyword":"german","description":"\n\t\n\t\t\n\t\tDanske oversÃ¦ttelser\n\t\n\nTak til Helsinki-NLP for deres tatoeba dataset (CC-BY-2.0).\nModeller der kan adskillige sprog kan sjÃ¦ldent dansk. At oversÃ¦tte eksisterende dataset virker som en fornuftig lÃ¸sning pÃ¥ det problem, men af fornuftige oversÃ¦ttelsesvÃ¦rktÃ¸jer er der kun fÃ¥. Mad props til Mabeck for arbejdet med SlimOrca. Much inspired. Great thank.\nSom sagt kan polylinvistiske modeller som regel engelsk, kinesisk, fransk, tysk, osv. og mÃ¥ske mangler der bare noget brobygningshysteriâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/trollek/ManyToDanishTranslations-tatoeba.","url":"https://huggingface.co/datasets/trollek/ManyToDanishTranslations-tatoeba","creator_name":"Trolle Karlsson","creator_url":"https://huggingface.co/trollek","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["translation","Danish","English","German","Spanish"],"keywords_longer_than_N":true},
	{"name":"webfaq","keyword":"german","description":"WebFAQ Q&A Dataset\n\n   \n       Overview |\n       Details  |\n       Structure  |\n       Examples |\n       Considerations |\n       License |\n       Citation |\n       Contact |\n       Acknowledgement\n   \n\n\n\n\t\n\t\t\n\t\n\t\n\t\tOverview\n\t\n\nThe WebFAQ Q&A Dataset is a broad-coverage corpus of 96 million natural question-answer (QA) pairs in 75 languages, gathered from FAQ pages on the web. It leverages structured schema.org FAQPage annotations, making it a unique resource for large-scale Question Answeringâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/PaDaS-Lab/webfaq.","url":"https://huggingface.co/datasets/PaDaS-Lab/webfaq","creator_name":"Chair of Data Science, University of Passau","creator_url":"https://huggingface.co/PaDaS-Lab","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["question-answering","multilingual","Afrikaans","Amharic","Arabic"],"keywords_longer_than_N":true},
	{"name":"floras","keyword":"german","description":"\n\t\n\t\t\n\t\tFLORAS\n\t\n\nFLORAS is a 50-language benchmark For LOng-form Recognition And Summarization of spoken language. \nThe goal of FLORAS is to create a more realistic benchmarking environment for speech recognition, translation, and summarization models. \nUnlike typical academic benchmarks like LibriSpeech and FLEURS that uses pre-segmented single-speaker read-speech, FLORAS tests the capabilities of models on raw long-form conversational audio, which can have one or many speakers.\nTo encourageâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/espnet/floras.","url":"https://huggingface.co/datasets/espnet/floras","creator_name":"ESPnet","creator_url":"https://huggingface.co/espnet","license_name":"Creative Commons Attribution 3.0","license_url":"https://scancode-licensedb.aboutcode.org/cc-by-3.0.html","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","translation","summarization","English","Spanish"],"keywords_longer_than_N":true},
	{"name":"PotTS","keyword":"german","description":"\n\t\n\t\t\n\t\tPotTS: The Potsdam Twitter Sentiment Corpus\n\t\n\nThis dataset contains the Potsdam Twitter Sentiment Corpus based on this data.\nThe link to the original annotated dataset can be found under Links.\nThe only difference is that the mixed sentiment is removed (32 dev/55 test/401 train).\n\n\t\n\t\t\n\t\tLinks\n\t\n\nhttps://github.com/WladimirSidorenko/PotTS\n\n\t\n\t\t\n\t\tCitation Information\n\t\n\n@inproceedings{sidarenka-2016-potts,\n    title = \"{P}ot{TS}: The {P}otsdam {T}witter Sentiment Corpus\",\n    author =â€¦ See the full description on the dataset page: https://huggingface.co/datasets/Alienmaster/PotTS.","url":"https://huggingface.co/datasets/Alienmaster/PotTS","creator_name":"Robert Geislinger","creator_url":"https://huggingface.co/Alienmaster","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","German","mit","1K - 10K","csv"],"keywords_longer_than_N":true},
	{"name":"german-mongotom","keyword":"german","description":"Fischerboot/german-mongotom dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/Fischerboot/german-mongotom","creator_name":"Moritz Nickel","creator_url":"https://huggingface.co/Fischerboot","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["German","apache-2.0","1K - 10K","json","Text"],"keywords_longer_than_N":true},
	{"name":"WildChat-curated","keyword":"german","description":"As part of the lock-in hypothesis research project (Qiu et al., 2025), this dataset is transformed from raw WildChat-1M dataset (Zhao et al., 2024) into a structured analysis-ready format through:\n\nData cleaning by deduplicating users based on IP address co-occurrence and removing templated prompts (i.e. people using the WildChat platform as a free API to do repetitive tasks).\nExtracting key concepts from each dialogue using a large language model (Llama-3.1-8B-Instruct), which are thenâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Project-Prevail/WildChat-curated.","url":"https://huggingface.co/datasets/Project-Prevail/WildChat-curated","creator_name":"Project Prevail","creator_url":"https://huggingface.co/Project-Prevail","license_name":"Open Data Commons Attribution License v1.0","license_url":"https://scancode-licensedb.aboutcode.org/odc-by-1.0.html","language":"en","first_N":5,"first_N_keywords":["text-generation","allenai/WildChat","English","Chinese","Russian"],"keywords_longer_than_N":true},
	{"name":"germanrag","keyword":"german","description":"\n\t\n\t\t\n\t\tGermanRAG ðŸ‡©ðŸ‡ªðŸ“œðŸ¦œ\n\t\n\nThis dataset is derived from the GermanDPR dataset and enhances it by providing fully formulated answers instead of answer spans.\nIt can be used to finetune for retrieval augmented generation tasks (RAG) in German.\nWe deduplicated the original contexts resulting in 2243 unique contexts and repeated the hard negatives of half of them, such that the last third of the total dataset contains only not answerable examples.\nIn contrast to the original dataset the numberâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/DiscoResearch/germanrag.","url":"https://huggingface.co/datasets/DiscoResearch/germanrag","creator_name":"Disco Research","creator_url":"https://huggingface.co/DiscoResearch","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["question-answering","text-retrieval","open-domain-qa","document-retrieval","document-question-answering"],"keywords_longer_than_N":true},
	{"name":"german-disinformation-narratives-synthetic","keyword":"german","description":"\n\t\n\t\t\n\t\tDataset Card for \"german-disinformation-narratives-synthetic\"\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset is built using GPT-4o and contains 41 narratives that are frequently encountered by German fact-checkers. Each narrative has been expanded using GPT-4o to generate multiple supporting, unrelated, or contradicting text units. These expansions are presented from various perspectives, including that of a politician, an angry citizen, a conspiracy theorist, and others. \nThe dataset isâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Sami92/german-disinformation-narratives-synthetic.","url":"https://huggingface.co/datasets/Sami92/german-disinformation-narratives-synthetic","creator_name":"Sami Nenno","creator_url":"https://huggingface.co/Sami92","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["zero-shot-classification","German","apache-2.0","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"apertus-pretrain-swiss","keyword":"german","description":"\n\t\n\t\t\n\t\tSwiss Pretrain Data\n\t\n\nThis dataset provides a large collection of open-access and license-compliant Swiss data sources for language model training.\nThe dataset includes the following sources:\n\n\t\n\t\t\nName\nInternal ID\nTokens (B)\nDescription\n\n\n\t\t\nCuria Vista\ncuriavista\n0.5\nLegal and administrative documents from the Swiss database of parliamentary proceedings.\n\n\nenscheidsuche\nenscheidsuche_html\n4.5\nSwiss court decisions, sampled at 50% for balance.\n\n\nFineWeb-2â€¦ See the full description on the dataset page: https://huggingface.co/datasets/swiss-ai/apertus-pretrain-swiss.","url":"https://huggingface.co/datasets/swiss-ai/apertus-pretrain-swiss","creator_name":"Swiss AI Initiative","creator_url":"https://huggingface.co/swiss-ai","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["fill-mask","text-generation","French","English","German"],"keywords_longer_than_N":true},
	{"name":"bio-mqm-dataset","keyword":"german","description":"This dataset is compiled from the official Amazon repository (all respective licensing applies).\nIt contains system translations, multiple references, and their quality evaluation on the MQM scale. It accompanies the ACL 2024 paper Fine-Tuned Machine Translation Metrics Struggle in Unseen Domains.\nWatch a brief 4 minutes-long video.\n\nAbstract: We introduce a new, extensive multidimensional quality metrics (MQM) annotated dataset covering 11 language pairs in the biomedical domain. We use thisâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/zouharvi/bio-mqm-dataset.","url":"https://huggingface.co/datasets/zouharvi/bio-mqm-dataset","creator_name":"VilÃ©m Zouhar","creator_url":"https://huggingface.co/zouharvi","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["translation","English","German","Spanish","Basque"],"keywords_longer_than_N":true},
	{"name":"gooaq_mt_german_0_hard_negatives","keyword":"german","description":"\n\t\n\t\t\n\t\tRemaining GooAQ (Google Answers to Google Questions) question-answer pairs in German without hard negatives.\n\t\n\n\n\t\n\t\t\n\t\tAbout\n\t\n\nThis dataset contains the remaining 600K of lines of german machine translated texts of the mined hard negatives ~2M question-answer-negative triplets and question-answer-negative_1...-negative_5 tuples gooaq_mt_german_5_hard_negatives. The full original Gooaq dataset in english only: (link to original dataset). This dataset can be used directly with Sentenceâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/MarcGrumpyOlejak/gooaq_mt_german_0_hard_negatives.","url":"https://huggingface.co/datasets/MarcGrumpyOlejak/gooaq_mt_german_0_hard_negatives","creator_name":"Marc Olejak","creator_url":"https://huggingface.co/MarcGrumpyOlejak","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","question-answering","German","apache-2.0","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"wikifacts-bench","keyword":"german","description":"kaengreg/wikifacts-bench dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/kaengreg/wikifacts-bench","creator_name":"Grigory Kovalev","creator_url":"https://huggingface.co/kaengreg","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["Russian","English","German","French","Portuguese"],"keywords_longer_than_N":true},
	{"name":"Multilingual_Topic-Specific_Article-Extraction_and_Classification","keyword":"german","description":"\n\t\n\t\t\n\t\tDataset Card for Multilingual Historical News Article Extraction and Classification Dataset\n\t\n\nThis dataset was created specifically to test Large Language Models' (LLMs) capabilities in processing and extracting topic-specific content from historical newspapers based on OCR'd text.\n\n\t\n\t\t\n\t\tCite the Dataset\n\t\n\nMauermann, Johanna, GonzÃ¡lez-Gallardo, Carlos-Emiliano, and Oberbichler, Sarah. (2025). Multilingual Topic-Specific Article-Extraction and Classification [Data set]. Huggingâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/oberbics/Multilingual_Topic-Specific_Article-Extraction_and_Classification.","url":"https://huggingface.co/datasets/oberbics/Multilingual_Topic-Specific_Article-Extraction_and_Classification","creator_name":"Oberbichler","creator_url":"https://huggingface.co/oberbics","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["text2text-generation","text-classification","German","French","English"],"keywords_longer_than_N":true},
	{"name":"jinaai_jina-embeddings-v2-base-en-03092024-97u6-webapp","keyword":"german","description":"\n\t\n\t\t\n\t\tjinaai_jina-embeddings-v2-base-en-03092024-97u6-webapp Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"health insurance information retrieval system\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the jinaai_jina-embeddings-v2-base-en-03092024-97u6-webapp model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load itâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/jinaai_jina-embeddings-v2-base-en-03092024-97u6-webapp.","url":"https://huggingface.co/datasets/fine-tuned/jinaai_jina-embeddings-v2-base-en-03092024-97u6-webapp","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","German","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"jinaai_jina-embeddings-v2-base-en-03092024-97u6-webapp","keyword":"german","description":"\n\t\n\t\t\n\t\tjinaai_jina-embeddings-v2-base-en-03092024-97u6-webapp Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"health insurance information retrieval system\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the jinaai_jina-embeddings-v2-base-en-03092024-97u6-webapp model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load itâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/jinaai_jina-embeddings-v2-base-en-03092024-97u6-webapp.","url":"https://huggingface.co/datasets/fine-tuned/jinaai_jina-embeddings-v2-base-en-03092024-97u6-webapp","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","German","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"German-RAG-ORPO-ShareGPT-HESSIAN-AI","keyword":"german","description":"\n\t\n\t\t\n\t\tGerman-RAG-ORPO (Odds Ratio Preference Optimization) ShareGPT-Format\n\t\n\n\n\t\n\t\t\n\t\tGerman-RAG - German Retrieval Augmented Generation\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThe ORPO Tasks Dataset represents a specialized collection for fine-tuning language models with a focus on RAG-specific capabilities. \nThe subsets can be for this training step are derived from 3 different sources:\n\nSauerkrautLM Preference Datasets:\nSauerkrautLM-Fermented-GER-DPO:  is a specialized dataset designed for trainingâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/avemio/German-RAG-ORPO-ShareGPT-HESSIAN-AI.","url":"https://huggingface.co/datasets/avemio/German-RAG-ORPO-ShareGPT-HESSIAN-AI","creator_name":"Avemio AG","creator_url":"https://huggingface.co/avemio","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["question-answering","summarization","German","English","mit"],"keywords_longer_than_N":true},
	{"name":"German-RAG-ORPO-ShareGPT-HESSIAN-AI","keyword":"german","description":"\n\t\n\t\t\n\t\tGerman-RAG-ORPO (Odds Ratio Preference Optimization) ShareGPT-Format\n\t\n\n\n\t\n\t\t\n\t\tGerman-RAG - German Retrieval Augmented Generation\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThe ORPO Tasks Dataset represents a specialized collection for fine-tuning language models with a focus on RAG-specific capabilities. \nThe subsets can be for this training step are derived from 3 different sources:\n\nSauerkrautLM Preference Datasets:\nSauerkrautLM-Fermented-GER-DPO:  is a specialized dataset designed for trainingâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/avemio/German-RAG-ORPO-ShareGPT-HESSIAN-AI.","url":"https://huggingface.co/datasets/avemio/German-RAG-ORPO-ShareGPT-HESSIAN-AI","creator_name":"Avemio AG","creator_url":"https://huggingface.co/avemio","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["question-answering","summarization","German","English","mit"],"keywords_longer_than_N":true},
	{"name":"MultiEup-v2","keyword":"german","description":"\n\t\n\t\t\n\t\tMulti-EuP-v2\n\t\n\nThis dataset card documents Multi-EuP-v2, a multilingual corpus of European Parliament debate speeches enriched with Member of European Parliament (MEP) metadata and multilingual debate titles/IDs. It supports research on political text analysis, speaker-attribute prediction, stance/vote prediction, multilingual NLP, and retrieval.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nMulti-EuP-v2 aggregates 50,337 debate speeches (each a unique did) in 24â€¦ See the full description on the dataset page: https://huggingface.co/datasets/unimelb-nlp/MultiEup-v2.","url":"https://huggingface.co/datasets/unimelb-nlp/MultiEup-v2","creator_name":"The University of Melbourne","creator_url":"https://huggingface.co/unimelb-nlp","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","text-retrieval","text-generation","multilingual","Bulgarian"],"keywords_longer_than_N":true},
	{"name":"hegel-phenomenology","keyword":"german","description":"\n\t\n\t\t\n\t\tSerialized biligual text of Phenomenology of Spirit by GWF Hegel (1807)\n\t\n\n\nserial: value corresponding to paragraph number in main text\nenglish: english translation by J B Baillie (1910)\nreader: corresponding extracts from reading guide by Terry Pinkard (2023)\ngerman: corresponding orignal text\n\nDisclaimer: This dataset includes material derived from Terry Pinkard's Hegel's Phenomenology of Spirit: A Guide \nand hegel.net 's' Phenomenology of Spirit/Mind: Bilingual, with Dictionary.\nItâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/zayzay58/hegel-phenomenology.","url":"https://huggingface.co/datasets/zayzay58/hegel-phenomenology","creator_name":"Zayyan Sahar","creator_url":"https://huggingface.co/zayzay58","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["translation","English","German","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"MAPS","keyword":"german","description":"\n\t\n\t\t\n\t\tDataset Card for Multilingual Benchmark for Global Agent Performance and Security\n\t\n\nThis is the first Multilingual Agentic AI Benchmark for evaluating agentic AI systems across different languages and diverse tasks. Benchmark enables systematic analysis of how agents perform under multilingual conditions. To balance performance and safety evaluation, our benchmark comprises 805 tasks: 405 from performance-oriented datasets (GAIA, SWE-bench, MATH) and 400 from the Agent Securityâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Fujitsu-FRE/MAPS.","url":"https://huggingface.co/datasets/Fujitsu-FRE/MAPS","creator_name":"Fujitsu Research of Europe","creator_url":"https://huggingface.co/Fujitsu-FRE","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-generation","question-answering","Arabic","English","Japanese"],"keywords_longer_than_N":true},
	{"name":"genrescoh","keyword":"german","description":"\n\t\n\t\t\n\t\tDataset Card for GenResCoh\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nGenResCoh is a collection of positive and negative responses focused on coherence. It is generated using GPT-3.5-Turbo and GPT-4, and contains over 130k responses in different languages (English, French, German, Italian, and Chinese), together with their corresponding explanations (in English).\nGenResCoh was used to train the ECoh family of models.\n\n\t\n\t\t\n\t\n\t\n\t\tLanguages\n\t\n\n\nEnglish\nGerman\nItalian\nFrench\nChinese (Simplified)â€¦ See the full description on the dataset page: https://huggingface.co/datasets/Johndfm/genrescoh.","url":"https://huggingface.co/datasets/Johndfm/genrescoh","creator_name":"John MendonÃ§a","creator_url":"https://huggingface.co/Johndfm","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["English","German","Italian","Chinese","French"],"keywords_longer_than_N":true},
	{"name":"GlotCC-V1","keyword":"swiss german","description":"\n\t\n\t\t\n\t\tDataset Summary\n\t\n\n \n\nGlotCC-V1.0 is a document-level, general domain dataset derived from CommonCrawl, covering more than 1000 languages.It is built using the GlotLID language identification and Ungoliant pipeline from CommonCrawl.We release our pipeline as open-source at https://github.com/cisnlp/GlotCC.  \nList of Languages: See https://datasets-server.huggingface.co/splits?dataset=cis-lmu/GlotCC-V1 to get the list of splits available.\n\n\t\t\n\t\tUsage (Huggingface Hub -- Recommended)â€¦ See the full description on the dataset page: https://huggingface.co/datasets/cis-lmu/GlotCC-V1.","url":"https://huggingface.co/datasets/cis-lmu/GlotCC-V1","creator_name":"CIS, LMU Munich","creator_url":"https://huggingface.co/cis-lmu","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["multilingual","Abau","Amarasi","Abkhaz","Abkhazian"],"keywords_longer_than_N":true},
	{"name":"HPLT2.0_cleaned","keyword":"german","description":"This is a large-scale collection of web-crawled documents in 191 world languages, produced by the HPLT project. \nThe source of the data is mostly Internet Archive with some additions from Common Crawl.\nFor a detailed description of the dataset, please refer to https://hplt-project.org/datasets/v2.0\nThe Cleaned variant of HPLT Datasets v2.0\nThis is the cleaned variant of the HPLT Datasets v2.0 converted to the Parquet format semi-automatically when being uploaded here. \nThe original JSONL filesâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/jobs-git/HPLT2.0_cleaned.","url":"https://huggingface.co/datasets/jobs-git/HPLT2.0_cleaned","creator_name":"James Guana","creator_url":"https://huggingface.co/jobs-git","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["fill-mask","text-generation","language-modeling","multilingual","Achinese"],"keywords_longer_than_N":true},
	{"name":"german-parliament-speeches","keyword":"german","description":"\n\t\n\t\t\n\t\tGerman Parliament Speeches\n\t\n\nThis dataset contains speeches from the German parliament, derived from the Open Discourse Project (Harvard Dataverse).\n\n\t\n\t\t\n\t\tSource\n\t\n\nData source:  \nOpen Discourse ProjectHarvard DataverseDOI: 10.7910/DVN/FIKIBO\nOriginal citation:\n@data{DVN/FIKIBO_2020,\nauthor = {Richter, Florian and Koch, Philipp and Franke, Oliver and Kraus, Jakob and Kuruc, Fabrizio and Thiem, Anja and HÃ¶gerl, Judith and Heine, Stella and SchÃ¶ps, Konstantin},\npublisher = {Harvardâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/emilpartow/german-parliament-speeches.","url":"https://huggingface.co/datasets/emilpartow/german-parliament-speeches","creator_name":"Emil Partow","creator_url":"https://huggingface.co/emilpartow","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","summarization","text-generation","question-answering","German"],"keywords_longer_than_N":true},
	{"name":"german-parliament-speeches","keyword":"german","description":"\n\t\n\t\t\n\t\tGerman Parliament Speeches\n\t\n\nThis dataset contains speeches from the German parliament, derived from the Open Discourse Project (Harvard Dataverse).\n\n\t\n\t\t\n\t\tSource\n\t\n\nData source:  \nOpen Discourse ProjectHarvard DataverseDOI: 10.7910/DVN/FIKIBO\nOriginal citation:\n@data{DVN/FIKIBO_2020,\nauthor = {Richter, Florian and Koch, Philipp and Franke, Oliver and Kraus, Jakob and Kuruc, Fabrizio and Thiem, Anja and HÃ¶gerl, Judith and Heine, Stella and SchÃ¶ps, Konstantin},\npublisher = {Harvardâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/emilpartow/german-parliament-speeches.","url":"https://huggingface.co/datasets/emilpartow/german-parliament-speeches","creator_name":"Emil Partow","creator_url":"https://huggingface.co/emilpartow","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","summarization","text-generation","question-answering","German"],"keywords_longer_than_N":true},
	{"name":"GlotCC-V1","keyword":"german","description":"\n\t\n\t\t\n\t\tDataset Summary\n\t\n\n \n\nGlotCC-V1.0 is a document-level, general domain dataset derived from CommonCrawl, covering more than 1000 languages.It is built using the GlotLID language identification and Ungoliant pipeline from CommonCrawl.We release our pipeline as open-source at https://github.com/cisnlp/GlotCC.  \nList of Languages: See https://datasets-server.huggingface.co/splits?dataset=cis-lmu/GlotCC-V1 to get the list of splits available.\n\n\t\t\n\t\tUsage (Huggingface Hub -- Recommended)â€¦ See the full description on the dataset page: https://huggingface.co/datasets/cis-lmu/GlotCC-V1.","url":"https://huggingface.co/datasets/cis-lmu/GlotCC-V1","creator_name":"CIS, LMU Munich","creator_url":"https://huggingface.co/cis-lmu","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["multilingual","Abau","Amarasi","Abkhaz","Abkhazian"],"keywords_longer_than_N":true},
	{"name":"GlotCC-V1","keyword":"german","description":"\n\t\n\t\t\n\t\tDataset Summary\n\t\n\n \n\nGlotCC-V1.0 is a document-level, general domain dataset derived from CommonCrawl, covering more than 1000 languages.It is built using the GlotLID language identification and Ungoliant pipeline from CommonCrawl.We release our pipeline as open-source at https://github.com/cisnlp/GlotCC.  \nList of Languages: See https://datasets-server.huggingface.co/splits?dataset=cis-lmu/GlotCC-V1 to get the list of splits available.\n\n\t\t\n\t\tUsage (Huggingface Hub -- Recommended)â€¦ See the full description on the dataset page: https://huggingface.co/datasets/cis-lmu/GlotCC-V1.","url":"https://huggingface.co/datasets/cis-lmu/GlotCC-V1","creator_name":"CIS, LMU Munich","creator_url":"https://huggingface.co/cis-lmu","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["multilingual","Abau","Amarasi","Abkhaz","Abkhazian"],"keywords_longer_than_N":true},
	{"name":"jupiter","keyword":"german","description":"\n\t\n\t\t\n\t\tEris Dataset\n\t\n\nEris Dataset is part of an initiative associated with Berinspa, a social media application focused on personal development. Berinspa is developed by Berinspa Group and led by Shi Thumb (birth name: Umar Abdul Aziz) as its CEO.\nThis dataset is released as open source under the Apache License 2.0, allowing users to freely use, modify, and distribute it, as long as the terms of the license are respected.\n\n\t\n\t\t\n\t\n\t\n\t\tKey Features\n\t\n\n\nðŸŒ Multilingual: This dataset isâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/erisdataworks/jupiter.","url":"https://huggingface.co/datasets/erisdataworks/jupiter","creator_name":"Eris Dataworks","creator_url":"https://huggingface.co/erisdataworks","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["Indonesian","English","Spanish","German","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"slimorca_dedup_german_experimental-scored","keyword":"german","description":"\n\t\n\t\t\n\t\tModifications\n\t\n\nThis is the original and unchanged german translated dataset (train split only) in original order from jphme/slimorca_dedup_german_experimental with added cosine-similarity scores. As no license was given for this version, I chose the MIT license from the original Open-Orca/SlimOrca-Dedup dataset.\nThe scores have been calculated using the best static multilingual embedding model (for my needs): sentence-transformers/static-similarity-mrl-multilingual-v1 for fasterâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/MarcGrumpyOlejak/slimorca_dedup_german_experimental-scored.","url":"https://huggingface.co/datasets/MarcGrumpyOlejak/slimorca_dedup_german_experimental-scored","creator_name":"Marc Olejak","creator_url":"https://huggingface.co/MarcGrumpyOlejak","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","German","mit","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"GermEval18","keyword":"german","description":"\n\t\n\t\t\n\t\tGermEval18 Loader\n\t\n\n\nData Repository: https://github.com/uds-lsv/GermEval-2018-Data\nData Reference: https://doi.org/10.11588/data/0B5VML\nPaper: https://epub.oeaw.ac.at/0xc1aa5576_0x003a10d2.pdf\n\n\n\t\n\t\t\n\t\n\t\n\t\tInfo\n\t\n\nNote: This dataset is a loader script that pulls the data straight from the official GitHub repository.\nWhat is the difference to philschmid/germeval18?: We did not get all samples, when using the former script.\nOutput from philschmid/germeval18:\nDatasetDict({\n  train:â€¦ See the full description on the dataset page: https://huggingface.co/datasets/jfrei/GermEval18.","url":"https://huggingface.co/datasets/jfrei/GermEval18","creator_name":"Johann Frei","creator_url":"https://huggingface.co/jfrei","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","German","cc-by-4.0","1K - 10K","parquet"],"keywords_longer_than_N":true},
	{"name":"fusion-synth-data-ufb","keyword":"german","description":"\n\t\n\t\t\n\t\tOffline Synthetic Data (UFB) for: Making, not taking, the Best-of-N\n\t\n\n\n\t\n\t\t\n\t\tContent\n\t\n\nThis data contains completions for a 10,000 subset of the  UFB prompts (translated into 9 languages)  from 5 different teacher models and 2 aggregations:\nTeachers: We sample one completion from each of the following models at temperature T=0.3. For kimik2, qwen3, and deepseek-v3 we use TogetherAI, for gemma3-27b and command-a we use locally hosted images.\n\ngemma3-27b: GEMMA3-27B-IT\nkimik2:â€¦ See the full description on the dataset page: https://huggingface.co/datasets/CohereLabs/fusion-synth-data-ufb.","url":"https://huggingface.co/datasets/CohereLabs/fusion-synth-data-ufb","creator_name":"Cohere Labs","creator_url":"https://huggingface.co/CohereLabs","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-generation","English","French","German","Spanish"],"keywords_longer_than_N":true},
	{"name":"nanobeir-multilingual","keyword":"german","description":"This multilingual collection is derived from the original English NanoBEIR datasets, which are smaller versions of BEIR datasets.\nThe compact size of these datasets makes them ideal for conducting quick and efficient evaluations during training.\nTo facilitate broader research in cross-lingual information retrieval, our dataset has been machine-translated from the original English\ninto eight additional languages: Arabic (ar), German (de), Spanish (es), French (fr), Italian (it), Norwegian (no)â€¦ See the full description on the dataset page: https://huggingface.co/datasets/lightonai/nanobeir-multilingual.","url":"https://huggingface.co/datasets/lightonai/nanobeir-multilingual","creator_name":"LightOn AI","creator_url":"https://huggingface.co/lightonai","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","French","Arabic","English","German"],"keywords_longer_than_N":true},
	{"name":"apertus-sft-mixture","keyword":"german","description":"\n\t\n\t\t\n\t\tApertus Supervised Finetuning Data\n\t\n\nOur supervised finetuning data contains a carefully curated blend of instruction-following datasets, \ndeveloped through eight iterations of empirical evaluation. This final mixture comprises approximately \n3.8 million examples from diverse sources, balancing generalinstruction-following, mathematical reasoning, \ncode generation, and multilingual capabilities. \nMore details about data provenance, preparation, and statistics can be found in our techâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/swiss-ai/apertus-sft-mixture.","url":"https://huggingface.co/datasets/swiss-ai/apertus-sft-mixture","creator_name":"Swiss AI Initiative","creator_url":"https://huggingface.co/swiss-ai","license_name":"Open Data Commons Attribution License v1.0","license_url":"https://scancode-licensedb.aboutcode.org/odc-by-1.0.html","language":"en","first_N":5,"first_N_keywords":["text-generation","English","French","German","Italian"],"keywords_longer_than_N":true},
	{"name":"Wikipedia-X-Concat","keyword":"german","description":"We have combined title and abstracts together into the Concat Abstract column in this dataset. It's a slight modification over our original Wikipedia X dataset. It's done for RAG project purposes.\n","url":"https://huggingface.co/datasets/laion/Wikipedia-X-Concat","creator_name":"LAION eV","creator_url":"https://huggingface.co/laion","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["question-answering","German","English","mit","10M - 100M"],"keywords_longer_than_N":true},
	{"name":"reasoning-multilingual-R1-Llama-70B-train","keyword":"german","description":"\n\t\n\t\t\n\t\tlightblue/reasoning-multilingual-R1-Llama-70B-train\n\t\n\nThis is a multilingual reasoning dataset covering more than 30 languages.\nThis dataset was made by:\n\nSampling prompts from English datasets and translating them to various languages\nGenerating responses to these prompts 8 times using deepseek-ai/DeepSeek-R1-Distill-Llama-70B\nFiltering out <think> sections with incorrect language, non-fluent language, and incorrect answers\n\nThis dataset was then used to train a multilingualâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/lightblue/reasoning-multilingual-R1-Llama-70B-train.","url":"https://huggingface.co/datasets/lightblue/reasoning-multilingual-R1-Llama-70B-train","creator_name":"Lightblue KK.","creator_url":"https://huggingface.co/lightblue","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["Amharic","Arabic","Bengali","Chinese","Czech"],"keywords_longer_than_N":true},
	{"name":"gutenberg_de","keyword":"german","description":"German subset of sedthh/gutenberg_multilang\n","url":"https://huggingface.co/datasets/LemiSt/gutenberg_de","creator_name":"Lennard Michael Strohmeyer","creator_url":"https://huggingface.co/LemiSt","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-generation","German","mit","1K - 10K","parquet"],"keywords_longer_than_N":true},
	{"name":"quran","keyword":"german","description":"\n\t\n\t\t\n\t\tDataset Card for the Quran\n\t\n\n\n\t\n\t\t\n\t\tSummary\n\t\n\nThe Quran with metadata, translations, and multiple Arabic text (can use specific types for embeddings, search, classification, and display). There are 126+ columns containing 43+ languages.\n\n\t\n\t\t\n\t\tTODO\n\t\n\n\n Add Tafsirs  \n Add topics/ontology\n\n\n\t\n\t\t\n\t\tUsage\n\t\n\nfrom datasets import load_dataset\n\nds = load_dataset(\"nazimali/quran\", split=\"train\")\nds\n\nOutput:\nDataset({\n    features: ['surah', 'ayah', 'surah-name', 'surah-total-ayas'â€¦ See the full description on the dataset page: https://huggingface.co/datasets/nazimali/quran.","url":"https://huggingface.co/datasets/nazimali/quran","creator_name":"Nazim Ali","creator_url":"https://huggingface.co/nazimali","license_name":"Creative Commons Attribution 3.0","license_url":"https://scancode-licensedb.aboutcode.org/cc-by-3.0.html","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","translation","feature-extraction","text-generation"],"keywords_longer_than_N":true},
	{"name":"wikipedia-2024-06-bge-m3","keyword":"german","description":"\n\t\n\t\t\n\t\tWikipedia Embeddings with BGE-M3\n\t\n\nThis dataset contains embeddings from the\nJune 2024 Wikipedia dump\nfor the 11 most popular languages.\nThe embeddings are generated with the multilingual\nBGE-M3 model.\nThe dataset consists of Wikipedia articles split into paragraphs,\nand embedded with the aforementioned model.\nTo enhance search quality, the paragraphs are prefixed with their\nrespective article titles before embedding.\nAdditionally, paragraphs containing fewer than 100 charactersâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Upstash/wikipedia-2024-06-bge-m3.","url":"https://huggingface.co/datasets/Upstash/wikipedia-2024-06-bge-m3","creator_name":"Upstash","creator_url":"https://huggingface.co/Upstash","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["English","German","Spanish","Persian","French"],"keywords_longer_than_N":true},
	{"name":"wiktionary-data","keyword":"german","description":"\n\t\n\t\t\n\t\tWiktionary Data on Hugging Face Datasets\n\t\n\n\n\n\n\nwiktionary-data is a sub-data extraction of the English Wiktionary that currently\nsupports the following languages:\n\nDeutsch - German\nLatinum - Latin\ná¼™Î»Î»Î·Î½Î¹ÎºÎ® - Ancient Greek\ní•œêµ­ì–´ - Korean\nðŽ ðŽ¼ðŽ¹ - Old Persian\nð’€ð’…—ð’ºð’Œ‘(ð’Œ) - Akkadian\nElamite\nà¤¸à¤‚à¤¸à¥à¤•à¥ƒà¤¤à¤®à¥ - Sanskrit, or Classical Sanskrit\n\nwiktionary-data was originally a sub-module of wilhelm-graphdb. While\nthe dataset it's getting bigger, I noticed a wave of more exciting potentials thisâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/QubitPi/wiktionary-data.","url":"https://huggingface.co/datasets/QubitPi/wiktionary-data","creator_name":"Jiaqi","creator_url":"https://huggingface.co/QubitPi","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["English","German","Latin","Ancient Greek (to 1453)","Korean"],"keywords_longer_than_N":true},
	{"name":"wiktionary-data","keyword":"german","description":"\n\t\n\t\t\n\t\tWiktionary Data on Hugging Face Datasets\n\t\n\n\n\n\n\nwiktionary-data is a sub-data extraction of the English Wiktionary that currently\nsupports the following languages:\n\nDeutsch - German\nLatinum - Latin\ná¼™Î»Î»Î·Î½Î¹ÎºÎ® - Ancient Greek\ní•œêµ­ì–´ - Korean\nðŽ ðŽ¼ðŽ¹ - Old Persian\nð’€ð’…—ð’ºð’Œ‘(ð’Œ) - Akkadian\nElamite\nà¤¸à¤‚à¤¸à¥à¤•à¥ƒà¤¤à¤®à¥ - Sanskrit, or Classical Sanskrit\n\nwiktionary-data was originally a sub-module of wilhelm-graphdb. While\nthe dataset it's getting bigger, I noticed a wave of more exciting potentials thisâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/QubitPi/wiktionary-data.","url":"https://huggingface.co/datasets/QubitPi/wiktionary-data","creator_name":"Jiaqi","creator_url":"https://huggingface.co/QubitPi","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["English","German","Latin","Ancient Greek (to 1453)","Korean"],"keywords_longer_than_N":true},
	{"name":"filtered_convos_research_llm_summaries_cleaned_v123","keyword":"german","description":"\n\t\n\t\t\n\t\tSynthetic Call Center Summaries Dataset Cleaned - Combined V1-V3\n\t\n\n\n\t\n\t\t\n\t\tDataset Composition\n\t\n\nThis dataset combines three versions of synthetic summaries:\n\nV1 & V2: Filtered for 4-5 sentence summaries\nV3: Cleaned and extracted final summaries\n\n\n\t\n\t\t\n\t\tProcessing Steps\n\t\n\n\nV1 and V2 Processing:\n\nFiltered to include only 4-5 sentence summaries\nRemoved length metadata for consistency\n\n\nV3 Processing:\n\nExtracted final summaries from tagged content\nRemoved length metadata forâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/marccgrau/filtered_convos_research_llm_summaries_cleaned_v123.","url":"https://huggingface.co/datasets/marccgrau/filtered_convos_research_llm_summaries_cleaned_v123","creator_name":"Marc Christopher Grau","creator_url":"https://huggingface.co/marccgrau","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["summarization","text-generation","synthetic","monolingual","German"],"keywords_longer_than_N":true},
	{"name":"tatoeba_kbd","keyword":"german","description":"\n\t\n\t\t\n\t\tTatoeba Translations Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset contains parallel sentence translations from Tatoeba to Kabardian language (kbd), filtered by similarity score. The source languages are:\n\nGerman (deu)\nEnglish (eng)\nFrench (fra)\nPortuguese (por)\nRussian (rus)\nSpanish (spa)\nTurkish (tur)\n\nAll translations in this dataset are paired with Kabardian (kbd) as the target language.\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThe dataset consists of high-quality parallelâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/panagoa/tatoeba_kbd.","url":"https://huggingface.co/datasets/panagoa/tatoeba_kbd","creator_name":"adam panagov","creator_url":"https://huggingface.co/panagoa","license_name":"Creative Commons Attribution 2.0","license_url":"https://scancode-licensedb.aboutcode.org/cc-by-2.0.html","language":"en","first_N":5,"first_N_keywords":["translation","Kabardian","German","English","French"],"keywords_longer_than_N":true},
	{"name":"semeval-2025-task11-track-a","keyword":"german","description":"\n\t\n\t\t\n\t\tSemEval 2025 Task 11 - Track A Dataset\n\t\n\nThis dataset contains the data for SemEval 2025 Task 11: Bridging the Gap in Text-Based Emotion Detection - Track A, organized as language-specific configurations.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset is a multi-language, multi-label emotion classification dataset with separate configurations for each language.\n\nTotal languages: 26 standard ISO codes\nTotal examples: 115159\nSplits: train, dev, test\n\n\n\t\n\t\t\n\t\tLanguage Configurations\n\t\n\nEachâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/vgaraujov/semeval-2025-task11-track-a.","url":"https://huggingface.co/datasets/vgaraujov/semeval-2025-task11-track-a","creator_name":"Vladimir Araujo","creator_url":"https://huggingface.co/vgaraujov","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["Afrikaans","Amharic","Arabic","German","English"],"keywords_longer_than_N":true},
	{"name":"aya_dataset","keyword":"german","description":"\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThe Aya Dataset is a multilingual instruction fine-tuning dataset curated by an open-science community via Aya Annotation Platform from Cohere Labs. The dataset contains a total of 204k human-annotated prompt-completion pairs along with the demographics data of the annotators.\nThis dataset can be used to train, finetune, and evaluate multilingual LLMs.\n\nCurated by: Contributors of Aya Open Science Intiative.\n\nLanguage(s): 65 languages (71 including dialects &â€¦ See the full description on the dataset page: https://huggingface.co/datasets/CohereLabs/aya_dataset.","url":"https://huggingface.co/datasets/CohereLabs/aya_dataset","creator_name":"Cohere Labs","creator_url":"https://huggingface.co/CohereLabs","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["other","crowdsourced","expert-generated","crowdsourced","expert-generated"],"keywords_longer_than_N":true},
	{"name":"fleurs_clean","keyword":"german","description":"\n\t\n\t\t\n\t\n\t\n\t\tFLEURS\n\t\n\nFleurs is the speech version of the FLoRes machine translation benchmark. \nWe use 2009 n-way parallel sentences from the FLoRes dev and devtest publicly available sets, in 102 languages. \nTraining sets have around 10 hours of supervision. Speakers of the train sets are different than speakers from the dev/test sets. Multilingual fine-tuning is\nused and â€unit error rateâ€ (characters, signs) of all languages is averaged. Languages and results are also grouped into sevenâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Helloworld668/fleurs_clean.","url":"https://huggingface.co/datasets/Helloworld668/fleurs_clean","creator_name":"zhide Tang","creator_url":"https://huggingface.co/Helloworld668","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","expert-generated","crowdsourced","machine-generated","crowdsourced"],"keywords_longer_than_N":true},
	{"name":"BRIGHTER-emotion-intensities","keyword":"german","description":"\n\t\n\t\t\n\t\tBRIGHTER Emotion Intensities Dataset\n\t\n\nThis dataset contains the emotion intensities data from the BRIGHTER paper: BRIdging the Gap in Human-Annotated Textual Emotion Recognition Datasets for 28 Languages.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe BRIGHTER Emotion Intensities dataset is a comprehensive multi-language emotion intensity dataset with separate configurations for each language. It represents one of the largest human-annotated emotion datasets across multiple languages, providingâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/brighter-dataset/BRIGHTER-emotion-intensities.","url":"https://huggingface.co/datasets/brighter-dataset/BRIGHTER-emotion-intensities","creator_name":"BRIGHTER Dataset","creator_url":"https://huggingface.co/brighter-dataset","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["Arabic","German","English","Spanish","Hausa"],"keywords_longer_than_N":true},
	{"name":"Web-multilingual","keyword":"german","description":"\n\t\n\t\t\n\t\tDataset Card for Dataset Name\n\t\n\nThis dataset contains 1,141 multilingual web pages.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\n Each page contains the visible text extracted from the page. Each page includes 2 or more languages, with 2 prominent languages. \n page.csv lists the 2 prominent for each page. The content of the page is found in the pages/ folder.\n The breakdown of languages is the following:\n   1705 en\n   1043 fr\n    336 zh\n     90 es\n     79 id\n     77 de\n     75 pt\n     40 it\n     34â€¦ See the full description on the dataset page: https://huggingface.co/datasets/MAximeSobrier/Web-multilingual.","url":"https://huggingface.co/datasets/MAximeSobrier/Web-multilingual","creator_name":"Maxime Sobrier","creator_url":"https://huggingface.co/MAximeSobrier","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","French","English","Chinese","Portuguese"],"keywords_longer_than_N":true},
	{"name":"multiblimp","keyword":"german","description":"\n\t\n\t\t\n\t\tMultiBLiMP\n\t\n\nMultiBLiMP is a massively Multilingual Benchmark for Linguistic Minimal Pairs. The dataset is composed of synthetic pairs generated using Universal Dependencies and UniMorph.\nThe paper can be found here.\nWe split the data set by language: each language consists of a single .tsv file. The rows contain many attributes for a particular pair, most important are the sen and wrong_sen fields, which we use for evaluating the language models.\n\n\t\n\t\t\n\t\n\t\n\t\tUsing MultiBLiMP\n\t\n\nToâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/jumelet/multiblimp.","url":"https://huggingface.co/datasets/jumelet/multiblimp","creator_name":"Jaap Jumelet","creator_url":"https://huggingface.co/jumelet","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["multilingual","Buriat","Spanish","Sanskrit","Romanian"],"keywords_longer_than_N":true},
	{"name":"MCIF","keyword":"german","description":"\n\t\n\t\t\n\t\tDataset Description, Collection, and Source\n\t\n\nMCIF (Multimodal Crosslingual Instruction Following) is a multilingual human-annotated benchmark \nbased on scientific talks that is designed to evaluate instruction-following in crosslingual, \nmultimodal settings over both short- and long-form inputs. \nMCIF spans three core modalities -- speech, vision, and text -- and four diverse languages (English, German, Italian, and Chinese), \nenabling a comprehensive evaluation of MLLMs' abilitiesâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/danniliu/MCIF.","url":"https://huggingface.co/datasets/danniliu/MCIF","creator_name":"Danni Liu","creator_url":"https://huggingface.co/danniliu","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","question-answering","summarization","visual-question-answering","translation"],"keywords_longer_than_N":true},
	{"name":"pawsx_mt_triplet","keyword":"german","description":"\n\t\n\t\t\n\t\tPAWS-X Multilingual Triplet Dataset\n\t\n\nThis dataset contains PAWS-X (Paraphrase Adversaries from Word Scrambling) data organized by translation models for paraphrase detection and text similarity tasks.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nEach sample contains the following fields:\n\nid: Unique identifier for the text pair\ntext1: First sentence (originally sentence1)\ntext2: Second sentence (originally sentence2)  \nlabel: Binary label (1 for paraphrase, 0 for non-paraphrase)\nmodel: Translationâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/patrickamadeus/pawsx_mt_triplet.","url":"https://huggingface.co/datasets/patrickamadeus/pawsx_mt_triplet","creator_name":"Patrick Amadeus Irawan","creator_url":"https://huggingface.co/patrickamadeus","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","translation","German","Spanish","French"],"keywords_longer_than_N":true},
	{"name":"4PLANSMOBUDDY03","keyword":"german","description":"HDBrinkmann/4PLANSMOBUDDY03 dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/HDBrinkmann/4PLANSMOBUDDY03","creator_name":"Brinkmann","creator_url":"https://huggingface.co/HDBrinkmann","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["German","apache-2.0","1K - 10K","csv","Text"],"keywords_longer_than_N":true},
	{"name":"TransCorpus-bio-de","keyword":"german","description":"\n\t\n\t\t\n\t\tTransCorpus-bio-de\n\t\n\nTransCorpus-bio-de is a large-scale, parallel biomedical corpus consisting of German synthetic translations of PubMed abstracts. This dataset was created using the TransCorpus framework and is designed to enable high-quality German biomedical language modeling and downstream NLP research.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\nSource: PubMed abstracts (English)\nTarget: German (synthetic, machine-translated)\nTranslation Model: M2M-100 (1.2B) using TransCorpus Toolkit\nSize: 22â€¦ See the full description on the dataset page: https://huggingface.co/datasets/jknafou/TransCorpus-bio-de.","url":"https://huggingface.co/datasets/jknafou/TransCorpus-bio-de","creator_name":"Julien Knafou","creator_url":"https://huggingface.co/jknafou","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["German","mit","10M - 100M","text","Text"],"keywords_longer_than_N":true},
	{"name":"wmt24pp-rm","keyword":"german","description":"\n\t\n\t\t\n\t\tWMT24++ Reference Translations for Romansh\n\t\n\n\n\t\n\t\t\n\t\tDescription\n\t\n\nWMT24++ benchmark in Romansh (six varieties: Rumantsch Grischun, Sursilvan, Sutsilvan, Surmiran, Puter, and Vallader).\n\nPaper: \"Expanding the WMT24++ Benchmark with Rumantsch Grischun, Sursilvan, Sutsilvan, Surmiran, Puter, and Vallader\"\n\nCode: https://github.com/ZurichNLP/romansh_mt_eval\n\nOriginal WMT24++ benchmark (55 languages): https://huggingface.co/datasets/google/wmt24pp\n\nThe reference translation have beenâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/ZurichNLP/wmt24pp-rm.","url":"https://huggingface.co/datasets/ZurichNLP/wmt24pp-rm","creator_name":"University of Zurich, Department of Computational Linguistics","creator_url":"https://huggingface.co/ZurichNLP","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["translation","Romansh","German","apache-2.0","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"invoices-example","keyword":"german","description":"\n\t\n\t\t\n\t\tInoices Sample Dataset\n\t\n\nThis is a sample dataset generated on app.parsee.ai for invoices. The goal was to evaluate different LLMs on this RAG task using the Parsee evaluation tools. A full study can be found here: https://github.com/parsee-ai/parsee-datasets/blob/main/datasets/invoices/parsee-loader/README.md\nparsee-core version used: 0.1.3.11\nThis dataset was created on the basis of 15 sample invoices (PDF files).\nAll PDF files are publicly accessible on parsee.ai, to access themâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/parsee-ai/invoices-example.","url":"https://huggingface.co/datasets/parsee-ai/invoices-example","creator_name":"Parsee.ai","creator_url":"https://huggingface.co/parsee-ai","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["question-answering","English","German","mit","< 1K"],"keywords_longer_than_N":true},
	{"name":"Multi-EuP","keyword":"german","description":"\n\t\n\t\t\n\t\tNOTES FOR DOWNLOAD!\n\t\n\n\nHighly recommend downloading it via the API:\n\ncurl -X GET \\\n     \"https://datasets-server.huggingface.co/first-rows?dataset=unimelb-nlp%2FMulti-EuP&config=default&split=full\"\n\n\nIf you are using the HuggingFace library, please follow these steps:\n\npip install datasets\n\nfrom datasets import load_dataset\n\ndataset = load_dataset(\"unimelb-nlp/Multi-EuP\", keep_default_na=False)\n\nNote: It's crucial to use keep_default_na=False because some datasets contain 'null'â€¦ See the full description on the dataset page: https://huggingface.co/datasets/unimelb-nlp/Multi-EuP.","url":"https://huggingface.co/datasets/unimelb-nlp/Multi-EuP","creator_name":"The University of Melbourne","creator_url":"https://huggingface.co/unimelb-nlp","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","English","German","French","Italian"],"keywords_longer_than_N":true},
	{"name":"oscar-mini","keyword":"german","description":"The Open Super-large Crawled ALMAnaCH coRpus is a huge multilingual corpus obtained by language classification and filtering of the Common Crawl corpus using the goclassy architecture.\\","url":"https://huggingface.co/datasets/nthngdy/oscar-mini","creator_name":"Nathan Godey","creator_url":"https://huggingface.co/nthngdy","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":null,"first_N":5,"first_N_keywords":["text-generation","language-modeling","no-annotation","found","multilingual"],"keywords_longer_than_N":true},
	{"name":"JinaVDREuropeanaDeNewsRetrieval","keyword":"german","description":"\n  JinaVDREuropeanaDeNewsRetrieval\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nRetrieve German news articles based on LLM generated queries.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2i\n\n\nDomains\nNews\n\n\nReference\nhttps://huggingface.co/datasets/jinaai/europeana-de-news_beir\n\n\n\t\n\nSource datasets:\n\njinaai/europeana-de-news_beir\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask =â€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/JinaVDREuropeanaDeNewsRetrieval.","url":"https://huggingface.co/datasets/mteb/JinaVDREuropeanaDeNewsRetrieval","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["visual-document-retrieval","image-to-text","text-to-image","LM-generated","monolingual"],"keywords_longer_than_N":true},
	{"name":"blbooks-parquet-embedded","keyword":"german","description":"\n\t\n\t\t\n\t\tDataset Card for \"blbooks-parquet-embedded\"\n\t\n\nMore Information needed\n","url":"https://huggingface.co/datasets/davanstrien/blbooks-parquet-embedded","creator_name":"Daniel van Strien","creator_url":"https://huggingface.co/davanstrien","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","fill-mask","other","language-modeling","masked-language-modeling"],"keywords_longer_than_N":true},
	{"name":"ARK-Metadata-V2","keyword":"german","description":"\n\t\n\t\t\n\t\tTitle\n\t\n\nMetadata of the \"Alter Realkatalog\" (ARK) of Berlin State Library (SBB) Version 2 â€“ August 2025\n\n\t\n\t\t\n\t\tDescription\n\t\n\nThis dataset was created with the intent to provide a single larger set of metadata from Berlin State Library for research purposes and the development of AI applications.\nThe dataset comprises descriptive metadata of 2.639.554 titles derived from the union catalogue K10plus, a database with about 200 million records from libraries across 11 German states.â€¦ See the full description on the dataset page: https://huggingface.co/datasets/SBB/ARK-Metadata-V2.","url":"https://huggingface.co/datasets/SBB/ARK-Metadata-V2","creator_name":"Staatsbibliothek zu Berlin - PreuÃŸischer Kulturbesitz","creator_url":"https://huggingface.co/SBB","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","feature-extraction","German","Latin","English"],"keywords_longer_than_N":true},
	{"name":"voxpopuli","keyword":"german","description":"A large-scale multilingual speech corpus for representation learning, semi-supervised learning and interpretation.","url":"https://huggingface.co/datasets/facebook/voxpopuli","creator_name":"AI at Meta","creator_url":"https://huggingface.co/facebook","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":null,"first_N":5,"first_N_keywords":["automatic-speech-recognition","multilingual","English","German","French"],"keywords_longer_than_N":true},
	{"name":"German-PD-Newspapers","keyword":"german","description":"\n\t\n\t\t\n\t\tDataset Card for Public Domain Newspapers (German)\n\t\n\n\n\nThis dataset contains 13 billion words of OCR text extracted from German historical newspapers. \n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\n\n\n\n\nCurated by: Sebastian Majstorovic\nLanguage(s) (NLP): German\nLicense: Dataset: CC0, Texts: Public Domain\n\n\n\t\n\t\t\n\t\tDataset Sources [optional]\n\t\n\n\n\n\nRepository: https://www.deutsche-digitale-bibliothek.de/newspaper\n\n\n\t\n\t\t\n\t\tCopyright & License\n\t\n\nThe newspapers texts have beenâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/storytracer/German-PD-Newspapers.","url":"https://huggingface.co/datasets/storytracer/German-PD-Newspapers","creator_name":"Sebastian Majstorovic","creator_url":"https://huggingface.co/storytracer","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","German","cc0-1.0","1M - 10M","parquet"],"keywords_longer_than_N":true},
	{"name":"bnl_newspapers","keyword":"german","description":"\n\t\n\t\t\n\t\tDataset Card for BnL Historical Newspapers\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThe BnL has digitised over 800.000 pages of Luxembourg newspapers. This dataset currently has one configuration covering a subset of these newspapers, which sit under the \"Processed Datasets\" collection. The BNL:\n\nprocessed all newspapers and monographs that are in the public domain and extracted the full text and associated meta data of every single article, section, advertisementâ€¦ The result is a large number ofâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/bnl-data/bnl_newspapers.","url":"https://huggingface.co/datasets/bnl-data/bnl_newspapers","creator_name":"BnL Open Data","creator_url":"https://huggingface.co/bnl-data","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","fill-mask","language-modeling","masked-language-modeling","no-annotation"],"keywords_longer_than_N":true},
	{"name":"para_crawl","keyword":"german","description":"\n\t\n\t\t\n\t\tDataset Card for \"para_crawl\"\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nWeb-Scale Parallel Corpora for Official European Languages.\n\n\t\n\t\t\n\t\tSupported Tasks and Leaderboards\n\t\n\nMore Information Needed\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nMore Information Needed\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\n\t\n\t\t\n\t\tData Instances\n\t\n\n\n\t\n\t\t\n\t\tenbg\n\t\n\n\nSize of downloaded dataset files: 103.75 MB\nSize of the generated dataset: 356.54 MB\nTotal amount of disk used: 460.27 MB\n\nAn example of 'train' looks as follows.\nThis example was tooâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/ParaCrawl/para_crawl.","url":"https://huggingface.co/datasets/ParaCrawl/para_crawl","creator_name":"ParaCrawl","creator_url":"https://huggingface.co/ParaCrawl","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":null,"first_N":5,"first_N_keywords":["translation","no-annotation","found","translation","original"],"keywords_longer_than_N":true},
	{"name":"WikidataLabels","keyword":"german","description":"\n\t\n\t\t\n\t\tWikidata Labels\n\t\n\nLarge parallel corpus for machine translation\n\nEntity label data extracted from Wikidata (2022-01-03), filtered for item entities only  \nOnly download the languages you need with datasets>=2.14.0\nSimilar dataset: https://huggingface.co/datasets/wmt/wikititles (18 Wikipedia titles pairs instead of all Wikidata entities)\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Sources\n\t\n\n\nWikidata JSON dump (wikidata-20220103-all.json.gz)â€¦ See the full description on the dataset page: https://huggingface.co/datasets/rayliuca/WikidataLabels.","url":"https://huggingface.co/datasets/rayliuca/WikidataLabels","creator_name":"Ray Liu","creator_url":"https://huggingface.co/rayliuca","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["translation","English","French","German","Japanese"],"keywords_longer_than_N":true},
	{"name":"language_tags","keyword":"german","description":"\n\t\n\t\t\n\t\tDescription\n\t\n\nDataset listing 27,328 languages and dialects (also includes macrolanguage names).For each language, either the ISO 639 code, the Glottolog code or both are provided.\n\n\t\n\t\t\n\t\tColumns\n\t\n\n\nEnglish_Name: Language name in English (e.g. \"French\").\nNative_Name: If value is not 0, corresponds to the name of the language by native speakers (e.g. \"FranÃ§ais\") which may have been found in Wikipedia's nativename field.\nGlottocode: The language tag in the Glottolog convention (e.g.â€¦ See the full description on the dataset page: https://huggingface.co/datasets/lbourdois/language_tags.","url":"https://huggingface.co/datasets/lbourdois/language_tags","creator_name":"LoÃ¯ck BOURDOIS","creator_url":"https://huggingface.co/lbourdois","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["Afade","ParÃ¡ ArÃ¡ra","Afar","Aka-Bea","Abon"],"keywords_longer_than_N":true},
	{"name":"language_tags","keyword":"swiss german","description":"\n\t\n\t\t\n\t\tDescription\n\t\n\nDataset listing 27,328 languages and dialects (also includes macrolanguage names).For each language, either the ISO 639 code, the Glottolog code or both are provided.\n\n\t\n\t\t\n\t\tColumns\n\t\n\n\nEnglish_Name: Language name in English (e.g. \"French\").\nNative_Name: If value is not 0, corresponds to the name of the language by native speakers (e.g. \"FranÃ§ais\") which may have been found in Wikipedia's nativename field.\nGlottocode: The language tag in the Glottolog convention (e.g.â€¦ See the full description on the dataset page: https://huggingface.co/datasets/lbourdois/language_tags.","url":"https://huggingface.co/datasets/lbourdois/language_tags","creator_name":"LoÃ¯ck BOURDOIS","creator_url":"https://huggingface.co/lbourdois","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["Afade","ParÃ¡ ArÃ¡ra","Afar","Aka-Bea","Abon"],"keywords_longer_than_N":true},
	{"name":"intel_orca_dpo_pairs_de","keyword":"german","description":"german auzureml translation from mayflowergmbh/intel_orca_dpo_pairs_de, here only put back to original jsonl structure\n","url":"https://huggingface.co/datasets/cstr/intel_orca_dpo_pairs_de","creator_name":"cstr","creator_url":"https://huggingface.co/cstr","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["German","apache-2.0","10K - 100K","json","Text"],"keywords_longer_than_N":true},
	{"name":"fleurs","keyword":"german","description":"\n\t\n\t\t\n\t\tFLEURS\n\t\n\nFleurs is the speech version of the FLoRes machine translation benchmark. \nWe use 2009 n-way parallel sentences from the FLoRes dev and devtest publicly available sets, in 102 languages. \nTraining sets have around 10 hours of supervision. Speakers of the train sets are different than speakers from the dev/test sets. Multilingual fine-tuning is\nused and â€unit error rateâ€ (characters, signs) of all languages is averaged. Languages and results are also grouped into sevenâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/cahya/fleurs.","url":"https://huggingface.co/datasets/cahya/fleurs","creator_name":"Cahya Wirawan","creator_url":"https://huggingface.co/cahya","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":null,"first_N":5,"first_N_keywords":["automatic-speech-recognition","expert-generated","crowdsourced","machine-generated","crowdsourced"],"keywords_longer_than_N":true},
	{"name":"all-scam-spam","keyword":"german","description":"This is a large corpus of 42,619 preprocessed text messages and emails sent by humans in 43 languages. is_spam=1 means spam and is_spam=0 means ham.\n1040 rows of balanced data, consisting of casual conversations and scam emails in â‰ˆ10 languages, were manually collected and annotated by me, with some help from ChatGPT.\n\n\n\n\t\n\t\t\n\t\tSome preprcoessing algorithms\n\t\n\n\nspam_assassin.js, followed by spam_assassin.py\nenron_spam.py\n\n\n\n\n\t\n\t\t\n\t\tData composition\n\t\n\n\n\n\n\n\t\n\t\t\n\t\tDescription\n\t\n\nTo make the textâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/FredZhang7/all-scam-spam.","url":"https://huggingface.co/datasets/FredZhang7/all-scam-spam","creator_name":"Fred Zhang","creator_url":"https://huggingface.co/FredZhang7","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","zero-shot-classification","Norwegian","Spanish","Somali"],"keywords_longer_than_N":true},
	{"name":"oasst2_top1_chat_format","keyword":"german","description":"\n\t\n\t\t\n\t\tOpenAssistant TOP-1 Conversation Threads in huggingface chat format\n\t\n\nExport of oasst2 only top 1 threads in huggingface chat format\n\n\t\n\t\t\n\t\tScript\n\t\n\nThe convert script can be find here\n","url":"https://huggingface.co/datasets/blancsw/oasst2_top1_chat_format","creator_name":"Blanc Swan","creator_url":"https://huggingface.co/blancsw","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["English","Spanish","Russian","German","Polish"],"keywords_longer_than_N":true},
	{"name":"MCIF","keyword":"german","description":"\n\n\n\n\n\t\n\t\t\n\t\tDataset Description, Collection, and Source\n\t\n\nMCIF (Multimodal Crosslingual Instruction Following) is a multilingual human-annotated benchmark \nbased on scientific talks that is designed to evaluate instruction-following in crosslingual,\nmultimodal settings over both short- and long-form inputs. \nMCIF spans three core modalities -- speech, vision, and text -- and four diverse languages (English, German, Italian, and Chinese), \nenabling a comprehensive evaluation of MLLMs'â€¦ See the full description on the dataset page: https://huggingface.co/datasets/FBK-MT/MCIF.","url":"https://huggingface.co/datasets/FBK-MT/MCIF","creator_name":"FBK-MT","creator_url":"https://huggingface.co/FBK-MT","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","question-answering","summarization","visual-question-answering","translation"],"keywords_longer_than_N":true},
	{"name":"Vidore2EconomicsReportsRetrieval","keyword":"german","description":"\n  Vidore2EconomicsReportsRetrieval\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nRetrieve associated pages according to questions.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2i\n\n\nDomains\nAcademic\n\n\nReference\nhttps://arxiv.org/pdf/2407.01449\n\n\n\t\n\nSource datasets:\n\nvidore/economics_reports_v2\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask = mteb.get_task(\"Vidore2EconomicsReportsRetrieval\")\nevaluator =â€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/Vidore2EconomicsReportsRetrieval.","url":"https://huggingface.co/datasets/mteb/Vidore2EconomicsReportsRetrieval","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["visual-document-retrieval","image-to-text","text-to-image","derived","multilingual"],"keywords_longer_than_N":true},
	{"name":"mittens","keyword":"german","description":"\n\t\n\t\t\n\t\tMiTTenS: A Dataset for Evaluating Misgendering in Translation\n\t\n\nMisgendering is the act of referring to someone in a way that does not reflect their gender identity.  Translation systems, including foundation models capable of translation, can produce errors that result in misgendering harms. To measure the extent of such potential harms when translating into and out of English, we introduce a dataset, MiTTenS, covering 26 languages from a variety of language families and scriptsâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/google/mittens.","url":"https://huggingface.co/datasets/google/mittens","creator_name":"Google","creator_url":"https://huggingface.co/google","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["translation","Arabic","Finnish","Oromo","Ganda"],"keywords_longer_than_N":true},
	{"name":"wmt-mqm-human-evaluation","keyword":"german","description":"\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset contains all MQM human annotations from previous WMT Metrics shared tasks and the MQM annotations from Experts, Errors, and Context.\nThe data is organised into 8 columns:\n\nlp: language pair\nsrc: input text\nmt: translation\nref: reference translation\nscore: MQM score\nsystem: MT Engine that produced the translation\nannotators: number of annotators\ndomain: domain of the input text (e.g. news)\nyear: collection year\n\nYou can also find the original data here.â€¦ See the full description on the dataset page: https://huggingface.co/datasets/RicardoRei/wmt-mqm-human-evaluation.","url":"https://huggingface.co/datasets/RicardoRei/wmt-mqm-human-evaluation","creator_name":"Ricardo Rei","creator_url":"https://huggingface.co/RicardoRei","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["English","German","Russian","Chinese","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"professor_heideltime_en","keyword":"german","description":"\n\t\n\t\t\n\t\tProfessor HeidelTime\n\t\n\n\n\nProfessor HeidelTime is a project to create a multilingual corpus weakly labeled with HeidelTime, a temporal tagger.\n\n\t\n\t\t\n\t\n\t\n\t\tCorpus Details\n\t\n\nThe weak labeling was performed in six languages. Here are the specifics of the corpus for each language:\n\n\t\n\t\t\nDataset\nLanguage\nDocuments\nFrom\nTo\nTokens\nTimexs\n\n\n\t\t\nAll the News 2.0\nEN\n24,642\n2016-01-01\n2020-04-0218,755,616\n254,803\n\n\nItalian Crime News\nIT\n9,619\n2011-01-01\n2021-12-31\n3,296,898\n58,823\n\n\nGerman Newsâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/hugosousa/professor_heideltime_en.","url":"https://huggingface.co/datasets/hugosousa/professor_heideltime_en","creator_name":"Hugo Sousa","creator_url":"https://huggingface.co/hugosousa","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["token-classification","parsing","part-of-speech","named-entity-recognition","machine-generated"],"keywords_longer_than_N":true},
	{"name":"malicious-website-features-2.4M","keyword":"german","description":"Important Notice:\n\nA subset of the URL dataset is from Kaggle, and the Kaggle datasets contained 10%-15% mislabelled data. See this dicussion I opened for some false positives. I have contacted Kaggle regarding their erroneous \"Usability\" score calculation for these unreliable datasets.\nThe feature extraction methods shown here are not robust at all in 2023, and there're even silly mistakes in 3 functions: not_indexed_by_google, domain_registration_length, and age_of_domain.\n\n\n\nThe featuresâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/FredZhang7/malicious-website-features-2.4M.","url":"https://huggingface.co/datasets/FredZhang7/malicious-website-features-2.4M","creator_name":"Fred Zhang","creator_url":"https://huggingface.co/FredZhang7","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","feature-extraction","tabular-classification","Norwegian","Afrikaans"],"keywords_longer_than_N":true},
	{"name":"saf_micro_job_german","keyword":"german","description":"\n\t\n\t\t\n\t\tDataset Card for \"saf_micro_job_german\"\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nShort Answer Feedback (SAF) dataset is a short answer dataset introduced in Your Answer is Incorrect... Would you like to know why? Introducing a Bilingual Short Answer Feedback Dataset (Filighera et al., ACL 2022) as a way to remedy the lack of content-focused feedback datasets. This version of the dataset contains 8 German questions used in micro-job training on the crowd-worker platform appJobber - while theâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Short-Answer-Feedback/saf_micro_job_german.","url":"https://huggingface.co/datasets/Short-Answer-Feedback/saf_micro_job_german","creator_name":"Short Answer Feedback Interest Group","creator_url":"https://huggingface.co/Short-Answer-Feedback","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["expert-generated","other","monolingual","original","German"],"keywords_longer_than_N":true},
	{"name":"tatoeba","keyword":"german","description":"This is a collection of translated sentences from Tatoeba\n359 languages, 3,403 bitexts\ntotal number of files: 750\ntotal number of tokens: 65.54M\ntotal number of sentence fragments: 8.96M","url":"https://huggingface.co/datasets/Helsinki-NLP/tatoeba","creator_name":"Language Technology Research Group at the University of Helsinki","creator_url":"https://huggingface.co/Helsinki-NLP","license_name":"Creative Commons Attribution 2.0","license_url":"https://scancode-licensedb.aboutcode.org/cc-by-2.0.html","language":null,"first_N":5,"first_N_keywords":["translation","found","found","multilingual","original"],"keywords_longer_than_N":true},
	{"name":"MultiLegalPile_Wikipedia_Filtered","keyword":"german","description":"A filtered version of the MultiLegalPile dataset, together with wikipedia articles.","url":"https://huggingface.co/datasets/joelniklaus/MultiLegalPile_Wikipedia_Filtered","creator_name":"Joel Niklaus","creator_url":"https://huggingface.co/joelniklaus","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["fill-mask","other","found","multilingual","original"],"keywords_longer_than_N":true},
	{"name":"xcsr","keyword":"german","description":"\n\t\n\t\t\n\t\tDataset Card for X-CSR\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nTo evaluate multi-lingual language models (ML-LMs) for commonsense reasoning in a cross-lingual zero-shot transfer setting (X-CSR), i.e., training in English and test in other languages, we create two benchmark datasets, namely X-CSQA and X-CODAH. Specifically, we automatically translate the original CSQA and CODAH datasets, which only have English versions, to 15 other languages, forming development and test sets for studying X-CSR.â€¦ See the full description on the dataset page: https://huggingface.co/datasets/INK-USC/xcsr.","url":"https://huggingface.co/datasets/INK-USC/xcsr","creator_name":"INK Lab @ USC","creator_url":"https://huggingface.co/INK-USC","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["question-answering","multiple-choice-qa","crowdsourced","crowdsourced","machine-generated"],"keywords_longer_than_N":true},
	{"name":"tatoeba","keyword":"swiss german","description":"This is a collection of translated sentences from Tatoeba\n359 languages, 3,403 bitexts\ntotal number of files: 750\ntotal number of tokens: 65.54M\ntotal number of sentence fragments: 8.96M","url":"https://huggingface.co/datasets/Helsinki-NLP/tatoeba","creator_name":"Language Technology Research Group at the University of Helsinki","creator_url":"https://huggingface.co/Helsinki-NLP","license_name":"Creative Commons Attribution 2.0","license_url":"https://scancode-licensedb.aboutcode.org/cc-by-2.0.html","language":null,"first_N":5,"first_N_keywords":["translation","found","found","multilingual","original"],"keywords_longer_than_N":true},
	{"name":"ms_terms","keyword":"german","description":"The Microsoft Terminology Collection can be used to develop localized versions of applications that integrate with Microsoft products.\nIt can also be used to integrate Microsoft terminology into other terminology collections or serve as a base IT glossary\nfor language development in the nearly 100 languages available. Terminology is provided in .tbx format, an industry standard for terminology exchange.","url":"https://huggingface.co/datasets/microsoft/ms_terms","creator_name":"Microsoft","creator_url":"https://huggingface.co/microsoft","license_name":"Microsoft Public License","license_url":"https://choosealicense.com/licenses/ms-pl/","language":null,"first_N":5,"first_N_keywords":["translation","expert-generated","expert-generated","multilingual","translation"],"keywords_longer_than_N":true},
	{"name":"ws-semantics-simnrel","keyword":"german","description":"\n\t\n\t\t\n\t\tDataset Card for WS353-semantics-sim-and-rel with ~2K entries.\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nLicense: Apache-2.0. Contains CSV of a list of word1, word2, their connection score, type of connection and language.\n\n\n\t\n\t\t\n\t\tOriginal Datasets are available here:\n\t\n\n\nhttps://leviants.com/multilingual-simlex999-and-wordsim353/\n\n\n\n\t\n\t\t\n\t\tPaper of original Dataset:\n\t\n\n\nhttps://arxiv.org/pdf/1508.00106v5.pdf\n\n","url":"https://huggingface.co/datasets/0x22almostEvil/ws-semantics-simnrel","creator_name":"David Glushkov","creator_url":"https://huggingface.co/0x22almostEvil","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","English","Russian","German","Italian"],"keywords_longer_than_N":true},
	{"name":"german-multifin","keyword":"german","description":"\n\t\n\t\t\n\t\tDataset Card for Geman financial text (sentence) classification dataset\n\t\n\n\n\n\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset contains real-world financial article headlines annotated with both high-level and low-level topics. \nThe dataset is annotated with 6 high-level topics and 23 low-level topics for multi-class and multi-label \nclassification, respectively. For the multi-label classification task, there are up to 3 annotations per example, which sums up to 14â€¦ See the full description on the dataset page: https://huggingface.co/datasets/anhaltai/german-multifin.","url":"https://huggingface.co/datasets/anhaltai/german-multifin","creator_name":"Artificial Intelligence at Anhalt University of Applied Sciences","creator_url":"https://huggingface.co/anhaltai","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","German","cc-by-4.0","10K - 100K","json"],"keywords_longer_than_N":true},
	{"name":"Sci-Fi-Books-gutenberg","keyword":"german","description":"\n\t\n\t\t\n\t\tGutenberg Sci-Fi Book Dataset\n\t\n\nThis dataset contains information about science fiction books. Itâ€™s designed for training AI models, research, or any other purpose related to natural language processing.\n\n\t\n\t\t\n\t\tData Format\n\t\n\nThe dataset is provided in CSV format. Each record represents a book and includes the following fields:\nID: A unique identifier for the book.\nTitle: The title of the book.\nAuthor: The author(s) of the book.\nText: The text content of the book (e.g., summaryâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/stevez80/Sci-Fi-Books-gutenberg.","url":"https://huggingface.co/datasets/stevez80/Sci-Fi-Books-gutenberg","creator_name":"Steve t","creator_url":"https://huggingface.co/stevez80","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","English","German","apache-2.0","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"MultiLegalPileWikipediaFiltered","keyword":"german","description":"A filtered version of the MultiLegalPile dataset, together with wikipedia articles.","url":"https://huggingface.co/datasets/joelniklaus/MultiLegalPileWikipediaFiltered","creator_name":"Joel Niklaus","creator_url":"https://huggingface.co/joelniklaus","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["fill-mask","other","found","multilingual","original"],"keywords_longer_than_N":true},
	{"name":"LHM-Dienstleistungen-QA","keyword":"german","description":"\n\t\n\t\t\n\t\tLHM-Dienstleistungen-QA - german public domain question-answering dataset\n\t\n\nDatasets created based on data from Munich city administration.\nFormat inspired by GermanQuAD. \n\n\t\n\t\t\n\t\tAnnotated by:\n\t\n\n\n  Institute for Applied Artificial Intelligence: Leon Marius SchrÃ¶der \n\n\n  BettercallPaul GmbH: Clemens Gutknecht, Oubada Alkiddeh, Susanne WeiÃŸ \n\n\n  Stadt MÃ¼nchen: Leon Lukas\n\n\n\n\n\t\n\t\t\n\t\tData basis\n\t\n\nTexts taken from the â€œDienstleistungsfinderâ€œ of the city of Munich administration. \nThereâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/it-at-m/LHM-Dienstleistungen-QA.","url":"https://huggingface.co/datasets/it-at-m/LHM-Dienstleistungen-QA","creator_name":"it@M","creator_url":"https://huggingface.co/it-at-m","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["question-answering","German","mit","1K - 10K","parquet"],"keywords_longer_than_N":true},
	{"name":"gerlayqa-stgb-paraphrased","keyword":"german","description":"\n\t\n\t\t\n\t\tGerLayQA-StGB Paraphrased ðŸ‡©ðŸ‡ªâš–ï¸\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis is a paraphrased and restructured version of the GerLayQA StGB (Strafgesetzbuch / German Criminal Code) dataset, specifically prepared for fine-tuning large language models on German criminal law question-answering tasks.\n\n\t\n\t\t\n\t\tKey Features\n\t\n\n\n1,207 high-quality QA pairs about German Criminal Law (StGB)\nParaphrased questions to remove plagiarism while maintaining legal accuracy\nStructured 7-section answersâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/DomainLLM/gerlayqa-stgb-paraphrased.","url":"https://huggingface.co/datasets/DomainLLM/gerlayqa-stgb-paraphrased","creator_name":"DomainLLM","creator_url":"https://huggingface.co/DomainLLM","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["question-answering","text-generation","German","cc-by-4.0","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"MultiCoNER","keyword":"german","description":"We present MultiCoNER, a large multilingual dataset for Named Entity Recognition that covers 3 domains (Wiki sentences, questions, and search queries) across 11 languages, as well as multilingual and code-mixing subsets. This dataset is designed to represent contemporary challenges in NER, including low-context scenarios (short and uncased text), syntactically complex entities like movie titles, and long-tail entity distributions. The 26M token dataset is compiled from public resources using techniques such as heuristic-based sentence sampling, template extraction and slotting, and machine translation. We applied two NER models on our dataset: a baseline XLM-RoBERTa model, and a state-of-the-art GEMNET model that leverages gazetteers. The baseline achieves moderate performance (macro-F1=54%), highlighting the difficulty of our data. GEMNET, which uses gazetteers, improvement significantly (average improvement of macro-F1=+30%). MultiCoNER poses challenges even for large pre-trained language models, and we believe that it can help further research in building robust NER systems. MultiCoNER is publicly available at https://registry.opendata.aws/multiconer/ and we hope that this resource will help advance research in various aspects of NER.","url":"https://huggingface.co/datasets/tomaarsen/MultiCoNER","creator_name":"Tom Aarsen","creator_url":"https://huggingface.co/tomaarsen","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["token-classification","Bengali","German","English","Spanish"],"keywords_longer_than_N":true},
	{"name":"bnl_newspapers1841-1879","keyword":"german","description":"\n\t\n\t\t\n\t\tDataset Card for BnL Newspapers 1841-1881\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\n592.192 articles from historical newspapers (1841-1881) along with metadata and the full text.\n21 newspaper titles\n24.415 newspaper issues\n99.957 scanned pages\nTranscribed using a variety of OCR engines and corrected using https://github.com/natliblux/nautilusocr (95% threshold)\nPublic Domain, CC0 (See copyright notice)\nThe newspapers used are:\n\nDer Arbeiter (1878-1881)\nL'Arlequin (1848-1848)\nL'Avenir (1868-1871)â€¦ See the full description on the dataset page: https://huggingface.co/datasets/biglam/bnl_newspapers1841-1879.","url":"https://huggingface.co/datasets/biglam/bnl_newspapers1841-1879","creator_name":"BigLAM: BigScience Libraries, Archives and Museums","creator_url":"https://huggingface.co/biglam","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","fill-mask","language-modeling","masked-language-modeling","no-annotation"],"keywords_longer_than_N":true},
	{"name":"common_voice_17_0","keyword":"german","description":"\n\t\n\t\t\n\t\tDataset Card for Common Voice Corpus 17.0\n\t\n\n\n\nThis dataset is an unofficial version of the Mozilla Common Voice Corpus 17. It was downloaded and converted from the project's website https://commonvoice.mozilla.org/.\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nAbkhaz, Albanian, Amharic, Arabic, Armenian, Assamese, Asturian, Azerbaijani, Basaa, Bashkir, Basque, Belarusian, Bengali, Breton, Bulgarian, Cantonese, Catalan, Central Kurdish, Chinese (China), Chinese (Hong Kong), Chinese (Taiwan), Chuvash, Czechâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fsicoli/common_voice_17_0.","url":"https://huggingface.co/datasets/fsicoli/common_voice_17_0","creator_name":"Fabio Sicoli","creator_url":"https://huggingface.co/fsicoli","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":null,"first_N":5,"first_N_keywords":["automatic-speech-recognition","Abkhaz","Afrikaans","Amharic","Arabic"],"keywords_longer_than_N":true},
	{"name":"project_gutenberg","keyword":"german","description":"SinclairSchneider/project_gutenberg dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/SinclairSchneider/project_gutenberg","creator_name":"Sinclair Schneider","creator_url":"https://huggingface.co/SinclairSchneider","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-generation","German","English","Finnish","French"],"keywords_longer_than_N":true},
	{"name":"tulu-3-sft-olmo-2-mixture","keyword":"german","description":"Note that this collection is licensed under ODC-BY-1.0 license; different licenses apply to subsets of the data. Some portions of the dataset are non-commercial. We present the mixture as a research artifact.\nThe OLMo v2 SFT mixture was used to train the OLMo models.\nIt contains 939,344 samples from the following sets:\n\nCoCoNot (ODC-BY-1.0), 10,983 prompts (Brahman et al., 2024)\nFLAN v2 via ai2-adapt-dev/flan_v2_converted, 89,982 prompts (Longpre et al., 2023)\nNo Robots (CC-BY-NC-4.0), 9,500â€¦ See the full description on the dataset page: https://huggingface.co/datasets/allenai/tulu-3-sft-olmo-2-mixture.","url":"https://huggingface.co/datasets/allenai/tulu-3-sft-olmo-2-mixture","creator_name":"Ai2","creator_url":"https://huggingface.co/allenai","license_name":"Open Data Commons Attribution License v1.0","license_url":"https://scancode-licensedb.aboutcode.org/odc-by-1.0.html","language":"en","first_N":5,"first_N_keywords":["other","crowdsourced","expert-generated","machine-generated","multilingual"],"keywords_longer_than_N":true},
	{"name":"entity_cs","keyword":"german","description":"\n\t\n\t\t\n\t\tDataset Card for EntityCS\n\t\n\n\nRepository: https://github.com/huawei-noah/noah-research/tree/master/NLP/EntityCS  \nPaper: https://aclanthology.org/2022.findings-emnlp.499.pdf  \nPoint of Contact: Fenia Christopoulou, Chenxi Whitehouse\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Description\n\t\n\nWe use the English Wikipedia and leverage entity information from Wikidata to construct an entity-based Code Switching corpus. \nTo achieve this, we make use of wikilinks in Wikipedia, i.e. links from one page to another.â€¦ See the full description on the dataset page: https://huggingface.co/datasets/huawei-noah/entity_cs.","url":"https://huggingface.co/datasets/huawei-noah/entity_cs","creator_name":"HUAWEI Noah's Ark Lab","creator_url":"https://huggingface.co/huawei-noah","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["Afrikaans","Amharic","Arabic","Assamese","Azerbaijani"],"keywords_longer_than_N":true},
	{"name":"german_municipal_coat_of_arms","keyword":"german","description":"\n\t\n\t\t\n\t\tGerman Municipal Coat of Arms Dataset\n\t\n\nThis dataset contains 13104 samples for German municipal coat of arms.\nEach sample consists of the following features: 'img', 'acceptance', 'municipality', 'description', 'id', historicalJustification', 'municipalityName', 'uri', 'figure', 'cancellation', 'cancellationReason', 'author'\n","url":"https://huggingface.co/datasets/johko/german_municipal_coat_of_arms","creator_name":"Johannes Kolbe","creator_url":"https://huggingface.co/johko","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["German","cc-by-4.0","1K - 10K","json","Image"],"keywords_longer_than_N":true},
	{"name":"wiki_lingua","keyword":"german","description":"\n\t\n\t\t\n\t\tDataset Card for \"wiki_lingua\"\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nWe introduce WikiLingua, a large-scale, multilingual dataset for the evaluation of cross-lingual abstractive summarization systems. We extract article and summary pairs in 18 languages from WikiHow, a high quality, collaborative resource of how-to guides on a diverse set of topics written by human authors. We create gold-standard article-summary alignments across languages by aligning the images that are used to describe eachâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/esdurmus/wiki_lingua.","url":"https://huggingface.co/datasets/esdurmus/wiki_lingua","creator_name":"Esin Durmus","creator_url":"https://huggingface.co/esdurmus","license_name":"Creative Commons Attribution 3.0","license_url":"https://scancode-licensedb.aboutcode.org/cc-by-3.0.html","language":"en","first_N":5,"first_N_keywords":["summarization","crowdsourced","crowdsourced","multilingual","original"],"keywords_longer_than_N":true},
	{"name":"common_language","keyword":"german","description":"This dataset is composed of speech recordings from languages that were carefully selected from the CommonVoice database.\nThe total duration of audio recordings is 45.1 hours (i.e., 1 hour of material for each language).\nThe dataset has been extracted from CommonVoice to train language-id systems.","url":"https://huggingface.co/datasets/speechbrain/common_language","creator_name":"SpeechBrain","creator_url":"https://huggingface.co/speechbrain","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":null,"first_N":5,"first_N_keywords":["audio-classification","speaker-identification","crowdsourced","crowdsourced","multilingual"],"keywords_longer_than_N":true},
	{"name":"ahe-sft","keyword":"german","description":"NoahF7504/ahe-sft dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/NoahF7504/ahe-sft","creator_name":"Noah FlÃ¼chter","creator_url":"https://huggingface.co/NoahF7504","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-generation","German","mit","1K - 10K","json"],"keywords_longer_than_N":true},
	{"name":"rebel-dataset-de","keyword":"german","description":"\n\t\n\t\t\n\t\tDataset Card for German REBEL Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset is the German version of Babelscape/rebel-dataset. It has been generated using CROCODILE.\nThe Wikipedia Version is from November 2022. \n\n\t\n\t\t\n\t\tLanguages\n\t\n\n\nGerman\n\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n{\"docid\": \"9400003\",\n \"title\": \"Odin-Gletscher\",\n \"uri\": \"Q7077818\",\n \"text\": \"Der Odin-Gletscher ist ein kleiner Gletscher im ostantarktischen Viktorialand. Er flieÃŸt von den WesthÃ¤ngen des Mount Odin in derâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/mingaflo/rebel-dataset-de.","url":"https://huggingface.co/datasets/mingaflo/rebel-dataset-de","creator_name":"Florian","creator_url":"https://huggingface.co/mingaflo","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["summarization","German","mit","100K - 1M","json"],"keywords_longer_than_N":true},
	{"name":"minigpt4-13b-ggml","keyword":"german","description":"These are quantized ggml binary files for minigpt4 13B model.\nThese files can be used in conjunction with vicuna v0 ggml models to get minigpt4 working.\nNot all implementations were tested. If there are any issues, use f16.\n","url":"https://huggingface.co/datasets/maknee/minigpt4-13b-ggml","creator_name":"maknee","creator_url":"https://huggingface.co/maknee","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":null,"first_N":5,"first_N_keywords":["English","Bulgarian","Catalan","Czech","Danish"],"keywords_longer_than_N":true},
	{"name":"openassistant-falcon","keyword":"german","description":"\n\t\n\t\t\n\t\tChat Fine-tuning Dataset - OpenAssistant Falcon\n\t\n\nThis dataset allows for fine-tuning chat models using '\\Human:' AND '\\nAssistant:' to wrap user messages.\nIt still uses <|endoftext|> as EOS and BOS token, as per Falcon.\nSample \nPreparation:\n\nThe dataset is cloned from TimDettmers, which itself is a subset of the Open Assistant dataset, which you can find here. This subset of the data only contains the highest-rated paths in the conversation tree, with a total of 9,846 samples.\nTheâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Trelis/openassistant-falcon.","url":"https://huggingface.co/datasets/Trelis/openassistant-falcon","creator_name":"Trelis","creator_url":"https://huggingface.co/Trelis","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["English","Spanish","Russian","German","Polish"],"keywords_longer_than_N":true},
	{"name":"minds14-mirror","keyword":"german","description":"MINDS-14 is training and evaluation resource for intent\ndetection task with spoken data. It covers 14\nintents extracted from a commercial system\nin the e-banking domain, associated with spoken examples in 14 diverse language varieties.","url":"https://huggingface.co/datasets/a6kme/minds14-mirror","creator_name":"Abhishek Kumar","creator_url":"https://huggingface.co/a6kme","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":null,"first_N":5,"first_N_keywords":["automatic-speech-recognition","keyword-spotting","expert-generated","crowdsourced","machine-generated"],"keywords_longer_than_N":true},
	{"name":"germeval2018","keyword":"german","description":"# Task Description\n\nParticipants were allowed to participate in one or\nboth tasks and submit at most three runs per task.\n\n## Task 1: Coarse-grained Binary Classification\n\nTask 1 was to decide whether a tweet includes some\nform of offensive language or not. The tweets had\nto be classified into the two classes OFFENSE and\nOTHER. The OFFENSE category covered abusive\nlanguage, insults, as well as merely profane statements.\n\n## Task 2: Fine-grained 4-way Classification\n\nThe second task involved four categories, a nonoffensive OTHER class and three sub-categories of what is OFFENSE in \nTask 1. In the case of PROFANITY, profane words are used, however, the tweet does not want to insult anyone. This \ntypically concerns the usage of swearwords (ScheiÃŸe, Fuck etc.) and cursing (Zur Holle! Verdammt! etc.). This can be \noften found in youth language. Swearwords and cursing may, but need not, co-occur with insults or abusive speech. \nProfane language may in fact be used in tweets with positive sentiment to express emphasis. Whenever profane words are \nnot directed towards a specific person or group of persons and there are no separate cues of INSULT or ABUSE, then \ntweets are labeled as simple cases of PROFANITY.\n\nIn the case of INSULT, unlike PROFANITY, the tweet clearly wants to offend someone. INSULT is the ascription of \nnegatively evaluated qualities or deficiencies or the labeling of persons as unworthy (in some sense) or unvalued. \nInsults convey disrespect and contempt. Whether an utterance is an insult usually depends on the community in which it \nis made, on the social context (ongoing activity etc.) in which it is made, and on the linguistic means that are used \n(which have to be found to be conventional means whose assessment as insulting are intersubjectively reasonably \nstable).\n\nAnd finally, in the case of ABUSE, the tweet does not just insult a person but represents the stronger form of abusive \nlanguage. By abuse we define a special type of degradation. This type of degrading consists in ascribing a social \nidentity to a person that is judged negatively by a (perceived) majority of society. The identity in question is seen \nas a shameful, unworthy, morally objectionable or marginal identity. In contrast to insults, instances of abusive \nlanguage require that the target of judgment is seen as a representative of a group and it is ascribed negative \nqualities that are taken to be universal, omnipresent and unchangeable characteristics of the group. (This part of the \ndefinition largely co-incides with what is referred to as abusive speech in other research.) Aside from the cases where \npeople are degraded based on their membership in some group, we also classify it as abusive language when \ndehumanization is employed even just towards an individual (i.e. describing a person as scum or vermin etc.).","url":"https://huggingface.co/datasets/gwlms/germeval2018","creator_name":"German Wikipedia LMs","creator_url":"https://huggingface.co/gwlms","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":null,"first_N":5,"first_N_keywords":["text-classification","German","cc-by-4.0","ðŸ‡ºðŸ‡¸ Region: US"],"keywords_longer_than_N":false},
	{"name":"synthetic_pii_finance_multilingual","keyword":"german","description":"\n  \n  Image generated by DALL-E. See prompt for more details\n\n\n\n\t\n\t\t\n\t\tðŸ’¼ ðŸ“Š Synthetic Financial Domain Documents with PII Labels\n\t\n\ngretelai/synthetic_pii_finance_multilingual is a dataset of full length synthetic financial documents containing Personally Identifiable Information (PII), generated using Gretel Navigator and released under Apache 2.0.\nThis dataset is designed to assist with the following use cases:\n\nðŸ·ï¸ Training NER (Named Entity Recognition) models to detect and label PII inâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/gretelai/synthetic_pii_finance_multilingual.","url":"https://huggingface.co/datasets/gretelai/synthetic_pii_finance_multilingual","creator_name":"Gretel.ai","creator_url":"https://huggingface.co/gretelai","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","fill-mask","token-classification","English","French"],"keywords_longer_than_N":true},
	{"name":"oasst1","keyword":"german","description":"\n\t\n\t\t\n\t\tOpenAssistant Conversations Dataset (OASST1)\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nIn an effort to democratize research on large-scale alignment, we release OpenAssistant \nConversations (OASST1), a human-generated, human-annotated assistant-style conversation \ncorpus consisting of 161,443 messages in 35 different languages, annotated with 461,292 \nquality ratings, resulting in over 10,000 fully annotated conversation trees. The corpus \nis a product of a worldwide crowd-sourcing effortâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/OpenAssistant/oasst1.","url":"https://huggingface.co/datasets/OpenAssistant/oasst1","creator_name":"OpenAssistant","creator_url":"https://huggingface.co/OpenAssistant","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["English","Spanish","Russian","German","Polish"],"keywords_longer_than_N":true},
	{"name":"ACAData","keyword":"german","description":"\n\t\n\t\t\n\t\tDataset Card for ACAData\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nACAData is a multilingual instruction tuning dataset containing parallel text paragraphs from the academic domain.\n\n\t\n\t\t\n\t\tSupported Tasks and Leaderboards\n\t\n\nThe dataset is meant to be used for fine-tuning and benchmarking general purpose LLM's on Machine Translation tasks.\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nThe dataset contains (mainly long) paragraph of scientific texts from the academic domain in many European language pairs.\nThe languageâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/BSC-LT/ACAData.","url":"https://huggingface.co/datasets/BSC-LT/ACAData","creator_name":"Language Technologies Laboratory @ Barcelona Supercomputing Center","creator_url":"https://huggingface.co/BSC-LT","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["translation","Spanish","English","Catalan","Portuguese"],"keywords_longer_than_N":true},
	{"name":"swiss-code-of-obligations","keyword":"german","description":"\n\t\n\t\t\n\t\tSwiss Code of Obligations (OR) and Swiss Civil Code\n\t\n\n\n\t\n\t\t\n\t\t(Part Five: The Code of Obligations) of 30 March 1911 (Status as of 1 September 2023)\n\t\n\nFiles generated from the Swiss publication platform for federal law\nSwiss Code of Obligations\n\n\t\n\t\t\n\t\tFormat\n\t\n\nEach article has the following type definition:\n\n\t\n\t\t\n\t\tWith vector embeddings by Xenova/paraphrase-multilingual-mpnet-base-v2\n\t\n\n\nswiss-civil-code-de-paraphrase-multilingual-mpnet-base-v2.jsonlâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/brunnolou/swiss-code-of-obligations.","url":"https://huggingface.co/datasets/brunnolou/swiss-code-of-obligations","creator_name":"Bruno","creator_url":"https://huggingface.co/brunnolou","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["question-answering","English","German","apache-2.0","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"FineWeb2-HQ","keyword":"german","description":"\n\t\n\t\t\n\t\tFineWeb2-HQ\n\t\n\n\n\t\n\t\t\n\t\tDataset summary\n\t\n\nFineWeb2-HQ is a high-quality, model-filtered pretraining dataset derived as a subset of FineWeb2, spanning 20 languages. It enables around 6x faster pretraining compared to the base dataset. FineWeb2-HQ was created by selecting the top 10% quality documents of FineWeb2 in each language, based on scores assigned by a deep learning classifier trained to identify structured and knowledge-rich samples using XLM-RoBERTa embeddings.\n\n  \n\n\nValidationâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/epfml/FineWeb2-HQ.","url":"https://huggingface.co/datasets/epfml/FineWeb2-HQ","creator_name":"EPFL Machine Learning and Optimization Laboratory","creator_url":"https://huggingface.co/epfml","license_name":"Open Data Commons Attribution License v1.0","license_url":"https://scancode-licensedb.aboutcode.org/odc-by-1.0.html","language":"en","first_N":5,"first_N_keywords":["text-generation","Russian","Chinese","German","Japanese"],"keywords_longer_than_N":true},
	{"name":"BenchMAX_Science","keyword":"german","description":"\n\t\n\t\t\n\t\tDataset Sources\n\t\n\n\nPaper: BenchMAX: A Comprehensive Multilingual Evaluation Suite for Large Language Models\nLink: https://huggingface.co/papers/2502.07346\nRepository: https://github.com/CONE-MT/BenchMAX\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nBenchMAX_Science is a dataset of BenchMAX, sourcing from GPQA, which evaluates the natural science reasoning capability in multilingual scenarios.\nWe extend the original English dataset to 16 non-English languages.\nThe data is first translated by Googleâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/LLaMAX/BenchMAX_Science.","url":"https://huggingface.co/datasets/LLaMAX/BenchMAX_Science","creator_name":"LLaMAX","creator_url":"https://huggingface.co/LLaMAX","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["question-answering","multilingual","English","Chinese","Spanish"],"keywords_longer_than_N":true},
	{"name":"FineWeb2-embedded","keyword":"german","description":"\n\t\n\t\t\n\t\tFineWeb2-embedded\n\t\n\n\n\t\n\t\t\n\t\tDataset summary\n\t\n\nFineWeb2-embedded is an extension of the FineWeb2 dataset, annotated with document-level XLM-RoBERTa embeddings for 20 languages, making the dataset useful for a variety of tasks, including document clustering, filtering, and other multilingual research.\nSince XLM-RoBERTa has a sequence length limit of 512 tokens, each document's embeddings are obtained by mean-pooling 512 token chunks of the XLM-RoBERTa output. Therefore, longer textsâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/epfml/FineWeb2-embedded.","url":"https://huggingface.co/datasets/epfml/FineWeb2-embedded","creator_name":"EPFL Machine Learning and Optimization Laboratory","creator_url":"https://huggingface.co/epfml","license_name":"Open Data Commons Attribution License v1.0","license_url":"https://scancode-licensedb.aboutcode.org/odc-by-1.0.html","language":"en","first_N":5,"first_N_keywords":["text-generation","Russian","Chinese","German","Japanese"],"keywords_longer_than_N":true},
	{"name":"semeval-2025-task11-track-c","keyword":"german","description":"\n\t\n\t\t\n\t\tSemEval 2025 Task 11 - Track C Dataset\n\t\n\nThis dataset contains the data for SemEval 2025 Task 11: Bridging the Gap in Text-Based Emotion Detection - Track C, organized as language-specific configurations.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset is a multi-language, multi-label emotion classification dataset with separate configurations for each language.\n\nTotal languages: 30 standard ISO codes\nTotal examples: 57254\nSplits: dev, test (Track C has no train split)\n\n\n\t\n\t\t\n\t\tTrackâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/vgaraujov/semeval-2025-task11-track-c.","url":"https://huggingface.co/datasets/vgaraujov/semeval-2025-task11-track-c","creator_name":"Vladimir Araujo","creator_url":"https://huggingface.co/vgaraujov","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["Afrikaans","Amharic","Arabic","German","English"],"keywords_longer_than_N":true},
	{"name":"HPLT2.0_cleaned","keyword":"german","description":"This is a large-scale collection of web-crawled documents in 191 world languages, produced by the HPLT project. \nThe source of the data is mostly Internet Archive with some additions from Common Crawl.\nFor a detailed description of the dataset, please refer to our website and our pre-print.\n\n\t\n\t\t\n\t\n\t\n\t\tThe Cleaned variant of HPLT Datasets v2.0\n\t\n\nThis is the cleaned variant of the HPLT Datasets v2.0 converted to the Parquet format semi-automatically when being uploaded here. \nThe originalâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/HPLT/HPLT2.0_cleaned.","url":"https://huggingface.co/datasets/HPLT/HPLT2.0_cleaned","creator_name":"HPLT","creator_url":"https://huggingface.co/HPLT","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["fill-mask","text-generation","language-modeling","multilingual","Achinese"],"keywords_longer_than_N":true},
	{"name":"DATA-AI_Chat","keyword":"german","description":"\n\t\n\t\t\n\t\tDATA-AI: Il Modello di IA di M.INC.\n\t\n\n\n\t\n\t\t\n\t\tðŸ“Œ Introduzione\n\t\n\nDATA-AI Ã¨ un avanzato modello di intelligenza artificiale sviluppato da *M.INC., un'azienda italiana fondata da *Mattimax (M. Marzorati).Questo modello Ã¨ basato sull'architettura ELNS (Elaborazione del Linguaggio Naturale Semplice), un sistema innovativo progettato per rendere l'IA accessibile su quasi qualsiasi dispositivo, garantendo prestazioni ottimali anche su hardware limitato.  \nDATA-AI Ã¨ stato addestrato su unâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Mattimax/DATA-AI_Chat.","url":"https://huggingface.co/datasets/Mattimax/DATA-AI_Chat","creator_name":"M.INC.","creator_url":"https://huggingface.co/Mattimax","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["Italian","English","Spanish","Russian","German"],"keywords_longer_than_N":true},
	{"name":"laions_got_talent_with_voice_emotion_speed_tags_for_orpheus_tuning","keyword":"german","description":"LAION's Got Talent: Generated Voice Acting Dataset\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\n\"LAION's Got Talent\" is a synthetic voice acting dataset designed to offer a broad range of emotional expressions, vocal bursts, and multi-language utterances. This dataset is a component of the BUD-E project, led by LAION with support from Intel, and aims to drive forward research in context-aware and empathetic AI voice assistants.\n\n\n\t\n\t\t\n\t\tUpdated Composition\n\t\n\n\nVoices and Languages  \n\nEnglish: 11 OpenAI voices, eachâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/laion/laions_got_talent_with_voice_emotion_speed_tags_for_orpheus_tuning.","url":"https://huggingface.co/datasets/laion/laions_got_talent_with_voice_emotion_speed_tags_for_orpheus_tuning","creator_name":"LAION eV","creator_url":"https://huggingface.co/laion","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["English","French","German","Spanish","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"EmoTalk-7","keyword":"german","description":"\n\t\n\t\t\n\t\tEmoTalk-7\n\t\n\nEmoTalk-7 is a large-scale, multilingual, synthetic multimodal emotion recognition dataset generated using the Mistral API. It covers 7 major European languages and contains realistic social media scenarios with comprehensive emotion analysis, visual descriptions, and cultural context annotations.\n\n\t\n\t\t\n\t\tðŸ“ Dataset Summary\n\t\n\nEmoTalk-7 contains 1400+ multimodal emotion records with high-quality annotations. It is designed to simulate authentic social media content acrossâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/NoeFlandre/EmoTalk-7.","url":"https://huggingface.co/datasets/NoeFlandre/EmoTalk-7","creator_name":"NoÃ© Flandre","creator_url":"https://huggingface.co/NoeFlandre","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","English","French","Spanish","German"],"keywords_longer_than_N":true},
	{"name":"medical-translation-test-set","keyword":"german","description":"ai-amplified/medical-translation-test-set dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/ai-amplified/medical-translation-test-set","creator_name":"admin","creator_url":"https://huggingface.co/ai-amplified","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["English","French","Portuguese","Romanian","German"],"keywords_longer_than_N":true},
	{"name":"MultiLingualSentiment","keyword":"german","description":"\n\t\n\t\t\n\t\tOverview\n\t\n\nMultilingualSentiment is a sentiment classification dataset that encompasses three sentiment labels: Positive, Neutral, Negative\nThe dataset spans multiple languages and covers a wide range of domains, making it ideal for multilingual sentiment analysis tasks.\n\n\t\n\t\t\n\t\tDataset Information\n\t\n\nThe dataset was meticulously collected and aggregated from various sources, including Hugging Face and Kaggle. These sources provide diverse languages and domains to ensure aâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/clapAI/MultiLingualSentiment.","url":"https://huggingface.co/datasets/clapAI/MultiLingualSentiment","creator_name":"clapAI","creator_url":"https://huggingface.co/clapAI","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","Arabic","German","English","Spanish"],"keywords_longer_than_N":true},
	{"name":"MintakaRetrieval","keyword":"german","description":"\n  MintakaRetrieval\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nWe introduce Mintaka, a complex, natural, and multilingual dataset designed for experimenting with end-to-end question-answering models. Mintaka is composed of 20,000 question-answer pairs collected in English, annotated with Wikidata entities, and translated into Arabic, French, German, Hindi, Italian, Japanese, Portuguese, and Spanish for a total of 180,000 samples. Mintaka includes 8 types of complex questionsâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/MintakaRetrieval.","url":"https://huggingface.co/datasets/mteb/MintakaRetrieval","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","multiple-choice-qa","derived","translated","jinaai/mintakaqa"],"keywords_longer_than_N":true},
	{"name":"WildChat-curated","keyword":"german","description":"As part of the lock-in hypothesis research project (Qiu et al., 2025), this dataset is transformed from raw WildChat-1M dataset (Zhao et al., 2024) into a structured analysis-ready format through:\n\nData cleaning by deduplicating users based on IP address co-occurrence and removing templated prompts (i.e. people using the WildChat platform as a free API to do repetitive tasks).\nExtracting key concepts from each dialogue using a large language model (Llama-3.1-8B-Instruct), which are thenâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/TianyiQ/WildChat-curated.","url":"https://huggingface.co/datasets/TianyiQ/WildChat-curated","creator_name":"Tianyi Qiu","creator_url":"https://huggingface.co/TianyiQ","license_name":"Open Data Commons Attribution License v1.0","license_url":"https://scancode-licensedb.aboutcode.org/odc-by-1.0.html","language":"en","first_N":5,"first_N_keywords":["text-generation","allenai/WildChat","English","Chinese","Russian"],"keywords_longer_than_N":true},
	{"name":"messio","keyword":"german","description":"noahgeiger2000/messio dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/noahgeiger2000/messio","creator_name":"Noah Geiger","creator_url":"https://huggingface.co/noahgeiger2000","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["German","apache-2.0","< 1K","json","Text"],"keywords_longer_than_N":true},
	{"name":"reranker_continuous_filt_max7_train","keyword":"german","description":"\n\t\n\t\t\n\t\tReranker training data\n\t\n\nThis data was generated using 4 steps:\n\nWe gathered queries and corresponding text data from 35 high quality datasets covering more than 95 languages.\nFor datasets which did not already have negative texts for queries, we mined hard negatives using the BAAI/bge-m3 embedding model.\nFor each query, we selected one positive and one negative text and used Qwen/Qwen2.5-32B-Instruct-GPTQ-Int4 to rate the relatedness of each query-text pair using a token \"1\", \"2\"â€¦ See the full description on the dataset page: https://huggingface.co/datasets/lightblue/reranker_continuous_filt_max7_train.","url":"https://huggingface.co/datasets/lightblue/reranker_continuous_filt_max7_train","creator_name":"Lightblue KK.","creator_url":"https://huggingface.co/lightblue","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["English","Chinese","Spanish","German","Arabic"],"keywords_longer_than_N":true},
	{"name":"Multilingual-Alpaca-Speech","keyword":"german","description":"\n\t\n\t\t\n\t\tMultilingual Alpaca Speech Dataset\n\t\n\nMultilingual Alpaca Speech is a high-quality speech instruction-following dataset supporting Japanese (ja), German (de), and French (fr) . It is generated via a pipeline: filtering Alpaca text data, translating to target languages, converting to speech with fish-speech v1.5.\nThe dataset includes .tar.gz files with speech-text data and .list files with metadata for each language, plus a test set (test.tar.gz) . It helps enhance non-core languageâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/ASLP-lab/Multilingual-Alpaca-Speech.","url":"https://huggingface.co/datasets/ASLP-lab/Multilingual-Alpaca-Speech","creator_name":"ASLP-lab","creator_url":"https://huggingface.co/ASLP-lab","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["German","Japanese","French","apache-2.0","10K<n<100K"],"keywords_longer_than_N":true},
	{"name":"qonto-open-qa","keyword":"german","description":"ThomasCdnns/qonto-open-qa dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/ThomasCdnns/qonto-open-qa","creator_name":"Thomas Chardonnens","creator_url":"https://huggingface.co/ThomasCdnns","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["question-answering","English","French","Spanish","Italian"],"keywords_longer_than_N":true},
	{"name":"sun_facts","keyword":"german","description":"\n\t\n\t\t\n\t\tðŸŒž Solar Facts Dataset\n\t\n\nA collection of interesting facts about the Sun in 6 different languages: Indonesian, English, Mandarin (Chinese), Japanese, Spanish, and German.\n\n\t\n\t\t\n\t\tðŸ“Š Dataset Statistics\n\t\n\n\nTotal Dataset: 600 conversation/fact rows\nAvailable Languages: 6 languages\nFile Formats: CSV, JSON, Parquet\nDataset Size: ~50 KB\n\n\n\t\n\t\t\n\t\tðŸŒ Available Languages\n\t\n\n\n\t\n\t\t\nLanguage\nCode\nUnique Facts Count\n\n\n\t\t\nIndonesian\nIndonesia\n20 facts\n\n\nEnglish\nEnglish\n20 facts\n\n\nChinese\nChineseâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/erisdataworks/sun_facts.","url":"https://huggingface.co/datasets/erisdataworks/sun_facts","creator_name":"Eris Dataworks","creator_url":"https://huggingface.co/erisdataworks","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["Indonesian","English","Chinese","Japanese","Spanish"],"keywords_longer_than_N":true},
	{"name":"ronaldo","keyword":"german","description":"noahgeiger2000/ronaldo dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/noahgeiger2000/ronaldo","creator_name":"Noah Geiger","creator_url":"https://huggingface.co/noahgeiger2000","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["German","apache-2.0","< 1K","json","Text"],"keywords_longer_than_N":true},
	{"name":"MAGBIG","keyword":"german","description":"\n\t\n\t\t\n\t\tMAGBIG benchmark\n\t\n\nThis is the MAGBIG benchmark proposed in https://arxiv.org/abs/2401.16092\nThis benchmark is intended for multilingual text-to-image models. With MAGBIG, you can generate images for a diverse set of prompts across ten different languages. These images can be evaluated for differences across languages. MAGBIG is designed to uncover and assess biases across languages such as gender, race, age, etc. This way, we can measure whether bias exists in a language, but alsoâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/felfri/MAGBIG.","url":"https://huggingface.co/datasets/felfri/MAGBIG","creator_name":"Felix Friedrich","creator_url":"https://huggingface.co/felfri","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-to-image","English","German","Italian","French"],"keywords_longer_than_N":true},
	{"name":"eng_montok","keyword":"german","description":"\n\t\n\t\t\n\t\tMonTok: A Suite of Monolingual Tokenizers\n\t\n\nThis is a set of monolingual tokenizers for 98 languages. For each language, there are Unigram, BPE, and SuperBPE tokenizers, ranging in vocabulary size from around 6k to over 200k.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\n","url":"https://huggingface.co/datasets/catherinearnett/eng_montok","creator_name":"Catherine Arnett","creator_url":"https://huggingface.co/catherinearnett","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["Afrikaans","Tosk Albanian","Amharic","Standard Arabic","Assamese"],"keywords_longer_than_N":true},
	{"name":"SOC-2508-MULTI","keyword":"german","description":"\n\t\n\t\t\n\t\tDataset Card for Multilingual Synthetic Online Conversations\n\t\n\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset contains multilingual translations of the Synthetic Online Conversations (SOC-2508) dataset. Each conversation from the original dataset has been translated into French, Italian, German, Spanish, providing over 1,180 synthetically generated, multi-turn online conversations in multiple languages.\nThe translations were generated using google/gemma-3n-E4B-it with vLLM as the inferenceâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/marcodsn/SOC-2508-MULTI.","url":"https://huggingface.co/datasets/marcodsn/SOC-2508-MULTI","creator_name":"Marco De Santis","creator_url":"https://huggingface.co/marcodsn","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["English","French","Italian","German","Spanish"],"keywords_longer_than_N":true},
	{"name":"FL_History_GER","keyword":"german","description":"All of the articles of the Liechtenstein historical encyclopaedia are contained in this dataset in textual form. Additionally, the historical and cultural publications and books gathered from eliechtensteinen-sia.li are also included. Only one column called â€œtextâ€ is contained in the dataset. The dataset is published exclusively in German language and around 17â€™000 rows are included in the dataset.\nThe dataset is intended as is to be used for pretraining. However, further data cleaning isâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/JoeUnili/FL_History_GER.","url":"https://huggingface.co/datasets/JoeUnili/FL_History_GER","creator_name":"Joel","creator_url":"https://huggingface.co/JoeUnili","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","German","apache-2.0","10K - 100K","text"],"keywords_longer_than_N":true},
	{"name":"ipa-childes-split","keyword":"german","description":"\n\t\n\t\t\n\t\tIPA-CHILDES split\n\t\n\nThis dataset is a postprocessed version of the IPA-CHILDES dataset. In particular,\nthe following changes have been implemented:\n\ncolumn processed_gloss dropped as it duplicates information of gloss up to punctuation\ncolumn gloss renamed as sentence, and column ipa_transcription renamed as ipa_g2p_plus (cf. G2P+)\ncolumn lang added to make IETF language tags accessible for training and inference; language tags normalized by the langcodes package\ncolumns ipa_espeakâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fdemelo/ipa-childes-split.","url":"https://huggingface.co/datasets/fdemelo/ipa-childes-split","creator_name":"FlÃ¡vio Eler De Melo","creator_url":"https://huggingface.co/fdemelo","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["Catalan","Welsh","Danish","German","English"],"keywords_longer_than_N":true},
	{"name":"Reddit-MultiGEC","keyword":"german","description":"\n\t\n\t\t\n\t\tReddit-MultiGEC Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nReddit-MultiGEC is a large multilingual corpus of posts scraped from Reddit, automatically corrected using the approach (TBU).\n\n\t\n\t\t\n\t\tStructure\n\t\n\n\nreddit_multi_gec.csv - main data.\nlanguage - language of text; \ntext - original text; \ncorrection - corrected text;\n\n\nreddit_uk_annotations.csv - contains human annotations for 1500 samples for the Ukrainian language.\ntext - original text; \ncorrection - corrected text;\nscore - annotator score;â€¦ See the full description on the dataset page: https://huggingface.co/datasets/lang-uk/Reddit-MultiGEC.","url":"https://huggingface.co/datasets/lang-uk/Reddit-MultiGEC","creator_name":"Lang UK","creator_url":"https://huggingface.co/lang-uk","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-generation","Ukrainian","English","German","Czech"],"keywords_longer_than_N":true},
	{"name":"deep-argmap-conversations","keyword":"german","description":"\n\t\n\t\t\n\t\tSummary\n\t\n\nThis converstional dataset contains examples for how to create and work with Argdown argument maps.\nThe following tasks are covered:\n\nCreate an argument map from a list of statements\nCreate an argument map from a pros and cons list\nAdd claims / arguments to an existing argument map\nCorrect and revise a broken argument map\nMerge several argument maps into a single comprehensive one\nIdentify and add premises / conclusions to an argument map\nReconstruct an argument from a mapâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/DebateLabKIT/deep-argmap-conversations.","url":"https://huggingface.co/datasets/DebateLabKIT/deep-argmap-conversations","creator_name":"DebateLab at KIT","creator_url":"https://huggingface.co/DebateLabKIT","license_name":"Open Data Commons Attribution License v1.0","license_url":"https://scancode-licensedb.aboutcode.org/odc-by-1.0.html","language":"en","first_N":5,"first_N_keywords":["text-generation","English","German","odc-by","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"multilingual-speech-commands-15lang-zip","keyword":"german","description":"\n\t\n\t\t\n\t\tMultilingual Speech Commands Dataset (15 Languages, Augmented)\n\t\n\nThis dataset contains augmented speech command samples in 15 languages, derived from multiple public datasets. Only commands that overlap with the Google Speech Commands (GSC) vocabulary are included, making the dataset suitable for multilingual keyword spotting tasks aligned with GSC-style classification.\nAudio samples have been augmented using standard audio techniques to improve model robustness (e.g., time-shiftingâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/artur-muratov/multilingual-speech-commands-15lang-zip.","url":"https://huggingface.co/datasets/artur-muratov/multilingual-speech-commands-15lang-zip","creator_name":"Artur Muratov","creator_url":"https://huggingface.co/artur-muratov","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["English","Russian","Kazakh","Tatar","Arabic"],"keywords_longer_than_N":true},
	{"name":"WikiEdits-MultiGEC","keyword":"german","description":"\n\t\n\t\t\n\t\tWikiEdits-MultiGEC Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nWikiEdits-MultiGEC is a small dataset of human error corrections made by Wikipedia contributors for eleven languages.\nThese revisions were obtained using the official Wikipedia API, covering the six months from September 28, 2024, to May 15, 2025.\n\n\t\n\t\t\n\t\tStructure\n\t\n\n\nwikiedits_multi_gec.csv - main data.\nindex - index;\nlanguage - language of text; \ntext - original text; \ncorrection - corrected text;\n\n\nwikiedits_multi_gec_metadata.csv -â€¦ See the full description on the dataset page: https://huggingface.co/datasets/lang-uk/WikiEdits-MultiGEC.","url":"https://huggingface.co/datasets/lang-uk/WikiEdits-MultiGEC","creator_name":"Lang UK","creator_url":"https://huggingface.co/lang-uk","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-generation","Ukrainian","English","German","cz"],"keywords_longer_than_N":true},
	{"name":"filtered_convos_research_llm_summaries_cleaned","keyword":"german","description":"\n\t\n\t\t\n\t\tSynthetic Call Center Summaries Dataset Cleaned\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset contains synthetic summaries of call center conversations generated by different prompt configurations.\nEach record (in JSON Lines format) includes:\n\nThe original dialogue metadata.\nA generated summary tailored to provide quick insights for call center service agents.\nEvaluation metrics\n\n\n\t\n\t\t\n\t\tPrompts for summarization\n\t\n\n\nNarrative: A narrative summary of the conversation.\nBullet Points: A summary ofâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/marccgrau/filtered_convos_research_llm_summaries_cleaned.","url":"https://huggingface.co/datasets/marccgrau/filtered_convos_research_llm_summaries_cleaned","creator_name":"Marc Christopher Grau","creator_url":"https://huggingface.co/marccgrau","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["summarization","text-generation","synthetic","monolingual","German"],"keywords_longer_than_N":true},
	{"name":"Everything_Instruct_Multilingual","keyword":"german","description":"\n\t\n\t\t\n\t\tEverything Instruct (Multilingual Edition)\n\t\n\nEverything you need... all in one place ðŸ’˜\n\nEverything instruct (Multilingual Edition) is a massive alpaca instruct formatted dataset consisting of a wide variety of topics meant to bring LLM's to the next level in open source AI.\nNote: This dataset is fully uncensored (No model will refuse any request trained on this dataset unless otherwise aligned)\nNote2: This version of the dataset supports the following languages:\n\nEnglish\nRussianâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/rombodawg/Everything_Instruct_Multilingual.","url":"https://huggingface.co/datasets/rombodawg/Everything_Instruct_Multilingual","creator_name":"rombo dawg","creator_url":"https://huggingface.co/rombodawg","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["English","Russian","Chinese","Korean","Urdu"],"keywords_longer_than_N":true},
	{"name":"mm","keyword":"german","description":"MARKETMECHANIK/mm dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/MARKETMECHANIK/mm","creator_name":"AMIR","creator_url":"https://huggingface.co/MARKETMECHANIK","license_name":"Academic Free License v3.0","license_url":"https://choosealicense.com/licenses/afl-3.0/","language":null,"first_N":5,"first_N_keywords":["text-classification","table-question-answering","translation","fill-mask","text-to-speech"],"keywords_longer_than_N":true},
	{"name":"GermanPhoneConversation","keyword":"german","description":"masterchatbot/GermanPhoneConversation dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/masterchatbot/GermanPhoneConversation","creator_name":"Eugen Graf","creator_url":"https://huggingface.co/masterchatbot","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["German","apache-2.0","< 1K","text","Text"],"keywords_longer_than_N":true},
	{"name":"course_competency_alignment_de","keyword":"german","description":"\n\t\n\t\t\n\t\t!This is a draft!\n\t\n\n\n\t\n\t\t\n\t\tGerman Course Competency Alignment\n\t\n\n\n\t\n\t\t\n\t\tDescription\n\t\n\nThe \"German Course Competency Alignment\" dataset consists of triplets incorporating German course descriptions, positive competency labels, and negative competency labels. Its primary purpose is to train language models for information retrieval tasks, specifically to annotate courses with standardized competencies based on learning outcomes. This dataset leverages various competency frameworksâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/isy-thl/course_competency_alignment_de.","url":"https://huggingface.co/datasets/isy-thl/course_competency_alignment_de","creator_name":"Institut fÃ¼r Interaktive Systeme der Technischen Hochschule LÃ¼beck","creator_url":"https://huggingface.co/isy-thl","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["sentence-similarity","German","mit","1K<n<10K","ðŸ‡ºðŸ‡¸ Region: US"],"keywords_longer_than_N":true},
	{"name":"dtaec-lexicon","keyword":"german","description":"\n\t\n\t\t\n\t\tDTA EvalCorpus Lexicon\n\t\n\nThis dataset is a derivative of the DTA EvalCorpus which is a parallel corpus by the Deutsche Textarchiv (DTA), of the Deutsche Textarchiv (German Text Archive), who aligned historic prints of documents with their respective modern editions normalized contemporary orthography.\nIn particular, this dataset is constructed from a subset of 85 literary documents of the DTA EvalCorpus, and then counting the normalization pairs. The dataset can be replicated from theâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/aehrm/dtaec-lexicon.","url":"https://huggingface.co/datasets/aehrm/dtaec-lexicon","creator_name":"Anton Ehrmanntraut","creator_url":"https://huggingface.co/aehrm","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["translation","German","cc0-1.0","100K - 1M","parquet"],"keywords_longer_than_N":true},
	{"name":"amazon-review-authorship-verification","keyword":"german","description":"Usage\nfrom datasets import load_dataset\n\n# Load German part of the dataset\ndataset = load_dataset(\"sobamchan/amazon-review-authorship-verification\", \"de\")\n\nprint(dataset[\"train\"][0])\n# {'review_1': {'language': 'de',\n#   'product_category': 'home_improvement',\n#   'product_id': 'product_de_0996190',\n#   'review_body': 'Trotz diesem Fliegengitter haben ungebetene GÃ¤ste MÃ¶glicheiten zum Zutritt. Einfach nur schlecht verarbeitet.Kleine LÃ¶cher schon enstanden im Fliegengitter und das kleben warâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/sobamchan/amazon-review-authorship-verification.","url":"https://huggingface.co/datasets/sobamchan/amazon-review-authorship-verification","creator_name":"sotaro takeshita","creator_url":"https://huggingface.co/sobamchan","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","English","German","mit","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"multivsr","keyword":"german","description":"\n\t\n\t\t\n\t\tDataset: MultiVSR\n\t\n\nWe introduce a large-scale multilingual lip-reading dataset: MultiVSR. The dataset comprises a total of 12,000 hours of video footage, covering English + 12 non-English languages. MultiVSR is a massive dataset with a huge diversity in terms of the speakers as well as languages, with approximately 1.6M video clips across 123K YouTube videos. Please check the website for samples.\n\n  \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDownload instructions\n\t\n\nPlease check the GitHub repo to downloadâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/sindhuhegde/multivsr.","url":"https://huggingface.co/datasets/sindhuhegde/multivsr","creator_name":"Sindhu Hegde","creator_url":"https://huggingface.co/sindhuhegde","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["English","French","German","Spanish","Italian"],"keywords_longer_than_N":true},
	{"name":"10kgnad","keyword":"german","description":"\n\t\n\t\t\n\t\t10kGNAD - Ten Thousand German News Articles Dataset\n\t\n\nGerman news articels, categorized. Category is the actual category name, one of: 'Etat', 'Inland', 'International', 'Kultur', 'Panorama', 'Sport', 'Web', 'Wirtschaft', 'Wissenschaft'. The label is the index as an integer.\nDatasetDict({\n    train: Dataset({\n        features: ['category', 'text', 'label'],\n        num_rows: 9245\n    })\n    test: Dataset({\n        features: ['category', 'text', 'label'],\n        num_rows: 1028\n    })â€¦ See the full description on the dataset page: https://huggingface.co/datasets/lschoen/10kgnad.","url":"https://huggingface.co/datasets/lschoen/10kgnad","creator_name":"Levente Schoenherr","creator_url":"https://huggingface.co/lschoen","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","German","mit","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"Colibri","keyword":"german","description":"\n\t\n\t\t\n\t\tTitle\n\t\n\nColibri: Illustrations in 19th Century Children's and Youth Books\n\n\t\n\t\t\n\t\tDescription\n\t\n\nThis data publication was created with the intent to provide a single annotated computer vision dataset for research purposes and the development of AI applications. This data publication comprises 53,533 illustrations extracted from 3,412 children's and youth books published between 1800 and 1925, accompanied by metadata and annotations and example images for each annotated class.\nTheâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/SBB/Colibri.","url":"https://huggingface.co/datasets/SBB/Colibri","creator_name":"Staatsbibliothek zu Berlin - PreuÃŸischer Kulturbesitz","creator_url":"https://huggingface.co/SBB","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["image-feature-extraction","German","English","cc-by-4.0","10K<n<100K"],"keywords_longer_than_N":true},
	{"name":"finepdfs-summaries","keyword":"german","description":"\n\t\n\t\t\n\t\tfinepdfs-summaries\n\t\n\nSummaries generated with Qwen3-Next-80B-A3B-Instruct for documents from finepdfs.\nWork in progress, still generating more data.\nThe following table shows the data available for each language:\n\n\t\n\t\t\nLanguage\nSummaries\nTokens\nDisk size\n\n\n\t\t\nAll\n838,268,819\n247 B\n366 GB\n\n\ndeu_Latn\n363,671,069\n113 B\n149 GB\n\n\neng_Latn\n353,969,370\n89 B\n162 GB\nfra_Latn\n27,308,302\n10 B\n14 GB\n\n\nspa_Latn\n25,624,727\n9 B\n12 GB\n\n\nita_Latn\n17,587,618\n6 B\n8 GB\n\n\npor_Latn\n12,043,607\n4 B\n5 GBâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/MultiSynt/finepdfs-summaries.","url":"https://huggingface.co/datasets/MultiSynt/finepdfs-summaries","creator_name":"MultiSynt","creator_url":"https://huggingface.co/MultiSynt","license_name":"Open Data Commons Attribution License v1.0","license_url":"https://scancode-licensedb.aboutcode.org/odc-by-1.0.html","language":"en","first_N":5,"first_N_keywords":["text-generation","summarization","English","German","French"],"keywords_longer_than_N":true},
	{"name":"PleIAs-ToxicCommons","keyword":"german","description":"\n\t\n\t\t\n\t\tPleIAs/ToxicCommons\n\t\n\nThis dataset is a refined version of the PleIAs/ToxicCommons collection, focusing on historical texts labeled for content that may be considered objectionable by modern standards (what the authors of the dataset deem \"toxic\"). \nThe cleaned dataset contains 1â€‰051â€‰027 rows, each representing a text sample with associated toxicity scores across five dimensions:\n\nRace and origin-based bias\nGender and sexuality-based bias\nReligious bias\nAbility bias\nViolence and abuseâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/agentlans/PleIAs-ToxicCommons.","url":"https://huggingface.co/datasets/agentlans/PleIAs-ToxicCommons","creator_name":"Alan Tseng","creator_url":"https://huggingface.co/agentlans","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","English","French","Spanish","German"],"keywords_longer_than_N":true},
	{"name":"synthetic_multilingual_llm_prompts","keyword":"german","description":"\n  \n  Image generated by DALL-E. See prompt for more details\n\n\n\n\t\n\t\t\n\t\tðŸ“ðŸŒ Synthetic Multilingual LLM Prompts\n\t\n\nWelcome to the \"Synthetic Multilingual LLM Prompts\" dataset! This comprehensive collection features 1,250 synthetic LLM prompts generated using Gretel Navigator, available in seven different languages. To ensure accuracy and diversity in prompts, and translation quality and consistency across the different languages, we employed Gretel Navigator both as a generation tool and as anâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/gretelai/synthetic_multilingual_llm_prompts.","url":"https://huggingface.co/datasets/gretelai/synthetic_multilingual_llm_prompts","creator_name":"Gretel.ai","creator_url":"https://huggingface.co/gretelai","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","translation","question-answering","English","Dutch"],"keywords_longer_than_N":true},
	{"name":"Open-R1-Mulitlingual-SFT","keyword":"german","description":"\n\t\n\t\t\n\t\tOpen-R1-Mulitlingual-SFT\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nOpen-R1-Mulitlingual-SFT is a curated dataset designed for multilingual supervised fine-tuning.\nThe source data comprises multiple datasets containing original prompts and responses, which were subsequently translated into 14 languages using GPT-4o.\n\n\t\n\t\t\n\t\tSources\n\t\n\nThe dataset is derived from:\n\nopen-thoughts/OpenThoughts-114kHugging Face: open-thoughts/OpenThoughts-114k\nbespokelabs/Bespoke-Stratos-17kHugging Face:â€¦ See the full description on the dataset page: https://huggingface.co/datasets/amphora/Open-R1-Mulitlingual-SFT.","url":"https://huggingface.co/datasets/amphora/Open-R1-Mulitlingual-SFT","creator_name":"GUIJIN SON","creator_url":"https://huggingface.co/amphora","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["Afrikaans","Arabic","Chinese","English","French"],"keywords_longer_than_N":true},
	{"name":"axolotl-wiktionary-definitions","keyword":"german","description":"\n\t\n\t\t\n\t\tCitation\n\t\n\n@misc{dorkin2024tartunlpaxolotl24leveraging,\n      title={TartuNLP @ AXOLOTL-24: Leveraging Classifier Output for New Sense Detection in Lexical Semantics}, \n      author={Aleksei Dorkin and Kairit Sirts},\n      year={2024},\n      eprint={2407.03861},\n      archivePrefix={arXiv},\n      primaryClass={cs.CL},\n      url={https://arxiv.org/abs/2407.03861}, \n}\n\n","url":"https://huggingface.co/datasets/adorkin/axolotl-wiktionary-definitions","creator_name":"Aleksei Dorkin","creator_url":"https://huggingface.co/adorkin","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["Finnish","German","Russian","cc-by-4.0","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"X-ALMA-Preference","keyword":"german","description":"This is the translation preference dataset used by X-ALMA.\nsource: the source sentence.\nchosen: the preferred translation.\nreject: the dis-preferred translation.\ndirections: the translation direction.\n@misc{xu2024xalmaplugplay,\n      title={X-ALMA: Plug & Play Modules and Adaptive Rejection for Quality Translation at Scale}, \n      author={Haoran Xu and Kenton Murray and Philipp Koehn and Hieu Hoang and Akiko Eriguchi and Huda Khayrallah},\n      year={2024},\n      eprint={2410.03115}â€¦ See the full description on the dataset page: https://huggingface.co/datasets/haoranxu/X-ALMA-Preference.","url":"https://huggingface.co/datasets/haoranxu/X-ALMA-Preference","creator_name":"Haoran Xu","creator_url":"https://huggingface.co/haoranxu","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["English","Danish","Dutch","German","Icelandic"],"keywords_longer_than_N":true},
	{"name":"wilhelm-vocabulary","keyword":"german","description":"\n\t\n\t\t\n\t\tWilhelm Vocabulary\n\t\n\n[![Hugging Face dataset badge]][Hugging Face dataset URL]\n[![Vocabulary count - German]][Docker Hub URL]\n[![Vocabulary count - Latin]][Docker Hub URL]\n[![Vocabulary count - Ancient Greek]][Docker Hub URL]\n[![Docker Hub][Docker Pulls Badge]][Docker Hub URL]\n[![GitHub workflow status badge][GitHub workflow status badge]][GitHub workflow status URL]\n[![Hugging Face sync status badge]][Hugging Face sync status URL]\n[![Apache License Badge]][Apache License, Versionâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/QubitPi/wilhelm-vocabulary.","url":"https://huggingface.co/datasets/QubitPi/wilhelm-vocabulary","creator_name":"Jiaqi","creator_url":"https://huggingface.co/QubitPi","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["English","German","Latin","Ancient Greek (to 1453)","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"wilhelm-vocabulary","keyword":"german","description":"\n\t\n\t\t\n\t\tWilhelm Vocabulary\n\t\n\n[![Hugging Face dataset badge]][Hugging Face dataset URL]\n[![Vocabulary count - German]][Docker Hub URL]\n[![Vocabulary count - Latin]][Docker Hub URL]\n[![Vocabulary count - Ancient Greek]][Docker Hub URL]\n[![Docker Hub][Docker Pulls Badge]][Docker Hub URL]\n[![GitHub workflow status badge][GitHub workflow status badge]][GitHub workflow status URL]\n[![Hugging Face sync status badge]][Hugging Face sync status URL]\n[![Apache License Badge]][Apache License, Versionâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/QubitPi/wilhelm-vocabulary.","url":"https://huggingface.co/datasets/QubitPi/wilhelm-vocabulary","creator_name":"Jiaqi","creator_url":"https://huggingface.co/QubitPi","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["English","German","Latin","Ancient Greek (to 1453)","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"kassenzettel-synth","keyword":"german","description":"\n\t\n\t\t\n\t\tkassenzettel-synth\n\t\n\n\n\nThis dataset contains generate images of receipts.\nIt has been generated using github.com/nimalu/kassenzettel.\nThe current version contains 1000 samples.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nFor each instance, there is the underlying data, an image of the receipt, an image of the masks and both images augmented by adding crinkles.\n \n\n","url":"https://huggingface.co/datasets/nimalu/kassenzettel-synth","creator_name":"Niklas","creator_url":"https://huggingface.co/nimalu","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["image-to-text","image-segmentation","German","mit","< 1K"],"keywords_longer_than_N":true},
	{"name":"xgqa","keyword":"german","description":"\n\t\n\t\t\n\t\txGQA\n\t\n\n\n\t\n\t\t\n\t\tThis is a clone of the few_shot-test split of the xGQA dataset\n\t\n\nPlease find the original repository here: https://github.com/adapter-hub/xGQA\nIf you use this dataset, please cite the original authors:\n@inproceedings{pfeiffer-etal-2021-xGQA,\n    title={{xGQA: Cross-Lingual Visual Question Answering}},\n    author={ Jonas Pfeiffer and Gregor Geigle and Aishwarya Kamath and Jan-Martin O. Steitz and Stefan Roth and Ivan Vuli{\\'{c}} and Iryna Gurevych},\n    booktitle =â€¦ See the full description on the dataset page: https://huggingface.co/datasets/floschne/xgqa.","url":"https://huggingface.co/datasets/floschne/xgqa","creator_name":"Flo Schneider","creator_url":"https://huggingface.co/floschne","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["visual-question-answering","Bengali","German","English","Indonesian"],"keywords_longer_than_N":true},
	{"name":"world-languages-dataset","keyword":"german","description":"\n\t\n\t\t\n\t\tðŸŒ World Languages Dataset\n\t\n\nThis dataset contains a list of official and unofficial languages categorized by language families...\n","url":"https://huggingface.co/datasets/SivaMallikarjun/world-languages-dataset","creator_name":"Parvatham Siva Mallikarjun","creator_url":"https://huggingface.co/SivaMallikarjun","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","language-identification","expert-generated","multilingual","original"],"keywords_longer_than_N":true},
	{"name":"German-RAG-LLM-EASY-BENCHMARK","keyword":"german","description":"\n\t\n\t\t\n\t\tGerman-RAG-LLM-EASY-BENCHMARK\n\t\n\n\n\t\n\t\t\n\t\tGerman-RAG - German Retrieval Augmented Generation\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis German-RAG-LLM-BENCHMARK represents a specialized collection for evaluating language models with a focus on source citation, time difference stating in RAG-specific tasks.\nTo evaluate models compatible with OpenAI-Endpoints you can refer to our Github Repo: https://github.com/avemio-digital/German-RAG-LLM-EASY-BENCHMARK/\nMost of the Subsets are syntheticallyâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/avemio/German-RAG-LLM-EASY-BENCHMARK.","url":"https://huggingface.co/datasets/avemio/German-RAG-LLM-EASY-BENCHMARK","creator_name":"Avemio AG","creator_url":"https://huggingface.co/avemio","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","question-answering","summarization","German","English"],"keywords_longer_than_N":true},
	{"name":"German-RAG-LLM-EASY-BENCHMARK","keyword":"german","description":"\n\t\n\t\t\n\t\tGerman-RAG-LLM-EASY-BENCHMARK\n\t\n\n\n\t\n\t\t\n\t\tGerman-RAG - German Retrieval Augmented Generation\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis German-RAG-LLM-BENCHMARK represents a specialized collection for evaluating language models with a focus on source citation, time difference stating in RAG-specific tasks.\nTo evaluate models compatible with OpenAI-Endpoints you can refer to our Github Repo: https://github.com/avemio-digital/German-RAG-LLM-EASY-BENCHMARK/\nMost of the Subsets are syntheticallyâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/avemio/German-RAG-LLM-EASY-BENCHMARK.","url":"https://huggingface.co/datasets/avemio/German-RAG-LLM-EASY-BENCHMARK","creator_name":"Avemio AG","creator_url":"https://huggingface.co/avemio","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","question-answering","summarization","German","English"],"keywords_longer_than_N":true},
	{"name":"multilingual_translation_gpt4o_gen","keyword":"german","description":"Youseff1987/multilingual_translation_gpt4o_gen dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/Youseff1987/multilingual_translation_gpt4o_gen","creator_name":"JOON HYOUNG JUN","creator_url":"https://huggingface.co/Youseff1987","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["translation","Korean","English","Chinese","Zulu"],"keywords_longer_than_N":true},
	{"name":"retrieval_qa","keyword":"german","description":"\n\t\n\t\t\n\t\tRetrieval_QA: A Simple Multilingual Benchmark For Retrieval Encoder Models\n\t\n\n\n\nThe purpose of this dataset is to provide a simple and easy-to-use benchmark for retrieval encoder models, which helps researchers quickly select the most effective retrieval encoder for text extraction and achieve optimal results in subsequent retrieval tasks such as retrieval-augmented-generation (RAG). The dataset contains multiple document-question pairs, where each document is a short text about theâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/lnwang/retrieval_qa.","url":"https://huggingface.co/datasets/lnwang/retrieval_qa","creator_name":"Luning Wang","creator_url":"https://huggingface.co/lnwang","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["English","Chinese","Japanese","Spanish","German"],"keywords_longer_than_N":true},
	{"name":"IndEgo_Demo","keyword":"german","description":"\n\t\n\t\t\n\t\tIndEgo: A Dataset of Industrial Scenarios and Collaborative Work for Egocentric Assistants\n\t\n\n\nWe are sharing a portion of the dataset.\nðŸš§ This dataset is a work-in-progress. Documentation, metadata, and proper usage guidelines will be added shortly. Use with caution.\n\n\n\t\n\t\n\t\n\t\tAcknowledgements: Meta Reality Labs for their support and open-science initiative with Project Aria.\n\t\n\n","url":"https://huggingface.co/datasets/vivek9chavan/IndEgo_Demo","creator_name":"Vivek Chavan","creator_url":"https://huggingface.co/vivek9chavan","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["visual-question-answering","summarization","video-classification","any-to-any","English"],"keywords_longer_than_N":true},
	{"name":"LLM-Interaction","keyword":"german","description":"This is a temporary dataset used for initial testing.\n","url":"https://huggingface.co/datasets/Yliu566/LLM-Interaction","creator_name":"Yiqi Liu","creator_url":"https://huggingface.co/Yliu566","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["English","German","apache-2.0","1K - 10K","parquet"],"keywords_longer_than_N":true},
	{"name":"EC-Guide","keyword":"german","description":"\n\t\n\t\t\n\t\tThis repo is only used for dataset viewer. Please download from here.\n\t\n\n\n\t\n\t\t\n\t\tAmazon KDDCup 2024 Team ZJU-AI4Hâ€™s Solution and Dataset (Track 2 Top 2; Track 5 Top 5)\n\t\n\nThe Amazon KDD Cupâ€™24 competition presents a unique challenge by focusing on the application of LLMs in E-commerce across multiple tasks. Our solution for addressing Tracks 2 and 5 involves a comprehensive pipeline encompassing dataset construction, instruction tuning, post-training quantization, and inferenceâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/AiMijie/EC-Guide.","url":"https://huggingface.co/datasets/AiMijie/EC-Guide","creator_name":"AiMijie","creator_url":"https://huggingface.co/AiMijie","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["question-answering","text-generation","translation","English","Chinese"],"keywords_longer_than_N":true},
	{"name":"m-ArenaHard","keyword":"german","description":"\n\t\n\t\t\n\t\tDataset Card for m-ArenaHard\n\t\n\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\nThe m-ArenaHard dataset is a multilingual LLM evaluation set. This dataset was created by translating the prompts from the originally English-only LMarena (formerly LMSYS) arena-hard-auto-v0.1 test dataset using Google Translate API v3 to 22 languages. The original English-only prompts were created by Li et al. (2024) and consist of 500 challenging user queries sourced from Chatbot Arena. The authors show that these can be usedâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/CohereLabs/m-ArenaHard.","url":"https://huggingface.co/datasets/CohereLabs/m-ArenaHard","creator_name":"Cohere Labs","creator_url":"https://huggingface.co/CohereLabs","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["English","French","German","Spanish","Italian"],"keywords_longer_than_N":true},
	{"name":"german_handwriting","keyword":"german","description":"\n\t\n\t\t\n\t\tGerman handwriting\n\t\n\nThis dataset contains German handwriting images and corresponding text labels. In total, the dataset contains around 10,000 entries with handwriting from 15 different people.\nThe data was created with the help of transcripts from school and university.\nThe dataset was created as part of a handwriting recognition project at the FH-SWF.\n\n\t\n\t\t\n\t\tHow to use:\n\t\n\nfrom datasets import load_dataset\n\ndataset = load_dataset('fhswf/german_handwriting')\n\n","url":"https://huggingface.co/datasets/fhswf/german_handwriting","creator_name":"Fachhochschule SÃ¼dwestfalen","creator_url":"https://huggingface.co/fhswf","license_name":"Academic Free License v3.0","license_url":"https://choosealicense.com/licenses/afl-3.0/","language":"en","first_N":5,"first_N_keywords":["image-to-text","German","afl-3.0","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"code-switching-tokenizer-robustness","keyword":"german","description":"\n\t\n\t\t\n\t\tCode-Switching Dataset for Tokenizer Robustness Analysis\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset is designed for tokenizer robustness testing in multilingual and code-switching contexts. It contains identical content expressed across 16 different language variants, including pure English and 15 English-X code-switching pairs, allowing researchers to isolate tokenization effects from semantic differences when evaluating language models.\n\n\t\n\t\t\n\t\tPurpose\n\t\n\n\nTokenizer Comparison:â€¦ See the full description on the dataset page: https://huggingface.co/datasets/Malikeh1375/code-switching-tokenizer-robustness.","url":"https://huggingface.co/datasets/Malikeh1375/code-switching-tokenizer-robustness","creator_name":"Malikeh Ehghaghi","creator_url":"https://huggingface.co/Malikeh1375","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","text-classification","multilingual","English","Russian"],"keywords_longer_than_N":true},
	{"name":"trainset_political_party_big","keyword":"german","description":"\n\t\n\t\t\n\t\tðŸ“š Dataset Card for SinclairSchneider/trainset_political_party_big\n\t\n\n\nThis card follows Datasheets for Datasets (Gebru et al., 2021) sections.\n\n\n\n\t\n\t\t\n\t\t1) Motivation\n\t\n\nPurpose. A large German-language corpus for party classification and per-party stance/sentiment modeling across modern German political discourse.\nIntended users. NLP researchers and practitioners working on German parliamentary language, party stance detection, sentiment, temporal drift, and style robustness.â€¦ See the full description on the dataset page: https://huggingface.co/datasets/SinclairSchneider/trainset_political_party_big.","url":"https://huggingface.co/datasets/SinclairSchneider/trainset_political_party_big","creator_name":"Sinclair Schneider","creator_url":"https://huggingface.co/SinclairSchneider","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","German","cc-by-4.0","100K - 1M","parquet"],"keywords_longer_than_N":true},
	{"name":"JQL-LLM-Edu-Annotations","keyword":"german","description":"\n\t\n\t\t\n\t\tðŸ“š JQL Educational Quality Annotations from LLMs\n\t\n\nThis dataset provides 17,186,606 documents with high-quality LLM annotations for evaluating the educational value of web documents, and serves as a benchmark for training and evaluating multilingual LLM annotators as described in the JQL paper.\n\n\n\t\n\t\t\n\t\tðŸ“ Dataset Summary\n\t\n\n  Multilingual document-level quality annotations scored on a 0â€“5 educational value scale by three state-of-the-art LLMs:\n  Gemma-3-27B-it, Mistral-3.1-24B-itâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/JQL-AI/JQL-LLM-Edu-Annotations.","url":"https://huggingface.co/datasets/JQL-AI/JQL-LLM-Edu-Annotations","creator_name":"JQL-AI","creator_url":"https://huggingface.co/JQL-AI","license_name":"Open Data Commons Attribution License v1.0","license_url":"https://scancode-licensedb.aboutcode.org/odc-by-1.0.html","language":"en","first_N":5,"first_N_keywords":["Bulgarian","Czech","Croatian","Macedonian","Polish"],"keywords_longer_than_N":true},
	{"name":"rework_undl_text","keyword":"german","description":"\n\t\n\t\t\n\t\tè”åˆå›½æ•°å­—å›¾ä¹¦é¦†ODSé‡Œçˆ¬å‡ºæ¥çš„å¹³è¡Œè¯­æ–™ Parallel Corpus from United Nations Digital Library ODSï¼ˆ2000-2023ï¼‰\n\t\n\næ•°æ®æºé“¾æŽ¥ï¼ˆç½‘ç«™é€»è¾‘æ¯”èµ·çˆ¬å–è¿™äº›æ•°æ®æ—¶å·²ç»é‡æž„æ›´æ–°ï¼Œå¯èƒ½ä¼šæœ‰ä¸ä¸€è‡´çš„æƒ…å†µï¼‰ï¼šhttps://search.un.org/search?collection=ods&currentPageNumber=1&q=*&row=10&sort=relevance\npandocè½¬docxå‡ºçš„æºæ–‡æœ¬ï¼Œæ‰€ç”¨å‘½ä»¤ä¸ºï¼špandoc -i {filepath} -t plain -o {outpath} --strip-comments\nè¿™äº›æ–‡æœ¬å¯èƒ½ä»éœ€ä¸€å®šçš„æ­¥éª¤åŽ»å™ªï¼Œæ¯”å¦‚åŽ»æŽ‰å…¨æ˜¯æ¨ªçº¿çš„åˆ†éš”ç¬¦ã€åŽ»æŽ‰è¡¨æ ¼å…ƒç´ ï¼Œæ‰èƒ½ç”¨äºŽåŽç»­çš„ç¿»è¯‘åŠå¯¹é½æ­¥éª¤\næ—§ç‰ˆæ•°æ®é“¾æŽ¥ https://huggingface.co/datasets/bot-yaya/undl_text \nå› ä¸ºæ—§ç‰ˆå‚æ•°ä¸å½“ï¼Œå¤„ç†çš„æ—¶å€™ä¸¢æŽ‰äº†ä¸€éƒ¨åˆ†æ•°æ®ï¼Œæ‰€ä»¥é‡åšäº†ä¸€ä»½é‡æ–°ä¸Šä¼ ï¼Œå»ºè®®æ˜¯ä¸‹è½½ä½¿ç”¨è¿™ä»½ï¼Œè€Œä¸æ˜¯æ—§ç‰ˆ\n","url":"https://huggingface.co/datasets/bot-yaya/rework_undl_text","creator_name":"yaya","creator_url":"https://huggingface.co/bot-yaya","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["translation","Arabic","English","French","Spanish"],"keywords_longer_than_N":true},
	{"name":"AtomicGPT2-data","keyword":"german","description":"Atomic-Ai/AtomicGPT2-data dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/Atomic-Ai/AtomicGPT2-data","creator_name":"Atomic Ai Studios","creator_url":"https://huggingface.co/Atomic-Ai","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["question-answering","German","mit","10K - 100K","text"],"keywords_longer_than_N":true},
	{"name":"OGC_Renewable_Regulation","keyword":"german","description":"\n\t\n\t\t\n\t\tOGC_Renewable_Regulation - Overview\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nOGC_Renewable_Regulation is a curated multimodal dataset focused on renewable energy technical documents, regulations, and legal frameworks. It combines text and image data extracted from real scientific and regulatory PDFs to support tasks such as RAG DSE, question answering, document search, and vision-language model training.\n\n\t\n\t\t\n\t\tDataset Creation\n\t\n\nThis dataset was created using our open-source toolâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/racineai/OGC_Renewable_Regulation.","url":"https://huggingface.co/datasets/racineai/OGC_Renewable_Regulation","creator_name":"racine.ai","creator_url":"https://huggingface.co/racineai","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["question-answering","visual-question-answering","text-retrieval","English","French"],"keywords_longer_than_N":true},
	{"name":"ultradistil-intel-orca-dpo-de-scored","keyword":"german","description":"\n\t\n\t\t\n\t\tModifications\n\t\n\nThis is the original and unchanged german translated dataset (train split only) in original order from aari1995/ultradistil-intel-orca-dpo-de with added cosine-similarity scores.\nOnly for 'input' and 'chosen' scores have been calculated. The scores have been calculated using the best static multilingual embedding model (for my needs): sentence-transformers/static-similarity-mrl-multilingual-v1 for faster distinction if an answer corresponds to a query upon the content.â€¦ See the full description on the dataset page: https://huggingface.co/datasets/MarcGrumpyOlejak/ultradistil-intel-orca-dpo-de-scored.","url":"https://huggingface.co/datasets/MarcGrumpyOlejak/ultradistil-intel-orca-dpo-de-scored","creator_name":"Marc Olejak","creator_url":"https://huggingface.co/MarcGrumpyOlejak","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","German","apache-2.0","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"paracrawl_context","keyword":"german","description":"\n\t\n\t\t\n\t\tDataset Card for ParaCrawl_Context\n\t\n\n\n\nThis is a dataset for document-level machine translation introduced in the ACL 2024 paper Document-Level Machine Translation with Large-Scale Public Parallel Data. It is a dataset consisting of parallel sentence pairs from the ParaCrawl dataset along with corresponding preceding context extracted from the webpages the sentences were crawled from.\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Description\n\t\n\n\nThis dataset adds document-levelâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Proyag/paracrawl_context.","url":"https://huggingface.co/datasets/Proyag/paracrawl_context","creator_name":"Proyag Pal","creator_url":"https://huggingface.co/Proyag","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["translation","English","German","French","Czech"],"keywords_longer_than_N":true},
	{"name":"CTA-synthetic-dataset","keyword":"german","description":"\n\t\n\t\t\n\t\tGerman Instagram Political Communication 2021 - Synthetic Call to Action Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Overview\n\t\n\nThis dataset consists of synthetic training data used to detect Calls to Action (CTAs) in German political Instagram content from the 2021 Federal Election. The synthetic data was generated using OpenAI's GPT-4o to augment original human-annotated examples. The dataset aims to address class imbalance issues for improved model performance in political communication studies.â€¦ See the full description on the dataset page: https://huggingface.co/datasets/chaichy/CTA-synthetic-dataset.","url":"https://huggingface.co/datasets/chaichy/CTA-synthetic-dataset","creator_name":"Michael Achmann-Denkler","creator_url":"https://huggingface.co/chaichy","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","German","apache-2.0","< 1K","parquet"],"keywords_longer_than_N":true},
	{"name":"jinaai_jina-embeddings-v2-base-en-03092024-oix8-webapp","keyword":"german","description":"\n\t\n\t\t\n\t\tjinaai_jina-embeddings-v2-base-en-03092024-oix8-webapp Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"health insurance information\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the jinaai_jina-embeddings-v2-base-en-03092024-oix8-webapp model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Huggingâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/jinaai_jina-embeddings-v2-base-en-03092024-oix8-webapp.","url":"https://huggingface.co/datasets/fine-tuned/jinaai_jina-embeddings-v2-base-en-03092024-oix8-webapp","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","German","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"jinaai_jina-embeddings-v2-base-en-03092024-oix8-webapp","keyword":"german","description":"\n\t\n\t\t\n\t\tjinaai_jina-embeddings-v2-base-en-03092024-oix8-webapp Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"health insurance information\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the jinaai_jina-embeddings-v2-base-en-03092024-oix8-webapp model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it using the Huggingâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/jinaai_jina-embeddings-v2-base-en-03092024-oix8-webapp.","url":"https://huggingface.co/datasets/fine-tuned/jinaai_jina-embeddings-v2-base-en-03092024-oix8-webapp","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","German","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"mmmlu_lite","keyword":"german","description":"\n\t\n\t\t\n\t\tMMMLU-Lite\n\t\n\n\n\t\n\t\t\n\t\tIntroduction\n\t\n\nA lite version of the MMMLU dataset, which is an community version of the MMMLU dataset by OpenCompass. Due to the large size of the original dataset (about 200k questions), we have created a lite version of the dataset to make it easier to use. We sample 25 examples from each language subject in the original dataset with fixed seed to ensure reproducibility, finally we have 19950 examples in the lite version of the dataset, which is about 10% ofâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/opencompass/mmmlu_lite.","url":"https://huggingface.co/datasets/opencompass/mmmlu_lite","creator_name":"OpenCompass","creator_url":"https://huggingface.co/opencompass","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["question-answering","Arabic","Bengali","German","Spanish"],"keywords_longer_than_N":true},
	{"name":"youtube-commons-small","keyword":"german","description":"\n\t\n\t\t\n\t\tðŸ“º YouTube-Commons-Small ðŸ“º\n\t\n\nThis is a smaller subset of the YouTube-Commons dataset, which is a collection of audio transcripts from videos shared on YouTube under a CC-By license.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis smaller version contains a subset of the original dataset, maintaining the same structure and features. It's designed for easier experimentation and testing purposes.\n\n\t\n\t\t\n\t\tFeatures\n\t\n\nThe dataset includes the following information for each video:\n\nVideo ID and linkâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/dm-petrov/youtube-commons-small.","url":"https://huggingface.co/datasets/dm-petrov/youtube-commons-small","creator_name":"Dmitry Petrov","creator_url":"https://huggingface.co/dm-petrov","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","English","French","Spanish","Portuguese"],"keywords_longer_than_N":true},
	{"name":"agentic_synthetic_customer_service_conversations","keyword":"german","description":"\n\t\n\t\t\n\t\tLLM-filtered Customer Service Conversations Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset contains simulated conversations generated by our agentic simulation system.\nThe conversations are filtered by a LLM to ensure they are of high quality.\nEach record is stored in JSON Lines (JSONL) format and includes:\n\nInput Settings: Metadata such as selected bank, customer, agent profiles, and task details.\nMessages: The full conversation messages.\nSummary: A German summary of the conversation.â€¦ See the full description on the dataset page: https://huggingface.co/datasets/marccgrau/agentic_synthetic_customer_service_conversations.","url":"https://huggingface.co/datasets/marccgrau/agentic_synthetic_customer_service_conversations","creator_name":"Marc Christopher Grau","creator_url":"https://huggingface.co/marccgrau","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","summarization","synthetic","monolingual","German"],"keywords_longer_than_N":true},
	{"name":"CIVICS","keyword":"german","description":"\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\tUses\n\t\n\nEvaluating a language modelâ€™s treatment of different ethical values, specifically for different civics topics relevant to sensitive groups. â€œTreatmentâ€ includes the likelihood a model gives to different value-laden statements and whether different implicit values in inputs lead to different generations by the model, in response to the provided prompts.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\nLanguage: One of â€œGermanâ€, â€œEnglishâ€, â€œFrenchâ€, â€œItalianâ€, â€œTurkishâ€.â€¦ See the full description on the dataset page: https://huggingface.co/datasets/CIVICS-dataset/CIVICS.","url":"https://huggingface.co/datasets/CIVICS-dataset/CIVICS","creator_name":"CIVICS dataset organization","creator_url":"https://huggingface.co/CIVICS-dataset","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["English","Italian","German","Turkish","French"],"keywords_longer_than_N":true},
	{"name":"aya_collection","keyword":"german","description":"\nThis dataset is uploaded in two places: here and additionally here as 'Aya Collection Language Split.' These datasets are identical in content but differ in structure of upload. This dataset is structured by folders split according to dataset name. The version here instead divides the Aya collection into folders split by language. We recommend you use the language split version if you are only interested in downloading data for a single or smaller set of languages, and this version if youâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/CohereLabs/aya_collection.","url":"https://huggingface.co/datasets/CohereLabs/aya_collection","creator_name":"Cohere Labs","creator_url":"https://huggingface.co/CohereLabs","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","summarization","translation","Achinese","Afrikaans"],"keywords_longer_than_N":true},
	{"name":"page-summarization-eval-de","keyword":"german","description":"Mozilla/page-summarization-eval-de dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/Mozilla/page-summarization-eval-de","creator_name":"mozilla","creator_url":"https://huggingface.co/Mozilla","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["summarization","German","apache-2.0","< 1K","parquet"],"keywords_longer_than_N":true},
	{"name":"absinth_german_faithfulness_detection_dataset","keyword":"german","description":"\n\t\n\t\t\n\t\tDataset Card for \"Absinth - Hallucination Detection Dataset of German News Summarization\"\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nAbsinth is a human-annotated dataset for faithfulness detection in the context of German news summarization. \nThe dataset has 4335 instances in total, where each instance consists of:\n\nNews Article: The original news article from the 20Minuten dataset. Please note that original source articles are not included in the dataset and need to be downloaded seperatelyâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/mtc/absinth_german_faithfulness_detection_dataset.","url":"https://huggingface.co/datasets/mtc/absinth_german_faithfulness_detection_dataset","creator_name":"MTC","creator_url":"https://huggingface.co/mtc","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","German","apache-2.0","1K - 10K","parquet"],"keywords_longer_than_N":true},
	{"name":"semeval-2025-task11-track-b","keyword":"german","description":"\n\t\n\t\t\n\t\tSemEval 2025 Task 11 - Track B Dataset\n\t\n\nThis dataset contains the data for SemEval 2025 Task 11: Bridging the Gap in Text-Based Emotion Detection - Track B, organized as language-specific configurations.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset is a multi-language, multi-label emotion classification dataset with separate configurations for each language.\n\nTotal languages: 11 standard ISO codes\nTotal examples: 47111\nSplits: train, dev, test\n\n\n\t\n\t\t\n\t\tTrack Information\n\t\n\nTrack B hasâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/vgaraujov/semeval-2025-task11-track-b.","url":"https://huggingface.co/datasets/vgaraujov/semeval-2025-task11-track-b","creator_name":"Vladimir Araujo","creator_url":"https://huggingface.co/vgaraujov","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["Amharic","Arabic","German","English","Spanish"],"keywords_longer_than_N":true},
	{"name":"mHumanEval-Benchmark","keyword":"german","description":"\n\n\n\t\n\t\t\n\t\tðŸ”· Accepted in NAACL Proceedings (2025) ðŸ”·\n\t\n\n\n\n\n\n  \n    \n      \n        \n          \n        \n      \n      \n        \n          \n        \n      \n      \n        \n          \n        \n      \n    \n  \n\n\n\n\n\n  \n\n\t\n\t\n\t\n\t\tmHumanEval\n\t\n\nThe mHumanEval benchmark is curated based on prompts from the original HumanEval ðŸ“š [Chen et al., 2021]. It includes a total of 33,456 prompts for Python, and 836,400 in total - significantly expanding from the original 164. \n\n\n\t\n\t\t\n\t\tQuick Start\n\t\n\n  Detailedâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/md-nishat-008/mHumanEval-Benchmark.","url":"https://huggingface.co/datasets/md-nishat-008/mHumanEval-Benchmark","creator_name":"Nishat Raihan","creator_url":"https://huggingface.co/md-nishat-008","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["Afar","Abkhaz","Avestan","Afrikaans","Akan"],"keywords_longer_than_N":true},
	{"name":"text-moderation-02-multilingual","keyword":"german","description":"This dataset is based on Kaggle.It represents a version of @ifmain/text-moderation-410K that has been cleansed of semantically similar values and normalized to a 50/50 ratio of negative and neutral entries.\nThe dataset contains 1.5M entries (91K * 17 languages).  \nBefore use, augmentation is recommended! (e.g., character substitution to bypass moderation).\nFor augmentation, you can use @ifmain/StringAugmentor.  \nEnjoy using it!\n","url":"https://huggingface.co/datasets/ifmain/text-moderation-02-multilingual","creator_name":"Mike Afton","creator_url":"https://huggingface.co/ifmain","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["English","German","French","Spanish","Italian"],"keywords_longer_than_N":true},
	{"name":"Multilingual-Thinking","keyword":"german","description":"\n\t\n\t\t\n\t\tDataset summary\n\t\n\nMultilingual-Thinking is a reasoning dataset where the chain-of-thought has been translated from English into one of 4 languages: Spanish, French, Italian, and German. The dataset was created by sampling 1k training samples from the SystemChat subset of SmolTalk2 and translating the reasoning traces with another language model. \nThis dataset was used in the OpenAI Cookbook to fine-tune the OpenAI gpt-oss models.\nYou can load the dataset using:\nfrom datasets importâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/HuggingFaceH4/Multilingual-Thinking.","url":"https://huggingface.co/datasets/HuggingFaceH4/Multilingual-Thinking","creator_name":"Hugging Face H4","creator_url":"https://huggingface.co/HuggingFaceH4","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","English","German","French","Spanish"],"keywords_longer_than_N":true},
	{"name":"global-festivals-translated","keyword":"german","description":"azminetoushikwasi/global-festivals-translated dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/azminetoushikwasi/global-festivals-translated","creator_name":"Azmine Toushik Wasi","creator_url":"https://huggingface.co/azminetoushikwasi","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","English","French","Spanish","German"],"keywords_longer_than_N":true},
	{"name":"biblenlp-corpus-mmteb","keyword":"german","description":"This dataset pre-computes all English-centric directions from bible-nlp/biblenlp-corpus, and as a result loading is significantly faster.\nLoading example:\n>>> from datasets import load_dataset\n>>> dataset = load_dataset(\"davidstap/biblenlp-corpus-mmteb\", \"eng-arb\", trust_remote_code=True)\n>>> dataset\nDatasetDict({\n    train: Dataset({\n        features: ['eng', 'arb'],\n        num_rows: 28723\n    })\n    validation: Dataset({\n        features: ['eng', 'arb'],\n        num_rows: 1578\n    })â€¦ See the full description on the dataset page: https://huggingface.co/datasets/davidstap/biblenlp-corpus-mmteb.","url":"https://huggingface.co/datasets/davidstap/biblenlp-corpus-mmteb","creator_name":"David Stap","creator_url":"https://huggingface.co/davidstap","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["no-annotation","expert-generated","translation","multilingual","Arifama-Miniafia"],"keywords_longer_than_N":true},
	{"name":"biblenlp-corpus-mmteb","keyword":"german","description":"This dataset pre-computes all English-centric directions from bible-nlp/biblenlp-corpus, and as a result loading is significantly faster.\nLoading example:\n>>> from datasets import load_dataset\n>>> dataset = load_dataset(\"davidstap/biblenlp-corpus-mmteb\", \"eng-arb\", trust_remote_code=True)\n>>> dataset\nDatasetDict({\n    train: Dataset({\n        features: ['eng', 'arb'],\n        num_rows: 28723\n    })\n    validation: Dataset({\n        features: ['eng', 'arb'],\n        num_rows: 1578\n    })â€¦ See the full description on the dataset page: https://huggingface.co/datasets/davidstap/biblenlp-corpus-mmteb.","url":"https://huggingface.co/datasets/davidstap/biblenlp-corpus-mmteb","creator_name":"David Stap","creator_url":"https://huggingface.co/davidstap","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["no-annotation","expert-generated","translation","multilingual","Arifama-Miniafia"],"keywords_longer_than_N":true},
	{"name":"MultiMed-ST","keyword":"german","description":"\n\t\n\t\t\n\t\tMultiMed-ST: Large-scale Many-to-many Multilingual Medical Speech Translation\n\t\n\nPreprint\nKhai Le-Duc*, Tuyen Tran*,\nBach Phan Tat, Nguyen Kim Hai Bui, Quan Dang, Hung-Phong Tran, Thanh-Thuy Nguyen, Ly Nguyen, Tuan-Minh Phan, Thi Thu Phuong Tran, Chris Ngo,\nNguyen X. Khanh**, Thanh Nguyen-Tang**\n\n\n*Equal contribution\n**Equal supervision\n\n\nAbstract:\nMultilingual speech translation (ST) in the medical domain  enhances patient care by enabling efficient communication across languageâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/leduckhai/MultiMed-ST.","url":"https://huggingface.co/datasets/leduckhai/MultiMed-ST","creator_name":"Le Duc Khai","creator_url":"https://huggingface.co/leduckhai","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["translation","automatic-speech-recognition","Vietnamese","English","German"],"keywords_longer_than_N":true},
	{"name":"toxi-text-3M","keyword":"german","description":"This is a large multilingual toxicity dataset with 3M rows of text data from 55 natural languages, all of which are written/sent by humans, not machine translation models.\nThe preprocessed training data alone consists of 2,880,667 rows of comments, tweets, and messages. Among these rows, 416,529 are classified as toxic, while the remaining 2,463,773 are considered neutral. Below is a table to illustrate the data composition:\n\n\t\n\t\t\n\nToxic\nNeutral\nTotal\n\n\n\t\t\nmultilingual-train-deduplicated.csvâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/FredZhang7/toxi-text-3M.","url":"https://huggingface.co/datasets/FredZhang7/toxi-text-3M","creator_name":"Fred Zhang","creator_url":"https://huggingface.co/FredZhang7","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","zero-shot-classification","Arabic","Spanish","Panjabi"],"keywords_longer_than_N":true},
	{"name":"german_tlr_gold_14k","keyword":"german","description":"\n\t\n\t\t\n\t\tðŸ§  German TLR Gold Dataset (14.5k)\n\t\n\n\n\t\n\t\t\n\t\tðŸ“Š Dataset Overview\n\t\n\nEin hochwertiger deutschsprachiger Datensatz mit 14.500 Samples im Think-Learn-Respond (TLR) Format fÃ¼r das Training von reasoning-fÃ¤higen Large Language Models.\nFormat: Jede Antwort ist strukturiert in:\n\n<think>: Strukturierter Denkprozess und Reasoning\n<answer>: Finale, klare Antwort\n\n\n\t\n\t\t\n\t\tðŸŽ¯ Anwendung\n\t\n\nDieses Dataset wurde speziell entwickelt fÃ¼r:\n\nSupervised Fine-Tuning (SFT) von deutschen LLMs\nTraining vonâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/arnomatic/german_tlr_gold_14k.","url":"https://huggingface.co/datasets/arnomatic/german_tlr_gold_14k","creator_name":"arnomatic","creator_url":"https://huggingface.co/arnomatic","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-generation","question-answering","German","mit","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"german_tlr_gold_14k","keyword":"german","description":"\n\t\n\t\t\n\t\tðŸ§  German TLR Gold Dataset (14.5k)\n\t\n\n\n\t\n\t\t\n\t\tðŸ“Š Dataset Overview\n\t\n\nEin hochwertiger deutschsprachiger Datensatz mit 14.500 Samples im Think-Learn-Respond (TLR) Format fÃ¼r das Training von reasoning-fÃ¤higen Large Language Models.\nFormat: Jede Antwort ist strukturiert in:\n\n<think>: Strukturierter Denkprozess und Reasoning\n<answer>: Finale, klare Antwort\n\n\n\t\n\t\t\n\t\tðŸŽ¯ Anwendung\n\t\n\nDieses Dataset wurde speziell entwickelt fÃ¼r:\n\nSupervised Fine-Tuning (SFT) von deutschen LLMs\nTraining vonâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/arnomatic/german_tlr_gold_14k.","url":"https://huggingface.co/datasets/arnomatic/german_tlr_gold_14k","creator_name":"arnomatic","creator_url":"https://huggingface.co/arnomatic","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-generation","question-answering","German","mit","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"orca_dpo_pairs","keyword":"german","description":"\n    \n\n\nmLLM IMPLEMENTATION OF Intel/orca_dpo_pairs.\nLANGUAGES:\nARABIC\nCHINESE\nFRENCH\nGERMAN\nRUSSIAN\nSPANISH\nTURKISH\n(WIP)\n","url":"https://huggingface.co/datasets/multilingual/orca_dpo_pairs","creator_name":"mLLM multilingual","creator_url":"https://huggingface.co/multilingual","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","Arabic","Chinese","German","French"],"keywords_longer_than_N":true},
	{"name":"swiss-german-dialect","keyword":"german","description":"\n\t\n\t\t\n\t\tSwiss German Language Dataset\n\t\n\nThis dataset contains Swiss German language content extracted from a forum discussion. It is designed for training language models to better understand and generate Swiss German dialect text.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\nThe dataset consists of conversations and discussions in Swiss German, focusing on various dialect terms, phrases, and expressions. The data is structured in JSON format, with each entry containing a unique identifier, a tag, a topic, aâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Kenshiii/swiss-german-dialect.","url":"https://huggingface.co/datasets/Kenshiii/swiss-german-dialect","creator_name":"Sho","creator_url":"https://huggingface.co/Kenshiii","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["German","mit","< 1K","json","Text"],"keywords_longer_than_N":true},
	{"name":"NOVA-63","keyword":"german","description":"\n\t\n\t\n\t\n\t\tWe released this dataset under the MIT License. This means that anyone is free to use, copy, modify, distribute, and reuse our data, provided that the original copyright notice and license information are retained.\nThis work is jointly completed by PKU & Alibaba Group. The dataset is currently under review. Please be patient. We also hope this dataset can help more partners/colleagues in the community.\nTo ensure the validity and fairness of the benchmark evaluation, we explicitlyâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/zjy1298/NOVA-63.","url":"https://huggingface.co/datasets/zjy1298/NOVA-63","creator_name":"Zhang","creator_url":"https://huggingface.co/zjy1298","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":null,"first_N":5,"first_N_keywords":["Arabic","Chinese","English","French","Spanish"],"keywords_longer_than_N":true},
	{"name":"clams","keyword":"german","description":"\n\t\n\t\t\n\t\tCLAMS - Cross-Linguistic Assessment of Models on Syntax\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nCLAMS (Cross-Linguistic Assessment of Models on Syntax) is a dataset of syntactic minimal pairs for English, French, German, Hebrew, and Russian. The dataset contains grammaticality judgment pairs (good/bad sentence pairs) for various syntactic phenomena, designed to evaluate language models' syntactic knowledge across different languages.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nThe dataset contains minimalâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/juletxara/clams.","url":"https://huggingface.co/datasets/juletxara/clams","creator_name":"Julen Etxaniz","creator_url":"https://huggingface.co/juletxara","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["other","expert-generated","expert-generated","multilingual","original"],"keywords_longer_than_N":true},
	{"name":"openlegaldata","keyword":"german","description":"Clean Open Legal Data\n\n   \n       Overview |\n       Dataset Structure  |\n       Key Fields  |\n       Example Entry |\n       Using the Dataset with Python |\n       License\n   \n\n\n\n\t\n\t\t\n\t\n\t\n\t\tOverview\n\t\n\nThis dataset is a comprehensive collection of open legal case records in JSONL format. It comprises 251,038 cases extracted and processed from the Open Legal Data dump (as of 2022-10-18). The dataset is designed for legal research, data science, and natural language processing applications. Eachâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/harshildarji/openlegaldata.","url":"https://huggingface.co/datasets/harshildarji/openlegaldata","creator_name":"Harshil","creator_url":"https://huggingface.co/harshildarji","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","text-generation","German","mit","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"tatoeba_raw_deu_kbd","keyword":"german","description":"\n\t\n\t\t\n\t\tGerman-to-Kabardian Tatoeba Raw Machine Translations Dataset\n\t\n\nThis dataset contains translations of sentences from German to Kabardian, sourced from the Tatoeba project. It provides a substantial parallel corpus for machine translation and linguistic research involving the Kabardian language.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\n\n\t\n\t\t\n\t\tDataset Overview\n\t\n\nThis dataset contains over 14 million sentence pairs, with source sentences in German and their translations in Kabardian. Each entryâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/panagoa/tatoeba_raw_deu_kbd.","url":"https://huggingface.co/datasets/panagoa/tatoeba_raw_deu_kbd","creator_name":"adam panagov","creator_url":"https://huggingface.co/panagoa","license_name":"Creative Commons Attribution 2.0","license_url":"https://scancode-licensedb.aboutcode.org/cc-by-2.0.html","language":"en","first_N":5,"first_N_keywords":["translation","German","Kabardian","cc-by-2.0","1M - 10M"],"keywords_longer_than_N":true},
	{"name":"mc-translation","keyword":"german","description":"This dataset contains professional human translations from OpenAI's MMMLU dataset, repurposed to train translation models that can help translate future evaluation datasets.\n\n\t\n\t\t\n\t\tWhy This Dataset?\n\t\n\nTranslation of evaluation benchmarks is a critical but challenging task. While automated translations may introduce errors or biases, professional human translations are expensive and time-consuming. This dataset leverages existing professional translations (MMMLU) to train specializedâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/efederici/mc-translation.","url":"https://huggingface.co/datasets/efederici/mc-translation","creator_name":"Edoardo Federici","creator_url":"https://huggingface.co/efederici","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["translation","English","Swahili","Spanish","German"],"keywords_longer_than_N":true},
	{"name":"filtered_convos_research_llm_summaries_cleaned_v2","keyword":"german","description":"\n\t\n\t\t\n\t\tSynthetic Call Center Summaries Dataset Cleaned - Prompt V2\n\t\n\n\n\t\n\t\t\n\t\tPrompt Changes\n\t\n\n\nClarify objective and style\nShow examples dialogue and best-case summary\nInclude Chain-of-Thought Guidance (show individual subtasks)\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset contains synthetic summaries of call center conversations generated by different prompt configurations.\nEach record (in JSON Lines format) includes:\n\nThe original dialogue metadata.\nA generated summary tailored to provide quickâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/marccgrau/filtered_convos_research_llm_summaries_cleaned_v2.","url":"https://huggingface.co/datasets/marccgrau/filtered_convos_research_llm_summaries_cleaned_v2","creator_name":"Marc Christopher Grau","creator_url":"https://huggingface.co/marccgrau","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["summarization","text-generation","synthetic","monolingual","German"],"keywords_longer_than_N":true},
	{"name":"muri-it","keyword":"german","description":"\n\t\n\t\t\n\t\tMURI-IT: Multilingual Instruction Tuning Dataset for 200 Languages via Multilingual Reverse Instructions\n\t\n\nMURI-IT is a large-scale multilingual instruction tuning dataset containing 2.2 million instruction-output pairs across 200 languages. It is designed to address the challenges of instruction tuning in low-resource languages with Multilingual Reverse Instructions (MURI), which ensures that the output is human-written, high-quality, and authentic to the cultural and linguisticâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/akoksal/muri-it.","url":"https://huggingface.co/datasets/akoksal/muri-it","creator_name":"Abdullatif Koksal","creator_url":"https://huggingface.co/akoksal","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text2text-generation","text-generation","question-answering","summarization","Achinese"],"keywords_longer_than_N":true},
	{"name":"cml-tts-filtered-annotated","keyword":"german","description":"\n\t\n\t\t\n\t\tDataset Card for Filtred and annotated CML TTS\n\t\n\nThis dataset is an annotated and filtred version of a CML-TTS [1]. \nCML-TTS [1] CML-TTS is a recursive acronym for CML-Multi-Lingual-TTS, a Text-to-Speech (TTS) dataset developed at the Center of Excellence in Artificial Intelligence (CEIA) of the Federal University of Goias (UFG). CML-TTS is a dataset comprising audiobooks sourced from the public domain books of Project Gutenberg, read by volunteers from the LibriVox project. Theâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/PHBJT/cml-tts-filtered-annotated.","url":"https://huggingface.co/datasets/PHBJT/cml-tts-filtered-annotated","creator_name":"Paul Henri Biojout","creator_url":"https://huggingface.co/PHBJT","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-to-speech","French","German","Italian","Spanish"],"keywords_longer_than_N":true},
	{"name":"BenchMAX_Function_Completion","keyword":"german","description":"\n\t\n\t\t\n\t\tDataset Sources\n\t\n\n\nPaper: BenchMAX: A Comprehensive Multilingual Evaluation Suite for Large Language Models\nLink: https://huggingface.co/papers/2502.07346\nRepository: https://github.com/CONE-MT/BenchMAX\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nBenchMAX_Function_Completion is a dataset of BenchMAX, sourcing from humanevalplus, which evaluates the code generation capability in multilingual scenarios.\nWe extend the original English dataset to 16 non-English languages.\nThe data is first translatedâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/LLaMAX/BenchMAX_Function_Completion.","url":"https://huggingface.co/datasets/LLaMAX/BenchMAX_Function_Completion","creator_name":"LLaMAX","creator_url":"https://huggingface.co/LLaMAX","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","multilingual","English","Chinese","Spanish"],"keywords_longer_than_N":true},
	{"name":"PolyGuardMix","keyword":"german","description":"\n\t\n\t\t\n\t\tPolyGuard: A Multilingual Safety Moderation Tool for 17 Languages\n\t\n\nAbstract: Truly multilingual safety moderation efforts for Large Language Models (LLMs) have been hindered by a narrow focus on a small set of languages (e.g., English, Chinese) as well as a limited scope of safety definition, resulting in significant gaps in moderation capabilities. To bridge these gaps, we release PolyGuard, a new state-of-the-art multilingual safety model for safeguarding LLM generations, and theâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/ToxicityPrompts/PolyGuardMix.","url":"https://huggingface.co/datasets/ToxicityPrompts/PolyGuardMix","creator_name":"ToxicityPrompts","creator_url":"https://huggingface.co/ToxicityPrompts","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["Arabic","Chinese","Czech","Dutch","English"],"keywords_longer_than_N":true},
	{"name":"BK-Training-Dataset","keyword":"german","description":"\n\t\n\t\t\n\t\tTitle\n\t\n\n\"Basisklassifikation\" (BK) Training Dataset for Automatic Subject Indexing: Titles and Subjects from the K10plus Library Catalogue\n\n\t\n\t\t\n\t\tDescription\n\t\n\nThis is a training dataset for automatic subject indexing containing more than 6 million titles and their corresponding subjects (classes) from the \"Basisklassifikation\" (BK). Initially introduced in the 1980s, today the Basisklassifikation constitutes the most widely used classification system for subject indexing within theâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/SBB/BK-Training-Dataset.","url":"https://huggingface.co/datasets/SBB/BK-Training-Dataset","creator_name":"Staatsbibliothek zu Berlin - PreuÃŸischer Kulturbesitz","creator_url":"https://huggingface.co/SBB","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","German","English","French","Italian"],"keywords_longer_than_N":true},
	{"name":"InVar-100","keyword":"german","description":"\n\t\n\t\t\n\t\tTowards Realistic Evaluation of Industrial Continual Learning Scenarios with an Emphasis on Energy Consumption and Computational Footprint\n\t\n\n[Paper] [Poster] [Summary Video]\nAbstract: Incremental Learning (IL) aims to develop Machine Learning (ML) models that can learn from continuous streams of data and mitigate catastrophic forgetting. We analyze the current state-of-the-art Class-IL implementations and demonstrate why the current body of research tends to be one-dimensional, withâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/vivek9chavan/InVar-100.","url":"https://huggingface.co/datasets/vivek9chavan/InVar-100","creator_name":"Vivek Chavan","creator_url":"https://huggingface.co/vivek9chavan","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["image-classification","English","German","cc-by-4.0","10K<n<100K"],"keywords_longer_than_N":true},
	{"name":"comment-translation-01","keyword":"german","description":"This dataset is based on Kaggle.  \nThis dataset includes translations of 69,000 Reddit comments into 17 languages (English to 16 languages):\nBelarusian, Czech, German,\nEnglish, Spanish, Finnish,\nFrench, Italian, Japanese,\nKazakh, Korean, Latvian,\nPolish, Russian, Swedish,\nUkrainian, and Chinese.\nIt contains 50% regular comments and 50% highly negative ones.\nEnjoy using it!\n","url":"https://huggingface.co/datasets/ifmain/comment-translation-01","creator_name":"Mike Afton","creator_url":"https://huggingface.co/ifmain","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["English","German","French","Spanish","Italian"],"keywords_longer_than_N":true},
	{"name":"moniteur-belge","keyword":"german","description":"\n\t\n\t\t\n\t\tDataset Description\n\t\n\n\n\nThe most up to date data can be found here: https://huggingface.co/datasets/guust-franssens/belgian-journal\nDue to the different languages in Belgium, I decided to create three datasets belgian-journal/moniteur-belge/belgisch-staatsblad in order to make it more visible.\nDataset contains the metadata + the text of bylaw publications of Belgian companies on the Belgian Journal (Moniteur Belge/Belgisch Staatstblad).\nThis data was collected by webscraping theâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/guust-franssens/moniteur-belge.","url":"https://huggingface.co/datasets/guust-franssens/moniteur-belge","creator_name":"Guust Franssens","creator_url":"https://huggingface.co/guust-franssens","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","French","Dutch","German","cc0-1.0"],"keywords_longer_than_N":true},
	{"name":"MSD_instruct","keyword":"german","description":"\n\t\n\t\t\n\t\tMSD_manual_topics_user_base\n\t\n\nThis dataset has been built with the website https://www.msdmanuals.com/ provided by Merck & Co for the greater audience.\nThe MSD manual is an essential source of knowledge for many topics related to symptoms, diseases, health and other related topics. The manual makes an extra effort to make it available both for professionals and patients by having two distinct version. \nThe content, while being labelled the same, differs by the type of user in order toâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/nuvocare/MSD_instruct.","url":"https://huggingface.co/datasets/nuvocare/MSD_instruct","creator_name":"Nuvocare","creator_url":"https://huggingface.co/nuvocare","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","text2text-generation","German","Spanish","French"],"keywords_longer_than_N":true},
	{"name":"prune-texts-en-de","keyword":"german","description":"This dataset was created as a calibration dataset for use with PruneMe. It contains the first 5000 entries each of the English and German subsets of allenai/c4.\n","url":"https://huggingface.co/datasets/LenDigLearn/prune-texts-en-de","creator_name":"Lennard Michael Strohmeyer","creator_url":"https://huggingface.co/LenDigLearn","license_name":"Open Data Commons Attribution License v1.0","license_url":"https://scancode-licensedb.aboutcode.org/odc-by-1.0.html","language":"en","first_N":5,"first_N_keywords":["text-generation","English","German","odc-by","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"FineNews-unfiltered","keyword":"german","description":"\n\t\n\t\t\n\t\tFineNews\n\t\n\nWIP. Like FineWeb, but built from Common Crawl News instead of main web.\nFor languages not listed as a split, check the data/ directory.\nFor now, it contains the 2024-05 (May),-04 (April),-03 (March) dumps.\nThis is the unfiltered version, with only URL filtering applied.\n\n\t\n\t\t\n\t\tSome initial stats\n\t\n\nTotal number of documents: 35M\n\n\t\n\t\t\nDump\nNumber of docs\nDisk size (compressed)\n\n\n\t\t\nCC-NEWS-2024-05\n11_715_084\n11G\n\n\nCC-NEWS-2024-04\n11_546_298\n11G\n\n\nCC-NEWS-2024-03â€¦ See the full description on the dataset page: https://huggingface.co/datasets/maxidl/FineNews-unfiltered.","url":"https://huggingface.co/datasets/maxidl/FineNews-unfiltered","creator_name":"Max Idahl","creator_url":"https://huggingface.co/maxidl","license_name":"Open Data Commons Attribution License v1.0","license_url":"https://scancode-licensedb.aboutcode.org/odc-by-1.0.html","language":"en","first_N":5,"first_N_keywords":["text-generation","English","German","French","Polish"],"keywords_longer_than_N":true},
	{"name":"German-RAG-ORPO-Alpaca-HESSIAN-AI","keyword":"german","description":"\n\t\n\t\t\n\t\tGerman-RAG-ORPO (Odds Ratio Preference Optimization) Alpaca-Format\n\t\n\n\n\t\n\t\t\n\t\tGerman-RAG - German Retrieval Augmented Generation\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThe ORPO Tasks Dataset represents a specialized collection for fine-tuning language models with a focus on RAG-specific capabilities. \nThe subsets can be for this training step are derived from 2 different sources:\n\nSauerkrautLM Preference Datasets:\nSauerkrautLM-Fermented-GER-DPO:  is a specialized dataset designed for trainingâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/avemio/German-RAG-ORPO-Alpaca-HESSIAN-AI.","url":"https://huggingface.co/datasets/avemio/German-RAG-ORPO-Alpaca-HESSIAN-AI","creator_name":"Avemio AG","creator_url":"https://huggingface.co/avemio","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["question-answering","summarization","German","English","mit"],"keywords_longer_than_N":true},
	{"name":"German-RAG-ORPO-Alpaca-HESSIAN-AI","keyword":"german","description":"\n\t\n\t\t\n\t\tGerman-RAG-ORPO (Odds Ratio Preference Optimization) Alpaca-Format\n\t\n\n\n\t\n\t\t\n\t\tGerman-RAG - German Retrieval Augmented Generation\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThe ORPO Tasks Dataset represents a specialized collection for fine-tuning language models with a focus on RAG-specific capabilities. \nThe subsets can be for this training step are derived from 2 different sources:\n\nSauerkrautLM Preference Datasets:\nSauerkrautLM-Fermented-GER-DPO:  is a specialized dataset designed for trainingâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/avemio/German-RAG-ORPO-Alpaca-HESSIAN-AI.","url":"https://huggingface.co/datasets/avemio/German-RAG-ORPO-Alpaca-HESSIAN-AI","creator_name":"Avemio AG","creator_url":"https://huggingface.co/avemio","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["question-answering","summarization","German","English","mit"],"keywords_longer_than_N":true},
	{"name":"solarsystem","keyword":"german","description":"\n\t\n\t\t\n\t\tMultilingual Solar System Planet Dataset\n\t\n\nThis dataset contains information about the eight primary planets in our solar system, presented in five languages: Indonesian, English, Spanish, French, and German.\n\n\t\n\t\t\n\t\tðŸª Dataset Overview\n\t\n\n\nEntries: 8 planets\nLanguages: Indonesian, English, Spanish, French, German\nAttributes:\nOrbital order from the Sun\nPlanet names in five languages\nDiameter (in km)\nDistance from the Sun (in million km)\nBrief description in five languagesâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/erisdataworks/solarsystem.","url":"https://huggingface.co/datasets/erisdataworks/solarsystem","creator_name":"Eris Dataworks","creator_url":"https://huggingface.co/erisdataworks","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["English","Indonesian","Spanish","German","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"ParaNames","keyword":"german","description":"\n\t\n\t\t\n\t\n\t\n\t\tDataset Card for Dataset Name\n\t\n\n\n\nThis dataset card aims to be a base template for new datasets. It has been generated using this raw template.\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Description\n\t\n\n\n\n\n\n\nCurated by: [More Information Needed]\nFunded by [optional]: [More Information Needed]\nShared by [optional]: [More Information Needed]\nLanguage(s) (NLP): [More Information Needed]\nLicense: [More Information Needed]\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Sources [optional]â€¦ See the full description on the dataset page: https://huggingface.co/datasets/bltlab/ParaNames.","url":"https://huggingface.co/datasets/bltlab/ParaNames","creator_name":"Broadening Linguistic Technologies Lab (BLT Lab)","creator_url":"https://huggingface.co/bltlab","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["token-classification","Nias","Kotava","Banjar","Angika"],"keywords_longer_than_N":true},
	{"name":"ParaNames","keyword":"swiss german","description":"\n\t\n\t\t\n\t\n\t\n\t\tDataset Card for Dataset Name\n\t\n\n\n\nThis dataset card aims to be a base template for new datasets. It has been generated using this raw template.\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Description\n\t\n\n\n\n\n\n\nCurated by: [More Information Needed]\nFunded by [optional]: [More Information Needed]\nShared by [optional]: [More Information Needed]\nLanguage(s) (NLP): [More Information Needed]\nLicense: [More Information Needed]\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Sources [optional]â€¦ See the full description on the dataset page: https://huggingface.co/datasets/bltlab/ParaNames.","url":"https://huggingface.co/datasets/bltlab/ParaNames","creator_name":"Broadening Linguistic Technologies Lab (BLT Lab)","creator_url":"https://huggingface.co/bltlab","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["token-classification","Nias","Kotava","Banjar","Angika"],"keywords_longer_than_N":true},
	{"name":"nn-auto-bench-ds","keyword":"german","description":"\n\t\n\t\t\n\t\tnn-auto-bench-ds\n\t\n\nnn-auto-bench-ds is a dataset designed for key information extraction (KIE) and serves as a benchmark dataset for nn-auto-bench.\n\n\t\n\t\t\n\t\tDataset Overview\n\t\n\nThe dataset comprises 1,000 documents, categorized into the following types:\n\nInvoice\nReceipt\nPassport\nBank Statement\n\nThe documents are primarily available in English, with some also in German and Arabic. Each document is annotated for key information extraction and specific tasks. The dataset can be used toâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/nanonets/nn-auto-bench-ds.","url":"https://huggingface.co/datasets/nanonets/nn-auto-bench-ds","creator_name":"Nanonets","creator_url":"https://huggingface.co/nanonets","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["question-answering","English","German","Arabic","mit"],"keywords_longer_than_N":true},
	{"name":"redblueai.sed","keyword":"german","description":"Ahiyan/redblueai.sed dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/Ahiyan/redblueai.sed","creator_name":"Ahiyan Kabir","creator_url":"https://huggingface.co/Ahiyan","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["question-answering","summarization","text-to-image","English","German"],"keywords_longer_than_N":true},
	{"name":"FalseFriendsDeEnPC","keyword":"german","description":"\n  FalseFriendsGermanEnglish\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nA dataset to identify False Friends / false cognates between English and German. A generally challenging task for multilingual models.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2t\n\n\nDomains\nWritten\nReference\nhttps://drive.google.com/file/d/1jgq0nBnV-UiYNxbKNrrr2gxDEHm-DMKH/view?usp=share_link\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mtebâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/FalseFriendsDeEnPC.","url":"https://huggingface.co/datasets/mteb/FalseFriendsDeEnPC","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","semantic-similarity-classification","human-annotated","monolingual","aari1995/false_friends_de_en_mteb"],"keywords_longer_than_N":true},
	{"name":"Wikipedia-Abstract","keyword":"german","description":"Wikipedia Abstract\n\n\n  \n\n\n\nIntroducing Wikipedia Abstract, a comprehensive dataset encompassing abstracts, complete articles, and a popularity score index for both widely spoken and lesser-known Wikipedia subsets. Our dedication to Wikipedia-X ensures a centralized Wikipedia dataset that undergoes regular updates and adheres to the highest standards.\nA central focus of our efforts was to include exotic languages that often lack up-to-date Wikipedia dumps or may not have any dumps at all.â€¦ See the full description on the dataset page: https://huggingface.co/datasets/laion/Wikipedia-Abstract.","url":"https://huggingface.co/datasets/laion/Wikipedia-Abstract","creator_name":"LAION eV","creator_url":"https://huggingface.co/laion","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","question-answering","text-generation","fill-mask","Arabic"],"keywords_longer_than_N":true},
	{"name":"xP3x-Kongo","keyword":"german","description":"\n\t\n\t\t\n\t\tDataset Card for xP3x Kikongo Focus\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\n\nxP3x (Crosslingual Public Pool of Prompts eXtended) is a collection of prompts & datasets across 277 languages & 16 NLP tasks. It contains all of xP3 + much more! It is used for training future contenders of mT0 & BLOOMZ at project Aya @C4AI ðŸ§¡\n\n\nCreation: The dataset can be recreated using instructions available here together with the file in this repository named xp3x_create.py. We provide this version to saveâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Svngoku/xP3x-Kongo.","url":"https://huggingface.co/datasets/Svngoku/xP3x-Kongo","creator_name":"NIONGOLO Chrys FÃ©-Marty","creator_url":"https://huggingface.co/Svngoku","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["other","translation","expert-generated","crowdsourced","multilingual"],"keywords_longer_than_N":true},
	{"name":"cv-22-de","keyword":"german","description":"German split of Common Voice 22. cc0 license\n","url":"https://huggingface.co/datasets/fidoriel/cv-22-de","creator_name":"fidoriel","creator_url":"https://huggingface.co/fidoriel","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","German","cc0-1.0","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"data-kit-sub-iwslt2025-if-long-constraint","keyword":"german","description":"\n\t\n\t\t\n\t\tData for KITâ€™s Instruction Following Submission for IWSLT 2025\n\t\n\nThis repo contains the data used to train our model for IWSLT 2025's Instruction-Following (IF) Speech Processing track.\nIWSLT 2025's Instruction-Following (IF) Speech Processing track in the scientific domain aims to benchmark foundation models that can follow natural \nlanguage instructionsâ€”an ability well-established in textbased LLMs but still emerging in speech-based counterparts. Our approach employs an end-to-endâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/maikezu/data-kit-sub-iwslt2025-if-long-constraint.","url":"https://huggingface.co/datasets/maikezu/data-kit-sub-iwslt2025-if-long-constraint","creator_name":"Maike ZÃ¼fle","creator_url":"https://huggingface.co/maikezu","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","summarization","question-answering","translation","English"],"keywords_longer_than_N":true},
	{"name":"CircuitSketchTextAnnotations","keyword":"german","description":"edesaras/CircuitSketchTextAnnotations dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/edesaras/CircuitSketchTextAnnotations","creator_name":"Aras EdeÅŸ","creator_url":"https://huggingface.co/edesaras","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["image-to-text","English","German","mit","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"voices-of-civilizations","keyword":"german","description":"\n\t\n\t\t\n\t\tVoices of Civilizations (VoC)\n\t\n\nVoices of Civilizations (VoC) is the first multilingual QA benchmark designed to assess audio LLMsâ€™ cultural comprehension using full-length music recordings. VoC spans:\n\n38 languages ðŸ‡¸ðŸ‡¦ Arabic (ar), ðŸ‡§ðŸ‡© Bengali (bn), ðŸ‡§ðŸ‡¬ Bulgarian (bg), ðŸ‡¨ðŸ‡³ Chinese (zh), ðŸ‡­ðŸ‡· Croatian (hr), ðŸ‡¨ðŸ‡¿ Czech (cs), ðŸ‡©ðŸ‡° Danish (da), ðŸ‡³ðŸ‡± Dutch (nl), ðŸ‡¬ðŸ‡§ English (en), ðŸ‡ªðŸ‡ª Estonian (et), ðŸ‡«ðŸ‡® Finnish (fi), ðŸ‡«ðŸ‡· French (fr), ðŸ‡©ðŸ‡ª German (de), ðŸ‡¬ðŸ‡· Greek (el), ðŸ‡®ðŸ‡± Hebrewâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/sander-wood/voices-of-civilizations.","url":"https://huggingface.co/datasets/sander-wood/voices-of-civilizations","creator_name":"Shangda Wu (Sander Wood)","creator_url":"https://huggingface.co/sander-wood","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["question-answering","Arabic","Bengali","Bulgarian","Chinese"],"keywords_longer_than_N":true},
	{"name":"wikipedia-citation-index","keyword":"german","description":"Dataset with citation indexes as of 1 August 2024 for 47 million Wikipedia articles in 55 language versions. Research: ArXiv\n","url":"https://huggingface.co/datasets/lewoniewski/wikipedia-citation-index","creator_name":"WÅ‚odzimierz Lewoniewski","creator_url":"https://huggingface.co/lewoniewski","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["Arabic","Azerbaijani","Belarusian","Bulgarian","Catalan"],"keywords_longer_than_N":true},
	{"name":"PearlDiver","keyword":"german","description":"Listing of the >7k books I've read recently. Some claim it's actually data scraped from website Perlentaucher. Which you believe is up to you, but here's a video of my occasional reading activity (haters gonna say it's fake).\n\n\n\t\n\t\t\n\t\tDataset card\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe data set contains information of books that have been reviewed at least once. \nThe reviews are received from reputable German print media such as the Frankfurter Allgemeine Zeitung (FAZ), SÃ¼ddeutsche Zeitung (SZ)â€¦ See the full description on the dataset page: https://huggingface.co/datasets/JoaoSchneider/PearlDiver.","url":"https://huggingface.co/datasets/JoaoSchneider/PearlDiver","creator_name":"Joao Schneider","creator_url":"https://huggingface.co/JoaoSchneider","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["German","cc-by-4.0","10K - 100K","parquet","Tabular"],"keywords_longer_than_N":true},
	{"name":"synthetic_social_media_fitness-bodyshaming-bodypositivity_german","keyword":"german","description":"This dataset consists of syntetic Social Media Posts generated with ChatGPT (gpt-5) and K!mpuls (gpt-o4-mini). The topics of the posts are fitness, bodyimage, sports, health and nutrition.\nThe data has the following categories:\n\nneutral (neutral posts about fitness ect.)\n\"kÃ¶rperbild-gefÃ¤hrdend\" (potentially harmful content for unhealth bodyimage)\n\"essstÃ¶rungsfÃ¶rdernd\" (contributing to eating disorders)\n\"bodypositivity\" (contributing to positive bodyimage)\n\n","url":"https://huggingface.co/datasets/plaufer/synthetic_social_media_fitness-bodyshaming-bodypositivity_german","creator_name":"Pauline","creator_url":"https://huggingface.co/plaufer","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","German","mit","1K - 10K","csv"],"keywords_longer_than_N":true},
	{"name":"fact-or-opinion","keyword":"german","description":"agentlans/fact-or-opinion dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/agentlans/fact-or-opinion","creator_name":"Alan Tseng","creator_url":"https://huggingface.co/agentlans","license_name":"Open Data Commons Attribution License v1.0","license_url":"https://scancode-licensedb.aboutcode.org/odc-by-1.0.html","language":"en","first_N":5,"first_N_keywords":["text-classification","Amharic","Arabic","Bengali","German"],"keywords_longer_than_N":true},
	{"name":"Text-Moderation-Multilingual","keyword":"german","description":"\n\t\n\t\t\n\t\tText-Moderation-Multilingual\n\t\n\nA comprehensive multilingual text moderation dataset combining multiple high-quality sources for training robust content moderation classifiers.\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset aggregates text moderation data from multiple sources to create a large-scale, diverse training corpus for content moderation systems. It includes text samples labeled across multiple harmful content categories, supporting both multilingual and English-specific moderationâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/KoalaAI/Text-Moderation-Multilingual.","url":"https://huggingface.co/datasets/KoalaAI/Text-Moderation-Multilingual","creator_name":"Koala AI","creator_url":"https://huggingface.co/KoalaAI","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","English","German","French","Spanish"],"keywords_longer_than_N":true},
	{"name":"germanquad-retrieval","keyword":"german","description":"\n  GermanQuAD-Retrieval\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nContext Retrieval for German Question Answering\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2t\n\n\nDomains\nWritten, Non-fiction, Web\n\n\nReference\nhttps://huggingface.co/datasets/deepset/germanquad\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask = mteb.get_tasks([\"GermanQuAD-Retrieval\"])\nevaluator = mteb.MTEB(task)\n\nmodel =â€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/germanquad-retrieval.","url":"https://huggingface.co/datasets/mteb/germanquad-retrieval","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","multiple-choice-qa","human-annotated","monolingual","German"],"keywords_longer_than_N":true},
	{"name":"eurlex-small-dump","keyword":"german","description":"\n\t\n\t\t\n\t\tGerman Case Law Dump\n\t\n\nThis dataset contains 3,358 documents of European court decisions (as of July 31, 2025) collected from the EUR-Lex website.  \n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\nThe dataset is provided in JSONL (JSON Lines) format.  \nEach line represents a single case law.\n\n\n\t\n\t\t\n\t\tFeatures\n\t\n\nEach JSON object contains the following fields:\n\nTitel: Title of the legal document  \nUntertitel: Subtitle, if available  \nCELEX-Nummer: Unique identifier in the CELEX databaseâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/elenanereiss/eurlex-small-dump.","url":"https://huggingface.co/datasets/elenanereiss/eurlex-small-dump","creator_name":"Elena Leitner","creator_url":"https://huggingface.co/elenanereiss","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["fill-mask","German","cc0-1.0","1K - 10K","json"],"keywords_longer_than_N":true},
	{"name":"eurlex-small-dump","keyword":"german","description":"\n\t\n\t\t\n\t\tGerman Case Law Dump\n\t\n\nThis dataset contains 3,358 documents of European court decisions (as of July 31, 2025) collected from the EUR-Lex website.  \n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\nThe dataset is provided in JSONL (JSON Lines) format.  \nEach line represents a single case law.\n\n\n\t\n\t\t\n\t\tFeatures\n\t\n\nEach JSON object contains the following fields:\n\nTitel: Title of the legal document  \nUntertitel: Subtitle, if available  \nCELEX-Nummer: Unique identifier in the CELEX databaseâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/elenanereiss/eurlex-small-dump.","url":"https://huggingface.co/datasets/elenanereiss/eurlex-small-dump","creator_name":"Elena Leitner","creator_url":"https://huggingface.co/elenanereiss","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["fill-mask","German","cc0-1.0","1K - 10K","json"],"keywords_longer_than_N":true},
	{"name":"DataMix","keyword":"german","description":"this dataset is a mix of of some datasets available on huggingface for text-to-text generation, it's not cleaned, it's not deduplicated.\nIt's not recommend to use it in it's current state.\nas the higghest restriction counts, it's only for private and research usable - it's not allowed to create an competitive model to \"whatever\".\nNever use it for commercial purposes describes it for all Datasets in this repository.\n","url":"https://huggingface.co/datasets/emogie3D/DataMix","creator_name":"Andreas","creator_url":"https://huggingface.co/emogie3D","license_name":"Academic Free License v3.0","license_url":"https://choosealicense.com/licenses/afl-3.0/","language":"en","first_N":5,"first_N_keywords":["English","German","afl-3.0","10M - 100M","parquet"],"keywords_longer_than_N":true},
	{"name":"thinking-multilingual-30-23-small-690","keyword":"german","description":"\nBased on OPENO1 math, this is a translated dataset of 30 high quality questions & answers in 23 languages. \nOr use the \"big\" version: big 10k rows version\n","url":"https://huggingface.co/datasets/Pinkstack/thinking-multilingual-30-23-small-690","creator_name":"Pinkstack","creator_url":"https://huggingface.co/Pinkstack","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","Arabic","Chinese","Czech","Danish"],"keywords_longer_than_N":true},
	{"name":"M4U","keyword":"german","description":"\n\t\n\t\t\n\t\tM4U: Evaluating Multilingual Understanding and Reasoning for Large Multimodal Models\n\t\n\nCode for the Paper M4U: Evaluating Multilingual Understanding and Reasoning for Large Multimodal Models.\n[Webpage] [Paper] [Huggingface Dataset] [Leaderboard]\n\n\t\n\t\t\n\t\n\t\n\t\tðŸ’¥ News ðŸ’¥\n\t\n\n\n[2024.05.23] Our paper, dataset and code are public aviailable.\n\n\n\t\n\t\n\t\n\t\tðŸ‘€ About M4U\n\t\n\n\n     \n\n\nMultilingual multimodal reasoning is a core component to achieve human-level intelligence. However, most of theâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/M4U-Benchmark/M4U.","url":"https://huggingface.co/datasets/M4U-Benchmark/M4U","creator_name":"M4U-Benchmark","creator_url":"https://huggingface.co/M4U-Benchmark","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["visual-question-answering","English","Chinese","German","mit"],"keywords_longer_than_N":true},
	{"name":"multilingual-speech-commands-15lang","keyword":"german","description":"\n\t\n\t\t\n\t\tMultilingual Speech Commands Dataset (15 Languages, Augmented)\n\t\n\nThis dataset contains augmented speech command samples in 15 languages, derived from multiple public datasets. Only commands that overlap with the Google Speech Commands (GSC) vocabulary are included, making the dataset suitable for multilingual keyword spotting tasks aligned with GSC-style classification.\nAudio samples have been augmented using standard audio techniques to improve model robustness (e.g., time-shiftingâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/artur-muratov/multilingual-speech-commands-15lang.","url":"https://huggingface.co/datasets/artur-muratov/multilingual-speech-commands-15lang","creator_name":"Artur Muratov","creator_url":"https://huggingface.co/artur-muratov","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["English","Russian","Kazakh","Tatar","Arabic"],"keywords_longer_than_N":true},
	{"name":"NewsEye-Austrian-line","keyword":"german","description":"\n\t\n\t\t\n\t\tNewsEye Austrian - line level\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThe dataset comprises Austrian newspaper pages from 19th and early 20th century. The images were provided by the Austrian National Library.\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nThe documents are in Austrian German with the Fraktur font.\nNote that all images are resized to a fixed height of 128 pixels.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\n\t\n\t\t\n\t\tData Instances\n\t\n\n{\n  'image': <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=4300x128 atâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Teklia/NewsEye-Austrian-line.","url":"https://huggingface.co/datasets/Teklia/NewsEye-Austrian-line","creator_name":"Teklia","creator_url":"https://huggingface.co/Teklia","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["image-to-text","German","mit","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"OGC_Cooking_Recipes","keyword":"german","description":"\n\t\n\t\t\n\t\tOGC_Cooking_Recipes - Overview\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nOGC_Cooking_Recipes is a curated multimodal dataset focused on cooking recipe documents, culinary guides, and food preparation instructions. It combines text and image data extracted from real culinary PDFs to support tasks such as RAG DSE, question answering, document search, and vision-language model training.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\tDataset Creation\n\t\n\nThis dataset was created using our open-source toolâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/racineai/OGC_Cooking_Recipes.","url":"https://huggingface.co/datasets/racineai/OGC_Cooking_Recipes","creator_name":"racine.ai","creator_url":"https://huggingface.co/racineai","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["visual-document-retrieval","text-retrieval","English","French","Chinese"],"keywords_longer_than_N":true},
	{"name":"actuarial-global-glossary-multilingual","keyword":"german","description":"\n  \n\n\n\n  \n\n\n\t\n\t\t\n\t\tðŸ¤ Connect with me on LinkedIn!\n\t\n\n  \n  Join the mission to make actuarial knowledge accessible worldwide\n  Let's discuss how AI can transform professional education and break language barriers in finance!\n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tðŸŒ Global Actuarial Glossary - Breaking Language Barriers in Finance\n\t\n\n\n\n\n\n\n\t\n\t\t\n\t\tðŸš€ The World's Most Comprehensive Multilingual Actuarial Dataset\n\t\n\nImagine: A brilliant actuarial student in Tokyo, a risk analyst in SÃ£o Paulo, and an insurance executiveâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/manuelcaccone/actuarial-global-glossary-multilingual.","url":"https://huggingface.co/datasets/manuelcaccone/actuarial-global-glossary-multilingual","creator_name":"Manuel Caccone","creator_url":"https://huggingface.co/manuelcaccone","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","translation","text-generation","question-answering","multi-class-classification"],"keywords_longer_than_N":true},
	{"name":"reranking-datasets-light","keyword":"german","description":"\n\t\n\t\t\n\t\tðŸ”¥ Rankify: A Comprehensive Python Toolkit for Retrieval, Re-Ranking, and Retrieval-Augmented Generation ðŸ”¥\n\t\n\n\n\t\n\t\t\n\t\n\t\n\t\tReRanking Datasets : A comprehensive collection of retrieval and reranking datasets with full passage contexts, including titles, text, and metadata for in-depth research.\n\t\n\n\n    \n    \n    \n    \n    \n    \n        \n    \n    \n        \n    \n    \n        \n    \n    \n        \n    \n    \n    \n\n\n\nA curated collection of ready-to-use datasets for retrieval and rerankingâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/abdoelsayed/reranking-datasets-light.","url":"https://huggingface.co/datasets/abdoelsayed/reranking-datasets-light","creator_name":"Abdelrahman Abdallah","creator_url":"https://huggingface.co/abdoelsayed","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["question-answering","English","Arabic","German","French"],"keywords_longer_than_N":true},
	{"name":"gsm-1k-de","keyword":"german","description":"\n\t\n\t\t\n\t\tGSM 1k DE\n\t\n\nGSM-1k-de is a translated(english -> german) subset of the first 1000 items of GSM8K\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nThe text in the dataset is in german. The associated BCP-47 code is de.\n\n\t\n\t\t\n\t\tStructure\n\t\n\nEach instance contains a string for the grade-school level math question and a string for the corresponding answer with multiple steps of reasoning and calculator annotations.\n{\n  \"question\": \"Natalie ...\",\n  \"answer\": \"Natalie ...\"\n}\n\nquestion: The question string to a gradeâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/D4ve-R/gsm-1k-de.","url":"https://huggingface.co/datasets/D4ve-R/gsm-1k-de","creator_name":"David","creator_url":"https://huggingface.co/D4ve-R","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["question-answering","text2text-generation","German","mit","< 1K"],"keywords_longer_than_N":true},
	{"name":"AyaVisionBench","keyword":"german","description":"\n\t\n\t\t\n\t\tDataset Card for Aya Vision Benchmark\n\t\n\n\n\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\nThe Aya Vision Benchmark is designed to evaluate vision-language models in real-world multilingual scenarios. It spans 23 languages and 9 distinct task categories, with 15 samples per category, resulting in 135 image-question pairs per language. \nEach question requires visual context for the answer and covers languages that half of the world's population speaks, making this dataset particularly suited forâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/CohereLabs/AyaVisionBench.","url":"https://huggingface.co/datasets/CohereLabs/AyaVisionBench","creator_name":"Cohere Labs","creator_url":"https://huggingface.co/CohereLabs","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["English","French","German","Spanish","Italian"],"keywords_longer_than_N":true},
	{"name":"BenchMAX_Multiple_Functions","keyword":"german","description":"\n\t\n\t\t\n\t\tDataset Sources\n\t\n\n\nPaper: BenchMAX: A Comprehensive Multilingual Evaluation Suite for Large Language Models\nLink: https://huggingface.co/papers/2502.07346\nRepository: https://github.com/CONE-MT/BenchMAX\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nBenchMAX_Multiple_Functions is a dataset of BenchMAX, sourcing from Nexus.\nThis dataset evaluates the tool use capability in multilingual senarios, which requires a model to call the correct function given the user query and multiple functions.\nWeâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/LLaMAX/BenchMAX_Multiple_Functions.","url":"https://huggingface.co/datasets/LLaMAX/BenchMAX_Multiple_Functions","creator_name":"LLaMAX","creator_url":"https://huggingface.co/LLaMAX","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","multilingual","English","Chinese","Spanish"],"keywords_longer_than_N":true},
	{"name":"undl_de2en_aligned","keyword":"german","description":"\n\t\n\t\t\n\t\tDataset Card for \"undl_de2en_aligned\"\n\t\n\nMore Information needed\n","url":"https://huggingface.co/datasets/bot-yaya/undl_de2en_aligned","creator_name":"yaya","creator_url":"https://huggingface.co/bot-yaya","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["translation","German","English","mit","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"include-base-44","keyword":"german","description":"\n\t\n\t\t\n\t\tINCLUDE-base (44 languages)\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\n\n\nPaper: http://arxiv.org/abs/2411.19799\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nINCLUDE is a comprehensive knowledge- and reasoning-centric benchmark across 44 languages that evaluates multilingual LLMs for performance in the actual language environments where they would be deployed. \nIt contains 22,637 4-option multiple-choice-questions (MCQ) extracted from academic and professional exams, covering 57 topics, including regionalâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/CohereLabs/include-base-44.","url":"https://huggingface.co/datasets/CohereLabs/include-base-44","creator_name":"Cohere Labs","creator_url":"https://huggingface.co/CohereLabs","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["multiple-choice","Albanian","Arabic","Armenian","Azerbaijani"],"keywords_longer_than_N":true},
	{"name":"instruct-snippet-mlsum","keyword":"german","description":"\n\t\n\t\t\n\t\tDataset Card for Instruct-Snippet-MLSUM-500\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis is a dataset for multitask instruction finetuning dataset for the task of news snippet generation. It is built from a sample of ~500 news articles from the MLSUM dataset, augmented with machine generated news snippets.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThis dataset was created to support the task of generating news snippets such as title, teaser, keywords, serp and tweet for news articles in German language.â€¦ See the full description on the dataset page: https://huggingface.co/datasets/snipaid/instruct-snippet-mlsum.","url":"https://huggingface.co/datasets/snipaid/instruct-snippet-mlsum","creator_name":"SnipAId","creator_url":"https://huggingface.co/snipaid","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["summarization","German","mit","1K - 10K","csv"],"keywords_longer_than_N":true},
	{"name":"cvss","keyword":"german","description":"CVSS is a massively multilingual-to-English speech-to-speech translation corpus,\ncovering sentence-level parallel speech-to-speech translation pairs from 21\nlanguages into English.","url":"https://huggingface.co/datasets/google/cvss","creator_name":"Google","creator_url":"https://huggingface.co/google","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":null,"first_N":5,"first_N_keywords":["English","Arabic","Catalan","Welsh","German"],"keywords_longer_than_N":true},
	{"name":"DIDI","keyword":"german","description":"PeepDaSlan9/DIDI dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/PeepDaSlan9/DIDI","creator_name":"Ohenenoo","creator_url":"https://huggingface.co/PeepDaSlan9","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":null,"first_N":5,"first_N_keywords":["text-classification","table-question-answering","question-answering","translation","summarization"],"keywords_longer_than_N":true},
	{"name":"Pornhub","keyword":"german","description":"\n\t\n\t\t\n\t\tPornhub Dataset\n\t\n\nThe Pornhub Dataset provides a comprehensive collection of data sourced from pornhub.com, encompassing various details from MANYYY videos available on the platform.\nThe file consists of 742.133 lines of videos.\n\n\t\n\t\t\n\t\tData Description\n\t\n\n\nDelimiter: â€½\nFile Format: CSV\nContent:\nURL: The URL of the video.\nCategory: The genre or category of the video.\nUser: The username of the uploader.\nVideo_title: The title of the video.\nViews: The number of views the video hasâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Nikity/Pornhub.","url":"https://huggingface.co/datasets/Nikity/Pornhub","creator_name":"Nikita","creator_url":"https://huggingface.co/Nikity","license_name":"Open Data Commons Attribution License v1.0","license_url":"https://scancode-licensedb.aboutcode.org/odc-by-1.0.html","language":"en","first_N":5,"first_N_keywords":["Albanian","Arabic","Bengali","Bulgarian","Chinese"],"keywords_longer_than_N":true},
	{"name":"xtreme","keyword":"german","description":"\n\t\n\t\t\n\t\tDataset Card for \"xtreme\"\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThe Cross-lingual Natural Language Inference (XNLI) corpus is a crowd-sourced collection of 5,000 test and\n2,500 dev pairs for the MultiNLI corpus. The pairs are annotated with textual entailment and translated into\n14 languages: French, Spanish, German, Greek, Bulgarian, Russian, Turkish, Arabic, Vietnamese, Thai, Chinese,\nHindi, Swahili and Urdu. This results in 112.5k annotated pairs. Each premise can be associated with theâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/google/xtreme.","url":"https://huggingface.co/datasets/google/xtreme","creator_name":"Google","creator_url":"https://huggingface.co/google","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["multiple-choice","question-answering","token-classification","text-classification","text-retrieval"],"keywords_longer_than_N":true},
	{"name":"gutenberg_multilang","keyword":"german","description":"\n\t\n\t\t\n\t\tDataset Card for Project Gutenber - Multilanguage eBooks\n\t\n\nA collection of non-english language eBooks (7907, about 75-80% of all the ES, DE, FR, NL, IT, PT, HU books available on the site) from the Project Gutenberg site with metadata removed. \nOriginally colected for https://github.com/LAION-AI/Open-Assistant\n\n\t\n\t\t\nLANG\nEBOOKS\n\n\n\t\t\nES\n717\n\n\nDE\n1735\n\n\nFR\n2863\n\n\nNL\n904\n\n\nIT\n692\n\n\nPT\n501\n\n\nHU\n495\n\n\n\t\n\nThe METADATA column contains catalogue meta information on each book as a serializedâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/sedthh/gutenberg_multilang.","url":"https://huggingface.co/datasets/sedthh/gutenberg_multilang","creator_name":"Richard Nagyfi","creator_url":"https://huggingface.co/sedthh","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-generation","Spanish","German","French","Dutch"],"keywords_longer_than_N":true},
	{"name":"para_pat","keyword":"german","description":"ParaPat: The Multi-Million Sentences Parallel Corpus of Patents Abstracts\n\nThis dataset contains the developed parallel corpus from the open access Google\nPatents dataset in 74 language pairs, comprising more than 68 million sentences\nand 800 million tokens. Sentences were automatically aligned using the Hunalign algorithm\nfor the largest 22 language pairs, while the others were abstract (i.e. paragraph) aligned.","url":"https://huggingface.co/datasets/ParaPat/para_pat","creator_name":"ParaPat","creator_url":"https://huggingface.co/ParaPat","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":null,"first_N":5,"first_N_keywords":["text-generation","fill-mask","translation","language-modeling","masked-language-modeling"],"keywords_longer_than_N":true},
	{"name":"tatoeba_mt","keyword":"german","description":"The Tatoeba Translation Challenge is a multilingual data set of\nmachine translation benchmarks derived from user-contributed\ntranslations collected by [Tatoeba.org](https://tatoeba.org/) and\nprovided as parallel corpus from [OPUS](https://opus.nlpl.eu/). This\ndataset includes test and development data sorted by language pair. It\nincludes test sets for hundreds of language pairs and is continuously\nupdated. Please, check the version number tag to refer to the release\nthat your are using.","url":"https://huggingface.co/datasets/Helsinki-NLP/tatoeba_mt","creator_name":"Language Technology Research Group at the University of Helsinki","creator_url":"https://huggingface.co/Helsinki-NLP","license_name":"Creative Commons Attribution 2.0","license_url":"https://scancode-licensedb.aboutcode.org/cc-by-2.0.html","language":null,"first_N":5,"first_N_keywords":["text-generation","translation","no-annotation","crowdsourced","translation"],"keywords_longer_than_N":true},
	{"name":"RotoWire_English-German","keyword":"german","description":"Dataset for the WNGT 2019 DGT shared task on \"Document-Level Generation and Translationâ€.","url":"https://huggingface.co/datasets/GEM/RotoWire_English-German","creator_name":"GEM benchmark","creator_url":"https://huggingface.co/GEM","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["table-to-text","automatically-created","unknown","unknown","original"],"keywords_longer_than_N":true},
	{"name":"multilexnorm","keyword":"german","description":"For this task, participants are asked to develop a system that performs lexical normalization: the conversion of non-canonical texts to their canonical equivalent form. In particular, this task includes data from 12 languages.","url":"https://huggingface.co/datasets/larrylawl/multilexnorm","creator_name":"Law Ann Liat Larry","creator_url":"https://huggingface.co/larrylawl","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":null,"first_N":5,"first_N_keywords":["text-generation","English","Danish","German","Spanish"],"keywords_longer_than_N":true},
	{"name":"tweetyface","keyword":"german","description":"Dataset containing Tweets from prominent Twitter Users in various languages. The dataset has been created utilizing a crawler for the Twitter API.\\n \\","url":"https://huggingface.co/datasets/ML-Projects-Kiel/tweetyface","creator_name":"Machine Learning Projects FH Kiel","creator_url":"https://huggingface.co/ML-Projects-Kiel","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","machine-generated","crowdsourced","multilingual","English"],"keywords_longer_than_N":true},
	{"name":"PsiloQA","keyword":"german","description":"\n\n\t\n\t\t\n\t\tWhat is it?\n\t\n\nPsiloQA is the largest dataset for training and evaluating systems on multilingual span-level hallucination detection with retrieved context. It offers:\n\nAn automated and scalable pipeline for generating, annotating and filtering data for hallucination detection task\nA large multilingual dataset for 14 languages with high-quality and fine-grained span-level hallucination annotations for numerous open-source LLMs\nA comprehensive empirical evaluations of variousâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/s-nlp/PsiloQA.","url":"https://huggingface.co/datasets/s-nlp/PsiloQA","creator_name":"s-nlp","creator_url":"https://huggingface.co/s-nlp","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["token-classification","text-classification","text-generation","zero-shot-classification","question-answering"],"keywords_longer_than_N":true},
	{"name":"common_voice_16_0","keyword":"german","description":"\n\t\n\t\t\n\t\tDataset Card for Common Voice Corpus 16.0\n\t\n\n\n\nThis dataset is an unofficial version of the Mozilla Common Voice Corpus 16. It was downloaded and converted from the project's website https://commonvoice.mozilla.org/.\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nAbkhaz, Albanian, Amharic, Arabic, Armenian, Assamese, Asturian, Azerbaijani, Basaa, Bashkir, Basque, Belarusian, Bengali, Breton, Bulgarian, Cantonese, Catalan, Central Kurdish, Chinese (China), Chinese (Hong Kong), Chinese (Taiwan), Chuvash, Czechâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fsicoli/common_voice_16_0.","url":"https://huggingface.co/datasets/fsicoli/common_voice_16_0","creator_name":"Fabio Sicoli","creator_url":"https://huggingface.co/fsicoli","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":null,"first_N":5,"first_N_keywords":["automatic-speech-recognition","Abkhaz","Afrikaans","Amharic","Arabic"],"keywords_longer_than_N":true},
	{"name":"DocNMT","keyword":"german","description":"\n\t\n\t\t\n\t\tDataset Card for Dataset Name\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThe benchmark datasets for document-level machine translation.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nDocument-level Machine Translation Tasks.\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nEnglish-German\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\n\t\n\t\t\n\t\tData Instances\n\t\n\nTED: iwslt17, News: nc2016, Europarl: europarl7\n\n\t\n\t\t\n\t\tData Fields\n\t\n\nPure text that each line represents a sentence and multiple lines separated by '<d>' line form a document.\n\n\t\n\t\t\n\t\tData Splits\n\t\n\ntrainâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/gshbao/DocNMT.","url":"https://huggingface.co/datasets/gshbao/DocNMT","creator_name":"Guangsheng Bao","creator_url":"https://huggingface.co/gshbao","license_name":"Academic Free License v3.0","license_url":"https://choosealicense.com/licenses/afl-3.0/","language":"en","first_N":5,"first_N_keywords":["translation","English","German","afl-3.0","1M - 10M"],"keywords_longer_than_N":true},
	{"name":"mdk_gov_data_titles_clf","keyword":"german","description":"\n\t\n\t\t\n\t\tDataset Card for MDK\n\t\n\nThis dataset was created as part of the Bertelsmann Foundation's \nMusterdatenkatalog (MDK) project. The MDK provides an overview of Open Data in municipalities in Germany. It is intended to help municipalities in Germany, as well as data analysts and journalists, to get an overview of the topics and the extent to which cities have already published data sets.\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Description\n\t\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThe dataset is an annotated corpus ofâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/and-effect/mdk_gov_data_titles_clf.","url":"https://huggingface.co/datasets/and-effect/mdk_gov_data_titles_clf","creator_name":"&effect data solutions GmbH","creator_url":"https://huggingface.co/and-effect","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","monolingual","extended","German","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"instruct-snippet-mlsum-v2","keyword":"german","description":"\n\t\n\t\t\n\t\tDataset Card for Instruct-Snippet-MLSUM-500-V2\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis is a dataset for multitask instruction finetuning dataset for the task of news snippet generation. It is built from a sample of ~500 news articles from the MLSUM dataset, augmented with machine generated news snippets.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\nThis dataset was created to support the task of generating news snippets such as title, teaser, summary, keywords, serp and tweet for news articles in Germanâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/snipaid/instruct-snippet-mlsum-v2.","url":"https://huggingface.co/datasets/snipaid/instruct-snippet-mlsum-v2","creator_name":"SnipAId","creator_url":"https://huggingface.co/snipaid","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["summarization","German","mit","1K - 10K","csv"],"keywords_longer_than_N":true},
	{"name":"Mietvertraege","keyword":"german","description":"ulajessen/Mietvertraege dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/ulajessen/Mietvertraege","creator_name":"Urszula Jessen","creator_url":"https://huggingface.co/ulajessen","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["German","English","mit","ðŸ‡ºðŸ‡¸ Region: US"],"keywords_longer_than_N":false},
	{"name":"openassistant-deepseek-coder","keyword":"german","description":"\n\t\n\t\t\n\t\tChat Fine-tuning Dataset - OpenAssistant DeepSeek Coder\n\t\n\nThis dataset allows for fine-tuning chat models using:\nB_INST = '\\n### Instruction:\\n'\nE_INST = '\\n### Response:\\n'\nBOS = '<ï½œbeginâ–ofâ–sentenceï½œ>'\nEOS = '\\n<|EOT|>\\n'\n\nSample Preparation:\n\nThe dataset is cloned from TimDettmers, which itself is a subset of the Open Assistant dataset, which you can find here. This subset of the data only contains the highest-rated paths in the conversation tree, with a total of 9,846 samples.\nTheâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Trelis/openassistant-deepseek-coder.","url":"https://huggingface.co/datasets/Trelis/openassistant-deepseek-coder","creator_name":"Trelis","creator_url":"https://huggingface.co/Trelis","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["English","Spanish","Russian","German","Polish"],"keywords_longer_than_N":true},
	{"name":"intensified-phoenix-14-t","keyword":"german","description":"\n\t\n\t\t\n\t\tIntensified PHOENIX 14-T German Sign Language Dataset\n\t\n\n\n\nThis is a German-to-German Sign Language (DGS) dataset of weather forecasts. It is a prosodically-enhanced version of the RWTH-PHOENIX-Weather-2014T dataset.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\n\n\n\nCurated by: [Mert Inan]\nLanguage(s) (NLP): German, DGS (German Sign Language)\n\n\n\t\n\t\t\n\t\tDataset Sources [optional]\n\t\n\n\nRepository: Modeling Intensification for Sign Language Generation\nPaper: Modelingâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/merterm/intensified-phoenix-14-t.","url":"https://huggingface.co/datasets/merterm/intensified-phoenix-14-t","creator_name":"Mert Inan","creator_url":"https://huggingface.co/merterm","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-generation","German","mit","10K - 100K","csv"],"keywords_longer_than_N":true},
	{"name":"xtreme_s","keyword":"german","description":"XTREME-S covers four task families: speech recognition, classification, speech-to-text translation and retrieval. Covering 102\nlanguages from 10+ language families, 3 different domains and 4\ntask families, XTREME-S aims to simplify multilingual speech\nrepresentation evaluation, as well as catalyze research in â€œuniversalâ€ speech representation learning.","url":"https://huggingface.co/datasets/google/xtreme_s","creator_name":"Google","creator_url":"https://huggingface.co/google","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":null,"first_N":5,"first_N_keywords":["automatic-speech-recognition","expert-generated","crowdsourced","machine-generated","crowdsourced"],"keywords_longer_than_N":true},
	{"name":"SLR-Bench-German","keyword":"german","description":" \n\n\n\t\n\t\t\n\t\tðŸ§  SLR-Bench-German: Scalable Logical Reasoning Benchmark (German Edition)\n\t\n\n\n\n\n\nSLR-Bench-German is the German-language pendant of the original SLR-Bench dataset.\nIt follows the same symbolic structure, evaluation framework, and curriculum as the English version but provides all natural-language task prompts translated into German.\nThis enables systematic evaluation and training of Large Language Models (LLMs) in logical reasoning in german, supporting both multilingual reasoningâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/AIML-TUDA/SLR-Bench-German.","url":"https://huggingface.co/datasets/AIML-TUDA/SLR-Bench-German","creator_name":"Artificial Intelligence & Machine Learning Lab at TU Darmstadt","creator_url":"https://huggingface.co/AIML-TUDA","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["German","cc-by-4.0","10K - 100K","parquet","Tabular"],"keywords_longer_than_N":true},
	{"name":"super_eurlex","keyword":"german","description":"Super-EURLEX dataset containing legal documents from multiple languages.\n                The datasets are build/scrapped from the EURLEX Website [https://eur-lex.europa.eu/homepage.html]\n                With one split per language and sector, because the available features (metadata) differs for each \n                sector. Therefore, each sample contains the content of a full legal document in up to 3 different \n                formats. Those are raw HTML and cleaned HTML (if the HTML format was available on the EURLEX website \n                during the scrapping process) and cleaned text.\n                The cleaned text should be available for each sample and was extracted from HTML or PDF.\n                'Cleaned' HTML stands here for minor cleaning that was done to preserve to a large extent the necessary \n                HTML information like table structures while removing unnecessary complexity which was introduced to the \n                original documents due to actions like writing each sentence into a new object. \n                Additionally, each sample contains metadata which was scrapped on the fly, this implies the following \n                2 things. First, not every sector contains the same metadata. Second, most metadata might be \n                irrelevant for most use cases. \n                In our minds the most interesting metadata is the celex-id which is used to identify the legal \n                document at hand, but also contains a lot of information about the document \n                see [https://eur-lex.europa.eu/content/tools/eur-lex-celex-infographic-A3.pdf] as well as eurovoc-\n                concepts, which are labels that define the content of the documents. \n                Eurovoc-Concepts are, for example, only available for the sectors 1, 2, 3, 4, 5, 6, 9, C, and E.\n                The Naming of most metadata is kept like it was on the eurlex website, except for converting \n                it to lower case and replacing whitespaces with '_'.","url":"https://huggingface.co/datasets/ddrg/super_eurlex","creator_name":"Dresden Database Research Group","creator_url":"https://huggingface.co/ddrg","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":null,"first_N":5,"first_N_keywords":["text-classification","fill-mask","multi-class-classification","multi-label-classification","found"],"keywords_longer_than_N":true},
	{"name":"TruthfulQA_de","keyword":"german","description":"\n\t\n\t\t\n\t\tDataset Card for truthful_qa\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nTruthfulQA is a benchmark to measure whether a language model is truthful in generating answers to questions. The benchmark comprises 817 questions that span 38 categories, including health, law, finance and politics. Questions are crafted so that some humans would answer falsely due to a false belief or misconception. To perform well, models must avoid generating false answers learned from imitating human texts.â€¦ See the full description on the dataset page: https://huggingface.co/datasets/LeoLM/TruthfulQA_de.","url":"https://huggingface.co/datasets/LeoLM/TruthfulQA_de","creator_name":"LAION LeoLM","creator_url":"https://huggingface.co/LeoLM","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["multiple-choice","German","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"LoLLMS-Open-Community-discussions","keyword":"german","description":"\n\t\n\t\t\n\t\tDataset Card for GPT4All-Community-Discussions\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset contains ethically gathered discussions from the community, who shared their experiences with various open source discussion models using the GPT4All-ui tool. The dataset is open for any use, including commercial use, as long as proper citation is given to acknowledge the contributions of the community. \nThe GPT4All-ui tool allows users to have conversations with various open source AIs andâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/ParisNeo/LoLLMS-Open-Community-discussions.","url":"https://huggingface.co/datasets/ParisNeo/LoLLMS-Open-Community-discussions","creator_name":"Saifeddine ALOUI","creator_url":"https://huggingface.co/ParisNeo","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["English","French","German","Arabic","Italian"],"keywords_longer_than_N":true},
	{"name":"multilingual-gec","keyword":"german","description":"\n\t\n\t\t\n\t\tDataset Card for Multilingual Grammar Error Correction\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset can be used to train a transformer model (we used T5) to correct grammar errors in simple sentences written in English, Spanish, French, or German. \nThis dataset was developed as a component for the Squidigies platform.\n\n\t\n\t\t\n\t\tSupported Tasks and Leaderboards\n\t\n\n\nGrammar Error Correction: By appending the prefix fix grammar: to the prrompt.\nLanguage Detection: By appending the prefix:â€¦ See the full description on the dataset page: https://huggingface.co/datasets/juancavallotti/multilingual-gec.","url":"https://huggingface.co/datasets/juancavallotti/multilingual-gec","creator_name":"Juan Alberto Lopez Cavallotti","creator_url":"https://huggingface.co/juancavallotti","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["translation","English","Spanish","French","German"],"keywords_longer_than_N":true},
	{"name":"oscar-small","keyword":"german","description":"The Open Super-large Crawled ALMAnaCH coRpus is a huge multilingual corpus obtained by language classification and filtering of the Common Crawl corpus using the goclassy architecture.\\","url":"https://huggingface.co/datasets/djstrong/oscar-small","creator_name":"Krzysztof WrÃ³bel","creator_url":"https://huggingface.co/djstrong","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","language-modeling","no-annotation","found","multilingual"],"keywords_longer_than_N":true},
	{"name":"oscar-small","keyword":"german","description":"The Open Super-large Crawled ALMAnaCH coRpus is a huge multilingual corpus obtained by language classification and filtering of the Common Crawl corpus using the goclassy architecture.\\","url":"https://huggingface.co/datasets/nthngdy/oscar-small","creator_name":"Nathan Godey","creator_url":"https://huggingface.co/nthngdy","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","language-modeling","no-annotation","found","multilingual"],"keywords_longer_than_N":true},
	{"name":"multilingual-pl-bert","keyword":"german","description":"Attribution: Wikipedia.org\n","url":"https://huggingface.co/datasets/styletts2-community/multilingual-pl-bert","creator_name":"StyleTTS 2 Community","creator_url":"https://huggingface.co/styletts2-community","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["Afrikaans","Aragonese","Arabic","Azerbaijani","Bashkir"],"keywords_longer_than_N":true},
	{"name":"miracl","keyword":"german","description":"\n\t\n\t\t\n\t\tDataset Card for MIRACL (Topics and Qrels)\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nHomepage | \nRepository: | \nPaper | \nArXiv\nMIRACL ðŸŒðŸ™ŒðŸŒ (Multilingual Information Retrieval Across a Continuum of Languages) is a multilingual retrieval dataset that focuses on search across 18 different languages, which collectively encompass over three billion native speakers around the world.\nThis dataset contains the collection data of the 16 \"known languages\". The remaining 2 \"surprise languages\" will notâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/miracl/miracl.","url":"https://huggingface.co/datasets/miracl/miracl","creator_name":"MIRACL","creator_url":"https://huggingface.co/miracl","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":null,"first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","expert-generated","multilingual","Arabic"],"keywords_longer_than_N":true},
	{"name":"pwesuite-eval","keyword":"german","description":"\n\n\t\n\t\t\n\t\tPWESuite-Eval\n\t\n\nDataset composed of multiple smaller datasets used for the evaluation of phonetic word embeddings.\nSee code for evaluation here.\nIf you use this dataset/evaluation, please cite the paper at LREC-COLING 2024:\n@inproceedings{zouhar-etal-2024-pwesuite,\n    title = \"{PWES}uite: Phonetic Word Embeddings and Tasks They Facilitate\",\n    author = \"Zouhar, Vil{\\'e}m  and\n      Chang, Kalvin  and\n      Cui, Chenxuan  and\n      Carlson, Nate B.  and\n      Robinson, Nathanielâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/zouharvi/pwesuite-eval.","url":"https://huggingface.co/datasets/zouharvi/pwesuite-eval","creator_name":"VilÃ©m Zouhar","creator_url":"https://huggingface.co/zouharvi","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["multilingual","English","Amharic","Bengali","Swahili"],"keywords_longer_than_N":true},
	{"name":"mapa","keyword":"german","description":"\n\t\n\t\t\n\t\tDataset Card for Multilingual European Datasets for Sensitive Entity Detection in the Legal Domain\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThe dataset consists of 12 documents (9 for Spanish due to parsing errors) taken from EUR-Lex, a multilingual corpus of court\ndecisions and legal dispositions in the 24 official languages of the European Union. The documents have been annotated\nfor named entities following the guidelines of the MAPA project which foresees two\nannotation level, a general and aâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/joelniklaus/mapa.","url":"https://huggingface.co/datasets/joelniklaus/mapa","creator_name":"Joel Niklaus","creator_url":"https://huggingface.co/joelniklaus","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["token-classification","named-entity-recognition","other","found","multilingual"],"keywords_longer_than_N":true},
	{"name":"tatoeba-mt-qna-oa","keyword":"german","description":"\n\t\n\t\t\n\t\tDataset Card for multilingual tatoeba QnA translation with ~120K entries.\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nContains Parquet of a list of instructions and translation articles on different languages.\nEach row consists of\n\nINSTRUCTION\nRESPONSE\nSOURCE (tatoeba)\nMETADATA (json with language, text length, uuid, langs-pair).\n\n\n\t\n\t\t\n\t\tOriginal Dataset is avalible here:\n\t\n\n\nhttps://huggingface.co/datasets/Helsinki-NLP/tatoeba_mt\n\n","url":"https://huggingface.co/datasets/0x22almostEvil/tatoeba-mt-qna-oa","creator_name":"David Glushkov","creator_url":"https://huggingface.co/0x22almostEvil","license_name":"Creative Commons Attribution 2.0","license_url":"https://scancode-licensedb.aboutcode.org/cc-by-2.0.html","language":"en","first_N":5,"first_N_keywords":["question-answering","translation","English","Russian","German"],"keywords_longer_than_N":true},
	{"name":"miracl-de-corpus-22-12","keyword":"german","description":"\n\t\n\t\t\n\t\tMIRACL (de) embedded with cohere.ai multilingual-22-12 encoder\n\t\n\nWe encoded the MIRACL dataset using the cohere.ai multilingual-22-12 embedding model.\nThe query embeddings can be found in Cohere/miracl-de-queries-22-12 and the corpus embeddings can be found in Cohere/miracl-de-corpus-22-12.\nFor the orginal datasets, see miracl/miracl and miracl/miracl-corpus.\nDataset info:\n\nMIRACL ðŸŒðŸ™ŒðŸŒ (Multilingual Information Retrieval Across a Continuum of Languages) is a multilingual retrievalâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Cohere/miracl-de-corpus-22-12.","url":"https://huggingface.co/datasets/Cohere/miracl-de-corpus-22-12","creator_name":"Cohere","creator_url":"https://huggingface.co/Cohere","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","expert-generated","multilingual","German"],"keywords_longer_than_N":true},
	{"name":"sumstew","keyword":"german","description":"\n\t\n\t\t\n\t\tDataset Card for \"sumstew\"\n\t\n\n\n\t\n\t\t\n\t\tTL;DR:\n\t\n\nSumstew is a abstractive, multilingual Dataset, with a balanced number of samples from a diverse set of summarization Datasets. The input sizes range up to 16384 tokens.\nFiltered using a diverse set of heuristics to encourage high coverage, accuracy and factual consistency. Code to reproduce Dataset available at TODO\n\n\t\n\t\t\n\t\tTask Information\n\t\n\n\nTask Categories: The tasks covered by this dataset are primarily summarization tasks.â€¦ See the full description on the dataset page: https://huggingface.co/datasets/Joemgu/sumstew.","url":"https://huggingface.co/datasets/Joemgu/sumstew","creator_name":"Jonas","creator_url":"https://huggingface.co/Joemgu","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["summarization","English","German","French","Italian"],"keywords_longer_than_N":true},
	{"name":"APIS_OEBL__Named_Entity_Recognition","keyword":"german","description":"JSON file of 6,941 sentences of historical biographies, annotated with \"PER\" (Person), \"ORG\" (Organisation), \"LOC\" (Location).\n\n\t\n\t\t\n\t\tsource\n\t\n\nThe original data was extracted from the Austrian Biographical Lexicon (Ã–BL) in the context of the Austrian Prosopographical Information System (APIS) project.\nFrom there, samples were randomly pulled and annotated for Named Entity Recognition tasks, which form this dataset.\nThe texts concern numerous smaller biographies in the time period betweenâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/SteffRhes/APIS_OEBL__Named_Entity_Recognition.","url":"https://huggingface.co/datasets/SteffRhes/APIS_OEBL__Named_Entity_Recognition","creator_name":"Stefan Resch","creator_url":"https://huggingface.co/SteffRhes","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["token-classification","German","mit","ðŸ‡ºðŸ‡¸ Region: US"],"keywords_longer_than_N":false},
	{"name":"german-law-bgb","keyword":"german","description":"The BÃ¼rgerliche Gesetzbuch divided by each paragraph for text-generation.\n","url":"https://huggingface.co/datasets/wndknd/german-law-bgb","creator_name":"Lukas K","creator_url":"https://huggingface.co/wndknd","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-generation","German","mit","1K - 10K","json"],"keywords_longer_than_N":true},
	{"name":"sharegpt-deduplicated","keyword":"german","description":"\n\t\n\t\t\n\t\tDataset Card for Dataset Name\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset is a deduplicated version of sharegpt4. \nThe deduplication process has two steps:\n\nThe literal duplicates (both input and outputs) are removed\nThe remaining (5749) instances are embedded with the SentenceTransformer library (\"paraphrase-multilingual-mpnet-base-v2\" model).\nThen, we compute the cosine similarity among all the possible pairs, and consider paraphrases those pairs with aâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/CaterinaLac/sharegpt-deduplicated.","url":"https://huggingface.co/datasets/CaterinaLac/sharegpt-deduplicated","creator_name":"Caterina Lacerra","creator_url":"https://huggingface.co/CaterinaLac","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["English","Chinese","Korean","French","Japanese"],"keywords_longer_than_N":true},
	{"name":"eagle","keyword":"german","description":"\n\t\n\t\t\n\t\tEagle ðŸ¦…: Ethical Dataset Given from Real Interactions\n\t\n\n\n\n\t\n\t\t\n\t\tIntroduction\n\t\n\nThis repository contains the Eagle dataset, which is an ethical dataset of real interactions between humans and ChatGPT. This dataset is created to evaluate social bias, opinion bias, toxic language, and morality in Large Language Models (LLMs).\nIf you use the Eagle dataset in your research, please cite the following:\n@inproceedings{Eagle:arxiv:2024,\n    title={Eagle: Ethical Dataset Given from Realâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/MasahiroKaneko/eagle.","url":"https://huggingface.co/datasets/MasahiroKaneko/eagle","creator_name":"Masahiro Kaneko","creator_url":"https://huggingface.co/MasahiroKaneko","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-generation","English","Chinese","French","Korean"],"keywords_longer_than_N":true},
	{"name":"docfullstructure_dataset","keyword":"german","description":"kopan/docfullstructure_dataset dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/kopan/docfullstructure_dataset","creator_name":"Ilia Kopanichuk","creator_url":"https://huggingface.co/kopan","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":null,"first_N":5,"first_N_keywords":["text-classification","Russian","English","Kazakh","Bulgarian"],"keywords_longer_than_N":true},
	{"name":"en-de-text-translation","keyword":"german","description":"\n\t\n\t\t\n\t\tEnglishâ€“German Translation Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is designed for machine translation tasks between English and German.It contains parallel text pairs where each English sentence corresponds to its German translation.\nThe dataset is provided in the Hugging Face DatasetDict format with a single split (train).\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nDatasetDict({ \ntrain: Dataset({\n\n    features: ['Unnamed: 0', 'ENGLISH', 'GERMAN'],\n    \n    num_rows: 152820\n    \n})\n\n})\n","url":"https://huggingface.co/datasets/Keyurjotaniya007/en-de-text-translation","creator_name":"Keyur Jotaniya","creator_url":"https://huggingface.co/Keyurjotaniya007","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["translation","English","German","apache-2.0","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"semantics-ws-qna-oa","keyword":"german","description":"\n\t\n\t\t\n\t\tDataset Card for semantics-ws-qna-oa with ~2K entries.\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nLicense: Apache-2.0. Contains parquet of INSTRUCTION, RESPONSE, SOURCE and METADATA.\n\n\n\t\n\t\t\n\t\tOriginal Datasets are available here:\n\t\n\n\nhttps://leviants.com/multilingual-simlex999-and-wordsim353/\n\n\n\n\t\n\t\t\n\t\tPaper of original Dataset:\n\t\n\n\nhttps://arxiv.org/pdf/1508.00106v5.pdf\n\n","url":"https://huggingface.co/datasets/0x22almostEvil/semantics-ws-qna-oa","creator_name":"David Glushkov","creator_url":"https://huggingface.co/0x22almostEvil","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","English","Russian","German","Italian"],"keywords_longer_than_N":true},
	{"name":"wikitext-en-de","keyword":"german","description":"\n\t\n\t\t\n\t\tGerman+English Wikitext\n\t\n\nWikitext_en_de is a replication of the wikitext dataset following the work by Merity et al. (2016). \nIt contains (mostly) all articles that Wikipedia classifies as \"exzellent\" or \"featured\" and can be used for example for perplexity evaluation.\nThis dataset was created by first scraping the names of the articles belonging to these categories from Wikipedia. Afterwards, we take a recent dump from \nwikipedia (\"20230901.de\" from graelo/wikipedia) and filter theâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/LeoLM/wikitext-en-de.","url":"https://huggingface.co/datasets/LeoLM/wikitext-en-de","creator_name":"LAION LeoLM","creator_url":"https://huggingface.co/LeoLM","license_name":"Creative Commons Attribution 3.0","license_url":"https://scancode-licensedb.aboutcode.org/cc-by-3.0.html","language":"en","first_N":5,"first_N_keywords":["German","English","cc-by-3.0","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"BioInstructQA","keyword":"german","description":"Large Language Models (LLMs) have demonstrated remarkable versatility \nin recent years, offering potential applications across specialized \ndomains such as healthcare and medicine. Despite the availability of \nvarious open-source LLMs tailored for health contexts, adapting \ngeneral-purpose LLMs to the medical domain presents significant\nchallenges. In this paper, we introduce BioMistral, an open-source\nLLM tailored for the biomedical domain, utilizing Mistral as its \nfoundation model and further pre-trained on PubMed Central. We conduct \na comprehensive evaluation of BioMistral on a benchmark comprising 10 \nestablished medical question-answering (QA) tasks in English. We also \nexplore lightweight models obtained through quantization and model \nmerging approaches. Our results demonstrate BioMistral's superior \nperformance compared to existing open-source medical models and its \ncompetitive edge against proprietary counterparts. Finally, to address \nthe limited availability of data beyond English and to assess the multilingual \ngeneralization of medical LLMs, we automatically translated and evaluated this\nbenchmark into 7 other languages. This marks the first large-scale\nmultilingual evaluation of LLMs in the medical domain. Datasets, \nmultilingual evaluation benchmarks, scripts, and all the models obtained \nduring our experiments are freely released.","url":"https://huggingface.co/datasets/BioMistral/BioInstructQA","creator_name":"BioMistral","creator_url":"https://huggingface.co/BioMistral","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":null,"first_N":5,"first_N_keywords":["question-answering","French","English","German","Spanish"],"keywords_longer_than_N":true},
	{"name":"openassistant-guanaco-EOS","keyword":"german","description":"\n\t\n\t\t\n\t\tChat Fine-tuning Dataset - Guanaco Style\n\t\n\nThis dataset allows for fine-tuning chat models using \"### Human:\" AND \"### Assistant\" as the beginning and end of sequence tokens.\nPreparation:\n\nThe dataset is cloned from TimDettmers, which itself is a subset of the Open Assistant dataset, which you can find here. This subset of the data only contains the highest-rated paths in the conversation tree, with a total of 9,846 samples.\nThe dataset was then slightly adjusted to:\n\n\nif a row ofâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Trelis/openassistant-guanaco-EOS.","url":"https://huggingface.co/datasets/Trelis/openassistant-guanaco-EOS","creator_name":"Trelis","creator_url":"https://huggingface.co/Trelis","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["English","Spanish","Russian","German","Polish"],"keywords_longer_than_N":true},
	{"name":"germaner","keyword":"german","description":"GermaNER is a freely available statistical German Named Entity Tagger based on conditional random fields(CRF). The tagger is trained and evaluated on the NoSta-D Named Entity dataset, which was used in the GermEval 2014 for named entity recognition. The tagger comes close to the performance of the best (proprietary) system in the competition with 77% F-measure (this is the latest result; the one reported in the paper is 76%) test set performance on the four standard NER classes (PERson, LOCation, ORGanisation and OTHer).\n\nWe describe a range of features and their influence on German NER classification and provide a comparative evaluation and some analysis of the results. The software components, the training data and all data used for feature generation are distributed under permissive licenses, thus this tagger can be used in academic and commercial settings without restrictions or fees. The tagger is available as a command-line tool and as an Apache UIMA component.","url":"https://huggingface.co/datasets/tudarmstadt-lt/germaner","creator_name":"Language Technology Group, TU Darmstadt) ","creator_url":"https://huggingface.co/tudarmstadt-lt","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":null,"first_N":5,"first_N_keywords":["token-classification","named-entity-recognition","crowdsourced","found","monolingual"],"keywords_longer_than_N":true},
	{"name":"smartdata","keyword":"german","description":"DFKI SmartData Corpus is a dataset of 2598 German-language documents\nwhich has been annotated with fine-grained geo-entities, such as streets,\nstops and routes, as well as standard named entity types. It has also\nbeen annotated with a set of 15 traffic- and industry-related n-ary\nrelations and events, such as Accidents, Traffic jams, Acquisitions,\nand Strikes. The corpus consists of newswire texts, Twitter messages,\nand traffic reports from radio stations, police and railway companies.\nIt allows for training and evaluating both named entity recognition\nalgorithms that aim for fine-grained typing of geo-entities, as well\nas n-ary relation extraction systems.","url":"https://huggingface.co/datasets/dfki-nlp/smartdata","creator_name":"dfki-nlp","creator_url":"https://huggingface.co/dfki-nlp","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":null,"first_N":5,"first_N_keywords":["token-classification","named-entity-recognition","expert-generated","found","monolingual"],"keywords_longer_than_N":true},
	{"name":"intel_orca_dpo_pairs_de","keyword":"german","description":"German translation of Intel/orca_dpo_pairs\nUsing azureml for translation and hermeo-7b for rejected answers.\n","url":"https://huggingface.co/datasets/mayflowergmbh/intel_orca_dpo_pairs_de","creator_name":"Mayflower GmbH","creator_url":"https://huggingface.co/mayflowergmbh","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","German","apache-2.0","10K - 100K","json"],"keywords_longer_than_N":true},
	{"name":"Wikinews-multilingual","keyword":"german","description":"\n\t\n\t\t\n\t\tWikinews - weakly aligned multilingual pararell sentence datasets\n\t\n\nThis dataset contains 15,200 multilingual WikiNews articles in 33 languages.\nOut of 15,200 articles, 9,960 are non-English news and 5240 are English news.  All non-English news are linked to one of 5240 English news. Linked articles show the same event.\nList of non-English languages are: Spanish, French, German, Portuguese, Polish, Italian, Chinese, Russian, Japanese, Dutch, Swedish, Tamil, Serbian, Czech, Catalanâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Fumika/Wikinews-multilingual.","url":"https://huggingface.co/datasets/Fumika/Wikinews-multilingual","creator_name":"Fumika Isono","creator_url":"https://huggingface.co/Fumika","license_name":"Creative Commons Attribution 2.5","license_url":"https://scancode-licensedb.aboutcode.org/cc-by-2.5.html","language":"en","first_N":5,"first_N_keywords":["text-classification","feature-extraction","English","Spanish","French"],"keywords_longer_than_N":true},
	{"name":"wmt-human-all","keyword":"german","description":"This dataset is continuously updated and contains a compilation of human translation quality assessment from past WMT campaigns.\nSpecifically, this dataset merges all annotation protocols (DA, MQM, ESA) on a semi-unified scale (0 to 100).\nThe current version of the dataset includes human scores up to WMT 2024 (inclusive) and has been created with the following script:\nimport subset2evaluate # version 1.0.14\nimport json\nimport statistics\n\ndata =â€¦ See the full description on the dataset page: https://huggingface.co/datasets/zouharvi/wmt-human-all.","url":"https://huggingface.co/datasets/zouharvi/wmt-human-all","creator_name":"VilÃ©m Zouhar","creator_url":"https://huggingface.co/zouharvi","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["Bengali","Czech","German","English","Spanish"],"keywords_longer_than_N":true},
	{"name":"Trucks-Detection-Yolov8","keyword":"german","description":"\n\t\n\t\t\n\t\tTrucks Detection - v1\n\t\n\nThis dataset was exported via roboflow.com on September 11, 2023 at 8:38 AM GMT\nRoboflow is an end-to-end computer vision platform that helps you\n\ncollaborate with your team on computer vision projects\ncollect & organize images\nunderstand and search unstructured image data\nannotate, and create datasets\nexport, train, and deploy computer vision models\nuse active learning to improve your dataset over time\n\nThe dataset includes 746 images.\nTrucks are annotated inâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/beethogedeon/Trucks-Detection-Yolov8.","url":"https://huggingface.co/datasets/beethogedeon/Trucks-Detection-Yolov8","creator_name":"Gedeon J. Gbedonou","creator_url":"https://huggingface.co/beethogedeon","license_name":"Creative Commons Attribution 3.0","license_url":"https://scancode-licensedb.aboutcode.org/cc-by-3.0.html","language":null,"first_N":5,"first_N_keywords":["object-detection","English","French","German","Italian"],"keywords_longer_than_N":true},
	{"name":"multiconer_v2","keyword":"german","description":"Complex named entities (NE), like the titles of creative works, are not simple nouns and pose challenges for NER systems (Ashwini and Choi, 2014). They can take the form of any linguistic constituent, like an imperative clause (â€œDial M for Murderâ€), and do not look like traditional NEs (Persons, Locations, etc.). This syntactic ambiguity makes it challenging to recognize them based on context. We organized the MultiCoNER task (Malmasi et al., 2022) at SemEval-2022 to address these challenges in 11 languages, receiving a very positive community response with 34 system papers. Results confirmed the challenges of processing complex and long-tail NEs: even the largest pre-trained Transformers did not achieve top performance without external knowledge. The top systems infused transformers with knowledge bases and gazetteers. However, such solutions are brittle against out of knowledge-base entities and noisy scenarios like the presence of spelling mistakes and typos. We propose MultiCoNER II which represents novel challenges through new tasks that emphasize the shortcomings of the current top models.\n\nMultiCoNER II features complex NER in these languages:\n\n1. English\n2. Spanish\n3. Hindi\n4. Bangla\n5. Chinese\n6. Swedish\n7. Farsi\n8. French\n9. Italian\n10. Portugese\n11. Ukranian\n12. German\n\nFor more details see https://multiconer.github.io/\n\n## References\n* Sandeep Ashwini and Jinho D. Choi. 2014. Targetable named entity recognition in social media. CoRR, abs/1408.0782.\n* Shervin Malmasi, Anjie Fang, Besnik Fetahu, Sudipta Kar, Oleg Rokhlenko. 2022. SemEval-2022 Task 11: Multilingual Complex Named Entity Recognition (MultiCoNER).","url":"https://huggingface.co/datasets/MultiCoNER/multiconer_v2","creator_name":"MultiCoNER","creator_url":"https://huggingface.co/MultiCoNER","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["token-classification","Bengali","Chinese","German","English"],"keywords_longer_than_N":true},
	{"name":"german-court-decisions","keyword":"german","description":"\n\t\n\t\t\n\t\tDataset Card for german-court-decisions\n\t\n\n60k judicial decisions in Germany retrieved on January 1, 2024.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nLanguage(s) (NLP): German\nLicense: MIT\nCopyright notice: Automated retrieval of decisions from federal and state databases in Germany is permitted for non-commercial purposes only. As a result, the use of this dataset is permitted for non-commercial purposes only.\n\n\t\n\t\t\n\t\tUses\n\t\n\nPrediction of verdicts based on statement of facts.\n\n\t\n\t\t\n\t\tDirect Useâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/SH108/german-court-decisions.","url":"https://huggingface.co/datasets/SH108/german-court-decisions","creator_name":"Stefan HÃ¤usler","creator_url":"https://huggingface.co/SH108","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","German","mit","10K - 100K","json"],"keywords_longer_than_N":true},
	{"name":"gerlayqa-combined-paraphrased","keyword":"german","description":"\n\t\n\t\t\n\t\tGerLayQA Combined Paraphrased ðŸ‡©ðŸ‡ªâš–ï¸\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis is a combined, shuffled dataset merging both the BGB (civil law) and StGB (criminal law) paraphrased German legal QA datasets. All examples are paraphrased and restructured by GPT-5 for fine-tuning large language models on German legal question-answering tasks.\n\n\t\n\t\t\n\t\tKey Features\n\t\n\n\n6,462 high-quality QA pairs covering both German Civil and Criminal Law\nCombined coverage: BGB (BÃ¼rgerliches Gesetzbuch) + StGBâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/DomainLLM/gerlayqa-combined-paraphrased.","url":"https://huggingface.co/datasets/DomainLLM/gerlayqa-combined-paraphrased","creator_name":"DomainLLM","creator_url":"https://huggingface.co/DomainLLM","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["question-answering","text-generation","German","cc-by-4.0","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"subject-indexing-dataset","keyword":"german","description":"TIB/subject-indexing-dataset dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/TIB/subject-indexing-dataset","creator_name":"TIB â€“ Leibniz Information Centre for Science and Technology and University Library","creator_url":"https://huggingface.co/TIB","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":null,"first_N":5,"first_N_keywords":["text-classification","English","German","cc-by-4.0","100K<n<1M"],"keywords_longer_than_N":true},
	{"name":"mobie","keyword":"german","description":"\n\t\n\t\t\n\t\tDataset Card for \"MobIE\"\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis script is for loading the MobIE dataset from https://github.com/dfki-nlp/mobie. \nMobIE is a German-language dataset which is human-annotated with 20 coarse- and fine-grained entity types and entity linking information for geographically linkable entities. The dataset consists of 3,232 social media texts and traffic reports with 91K tokens, and contains 20.5K annotated entities, 13.1K of which are linked to a knowledge base. Aâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/DFKI-SLT/mobie.","url":"https://huggingface.co/datasets/DFKI-SLT/mobie","creator_name":"Speech and Language Technology, DFKI","creator_url":"https://huggingface.co/DFKI-SLT","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","named-entity-recognition","entity-linking-classification","multi-class-classification"],"keywords_longer_than_N":true},
	{"name":"mc4-sampling","keyword":"german","description":"A sampling-enabled version of mC4, the colossal, cleaned version of Common Crawl's web crawl corpus.\n\nBased on Common Crawl dataset: \"https://commoncrawl.org\".\n\nThis is a version of the processed version of Google's mC4 dataset by AllenAI, in which sampling methods are implemented to perform on the fly.","url":"https://huggingface.co/datasets/bertin-project/mc4-sampling","creator_name":"BERTIN Project","creator_url":"https://huggingface.co/bertin-project","license_name":"Open Data Commons Attribution License v1.0","license_url":"https://scancode-licensedb.aboutcode.org/odc-by-1.0.html","language":null,"first_N":5,"first_N_keywords":["text-generation","fill-mask","language-modeling","no-annotation","found"],"keywords_longer_than_N":true},
	{"name":"de-en-paracrawl-doc","keyword":"german","description":"chaley22/de-en-paracrawl-doc dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/chaley22/de-en-paracrawl-doc","creator_name":"Coleman Haley","creator_url":"https://huggingface.co/chaley22","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["translation","German","English","mit","< 1K"],"keywords_longer_than_N":true},
	{"name":"sv-ident","keyword":"german","description":"The SV-Ident corpus (version 0.3) is a collection of 4,248 expert-annotated English\nand German sentences from social science publications, supporting the task of\nmulti-label text classification.","url":"https://huggingface.co/datasets/vadis/sv-ident","creator_name":"VAriable Detection, Interlinking and Summarization project","creator_url":"https://huggingface.co/vadis","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","multi-label-classification","semantic-similarity-classification","expert-generated","expert-generated"],"keywords_longer_than_N":true},
	{"name":"Text_Classification_Deutsch_Beispiel","keyword":"german","description":"mindchain/Text_Classification_Deutsch_Beispiel dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/mindchain/Text_Classification_Deutsch_Beispiel","creator_name":"Jan Karsten Kuhnke","creator_url":"https://huggingface.co/mindchain","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":null,"first_N":5,"first_N_keywords":["German","apache-2.0","1K<n<10K","ðŸ‡ºðŸ‡¸ Region: US"],"keywords_longer_than_N":false},
	{"name":"xlel_wd","keyword":"german","description":"XLEL-WD is a multilingual event linking dataset. This dataset contains mention references from multilingual Wikipedia/Wikinews articles to event items in Wikidata. The text descriptions for Wikidata events are compiled from Wikipedia articles.","url":"https://huggingface.co/datasets/adithya7/xlel_wd","creator_name":"Adithya Pratapa","creator_url":"https://huggingface.co/adithya7","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["found","found","multilingual","original","Afrikaans"],"keywords_longer_than_N":true},
	{"name":"olaph-data","keyword":"german","description":"\n\t\n\t\t\n\t\tOLaPh Phonemization Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset was created with the OLaPh framework and used to train the OLaPh grapheme-to-phoneme model. It contains multilingual text from the FineWeb datasets, automatically phonemized into textâ€“phoneme pairs for English, German, French, and Spanish.\n\n\t\n\t\t\n\t\tSource Data\n\t\n\nText was taken from:\n\nHuggingFaceFW/fineweb\nHuggingFaceFW/fineweb-2\n\n\n\t\n\t\t\n\t\tPhonemization\n\t\n\nAll text was processed and phonemized automatically using theâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/iisys-hof/olaph-data.","url":"https://huggingface.co/datasets/iisys-hof/olaph-data","creator_name":"Institute for Information Systems of Hof University","creator_url":"https://huggingface.co/iisys-hof","license_name":"Open Data Commons Attribution License v1.0","license_url":"https://scancode-licensedb.aboutcode.org/odc-by-1.0.html","language":"en","first_N":5,"first_N_keywords":["English","German","French","Spanish","odc-by"],"keywords_longer_than_N":true},
	{"name":"gerlayqa-bgb-paraphrased","keyword":"german","description":"\n\t\n\t\t\n\t\tGerLayQA-BGB Paraphrased ðŸ‡©ðŸ‡ªâš–ï¸\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis is a paraphrased and restructured version of the GerLayQA BGB (BÃ¼rgerliches Gesetzbuch / German Civil Code) dataset, specifically prepared for fine-tuning large language models on German civil law question-answering tasks.\n\n\t\n\t\t\n\t\tKey Features\n\t\n\n\n5,255 high-quality QA pairs about German Civil Law (BGB)\nParaphrased questions to remove plagiarism while maintaining legal accuracy\nStructured 7-section answers followingâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/DomainLLM/gerlayqa-bgb-paraphrased.","url":"https://huggingface.co/datasets/DomainLLM/gerlayqa-bgb-paraphrased","creator_name":"DomainLLM","creator_url":"https://huggingface.co/DomainLLM","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["question-answering","text-generation","German","cc-by-4.0","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"icfhr-2016","keyword":"german","description":"\n\t\n\t\t\n\t\tHTR Dataset ICFHR 2016\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe HTR Dataset ICFHR 2016 is a historical document image dataset primarily intended for Handwriting Text Recognition (HTR) research and benchmarking.\nThis dataset was created as part of the European Commission's READ project (Recognition and Enrichment of Archival Documents) and consists of a subset of documents from the Ratsprotokolle collection, which contains minutes of council meetings held from 1470 to 1805.\nThe documentsâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/SSamDav/icfhr-2016.","url":"https://huggingface.co/datasets/SSamDav/icfhr-2016","creator_name":"Samuel Arcadinho","creator_url":"https://huggingface.co/SSamDav","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["German","cc-by-4.0","< 1K","parquet","Image"],"keywords_longer_than_N":true},
	{"name":"qg_dequad","keyword":"german","description":"[GermanSQuAD](https://huggingface.co/datasets/deepset/germanquad) dataset for question generation (QG) task.","url":"https://huggingface.co/datasets/lmqg/qg_dequad","creator_name":"LMQG","creator_url":"https://huggingface.co/lmqg","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":null,"first_N":5,"first_N_keywords":["text-generation","language-modeling","monolingual","deepset/germanquad","German"],"keywords_longer_than_N":true},
	{"name":"ShareGPT52K","keyword":"german","description":"\n\t\n\t\t\n\t\tDataset Card for ShareGPT52K90K\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset is a collection of approximately 52,00090,000 conversations scraped via the ShareGPT API before it was shut down.\nThese conversations include both user prompts and responses from OpenAI's ChatGPT.\nThis repository now contains the new 90K conversations version. The previous 52K may\nbe found in the old/ directory.\n\n\t\n\t\t\n\t\tSupported Tasks and Leaderboards\n\t\n\n\ntext-generation\n\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nThis dataset isâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/RyokoAI/ShareGPT52K.","url":"https://huggingface.co/datasets/RyokoAI/ShareGPT52K","creator_name":"Ryoko AI","creator_url":"https://huggingface.co/RyokoAI","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","English","Spanish","German","multilingual"],"keywords_longer_than_N":true},
	{"name":"blbooksgenre","keyword":"german","description":"This dataset contains metadata for resources belonging to the British Libraryâ€™s digitised printed books (18th-19th century) collection (bl.uk/collection-guides/digitised-printed-books).\nThis metadata has been extracted from British Library catalogue records.\nThe metadata held within our main catalogue is updated regularly.\nThis metadata dataset should be considered a snapshot of this metadata.","url":"https://huggingface.co/datasets/TheBritishLibrary/blbooksgenre","creator_name":"British Library","creator_url":"https://huggingface.co/TheBritishLibrary","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","text-generation","fill-mask","topic-classification","multi-label-classification"],"keywords_longer_than_N":true},
	{"name":"opus_paracrawl","keyword":"german","description":"\n\t\n\t\t\n\t\tDataset Card for OpusParaCrawl\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nParallel corpora from Web Crawls collected in the ParaCrawl project.\nTha dataset contains:\n\n42 languages, 43 bitexts\ntotal number of files: 59,996\ntotal number of tokens: 56.11G\ntotal number of sentence fragments: 3.13G\n\nTo load a language pair which isn't part of the config, all you need to do is specify the language code as pairs,\ne.g.\ndataset = load_dataset(\"opus_paracrawl\", lang1=\"en\", lang2=\"so\")\n\nYou can find the validâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Helsinki-NLP/opus_paracrawl.","url":"https://huggingface.co/datasets/Helsinki-NLP/opus_paracrawl","creator_name":"Language Technology Research Group at the University of Helsinki","creator_url":"https://huggingface.co/Helsinki-NLP","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["translation","found","found","multilingual","original"],"keywords_longer_than_N":true},
	{"name":"panlex","keyword":"swiss german","description":"\n\t\n\t\t\n\t\tPanLex\n\t\n\nJanuary 1, 2024 version of PanLex Language Vocabulary with 24,650,274 rows covering 6,152 languages.\n\n\t\n\t\t\n\t\tColumns\n\t\n\n\nvocab: contains the text entry.  \n639-3: contains the ISO 639-3 languages tags to allow users to filter on the language(s) of their choice.\n639-3_english_name: the English language name associated to the code ISO 639-3. \nvar_code: contains a code to differentiate language variants. In practice, this is the code 639-3 + a number.  If 000, it corresponds toâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/lbourdois/panlex.","url":"https://huggingface.co/datasets/lbourdois/panlex","creator_name":"LoÃ¯ck BOURDOIS","creator_url":"https://huggingface.co/lbourdois","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["Ghotuo","Alumu-Tesu","Ari","Amal","ArbÃ«reshÃ« Albanian"],"keywords_longer_than_N":true},
	{"name":"panlex","keyword":"german","description":"\n\t\n\t\t\n\t\tPanLex\n\t\n\nJanuary 1, 2024 version of PanLex Language Vocabulary with 24,650,274 rows covering 6,152 languages.\n\n\t\n\t\t\n\t\tColumns\n\t\n\n\nvocab: contains the text entry.  \n639-3: contains the ISO 639-3 languages tags to allow users to filter on the language(s) of their choice.\n639-3_english_name: the English language name associated to the code ISO 639-3. \nvar_code: contains a code to differentiate language variants. In practice, this is the code 639-3 + a number.  If 000, it corresponds toâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/lbourdois/panlex.","url":"https://huggingface.co/datasets/lbourdois/panlex","creator_name":"LoÃ¯ck BOURDOIS","creator_url":"https://huggingface.co/lbourdois","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["Ghotuo","Alumu-Tesu","Ari","Amal","ArbÃ«reshÃ« Albanian"],"keywords_longer_than_N":true},
	{"name":"germanquad_qg_dataset","keyword":"german","description":"fathyshalab/germanquad_qg_dataset dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/fathyshalab/germanquad_qg_dataset","creator_name":"FathÃ½ Shalaby","creator_url":"https://huggingface.co/fathyshalab","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["German","cc-by-4.0","10K - 100K","parquet","Text"],"keywords_longer_than_N":true},
	{"name":"tatoeba-mt-all-in-one","keyword":"german","description":"\n\t\n\t\t\n\t\tDataset Card for The Tatoeba Translation Challenge | All In One\n\t\n\n~7.3M entries.\nJust more user-friendly version that combines all of the entries of original dataset in a single file:\nhttps://huggingface.co/datasets/Helsinki-NLP/tatoeba_mt\n","url":"https://huggingface.co/datasets/0x22almostEvil/tatoeba-mt-all-in-one","creator_name":"David Glushkov","creator_url":"https://huggingface.co/0x22almostEvil","license_name":"Creative Commons Attribution 2.0","license_url":"https://scancode-licensedb.aboutcode.org/cc-by-2.0.html","language":"en","first_N":5,"first_N_keywords":["Helsinki-NLP","crowdsourced","translation","Helsinki-NLP/tatoeba_mt","Afrikaans"],"keywords_longer_than_N":true},
	{"name":"YouTube-Commons","keyword":"german","description":"\n\t\n\t\t\n\t\tðŸ“º YouTube-Commons ðŸ“º\n\t\n\nYouTube-Commons is a collection of audio transcripts of 2,063,066 videos shared on YouTube under a CC-By license.\n\n\t\n\t\t\n\t\tContent\n\t\n\nThe collection comprises 22,709,724 original and automatically translated transcripts from 3,156,703 videos (721,136 individual channels).\nIn total, this represents nearly 45 billion words (44,811,518,375).\nAll the videos where shared on YouTube with a CC-BY license: the dataset provide all the necessary provenance informationâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/gautijha37/YouTube-Commons.","url":"https://huggingface.co/datasets/gautijha37/YouTube-Commons","creator_name":"Gautam Jha","creator_url":"https://huggingface.co/gautijha37","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","English","French","Spanish","Portuguese"],"keywords_longer_than_N":true},
	{"name":"tatoeba-mt-llama-only","keyword":"german","description":"\n\t\n\t\t\n\t\tDataset Card for multilingual tatoeba translations with ~3M entries (llama supported languages only).\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\n~3M entries. Just more user-friendly version that combines all of the entries of original dataset in a single file (llama supported languages only):\nhttps://huggingface.co/datasets/Helsinki-NLP/tatoeba_mt\n","url":"https://huggingface.co/datasets/0x22almostEvil/tatoeba-mt-llama-only","creator_name":"David Glushkov","creator_url":"https://huggingface.co/0x22almostEvil","license_name":"Creative Commons Attribution 2.0","license_url":"https://scancode-licensedb.aboutcode.org/cc-by-2.0.html","language":"en","first_N":5,"first_N_keywords":["translation","English","Russian","German","Ukrainian"],"keywords_longer_than_N":true},
	{"name":"mswc_fscil_subset","keyword":"german","description":"This is a subset of the Multilingual Spoken Word Corpus dataset, which is built specifically for the Few-shot Class-incremental Learning (FSCIL) task. \nA total of 15 languages are chosen, split into 5 base languages (English, German, Catalan, French, Kinyarwanda) and 10 incrementally learned languages (Persian, Spanish, Russian, Welsh, Italian, Basque, Polish, Esparanto, Portuguese, Dutch).\nThe FSCIL task entails first training a model using abundant training data on words from the 5 baseâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/NeuroBench/mswc_fscil_subset.","url":"https://huggingface.co/datasets/NeuroBench/mswc_fscil_subset","creator_name":"NeuroBench","creator_url":"https://huggingface.co/NeuroBench","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["English","Spanish","Catalan","French","Kinyarwanda"],"keywords_longer_than_N":true},
	{"name":"tokenizer-wiki-bench","keyword":"german","description":"\n\t\n\t\t\n\t\tMultilingual Tokenizer Benchmark\n\t\n\nThis dataset includes pre-processed wikipedia data for tokenizer evaluation in 45 languages. We provide more information on the evaluation task in general this blogpost.\n\n\t\n\t\t\n\t\tUsage\n\t\n\nThe dataset allows us to easily calculate tokenizer fertility and the proportion of continued words on any of the supported languages. In the example below we take the Mistral tokenizer and evaluate its performance on Slovak. \nfrom transformers import AutoTokenizerâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/occiglot/tokenizer-wiki-bench.","url":"https://huggingface.co/datasets/occiglot/tokenizer-wiki-bench","creator_name":"Occiglot","creator_url":"https://huggingface.co/occiglot","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["Afrikaans","Arabic","Bulgarian","Catalan","Czech"],"keywords_longer_than_N":true},
	{"name":"co-funer","keyword":"german","description":"\n\t\n\t\t\n\t\tCO-Fun: A German Dataset on Company Outsourcing in Fund Prospectuses for Named Entity Recognition and Relation Extraction\n\t\n\nThis inofficial dataset repository provides a CoNLL-like version of the CO-Fun NER dataset, that was proposed in the CO-Fun paper (https://arxiv.org/abs/2403.15322):\n\nThe process of cyber mapping gives insights in relationships among financial entities and service providers. Centered around the outsourcing practices of companies within fund prospectuses inâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/stefan-it/co-funer.","url":"https://huggingface.co/datasets/stefan-it/co-funer","creator_name":"Stefan Schweter","creator_url":"https://huggingface.co/stefan-it","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["token-classification","German","mit","arxiv:2403.15322","ðŸ‡ºðŸ‡¸ Region: US"],"keywords_longer_than_N":false},
	{"name":"germanquad","keyword":"german","description":"In order to raise the bar for non-English QA, we are releasing a high-quality, human-labeled German QA dataset consisting of 13 722 questions, incl. a three-way annotated test set.\nThe creation of GermanQuAD is inspired by insights from existing datasets as well as our labeling experience from several industry projects. We combine the strengths of SQuAD, such as high out-of-domain performance, with self-sufficient questions that contain all relevant information for open-domain QA as in the NaturalQuestions dataset. Our training and test datasets do not overlap like other popular datasets and include complex questions that cannot be answered with a single entity or only a few words.","url":"https://huggingface.co/datasets/deepset/germanquad","creator_name":"deepset","creator_url":"https://huggingface.co/deepset","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":null,"first_N":5,"first_N_keywords":["question-answering","text-retrieval","extractive-qa","closed-domain-qa","open-domain-qa"],"keywords_longer_than_N":true},
	{"name":"math-prm-800k-de","keyword":"german","description":"German version of prm800k. Translated using DeepL (informal style).\n\n\t\n\t\t\nlang\n#chars\n\n\n\t\t\nen\n11_479_654\n\n\nde\n12_516_903\n\n\n\t\n\n","url":"https://huggingface.co/datasets/maxidl/math-prm-800k-de","creator_name":"Max Idahl","creator_url":"https://huggingface.co/maxidl","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-generation","German","English","mit","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"Open_Assistant_Chains_German_Translation","keyword":"german","description":"\n\t\n\t\t\n\t\tDataset Card for Dataset Name\n\t\n\n\n\t\n\t\t\n\t\tDataset description\n\t\n\n\n\nThis dataset is derived from OpenAssistant Conversation Chains, which is a reformatting of OpenAssistant Conversations (OASST1), which is itself\n\na human-generated, human-annotated assistant-style conversation corpus consisting of 161,443 messages in 35 different languages, annotated with 461,292 quality ratings, resulting in over 10,000 fully annotated conversation trees. The corpus is a product of a worldwideâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/m-ric/Open_Assistant_Chains_German_Translation.","url":"https://huggingface.co/datasets/m-ric/Open_Assistant_Chains_German_Translation","creator_name":"Aymeric Roucher","creator_url":"https://huggingface.co/m-ric","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","English","German","apache-2.0","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"CommonPhoneDataset","keyword":"german","description":"\n\t\n\t\t\n\t\tDataset Card for Common Phone\n\t\n\nThis corpus aims to provide a basis for Machine Learning (ML) researchers and enthusiasts to train and test their models against a wide variety of speakers, hardware/software ecosystems and acoustic conditions to improve generalization and availability of ML in real-world speech applications.\nThe current version of Common Phone comprises 116,5 hours of speech samples, collected from 11.246 speakers in 6 languages.\nCommon Phone has been used as theâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/pklumpp/CommonPhoneDataset.","url":"https://huggingface.co/datasets/pklumpp/CommonPhoneDataset","creator_name":"Philipp Klumpp","creator_url":"https://huggingface.co/pklumpp","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","English","German","French","Italian"],"keywords_longer_than_N":true},
	{"name":"JinaVDRAirbnbSyntheticRetrieval","keyword":"german","description":"\n  JinaVDRAirbnbSyntheticRetrieval\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nRetrieve rendered tables from Airbnb listings based on templated queries.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2i\n\n\nDomains\nWeb\n\n\nReference\nhttps://huggingface.co/datasets/jinaai/airbnb-synthetic-retrieval_beir\n\n\n\t\n\nSource datasets:\n\njinaai/airbnb-synthetic-retrieval_beir\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask =â€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/JinaVDRAirbnbSyntheticRetrieval.","url":"https://huggingface.co/datasets/mteb/JinaVDRAirbnbSyntheticRetrieval","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["visual-document-retrieval","image-to-text","text-to-image","derived","multilingual"],"keywords_longer_than_N":true},
	{"name":"voxpopolo_2","keyword":"german","description":"A large-scale multilingual speech corpus for representation learning, semi-supervised learning and interpretation.","url":"https://huggingface.co/datasets/mcapozi/voxpopolo_2","creator_name":"Matteo Capozi","creator_url":"https://huggingface.co/mcapozi","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":null,"first_N":5,"first_N_keywords":["automatic-speech-recognition","multilingual","English","German","French"],"keywords_longer_than_N":true},
	{"name":"Kaleidoscope","keyword":"german","description":"\n\t\n\t\t\n\t\tKaleidoscope  (18 Languages)\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe Kaleidoscope Benchmark is a \nglobal collection of multiple-choice questions sourced from real-world exams, \nwith the goal of evaluating multimodal and multilingual understanding in VLMs. \nThe collected exams are in a Multiple-choice question answering (MCQA) \nformat which provides a structured framework for evaluation by prompting \nmodels with predefined answer choices, closely mimicking conventional human testingâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Anonym-sub/Kaleidoscope.","url":"https://huggingface.co/datasets/Anonym-sub/Kaleidoscope","creator_name":"Anonymous submission","creator_url":"https://huggingface.co/Anonym-sub","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["Arabic","Bengali","Croatian","Dutch","English"],"keywords_longer_than_N":true},
	{"name":"ApolloMoEBench","keyword":"german","description":"\n\t\n\t\t\n\t\tDemocratizing Medical LLMs For Much More Languages\n\t\n\nCovering 12 Major Languages including English, Chinese, French, Hindi, Spanish, Arabic, Russian, Japanese, Korean, German, Italian, Portuguese and 38 Minor Languages So far.\n\n   ðŸ“ƒ Paper â€¢ ðŸŒ Demo â€¢ ðŸ¤— ApolloMoEDataset â€¢ ðŸ¤— ApolloMoEBench  â€¢ ðŸ¤— Models  â€¢ðŸŒ Apollo  â€¢ ðŸŒ ApolloMoE\n\n\n\n\n\n\n\t\n\t\t\n\t\tðŸŒˆ Update\n\t\n\n\n[2024.10.15] ApolloMoE repo is publishedï¼ðŸŽ‰\n\n\n\t\n\t\t\n\t\tLanguages Coverage\n\t\n\n12 Major Languages and 38 Minor Languages\n\n  Click toâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/FreedomIntelligence/ApolloMoEBench.","url":"https://huggingface.co/datasets/FreedomIntelligence/ApolloMoEBench","creator_name":"FreedomAI","creator_url":"https://huggingface.co/FreedomIntelligence","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["question-answering","Arabic","English","Chinese","Korean"],"keywords_longer_than_N":true},
	{"name":"WiNNL","keyword":"german","description":"\n\t\n\t\t\n\t\tWiNNL\n\t\n\nWikiNews Named entity recognition and Linking (WiNNL) is a multilingual news NER & NEL benchmark based on Wikinews articles.\nThe dataset was created by automatically scraping and tagging news articles, and manually corrected by native speakers to ensure accuracy.\nYou can find more information in the paper:\nhttps://aclanthology.org/2024.dlnld-1.3.pdf\nThe dataset includes the following NER classes in IOB format (labels):\n\nPER (Person): person names \nLOC (Location): geographicalâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/peemil/WiNNL.","url":"https://huggingface.co/datasets/peemil/WiNNL","creator_name":"Emile Peetermans","creator_url":"https://huggingface.co/peemil","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["token-classification","Dutch","English","Spanish","Portuguese"],"keywords_longer_than_N":true},
	{"name":"Synthdog-Multilingual-100","keyword":"german","description":"\n\t\n\t\t\n\t\tSynthdog Multilingual\n\t\n\n\n\nThe Synthdog dataset created for training in Centurio: On Drivers of Multilingual Ability of Large Vision-Language Model.\nUsing the official Synthdog code, we created >1 million training samples for improving OCR capabilities in Large Vision-Language Models.\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Details\n\t\n\nWe provide the images for download in two .tar.gz files. Download and extract them in folders of the same name (so cat images.tar.gz.* | tar xvzf -C images; tar xvzfâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/WueNLP/Synthdog-Multilingual-100.","url":"https://huggingface.co/datasets/WueNLP/Synthdog-Multilingual-100","creator_name":"WÃ¼NLP","creator_url":"https://huggingface.co/WueNLP","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["image-to-text","multilingual","Afrikaans","Amharic","Arabic"],"keywords_longer_than_N":true},
	{"name":"multilingual-queries-for-collected-works-of-milton-h-erickson","keyword":"german","description":"\n\t\n\t\t\n\t\tMultilingual Queries for the Collected Works of Milton H. Erickson\n\t\n\nThis collection contains machine-generated and translated queries designed to evaluate the performance of a multilingual retriever adapted to Ericksonian terminology.\nTo create the queries, the Collected Works of Milton H. Erickson was segmented into 500-word samples. Also, a list of relevant keywords was extracted from the Glossary of Ericksonian Terminology. Using the samples and keywords, queries were generated byâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/LoneWolfgang/multilingual-queries-for-collected-works-of-milton-h-erickson.","url":"https://huggingface.co/datasets/LoneWolfgang/multilingual-queries-for-collected-works-of-milton-h-erickson","creator_name":"Jordan Wolfgang Klein","creator_url":"https://huggingface.co/LoneWolfgang","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["translation","English","Portuguese","Japanese","Chinese"],"keywords_longer_than_N":true},
	{"name":"Tuda-De","keyword":"german","description":"\n\t\n\t\t\n\t\tOpen speech data for German speech recognition\n\t\n\nLanguage Technology, UniversitÃ¤t Hamburg, Germany\nhttps://www.inf.uni-hamburg.de/en/inst/ab/lt (formerly TU-Darmstadt)\nhttps://www.lt.tu-darmstadt.de\nTelecooperation labs, TU-Darmstadt, Germany\nhttps://www.tk.informatik.tu-darmstadt.de\n\n\t\n\t\t\n\t\n\t\n\t\tGeneral information\n\t\n\n\nThe speech data was collected in a controlled environment (same room, same microphone distances, etc. )\nDistance between speakers and the microphones is about 1 meterâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/uhhlt/Tuda-De.","url":"https://huggingface.co/datasets/uhhlt/Tuda-De","creator_name":"LT Group at UHH","creator_url":"https://huggingface.co/uhhlt","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","expert-generated","crowdsourced","monolingual","German"],"keywords_longer_than_N":true},
	{"name":"xgqa_1k","keyword":"german","description":"\n\t\n\t\t\n\t\txGQA 1K\n\t\n\n\n\t\n\t\t\n\t\tThis is a 1K subset of the few_shot-test split of the xGQA dataset\n\t\n\nPlease find the original repository here: https://github.com/adapter-hub/xGQA\nIf you use this dataset, please cite the original authors:\n@inproceedings{pfeiffer-etal-2021-xGQA,\n    title={{xGQA: Cross-Lingual Visual Question Answering}},\n    author={ Jonas Pfeiffer and Gregor Geigle and Aishwarya Kamath and Jan-Martin O. Steitz and Stefan Roth and Ivan Vuli{\\'{c}} and Iryna Gurevych},\n    booktitleâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/floschne/xgqa_1k.","url":"https://huggingface.co/datasets/floschne/xgqa_1k","creator_name":"Flo Schneider","creator_url":"https://huggingface.co/floschne","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["visual-question-answering","Bengali","German","English","Indonesian"],"keywords_longer_than_N":true},
	{"name":"MOL","keyword":"german","description":"\n\t\n\t\t\n\t\tMOL - Context-Aware Multilingual Offensive Lexicon\n\t\n\nThe MOL is the first specialized lexicon for hate speech detection, annotated with contextual information.\nIt consists of 1,000 explicit and implicit (clue-based) human-annotated rationales used with pejorative connotations, manually identified by a linguist and annotated by three experts regarding their contextual dependency (context-dependent or context-independent).\nFor example, the term \"stupid\" is classified as aâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/franciellevargas/MOL.","url":"https://huggingface.co/datasets/franciellevargas/MOL","creator_name":"Francielle Vargas","creator_url":"https://huggingface.co/franciellevargas","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","Portuguese","English","German","Spanish"],"keywords_longer_than_N":true},
	{"name":"integreat-qa","keyword":"german","description":"\n\t\n\t\t\n\t\tDataset\n\t\n\nOur dataset consists of 906 diverse QA pairs in German and English.\nThe dataset is extractive, i.e., answers are given as sentence indices (breaking at the newline character \\n).\nQuestions are automatically generated using an LLM.\nThe answers are manually annotated using voluntary crowdsourcing.\nRepository: More Information Needed\nPaper:\n\nhttps://arxiv.org/abs/1806.03822\nhttps://aclanthology.org/2024.konvens-main.25/\n\nOur dataset is licensed under cc-by-4.0.\n\n\t\t\n\t\tPropertiesâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/digitalfabrik/integreat-qa.","url":"https://huggingface.co/datasets/digitalfabrik/integreat-qa","creator_name":"TÃ¼r an TÃ¼r - Digitalfabrik gGmbH","creator_url":"https://huggingface.co/digitalfabrik","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["question-answering","extractive-qa","crowdsourced","original","German"],"keywords_longer_than_N":true},
	{"name":"multilingual-coco","keyword":"german","description":"\n\t\n\t\t\n\t\tMultilingual Common Objects in Context (COCO) Dataset\n\t\n\nThis dataset is a collection of multiple language open-source captions of COCO dataset. \nThe split in this dataset is set according to Andrej Karpathy's split from dataset_coco.json file. The collection was created specifically for simplicity of use in training and evaluation pipeline by non-commercial and research purposes. The COCO images dataset is licensed under a Creative Commons Attribution 4.0 License.â€¦ See the full description on the dataset page: https://huggingface.co/datasets/romrawinjp/multilingual-coco.","url":"https://huggingface.co/datasets/romrawinjp/multilingual-coco","creator_name":"Romrawin Chumpu","creator_url":"https://huggingface.co/romrawinjp","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["image-to-text","English","Thai","Russian","Japanese"],"keywords_longer_than_N":true},
	{"name":"orpo-dpo-mix-40k-llama3-de","keyword":"german","description":"johannhartmann/orpo-dpo-mix-40k-llama3-de dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/johannhartmann/orpo-dpo-mix-40k-llama3-de","creator_name":"Johann-Peter Hartmann","creator_url":"https://huggingface.co/johannhartmann","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["German","apache-2.0","10K - 100K","json","Text"],"keywords_longer_than_N":true},
	{"name":"MultiQ","keyword":"german","description":"\n\t\n\t\t\n\t\tDataset Card for MultiQ\n\t\n\nThis is the dataset corresponding to the paper \"Evaluating the Elementary Multilingual Capabilities of Large Language Models with MultiQ\". \nIt is a silver standard benchmark that can be used to evaluate the basic multilingual capabilities of LLMs. It contains 200 open ended questions automatically \ntranslated into 137 typologically diverse languages. \n\nCurated by: Carolin Holtermann, Paul RÃ¶ttger, Timm Dill, Anne Lauscher\nLanguage(s) (NLP): 137 diverseâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/caro-holt/MultiQ.","url":"https://huggingface.co/datasets/caro-holt/MultiQ","creator_name":"Holtermann","creator_url":"https://huggingface.co/caro-holt","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["question-answering","Tagalog","Samoan","Macedonian","Gujarati"],"keywords_longer_than_N":true},
	{"name":"OGC_Nuclear","keyword":"german","description":"\n\t\n\t\t\n\t\tOGC_Nuclear - Overview\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nOGC_Nuclear is a curated multimodal dataset focused on nuclear technical documents, regulations, and legal frameworks. It combines text and image data extracted from real scientific and regulatory PDFs to support tasks such as RAG DSE, question answering, document search, and vision-language model training.\n\n\t\n\t\t\n\t\tDataset Creation\n\t\n\nThis dataset was created using our open-source tool OGC_pdf-to-parquet.\nNuclear-related PDFs wereâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/racineai/OGC_Nuclear.","url":"https://huggingface.co/datasets/racineai/OGC_Nuclear","creator_name":"racine.ai","creator_url":"https://huggingface.co/racineai","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["question-answering","visual-question-answering","text-retrieval","English","French"],"keywords_longer_than_N":true},
	{"name":"CodeMixBench","keyword":"german","description":"\n\t\n\t\t\n\t\tâ„¹ï¸Dataset Card for CodeMixBench\n\t\n\n\n\t\n\t\t\n\t\t[EMNLP'25] CodeMixBench: Evaluating Code-Mixing Capabilities of LLMs Across 18 Languages\n\t\n\n   \n      \n   \n        \n  \n      \n   \n  \n      \n   \n\n\n\n\n\nCode-mixing is a linguistic phenomenon where multilingual speakers switch or mix two or more languages within a single utterance or conversation. \nTo evaluate LLMsâ€™ comprehension of multilingual code-mixed texts, we introduce CodeMixBench, a benchmark comprising eight tasks across 18 languages.â€¦ See the full description on the dataset page: https://huggingface.co/datasets/CodeMixBench/CodeMixBench.","url":"https://huggingface.co/datasets/CodeMixBench/CodeMixBench","creator_name":"CodeMixBench","creator_url":"https://huggingface.co/CodeMixBench","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["Chinese","English","Spanish","Hindi","German"],"keywords_longer_than_N":true},
	{"name":"JQL-Human-Edu-Annotations","keyword":"german","description":"\n\t\n\t\t\n\t\tðŸ“š JQL Multilingual Educational Quality Annotations\n\t\n\nThis dataset provides high-quality human annotations for evaluating the educational value of web documents, and serves as a benchmark for training and evaluating multilingual LLM annotators as described in the JQL paper.\n\n\n\t\n\t\t\n\t\tðŸ“ Dataset Summary\n\t\n\n\nDocuments: 511 English texts  \nAnnotations: 3 human ratings per document (0â€“5 scale)  \nTranslations: Into 35 European languages using DeepL and GPT-4o  \nPurpose: For training andâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/JQL-AI/JQL-Human-Edu-Annotations.","url":"https://huggingface.co/datasets/JQL-AI/JQL-Human-Edu-Annotations","creator_name":"JQL-AI","creator_url":"https://huggingface.co/JQL-AI","license_name":"Open Data Commons Attribution License v1.0","license_url":"https://scancode-licensedb.aboutcode.org/odc-by-1.0.html","language":"en","first_N":5,"first_N_keywords":["text-classification","Bulgarian","Czech","Croatian","Macedonian"],"keywords_longer_than_N":true},
	{"name":"Topic-specific-disambiguation_evaluation-dataset_German_historical-newspapers","keyword":"german","description":"\n\t\n\t\t\n\t\tDataset Card for German Topic-specific Disambiguation Dataset Historical Newspapers\n\t\n\nThis dataset contains German newspaper articles (1850-1950) labeled as either about relevant for \"return migration\" or not. It helps researchers develop word sense disambiguation methods - technology that can tell when the German word \"Heimkehr\" or \"RÃ¼ckkehr\" (return/homecoming) is being used to discuss people returning to their home countries versus when it's used in different contexts. This mattersâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/oberbics/Topic-specific-disambiguation_evaluation-dataset_German_historical-newspapers.","url":"https://huggingface.co/datasets/oberbics/Topic-specific-disambiguation_evaluation-dataset_German_historical-newspapers","creator_name":"Oberbichler","creator_url":"https://huggingface.co/oberbics","license_name":"Academic Free License v3.0","license_url":"https://choosealicense.com/licenses/afl-3.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","German","afl-3.0","< 1K","csv"],"keywords_longer_than_N":true},
	{"name":"OGC_Qualitative","keyword":"german","description":"\n\t\n\t\t\n\t\tOGC_Qualitative\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nOGC_Qualitative is a high-quality multimodal dataset created through the merge of multiple domain-specific datasets with enhanced data processing techniques. This dataset represents our most refined approach to multimodal data generation, incorporating filtering algorithms and improved AI-assisted content generation to deliver superior quality for RAG, DSE, question answering, document search, and vision-language model training tasks.â€¦ See the full description on the dataset page: https://huggingface.co/datasets/racineai/OGC_Qualitative.","url":"https://huggingface.co/datasets/racineai/OGC_Qualitative","creator_name":"racine.ai","creator_url":"https://huggingface.co/racineai","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["question-answering","visual-question-answering","text-retrieval","English","French"],"keywords_longer_than_N":true},
	{"name":"language-dataset","keyword":"german","description":"\n","url":"https://huggingface.co/datasets/neon-mao/language-dataset","creator_name":"maoqifan","creator_url":"https://huggingface.co/neon-mao","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","English","Chinese","French","Russian"],"keywords_longer_than_N":true},
	{"name":"SteamGRS","keyword":"german","description":"Steam German Review Sentiment (SteamGRS) for seminar work (LoRA experiments).\n","url":"https://huggingface.co/datasets/GabrielML/SteamGRS","creator_name":"Gabriel Schurr","creator_url":"https://huggingface.co/GabrielML","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","German","apache-2.0","10K - 100K","csv"],"keywords_longer_than_N":true},
	{"name":"multi30k","keyword":"german","description":"\n\t\n\t\t\n\t\tMulti30k Dataset\n\t\n\nThis dataset is a rearrangement version of the Multi30k dataset. The dataset was partially retrived from Multi30k original github.\n\n\t\n\t\t\n\t\tHow to use\n\t\n\nThis dataset can be downloaded from datasets library. train, validation, and test set are included in the dataset.\nfrom datasets import load_dataset\n\ndataset = load_dataset(\"romrawinjp/multi30k\")\n\n\n\t\n\t\t\n\t\tReference\n\t\n\nIf you find this dataset beneficial, please directly cite to their incredible work.â€¦ See the full description on the dataset page: https://huggingface.co/datasets/romrawinjp/multi30k.","url":"https://huggingface.co/datasets/romrawinjp/multi30k","creator_name":"Romrawin Chumpu","creator_url":"https://huggingface.co/romrawinjp","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["English","Czech","French","German","mit"],"keywords_longer_than_N":true},
	{"name":"ToxicCommons","keyword":"german","description":"\n\t\n\t\t\n\t\tToxic Commons\n\t\n\nToxic Commons is a release of 2 million samples of annotated, public domain, multilingual text that was used to train Celadon. \nIt is being released alongside Celadon, in order to better understand multilingual and multicultural toxicity. \nEach sample was classified across 5 axes of toxicity:\n\nRace and origin-based bias: includes racism as well as bias against someoneâ€™s country or region of origin or immigration status, especially immigrant or refugee status. \nGenderâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/PleIAs/ToxicCommons.","url":"https://huggingface.co/datasets/PleIAs/ToxicCommons","creator_name":"PleIAs","creator_url":"https://huggingface.co/PleIAs","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","English","French","Spanish","German"],"keywords_longer_than_N":true},
	{"name":"xtreme-up-semantic-parsing","keyword":"german","description":"\n\t\n\t\t\n\t\tDataset Card for afrixnli\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nSee XTREME-UP GitHub\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nThere are 20 languages available :\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\n\t\n\t\t\n\t\tData Instances\n\t\n\nThe examples look like this for English:\nfrom datasets import load_dataset\ndata = load_dataset('Davlan/xtreme-up-semantic-parsing', 'yor') \n# Please, specify the language code\n# A data point example is below:\n{\n\"id\": \"3231323330393336\",\n\"split\": \"test\",\n\"intent\": \"IN:GET_REMINDER\",\n\"locale\": \"en\"â€¦ See the full description on the dataset page: https://huggingface.co/datasets/Davlan/xtreme-up-semantic-parsing.","url":"https://huggingface.co/datasets/Davlan/xtreme-up-semantic-parsing","creator_name":"David Adelani","creator_url":"https://huggingface.co/Davlan","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","multilingual","Amharic","Belarusian","Bengali"],"keywords_longer_than_N":true},
	{"name":"emilia-yodas","keyword":"german","description":"A mirror of the Emilia-YODAS dataset. Only includes the YODAS subset from the original dataset.\nhttps://huggingface.co/datasets/amphion/Emilia-Dataset\n","url":"https://huggingface.co/datasets/TTS-AGI/emilia-yodas","creator_name":"TTS AGI","creator_url":"https://huggingface.co/TTS-AGI","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-to-speech","automatic-speech-recognition","English","German","French"],"keywords_longer_than_N":true},
	{"name":"MultiPICo","keyword":"german","description":"\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nMultiPICo (Multilingual Perspectivist Irony Corpus) is a disaggregated multilingual corpus for irony detection, containing 18,778 pairs of short conversations (post-reply) from Twitter (8,956) and Reddit (9,822), along with the demographic information of each annotator (age, nationality, gender, and so on). \n\n\t\n\t\t\n\t\tSupported Tasks and Leaderboards\n\t\n\nIrony classification task using soft labels (i.e., distribution of annotations) or hard labels (i.e., aggregatedâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Multilingual-Perspectivist-NLU/MultiPICo.","url":"https://huggingface.co/datasets/Multilingual-Perspectivist-NLU/MultiPICo","creator_name":"MultilingualPerspectivistNLU","creator_url":"https://huggingface.co/Multilingual-Perspectivist-NLU","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["Spanish","English","German","Arabic","Portuguese"],"keywords_longer_than_N":true},
	{"name":"German_RisingWorld_prompt-text-rejected_Jsonl","keyword":"german","description":"\n\t\n\t\t\n\t\tGerman \"Rising World\"-Game Dataset\n\t\n\n\n\t\n\t\t\n\t\tData Description\n\t\n\nThis HF data repository contains the German dataset for the open-world sandbox game \"Rising World\".\nDieses HF-Datenrepository enthÃ¤lt den deutschen Datensatz fÃ¼r das Open-World-Sandbox-Spiel \"Rising World\".\n\n\t\n\t\t\n\t\tUsage\n\t\n\n\nThis data is intended for fine-tuning\nThis data is useful for \"Rising World\" plug-in developers\n\n","url":"https://huggingface.co/datasets/Andzej-75/German_RisingWorld_prompt-text-rejected_Jsonl","creator_name":"Andzej Ktowierzy","creator_url":"https://huggingface.co/Andzej-75","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","question-answering","German","apache-2.0","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"German_RisingWorld_prompt-text-rejected_Jsonl","keyword":"german","description":"\n\t\n\t\t\n\t\tGerman \"Rising World\"-Game Dataset\n\t\n\n\n\t\n\t\t\n\t\tData Description\n\t\n\nThis HF data repository contains the German dataset for the open-world sandbox game \"Rising World\".\nDieses HF-Datenrepository enthÃ¤lt den deutschen Datensatz fÃ¼r das Open-World-Sandbox-Spiel \"Rising World\".\n\n\t\n\t\t\n\t\tUsage\n\t\n\n\nThis data is intended for fine-tuning\nThis data is useful for \"Rising World\" plug-in developers\n\n","url":"https://huggingface.co/datasets/Andzej-75/German_RisingWorld_prompt-text-rejected_Jsonl","creator_name":"Andzej Ktowierzy","creator_url":"https://huggingface.co/Andzej-75","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","question-answering","German","apache-2.0","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"Diplomatarium-Fennicum","keyword":"german","description":"\n\t\n\t\t\n\t\tDiplomatarium Fennicum-dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset summary\n\t\n\nDataset consisting of eight data fields taken from the Diplomatarium Fennicum -database. \nDiplomatarium Fennicum -database contains medieval charters and text excerpts conserning Finland and Finns, \nand is published and maintained by the National Archives of Finland.\nThe data fields selected are central to identifying, categorizing and analyzing the texts. \nThe dataset represents only very minimally the whole database; theâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Kansallisarkisto/Diplomatarium-Fennicum.","url":"https://huggingface.co/datasets/Kansallisarkisto/Diplomatarium-Fennicum","creator_name":"National Archives of Finland","creator_url":"https://huggingface.co/Kansallisarkisto","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["Finnish","Swedish","Latin","German","cc0-1.0"],"keywords_longer_than_N":true},
	{"name":"tatoeba_kbd_filtered","keyword":"german","description":"\n\t\n\t\t\n\t\tTatoeba Kabardian Filtered Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset is a filtered version of the Multilingual-to-Kabardian Tatoeba Translations Dataset, containing higher-quality parallel sentence translations to Kabardian language (kbd). The dataset has been further filtered to ensure greater translation accuracy and consistency.\nThe source languages are:\n\n\t\n\t\t\nLanguage Code\nLanguage Name\nNumber of Examples\n\n\n\t\t\neng_Latn\nEnglish\n468,894\n\n\nrus_Cyrl\nRussian\n284,256â€¦ See the full description on the dataset page: https://huggingface.co/datasets/panagoa/tatoeba_kbd_filtered.","url":"https://huggingface.co/datasets/panagoa/tatoeba_kbd_filtered","creator_name":"adam panagov","creator_url":"https://huggingface.co/panagoa","license_name":"Creative Commons Attribution 2.0","license_url":"https://scancode-licensedb.aboutcode.org/cc-by-2.0.html","language":"en","first_N":5,"first_N_keywords":["translation","Kabardian","German","English","French"],"keywords_longer_than_N":true},
	{"name":"multilingual_translation_sft","keyword":"german","description":"Youseff1987/multilingual_translation_sft dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/Youseff1987/multilingual_translation_sft","creator_name":"JOON HYOUNG JUN","creator_url":"https://huggingface.co/Youseff1987","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["translation","Korean","English","Chinese","Zulu"],"keywords_longer_than_N":true},
	{"name":"finepdfs-summaries","keyword":"german","description":"\n\t\n\t\t\n\t\tfinepdfs-summaries\n\t\n\nSummaries generated with Qwen3-Next-80B-A3B-Instruct for documents from finepdfs.\nWork in progress, still generating more data.\nThe following table shows the size for each language:\n\n\t\n\t\t\nLanguage\nSummaries\nTokens\nDisk size\n\n\n\t\t\nAll\n764,482,142\n224 B\n336 GB\n\n\ndeu_Latn\n343,089,235\n106 B\n141 GB\n\n\neng_Latn\n321,343,046\n81 B\n150 GB\n\nfra_Latn\n27,308,302\n10 B\n14 GB\n\n\nspa_Latn\n25,624,727\n9 B\n12 GB\n\n\nita_Latn\n17,587,618\n6 B\n8 GB\n\n\npor_Latn\n12,043,607\n4 B\n5 GB\n\n\npol_Latn\n9â€¦ See the full description on the dataset page: https://huggingface.co/datasets/maxidl/finepdfs-summaries.","url":"https://huggingface.co/datasets/maxidl/finepdfs-summaries","creator_name":"Max Idahl","creator_url":"https://huggingface.co/maxidl","license_name":"Open Data Commons Attribution License v1.0","license_url":"https://scancode-licensedb.aboutcode.org/odc-by-1.0.html","language":"en","first_N":5,"first_N_keywords":["text-generation","summarization","English","German","French"],"keywords_longer_than_N":true},
	{"name":"mtg-cards-SIFT-Features","keyword":"german","description":"\n\t\n\t\t\n\t\tMTG Card SIFT Features Dataset (v5.1)\n\t\n\n\nThis dataset contains the latest incremental MTG card SIFT + RootSIFT feature extraction pipeline. It is designed for server-side production inference, enabling additive updates to the FAISS index and id_map.json without retraining or reindexing from scratch.\n\nNote: This version aligns with a daily resources-nightly.zip Hugging Face upload workflow for reliable continuous deployment via my production server.\n\n\n\n\t\n\t\n\t\n\t\tWhatâ€™s New in v5.1?â€¦ See the full description on the dataset page: https://huggingface.co/datasets/JakeTurner616/mtg-cards-SIFT-Features.","url":"https://huggingface.co/datasets/JakeTurner616/mtg-cards-SIFT-Features","creator_name":"Jake Turner","creator_url":"https://huggingface.co/JakeTurner616","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":null,"first_N":5,"first_N_keywords":["feature-extraction","English","French","German","Italian"],"keywords_longer_than_N":true},
	{"name":"YouTube-Commons-descriptions","keyword":"german","description":"\n\t\n\t\t\n\t\tYouTube Commons Descriptions and Language Detection\n\t\n\nThis dataset adds titles, descriptions and language detection to YouTube Commons, a valuable open dataset:\n\nYouTube-Commons is a collection of audio transcripts of 2,063,066 videos shared on YouTube under a CC BY 4.0 license.\nContent\nThe collection comprises 22,709,724 original and automatically translated transcripts from 3,156,703 videos (721,136 individual channels).\n\nUnfortunately I have found that the detection of the originalâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Rijgersberg/YouTube-Commons-descriptions.","url":"https://huggingface.co/datasets/Rijgersberg/YouTube-Commons-descriptions","creator_name":"Edwin Rijgersberg","creator_url":"https://huggingface.co/Rijgersberg","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["English","French","Spanish","Portuguese","German"],"keywords_longer_than_N":true},
	{"name":"M-ABSA","keyword":"german","description":"\n\t\n\t\t\n\t\tM-ABSA\n\t\n\nThis repo contains the data for our paper M-ABSA: A Multilingual Dataset for Aspect-Based Sentiment Analysis.\n\n\n\t\n\t\t\n\t\tData Description:\n\t\n\nThis is a dataset suitable for the multilingual ABSA task with triplet extraction.\nAll datasets are stored in the data/ folder:\n\nAll dataset contains 7 domains.\n\ndomains = [\"coursera\", \"hotel\", \"laptop\", \"restaurant\", \"phone\", \"sight\", \"food\"]\n\n\nEach dataset contains 21 languages.\n\nlangs = [\"ar\", \"da\", \"de\", \"en\", \"es\", \"fr\", \"hi\", \"hr\"â€¦ See the full description on the dataset page: https://huggingface.co/datasets/Multilingual-NLP/M-ABSA.","url":"https://huggingface.co/datasets/Multilingual-NLP/M-ABSA","creator_name":"multilingual-NLP","creator_url":"https://huggingface.co/Multilingual-NLP","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["token-classification","text-classification","Arabic","Danish","German"],"keywords_longer_than_N":true},
	{"name":"wikipedia_quality_wikirank","keyword":"german","description":"Datasets with WikiRank quality score as of 1 August 2024 for 47 million Wikipedia articles in 55 language versions (also simplified version for each language in separate files).\nThe WikiRank quality score is a metric designed to assess the overall quality of a Wikipedia article. Although its specific algorithm can vary depending on the implementation, the score typically combines several key features of the Wikipedia article.\n\n\t\n\t\t\n\t\n\t\n\t\tWhy Itâ€™s Important\n\t\n\n\nEnhances Trust: For readers andâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/lewoniewski/wikipedia_quality_wikirank.","url":"https://huggingface.co/datasets/lewoniewski/wikipedia_quality_wikirank","creator_name":"WÅ‚odzimierz Lewoniewski","creator_url":"https://huggingface.co/lewoniewski","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["Arabic","Azerbaijani","Belarusian","Bulgarian","Catalan"],"keywords_longer_than_N":true},
	{"name":"SpeakGer_sample","keyword":"german","description":"This data set contains all speeches of all German federal state parliaments as well as the Bundestag from 2022, that are not interjections from the crowd or comments by the chair of the plenary session. Some additional meta data is provided, such as the date of the speech as well as the party/parties of the speaker.\nThis is a small test sample of the SpeakGer data set, restricted to the year 2022 and with limited meta data. For more information, please visit the official GitHub page. Whenâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/K-RLange/SpeakGer_sample.","url":"https://huggingface.co/datasets/K-RLange/SpeakGer_sample","creator_name":"Kai Robin Lange","creator_url":"https://huggingface.co/K-RLange","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["German","mit","100K - 1M","csv","Text"],"keywords_longer_than_N":true},
	{"name":"emonet-voice-foundation","keyword":"german","description":"EmoNet Voice Foundation can be found under this link.\n","url":"https://huggingface.co/datasets/t1a5anu-anon/emonet-voice-foundation","creator_name":"t1a5anu-anon","creator_url":"https://huggingface.co/t1a5anu-anon","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":null,"first_N":5,"first_N_keywords":["English","French","Spanish","German","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"swiss-ner","keyword":"german","description":"SwissNER-Spoken is a curated collection of 173 short, spoken-style German sentences\n    designed to evaluate Named-Entity Recognition (NER) and Automatic Speech Recognition (ASR)\n    systems on Swiss-specific proper nouns.\n\n\t\n\t\t\n\t\tKey features\n\t\n\nâ€¢ Focus on Switzerland â€“ Every sentence contains up to three named entities that appear\nin everyday Swiss contexts: cities, villages, cantons, companies, mountains, lakes,\nrivers, landmarks, organizations, events and well-known personalities.\nâ€¢â€¦ See the full description on the dataset page: https://huggingface.co/datasets/i4ds/swiss-ner.","url":"https://huggingface.co/datasets/i4ds/swiss-ner","creator_name":"Institute for Data Science","creator_url":"https://huggingface.co/i4ds","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["German","cc-by-4.0","< 1K","parquet","Audio"],"keywords_longer_than_N":true},
	{"name":"fineweb-2","keyword":"german","description":"\n\t\n\t\t\n\t\tðŸ¥‚ FineWeb2\n\t\n\n\n    \n\n\n\nA sparkling update with 1000s of languages\n\n\n\t\n\t\t\n\t\tWhat is it?\n\t\n\nThis is the second iteration of the popular ðŸ· FineWeb dataset, bringing high quality pretraining data to over 1000 ðŸ—£ï¸ languages.\nThe ðŸ¥‚ FineWeb2 dataset is fully reproducible, available under the permissive ODC-By 1.0 license and extensively validated through hundreds of ablation experiments.\nIn particular, on the set of 9 diverse languages we used to guide our processing decisions, ðŸ¥‚ FineWeb2â€¦ See the full description on the dataset page: https://huggingface.co/datasets/HuggingFaceFW/fineweb-2.","url":"https://huggingface.co/datasets/HuggingFaceFW/fineweb-2","creator_name":"FineData","creator_url":"https://huggingface.co/HuggingFaceFW","license_name":"Open Data Commons Attribution License v1.0","license_url":"https://scancode-licensedb.aboutcode.org/odc-by-1.0.html","language":"en","first_N":5,"first_N_keywords":["text-generation","Arifama-Miniafia","Ankave","Abau","Amarasi"],"keywords_longer_than_N":true},
	{"name":"fineweb-2","keyword":"swiss german","description":"\n\t\n\t\t\n\t\tðŸ¥‚ FineWeb2\n\t\n\n\n    \n\n\n\nA sparkling update with 1000s of languages\n\n\n\t\n\t\t\n\t\tWhat is it?\n\t\n\nThis is the second iteration of the popular ðŸ· FineWeb dataset, bringing high quality pretraining data to over 1000 ðŸ—£ï¸ languages.\nThe ðŸ¥‚ FineWeb2 dataset is fully reproducible, available under the permissive ODC-By 1.0 license and extensively validated through hundreds of ablation experiments.\nIn particular, on the set of 9 diverse languages we used to guide our processing decisions, ðŸ¥‚ FineWeb2â€¦ See the full description on the dataset page: https://huggingface.co/datasets/HuggingFaceFW/fineweb-2.","url":"https://huggingface.co/datasets/HuggingFaceFW/fineweb-2","creator_name":"FineData","creator_url":"https://huggingface.co/HuggingFaceFW","license_name":"Open Data Commons Attribution License v1.0","license_url":"https://scancode-licensedb.aboutcode.org/odc-by-1.0.html","language":"en","first_N":5,"first_N_keywords":["text-generation","Arifama-Miniafia","Ankave","Abau","Amarasi"],"keywords_longer_than_N":true},
	{"name":"panlex-definitions","keyword":"german","description":"\n\t\n\t\t\n\t\tDataset Card for panlex-definitions\n\t\n\nThis is a dataset of word definitions in several hudnred languages, extracted from https://panlex.org.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset has been extracted from https://panlex.org (the 20250201 database dump) and rearranged on the per-language basis (by the language of the definition).\nEach language subset consists of definitions (short phrases).\nEach definition is associated with some meanings (if there isâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/cointegrated/panlex-definitions.","url":"https://huggingface.co/datasets/cointegrated/panlex-definitions","creator_name":"David Dale","creator_url":"https://huggingface.co/cointegrated","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["translation","Abkhazian","Hijazi Arabic","Afrikaans","Ainu (Japan)"],"keywords_longer_than_N":true},
	{"name":"common_voice_21_0","keyword":"german","description":"Due to storage limits some files had to be split into multiple parts. They can be merged like this: cat file.* > file.\n","url":"https://huggingface.co/datasets/2Jyq/common_voice_21_0","creator_name":"2Jyq","creator_url":"https://huggingface.co/2Jyq","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["crowdsourced","crowdsourced","multilingual","extended|common_voice","Abkhaz"],"keywords_longer_than_N":true},
	{"name":"MELA","keyword":"german","description":"See the GitHub repo for details.\n","url":"https://huggingface.co/datasets/Geralt-Targaryen/MELA","creator_name":"Ziyin Zhang","creator_url":"https://huggingface.co/Geralt-Targaryen","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","English","Chinese","Italian","Russian"],"keywords_longer_than_N":true},
	{"name":"panlex-definitions","keyword":"swiss german","description":"\n\t\n\t\t\n\t\tDataset Card for panlex-definitions\n\t\n\nThis is a dataset of word definitions in several hudnred languages, extracted from https://panlex.org.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset has been extracted from https://panlex.org (the 20250201 database dump) and rearranged on the per-language basis (by the language of the definition).\nEach language subset consists of definitions (short phrases).\nEach definition is associated with some meanings (if there isâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/cointegrated/panlex-definitions.","url":"https://huggingface.co/datasets/cointegrated/panlex-definitions","creator_name":"David Dale","creator_url":"https://huggingface.co/cointegrated","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["translation","Abkhazian","Hijazi Arabic","Afrikaans","Ainu (Japan)"],"keywords_longer_than_N":true},
	{"name":"R3-eval-MMMLU","keyword":"german","description":"HLeiTR/R3-eval-MMMLU dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/HLeiTR/R3-eval-MMMLU","creator_name":"Shou-Yi Hung","creator_url":"https://huggingface.co/HLeiTR","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["question-answering","Arabic","Bengali","German","Spanish"],"keywords_longer_than_N":true},
	{"name":"jinaai_jina-embeddings-v2-base-en-03092024-k007-webapp","keyword":"german","description":"\n\t\n\t\t\n\t\tjinaai_jina-embeddings-v2-base-en-03092024-k007-webapp Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset \"health insurance information in German\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\n\n\t\n\t\t\n\t\tAssociated Model\n\t\n\nThis dataset was used to train the jinaai_jina-embeddings-v2-base-en-03092024-k007-webapp model.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nTo use this dataset for model training or evaluation, you can load it usingâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/jinaai_jina-embeddings-v2-base-en-03092024-k007-webapp.","url":"https://huggingface.co/datasets/fine-tuned/jinaai_jina-embeddings-v2-base-en-03092024-k007-webapp","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","German","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"GPT-4-Self-Instruct-German","keyword":"german","description":"Here we share a German dataset synthesized using the OpenAI GPT-4 model with Self-Instruct, utilizing some excess Azure credits. Please feel free to use it. All questions and answers are newly generated by GPT-4, without specialized verification, only simple filtering and strict semantic similarity control have been applied.\nWe hope that this will be helpful for fine-tuning open-source models for non-English languages, particularly German. This dataset will be updated continuously.\n","url":"https://huggingface.co/datasets/CausalLM/GPT-4-Self-Instruct-German","creator_name":"CausalLM","creator_url":"https://huggingface.co/CausalLM","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","German","cc-by-4.0","10K - 100K","json"],"keywords_longer_than_N":true},
	{"name":"PolyGuardPrompts","keyword":"german","description":"\n\t\n\t\t\n\t\tPolyGuard: A Multilingual Safety Moderation Tool for 17 Languages\n\t\n\nAbstract: Truly multilingual safety moderation efforts for Large Language Models (LLMs) have been hindered by a narrow focus on a small set of languages (e.g., English, Chinese) as well as a limited scope of safety definition, resulting in significant gaps in moderation capabilities. To bridge these gaps, we release PolyGuard, a new state-of-the-art multilingual safety model for safeguarding LLM generations, and theâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/ToxicityPrompts/PolyGuardPrompts.","url":"https://huggingface.co/datasets/ToxicityPrompts/PolyGuardPrompts","creator_name":"ToxicityPrompts","creator_url":"https://huggingface.co/ToxicityPrompts","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["Arabic","Chinese","Czech","Dutch","English"],"keywords_longer_than_N":true},
	{"name":"BenchMAX_Domain_Translation","keyword":"german","description":"\n\t\n\t\t\n\t\tDataset Sources\n\t\n\n\nPaper: BenchMAX: A Comprehensive Multilingual Evaluation Suite for Large Language Models\nLink: https://huggingface.co/papers/2502.07346\nRepository: https://github.com/CONE-MT/BenchMAX\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nBenchMAX_Domain_Translation is a dataset of BenchMAX, which evaluates the translation capability on specific domains.\nWe collect the domain multi-way parallel data from other tasks in BenchMAX, such as math data, code data, etc.\nEach sample contains oneâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/LLaMAX/BenchMAX_Domain_Translation.","url":"https://huggingface.co/datasets/LLaMAX/BenchMAX_Domain_Translation","creator_name":"LLaMAX","creator_url":"https://huggingface.co/LLaMAX","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["translation","multilingual","English","Chinese","Spanish"],"keywords_longer_than_N":true},
	{"name":"GlobalDISCO","keyword":"german","description":"\n\t\n\t\t\n\t\tGlobalDISCO\n\t\n\nGlobalDISCO is a large-scale dataset consisting of 73k music tracks generated by state-of-the-art commercial generative music models, along with paired links to 93k reference tracks in LAION-DISCO-12M. The dataset spans 147 languages and includes musical style prompts extracted from MusicBrainz and Wikipedia. The dataset is globally balanced, representing musical styles from artists across 79 countries and five continents. It is aimed to support the research community inâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/disco-eth/GlobalDISCO.","url":"https://huggingface.co/datasets/disco-eth/GlobalDISCO","creator_name":"DISCO","creator_url":"https://huggingface.co/disco-eth","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["audio-classification","English","Spanish","French","German"],"keywords_longer_than_N":true},
	{"name":"TransWebEdu","keyword":"german","description":"\n\t\n\t\t\n\t\tTransWebEdu\n\t\n\nTransWebEdu is a machine-translated, multi-way parallel, multilingual dataset at pretrain scale, supporting ten languages: Arabic, Welsh, German, English, Spanish, French, Indonesian, Italian, Russian, and Swahili.It is used to pretrain the TransWebLLM model from scratch, with a focus on multilingual web-based education content.\nFor more information, see the paper:Multilingual Language Model Pretraining using Machine-translated Data\n\n\t\n\t\t\n\t\n\t\n\t\tLanguages Supportedâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/britllm/TransWebEdu.","url":"https://huggingface.co/datasets/britllm/TransWebEdu","creator_name":"BritLLM","creator_url":"https://huggingface.co/britllm","license_name":"Open Data Commons Attribution License v1.0","license_url":"https://scancode-licensedb.aboutcode.org/odc-by-1.0.html","language":null,"first_N":5,"first_N_keywords":["Arabic","Welsh","English","Spanish","French"],"keywords_longer_than_N":true},
	{"name":"Voila-million-voice","keyword":"german","description":"\n    \n    Voila: Voice-Language Foundation Models\n    ðŸ’œ Project Page Â Â  ï½œ Â Â  ðŸ–¥ï¸ GitHub Â Â   | Â Â ðŸ¤— Hugging FaceÂ Â  | Â Â  ðŸ“‘ Paper Â Â  | Â Â  ðŸŒ Online Demo Â Â | Â Â  ðŸ Maitrix.org\n\n\nVoila is a new family of large voice-language foundation models aiming to lift human-AI interaction experiences to the next level. Breaking away from the constraints of traditional voice AI systemsâ€”high latency, loss of vocal nuances, and mechanical responsesâ€”Voila employs an innovative end-to-end model design and a novelâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/maitrix-org/Voila-million-voice.","url":"https://huggingface.co/datasets/maitrix-org/Voila-million-voice","creator_name":"Maitrix.org","creator_url":"https://huggingface.co/maitrix-org","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":null,"first_N":5,"first_N_keywords":["English","Chinese","French","German","Japanese"],"keywords_longer_than_N":true},
	{"name":"ngram-google-2012","keyword":"german","description":"python -m spacy download en_core_web_sm\n\nTitles:\njq -s '.[].title' raw/dict.jsonl\n\nreturns\n\n \"English\"\n \"English One Million\"\n \"American English\"\n \"British English\"\n \"English Fiction\"\n \"Chinese (simplified)\"\n \"French\"\n \"German\"\n \"Hebrew\"\n \"Italian\"\n \"Russian\"\n \"Spanish\"\n\nSpellcheck:\nhttps://pypi.org/project/pyspellchecker/\nEnglish - â€˜enâ€™\nSpanish - â€˜esâ€™\nFrench - â€˜frâ€™\nPortuguese - â€˜ptâ€™\nGerman - â€˜deâ€™\nRussian - â€˜ruâ€™\nArabic - â€˜arâ€™\n\nSets now:\n\n \"English\" - en\n \"Spanish\" - es\n \"French\" - fr\n \"German\"â€¦ See the full description on the dataset page: https://huggingface.co/datasets/gustawdaniel/ngram-google-2012.","url":"https://huggingface.co/datasets/gustawdaniel/ngram-google-2012","creator_name":"Daniel Gustaw","creator_url":"https://huggingface.co/gustawdaniel","license_name":"Creative Commons Attribution 3.0","license_url":"https://scancode-licensedb.aboutcode.org/cc-by-3.0.html","language":"en","first_N":5,"first_N_keywords":["English","Spanish","French","Portuguese","German"],"keywords_longer_than_N":true},
	{"name":"German4All-Corpus","keyword":"german","description":"\n\t\n\t\t\n\t\tDataset Card for the German4All Corpus of datasets\n\t\n\nPaper | Code\n\n\t\n\t\t\n\t\tCorpus Overview\n\t\n\nGerman4All is a synthetic data corpus consisting of 3 datasets. Each dataset consists of German Wikipedia paragraphs that are paraphrased in five different complexity levels. The 3 datasets are:\n\nGerman4All-Main (subfolder \"main\"): The main synthetic dataset containing 25,459 elements, each featuring an\noriginal text along with its five-level paraphrases. \nGerman4All-Main-old (subfolderâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/tum-nlp/German4All-Corpus.","url":"https://huggingface.co/datasets/tum-nlp/German4All-Corpus","creator_name":"Natural Language Processing @ TUM","creator_url":"https://huggingface.co/tum-nlp","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-generation","German","mit","10K<n<100K","arxiv:2508.17973"],"keywords_longer_than_N":true},
	{"name":"German4All-Corpus","keyword":"german","description":"\n\t\n\t\t\n\t\tDataset Card for the German4All Corpus of datasets\n\t\n\nPaper | Code\n\n\t\n\t\t\n\t\tCorpus Overview\n\t\n\nGerman4All is a synthetic data corpus consisting of 3 datasets. Each dataset consists of German Wikipedia paragraphs that are paraphrased in five different complexity levels. The 3 datasets are:\n\nGerman4All-Main (subfolder \"main\"): The main synthetic dataset containing 25,459 elements, each featuring an\noriginal text along with its five-level paraphrases. \nGerman4All-Main-old (subfolderâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/tum-nlp/German4All-Corpus.","url":"https://huggingface.co/datasets/tum-nlp/German4All-Corpus","creator_name":"Natural Language Processing @ TUM","creator_url":"https://huggingface.co/tum-nlp","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-generation","German","mit","10K<n<100K","arxiv:2508.17973"],"keywords_longer_than_N":true},
	{"name":"RAGAS_xquad","keyword":"german","description":"data source: https://github.com/google-deepmind/xquad (base on squad 1.0)\ndocument_en/de.zip contains all 48 documents for answer the question: created by concatenate continous pragraphs\nQuestion,Answer, Context (QAC) pair in english(en) AND german(de)\n\nclean_full_en_de: 48 documents, 5 paragraphs per document, multiple questions per paragraph\nsingle_qa_en_de: 48 documents, 5 paragraphs per document, one question per paragraph\ntest_half: 24 documents, 5 paragraphs per document, one questionâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/xxizhouu/RAGAS_xquad.","url":"https://huggingface.co/datasets/xxizhouu/RAGAS_xquad","creator_name":"Zhou","creator_url":"https://huggingface.co/xxizhouu","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["question-answering","German","English","mit","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"open_government","keyword":"german","description":"\n\t\n\t\t\n\t\tOpen Government Dataset\n\t\n\nOpen Government is the largest agregation of governement text and data made available as part of open data programs. \nIn total, the dataset contains approximately 380B tokens. While Open Government aims to become a global resource, in its current state it mostly features open datasets from the US, France, European and international organizations.\nThe dataset comprises 16 collections curated through two different initiaties: Finance commons and Legal commons.â€¦ See the full description on the dataset page: https://huggingface.co/datasets/AgentPublic/open_government.","url":"https://huggingface.co/datasets/AgentPublic/open_government","creator_name":"AgentPublic","creator_url":"https://huggingface.co/AgentPublic","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","English","French","Bulgarian","Croatian"],"keywords_longer_than_N":true},
	{"name":"ARK-Metadata","keyword":"german","description":"\n\t\n\t\t\n\t\tMetadata of the \"Alter Realkatalog\" (ARK) of Berlin State Library (SBB)\n\t\n\n\n\t\n\t\t\n\t\tMotivation\n\t\n\nThis dataset was created with the intent to provide a single larger set of metadata from Berlin State Library for research purposes and the development of AI applications.\nThe dataset comprises of descriptive metadata of 2.619.397 titles, which together form the \"Alte Realkatalog\" of Berlin State Libray, which may be translated to \"Old Subject Catalogue\". The data are stored in columnarâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/SBB/ARK-Metadata.","url":"https://huggingface.co/datasets/SBB/ARK-Metadata","creator_name":"Staatsbibliothek zu Berlin - PreuÃŸischer Kulturbesitz","creator_url":"https://huggingface.co/SBB","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","feature-extraction","German","Latin","English"],"keywords_longer_than_N":true},
	{"name":"wildchat-filtered","keyword":"german","description":"\n\t\n\t\t\n\t\tWildChat Filtered Dataset\n\t\n\nThis is a filtered version of the WildChat-4.8M dataset.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset contains 3,199,860 conversations between human users and ChatGPT, filtered to keep only the essential conversation structure.\n\n\t\n\t\t\n\t\tData Structure\n\t\n\nEach conversation contains only:\n\nconversations: A list of message objects with:\nrole: Either \"user\" or \"assistant\"\ncontent: The text content of the message\n\n\n\nAll other metadata (timestamps, moderationâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/rayonlabs/wildchat-filtered.","url":"https://huggingface.co/datasets/rayonlabs/wildchat-filtered","creator_name":"Rayon Labs","creator_url":"https://huggingface.co/rayonlabs","license_name":"Open Data Commons Attribution License v1.0","license_url":"https://scancode-licensedb.aboutcode.org/odc-by-1.0.html","language":"en","first_N":5,"first_N_keywords":["text-generation","question-answering","English","Spanish","French"],"keywords_longer_than_N":true},
	{"name":"wildchat-filtered","keyword":"swiss german","description":"\n\t\n\t\t\n\t\tWildChat Filtered Dataset\n\t\n\nThis is a filtered version of the WildChat-4.8M dataset.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset contains 3,199,860 conversations between human users and ChatGPT, filtered to keep only the essential conversation structure.\n\n\t\n\t\t\n\t\tData Structure\n\t\n\nEach conversation contains only:\n\nconversations: A list of message objects with:\nrole: Either \"user\" or \"assistant\"\ncontent: The text content of the message\n\n\n\nAll other metadata (timestamps, moderationâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/rayonlabs/wildchat-filtered.","url":"https://huggingface.co/datasets/rayonlabs/wildchat-filtered","creator_name":"Rayon Labs","creator_url":"https://huggingface.co/rayonlabs","license_name":"Open Data Commons Attribution License v1.0","license_url":"https://scancode-licensedb.aboutcode.org/odc-by-1.0.html","language":"en","first_N":5,"first_N_keywords":["text-generation","question-answering","English","Spanish","French"],"keywords_longer_than_N":true},
	{"name":"GPT-CitizenService-QA-de","keyword":"german","description":"D4ve-R/GPT-CitizenService-QA-de dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/D4ve-R/GPT-CitizenService-QA-de","creator_name":"David","creator_url":"https://huggingface.co/D4ve-R","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["question-answering","text2text-generation","German","mit","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"mars","keyword":"german","description":"\n\t\n\t\t\n\t\tEris Dataworks - Mars Data Overview\n\t\n\nEris Dataworks is a part of Berinspa, an initiative focused on data exploration and intelligent technologies for a better future.\nThis repository contains exploration data related to the planet Mars, stored in the mars.csv file. The data can be used for scientific analysis, machine learning, or data visualization purposes.\n\n\t\n\t\t\n\t\tData Structure\n\t\n\nThe mars.csv file may include (depending on its contents):\n\nMars environmental parametersâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/erisdataworks/mars.","url":"https://huggingface.co/datasets/erisdataworks/mars","creator_name":"Eris Dataworks","creator_url":"https://huggingface.co/erisdataworks","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["Indonesian","English","Spanish","German","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"ai-culture-multilingual-json-dolma","keyword":"german","description":"\n\t\n\t\t\n\t\tAI-Culture Multilingual JSON + DOLMA Corpus\n\t\n\n\n16M words Â· 12 languages Â· CC-BY-4.0\n\nThe AI-Culture corpus contains 5K articles providing comprehensive philosophical and cultural content, exploring the intersection of technology, artificial intelligence, and human culture, perfectly aligned across 12 languages. All content maintains identical parallel structure across translations with zero duplication and editor-curated quality.\nThis project is maintained by a non-profit digitalâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/AI-Culture-Commons/ai-culture-multilingual-json-dolma.","url":"https://huggingface.co/datasets/AI-Culture-Commons/ai-culture-multilingual-json-dolma","creator_name":"AIâ€‘Cultureâ€‘Commons","creator_url":"https://huggingface.co/AI-Culture-Commons","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["translation","text-generation","text-classification","sentence-similarity","summarization"],"keywords_longer_than_N":true},
	{"name":"tatoeba-bitext-mining","keyword":"swiss german","description":"\n  Tatoeba\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\n1,000 English-aligned sentence pairs for each language based on the Tatoeba corpus\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2t\n\n\nDomains\nWritten\n\n\nReference\nhttps://github.com/facebookresearch/LASER/tree/main/data/tatoeba/v1\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask = mteb.get_tasks([\"Tatoeba\"])\nevaluator = mteb.MTEB(task)\n\nmodel =â€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/tatoeba-bitext-mining.","url":"https://huggingface.co/datasets/mteb/tatoeba-bitext-mining","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"Creative Commons Attribution 2.0","license_url":"https://scancode-licensedb.aboutcode.org/cc-by-2.0.html","language":"en","first_N":5,"first_N_keywords":["translation","human-annotated","multilingual","Afrikaans","Amharic"],"keywords_longer_than_N":true},
	{"name":"SN-echoes","keyword":"german","description":"[Paper] | [GitHub]\n\n\t\n\t\t\n\t\tDataset Card for SoccerNet-Echoes\n\t\n\nThis dataset card aims to provide comprehensive details for the SoccerNet-Echoes dataset, an audio commentary dataset for soccer games.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nSoccerNet-Echoes is an audio commentary dataset for soccer games, curated by SimulaMet under the AI-Storyteller project. It is funded by the Research Council of Norway (project number 346671) and shared by the SoccerNet team. The datasetâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/SoccerNet/SN-echoes.","url":"https://huggingface.co/datasets/SoccerNet/SN-echoes","creator_name":"SoccerNet","creator_url":"https://huggingface.co/SoccerNet","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["summarization","translation","English","Spanish","Russian"],"keywords_longer_than_N":true},
	{"name":"cghd","keyword":"german","description":"\n\t\n\t\t\n\t\tA Public Ground-Truth Dataset for Handwritten Circuit Diagrams (CGHD)\n\t\n\nThis repository contains images of hand-drawn electrical circuit diagrams as well as accompanying bounding box annotation, polygon annotation and segmentation files. These annotations serve as ground truth to train and evaluate several image processing tasks like object detection, instance segmentation and text detection. The purpose of this dataset is to facilitate the automated extraction of electrical graphâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/lowercaseonly/cghd.","url":"https://huggingface.co/datasets/lowercaseonly/cghd","creator_name":"Johannes Bayer","creator_url":"https://huggingface.co/lowercaseonly","license_name":"Creative Commons Attribution 3.0","license_url":"https://scancode-licensedb.aboutcode.org/cc-by-3.0.html","language":"en","first_N":5,"first_N_keywords":["object-detection","image-segmentation","English","German","cc-by-3.0"],"keywords_longer_than_N":true},
	{"name":"TRUEBench","keyword":"german","description":"\n\t\n\t\t\n\t\tTRUEBench: A Benchmark for Assessing LLMs as Human Job Productivity Assistants\n\t\n\nTRUEBench is a benchmark introduced by Samsung Research to evaluate the performance of large language models (LLMs) as human job assistants which consists of over 2,400 realistic and challenging samples. \nTo assess performance in real-world applications, TRUEBench includes diverse dialog scenarios and language conditions.\n\n\t\n\t\t\n\t\tMain Features\n\t\n\n\nMultilinguality: The user instructions are written in aâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/SamsungResearch/TRUEBench.","url":"https://huggingface.co/datasets/SamsungResearch/TRUEBench","creator_name":"Samsung Research","creator_url":"https://huggingface.co/SamsungResearch","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","Korean","English","Japanese","Chinese"],"keywords_longer_than_N":true},
	{"name":"tatoeba-bitext-mining","keyword":"german","description":"\n  Tatoeba\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\n1,000 English-aligned sentence pairs for each language based on the Tatoeba corpus\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2t\n\n\nDomains\nWritten\n\n\nReference\nhttps://github.com/facebookresearch/LASER/tree/main/data/tatoeba/v1\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask = mteb.get_tasks([\"Tatoeba\"])\nevaluator = mteb.MTEB(task)\n\nmodel =â€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/tatoeba-bitext-mining.","url":"https://huggingface.co/datasets/mteb/tatoeba-bitext-mining","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"Creative Commons Attribution 2.0","license_url":"https://scancode-licensedb.aboutcode.org/cc-by-2.0.html","language":"en","first_N":5,"first_N_keywords":["translation","human-annotated","multilingual","Afrikaans","Amharic"],"keywords_longer_than_N":true},
	{"name":"tulu3-100samples","keyword":"german","description":"\n\t\n\t\t\n\t\tDataset\n\t\n\nThis dataset contains 100 samples from the Tulu 3 SFT Mixture.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nEach example in the dataset contains the standard instruction-tuning data points as follow:\n\nid (str): a unique identifier\nmessages (list): message format used for supervised fine-tuning (this contains user prompt and assistant responses)\nsource (str): the source dataset for the given sample\n\n\n\t\n\t\t\n\t\tLicense\n\t\n\nThis dataset is licensed under ODC-BY-1.0. It is intended for research andâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/anayak/tulu3-100samples.","url":"https://huggingface.co/datasets/anayak/tulu3-100samples","creator_name":"Akash Nayak","creator_url":"https://huggingface.co/anayak","license_name":"Open Data Commons Attribution License v1.0","license_url":"https://scancode-licensedb.aboutcode.org/odc-by-1.0.html","language":null,"first_N":5,"first_N_keywords":["other","crowdsourced","expert-generated","machine-generated","multilingual"],"keywords_longer_than_N":true},
	{"name":"subtractionerror","keyword":"german","description":"\n\t\n\t\t\n\t\tDataset Card for Subtractionerror\n\t\n\nThis dataset mimics a primary student that has troubles with substracting over the tens.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset mimics a primary student that has troubles with substracting over the tens.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nThe data is a json file with questions and answers\n","url":"https://huggingface.co/datasets/TinaAbt/subtractionerror","creator_name":"Tina Abt","creator_url":"https://huggingface.co/TinaAbt","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["question-answering","German","mit","< 1K","json"],"keywords_longer_than_N":true},
	{"name":"fact-check-bureau","keyword":"german","description":"\n\t\n\t\t\n\t\n\t\n\t\tFact-Check Retrieval Dataset\n\t\n\nThis dataset is designed to support the development and evaluation of fact-check retrieval pipelines. It is structured to work with FactCheckBureau, a tool for designing and evaluating fact-check retrieval pipelines. The dataset comprises a list of claims, fact-check articles, and precomputed embeddings for English and French fact-checks.\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Structure\n\t\n\nThe dataset consists of the following files and directories:\n\narticles.csv:â€¦ See the full description on the dataset page: https://huggingface.co/datasets/NaughtyConstrictor/fact-check-bureau.","url":"https://huggingface.co/datasets/NaughtyConstrictor/fact-check-bureau","creator_name":"Younes","creator_url":"https://huggingface.co/NaughtyConstrictor","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["English","French","Portuguese","Spanish","Arabic"],"keywords_longer_than_N":true},
	{"name":"multilingual_refusals","keyword":"german","description":"\n\t\n\t\t\n\t\tData description\n\t\n\nThis dataset is designed to train and evaluate models for the task of refusal detection in generated responses. The dataset consists of input prompts sourced from the lmsys/lmsys-chat-1m collection, encompassing a variety of languages including English, German, French, Russian, and Spanish. To increase refusal diversity, the responses and refusals were generated using two models, Gemini Flash 1.5 and LLaMA-3.3-70b.\nThe dataset is primarily intended to trainâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/s-nlp/multilingual_refusals.","url":"https://huggingface.co/datasets/s-nlp/multilingual_refusals","creator_name":"s-nlp","creator_url":"https://huggingface.co/s-nlp","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","English","German","Russian","French"],"keywords_longer_than_N":true},
	{"name":"gooaq_mt_german_5_hard_negatives","keyword":"german","description":"\n\t\n\t\t\n\t\tGooAQ (Google Answers to Google Questions) question-answer pairs in German with 5 mined hard negatives.\n\t\n\n\n\t\n\t\t\n\t\tAbout\n\t\n\nThis dataset is a collection of ~2M question-answer-negative triplets and question-answer-negative_1...-negative_5 tuples from the machine translated version of MarcGrumpyOlejak/gooaq_mt_german. The full original Gooaq dataset in english only: (link to original dataset). This dataset can be used directly with Sentence Transformers to train embedding models.â€¦ See the full description on the dataset page: https://huggingface.co/datasets/MarcGrumpyOlejak/gooaq_mt_german_5_hard_negatives.","url":"https://huggingface.co/datasets/MarcGrumpyOlejak/gooaq_mt_german_5_hard_negatives","creator_name":"Marc Olejak","creator_url":"https://huggingface.co/MarcGrumpyOlejak","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","question-answering","German","apache-2.0","1M - 10M"],"keywords_longer_than_N":true},
	{"name":"OmniGEC-ModelTraining","keyword":"german","description":"\n\t\n\t\t\n\t\tOmniGEC-Model Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nOmniGEC-Model is a large multilingual dataset that comprises data from both WikiEdits-MultiGEC \nand Reddit-MultiGEC.\nThe dataset was constructed using the same data used for model training to enable the reproducibility of results.\nA link to the model and the associated paper will be provided at a later stage.\n\n\t\n\t\t\n\t\n\t\n\t\tCitation\n\t\n\nIf you use or discuss this project/dataset in your work, please cite our paper:Paper: Introducing OmniGEC: Aâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/peterua/OmniGEC-ModelTraining.","url":"https://huggingface.co/datasets/peterua/OmniGEC-ModelTraining","creator_name":"Petro Ivaniuk","creator_url":"https://huggingface.co/peterua","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["Ukrainian","English","German","cz","Italian"],"keywords_longer_than_N":true},
	{"name":"moosa2022multilingual-cross-lingual-archived","keyword":"german","description":"\n\t\n\t\t\n\t\tDataset Card for Multilingual Hate Speech Dataset\n\t\n\n\n\nThis dataset card provides information about the Multilingual Hate Speech Dataset, which was originally hosted on Kaggle. \nThe Multilingual Hate Speech Dataset is a modified version of an original multilingual hate speech dataset. In this version, examples from each language have been translated into the other languages present in the dataset, creating a more comprehensive cross-lingual resource.\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Detailsâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/ysenarath/moosa2022multilingual-cross-lingual-archived.","url":"https://huggingface.co/datasets/ysenarath/moosa2022multilingual-cross-lingual-archived","creator_name":"Yasas","creator_url":"https://huggingface.co/ysenarath","license_name":"Open Data Commons Attribution License v1.0","license_url":"https://scancode-licensedb.aboutcode.org/odc-by-1.0.html","language":"en","first_N":5,"first_N_keywords":["text-classification","Arabic","English","Chinese","French"],"keywords_longer_than_N":true},
	{"name":"kaleidoscope","keyword":"german","description":"\n\t\n\t\t\n\t\tKaleidoscope  (18 Languages)\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe Kaleidoscope Benchmark is a \nglobal collection of multiple-choice questions sourced from real-world exams, \nwith the goal of evaluating multimodal and multilingual understanding in VLMs. \nThe collected exams are in a Multiple-choice question answering (MCQA) \nformat which provides a structured framework for evaluation by prompting \nmodels with predefined answer choices, closely mimicking conventional human testingâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/CohereLabs/kaleidoscope.","url":"https://huggingface.co/datasets/CohereLabs/kaleidoscope","creator_name":"Cohere Labs","creator_url":"https://huggingface.co/CohereLabs","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["Arabic","Bengali","Croatian","Dutch","English"],"keywords_longer_than_N":true},
	{"name":"Intermediate-Thinking-130k","keyword":"german","description":"\n\t\n\t\t\n\t\tIntermediate-Thinking-130k\n\t\n\nA comprehensive dataset of 135,000 high-quality samples designed to advance language model reasoning capabilities through structured intermediate thinking processes. This dataset enables training and evaluation of models with sophisticated self-correction and iterative reasoning abilities across 42 languages.\nOG Link\n\n\t\n\t\t\n\t\n\t\n\t\tOverview\n\t\n\nIntermediate-Thinking-130k addresses a fundamental limitation in current language models: their inability to pauseâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/mlx-community/Intermediate-Thinking-130k.","url":"https://huggingface.co/datasets/mlx-community/Intermediate-Thinking-130k","creator_name":"MLX Community","creator_url":"https://huggingface.co/mlx-community","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","Afrikaans","Arabic","Bengali","Bulgarian"],"keywords_longer_than_N":true},
	{"name":"Parallel_Dataset","keyword":"german","description":"\n\t\n\t\t\n\t\tDataset Sources\n\t\n\n\nPaper: LegoMT2: Selective Asynchronous Sharded Data Parallel Training for Massive Neural Machine Translation\nLink: https://aclanthology.org/2025.findings-acl.1200.pdf\nRepository: https://github.com/CONE-MT/CONE\n\n","url":"https://huggingface.co/datasets/Lego-MT/Parallel_Dataset","creator_name":"Lego-MT","creator_url":"https://huggingface.co/Lego-MT","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["translation","English","Chinese","Spanish","French"],"keywords_longer_than_N":true},
	{"name":"high-quality-multilingual-sentences","keyword":"german","description":"\n\t\n\t\t\n\t\tHigh Quality Multilingual Sentences\n\t\n\n\nThis dataset contains multilingual sentences derived from the agentlans/LinguaNova dataset.\nIt includes 1.58 million rows across 51 different languages, each in its own configuration.\n\nExample row (from the all config):\n{\n    \"text\": \"Ø§Ù…Ø§Ù… Ø¬Ù…Ø¹Ù‡ Ø§ØµÙÙ‡Ø§Ù† Ú¯ÙØª: Ù…ÛŒØ²Ø§Ù† Ù†ÛŒØ§Ø² Ø¢Ø¨ Ø´Ø±Ø¨ Ø§ØµÙÙ‡Ø§Ù† Û±Û±.Ûµ Ù…ØªØ± Ù…Ú©Ø¹Ø¨ Ø§Ø³Øª Ú©Ù‡ ØªÙ…Ø§Ù… Ø§Ø³ØªØ§Ù† Ø§ØµÙÙ‡Ø§Ù† Ø±Ø§ Ù¾ÙˆØ´Ø´ Ù…ÛŒØ¯Ù‡Ø¯ Ùˆ Ù†Ø³Ø¨Øª Ø¨Ù‡ Ù‚Ø¨Ù„ Ø§Ø² Ø§Ù†Ù‚Ù„Ø§Ø¨ ÛŒÚ©ÛŒ Ø§Ø² Ù¾ÛŒØ´Ø±ÙØªÙ‡Ø§ Ø¯Ø± Ø­ÙˆØ²Ù‡ Ø¢Ø¨ Ø¨ÙˆØ¯Ù‡ Ø§Ø³Øª.\",\n    \"fasttext\": \"fa\",\n    \"gcld3\": \"fa\"\n}\n\nFields:â€¦ See the full description on the dataset page: https://huggingface.co/datasets/agentlans/high-quality-multilingual-sentences.","url":"https://huggingface.co/datasets/agentlans/high-quality-multilingual-sentences","creator_name":"Alan Tseng","creator_url":"https://huggingface.co/agentlans","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","text-classification","text-retrieval","multilingual","Arabic"],"keywords_longer_than_N":true},
	{"name":"MSTS","keyword":"german","description":"\n\t\n\t\t\n\t\tDisclaimer\n\t\n\nThe MSTS dataset contains content that may be offensive or upsetting in nature. Topics include, but are not limited to, discriminatory language and discussions of abuse, violence, self-harm, exploitation, and other potentially upsetting subject matter. \nPlease only engage with the data in accordance with your own personal risk tolerance. The data are intended for research purposes, especially research that can make models less harmful.\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Card for theâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/felfri/MSTS.","url":"https://huggingface.co/datasets/felfri/MSTS","creator_name":"Felix Friedrich","creator_url":"https://huggingface.co/felfri","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["image-text-to-text","English","Arabic","French","German"],"keywords_longer_than_N":true},
	{"name":"venus","keyword":"german","description":"\n\t\n\t\t\n\t\tVenus Facts Multilingual Dataset\n\t\n\n\nA comprehensive collection of 1000+ facts about Venus in four languages (English, Indonesian, Spanish, and German) in CSV format.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\nFormat: CSV (Comma Separated Values)\nFields: \nfact_id: Unique identifier\nenglish: Fact in English\nindonesian: Fact in Indonesian\nspanish: Fact in Spanish\ngerman: Fact in German\ncategory: Fact category (atmosphere, surface, orbit, etc.)\n\n\nSize: 1000+ records\nLicense: Apache 2.0â€¦ See the full description on the dataset page: https://huggingface.co/datasets/erisdataworks/venus.","url":"https://huggingface.co/datasets/erisdataworks/venus","creator_name":"Eris Dataworks","creator_url":"https://huggingface.co/erisdataworks","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["Indonesian","English","German","Spanish","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"mu-shroom","keyword":"german","description":"\n\t\n\t\t\n\t\tThe Mu-SHROOM dataset for Multilingual Hallucination and Overgeneration detection.\n\t\n\nMu-SHROOM: Multilingual Shared-task on Hallucinations and Related Observable Overgeneration Mistakes and Related Observable Overgeneration Mistakes\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nMu-SHROOM is a multilingual dataset for detecting hallucination spans in LLM outputs across 14 languages. It was created for SemEval-2025 Task 3.\ndisclaimer: Mu-SHROOM is not properly a fact-checking dataset, but we mark isâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Helsinki-NLP/mu-shroom.","url":"https://huggingface.co/datasets/Helsinki-NLP/mu-shroom","creator_name":"Language Technology Research Group at the University of Helsinki","creator_url":"https://huggingface.co/Helsinki-NLP","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["token-classification","fact-checking","Arabic","Catalan","Czech"],"keywords_longer_than_N":true},
	{"name":"MMMLU","keyword":"german","description":"\n\t\n\t\t\n\t\tMultilingual Massive Multitask Language Understanding (MMMLU)\n\t\n\nThe MMLU is a widely recognized benchmark of general knowledge attained by AI models. It covers a broad range of topics from 57 different categories, covering elementary-level knowledge up to advanced professional subjects like law, physics, history, and computer science.\nWe translated the MMLUâ€™s test set into 14 languages using professional human translators. Relying on human translators for this evaluation increasesâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/bzantium/MMMLU.","url":"https://huggingface.co/datasets/bzantium/MMMLU","creator_name":"Minho Ryu","creator_url":"https://huggingface.co/bzantium","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["question-answering","Arabic","Bengali","German","Spanish"],"keywords_longer_than_N":true},
	{"name":"noise-dataset-de","keyword":"german","description":"\n\t\n\t\t\n\t\tGerman Noise-Augmented Speech Demo Dataset\n\t\n\nThis dataset provides German speech samples augmented with realistic noise scenarios such as office noise, street noise, white noise, echo, and lowpass filtering.It is designed for testing and improving the robustness of ASR (Automatic Speech Recognition) systems.\n\n\t\n\t\t\n\t\tðŸ’¡ Source\n\t\n\n\nOriginal voice samples: Mozilla Common Voice (CC0)\nNoise layers: custom augmented (see noise.rolgor.de)\n\n\n\t\n\t\t\n\t\tâš ï¸ Privacy\n\t\n\nPlease respect speakerâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/rolgor/noise-dataset-de.","url":"https://huggingface.co/datasets/rolgor/noise-dataset-de","creator_name":"rol gor","creator_url":"https://huggingface.co/rolgor","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["keyword-spotting","crowdsourced","found","monolingual","original"],"keywords_longer_than_N":true},
	{"name":"oscar-en-de-synthetic","keyword":"german","description":"\n\t\n\t\t\n\t\tOSCAR EN-DE Machine Translation Dataset (Gemini 2.0 Flash)\n\t\n\nThis dataset contains 80,000 English-German parallel sentence pairs, automatically translated using Gemini 2.0 Flash, a high-quality LLM model by Google.\n\n\t\n\t\t\n\t\tðŸ”¹ Key Features\n\t\n\nThis dataset was created to offer a high-quality, modern alternative to traditional parallel corpora. Its main strengths are:\n\nDiverse and Natural Language: Sourced from the OSCAR web corpus, the dataset includes a wide variety of topics andâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/arhunov/oscar-en-de-synthetic.","url":"https://huggingface.co/datasets/arhunov/oscar-en-de-synthetic","creator_name":"Maksym Arhunov","creator_url":"https://huggingface.co/arhunov","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["translation","English","German","cc-by-4.0","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"GammaCorpus-Polylingo-50k","keyword":"german","description":"\n\t\n\t\t\n\t\tGammaCorpus Polylingo 50k\n\t\n\n\n\t\n\t\t\n\t\tWhat is it?\n\t\n\nThe GammaCorpus Polylingo 50k dataset consists of 50,000 structured, unfiltered, single-turn conversations, where each interaction includes:\n\nInput: A user prompt or question.\nOutput: A response generated by an AI assistant.\nLanguage: The language used in the interaction.\n\nThis dataset is designed to help in the training and evaluation of conversational AI models for linguistic purposes. This dataset can be especially helpful if youâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/rubenroy/GammaCorpus-Polylingo-50k.","url":"https://huggingface.co/datasets/rubenroy/GammaCorpus-Polylingo-50k","creator_name":"Ruben Roy","creator_url":"https://huggingface.co/rubenroy","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","English","Russian","Vietnamese","German"],"keywords_longer_than_N":true},
	{"name":"ProgressGym-HistText","keyword":"german","description":"*Huggingface dataset preview for 19th, 20th, and 21st centuries is not available due to lack of support for array types. Instead, consider downloading those files for manual inspection, or see the Data Samples section below for more examples.\n\n\t\n\t\t\n\t\n\t\n\t\tProgressGym-HistText\n\t\n\n\n\t\n\t\t\n\t\n\t\n\t\tOverview\n\t\n\n\n\t\n\t\t\n\t\n\t\n\t\tThe ProgressGym Framework\n\t\n\n\nProgressGym-HistText is part of the ProgressGym framework for research and experimentation on progress alignment - the emulation of moral progress in AIâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/PKU-Alignment/ProgressGym-HistText.","url":"https://huggingface.co/datasets/PKU-Alignment/ProgressGym-HistText","creator_name":"PKU-Alignment","creator_url":"https://huggingface.co/PKU-Alignment","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","pile-of-law/pile-of-law","EEBO","Library of Congress","Project Gutenberg (Standardized Project Gutenberg Corpus)"],"keywords_longer_than_N":true},
	{"name":"German-RAG-LLM-HARD-BENCHMARK","keyword":"german","description":"\n\t\n\t\t\n\t\tGerman-RAG-LLM-HARD Benchmark\n\t\n\n\n\t\n\t\t\n\t\tGerman-RAG - German Retrieval Augmented Generation\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis German-RAG-LLM-HARD-BENCHMARK represents a specialized collection for evaluate language models with a focus on hard to solve RAG-specific capabilities. To evaluate models compatible with OpenAI-Endpoints you can refer to our Github Repo: https://github.com/avemio-digital/GRAG-LLM-HARD-BENCHMARK\nThe subsets are derived from Synthetic generation inspired byâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/avemio/German-RAG-LLM-HARD-BENCHMARK.","url":"https://huggingface.co/datasets/avemio/German-RAG-LLM-HARD-BENCHMARK","creator_name":"Avemio AG","creator_url":"https://huggingface.co/avemio","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["question-answering","summarization","German","English","mit"],"keywords_longer_than_N":true},
	{"name":"German-RAG-LLM-HARD-BENCHMARK","keyword":"german","description":"\n\t\n\t\t\n\t\tGerman-RAG-LLM-HARD Benchmark\n\t\n\n\n\t\n\t\t\n\t\tGerman-RAG - German Retrieval Augmented Generation\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis German-RAG-LLM-HARD-BENCHMARK represents a specialized collection for evaluate language models with a focus on hard to solve RAG-specific capabilities. To evaluate models compatible with OpenAI-Endpoints you can refer to our Github Repo: https://github.com/avemio-digital/GRAG-LLM-HARD-BENCHMARK\nThe subsets are derived from Synthetic generation inspired byâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/avemio/German-RAG-LLM-HARD-BENCHMARK.","url":"https://huggingface.co/datasets/avemio/German-RAG-LLM-HARD-BENCHMARK","creator_name":"Avemio AG","creator_url":"https://huggingface.co/avemio","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["question-answering","summarization","German","English","mit"],"keywords_longer_than_N":true},
	{"name":"synthetic_call_center_summaries","keyword":"german","description":"\n\t\n\t\t\n\t\tSynthetic Call Center Summaries Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset contains synthetic summaries of call center conversations generated by different prompt configurations.\nEach record (in JSON Lines format) includes:\n\nThe original dialogue metadata.\nA generated summary tailored to provide quick insights for call center service agents.\nExtensive evaluation metrics and attributes such as conciseness, formatting, contextual relevance, tone, and actionability.\n\n\n\t\n\t\t\n\t\n\t\n\t\tIntendedâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/marccgrau/synthetic_call_center_summaries.","url":"https://huggingface.co/datasets/marccgrau/synthetic_call_center_summaries","creator_name":"Marc Christopher Grau","creator_url":"https://huggingface.co/marccgrau","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["summarization","text-generation","synthetic","monolingual","German"],"keywords_longer_than_N":true},
	{"name":"nemotron-cc-translated-by-opus","keyword":"german","description":"The dataset is translated from Nemotron-CC with OPUS-MT models.\n","url":"https://huggingface.co/datasets/MultiSynt/nemotron-cc-translated-by-opus","creator_name":"MultiSynt","creator_url":"https://huggingface.co/MultiSynt","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["translation","text-generation","German","Finnish","Swedish"],"keywords_longer_than_N":true},
	{"name":"test_4","keyword":"german","description":"\n\t\n\t\t\n\t\n\t\n\t\tFLEURS\n\t\n\nFleurs is the speech version of the FLoRes machine translation benchmark. \nWe use 2009 n-way parallel sentences from the FLoRes dev and devtest publicly available sets, in 102 languages. \nTraining sets have around 10 hours of supervision. Speakers of the train sets are different than speakers from the dev/test sets. Multilingual fine-tuning is\nused and â€unit error rateâ€ (characters, signs) of all languages is averaged. Languages and results are also grouped into sevenâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/tunngo/test_4.","url":"https://huggingface.co/datasets/tunngo/test_4","creator_name":"nguyen tuan","creator_url":"https://huggingface.co/tunngo","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","expert-generated","crowdsourced","machine-generated","crowdsourced"],"keywords_longer_than_N":true},
	{"name":"literary-synthesis","keyword":"german","description":"\n\t\n\t\t\n\t\tLiterary Synthesis\n\t\n\nThis dataset repurposes the original agentlans/literary-reasoning \ndata by reformatting it as creative writing prompts paired with literary-style outputs. \n\nWriting style attributes were put in random order, with prompts randomly either prepended or appended.\nThe output text has been cleaned to make it suitable for creative writing and literary generation tasks.\nThe rows were sorted by increasing reading difficulty for curriculum learning.\n\n","url":"https://huggingface.co/datasets/agentlans/literary-synthesis","creator_name":"Alan Tseng","creator_url":"https://huggingface.co/agentlans","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","English","French","German","Spanish"],"keywords_longer_than_N":true},
	{"name":"Product_Similarity_Dataset","keyword":"german","description":"This following dataset is a rich dataset of product similarity. The dataset has been design to be challenging to train on by having quite a lot of hard negatives\nThis dataset is especially targeted toward fine-tuning usecase, especially to finetune reranker or embedding model.\nThe data are especially adapted for listwise loss like LambdaLoss or ListNetLoss.\nThe data are in JSONL and each line follow the same format as here below : \n\nA \"query\", the anchor product label\n\"docs\", the potentialâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Antix5/Product_Similarity_Dataset.","url":"https://huggingface.co/datasets/Antix5/Product_Similarity_Dataset","creator_name":"Antoine Demangeon","creator_url":"https://huggingface.co/Antix5","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-ranking","feature-extraction","French","German","Chinese"],"keywords_longer_than_N":true},
	{"name":"GlobalNLI","keyword":"german","description":"\n\t\n\t\t\n\t\tDataset Card for global_nli\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nGlobal NLI is a new text-based benchmark based on the aggregation of existing NLI datasets that are publicly available.\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nThere are 59 languages available :\n{\n    'amh': 'Amharic',\n    'ara': 'Arabic',\n    'asm': 'Assamese',\n    'aym': 'Aymara',\n    'ben': 'Bengali',\n    'bul': 'Bulgarian',\n    'bzd': 'Bribri',\n    'cat': 'Catalan',\n    'cni': 'AshÃ¡ninka',\n    'deu': 'German',\n    'ell': 'Greek',\n    'eng':â€¦ See the full description on the dataset page: https://huggingface.co/datasets/McGill-NLP/GlobalNLI.","url":"https://huggingface.co/datasets/McGill-NLP/GlobalNLI","creator_name":"McGill NLP Group","creator_url":"https://huggingface.co/McGill-NLP","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","natural-language-inference","multilingual","XNLI, AfriXNLI, IndicXNLI, AmericasNLI [30], XNLI-ca, myXNLI, IndoNLI, JNLI , InferBR, sick_pl, JamPatoisNLI, KLUE, RoNLI.","Amharic"],"keywords_longer_than_N":true},
	{"name":"opendata-iisys-hui","keyword":"german","description":"\n\n\t\n\t\t\n\t\tHUI-Audio-Corpus-German Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThe HUI-Audio-Corpus-German is a high-quality Text-To-Speech (TTS) dataset developed by researchers at the Institute of Information Systems (IISYS). This dataset is designed to facilitate the development and training of TTS applications, particularly in the German language. The associated research paper can be found here.\n\n\t\n\t\t\n\t\tDataset Contents\n\t\n\nThe dataset comprises recordings from multiple speakers, with the five mostâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Paradoxia/opendata-iisys-hui.","url":"https://huggingface.co/datasets/Paradoxia/opendata-iisys-hui","creator_name":"Firat Tay","creator_url":"https://huggingface.co/Paradoxia","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["German","mit","10K - 100K","parquet","Audio"],"keywords_longer_than_N":true},
	{"name":"quickmt-train.de-en","keyword":"german","description":"\n\t\n\t\t\n\t\tquickmt de-en Training Corpus\n\t\n\nContains the following datasets downloaded with mtdata after deduplication and basic filtering with quickmt:\n\nStatmt-commoncrawl_wmt13-1-deu-eng\nStatmt-europarl_wmt13-7-deu-eng\nStatmt-news_commentary_wmt18-13-deu-eng\nStatmt-europarl-9-deu-eng\nStatmt-europarl-7-deu-eng\nStatmt-news_commentary-14-deu-eng\nStatmt-news_commentary-15-deu-eng\nStatmt-news_commentary-16-deu-eng\nStatmt-news_commentary-17-deu-eng\nStatmt-news_commentary-18-deu-engâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/quickmt/quickmt-train.de-en.","url":"https://huggingface.co/datasets/quickmt/quickmt-train.de-en","creator_name":"quickmt","creator_url":"https://huggingface.co/quickmt","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["translation","German","English","cc-by-4.0","100M - 1B"],"keywords_longer_than_N":true},
	{"name":"russian_trolls","keyword":"german","description":"\n\t\n\t\t\n\t\tDataset Card for Dataset Name\n\t\n\n\n\nThe Russian Trolls twitter dataset as released and reported by NBC News.\nFrom the original data file header:\n\"Tweets from confirmed Russian trolls, shows only username, timestamp (in UTC), tweet text, and number of times tweet was retweeted and favorited according to our data\",,,,,,,,,,,,,,,,,\nFrom NBC News' story: https://www.nbcnews.com/tech/social-media/now-available-more-200-000-deleted-russian-troll-tweets-n844731,,,,,,,,,,,,,,,,,\n\"If you publishâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Kristijan/russian_trolls.","url":"https://huggingface.co/datasets/Kristijan/russian_trolls","creator_name":"Kristijan Armeni","creator_url":"https://huggingface.co/Kristijan","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["English","German","Russian","mit","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"SwissJudgementClassification","keyword":"german","description":"\n  SwissJudgementClassification\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nMultilingual, diachronic dataset of Swiss Federal Supreme Court cases annotated with the respective binarized judgment outcome (approval/dismissal)\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2c\n\n\nDomainsLegal, Written\n\n\nReference\nhttps://aclanthology.org/2021.nllp-1.3/\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask =â€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/SwissJudgementClassification.","url":"https://huggingface.co/datasets/mteb/SwissJudgementClassification","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","expert-annotated","multilingual","rcds/swiss_judgment_prediction","German"],"keywords_longer_than_N":true},
	{"name":"newscrawl_enhanced_gender_balance","keyword":"german","description":"This dataset is the product of our work focused on the investigation of the development of the representation of gender forms, specifically male and female forms of occupations, in textual data.\nWe used the newscrawl dataset (Newscrawl doc-split data; WMT overview paper) for Czech, German, Spanish and Polish and employed clustering and filtering techniques (based on temporal and topic information) to extract a gender-balanced portion of the data. The dataset is therefore released under theâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/jurasova/newscrawl_enhanced_gender_balance.","url":"https://huggingface.co/datasets/jurasova/newscrawl_enhanced_gender_balance","creator_name":"Daniela JurÃ¡Å¡ovÃ¡","creator_url":"https://huggingface.co/jurasova","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["translation","Czech","German","Spanish","Polish"],"keywords_longer_than_N":true},
	{"name":"belgisch-staatsblad","keyword":"german","description":"\n\t\n\t\t\n\t\tDataset Description\n\t\n\n\n\nThe most up to date data can be found here: https://huggingface.co/datasets/guust-franssens/belgian-journal\nDue to the different languages in Belgium, I decided to create three datasets belgian-journal/moniteur-belge/belgisch-staatsblad in order to make it more visible.\nDataset contains the metadata + the text of bylaw publications of Belgian companies on the Belgian Journal (Moniteur Belge/Belgisch Staatstblad).\nThis data was collected by webscraping theâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/guust-franssens/belgisch-staatsblad.","url":"https://huggingface.co/datasets/guust-franssens/belgisch-staatsblad","creator_name":"Guust Franssens","creator_url":"https://huggingface.co/guust-franssens","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","French","Dutch","German","cc0-1.0"],"keywords_longer_than_N":true},
	{"name":"my_iris","keyword":"german","description":"\n\t\n\t\t\n\t\tIris Species Dataset\n\t\n\nThe Iris dataset was used in R.A. Fisher's classic 1936 paper, The Use of Multiple Measurements in Taxonomic Problems, and can also be found on the UCI Machine Learning Repository.\nIt includes three iris species with 50 samples each as well as some properties about each flower. One flower species is linearly separable from the other two, but the other two are not linearly separable from each other.\nThe dataset is taken from UCI Machine Learning Repository'sâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/beierr1/my_iris.","url":"https://huggingface.co/datasets/beierr1/my_iris","creator_name":"Ralf Beier","creator_url":"https://huggingface.co/beierr1","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["German","cc0-1.0","< 1K","csv","Tabular"],"keywords_longer_than_N":true},
	{"name":"TV-24kHz-Neutral","keyword":"german","description":"\n\t\n\t\t\n\t\tThorsten-Voice TV-24kHz-Neutral Dataset\n\t\n\nThis dataset is a resampled version of the \"TV-2022.10-Neutral\" configuration from the original Thorsten-Voice TV-44kHz-Full dataset, converted from 44.1kHz to 24kHz sampling rate.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe Thorsten-Voice dataset contains German speech recordings by Thorsten MÃ¼ller, suitable for text-to-speech (TTS) training and other speech synthesis tasks.\n\n\t\n\t\t\n\t\tChanges from Original\n\t\n\n\nSample Rate: Converted from 44.1kHz toâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Thorsten-Voice/TV-24kHz-Neutral.","url":"https://huggingface.co/datasets/Thorsten-Voice/TV-24kHz-Neutral","creator_name":"Thorsten MÃ¼ller","creator_url":"https://huggingface.co/Thorsten-Voice","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["German","cc-by-4.0","10K - 100K","parquet","Audio"],"keywords_longer_than_N":true},
	{"name":"TV-24kHz-Neutral","keyword":"german","description":"\n\t\n\t\t\n\t\tThorsten-Voice TV-24kHz-Neutral Dataset\n\t\n\nThis dataset is a resampled version of the \"TV-2022.10-Neutral\" configuration from the original Thorsten-Voice TV-44kHz-Full dataset, converted from 44.1kHz to 24kHz sampling rate.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe Thorsten-Voice dataset contains German speech recordings by Thorsten MÃ¼ller, suitable for text-to-speech (TTS) training and other speech synthesis tasks.\n\n\t\n\t\t\n\t\tChanges from Original\n\t\n\n\nSample Rate: Converted from 44.1kHz toâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Thorsten-Voice/TV-24kHz-Neutral.","url":"https://huggingface.co/datasets/Thorsten-Voice/TV-24kHz-Neutral","creator_name":"Thorsten MÃ¼ller","creator_url":"https://huggingface.co/Thorsten-Voice","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["German","cc-by-4.0","10K - 100K","parquet","Audio"],"keywords_longer_than_N":true},
	{"name":"ALMA-R-Preference","keyword":"german","description":"\n\t\n\t\t\n\t\tDataset Card for \"ALMA-R-Preference\"\n\t\n\nThis is triplet preference data used by ALMA-R model.\nThe triplet preference data, supporting 10 translation directions, is built upon the FLORES-200 development and test data. For each direction, we provide a source sentence along with three translations: one from GPT-4, another from ALMA-13B-LoRA, and a reference translation. For instance, in the English-German pair, our data structure is as follows:\n\n\t\n\t\t\n\t\n\t\n\t\tSentences:\n\t\n\n\nde: Originalâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/haoranxu/ALMA-R-Preference.","url":"https://huggingface.co/datasets/haoranxu/ALMA-R-Preference","creator_name":"Haoran Xu","creator_url":"https://huggingface.co/haoranxu","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["translation","Russian","Czech","Chinese","Icelandic"],"keywords_longer_than_N":true},
	{"name":"m-WildVision","keyword":"german","description":"\n\t\n\t\t\n\t\tDataset Card for m-WildVision\n\t\n\n\n\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\nThe m-WildVision dataset is a multilingual multimodal LLM evaluation set covering 23 languages.  It was created by translating prompts from the original English-only WildVision (vision_bench_0617) test set. \nThe original prompts, developed by Lu et al. (2024) , consist of 500 challenging user queries sourced from the WildVision-Arena platform. \nThe authors demonstrated that these prompts enable automatic LLM judgeâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/CohereLabs/m-WildVision.","url":"https://huggingface.co/datasets/CohereLabs/m-WildVision","creator_name":"Cohere Labs","creator_url":"https://huggingface.co/CohereLabs","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["English","French","German","Spanish","Italian"],"keywords_longer_than_N":true},
	{"name":"NaVAB","keyword":"german","description":"\n\t\n\t\t\n\t\tDataset Card for NaVAB\n\t\n\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nNaVAB is a comprehensive benchmark designed to evaluate the alignment of Large Language Models (LLMs) with the values of five major nations: China, the United States, the United Kingdom, France, and Germany. The dataset addresses the limitations of existing benchmarks, which often fail to capture the dynamic nature of values across countries and lack sufficient evaluation data.\nThe dataset enables theâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/JadenGGGeee/NaVAB.","url":"https://huggingface.co/datasets/JadenGGGeee/NaVAB","creator_name":"JCY","creator_url":"https://huggingface.co/JadenGGGeee","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["English","Chinese","French","German","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"open-dict-words-ipa","keyword":"german","description":"\n\t\n\t\t\n\t\tOpen-dict Words IPA\n\t\n\nThis dataset is a copy of https://github.com/open-dict-data/ipa-dict\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nIPA data is currently available for the following languages:\n\n\t\n\t\t\nLanguage\nCode\n\n\n\t\t\nar\nArabic (Modern Standard)\n\n\nde\nGerman\n\n\nen_UK\nEnglish (Received Pronunciation)\n\n\nen_US\nEnglish (General American)\n\n\neo\nEsperanto\n\n\nes_ES\nSpanish (Spain)\n\n\nes_MX\nSpanish (Mexico)\n\n\nfa\nPersian\n\n\nfi\nFinnish\n\n\nfr_FR\nFrench (France)\n\n\nfr_QC\nFrench (QuÃ©bec)\n\n\nis\nIcelandic\n\n\nja\nJapanese\n\n\njamâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/StephanAkkerman/open-dict-words-ipa.","url":"https://huggingface.co/datasets/StephanAkkerman/open-dict-words-ipa","creator_name":"Stephan Akkerman","creator_url":"https://huggingface.co/StephanAkkerman","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["Arabic","German","English","Esperanto","Spanish"],"keywords_longer_than_N":true},
	{"name":"filtered_convos_research_llm_summaries_cleaned_v3","keyword":"german","description":"\n\t\n\t\t\n\t\tSynthetic Call Center Summaries Dataset Cleaned - Prompt V3\n\t\n\n\n\t\n\t\t\n\t\tPrompt Changes\n\t\n\n\nAdapted prompt from yourbench\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset contains synthetic summaries of call center conversations generated by different prompt configurations.\nEach record (in JSON Lines format) includes:\n\nThe original dialogue metadata.\nA generated summary tailored to provide quick insights for call center service agents.\nEvaluation metrics\n\n\n\t\n\t\t\n\t\tPrompts for summarizationâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/marccgrau/filtered_convos_research_llm_summaries_cleaned_v3.","url":"https://huggingface.co/datasets/marccgrau/filtered_convos_research_llm_summaries_cleaned_v3","creator_name":"Marc Christopher Grau","creator_url":"https://huggingface.co/marccgrau","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["summarization","text-generation","synthetic","monolingual","German"],"keywords_longer_than_N":true},
	{"name":"Phonemized-UD","keyword":"german","description":"\n\t\n\t\t\n\t\tPhoneme-UD: A Multilingual Phonemized Universal Dependencies Corpus for 34+ Languages\n\t\n\n\n\t\n\t\t\n\t\tG2P+ Phonemizer\n\t\n\nWe use G2P+ to phonemize Universal Dependencies. Here is an example usage: \n# Install required packages\n!apt-get install -y espeak-ng\n!pip install phonemizer g2p-plus\n# Set the environment variable from Python\nimport os\nos.environ[\"PHONEMIZER_ESPEAK_LIBRARY\"] = \"/usr/lib/x86_64-linux-gnu/libespeak-ng.so.1\"\n\n# Now run your transcription\nfrom g2p_plus importâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/suchirsalhan/Phonemized-UD.","url":"https://huggingface.co/datasets/suchirsalhan/Phonemized-UD","creator_name":"Suchir Salhan","creator_url":"https://huggingface.co/suchirsalhan","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["Afrikaans","Amharic","Arabic","Azerbaijani","Catalan"],"keywords_longer_than_N":true},
	{"name":"ragkeep-deutsche-klassik-books-de","keyword":"german","description":"\n\t\n\t\t\n\t\tragkeep-weimarer-klassik-books-de\n\t\n\nReleased subset of Weimarer Klassik books curated in ragkeep and prepared by ragprep.\n\n\t\n\t\t\n\t\tContents (HF subset)\n\t\n\n\nReleased Markdown: books/**/results/_released.md\nHTML rendering: books/**/results/html/<bookname>.html\nTOC JSON: books/**/results/toc.json\nProvenance & corrections: book-manifest.yaml, errata.txt\n\n<bookname> = canonical folder basename Author#Title#Index.\n\n\t\n\t\t\n\t\tLoading\n\t\n\nfrom datasets import load_dataset\n\nmd =â€¦ See the full description on the dataset page: https://huggingface.co/datasets/Lafisrap/ragkeep-deutsche-klassik-books-de.","url":"https://huggingface.co/datasets/Lafisrap/ragkeep-deutsche-klassik-books-de","creator_name":"Michael Schmidt","creator_url":"https://huggingface.co/Lafisrap","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["German","mit","< 1K","text","Text"],"keywords_longer_than_N":true},
	{"name":"gpt-4-self-instruct-german-scored","keyword":"german","description":"\n\t\n\t\t\n\t\tModifications\n\t\n\nThis is the original and unchanged german translated dataset (train split only) in original order from CausalLM/GPT-4-Self-Instruct-German with added cosine-similarity scores.\nThe scores have been calculated using the best static multilingual embedding model (for my needs): sentence-transformers/static-similarity-mrl-multilingual-v1 for faster distinction if an answer corresponds to a query upon the content.\n\n\t\n\t\t\n\t\n\t\n\t\tWhy?\n\t\n\nTo build an experimental static embeddingâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/MarcGrumpyOlejak/gpt-4-self-instruct-german-scored.","url":"https://huggingface.co/datasets/MarcGrumpyOlejak/gpt-4-self-instruct-german-scored","creator_name":"Marc Olejak","creator_url":"https://huggingface.co/MarcGrumpyOlejak","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","sentence-similarity","German","cc-by-4.0","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"OGC_colpali-VisRAG-vdr","keyword":"german","description":"\n\t\n\t\t\n\t\tWIP - there might be issues with the negatives\n\t\n\n\n\t\n\t\t\n\t\tOGC - Organized, Grouped, Cleaned\n\t\n\n\nIntended for image/text to vector (DSE)\n\n\n\t\n\t\t\n\t\tDataset Composition\n\t\n\nThe dataset merges, shuffles, and formats data from:\n\nvidore/colpali_train_set\nopenbmb/VisRAG-Ret-Train-Synthetic-data\nllamaindex/vdr-multilingual-train\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Statistics\n\t\n\n\n\t\n\t\t\nMetric\nValue\n\n\n\t\t\nTotal rows\n700,000+\n\n\nRows with negatives\nâ‰ˆ 33%\n\n\nRows without queries (image negatives only)\nâ‰ˆ 25%â€¦ See the full description on the dataset page: https://huggingface.co/datasets/racineai/OGC_colpali-VisRAG-vdr.","url":"https://huggingface.co/datasets/racineai/OGC_colpali-VisRAG-vdr","creator_name":"racine.ai","creator_url":"https://huggingface.co/racineai","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["visual-document-retrieval","text-retrieval","English","French","Spanish"],"keywords_longer_than_N":true},
	{"name":"300chat_universe","keyword":"german","description":"\n\t\n\t\t\n\t\tðŸŒŒ Universe Q&A Multilingual Dataset\n\t\n\nThis repository contains a multilingual Questionâ€“Answer dataset about the universe, generated by Eris Dataworks as part of the Berinspa open science initiative.\nThe dataset is suitable for:\n\nMultilingual NLP model training and evaluation  \nAstronomy education  \nOpen science and translation projects\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tðŸ“„ Dataset Details\n\t\n\nFilename: universe_chat_dataset_300.csvLanguages Included:\n\nðŸ‡®ðŸ‡© Bahasa Indonesia  \nðŸ‡¯ðŸ‡µ Japanese  \nðŸ‡¨ðŸ‡³ Chineseâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/erisdataworks/300chat_universe.","url":"https://huggingface.co/datasets/erisdataworks/300chat_universe","creator_name":"Eris Dataworks","creator_url":"https://huggingface.co/erisdataworks","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["Indonesian","Japanese","Chinese","English","Spanish"],"keywords_longer_than_N":true},
	{"name":"linkedin-industry-list","keyword":"german","description":"fantastic-jobs/linkedin-industry-list dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/fantastic-jobs/linkedin-industry-list","creator_name":"Fantastic.jobs","creator_url":"https://huggingface.co/fantastic-jobs","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","translation","English","Korean","Spanish"],"keywords_longer_than_N":true},
	{"name":"GlobalNLI","keyword":"german","description":"\n\t\n\t\t\n\t\tDataset Card for global_nli\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nGlobal NLI is a new text-based benchmark based on the aggregation of existing NLI datasets that are publicly available.\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nThere are 59 languages available :\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\n\t\n\t\t\n\t\tData Instances\n\t\n\nThe examples look like this for English:\nfrom datasets import load_dataset\ndata = load_dataset('vivekvermaiit/globalnli', 'eng') \n# Please, specify the language code\n# A data point example is below:\n{â€¦ See the full description on the dataset page: https://huggingface.co/datasets/vivekvermaiit/GlobalNLI.","url":"https://huggingface.co/datasets/vivekvermaiit/GlobalNLI","creator_name":"Vivek Verma","creator_url":"https://huggingface.co/vivekvermaiit","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","natural-language-inference","multilingual","XNLI, AfriXNLI, IndicXNLI, AmericasNLI [30], XNLI-ca, myXNLI, IndoNLI, JNLI , InferBR, sick_pl, JamPatoisNLI, KLUE, RoNLI.","Amharic"],"keywords_longer_than_N":true},
	{"name":"MKQARetrieval","keyword":"german","description":"\n  MKQARetrieval\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nMultilingual Knowledge Questions & Answers (MKQA)contains 10,000 queries sampled from the Google Natural Questions dataset.\n        For each query we collect new passage-independent answers. These queries and answers are then human translated into 25 Non-English languages.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2t\n\n\nDomains\nWritten\n\n\nReference\nhttps://github.com/apple/ml-mkqa\n\n\n\t\n\nSource datasets:\n\napple/mkqa\n\n\n\t\n\t\t\n\t\tHow to evaluateâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/MKQARetrieval.","url":"https://huggingface.co/datasets/mteb/MKQARetrieval","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"Creative Commons Attribution 3.0","license_url":"https://scancode-licensedb.aboutcode.org/cc-by-3.0.html","language":"en","first_N":5,"first_N_keywords":["text-retrieval","multiple-choice-qa","human-annotated","multilingual","apple/mkqa"],"keywords_longer_than_N":true},
	{"name":"GerDaLIRSmall","keyword":"german","description":"\n  GerDaLIRSmall\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nThe dataset consists of documents, passages and relevance labels in German. In contrast to the original dataset, only documents that have corresponding queries in the query set are chosen to create a smaller corpus for evaluation purposes.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2t\n\n\nDomains\nLegal, Written\n\n\nReference\nhttps://github.com/lavis-nlp/GerDaLIR\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding modelâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/GerDaLIRSmall.","url":"https://huggingface.co/datasets/mteb/GerDaLIRSmall","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","derived","monolingual","German"],"keywords_longer_than_N":true},
	{"name":"napierone-epub-raw","keyword":"german","description":"\n\t\n\t\t\n\t\tBEE-spoke-data/napierone-epub-raw\n\t\n\nNapierOne EPUB files converted with marker. Seems to contain mostly books from Project Gutenberg.\n\n\t\n\t\t\n\t\tdetected languages\n\t\n\nvia fasttext-langdetect\n{'ca': 1,\n 'cy': 1,\n 'da': 6,\n 'de': 105,\n 'en': 4403,\n 'eo': 2,\n 'es': 61,\n 'fi': 76,\n 'fr': 189,\n 'he': 1,\n 'hu': 5,\n 'is': 1,\n 'it': 40,\n 'la': 6,\n 'nl': 41,\n 'pl': 4,\n 'pt': 38,\n 'sv': 10,\n 'tl': 9}\n\n","url":"https://huggingface.co/datasets/BEE-spoke-data/napierone-epub-raw","creator_name":"BEEspoke Data","creator_url":"https://huggingface.co/BEE-spoke-data","license_name":"Open Data Commons Attribution License v1.0","license_url":"https://scancode-licensedb.aboutcode.org/odc-by-1.0.html","language":"en","first_N":5,"first_N_keywords":["text-generation","feature-extraction","English","Spanish","Finnish"],"keywords_longer_than_N":true},
	{"name":"MultiLongDocRetrieval","keyword":"german","description":"\n  MultiLongDocRetrieval\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nMulti Long Doc Retrieval (MLDR) 'is curated by the multilingual articles from Wikipedia, Wudao and mC4 (see Table 7), and NarrativeQA (KocË‡isky Ì et al., 2018; Gu Ìˆnther et al., 2023), which is only for English.' (Chen et al., 2024).\n        It is constructed by sampling lengthy articles from Wikipedia, Wudao and mC4 datasets and randomly choose paragraphs from them. Then we use GPT-3.5 to generate questions basedâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/MultiLongDocRetrieval.","url":"https://huggingface.co/datasets/mteb/MultiLongDocRetrieval","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","LM-generated","multilingual","Shitao/MLDR","Arabic"],"keywords_longer_than_N":true},
	{"name":"vdr-multilingual-train","keyword":"german","description":"\n\t\n\t\t\n\t\tMultilingual Visual Document Retrieval Dataset\n\t\n\n\n\nThis dataset consists of 500k multilingual query image samples, collected and generated from scratch using public internet pdfs. The queries are synthetic and generated using VLMs (gemini-1.5-pro and Qwen2-VL-72B).\n\nIt was used to train the vdr-2b-multi-v1 retrieval multimodal, multilingual embedding model.\n\n\t\n\t\t\n\t\n\t\n\t\tHow it was created\n\t\n\nThis is the entire data pipeline used to create the Italian subset of this dataset. Each stepâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/llamaindex/vdr-multilingual-train.","url":"https://huggingface.co/datasets/llamaindex/vdr-multilingual-train","creator_name":"LlamaIndex","creator_url":"https://huggingface.co/llamaindex","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["multilingual","German","Italian","French","Spanish"],"keywords_longer_than_N":true},
	{"name":"german-webtext-quality-classification-dataset","keyword":"german","description":"\n\t\n\t\t\n\t\tDataset Card for Dataset Name\n\t\n\nTrain and (manually annotated) test data of Paper: \nBootstrapping a Sentence-Level Corpus Quality Classifier for Web Text using Active Learning (RANLP25)\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\nsee: TODO url\n","url":"https://huggingface.co/datasets/mbley/german-webtext-quality-classification-dataset","creator_name":"Maximilian Bley","creator_url":"https://huggingface.co/mbley","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","German","mit","1K - 10K","parquet"],"keywords_longer_than_N":true},
	{"name":"PangeaBench-xm100","keyword":"german","description":"\n\t\n\t\t\n\t\n\t\n\t\tXM100\n\t\n\n\n\t\n\t\t\n\t\n\t\n\t\tThis is a copy from https://google.github.io/crossmodal-3600/\n\t\n\nIf you use this dataset, please cite the original authors:\n@inproceedings{ThapliyalCrossmodal2022,\n  author = {Ashish Thapliyal and Jordi Pont-Tuset and Xi Chen and Radu Soricut},\n  title = {{Crossmodal-3600: A Massively Multilingual Multimodal Evaluation Dataset}},\n  booktitle = {EMNLP},\n  year = {2022}\n}\n\n","url":"https://huggingface.co/datasets/neulab/PangeaBench-xm100","creator_name":"NeuLab @ LTI/CMU","creator_url":"https://huggingface.co/neulab","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["image-to-text","Arabic","Bengali","Czech","Danish"],"keywords_longer_than_N":true},
	{"name":"mls-annotated","keyword":"german","description":"\n\t\n\t\t\n\t\tDataset Card for Annotations of non English MLS\n\t\n\nThis dataset consists in annotations of a the Non English subset of the Multilingual LibriSpeech (MLS) dataset. \nMLS dataset is a large multilingual corpus suitable for speech research. The dataset is derived from read audiobooks from LibriVox and consists of \n8 languages - English, German, Dutch, Spanish, French, Italian, Portuguese, Polish. It includes about 44.5K hours of English and a total of about 6K hours for other languages.â€¦ See the full description on the dataset page: https://huggingface.co/datasets/PHBJT/mls-annotated.","url":"https://huggingface.co/datasets/PHBJT/mls-annotated","creator_name":"Paul Henri Biojout","creator_url":"https://huggingface.co/PHBJT","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-to-speech","French","German","Dutch","Portuguese"],"keywords_longer_than_N":true},
	{"name":"PoliTok-DE","keyword":"german","description":"tomasruiz/PoliTok-DE dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/tomasruiz/PoliTok-DE","creator_name":"Tomas Ruiz","creator_url":"https://huggingface.co/tomasruiz","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":null,"first_N":5,"first_N_keywords":["video-classification","image-classification","German","English","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"FL_QA_GER","keyword":"german","description":"Question-Answer style Dataset containing 3069 different questions regarding the Principality of Liechtenstein.\nContains 1409 questions in the legal domain and 1660 questions in the historical / cultural domain.\nThe questions are generated using OpenAI ChatGPT 4, asking ChatGPT to produce question-answer pairs for the text content given. The text content is based on the documents and articles used in the FL_Legal_GER and FL_History_GER textual datasets.\nDataset is made available in Germanâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/JoeUnili/FL_QA_GER.","url":"https://huggingface.co/datasets/JoeUnili/FL_QA_GER","creator_name":"Joel","creator_url":"https://huggingface.co/JoeUnili","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["question-answering","text-generation","German","apache-2.0","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"multi-hatecheck","keyword":"german","description":"\n  MultiHateClassification\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nHate speech detection dataset with binary\n                       (hateful vs non-hateful) labels. Includes 25+ distinct types of hate\n                       and challenging non-hate, and 11 languages.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask categoryt2c\n\n\nDomains\nConstructed, Written\n\n\nReference\nhttps://aclanthology.org/2022.woah-1.15/\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this datasetâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/multi-hatecheck.","url":"https://huggingface.co/datasets/mteb/multi-hatecheck","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","sentiment-analysis","sentiment-scoring","sentiment-classification","hate-speech-detection"],"keywords_longer_than_N":true},
	{"name":"MultiMed-TSS","keyword":"german","description":"SehwanMoon/MultiMed-TSS dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/SehwanMoon/MultiMed-TSS","creator_name":"Sehwan Moon","creator_url":"https://huggingface.co/SehwanMoon","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","English","German","French","Chinese"],"keywords_longer_than_N":true},
	{"name":"cml-tts-filtered","keyword":"german","description":"\n\t\n\t\t\n\t\tDataset Card for Filtred and CML-TTS\n\t\n\nThis dataset is a filtred version of a CML-TTS [1]. \nCML-TTS [1] CML-TTS is a recursive acronym for CML-Multi-Lingual-TTS, a Text-to-Speech (TTS) dataset developed at the Center of Excellence in Artificial Intelligence (CEIA) of the Federal University of Goias (UFG). CML-TTS is a dataset comprising audiobooks sourced from the public domain books of Project Gutenberg, read by volunteers from the LibriVox project. The dataset includes recordings inâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/PHBJT/cml-tts-filtered.","url":"https://huggingface.co/datasets/PHBJT/cml-tts-filtered","creator_name":"Paul Henri Biojout","creator_url":"https://huggingface.co/PHBJT","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-to-speech","French","German","Dutch","Polish"],"keywords_longer_than_N":true},
	{"name":"GermanGovServiceRetrieval","keyword":"german","description":"\n  GermanGovServiceRetrieval\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nLHM-Dienstleistungen-QA is a German question answering dataset for government services of the Munich city administration. It associates questions with a textual context containing the answer\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask categoryt2t\n\n\nDomains\nGovernment, Written\n\n\nReference\nhttps://huggingface.co/datasets/it-at-m/LHM-Dienstleistungen-QA\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model onâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/GermanGovServiceRetrieval.","url":"https://huggingface.co/datasets/mteb/GermanGovServiceRetrieval","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","multiple-choice-qa","derived","monolingual","German"],"keywords_longer_than_N":true},
	{"name":"parallel_corpus_game","keyword":"german","description":"https://github.com/mnbvc-parallel-corpus-team/parallel_corpus_mnbvc\nGame Corpus Collected by MNBVC Parallel Corpus Team.\n\n\t\n\t\t\n\t\t09/17/2025 Updated\n\t\n\n\nHollow Knight\n\n\n\t\n\t\t\n\t\t09/15/2025 Updated\n\t\n\n\nLimbus Company\nMirror\n\n\n\t\n\t\t\n\t\t09/08/2025 Updated\n\t\n\n\nSpice and Wolf VR (1&2)\nDeep Rock Galactic\nCities Skylines 1\n\n\n\t\n\t\t\n\t\t09/02/2025 Updated\n\t\n\n\nPlague Inc\n\n\n\t\n\t\t\n\t\t09/01/2025 Updated\n\t\n\n\nBanGDream from https://bestdori.com/\n\n\n\t\n\t\t\n\t\t08/15/2025 Updated\n\t\n\n\nATRI fromâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/bot-yaya/parallel_corpus_game.","url":"https://huggingface.co/datasets/bot-yaya/parallel_corpus_game","creator_name":"yaya","creator_url":"https://huggingface.co/bot-yaya","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["translation","Arabic","Chinese","German","English"],"keywords_longer_than_N":true},
	{"name":"ValueConsistency","keyword":"german","description":"\n\t\n\t\t\n\t\n\t\n\t\tDataset Card for ValueConsistency\n\t\n\n\n\nThis is the ValueConsistency data set as introduced in the paper\n\"Are Large Language Models Consistent over Value-laden Questions?\".\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Description\n\t\n\n\nValueConsistency is a dataset of both controversial and uncontroversial questions \nin English, Chinese, German, and Japanese for topics from the U.S., China, Germany, and Japan. \nIt was generated via prompting by GPT-4 and validated manually.\nYouâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/jlcmoore/ValueConsistency.","url":"https://huggingface.co/datasets/jlcmoore/ValueConsistency","creator_name":"Jared","creator_url":"https://huggingface.co/jlcmoore","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["English","Chinese","German","Japanese","mit"],"keywords_longer_than_N":true},
	{"name":"BigAudioDataset","keyword":"german","description":"\n\t\n\t\t\n\t\tAstraMindAI/BigAudioDataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nAstraMindAI/BigAudioDataset is a large-scale, multilingual dataset designed for a wide range of audio and speech processing tasks. It comprises a diverse collection of audio clips, including both spoken voice and music, making it a valuable resource for training and evaluating models for automatic speech recognition (ASR), text-to-speech (TTS), audio classification, and more.\nThe voice data is aggregated from well-knownâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/AstraMindAI/BigAudioDataset.","url":"https://huggingface.co/datasets/AstraMindAI/BigAudioDataset","creator_name":"AstraMindAI","creator_url":"https://huggingface.co/AstraMindAI","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["multilingual","English","Italian","French","German"],"keywords_longer_than_N":true},
	{"name":"gsm8k-translated","keyword":"german","description":"Sara237/gsm8k-translated dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/Sara237/gsm8k-translated","creator_name":"Sara Rajaee","creator_url":"https://huggingface.co/Sara237","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text2text-generation","English","German","Spanish","French"],"keywords_longer_than_N":true},
	{"name":"acl-6060","keyword":"german","description":"\n\t\n\t\t\n\t\tACL 60/60\n\t\n\n\n\t\n\t\t\n\t\tDataset details\n\t\n\nACL 60/60 evaluation sets for multilingual translation of ACL 2022 technical presentations into 10 target languages.\n\n\t\n\t\t\n\t\tCitation\n\t\n\n@inproceedings{salesky-etal-2023-evaluating,\n    title = \"Evaluating Multilingual Speech Translation under Realistic Conditions with Resegmentation and Terminology\",\n    author = \"Salesky, Elizabeth  and\n      Darwish, Kareem  and\n      Al-Badrashiny, Mohamed  and\n      Diab, Mona  and\n      Niehues, Jan\"â€¦ See the full description on the dataset page: https://huggingface.co/datasets/ymoslem/acl-6060.","url":"https://huggingface.co/datasets/ymoslem/acl-6060","creator_name":"Yasmin Moslem","creator_url":"https://huggingface.co/ymoslem","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["translation","automatic-speech-recognition","English","Arabic","German"],"keywords_longer_than_N":true},
	{"name":"Global-MMLU","keyword":"german","description":"\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nGlobal-MMLU ðŸŒ is a multilingual evaluation set spanning 42 languages, including English. This dataset combines machine translations for MMLU questions along with professional translations and crowd-sourced post-edits.\nIt also includes cultural sensitivity annotations for a subset of the questions (2850 questions per language) and classifies them as Culturally Sensitive (CS) ðŸ—½ or Culturally Agnostic (CA) âš–ï¸. These annotations were collected as part of an openâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/CohereLabs/Global-MMLU.","url":"https://huggingface.co/datasets/CohereLabs/Global-MMLU","creator_name":"Cohere Labs","creator_url":"https://huggingface.co/CohereLabs","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["English","Arabic","Bengali","Spanish","French"],"keywords_longer_than_N":true},
	{"name":"german-ler","keyword":"german","description":"\n\t\n\t\t\n\t\tDataset Card for \"German LER\"\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nA dataset of Legal Documents from German federal court decisions for Named Entity Recognition. The dataset is human-annotated with 19 fine-grained entity classes. The dataset consists of approx. 67,000 sentences and contains 54,000 annotated entities. NER tags use the BIO tagging scheme. \nThe dataset includes two different versions of annotations, one with a set of 19 fine-grained semantic classes (ner_tags) and another oneâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/elenanereiss/german-ler.","url":"https://huggingface.co/datasets/elenanereiss/german-ler","creator_name":"Elena Leitner","creator_url":"https://huggingface.co/elenanereiss","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["token-classification","named-entity-recognition","expert-generated","found","monolingual"],"keywords_longer_than_N":true},
	{"name":"ALMA-prompt-completion","keyword":"german","description":"\n\t\n\t\t\n\t\tDataset Card for ALMA-prompt-completion\n\t\n\n ALMA Dataset if format of prompt-completion\n\nCreated by: fe1ixxu\nShared by: me\nLanguage(s) (NLP): English, Czech, German, Russian, Islandic, Chinese\nLicense: MIT\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Sources [optional]\n\t\n\n\n\n\nRepository: [https://github.com/fe1ixxu/ALMA]\nPaper [optional]: [https://arxiv.org/abs/2309.11674]\n\n\n\t\n\t\n\t\n\t\tUses\n\t\n\nLLM translators\n","url":"https://huggingface.co/datasets/kristaller486/ALMA-prompt-completion","creator_name":"Kristaller486","creator_url":"https://huggingface.co/kristaller486","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["translation","English","Russian","Czech","German"],"keywords_longer_than_N":true},
	{"name":"ComMT","keyword":"german","description":"\n\t\n\t\t\n\t\tComMT\n\t\n\n\nGithub: https://github.com/NiuTrans/LaMaTE/\nPaper: https://arxiv.org/abs/2503.06594\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nComMT is a comprehensive dataset suite designed to support the development and evaluation of universal translation models. \nIt includes diverse translation-related tasks, providing a well-curated data resource for training and testing LLM-based machine translation systems.\nThe dataset is meticulously curated from over 60+ publicly available data sources. \nTheâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/NiuTrans/ComMT.","url":"https://huggingface.co/datasets/NiuTrans/ComMT","creator_name":"NiuTrans","creator_url":"https://huggingface.co/NiuTrans","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["translation","text-generation","English","Chinese","German"],"keywords_longer_than_N":true},
	{"name":"COLING-2025-GENAI-3","keyword":"german","description":"\nðŸš¨ RAID: A Shared Benchmark for Robust Evaluation of Machine-Generated Text Detectors ðŸš¨\nðŸŒ Website, ðŸ–¥ï¸ Github, ðŸ“ Paper\n\n\nRAID is the largest & most comprehensive dataset for evaluating AI-generated text detectors. \nIt contains over 10 million documents spanning 11 LLMs, 11 genres, 4 decoding strategies, and 12 adversarial attacks. \nIt is designed to be the go-to location for trustworthy third-party evaluation of both open-source and closed-source generated text detectors.\n\n\t\n\t\t\n\t\n\t\n\t\tLoadâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/1-800-SHARED-TASKS/COLING-2025-GENAI-3.","url":"https://huggingface.co/datasets/1-800-SHARED-TASKS/COLING-2025-GENAI-3","creator_name":"1-800-SHARED-TASKS","creator_url":"https://huggingface.co/1-800-SHARED-TASKS","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","English","Czech","German","mit"],"keywords_longer_than_N":true},
	{"name":"SiMT-Multi-90K","keyword":"german","description":"90K high-quality multilingual SiMT training data for EAST (paper and code), includes eight directions: De-En, En-De, Zh-En, En-Zh, Ru-En, En-Ru, Cs-En and En-Cs.\n","url":"https://huggingface.co/datasets/biaofu-xmu/SiMT-Multi-90K","creator_name":"Biao Fu","creator_url":"https://huggingface.co/biaofu-xmu","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["translation","English","German","Chinese","Russian"],"keywords_longer_than_N":true},
	{"name":"allenai_tulu-3-sft-mixture-DolphinLabeled","keyword":"german","description":"\n\t\n\t\t\n\t\tallenai tulu-3-sft-mixture DolphinLabeled\n\t\n\n\n\t\n\t\t\n\t\tPart of the DolphinLabeled series of datasets\n\t\n\n\n\t\n\t\t\n\t\tPresented by Eric Hartford and Cognitive Computations\n\t\n\nThe purpose of this dataset is to enable filtering of allenai/tulu-3-sft-mixture dataset.\nThe original dataset is allenai/tulu-3-sft-mixture\nI have modified the dataset using two scripts.\n\ndedupe.py - removes rows with identical final message content\nlabel.py - adds a \"flags\" column containing the following booleanâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/cognitivecomputations/allenai_tulu-3-sft-mixture-DolphinLabeled.","url":"https://huggingface.co/datasets/cognitivecomputations/allenai_tulu-3-sft-mixture-DolphinLabeled","creator_name":"Cognitive Computations","creator_url":"https://huggingface.co/cognitivecomputations","license_name":"Open Data Commons Attribution License v1.0","license_url":"https://scancode-licensedb.aboutcode.org/odc-by-1.0.html","language":"en","first_N":5,"first_N_keywords":["other","crowdsourced","expert-generated","machine-generated","multilingual"],"keywords_longer_than_N":true},
	{"name":"LegalQuAD","keyword":"german","description":"\n  LegalQuAD\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nThe dataset consists of questions and legal documents in German.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2t\n\n\nDomains\nLegal, Written\n\n\nReference\nhttps://github.com/Christoph911/AIKE2021_Appendix\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask = mteb.get_tasks([\"LegalQuAD\"])\nevaluator = mteb.MTEB(task)\n\nmodel = mteb.get_model(YOUR_MODEL)â€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/LegalQuAD.","url":"https://huggingface.co/datasets/mteb/LegalQuAD","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","multiple-choice-qa","derived","monolingual","German"],"keywords_longer_than_N":true},
	{"name":"fusion-synth-data-s1kx","keyword":"german","description":"\n\t\n\t\t\n\t\tOffline Synthetic Data (s1K-X) for: Making, not taking, the Best-of-N\n\t\n\n\n\t\n\t\t\n\t\tContent\n\t\n\nThis data contains completions for the  s1K-X training split prompts from 5 different teacher models and 2 aggregations:\nTeachers: We sample one completion from each of the following models at temperature T=0.3. For kimik2, qwen3, and deepseek-v3 we use TogetherAI, for gemma3-27b and command-a we use locally hosted images.\n\ngemma3-27b: GEMMA3-27B-IT\nkimik2: KIMI-K2-INSTRUCT\nqwen3: QWEN3-235Bâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/CohereLabs/fusion-synth-data-s1kx.","url":"https://huggingface.co/datasets/CohereLabs/fusion-synth-data-s1kx","creator_name":"Cohere Labs","creator_url":"https://huggingface.co/CohereLabs","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-generation","question-answering","English","German","Spanish"],"keywords_longer_than_N":true},
	{"name":"Openpdf-MultiReceipt-1K","keyword":"german","description":"\n\t\n\t\t\n\t\tOpenpdf-MultiReceipt-1K\n\t\n\nOpenpdf-MultiReceipt-1K is a dataset consisting of over 1,000 receipt documents in PDF format. This dataset is designed for use in image-to-text and document understanding tasks, particularly Optical Character Recognition (OCR), receipt parsing, and layout analysis.\n\n\t\n\t\t\n\t\tNotes\n\t\n\n\nNo text annotations or metadata are provided â€” only the raw PDFs.\nIdeal for tasks requiring raw document inputs like PDF-to-Text pipelines.\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\n\nSize: 1â€¦ See the full description on the dataset page: https://huggingface.co/datasets/prithivMLmods/Openpdf-MultiReceipt-1K.","url":"https://huggingface.co/datasets/prithivMLmods/Openpdf-MultiReceipt-1K","creator_name":"Prithiv Sakthi","creator_url":"https://huggingface.co/prithivMLmods","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["image-to-text","English","German","apache-2.0","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"quran_multilingual_parallel","keyword":"german","description":"\n\t\n\t\t\n\t\tðŸ“˜ Qurâ€™an Multilingual Parallel Dataset (quran_multilingual_parallel)\n\t\n\nThis dataset presents a clean, structurally-aligned multilingual parallel corpus of the Qurâ€™anic text. It is intended for linguistic, computational, and cross-lingual AI applications â€” not only for religious interpretation.\nIt contains over 6,200 verse-level alignments in 54 human languages, formatted in a machine-friendly .csv structure with language-specific translation fields.\n\n\n\t\n\t\t\n\t\n\t\n\t\tðŸ§  Dataset Highlightsâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/freococo/quran_multilingual_parallel.","url":"https://huggingface.co/datasets/freococo/quran_multilingual_parallel","creator_name":"Wynn","creator_url":"https://huggingface.co/freococo","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["translation","Arabic","Albanian","Amharic","Azerbaijani"],"keywords_longer_than_N":true},
	{"name":"GraSCCo","keyword":"german","description":"\n\t\n\t\t\n\t\tDataset Card for GraSCCo\n\t\n\nThe dataset contains clinical discharge summaries along with their corresponding summarizations. The source texts are from the GraSCCo dataset.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe summarization texts were created using ChatGPT-3.5, followed by manual corrections and refinements. As mentioned in the GraSCCo paper, the source texts were synthetically generated based on real medical data. Consequently, the texts are no longer medicallyâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/johannsr/GraSCCo.","url":"https://huggingface.co/datasets/johannsr/GraSCCo","creator_name":"Johann Simon Reichel","creator_url":"https://huggingface.co/johannsr","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["summarization","German","mit","< 1K","parquet"],"keywords_longer_than_N":true},
	{"name":"Tridis_layout_manuscripts","keyword":"german","description":"\n\t\n\t\t\n\t\tA Unified Dataset for Codicological Document Layout Analysis\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis repository contains a large-scale, unified dataset for Document Layout Analysis (DLA) in historical manuscripts. It was created by harmonizing three distinct public corporaâ€”e-NDP, CATMuS, and HORAEâ€”which cover a wide range of document types from the 12th to the 17th century (administrative registers, literary manuscripts, printed books, and Books of Hours).\nThe key feature of thisâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/magistermilitum/Tridis_layout_manuscripts.","url":"https://huggingface.co/datasets/magistermilitum/Tridis_layout_manuscripts","creator_name":"Sergio Torres","creator_url":"https://huggingface.co/magistermilitum","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["English","French","Latin","German","mit"],"keywords_longer_than_N":true},
	{"name":"Testset","keyword":"german","description":"Cesarus/Testset dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/Cesarus/Testset","creator_name":"Stefan Maier","creator_url":"https://huggingface.co/Cesarus","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["German","apache-2.0","< 1K","json","Text"],"keywords_longer_than_N":true},
	{"name":"VD-Metadata","keyword":"german","description":"\n\t\n\t\t\n\t\tMetadata of the \"Verzeichnis der im deutschen Sprachraum erschienen Drucke\"\n\t\n\n\n\t\n\t\t\n\t\tTitle\n\t\n\nMetadata of the \"Verzeichnis der im deutschen Sprachraum erschienen Drucke\"\n\n\t\n\t\t\n\t\tDescription and Motivation\n\t\n\nThis data publication was created with the intent to provide bibliographic and subject indexing metadata for research purposes and the development of AI applications. This data publication can be regarded as the German national bibliography of the period 1500â€“1800. It consists ofâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/SBB/VD-Metadata.","url":"https://huggingface.co/datasets/SBB/VD-Metadata","creator_name":"Staatsbibliothek zu Berlin - PreuÃŸischer Kulturbesitz","creator_url":"https://huggingface.co/SBB","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","feature-extraction","German","Latin","Greek"],"keywords_longer_than_N":true},
	{"name":"MultiMed","keyword":"german","description":"\n\t\n\t\t\n\t\tMultiMed: Multilingual Medical Speech Recognition via Attention Encoder Decoder\n\t\n\nACL 2025\nKhai Le-Duc, Phuc Phan, Tan-Hanh Pham, Bach Phan Tat,\n\nMinh-Huong Ngo, Chris Ngo, Thanh Nguyen-Tang, Truong-Son Hy\n\n\nPlease press â­ button and/or cite papers if you feel helpful.\n\n\n  \n\n\n\nAbstract:\nMultilingual automatic speech recognition (ASR) in the medical domain serves as a foundational task for various downstream applications such as speech translation, spoken language understanding, andâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/leduckhai/MultiMed.","url":"https://huggingface.co/datasets/leduckhai/MultiMed","creator_name":"Le Duc Khai","creator_url":"https://huggingface.co/leduckhai","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","Vietnamese","English","German","French"],"keywords_longer_than_N":true},
	{"name":"Tridis","keyword":"german","description":"This is the first version of the dataset derived from the corpora used for TRIDIS (Tria Digita Scribunt). \nTRIDIS encompasses a series of Handwriting Text Recognition (HTR) models trained using semi-diplomatic transcriptions of medieval and early modern manuscripts.\nThe semi-diplomatic transcription approach involves resolving abbreviations found in the original manuscripts and normalizing Punctuation and Allographs.\nThe dataset contains approximately 4,000 pages of manuscripts and isâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/magistermilitum/Tridis.","url":"https://huggingface.co/datasets/magistermilitum/Tridis","creator_name":"Sergio Torres","creator_url":"https://huggingface.co/magistermilitum","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["image-to-text","French","Spanish","Latin","German"],"keywords_longer_than_N":true},
	{"name":"de_en","keyword":"german","description":"\n\t\n\t\t\n\t\tDataset Card for Dataset Name\n\t\n\n\n\nThis dataset card aims to be a base template for new datasets. It has been generated using this raw template.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\n\n\n\n\n\nCurated by: [More Information Needed]\nFunded by [optional]: [More Information Needed]\nShared by [optional]: [More Information Needed]\nLanguage(s) (NLP): [More Information Needed]\nLicense: [More Information Needed]\n\n\n\t\n\t\t\n\t\tDataset Sources [optional]\n\t\n\n\n\n\nRepository: [Moreâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Sohy/de_en.","url":"https://huggingface.co/datasets/Sohy/de_en","creator_name":"Sohyun Son","creator_url":"https://huggingface.co/Sohy","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text2text-generation","German","English","apache-2.0","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"BenchMAX_Question_Answering","keyword":"german","description":"\n\t\n\t\t\n\t\tDataset Sources\n\t\n\n\nPaper: BenchMAX: A Comprehensive Multilingual Evaluation Suite for Large Language Models\nLink: https://huggingface.co/papers/2502.07346\nRepository: https://github.com/CONE-MT/BenchMAX\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nBenchMAX_Question_Answering is a dataset of BenchMAX for evaluating the long-context capability of LLMs in multilingual scenarios.\nThe subtasks are similar to the subtasks in RULER.\nThe data is sourcing from UN Parallel Corpus and xquad.\nThe haystacksâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/LLaMAX/BenchMAX_Question_Answering.","url":"https://huggingface.co/datasets/LLaMAX/BenchMAX_Question_Answering","creator_name":"LLaMAX","creator_url":"https://huggingface.co/LLaMAX","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","multilingual","English","Chinese","Spanish"],"keywords_longer_than_N":true},
	{"name":"multiCHILDES","keyword":"german","description":"\n\t\n\t\t\n\t\tmultiCHILDES: Multilingual Child-Directed Speech Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset contains child-directed speech from 19 languages, extracted from the CHILDES corpus. The text has been cleaned and is designed for text generation tasks, particularly in studying early language acquisition.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\nSource: CHILDES corpus\nLanguages: 19 languages\nText Type: Child-directed speech\nTask: Text Generation, Language Modeling\nData Processing: The datasetâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/IParraMartin/multiCHILDES.","url":"https://huggingface.co/datasets/IParraMartin/multiCHILDES","creator_name":"IÃ±igo Parra","creator_url":"https://huggingface.co/IParraMartin","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-generation","English","Basque","Spanish","Portuguese"],"keywords_longer_than_N":true}
]
;
