const data_for_language_europe_dutch = 
[
	{"name":"COVID-19-disinformation","keyword":"dutch","description":"\n\t\n\t\t\n\t\tCOVID-19 Infodemic Multilingual Dataset\n\t\n\nThis repository contains a multilingual dataset related to the COVID-19 infodemic, annotated with fine-grained labels. The dataset is curated to address questions of interest to journalists, fact-checkers, social media platforms, policymakers, and the general public. The dataset includes tweets in Arabic, Bulgarian, Dutch, and English, focusing on both binary (misinformation detection) and multiclass classification (different types of‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/QCRI/COVID-19-disinformation.","url":"https://huggingface.co/datasets/QCRI/COVID-19-disinformation","creator_name":"Qatar Computing Research Institute","creator_url":"https://huggingface.co/QCRI","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","Arabic","Bulgarian","Dutch","English"],"keywords_longer_than_N":true},
	{"name":"no_robots_dutch","keyword":"dutch","description":"\n\t\n\t\t\n\t\tDataset Card for No Robots Dutch\n\t\n\n\n\t\n\t\t\n\t\tCitation\n\t\n\nIf you use this dataset, GEITje 7B Ultra (SFT) or any of its derivatives or quantizations, place cite the following paper:\n@misc{vanroy2024geitje7bultraconversational,\n      title={GEITje 7B Ultra: A Conversational Model for Dutch}, \n      author={Bram Vanroy},\n      year={2024},\n      eprint={2412.04092},\n      archivePrefix={arXiv},\n      primaryClass={cs.CL},\n      url={https://arxiv.org/abs/2412.04092}, \n}\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/BramVanroy/no_robots_dutch.","url":"https://huggingface.co/datasets/BramVanroy/no_robots_dutch","creator_name":"Bram Vanroy","creator_url":"https://huggingface.co/BramVanroy","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","Dutch","apache-2.0","1K - 10K","parquet"],"keywords_longer_than_N":true},
	{"name":"allenai_tulu-3-sft-mixture-DolphinLabeled","keyword":"dutch","description":"\n\t\n\t\t\n\t\tallenai tulu-3-sft-mixture DolphinLabeled\n\t\n\n\n\t\n\t\t\n\t\tPart of the DolphinLabeled series of datasets\n\t\n\n\n\t\n\t\t\n\t\tPresented by Eric Hartford and Cognitive Computations\n\t\n\nThe purpose of this dataset is to enable filtering of allenai/tulu-3-sft-mixture dataset.\nThe original dataset is allenai/tulu-3-sft-mixture\nI have modified the dataset using two scripts.\n\ndedupe.py - removes rows with identical final message content\nlabel.py - adds a \"flags\" column containing the following boolean‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/QuixiAI/allenai_tulu-3-sft-mixture-DolphinLabeled.","url":"https://huggingface.co/datasets/QuixiAI/allenai_tulu-3-sft-mixture-DolphinLabeled","creator_name":"Quixi AI","creator_url":"https://huggingface.co/QuixiAI","license_name":"Open Data Commons Attribution License v1.0","license_url":"https://scancode-licensedb.aboutcode.org/odc-by-1.0.html","language":"en","first_N":5,"first_N_keywords":["other","crowdsourced","expert-generated","machine-generated","multilingual"],"keywords_longer_than_N":true},
	{"name":"xlel_wd_dictionary","keyword":"dutch","description":"XLEL-WD is a multilingual event linking dataset. This sub-dataset contains a dictionary of events from Wikidata. The multilingual descriptions for Wikidata event items are taken from the corresponding Wikipedia articles.","url":"https://huggingface.co/datasets/adithya7/xlel_wd_dictionary","creator_name":"Adithya Pratapa","creator_url":"https://huggingface.co/adithya7","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["found","found","multilingual","original","Afrikaans"],"keywords_longer_than_N":true},
	{"name":"minigpt4-7b-ggml","keyword":"dutch","description":"These are quantized ggml binary files for minigpt4 7B model.\nThese files can be used in conjunction with vicuna v0 ggml models to get minigpt4 working.\nNot all implementations were tested. If there are any issues, use f16.\n","url":"https://huggingface.co/datasets/maknee/minigpt4-7b-ggml","creator_name":"maknee","creator_url":"https://huggingface.co/maknee","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":null,"first_N":5,"first_N_keywords":["English","Bulgarian","Catalan","Czech","Danish"],"keywords_longer_than_N":true},
	{"name":"seamless-align","keyword":"dutch","description":"\n\t\n\t\t\n\t\tDataset Card for Seamless-Align (WIP). Inspired by https://huggingface.co/datasets/allenai/nllb\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset was created based on metadata for mined Speech-to-Speech(S2S), Text-to-Speech(TTS) and Speech-to-Text(S2T) released by Meta AI.  The S2S contains data for 35 language pairs. The S2S dataset is ~1000GB compressed.\n\n\t\n\t\t\n\t\tHow to use the data\n\t\n\nThere are two ways to access the data:\n\nVia the Hugging Face Python datasets library\n\nScripts coming soon‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/jhu-clsp/seamless-align.","url":"https://huggingface.co/datasets/jhu-clsp/seamless-align","creator_name":"Center for Language and Speech Processing @ JHU","creator_url":"https://huggingface.co/jhu-clsp","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["translation","audio-to-audio","Maltese","English","Welsh"],"keywords_longer_than_N":true},
	{"name":"tulu-3-sft-mixture","keyword":"dutch","description":"\n\n\n\t\n\t\t\n\t\tTulu 3 SFT Mixture\n\t\n\nNote that this collection is licensed under ODC-BY-1.0 license; different licenses apply to subsets of the data. Some portions of the dataset are non-commercial. We present the mixture as a research artifact.\nThe Tulu 3 SFT mixture was used to train the Tulu 3 series of models.\nIt contains 939,344 samples from the following sets:\n\nCoCoNot (ODC-BY-1.0), 10,983 prompts (Brahman et al., 2024)\nFLAN v2 via ai2-adapt-dev/flan_v2_converted, 89,982 prompts (Longpre et‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/allenai/tulu-3-sft-mixture.","url":"https://huggingface.co/datasets/allenai/tulu-3-sft-mixture","creator_name":"Ai2","creator_url":"https://huggingface.co/allenai","license_name":"Open Data Commons Attribution License v1.0","license_url":"https://scancode-licensedb.aboutcode.org/odc-by-1.0.html","language":"en","first_N":5,"first_N_keywords":["other","crowdsourced","expert-generated","machine-generated","multilingual"],"keywords_longer_than_N":true},
	{"name":"sick_nl","keyword":"dutch","description":"\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nAn automatically translated, manually corrected translation of the SICK dataset of Marelli et al. 2014, intended to boost research in Dutch NLP.\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nThe dataset is in Dutch.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\n\t\n\t\t\n\t\tData Fields\n\t\n\n\npair_ID: sentence pair ID\nsentence_A: sentence A\nsentence_B: sentence B\nlabel: textual entailment gold label: entailment (0), neutral (1) or contradiction (2)\nrelatedness_score: semantic relatedness gold score (on a 1-5‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/maximedb/sick_nl.","url":"https://huggingface.co/datasets/maximedb/sick_nl","creator_name":"Maxime De Bruyn","creator_url":"https://huggingface.co/maximedb","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","Dutch","mit","1K - 10K","parquet"],"keywords_longer_than_N":true},
	{"name":"mteb-nl-sick-pcls-pr","keyword":"dutch","description":"\n  SICKNLPairClassification\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nSICK-NL is a Dutch translation of SICK \n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2t\n\n\nDomains\nWeb, Written\n\n\nReference\nhttps://aclanthology.org/2021.eacl-main.126/\n\n\n\t\n\nSource datasets:\n\nclips/mteb-nl-sick\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask = mteb.get_task(\"SICKNLPairClassification\")\nevaluator = mteb.MTEB([task])\n\nmodel =‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/clips/mteb-nl-sick-pcls-pr.","url":"https://huggingface.co/datasets/clips/mteb-nl-sick-pcls-pr","creator_name":"CLiPS","creator_url":"https://huggingface.co/clips","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","human-annotated","translated","clips/mteb-nl-sick","Dutch"],"keywords_longer_than_N":true},
	{"name":"mteb-nl-vabb-mlcls-pr","keyword":"dutch","description":"\n  VABBMultiLabelClassification\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nThis dataset contains the fourteenth edition of the Flemish Academic Bibliography for the Social Sciences and Humanities (VABB-SHW), a database of academic publications from the social sciences and humanities authored by researchers affiliated to Flemish universities (more information). Publications in the database are used as one of the parameters of the Flemish performance-based research funding system‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/clips/mteb-nl-vabb-mlcls-pr.","url":"https://huggingface.co/datasets/clips/mteb-nl-vabb-mlcls-pr","creator_name":"CLiPS","creator_url":"https://huggingface.co/clips","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","human-annotated","monolingual","clips/mteb-nl-vabb","Dutch"],"keywords_longer_than_N":true},
	{"name":"mteb-nl-opentender-cls-pr","keyword":"dutch","description":"\n  OpenTenderClassification\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nThis dataset contains Belgian and Dutch tender calls from OpenTender in Dutch\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2c\n\n\nDomains\nGovernment, Written\n\n\nReference\nhttps://arxiv.org/abs/2509.12340\n\n\n\t\n\nSource datasets:\n\nclips/mteb-nl-opentender-cls\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask =‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/clips/mteb-nl-opentender-cls-pr.","url":"https://huggingface.co/datasets/clips/mteb-nl-opentender-cls-pr","creator_name":"CLiPS","creator_url":"https://huggingface.co/clips","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","human-annotated","monolingual","clips/mteb-nl-opentender-cls","Dutch"],"keywords_longer_than_N":true},
	{"name":"fleurs-hs","keyword":"dutch","description":"\n\t\n\t\t\n\t\tFLEURS-HS\n\t\n\nAn extension of the FLEURS dataset for synthetic speech detection using text-to-speech, featured in the paper Synthetic speech detection with Wav2Vec 2.0 in various language settings.\nThis dataset is 1 of 3 used in the paper, the others being:\n\nFLEURS-HS VITS\ntest set containing (generally) more difficult synthetic samples\nseparated due to different licensing\n\n\nARCTIC-HS\nextension of the CMU_ARCTIC and L2-ARCTIC sets in a similar manner\n\n\n\n\t\n\t\t\n\t\tDataset Details‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/realnetworks-kontxt/fleurs-hs.","url":"https://huggingface.co/datasets/realnetworks-kontxt/fleurs-hs","creator_name":"KONTXT by RealNetworks","creator_url":"https://huggingface.co/realnetworks-kontxt","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":null,"first_N":5,"first_N_keywords":["audio-classification","German","English","Spanish","French"],"keywords_longer_than_N":true},
	{"name":"synthetic-multi-pii-ner-v1","keyword":"dutch","description":"\n\t\n\t\t\n\t\tSynthetic Multilingual PII NER Dataset\n\t\n\n\n\t\n\t\t\n\t\tModels Trained Using this Dataset\n\t\n\n\nE3-JSI/gliner-multi-pii-domains-v1\n\n\n\t\n\t\t\n\t\tDescription\n\t\n\nThis is a synthetic dataset created for the purposes for training multilingual personally identifiable information (PII) named entity recognition (NER) models.\nThe examples were generated using a prompt that generates the text and the entities present in the text. In addition, the generated response had to follow the restrictions:\n\nthe‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/E3-JSI/synthetic-multi-pii-ner-v1.","url":"https://huggingface.co/datasets/E3-JSI/synthetic-multi-pii-ner-v1","creator_name":"Department for Artificial Intelligence, Jo≈æef Stefan Institute","creator_url":"https://huggingface.co/E3-JSI","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["token-classification","English","French","German","Greek"],"keywords_longer_than_N":true},
	{"name":"c4","keyword":"dutch","description":"\n\t\n\t\t\n\t\tC4\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nA colossal, cleaned version of Common Crawl's web crawl corpus. Based on Common Crawl dataset: \"https://commoncrawl.org\".\nThis is the processed version of Google's C4 dataset\nWe prepared five variants of the data: en, en.noclean, en.noblocklist, realnewslike, and multilingual (mC4).\nFor reference, these are the sizes of the variants:\n\nen: 305GB\nen.noclean: 2.3TB\nen.noblocklist: 380GB\nrealnewslike: 15GB\nmultilingual (mC4): 9.7TB (108 subsets, one per‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/allenai/c4.","url":"https://huggingface.co/datasets/allenai/c4","creator_name":"Ai2","creator_url":"https://huggingface.co/allenai","license_name":"Open Data Commons Attribution License v1.0","license_url":"https://scancode-licensedb.aboutcode.org/odc-by-1.0.html","language":"en","first_N":5,"first_N_keywords":["text-generation","fill-mask","language-modeling","masked-language-modeling","no-annotation"],"keywords_longer_than_N":true},
	{"name":"divemt_attributions","keyword":"dutch","description":"\n\t\n\t\t\n\t\tDataset Card for DivEMT Attributions\n\t\n\nFor more details on DivEMT, see our EMNLP 2022 Paper and our Github repository\n","url":"https://huggingface.co/datasets/inseq/divemt_attributions","creator_name":"Inseq","creator_url":"https://huggingface.co/inseq","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["translation","machine-generated","translation","Italian","Arabic"],"keywords_longer_than_N":true},
	{"name":"ultra_feedback_dutch_cleaned","keyword":"dutch","description":"\n\t\n\t\t\n\t\tUltra Feedback Dutch Cleaned\n\t\n\nThis is a cleaned version of BramVanroy/ultra_feedback_dutch, based on the cleaning done by Argilla on the original Ultra Feedback dataset. Another difference is that we only include GEITje 7B Ultra and GPT-4-Turbo. GEITje chat, which was used in the original dataset, is not used.\nAfter cleaning I also generated replies for other models (like TowerInstruct, Mistral), but the results were too poor (in Dutch) to include so we only kept the GEITje Ultra and‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/BramVanroy/ultra_feedback_dutch_cleaned.","url":"https://huggingface.co/datasets/BramVanroy/ultra_feedback_dutch_cleaned","creator_name":"Bram Vanroy","creator_url":"https://huggingface.co/BramVanroy","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","Dutch","apache-2.0","100K - 1M","parquet"],"keywords_longer_than_N":true},
	{"name":"cnn_dailymail_nl","keyword":"dutch","description":"    This dataset is the CNN/Dailymail dataset translated to Dutch.\n    This is the original dataset:\n    ```\n    load_dataset(\"cnn_dailymail\", '3.0.0')\n    ```\n    And this is the HuggingFace translation pipeline:\n    ```\n    pipeline(\n        task='translation_en_to_nl',\n        model='Helsinki-NLP/opus-mt-en-nl',\n        tokenizer='Helsinki-NLP/opus-mt-en-nl')\n    ```","url":"https://huggingface.co/datasets/ml6team/cnn_dailymail_nl","creator_name":"ML6 Team","creator_url":"https://huggingface.co/ml6team","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":null,"first_N":5,"first_N_keywords":["no-annotation","found","monolingual","https://github.com/huggingface/datasets/tree/master/datasets/cnn_dailymail","Dutch"],"keywords_longer_than_N":true},
	{"name":"udhr-lid","keyword":"dutch","description":"\n\t\n\t\t\n\t\tUDHR-LID\n\t\n\nWhy UDHR-LID?\nYou can access UDHR (Universal Declaration of Human Rights) here, but when a verse is missing, they have texts such as \"missing\" or \"?\". Also, about 1/3 of the sentences consist only of \"articles 1-30\" in different languages. We cleaned the entire dataset from XML files and selected only the paragraphs. We cleared any unrelated language texts from the data and also removed the cases that were incorrect.\nIncorrect? Look at the ckb and kmr files in the UDHR.‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/cis-lmu/udhr-lid.","url":"https://huggingface.co/datasets/cis-lmu/udhr-lid","creator_name":"CIS, LMU Munich","creator_url":"https://huggingface.co/cis-lmu","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["multilingual","Tigrinya","Balkan Romani","Standard Arabic","Metlat√≥noc Mixtec"],"keywords_longer_than_N":true},
	{"name":"mqa","keyword":"dutch","description":"MQA is a multilingual corpus of questions and answers parsed from the Common Crawl. Questions are divided between Frequently Asked Questions (FAQ) pages and Community Question Answering (CQA) pages.","url":"https://huggingface.co/datasets/clips/mqa","creator_name":"CLiPS","creator_url":"https://huggingface.co/clips","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["question-answering","multiple-choice-qa","no-annotation","other","multilingual"],"keywords_longer_than_N":true},
	{"name":"CC-Cat","keyword":"dutch","description":"\n\t\n\t\t\n\t\tCC_Cat\n\t\n\n\nExtract from CC-WARC snapshots.\nMainly includes texts with 149 languages.\nPDF/IMAGE/AUDIO/VIDEO raw downloading link.\n\n\n\t\n\t\t\n\t\tNotice\n\t\n\n\nSince my computing resources are limited, this dataset will update by one-day of CC snapshots timestampts.\nAfter a snapshot is updated, the deduplicated version will be uploaded.\nIf you are interested in providing computing resources or have cooperation needs, please contact me.\n  carreyallthetime@gmail.com  \n      \n  \n\n","url":"https://huggingface.co/datasets/chengshidehaimianti/CC-Cat","creator_name":"zyq","creator_url":"https://huggingface.co/chengshidehaimianti","license_name":"Open Data Commons Attribution License v1.0","license_url":"https://scancode-licensedb.aboutcode.org/odc-by-1.0.html","language":"en","first_N":5,"first_N_keywords":["text-generation","Chinese","English","German","Russian"],"keywords_longer_than_N":true},
	{"name":"contentious_contexts","keyword":"dutch","description":"This dataset contains extracts from historical Dutch newspapers which have been containing keywords of potentially contentious words (according to present-day sensibilities). \nThe dataset contains multiple annotations per instance, given the option to quantify agreement scores for annotations. This dataset can be used to track how words and their meanings have changed over time","url":"https://huggingface.co/datasets/biglam/contentious_contexts","creator_name":"BigLAM: BigScience Libraries, Archives and Museums","creator_url":"https://huggingface.co/biglam","license_name":"Creative Commons Attribution 2.0","license_url":"https://scancode-licensedb.aboutcode.org/cc-by-2.0.html","language":null,"first_N":5,"first_N_keywords":["text-classification","sentiment-scoring","multi-label-classification","expert-generated","crowdsourced"],"keywords_longer_than_N":true},
	{"name":"contentious_contexts","keyword":"dutch","description":"This dataset contains extracts from historical Dutch newspapers which have been containing keywords of potentially contentious words (according to present-day sensibilities). \nThe dataset contains multiple annotations per instance, given the option to quantify agreement scores for annotations. This dataset can be used to track how words and their meanings have changed over time","url":"https://huggingface.co/datasets/biglam/contentious_contexts","creator_name":"BigLAM: BigScience Libraries, Archives and Museums","creator_url":"https://huggingface.co/biglam","license_name":"Creative Commons Attribution 2.0","license_url":"https://scancode-licensedb.aboutcode.org/cc-by-2.0.html","language":null,"first_N":5,"first_N_keywords":["text-classification","sentiment-scoring","multi-label-classification","expert-generated","crowdsourced"],"keywords_longer_than_N":true},
	{"name":"oasst2","keyword":"dutch","description":"\n\t\n\t\t\n\t\tOpen Assistant Conversations Dataset Release 2 (OASST2)\n\t\n\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nThis dataset contains message trees. Each message tree has an initial prompt message as the root node, \nwhich can have multiple child messages as replies, and these child messages can have multiple replies. \nAll messages have a role property: this can either be \"assistant\" or \"prompter\". The roles in \nconversation threads from prompt to leaf node strictly alternate between \"prompter\" and‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/OpenAssistant/oasst2.","url":"https://huggingface.co/datasets/OpenAssistant/oasst2","creator_name":"OpenAssistant","creator_url":"https://huggingface.co/OpenAssistant","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["English","Spanish","Russian","German","Polish"],"keywords_longer_than_N":true},
	{"name":"fleurs","keyword":"dutch","description":"\n\t\n\t\t\n\t\tFLEURS\n\t\n\nFleurs is the speech version of the FLoRes machine translation benchmark. \nWe use 2009 n-way parallel sentences from the FLoRes dev and devtest publicly available sets, in 102 languages. \nTraining sets have around 10 hours of supervision. Speakers of the train sets are different than speakers from the dev/test sets. Multilingual fine-tuning is\nused and ‚Äùunit error rate‚Äù (characters, signs) of all languages is averaged. Languages and results are also grouped into seven‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/google/fleurs.","url":"https://huggingface.co/datasets/google/fleurs","creator_name":"Google","creator_url":"https://huggingface.co/google","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":null,"first_N":5,"first_N_keywords":["automatic-speech-recognition","expert-generated","crowdsourced","machine-generated","crowdsourced"],"keywords_longer_than_N":true},
	{"name":"tapaco","keyword":"dutch","description":"\n\t\n\t\t\n\t\tDataset Card for TaPaCo Corpus\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nA freely available paraphrase corpus for 73 languages extracted from the Tatoeba database. \nTatoeba is a crowdsourcing project mainly geared towards language learners. Its aim is to provide example sentences \nand translations for particular linguistic constructions and words. The paraphrase corpus is created by populating a \ngraph with Tatoeba sentences and equivalence links between sentences ‚Äúmeaning the same thing‚Äù. This‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/community-datasets/tapaco.","url":"https://huggingface.co/datasets/community-datasets/tapaco","creator_name":"Community Datasets","creator_url":"https://huggingface.co/community-datasets","license_name":"Creative Commons Attribution 2.0","license_url":"https://scancode-licensedb.aboutcode.org/cc-by-2.0.html","language":"en","first_N":5,"first_N_keywords":["translation","text-classification","semantic-similarity-classification","machine-generated","crowdsourced"],"keywords_longer_than_N":true},
	{"name":"mkqa","keyword":"dutch","description":"We introduce MKQA, an open-domain question answering evaluation set comprising 10k question-answer pairs sampled from the Google Natural Questions dataset, aligned across 26 typologically diverse languages (260k question-answer pairs in total). For each query we collected new passage-independent answers. These queries and answers were then human translated into 25 Non-English languages.","url":"https://huggingface.co/datasets/apple/mkqa","creator_name":"Apple","creator_url":"https://huggingface.co/apple","license_name":"Creative Commons Attribution 3.0","license_url":"https://scancode-licensedb.aboutcode.org/cc-by-3.0.html","language":null,"first_N":5,"first_N_keywords":["question-answering","open-domain-qa","crowdsourced","found","multilingual"],"keywords_longer_than_N":true},
	{"name":"multi_para_crawl","keyword":"dutch","description":"Parallel corpora from Web Crawls collected in the ParaCrawl project and further processed for making it a multi-parallel corpus by pivoting via English. Here we only provide the additional language pairs that came out of pivoting. The bitexts for English are available from the ParaCrawl release.\n40 languages, 669 bitexts\ntotal number of files: 40\ntotal number of tokens: 10.14G\ntotal number of sentence fragments: 505.48M\n\nPlease, acknowledge the ParaCrawl project at http://paracrawl.eu. This version is derived from the original release at their website adjusted for redistribution via the OPUS corpus collection. Please, acknowledge OPUS as well for this service.","url":"https://huggingface.co/datasets/Helsinki-NLP/multi_para_crawl","creator_name":"Language Technology Research Group at the University of Helsinki","creator_url":"https://huggingface.co/Helsinki-NLP","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":null,"first_N":5,"first_N_keywords":["translation","found","found","multilingual","original"],"keywords_longer_than_N":true},
	{"name":"ml_spoken_words","keyword":"dutch","description":"Multilingual Spoken Words Corpus is a large and growing audio dataset of spoken\nwords in 50 languages collectively spoken by over 5 billion people, for academic\nresearch and commercial applications in keyword spotting and spoken term search,\nlicensed under CC-BY 4.0. The dataset contains more than 340,000 keywords,\ntotaling 23.4 million 1-second spoken examples (over 6,000 hours). The dataset\nhas many use cases, ranging from voice-enabled consumer devices to call center\nautomation. This dataset is generated by applying forced alignment on crowd-sourced sentence-level\naudio to produce per-word timing estimates for extraction.\nAll alignments are included in the dataset.","url":"https://huggingface.co/datasets/MLCommons/ml_spoken_words","creator_name":"MLCommons","creator_url":"https://huggingface.co/MLCommons","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":null,"first_N":5,"first_N_keywords":["audio-classification","machine-generated","other","multilingual","extended|common_voice"],"keywords_longer_than_N":true},
	{"name":"openassistant-llama-style","keyword":"dutch","description":"\n\t\n\t\t\n\t\tChat Fine-tuning Dataset - Llama 2 Style\n\t\n\nThis dataset allows for fine-tuning chat models using [INST] AND [/INST] to wrap user messages.\nPreparation:\n\nThe dataset is cloned from TimDettmers, which itself is a subset of the Open Assistant dataset, which you can find here. This subset of the data only contains the highest-rated paths in the conversation tree, with a total of 9,846 samples.\nThe dataset was then filtered to:\n\n\nreplace instances of '### Human:' with '[INST]'\nreplace‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Trelis/openassistant-llama-style.","url":"https://huggingface.co/datasets/Trelis/openassistant-llama-style","creator_name":"Trelis","creator_url":"https://huggingface.co/Trelis","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["English","Spanish","Russian","German","Polish"],"keywords_longer_than_N":true},
	{"name":"mapa-eur-lex","keyword":"dutch","description":"\n\t\n\t\t\n\t\tDataset Card for Multilingual European Datasets for Sensitive Entity Detection in the Legal Domain\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset is a completed version of the MAPA EUR-LEX dataset, originally converted to Huggingface format by joelniklaus. See the dataset card for more information about MAPA.\n3 of the (Spanish) EUR-LEX WebAnno TSV files in the source MAPA repository are malformed, so they were omitted from the original conversion, causing under-representation of the‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/dglover1/mapa-eur-lex.","url":"https://huggingface.co/datasets/dglover1/mapa-eur-lex","creator_name":"D Glover","creator_url":"https://huggingface.co/dglover1","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["token-classification","named-entity-recognition","other","found","multilingual"],"keywords_longer_than_N":true},
	{"name":"DBRD","keyword":"dutch","description":"configs:\n\nconfig_name: default\ndata_files:\nsplit: train\npath: train/neg/, train/pos/\nsplit: test\npath: test/neg/, test/pos/\n\n\n\ndataset_info:\n  features:\n\nname: text\ndtype: string\nname: label\ndtype: integer (1 for positive, -1 for negative)\nsplits:\nname: train\nnum_examples: 20027\nname: test\nnum_examples: 2223\ndownload_size: 79.1MB\ndataset_size: 773,4MB\n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Card for \"DBRD: Dutch Book Reviews Dataset\"\n\t\n\nTranslation of the Dutch Book Review Dataset (DBRD), an extensive‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ebrigham/DBRD.","url":"https://huggingface.co/datasets/ebrigham/DBRD","creator_name":"Eduardo Ferreira Brigham","creator_url":"https://huggingface.co/ebrigham","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","Dutch","mit","10K - 100K","csv"],"keywords_longer_than_N":true},
	{"name":"lawinstruct","keyword":"dutch","description":"LawInstruct is an instruction tuning dataset of multilingual legal documents.","url":"https://huggingface.co/datasets/lawinstruct/lawinstruct","creator_name":"lawinstruct","creator_url":"https://huggingface.co/lawinstruct","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":null,"first_N":5,"first_N_keywords":["fill-mask","other","found","multilingual","original"],"keywords_longer_than_N":true},
	{"name":"orca_dpo_pairs_dutch","keyword":"dutch","description":"\n\t\n\t\t\n\t\tDataset Card for Orca DPO Pairs Dutch\n\t\n\n\n[!TIP]\nI recommend using the cleaned, deduplicated version. https://huggingface.co/datasets/BramVanroy/orca_dpo_pairs_dutch_cleaned\n\n\n\t\n\t\t\n\t\tCitation\n\t\n\nIf you use this dataset, GEITje 7B Ultra (SFT) or any of its derivatives or quantizations, place cite the following paper:\n@misc{vanroy2024geitje7bultraconversational,\n      title={GEITje 7B Ultra: A Conversational Model for Dutch}, \n      author={Bram Vanroy},\n      year={2024}‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/BramVanroy/orca_dpo_pairs_dutch.","url":"https://huggingface.co/datasets/BramVanroy/orca_dpo_pairs_dutch","creator_name":"Bram Vanroy","creator_url":"https://huggingface.co/BramVanroy","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","Dutch","apache-2.0","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"amazon_massive_intent","keyword":"dutch","description":"\n  MassiveIntentClassification\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nMASSIVE: A 1M-Example Multilingual Natural Language Understanding Dataset with 51 Typologically-Diverse Languages\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2c\n\n\nDomains\nSpoken\n\n\nReference\nhttps://arxiv.org/abs/2204.08582\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask = mteb.get_tasks([\"MassiveIntentClassification\"])\nevaluator =‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/amazon_massive_intent.","url":"https://huggingface.co/datasets/mteb/amazon_massive_intent","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","human-annotated","translated","Afrikaans","Amharic"],"keywords_longer_than_N":true},
	{"name":"belgian-journal","keyword":"dutch","description":"\n\t\n\t\t\n\t\tDataset Description\n\t\n\n\n\nDataset contains the metadata + the text of company bylaws publications of Belgian companies on the Belgian Journal (Moniteur Belge/Belgisch Staatstblad).\nThis data was collected by webscraping the Belgian Journal, for more info see: https://github.com/Guust-Franssens/belgian-journal.\n\nLanguage(s) (NLP): French, Dutch and a small subset German (official languages of Belgium.)\nLicense: Creative Commons Zero v1.0 Universal\n\n","url":"https://huggingface.co/datasets/guust-franssens/belgian-journal","creator_name":"Guust Franssens","creator_url":"https://huggingface.co/guust-franssens","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","fill-mask","language-modeling","masked-language-modeling","French"],"keywords_longer_than_N":true},
	{"name":"finepdfs","keyword":"dutch","description":"\n\nLiberating 3T of the finest tokens from PDFs\n\n\n\t\n\t\t\n\t\tWhat is this?\n\t\n\nAs we run out of web pages to process, the natural question has always been: what to do next? Only a few knew about a data source that everyone avoided for ages, due to its incredible extraction cost and complexity: PDFs.\nüìÑ FinePDFs is exactly that. It is the largest publicly available corpus sourced exclusively from PDFs, containing about 3 trillion tokens across 475 million documents in 1733 languages.\nCompared to HTML‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/HuggingFaceFW/finepdfs.","url":"https://huggingface.co/datasets/HuggingFaceFW/finepdfs","creator_name":"FineData","creator_url":"https://huggingface.co/HuggingFaceFW","license_name":"Open Data Commons Attribution License v1.0","license_url":"https://scancode-licensedb.aboutcode.org/odc-by-1.0.html","language":"en","first_N":5,"first_N_keywords":["text-generation","Arifama-Miniafia","Ankave","Abau","Amarasi"],"keywords_longer_than_N":true},
	{"name":"Question-Sparql","keyword":"dutch","description":"\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset contains 895,954 examples of natural language questions paired with their corresponding SPARQL queries. It spans 12 languages and targets 15 distinct knowledge graphs, with a significant portion focused on Wikidata and DBpedia.\nThe dataset was developed as a contribution for the Master Thesis: \"Impact of Continual Multilingual Pre-training on Cross-Lingual Transferability for Source Languages\". Its purpose is to facilitate research in text-to-SPARQL‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/julioc-p/Question-Sparql.","url":"https://huggingface.co/datasets/julioc-p/Question-Sparql","creator_name":"Julio Perez","creator_url":"https://huggingface.co/julioc-p","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-generation","English","German","Hebrew","Kannada"],"keywords_longer_than_N":true},
	{"name":"gigantic_dutch_dataset_new","keyword":"dutch","description":"\n\t\n\t\t\n\t\tNOT FOR COMMERCIAL USE\n\t\n\nexamples of content of the dataset:\nüìö Gratis flipbare glossy magazines publiceren ‚Äî Online Touch: Online publishing system; publiceer glossy magazine.\nHeb je aantrekkelijke glossy magazines die je snel op een aansprekende manier op je web site wilt plaatsen of via Facebook en LinkedIn wilt delen? Het maakt niet uit hoe fraai je gedrukte glossy magazines zijn, je zult op je prospects geen indruk maken als je een eenvoudige PDF-versie op je website of social‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/joepai/gigantic_dutch_dataset_new.","url":"https://huggingface.co/datasets/joepai/gigantic_dutch_dataset_new","creator_name":"joep van opdorp","creator_url":"https://huggingface.co/joepai","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["Dutch","mit","100B<n<1T","üá∫üá∏ Region: US"],"keywords_longer_than_N":false},
	{"name":"EuroGEC-7","keyword":"dutch","description":"\n\t\n\t\t\n\t\tEuroGEC-7: A Growing Multilingual Dataset for Grammatical Error Correction\n\t\n\nEuroGEC-7 is a large-scale, synthetic, multilingual grammatical error correction (GEC) dataset created using the Mistral API. It is specifically designed to simulate learner-style grammar mistakes across 7 major European languages ‚Äî with over 20,000 annotated pairs and counting.\nThis dataset is actively maintained and continuously expanding, both in scale and coverage. New entries are generated daily from a‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/NoeFlandre/EuroGEC-7.","url":"https://huggingface.co/datasets/NoeFlandre/EuroGEC-7","creator_name":"No√© Flandre","creator_url":"https://huggingface.co/NoeFlandre","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["English","French","Spanish","German","Italian"],"keywords_longer_than_N":true},
	{"name":"Granary","keyword":"dutch","description":"\n\t\n\t\t\n\t\tGranary: Speech Recognition and Translation Dataset in 25 European Languages\n\t\n\nGranary is a large-scale, open-source multilingual speech dataset covering 25 European languages for Automatic Speech Recognition (ASR) and Automatic Speech Translation (AST) tasks. \n\n\n\n\t\n\t\t\n\n\n\n\n\t\t\n\n\n\n\n\t\n\n\n\n\n\n\t\n\t\n\t\n\t\tOverview\n\t\n\nGranary addresses the scarcity of high-quality speech data for low-resource languages by consolidating multiple datasets under a unified framework:\nüó£Ô∏è ~1M hours of high-quality‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/nvidia/Granary.","url":"https://huggingface.co/datasets/nvidia/Granary","creator_name":"NVIDIA","creator_url":"https://huggingface.co/nvidia","license_name":"Creative Commons Attribution 3.0","license_url":"https://scancode-licensedb.aboutcode.org/cc-by-3.0.html","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","translation","Bulgarian","Czech","Danish"],"keywords_longer_than_N":true},
	{"name":"xP3x","keyword":"dutch","description":"\n\t\n\t\t\n\t\tDataset Card for xP3x\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\n\nxP3x (Crosslingual Public Pool of Prompts eXtended) is a collection of prompts & datasets across 277 languages & 16 NLP tasks. It contains all of xP3 + much more! It is used for training future contenders of mT0 & BLOOMZ at project Aya @Cohere Labs üß°\n\n\nCreation: The dataset can be recreated using instructions available here together with the file in this repository named xp3x_create.py. We provide this version to save processing‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/CohereLabs/xP3x.","url":"https://huggingface.co/datasets/CohereLabs/xP3x","creator_name":"Cohere Labs","creator_url":"https://huggingface.co/CohereLabs","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["other","expert-generated","crowdsourced","multilingual","Afrikaans"],"keywords_longer_than_N":true},
	{"name":"llm-metric-mrewardbench","keyword":"dutch","description":"rifqifarhansyah/llm-metric-mrewardbench dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/rifqifarhansyah/llm-metric-mrewardbench","creator_name":"Mohammad Rifqi Farhansyah","creator_url":"https://huggingface.co/rifqifarhansyah","license_name":"Open Data Commons Attribution License v1.0","license_url":"https://scancode-licensedb.aboutcode.org/odc-by-1.0.html","language":"en","first_N":5,"first_N_keywords":["Arabic","Chinese","Czech","Dutch","French"],"keywords_longer_than_N":true},
	{"name":"mls_sidon","keyword":"dutch","description":"\n\t\n\t\t\n\t\tMLS-Sidon\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is a cleansed version of Multilingual LibriSpeech (MLS) with Sidon speech restoration mode for Speech Synthesis and Spoken Language Modeling.  \nThe dataset is provided in WebDataset format for efficient large-scale training.  \n\nSource: Multilingual LibriSpeech\nLanguages: English, German, French, Spanish, Italian, Portuguese, Polish, Dutch  \nFormat: WebDataset (.tar shards)  \nLicense: CC-BY-4.0\n\n\n\n\t\n\t\n\t\n\t\tDataset Structure\n\t\n\nEach sample in‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/sarulab-speech/mls_sidon.","url":"https://huggingface.co/datasets/sarulab-speech/mls_sidon","creator_name":"SaruLab Speech group","creator_url":"https://huggingface.co/sarulab-speech","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":null,"first_N":5,"first_N_keywords":["text-to-speech","English","French","German","Spanish"],"keywords_longer_than_N":true},
	{"name":"bhojpuri","keyword":"dutch","description":"\n\t\n\t\t\n\t\n\t\n\t\tFLEURS\n\t\n\nFleurs is the speech version of the FLoRes machine translation benchmark. \nWe use 2009 n-way parallel sentences from the FLoRes dev and devtest publicly available sets, in 102 languages. \nTraining sets have around 10 hours of supervision. Speakers of the train sets are different than speakers from the dev/test sets. Multilingual fine-tuning is\nused and ‚Äùunit error rate‚Äù (characters, signs) of all languages is averaged. Languages and results are also grouped into seven‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ankur02/bhojpuri.","url":"https://huggingface.co/datasets/ankur02/bhojpuri","creator_name":"Ankur Verma","creator_url":"https://huggingface.co/ankur02","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","expert-generated","crowdsourced","machine-generated","crowdsourced"],"keywords_longer_than_N":true},
	{"name":"vox-communis-parallel-g2p","keyword":"dutch","description":"\n\t\n\t\t\n\t\tVoxCommunis Parallel G2P dataset\n\t\n\nThis dataset was derived from the VoxCommunis Corpus to provide pairs of utterances along with their\ncorresponding phonemes, side by side, as to ease the training of grapheme-to-phoneme (G2P) models.\nThe original VoxCommunis Corpus features force-aligned TextGrids with phone- and word-level segmentations derived from the Mozilla Common Voice Corpus.\nThe lexicons were developed using Epitran, the XPF Corpus, Charsiu, and some custom dictionaries.‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/fdemelo/vox-communis-parallel-g2p.","url":"https://huggingface.co/datasets/fdemelo/vox-communis-parallel-g2p","creator_name":"Fl√°vio Eler De Melo","creator_url":"https://huggingface.co/fdemelo","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["Abkhaz","Amharic","Bashkir","Belarusian","Bulgarian"],"keywords_longer_than_N":true},
	{"name":"multilingual_translation_gen_binarized","keyword":"dutch","description":"Youseff1987/multilingual_translation_gen_binarized dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/Youseff1987/multilingual_translation_gen_binarized","creator_name":"JOON HYOUNG JUN","creator_url":"https://huggingface.co/Youseff1987","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["translation","Korean","English","Chinese","Zulu"],"keywords_longer_than_N":true},
	{"name":"domain-translations","keyword":"dutch","description":"\n\t\n\t\t\n\t\tMultilingual Domain Name Translations Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset contains 155,004 domain names with their multilingual translations across 20 languages. Each domain has been segmented into constituent words and translated while preserving semantic meaning and commercial appeal. The dataset is particularly valuable for domain name research, multilingual NLP tasks, and understanding how brand names and concepts translate across languages.\n\n\t\n\t\t\n\t\tDataset‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/humbleworth/domain-translations.","url":"https://huggingface.co/datasets/humbleworth/domain-translations","creator_name":"HumbleWorth","creator_url":"https://huggingface.co/humbleworth","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["translation","text-generation","feature-extraction","multilingual","Arabic"],"keywords_longer_than_N":true},
	{"name":"aya_dataset_dutch_example","keyword":"dutch","description":"data-is-better-together/aya_dataset_dutch_example dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/data-is-better-together/aya_dataset_dutch_example","creator_name":"Data Is Better Together","creator_url":"https://huggingface.co/data-is-better-together","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","Dutch","apache-2.0","1K - 10K","parquet"],"keywords_longer_than_N":true},
	{"name":"beir-nl-cqadupstack","keyword":"dutch","description":"\n\t\n\t\t\n\t\tDataset Card for BEIR-NL Benchmark\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nBEIR-NL is a Dutch-translated version of the BEIR benchmark, a diverse and heterogeneous collection of datasets covering various domains from biomedical and financial texts to general web content. Our benchmark is integrated into the Massive Multilingual Text Embedding Benchmark (MMTEB).\nBEIR-NL contains the following tasks:\n\nFact-checking: FEVER, Climate-FEVER, SciFact\nQuestion-Answering: NQ, HotpotQA, FiQA-2018‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/clips/beir-nl-cqadupstack.","url":"https://huggingface.co/datasets/clips/beir-nl-cqadupstack","creator_name":"CLiPS","creator_url":"https://huggingface.co/clips","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","Dutch","apache-2.0","100K - 1M","json"],"keywords_longer_than_N":true},
	{"name":"Dutch-RVO-blogs","keyword":"dutch","description":"vGassen/Dutch-RVO-blogs dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/vGassen/Dutch-RVO-blogs","creator_name":"Ernst van Gassen","creator_url":"https://huggingface.co/vGassen","license_name":"Public Domain Dedication & License","license_url":"https://scancode-licensedb.aboutcode.org/pddl-1.0.html","language":"en","first_N":5,"first_N_keywords":["Dutch","pddl","< 1K","parquet","Text"],"keywords_longer_than_N":true},
	{"name":"dhanishtha-2.0-superthinker","keyword":"dutch","description":"\n\t\n\t\t\n\t\tüì¶ Dhanishtha-2.0-SUPERTHINKER-MLX\n\t\n\n A distilled corpus of 11.7K high-quality samples showcasing multi-phase reasoning and structured emotional cognition. Sourced directly from the internal training data of Dhanishtha-2.0 ‚Äî the world‚Äôs first Large Language Model (LLM) to implement Intermediate Thinking, featuring multiple <think> and <ser> blocks per response\n\n\t\n\t\t\n\t\n\t\n\t\tExample with MLX-LM-LoRA:\n\t\n\nmlx_lm_lora.train \\\n--model‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mlx-community/dhanishtha-2.0-superthinker.","url":"https://huggingface.co/datasets/mlx-community/dhanishtha-2.0-superthinker","creator_name":"MLX Community","creator_url":"https://huggingface.co/mlx-community","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","Afrikaans","Arabic","Bulgarian","Catalan"],"keywords_longer_than_N":true},
	{"name":"fineweb2hq-vs-c4","keyword":"dutch","description":"This dataset includes 5000 rows per language from each of two sources: the higher-quality epfml/FineWeb2-HQ\nand the lower-quality allenai/c4. The data is split 80/20 into training and test sets.\nLanguages were carefully chosen to ensure balanced representation across both splits:\nArabic, Chinese, Czech, Danish, Dutch, French, German, Greek, Hungarian, Indonesian, Italian, Japanese, Persian, Polish, Portuguese, Russian, Spanish, Swedish, Turkish, and Vietnamese.\n","url":"https://huggingface.co/datasets/agentlans/fineweb2hq-vs-c4","creator_name":"Alan Tseng","creator_url":"https://huggingface.co/agentlans","license_name":"Open Data Commons Attribution License v1.0","license_url":"https://scancode-licensedb.aboutcode.org/odc-by-1.0.html","language":"en","first_N":5,"first_N_keywords":["text-classification","Portuguese","Danish","Persian","German"],"keywords_longer_than_N":true},
	{"name":"gigantic_dutch_dataset","keyword":"dutch","description":"\n\t\n\t\t\n\t\tenglish: this is a dutch dataset for llm training and finetuning\n\t\n\nthe dataset size of the compressed files(compressed with gzip compression level -6) is 16.2 GB \n\n\t\n\t\t\n\t\tNOT FOR COMMERCIAL USE\n\t\n\nwarning: the convertet parquet dataset is not complete DO NOT USE IT\nfull version: https://huggingface.co/datasets/joepai/gigantic_dutch_dataset_new\n","url":"https://huggingface.co/datasets/joepai/gigantic_dutch_dataset","creator_name":"joep van opdorp","creator_url":"https://huggingface.co/joepai","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["Dutch","mit","10K - 100K","text","Text"],"keywords_longer_than_N":true},
	{"name":"mteb-nl-vabb-ret","keyword":"dutch","description":"This dataset is based on the VABB dataset, the Flemish Academic Bibliography for the Social Sciences and Humanities.\n\n\t\n\t\t\n\t\tCitation Information\n\t\n\nIf you find our paper, benchmark or models helpful, please consider cite as follows:\n@misc{banar2025mtebnle5nlembeddingbenchmark,\n      title={MTEB-NL and E5-NL: Embedding Benchmark and Models for Dutch}, \n      author={Nikolay Banar and Ehsan Lotfi and Jens Van Nooten and Cristina Arhiliuc and Marija Kliocaite and Walter Daelemans}‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/clips/mteb-nl-vabb-ret.","url":"https://huggingface.co/datasets/clips/mteb-nl-vabb-ret","creator_name":"CLiPS","creator_url":"https://huggingface.co/clips","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["Dutch","cc-by-4.0","10K - 100K","parquet","Tabular"],"keywords_longer_than_N":true},
	{"name":"omgevingswet_participatie_qa","keyword":"dutch","description":"\n\t\n\t\t\n\t\tOmgevingswet & Participatie Q&A\n\t\n\n1000 NL conversaties in ShareGPT-formaat met:\n\nid\nconversations: lijst van beurtwisselingen {from: \"human\"/\"gpt\", value: \"...\"}\n\nSplits: train (900), test (100).\n\n\t\n\t\t\n\t\tVoorbeeld\n\t\n\n{\n    \"id\": \"q0001\",\n    \"conversations\": [\n        { \"from\": \"human\", \"value\": \"Wat is ...?\" },\n        { \"from\": \"gpt\", \"value\": \"Antwoord ...\" }\n    ]\n}\n\n","url":"https://huggingface.co/datasets/mamersfo/omgevingswet_participatie_qa","creator_name":"Martin van Amersfoorth","creator_url":"https://huggingface.co/mamersfo","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["question-answering","expert-generated","monolingual","original","Dutch"],"keywords_longer_than_N":true},
	{"name":"llm-metric-mrewardbench","keyword":"dutch","description":"rubricreward/llm-metric-mrewardbench dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/rubricreward/llm-metric-mrewardbench","creator_name":"rubricreward","creator_url":"https://huggingface.co/rubricreward","license_name":"Open Data Commons Attribution License v1.0","license_url":"https://scancode-licensedb.aboutcode.org/odc-by-1.0.html","language":"en","first_N":5,"first_N_keywords":["Arabic","Chinese","Czech","Dutch","French"],"keywords_longer_than_N":true},
	{"name":"phonetic-piper-recording-studio-prompts","keyword":"dutch","description":"\n\t\n\t\t\n\t\tPhonetic Piper Studio Recordings Prompts\n\t\n\nThis dataset is a processed version of an utterance dataset made available for various languages as prompts for the Piper recording studio. Along with the original prompts, we include:\n\ncolumns ipa_espeak and ipa_epitran containing phonemized versions of the original sentences according to espeak-ng and Epitran phonemizers, respectively\ncolumns lang, espeak_lang_code, epitran_lang_code containing the language codes as reported by piper‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/fdemelo/phonetic-piper-recording-studio-prompts.","url":"https://huggingface.co/datasets/fdemelo/phonetic-piper-recording-studio-prompts","creator_name":"Fl√°vio Eler De Melo","creator_url":"https://huggingface.co/fdemelo","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["Afrikaans","Arabic","Bulgarian","Catalan","Czech"],"keywords_longer_than_N":true},
	{"name":"mteb-nl-sarcastic-headlines","keyword":"dutch","description":" This dataset contains news headlines from a satirical news website (Speld.nl) and a regular news website that are annotated with binary sarcasm labels (1 indicating sarcasm, 0 indicating non-sarcasm). All headlines from Speld.nl are annotated as sarcastic, whereas all headlines from nu.nl are not.\n\n\t\n\t\t\n\t\tCitation Information\n\t\n\nIf you find our paper, benchmark or models helpful, please consider cite as follows:\n@misc{banar2025mtebnle5nlembeddingbenchmark,\n      title={MTEB-NL and E5-NL:‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/clips/mteb-nl-sarcastic-headlines.","url":"https://huggingface.co/datasets/clips/mteb-nl-sarcastic-headlines","creator_name":"CLiPS","creator_url":"https://huggingface.co/clips","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["Dutch","cc0-1.0","10K - 100K","json","Tabular"],"keywords_longer_than_N":true},
	{"name":"V1Q","keyword":"dutch","description":"from datasets import load_dataset\nds = load_dataset(\"b3x0m/Chinese-H-Novels\")\nimport sagemaker\nimport boto3\nfrom sagemaker.huggingface import HuggingFaceModel\ntry:\n    role = sagemaker.get_execution_role()\nexcept ValueError:\n    iam = boto3.client('iam')\n    role = iam.get_role(RoleName='sagemaker_execution_role')['Role']['Arn']\n\n\t\n\t\t\n\t\tHub Model configuration. https://huggingface.co/models\n\t\n\nhub = {\n    'HF_MODEL_ID':'deepseek-ai/Janus-Pro-7B',\n    'HF_TASK':'any-to-any'\n}\n\n\t\n\t\t\n\t\tcreate‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/YuRiVeRTi/V1Q.","url":"https://huggingface.co/datasets/YuRiVeRTi/V1Q","creator_name":"YuRiVeRTical","creator_url":"https://huggingface.co/YuRiVeRTi","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","table-question-answering","question-answering","zero-shot-classification"],"keywords_longer_than_N":true},
	{"name":"LLM_Multilingual_dataset","keyword":"dutch","description":"\n\t\n\t\t\n\t\tDataset Card for Dataset Name\n\t\n\n\n\nThis dataset card aims to be a base template for new datasets. It has been generated using this raw template.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\n\n\n\n\n\nCurated by: [More Information Needed]\nFunded by [optional]: [More Information Needed]\nShared by [optional]: [More Information Needed]\nLanguage(s) (NLP): [More Information Needed]\nLicense: [More Information Needed]\n\n\n\t\n\t\t\n\t\tDataset Sources [optional]\n\t\n\n\n\n\nRepository: [More‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/lewishamilton21/LLM_Multilingual_dataset.","url":"https://huggingface.co/datasets/lewishamilton21/LLM_Multilingual_dataset","creator_name":"Kesavprabu","creator_url":"https://huggingface.co/lewishamilton21","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["table-question-answering","Japanese","Finnish","Indonesian","Russian"],"keywords_longer_than_N":true},
	{"name":"Paradoxical_AI_Reflections","keyword":"dutch","description":"\n\t\n\t\t\n\t\tDataset Card for Dataset Name\n\t\n\n\n\nThis dataset card aims to be a base template for new datasets. It has been generated using this raw template.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\n\n\n\n\n\nCurated by: [More Information Needed]\nFunded by [optional]: [More Information Needed]\nShared by [optional]: [More Information Needed]\nLanguage(s) (NLP): [More Information Needed]\nLicense: [More Information Needed]\n\n\n\t\n\t\t\n\t\tDataset Sources [optional]\n\t\n\n\n\n\nRepository: [More‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/BrinzShoota/Paradoxical_AI_Reflections.","url":"https://huggingface.co/datasets/BrinzShoota/Paradoxical_AI_Reflections","creator_name":"Lucas Coroi","creator_url":"https://huggingface.co/BrinzShoota","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","English","Dutch","cc-by-4.0","1K<n<10K"],"keywords_longer_than_N":true},
	{"name":"OpenHumanreasoning-multilingual-2.2k","keyword":"dutch","description":"Based off of Pinkstackorg/humanreasoning-testing-en, it is a human-generated dataset where a real person had to create most of the reasoning and the final output. If there are any mistakes please let us know.\nWe offer this dataset at an apache-2.0 license to make it useful for everybody.\nnote: translations are not human generated.\n","url":"https://huggingface.co/datasets/Pinkstack/OpenHumanreasoning-multilingual-2.2k","creator_name":"Pinkstack","creator_url":"https://huggingface.co/Pinkstack","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","Arabic","Chinese","Czech","Danish"],"keywords_longer_than_N":true},
	{"name":"wmt24pp","keyword":"dutch","description":"\n\t\n\t\t\n\t\tWMT24++\n\t\n\nThis repository contains the human translation and post-edit data for the 55 en->xx language pairs released in\nthe publication\nWMT24++: Expanding the Language Coverage of WMT24 to 55 Languages & Dialects.\nIf you are interested in the MT/LLM system outputs and automatic metric scores, please see MTME.\nIf you are interested in the images of the source URLs for each document, please see here.\n\n\t\n\t\t\n\t\n\t\n\t\tSchema\n\t\n\nEach language pair is stored in its own jsonl file.\nEach row is‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/google/wmt24pp.","url":"https://huggingface.co/datasets/google/wmt24pp","creator_name":"Google","creator_url":"https://huggingface.co/google","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["translation","Arabic","Bulgarian","Bengali","Catalan"],"keywords_longer_than_N":true},
	{"name":"x-fact","keyword":"dutch","description":"\n\t\n\t\t\n\t\tDataset Card for \"x-fact\"\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nX-FACT is a multilingual dataset for fact-checking with real world claims. The dataset contains short statments in 25 languages with top five evidence documents retrieved by performing google search with claim statements. The dataset contains two additional evaluation splits (in addition to a traditional test set): ood and zeroshot. ood measures out-of-domain generalization where while the language‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/utahnlp/x-fact.","url":"https://huggingface.co/datasets/utahnlp/x-fact","creator_name":"NLP at University of Utah","creator_url":"https://huggingface.co/utahnlp","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","Arabic","Bengali","Spanish","Persian"],"keywords_longer_than_N":true},
	{"name":"OGC_Military","keyword":"dutch","description":"\n\t\n\t\t\n\t\tOGC - Organized, Grouped, Cleaned\n\t\n\n\n\t\n\t\t\n\t\tMilitary Vision DSE\n\t\n\n\nIntended for image/text to vector (DSE)\n\n\n\t\n\t\t\n\t\tDataset Composition\n\t\n\nMade with https://github.com/RacineAIOS/OGC_pdf-to-parquet\nThis dataset was created by scraping PDF documents from online sources and generating relevant synthetic queries.\nWe used Google's Gemini 2.0 Flash Lite model in our custom pipeline to produce the queries, allowing us to create a diverse set of questions based on the document content.‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/racineai/OGC_Military.","url":"https://huggingface.co/datasets/racineai/OGC_Military","creator_name":"racine.ai","creator_url":"https://huggingface.co/racineai","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["visual-document-retrieval","text-retrieval","English","French","Arabic"],"keywords_longer_than_N":true},
	{"name":"qe4pe","keyword":"dutch","description":"\n\t\n\t\t\n\t\tQuality Estimation for Post-Editing (QE4PE)\n\t\n\nFor more details on QE4PE, see our paper and our Github repository\nGabriele Sarti ‚Ä¢ Vil√©m Zouhar ‚Ä¢ Grzegorz Chrupa≈Ça ‚Ä¢ Ana Guerberof Arenas ‚Ä¢ Malvina Nissim ‚Ä¢ Arianna Bisazza\n\n    \n\n\n\nWord-level quality estimation (QE) detects erroneous spans in machine translations, which can direct and facilitate human post-editing. While the accuracy of word-level QE systems has been assessed extensively, their usability and downstream influence on the‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/gsarti/qe4pe.","url":"https://huggingface.co/datasets/gsarti/qe4pe","creator_name":"Gabriele Sarti","creator_url":"https://huggingface.co/gsarti","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["translation","machine-generated","machine-generated","expert-generated","Unbabel/TowerEval-Data-v0.1"],"keywords_longer_than_N":true},
	{"name":"librivox-tracks","keyword":"dutch","description":"A dataset of all audio files uploaded to LibriVox before 26th September 2023.\nForked from https://huggingface.co/datasets/pykeio/librivox-tracks\nChanges:\n\nUsed archive.org metadata API to annotate rows with \"duration\" column\n\n","url":"https://huggingface.co/datasets/xacer/librivox-tracks","creator_name":"xacer","creator_url":"https://huggingface.co/xacer","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-to-speech","automatic-speech-recognition","feature-extraction","Achinese","Afrikaans"],"keywords_longer_than_N":true},
	{"name":"TRECCOVID-NL","keyword":"dutch","description":"\n  TRECCOVID-NL\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nTRECCOVID is an ad-hoc search challenge based on the COVID-19 dataset containing scientific articles related to the COVID-19 pandemic. TRECCOVID-NL is a Dutch translation. \n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2t\n\n\nDomains\nMedical, Academic, Written\n\n\nReference\nhttps://colab.research.google.com/drive/1R99rjeAGt8S9IfAIRR3wS052sNu3Bjo-#scrollTo=4HduGW6xHnrZ\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/TRECCOVID-NL.","url":"https://huggingface.co/datasets/mteb/TRECCOVID-NL","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","derived","translated","mteb/trec-covid","Dutch"],"keywords_longer_than_N":true},
	{"name":"multilingual-reward-bench","keyword":"dutch","description":"\n\t\n\t\t\n\t\tMultilingual Reward Bench (v1.0)\n\t\n\nReward models (RMs) have driven the development of state-of-the-art LLMs today, with unprecedented impact across the globe. However, their performance in multilingual settings still remains understudied. \nIn order to probe reward model behavior on multilingual data, we present M-RewardBench, a benchmark for 23 typologically diverse languages. \nM-RewardBench contains prompt-chosen-rejected preference triples obtained by curating and translating chat‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/CohereLabsCommunity/multilingual-reward-bench.","url":"https://huggingface.co/datasets/CohereLabsCommunity/multilingual-reward-bench","creator_name":"Cohere Labs Community","creator_url":"https://huggingface.co/CohereLabsCommunity","license_name":"Open Data Commons Attribution License v1.0","license_url":"https://scancode-licensedb.aboutcode.org/odc-by-1.0.html","language":"en","first_N":5,"first_N_keywords":["Arabic","Chinese","Czech","Dutch","French"],"keywords_longer_than_N":true},
	{"name":"orca_dpo_pairs_dutch_cleaned","keyword":"dutch","description":"\n\t\n\t\t\n\t\tDataset Card for Orca DPO Pairs Dutch Cleaned\n\t\n\n\n\t\n\t\t\n\t\tCitation\n\t\n\nIf you use this dataset, GEITje 7B Ultra (SFT) or any of its derivatives or quantizations, place cite the following paper:\n@misc{vanroy2024geitje7bultraconversational,\n      title={GEITje 7B Ultra: A Conversational Model for Dutch}, \n      author={Bram Vanroy},\n      year={2024},\n      eprint={2412.04092},\n      archivePrefix={arXiv},\n      primaryClass={cs.CL},\n      url={https://arxiv.org/abs/2412.04092}, \n}‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/BramVanroy/orca_dpo_pairs_dutch_cleaned.","url":"https://huggingface.co/datasets/BramVanroy/orca_dpo_pairs_dutch_cleaned","creator_name":"Bram Vanroy","creator_url":"https://huggingface.co/BramVanroy","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","Dutch","apache-2.0","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"include-lite-44","keyword":"dutch","description":"\n\t\n\t\t\n\t\tINCLUDE-lite (44 languages)\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\n\n\nPaper: http://arxiv.org/abs/2411.19799\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nINCLUDE is a comprehensive knowledge- and reasoning-centric benchmark across 44 languages that evaluates multilingual LLMs for performance in the actual language environments where they would be deployed. \nIt contains 11,095 4-option multiple-choice-questions (MCQ) extracted from academic and professional exams, covering 57 topics, including regional‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/CohereLabs/include-lite-44.","url":"https://huggingface.co/datasets/CohereLabs/include-lite-44","creator_name":"Cohere Labs","creator_url":"https://huggingface.co/CohereLabs","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["multiple-choice","Albanian","Arabic","Armenian","Azerbaijani"],"keywords_longer_than_N":true},
	{"name":"VoxCommunis","keyword":"dutch","description":"\n\t\n\t\t\n\t\tVoxCommunis Corpus\n\t\n\nThe VoxCommunis Corpus is a phonetic corpus derived from the Mozilla Common Voice Corpus. Corresponding audio files and corpus metadata can be downloaded from Mozilla Common Voice, or from one of several Hugging Face repositories for the differing versions. \nWithin each folder, the filenames share similar structure and contain critical information for effectively using the file. More detail regarding the specifics of the filename for each file type is provided‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/pacscilab/VoxCommunis.","url":"https://huggingface.co/datasets/pacscilab/VoxCommunis","creator_name":"PaCSciLab @ UZH","creator_url":"https://huggingface.co/pacscilab","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["Abkhaz","Amharic","Bashkir","Belarusian","Bulgarian"],"keywords_longer_than_N":true},
	{"name":"common_voice_21_0","keyword":"dutch","description":"\n\t\n\t\t\n\t\tDataset Card for Common Voice Corpus 21.0\n\t\n\n\n\nThis dataset is an unofficial version of the Mozilla Common Voice Corpus 21. It was downloaded and converted from the project's website https://commonvoice.mozilla.org/.\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nAbkhaz, Albanian, Amharic, Arabic, Armenian, Assamese, Asturian, Azerbaijani, Basaa, Bashkir, Basque, Belarusian, Bengali, Breton, Bulgarian, Cantonese, Catalan, Central Kurdish, Chinese (China), Chinese (Hong Kong), Chinese (Taiwan), Chuvash, Czech‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/fsicoli/common_voice_21_0.","url":"https://huggingface.co/datasets/fsicoli/common_voice_21_0","creator_name":"Fabio Sicoli","creator_url":"https://huggingface.co/fsicoli","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":null,"first_N":5,"first_N_keywords":["automatic-speech-recognition","Abkhaz","Afrikaans","Amharic","Arabic"],"keywords_longer_than_N":true},
	{"name":"HelpSteer3","keyword":"dutch","description":"\n\t\n\t\t\n\t\tHelpSteer3\n\t\n\nHelpSteer3 is an open-source dataset (CC-BY-4.0) that supports aligning models to become more helpful in responding to user prompts.\nHelpSteer3-Preference can be used to train Llama 3.3 Nemotron Super 49B v1 (for Generative RMs) and Llama 3.3 70B Instruct Models (for Bradley-Terry RMs) to produce Reward Models that score as high as 85.5% on RM-Bench and 78.6% on JudgeBench, which substantially surpass existing Reward Models on these benchmarks.\nHelpSteer3-Feedback and‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/nvidia/HelpSteer3.","url":"https://huggingface.co/datasets/nvidia/HelpSteer3","creator_name":"NVIDIA","creator_url":"https://huggingface.co/nvidia","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["English","Chinese","Korean","French","Spanish"],"keywords_longer_than_N":true},
	{"name":"Multilingual-Benchmark","keyword":"dutch","description":"These are the GSM8K and ARC dataset translated by Google Translate. \nBibTex\n@misc{lu2024languagecountslearnunlearn,\n      title={Every Language Counts: Learn and Unlearn in Multilingual LLMs}, \n      author={Taiming Lu and Philipp Koehn},\n      year={2024},\n      eprint={2406.13748},\n      archivePrefix={arXiv},\n      primaryClass={cs.CL},\n      url={https://arxiv.org/abs/2406.13748}, \n}\n\n","url":"https://huggingface.co/datasets/TaiMingLu/Multilingual-Benchmark","creator_name":"TaiMing","creator_url":"https://huggingface.co/TaiMingLu","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["zero-shot-classification","question-answering","translation","English","German"],"keywords_longer_than_N":true},
	{"name":"test","keyword":"dutch","description":"Ehsanl/test dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/Ehsanl/test","creator_name":"Ehsan","creator_url":"https://huggingface.co/Ehsanl","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","text-classification","document-retrieval","topic-classification","expert-generated"],"keywords_longer_than_N":true},
	{"name":"dutch-central-exam-mcq-multimodal-subset","keyword":"dutch","description":"Multimodal Multiple Choice Questions of the Dutch Central Exam 1999-2024\n\nWhat?\n\nThis dataset contains only multimodal multiple choice questions from the Dutch Central Exam (High School level). From Wikipedia:\nThe Eindexamen (Dutch pronunciation: [Àà…õiÃØnt…õksam…ôn]) or centraal examen (CE) is the matriculation exam in the Netherlands, which takes place in a student's final year of high school education (voortgezet onderwijs; \"continued education\"). The exam is regulated by the Dutch Secondary‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/jjzha/dutch-central-exam-mcq-multimodal-subset.","url":"https://huggingface.co/datasets/jjzha/dutch-central-exam-mcq-multimodal-subset","creator_name":"Mike Zhang","creator_url":"https://huggingface.co/jjzha","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["question-answering","Dutch","cc-by-4.0","< 1K","imagefolder"],"keywords_longer_than_N":true},
	{"name":"mmlux","keyword":"dutch","description":"\n\t\n\t\t\n\t\tCitation Information\n\t\n\nIf you find benchmarks useful in your research, please consider citing the test and also the MMLU dataset it draws from:\n    @misc{thellmann2024crosslingual,\n    title={Towards Cross-Lingual LLM Evaluation for European Languages},\n    author={Klaudia Thellmann and Bernhard Stadler and Michael Fromm and Jasper Schulze Buschhoff and Alex Jude and Fabio Barth and Johannes Leveling and Nicolas Flores-Herr and Joachim K√∂hler and Ren√© J√§kel and Mehdi Ali}‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Eurolingua/mmlux.","url":"https://huggingface.co/datasets/Eurolingua/mmlux","creator_name":"EuroLingua-GPT","creator_url":"https://huggingface.co/Eurolingua","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":null,"first_N":5,"first_N_keywords":["multiple-choice","expert-generated","multilingual","cais/mmlu","German"],"keywords_longer_than_N":true},
	{"name":"montok","keyword":"dutch","description":"\n\t\n\t\t\n\t\tMonTok: A Suite of Monolingual Tokenizers\n\t\n\nThis is a set of monolingual tokenizers for 98 languages. For each language, there are Unigram, BPE, and SuperBPE tokenizers, ranging in vocabulary size from around 6k to over 200k.\n\n\t\n\t\t\n\t\tTraining Details\n\t\n\n\n\t\n\t\t\n\t\tTraining Data\n\t\n\nAll tokenizers are trained on samples of the data used to the train the Goldfish language models. \nThe tokenizers were either trained on scaled or unscaled data. This refers to whether the models are trained on‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/catherinearnett/montok.","url":"https://huggingface.co/datasets/catherinearnett/montok","creator_name":"Catherine Arnett","creator_url":"https://huggingface.co/catherinearnett","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["Afrikaans","Tosk Albanian","Amharic","Standard Arabic","Assamese"],"keywords_longer_than_N":true},
	{"name":"librivox-tracks","keyword":"dutch","description":"A dataset of all audio files uploaded to LibriVox before 26th September 2023.\n","url":"https://huggingface.co/datasets/pykeio/librivox-tracks","creator_name":"pyke.io","creator_url":"https://huggingface.co/pykeio","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-to-speech","automatic-speech-recognition","Achinese","Afrikaans","Ancient Greek (to 1453)"],"keywords_longer_than_N":true},
	{"name":"yodas-granary","keyword":"dutch","description":"\n\t\n\t\t\n\t\tDataset Card for YODAS-Granary\n\t\n\n\nRepository: NeMo-speech-data-processor: Granary\nPaper: Granary: Speech Recognition and Translation Dataset in 25 European Languages\nShared by: ESPnet\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Description\n\t\n\nYODAS-Granary is a curated subset of the larger nvidia/Granary dataset, focusing on high-quality pseudo-labeled speech data for Automatic Speech Recognition (ASR) and Automatic Speech Translation (AST) across 23 European languages.\n\n\t\n\t\n\t\n\t\tOverview‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/espnet/yodas-granary.","url":"https://huggingface.co/datasets/espnet/yodas-granary","creator_name":"ESPnet","creator_url":"https://huggingface.co/espnet","license_name":"Creative Commons Attribution 3.0","license_url":"https://scancode-licensedb.aboutcode.org/cc-by-3.0.html","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","translation","Bulgarian","Czech","Danish"],"keywords_longer_than_N":true},
	{"name":"fiNERweb","keyword":"dutch","description":"fiNERweb is a multilingual named entity recognition dataset containing annotated text in multiple languages.\nEach example contains the original text, tokenized text, BIO tags, and character/token spans for entities.","url":"https://huggingface.co/datasets/whoisjones/fiNERweb","creator_name":"Jonas Golde","creator_url":"https://huggingface.co/whoisjones","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":null,"first_N":5,"first_N_keywords":["token-classification","named-entity-recognition","Vietnamese","Tamil","Oriya"],"keywords_longer_than_N":true},
	{"name":"multilingual-text","keyword":"dutch","description":"\n\t\n\t\t\n\t\tMultilingual Text Dataset\n\t\n\nThis dataset contains a curated selection of rows from multiple input datasets, where each row includes a text chunk of approximately 2000 tokens (as measured by Llama 3.1 tokenizer) verified to be written in the correct language. Only rows with properly classified language chunks are retained, ensuring high-quality multilingual data for analysis or model training.\n\n\t\n\t\t\n\t\tPreprocessing Steps\n\t\n\n\nNormalized whitespace, punctuation, Unicode characters, and‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/agentlans/multilingual-text.","url":"https://huggingface.co/datasets/agentlans/multilingual-text","creator_name":"Alan Tseng","creator_url":"https://huggingface.co/agentlans","license_name":"Open Data Commons Attribution License v1.0","license_url":"https://scancode-licensedb.aboutcode.org/odc-by-1.0.html","language":"en","first_N":5,"first_N_keywords":["text-generation","text-classification","Amharic","Arabic","Bengali"],"keywords_longer_than_N":true},
	{"name":"Chatgpt","keyword":"dutch","description":"\n\t\n\t\t\n\t\tOpenAssistant Conversations Dataset (OASST1)\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nIn an effort to democratize research on large-scale alignment, we release OpenAssistant \nConversations (OASST1), a human-generated, human-annotated assistant-style conversation \ncorpus consisting of 161,443 messages in 35 different languages, annotated with 461,292 \nquality ratings, resulting in over 10,000 fully annotated conversation trees. The corpus \nis a product of a worldwide crowd-sourcing effort‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/RajChat/Chatgpt.","url":"https://huggingface.co/datasets/RajChat/Chatgpt","creator_name":"Rajdeep Chatterjee ","creator_url":"https://huggingface.co/RajChat","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["English","Spanish","Russian","German","Polish"],"keywords_longer_than_N":true},
	{"name":"common_voice_22_0","keyword":"dutch","description":"\n\t\n\t\t\n\t\tDataset Card for Common Voice Corpus 22.0\n\t\n\n\n\nThis dataset is an unofficial version of the Mozilla Common Voice Corpus 22. It was downloaded and converted from the project's website https://commonvoice.mozilla.org/.\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nAbkhaz, Albanian, Amharic, Arabic, Armenian, Assamese, Asturian, Azerbaijani, Basaa, Bashkir, Basque, Belarusian, Bengali, Breton, Bulgarian, Cantonese, Catalan, Central Kurdish, Chinese (China), Chinese (Hong Kong), Chinese (Taiwan), Chuvash, Czech‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/fsicoli/common_voice_22_0.","url":"https://huggingface.co/datasets/fsicoli/common_voice_22_0","creator_name":"Fabio Sicoli","creator_url":"https://huggingface.co/fsicoli","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":null,"first_N":5,"first_N_keywords":["automatic-speech-recognition","Abkhaz","Afrikaans","Amharic","Arabic"],"keywords_longer_than_N":true},
	{"name":"bordirlines","keyword":"dutch","description":"\n\t\n\t\t\n\t\tBordIRLines Dataset\n\t\n\nThis is the dataset associated with the paper \"BordIRlines: A Dataset for Evaluating Cross-lingual Retrieval-Augmented Generation\" (link).\nCode: https://github.com/manestay/bordIRlines\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThe BordIRLines Dataset is an information retrieval (IR) dataset constructed from various language corpora. It contains queries and corresponding ranked docs along with their relevance scores. The dataset includes multiple languages, including English‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/borderlines/bordirlines.","url":"https://huggingface.co/datasets/borderlines/bordirlines","creator_name":"cross-lingual LLMs and RAG","creator_url":"https://huggingface.co/borderlines","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":null,"first_N":5,"first_N_keywords":["question-answering","human","machine-generated","found","multilingual"],"keywords_longer_than_N":true},
	{"name":"text_ratings","keyword":"dutch","description":"Todo - Write dataset card\n","url":"https://huggingface.co/datasets/lightblue/text_ratings","creator_name":"Lightblue KK.","creator_url":"https://huggingface.co/lightblue","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["Amharic","Arabic","Bulgarian","Bengali","Czech"],"keywords_longer_than_N":true},
	{"name":"css10-ljspeech","keyword":"dutch","description":"\n\t\n\t\t\n\t\tCSS10-LJSpeech\n\t\n\nCSS10-LJSpeech „ÅØ„ÄÅPark et al. „ÅåÂÖ¨Èñã„Åó„Åü CSS10 „Éá„Éº„Çø„Çª„ÉÉ„Éà„Çí„ÄÅLJSpeech‰∫íÊèõ„Éï„Ç©„Éº„Éû„ÉÉ„Éà„Å´Â§âÊèõ„Åó„Åü10Ë®ÄË™û„ÅÆÈü≥Â£∞ÂêàÊàêÁî®„Éá„Éº„Çø„Çª„ÉÉ„Éà„Åß„Åô„ÄÇÂêÑË®ÄË™û„ÅÆÊñáÂ≠¶‰ΩúÂìÅ„ÇíÈü≥Â£∞Âåñ„Åó„ÅüÈ´òÂìÅË≥™„Å™Èü≥Â£∞„Éá„Éº„Çø„ÇíÊèê‰æõ„Åó„ÄÅLJSpeech„Éï„Ç©„Éº„Éû„ÉÉ„ÉàÔºàid|text & wavs/*.wavÔºâ„Å´Áµ±‰∏Ä„Åï„Çå„Å¶„ÅÑ„Åæ„Åô„ÄÇ\n\n\t\n\t\t\n\t\t„Éá„Éº„ÇøÊ¶ÇË¶Å\n\t\n\n\n\t\n\t\t\nÈ†ÖÁõÆ\nÂÄ§\n\n\n\t\t\nË©±ËÄÖÊï∞\n10 (Ë®ÄË™ûÂà•)\n\n\nÁ∑èÈü≥Â£∞Êï∞\n64,196\n\n\nÂêàË®àÊôÇÈñì\nÁ¥Ñ 140 ÊôÇÈñì\n\n\n„Çµ„É≥„Éó„É™„É≥„Ç∞„É¨„Éº„Éà\n22,050 Hz\n\n\nÈü≥Â£∞„Éï„Ç©„Éº„Éû„ÉÉ„Éà\nIEEEÊµÆÂãïÂ∞èÊï∞ÁÇπ (32bit)\n\n\n„ÉÜ„Ç≠„Çπ„ÉàË®ÄË™û\n10Ë®ÄË™û\n\n\n„Éï„Ç©„Éº„Éû„ÉÉ„Éà\n`id\n\n\n\t\n\n\n\t\n\t\t\n\t\tË®ÄË™ûÂà•Áµ±Ë®à\n\t\n\n\n\t\n\t\t\nË®ÄË™û\nË®ÄË™û„Ç≥„Éº„Éâ\nÈü≥Â£∞Êï∞\nÂêàË®àÊôÇÈñì\n\n\n\t\t\n„Éâ„Ç§„ÉÑË™û\nde\n7,428\n16.14ÊôÇÈñì\n\n\n„ÇÆ„É™„Ç∑„É£Ë™û\nel\n1,844\n4.14ÊôÇÈñì\n\n\n„Çπ„Éö„Ç§„É≥Ë™û\nes\n11,016\n19.15ÊôÇÈñì\n\n\n„Éï„Ç£„É≥„É©„É≥„ÉâË™û\nfi\n4,842\n10.53ÊôÇÈñì‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ayousanz/css10-ljspeech.","url":"https://huggingface.co/datasets/ayousanz/css10-ljspeech","creator_name":"yousan","creator_url":"https://huggingface.co/ayousanz","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["German","Greek","Spanish","Finnish","French"],"keywords_longer_than_N":true},
	{"name":"css10-ljspeech","keyword":"dutch","description":"\n\t\n\t\t\n\t\tCSS10-LJSpeech\n\t\n\nCSS10-LJSpeech „ÅØ„ÄÅPark et al. „ÅåÂÖ¨Èñã„Åó„Åü CSS10 „Éá„Éº„Çø„Çª„ÉÉ„Éà„Çí„ÄÅLJSpeech‰∫íÊèõ„Éï„Ç©„Éº„Éû„ÉÉ„Éà„Å´Â§âÊèõ„Åó„Åü10Ë®ÄË™û„ÅÆÈü≥Â£∞ÂêàÊàêÁî®„Éá„Éº„Çø„Çª„ÉÉ„Éà„Åß„Åô„ÄÇÂêÑË®ÄË™û„ÅÆÊñáÂ≠¶‰ΩúÂìÅ„ÇíÈü≥Â£∞Âåñ„Åó„ÅüÈ´òÂìÅË≥™„Å™Èü≥Â£∞„Éá„Éº„Çø„ÇíÊèê‰æõ„Åó„ÄÅLJSpeech„Éï„Ç©„Éº„Éû„ÉÉ„ÉàÔºàid|text & wavs/*.wavÔºâ„Å´Áµ±‰∏Ä„Åï„Çå„Å¶„ÅÑ„Åæ„Åô„ÄÇ\n\n\t\n\t\t\n\t\t„Éá„Éº„ÇøÊ¶ÇË¶Å\n\t\n\n\n\t\n\t\t\nÈ†ÖÁõÆ\nÂÄ§\n\n\n\t\t\nË©±ËÄÖÊï∞\n10 (Ë®ÄË™ûÂà•)\n\n\nÁ∑èÈü≥Â£∞Êï∞\n64,196\n\n\nÂêàË®àÊôÇÈñì\nÁ¥Ñ 140 ÊôÇÈñì\n\n\n„Çµ„É≥„Éó„É™„É≥„Ç∞„É¨„Éº„Éà\n22,050 Hz\n\n\nÈü≥Â£∞„Éï„Ç©„Éº„Éû„ÉÉ„Éà\nIEEEÊµÆÂãïÂ∞èÊï∞ÁÇπ (32bit)\n\n\n„ÉÜ„Ç≠„Çπ„ÉàË®ÄË™û\n10Ë®ÄË™û\n\n\n„Éï„Ç©„Éº„Éû„ÉÉ„Éà\n`id\n\n\n\t\n\n\n\t\n\t\t\n\t\tË®ÄË™ûÂà•Áµ±Ë®à\n\t\n\n\n\t\n\t\t\nË®ÄË™û\nË®ÄË™û„Ç≥„Éº„Éâ\nÈü≥Â£∞Êï∞\nÂêàË®àÊôÇÈñì\n\n\n\t\t\n„Éâ„Ç§„ÉÑË™û\nde\n7,428\n16.14ÊôÇÈñì\n\n\n„ÇÆ„É™„Ç∑„É£Ë™û\nel\n1,844\n4.14ÊôÇÈñì\n\n\n„Çπ„Éö„Ç§„É≥Ë™û\nes\n11,016\n19.15ÊôÇÈñì\n\n\n„Éï„Ç£„É≥„É©„É≥„ÉâË™û\nfi\n4,842\n10.53ÊôÇÈñì‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ayousanz/css10-ljspeech.","url":"https://huggingface.co/datasets/ayousanz/css10-ljspeech","creator_name":"yousan","creator_url":"https://huggingface.co/ayousanz","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["German","Greek","Spanish","Finnish","French"],"keywords_longer_than_N":true},
	{"name":"europa","keyword":"dutch","description":"\n\t\n\t\t\n\t\tDataset Card for EUROPA\n\t\n\nThis dataset card aims to be a base template for new datasets. It has been generated using this raw template.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nEUROPA is a dataset designed for training and evaluating multilingual keyphrase generation models in the legal domain. It consists of legal judgments from the Court of Justice of the European Union (EU) and includes instances in all 24 official EU languages.\nKey Features:\nMultilingual: Covers‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/NCube/europa.","url":"https://huggingface.co/datasets/NCube/europa","creator_name":"Neural Network Nomads (We are GLOSS)","creator_url":"https://huggingface.co/NCube","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["French","German","English","Italian","Dutch"],"keywords_longer_than_N":true},
	{"name":"xm3600","keyword":"dutch","description":"\n\t\n\t\t\n\t\n\t\n\t\tXM3600 - Crossmodal-3600\n\t\n\n\n\t\n\t\t\n\t\n\t\n\t\tThis is a copy from https://google.github.io/crossmodal-3600/\n\t\n\nIf you use this dataset, please cite the original authors:\n@inproceedings{ThapliyalCrossmodal2022,\n  author = {Ashish Thapliyal and Jordi Pont-Tuset and Xi Chen and Radu Soricut},\n  title = {{Crossmodal-3600: A Massively Multilingual Multimodal Evaluation Dataset}},\n  booktitle = {EMNLP},\n  year = {2022}\n}\n\nIt also includes the image features as PIL Image and has a uniform and‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/floschne/xm3600.","url":"https://huggingface.co/datasets/floschne/xm3600","creator_name":"Flo Schneider","creator_url":"https://huggingface.co/floschne","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["image-to-text","Arabic","Bengali","Czech","Danish"],"keywords_longer_than_N":true},
	{"name":"xm3600_1k","keyword":"dutch","description":"\n\t\n\t\t\n\t\n\t\n\t\tXM3600 - Crossmodal-3600 - 1K Split\n\t\n\n\n\t\n\t\t\n\t\n\t\n\t\tThis is a copy from https://google.github.io/crossmodal-3600/\n\t\n\nIf you use this dataset, please cite the original authors:\n@inproceedings{ThapliyalCrossmodal2022,\n  author = {Ashish Thapliyal and Jordi Pont-Tuset and Xi Chen and Radu Soricut},\n  title = {{Crossmodal-3600: A Massively Multilingual Multimodal Evaluation Dataset}},\n  booktitle = {EMNLP},\n  year = {2022}\n}\n\n\n\t\n\t\t\n\t\n\t\n\t\tThis is a 1K split of XM3600!\n\t\n\nFor this, we‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/floschne/xm3600_1k.","url":"https://huggingface.co/datasets/floschne/xm3600_1k","creator_name":"Flo Schneider","creator_url":"https://huggingface.co/floschne","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["image-to-text","Arabic","Bengali","Czech","Danish"],"keywords_longer_than_N":true},
	{"name":"mmarco-hard-negatives-reranker-score","keyword":"dutch","description":"\nhotchpotch/mmarco-hard-negatives-reranker-score\n\nThis repository contains data from mMARCO scored using the reranker BAAI/bge-reranker-v2-m3.\n\n\t\n\t\t\n\t\tLanguages Covered\n\t\n\ntarget_languages = [\n    \"english\",\n    \"chinese\", \n    \"french\",\n    \"german\",\n    \"indonesian\",\n    \"italian\",\n    \"portuguese\",\n    \"russian\",\n    \"spanish\",\n    \"arabic\",\n    \"dutch\",\n    \"hindi\",\n    \"japanese\",\n    \"vietnamese\"\n]\n\n\n\t\n\t\t\n\t\tHard Negative Data\n\t\n\nThe hard negative data is derived from‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/hotchpotch/mmarco-hard-negatives-reranker-score.","url":"https://huggingface.co/datasets/hotchpotch/mmarco-hard-negatives-reranker-score","creator_name":"Yuichi Tateno","creator_url":"https://huggingface.co/hotchpotch","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["English","Chinese","French","German","Indonesian"],"keywords_longer_than_N":true},
	{"name":"aya_collection_language_split","keyword":"dutch","description":"\nThis is a re-upload of the aya_collection, and only differs in the structure of upload. While the original aya_collection is structured by folders split according to dataset name, this dataset is split by language. We recommend you use this version of the dataset if you are only interested in downloading all of the Aya collection for a single or smaller set of languages.\n\n\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThe Aya Collection is a massive multilingual collection consisting of 513 million instances of‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/CohereLabs/aya_collection_language_split.","url":"https://huggingface.co/datasets/CohereLabs/aya_collection_language_split","creator_name":"Cohere Labs","creator_url":"https://huggingface.co/CohereLabs","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["Achinese","Afrikaans","Amharic","Arabic","Azerbaijani"],"keywords_longer_than_N":true},
	{"name":"fineweb-edu-translated","keyword":"dutch","description":"\n\t\n\t\t\n\t\tHelsinki-NLP/fineweb-edu-translated\n\t\n\nAutomatically translated documents from fineweb-edu. Translations are based on OPUS-MT and HPLT-MT models.\n","url":"https://huggingface.co/datasets/Helsinki-NLP/fineweb-edu-translated","creator_name":"Language Technology Research Group at the University of Helsinki","creator_url":"https://huggingface.co/Helsinki-NLP","license_name":"Open Data Commons Attribution License v1.0","license_url":"https://scancode-licensedb.aboutcode.org/odc-by-1.0.html","language":"en","first_N":5,"first_N_keywords":["text-generation","Bulgarian","Catalan","Czech","Danish"],"keywords_longer_than_N":true},
	{"name":"imatrix-calibration","keyword":"dutch","description":"\n\t\n\t\t\n\t\tImportance Matrix Calibration Datasets\n\t\n\nThis repository contains calibration datasets used to generate importance matrices (imatrix), which in turn help minimise errors introduced during quantization.\n\n\t\n\t\t\n\t\tMath calibration datasets\n\t\n\nThis dataset consists of over 10M tokens of cleaned math prompts and is available in six sizes, ranging from huge (~ 430,000 lines equivalent to approx. 10M tokens), to micro (~ 13,700 lines and 1.7M tokens avg).\nOriginal data sourced from‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/eaddario/imatrix-calibration.","url":"https://huggingface.co/datasets/eaddario/imatrix-calibration","creator_name":"Ed Addario","creator_url":"https://huggingface.co/eaddario","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-generation","Arabic","Chinese","German","English"],"keywords_longer_than_N":true},
	{"name":"europa-random-split","keyword":"dutch","description":"\n\t\n\t\t\n\t\tDataset Card for EUROPA\n\t\n\nThis dataset card aims to be a base template for new datasets. It has been generated using this raw template.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nEUROPA is a dataset designed for training and evaluating multilingual keyphrase generation models in the legal domain. It consists of legal judgments from the Court of Justice of the European Union (EU) and includes instances in all 24 official EU languages.\nKey Features:\nMultilingual: Covers‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/NCube/europa-random-split.","url":"https://huggingface.co/datasets/NCube/europa-random-split","creator_name":"Neural Network Nomads (We are GLOSS)","creator_url":"https://huggingface.co/NCube","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["French","German","English","Italian","Dutch"],"keywords_longer_than_N":true},
	{"name":"epfml-FineWeb2-HQ-sample","keyword":"dutch","description":"\n\t\n\t\t\n\t\tepfml/FineWeb2-HQ\n\t\n\nA curated subset of the epfml/FineWeb2-HQ dataset featuring high-quality multilingual text.\n\n\t\n\t\t\n\t\tDetails\n\t\n\n\nFirst 25‚Äâ000 rows per config (language and script pair)\nDuplicates removed\nTexts truncated to 512 LLaMA 3.1 tokens\nScores transformed with log10\nRows shuffled and 20% of the rows split into the test set (stratified by config)\n\n\n\t\n\t\t\n\t\tExample\n\t\n\n{\n  \"text\": \"ÁàµÂ£´Â§ßÂ∏àTim Garland Ê∑±Âú≥‰∏ìÂú∫ - [jazz]\\nTim Garland Lighthouse‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/agentlans/epfml-FineWeb2-HQ-sample.","url":"https://huggingface.co/datasets/agentlans/epfml-FineWeb2-HQ-sample","creator_name":"Alan Tseng","creator_url":"https://huggingface.co/agentlans","license_name":"Open Data Commons Attribution License v1.0","license_url":"https://scancode-licensedb.aboutcode.org/odc-by-1.0.html","language":"en","first_N":5,"first_N_keywords":["text-generation","Russian","Chinese","German","Japanese"],"keywords_longer_than_N":true},
	{"name":"Tatoeba-Translations","keyword":"dutch","description":"\n\t\n\t\t\n\t\tDataset Details\n\t\n\nThis is the latest version of Tatoeba translations as of December 2024.\nThe sentences are downloaded from the Tatoeba collection website.\nThe dataset is processed through mapping sentences.tar.bz2 using sentences_base.tar.bz2 to find source (sentence_src) and target (sentence_tgt) sentences.\nWhile lang_src and lang_tgt columns follow the mapping provided by Tatoeba, the lang_pair column merely lists the two languages in the translation pair.\n\n\t\n\t\t\n\t\n\t\n\t\tStatistics‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ymoslem/Tatoeba-Translations.","url":"https://huggingface.co/datasets/ymoslem/Tatoeba-Translations","creator_name":"Yasmin Moslem","creator_url":"https://huggingface.co/ymoslem","license_name":"Creative Commons Attribution 2.0","license_url":"https://scancode-licensedb.aboutcode.org/cc-by-2.0.html","language":"en","first_N":5,"first_N_keywords":["translation","multilingual","Abkhaz","Afrikaans","Amharic"],"keywords_longer_than_N":true},
	{"name":"dutch-notarial-ner","keyword":"dutch","description":"\n\t\n\t\t\n\t\tDutch Historical Notarial NER Dataset\n\t\n\nThis dataset is a relabeled version of the \"AI-trainingset voor Named Entity Recognition (NER)\" created during the crowdsourcing project \"Tag de Tekst\" on VeleHanden.nl in 2020. It has been adapted for use in Named Entity Recognition (NER) tasks, with relabeling conducted using Google Deepmind's Gemini 2.0 Flash  model.\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Overview\n\t\n\n\nOriginal Source: Transcriptions of Dutch notarial texts from the 17th to 19th centuries.‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/TimKoornstra/dutch-notarial-ner.","url":"https://huggingface.co/datasets/TimKoornstra/dutch-notarial-ner","creator_name":"Tim Koornstra","creator_url":"https://huggingface.co/TimKoornstra","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["token-classification","Dutch","cc-by-4.0","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"dutch-notarial-ner","keyword":"dutch","description":"\n\t\n\t\t\n\t\tDutch Historical Notarial NER Dataset\n\t\n\nThis dataset is a relabeled version of the \"AI-trainingset voor Named Entity Recognition (NER)\" created during the crowdsourcing project \"Tag de Tekst\" on VeleHanden.nl in 2020. It has been adapted for use in Named Entity Recognition (NER) tasks, with relabeling conducted using Google Deepmind's Gemini 2.0 Flash  model.\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Overview\n\t\n\n\nOriginal Source: Transcriptions of Dutch notarial texts from the 17th to 19th centuries.‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/TimKoornstra/dutch-notarial-ner.","url":"https://huggingface.co/datasets/TimKoornstra/dutch-notarial-ner","creator_name":"Tim Koornstra","creator_url":"https://huggingface.co/TimKoornstra","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["token-classification","Dutch","cc-by-4.0","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"biblenlp-corpus","keyword":"dutch","description":"\n\t\n\t\t\n\t\tDataset Card for BibleNLP Corpus\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nPartial and complete Bible translations in 833 languages, aligned by verse.\n\n\t\n\t\t\n\t\tLanguages\n\t\n\naai, aak, aau, aaz, abt, abx, aby, acf, acr, acu, adz, aer, aey, agd, agg, agm, agn, agr, agt, agu, aia, aii, aka, ake, alp, alq, als, aly, ame, amf, amk, amm, amn, amo, amp, amr, amu, amx, anh, anv, aoi, aoj, aom, aon, apb, ape, apn, apr, apu, apw, apz, arb, are, arl, arn, arp, asm, aso, ata, atb, atd, atg, att, auc, aui, auy‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/bible-nlp/biblenlp-corpus.","url":"https://huggingface.co/datasets/bible-nlp/biblenlp-corpus","creator_name":"The Partnership for Applied Biblical NLP","creator_url":"https://huggingface.co/bible-nlp","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":null,"first_N":5,"first_N_keywords":["translation","no-annotation","expert-generated","translation","multilingual"],"keywords_longer_than_N":true},
	{"name":"biblenlp-corpus","keyword":"dutch","description":"\n\t\n\t\t\n\t\tDataset Card for BibleNLP Corpus\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nPartial and complete Bible translations in 833 languages, aligned by verse.\n\n\t\n\t\t\n\t\tLanguages\n\t\n\naai, aak, aau, aaz, abt, abx, aby, acf, acr, acu, adz, aer, aey, agd, agg, agm, agn, agr, agt, agu, aia, aii, aka, ake, alp, alq, als, aly, ame, amf, amk, amm, amn, amo, amp, amr, amu, amx, anh, anv, aoi, aoj, aom, aon, apb, ape, apn, apr, apu, apw, apz, arb, are, arl, arn, arp, asm, aso, ata, atb, atd, atg, att, auc, aui, auy‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/bible-nlp/biblenlp-corpus.","url":"https://huggingface.co/datasets/bible-nlp/biblenlp-corpus","creator_name":"The Partnership for Applied Biblical NLP","creator_url":"https://huggingface.co/bible-nlp","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":null,"first_N":5,"first_N_keywords":["translation","no-annotation","expert-generated","translation","multilingual"],"keywords_longer_than_N":true},
	{"name":"HashtagPrediction","keyword":"dutch","description":"\n\t\n\t\t\n\t\tHashtag Prediction Dataset from paper TwHIN-BERT: A Socially-Enriched Pre-trained Language Model for Multilingual Tweet Representations\n\t\n\n  \nThis repo contains the Hashtag prediction dataset from our paper TwHIN-BERT: A Socially-Enriched Pre-trained Language Model for Multilingual Tweet Representations. \n[arXiv][HuggingFace Models]\n[Github repo]\nThis work is licensed under a Creative Commons Attribution 4.0 International License.\n\n\t\n\t\t\n\t\n\t\n\t\tDownload\n\t\n\nUse the‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Twitter/HashtagPrediction.","url":"https://huggingface.co/datasets/Twitter/HashtagPrediction","creator_name":"Twitter","creator_url":"https://huggingface.co/Twitter","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["Slovenian","Urdu","Sindhi","Polish","Vietnamese"],"keywords_longer_than_N":true},
	{"name":"ultra_feedback_dutch","keyword":"dutch","description":"\n\t\n\t\t\n\t\tDataset Card for Ultra Feedback Dutch\n\t\n\n\n[!WARNING]\nIt is recommended to use the cleaned version for your experiments.\n\n\n\t\n\t\t\n\t\tCitation\n\t\n\nIf you use this dataset, GEITje 7B Ultra (SFT) or any of its derivatives or quantizations, place cite the following paper:\n@misc{vanroy2024geitje7bultraconversational,\n      title={GEITje 7B Ultra: A Conversational Model for Dutch}, \n      author={Bram Vanroy},\n      year={2024},\n      eprint={2412.04092},\n      archivePrefix={arXiv}‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/BramVanroy/ultra_feedback_dutch.","url":"https://huggingface.co/datasets/BramVanroy/ultra_feedback_dutch","creator_name":"Bram Vanroy","creator_url":"https://huggingface.co/BramVanroy","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","Dutch","apache-2.0","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"bernice-pretrain-data","keyword":"dutch","description":"Tweet IDs for the 2.5 billion multilingual tweets used to train Bernice, a Twitter encoder.\nThe tweets are from the public 1% Twitter API stream from January 2016 to December 2021. \nTwitter-provided language metadata is provided with the tweet ID. The data contains 66 unique languages, \nas identified by ISO 639 language codes, including `und` for undefined languages.\nTweets need to be re-gathered via the Twitter API.","url":"https://huggingface.co/datasets/jhu-clsp/bernice-pretrain-data","creator_name":"Center for Language and Speech Processing @ JHU","creator_url":"https://huggingface.co/jhu-clsp","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":null,"first_N":5,"first_N_keywords":["other","no-annotation","found","multilingual","original"],"keywords_longer_than_N":true},
	{"name":"home-assistant-nl","keyword":"dutch","description":"BramNH/home-assistant-nl dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/BramNH/home-assistant-nl","creator_name":"Bram Nijenhuis","creator_url":"https://huggingface.co/BramNH","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["Dutch","mit","10K - 100K","json","Text"],"keywords_longer_than_N":true},
	{"name":"mteb-nl-sick-sts-pr","keyword":"dutch","description":"\n  SICK-NL-STS\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nSICK-NL (read: signal), a dataset targeting Natural Language Inference in Dutch. SICK-NL is obtained by translating the SICK dataset of (Marelli et al., 2014) from English into Dutch.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2t\n\nDomains\nNews, Social, Web, Spoken, Written\n\n\nReference\nhttps://aclanthology.org/2021.eacl-main.126/\n\n\n\t\n\nSource datasets:\n\nclips/mteb-nl-sick\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/clips/mteb-nl-sick-sts-pr.","url":"https://huggingface.co/datasets/clips/mteb-nl-sick-sts-pr","creator_name":"CLiPS","creator_url":"https://huggingface.co/clips","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["sentence-similarity","human-annotated","translated","clips/mteb-nl-sick","Dutch"],"keywords_longer_than_N":true},
	{"name":"ChatML-aya_dataset","keyword":"dutch","description":"CohereForAI/aya_dataset in ChatML format, ready to use in HuggingFace TRL's SFT Trainer.\nPython code used for conversion:\nfrom datasets import load_dataset\nfrom transformers import AutoTokenizer\n\ntokenizer = AutoTokenizer.from_pretrained(\"Felladrin/Llama-160M-Chat-v1\")\n\ndataset = load_dataset(\"CohereForAI/aya_dataset\", split=\"train\")\n\ndef format(columns):\n    messages = [\n        {\n            \"role\": \"user\",\n            \"content\": columns[\"inputs\"].strip(),\n        },\n        {‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Felladrin/ChatML-aya_dataset.","url":"https://huggingface.co/datasets/Felladrin/ChatML-aya_dataset","creator_name":"Victor Nogueira","creator_url":"https://huggingface.co/Felladrin","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["question-answering","text-generation","crowdsourced","expert-generated","crowdsourced"],"keywords_longer_than_N":true},
	{"name":"lextreme","keyword":"dutch","description":"The LEXTREME Benchmark is a collection of multilingual datasets for evaluating model performance \nacross a diverse set of legal NLU tasks.","url":"https://huggingface.co/datasets/joelniklaus/lextreme","creator_name":"Joel Niklaus","creator_url":"https://huggingface.co/joelniklaus","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","multi-class-classification","multi-label-classification","topic-classification"],"keywords_longer_than_N":true},
	{"name":"fleurs-hs-vits","keyword":"dutch","description":"\n\t\n\t\t\n\t\tFLEURS-HS VITS\n\t\n\nAn extension of the FLEURS dataset for synthetic speech detection using text-to-speech, featured in the paper Synthetic speech detection with Wav2Vec 2.0 in various language settings.\nThis dataset is 1 of 3 used in the paper, the others being:\n\nFLEURS-HS\nthe default train, dev and test sets\nseparated due to different licensing\n\n\nARCTIC-HS\nextension of the CMU_ARCTIC and L2-ARCTIC sets in a similar manner\n\n\n\n\n\t\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/realnetworks-kontxt/fleurs-hs-vits.","url":"https://huggingface.co/datasets/realnetworks-kontxt/fleurs-hs-vits","creator_name":"KONTXT by RealNetworks","creator_url":"https://huggingface.co/realnetworks-kontxt","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":null,"first_N":5,"first_N_keywords":["audio-classification","German","English","Spanish","French"],"keywords_longer_than_N":true},
	{"name":"xtr-wiki_qa","keyword":"dutch","description":"\n\t\n\t\t\n\t\tXtr-WikiQA\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nXtr-WikiQA is an Answer Sentence Selection (AS2) dataset in 9 non-English languages, proposed in our paper accepted at ACL 2023 (Findings): Cross-Lingual Knowledge Distillation for Answer Sentence Selection in Low-Resource Languages.\nThis dataset is based on an English AS2 dataset, WikiQA (Original, Hugging Face).\nFor translations, we used Amazon Translate.\n\n\t\n\t\t\n\t\n\t\n\t\tLanguages\n\t\n\n\nArabic (ar)\nSpanish (es)\nFrench (fr)\nGerman (de)\nHindi (hi)‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/AmazonScience/xtr-wiki_qa.","url":"https://huggingface.co/datasets/AmazonScience/xtr-wiki_qa","creator_name":"Amazon Science","creator_url":"https://huggingface.co/AmazonScience","license_name":"Community Data License Agreement Permissive 2.0","license_url":"https://scancode-licensedb.aboutcode.org/cdla-permissive-2.0.html","language":"en","first_N":5,"first_N_keywords":["question-answering","text-retrieval","open-domain-qa","machine-generated","found"],"keywords_longer_than_N":true},
	{"name":"multilingual_librispeech","keyword":"dutch","description":"\n\t\n\t\t\n\t\tDataset Card for MultiLingual LibriSpeech\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis is a streamable version of the Multilingual LibriSpeech (MLS) dataset. \nThe data archives were restructured from the original ones from OpenSLR to make it easier to stream.\nMLS dataset is a large multilingual corpus suitable for speech research. The dataset is derived from read audiobooks from LibriVox and consists of \n8 languages - English, German, Dutch, Spanish, French, Italian, Portuguese, Polish. It‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/facebook/multilingual_librispeech.","url":"https://huggingface.co/datasets/facebook/multilingual_librispeech","creator_name":"AI at Meta","creator_url":"https://huggingface.co/facebook","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","text-to-audio","expert-generated","crowdsourced"],"keywords_longer_than_N":true},
	{"name":"mfaq","keyword":"dutch","description":"We present the first multilingual FAQ dataset publicly available. We collected around 6M FAQ pairs from the web, in 21 different languages.","url":"https://huggingface.co/datasets/clips/mfaq","creator_name":"CLiPS","creator_url":"https://huggingface.co/clips","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["question-answering","multiple-choice-qa","no-annotation","other","multilingual"],"keywords_longer_than_N":true},
	{"name":"blbooks-parquet","keyword":"dutch","description":"\n\t\n\t\t\n\t\tDataset Card for British Library Books\n\t\n\nThis dataset is the same as https://huggingface.co/datasets/TheBritishLibrary/blbooks, however, this version is stored as parquet to avoid needing to run a datasets script. This also makes loading this dataset much quicker. \n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset consists of books digitised by the British Library in partnership with Microsoft. The dataset includes ~25 million pages of out of copyright texts. The majority of the texts were‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/biglam/blbooks-parquet.","url":"https://huggingface.co/datasets/biglam/blbooks-parquet","creator_name":"BigLAM: BigScience Libraries, Archives and Museums","creator_url":"https://huggingface.co/biglam","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","fill-mask","other","language-modeling","masked-language-modeling"],"keywords_longer_than_N":true},
	{"name":"Open_Assistant_Conversation_Chains","keyword":"dutch","description":"\n\t\n\t\t\n\t\tDataset Card for Dataset Name\n\t\n\n\n\t\n\t\t\n\t\tDataset description\n\t\n\n\n\nThis dataset is a reformatting of OpenAssistant Conversations (OASST1), which is\n\na human-generated, human-annotated assistant-style conversation corpus consisting of 161,443 messages in 35 different languages, annotated with 461,292 quality ratings, resulting in over 10,000 fully annotated conversation trees. The corpus is a product of a worldwide crowd-sourcing effort involving over 13,500 volunteers.\n\nIt was modified‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/m-ric/Open_Assistant_Conversation_Chains.","url":"https://huggingface.co/datasets/m-ric/Open_Assistant_Conversation_Chains","creator_name":"Aymeric Roucher","creator_url":"https://huggingface.co/m-ric","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","English","Spanish","Russian","German"],"keywords_longer_than_N":true},
	{"name":"cnn_dailymail_dutch","keyword":"dutch","description":"CNN/DailyMail non-anonymized summarization dataset, translated to Dutch with ccmatrix.\nThere are two features:\n  - article: text of news article, used as the document to be summarized\n  - highlights: joined text of highlights with <s> and </s> around each\n    highlight, which is the target summary","url":"https://huggingface.co/datasets/yhavinga/cnn_dailymail_dutch","creator_name":"Yeb Havinga","creator_url":"https://huggingface.co/yhavinga","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":null,"first_N":5,"first_N_keywords":["summarization","news-articles-summarization","no-annotation","found","monolingual"],"keywords_longer_than_N":true},
	{"name":"legal-mc4","keyword":"dutch","description":"Legal-MC4: A Corpus Covering the Legal Part of MC4 for European Languages","url":"https://huggingface.co/datasets/joelniklaus/legal-mc4","creator_name":"Joel Niklaus","creator_url":"https://huggingface.co/joelniklaus","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["fill-mask","other","found","multilingual","original"],"keywords_longer_than_N":true},
	{"name":"ggml-vicuna-v0-quantized","keyword":"dutch","description":"These are quantized ggml binary files for vicuna 7B and 13B models. The version of vicuna for these models are v0.\nThese files can be used in conjunction with minigpt4 ggml models 7B and 13B in minigpt4.cpp\nRecommended are the Q5_K and Q6_K implementations. If there are any issues, use Q4_1 or Q4_0.\n\n\n\t\n\t\t\n\t\n\t\n\t\tVicuna Model Card\n\t\n\n\n\t\n\t\t\n\t\n\t\n\t\tModel details\n\t\n\nModel type:\nVicuna is an open-source chatbot trained by fine-tuning LLaMA on user-shared conversations collected from ShareGPT.\nIt is‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/maknee/ggml-vicuna-v0-quantized.","url":"https://huggingface.co/datasets/maknee/ggml-vicuna-v0-quantized","creator_name":"maknee","creator_url":"https://huggingface.co/maknee","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["English","Bulgarian","Catalan","Czech","Danish"],"keywords_longer_than_N":true},
	{"name":"ParlaMint3","keyword":"dutch","description":"ParlaMint 3.0 is a multilingual set of 26 comparable corpora containing parliamentary debates mostly starting in 2015 and extending to mid-2022. \nThe corpora have extensive metadata, including aspects of the parliament; the speakers (name, gender, MP status, party affiliation, party coalition/opposition); \nare structured into time-stamped terms, sessions and meetings; and with speeches being marked by the speaker and their role (e.g. chair, regular speaker). \nThe speeches also contain marked-up transcriber comments, such as gaps in the transcription, interruptions, applause, etc. \nNote that some corpora have further information, e.g. the year of birth of the speakers, links to their Wikipedia articles, their membership in various committees, etc. \nThe corpora are also marked to the subcorpus they belong to (\"reference\", until 2020-01-30, \"covid\", from 2020-01-31, and \"war\", from 2022-02-24). \nThe corpora are encoded according to the Parla-CLARIN TEI recommendation (https://clarin-eric.github.io/parla-clarin/), but have been encoded against the compatible, \nbut much stricter ParlaMint encoding guidelines (https://clarin-eric.github.io/ParlaMint/) and schemas (included in this distribution). \nThis entry contains the ParlaMint TEI-encoded corpora with the derived plain text versions of the corpora along with TSV metadata of the speeches. \nAlso included is the 3.0 release of the data and scripts available at the GitHub repository of the ParlaMint project.","url":"https://huggingface.co/datasets/cjvt/ParlaMint3","creator_name":"Center za jezikovne vire in tehnologije Univerze v Ljubljani","creator_url":"https://huggingface.co/cjvt","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":null,"first_N":5,"first_N_keywords":["other","multilingual","Slovenian","German","Bosnian"],"keywords_longer_than_N":true},
	{"name":"europa_eac_tm","keyword":"dutch","description":"\n\t\n\t\t\n\t\tDataset Card for Europa Education and Culture Translation Memory (EAC-TM)\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset is a corpus of manually produced translations from english to up to 25 languages, released in 2012 by the European Union's Directorate General for Education and Culture (EAC).\nTo load a language pair that is not part of the config, just specify the language code as language pair. For example, if you want to translate Czech to Greek:\ndataset = load_dataset(\"europa_eac_tm\"‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/community-datasets/europa_eac_tm.","url":"https://huggingface.co/datasets/community-datasets/europa_eac_tm","creator_name":"Community Datasets","creator_url":"https://huggingface.co/community-datasets","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["translation","expert-generated","expert-generated","translation","original"],"keywords_longer_than_N":true},
	{"name":"multilingual_librispeech","keyword":"dutch","description":"Multilingual LibriSpeech (MLS) dataset is a large multilingual corpus suitable for speech research. The dataset is derived from read audiobooks from LibriVox and consists of 8 languages - English, German, Dutch, Spanish, French, Italian, Portuguese, Polish.","url":"https://huggingface.co/datasets/legacy-datasets/multilingual_librispeech","creator_name":"Legacy Datasets","creator_url":"https://huggingface.co/legacy-datasets","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":null,"first_N":5,"first_N_keywords":["automatic-speech-recognition","audio-classification","speaker-identification","expert-generated","crowdsourced"],"keywords_longer_than_N":true},
	{"name":"eur-lex-sum","keyword":"dutch","description":"The EUR-Lex-Sum dataset is a multilingual resource intended for text summarization in the legal domain.\nIt is based on human-written summaries of legal acts issued by the European Union.\nIt distinguishes itself by introducing a smaller set of high-quality human-written samples,\neach of which have much longer references (and summaries!) than comparable datasets.\nAdditionally, the underlying legal acts provide a challenging domain-specific application to legal texts,\nwhich are so far underrepresented in non-English languages.\nFor each legal act, the sample can be available in up to 24 languages\n(the officially recognized languages in the European Union);\nthe validation and test samples consist entirely of samples available in all languages,\nand are aligned across all languages at the paragraph level.","url":"https://huggingface.co/datasets/dennlinger/eur-lex-sum","creator_name":"Dennis Aumiller","creator_url":"https://huggingface.co/dennlinger","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":null,"first_N":5,"first_N_keywords":["translation","summarization","found","expert-generated","found"],"keywords_longer_than_N":true},
	{"name":"ik-nlp-22_transqe","keyword":"dutch","description":"The e-SNLI dataset extends the Stanford Natural Language Inference Dataset to\ninclude human-annotated natural language explanations of the entailment\nrelations. This version includes an automatic translation to Dutch and two quality estimation annotations\nfor each translated field.","url":"https://huggingface.co/datasets/GroNLP/ik-nlp-22_transqe","creator_name":"GroNLP","creator_url":"https://huggingface.co/GroNLP","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","natural-language-inference","expert-generated","expert-generated","machine-generated"],"keywords_longer_than_N":true},
	{"name":"EU_Wikipedias","keyword":"dutch","description":"Wikipedia dataset containing cleaned articles of all languages.\nThe datasets are built from the Wikipedia dump\n(https://dumps.wikimedia.org/) with one split per language. Each example\ncontains the content of one full Wikipedia article with cleaning to strip\nmarkdown and unwanted sections (references, etc.).","url":"https://huggingface.co/datasets/joelniklaus/EU_Wikipedias","creator_name":"Joel Niklaus","creator_url":"https://huggingface.co/joelniklaus","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["fill-mask","other","found","multilingual","original"],"keywords_longer_than_N":true},
	{"name":"nllb-200-10M-sample","keyword":"dutch","description":"\n\t\n\t\t\n\t\tDataset Card for \"nllb-200-10M-sample\"\n\t\n\nThis is a sample of nearly 10M sentence pairs from the NLLB-200 \nmined dataset allenai/nllb, \nscored with the model facebook/blaser-2.0-qe \ndescribed in the SeamlessM4T paper.\nThe sample is not random; instead, we just took the top n sentence pairs from each translation direction.\nThe number n was computed with the goal of upsamping the directions that contain underrepresented languages.\nNevertheless, the 187 languoids (language and script‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/slone/nllb-200-10M-sample.","url":"https://huggingface.co/datasets/slone/nllb-200-10M-sample","creator_name":"SLONE","creator_url":"https://huggingface.co/slone","license_name":"Open Data Commons Attribution License v1.0","license_url":"https://scancode-licensedb.aboutcode.org/odc-by-1.0.html","language":"en","first_N":5,"first_N_keywords":["translation","Akan","Amharic","Arabic","Awadhi"],"keywords_longer_than_N":true},
	{"name":"JinaVDREuropeanaNlLegalRetrieval","keyword":"dutch","description":"\n  JinaVDREuropeanaNlLegalRetrieval\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nRetrieve Dutch historical legal documents based on LLM generated queries.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2i\n\n\nDomains\nLegal\n\n\nReference\nhttps://huggingface.co/datasets/jinaai/europeana-nl-legal_beir\n\n\n\t\n\nSource datasets:\n\njinaai/europeana-nl-legal_beir\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask =‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/JinaVDREuropeanaNlLegalRetrieval.","url":"https://huggingface.co/datasets/mteb/JinaVDREuropeanaNlLegalRetrieval","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["visual-document-retrieval","image-to-text","text-to-image","LM-generated","monolingual"],"keywords_longer_than_N":true},
	{"name":"bible_para","keyword":"dutch","description":"This is a multilingual parallel corpus created from translations of the Bible compiled by Christos Christodoulopoulos and Mark Steedman.\n\n102 languages, 5,148 bitexts\ntotal number of files: 107\ntotal number of tokens: 56.43M\ntotal number of sentence fragments: 2.84M","url":"https://huggingface.co/datasets/Helsinki-NLP/bible_para","creator_name":"Language Technology Research Group at the University of Helsinki","creator_url":"https://huggingface.co/Helsinki-NLP","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":null,"first_N":5,"first_N_keywords":["translation","found","found","multilingual","original"],"keywords_longer_than_N":true},
	{"name":"CulturaY","keyword":"dutch","description":"\n\t\n\t\t\n\t\tCulturaY: A Large Cleaned Multilingual Dataset of 75 Languages\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nFrom the team that brought you CulturaX, we present CulturaY, another substantial multilingual dataset of 15TB (uncompressed)/3TB (zstd-compressed) that applies the same dataset cleaning methodology to the HPLT v1.1 dataset. \nPlease note that HPLT v1.2 has also been released and is an alternative verison with different cleaning methodolgies. \nThis data was used in part to train our SOTA‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Viet-Mistral/CulturaY.","url":"https://huggingface.co/datasets/Viet-Mistral/CulturaY","creator_name":"Vietnamese Mistral","creator_url":"https://huggingface.co/Viet-Mistral","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","fill-mask","language-modeling","masked-language-modeling","no-annotation"],"keywords_longer_than_N":true},
	{"name":"Fact-Completion","keyword":"dutch","description":"\n\t\n\t\t\n\t\tDataset Card\n\t\n\n\nHomepage: https://bit.ly/ischool-berkeley-capstone\nRepository: https://github.com/daniel-furman/Capstone\nPoint of Contact: daniel_furman@berkeley.edu\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis is the dataset for Polyglot or Not?: Measuring Multilingual Encyclopedic Knowledge Retrieval from Foundation Language Models.\n\n\t\n\t\t\n\t\n\t\n\t\tTest Description\n\t\n\n Given a factual association such as The capital of France is Paris, we determine whether a model adequately \"knows\" this‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Polyglot-or-Not/Fact-Completion.","url":"https://huggingface.co/datasets/Polyglot-or-Not/Fact-Completion","creator_name":"Polyglot-or-Not","creator_url":"https://huggingface.co/Polyglot-or-Not","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","fill-mask","expert-generated","machine-generated","multilingual"],"keywords_longer_than_N":true},
	{"name":"massive_translation_dataset","keyword":"dutch","description":"\n\t\n\t\t\n\t\tDataset Card for Massive Dataset for Translation\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset is derived from AmazonScience/MASSIVE dataset for translation task purpose.\n\n\t\n\t\t\n\t\tSupported Tasks and Leaderboards\n\t\n\nTranslation\n\n\t\n\t\t\n\t\tLanguages\n\t\n\n\nEnglish (en_US)\nGerman (de_DE)\nHindi (hi_IN)\nSpanish (es_ES)\nFrench (fr_FR)\nItalian (it_IT)\nArabic (ar_SA)\nDutch (nl_NL)\nJapanese (ja_JP)\nPortugese (pt_PT)\n\n","url":"https://huggingface.co/datasets/Amani27/massive_translation_dataset","creator_name":"Amani N","creator_url":"https://huggingface.co/Amani27","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["translation","English","German","Spanish","Hindi"],"keywords_longer_than_N":true},
	{"name":"mc4_legal","keyword":"dutch","description":"\n\t\n\t\t\n\t\tDataset Card for MC4_Legal: A Corpus Covering the Legal Part of MC4 for European Languages\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset contains large text resources (~133GB in total) from mc4 filtered for legal data that can be used for pretraining language models.\nUse the dataset like this:\nfrom datasets import load_dataset\ndataset = load_dataset(\"joelito/mc4_legal\", \"de\", split='train', streaming=True)\n\n\n\t\n\t\t\n\t\n\t\n\t\tSupported Tasks and Leaderboards\n\t\n\nThe dataset supports the task of‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/joelniklaus/mc4_legal.","url":"https://huggingface.co/datasets/joelniklaus/mc4_legal","creator_name":"Joel Niklaus","creator_url":"https://huggingface.co/joelniklaus","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["fill-mask","other","found","multilingual","original"],"keywords_longer_than_N":true},
	{"name":"eurlex_resources","keyword":"dutch","description":"\n\t\n\t\t\n\t\tDataset Card for EurlexResources: A Corpus Covering the Largest EURLEX Resources\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset contains large text resources (~179GB in total) from EURLEX that can be used for pretraining language models.\nUse the dataset like this:\nfrom datasets import load_dataset\nconfig = \"de_caselaw\" # {lang}_{resource}\ndataset = load_dataset(\"joelito/eurlex_resources\", config, split='train', streaming=True) \n\n\n\t\n\t\t\n\t\n\t\n\t\tSupported Tasks and Leaderboards\n\t\n\nThe dataset‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/joelniklaus/eurlex_resources.","url":"https://huggingface.co/datasets/joelniklaus/eurlex_resources","creator_name":"Joel Niklaus","creator_url":"https://huggingface.co/joelniklaus","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":null,"first_N":5,"first_N_keywords":["fill-mask","other","found","multilingual","original"],"keywords_longer_than_N":true},
	{"name":"conceptnet5","keyword":"dutch","description":"\n\t\n\t\t\n\t\tDataset Card for Conceptnet5\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nConceptNet is a multilingual knowledge base, representing words and\nphrases that people use and the common-sense relationships between\nthem. The knowledge in ConceptNet is collected from a variety of\nresources, including crowd-sourced resources (such as Wiktionary and\nOpen Mind Common Sense), games with a purpose (such as Verbosity and\nnadya.jp), and expert-created resources (such as WordNet and JMDict).\nYou can browse what‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/conceptnet5/conceptnet5.","url":"https://huggingface.co/datasets/conceptnet5/conceptnet5","creator_name":"conceptnet5","creator_url":"https://huggingface.co/conceptnet5","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","multi-class-classification","crowdsourced","crowdsourced","found"],"keywords_longer_than_N":true},
	{"name":"xP3x-sample","keyword":"dutch","description":"A multilingual collection of Winograd Schemas in six languages that can be used for evaluation of cross-lingual commonsense reasoning capabilities.","url":"https://huggingface.co/datasets/Muennighoff/xP3x-sample","creator_name":"Niklas Muennighoff","creator_url":"https://huggingface.co/Muennighoff","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["other","expert-generated","crowdsourced","multilingual","Afrikaans"],"keywords_longer_than_N":true},
	{"name":"sbb-dc-ocr","keyword":"dutch","description":"\n\t\n\t\t\n\t\tDataset Card for Berlin State Library OCR data\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\n\nThe digital collections of the SBB contain 153,942 digitized works from the time period of 1470 to 1945.\n\n\nAt the time of publication, 28,909 works have been OCR-processed resulting in 4,988,099 full-text pages.\nFor each page with OCR text, the language has been determined by langid (Lui/Baldwin 2012).\n\n\n\t\n\t\t\n\t\tSupported Tasks and Leaderboards\n\t\n\n\nlanguage-modeling: this dataset has the potential to be used‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/SBB/sbb-dc-ocr.","url":"https://huggingface.co/datasets/SBB/sbb-dc-ocr","creator_name":"Staatsbibliothek zu Berlin - Preu√üischer Kulturbesitz","creator_url":"https://huggingface.co/SBB","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["fill-mask","text-generation","masked-language-modeling","language-modeling","machine-generated"],"keywords_longer_than_N":true},
	{"name":"CACAPO_E2E","keyword":"dutch","description":"The full dataset card is visible in the JSON file named \"original_cacapo_for_e2e_models-02_13_2023_19_30_07\", which has been made with GEMs second datacard creation GUI.\n","url":"https://huggingface.co/datasets/GEM/CACAPO_E2E","creator_name":"GEM benchmark","creator_url":"https://huggingface.co/GEM","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","Dutch","English","cc-by-4.0","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"CACAPO_E2E","keyword":"dutch","description":"The full dataset card is visible in the JSON file named \"original_cacapo_for_e2e_models-02_13_2023_19_30_07\", which has been made with GEMs second datacard creation GUI.\n","url":"https://huggingface.co/datasets/GEM/CACAPO_E2E","creator_name":"GEM benchmark","creator_url":"https://huggingface.co/GEM","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","Dutch","English","cc-by-4.0","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"hatecheck-dutch","keyword":"dutch","description":"\n\t\n\t\t\n\t\tDataset Card for Multilingual HateCheck\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nMultilingual HateCheck (MHC) is a suite of functional tests for hate speech detection models in 10 different languages: Arabic, Dutch, French, German, Hindi, Italian, Mandarin, Polish, Portuguese and Spanish.\nFor each language, there are 25+ functional tests that correspond to distinct types of hate and challenging non-hate.\nThis allows for targeted diagnostic insights into model performance.\nFor more details‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Paul/hatecheck-dutch.","url":"https://huggingface.co/datasets/Paul/hatecheck-dutch","creator_name":"Paul R√∂ttger","creator_url":"https://huggingface.co/Paul","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","hate-speech-detection","crowdsourced","expert-generated","monolingual"],"keywords_longer_than_N":true},
	{"name":"euronews","keyword":"dutch","description":"\n\t\n\t\t\n\t\tDataset Card for Europeana Newspapers\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tSupported Tasks and Leaderboards\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tLanguages\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\n\t\n\t\t\n\t\tData Instances\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tData Fields\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tData Splits\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tDataset Creation\n\t\n\n\n\t\n\t\t\n\t\tCuration Rationale\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tSource‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/community-datasets/euronews.","url":"https://huggingface.co/datasets/community-datasets/euronews","creator_name":"Community Datasets","creator_url":"https://huggingface.co/community-datasets","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["token-classification","named-entity-recognition","expert-generated","crowdsourced","multilingual"],"keywords_longer_than_N":true},
	{"name":"blbooks","keyword":"dutch","description":"A dataset comprising of text created by OCR from the 49,455 digitised books, equating to 65,227 volumes (25+ million pages), published between c. 1510 - c. 1900.\nThe books cover a wide range of subject areas including philosophy, history, poetry and literature.","url":"https://huggingface.co/datasets/TheBritishLibrary/blbooks","creator_name":"British Library","creator_url":"https://huggingface.co/TheBritishLibrary","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":null,"first_N":5,"first_N_keywords":["text-generation","fill-mask","other","language-modeling","masked-language-modeling"],"keywords_longer_than_N":true},
	{"name":"covid19_emergency_event","keyword":"dutch","description":"\n\t\n\t\t\n\t\tDataset Card for EXCEPTIUS Corpus\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset presents a new corpus of legislative documents from 8 European countries (Beglium, France, Hunary, Italy, Netherlands, Norway, Poland, UK) in 7 languages (Dutch, English, French, Hungarian, Italian, Norwegian Bokm√•l, Polish) manually annotated for exceptional measures against COVID-19. The annotation was done on the sentence level.\n\n\t\n\t\t\n\t\tSupported Tasks and Leaderboards\n\t\n\nThe dataset can be used for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/joelniklaus/covid19_emergency_event.","url":"https://huggingface.co/datasets/joelniklaus/covid19_emergency_event","creator_name":"Joel Niklaus","creator_url":"https://huggingface.co/joelniklaus","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","multi-label-classification","found","other","found"],"keywords_longer_than_N":true},
	{"name":"urban_sounds_small","keyword":"dutch","description":"The Urban Sounds dataset consists of audio samples collected in Amsterdam in the period 2018 - 2020. \nThe datasamples were collected for a project to create a sensor to classify audio events, with the goal of tackling noise pollution in the city.\nThis 'urban sounds small' dataset is a small part of the dataset, used for testing and prototyping purposes.\nMore on the sensor can be found here: https://github.com/sensemakersamsterdam/OpenEars \n","url":"https://huggingface.co/datasets/UrbanSounds/urban_sounds_small","creator_name":"Sensemakers Amsterdam UrbanSounds repo","creator_url":"https://huggingface.co/UrbanSounds","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["audio-classification","Dutch","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"NQ-NL","keyword":"dutch","description":"\n  NQ-NL\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nNQ-NL is a translation of NQ\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2t\n\n\nDomains\nWritten, Encyclopaedic\n\n\nReference\nhttps://huggingface.co/datasets/clips/beir-nl-nq\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask = mteb.get_tasks([\"NQ-NL\"])\nevaluator = mteb.MTEB(task)\n\nmodel = mteb.get_model(YOUR_MODEL)\nevaluator.run(model)\n\n\nTo learn more about how‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/NQ-NL.","url":"https://huggingface.co/datasets/mteb/NQ-NL","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","multiple-choice-qa","derived","translated","mteb/nq"],"keywords_longer_than_N":true},
	{"name":"Klipperai","keyword":"dutch","description":"IPNET/Klipperai dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/IPNET/Klipperai","creator_name":"daniel","creator_url":"https://huggingface.co/IPNET","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","Dutch","German","English","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"BramVanroy_ultrachat_200k_dutch_reformat","keyword":"dutch","description":"CultriX/BramVanroy_ultrachat_200k_dutch_reformat dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/CultriX/BramVanroy_ultrachat_200k_dutch_reformat","creator_name":"CultriX","creator_url":"https://huggingface.co/CultriX","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","Dutch","apache-2.0","100K<n<1M","üá∫üá∏ Region: US"],"keywords_longer_than_N":true},
	{"name":"BramVanroy_ultrachat_200k_dutch_reformat","keyword":"dutch","description":"CultriX/BramVanroy_ultrachat_200k_dutch_reformat dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/CultriX/BramVanroy_ultrachat_200k_dutch_reformat","creator_name":"CultriX","creator_url":"https://huggingface.co/CultriX","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","Dutch","apache-2.0","100K<n<1M","üá∫üá∏ Region: US"],"keywords_longer_than_N":true},
	{"name":"xsimplusplus","keyword":"dutch","description":"xSIM++ is an extension of xSIM. In comparison to xSIM, this evaluates using target-side data with additional synthetic, hard-to-distinguish examples. You can find more details about it in the publication: xSIM++: An Improved Proxy to Bitext Mining Performance for Low-Resource Languages.\n","url":"https://huggingface.co/datasets/jaygala24/xsimplusplus","creator_name":"Jay Gala","creator_url":"https://huggingface.co/jaygala24","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["derived","multilingual","Achinese","Mesopotamian Arabic","Ta'izzi-Adeni Arabic"],"keywords_longer_than_N":true},
	{"name":"cml-tts","keyword":"dutch","description":"\n\t\n\t\t\n\t\tDataset Card for CML-TTS\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nCML-TTS is a recursive acronym for CML-Multi-Lingual-TTS, a Text-to-Speech (TTS) dataset developed at the Center of Excellence in Artificial Intelligence (CEIA) of the Federal University of Goias (UFG).\nCML-TTS is a dataset comprising audiobooks sourced from the public domain books of Project Gutenberg, read by volunteers from the LibriVox project. The dataset includes recordings in Dutch, German, French, Italian, Polish‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ylacombe/cml-tts.","url":"https://huggingface.co/datasets/ylacombe/cml-tts","creator_name":"Yoach Lacombe","creator_url":"https://huggingface.co/ylacombe","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-to-speech","text-to-audio","Dutch","French","German"],"keywords_longer_than_N":true},
	{"name":"truthfulqax","keyword":"dutch","description":"\n\t\n\t\t\n\t\tCitation Information\n\t\n\nIf you find benchmarks useful in your research, please consider citing the test and also the TruthfulQA dataset it draws from:\n    @misc{thellmann2024crosslingual,\n    title={Towards Cross-Lingual LLM Evaluation for European Languages},\n    author={Klaudia Thellmann and Bernhard Stadler and Michael Fromm and Jasper Schulze Buschhoff and Alex Jude and Fabio Barth and Johannes Leveling and Nicolas Flores-Herr and Joachim K√∂hler and Ren√© J√§kel and Mehdi Ali}‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Eurolingua/truthfulqax.","url":"https://huggingface.co/datasets/Eurolingua/truthfulqax","creator_name":"EuroLingua-GPT","creator_url":"https://huggingface.co/Eurolingua","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":null,"first_N":5,"first_N_keywords":["text-generation","German","French","Spanish","Italian"],"keywords_longer_than_N":true},
	{"name":"biblenlp-corpus-mmteb","keyword":"dutch","description":"This dataset pre-computes all English-centric directions from bible-nlp/biblenlp-corpus, and as a result loading is significantly faster.\nLoading example:\n>>> from datasets import load_dataset\n>>> dataset = load_dataset(\"davidstap/biblenlp-corpus-mmteb\", \"eng-arb\", trust_remote_code=True)\n>>> dataset\nDatasetDict({\n    train: Dataset({\n        features: ['eng', 'arb'],\n        num_rows: 28723\n    })\n    validation: Dataset({\n        features: ['eng', 'arb'],\n        num_rows: 1578\n    })‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/biblenlp-corpus-mmteb.","url":"https://huggingface.co/datasets/mteb/biblenlp-corpus-mmteb","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["no-annotation","expert-generated","translation","multilingual","Arifama-Miniafia"],"keywords_longer_than_N":true},
	{"name":"biblenlp-corpus-mmteb","keyword":"dutch","description":"This dataset pre-computes all English-centric directions from bible-nlp/biblenlp-corpus, and as a result loading is significantly faster.\nLoading example:\n>>> from datasets import load_dataset\n>>> dataset = load_dataset(\"davidstap/biblenlp-corpus-mmteb\", \"eng-arb\", trust_remote_code=True)\n>>> dataset\nDatasetDict({\n    train: Dataset({\n        features: ['eng', 'arb'],\n        num_rows: 28723\n    })\n    validation: Dataset({\n        features: ['eng', 'arb'],\n        num_rows: 1578\n    })‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/biblenlp-corpus-mmteb.","url":"https://huggingface.co/datasets/mteb/biblenlp-corpus-mmteb","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["no-annotation","expert-generated","translation","multilingual","Arifama-Miniafia"],"keywords_longer_than_N":true},
	{"name":"Thinking-multilingual-big-10k-sft","keyword":"dutch","description":"\nA dataset based off of openo1 math, 500 examples translated to 23 different languages. filtered out un-translated examples.\nenjoy üëç\n","url":"https://huggingface.co/datasets/Pinkstack/Thinking-multilingual-big-10k-sft","creator_name":"Pinkstack","creator_url":"https://huggingface.co/Pinkstack","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","Arabic","Chinese","Czech","Danish"],"keywords_longer_than_N":true},
	{"name":"FiQA2018-NL","keyword":"dutch","description":"\n  FiQA2018-NL\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nFinancial Opinion Mining and Question Answering. FiQA2018-NL is a Dutch translation\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2t\n\n\nDomains\nWritten, Non-fiction\n\n\nReference\nhttps://huggingface.co/datasets/clips/beir-nl-fiqa\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask = mteb.get_tasks([\"FiQA2018-NL\"])\nevaluator = mteb.MTEB(task)\n\nmodel =‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/FiQA2018-NL.","url":"https://huggingface.co/datasets/mteb/FiQA2018-NL","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","multiple-choice-qa","derived","translated","mteb/fiqa"],"keywords_longer_than_N":true},
	{"name":"HPLT-Dutch-cleaned-v1.2","keyword":"dutch","description":"\n\t\n\t\t\n\t\tHPLT Dutch cleaned v1.2\n\t\n\n\nData creator: High Performance Language Technologies\nData URL: https://hplt-project.org/datasets/v1.2\nTechnical data description: https://hplt-project.org/HPLT_D2_1___Initial_release_of_monolingual_and_parallel_data_sets-1.pdf\n\n\n\t\n\t\t\n\t\n\t\n\t\tFields\n\t\n\n\nid: Document ID\ndocument_lang: Document language identified by CLD2 during the WARC extraction process.\nscores: Language identification scores for each paragraph in the document. \nlangs: Language with highest‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/BramVanroy/HPLT-Dutch-cleaned-v1.2.","url":"https://huggingface.co/datasets/BramVanroy/HPLT-Dutch-cleaned-v1.2","creator_name":"Bram Vanroy","creator_url":"https://huggingface.co/BramVanroy","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","Dutch","cc0-1.0","10M - 100M","parquet"],"keywords_longer_than_N":true},
	{"name":"arc-challenge-nl","keyword":"dutch","description":"\n\t\n\t\t\n\t\tDataset Card for \"ai2_arc_nl\"\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nA new dutch translated original ai2_arc dataset of 7,787 genuine grade-school level, multiple-choice science questions, assembled to encourage research in\n advanced question-answering. The dataset is partitioned into a Challenge Set and an Easy Set, where the former contains\n only questions answered incorrectly by both a retrieval-based algorithm and a word co-occurrence algorithm. We are also\n including a corpus of over 14‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Cheremy/arc-challenge-nl.","url":"https://huggingface.co/datasets/Cheremy/arc-challenge-nl","creator_name":"Pongajow","creator_url":"https://huggingface.co/Cheremy","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["question-answering","Dutch","apache-2.0","1K - 10K","parquet"],"keywords_longer_than_N":true},
	{"name":"minds14","keyword":"dutch","description":"\n\t\n\t\t\n\t\tMInDS-14\n\t\n\nMINDS-14 is training and evaluation resource for intent detection task with spoken data. It covers 14 \nintents extracted from a commercial system in the e-banking domain, associated with spoken examples in 14 diverse language varieties.\n\n\t\n\t\t\n\t\tExample\n\t\n\nMInDS-14 can be downloaded and used as follows:\nfrom datasets import load_dataset\n\nminds_14 = load_dataset(\"PolyAI/minds14\", \"fr-FR\") # for French\n# to download all data for multi-lingual fine-tuning uncomment following‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/PolyAI/minds14.","url":"https://huggingface.co/datasets/PolyAI/minds14","creator_name":"PolyAI","creator_url":"https://huggingface.co/PolyAI","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","keyword-spotting","expert-generated","crowdsourced","machine-generated"],"keywords_longer_than_N":true},
	{"name":"apollo_english_guidelines_translated_to_dutch_with_nllb200","keyword":"dutch","description":"Apollo corpus, pre-trained, English guidelines translated to Dutch using NLLB200","url":"https://huggingface.co/datasets/UMCU/apollo_english_guidelines_translated_to_dutch_with_nllb200","creator_name":"Bram van Es","creator_url":"https://huggingface.co/UMCU","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","fill-mask","Dutch","apache-2.0","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"amazon_massive_scenario","keyword":"dutch","description":"\n  MassiveScenarioClassification\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nMASSIVE: A 1M-Example Multilingual Natural Language Understanding Dataset with 51 Typologically-Diverse Languages\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2c\n\n\nDomains\nSpoken\n\nReference\nhttps://arxiv.org/abs/2204.08582\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask = mteb.get_tasks([\"MassiveScenarioClassification\"])\nevaluator =‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/amazon_massive_scenario.","url":"https://huggingface.co/datasets/mteb/amazon_massive_scenario","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","human-annotated","translated","Afrikaans","Amharic"],"keywords_longer_than_N":true},
	{"name":"tatoeba_21-dec-2024","keyword":"dutch","description":"I would recommend anyone to download the most recent version of the files directly from Tatoeba. \nSince the most recent version of the dataset on huggingface is already quite old, I uploaded today's versions of the Tatoeba sentences. I uploaded the full dataset, as well as some files for some individual languages that I happen to speak. Honorable mention to Gronings, language code gos.\nExample code to download the most recent version of the Tatoeba dataset:\nimport requests\n\nwith‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Tom9358/tatoeba_21-dec-2024.","url":"https://huggingface.co/datasets/Tom9358/tatoeba_21-dec-2024","creator_name":"Tom","creator_url":"https://huggingface.co/Tom9358","license_name":"Creative Commons Attribution 2.0","license_url":"https://scancode-licensedb.aboutcode.org/cc-by-2.0.html","language":"en","first_N":5,"first_N_keywords":["translation","Dutch","English","German","Spanish"],"keywords_longer_than_N":true},
	{"name":"mewsli-x","keyword":"dutch","description":"I generated the dataset following mewsli-x.md#getting-started\nand converted into different parts (see process.py):\n\nar/de/en/es/fa/ja/pl/ro/ta/tr/uk wikinews_mentions dev and test (from wikinews_mentions-dev/test.jsonl)\ncandidate entities of 50 languages (from candidate_set_entities.jsonl)\nEnglish wikipedia_pairs to fine-tune models (from wikipedia_pairs-dev/train.jsonl)\n\nRaw data files are in raw.tar.gz, which contains:\n[...] 535M Feb 24 22:06 candidate_set_entities.jsonl\n[...] 9.8M Feb 24‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/izhx/mewsli-x.","url":"https://huggingface.co/datasets/izhx/mewsli-x","creator_name":"Xin Zhang","creator_url":"https://huggingface.co/izhx","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","entity-linking-retrieval","Afrikaans","Arabic","Azerbaijani"],"keywords_longer_than_N":true},
	{"name":"apollo_english_guidelines_translated_to_dutch_with_marianmt","keyword":"dutch","description":"Apollo corpus, pre-trained, English guidelines translated to Dutch using MariaNMT","url":"https://huggingface.co/datasets/UMCU/apollo_english_guidelines_translated_to_dutch_with_marianmt","creator_name":"Bram van Es","creator_url":"https://huggingface.co/UMCU","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","fill-mask","Dutch","apache-2.0","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"monumenten","keyword":"dutch","description":"This dataset contains the monumental statuses of all addressable units (verblijfsobjecten) found in the BAG of het Kadaster.\n\n[!NOTE]\nThe monumental statuses are added via the open-source Python package monumenten.Please keep in mind that this dataset might not be completely up-to-date. Check the git tag to see the last update date of this dataset.\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tContext\n\t\n\n\nSource for is_bescherm_gezicht (protected townspace): Cultural Heritage Agency(Rijksdienst voor Cultereel Erfgoed)‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/woonstadrotterdam/monumenten.","url":"https://huggingface.co/datasets/woonstadrotterdam/monumenten","creator_name":"Woonstad Rotterdam","creator_url":"https://huggingface.co/woonstadrotterdam","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["Dutch","mit","10M - 100M","parquet","Text"],"keywords_longer_than_N":true},
	{"name":"Paradoxical_AI_Reflections2","keyword":"dutch","description":"\n\t\n\t\t\n\t\tDataset Card for Dataset Name\n\t\n\n\n\nThis dataset card aims to be a base template for new datasets. It has been generated using this raw template.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\n\n\n\n\n\nCurated by: [More Information Needed]\nFunded by [optional]: [More Information Needed]\nShared by [optional]: [More Information Needed]\nLanguage(s) (NLP): [More Information Needed]\nLicense: [More Information Needed]\n\n\n\t\n\t\t\n\t\tDataset Sources [optional]\n\t\n\n\n\n\nRepository: [More‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/BrinzShoota/Paradoxical_AI_Reflections2.","url":"https://huggingface.co/datasets/BrinzShoota/Paradoxical_AI_Reflections2","creator_name":"Lucas Coroi","creator_url":"https://huggingface.co/BrinzShoota","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-generation","English","Dutch","mit","1K<n<10K"],"keywords_longer_than_N":true},
	{"name":"muri-it-language-split","keyword":"dutch","description":"\n\t\n\t\t\n\t\tMURI-IT: Multilingual Instruction Tuning Dataset for 200 Languages via Multilingual Reverse Instructions\n\t\n\nMURI-IT is a large-scale multilingual instruction tuning dataset containing 2.2 million instruction-output pairs across 200 languages. It is designed to address the challenges of instruction tuning in low-resource languages with Multilingual Reverse Instructions (MURI), which ensures that the output is human-written, high-quality, and authentic to the cultural and linguistic‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/akoksal/muri-it-language-split.","url":"https://huggingface.co/datasets/akoksal/muri-it-language-split","creator_name":"Abdullatif Koksal","creator_url":"https://huggingface.co/akoksal","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text2text-generation","text-generation","question-answering","summarization","Achinese"],"keywords_longer_than_N":true},
	{"name":"oaast_rm_full_jieba","keyword":"dutch","description":"Â∞ùËØïËß£ÂÜ≥\"llm repetition problem\"Ôºå‰ΩøÁî®ÂàÜËØçÊ®°ÂûãÂØπoaastËØ≠ÊñôËøõË°å‚ÄúÁªìÂ∑¥Âåñ‚ÄùÊï∞ÊçÆÂ¢ûÂº∫ÔºåÊèê‰æõÊõ¥Âº∫ÁöÑÈáçÂ§çÂÜÖÂÆπÊãíÁªùÊïàÊûú„ÄÇ\nAttempts to solve the \"llm repetition problem\" by using a segmentation model to enhance the oaast corpus with \"stuttering\" data to provide stronger rejection of duplicate content.\nÂÖ∂Ê¨°ÔºåËøòËøáÊª§Êéâ‰∫ÜÊâÄÊúâËá™ÊàëËÆ§Áü•ÁöÑÂæÆË∞ÉÊ†∑Êú¨„ÄÇ\nSecond, it also filters out all the fine-tuned samples of self-cognition.\nfiles:\n\noaast_rm_full_jieba.jsonl : word level repeat\noaast_rm_full_sent_jieba.jsonl : sentence level repeat\n\n","url":"https://huggingface.co/datasets/lenML/oaast_rm_full_jieba","creator_name":"len","creator_url":"https://huggingface.co/lenML","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["English","Spanish","Russian","German","Polish"],"keywords_longer_than_N":true},
	{"name":"aya_evaluation_suite","keyword":"dutch","description":"\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nAya Evaluation Suite contains a total of 26,750 open-ended conversation-style prompts to evaluate multilingual open-ended generation quality.To strike a balance between language coverage and the quality that comes with human curation, we create an evaluation suite that includes:\n\nhuman-curated examples in 7 languages (tur, eng, yor, arb, zho, por, tel) ‚Üí aya-human-annotated.\nmachine-translations of handpicked examples into 101 languages ‚Üí dolly-machine-translated.‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/CohereLabs/aya_evaluation_suite.","url":"https://huggingface.co/datasets/CohereLabs/aya_evaluation_suite","creator_name":"Cohere Labs","creator_url":"https://huggingface.co/CohereLabs","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","crowdsourced","expert-generated","machine-generated","multilingual"],"keywords_longer_than_N":true},
	{"name":"YouTube-Commons","keyword":"dutch","description":"\n\t\n\t\t\n\t\tYouTube Commons Re-upload\n\t\n\nThis is a re-upload of PleIAs' YouTube Commons, a valuable open dataset:\n\nYouTube-Commons is a collection of audio transcripts of 2,063,066 videos shared on YouTube under a CC BY 4.0 license.\nContent\nThe collection comprises 22,709,724 original and automatically translated transcripts from 3,156,703 videos (721,136 individual channels).\n\nUnfortunately, there are problems with loading YouTube Commons with Hugging Face Datasets.\nIn order to alleviate those‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Rijgersberg/YouTube-Commons.","url":"https://huggingface.co/datasets/Rijgersberg/YouTube-Commons","creator_name":"Edwin Rijgersberg","creator_url":"https://huggingface.co/Rijgersberg","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","English","French","Spanish","Portuguese"],"keywords_longer_than_N":true},
	{"name":"DBPedia-NL","keyword":"dutch","description":"\n  DBPedia-NL\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nDBpedia-Entity is a standard test collection for entity search over the DBpedia knowledge base. DBPedia-NL is a Dutch translation.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2t\n\n\nDomains\nWritten, Encyclopaedic\nReference\nhttps://huggingface.co/datasets/clips/beir-nl-dbpedia-entity\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask =‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/DBPedia-NL.","url":"https://huggingface.co/datasets/mteb/DBPedia-NL","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","derived","translated","mteb/dbpedia","Dutch"],"keywords_longer_than_N":true},
	{"name":"webui-dom-snapshots","keyword":"dutch","description":"\n\t\n\t\t\n\t\tDataset Card for WebUI DOM snapshots\n\t\n\n\n\nThis dataset card aims to be a base template for new datasets. It has been generated using this raw template.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\n\n\n\n\n\nCurated by: Gary Benson\nLanguages: Mostly English (87%);\nDutch, French, Chinese, Japanese (1-2% each); 30+ others (<1% each)\nLicense: CC0 1.0 Universal\n\n\n\t\n\t\t\n\t\tDataset Sources [optional]\n\t\n\n\n\n\nRepository: [More Information Needed]\nPaper [optional]: [More Information Needed]‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/gbenson/webui-dom-snapshots.","url":"https://huggingface.co/datasets/gbenson/webui-dom-snapshots","creator_name":"Gary Benson","creator_url":"https://huggingface.co/gbenson","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["image-feature-extraction","reinforcement-learning","text-classification","multilingual","biglab/webui-7k"],"keywords_longer_than_N":true},
	{"name":"dbnl.org-dutch-public-domain","keyword":"dutch","description":"\n\t\n\t\t\n\t\tDataset Card for \"dbnl.org-dutch-public-domain\"\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset comprises a collection of texts from the Dutch Literature in the public domain, specifically from the DBNL (Digitale Bibliotheek voor de Nederlandse Letteren) public domain collection. The collection includes books, poems, songs, and other documentation, letters, etc., that are at least 140 years old and thus free of copyright restrictions. Each entry in the dataset corresponds to one section of‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/jvdgoltz/dbnl.org-dutch-public-domain.","url":"https://huggingface.co/datasets/jvdgoltz/dbnl.org-dutch-public-domain","creator_name":"Julian von der Goltz","creator_url":"https://huggingface.co/jvdgoltz","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","fill-mask","monolingual","Dutch","cc0-1.0"],"keywords_longer_than_N":true},
	{"name":"panlex-meanings","keyword":"dutch","description":"\n\t\n\t\t\n\t\tDataset Card for panlex-meanings\n\t\n\nThis is a dataset of words in several thousand languages, extracted from https://panlex.org.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset has been extracted from https://panlex.org (the 20240301 database dump) and rearranged on the per-language basis.\nEach language subset consists of expressions (words and phrases). \nEach expression is associated with some meanings (if there is more than one meaning, they are in separate‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/cointegrated/panlex-meanings.","url":"https://huggingface.co/datasets/cointegrated/panlex-meanings","creator_name":"David Dale","creator_url":"https://huggingface.co/cointegrated","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["translation","Afar","Western Abnaki","Abkhazian","Abaza"],"keywords_longer_than_N":true},
	{"name":"Multilingal-sakalt-data","keyword":"dutch","description":"„Éû„É´„ÉÅ„É™„É≥„Ç¨„É´„Éá„Éº„Çø„Çª„ÉÉ„Éà„Åß„Åô„ÄÇmit„É©„Ç§„Çª„É≥„Çπ„Åß„Åô„ÄÇ\n","url":"https://huggingface.co/datasets/Sakalti/Multilingal-sakalt-data","creator_name":"sakasan","creator_url":"https://huggingface.co/Sakalti","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-generation","Abkhaz","Bhojpuri","Chechen","Czech"],"keywords_longer_than_N":true},
	{"name":"ChecketV2-Dataset","keyword":"dutch","description":"ODeNy/ChecketV2-Dataset dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/ODeNy/ChecketV2-Dataset","creator_name":"J De Nys","creator_url":"https://huggingface.co/ODeNy","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["Dutch","apache-2.0","10K - 100K","csv","Text"],"keywords_longer_than_N":true},
	{"name":"tulu-3-sft-mixture-with-language","keyword":"dutch","description":"\n\nJust a version of the good tulu-3-sft-mixture dataset with a column indicating language.\nLanguage detection has been performed with fastText.\n‚ö†Ô∏è It may contain errors.\n","url":"https://huggingface.co/datasets/anakin87/tulu-3-sft-mixture-with-language","creator_name":"Stefano Fiorucci","creator_url":"https://huggingface.co/anakin87","license_name":"Open Data Commons Attribution License v1.0","license_url":"https://scancode-licensedb.aboutcode.org/odc-by-1.0.html","language":"en","first_N":5,"first_N_keywords":["other","crowdsourced","expert-generated","machine-generated","multilingual"],"keywords_longer_than_N":true},
	{"name":"Lemonade","keyword":"dutch","description":"LEMONADE is a large, expert-annotated dataset for event extraction from news articles in 20 languages: English, Spanish, Arabic, French, Italian, Russian, German, Turkish, Burmese, Indonesian, Ukrainian, Korean, Portuguese, Dutch, Somali, Nepali, Chinese, Persian, Hebrew, and Japanese.\nSee https://github.com/stanford-oval/Lemonade for details.\n","url":"https://huggingface.co/datasets/stanford-oval/Lemonade","creator_name":"Stanford Open Virtual Assistant Lab (OVAL)","creator_url":"https://huggingface.co/stanford-oval","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","text-generation","English","Spanish","Arabic"],"keywords_longer_than_N":true},
	{"name":"NLSmell","keyword":"dutch","description":"pallie/NLSmell dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/pallie/NLSmell","creator_name":"Patrick Spaargaren","creator_url":"https://huggingface.co/pallie","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","Dutch","apache-2.0","10K - 100K","csv"],"keywords_longer_than_N":true},
	{"name":"mosel","keyword":"dutch","description":"\n\n\n\t\n\t\t\n\t\tDataset Description, Collection, and Source\n\t\n\nThe MOSEL corpus is a multilingual dataset collection including up to 950K hours of open-source speech recordings covering the 24 official languages of the European Union. We collect data by surveying labeled and unlabeled speech corpora under open-source compliant licenses.\nIn particular, MOSEL includes the automatic transcripts of 441k hours of unlabeled speech from VoxPopuli and LibriLight. The data is transcribed using Whisper large‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/FBK-MT/mosel.","url":"https://huggingface.co/datasets/FBK-MT/mosel","creator_name":"FBK-MT","creator_url":"https://huggingface.co/FBK-MT","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","machine-generated","found","multilingual"],"keywords_longer_than_N":true},
	{"name":"apollo_english_books_translated_to_dutch_with_geminiflash15","keyword":"dutch","description":"Translation of the English medical books that are part of the Apollo corpus, using the LLM Gemini Flash 1.5","url":"https://huggingface.co/datasets/UMCU/apollo_english_books_translated_to_dutch_with_geminiflash15","creator_name":"Bram van Es","creator_url":"https://huggingface.co/UMCU","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["Dutch","apache-2.0","100K - 1M","json","Tabular"],"keywords_longer_than_N":true},
	{"name":"apollo_english_books_translated_to_dutch_with_geminiflash15","keyword":"dutch","description":"Translation of the English medical books that are part of the Apollo corpus, using the LLM Gemini Flash 1.5","url":"https://huggingface.co/datasets/UMCU/apollo_english_books_translated_to_dutch_with_geminiflash15","creator_name":"Bram van Es","creator_url":"https://huggingface.co/UMCU","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["Dutch","apache-2.0","100K - 1M","json","Tabular"],"keywords_longer_than_N":true},
	{"name":"belastingdienst-dataset","keyword":"dutch","description":"\n\t\n\t\t\n\t\tDutch GOV Belastingdienst\n\t\n\nThis dataset is created by scraping https://www.belastingdienst.nl/, I used the titemap to get all possible allowed URLS.\nIt possible some URLS are missing.\nThe reason for creating this dataset is I couldn't find any other existing dataset with this data.\nSo here is this dataset, Enjoy!\n\n\t\n\t\t\n\t\n\t\n\t\tPlease note this dataset is not complety checked or cleaned, this was a personal research project.\n\t\n\n","url":"https://huggingface.co/datasets/ethux/belastingdienst-dataset","creator_name":"Gijsbert Westeneng","creator_url":"https://huggingface.co/ethux","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["Dutch","apache-2.0","< 1K","csv","Text"],"keywords_longer_than_N":true},
	{"name":"interesting-dom-snapshots","keyword":"dutch","description":"\n\t\n\t\t\n\t\tDataset Card for Interesting DOM snapshots\n\t\n\nA small split of gbenson/webui-dom-snapshots.\n\nCurated by: Gary Benson\nLanguages: Mostly English, some Chinese, Dutch, Czech and Korean\nLicense: CC0 1.0 Universal\n\n\n\t\n\t\t\n\t\n\t\n\t\tUses\n\t\n\nI'm using it to develop a DOM-aware tokenizer for HTML.\n\n\t\n\t\t\n\t\n\t\n\t\tBias, Risks, and Limitations\n\t\n\nThis isn't a representative split of the source dataset, it's a number of edge cases I flagged to investigate.\n","url":"https://huggingface.co/datasets/gbenson/interesting-dom-snapshots","creator_name":"Gary Benson","creator_url":"https://huggingface.co/gbenson","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["gbenson/webui-dom-snapshots","English","Chinese","Dutch","Czech"],"keywords_longer_than_N":true},
	{"name":"flemish_multimodal_exams_physician","keyword":"dutch","description":"jjzha/flemish_multimodal_exams_physician dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/jjzha/flemish_multimodal_exams_physician","creator_name":"Mike Zhang","creator_url":"https://huggingface.co/jjzha","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["Dutch","cc-by-4.0","< 1K","imagefolder","Image"],"keywords_longer_than_N":true},
	{"name":"ManyToDanishTranslations-tatoeba","keyword":"dutch","description":"\n\t\n\t\t\n\t\tDanske overs√¶ttelser\n\t\n\nTak til Helsinki-NLP for deres tatoeba dataset (CC-BY-2.0).\nModeller der kan adskillige sprog kan sj√¶ldent dansk. At overs√¶tte eksisterende dataset virker som en fornuftig l√∏sning p√• det problem, men af fornuftige overs√¶ttelsesv√¶rkt√∏jer er der kun f√•. Mad props til Mabeck for arbejdet med SlimOrca. Much inspired. Great thank.\nSom sagt kan polylinvistiske modeller som regel engelsk, kinesisk, fransk, tysk, osv. og m√•ske mangler der bare noget brobygningshysteri‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/trollek/ManyToDanishTranslations-tatoeba.","url":"https://huggingface.co/datasets/trollek/ManyToDanishTranslations-tatoeba","creator_name":"Trolle Karlsson","creator_url":"https://huggingface.co/trollek","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["translation","Danish","English","German","Spanish"],"keywords_longer_than_N":true},
	{"name":"webfaq","keyword":"dutch","description":"WebFAQ Q&A Dataset\n\n   \n       Overview |\n       Details  |\n       Structure  |\n       Examples |\n       Considerations |\n       License |\n       Citation |\n       Contact |\n       Acknowledgement\n   \n\n\n\n\t\n\t\t\n\t\n\t\n\t\tOverview\n\t\n\nThe WebFAQ Q&A Dataset is a broad-coverage corpus of 96 million natural question-answer (QA) pairs in 75 languages, gathered from FAQ pages on the web. It leverages structured schema.org FAQPage annotations, making it a unique resource for large-scale Question Answering‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/PaDaS-Lab/webfaq.","url":"https://huggingface.co/datasets/PaDaS-Lab/webfaq","creator_name":"Chair of Data Science, University of Passau","creator_url":"https://huggingface.co/PaDaS-Lab","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["question-answering","multilingual","Afrikaans","Amharic","Arabic"],"keywords_longer_than_N":true},
	{"name":"floras","keyword":"dutch","description":"\n\t\n\t\t\n\t\tFLORAS\n\t\n\nFLORAS is a 50-language benchmark For LOng-form Recognition And Summarization of spoken language. \nThe goal of FLORAS is to create a more realistic benchmarking environment for speech recognition, translation, and summarization models. \nUnlike typical academic benchmarks like LibriSpeech and FLEURS that uses pre-segmented single-speaker read-speech, FLORAS tests the capabilities of models on raw long-form conversational audio, which can have one or many speakers.\nTo encourage‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/espnet/floras.","url":"https://huggingface.co/datasets/espnet/floras","creator_name":"ESPnet","creator_url":"https://huggingface.co/espnet","license_name":"Creative Commons Attribution 3.0","license_url":"https://scancode-licensedb.aboutcode.org/cc-by-3.0.html","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","translation","summarization","English","Spanish"],"keywords_longer_than_N":true},
	{"name":"wikifacts-bench","keyword":"dutch","description":"kaengreg/wikifacts-bench dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/kaengreg/wikifacts-bench","creator_name":"Grigory Kovalev","creator_url":"https://huggingface.co/kaengreg","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["Russian","English","German","French","Portuguese"],"keywords_longer_than_N":true},
	{"name":"MultiEup-v2","keyword":"dutch","description":"\n\t\n\t\t\n\t\tMulti-EuP-v2\n\t\n\nThis dataset card documents Multi-EuP-v2, a multilingual corpus of European Parliament debate speeches enriched with Member of European Parliament (MEP) metadata and multilingual debate titles/IDs. It supports research on political text analysis, speaker-attribute prediction, stance/vote prediction, multilingual NLP, and retrieval.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nMulti-EuP-v2 aggregates 50,337 debate speeches (each a unique did) in 24‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/unimelb-nlp/MultiEup-v2.","url":"https://huggingface.co/datasets/unimelb-nlp/MultiEup-v2","creator_name":"The University of Melbourne","creator_url":"https://huggingface.co/unimelb-nlp","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","text-retrieval","text-generation","multilingual","Bulgarian"],"keywords_longer_than_N":true},
	{"name":"aya_dutch_dpo","keyword":"dutch","description":"\n  \n    \n  \n\n\n\n\t\n\t\t\n\t\tDataset Card for aya_dutch_dpo\n\t\n\nThis dataset has been created with distilabel.\nThis dataset was created as part of the Data is Better Together project, in particular as part of an ongoing effort to help foster the creation of DPO/ORPO datasets for more languages.\nThe dataset was constructed using the following steps:\n\nstarting with the aya_dataset and filtering for Dutch examples\nusing the Meta-Llama-3-70B-Instruct model to generate new examples for each promptUsing‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/data-is-better-together/aya_dutch_dpo.","url":"https://huggingface.co/datasets/data-is-better-together/aya_dutch_dpo","creator_name":"Data Is Better Together","creator_url":"https://huggingface.co/data-is-better-together","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","reinforcement-learning","Dutch","apache-2.0","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"HPLT2.0_cleaned","keyword":"dutch","description":"This is a large-scale collection of web-crawled documents in 191 world languages, produced by the HPLT project. \nThe source of the data is mostly Internet Archive with some additions from Common Crawl.\nFor a detailed description of the dataset, please refer to https://hplt-project.org/datasets/v2.0\nThe Cleaned variant of HPLT Datasets v2.0\nThis is the cleaned variant of the HPLT Datasets v2.0 converted to the Parquet format semi-automatically when being uploaded here. \nThe original JSONL files‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/jobs-git/HPLT2.0_cleaned.","url":"https://huggingface.co/datasets/jobs-git/HPLT2.0_cleaned","creator_name":"James Guana","creator_url":"https://huggingface.co/jobs-git","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["fill-mask","text-generation","language-modeling","multilingual","Achinese"],"keywords_longer_than_N":true},
	{"name":"GlotCC-V1","keyword":"dutch","description":"\n\t\n\t\t\n\t\tDataset Summary\n\t\n\n \n\nGlotCC-V1.0 is a document-level, general domain dataset derived from CommonCrawl, covering more than 1000 languages.It is built using the GlotLID language identification and Ungoliant pipeline from CommonCrawl.We release our pipeline as open-source at https://github.com/cisnlp/GlotCC.  \nList of Languages: See https://datasets-server.huggingface.co/splits?dataset=cis-lmu/GlotCC-V1 to get the list of splits available.\n\n\t\t\n\t\tUsage (Huggingface Hub -- Recommended)‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/cis-lmu/GlotCC-V1.","url":"https://huggingface.co/datasets/cis-lmu/GlotCC-V1","creator_name":"CIS, LMU Munich","creator_url":"https://huggingface.co/cis-lmu","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["multilingual","Abau","Amarasi","Abkhaz","Abkhazian"],"keywords_longer_than_N":true},
	{"name":"GlotCC-V1","keyword":"dutch","description":"\n\t\n\t\t\n\t\tDataset Summary\n\t\n\n \n\nGlotCC-V1.0 is a document-level, general domain dataset derived from CommonCrawl, covering more than 1000 languages.It is built using the GlotLID language identification and Ungoliant pipeline from CommonCrawl.We release our pipeline as open-source at https://github.com/cisnlp/GlotCC.  \nList of Languages: See https://datasets-server.huggingface.co/splits?dataset=cis-lmu/GlotCC-V1 to get the list of splits available.\n\n\t\t\n\t\tUsage (Huggingface Hub -- Recommended)‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/cis-lmu/GlotCC-V1.","url":"https://huggingface.co/datasets/cis-lmu/GlotCC-V1","creator_name":"CIS, LMU Munich","creator_url":"https://huggingface.co/cis-lmu","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["multilingual","Abau","Amarasi","Abkhaz","Abkhazian"],"keywords_longer_than_N":true},
	{"name":"x_likes","keyword":"dutch","description":"cast42/x_likes dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/cast42/x_likes","creator_name":"Lode Nachtergaele","creator_url":"https://huggingface.co/cast42","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["English","Dutch","mit","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"mmarco-lt","keyword":"dutch","description":"\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis is a variation of mMARCO by Bonifacio et al. used for the \"Improving Low-Resource Retrieval Effectiveness using Zero-Shot Linguistic Similarity Transfer\" ECIR2025 paper. \nThe source code for the paper can be found here\nmMARCO is a multilingual version of the MS MARCO passage ranking dataset.\nFor more information, checkout the original mMARCO papers:\n\nmMARCO: A Multilingual Version of the MS MARCO Passage Ranking Dataset\nA cost-benefit analysis of cross-lingual‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/andreaschari/mmarco-lt.","url":"https://huggingface.co/datasets/andreaschari/mmarco-lt","creator_name":"Andreas Chari","creator_url":"https://huggingface.co/andreaschari","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["Catalan","Dutch","French","Afrikaans","Irish"],"keywords_longer_than_N":true},
	{"name":"reasoning-multilingual-R1-Llama-70B-train","keyword":"dutch","description":"\n\t\n\t\t\n\t\tlightblue/reasoning-multilingual-R1-Llama-70B-train\n\t\n\nThis is a multilingual reasoning dataset covering more than 30 languages.\nThis dataset was made by:\n\nSampling prompts from English datasets and translating them to various languages\nGenerating responses to these prompts 8 times using deepseek-ai/DeepSeek-R1-Distill-Llama-70B\nFiltering out <think> sections with incorrect language, non-fluent language, and incorrect answers\n\nThis dataset was then used to train a multilingual‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/lightblue/reasoning-multilingual-R1-Llama-70B-train.","url":"https://huggingface.co/datasets/lightblue/reasoning-multilingual-R1-Llama-70B-train","creator_name":"Lightblue KK.","creator_url":"https://huggingface.co/lightblue","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["Amharic","Arabic","Bengali","Chinese","Czech"],"keywords_longer_than_N":true},
	{"name":"quran","keyword":"dutch","description":"\n\t\n\t\t\n\t\tDataset Card for the Quran\n\t\n\n\n\t\n\t\t\n\t\tSummary\n\t\n\nThe Quran with metadata, translations, and multiple Arabic text (can use specific types for embeddings, search, classification, and display). There are 126+ columns containing 43+ languages.\n\n\t\n\t\t\n\t\tTODO\n\t\n\n\n Add Tafsirs  \n Add topics/ontology\n\n\n\t\n\t\t\n\t\tUsage\n\t\n\nfrom datasets import load_dataset\n\nds = load_dataset(\"nazimali/quran\", split=\"train\")\nds\n\nOutput:\nDataset({\n    features: ['surah', 'ayah', 'surah-name', 'surah-total-ayas'‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/nazimali/quran.","url":"https://huggingface.co/datasets/nazimali/quran","creator_name":"Nazim Ali","creator_url":"https://huggingface.co/nazimali","license_name":"Creative Commons Attribution 3.0","license_url":"https://scancode-licensedb.aboutcode.org/cc-by-3.0.html","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","translation","feature-extraction","text-generation"],"keywords_longer_than_N":true},
	{"name":"fineweb-2-dutch","keyword":"dutch","description":"ssmits/fineweb-2-dutch dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/ssmits/fineweb-2-dutch","creator_name":"S. Smits","creator_url":"https://huggingface.co/ssmits","license_name":"Open Data Commons Attribution License v1.0","license_url":"https://scancode-licensedb.aboutcode.org/odc-by-1.0.html","language":"en","first_N":5,"first_N_keywords":["text-generation","Dutch","odc-by","10M - 100M","parquet"],"keywords_longer_than_N":true},
	{"name":"aya_dataset","keyword":"dutch","description":"\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThe Aya Dataset is a multilingual instruction fine-tuning dataset curated by an open-science community via Aya Annotation Platform from Cohere Labs. The dataset contains a total of 204k human-annotated prompt-completion pairs along with the demographics data of the annotators.\nThis dataset can be used to train, finetune, and evaluate multilingual LLMs.\n\nCurated by: Contributors of Aya Open Science Intiative.\n\nLanguage(s): 65 languages (71 including dialects &‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/CohereLabs/aya_dataset.","url":"https://huggingface.co/datasets/CohereLabs/aya_dataset","creator_name":"Cohere Labs","creator_url":"https://huggingface.co/CohereLabs","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["other","crowdsourced","expert-generated","crowdsourced","expert-generated"],"keywords_longer_than_N":true},
	{"name":"fleurs_clean","keyword":"dutch","description":"\n\t\n\t\t\n\t\n\t\n\t\tFLEURS\n\t\n\nFleurs is the speech version of the FLoRes machine translation benchmark. \nWe use 2009 n-way parallel sentences from the FLoRes dev and devtest publicly available sets, in 102 languages. \nTraining sets have around 10 hours of supervision. Speakers of the train sets are different than speakers from the dev/test sets. Multilingual fine-tuning is\nused and ‚Äùunit error rate‚Äù (characters, signs) of all languages is averaged. Languages and results are also grouped into seven‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Helloworld668/fleurs_clean.","url":"https://huggingface.co/datasets/Helloworld668/fleurs_clean","creator_name":"zhide Tang","creator_url":"https://huggingface.co/Helloworld668","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","expert-generated","crowdsourced","machine-generated","crowdsourced"],"keywords_longer_than_N":true},
	{"name":"Web-multilingual","keyword":"dutch","description":"\n\t\n\t\t\n\t\tDataset Card for Dataset Name\n\t\n\nThis dataset contains 1,141 multilingual web pages.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\n Each page contains the visible text extracted from the page. Each page includes 2 or more languages, with 2 prominent languages. \n page.csv lists the 2 prominent for each page. The content of the page is found in the pages/ folder.\n The breakdown of languages is the following:\n   1705 en\n   1043 fr\n    336 zh\n     90 es\n     79 id\n     77 de\n     75 pt\n     40 it\n     34‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/MAximeSobrier/Web-multilingual.","url":"https://huggingface.co/datasets/MAximeSobrier/Web-multilingual","creator_name":"Maxime Sobrier","creator_url":"https://huggingface.co/MAximeSobrier","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","French","English","Chinese","Portuguese"],"keywords_longer_than_N":true},
	{"name":"multiblimp","keyword":"dutch","description":"\n\t\n\t\t\n\t\tMultiBLiMP\n\t\n\nMultiBLiMP is a massively Multilingual Benchmark for Linguistic Minimal Pairs. The dataset is composed of synthetic pairs generated using Universal Dependencies and UniMorph.\nThe paper can be found here.\nWe split the data set by language: each language consists of a single .tsv file. The rows contain many attributes for a particular pair, most important are the sen and wrong_sen fields, which we use for evaluating the language models.\n\n\t\n\t\t\n\t\n\t\n\t\tUsing MultiBLiMP\n\t\n\nTo‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/jumelet/multiblimp.","url":"https://huggingface.co/datasets/jumelet/multiblimp","creator_name":"Jaap Jumelet","creator_url":"https://huggingface.co/jumelet","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["multilingual","Buriat","Spanish","Sanskrit","Romanian"],"keywords_longer_than_N":true},
	{"name":"Multi-EuP","keyword":"dutch","description":"\n\t\n\t\t\n\t\tNOTES FOR DOWNLOAD!\n\t\n\n\nHighly recommend downloading it via the API:\n\ncurl -X GET \\\n     \"https://datasets-server.huggingface.co/first-rows?dataset=unimelb-nlp%2FMulti-EuP&config=default&split=full\"\n\n\nIf you are using the HuggingFace library, please follow these steps:\n\npip install datasets\n\nfrom datasets import load_dataset\n\ndataset = load_dataset(\"unimelb-nlp/Multi-EuP\", keep_default_na=False)\n\nNote: It's crucial to use keep_default_na=False because some datasets contain 'null'‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/unimelb-nlp/Multi-EuP.","url":"https://huggingface.co/datasets/unimelb-nlp/Multi-EuP","creator_name":"The University of Melbourne","creator_url":"https://huggingface.co/unimelb-nlp","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","English","German","French","Italian"],"keywords_longer_than_N":true},
	{"name":"oscar-mini","keyword":"dutch","description":"The Open Super-large Crawled ALMAnaCH coRpus is a huge multilingual corpus obtained by language classification and filtering of the Common Crawl corpus using the goclassy architecture.\\","url":"https://huggingface.co/datasets/nthngdy/oscar-mini","creator_name":"Nathan Godey","creator_url":"https://huggingface.co/nthngdy","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":null,"first_N":5,"first_N_keywords":["text-generation","language-modeling","no-annotation","found","multilingual"],"keywords_longer_than_N":true},
	{"name":"blbooks-parquet-embedded","keyword":"dutch","description":"\n\t\n\t\t\n\t\tDataset Card for \"blbooks-parquet-embedded\"\n\t\n\nMore Information needed\n","url":"https://huggingface.co/datasets/davanstrien/blbooks-parquet-embedded","creator_name":"Daniel van Strien","creator_url":"https://huggingface.co/davanstrien","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","fill-mask","other","language-modeling","masked-language-modeling"],"keywords_longer_than_N":true},
	{"name":"voxpopuli","keyword":"dutch","description":"A large-scale multilingual speech corpus for representation learning, semi-supervised learning and interpretation.","url":"https://huggingface.co/datasets/facebook/voxpopuli","creator_name":"AI at Meta","creator_url":"https://huggingface.co/facebook","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":null,"first_N":5,"first_N_keywords":["automatic-speech-recognition","multilingual","English","German","French"],"keywords_longer_than_N":true},
	{"name":"bnl_newspapers","keyword":"dutch","description":"\n\t\n\t\t\n\t\tDataset Card for BnL Historical Newspapers\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThe BnL has digitised over 800.000 pages of Luxembourg newspapers. This dataset currently has one configuration covering a subset of these newspapers, which sit under the \"Processed Datasets\" collection. The BNL:\n\nprocessed all newspapers and monographs that are in the public domain and extracted the full text and associated meta data of every single article, section, advertisement‚Ä¶ The result is a large number of‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/bnl-data/bnl_newspapers.","url":"https://huggingface.co/datasets/bnl-data/bnl_newspapers","creator_name":"BnL Open Data","creator_url":"https://huggingface.co/bnl-data","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","fill-mask","language-modeling","masked-language-modeling","no-annotation"],"keywords_longer_than_N":true},
	{"name":"para_crawl","keyword":"dutch","description":"\n\t\n\t\t\n\t\tDataset Card for \"para_crawl\"\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nWeb-Scale Parallel Corpora for Official European Languages.\n\n\t\n\t\t\n\t\tSupported Tasks and Leaderboards\n\t\n\nMore Information Needed\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nMore Information Needed\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\n\t\n\t\t\n\t\tData Instances\n\t\n\n\n\t\n\t\t\n\t\tenbg\n\t\n\n\nSize of downloaded dataset files: 103.75 MB\nSize of the generated dataset: 356.54 MB\nTotal amount of disk used: 460.27 MB\n\nAn example of 'train' looks as follows.\nThis example was too‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ParaCrawl/para_crawl.","url":"https://huggingface.co/datasets/ParaCrawl/para_crawl","creator_name":"ParaCrawl","creator_url":"https://huggingface.co/ParaCrawl","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":null,"first_N":5,"first_N_keywords":["translation","no-annotation","found","translation","original"],"keywords_longer_than_N":true},
	{"name":"PubMedCausal_Dutch_translated_with_MariaNMT","keyword":"dutch","description":"\n\t\n\t\t\n\t\tDataset Card for \"PubMedCausal_Dutch_translated_with_MariaNMT\"\n\t\n\nTranslation of the English version of PubMedCausal,\nto Dutch using an Maria NMT model, trained by Helsinki NLP.\nNote, for reference: Maria NMT is based on BART, described here.\n\n\t\n\t\t\n\t\n\t\n\t\tAttribution\n\t\n\nIf you use this dataset please use the following to credit the creators of the Health Advice corpus:\n@inproceedings{yu-etal-2019-detecting,\n    title = \"Detecting Causal Language Use in Science Findings\",\n    author =‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/UMCU/PubMedCausal_Dutch_translated_with_MariaNMT.","url":"https://huggingface.co/datasets/UMCU/PubMedCausal_Dutch_translated_with_MariaNMT","creator_name":"Bram van Es","creator_url":"https://huggingface.co/UMCU","license_name":"Academic Free License v3.0","license_url":"https://choosealicense.com/licenses/afl-3.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","question-answering","sentence-similarity","Dutch","afl-3.0"],"keywords_longer_than_N":true},
	{"name":"language_tags","keyword":"dutch","description":"\n\t\n\t\t\n\t\tDescription\n\t\n\nDataset listing 27,328 languages and dialects (also includes macrolanguage names).For each language, either the ISO 639 code, the Glottolog code or both are provided.\n\n\t\n\t\t\n\t\tColumns\n\t\n\n\nEnglish_Name: Language name in English (e.g. \"French\").\nNative_Name: If value is not 0, corresponds to the name of the language by native speakers (e.g. \"Fran√ßais\") which may have been found in Wikipedia's nativename field.\nGlottocode: The language tag in the Glottolog convention (e.g.‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/lbourdois/language_tags.","url":"https://huggingface.co/datasets/lbourdois/language_tags","creator_name":"Lo√Øck BOURDOIS","creator_url":"https://huggingface.co/lbourdois","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["Afade","Par√° Ar√°ra","Afar","Aka-Bea","Abon"],"keywords_longer_than_N":true},
	{"name":"fleurs","keyword":"dutch","description":"\n\t\n\t\t\n\t\tFLEURS\n\t\n\nFleurs is the speech version of the FLoRes machine translation benchmark. \nWe use 2009 n-way parallel sentences from the FLoRes dev and devtest publicly available sets, in 102 languages. \nTraining sets have around 10 hours of supervision. Speakers of the train sets are different than speakers from the dev/test sets. Multilingual fine-tuning is\nused and ‚Äùunit error rate‚Äù (characters, signs) of all languages is averaged. Languages and results are also grouped into seven‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/cahya/fleurs.","url":"https://huggingface.co/datasets/cahya/fleurs","creator_name":"Cahya Wirawan","creator_url":"https://huggingface.co/cahya","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":null,"first_N":5,"first_N_keywords":["automatic-speech-recognition","expert-generated","crowdsourced","machine-generated","crowdsourced"],"keywords_longer_than_N":true},
	{"name":"all-scam-spam","keyword":"dutch","description":"This is a large corpus of 42,619 preprocessed text messages and emails sent by humans in 43 languages. is_spam=1 means spam and is_spam=0 means ham.\n1040 rows of balanced data, consisting of casual conversations and scam emails in ‚âà10 languages, were manually collected and annotated by me, with some help from ChatGPT.\n\n\n\n\t\n\t\t\n\t\tSome preprcoessing algorithms\n\t\n\n\nspam_assassin.js, followed by spam_assassin.py\nenron_spam.py\n\n\n\n\n\t\n\t\t\n\t\tData composition\n\t\n\n\n\n\n\n\t\n\t\t\n\t\tDescription\n\t\n\nTo make the text‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/FredZhang7/all-scam-spam.","url":"https://huggingface.co/datasets/FredZhang7/all-scam-spam","creator_name":"Fred Zhang","creator_url":"https://huggingface.co/FredZhang7","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","zero-shot-classification","Norwegian","Spanish","Somali"],"keywords_longer_than_N":true},
	{"name":"oasst2_top1_chat_format","keyword":"dutch","description":"\n\t\n\t\t\n\t\tOpenAssistant TOP-1 Conversation Threads in huggingface chat format\n\t\n\nExport of oasst2 only top 1 threads in huggingface chat format\n\n\t\n\t\t\n\t\tScript\n\t\n\nThe convert script can be find here\n","url":"https://huggingface.co/datasets/blancsw/oasst2_top1_chat_format","creator_name":"Blanc Swan","creator_url":"https://huggingface.co/blancsw","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["English","Spanish","Russian","German","Polish"],"keywords_longer_than_N":true},
	{"name":"malicious-website-features-2.4M","keyword":"dutch","description":"Important Notice:\n\nA subset of the URL dataset is from Kaggle, and the Kaggle datasets contained 10%-15% mislabelled data. See this dicussion I opened for some false positives. I have contacted Kaggle regarding their erroneous \"Usability\" score calculation for these unreliable datasets.\nThe feature extraction methods shown here are not robust at all in 2023, and there're even silly mistakes in 3 functions: not_indexed_by_google, domain_registration_length, and age_of_domain.\n\n\n\nThe features‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/FredZhang7/malicious-website-features-2.4M.","url":"https://huggingface.co/datasets/FredZhang7/malicious-website-features-2.4M","creator_name":"Fred Zhang","creator_url":"https://huggingface.co/FredZhang7","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","feature-extraction","tabular-classification","Norwegian","Afrikaans"],"keywords_longer_than_N":true},
	{"name":"tatoeba","keyword":"dutch","description":"This is a collection of translated sentences from Tatoeba\n359 languages, 3,403 bitexts\ntotal number of files: 750\ntotal number of tokens: 65.54M\ntotal number of sentence fragments: 8.96M","url":"https://huggingface.co/datasets/Helsinki-NLP/tatoeba","creator_name":"Language Technology Research Group at the University of Helsinki","creator_url":"https://huggingface.co/Helsinki-NLP","license_name":"Creative Commons Attribution 2.0","license_url":"https://scancode-licensedb.aboutcode.org/cc-by-2.0.html","language":null,"first_N":5,"first_N_keywords":["translation","found","found","multilingual","original"],"keywords_longer_than_N":true},
	{"name":"MultiLegalPile_Wikipedia_Filtered","keyword":"dutch","description":"A filtered version of the MultiLegalPile dataset, together with wikipedia articles.","url":"https://huggingface.co/datasets/joelniklaus/MultiLegalPile_Wikipedia_Filtered","creator_name":"Joel Niklaus","creator_url":"https://huggingface.co/joelniklaus","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["fill-mask","other","found","multilingual","original"],"keywords_longer_than_N":true},
	{"name":"xcsr","keyword":"dutch","description":"\n\t\n\t\t\n\t\tDataset Card for X-CSR\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nTo evaluate multi-lingual language models (ML-LMs) for commonsense reasoning in a cross-lingual zero-shot transfer setting (X-CSR), i.e., training in English and test in other languages, we create two benchmark datasets, namely X-CSQA and X-CODAH. Specifically, we automatically translate the original CSQA and CODAH datasets, which only have English versions, to 15 other languages, forming development and test sets for studying X-CSR.‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/INK-USC/xcsr.","url":"https://huggingface.co/datasets/INK-USC/xcsr","creator_name":"INK Lab @ USC","creator_url":"https://huggingface.co/INK-USC","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["question-answering","multiple-choice-qa","crowdsourced","crowdsourced","machine-generated"],"keywords_longer_than_N":true},
	{"name":"ms_terms","keyword":"dutch","description":"The Microsoft Terminology Collection can be used to develop localized versions of applications that integrate with Microsoft products.\nIt can also be used to integrate Microsoft terminology into other terminology collections or serve as a base IT glossary\nfor language development in the nearly 100 languages available. Terminology is provided in .tbx format, an industry standard for terminology exchange.","url":"https://huggingface.co/datasets/microsoft/ms_terms","creator_name":"Microsoft","creator_url":"https://huggingface.co/microsoft","license_name":"Microsoft Public License","license_url":"https://choosealicense.com/licenses/ms-pl/","language":null,"first_N":5,"first_N_keywords":["translation","expert-generated","expert-generated","multilingual","translation"],"keywords_longer_than_N":true},
	{"name":"HealthAdvice_Dutch_translated_with_MariaNMT","keyword":"dutch","description":"\n\t\n\t\t\n\t\tDataset Card for \"HealthAdvice_Dutch_translated_with_MariaNMT\"\n\t\n\nTranslation of the English version of HealthAdvice,\nto Dutch using an Maria NMT model, trained by Helsinki NLP.\nNote, for reference: Maria NMT is based on BART, described here.\n\n\t\n\t\t\n\t\n\t\n\t\tAttribution\n\t\n\nIf you use this dataset please use the following to credit the creators of the Health Advice corpus:\n@inproceedings{yu-etal-2019-detecting,\n    title = \"Detecting Causal Language Use in Science Findings\",\n    author =‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/UMCU/HealthAdvice_Dutch_translated_with_MariaNMT.","url":"https://huggingface.co/datasets/UMCU/HealthAdvice_Dutch_translated_with_MariaNMT","creator_name":"Bram van Es","creator_url":"https://huggingface.co/UMCU","license_name":"Academic Free License v3.0","license_url":"https://choosealicense.com/licenses/afl-3.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","question-answering","sentence-similarity","Dutch","afl-3.0"],"keywords_longer_than_N":true},
	{"name":"MultiLegalPileWikipediaFiltered","keyword":"dutch","description":"A filtered version of the MultiLegalPile dataset, together with wikipedia articles.","url":"https://huggingface.co/datasets/joelniklaus/MultiLegalPileWikipediaFiltered","creator_name":"Joel Niklaus","creator_url":"https://huggingface.co/joelniklaus","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["fill-mask","other","found","multilingual","original"],"keywords_longer_than_N":true},
	{"name":"MultiCoNER","keyword":"dutch","description":"We present MultiCoNER, a large multilingual dataset for Named Entity Recognition that covers 3 domains (Wiki sentences, questions, and search queries) across 11 languages, as well as multilingual and code-mixing subsets. This dataset is designed to represent contemporary challenges in NER, including low-context scenarios (short and uncased text), syntactically complex entities like movie titles, and long-tail entity distributions. The 26M token dataset is compiled from public resources using techniques such as heuristic-based sentence sampling, template extraction and slotting, and machine translation. We applied two NER models on our dataset: a baseline XLM-RoBERTa model, and a state-of-the-art GEMNET model that leverages gazetteers. The baseline achieves moderate performance (macro-F1=54%), highlighting the difficulty of our data. GEMNET, which uses gazetteers, improvement significantly (average improvement of macro-F1=+30%). MultiCoNER poses challenges even for large pre-trained language models, and we believe that it can help further research in building robust NER systems. MultiCoNER is publicly available at https://registry.opendata.aws/multiconer/ and we hope that this resource will help advance research in various aspects of NER.","url":"https://huggingface.co/datasets/tomaarsen/MultiCoNER","creator_name":"Tom Aarsen","creator_url":"https://huggingface.co/tomaarsen","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["token-classification","Bengali","German","English","Spanish"],"keywords_longer_than_N":true},
	{"name":"bnl_newspapers1841-1879","keyword":"dutch","description":"\n\t\n\t\t\n\t\tDataset Card for BnL Newspapers 1841-1881\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\n592.192 articles from historical newspapers (1841-1881) along with metadata and the full text.\n21 newspaper titles\n24.415 newspaper issues\n99.957 scanned pages\nTranscribed using a variety of OCR engines and corrected using https://github.com/natliblux/nautilusocr (95% threshold)\nPublic Domain, CC0 (See copyright notice)\nThe newspapers used are:\n\nDer Arbeiter (1878-1881)\nL'Arlequin (1848-1848)\nL'Avenir (1868-1871)‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/biglam/bnl_newspapers1841-1879.","url":"https://huggingface.co/datasets/biglam/bnl_newspapers1841-1879","creator_name":"BigLAM: BigScience Libraries, Archives and Museums","creator_url":"https://huggingface.co/biglam","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","fill-mask","language-modeling","masked-language-modeling","no-annotation"],"keywords_longer_than_N":true},
	{"name":"common_voice_17_0","keyword":"dutch","description":"\n\t\n\t\t\n\t\tDataset Card for Common Voice Corpus 17.0\n\t\n\n\n\nThis dataset is an unofficial version of the Mozilla Common Voice Corpus 17. It was downloaded and converted from the project's website https://commonvoice.mozilla.org/.\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nAbkhaz, Albanian, Amharic, Arabic, Armenian, Assamese, Asturian, Azerbaijani, Basaa, Bashkir, Basque, Belarusian, Bengali, Breton, Bulgarian, Cantonese, Catalan, Central Kurdish, Chinese (China), Chinese (Hong Kong), Chinese (Taiwan), Chuvash, Czech‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/fsicoli/common_voice_17_0.","url":"https://huggingface.co/datasets/fsicoli/common_voice_17_0","creator_name":"Fabio Sicoli","creator_url":"https://huggingface.co/fsicoli","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":null,"first_N":5,"first_N_keywords":["automatic-speech-recognition","Abkhaz","Afrikaans","Amharic","Arabic"],"keywords_longer_than_N":true},
	{"name":"tulu-3-sft-olmo-2-mixture","keyword":"dutch","description":"Note that this collection is licensed under ODC-BY-1.0 license; different licenses apply to subsets of the data. Some portions of the dataset are non-commercial. We present the mixture as a research artifact.\nThe OLMo v2 SFT mixture was used to train the OLMo models.\nIt contains 939,344 samples from the following sets:\n\nCoCoNot (ODC-BY-1.0), 10,983 prompts (Brahman et al., 2024)\nFLAN v2 via ai2-adapt-dev/flan_v2_converted, 89,982 prompts (Longpre et al., 2023)\nNo Robots (CC-BY-NC-4.0), 9,500‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/allenai/tulu-3-sft-olmo-2-mixture.","url":"https://huggingface.co/datasets/allenai/tulu-3-sft-olmo-2-mixture","creator_name":"Ai2","creator_url":"https://huggingface.co/allenai","license_name":"Open Data Commons Attribution License v1.0","license_url":"https://scancode-licensedb.aboutcode.org/odc-by-1.0.html","language":"en","first_N":5,"first_N_keywords":["other","crowdsourced","expert-generated","machine-generated","multilingual"],"keywords_longer_than_N":true},
	{"name":"NeoBabel-Eval","keyword":"dutch","description":"\n\t\n\t\t\n\t\tOfficial Multilingual Evaluation Suite of NeoBabel\n\t\n\nThis repository contains the full evaluation datasets used for benchmarking multilingual text-to-image generation in NeoBabel. We release two benchmarks: m-GenEval and m-DPG, both provided as .zip archives.\n\n\t\n\t\t\n\t\tm-GenEval\n\t\n\nThis dataset is a multilingual extension of the original GenEval benchmark. Each English prompt from GenEval has been translated into five additional languages: Chinese, Dutch, French, Hindi, and Persian.Each‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mderakhshani/NeoBabel-Eval.","url":"https://huggingface.co/datasets/mderakhshani/NeoBabel-Eval","creator_name":"Mohammad Mahdi Derakhshani","creator_url":"https://huggingface.co/mderakhshani","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-to-image","English","Dutch","French","Persian"],"keywords_longer_than_N":true},
	{"name":"entity_cs","keyword":"dutch","description":"\n\t\n\t\t\n\t\tDataset Card for EntityCS\n\t\n\n\nRepository: https://github.com/huawei-noah/noah-research/tree/master/NLP/EntityCS  \nPaper: https://aclanthology.org/2022.findings-emnlp.499.pdf  \nPoint of Contact: Fenia Christopoulou, Chenxi Whitehouse\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Description\n\t\n\nWe use the English Wikipedia and leverage entity information from Wikidata to construct an entity-based Code Switching corpus. \nTo achieve this, we make use of wikilinks in Wikipedia, i.e. links from one page to another.‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/huawei-noah/entity_cs.","url":"https://huggingface.co/datasets/huawei-noah/entity_cs","creator_name":"HUAWEI Noah's Ark Lab","creator_url":"https://huggingface.co/huawei-noah","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["Afrikaans","Amharic","Arabic","Assamese","Azerbaijani"],"keywords_longer_than_N":true},
	{"name":"wiki_lingua","keyword":"dutch","description":"\n\t\n\t\t\n\t\tDataset Card for \"wiki_lingua\"\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nWe introduce WikiLingua, a large-scale, multilingual dataset for the evaluation of cross-lingual abstractive summarization systems. We extract article and summary pairs in 18 languages from WikiHow, a high quality, collaborative resource of how-to guides on a diverse set of topics written by human authors. We create gold-standard article-summary alignments across languages by aligning the images that are used to describe each‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/esdurmus/wiki_lingua.","url":"https://huggingface.co/datasets/esdurmus/wiki_lingua","creator_name":"Esin Durmus","creator_url":"https://huggingface.co/esdurmus","license_name":"Creative Commons Attribution 3.0","license_url":"https://scancode-licensedb.aboutcode.org/cc-by-3.0.html","language":"en","first_N":5,"first_N_keywords":["summarization","crowdsourced","crowdsourced","multilingual","original"],"keywords_longer_than_N":true},
	{"name":"common_language","keyword":"dutch","description":"This dataset is composed of speech recordings from languages that were carefully selected from the CommonVoice database.\nThe total duration of audio recordings is 45.1 hours (i.e., 1 hour of material for each language).\nThe dataset has been extracted from CommonVoice to train language-id systems.","url":"https://huggingface.co/datasets/speechbrain/common_language","creator_name":"SpeechBrain","creator_url":"https://huggingface.co/speechbrain","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":null,"first_N":5,"first_N_keywords":["audio-classification","speaker-identification","crowdsourced","crowdsourced","multilingual"],"keywords_longer_than_N":true},
	{"name":"DBNL-public","keyword":"dutch","description":"\n\t\n\t\t\n\t\tDigitale Bibliotheek voor de Nederlandse Letteren (DBNL) - Public Domain Corpus\n\t\n\nA subset of the DBNL (Digital Library for Dutch Literature) public domain collection of copyright-free literature.\n\n\t\n\t\t\n\t\tDataset Information\n\t\n\n\nSource: DBNL Publieke Katalogus\nBooks: See BOOKS.txt\n\n\n\t\n\t\t\n\t\tQuestion-Answering (QA)\n\t\n\nThe original text corpus of transformed into a QA-style dataset containing (near-)verbatim passages from the literature.\nThe QA dataset is generated using GPT-OSS 120B‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/nscharrenberg/DBNL-public.","url":"https://huggingface.co/datasets/nscharrenberg/DBNL-public","creator_name":"Noah","creator_url":"https://huggingface.co/nscharrenberg","license_name":"Public Domain Dedication & License","license_url":"https://scancode-licensedb.aboutcode.org/pddl-1.0.html","language":"en","first_N":5,"first_N_keywords":["Dutch","pddl","10K - 100K","parquet","Tabular"],"keywords_longer_than_N":true},
	{"name":"minigpt4-13b-ggml","keyword":"dutch","description":"These are quantized ggml binary files for minigpt4 13B model.\nThese files can be used in conjunction with vicuna v0 ggml models to get minigpt4 working.\nNot all implementations were tested. If there are any issues, use f16.\n","url":"https://huggingface.co/datasets/maknee/minigpt4-13b-ggml","creator_name":"maknee","creator_url":"https://huggingface.co/maknee","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":null,"first_N":5,"first_N_keywords":["English","Bulgarian","Catalan","Czech","Danish"],"keywords_longer_than_N":true},
	{"name":"openassistant-falcon","keyword":"dutch","description":"\n\t\n\t\t\n\t\tChat Fine-tuning Dataset - OpenAssistant Falcon\n\t\n\nThis dataset allows for fine-tuning chat models using '\\Human:' AND '\\nAssistant:' to wrap user messages.\nIt still uses <|endoftext|> as EOS and BOS token, as per Falcon.\nSample \nPreparation:\n\nThe dataset is cloned from TimDettmers, which itself is a subset of the Open Assistant dataset, which you can find here. This subset of the data only contains the highest-rated paths in the conversation tree, with a total of 9,846 samples.\nThe‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Trelis/openassistant-falcon.","url":"https://huggingface.co/datasets/Trelis/openassistant-falcon","creator_name":"Trelis","creator_url":"https://huggingface.co/Trelis","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["English","Spanish","Russian","German","Polish"],"keywords_longer_than_N":true},
	{"name":"minds14-mirror","keyword":"dutch","description":"MINDS-14 is training and evaluation resource for intent\ndetection task with spoken data. It covers 14\nintents extracted from a commercial system\nin the e-banking domain, associated with spoken examples in 14 diverse language varieties.","url":"https://huggingface.co/datasets/a6kme/minds14-mirror","creator_name":"Abhishek Kumar","creator_url":"https://huggingface.co/a6kme","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":null,"first_N":5,"first_N_keywords":["automatic-speech-recognition","keyword-spotting","expert-generated","crowdsourced","machine-generated"],"keywords_longer_than_N":true},
	{"name":"synthetic_pii_finance_multilingual","keyword":"dutch","description":"\n  \n  Image generated by DALL-E. See prompt for more details\n\n\n\n\t\n\t\t\n\t\tüíº üìä Synthetic Financial Domain Documents with PII Labels\n\t\n\ngretelai/synthetic_pii_finance_multilingual is a dataset of full length synthetic financial documents containing Personally Identifiable Information (PII), generated using Gretel Navigator and released under Apache 2.0.\nThis dataset is designed to assist with the following use cases:\n\nüè∑Ô∏è Training NER (Named Entity Recognition) models to detect and label PII in‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/gretelai/synthetic_pii_finance_multilingual.","url":"https://huggingface.co/datasets/gretelai/synthetic_pii_finance_multilingual","creator_name":"Gretel.ai","creator_url":"https://huggingface.co/gretelai","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","fill-mask","token-classification","English","French"],"keywords_longer_than_N":true},
	{"name":"oasst1","keyword":"dutch","description":"\n\t\n\t\t\n\t\tOpenAssistant Conversations Dataset (OASST1)\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nIn an effort to democratize research on large-scale alignment, we release OpenAssistant \nConversations (OASST1), a human-generated, human-annotated assistant-style conversation \ncorpus consisting of 161,443 messages in 35 different languages, annotated with 461,292 \nquality ratings, resulting in over 10,000 fully annotated conversation trees. The corpus \nis a product of a worldwide crowd-sourcing effort‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/OpenAssistant/oasst1.","url":"https://huggingface.co/datasets/OpenAssistant/oasst1","creator_name":"OpenAssistant","creator_url":"https://huggingface.co/OpenAssistant","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["English","Spanish","Russian","German","Polish"],"keywords_longer_than_N":true},
	{"name":"ultrachat_200k_dutch","keyword":"dutch","description":"\n\t\n\t\t\n\t\tDataset Card for UltraChat 200k Dutch\n\t\n\n\n\t\n\t\t\n\t\tCitation\n\t\n\nIf you use this dataset, GEITje 7B Ultra (SFT) or any of its derivatives or quantizations, place cite the following paper:\n@misc{vanroy2024geitje7bultraconversational,\n      title={GEITje 7B Ultra: A Conversational Model for Dutch}, \n      author={Bram Vanroy},\n      year={2024},\n      eprint={2412.04092},\n      archivePrefix={arXiv},\n      primaryClass={cs.CL},\n      url={https://arxiv.org/abs/2412.04092}, \n}‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/BramVanroy/ultrachat_200k_dutch.","url":"https://huggingface.co/datasets/BramVanroy/ultrachat_200k_dutch","creator_name":"Bram Vanroy","creator_url":"https://huggingface.co/BramVanroy","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","Dutch","apache-2.0","100K - 1M","parquet"],"keywords_longer_than_N":true},
	{"name":"ACAData","keyword":"dutch","description":"\n\t\n\t\t\n\t\tDataset Card for ACAData\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nACAData is a multilingual instruction tuning dataset containing parallel text paragraphs from the academic domain.\n\n\t\n\t\t\n\t\tSupported Tasks and Leaderboards\n\t\n\nThe dataset is meant to be used for fine-tuning and benchmarking general purpose LLM's on Machine Translation tasks.\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nThe dataset contains (mainly long) paragraph of scientific texts from the academic domain in many European language pairs.\nThe language‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/BSC-LT/ACAData.","url":"https://huggingface.co/datasets/BSC-LT/ACAData","creator_name":"Language Technologies Laboratory @ Barcelona Supercomputing Center","creator_url":"https://huggingface.co/BSC-LT","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["translation","Spanish","English","Catalan","Portuguese"],"keywords_longer_than_N":true},
	{"name":"FineWeb2-HQ","keyword":"dutch","description":"\n\t\n\t\t\n\t\tFineWeb2-HQ\n\t\n\n\n\t\n\t\t\n\t\tDataset summary\n\t\n\nFineWeb2-HQ is a high-quality, model-filtered pretraining dataset derived as a subset of FineWeb2, spanning 20 languages. It enables around 6x faster pretraining compared to the base dataset. FineWeb2-HQ was created by selecting the top 10% quality documents of FineWeb2 in each language, based on scores assigned by a deep learning classifier trained to identify structured and knowledge-rich samples using XLM-RoBERTa embeddings.\n\n  \n\n\nValidation‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/epfml/FineWeb2-HQ.","url":"https://huggingface.co/datasets/epfml/FineWeb2-HQ","creator_name":"EPFL Machine Learning and Optimization Laboratory","creator_url":"https://huggingface.co/epfml","license_name":"Open Data Commons Attribution License v1.0","license_url":"https://scancode-licensedb.aboutcode.org/odc-by-1.0.html","language":"en","first_N":5,"first_N_keywords":["text-generation","Russian","Chinese","German","Japanese"],"keywords_longer_than_N":true},
	{"name":"mteb-nl-vabb","keyword":"dutch","description":"This dataset is based on the VABB dataset, the Flemish Academic Bibliography for the Social Sciences and Humanities.\n\n\t\n\t\t\n\t\tCitation Information\n\t\n\nIf you find our paper, benchmark or models helpful, please consider cite as follows:\n@misc{banar2025mtebnle5nlembeddingbenchmark,\n      title={MTEB-NL and E5-NL: Embedding Benchmark and Models for Dutch}, \n      author={Nikolay Banar and Ehsan Lotfi and Jens Van Nooten and Cristina Arhiliuc and Marija Kliocaite and Walter Daelemans}‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/clips/mteb-nl-vabb.","url":"https://huggingface.co/datasets/clips/mteb-nl-vabb","creator_name":"CLiPS","creator_url":"https://huggingface.co/clips","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["Dutch","cc-by-4.0","10K - 100K","parquet","Text"],"keywords_longer_than_N":true},
	{"name":"FineWeb2-embedded","keyword":"dutch","description":"\n\t\n\t\t\n\t\tFineWeb2-embedded\n\t\n\n\n\t\n\t\t\n\t\tDataset summary\n\t\n\nFineWeb2-embedded is an extension of the FineWeb2 dataset, annotated with document-level XLM-RoBERTa embeddings for 20 languages, making the dataset useful for a variety of tasks, including document clustering, filtering, and other multilingual research.\nSince XLM-RoBERTa has a sequence length limit of 512 tokens, each document's embeddings are obtained by mean-pooling 512 token chunks of the XLM-RoBERTa output. Therefore, longer texts‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/epfml/FineWeb2-embedded.","url":"https://huggingface.co/datasets/epfml/FineWeb2-embedded","creator_name":"EPFL Machine Learning and Optimization Laboratory","creator_url":"https://huggingface.co/epfml","license_name":"Open Data Commons Attribution License v1.0","license_url":"https://scancode-licensedb.aboutcode.org/odc-by-1.0.html","language":"en","first_N":5,"first_N_keywords":["text-generation","Russian","Chinese","German","Japanese"],"keywords_longer_than_N":true},
	{"name":"HPLT2.0_cleaned","keyword":"dutch","description":"This is a large-scale collection of web-crawled documents in 191 world languages, produced by the HPLT project. \nThe source of the data is mostly Internet Archive with some additions from Common Crawl.\nFor a detailed description of the dataset, please refer to our website and our pre-print.\n\n\t\n\t\t\n\t\n\t\n\t\tThe Cleaned variant of HPLT Datasets v2.0\n\t\n\nThis is the cleaned variant of the HPLT Datasets v2.0 converted to the Parquet format semi-automatically when being uploaded here. \nThe original‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/HPLT/HPLT2.0_cleaned.","url":"https://huggingface.co/datasets/HPLT/HPLT2.0_cleaned","creator_name":"HPLT","creator_url":"https://huggingface.co/HPLT","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["fill-mask","text-generation","language-modeling","multilingual","Achinese"],"keywords_longer_than_N":true},
	{"name":"DATA-AI_Chat","keyword":"dutch","description":"\n\t\n\t\t\n\t\tDATA-AI: Il Modello di IA di M.INC.\n\t\n\n\n\t\n\t\t\n\t\tüìå Introduzione\n\t\n\nDATA-AI √® un avanzato modello di intelligenza artificiale sviluppato da *M.INC., un'azienda italiana fondata da *Mattimax (M. Marzorati).Questo modello √® basato sull'architettura ELNS (Elaborazione del Linguaggio Naturale Semplice), un sistema innovativo progettato per rendere l'IA accessibile su quasi qualsiasi dispositivo, garantendo prestazioni ottimali anche su hardware limitato.  \nDATA-AI √® stato addestrato su un‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Mattimax/DATA-AI_Chat.","url":"https://huggingface.co/datasets/Mattimax/DATA-AI_Chat","creator_name":"M.INC.","creator_url":"https://huggingface.co/Mattimax","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["Italian","English","Spanish","Russian","German"],"keywords_longer_than_N":true},
	{"name":"mteb-nl-COVID-19-disinformation","keyword":"dutch","description":"This dataset contains Dutch tweets that were annotated for fine-grained disinformation analysis.\n\n\t\n\t\t\n\t\tCitation Information\n\t\n\nIf you find our paper, benchmark or models helpful, please consider cite as follows:\n@misc{banar2025mtebnle5nlembeddingbenchmark,\n      title={MTEB-NL and E5-NL: Embedding Benchmark and Models for Dutch}, \n      author={Nikolay Banar and Ehsan Lotfi and Jens Van Nooten and Cristina Arhiliuc and Marija Kliocaite and Walter Daelemans},\n      year={2025}‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/clips/mteb-nl-COVID-19-disinformation.","url":"https://huggingface.co/datasets/clips/mteb-nl-COVID-19-disinformation","creator_name":"CLiPS","creator_url":"https://huggingface.co/clips","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["Dutch","cc-by-4.0","1K - 10K","parquet","Text"],"keywords_longer_than_N":true},
	{"name":"multicultural-wvs-alignment","keyword":"dutch","description":"\n\t\n\t\t\n\t\tDataset Card: Multicultural WVS Alignment\n\t\n\nThis document is based on \"Datasheets for Datasets\" by Gebru et al. (arXiv:1803.09010). Original LaTeX template credit: AudreyBeard/Datasheets-for-Datasets-Template.\n\n\t\n\t\t\n\t\tModels Evaluated\n\t\n\n\n\t\n\t\t\nModel Name\nModel Family\n\n\n\t\t\nOLMo-2-0325-32B-Instruct\nolmo\n\n\nOLMo-2-1124-13B-Instruct\nolmo\n\n\nOLMo-2-1124-7B-Instruct\nolmo\n\n\ngemma-2-27b-it\ngemma\n\n\ngemma-2-2b-it\ngemma\n\n\ngemma-2-9b-it\ngemma\n\n\ngpt-3.5-turbo-0125\nopenai\n\n\ngpt-4-turbo-2024-04-09‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ryzzlestrizzle/multicultural-wvs-alignment.","url":"https://huggingface.co/datasets/ryzzlestrizzle/multicultural-wvs-alignment","creator_name":"Jonathan Rystr√∏m","creator_url":"https://huggingface.co/ryzzlestrizzle","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","Danish","Portuguese","Dutch","English"],"keywords_longer_than_N":true},
	{"name":"EmoTalk-7","keyword":"dutch","description":"\n\t\n\t\t\n\t\tEmoTalk-7\n\t\n\nEmoTalk-7 is a large-scale, multilingual, synthetic multimodal emotion recognition dataset generated using the Mistral API. It covers 7 major European languages and contains realistic social media scenarios with comprehensive emotion analysis, visual descriptions, and cultural context annotations.\n\n\t\n\t\t\n\t\tüìù Dataset Summary\n\t\n\nEmoTalk-7 contains 1400+ multimodal emotion records with high-quality annotations. It is designed to simulate authentic social media content across‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/NoeFlandre/EmoTalk-7.","url":"https://huggingface.co/datasets/NoeFlandre/EmoTalk-7","creator_name":"No√© Flandre","creator_url":"https://huggingface.co/NoeFlandre","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","English","French","Spanish","German"],"keywords_longer_than_N":true},
	{"name":"SciFact-NL","keyword":"dutch","description":"\n  SciFact-NL\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nSciFactNL verifies scientific claims in Dutch using evidence from the research literature containing scientific paper abstracts.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2t\n\n\nDomains\nAcademic, Medical, Written\nReference\nhttps://huggingface.co/datasets/clips/beir-nl-scifact\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask =‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/SciFact-NL.","url":"https://huggingface.co/datasets/mteb/SciFact-NL","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","derived","translated","mteb/scifact","Dutch"],"keywords_longer_than_N":true},
	{"name":"wim-instruct-signaalberichten-to-jsonld-agent-steps","keyword":"dutch","description":"\n\t\n\t\t\n\t\tDataset Card for UWV/wim_instruct_signaalberichten_to_jsonld_agent_steps\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset contains 116,056 instruction-following examples from a production pipeline that converts Dutch municipality complaint messages (signaalberichten) into structured JSON-LD knowledge graphs using Schema.org vocabulary. Each example represents an atomic LLM call from a 4-stage agent pipeline designed to extract semantic information from citizen-government communications.\nThe‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/UWV/wim-instruct-signaalberichten-to-jsonld-agent-steps.","url":"https://huggingface.co/datasets/UWV/wim-instruct-signaalberichten-to-jsonld-agent-steps","creator_name":"UWV","creator_url":"https://huggingface.co/UWV","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["Dutch","apache-2.0","100K - 1M","parquet","Text"],"keywords_longer_than_N":true},
	{"name":"reranker_continuous_filt_max7_train","keyword":"dutch","description":"\n\t\n\t\t\n\t\tReranker training data\n\t\n\nThis data was generated using 4 steps:\n\nWe gathered queries and corresponding text data from 35 high quality datasets covering more than 95 languages.\nFor datasets which did not already have negative texts for queries, we mined hard negatives using the BAAI/bge-m3 embedding model.\nFor each query, we selected one positive and one negative text and used Qwen/Qwen2.5-32B-Instruct-GPTQ-Int4 to rate the relatedness of each query-text pair using a token \"1\", \"2\"‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/lightblue/reranker_continuous_filt_max7_train.","url":"https://huggingface.co/datasets/lightblue/reranker_continuous_filt_max7_train","creator_name":"Lightblue KK.","creator_url":"https://huggingface.co/lightblue","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["English","Chinese","Spanish","German","Arabic"],"keywords_longer_than_N":true},
	{"name":"NFCorpus-NL","keyword":"dutch","description":"\n  NFCorpus-NL\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nNFCorpus: A Full-Text Learning to Rank Dataset for Medical Information Retrieval. NFCorpus-NL is a Dutch translation.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2t\n\n\nDomains\nMedical, Academic, Written\n\nReference\nhttps://huggingface.co/datasets/clips/beir-nl-nfcorpus\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask = mteb.get_tasks([\"NFCorpus-NL\"])‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/NFCorpus-NL.","url":"https://huggingface.co/datasets/mteb/NFCorpus-NL","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","derived","translated","mteb/nfcorpus","Dutch"],"keywords_longer_than_N":true},
	{"name":"eng_montok","keyword":"dutch","description":"\n\t\n\t\t\n\t\tMonTok: A Suite of Monolingual Tokenizers\n\t\n\nThis is a set of monolingual tokenizers for 98 languages. For each language, there are Unigram, BPE, and SuperBPE tokenizers, ranging in vocabulary size from around 6k to over 200k.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\n","url":"https://huggingface.co/datasets/catherinearnett/eng_montok","creator_name":"Catherine Arnett","creator_url":"https://huggingface.co/catherinearnett","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["Afrikaans","Tosk Albanian","Amharic","Standard Arabic","Assamese"],"keywords_longer_than_N":true},
	{"name":"ipa-childes-split","keyword":"dutch","description":"\n\t\n\t\t\n\t\tIPA-CHILDES split\n\t\n\nThis dataset is a postprocessed version of the IPA-CHILDES dataset. In particular,\nthe following changes have been implemented:\n\ncolumn processed_gloss dropped as it duplicates information of gloss up to punctuation\ncolumn gloss renamed as sentence, and column ipa_transcription renamed as ipa_g2p_plus (cf. G2P+)\ncolumn lang added to make IETF language tags accessible for training and inference; language tags normalized by the langcodes package\ncolumns ipa_espeak‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/fdemelo/ipa-childes-split.","url":"https://huggingface.co/datasets/fdemelo/ipa-childes-split","creator_name":"Fl√°vio Eler De Melo","creator_url":"https://huggingface.co/fdemelo","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["Catalan","Welsh","Danish","German","English"],"keywords_longer_than_N":true},
	{"name":"multilingual-speech-commands-15lang-zip","keyword":"dutch","description":"\n\t\n\t\t\n\t\tMultilingual Speech Commands Dataset (15 Languages, Augmented)\n\t\n\nThis dataset contains augmented speech command samples in 15 languages, derived from multiple public datasets. Only commands that overlap with the Google Speech Commands (GSC) vocabulary are included, making the dataset suitable for multilingual keyword spotting tasks aligned with GSC-style classification.\nAudio samples have been augmented using standard audio techniques to improve model robustness (e.g., time-shifting‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/artur-muratov/multilingual-speech-commands-15lang-zip.","url":"https://huggingface.co/datasets/artur-muratov/multilingual-speech-commands-15lang-zip","creator_name":"Artur Muratov","creator_url":"https://huggingface.co/artur-muratov","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["English","Russian","Kazakh","Tatar","Arabic"],"keywords_longer_than_N":true},
	{"name":"Everything_Instruct_Multilingual","keyword":"dutch","description":"\n\t\n\t\t\n\t\tEverything Instruct (Multilingual Edition)\n\t\n\nEverything you need... all in one place üíò\n\nEverything instruct (Multilingual Edition) is a massive alpaca instruct formatted dataset consisting of a wide variety of topics meant to bring LLM's to the next level in open source AI.\nNote: This dataset is fully uncensored (No model will refuse any request trained on this dataset unless otherwise aligned)\nNote2: This version of the dataset supports the following languages:\n\nEnglish\nRussian‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/rombodawg/Everything_Instruct_Multilingual.","url":"https://huggingface.co/datasets/rombodawg/Everything_Instruct_Multilingual","creator_name":"rombo dawg","creator_url":"https://huggingface.co/rombodawg","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["English","Russian","Chinese","Korean","Urdu"],"keywords_longer_than_N":true},
	{"name":"multivsr","keyword":"dutch","description":"\n\t\n\t\t\n\t\tDataset: MultiVSR\n\t\n\nWe introduce a large-scale multilingual lip-reading dataset: MultiVSR. The dataset comprises a total of 12,000 hours of video footage, covering English + 12 non-English languages. MultiVSR is a massive dataset with a huge diversity in terms of the speakers as well as languages, with approximately 1.6M video clips across 123K YouTube videos. Please check the website for samples.\n\n  \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDownload instructions\n\t\n\nPlease check the GitHub repo to download‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/sindhuhegde/multivsr.","url":"https://huggingface.co/datasets/sindhuhegde/multivsr","creator_name":"Sindhu Hegde","creator_url":"https://huggingface.co/sindhuhegde","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["English","French","German","Spanish","Italian"],"keywords_longer_than_N":true},
	{"name":"beir-nl-mmarco","keyword":"dutch","description":"\n\t\n\t\t\n\t\tDataset Card for BEIR-NL Benchmark\n\t\n\nBEIR-NL is a Dutch-translated version of the BEIR benchmark, a diverse and heterogeneous collection of datasets covering various domains from biomedical and financial texts to general web content. Our benchmark is integrated into the Massive Multilingual Text Embedding Benchmark (MMTEB).\n\n\t\n\t\t\n\t\tSource Data\n\t\n\nmMarco repository on GitHub.\n\n\t\n\t\t\n\t\tAdditional Information\n\t\n\n\n\t\n\t\t\n\t\tLicensing Information\n\t\n\nThis dataset is licensed under the Apache‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/clips/beir-nl-mmarco.","url":"https://huggingface.co/datasets/clips/beir-nl-mmarco","creator_name":"CLiPS","creator_url":"https://huggingface.co/clips","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","Dutch","apache-2.0","1M - 10M","json"],"keywords_longer_than_N":true},
	{"name":"finepdfs-summaries","keyword":"dutch","description":"\n\t\n\t\t\n\t\tfinepdfs-summaries\n\t\n\nSummaries generated with Qwen3-Next-80B-A3B-Instruct for documents from finepdfs.\nWork in progress, still generating more data.\nThe following table shows the data available for each language:\n\n\t\n\t\t\nLanguage\nSummaries\nTokens\nDisk size\n\n\n\t\t\nAll\n838,268,819\n247 B\n366 GB\n\n\ndeu_Latn\n363,671,069\n113 B\n149 GB\n\n\neng_Latn\n353,969,370\n89 B\n162 GB\nfra_Latn\n27,308,302\n10 B\n14 GB\n\n\nspa_Latn\n25,624,727\n9 B\n12 GB\n\n\nita_Latn\n17,587,618\n6 B\n8 GB\n\n\npor_Latn\n12,043,607\n4 B\n5 GB‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/MultiSynt/finepdfs-summaries.","url":"https://huggingface.co/datasets/MultiSynt/finepdfs-summaries","creator_name":"MultiSynt","creator_url":"https://huggingface.co/MultiSynt","license_name":"Open Data Commons Attribution License v1.0","license_url":"https://scancode-licensedb.aboutcode.org/odc-by-1.0.html","language":"en","first_N":5,"first_N_keywords":["text-generation","summarization","English","German","French"],"keywords_longer_than_N":true},
	{"name":"PleIAs-ToxicCommons","keyword":"dutch","description":"\n\t\n\t\t\n\t\tPleIAs/ToxicCommons\n\t\n\nThis dataset is a refined version of the PleIAs/ToxicCommons collection, focusing on historical texts labeled for content that may be considered objectionable by modern standards (what the authors of the dataset deem \"toxic\"). \nThe cleaned dataset contains 1‚Äâ051‚Äâ027 rows, each representing a text sample with associated toxicity scores across five dimensions:\n\nRace and origin-based bias\nGender and sexuality-based bias\nReligious bias\nAbility bias\nViolence and abuse‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/agentlans/PleIAs-ToxicCommons.","url":"https://huggingface.co/datasets/agentlans/PleIAs-ToxicCommons","creator_name":"Alan Tseng","creator_url":"https://huggingface.co/agentlans","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","English","French","Spanish","German"],"keywords_longer_than_N":true},
	{"name":"synthetic_multilingual_llm_prompts","keyword":"dutch","description":"\n  \n  Image generated by DALL-E. See prompt for more details\n\n\n\n\t\n\t\t\n\t\tüìùüåê Synthetic Multilingual LLM Prompts\n\t\n\nWelcome to the \"Synthetic Multilingual LLM Prompts\" dataset! This comprehensive collection features 1,250 synthetic LLM prompts generated using Gretel Navigator, available in seven different languages. To ensure accuracy and diversity in prompts, and translation quality and consistency across the different languages, we employed Gretel Navigator both as a generation tool and as an‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/gretelai/synthetic_multilingual_llm_prompts.","url":"https://huggingface.co/datasets/gretelai/synthetic_multilingual_llm_prompts","creator_name":"Gretel.ai","creator_url":"https://huggingface.co/gretelai","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","translation","question-answering","English","Dutch"],"keywords_longer_than_N":true},
	{"name":"apollo_english_guidelines_translated_to_dutch_with_geminiflash1.5","keyword":"dutch","description":"Translation of the English medical guidelines that are part of the Apollo corpus, using the LLM Gemini Flash 1.5","url":"https://huggingface.co/datasets/UMCU/apollo_english_guidelines_translated_to_dutch_with_geminiflash1.5","creator_name":"Bram van Es","creator_url":"https://huggingface.co/UMCU","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["Dutch","apache-2.0","10K - 100K","json","Tabular"],"keywords_longer_than_N":true},
	{"name":"apollo_english_guidelines_translated_to_dutch_with_geminiflash1.5","keyword":"dutch","description":"Translation of the English medical guidelines that are part of the Apollo corpus, using the LLM Gemini Flash 1.5","url":"https://huggingface.co/datasets/UMCU/apollo_english_guidelines_translated_to_dutch_with_geminiflash1.5","creator_name":"Bram van Es","creator_url":"https://huggingface.co/UMCU","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["Dutch","apache-2.0","10K - 100K","json","Tabular"],"keywords_longer_than_N":true},
	{"name":"X-ALMA-Preference","keyword":"dutch","description":"This is the translation preference dataset used by X-ALMA.\nsource: the source sentence.\nchosen: the preferred translation.\nreject: the dis-preferred translation.\ndirections: the translation direction.\n@misc{xu2024xalmaplugplay,\n      title={X-ALMA: Plug & Play Modules and Adaptive Rejection for Quality Translation at Scale}, \n      author={Haoran Xu and Kenton Murray and Philipp Koehn and Hieu Hoang and Akiko Eriguchi and Huda Khayrallah},\n      year={2024},\n      eprint={2410.03115}‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/haoranxu/X-ALMA-Preference.","url":"https://huggingface.co/datasets/haoranxu/X-ALMA-Preference","creator_name":"Haoran Xu","creator_url":"https://huggingface.co/haoranxu","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["English","Danish","Dutch","German","Icelandic"],"keywords_longer_than_N":true},
	{"name":"multilingual_translation_gpt4o_gen","keyword":"dutch","description":"Youseff1987/multilingual_translation_gpt4o_gen dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/Youseff1987/multilingual_translation_gpt4o_gen","creator_name":"JOON HYOUNG JUN","creator_url":"https://huggingface.co/Youseff1987","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["translation","Korean","English","Chinese","Zulu"],"keywords_longer_than_N":true},
	{"name":"flemish","keyword":"dutch","description":"\n\t\n\t\t\n\t\tFlemish Dataset\n\t\n\nThe vocabulary foundation is organized by linguistic categories (pronouns, verbs, nouns, adjectives) with over 200 core Flemish words.\n\n\t\n\t\t\n\t\tData Types\n\t\n\n\nsynthetic: 280,000 examples (35.0%)\npattern: 160,000 examples (20.0%)\nconversation: 120,000 examples (15.0%)\nqa: 96,000 examples (12.0%)\ntranslation: 64,000 examples (8.0%)\ngrammar: 40,000 examples (5.0%)\ndefinition: 18,000 examples (2.2%)\nstory: 12,000 examples (1.5%)\nculture: 6,000 examples (0.8%)\nproverb: 4‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/0xnu/flemish.","url":"https://huggingface.co/datasets/0xnu/flemish","creator_name":"Finbarrs Oketunji","creator_url":"https://huggingface.co/0xnu","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["Dutch","apache-2.0","1M - 10M","parquet","Tabular"],"keywords_longer_than_N":true},
	{"name":"m-ArenaHard","keyword":"dutch","description":"\n\t\n\t\t\n\t\tDataset Card for m-ArenaHard\n\t\n\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\nThe m-ArenaHard dataset is a multilingual LLM evaluation set. This dataset was created by translating the prompts from the originally English-only LMarena (formerly LMSYS) arena-hard-auto-v0.1 test dataset using Google Translate API v3 to 22 languages. The original English-only prompts were created by Li et al. (2024) and consist of 500 challenging user queries sourced from Chatbot Arena. The authors show that these can be used‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/CohereLabs/m-ArenaHard.","url":"https://huggingface.co/datasets/CohereLabs/m-ArenaHard","creator_name":"Cohere Labs","creator_url":"https://huggingface.co/CohereLabs","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["English","French","German","Spanish","Italian"],"keywords_longer_than_N":true},
	{"name":"JQL-LLM-Edu-Annotations","keyword":"dutch","description":"\n\t\n\t\t\n\t\tüìö JQL Educational Quality Annotations from LLMs\n\t\n\nThis dataset provides 17,186,606 documents with high-quality LLM annotations for evaluating the educational value of web documents, and serves as a benchmark for training and evaluating multilingual LLM annotators as described in the JQL paper.\n\n\n\t\n\t\t\n\t\tüìù Dataset Summary\n\t\n\n  Multilingual document-level quality annotations scored on a 0‚Äì5 educational value scale by three state-of-the-art LLMs:\n  Gemma-3-27B-it, Mistral-3.1-24B-it‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/JQL-AI/JQL-LLM-Edu-Annotations.","url":"https://huggingface.co/datasets/JQL-AI/JQL-LLM-Edu-Annotations","creator_name":"JQL-AI","creator_url":"https://huggingface.co/JQL-AI","license_name":"Open Data Commons Attribution License v1.0","license_url":"https://scancode-licensedb.aboutcode.org/odc-by-1.0.html","language":"en","first_N":5,"first_N_keywords":["Bulgarian","Czech","Croatian","Macedonian","Polish"],"keywords_longer_than_N":true},
	{"name":"OGC_Renewable_Regulation","keyword":"dutch","description":"\n\t\n\t\t\n\t\tOGC_Renewable_Regulation - Overview\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nOGC_Renewable_Regulation is a curated multimodal dataset focused on renewable energy technical documents, regulations, and legal frameworks. It combines text and image data extracted from real scientific and regulatory PDFs to support tasks such as RAG DSE, question answering, document search, and vision-language model training.\n\n\t\n\t\t\n\t\tDataset Creation\n\t\n\nThis dataset was created using our open-source tool‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/racineai/OGC_Renewable_Regulation.","url":"https://huggingface.co/datasets/racineai/OGC_Renewable_Regulation","creator_name":"racine.ai","creator_url":"https://huggingface.co/racineai","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["question-answering","visual-question-answering","text-retrieval","English","French"],"keywords_longer_than_N":true},
	{"name":"apollo_english_guidelines_translated_to_dutch_with_gpt4omini","keyword":"dutch","description":"Translation of the English medical guidelines that are part of the Apollo corpus, using the LLM GPT 4o mini","url":"https://huggingface.co/datasets/UMCU/apollo_english_guidelines_translated_to_dutch_with_gpt4omini","creator_name":"Bram van Es","creator_url":"https://huggingface.co/UMCU","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["Dutch","apache-2.0","10K - 100K","json","Tabular"],"keywords_longer_than_N":true},
	{"name":"apollo_english_guidelines_translated_to_dutch_with_gpt4omini","keyword":"dutch","description":"Translation of the English medical guidelines that are part of the Apollo corpus, using the LLM GPT 4o mini","url":"https://huggingface.co/datasets/UMCU/apollo_english_guidelines_translated_to_dutch_with_gpt4omini","creator_name":"Bram van Es","creator_url":"https://huggingface.co/UMCU","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["Dutch","apache-2.0","10K - 100K","json","Tabular"],"keywords_longer_than_N":true},
	{"name":"aya_collection","keyword":"dutch","description":"\nThis dataset is uploaded in two places: here and additionally here as 'Aya Collection Language Split.' These datasets are identical in content but differ in structure of upload. This dataset is structured by folders split according to dataset name. The version here instead divides the Aya collection into folders split by language. We recommend you use the language split version if you are only interested in downloading data for a single or smaller set of languages, and this version if you‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/CohereLabs/aya_collection.","url":"https://huggingface.co/datasets/CohereLabs/aya_collection","creator_name":"Cohere Labs","creator_url":"https://huggingface.co/CohereLabs","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","summarization","translation","Achinese","Afrikaans"],"keywords_longer_than_N":true},
	{"name":"mHumanEval-Benchmark","keyword":"dutch","description":"\n\n\n\t\n\t\t\n\t\tüî∑ Accepted in NAACL Proceedings (2025) üî∑\n\t\n\n\n\n\n\n  \n    \n      \n        \n          \n        \n      \n      \n        \n          \n        \n      \n      \n        \n          \n        \n      \n    \n  \n\n\n\n\n\n  \n\n\t\n\t\n\t\n\t\tmHumanEval\n\t\n\nThe mHumanEval benchmark is curated based on prompts from the original HumanEval üìö [Chen et al., 2021]. It includes a total of 33,456 prompts for Python, and 836,400 in total - significantly expanding from the original 164. \n\n\n\t\n\t\t\n\t\tQuick Start\n\t\n\n  Detailed‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/md-nishat-008/mHumanEval-Benchmark.","url":"https://huggingface.co/datasets/md-nishat-008/mHumanEval-Benchmark","creator_name":"Nishat Raihan","creator_url":"https://huggingface.co/md-nishat-008","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["Afar","Abkhaz","Avestan","Afrikaans","Akan"],"keywords_longer_than_N":true},
	{"name":"biblenlp-corpus-mmteb","keyword":"dutch","description":"This dataset pre-computes all English-centric directions from bible-nlp/biblenlp-corpus, and as a result loading is significantly faster.\nLoading example:\n>>> from datasets import load_dataset\n>>> dataset = load_dataset(\"davidstap/biblenlp-corpus-mmteb\", \"eng-arb\", trust_remote_code=True)\n>>> dataset\nDatasetDict({\n    train: Dataset({\n        features: ['eng', 'arb'],\n        num_rows: 28723\n    })\n    validation: Dataset({\n        features: ['eng', 'arb'],\n        num_rows: 1578\n    })‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/davidstap/biblenlp-corpus-mmteb.","url":"https://huggingface.co/datasets/davidstap/biblenlp-corpus-mmteb","creator_name":"David Stap","creator_url":"https://huggingface.co/davidstap","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["no-annotation","expert-generated","translation","multilingual","Arifama-Miniafia"],"keywords_longer_than_N":true},
	{"name":"biblenlp-corpus-mmteb","keyword":"dutch","description":"This dataset pre-computes all English-centric directions from bible-nlp/biblenlp-corpus, and as a result loading is significantly faster.\nLoading example:\n>>> from datasets import load_dataset\n>>> dataset = load_dataset(\"davidstap/biblenlp-corpus-mmteb\", \"eng-arb\", trust_remote_code=True)\n>>> dataset\nDatasetDict({\n    train: Dataset({\n        features: ['eng', 'arb'],\n        num_rows: 28723\n    })\n    validation: Dataset({\n        features: ['eng', 'arb'],\n        num_rows: 1578\n    })‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/davidstap/biblenlp-corpus-mmteb.","url":"https://huggingface.co/datasets/davidstap/biblenlp-corpus-mmteb","creator_name":"David Stap","creator_url":"https://huggingface.co/davidstap","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["no-annotation","expert-generated","translation","multilingual","Arifama-Miniafia"],"keywords_longer_than_N":true},
	{"name":"toxi-text-3M","keyword":"dutch","description":"This is a large multilingual toxicity dataset with 3M rows of text data from 55 natural languages, all of which are written/sent by humans, not machine translation models.\nThe preprocessed training data alone consists of 2,880,667 rows of comments, tweets, and messages. Among these rows, 416,529 are classified as toxic, while the remaining 2,463,773 are considered neutral. Below is a table to illustrate the data composition:\n\n\t\n\t\t\n\nToxic\nNeutral\nTotal\n\n\n\t\t\nmultilingual-train-deduplicated.csv‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/FredZhang7/toxi-text-3M.","url":"https://huggingface.co/datasets/FredZhang7/toxi-text-3M","creator_name":"Fred Zhang","creator_url":"https://huggingface.co/FredZhang7","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","zero-shot-classification","Arabic","Spanish","Panjabi"],"keywords_longer_than_N":true},
	{"name":"BTTM-Sentences","keyword":"dutch","description":"This dataset is work in progress. Its goal is to contain a lot of sentences, which will be translated later for my other dataset.\n","url":"https://huggingface.co/datasets/BasToTheMax/BTTM-Sentences","creator_name":"Basho","creator_url":"https://huggingface.co/BasToTheMax","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-generation","Dutch","English","mit","< 1K"],"keywords_longer_than_N":true},
	{"name":"muri-it","keyword":"dutch","description":"\n\t\n\t\t\n\t\tMURI-IT: Multilingual Instruction Tuning Dataset for 200 Languages via Multilingual Reverse Instructions\n\t\n\nMURI-IT is a large-scale multilingual instruction tuning dataset containing 2.2 million instruction-output pairs across 200 languages. It is designed to address the challenges of instruction tuning in low-resource languages with Multilingual Reverse Instructions (MURI), which ensures that the output is human-written, high-quality, and authentic to the cultural and linguistic‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/akoksal/muri-it.","url":"https://huggingface.co/datasets/akoksal/muri-it","creator_name":"Abdullatif Koksal","creator_url":"https://huggingface.co/akoksal","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text2text-generation","text-generation","question-answering","summarization","Achinese"],"keywords_longer_than_N":true},
	{"name":"cml-tts-filtered-annotated","keyword":"dutch","description":"\n\t\n\t\t\n\t\tDataset Card for Filtred and annotated CML TTS\n\t\n\nThis dataset is an annotated and filtred version of a CML-TTS [1]. \nCML-TTS [1] CML-TTS is a recursive acronym for CML-Multi-Lingual-TTS, a Text-to-Speech (TTS) dataset developed at the Center of Excellence in Artificial Intelligence (CEIA) of the Federal University of Goias (UFG). CML-TTS is a dataset comprising audiobooks sourced from the public domain books of Project Gutenberg, read by volunteers from the LibriVox project. The‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/PHBJT/cml-tts-filtered-annotated.","url":"https://huggingface.co/datasets/PHBJT/cml-tts-filtered-annotated","creator_name":"Paul Henri Biojout","creator_url":"https://huggingface.co/PHBJT","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-to-speech","French","German","Italian","Spanish"],"keywords_longer_than_N":true},
	{"name":"PolyGuardMix","keyword":"dutch","description":"\n\t\n\t\t\n\t\tPolyGuard: A Multilingual Safety Moderation Tool for 17 Languages\n\t\n\nAbstract: Truly multilingual safety moderation efforts for Large Language Models (LLMs) have been hindered by a narrow focus on a small set of languages (e.g., English, Chinese) as well as a limited scope of safety definition, resulting in significant gaps in moderation capabilities. To bridge these gaps, we release PolyGuard, a new state-of-the-art multilingual safety model for safeguarding LLM generations, and the‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ToxicityPrompts/PolyGuardMix.","url":"https://huggingface.co/datasets/ToxicityPrompts/PolyGuardMix","creator_name":"ToxicityPrompts","creator_url":"https://huggingface.co/ToxicityPrompts","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["Arabic","Chinese","Czech","Dutch","English"],"keywords_longer_than_N":true},
	{"name":"moniteur-belge","keyword":"dutch","description":"\n\t\n\t\t\n\t\tDataset Description\n\t\n\n\n\nThe most up to date data can be found here: https://huggingface.co/datasets/guust-franssens/belgian-journal\nDue to the different languages in Belgium, I decided to create three datasets belgian-journal/moniteur-belge/belgisch-staatsblad in order to make it more visible.\nDataset contains the metadata + the text of bylaw publications of Belgian companies on the Belgian Journal (Moniteur Belge/Belgisch Staatstblad).\nThis data was collected by webscraping the‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/guust-franssens/moniteur-belge.","url":"https://huggingface.co/datasets/guust-franssens/moniteur-belge","creator_name":"Guust Franssens","creator_url":"https://huggingface.co/guust-franssens","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","French","Dutch","German","cc0-1.0"],"keywords_longer_than_N":true},
	{"name":"FineNews-unfiltered","keyword":"dutch","description":"\n\t\n\t\t\n\t\tFineNews\n\t\n\nWIP. Like FineWeb, but built from Common Crawl News instead of main web.\nFor languages not listed as a split, check the data/ directory.\nFor now, it contains the 2024-05 (May),-04 (April),-03 (March) dumps.\nThis is the unfiltered version, with only URL filtering applied.\n\n\t\n\t\t\n\t\tSome initial stats\n\t\n\nTotal number of documents: 35M\n\n\t\n\t\t\nDump\nNumber of docs\nDisk size (compressed)\n\n\n\t\t\nCC-NEWS-2024-05\n11_715_084\n11G\n\n\nCC-NEWS-2024-04\n11_546_298\n11G\n\n\nCC-NEWS-2024-03‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/maxidl/FineNews-unfiltered.","url":"https://huggingface.co/datasets/maxidl/FineNews-unfiltered","creator_name":"Max Idahl","creator_url":"https://huggingface.co/maxidl","license_name":"Open Data Commons Attribution License v1.0","license_url":"https://scancode-licensedb.aboutcode.org/odc-by-1.0.html","language":"en","first_N":5,"first_N_keywords":["text-generation","English","German","French","Polish"],"keywords_longer_than_N":true},
	{"name":"ParaNames","keyword":"dutch","description":"\n\t\n\t\t\n\t\n\t\n\t\tDataset Card for Dataset Name\n\t\n\n\n\nThis dataset card aims to be a base template for new datasets. It has been generated using this raw template.\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Description\n\t\n\n\n\n\n\n\nCurated by: [More Information Needed]\nFunded by [optional]: [More Information Needed]\nShared by [optional]: [More Information Needed]\nLanguage(s) (NLP): [More Information Needed]\nLicense: [More Information Needed]\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Sources [optional]‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/bltlab/ParaNames.","url":"https://huggingface.co/datasets/bltlab/ParaNames","creator_name":"Broadening Linguistic Technologies Lab (BLT Lab)","creator_url":"https://huggingface.co/bltlab","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["token-classification","Nias","Kotava","Banjar","Angika"],"keywords_longer_than_N":true},
	{"name":"xP3x-Kongo","keyword":"dutch","description":"\n\t\n\t\t\n\t\tDataset Card for xP3x Kikongo Focus\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\n\nxP3x (Crosslingual Public Pool of Prompts eXtended) is a collection of prompts & datasets across 277 languages & 16 NLP tasks. It contains all of xP3 + much more! It is used for training future contenders of mT0 & BLOOMZ at project Aya @C4AI üß°\n\n\nCreation: The dataset can be recreated using instructions available here together with the file in this repository named xp3x_create.py. We provide this version to save‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Svngoku/xP3x-Kongo.","url":"https://huggingface.co/datasets/Svngoku/xP3x-Kongo","creator_name":"NIONGOLO Chrys F√©-Marty","creator_url":"https://huggingface.co/Svngoku","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["other","translation","expert-generated","crowdsourced","multilingual"],"keywords_longer_than_N":true},
	{"name":"blimp-nl","keyword":"dutch","description":"\n\t\n\t\t\n\t\tBLiMP-NL: Dutch BLIMP\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nBLiMP-NL is a dataset of Dutch linguistic minimal pairs for evaluating language models' syntactic knowledge. It contains minimal pairs for 22 grammatical phenomena in Dutch, further divided into 84 paradigms.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nThe dataset contains minimal pairs of grammatical and ungrammatical sentences in Dutch, organized into subsets testing various linguistic phenomena. Each minimal pair tests a specific grammatical‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/juletxara/blimp-nl.","url":"https://huggingface.co/datasets/juletxara/blimp-nl","creator_name":"Julen Etxaniz","creator_url":"https://huggingface.co/juletxara","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["Dutch","cc-by-4.0","1K - 10K","parquet","Text"],"keywords_longer_than_N":true},
	{"name":"voices-of-civilizations","keyword":"dutch","description":"\n\t\n\t\t\n\t\tVoices of Civilizations (VoC)\n\t\n\nVoices of Civilizations (VoC) is the first multilingual QA benchmark designed to assess audio LLMs‚Äô cultural comprehension using full-length music recordings. VoC spans:\n\n38 languages üá∏üá¶ Arabic (ar), üáßüá© Bengali (bn), üáßüá¨ Bulgarian (bg), üá®üá≥ Chinese (zh), üá≠üá∑ Croatian (hr), üá®üáø Czech (cs), üá©üá∞ Danish (da), üá≥üá± Dutch (nl), üá¨üáß English (en), üá™üá™ Estonian (et), üá´üáÆ Finnish (fi), üá´üá∑ French (fr), üá©üá™ German (de), üá¨üá∑ Greek (el), üáÆüá± Hebrew‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/sander-wood/voices-of-civilizations.","url":"https://huggingface.co/datasets/sander-wood/voices-of-civilizations","creator_name":"Shangda Wu (Sander Wood)","creator_url":"https://huggingface.co/sander-wood","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["question-answering","Arabic","Bengali","Bulgarian","Chinese"],"keywords_longer_than_N":true},
	{"name":"wikipedia-citation-index","keyword":"dutch","description":"Dataset with citation indexes as of 1 August 2024 for 47 million Wikipedia articles in 55 language versions. Research: ArXiv\n","url":"https://huggingface.co/datasets/lewoniewski/wikipedia-citation-index","creator_name":"W≈Çodzimierz Lewoniewski","creator_url":"https://huggingface.co/lewoniewski","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["Arabic","Azerbaijani","Belarusian","Bulgarian","Catalan"],"keywords_longer_than_N":true},
	{"name":"dutch-court-cases-rechtspraak","keyword":"dutch","description":"\n\t\n\t\t\n\t\tUitspraken Rechtspraak.nl (Open Data from the Dutch Judiciary)\n\t\n\nThis dataset contains a large collection of Dutch court rulings (uitspraken), sourced from the official open data REST API provided by the Raad voor de Rechtspraak (Council for the Judiciary).\nIt includes approximately 800,000 full-text court decisions across various legal domains ‚Äî civil, criminal, administrative, and others.\nThe dataset is currently being uploaded and will subsequently be updated daily via automated‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/vGassen/dutch-court-cases-rechtspraak.","url":"https://huggingface.co/datasets/vGassen/dutch-court-cases-rechtspraak","creator_name":"Ernst van Gassen","creator_url":"https://huggingface.co/vGassen","license_name":"Public Domain Dedication & License","license_url":"https://scancode-licensedb.aboutcode.org/pddl-1.0.html","language":"en","first_N":5,"first_N_keywords":["Dutch","pddl","1K - 10K","parquet","Text"],"keywords_longer_than_N":true},
	{"name":"dutch-central-exam-mcq","keyword":"dutch","description":"Multiple Choice Questions of the Dutch Central Exam 1999-2024\n\nImportant Note\n\nPer 01 Apr. 2025: This data is now split accordingly to the benchmark test sets of:\nhttps://huggingface.co/datasets/CohereForAI/include-base-44\nhttps://huggingface.co/datasets/CohereForAI/include-lite-44\nAny question that appears in the development or test set of the INCLUDE benchmark are now in a separate split. \nWe put both the base and lite questions in one test split.\nWe suggest using the INCLUDE benchmark for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/jjzha/dutch-central-exam-mcq.","url":"https://huggingface.co/datasets/jjzha/dutch-central-exam-mcq","creator_name":"Mike Zhang","creator_url":"https://huggingface.co/jjzha","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["multiple-choice","Dutch","cc-by-4.0","1K - 10K","parquet"],"keywords_longer_than_N":true},
	{"name":"thinking-multilingual-30-23-small-690","keyword":"dutch","description":"\nBased on OPENO1 math, this is a translated dataset of 30 high quality questions & answers in 23 languages. \nOr use the \"big\" version: big 10k rows version\n","url":"https://huggingface.co/datasets/Pinkstack/thinking-multilingual-30-23-small-690","creator_name":"Pinkstack","creator_url":"https://huggingface.co/Pinkstack","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","Arabic","Chinese","Czech","Danish"],"keywords_longer_than_N":true},
	{"name":"multilingual-speech-commands-15lang","keyword":"dutch","description":"\n\t\n\t\t\n\t\tMultilingual Speech Commands Dataset (15 Languages, Augmented)\n\t\n\nThis dataset contains augmented speech command samples in 15 languages, derived from multiple public datasets. Only commands that overlap with the Google Speech Commands (GSC) vocabulary are included, making the dataset suitable for multilingual keyword spotting tasks aligned with GSC-style classification.\nAudio samples have been augmented using standard audio techniques to improve model robustness (e.g., time-shifting‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/artur-muratov/multilingual-speech-commands-15lang.","url":"https://huggingface.co/datasets/artur-muratov/multilingual-speech-commands-15lang","creator_name":"Artur Muratov","creator_url":"https://huggingface.co/artur-muratov","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["English","Russian","Kazakh","Tatar","Arabic"],"keywords_longer_than_N":true},
	{"name":"AyaVisionBench","keyword":"dutch","description":"\n\t\n\t\t\n\t\tDataset Card for Aya Vision Benchmark\n\t\n\n\n\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\nThe Aya Vision Benchmark is designed to evaluate vision-language models in real-world multilingual scenarios. It spans 23 languages and 9 distinct task categories, with 15 samples per category, resulting in 135 image-question pairs per language. \nEach question requires visual context for the answer and covers languages that half of the world's population speaks, making this dataset particularly suited for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/CohereLabs/AyaVisionBench.","url":"https://huggingface.co/datasets/CohereLabs/AyaVisionBench","creator_name":"Cohere Labs","creator_url":"https://huggingface.co/CohereLabs","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["English","French","German","Spanish","Italian"],"keywords_longer_than_N":true},
	{"name":"include-base-44","keyword":"dutch","description":"\n\t\n\t\t\n\t\tINCLUDE-base (44 languages)\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\n\n\nPaper: http://arxiv.org/abs/2411.19799\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nINCLUDE is a comprehensive knowledge- and reasoning-centric benchmark across 44 languages that evaluates multilingual LLMs for performance in the actual language environments where they would be deployed. \nIt contains 22,637 4-option multiple-choice-questions (MCQ) extracted from academic and professional exams, covering 57 topics, including regional‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/CohereLabs/include-base-44.","url":"https://huggingface.co/datasets/CohereLabs/include-base-44","creator_name":"Cohere Labs","creator_url":"https://huggingface.co/CohereLabs","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["multiple-choice","Albanian","Arabic","Armenian","Azerbaijani"],"keywords_longer_than_N":true},
	{"name":"cvss","keyword":"dutch","description":"CVSS is a massively multilingual-to-English speech-to-speech translation corpus,\ncovering sentence-level parallel speech-to-speech translation pairs from 21\nlanguages into English.","url":"https://huggingface.co/datasets/google/cvss","creator_name":"Google","creator_url":"https://huggingface.co/google","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":null,"first_N":5,"first_N_keywords":["English","Arabic","Catalan","Welsh","German"],"keywords_longer_than_N":true},
	{"name":"Pornhub","keyword":"dutch","description":"\n\t\n\t\t\n\t\tPornhub Dataset\n\t\n\nThe Pornhub Dataset provides a comprehensive collection of data sourced from pornhub.com, encompassing various details from MANYYY videos available on the platform.\nThe file consists of 742.133 lines of videos.\n\n\t\n\t\t\n\t\tData Description\n\t\n\n\nDelimiter: ‚ÄΩ\nFile Format: CSV\nContent:\nURL: The URL of the video.\nCategory: The genre or category of the video.\nUser: The username of the uploader.\nVideo_title: The title of the video.\nViews: The number of views the video has‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Nikity/Pornhub.","url":"https://huggingface.co/datasets/Nikity/Pornhub","creator_name":"Nikita","creator_url":"https://huggingface.co/Nikity","license_name":"Open Data Commons Attribution License v1.0","license_url":"https://scancode-licensedb.aboutcode.org/odc-by-1.0.html","language":"en","first_N":5,"first_N_keywords":["Albanian","Arabic","Bengali","Bulgarian","Chinese"],"keywords_longer_than_N":true},
	{"name":"xtreme","keyword":"dutch","description":"\n\t\n\t\t\n\t\tDataset Card for \"xtreme\"\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThe Cross-lingual Natural Language Inference (XNLI) corpus is a crowd-sourced collection of 5,000 test and\n2,500 dev pairs for the MultiNLI corpus. The pairs are annotated with textual entailment and translated into\n14 languages: French, Spanish, German, Greek, Bulgarian, Russian, Turkish, Arabic, Vietnamese, Thai, Chinese,\nHindi, Swahili and Urdu. This results in 112.5k annotated pairs. Each premise can be associated with the‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/google/xtreme.","url":"https://huggingface.co/datasets/google/xtreme","creator_name":"Google","creator_url":"https://huggingface.co/google","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["multiple-choice","question-answering","token-classification","text-classification","text-retrieval"],"keywords_longer_than_N":true},
	{"name":"imdb-dutch-instruct","keyword":"dutch","description":"\n\t\n\t\t\n\t\tDataset Card for \"imdb-dutch-instruct\"\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe original IMBD dataset was translated to Dutch with yhavinga/ul2-large-en-nl.\nThen, the dataset is converted to an instruct-style dataset with the following templates:\nThe instruction templates:\n\"Is deze recensie positief of negatief?\",\n\"Wat is het sentiment van de recensie?\", \n\"Wat voor toon heeft de volgende recensie?\", \n\"Met wat voor sentiment zou je deze recensie beoordelen?\"\n\nThe target templates:\n\"De‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/jjzha/imdb-dutch-instruct.","url":"https://huggingface.co/datasets/jjzha/imdb-dutch-instruct","creator_name":"Mike Zhang","creator_url":"https://huggingface.co/jjzha","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["Dutch","apache-2.0","10K - 100K","json","Text"],"keywords_longer_than_N":true},
	{"name":"gutenberg_multilang","keyword":"dutch","description":"\n\t\n\t\t\n\t\tDataset Card for Project Gutenber - Multilanguage eBooks\n\t\n\nA collection of non-english language eBooks (7907, about 75-80% of all the ES, DE, FR, NL, IT, PT, HU books available on the site) from the Project Gutenberg site with metadata removed. \nOriginally colected for https://github.com/LAION-AI/Open-Assistant\n\n\t\n\t\t\nLANG\nEBOOKS\n\n\n\t\t\nES\n717\n\n\nDE\n1735\n\n\nFR\n2863\n\n\nNL\n904\n\n\nIT\n692\n\n\nPT\n501\n\n\nHU\n495\n\n\n\t\n\nThe METADATA column contains catalogue meta information on each book as a serialized‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/sedthh/gutenberg_multilang.","url":"https://huggingface.co/datasets/sedthh/gutenberg_multilang","creator_name":"Richard Nagyfi","creator_url":"https://huggingface.co/sedthh","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-generation","Spanish","German","French","Dutch"],"keywords_longer_than_N":true},
	{"name":"tatoeba_mt","keyword":"dutch","description":"The Tatoeba Translation Challenge is a multilingual data set of\nmachine translation benchmarks derived from user-contributed\ntranslations collected by [Tatoeba.org](https://tatoeba.org/) and\nprovided as parallel corpus from [OPUS](https://opus.nlpl.eu/). This\ndataset includes test and development data sorted by language pair. It\nincludes test sets for hundreds of language pairs and is continuously\nupdated. Please, check the version number tag to refer to the release\nthat your are using.","url":"https://huggingface.co/datasets/Helsinki-NLP/tatoeba_mt","creator_name":"Language Technology Research Group at the University of Helsinki","creator_url":"https://huggingface.co/Helsinki-NLP","license_name":"Creative Commons Attribution 2.0","license_url":"https://scancode-licensedb.aboutcode.org/cc-by-2.0.html","language":null,"first_N":5,"first_N_keywords":["text-generation","translation","no-annotation","crowdsourced","translation"],"keywords_longer_than_N":true},
	{"name":"multilexnorm","keyword":"dutch","description":"For this task, participants are asked to develop a system that performs lexical normalization: the conversion of non-canonical texts to their canonical equivalent form. In particular, this task includes data from 12 languages.","url":"https://huggingface.co/datasets/larrylawl/multilexnorm","creator_name":"Law Ann Liat Larry","creator_url":"https://huggingface.co/larrylawl","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":null,"first_N":5,"first_N_keywords":["text-generation","English","Danish","German","Spanish"],"keywords_longer_than_N":true},
	{"name":"common_voice_16_0","keyword":"dutch","description":"\n\t\n\t\t\n\t\tDataset Card for Common Voice Corpus 16.0\n\t\n\n\n\nThis dataset is an unofficial version of the Mozilla Common Voice Corpus 16. It was downloaded and converted from the project's website https://commonvoice.mozilla.org/.\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nAbkhaz, Albanian, Amharic, Arabic, Armenian, Assamese, Asturian, Azerbaijani, Basaa, Bashkir, Basque, Belarusian, Bengali, Breton, Bulgarian, Cantonese, Catalan, Central Kurdish, Chinese (China), Chinese (Hong Kong), Chinese (Taiwan), Chuvash, Czech‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/fsicoli/common_voice_16_0.","url":"https://huggingface.co/datasets/fsicoli/common_voice_16_0","creator_name":"Fabio Sicoli","creator_url":"https://huggingface.co/fsicoli","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":null,"first_N":5,"first_N_keywords":["automatic-speech-recognition","Abkhaz","Afrikaans","Amharic","Arabic"],"keywords_longer_than_N":true},
	{"name":"stackoverflow-chat-dutch","keyword":"dutch","description":"\n\t\n\t\t\n\t\tDataset Card for Stack Overflow Chat Dutch\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset contains 56,964 conversations between een AI assistant and a (fake) \"Human\" (generated) in Dutch, specifically in the domain of programming (Stack Overflow). They are translations of Baize's machine-generated answers to the Stack Overflow dataset. \n‚òï Want to help me out? Translating the data with the OpenAI API, and prompt testing, cost me üí∏$133.60üí∏. If you like this dataset, please consider buying‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/BramVanroy/stackoverflow-chat-dutch.","url":"https://huggingface.co/datasets/BramVanroy/stackoverflow-chat-dutch","creator_name":"Bram Vanroy","creator_url":"https://huggingface.co/BramVanroy","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["question-answering","text-generation","Dutch","apache-2.0","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"mc4_nl_cleaned","keyword":"dutch","description":"A thoroughly cleaned version of the Dutch portion of the multilingual \ncolossal, cleaned version of Common Crawl's web crawl corpus (mC4) by AllenAI.\n\nBased on Common Crawl dataset: \"https://commoncrawl.org\".\n\nThis is the processed version of Google's mC4 dataset by AllenAI, with further cleaning\ndetailed in the repository README file.","url":"https://huggingface.co/datasets/yhavinga/mc4_nl_cleaned","creator_name":"Yeb Havinga","creator_url":"https://huggingface.co/yhavinga","license_name":"Open Data Commons Attribution License v1.0","license_url":"https://scancode-licensedb.aboutcode.org/odc-by-1.0.html","language":null,"first_N":5,"first_N_keywords":["text-generation","language-modeling","no-annotation","found","monolingual"],"keywords_longer_than_N":true},
	{"name":"openassistant-deepseek-coder","keyword":"dutch","description":"\n\t\n\t\t\n\t\tChat Fine-tuning Dataset - OpenAssistant DeepSeek Coder\n\t\n\nThis dataset allows for fine-tuning chat models using:\nB_INST = '\\n### Instruction:\\n'\nE_INST = '\\n### Response:\\n'\nBOS = '<ÔΩúbegin‚ñÅof‚ñÅsentenceÔΩú>'\nEOS = '\\n<|EOT|>\\n'\n\nSample Preparation:\n\nThe dataset is cloned from TimDettmers, which itself is a subset of the Open Assistant dataset, which you can find here. This subset of the data only contains the highest-rated paths in the conversation tree, with a total of 9,846 samples.\nThe‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Trelis/openassistant-deepseek-coder.","url":"https://huggingface.co/datasets/Trelis/openassistant-deepseek-coder","creator_name":"Trelis","creator_url":"https://huggingface.co/Trelis","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["English","Spanish","Russian","German","Polish"],"keywords_longer_than_N":true},
	{"name":"xtreme_s","keyword":"dutch","description":"XTREME-S covers four task families: speech recognition, classification, speech-to-text translation and retrieval. Covering 102\nlanguages from 10+ language families, 3 different domains and 4\ntask families, XTREME-S aims to simplify multilingual speech\nrepresentation evaluation, as well as catalyze research in ‚Äúuniversal‚Äù speech representation learning.","url":"https://huggingface.co/datasets/google/xtreme_s","creator_name":"Google","creator_url":"https://huggingface.co/google","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":null,"first_N":5,"first_N_keywords":["automatic-speech-recognition","expert-generated","crowdsourced","machine-generated","crowdsourced"],"keywords_longer_than_N":true},
	{"name":"super_eurlex","keyword":"dutch","description":"Super-EURLEX dataset containing legal documents from multiple languages.\n                The datasets are build/scrapped from the EURLEX Website [https://eur-lex.europa.eu/homepage.html]\n                With one split per language and sector, because the available features (metadata) differs for each \n                sector. Therefore, each sample contains the content of a full legal document in up to 3 different \n                formats. Those are raw HTML and cleaned HTML (if the HTML format was available on the EURLEX website \n                during the scrapping process) and cleaned text.\n                The cleaned text should be available for each sample and was extracted from HTML or PDF.\n                'Cleaned' HTML stands here for minor cleaning that was done to preserve to a large extent the necessary \n                HTML information like table structures while removing unnecessary complexity which was introduced to the \n                original documents due to actions like writing each sentence into a new object. \n                Additionally, each sample contains metadata which was scrapped on the fly, this implies the following \n                2 things. First, not every sector contains the same metadata. Second, most metadata might be \n                irrelevant for most use cases. \n                In our minds the most interesting metadata is the celex-id which is used to identify the legal \n                document at hand, but also contains a lot of information about the document \n                see [https://eur-lex.europa.eu/content/tools/eur-lex-celex-infographic-A3.pdf] as well as eurovoc-\n                concepts, which are labels that define the content of the documents. \n                Eurovoc-Concepts are, for example, only available for the sectors 1, 2, 3, 4, 5, 6, 9, C, and E.\n                The Naming of most metadata is kept like it was on the eurlex website, except for converting \n                it to lower case and replacing whitespaces with '_'.","url":"https://huggingface.co/datasets/ddrg/super_eurlex","creator_name":"Dresden Database Research Group","creator_url":"https://huggingface.co/ddrg","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":null,"first_N":5,"first_N_keywords":["text-classification","fill-mask","multi-class-classification","multi-label-classification","found"],"keywords_longer_than_N":true},
	{"name":"oscar-small","keyword":"dutch","description":"The Open Super-large Crawled ALMAnaCH coRpus is a huge multilingual corpus obtained by language classification and filtering of the Common Crawl corpus using the goclassy architecture.\\","url":"https://huggingface.co/datasets/djstrong/oscar-small","creator_name":"Krzysztof Wr√≥bel","creator_url":"https://huggingface.co/djstrong","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","language-modeling","no-annotation","found","multilingual"],"keywords_longer_than_N":true},
	{"name":"oscar-small","keyword":"dutch","description":"The Open Super-large Crawled ALMAnaCH coRpus is a huge multilingual corpus obtained by language classification and filtering of the Common Crawl corpus using the goclassy architecture.\\","url":"https://huggingface.co/datasets/nthngdy/oscar-small","creator_name":"Nathan Godey","creator_url":"https://huggingface.co/nthngdy","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","language-modeling","no-annotation","found","multilingual"],"keywords_longer_than_N":true},
	{"name":"multilingual-pl-bert","keyword":"dutch","description":"Attribution: Wikipedia.org\n","url":"https://huggingface.co/datasets/styletts2-community/multilingual-pl-bert","creator_name":"StyleTTS 2 Community","creator_url":"https://huggingface.co/styletts2-community","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["Afrikaans","Aragonese","Arabic","Azerbaijani","Bashkir"],"keywords_longer_than_N":true},
	{"name":"mapa","keyword":"dutch","description":"\n\t\n\t\t\n\t\tDataset Card for Multilingual European Datasets for Sensitive Entity Detection in the Legal Domain\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThe dataset consists of 12 documents (9 for Spanish due to parsing errors) taken from EUR-Lex, a multilingual corpus of court\ndecisions and legal dispositions in the 24 official languages of the European Union. The documents have been annotated\nfor named entities following the guidelines of the MAPA project which foresees two\nannotation level, a general and a‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/joelniklaus/mapa.","url":"https://huggingface.co/datasets/joelniklaus/mapa","creator_name":"Joel Niklaus","creator_url":"https://huggingface.co/joelniklaus","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["token-classification","named-entity-recognition","other","found","multilingual"],"keywords_longer_than_N":true},
	{"name":"Augmented_CACAPO_for_E2E","keyword":"dutch","description":"The full dataset information can be found in the JSON file named \"augmented_cacapo_for_e2e-02_13_2023_22_17_09\", which was created with the interactive dataset creator provided by Huggingface.\n","url":"https://huggingface.co/datasets/GEM/Augmented_CACAPO_for_E2E","creator_name":"GEM benchmark","creator_url":"https://huggingface.co/GEM","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","Dutch","English","cc-by-4.0","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"Augmented_CACAPO_for_E2E","keyword":"dutch","description":"The full dataset information can be found in the JSON file named \"augmented_cacapo_for_e2e-02_13_2023_22_17_09\", which was created with the interactive dataset creator provided by Huggingface.\n","url":"https://huggingface.co/datasets/GEM/Augmented_CACAPO_for_E2E","creator_name":"GEM benchmark","creator_url":"https://huggingface.co/GEM","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","Dutch","English","cc-by-4.0","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"Elongated_CACAPO_for_E2E","keyword":"dutch","description":"Dataset information can be found in the JSON file named \"elongated_training_cacapo_updated-02_22_2023_23_23_20.json\", which was created with the interactive dataset creator provided by Huggingface.\n","url":"https://huggingface.co/datasets/GEM/Elongated_CACAPO_for_E2E","creator_name":"GEM benchmark","creator_url":"https://huggingface.co/GEM","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":null,"first_N":5,"first_N_keywords":["text-generation","Dutch","English","cc-by-4.0","10K<n<100K"],"keywords_longer_than_N":true},
	{"name":"Elongated_CACAPO_for_E2E","keyword":"dutch","description":"Dataset information can be found in the JSON file named \"elongated_training_cacapo_updated-02_22_2023_23_23_20.json\", which was created with the interactive dataset creator provided by Huggingface.\n","url":"https://huggingface.co/datasets/GEM/Elongated_CACAPO_for_E2E","creator_name":"GEM benchmark","creator_url":"https://huggingface.co/GEM","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":null,"first_N":5,"first_N_keywords":["text-generation","Dutch","English","cc-by-4.0","10K<n<100K"],"keywords_longer_than_N":true},
	{"name":"tatoeba-mt-qna-oa","keyword":"dutch","description":"\n\t\n\t\t\n\t\tDataset Card for multilingual tatoeba QnA translation with ~120K entries.\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nContains Parquet of a list of instructions and translation articles on different languages.\nEach row consists of\n\nINSTRUCTION\nRESPONSE\nSOURCE (tatoeba)\nMETADATA (json with language, text length, uuid, langs-pair).\n\n\n\t\n\t\t\n\t\tOriginal Dataset is avalible here:\n\t\n\n\nhttps://huggingface.co/datasets/Helsinki-NLP/tatoeba_mt\n\n","url":"https://huggingface.co/datasets/0x22almostEvil/tatoeba-mt-qna-oa","creator_name":"David Glushkov","creator_url":"https://huggingface.co/0x22almostEvil","license_name":"Creative Commons Attribution 2.0","license_url":"https://scancode-licensedb.aboutcode.org/cc-by-2.0.html","language":"en","first_N":5,"first_N_keywords":["question-answering","translation","English","Russian","German"],"keywords_longer_than_N":true},
	{"name":"docfullstructure_dataset","keyword":"dutch","description":"kopan/docfullstructure_dataset dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/kopan/docfullstructure_dataset","creator_name":"Ilia Kopanichuk","creator_url":"https://huggingface.co/kopan","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":null,"first_N":5,"first_N_keywords":["text-classification","Russian","English","Kazakh","Bulgarian"],"keywords_longer_than_N":true},
	{"name":"s2orc-citation-pairs-translated-nl","keyword":"dutch","description":"This is a Dutch version of the S2ORC: The Semantic Scholar Open Research Corpus. Which we have auto-translated from English into Dutch using Meta's No Language Left Behind model, specifically the huggingface implementation.\n","url":"https://huggingface.co/datasets/NetherlandsForensicInstitute/s2orc-citation-pairs-translated-nl","creator_name":"Netherlands Forensic Institute","creator_url":"https://huggingface.co/NetherlandsForensicInstitute","license_name":"Open Data Commons Attribution License v1.0","license_url":"https://scancode-licensedb.aboutcode.org/odc-by-1.0.html","language":"en","first_N":5,"first_N_keywords":["sentence-similarity","Dutch","odc-by","10M - 100M","json"],"keywords_longer_than_N":true},
	{"name":"VaccinChatNL","keyword":"dutch","description":"\n\t\n\t\t\n\t\tDataset Card for VaccinChatNL\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\n\n\nPoint of Contact:  Jeska Buhmann\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nVaccinChatNL is a Flemish Dutch FAQ dataset on the topic of COVID-19 vaccinations in Flanders. It consists of 12,833 user questions divided over 181 answer labels, thus providing large groups of semantically equivalent paraphrases (a many-to-one mapping of user questions to answer labels). VaccinChatNL is the first Dutch many-to-one FAQ dataset of this size.‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/clips/VaccinChatNL.","url":"https://huggingface.co/datasets/clips/VaccinChatNL","creator_name":"CLiPS","creator_url":"https://huggingface.co/clips","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","intent-classification","expert-generated","other","monolingual"],"keywords_longer_than_N":true},
	{"name":"medieval","keyword":"dutch","description":"\n\t\n\t\t\n\t\tDataset Card for CATMuS Medieval\n\t\n\n\nJoin our Discord to ask questions about the dataset: \n\n\t\n\t\t\n\t\n\t\n\t\tDataset Details\n\t\n\nHandwritten Text Recognition (HTR) has emerged as a crucial tool for converting manuscripts images into machine-readable formats, \nenabling researchers and scholars to analyse vast collections efficiently. \nDespite significant technological progress, establishing consistent ground truth across projects for HTR tasks, \nparticularly for complex and heterogeneous‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/CATMuS/medieval.","url":"https://huggingface.co/datasets/CATMuS/medieval","creator_name":"CATMuS: Consistent Approach to Transcribing ManuScripts","creator_url":"https://huggingface.co/CATMuS","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["image-to-text","French","English","Dutch","Italian"],"keywords_longer_than_N":true},
	{"name":"openassistant-guanaco-EOS","keyword":"dutch","description":"\n\t\n\t\t\n\t\tChat Fine-tuning Dataset - Guanaco Style\n\t\n\nThis dataset allows for fine-tuning chat models using \"### Human:\" AND \"### Assistant\" as the beginning and end of sequence tokens.\nPreparation:\n\nThe dataset is cloned from TimDettmers, which itself is a subset of the Open Assistant dataset, which you can find here. This subset of the data only contains the highest-rated paths in the conversation tree, with a total of 9,846 samples.\nThe dataset was then slightly adjusted to:\n\n\nif a row of‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Trelis/openassistant-guanaco-EOS.","url":"https://huggingface.co/datasets/Trelis/openassistant-guanaco-EOS","creator_name":"Trelis","creator_url":"https://huggingface.co/Trelis","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["English","Spanish","Russian","German","Polish"],"keywords_longer_than_N":true},
	{"name":"Wikinews-multilingual","keyword":"dutch","description":"\n\t\n\t\t\n\t\tWikinews - weakly aligned multilingual pararell sentence datasets\n\t\n\nThis dataset contains 15,200 multilingual WikiNews articles in 33 languages.\nOut of 15,200 articles, 9,960 are non-English news and 5240 are English news.  All non-English news are linked to one of 5240 English news. Linked articles show the same event.\nList of non-English languages are: Spanish, French, German, Portuguese, Polish, Italian, Chinese, Russian, Japanese, Dutch, Swedish, Tamil, Serbian, Czech, Catalan‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Fumika/Wikinews-multilingual.","url":"https://huggingface.co/datasets/Fumika/Wikinews-multilingual","creator_name":"Fumika Isono","creator_url":"https://huggingface.co/Fumika","license_name":"Creative Commons Attribution 2.5","license_url":"https://scancode-licensedb.aboutcode.org/cc-by-2.5.html","language":"en","first_N":5,"first_N_keywords":["text-classification","feature-extraction","English","Spanish","French"],"keywords_longer_than_N":true},
	{"name":"mc4-sampling","keyword":"dutch","description":"A sampling-enabled version of mC4, the colossal, cleaned version of Common Crawl's web crawl corpus.\n\nBased on Common Crawl dataset: \"https://commoncrawl.org\".\n\nThis is a version of the processed version of Google's mC4 dataset by AllenAI, in which sampling methods are implemented to perform on the fly.","url":"https://huggingface.co/datasets/bertin-project/mc4-sampling","creator_name":"BERTIN Project","creator_url":"https://huggingface.co/bertin-project","license_name":"Open Data Commons Attribution License v1.0","license_url":"https://scancode-licensedb.aboutcode.org/odc-by-1.0.html","language":null,"first_N":5,"first_N_keywords":["text-generation","fill-mask","language-modeling","no-annotation","found"],"keywords_longer_than_N":true},
	{"name":"xlel_wd","keyword":"dutch","description":"XLEL-WD is a multilingual event linking dataset. This dataset contains mention references from multilingual Wikipedia/Wikinews articles to event items in Wikidata. The text descriptions for Wikidata events are compiled from Wikipedia articles.","url":"https://huggingface.co/datasets/adithya7/xlel_wd","creator_name":"Adithya Pratapa","creator_url":"https://huggingface.co/adithya7","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["found","found","multilingual","original","Afrikaans"],"keywords_longer_than_N":true},
	{"name":"blbooksgenre","keyword":"dutch","description":"This dataset contains metadata for resources belonging to the British Library‚Äôs digitised printed books (18th-19th century) collection (bl.uk/collection-guides/digitised-printed-books).\nThis metadata has been extracted from British Library catalogue records.\nThe metadata held within our main catalogue is updated regularly.\nThis metadata dataset should be considered a snapshot of this metadata.","url":"https://huggingface.co/datasets/TheBritishLibrary/blbooksgenre","creator_name":"British Library","creator_url":"https://huggingface.co/TheBritishLibrary","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","text-generation","fill-mask","topic-classification","multi-label-classification"],"keywords_longer_than_N":true},
	{"name":"opus_paracrawl","keyword":"dutch","description":"\n\t\n\t\t\n\t\tDataset Card for OpusParaCrawl\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nParallel corpora from Web Crawls collected in the ParaCrawl project.\nTha dataset contains:\n\n42 languages, 43 bitexts\ntotal number of files: 59,996\ntotal number of tokens: 56.11G\ntotal number of sentence fragments: 3.13G\n\nTo load a language pair which isn't part of the config, all you need to do is specify the language code as pairs,\ne.g.\ndataset = load_dataset(\"opus_paracrawl\", lang1=\"en\", lang2=\"so\")\n\nYou can find the valid‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Helsinki-NLP/opus_paracrawl.","url":"https://huggingface.co/datasets/Helsinki-NLP/opus_paracrawl","creator_name":"Language Technology Research Group at the University of Helsinki","creator_url":"https://huggingface.co/Helsinki-NLP","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["translation","found","found","multilingual","original"],"keywords_longer_than_N":true},
	{"name":"panlex","keyword":"dutch","description":"\n\t\n\t\t\n\t\tPanLex\n\t\n\nJanuary 1, 2024 version of PanLex Language Vocabulary with 24,650,274 rows covering 6,152 languages.\n\n\t\n\t\t\n\t\tColumns\n\t\n\n\nvocab: contains the text entry.  \n639-3: contains the ISO 639-3 languages tags to allow users to filter on the language(s) of their choice.\n639-3_english_name: the English language name associated to the code ISO 639-3. \nvar_code: contains a code to differentiate language variants. In practice, this is the code 639-3 + a number.  If 000, it corresponds to‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/lbourdois/panlex.","url":"https://huggingface.co/datasets/lbourdois/panlex","creator_name":"Lo√Øck BOURDOIS","creator_url":"https://huggingface.co/lbourdois","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["Ghotuo","Alumu-Tesu","Ari","Amal","Arb√´resh√´ Albanian"],"keywords_longer_than_N":true},
	{"name":"tatoeba-mt-all-in-one","keyword":"dutch","description":"\n\t\n\t\t\n\t\tDataset Card for The Tatoeba Translation Challenge | All In One\n\t\n\n~7.3M entries.\nJust more user-friendly version that combines all of the entries of original dataset in a single file:\nhttps://huggingface.co/datasets/Helsinki-NLP/tatoeba_mt\n","url":"https://huggingface.co/datasets/0x22almostEvil/tatoeba-mt-all-in-one","creator_name":"David Glushkov","creator_url":"https://huggingface.co/0x22almostEvil","license_name":"Creative Commons Attribution 2.0","license_url":"https://scancode-licensedb.aboutcode.org/cc-by-2.0.html","language":"en","first_N":5,"first_N_keywords":["Helsinki-NLP","crowdsourced","translation","Helsinki-NLP/tatoeba_mt","Afrikaans"],"keywords_longer_than_N":true},
	{"name":"unsilence_voc","keyword":"dutch","description":"\n\t\n\t\t\n\t\tDataset Card for Unsilencing Colonial Archives via Automated Entity Recognition\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nNote: this data card was adapted from documentation and a data card written by the creators of the dataset.  \n\nColonial archives are at the center of increased interest from a variety of perspectives, as they contain traces of historically marginalized people. Unfortunately, like most archives, they remain difficult to access due to significant persisting barriers. We focus‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/biglam/unsilence_voc.","url":"https://huggingface.co/datasets/biglam/unsilence_voc","creator_name":"BigLAM: BigScience Libraries, Archives and Museums","creator_url":"https://huggingface.co/biglam","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["token-classification","named-entity-recognition","Dutch","cc-by-4.0","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"tatoeba-mt-llama-only","keyword":"dutch","description":"\n\t\n\t\t\n\t\tDataset Card for multilingual tatoeba translations with ~3M entries (llama supported languages only).\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\n~3M entries. Just more user-friendly version that combines all of the entries of original dataset in a single file (llama supported languages only):\nhttps://huggingface.co/datasets/Helsinki-NLP/tatoeba_mt\n","url":"https://huggingface.co/datasets/0x22almostEvil/tatoeba-mt-llama-only","creator_name":"David Glushkov","creator_url":"https://huggingface.co/0x22almostEvil","license_name":"Creative Commons Attribution 2.0","license_url":"https://scancode-licensedb.aboutcode.org/cc-by-2.0.html","language":"en","first_N":5,"first_N_keywords":["translation","English","Russian","German","Ukrainian"],"keywords_longer_than_N":true},
	{"name":"mswc_fscil_subset","keyword":"dutch","description":"This is a subset of the Multilingual Spoken Word Corpus dataset, which is built specifically for the Few-shot Class-incremental Learning (FSCIL) task. \nA total of 15 languages are chosen, split into 5 base languages (English, German, Catalan, French, Kinyarwanda) and 10 incrementally learned languages (Persian, Spanish, Russian, Welsh, Italian, Basque, Polish, Esparanto, Portuguese, Dutch).\nThe FSCIL task entails first training a model using abundant training data on words from the 5 base‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/NeuroBench/mswc_fscil_subset.","url":"https://huggingface.co/datasets/NeuroBench/mswc_fscil_subset","creator_name":"NeuroBench","creator_url":"https://huggingface.co/NeuroBench","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["English","Spanish","Catalan","French","Kinyarwanda"],"keywords_longer_than_N":true},
	{"name":"tokenizer-wiki-bench","keyword":"dutch","description":"\n\t\n\t\t\n\t\tMultilingual Tokenizer Benchmark\n\t\n\nThis dataset includes pre-processed wikipedia data for tokenizer evaluation in 45 languages. We provide more information on the evaluation task in general this blogpost.\n\n\t\n\t\t\n\t\tUsage\n\t\n\nThe dataset allows us to easily calculate tokenizer fertility and the proportion of continued words on any of the supported languages. In the example below we take the Mistral tokenizer and evaluate its performance on Slovak. \nfrom transformers import AutoTokenizer‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/occiglot/tokenizer-wiki-bench.","url":"https://huggingface.co/datasets/occiglot/tokenizer-wiki-bench","creator_name":"Occiglot","creator_url":"https://huggingface.co/occiglot","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["Afrikaans","Arabic","Bulgarian","Catalan","Czech"],"keywords_longer_than_N":true},
	{"name":"voxpopolo_2","keyword":"dutch","description":"A large-scale multilingual speech corpus for representation learning, semi-supervised learning and interpretation.","url":"https://huggingface.co/datasets/mcapozi/voxpopolo_2","creator_name":"Matteo Capozi","creator_url":"https://huggingface.co/mcapozi","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":null,"first_N":5,"first_N_keywords":["automatic-speech-recognition","multilingual","English","German","French"],"keywords_longer_than_N":true},
	{"name":"Kaleidoscope","keyword":"dutch","description":"\n\t\n\t\t\n\t\tKaleidoscope  (18 Languages)\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe Kaleidoscope Benchmark is a \nglobal collection of multiple-choice questions sourced from real-world exams, \nwith the goal of evaluating multimodal and multilingual understanding in VLMs. \nThe collected exams are in a Multiple-choice question answering (MCQA) \nformat which provides a structured framework for evaluation by prompting \nmodels with predefined answer choices, closely mimicking conventional human testing‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Anonym-sub/Kaleidoscope.","url":"https://huggingface.co/datasets/Anonym-sub/Kaleidoscope","creator_name":"Anonymous submission","creator_url":"https://huggingface.co/Anonym-sub","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["Arabic","Bengali","Croatian","Dutch","English"],"keywords_longer_than_N":true},
	{"name":"WiNNL","keyword":"dutch","description":"\n\t\n\t\t\n\t\tWiNNL\n\t\n\nWikiNews Named entity recognition and Linking (WiNNL) is a multilingual news NER & NEL benchmark based on Wikinews articles.\nThe dataset was created by automatically scraping and tagging news articles, and manually corrected by native speakers to ensure accuracy.\nYou can find more information in the paper:\nhttps://aclanthology.org/2024.dlnld-1.3.pdf\nThe dataset includes the following NER classes in IOB format (labels):\n\nPER (Person): person names \nLOC (Location): geographical‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/peemil/WiNNL.","url":"https://huggingface.co/datasets/peemil/WiNNL","creator_name":"Emile Peetermans","creator_url":"https://huggingface.co/peemil","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["token-classification","Dutch","English","Spanish","Portuguese"],"keywords_longer_than_N":true},
	{"name":"fineweb-dutch-edu-mt","keyword":"dutch","description":"\n\t\n\t\t\n\t\tFineWeb-Edu Dutch Machine Translated\n\t\n\nMachine-translated Dutch text dataset derived from the FineWeb-Edu corpus.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\nSource: HuggingFaceFW/fineweb-edu (sample-10BT subset)\nTranslation: English ‚Üí Dutch using Unbabel/Tower-Plus-9B\nSize: Up to 1.5M samples\nFormat: Translated text with original metadata\n\n\n\t\n\t\t\n\t\n\t\n\t\tSchema\n\t\n\n\ntext: Machine-translated Dutch text\nid: Original sample identifier from FineWeb-Edu\nurl: Source URL\n\n\n\t\n\t\t\n\t\n\t\n\t\tQuality Notice\n\t\n\n‚ö†Ô∏è This‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/pdelobelle/fineweb-dutch-edu-mt.","url":"https://huggingface.co/datasets/pdelobelle/fineweb-dutch-edu-mt","creator_name":"Pieter Delobelle","creator_url":"https://huggingface.co/pdelobelle","license_name":"Open Data Commons Attribution License v1.0","license_url":"https://scancode-licensedb.aboutcode.org/odc-by-1.0.html","language":"en","first_N":5,"first_N_keywords":["text-generation","Dutch","English","odc-by","1M - 10M"],"keywords_longer_than_N":true},
	{"name":"fineweb-dutch-edu-mt","keyword":"dutch","description":"\n\t\n\t\t\n\t\tFineWeb-Edu Dutch Machine Translated\n\t\n\nMachine-translated Dutch text dataset derived from the FineWeb-Edu corpus.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\nSource: HuggingFaceFW/fineweb-edu (sample-10BT subset)\nTranslation: English ‚Üí Dutch using Unbabel/Tower-Plus-9B\nSize: Up to 1.5M samples\nFormat: Translated text with original metadata\n\n\n\t\n\t\t\n\t\n\t\n\t\tSchema\n\t\n\n\ntext: Machine-translated Dutch text\nid: Original sample identifier from FineWeb-Edu\nurl: Source URL\n\n\n\t\n\t\t\n\t\n\t\n\t\tQuality Notice\n\t\n\n‚ö†Ô∏è This‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/pdelobelle/fineweb-dutch-edu-mt.","url":"https://huggingface.co/datasets/pdelobelle/fineweb-dutch-edu-mt","creator_name":"Pieter Delobelle","creator_url":"https://huggingface.co/pdelobelle","license_name":"Open Data Commons Attribution License v1.0","license_url":"https://scancode-licensedb.aboutcode.org/odc-by-1.0.html","language":"en","first_N":5,"first_N_keywords":["text-generation","Dutch","English","odc-by","1M - 10M"],"keywords_longer_than_N":true},
	{"name":"test2kgWdeepseek","keyword":"dutch","description":"This dataset contains snippets from Dutch Wikipedia transformed into RDF Knowledge Graphs (in Turtle syntax) and corresponding OWL ontology schemas.\nAs input the prompt column (unsimplified snippets) from UWV/Leesplank_NL_wikipedia_simplifications\nwas used.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset is derived from Dutch Wikipedia articles, processed to extract structured knowledge in two formats:\n\nKnowledge Graphs (KG): RDF triples encoded in Turtle syntax representing entities, attributes‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/yhavinga/test2kgWdeepseek.","url":"https://huggingface.co/datasets/yhavinga/test2kgWdeepseek","creator_name":"Yeb Havinga","creator_url":"https://huggingface.co/yhavinga","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["Dutch","apache-2.0","1K - 10K","parquet","Text"],"keywords_longer_than_N":true},
	{"name":"epfl_guidelines_dutch_marianmt","keyword":"dutch","description":"Machine Translation of the English medical guidelines that are part of the Meditron corpus, using the NMT MariaNMT","url":"https://huggingface.co/datasets/UMCU/epfl_guidelines_dutch_marianmt","creator_name":"Bram van Es","creator_url":"https://huggingface.co/UMCU","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-generation","fill-mask","Dutch","mit","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"epfl_guidelines_dutch_marianmt","keyword":"dutch","description":"Machine Translation of the English medical guidelines that are part of the Meditron corpus, using the NMT MariaNMT","url":"https://huggingface.co/datasets/UMCU/epfl_guidelines_dutch_marianmt","creator_name":"Bram van Es","creator_url":"https://huggingface.co/UMCU","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-generation","fill-mask","Dutch","mit","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"MultiQ","keyword":"dutch","description":"\n\t\n\t\t\n\t\tDataset Card for MultiQ\n\t\n\nThis is the dataset corresponding to the paper \"Evaluating the Elementary Multilingual Capabilities of Large Language Models with MultiQ\". \nIt is a silver standard benchmark that can be used to evaluate the basic multilingual capabilities of LLMs. It contains 200 open ended questions automatically \ntranslated into 137 typologically diverse languages. \n\nCurated by: Carolin Holtermann, Paul R√∂ttger, Timm Dill, Anne Lauscher\nLanguage(s) (NLP): 137 diverse‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/caro-holt/MultiQ.","url":"https://huggingface.co/datasets/caro-holt/MultiQ","creator_name":"Holtermann","creator_url":"https://huggingface.co/caro-holt","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["question-answering","Tagalog","Samoan","Macedonian","Gujarati"],"keywords_longer_than_N":true},
	{"name":"CodeMixBench","keyword":"dutch","description":"\n\t\n\t\t\n\t\t‚ÑπÔ∏èDataset Card for CodeMixBench\n\t\n\n\n\t\n\t\t\n\t\t[EMNLP'25] CodeMixBench: Evaluating Code-Mixing Capabilities of LLMs Across 18 Languages\n\t\n\n   \n      \n   \n        \n  \n      \n   \n  \n      \n   \n\n\n\n\n\nCode-mixing is a linguistic phenomenon where multilingual speakers switch or mix two or more languages within a single utterance or conversation. \nTo evaluate LLMs‚Äô comprehension of multilingual code-mixed texts, we introduce CodeMixBench, a benchmark comprising eight tasks across 18 languages.‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/CodeMixBench/CodeMixBench.","url":"https://huggingface.co/datasets/CodeMixBench/CodeMixBench","creator_name":"CodeMixBench","creator_url":"https://huggingface.co/CodeMixBench","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["Chinese","English","Spanish","Hindi","German"],"keywords_longer_than_N":true},
	{"name":"JQL-Human-Edu-Annotations","keyword":"dutch","description":"\n\t\n\t\t\n\t\tüìö JQL Multilingual Educational Quality Annotations\n\t\n\nThis dataset provides high-quality human annotations for evaluating the educational value of web documents, and serves as a benchmark for training and evaluating multilingual LLM annotators as described in the JQL paper.\n\n\n\t\n\t\t\n\t\tüìù Dataset Summary\n\t\n\n\nDocuments: 511 English texts  \nAnnotations: 3 human ratings per document (0‚Äì5 scale)  \nTranslations: Into 35 European languages using DeepL and GPT-4o  \nPurpose: For training and‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/JQL-AI/JQL-Human-Edu-Annotations.","url":"https://huggingface.co/datasets/JQL-AI/JQL-Human-Edu-Annotations","creator_name":"JQL-AI","creator_url":"https://huggingface.co/JQL-AI","license_name":"Open Data Commons Attribution License v1.0","license_url":"https://scancode-licensedb.aboutcode.org/odc-by-1.0.html","language":"en","first_N":5,"first_N_keywords":["text-classification","Bulgarian","Czech","Croatian","Macedonian"],"keywords_longer_than_N":true},
	{"name":"language-dataset","keyword":"dutch","description":"\n","url":"https://huggingface.co/datasets/neon-mao/language-dataset","creator_name":"maoqifan","creator_url":"https://huggingface.co/neon-mao","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","English","Chinese","French","Russian"],"keywords_longer_than_N":true},
	{"name":"ToxicCommons","keyword":"dutch","description":"\n\t\n\t\t\n\t\tToxic Commons\n\t\n\nToxic Commons is a release of 2 million samples of annotated, public domain, multilingual text that was used to train Celadon. \nIt is being released alongside Celadon, in order to better understand multilingual and multicultural toxicity. \nEach sample was classified across 5 axes of toxicity:\n\nRace and origin-based bias: includes racism as well as bias against someone‚Äôs country or region of origin or immigration status, especially immigrant or refugee status. \nGender‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/PleIAs/ToxicCommons.","url":"https://huggingface.co/datasets/PleIAs/ToxicCommons","creator_name":"PleIAs","creator_url":"https://huggingface.co/PleIAs","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","English","French","Spanish","German"],"keywords_longer_than_N":true},
	{"name":"Quora-NL","keyword":"dutch","description":"\n  Quora-NL\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nQuoraRetrieval is based on questions that are marked as duplicates on the Quora platform. Given a question, find other (duplicate) questions. QuoraRetrieval-NL is a Dutch translation.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2t\n\nDomains\nWritten\n\n\nReference\nhttps://huggingface.co/datasets/clips/beir-nl-quora\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/Quora-NL.","url":"https://huggingface.co/datasets/mteb/Quora-NL","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","derived","translated","mteb/quora","Dutch"],"keywords_longer_than_N":true},
	{"name":"MultiPICo","keyword":"dutch","description":"\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nMultiPICo (Multilingual Perspectivist Irony Corpus) is a disaggregated multilingual corpus for irony detection, containing 18,778 pairs of short conversations (post-reply) from Twitter (8,956) and Reddit (9,822), along with the demographic information of each annotator (age, nationality, gender, and so on). \n\n\t\n\t\t\n\t\tSupported Tasks and Leaderboards\n\t\n\nIrony classification task using soft labels (i.e., distribution of annotations) or hard labels (i.e., aggregated‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Multilingual-Perspectivist-NLU/MultiPICo.","url":"https://huggingface.co/datasets/Multilingual-Perspectivist-NLU/MultiPICo","creator_name":"MultilingualPerspectivistNLU","creator_url":"https://huggingface.co/Multilingual-Perspectivist-NLU","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["Spanish","English","German","Arabic","Portuguese"],"keywords_longer_than_N":true},
	{"name":"multilingual_translation_sft","keyword":"dutch","description":"Youseff1987/multilingual_translation_sft dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/Youseff1987/multilingual_translation_sft","creator_name":"JOON HYOUNG JUN","creator_url":"https://huggingface.co/Youseff1987","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["translation","Korean","English","Chinese","Zulu"],"keywords_longer_than_N":true},
	{"name":"finepdfs-summaries","keyword":"dutch","description":"\n\t\n\t\t\n\t\tfinepdfs-summaries\n\t\n\nSummaries generated with Qwen3-Next-80B-A3B-Instruct for documents from finepdfs.\nWork in progress, still generating more data.\nThe following table shows the size for each language:\n\n\t\n\t\t\nLanguage\nSummaries\nTokens\nDisk size\n\n\n\t\t\nAll\n764,482,142\n224 B\n336 GB\n\n\ndeu_Latn\n343,089,235\n106 B\n141 GB\n\n\neng_Latn\n321,343,046\n81 B\n150 GB\n\nfra_Latn\n27,308,302\n10 B\n14 GB\n\n\nspa_Latn\n25,624,727\n9 B\n12 GB\n\n\nita_Latn\n17,587,618\n6 B\n8 GB\n\n\npor_Latn\n12,043,607\n4 B\n5 GB\n\n\npol_Latn\n9‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/maxidl/finepdfs-summaries.","url":"https://huggingface.co/datasets/maxidl/finepdfs-summaries","creator_name":"Max Idahl","creator_url":"https://huggingface.co/maxidl","license_name":"Open Data Commons Attribution License v1.0","license_url":"https://scancode-licensedb.aboutcode.org/odc-by-1.0.html","language":"en","first_N":5,"first_N_keywords":["text-generation","summarization","English","German","French"],"keywords_longer_than_N":true},
	{"name":"YouTube-Commons-descriptions","keyword":"dutch","description":"\n\t\n\t\t\n\t\tYouTube Commons Descriptions and Language Detection\n\t\n\nThis dataset adds titles, descriptions and language detection to YouTube Commons, a valuable open dataset:\n\nYouTube-Commons is a collection of audio transcripts of 2,063,066 videos shared on YouTube under a CC BY 4.0 license.\nContent\nThe collection comprises 22,709,724 original and automatically translated transcripts from 3,156,703 videos (721,136 individual channels).\n\nUnfortunately I have found that the detection of the original‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Rijgersberg/YouTube-Commons-descriptions.","url":"https://huggingface.co/datasets/Rijgersberg/YouTube-Commons-descriptions","creator_name":"Edwin Rijgersberg","creator_url":"https://huggingface.co/Rijgersberg","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["English","French","Spanish","Portuguese","German"],"keywords_longer_than_N":true},
	{"name":"M-ABSA","keyword":"dutch","description":"\n\t\n\t\t\n\t\tM-ABSA\n\t\n\nThis repo contains the data for our paper M-ABSA: A Multilingual Dataset for Aspect-Based Sentiment Analysis.\n\n\n\t\n\t\t\n\t\tData Description:\n\t\n\nThis is a dataset suitable for the multilingual ABSA task with triplet extraction.\nAll datasets are stored in the data/ folder:\n\nAll dataset contains 7 domains.\n\ndomains = [\"coursera\", \"hotel\", \"laptop\", \"restaurant\", \"phone\", \"sight\", \"food\"]\n\n\nEach dataset contains 21 languages.\n\nlangs = [\"ar\", \"da\", \"de\", \"en\", \"es\", \"fr\", \"hi\", \"hr\"‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Multilingual-NLP/M-ABSA.","url":"https://huggingface.co/datasets/Multilingual-NLP/M-ABSA","creator_name":"multilingual-NLP","creator_url":"https://huggingface.co/Multilingual-NLP","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["token-classification","text-classification","Arabic","Danish","German"],"keywords_longer_than_N":true},
	{"name":"wikipedia_quality_wikirank","keyword":"dutch","description":"Datasets with WikiRank quality score as of 1 August 2024 for 47 million Wikipedia articles in 55 language versions (also simplified version for each language in separate files).\nThe WikiRank quality score is a metric designed to assess the overall quality of a Wikipedia article. Although its specific algorithm can vary depending on the implementation, the score typically combines several key features of the Wikipedia article.\n\n\t\n\t\t\n\t\n\t\n\t\tWhy It‚Äôs Important\n\t\n\n\nEnhances Trust: For readers and‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/lewoniewski/wikipedia_quality_wikirank.","url":"https://huggingface.co/datasets/lewoniewski/wikipedia_quality_wikirank","creator_name":"W≈Çodzimierz Lewoniewski","creator_url":"https://huggingface.co/lewoniewski","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["Arabic","Azerbaijani","Belarusian","Bulgarian","Catalan"],"keywords_longer_than_N":true},
	{"name":"fineweb-2","keyword":"dutch","description":"\n\t\n\t\t\n\t\tü•Ç FineWeb2\n\t\n\n\n    \n\n\n\nA sparkling update with 1000s of languages\n\n\n\t\n\t\t\n\t\tWhat is it?\n\t\n\nThis is the second iteration of the popular üç∑ FineWeb dataset, bringing high quality pretraining data to over 1000 üó£Ô∏è languages.\nThe ü•Ç FineWeb2 dataset is fully reproducible, available under the permissive ODC-By 1.0 license and extensively validated through hundreds of ablation experiments.\nIn particular, on the set of 9 diverse languages we used to guide our processing decisions, ü•Ç FineWeb2‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/HuggingFaceFW/fineweb-2.","url":"https://huggingface.co/datasets/HuggingFaceFW/fineweb-2","creator_name":"FineData","creator_url":"https://huggingface.co/HuggingFaceFW","license_name":"Open Data Commons Attribution License v1.0","license_url":"https://scancode-licensedb.aboutcode.org/odc-by-1.0.html","language":"en","first_N":5,"first_N_keywords":["text-generation","Arifama-Miniafia","Ankave","Abau","Amarasi"],"keywords_longer_than_N":true},
	{"name":"panlex-definitions","keyword":"dutch","description":"\n\t\n\t\t\n\t\tDataset Card for panlex-definitions\n\t\n\nThis is a dataset of word definitions in several hudnred languages, extracted from https://panlex.org.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset has been extracted from https://panlex.org (the 20250201 database dump) and rearranged on the per-language basis (by the language of the definition).\nEach language subset consists of definitions (short phrases).\nEach definition is associated with some meanings (if there is‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/cointegrated/panlex-definitions.","url":"https://huggingface.co/datasets/cointegrated/panlex-definitions","creator_name":"David Dale","creator_url":"https://huggingface.co/cointegrated","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["translation","Abkhazian","Hijazi Arabic","Afrikaans","Ainu (Japan)"],"keywords_longer_than_N":true},
	{"name":"common_voice_21_0","keyword":"dutch","description":"Due to storage limits some files had to be split into multiple parts. They can be merged like this: cat file.* > file.\n","url":"https://huggingface.co/datasets/2Jyq/common_voice_21_0","creator_name":"2Jyq","creator_url":"https://huggingface.co/2Jyq","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["crowdsourced","crowdsourced","multilingual","extended|common_voice","Abkhaz"],"keywords_longer_than_N":true},
	{"name":"PolyGuardPrompts","keyword":"dutch","description":"\n\t\n\t\t\n\t\tPolyGuard: A Multilingual Safety Moderation Tool for 17 Languages\n\t\n\nAbstract: Truly multilingual safety moderation efforts for Large Language Models (LLMs) have been hindered by a narrow focus on a small set of languages (e.g., English, Chinese) as well as a limited scope of safety definition, resulting in significant gaps in moderation capabilities. To bridge these gaps, we release PolyGuard, a new state-of-the-art multilingual safety model for safeguarding LLM generations, and the‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ToxicityPrompts/PolyGuardPrompts.","url":"https://huggingface.co/datasets/ToxicityPrompts/PolyGuardPrompts","creator_name":"ToxicityPrompts","creator_url":"https://huggingface.co/ToxicityPrompts","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["Arabic","Chinese","Czech","Dutch","English"],"keywords_longer_than_N":true},
	{"name":"GlobalDISCO","keyword":"dutch","description":"\n\t\n\t\t\n\t\tGlobalDISCO\n\t\n\nGlobalDISCO is a large-scale dataset consisting of 73k music tracks generated by state-of-the-art commercial generative music models, along with paired links to 93k reference tracks in LAION-DISCO-12M. The dataset spans 147 languages and includes musical style prompts extracted from MusicBrainz and Wikipedia. The dataset is globally balanced, representing musical styles from artists across 79 countries and five continents. It is aimed to support the research community in‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/disco-eth/GlobalDISCO.","url":"https://huggingface.co/datasets/disco-eth/GlobalDISCO","creator_name":"DISCO","creator_url":"https://huggingface.co/disco-eth","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["audio-classification","English","Spanish","French","German"],"keywords_longer_than_N":true},
	{"name":"open_government","keyword":"dutch","description":"\n\t\n\t\t\n\t\tOpen Government Dataset\n\t\n\nOpen Government is the largest agregation of governement text and data made available as part of open data programs. \nIn total, the dataset contains approximately 380B tokens. While Open Government aims to become a global resource, in its current state it mostly features open datasets from the US, France, European and international organizations.\nThe dataset comprises 16 collections curated through two different initiaties: Finance commons and Legal commons.‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/AgentPublic/open_government.","url":"https://huggingface.co/datasets/AgentPublic/open_government","creator_name":"AgentPublic","creator_url":"https://huggingface.co/AgentPublic","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","English","French","Bulgarian","Croatian"],"keywords_longer_than_N":true},
	{"name":"wildchat-filtered","keyword":"dutch","description":"\n\t\n\t\t\n\t\tWildChat Filtered Dataset\n\t\n\nThis is a filtered version of the WildChat-4.8M dataset.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset contains 3,199,860 conversations between human users and ChatGPT, filtered to keep only the essential conversation structure.\n\n\t\n\t\t\n\t\tData Structure\n\t\n\nEach conversation contains only:\n\nconversations: A list of message objects with:\nrole: Either \"user\" or \"assistant\"\ncontent: The text content of the message\n\n\n\nAll other metadata (timestamps, moderation‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/rayonlabs/wildchat-filtered.","url":"https://huggingface.co/datasets/rayonlabs/wildchat-filtered","creator_name":"Rayon Labs","creator_url":"https://huggingface.co/rayonlabs","license_name":"Open Data Commons Attribution License v1.0","license_url":"https://scancode-licensedb.aboutcode.org/odc-by-1.0.html","language":"en","first_N":5,"first_N_keywords":["text-generation","question-answering","English","Spanish","French"],"keywords_longer_than_N":true},
	{"name":"tatoeba-bitext-mining","keyword":"dutch","description":"\n  Tatoeba\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\n1,000 English-aligned sentence pairs for each language based on the Tatoeba corpus\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2t\n\n\nDomains\nWritten\n\n\nReference\nhttps://github.com/facebookresearch/LASER/tree/main/data/tatoeba/v1\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask = mteb.get_tasks([\"Tatoeba\"])\nevaluator = mteb.MTEB(task)\n\nmodel =‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/tatoeba-bitext-mining.","url":"https://huggingface.co/datasets/mteb/tatoeba-bitext-mining","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"Creative Commons Attribution 2.0","license_url":"https://scancode-licensedb.aboutcode.org/cc-by-2.0.html","language":"en","first_N":5,"first_N_keywords":["translation","human-annotated","multilingual","Afrikaans","Amharic"],"keywords_longer_than_N":true},
	{"name":"tulu3-100samples","keyword":"dutch","description":"\n\t\n\t\t\n\t\tDataset\n\t\n\nThis dataset contains 100 samples from the Tulu 3 SFT Mixture.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nEach example in the dataset contains the standard instruction-tuning data points as follow:\n\nid (str): a unique identifier\nmessages (list): message format used for supervised fine-tuning (this contains user prompt and assistant responses)\nsource (str): the source dataset for the given sample\n\n\n\t\n\t\t\n\t\tLicense\n\t\n\nThis dataset is licensed under ODC-BY-1.0. It is intended for research and‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/anayak/tulu3-100samples.","url":"https://huggingface.co/datasets/anayak/tulu3-100samples","creator_name":"Akash Nayak","creator_url":"https://huggingface.co/anayak","license_name":"Open Data Commons Attribution License v1.0","license_url":"https://scancode-licensedb.aboutcode.org/odc-by-1.0.html","language":null,"first_N":5,"first_N_keywords":["other","crowdsourced","expert-generated","machine-generated","multilingual"],"keywords_longer_than_N":true},
	{"name":"fact-check-bureau","keyword":"dutch","description":"\n\t\n\t\t\n\t\n\t\n\t\tFact-Check Retrieval Dataset\n\t\n\nThis dataset is designed to support the development and evaluation of fact-check retrieval pipelines. It is structured to work with FactCheckBureau, a tool for designing and evaluating fact-check retrieval pipelines. The dataset comprises a list of claims, fact-check articles, and precomputed embeddings for English and French fact-checks.\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Structure\n\t\n\nThe dataset consists of the following files and directories:\n\narticles.csv:‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/NaughtyConstrictor/fact-check-bureau.","url":"https://huggingface.co/datasets/NaughtyConstrictor/fact-check-bureau","creator_name":"Younes","creator_url":"https://huggingface.co/NaughtyConstrictor","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["English","French","Portuguese","Spanish","Arabic"],"keywords_longer_than_N":true},
	{"name":"kaleidoscope","keyword":"dutch","description":"\n\t\n\t\t\n\t\tKaleidoscope  (18 Languages)\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe Kaleidoscope Benchmark is a \nglobal collection of multiple-choice questions sourced from real-world exams, \nwith the goal of evaluating multimodal and multilingual understanding in VLMs. \nThe collected exams are in a Multiple-choice question answering (MCQA) \nformat which provides a structured framework for evaluation by prompting \nmodels with predefined answer choices, closely mimicking conventional human testing‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/CohereLabs/kaleidoscope.","url":"https://huggingface.co/datasets/CohereLabs/kaleidoscope","creator_name":"Cohere Labs","creator_url":"https://huggingface.co/CohereLabs","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["Arabic","Bengali","Croatian","Dutch","English"],"keywords_longer_than_N":true},
	{"name":"Intermediate-Thinking-130k","keyword":"dutch","description":"\n\t\n\t\t\n\t\tIntermediate-Thinking-130k\n\t\n\nA comprehensive dataset of 135,000 high-quality samples designed to advance language model reasoning capabilities through structured intermediate thinking processes. This dataset enables training and evaluation of models with sophisticated self-correction and iterative reasoning abilities across 42 languages.\nOG Link\n\n\t\n\t\t\n\t\n\t\n\t\tOverview\n\t\n\nIntermediate-Thinking-130k addresses a fundamental limitation in current language models: their inability to pause‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mlx-community/Intermediate-Thinking-130k.","url":"https://huggingface.co/datasets/mlx-community/Intermediate-Thinking-130k","creator_name":"MLX Community","creator_url":"https://huggingface.co/mlx-community","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","Afrikaans","Arabic","Bengali","Bulgarian"],"keywords_longer_than_N":true},
	{"name":"high-quality-multilingual-sentences","keyword":"dutch","description":"\n\t\n\t\t\n\t\tHigh Quality Multilingual Sentences\n\t\n\n\nThis dataset contains multilingual sentences derived from the agentlans/LinguaNova dataset.\nIt includes 1.58 million rows across 51 different languages, each in its own configuration.\n\nExample row (from the all config):\n{\n    \"text\": \"ÿßŸÖÿßŸÖ ÿ¨ŸÖÿπŸá ÿßÿµŸÅŸáÿßŸÜ ⁄ØŸÅÿ™: ŸÖ€åÿ≤ÿßŸÜ ŸÜ€åÿßÿ≤ ÿ¢ÿ® ÿ¥ÿ±ÿ® ÿßÿµŸÅŸáÿßŸÜ €±€±.€µ ŸÖÿ™ÿ± ŸÖ⁄©ÿπÿ® ÿßÿ≥ÿ™ ⁄©Ÿá ÿ™ŸÖÿßŸÖ ÿßÿ≥ÿ™ÿßŸÜ ÿßÿµŸÅŸáÿßŸÜ ÿ±ÿß ŸæŸàÿ¥ÿ¥ ŸÖ€åÿØŸáÿØ Ÿà ŸÜÿ≥ÿ®ÿ™ ÿ®Ÿá ŸÇÿ®ŸÑ ÿßÿ≤ ÿßŸÜŸÇŸÑÿßÿ® €å⁄©€å ÿßÿ≤ Ÿæ€åÿ¥ÿ±ŸÅÿ™Ÿáÿß ÿØÿ± ÿ≠Ÿàÿ≤Ÿá ÿ¢ÿ® ÿ®ŸàÿØŸá ÿßÿ≥ÿ™.\",\n    \"fasttext\": \"fa\",\n    \"gcld3\": \"fa\"\n}\n\nFields:‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/agentlans/high-quality-multilingual-sentences.","url":"https://huggingface.co/datasets/agentlans/high-quality-multilingual-sentences","creator_name":"Alan Tseng","creator_url":"https://huggingface.co/agentlans","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","text-classification","text-retrieval","multilingual","Arabic"],"keywords_longer_than_N":true},
	{"name":"MULTICOM","keyword":"dutch","description":"This repository hosts the MULTICOM dataset, a novel benchmark for evaluating the multilingual commonsense generation abilities of Large Language Models (LLMs), as presented in the paper Do LLMs exhibit the same commonsense capabilities across languages?.\nThe dataset extends the COCOTEROS dataset to four languages: English, Spanish, Dutch, and Valencian. The task involves generating a commonsensical sentence that includes a given triplet of words.\n","url":"https://huggingface.co/datasets/gplsi/MULTICOM","creator_name":"GPLSI UA","creator_url":"https://huggingface.co/gplsi","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","English","Spanish","Dutch","Catalan"],"keywords_longer_than_N":true},
	{"name":"GammaCorpus-Polylingo-50k","keyword":"dutch","description":"\n\t\n\t\t\n\t\tGammaCorpus Polylingo 50k\n\t\n\n\n\t\n\t\t\n\t\tWhat is it?\n\t\n\nThe GammaCorpus Polylingo 50k dataset consists of 50,000 structured, unfiltered, single-turn conversations, where each interaction includes:\n\nInput: A user prompt or question.\nOutput: A response generated by an AI assistant.\nLanguage: The language used in the interaction.\n\nThis dataset is designed to help in the training and evaluation of conversational AI models for linguistic purposes. This dataset can be especially helpful if you‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/rubenroy/GammaCorpus-Polylingo-50k.","url":"https://huggingface.co/datasets/rubenroy/GammaCorpus-Polylingo-50k","creator_name":"Ruben Roy","creator_url":"https://huggingface.co/rubenroy","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","English","Russian","Vietnamese","German"],"keywords_longer_than_N":true},
	{"name":"aya_dutch_dpo_binarized","keyword":"dutch","description":"\n  \n    \n  \n\n\n\n\t\n\t\t\n\t\tDataset Card for aya_dutch_dpo\n\t\n\nThis dataset has been created with distilabel.\nThis dataset was created as part of the Data is Better Together project, in particular as part of an ongoing effort to help foster the creation of DPO/ORPO datasets for more languages.\nThe dataset was constructed using the following steps:\n\nstarting with the aya_dataset and filtering for Dutch examples\nusing the Meta-Llama-3-70B-Instruct model to generate new examples for each promptUsing‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/CultriX/aya_dutch_dpo_binarized.","url":"https://huggingface.co/datasets/CultriX/aya_dutch_dpo_binarized","creator_name":"CultriX","creator_url":"https://huggingface.co/CultriX","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","reinforcement-learning","Dutch","apache-2.0","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"test_4","keyword":"dutch","description":"\n\t\n\t\t\n\t\n\t\n\t\tFLEURS\n\t\n\nFleurs is the speech version of the FLoRes machine translation benchmark. \nWe use 2009 n-way parallel sentences from the FLoRes dev and devtest publicly available sets, in 102 languages. \nTraining sets have around 10 hours of supervision. Speakers of the train sets are different than speakers from the dev/test sets. Multilingual fine-tuning is\nused and ‚Äùunit error rate‚Äù (characters, signs) of all languages is averaged. Languages and results are also grouped into seven‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/tunngo/test_4.","url":"https://huggingface.co/datasets/tunngo/test_4","creator_name":"nguyen tuan","creator_url":"https://huggingface.co/tunngo","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","expert-generated","crowdsourced","machine-generated","crowdsourced"],"keywords_longer_than_N":true},
	{"name":"Product_Similarity_Dataset","keyword":"dutch","description":"This following dataset is a rich dataset of product similarity. The dataset has been design to be challenging to train on by having quite a lot of hard negatives\nThis dataset is especially targeted toward fine-tuning usecase, especially to finetune reranker or embedding model.\nThe data are especially adapted for listwise loss like LambdaLoss or ListNetLoss.\nThe data are in JSONL and each line follow the same format as here below : \n\nA \"query\", the anchor product label\n\"docs\", the potential‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Antix5/Product_Similarity_Dataset.","url":"https://huggingface.co/datasets/Antix5/Product_Similarity_Dataset","creator_name":"Antoine Demangeon","creator_url":"https://huggingface.co/Antix5","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-ranking","feature-extraction","French","German","Chinese"],"keywords_longer_than_N":true},
	{"name":"music_playlist","keyword":"dutch","description":"\n\t\n\t\t\n\t\tDataset Card for LifeFlow Mood & Goal Tracker Dataset\n\t\n\nThis dataset card documents the LifeFlow UI dataset extracted from a goal-tracking and self-reflection application. It includes user inputs such as mood selection, journaling notes, and goal progress updates.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset captures multiple dimensions of personal productivity and emotional status. It includes:\n\nDaily emotion selections from a predefined set (üò°, üò¢, üòê, üòä‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/amr701/music_playlist.","url":"https://huggingface.co/datasets/amr701/music_playlist","creator_name":"Amr Ahmed","creator_url":"https://huggingface.co/amr701","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":null,"first_N":5,"first_N_keywords":["English","Dutch","mit","üá∫üá∏ Region: US","self-tracking"],"keywords_longer_than_N":true},
	{"name":"epfl_english_guidelines_translated_to_dutch_with_gpt4omini","keyword":"dutch","description":"Translation of the English medical guidelines that are part of the Meditron corpus, using the LLM GPT 4o mini","url":"https://huggingface.co/datasets/UMCU/epfl_english_guidelines_translated_to_dutch_with_gpt4omini","creator_name":"Bram van Es","creator_url":"https://huggingface.co/UMCU","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["Dutch","mit","10K - 100K","json","Tabular"],"keywords_longer_than_N":true},
	{"name":"epfl_english_guidelines_translated_to_dutch_with_gpt4omini","keyword":"dutch","description":"Translation of the English medical guidelines that are part of the Meditron corpus, using the LLM GPT 4o mini","url":"https://huggingface.co/datasets/UMCU/epfl_english_guidelines_translated_to_dutch_with_gpt4omini","creator_name":"Bram van Es","creator_url":"https://huggingface.co/UMCU","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["Dutch","mit","10K - 100K","json","Tabular"],"keywords_longer_than_N":true},
	{"name":"belgisch-staatsblad","keyword":"dutch","description":"\n\t\n\t\t\n\t\tDataset Description\n\t\n\n\n\nThe most up to date data can be found here: https://huggingface.co/datasets/guust-franssens/belgian-journal\nDue to the different languages in Belgium, I decided to create three datasets belgian-journal/moniteur-belge/belgisch-staatsblad in order to make it more visible.\nDataset contains the metadata + the text of bylaw publications of Belgian companies on the Belgian Journal (Moniteur Belge/Belgisch Staatstblad).\nThis data was collected by webscraping the‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/guust-franssens/belgisch-staatsblad.","url":"https://huggingface.co/datasets/guust-franssens/belgisch-staatsblad","creator_name":"Guust Franssens","creator_url":"https://huggingface.co/guust-franssens","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","French","Dutch","German","cc0-1.0"],"keywords_longer_than_N":true},
	{"name":"Dutch-QA-Pairs-Rijksoverheid","keyword":"dutch","description":"This dataset originates from the Open Government Web Portal provided by the Dutch Government. It contains Dutch question-answer pairs (vraag-antwoord combinaties or VAC), offering insights into various governmental inquiries and corresponding responses.\nColumns: [instruction, input, output, text]\nNr. of entries: 1940\n","url":"https://huggingface.co/datasets/Nelis5174473/Dutch-QA-Pairs-Rijksoverheid","creator_name":"C. Snoeij","creator_url":"https://huggingface.co/Nelis5174473","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["question-answering","Dutch","apache-2.0","1K - 10K","csv"],"keywords_longer_than_N":true},
	{"name":"m-WildVision","keyword":"dutch","description":"\n\t\n\t\t\n\t\tDataset Card for m-WildVision\n\t\n\n\n\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\nThe m-WildVision dataset is a multilingual multimodal LLM evaluation set covering 23 languages.  It was created by translating prompts from the original English-only WildVision (vision_bench_0617) test set. \nThe original prompts, developed by Lu et al. (2024) , consist of 500 challenging user queries sourced from the WildVision-Arena platform. \nThe authors demonstrated that these prompts enable automatic LLM judge‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/CohereLabs/m-WildVision.","url":"https://huggingface.co/datasets/CohereLabs/m-WildVision","creator_name":"Cohere Labs","creator_url":"https://huggingface.co/CohereLabs","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["English","French","German","Spanish","Italian"],"keywords_longer_than_N":true},
	{"name":"open-dict-words-ipa","keyword":"dutch","description":"\n\t\n\t\t\n\t\tOpen-dict Words IPA\n\t\n\nThis dataset is a copy of https://github.com/open-dict-data/ipa-dict\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nIPA data is currently available for the following languages:\n\n\t\n\t\t\nLanguage\nCode\n\n\n\t\t\nar\nArabic (Modern Standard)\n\n\nde\nGerman\n\n\nen_UK\nEnglish (Received Pronunciation)\n\n\nen_US\nEnglish (General American)\n\n\neo\nEsperanto\n\n\nes_ES\nSpanish (Spain)\n\n\nes_MX\nSpanish (Mexico)\n\n\nfa\nPersian\n\n\nfi\nFinnish\n\n\nfr_FR\nFrench (France)\n\n\nfr_QC\nFrench (Qu√©bec)\n\n\nis\nIcelandic\n\n\nja\nJapanese\n\n\njam‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/StephanAkkerman/open-dict-words-ipa.","url":"https://huggingface.co/datasets/StephanAkkerman/open-dict-words-ipa","creator_name":"Stephan Akkerman","creator_url":"https://huggingface.co/StephanAkkerman","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["Arabic","German","English","Esperanto","Spanish"],"keywords_longer_than_N":true},
	{"name":"Phonemized-UD","keyword":"dutch","description":"\n\t\n\t\t\n\t\tPhoneme-UD: A Multilingual Phonemized Universal Dependencies Corpus for 34+ Languages\n\t\n\n\n\t\n\t\t\n\t\tG2P+ Phonemizer\n\t\n\nWe use G2P+ to phonemize Universal Dependencies. Here is an example usage: \n# Install required packages\n!apt-get install -y espeak-ng\n!pip install phonemizer g2p-plus\n# Set the environment variable from Python\nimport os\nos.environ[\"PHONEMIZER_ESPEAK_LIBRARY\"] = \"/usr/lib/x86_64-linux-gnu/libespeak-ng.so.1\"\n\n# Now run your transcription\nfrom g2p_plus import‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/suchirsalhan/Phonemized-UD.","url":"https://huggingface.co/datasets/suchirsalhan/Phonemized-UD","creator_name":"Suchir Salhan","creator_url":"https://huggingface.co/suchirsalhan","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["Afrikaans","Amharic","Arabic","Azerbaijani","Catalan"],"keywords_longer_than_N":true},
	{"name":"linkedin-industry-list","keyword":"dutch","description":"fantastic-jobs/linkedin-industry-list dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/fantastic-jobs/linkedin-industry-list","creator_name":"Fantastic.jobs","creator_url":"https://huggingface.co/fantastic-jobs","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","translation","English","Korean","Spanish"],"keywords_longer_than_N":true},
	{"name":"MKQARetrieval","keyword":"dutch","description":"\n  MKQARetrieval\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nMultilingual Knowledge Questions & Answers (MKQA)contains 10,000 queries sampled from the Google Natural Questions dataset.\n        For each query we collect new passage-independent answers. These queries and answers are then human translated into 25 Non-English languages.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2t\n\n\nDomains\nWritten\n\n\nReference\nhttps://github.com/apple/ml-mkqa\n\n\n\t\n\nSource datasets:\n\napple/mkqa\n\n\n\t\n\t\t\n\t\tHow to evaluate‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/MKQARetrieval.","url":"https://huggingface.co/datasets/mteb/MKQARetrieval","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"Creative Commons Attribution 3.0","license_url":"https://scancode-licensedb.aboutcode.org/cc-by-3.0.html","language":"en","first_N":5,"first_N_keywords":["text-retrieval","multiple-choice-qa","human-annotated","multilingual","apple/mkqa"],"keywords_longer_than_N":true},
	{"name":"Dutch-GOV-Law-wetten.overheid.nl","keyword":"dutch","description":"\n\t\n\t\t\n\t\tDutch GOV Laws\n\t\n\nThis dataset is created by scraping https://wetten.overheid.nl, I used the Sitemap to get all possible URLS.\nIt possible some URLS are missing, around 1% gave a 404 or 405 error.\nThe reason for creating this dataset is I couldn't find any other existing dataset with this data.\nSo here is this dataset, Enjoy! \n\n\t\n\t\t\n\t\n\t\n\t\tPlease note this dataset is not complety checked or cleaned, this was a short research project for myself.\n\t\n\n","url":"https://huggingface.co/datasets/ethux/Dutch-GOV-Law-wetten.overheid.nl","creator_name":"Gijsbert Westeneng","creator_url":"https://huggingface.co/ethux","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["Dutch","apache-2.0","10K - 100K","csv","Text"],"keywords_longer_than_N":true},
	{"name":"napierone-epub-raw","keyword":"dutch","description":"\n\t\n\t\t\n\t\tBEE-spoke-data/napierone-epub-raw\n\t\n\nNapierOne EPUB files converted with marker. Seems to contain mostly books from Project Gutenberg.\n\n\t\n\t\t\n\t\tdetected languages\n\t\n\nvia fasttext-langdetect\n{'ca': 1,\n 'cy': 1,\n 'da': 6,\n 'de': 105,\n 'en': 4403,\n 'eo': 2,\n 'es': 61,\n 'fi': 76,\n 'fr': 189,\n 'he': 1,\n 'hu': 5,\n 'is': 1,\n 'it': 40,\n 'la': 6,\n 'nl': 41,\n 'pl': 4,\n 'pt': 38,\n 'sv': 10,\n 'tl': 9}\n\n","url":"https://huggingface.co/datasets/BEE-spoke-data/napierone-epub-raw","creator_name":"BEEspoke Data","creator_url":"https://huggingface.co/BEE-spoke-data","license_name":"Open Data Commons Attribution License v1.0","license_url":"https://scancode-licensedb.aboutcode.org/odc-by-1.0.html","language":"en","first_N":5,"first_N_keywords":["text-generation","feature-extraction","English","Spanish","Finnish"],"keywords_longer_than_N":true},
	{"name":"PangeaBench-xm100","keyword":"dutch","description":"\n\t\n\t\t\n\t\n\t\n\t\tXM100\n\t\n\n\n\t\n\t\t\n\t\n\t\n\t\tThis is a copy from https://google.github.io/crossmodal-3600/\n\t\n\nIf you use this dataset, please cite the original authors:\n@inproceedings{ThapliyalCrossmodal2022,\n  author = {Ashish Thapliyal and Jordi Pont-Tuset and Xi Chen and Radu Soricut},\n  title = {{Crossmodal-3600: A Massively Multilingual Multimodal Evaluation Dataset}},\n  booktitle = {EMNLP},\n  year = {2022}\n}\n\n","url":"https://huggingface.co/datasets/neulab/PangeaBench-xm100","creator_name":"NeuLab @ LTI/CMU","creator_url":"https://huggingface.co/neulab","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["image-to-text","Arabic","Bengali","Czech","Danish"],"keywords_longer_than_N":true},
	{"name":"mls-annotated","keyword":"dutch","description":"\n\t\n\t\t\n\t\tDataset Card for Annotations of non English MLS\n\t\n\nThis dataset consists in annotations of a the Non English subset of the Multilingual LibriSpeech (MLS) dataset. \nMLS dataset is a large multilingual corpus suitable for speech research. The dataset is derived from read audiobooks from LibriVox and consists of \n8 languages - English, German, Dutch, Spanish, French, Italian, Portuguese, Polish. It includes about 44.5K hours of English and a total of about 6K hours for other languages.‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/PHBJT/mls-annotated.","url":"https://huggingface.co/datasets/PHBJT/mls-annotated","creator_name":"Paul Henri Biojout","creator_url":"https://huggingface.co/PHBJT","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-to-speech","French","German","Dutch","Portuguese"],"keywords_longer_than_N":true},
	{"name":"multi-hatecheck","keyword":"dutch","description":"\n  MultiHateClassification\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nHate speech detection dataset with binary\n                       (hateful vs non-hateful) labels. Includes 25+ distinct types of hate\n                       and challenging non-hate, and 11 languages.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask categoryt2c\n\n\nDomains\nConstructed, Written\n\n\nReference\nhttps://aclanthology.org/2022.woah-1.15/\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/multi-hatecheck.","url":"https://huggingface.co/datasets/mteb/multi-hatecheck","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","sentiment-analysis","sentiment-scoring","sentiment-classification","hate-speech-detection"],"keywords_longer_than_N":true},
	{"name":"cml-tts-filtered","keyword":"dutch","description":"\n\t\n\t\t\n\t\tDataset Card for Filtred and CML-TTS\n\t\n\nThis dataset is a filtred version of a CML-TTS [1]. \nCML-TTS [1] CML-TTS is a recursive acronym for CML-Multi-Lingual-TTS, a Text-to-Speech (TTS) dataset developed at the Center of Excellence in Artificial Intelligence (CEIA) of the Federal University of Goias (UFG). CML-TTS is a dataset comprising audiobooks sourced from the public domain books of Project Gutenberg, read by volunteers from the LibriVox project. The dataset includes recordings in‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/PHBJT/cml-tts-filtered.","url":"https://huggingface.co/datasets/PHBJT/cml-tts-filtered","creator_name":"Paul Henri Biojout","creator_url":"https://huggingface.co/PHBJT","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-to-speech","French","German","Dutch","Polish"],"keywords_longer_than_N":true},
	{"name":"parallel_corpus_game","keyword":"dutch","description":"https://github.com/mnbvc-parallel-corpus-team/parallel_corpus_mnbvc\nGame Corpus Collected by MNBVC Parallel Corpus Team.\n\n\t\n\t\t\n\t\t09/17/2025 Updated\n\t\n\n\nHollow Knight\n\n\n\t\n\t\t\n\t\t09/15/2025 Updated\n\t\n\n\nLimbus Company\nMirror\n\n\n\t\n\t\t\n\t\t09/08/2025 Updated\n\t\n\n\nSpice and Wolf VR (1&2)\nDeep Rock Galactic\nCities Skylines 1\n\n\n\t\n\t\t\n\t\t09/02/2025 Updated\n\t\n\n\nPlague Inc\n\n\n\t\n\t\t\n\t\t09/01/2025 Updated\n\t\n\n\nBanGDream from https://bestdori.com/\n\n\n\t\n\t\t\n\t\t08/15/2025 Updated\n\t\n\n\nATRI from‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/bot-yaya/parallel_corpus_game.","url":"https://huggingface.co/datasets/bot-yaya/parallel_corpus_game","creator_name":"yaya","creator_url":"https://huggingface.co/bot-yaya","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["translation","Arabic","Chinese","German","English"],"keywords_longer_than_N":true},
	{"name":"acl-6060","keyword":"dutch","description":"\n\t\n\t\t\n\t\tACL 60/60\n\t\n\n\n\t\n\t\t\n\t\tDataset details\n\t\n\nACL 60/60 evaluation sets for multilingual translation of ACL 2022 technical presentations into 10 target languages.\n\n\t\n\t\t\n\t\tCitation\n\t\n\n@inproceedings{salesky-etal-2023-evaluating,\n    title = \"Evaluating Multilingual Speech Translation under Realistic Conditions with Resegmentation and Terminology\",\n    author = \"Salesky, Elizabeth  and\n      Darwish, Kareem  and\n      Al-Badrashiny, Mohamed  and\n      Diab, Mona  and\n      Niehues, Jan\"‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ymoslem/acl-6060.","url":"https://huggingface.co/datasets/ymoslem/acl-6060","creator_name":"Yasmin Moslem","creator_url":"https://huggingface.co/ymoslem","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["translation","automatic-speech-recognition","English","Arabic","German"],"keywords_longer_than_N":true},
	{"name":"Global-MMLU","keyword":"dutch","description":"\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nGlobal-MMLU üåç is a multilingual evaluation set spanning 42 languages, including English. This dataset combines machine translations for MMLU questions along with professional translations and crowd-sourced post-edits.\nIt also includes cultural sensitivity annotations for a subset of the questions (2850 questions per language) and classifies them as Culturally Sensitive (CS) üóΩ or Culturally Agnostic (CA) ‚öñÔ∏è. These annotations were collected as part of an open‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/CohereLabs/Global-MMLU.","url":"https://huggingface.co/datasets/CohereLabs/Global-MMLU","creator_name":"Cohere Labs","creator_url":"https://huggingface.co/CohereLabs","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["English","Arabic","Bengali","Spanish","French"],"keywords_longer_than_N":true},
	{"name":"nemotron-dutch-mt","keyword":"dutch","description":"\n\t\n\t\t\n\t\tNemotron Post-Training Dataset (Dutch Translation)\n\t\n\nMachine-translated Dutch version of NVIDIA's Nemotron Post-Training Dataset, specifically the chat conversations.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\nSource: nvidia/Nemotron-Post-Training-Dataset-v2 (chat split)\nTranslation: English ‚Üí Dutch using Unbabel/Tower-Plus-9B\nSize: 445,287 conversations with 1,327,548 total messages\nFormat: Conversational data with original structure preserved\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Statistics\n\t\n\n\nTotal‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/pdelobelle/nemotron-dutch-mt.","url":"https://huggingface.co/datasets/pdelobelle/nemotron-dutch-mt","creator_name":"Pieter Delobelle","creator_url":"https://huggingface.co/pdelobelle","license_name":"Open Data Commons Attribution License v1.0","license_url":"https://scancode-licensedb.aboutcode.org/odc-by-1.0.html","language":"en","first_N":5,"first_N_keywords":["text-generation","Dutch","English","odc-by","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"nemotron-dutch-mt","keyword":"dutch","description":"\n\t\n\t\t\n\t\tNemotron Post-Training Dataset (Dutch Translation)\n\t\n\nMachine-translated Dutch version of NVIDIA's Nemotron Post-Training Dataset, specifically the chat conversations.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\nSource: nvidia/Nemotron-Post-Training-Dataset-v2 (chat split)\nTranslation: English ‚Üí Dutch using Unbabel/Tower-Plus-9B\nSize: 445,287 conversations with 1,327,548 total messages\nFormat: Conversational data with original structure preserved\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Statistics\n\t\n\n\nTotal‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/pdelobelle/nemotron-dutch-mt.","url":"https://huggingface.co/datasets/pdelobelle/nemotron-dutch-mt","creator_name":"Pieter Delobelle","creator_url":"https://huggingface.co/pdelobelle","license_name":"Open Data Commons Attribution License v1.0","license_url":"https://scancode-licensedb.aboutcode.org/odc-by-1.0.html","language":"en","first_N":5,"first_N_keywords":["text-generation","Dutch","English","odc-by","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"allenai_tulu-3-sft-mixture-DolphinLabeled","keyword":"dutch","description":"\n\t\n\t\t\n\t\tallenai tulu-3-sft-mixture DolphinLabeled\n\t\n\n\n\t\n\t\t\n\t\tPart of the DolphinLabeled series of datasets\n\t\n\n\n\t\n\t\t\n\t\tPresented by Eric Hartford and Cognitive Computations\n\t\n\nThe purpose of this dataset is to enable filtering of allenai/tulu-3-sft-mixture dataset.\nThe original dataset is allenai/tulu-3-sft-mixture\nI have modified the dataset using two scripts.\n\ndedupe.py - removes rows with identical final message content\nlabel.py - adds a \"flags\" column containing the following boolean‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/cognitivecomputations/allenai_tulu-3-sft-mixture-DolphinLabeled.","url":"https://huggingface.co/datasets/cognitivecomputations/allenai_tulu-3-sft-mixture-DolphinLabeled","creator_name":"Cognitive Computations","creator_url":"https://huggingface.co/cognitivecomputations","license_name":"Open Data Commons Attribution License v1.0","license_url":"https://scancode-licensedb.aboutcode.org/odc-by-1.0.html","language":"en","first_N":5,"first_N_keywords":["other","crowdsourced","expert-generated","machine-generated","multilingual"],"keywords_longer_than_N":true},
	{"name":"quran_multilingual_parallel","keyword":"dutch","description":"\n\t\n\t\t\n\t\tüìò Qur‚Äôan Multilingual Parallel Dataset (quran_multilingual_parallel)\n\t\n\nThis dataset presents a clean, structurally-aligned multilingual parallel corpus of the Qur‚Äôanic text. It is intended for linguistic, computational, and cross-lingual AI applications ‚Äî not only for religious interpretation.\nIt contains over 6,200 verse-level alignments in 54 human languages, formatted in a machine-friendly .csv structure with language-specific translation fields.\n\n\n\t\n\t\t\n\t\n\t\n\t\tüß† Dataset Highlights‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/freococo/quran_multilingual_parallel.","url":"https://huggingface.co/datasets/freococo/quran_multilingual_parallel","creator_name":"Wynn","creator_url":"https://huggingface.co/freococo","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["translation","Arabic","Albanian","Amharic","Azerbaijani"],"keywords_longer_than_N":true},
	{"name":"mteb-nl-sick","keyword":"dutch","description":"This dataset is the Dutch machine-translated and human post-edited version of the original SICK dataset, which was constructed from image and video caption descriptions.\n\n\t\n\t\t\n\t\tCitation Information\n\t\n\nIf you find our paper, benchmark or models helpful, please consider cite as follows:\n@misc{banar2025mtebnle5nlembeddingbenchmark,\n      title={MTEB-NL and E5-NL: Embedding Benchmark and Models for Dutch}, \n      author={Nikolay Banar and Ehsan Lotfi and Jens Van Nooten and Cristina Arhiliuc and‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/clips/mteb-nl-sick.","url":"https://huggingface.co/datasets/clips/mteb-nl-sick","creator_name":"CLiPS","creator_url":"https://huggingface.co/clips","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["Dutch","mit","1K - 10K","json","Text"],"keywords_longer_than_N":true},
	{"name":"Tridis","keyword":"dutch","description":"This is the first version of the dataset derived from the corpora used for TRIDIS (Tria Digita Scribunt). \nTRIDIS encompasses a series of Handwriting Text Recognition (HTR) models trained using semi-diplomatic transcriptions of medieval and early modern manuscripts.\nThe semi-diplomatic transcription approach involves resolving abbreviations found in the original manuscripts and normalizing Punctuation and Allographs.\nThe dataset contains approximately 4,000 pages of manuscripts and is‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/magistermilitum/Tridis.","url":"https://huggingface.co/datasets/magistermilitum/Tridis","creator_name":"Sergio Torres","creator_url":"https://huggingface.co/magistermilitum","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["image-to-text","French","Spanish","Latin","German"],"keywords_longer_than_N":true}
]
;
