const data_for_language_europe_romanian = 
[
	{"name":"prompt_injections","keyword":"romanian","description":"\n\t\n\t\t\n\t\tDataset Card for Prompt Injections by  Yanis Miraoui  üëã\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset of prompt injections enriches Large Language Models (LLMs) by providing task-specific examples and prompts, helping improve LLMs' performance and control their behavior.\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset contains over 1000 rows of prompt injections in multiple languages. It contains examples of prompt injections using different techniques such as: prompt leaking, jailbreaking‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/yanismiraoui/prompt_injections.","url":"https://huggingface.co/datasets/yanismiraoui/prompt_injections","creator_name":"Yanis Miraoui","creator_url":"https://huggingface.co/yanismiraoui","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["no-annotation","multilingual","original","English","French"],"keywords_longer_than_N":true},
	{"name":"xlel_wd_dictionary","keyword":"romanian","description":"XLEL-WD is a multilingual event linking dataset. This sub-dataset contains a dictionary of events from Wikidata. The multilingual descriptions for Wikidata event items are taken from the corresponding Wikipedia articles.","url":"https://huggingface.co/datasets/adithya7/xlel_wd_dictionary","creator_name":"Adithya Pratapa","creator_url":"https://huggingface.co/adithya7","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["found","found","multilingual","original","Afrikaans"],"keywords_longer_than_N":true},
	{"name":"minigpt4-7b-ggml","keyword":"romanian","description":"These are quantized ggml binary files for minigpt4 7B model.\nThese files can be used in conjunction with vicuna v0 ggml models to get minigpt4 working.\nNot all implementations were tested. If there are any issues, use f16.\n","url":"https://huggingface.co/datasets/maknee/minigpt4-7b-ggml","creator_name":"maknee","creator_url":"https://huggingface.co/maknee","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":null,"first_N":5,"first_N_keywords":["English","Bulgarian","Catalan","Czech","Danish"],"keywords_longer_than_N":true},
	{"name":"ro-paraphrase-bible","keyword":"romanian","description":"\n\t\n\t\t\n\t\tDataset Card for \"Romanian Bible Paraphrase Corpus\"\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\n\n\nHomepage: https://github.com/AndyTheFactory/ro-paraphrase-bible\nRepository: https://github.com/AndyTheFactory/ro-paraphrase-bible\nPoint of Contact: Andrei Paraschiv\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nA paraphprase corpus created from 10 different Romanian language Bible versions. Since the Bible has all paragraphs uniquely numbered an alignment between two \nversions is straighforward. \nWe compiled a‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/andyP/ro-paraphrase-bible.","url":"https://huggingface.co/datasets/andyP/ro-paraphrase-bible","creator_name":"Andrei Paraschiv","creator_url":"https://huggingface.co/andyP","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["sentence-similarity","text-scoring","semantic-similarity-scoring","semantic-similarity-classification","machine-generated"],"keywords_longer_than_N":true},
	{"name":"ro-paraphrase-bible","keyword":"romanian","description":"\n\t\n\t\t\n\t\tDataset Card for \"Romanian Bible Paraphrase Corpus\"\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\n\n\nHomepage: https://github.com/AndyTheFactory/ro-paraphrase-bible\nRepository: https://github.com/AndyTheFactory/ro-paraphrase-bible\nPoint of Contact: Andrei Paraschiv\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nA paraphprase corpus created from 10 different Romanian language Bible versions. Since the Bible has all paragraphs uniquely numbered an alignment between two \nversions is straighforward. \nWe compiled a‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/andyP/ro-paraphrase-bible.","url":"https://huggingface.co/datasets/andyP/ro-paraphrase-bible","creator_name":"Andrei Paraschiv","creator_url":"https://huggingface.co/andyP","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["sentence-similarity","text-scoring","semantic-similarity-scoring","semantic-similarity-classification","machine-generated"],"keywords_longer_than_N":true},
	{"name":"c4","keyword":"romanian","description":"\n\t\n\t\t\n\t\tC4\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nA colossal, cleaned version of Common Crawl's web crawl corpus. Based on Common Crawl dataset: \"https://commoncrawl.org\".\nThis is the processed version of Google's C4 dataset\nWe prepared five variants of the data: en, en.noclean, en.noblocklist, realnewslike, and multilingual (mC4).\nFor reference, these are the sizes of the variants:\n\nen: 305GB\nen.noclean: 2.3TB\nen.noblocklist: 380GB\nrealnewslike: 15GB\nmultilingual (mC4): 9.7TB (108 subsets, one per‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/allenai/c4.","url":"https://huggingface.co/datasets/allenai/c4","creator_name":"Ai2","creator_url":"https://huggingface.co/allenai","license_name":"Open Data Commons Attribution License v1.0","license_url":"https://scancode-licensedb.aboutcode.org/odc-by-1.0.html","language":"en","first_N":5,"first_N_keywords":["text-generation","fill-mask","language-modeling","masked-language-modeling","no-annotation"],"keywords_longer_than_N":true},
	{"name":"REDv2","keyword":"romanian","description":"\n\t\n\t\t\n\t\tDataset Card for [REDv2]\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis is the second version of the Romanian Emotions Dataset (RED) containing 5449 tweets annotated in a multi-label fashion with the following 7 emotions: Anger (Furie), Fear (FricƒÉ), Joy (Bucurie), Sadness (Triste»õe), Surprise (SurprizƒÉ), Trust (√éncredere) and Neutral (Neutru).\n\n\t\n\t\t\n\t\tSupported Tasks and Leaderboards\n\t\n\nThis dataset is intended for multi-class & multi-label emotion classification.\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nThe data is‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Alegzandra/REDv2.","url":"https://huggingface.co/datasets/Alegzandra/REDv2","creator_name":"Alexandra Ciobotaru","creator_url":"https://huggingface.co/Alegzandra","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","Romanian","mit","1K - 10K","json"],"keywords_longer_than_N":true},
	{"name":"udhr-lid","keyword":"romanian","description":"\n\t\n\t\t\n\t\tUDHR-LID\n\t\n\nWhy UDHR-LID?\nYou can access UDHR (Universal Declaration of Human Rights) here, but when a verse is missing, they have texts such as \"missing\" or \"?\". Also, about 1/3 of the sentences consist only of \"articles 1-30\" in different languages. We cleaned the entire dataset from XML files and selected only the paragraphs. We cleared any unrelated language texts from the data and also removed the cases that were incorrect.\nIncorrect? Look at the ckb and kmr files in the UDHR.‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/cis-lmu/udhr-lid.","url":"https://huggingface.co/datasets/cis-lmu/udhr-lid","creator_name":"CIS, LMU Munich","creator_url":"https://huggingface.co/cis-lmu","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["multilingual","Tigrinya","Balkan Romani","Standard Arabic","Metlat√≥noc Mixtec"],"keywords_longer_than_N":true},
	{"name":"mqa","keyword":"romanian","description":"MQA is a multilingual corpus of questions and answers parsed from the Common Crawl. Questions are divided between Frequently Asked Questions (FAQ) pages and Community Question Answering (CQA) pages.","url":"https://huggingface.co/datasets/clips/mqa","creator_name":"CLiPS","creator_url":"https://huggingface.co/clips","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["question-answering","multiple-choice-qa","no-annotation","other","multilingual"],"keywords_longer_than_N":true},
	{"name":"CC-Cat","keyword":"romanian","description":"\n\t\n\t\t\n\t\tCC_Cat\n\t\n\n\nExtract from CC-WARC snapshots.\nMainly includes texts with 149 languages.\nPDF/IMAGE/AUDIO/VIDEO raw downloading link.\n\n\n\t\n\t\t\n\t\tNotice\n\t\n\n\nSince my computing resources are limited, this dataset will update by one-day of CC snapshots timestampts.\nAfter a snapshot is updated, the deduplicated version will be uploaded.\nIf you are interested in providing computing resources or have cooperation needs, please contact me.\n  carreyallthetime@gmail.com  \n      \n  \n\n","url":"https://huggingface.co/datasets/chengshidehaimianti/CC-Cat","creator_name":"zyq","creator_url":"https://huggingface.co/chengshidehaimianti","license_name":"Open Data Commons Attribution License v1.0","license_url":"https://scancode-licensedb.aboutcode.org/odc-by-1.0.html","language":"en","first_N":5,"first_N_keywords":["text-generation","Chinese","English","German","Russian"],"keywords_longer_than_N":true},
	{"name":"oasst2","keyword":"romanian","description":"\n\t\n\t\t\n\t\tOpen Assistant Conversations Dataset Release 2 (OASST2)\n\t\n\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nThis dataset contains message trees. Each message tree has an initial prompt message as the root node, \nwhich can have multiple child messages as replies, and these child messages can have multiple replies. \nAll messages have a role property: this can either be \"assistant\" or \"prompter\". The roles in \nconversation threads from prompt to leaf node strictly alternate between \"prompter\" and‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/OpenAssistant/oasst2.","url":"https://huggingface.co/datasets/OpenAssistant/oasst2","creator_name":"OpenAssistant","creator_url":"https://huggingface.co/OpenAssistant","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["English","Spanish","Russian","German","Polish"],"keywords_longer_than_N":true},
	{"name":"fleurs","keyword":"romanian","description":"\n\t\n\t\t\n\t\tFLEURS\n\t\n\nFleurs is the speech version of the FLoRes machine translation benchmark. \nWe use 2009 n-way parallel sentences from the FLoRes dev and devtest publicly available sets, in 102 languages. \nTraining sets have around 10 hours of supervision. Speakers of the train sets are different than speakers from the dev/test sets. Multilingual fine-tuning is\nused and ‚Äùunit error rate‚Äù (characters, signs) of all languages is averaged. Languages and results are also grouped into seven‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/google/fleurs.","url":"https://huggingface.co/datasets/google/fleurs","creator_name":"Google","creator_url":"https://huggingface.co/google","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":null,"first_N":5,"first_N_keywords":["automatic-speech-recognition","expert-generated","crowdsourced","machine-generated","crowdsourced"],"keywords_longer_than_N":true},
	{"name":"tapaco","keyword":"romanian","description":"\n\t\n\t\t\n\t\tDataset Card for TaPaCo Corpus\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nA freely available paraphrase corpus for 73 languages extracted from the Tatoeba database. \nTatoeba is a crowdsourcing project mainly geared towards language learners. Its aim is to provide example sentences \nand translations for particular linguistic constructions and words. The paraphrase corpus is created by populating a \ngraph with Tatoeba sentences and equivalence links between sentences ‚Äúmeaning the same thing‚Äù. This‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/community-datasets/tapaco.","url":"https://huggingface.co/datasets/community-datasets/tapaco","creator_name":"Community Datasets","creator_url":"https://huggingface.co/community-datasets","license_name":"Creative Commons Attribution 2.0","license_url":"https://scancode-licensedb.aboutcode.org/cc-by-2.0.html","language":"en","first_N":5,"first_N_keywords":["translation","text-classification","semantic-similarity-classification","machine-generated","crowdsourced"],"keywords_longer_than_N":true},
	{"name":"ro-political","keyword":"romanian","description":"\n\t\n\t\t\n\t\tDataset Card for \"RO-Political-Texts\"\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nRO-Political Corpus is a collection of datasets for RoNLP, focused on detecting the difference between political texts written by humans, during the presidential elections from Romania (2024-2025), and synthetic texts generated with LLM models, as well as on studying linguistic characteristics such as slang, idioms, figurative expressions and \"monkey business\" behaviors in political‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/petrematei/ro-political.","url":"https://huggingface.co/datasets/petrematei/ro-political","creator_name":"Petre Matei","creator_url":"https://huggingface.co/petrematei","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","Romanian","apache-2.0","100K - 1M","csv"],"keywords_longer_than_N":true},
	{"name":"ro-political","keyword":"romanian","description":"\n\t\n\t\t\n\t\tDataset Card for \"RO-Political-Texts\"\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nRO-Political Corpus is a collection of datasets for RoNLP, focused on detecting the difference between political texts written by humans, during the presidential elections from Romania (2024-2025), and synthetic texts generated with LLM models, as well as on studying linguistic characteristics such as slang, idioms, figurative expressions and \"monkey business\" behaviors in political‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/petrematei/ro-political.","url":"https://huggingface.co/datasets/petrematei/ro-political","creator_name":"Petre Matei","creator_url":"https://huggingface.co/petrematei","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","Romanian","apache-2.0","100K - 1M","csv"],"keywords_longer_than_N":true},
	{"name":"wiki-ro-qna","keyword":"romanian","description":"\n\t\n\t\t\n\t\tDescription\n\t\n\n\n\t\n\t\t\n\t\tThere are more than 550k questions with roughly 53k paragraphs. The questions were built using the ChatGPT 3.5 API.\n\t\n\n\n\t\n\t\t\n\t\tThe dataset is based on the Romanian Wikipedia 2020 June  dump, curated by Dumitrescu Stefan.\n\t\n\n\n\t\n\t\t\n\t\tThe paragraphs retained are those between 100 and 410 words (roughly 512 max tokens), using the following script:\n\t\n\n\n# Open the text file\nwith open('wiki-ro/corpus/wiki-ro/wiki.txt.train', 'r') as file:\n    # Read the entire content‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/catalin1122/wiki-ro-qna.","url":"https://huggingface.co/datasets/catalin1122/wiki-ro-qna","creator_name":"Dsa","creator_url":"https://huggingface.co/catalin1122","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["table-question-answering","question-answering","Romanian","mit","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"multi_para_crawl","keyword":"romanian","description":"Parallel corpora from Web Crawls collected in the ParaCrawl project and further processed for making it a multi-parallel corpus by pivoting via English. Here we only provide the additional language pairs that came out of pivoting. The bitexts for English are available from the ParaCrawl release.\n40 languages, 669 bitexts\ntotal number of files: 40\ntotal number of tokens: 10.14G\ntotal number of sentence fragments: 505.48M\n\nPlease, acknowledge the ParaCrawl project at http://paracrawl.eu. This version is derived from the original release at their website adjusted for redistribution via the OPUS corpus collection. Please, acknowledge OPUS as well for this service.","url":"https://huggingface.co/datasets/Helsinki-NLP/multi_para_crawl","creator_name":"Language Technology Research Group at the University of Helsinki","creator_url":"https://huggingface.co/Helsinki-NLP","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":null,"first_N":5,"first_N_keywords":["translation","found","found","multilingual","original"],"keywords_longer_than_N":true},
	{"name":"ml_spoken_words","keyword":"romanian","description":"Multilingual Spoken Words Corpus is a large and growing audio dataset of spoken\nwords in 50 languages collectively spoken by over 5 billion people, for academic\nresearch and commercial applications in keyword spotting and spoken term search,\nlicensed under CC-BY 4.0. The dataset contains more than 340,000 keywords,\ntotaling 23.4 million 1-second spoken examples (over 6,000 hours). The dataset\nhas many use cases, ranging from voice-enabled consumer devices to call center\nautomation. This dataset is generated by applying forced alignment on crowd-sourced sentence-level\naudio to produce per-word timing estimates for extraction.\nAll alignments are included in the dataset.","url":"https://huggingface.co/datasets/MLCommons/ml_spoken_words","creator_name":"MLCommons","creator_url":"https://huggingface.co/MLCommons","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":null,"first_N":5,"first_N_keywords":["audio-classification","machine-generated","other","multilingual","extended|common_voice"],"keywords_longer_than_N":true},
	{"name":"openassistant-llama-style","keyword":"romanian","description":"\n\t\n\t\t\n\t\tChat Fine-tuning Dataset - Llama 2 Style\n\t\n\nThis dataset allows for fine-tuning chat models using [INST] AND [/INST] to wrap user messages.\nPreparation:\n\nThe dataset is cloned from TimDettmers, which itself is a subset of the Open Assistant dataset, which you can find here. This subset of the data only contains the highest-rated paths in the conversation tree, with a total of 9,846 samples.\nThe dataset was then filtered to:\n\n\nreplace instances of '### Human:' with '[INST]'\nreplace‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Trelis/openassistant-llama-style.","url":"https://huggingface.co/datasets/Trelis/openassistant-llama-style","creator_name":"Trelis","creator_url":"https://huggingface.co/Trelis","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["English","Spanish","Russian","German","Polish"],"keywords_longer_than_N":true},
	{"name":"mapa-eur-lex","keyword":"romanian","description":"\n\t\n\t\t\n\t\tDataset Card for Multilingual European Datasets for Sensitive Entity Detection in the Legal Domain\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset is a completed version of the MAPA EUR-LEX dataset, originally converted to Huggingface format by joelniklaus. See the dataset card for more information about MAPA.\n3 of the (Spanish) EUR-LEX WebAnno TSV files in the source MAPA repository are malformed, so they were omitted from the original conversion, causing under-representation of the‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/dglover1/mapa-eur-lex.","url":"https://huggingface.co/datasets/dglover1/mapa-eur-lex","creator_name":"D Glover","creator_url":"https://huggingface.co/dglover1","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["token-classification","named-entity-recognition","other","found","multilingual"],"keywords_longer_than_N":true},
	{"name":"lawinstruct","keyword":"romanian","description":"LawInstruct is an instruction tuning dataset of multilingual legal documents.","url":"https://huggingface.co/datasets/lawinstruct/lawinstruct","creator_name":"lawinstruct","creator_url":"https://huggingface.co/lawinstruct","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":null,"first_N":5,"first_N_keywords":["fill-mask","other","found","multilingual","original"],"keywords_longer_than_N":true},
	{"name":"amazon_massive_intent","keyword":"romanian","description":"\n  MassiveIntentClassification\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nMASSIVE: A 1M-Example Multilingual Natural Language Understanding Dataset with 51 Typologically-Diverse Languages\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2c\n\n\nDomains\nSpoken\n\n\nReference\nhttps://arxiv.org/abs/2204.08582\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask = mteb.get_tasks([\"MassiveIntentClassification\"])\nevaluator =‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/amazon_massive_intent.","url":"https://huggingface.co/datasets/mteb/amazon_massive_intent","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","human-annotated","translated","Afrikaans","Amharic"],"keywords_longer_than_N":true},
	{"name":"finepdfs","keyword":"romanian","description":"\n\nLiberating 3T of the finest tokens from PDFs\n\n\n\t\n\t\t\n\t\tWhat is this?\n\t\n\nAs we run out of web pages to process, the natural question has always been: what to do next? Only a few knew about a data source that everyone avoided for ages, due to its incredible extraction cost and complexity: PDFs.\nüìÑ FinePDFs is exactly that. It is the largest publicly available corpus sourced exclusively from PDFs, containing about 3 trillion tokens across 475 million documents in 1733 languages.\nCompared to HTML‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/HuggingFaceFW/finepdfs.","url":"https://huggingface.co/datasets/HuggingFaceFW/finepdfs","creator_name":"FineData","creator_url":"https://huggingface.co/HuggingFaceFW","license_name":"Open Data Commons Attribution License v1.0","license_url":"https://scancode-licensedb.aboutcode.org/odc-by-1.0.html","language":"en","first_N":5,"first_N_keywords":["text-generation","Arifama-Miniafia","Ankave","Abau","Amarasi"],"keywords_longer_than_N":true},
	{"name":"Question-Sparql","keyword":"romanian","description":"\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset contains 895,954 examples of natural language questions paired with their corresponding SPARQL queries. It spans 12 languages and targets 15 distinct knowledge graphs, with a significant portion focused on Wikidata and DBpedia.\nThe dataset was developed as a contribution for the Master Thesis: \"Impact of Continual Multilingual Pre-training on Cross-Lingual Transferability for Source Languages\". Its purpose is to facilitate research in text-to-SPARQL‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/julioc-p/Question-Sparql.","url":"https://huggingface.co/datasets/julioc-p/Question-Sparql","creator_name":"Julio Perez","creator_url":"https://huggingface.co/julioc-p","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-generation","English","German","Hebrew","Kannada"],"keywords_longer_than_N":true},
	{"name":"Granary","keyword":"romanian","description":"\n\t\n\t\t\n\t\tGranary: Speech Recognition and Translation Dataset in 25 European Languages\n\t\n\nGranary is a large-scale, open-source multilingual speech dataset covering 25 European languages for Automatic Speech Recognition (ASR) and Automatic Speech Translation (AST) tasks. \n\n\n\n\t\n\t\t\n\n\n\n\n\t\t\n\n\n\n\n\t\n\n\n\n\n\n\t\n\t\n\t\n\t\tOverview\n\t\n\nGranary addresses the scarcity of high-quality speech data for low-resource languages by consolidating multiple datasets under a unified framework:\nüó£Ô∏è ~1M hours of high-quality‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/nvidia/Granary.","url":"https://huggingface.co/datasets/nvidia/Granary","creator_name":"NVIDIA","creator_url":"https://huggingface.co/nvidia","license_name":"Creative Commons Attribution 3.0","license_url":"https://scancode-licensedb.aboutcode.org/cc-by-3.0.html","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","translation","Bulgarian","Czech","Danish"],"keywords_longer_than_N":true},
	{"name":"xP3x","keyword":"romanian","description":"\n\t\n\t\t\n\t\tDataset Card for xP3x\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\n\nxP3x (Crosslingual Public Pool of Prompts eXtended) is a collection of prompts & datasets across 277 languages & 16 NLP tasks. It contains all of xP3 + much more! It is used for training future contenders of mT0 & BLOOMZ at project Aya @Cohere Labs üß°\n\n\nCreation: The dataset can be recreated using instructions available here together with the file in this repository named xp3x_create.py. We provide this version to save processing‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/CohereLabs/xP3x.","url":"https://huggingface.co/datasets/CohereLabs/xP3x","creator_name":"Cohere Labs","creator_url":"https://huggingface.co/CohereLabs","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["other","expert-generated","crowdsourced","multilingual","Afrikaans"],"keywords_longer_than_N":true},
	{"name":"llm-metric-mrewardbench","keyword":"romanian","description":"rifqifarhansyah/llm-metric-mrewardbench dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/rifqifarhansyah/llm-metric-mrewardbench","creator_name":"Mohammad Rifqi Farhansyah","creator_url":"https://huggingface.co/rifqifarhansyah","license_name":"Open Data Commons Attribution License v1.0","license_url":"https://scancode-licensedb.aboutcode.org/odc-by-1.0.html","language":"en","first_N":5,"first_N_keywords":["Arabic","Chinese","Czech","Dutch","French"],"keywords_longer_than_N":true},
	{"name":"bhojpuri","keyword":"romanian","description":"\n\t\n\t\t\n\t\n\t\n\t\tFLEURS\n\t\n\nFleurs is the speech version of the FLoRes machine translation benchmark. \nWe use 2009 n-way parallel sentences from the FLoRes dev and devtest publicly available sets, in 102 languages. \nTraining sets have around 10 hours of supervision. Speakers of the train sets are different than speakers from the dev/test sets. Multilingual fine-tuning is\nused and ‚Äùunit error rate‚Äù (characters, signs) of all languages is averaged. Languages and results are also grouped into seven‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ankur02/bhojpuri.","url":"https://huggingface.co/datasets/ankur02/bhojpuri","creator_name":"Ankur Verma","creator_url":"https://huggingface.co/ankur02","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","expert-generated","crowdsourced","machine-generated","crowdsourced"],"keywords_longer_than_N":true},
	{"name":"vox-communis-parallel-g2p","keyword":"romanian","description":"\n\t\n\t\t\n\t\tVoxCommunis Parallel G2P dataset\n\t\n\nThis dataset was derived from the VoxCommunis Corpus to provide pairs of utterances along with their\ncorresponding phonemes, side by side, as to ease the training of grapheme-to-phoneme (G2P) models.\nThe original VoxCommunis Corpus features force-aligned TextGrids with phone- and word-level segmentations derived from the Mozilla Common Voice Corpus.\nThe lexicons were developed using Epitran, the XPF Corpus, Charsiu, and some custom dictionaries.‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/fdemelo/vox-communis-parallel-g2p.","url":"https://huggingface.co/datasets/fdemelo/vox-communis-parallel-g2p","creator_name":"Fl√°vio Eler De Melo","creator_url":"https://huggingface.co/fdemelo","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["Abkhaz","Amharic","Bashkir","Belarusian","Bulgarian"],"keywords_longer_than_N":true},
	{"name":"multilingual_translation_gen_binarized","keyword":"romanian","description":"Youseff1987/multilingual_translation_gen_binarized dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/Youseff1987/multilingual_translation_gen_binarized","creator_name":"JOON HYOUNG JUN","creator_url":"https://huggingface.co/Youseff1987","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["translation","Korean","English","Chinese","Zulu"],"keywords_longer_than_N":true},
	{"name":"label-gender_agreement-sentence-rrt-v2","keyword":"romanian","description":"hartular/label-gender_agreement-sentence-rrt-v2 dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/hartular/label-gender_agreement-sentence-rrt-v2","creator_name":"Serban Hartular","creator_url":"https://huggingface.co/hartular","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","Romanian","mit","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"opus_and_europarl_en_ro","keyword":"romanian","description":"This dataset is a combination and conversion of two En-Ro datasets published by University of Helsinki,\nspecifically Opus-100 and Europarl.\n1,404,356 En-Ro text-pair samples were extracted and combined into a single dataset.\nEach sample is a dict with two keys corresponding to the text-pair languages names: en and ro and values of those keys represent the matching text in the given languages.\nNOTE:\nSome initial analysis reveals many of these samples face formatting issues, and might be facing‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/laelhalawani/opus_and_europarl_en_ro.","url":"https://huggingface.co/datasets/laelhalawani/opus_and_europarl_en_ro","creator_name":"lael al-halawani","creator_url":"https://huggingface.co/laelhalawani","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["translation","English","Romanian","mit","1M - 10M"],"keywords_longer_than_N":true},
	{"name":"dhanishtha-2.0-superthinker","keyword":"romanian","description":"\n\t\n\t\t\n\t\tüì¶ Dhanishtha-2.0-SUPERTHINKER-MLX\n\t\n\n A distilled corpus of 11.7K high-quality samples showcasing multi-phase reasoning and structured emotional cognition. Sourced directly from the internal training data of Dhanishtha-2.0 ‚Äî the world‚Äôs first Large Language Model (LLM) to implement Intermediate Thinking, featuring multiple <think> and <ser> blocks per response\n\n\t\n\t\t\n\t\n\t\n\t\tExample with MLX-LM-LoRA:\n\t\n\nmlx_lm_lora.train \\\n--model‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mlx-community/dhanishtha-2.0-superthinker.","url":"https://huggingface.co/datasets/mlx-community/dhanishtha-2.0-superthinker","creator_name":"MLX Community","creator_url":"https://huggingface.co/mlx-community","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","Afrikaans","Arabic","Bulgarian","Catalan"],"keywords_longer_than_N":true},
	{"name":"llm-metric-mrewardbench","keyword":"romanian","description":"rubricreward/llm-metric-mrewardbench dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/rubricreward/llm-metric-mrewardbench","creator_name":"rubricreward","creator_url":"https://huggingface.co/rubricreward","license_name":"Open Data Commons Attribution License v1.0","license_url":"https://scancode-licensedb.aboutcode.org/odc-by-1.0.html","language":"en","first_N":5,"first_N_keywords":["Arabic","Chinese","Czech","Dutch","French"],"keywords_longer_than_N":true},
	{"name":"phonetic-piper-recording-studio-prompts","keyword":"romanian","description":"\n\t\n\t\t\n\t\tPhonetic Piper Studio Recordings Prompts\n\t\n\nThis dataset is a processed version of an utterance dataset made available for various languages as prompts for the Piper recording studio. Along with the original prompts, we include:\n\ncolumns ipa_espeak and ipa_epitran containing phonemized versions of the original sentences according to espeak-ng and Epitran phonemizers, respectively\ncolumns lang, espeak_lang_code, epitran_lang_code containing the language codes as reported by piper‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/fdemelo/phonetic-piper-recording-studio-prompts.","url":"https://huggingface.co/datasets/fdemelo/phonetic-piper-recording-studio-prompts","creator_name":"Fl√°vio Eler De Melo","creator_url":"https://huggingface.co/fdemelo","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["Afrikaans","Arabic","Bulgarian","Catalan","Czech"],"keywords_longer_than_N":true},
	{"name":"V1Q","keyword":"romanian","description":"from datasets import load_dataset\nds = load_dataset(\"b3x0m/Chinese-H-Novels\")\nimport sagemaker\nimport boto3\nfrom sagemaker.huggingface import HuggingFaceModel\ntry:\n    role = sagemaker.get_execution_role()\nexcept ValueError:\n    iam = boto3.client('iam')\n    role = iam.get_role(RoleName='sagemaker_execution_role')['Role']['Arn']\n\n\t\n\t\t\n\t\tHub Model configuration. https://huggingface.co/models\n\t\n\nhub = {\n    'HF_MODEL_ID':'deepseek-ai/Janus-Pro-7B',\n    'HF_TASK':'any-to-any'\n}\n\n\t\n\t\t\n\t\tcreate‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/YuRiVeRTi/V1Q.","url":"https://huggingface.co/datasets/YuRiVeRTi/V1Q","creator_name":"YuRiVeRTical","creator_url":"https://huggingface.co/YuRiVeRTi","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","table-question-answering","question-answering","zero-shot-classification"],"keywords_longer_than_N":true},
	{"name":"wmt24pp","keyword":"romanian","description":"\n\t\n\t\t\n\t\tWMT24++\n\t\n\nThis repository contains the human translation and post-edit data for the 55 en->xx language pairs released in\nthe publication\nWMT24++: Expanding the Language Coverage of WMT24 to 55 Languages & Dialects.\nIf you are interested in the MT/LLM system outputs and automatic metric scores, please see MTME.\nIf you are interested in the images of the source URLs for each document, please see here.\n\n\t\n\t\t\n\t\n\t\n\t\tSchema\n\t\n\nEach language pair is stored in its own jsonl file.\nEach row is‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/google/wmt24pp.","url":"https://huggingface.co/datasets/google/wmt24pp","creator_name":"Google","creator_url":"https://huggingface.co/google","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["translation","Arabic","Bulgarian","Bengali","Catalan"],"keywords_longer_than_N":true},
	{"name":"x-fact","keyword":"romanian","description":"\n\t\n\t\t\n\t\tDataset Card for \"x-fact\"\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nX-FACT is a multilingual dataset for fact-checking with real world claims. The dataset contains short statments in 25 languages with top five evidence documents retrieved by performing google search with claim statements. The dataset contains two additional evaluation splits (in addition to a traditional test set): ood and zeroshot. ood measures out-of-domain generalization where while the language‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/utahnlp/x-fact.","url":"https://huggingface.co/datasets/utahnlp/x-fact","creator_name":"NLP at University of Utah","creator_url":"https://huggingface.co/utahnlp","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","Arabic","Bengali","Spanish","Persian"],"keywords_longer_than_N":true},
	{"name":"librivox-tracks","keyword":"romanian","description":"A dataset of all audio files uploaded to LibriVox before 26th September 2023.\nForked from https://huggingface.co/datasets/pykeio/librivox-tracks\nChanges:\n\nUsed archive.org metadata API to annotate rows with \"duration\" column\n\n","url":"https://huggingface.co/datasets/xacer/librivox-tracks","creator_name":"xacer","creator_url":"https://huggingface.co/xacer","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-to-speech","automatic-speech-recognition","feature-extraction","Achinese","Afrikaans"],"keywords_longer_than_N":true},
	{"name":"multilingual-reward-bench","keyword":"romanian","description":"\n\t\n\t\t\n\t\tMultilingual Reward Bench (v1.0)\n\t\n\nReward models (RMs) have driven the development of state-of-the-art LLMs today, with unprecedented impact across the globe. However, their performance in multilingual settings still remains understudied. \nIn order to probe reward model behavior on multilingual data, we present M-RewardBench, a benchmark for 23 typologically diverse languages. \nM-RewardBench contains prompt-chosen-rejected preference triples obtained by curating and translating chat‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/CohereLabsCommunity/multilingual-reward-bench.","url":"https://huggingface.co/datasets/CohereLabsCommunity/multilingual-reward-bench","creator_name":"Cohere Labs Community","creator_url":"https://huggingface.co/CohereLabsCommunity","license_name":"Open Data Commons Attribution License v1.0","license_url":"https://scancode-licensedb.aboutcode.org/odc-by-1.0.html","language":"en","first_N":5,"first_N_keywords":["Arabic","Chinese","Czech","Dutch","French"],"keywords_longer_than_N":true},
	{"name":"VoxCommunis","keyword":"romanian","description":"\n\t\n\t\t\n\t\tVoxCommunis Corpus\n\t\n\nThe VoxCommunis Corpus is a phonetic corpus derived from the Mozilla Common Voice Corpus. Corresponding audio files and corpus metadata can be downloaded from Mozilla Common Voice, or from one of several Hugging Face repositories for the differing versions. \nWithin each folder, the filenames share similar structure and contain critical information for effectively using the file. More detail regarding the specifics of the filename for each file type is provided‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/pacscilab/VoxCommunis.","url":"https://huggingface.co/datasets/pacscilab/VoxCommunis","creator_name":"PaCSciLab @ UZH","creator_url":"https://huggingface.co/pacscilab","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["Abkhaz","Amharic","Bashkir","Belarusian","Bulgarian"],"keywords_longer_than_N":true},
	{"name":"common_voice_21_0","keyword":"romanian","description":"\n\t\n\t\t\n\t\tDataset Card for Common Voice Corpus 21.0\n\t\n\n\n\nThis dataset is an unofficial version of the Mozilla Common Voice Corpus 21. It was downloaded and converted from the project's website https://commonvoice.mozilla.org/.\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nAbkhaz, Albanian, Amharic, Arabic, Armenian, Assamese, Asturian, Azerbaijani, Basaa, Bashkir, Basque, Belarusian, Bengali, Breton, Bulgarian, Cantonese, Catalan, Central Kurdish, Chinese (China), Chinese (Hong Kong), Chinese (Taiwan), Chuvash, Czech‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/fsicoli/common_voice_21_0.","url":"https://huggingface.co/datasets/fsicoli/common_voice_21_0","creator_name":"Fabio Sicoli","creator_url":"https://huggingface.co/fsicoli","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":null,"first_N":5,"first_N_keywords":["automatic-speech-recognition","Abkhaz","Afrikaans","Amharic","Arabic"],"keywords_longer_than_N":true},
	{"name":"mmlux","keyword":"romanian","description":"\n\t\n\t\t\n\t\tCitation Information\n\t\n\nIf you find benchmarks useful in your research, please consider citing the test and also the MMLU dataset it draws from:\n    @misc{thellmann2024crosslingual,\n    title={Towards Cross-Lingual LLM Evaluation for European Languages},\n    author={Klaudia Thellmann and Bernhard Stadler and Michael Fromm and Jasper Schulze Buschhoff and Alex Jude and Fabio Barth and Johannes Leveling and Nicolas Flores-Herr and Joachim K√∂hler and Ren√© J√§kel and Mehdi Ali}‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Eurolingua/mmlux.","url":"https://huggingface.co/datasets/Eurolingua/mmlux","creator_name":"EuroLingua-GPT","creator_url":"https://huggingface.co/Eurolingua","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":null,"first_N":5,"first_N_keywords":["multiple-choice","expert-generated","multilingual","cais/mmlu","German"],"keywords_longer_than_N":true},
	{"name":"montok","keyword":"romanian","description":"\n\t\n\t\t\n\t\tMonTok: A Suite of Monolingual Tokenizers\n\t\n\nThis is a set of monolingual tokenizers for 98 languages. For each language, there are Unigram, BPE, and SuperBPE tokenizers, ranging in vocabulary size from around 6k to over 200k.\n\n\t\n\t\t\n\t\tTraining Details\n\t\n\n\n\t\n\t\t\n\t\tTraining Data\n\t\n\nAll tokenizers are trained on samples of the data used to the train the Goldfish language models. \nThe tokenizers were either trained on scaled or unscaled data. This refers to whether the models are trained on‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/catherinearnett/montok.","url":"https://huggingface.co/datasets/catherinearnett/montok","creator_name":"Catherine Arnett","creator_url":"https://huggingface.co/catherinearnett","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["Afrikaans","Tosk Albanian","Amharic","Standard Arabic","Assamese"],"keywords_longer_than_N":true},
	{"name":"librivox-tracks","keyword":"romanian","description":"A dataset of all audio files uploaded to LibriVox before 26th September 2023.\n","url":"https://huggingface.co/datasets/pykeio/librivox-tracks","creator_name":"pyke.io","creator_url":"https://huggingface.co/pykeio","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-to-speech","automatic-speech-recognition","Achinese","Afrikaans","Ancient Greek (to 1453)"],"keywords_longer_than_N":true},
	{"name":"yodas-granary","keyword":"romanian","description":"\n\t\n\t\t\n\t\tDataset Card for YODAS-Granary\n\t\n\n\nRepository: NeMo-speech-data-processor: Granary\nPaper: Granary: Speech Recognition and Translation Dataset in 25 European Languages\nShared by: ESPnet\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Description\n\t\n\nYODAS-Granary is a curated subset of the larger nvidia/Granary dataset, focusing on high-quality pseudo-labeled speech data for Automatic Speech Recognition (ASR) and Automatic Speech Translation (AST) across 23 European languages.\n\n\t\n\t\n\t\n\t\tOverview‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/espnet/yodas-granary.","url":"https://huggingface.co/datasets/espnet/yodas-granary","creator_name":"ESPnet","creator_url":"https://huggingface.co/espnet","license_name":"Creative Commons Attribution 3.0","license_url":"https://scancode-licensedb.aboutcode.org/cc-by-3.0.html","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","translation","Bulgarian","Czech","Danish"],"keywords_longer_than_N":true},
	{"name":"fiNERweb","keyword":"romanian","description":"fiNERweb is a multilingual named entity recognition dataset containing annotated text in multiple languages.\nEach example contains the original text, tokenized text, BIO tags, and character/token spans for entities.","url":"https://huggingface.co/datasets/whoisjones/fiNERweb","creator_name":"Jonas Golde","creator_url":"https://huggingface.co/whoisjones","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":null,"first_N":5,"first_N_keywords":["token-classification","named-entity-recognition","Vietnamese","Tamil","Oriya"],"keywords_longer_than_N":true},
	{"name":"multilingual-text","keyword":"romanian","description":"\n\t\n\t\t\n\t\tMultilingual Text Dataset\n\t\n\nThis dataset contains a curated selection of rows from multiple input datasets, where each row includes a text chunk of approximately 2000 tokens (as measured by Llama 3.1 tokenizer) verified to be written in the correct language. Only rows with properly classified language chunks are retained, ensuring high-quality multilingual data for analysis or model training.\n\n\t\n\t\t\n\t\tPreprocessing Steps\n\t\n\n\nNormalized whitespace, punctuation, Unicode characters, and‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/agentlans/multilingual-text.","url":"https://huggingface.co/datasets/agentlans/multilingual-text","creator_name":"Alan Tseng","creator_url":"https://huggingface.co/agentlans","license_name":"Open Data Commons Attribution License v1.0","license_url":"https://scancode-licensedb.aboutcode.org/odc-by-1.0.html","language":"en","first_N":5,"first_N_keywords":["text-generation","text-classification","Amharic","Arabic","Bengali"],"keywords_longer_than_N":true},
	{"name":"Chatgpt","keyword":"romanian","description":"\n\t\n\t\t\n\t\tOpenAssistant Conversations Dataset (OASST1)\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nIn an effort to democratize research on large-scale alignment, we release OpenAssistant \nConversations (OASST1), a human-generated, human-annotated assistant-style conversation \ncorpus consisting of 161,443 messages in 35 different languages, annotated with 461,292 \nquality ratings, resulting in over 10,000 fully annotated conversation trees. The corpus \nis a product of a worldwide crowd-sourcing effort‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/RajChat/Chatgpt.","url":"https://huggingface.co/datasets/RajChat/Chatgpt","creator_name":"Rajdeep Chatterjee ","creator_url":"https://huggingface.co/RajChat","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["English","Spanish","Russian","German","Polish"],"keywords_longer_than_N":true},
	{"name":"common_voice_22_0","keyword":"romanian","description":"\n\t\n\t\t\n\t\tDataset Card for Common Voice Corpus 22.0\n\t\n\n\n\nThis dataset is an unofficial version of the Mozilla Common Voice Corpus 22. It was downloaded and converted from the project's website https://commonvoice.mozilla.org/.\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nAbkhaz, Albanian, Amharic, Arabic, Armenian, Assamese, Asturian, Azerbaijani, Basaa, Bashkir, Basque, Belarusian, Bengali, Breton, Bulgarian, Cantonese, Catalan, Central Kurdish, Chinese (China), Chinese (Hong Kong), Chinese (Taiwan), Chuvash, Czech‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/fsicoli/common_voice_22_0.","url":"https://huggingface.co/datasets/fsicoli/common_voice_22_0","creator_name":"Fabio Sicoli","creator_url":"https://huggingface.co/fsicoli","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":null,"first_N":5,"first_N_keywords":["automatic-speech-recognition","Abkhaz","Afrikaans","Amharic","Arabic"],"keywords_longer_than_N":true},
	{"name":"Romanian-BabyLM","keyword":"romanian","description":"\n\t\n\t\t\n\t\tThe Romanian BabyLM Corpus\n\t\n\nLEMI - Romanian children literature corpus. Towards Building the Readability Platform for Children‚Äôs Literature in the Romanian Language\nA Representative Corpus of the Romanian Language: Resources in Underrepresented Languages (Midrigan et al, 2020, LREC), available online: https://aclanthology.org/2020.lrec-1.402/\nThe Romanian Language Repository\n\nhttps://lmidriganciochina.github.io/romaniancorpus/\nhttps://github.com/lmidriganciochina/romaniancorpus‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/climb-mao/Romanian-BabyLM.","url":"https://huggingface.co/datasets/climb-mao/Romanian-BabyLM","creator_name":"CLIMB-MAO","creator_url":"https://huggingface.co/climb-mao","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["Romanian","apache-2.0","10K - 100K","text","Text"],"keywords_longer_than_N":true},
	{"name":"text_ratings","keyword":"romanian","description":"Todo - Write dataset card\n","url":"https://huggingface.co/datasets/lightblue/text_ratings","creator_name":"Lightblue KK.","creator_url":"https://huggingface.co/lightblue","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["Amharic","Arabic","Bulgarian","Bengali","Czech"],"keywords_longer_than_N":true},
	{"name":"europa","keyword":"romanian","description":"\n\t\n\t\t\n\t\tDataset Card for EUROPA\n\t\n\nThis dataset card aims to be a base template for new datasets. It has been generated using this raw template.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nEUROPA is a dataset designed for training and evaluating multilingual keyphrase generation models in the legal domain. It consists of legal judgments from the Court of Justice of the European Union (EU) and includes instances in all 24 official EU languages.\nKey Features:\nMultilingual: Covers‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/NCube/europa.","url":"https://huggingface.co/datasets/NCube/europa","creator_name":"Neural Network Nomads (We are GLOSS)","creator_url":"https://huggingface.co/NCube","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["French","German","English","Italian","Dutch"],"keywords_longer_than_N":true},
	{"name":"xm3600","keyword":"romanian","description":"\n\t\n\t\t\n\t\n\t\n\t\tXM3600 - Crossmodal-3600\n\t\n\n\n\t\n\t\t\n\t\n\t\n\t\tThis is a copy from https://google.github.io/crossmodal-3600/\n\t\n\nIf you use this dataset, please cite the original authors:\n@inproceedings{ThapliyalCrossmodal2022,\n  author = {Ashish Thapliyal and Jordi Pont-Tuset and Xi Chen and Radu Soricut},\n  title = {{Crossmodal-3600: A Massively Multilingual Multimodal Evaluation Dataset}},\n  booktitle = {EMNLP},\n  year = {2022}\n}\n\nIt also includes the image features as PIL Image and has a uniform and‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/floschne/xm3600.","url":"https://huggingface.co/datasets/floschne/xm3600","creator_name":"Flo Schneider","creator_url":"https://huggingface.co/floschne","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["image-to-text","Arabic","Bengali","Czech","Danish"],"keywords_longer_than_N":true},
	{"name":"xm3600_1k","keyword":"romanian","description":"\n\t\n\t\t\n\t\n\t\n\t\tXM3600 - Crossmodal-3600 - 1K Split\n\t\n\n\n\t\n\t\t\n\t\n\t\n\t\tThis is a copy from https://google.github.io/crossmodal-3600/\n\t\n\nIf you use this dataset, please cite the original authors:\n@inproceedings{ThapliyalCrossmodal2022,\n  author = {Ashish Thapliyal and Jordi Pont-Tuset and Xi Chen and Radu Soricut},\n  title = {{Crossmodal-3600: A Massively Multilingual Multimodal Evaluation Dataset}},\n  booktitle = {EMNLP},\n  year = {2022}\n}\n\n\n\t\n\t\t\n\t\n\t\n\t\tThis is a 1K split of XM3600!\n\t\n\nFor this, we‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/floschne/xm3600_1k.","url":"https://huggingface.co/datasets/floschne/xm3600_1k","creator_name":"Flo Schneider","creator_url":"https://huggingface.co/floschne","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["image-to-text","Arabic","Bengali","Czech","Danish"],"keywords_longer_than_N":true},
	{"name":"newsophy-v0.1","keyword":"romanian","description":"\n\n\n\t\n\t\t\n\t\tThis dataset was used to train the pansophic-1-preview model\n\t\n\nThis dataset was created using open-source, permissively licensed models. In addition to providing answers to a diverse set of questions, we leveraged multiple open-source pipelines to generate new tasks and questions, enriching the dataset's variety and complexity. The dataset includes examples that showcase tool usage, contextual understanding, and the application of system prompts.\n\n\t\n\t\t\n\t\n\t\n\t\tTopics distribtuion in‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/pansophic/newsophy-v0.1.","url":"https://huggingface.co/datasets/pansophic/newsophy-v0.1","creator_name":"pansophic.","creator_url":"https://huggingface.co/pansophic","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","question-answering","Romanian","English","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"aya_collection_language_split","keyword":"romanian","description":"\nThis is a re-upload of the aya_collection, and only differs in the structure of upload. While the original aya_collection is structured by folders split according to dataset name, this dataset is split by language. We recommend you use this version of the dataset if you are only interested in downloading all of the Aya collection for a single or smaller set of languages.\n\n\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThe Aya Collection is a massive multilingual collection consisting of 513 million instances of‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/CohereLabs/aya_collection_language_split.","url":"https://huggingface.co/datasets/CohereLabs/aya_collection_language_split","creator_name":"Cohere Labs","creator_url":"https://huggingface.co/CohereLabs","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["Achinese","Afrikaans","Amharic","Arabic","Azerbaijani"],"keywords_longer_than_N":true},
	{"name":"fineweb-edu-translated","keyword":"romanian","description":"\n\t\n\t\t\n\t\tHelsinki-NLP/fineweb-edu-translated\n\t\n\nAutomatically translated documents from fineweb-edu. Translations are based on OPUS-MT and HPLT-MT models.\n","url":"https://huggingface.co/datasets/Helsinki-NLP/fineweb-edu-translated","creator_name":"Language Technology Research Group at the University of Helsinki","creator_url":"https://huggingface.co/Helsinki-NLP","license_name":"Open Data Commons Attribution License v1.0","license_url":"https://scancode-licensedb.aboutcode.org/odc-by-1.0.html","language":"en","first_N":5,"first_N_keywords":["text-generation","Bulgarian","Catalan","Czech","Danish"],"keywords_longer_than_N":true},
	{"name":"europa-random-split","keyword":"romanian","description":"\n\t\n\t\t\n\t\tDataset Card for EUROPA\n\t\n\nThis dataset card aims to be a base template for new datasets. It has been generated using this raw template.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nEUROPA is a dataset designed for training and evaluating multilingual keyphrase generation models in the legal domain. It consists of legal judgments from the Court of Justice of the European Union (EU) and includes instances in all 24 official EU languages.\nKey Features:\nMultilingual: Covers‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/NCube/europa-random-split.","url":"https://huggingface.co/datasets/NCube/europa-random-split","creator_name":"Neural Network Nomads (We are GLOSS)","creator_url":"https://huggingface.co/NCube","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["French","German","English","Italian","Dutch"],"keywords_longer_than_N":true},
	{"name":"Tatoeba-Translations","keyword":"romanian","description":"\n\t\n\t\t\n\t\tDataset Details\n\t\n\nThis is the latest version of Tatoeba translations as of December 2024.\nThe sentences are downloaded from the Tatoeba collection website.\nThe dataset is processed through mapping sentences.tar.bz2 using sentences_base.tar.bz2 to find source (sentence_src) and target (sentence_tgt) sentences.\nWhile lang_src and lang_tgt columns follow the mapping provided by Tatoeba, the lang_pair column merely lists the two languages in the translation pair.\n\n\t\n\t\t\n\t\n\t\n\t\tStatistics‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ymoslem/Tatoeba-Translations.","url":"https://huggingface.co/datasets/ymoslem/Tatoeba-Translations","creator_name":"Yasmin Moslem","creator_url":"https://huggingface.co/ymoslem","license_name":"Creative Commons Attribution 2.0","license_url":"https://scancode-licensedb.aboutcode.org/cc-by-2.0.html","language":"en","first_N":5,"first_N_keywords":["translation","multilingual","Abkhaz","Afrikaans","Amharic"],"keywords_longer_than_N":true},
	{"name":"biblenlp-corpus","keyword":"romanian","description":"\n\t\n\t\t\n\t\tDataset Card for BibleNLP Corpus\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nPartial and complete Bible translations in 833 languages, aligned by verse.\n\n\t\n\t\t\n\t\tLanguages\n\t\n\naai, aak, aau, aaz, abt, abx, aby, acf, acr, acu, adz, aer, aey, agd, agg, agm, agn, agr, agt, agu, aia, aii, aka, ake, alp, alq, als, aly, ame, amf, amk, amm, amn, amo, amp, amr, amu, amx, anh, anv, aoi, aoj, aom, aon, apb, ape, apn, apr, apu, apw, apz, arb, are, arl, arn, arp, asm, aso, ata, atb, atd, atg, att, auc, aui, auy‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/bible-nlp/biblenlp-corpus.","url":"https://huggingface.co/datasets/bible-nlp/biblenlp-corpus","creator_name":"The Partnership for Applied Biblical NLP","creator_url":"https://huggingface.co/bible-nlp","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":null,"first_N":5,"first_N_keywords":["translation","no-annotation","expert-generated","translation","multilingual"],"keywords_longer_than_N":true},
	{"name":"HashtagPrediction","keyword":"romanian","description":"\n\t\n\t\t\n\t\tHashtag Prediction Dataset from paper TwHIN-BERT: A Socially-Enriched Pre-trained Language Model for Multilingual Tweet Representations\n\t\n\n  \nThis repo contains the Hashtag prediction dataset from our paper TwHIN-BERT: A Socially-Enriched Pre-trained Language Model for Multilingual Tweet Representations. \n[arXiv][HuggingFace Models]\n[Github repo]\nThis work is licensed under a Creative Commons Attribution 4.0 International License.\n\n\t\n\t\t\n\t\n\t\n\t\tDownload\n\t\n\nUse the‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Twitter/HashtagPrediction.","url":"https://huggingface.co/datasets/Twitter/HashtagPrediction","creator_name":"Twitter","creator_url":"https://huggingface.co/Twitter","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["Slovenian","Urdu","Sindhi","Polish","Vietnamese"],"keywords_longer_than_N":true},
	{"name":"bernice-pretrain-data","keyword":"romanian","description":"Tweet IDs for the 2.5 billion multilingual tweets used to train Bernice, a Twitter encoder.\nThe tweets are from the public 1% Twitter API stream from January 2016 to December 2021. \nTwitter-provided language metadata is provided with the tweet ID. The data contains 66 unique languages, \nas identified by ISO 639 language codes, including `und` for undefined languages.\nTweets need to be re-gathered via the Twitter API.","url":"https://huggingface.co/datasets/jhu-clsp/bernice-pretrain-data","creator_name":"Center for Language and Speech Processing @ JHU","creator_url":"https://huggingface.co/jhu-clsp","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":null,"first_N":5,"first_N_keywords":["other","no-annotation","found","multilingual","original"],"keywords_longer_than_N":true},
	{"name":"lextreme","keyword":"romanian","description":"The LEXTREME Benchmark is a collection of multilingual datasets for evaluating model performance \nacross a diverse set of legal NLU tasks.","url":"https://huggingface.co/datasets/joelniklaus/lextreme","creator_name":"Joel Niklaus","creator_url":"https://huggingface.co/joelniklaus","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","multi-class-classification","multi-label-classification","topic-classification"],"keywords_longer_than_N":true},
	{"name":"ro-MetaMathQA","keyword":"romanian","description":"This dataset is a translation of meta-math/MetaMathQA, using LLMic, a bilingual Romanian-English LLM.\n@article{yu2023metamath,\n  title={MetaMath: Bootstrap Your Own Mathematical Questions for Large Language Models},\n  author={Yu, Longhui and Jiang, Weisen and Shi, Han and Yu, Jincheng and Liu, Zhengying and Zhang, Yu and Kwok, James T and Li, Zhenguo and Weller, Adrian and Liu, Weiyang},\n  journal={arXiv preprint arXiv:2309.12284},\n  year={2023}\n}\n\n@article{buadoiu2025llmic,\n  title={LLMic:‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/faur-ai/ro-MetaMathQA.","url":"https://huggingface.co/datasets/faur-ai/ro-MetaMathQA","creator_name":"faur-ai","creator_url":"https://huggingface.co/faur-ai","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["Romanian","mit","100K - 1M","json","Text"],"keywords_longer_than_N":true},
	{"name":"ro-offense","keyword":"romanian","description":"\n\t\n\t\t\n\t\tDataset Card for \"RO-Offense-Sequences\"\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\n\n\nHomepage: https://github.com/readerbench/ro-offense-sequences\nRepository: https://github.com/readerbench/ro-offense-sequences\nPoint of Contact: Andrei Paraschiv\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\na novel Romanian language dataset for offensive language detection with manually \nannotated offensive labels from a local Romanian sports news website (gsp.ro):\nResulting in 12,445 annotated messages\n\n\t\n\t\n\t\n\t\tLanguages‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/readerbench/ro-offense.","url":"https://huggingface.co/datasets/readerbench/ro-offense","creator_name":"ReaderBench","creator_url":"https://huggingface.co/readerbench","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","hate-speech-detection","expert-generated","found","monolingual"],"keywords_longer_than_N":true},
	{"name":"ro-offense","keyword":"romanian","description":"\n\t\n\t\t\n\t\tDataset Card for \"RO-Offense-Sequences\"\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\n\n\nHomepage: https://github.com/readerbench/ro-offense-sequences\nRepository: https://github.com/readerbench/ro-offense-sequences\nPoint of Contact: Andrei Paraschiv\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\na novel Romanian language dataset for offensive language detection with manually \nannotated offensive labels from a local Romanian sports news website (gsp.ro):\nResulting in 12,445 annotated messages\n\n\t\n\t\n\t\n\t\tLanguages‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/readerbench/ro-offense.","url":"https://huggingface.co/datasets/readerbench/ro-offense","creator_name":"ReaderBench","creator_url":"https://huggingface.co/readerbench","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","hate-speech-detection","expert-generated","found","monolingual"],"keywords_longer_than_N":true},
	{"name":"mfaq","keyword":"romanian","description":"We present the first multilingual FAQ dataset publicly available. We collected around 6M FAQ pairs from the web, in 21 different languages.","url":"https://huggingface.co/datasets/clips/mfaq","creator_name":"CLiPS","creator_url":"https://huggingface.co/clips","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["question-answering","multiple-choice-qa","no-annotation","other","multilingual"],"keywords_longer_than_N":true},
	{"name":"Open_Assistant_Conversation_Chains","keyword":"romanian","description":"\n\t\n\t\t\n\t\tDataset Card for Dataset Name\n\t\n\n\n\t\n\t\t\n\t\tDataset description\n\t\n\n\n\nThis dataset is a reformatting of OpenAssistant Conversations (OASST1), which is\n\na human-generated, human-annotated assistant-style conversation corpus consisting of 161,443 messages in 35 different languages, annotated with 461,292 quality ratings, resulting in over 10,000 fully annotated conversation trees. The corpus is a product of a worldwide crowd-sourcing effort involving over 13,500 volunteers.\n\nIt was modified‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/m-ric/Open_Assistant_Conversation_Chains.","url":"https://huggingface.co/datasets/m-ric/Open_Assistant_Conversation_Chains","creator_name":"Aymeric Roucher","creator_url":"https://huggingface.co/m-ric","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","English","Spanish","Russian","German"],"keywords_longer_than_N":true},
	{"name":"legal-mc4","keyword":"romanian","description":"Legal-MC4: A Corpus Covering the Legal Part of MC4 for European Languages","url":"https://huggingface.co/datasets/joelniklaus/legal-mc4","creator_name":"Joel Niklaus","creator_url":"https://huggingface.co/joelniklaus","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["fill-mask","other","found","multilingual","original"],"keywords_longer_than_N":true},
	{"name":"ro-camelai","keyword":"romanian","description":"This dataset is a translation of camel-ai/math, camel-ai/chemistry, camel-ai/biology, camel-ai/physics\nusing LLMic, a bilingual Romanian-English LLM.\n@misc{li2023camel,\n      title={CAMEL: Communicative Agents for \"Mind\" Exploration of Large Scale Language Model Society}, \n      author={Guohao Li and Hasan Abed Al Kader Hammoud and Hani Itani and Dmitrii Khizbullin and Bernard Ghanem},\n      year={2023},\n      eprint={2303.17760},\n      archivePrefix={arXiv},\n      primaryClass={cs.AI}\n}‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/faur-ai/ro-camelai.","url":"https://huggingface.co/datasets/faur-ai/ro-camelai","creator_name":"faur-ai","creator_url":"https://huggingface.co/faur-ai","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","Romanian","cc-by-4.0","100K - 1M","json"],"keywords_longer_than_N":true},
	{"name":"ggml-vicuna-v0-quantized","keyword":"romanian","description":"These are quantized ggml binary files for vicuna 7B and 13B models. The version of vicuna for these models are v0.\nThese files can be used in conjunction with minigpt4 ggml models 7B and 13B in minigpt4.cpp\nRecommended are the Q5_K and Q6_K implementations. If there are any issues, use Q4_1 or Q4_0.\n\n\n\t\n\t\t\n\t\n\t\n\t\tVicuna Model Card\n\t\n\n\n\t\n\t\t\n\t\n\t\n\t\tModel details\n\t\n\nModel type:\nVicuna is an open-source chatbot trained by fine-tuning LLaMA on user-shared conversations collected from ShareGPT.\nIt is‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/maknee/ggml-vicuna-v0-quantized.","url":"https://huggingface.co/datasets/maknee/ggml-vicuna-v0-quantized","creator_name":"maknee","creator_url":"https://huggingface.co/maknee","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["English","Bulgarian","Catalan","Czech","Danish"],"keywords_longer_than_N":true},
	{"name":"europa_eac_tm","keyword":"romanian","description":"\n\t\n\t\t\n\t\tDataset Card for Europa Education and Culture Translation Memory (EAC-TM)\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset is a corpus of manually produced translations from english to up to 25 languages, released in 2012 by the European Union's Directorate General for Education and Culture (EAC).\nTo load a language pair that is not part of the config, just specify the language code as language pair. For example, if you want to translate Czech to Greek:\ndataset = load_dataset(\"europa_eac_tm\"‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/community-datasets/europa_eac_tm.","url":"https://huggingface.co/datasets/community-datasets/europa_eac_tm","creator_name":"Community Datasets","creator_url":"https://huggingface.co/community-datasets","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["translation","expert-generated","expert-generated","translation","original"],"keywords_longer_than_N":true},
	{"name":"eur-lex-sum","keyword":"romanian","description":"The EUR-Lex-Sum dataset is a multilingual resource intended for text summarization in the legal domain.\nIt is based on human-written summaries of legal acts issued by the European Union.\nIt distinguishes itself by introducing a smaller set of high-quality human-written samples,\neach of which have much longer references (and summaries!) than comparable datasets.\nAdditionally, the underlying legal acts provide a challenging domain-specific application to legal texts,\nwhich are so far underrepresented in non-English languages.\nFor each legal act, the sample can be available in up to 24 languages\n(the officially recognized languages in the European Union);\nthe validation and test samples consist entirely of samples available in all languages,\nand are aligned across all languages at the paragraph level.","url":"https://huggingface.co/datasets/dennlinger/eur-lex-sum","creator_name":"Dennis Aumiller","creator_url":"https://huggingface.co/dennlinger","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":null,"first_N":5,"first_N_keywords":["translation","summarization","found","expert-generated","found"],"keywords_longer_than_N":true},
	{"name":"paraphrase-ro","keyword":"romanian","description":"\n\t\n\t\t\n\t\tRomanian paraphrase dataset\n\t\n\nThis data set was created by me, special for paraphrase\nt5-small-paraphrase-ro\nt5-small-paraphrase-ro-v2\nt5-base-paraphrase-ro\nt5-base-paraphrase-ro-v2\nHere you can find ~100k examples of paraphrase.\n","url":"https://huggingface.co/datasets/BlackKakapo/paraphrase-ro","creator_name":"Alexandru Petrachi","creator_url":"https://huggingface.co/BlackKakapo","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["monolingual","Romanian","apache-2.0","10K - 100K","csv"],"keywords_longer_than_N":true},
	{"name":"EU_Wikipedias","keyword":"romanian","description":"Wikipedia dataset containing cleaned articles of all languages.\nThe datasets are built from the Wikipedia dump\n(https://dumps.wikimedia.org/) with one split per language. Each example\ncontains the content of one full Wikipedia article with cleaning to strip\nmarkdown and unwanted sections (references, etc.).","url":"https://huggingface.co/datasets/joelniklaus/EU_Wikipedias","creator_name":"Joel Niklaus","creator_url":"https://huggingface.co/joelniklaus","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["fill-mask","other","found","multilingual","original"],"keywords_longer_than_N":true},
	{"name":"nllb-200-10M-sample","keyword":"romanian","description":"\n\t\n\t\t\n\t\tDataset Card for \"nllb-200-10M-sample\"\n\t\n\nThis is a sample of nearly 10M sentence pairs from the NLLB-200 \nmined dataset allenai/nllb, \nscored with the model facebook/blaser-2.0-qe \ndescribed in the SeamlessM4T paper.\nThe sample is not random; instead, we just took the top n sentence pairs from each translation direction.\nThe number n was computed with the goal of upsamping the directions that contain underrepresented languages.\nNevertheless, the 187 languoids (language and script‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/slone/nllb-200-10M-sample.","url":"https://huggingface.co/datasets/slone/nllb-200-10M-sample","creator_name":"SLONE","creator_url":"https://huggingface.co/slone","license_name":"Open Data Commons Attribution License v1.0","license_url":"https://scancode-licensedb.aboutcode.org/odc-by-1.0.html","language":"en","first_N":5,"first_N_keywords":["translation","Akan","Amharic","Arabic","Awadhi"],"keywords_longer_than_N":true},
	{"name":"bible_para","keyword":"romanian","description":"This is a multilingual parallel corpus created from translations of the Bible compiled by Christos Christodoulopoulos and Mark Steedman.\n\n102 languages, 5,148 bitexts\ntotal number of files: 107\ntotal number of tokens: 56.43M\ntotal number of sentence fragments: 2.84M","url":"https://huggingface.co/datasets/Helsinki-NLP/bible_para","creator_name":"Language Technology Research Group at the University of Helsinki","creator_url":"https://huggingface.co/Helsinki-NLP","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":null,"first_N":5,"first_N_keywords":["translation","found","found","multilingual","original"],"keywords_longer_than_N":true},
	{"name":"CulturaY","keyword":"romanian","description":"\n\t\n\t\t\n\t\tCulturaY: A Large Cleaned Multilingual Dataset of 75 Languages\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nFrom the team that brought you CulturaX, we present CulturaY, another substantial multilingual dataset of 15TB (uncompressed)/3TB (zstd-compressed) that applies the same dataset cleaning methodology to the HPLT v1.1 dataset. \nPlease note that HPLT v1.2 has also been released and is an alternative verison with different cleaning methodolgies. \nThis data was used in part to train our SOTA‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Viet-Mistral/CulturaY.","url":"https://huggingface.co/datasets/Viet-Mistral/CulturaY","creator_name":"Vietnamese Mistral","creator_url":"https://huggingface.co/Viet-Mistral","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","fill-mask","language-modeling","masked-language-modeling","no-annotation"],"keywords_longer_than_N":true},
	{"name":"Fact-Completion","keyword":"romanian","description":"\n\t\n\t\t\n\t\tDataset Card\n\t\n\n\nHomepage: https://bit.ly/ischool-berkeley-capstone\nRepository: https://github.com/daniel-furman/Capstone\nPoint of Contact: daniel_furman@berkeley.edu\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis is the dataset for Polyglot or Not?: Measuring Multilingual Encyclopedic Knowledge Retrieval from Foundation Language Models.\n\n\t\n\t\t\n\t\n\t\n\t\tTest Description\n\t\n\n Given a factual association such as The capital of France is Paris, we determine whether a model adequately \"knows\" this‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Polyglot-or-Not/Fact-Completion.","url":"https://huggingface.co/datasets/Polyglot-or-Not/Fact-Completion","creator_name":"Polyglot-or-Not","creator_url":"https://huggingface.co/Polyglot-or-Not","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","fill-mask","expert-generated","machine-generated","multilingual"],"keywords_longer_than_N":true},
	{"name":"mc4_legal","keyword":"romanian","description":"\n\t\n\t\t\n\t\tDataset Card for MC4_Legal: A Corpus Covering the Legal Part of MC4 for European Languages\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset contains large text resources (~133GB in total) from mc4 filtered for legal data that can be used for pretraining language models.\nUse the dataset like this:\nfrom datasets import load_dataset\ndataset = load_dataset(\"joelito/mc4_legal\", \"de\", split='train', streaming=True)\n\n\n\t\n\t\t\n\t\n\t\n\t\tSupported Tasks and Leaderboards\n\t\n\nThe dataset supports the task of‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/joelniklaus/mc4_legal.","url":"https://huggingface.co/datasets/joelniklaus/mc4_legal","creator_name":"Joel Niklaus","creator_url":"https://huggingface.co/joelniklaus","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["fill-mask","other","found","multilingual","original"],"keywords_longer_than_N":true},
	{"name":"ro-political-ai","keyword":"romanian","description":"\n\t\n\t\t\n\t\tDataset Card for \"RO-Political-Texts\"\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nRO-Political-AI is a collection of datasets for RoNLP, focused on detecting the difference between political texts written by humans, during the presidential elections from Romania (2024-2025), and synthetic texts generated with LLM models, as well as on studying linguistic characteristics such as slang, idioms, figurative expressions and \"monkey business\" behaviors in political discourse‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/petrematei/ro-political-ai.","url":"https://huggingface.co/datasets/petrematei/ro-political-ai","creator_name":"Petre Matei","creator_url":"https://huggingface.co/petrematei","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","Romanian","apache-2.0","100K - 1M","csv"],"keywords_longer_than_N":true},
	{"name":"ro-political-ai","keyword":"romanian","description":"\n\t\n\t\t\n\t\tDataset Card for \"RO-Political-Texts\"\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nRO-Political-AI is a collection of datasets for RoNLP, focused on detecting the difference between political texts written by humans, during the presidential elections from Romania (2024-2025), and synthetic texts generated with LLM models, as well as on studying linguistic characteristics such as slang, idioms, figurative expressions and \"monkey business\" behaviors in political discourse‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/petrematei/ro-political-ai.","url":"https://huggingface.co/datasets/petrematei/ro-political-ai","creator_name":"Petre Matei","creator_url":"https://huggingface.co/petrematei","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","Romanian","apache-2.0","100K - 1M","csv"],"keywords_longer_than_N":true},
	{"name":"eurlex_resources","keyword":"romanian","description":"\n\t\n\t\t\n\t\tDataset Card for EurlexResources: A Corpus Covering the Largest EURLEX Resources\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset contains large text resources (~179GB in total) from EURLEX that can be used for pretraining language models.\nUse the dataset like this:\nfrom datasets import load_dataset\nconfig = \"de_caselaw\" # {lang}_{resource}\ndataset = load_dataset(\"joelito/eurlex_resources\", config, split='train', streaming=True) \n\n\n\t\n\t\t\n\t\n\t\n\t\tSupported Tasks and Leaderboards\n\t\n\nThe dataset‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/joelniklaus/eurlex_resources.","url":"https://huggingface.co/datasets/joelniklaus/eurlex_resources","creator_name":"Joel Niklaus","creator_url":"https://huggingface.co/joelniklaus","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":null,"first_N":5,"first_N_keywords":["fill-mask","other","found","multilingual","original"],"keywords_longer_than_N":true},
	{"name":"ro_sts","keyword":"romanian","description":"The RO-STS (Romanian Semantic Textual Similarity) dataset contains 8628 pairs of sentences with their similarity score. It is a high-quality translation of the STS benchmark dataset.","url":"https://huggingface.co/datasets/dumitrescustefan/ro_sts","creator_name":"Dumitrescu Stefan","creator_url":"https://huggingface.co/dumitrescustefan","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":null,"first_N":5,"first_N_keywords":["text-classification","text-scoring","semantic-similarity-scoring","crowdsourced","crowdsourced"],"keywords_longer_than_N":true},
	{"name":"ro-human-machine-60k","keyword":"romanian","description":"The corpus for this study consists of multiple datasets of comparable text lengths, both machine-generated and human-written.\n\n1401 books: \n\n841 manually written abstracts provided by the Central University Library of Bucharest, representing descriptions of Romanian old documents (literary magazines and books dated between the 19th century and the present),\n560 books descriptions (cartigratis.com, accessed 8 January 2024);\n\n\n4320 news articles crawled from DigiNews (digi24.ro, accessed 8‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/readerbench/ro-human-machine-60k.","url":"https://huggingface.co/datasets/readerbench/ro-human-machine-60k","creator_name":"ReaderBench","creator_url":"https://huggingface.co/readerbench","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","translation","Romanian","apache-2.0","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"xP3x-sample","keyword":"romanian","description":"A multilingual collection of Winograd Schemas in six languages that can be used for evaluation of cross-lingual commonsense reasoning capabilities.","url":"https://huggingface.co/datasets/Muennighoff/xP3x-sample","creator_name":"Niklas Muennighoff","creator_url":"https://huggingface.co/Muennighoff","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["other","expert-generated","crowdsourced","multilingual","Afrikaans"],"keywords_longer_than_N":true},
	{"name":"ro-romani","keyword":"romanian","description":"\n\t\n\t\t\n\t\tDataset Card for \"ro-romani\"\n\t\n\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\nThis dataset consists of parallel sentences extracted from online versions of the Bible (both Old and New Testaments) for the Romanian and Kalderash Romani languages.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\n\t\n\t\t\n\t\tData Instances\n\t\n\nAn example looks like this:\n{\n 'book': 'GEN',\n 'chapter': 38,\n 'ro': 'A mai nascut iarasi un fiu, caruia i-a pus numele Sela; Iuda era la '\n       'Czib cand a nascut ea.',\n 'rom': 'Mai kƒÉrdea pale khƒÉ ≈°eau‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/IoanRazvan/ro-romani.","url":"https://huggingface.co/datasets/IoanRazvan/ro-romani","creator_name":"Ioan Razvan Rusu","creator_url":"https://huggingface.co/IoanRazvan","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["translation","Romanian","mit","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"ELTeC-rom","keyword":"romanian","description":"Original github link : https://github.com/COST-ELTeC/ELTeC-rom\n","url":"https://huggingface.co/datasets/ClaudiuT/ELTeC-rom","creator_name":"Claudiu Traistaru","creator_url":"https://huggingface.co/ClaudiuT","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["Romanian","mit","100K - 1M","parquet","Text"],"keywords_longer_than_N":true},
	{"name":"ELTeC-rom","keyword":"romanian","description":"Original github link : https://github.com/COST-ELTeC/ELTeC-rom\n","url":"https://huggingface.co/datasets/ClaudiuT/ELTeC-rom","creator_name":"Claudiu Traistaru","creator_url":"https://huggingface.co/ClaudiuT","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["Romanian","mit","100K - 1M","parquet","Text"],"keywords_longer_than_N":true},
	{"name":"xsimplusplus","keyword":"romanian","description":"xSIM++ is an extension of xSIM. In comparison to xSIM, this evaluates using target-side data with additional synthetic, hard-to-distinguish examples. You can find more details about it in the publication: xSIM++: An Improved Proxy to Bitext Mining Performance for Low-Resource Languages.\n","url":"https://huggingface.co/datasets/jaygala24/xsimplusplus","creator_name":"Jay Gala","creator_url":"https://huggingface.co/jaygala24","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["derived","multilingual","Achinese","Mesopotamian Arabic","Ta'izzi-Adeni Arabic"],"keywords_longer_than_N":true},
	{"name":"truthfulqax","keyword":"romanian","description":"\n\t\n\t\t\n\t\tCitation Information\n\t\n\nIf you find benchmarks useful in your research, please consider citing the test and also the TruthfulQA dataset it draws from:\n    @misc{thellmann2024crosslingual,\n    title={Towards Cross-Lingual LLM Evaluation for European Languages},\n    author={Klaudia Thellmann and Bernhard Stadler and Michael Fromm and Jasper Schulze Buschhoff and Alex Jude and Fabio Barth and Johannes Leveling and Nicolas Flores-Herr and Joachim K√∂hler and Ren√© J√§kel and Mehdi Ali}‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Eurolingua/truthfulqax.","url":"https://huggingface.co/datasets/Eurolingua/truthfulqax","creator_name":"EuroLingua-GPT","creator_url":"https://huggingface.co/Eurolingua","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":null,"first_N":5,"first_N_keywords":["text-generation","German","French","Spanish","Italian"],"keywords_longer_than_N":true},
	{"name":"ro_wiki","keyword":"romanian","description":"\n\t\n\t\t\n\t\tDataset Description\n\t\n\n\nRoWiki is cleaned dump of the June 2020 Romanian Wikipedia. It is meant as a reference text upon which to calculate Language Model capacity and/or perplexity. \nThis dataset is used as a benchmark and is part of the evaluation protocol for Romanian LLMs proposed in \"Vorbe≈üti Rom√¢ne≈üte?\" A Recipe to Train Powerful Romanian LLMs with English Instructions (Masala et al., 2024)\n\n\t\n\t\t\n\t\n\t\n\t\tCitation\n\t\n\n\n\n@article{masala2024vorbecstiromanecsterecipetrain‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/OpenLLM-Ro/ro_wiki.","url":"https://huggingface.co/datasets/OpenLLM-Ro/ro_wiki","creator_name":"OpenLLM-Ro","creator_url":"https://huggingface.co/OpenLLM-Ro","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["Romanian","mit","100K - 1M","json","Text"],"keywords_longer_than_N":true},
	{"name":"biblenlp-corpus-mmteb","keyword":"romanian","description":"This dataset pre-computes all English-centric directions from bible-nlp/biblenlp-corpus, and as a result loading is significantly faster.\nLoading example:\n>>> from datasets import load_dataset\n>>> dataset = load_dataset(\"davidstap/biblenlp-corpus-mmteb\", \"eng-arb\", trust_remote_code=True)\n>>> dataset\nDatasetDict({\n    train: Dataset({\n        features: ['eng', 'arb'],\n        num_rows: 28723\n    })\n    validation: Dataset({\n        features: ['eng', 'arb'],\n        num_rows: 1578\n    })‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/biblenlp-corpus-mmteb.","url":"https://huggingface.co/datasets/mteb/biblenlp-corpus-mmteb","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["no-annotation","expert-generated","translation","multilingual","Arifama-Miniafia"],"keywords_longer_than_N":true},
	{"name":"bad_sentences_ro_gender","keyword":"romanian","description":"hartular/bad_sentences_ro_gender dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/hartular/bad_sentences_ro_gender","creator_name":"Serban Hartular","creator_url":"https://huggingface.co/hartular","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","question-answering","Romanian","mit","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"amazon_massive_scenario","keyword":"romanian","description":"\n  MassiveScenarioClassification\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nMASSIVE: A 1M-Example Multilingual Natural Language Understanding Dataset with 51 Typologically-Diverse Languages\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2c\n\n\nDomains\nSpoken\n\nReference\nhttps://arxiv.org/abs/2204.08582\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask = mteb.get_tasks([\"MassiveScenarioClassification\"])\nevaluator =‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/amazon_massive_scenario.","url":"https://huggingface.co/datasets/mteb/amazon_massive_scenario","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","human-annotated","translated","Afrikaans","Amharic"],"keywords_longer_than_N":true},
	{"name":"MAiDE-up","keyword":"romanian","description":"\n\t\n\t\t\n\t\tDataset Card for MAiDE-up: Multilingual Deception Detection of GPT-generated Hotel Reviews\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nMultilingual Deception Detection of GPT-generated Hotel Reviews. We compare real hotel reviews from Booking with LLM-generated hotel reviews in 10 languages.\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nThe text in the dataset is in 10 languages: Chinese, English, French, German, Italian, Romanian, Korean, Russian, Spanish, Turkish\n\n\t\n\t\t\n\t\tSupported Tasks and Leaderboards\n\t\n\nTODO‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/MichiganNLP/MAiDE-up.","url":"https://huggingface.co/datasets/MichiganNLP/MAiDE-up","creator_name":"LIT @ UMich","creator_url":"https://huggingface.co/MichiganNLP","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","zero-shot-classification","English","Chinese","French"],"keywords_longer_than_N":true},
	{"name":"Moroco","keyword":"romanian","description":"\n  Moroco\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nThe Moldavian and Romanian Dialectal Corpus. The MOROCO data set contains Moldavian and Romanian samples of text collected from the news domain. The samples belong to one of the following six topics: (0) culture, (1) finance, (2) politics, (3) science, (4) sports, (5) tech\n\n\t\n\t\t\n\n\n\n\t\t\nTask category\nt2c\n\n\nDomains\nNews, Written\n\n\nReference\nhttps://huggingface.co/datasets/moroco\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/Moroco.","url":"https://huggingface.co/datasets/mteb/Moroco","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","topic-classification","derived","monolingual","Romanian"],"keywords_longer_than_N":true},
	{"name":"mewsli-x","keyword":"romanian","description":"I generated the dataset following mewsli-x.md#getting-started\nand converted into different parts (see process.py):\n\nar/de/en/es/fa/ja/pl/ro/ta/tr/uk wikinews_mentions dev and test (from wikinews_mentions-dev/test.jsonl)\ncandidate entities of 50 languages (from candidate_set_entities.jsonl)\nEnglish wikipedia_pairs to fine-tune models (from wikipedia_pairs-dev/train.jsonl)\n\nRaw data files are in raw.tar.gz, which contains:\n[...] 535M Feb 24 22:06 candidate_set_entities.jsonl\n[...] 9.8M Feb 24‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/izhx/mewsli-x.","url":"https://huggingface.co/datasets/izhx/mewsli-x","creator_name":"Xin Zhang","creator_url":"https://huggingface.co/izhx","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","entity-linking-retrieval","Afrikaans","Arabic","Azerbaijani"],"keywords_longer_than_N":true},
	{"name":"Jjsjd","keyword":"romanian","description":"Gargaz/Jjsjd dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/Gargaz/Jjsjd","creator_name":"LUCA ","creator_url":"https://huggingface.co/Gargaz","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["Romanian","apache-2.0","10K - 100K","csv","Text"],"keywords_longer_than_N":true},
	{"name":"morovoc","keyword":"romanian","description":"\n\t\n\t\t\n\t\tMoRoVoc\n\t\n\nMoRoVoc is a dataset that contains audio recordings with the following metadata:\n\nrecord_id: Unique identifier for each record\ndialect: Dialect/language variant of the speaker (i.e., either Romanian or Moldavian)\ngender: Gender of the speaker\nage: Age range of the speaker\naudio: Audio file (WAV format)\nsr: Sample rate of the audio\n\nYou can read more about the dataset in the following paper: work in progress.\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Structure\n\t\n\n\nTrain: 77638 samples\nValidation:‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/avramandrei/morovoc.","url":"https://huggingface.co/datasets/avramandrei/morovoc","creator_name":"Andrei-Marius Avram","creator_url":"https://huggingface.co/avramandrei","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["audio-classification","Romanian","mit","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"FairytaleQA-translated-romanian","keyword":"romanian","description":"\n\t\n\t\t\n\t\tDataset Card for FairytaleQA-translated-ptBR\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis repository contains the Romanian machine-translated version of the original English FairytaleQA dataset (https://huggingface.co/datasets/WorkInTheDark/FairytaleQA). FairytaleQA is an open-source dataset designed to enhance comprehension of narratives, aimed at students from kindergarten to eighth grade. The dataset is meticulously annotated by education experts following an evidence-based theoretical‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/benjleite/FairytaleQA-translated-romanian.","url":"https://huggingface.co/datasets/benjleite/FairytaleQA-translated-romanian","creator_name":"Bernardo Leite","creator_url":"https://huggingface.co/benjleite","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["question-answering","text-generation","Romanian","apache-2.0","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"muri-it-language-split","keyword":"romanian","description":"\n\t\n\t\t\n\t\tMURI-IT: Multilingual Instruction Tuning Dataset for 200 Languages via Multilingual Reverse Instructions\n\t\n\nMURI-IT is a large-scale multilingual instruction tuning dataset containing 2.2 million instruction-output pairs across 200 languages. It is designed to address the challenges of instruction tuning in low-resource languages with Multilingual Reverse Instructions (MURI), which ensures that the output is human-written, high-quality, and authentic to the cultural and linguistic‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/akoksal/muri-it-language-split.","url":"https://huggingface.co/datasets/akoksal/muri-it-language-split","creator_name":"Abdullatif Koksal","creator_url":"https://huggingface.co/akoksal","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text2text-generation","text-generation","question-answering","summarization","Achinese"],"keywords_longer_than_N":true},
	{"name":"oaast_rm_full_jieba","keyword":"romanian","description":"Â∞ùËØïËß£ÂÜ≥\"llm repetition problem\"Ôºå‰ΩøÁî®ÂàÜËØçÊ®°ÂûãÂØπoaastËØ≠ÊñôËøõË°å‚ÄúÁªìÂ∑¥Âåñ‚ÄùÊï∞ÊçÆÂ¢ûÂº∫ÔºåÊèê‰æõÊõ¥Âº∫ÁöÑÈáçÂ§çÂÜÖÂÆπÊãíÁªùÊïàÊûú„ÄÇ\nAttempts to solve the \"llm repetition problem\" by using a segmentation model to enhance the oaast corpus with \"stuttering\" data to provide stronger rejection of duplicate content.\nÂÖ∂Ê¨°ÔºåËøòËøáÊª§Êéâ‰∫ÜÊâÄÊúâËá™ÊàëËÆ§Áü•ÁöÑÂæÆË∞ÉÊ†∑Êú¨„ÄÇ\nSecond, it also filters out all the fine-tuned samples of self-cognition.\nfiles:\n\noaast_rm_full_jieba.jsonl : word level repeat\noaast_rm_full_sent_jieba.jsonl : sentence level repeat\n\n","url":"https://huggingface.co/datasets/lenML/oaast_rm_full_jieba","creator_name":"len","creator_url":"https://huggingface.co/lenML","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["English","Spanish","Russian","German","Polish"],"keywords_longer_than_N":true},
	{"name":"BRIGHTER-emotion-categories","keyword":"romanian","description":"\n\t\n\t\t\n\t\tBRIGHTER Emotion Categories Dataset\n\t\n\nThis dataset contains the emotion categories data from the BRIGHTER paper: BRIdging the Gap in Human-Annotated Textual Emotion Recognition Datasets for 28 Languages.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe BRIGHTER Emotion Categories dataset is a comprehensive multi-language, multi-label emotion classification dataset with separate configurations for each language. It represents one of the largest human-annotated emotion datasets across multiple‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/brighter-dataset/BRIGHTER-emotion-categories.","url":"https://huggingface.co/datasets/brighter-dataset/BRIGHTER-emotion-categories","creator_name":"BRIGHTER Dataset","creator_url":"https://huggingface.co/brighter-dataset","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["Afrikaans","Arabic","German","English","Spanish"],"keywords_longer_than_N":true},
	{"name":"aya_evaluation_suite","keyword":"romanian","description":"\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nAya Evaluation Suite contains a total of 26,750 open-ended conversation-style prompts to evaluate multilingual open-ended generation quality.To strike a balance between language coverage and the quality that comes with human curation, we create an evaluation suite that includes:\n\nhuman-curated examples in 7 languages (tur, eng, yor, arb, zho, por, tel) ‚Üí aya-human-annotated.\nmachine-translations of handpicked examples into 101 languages ‚Üí dolly-machine-translated.‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/CohereLabs/aya_evaluation_suite.","url":"https://huggingface.co/datasets/CohereLabs/aya_evaluation_suite","creator_name":"Cohere Labs","creator_url":"https://huggingface.co/CohereLabs","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","crowdsourced","expert-generated","machine-generated","multilingual"],"keywords_longer_than_N":true},
	{"name":"panlex-meanings","keyword":"romanian","description":"\n\t\n\t\t\n\t\tDataset Card for panlex-meanings\n\t\n\nThis is a dataset of words in several thousand languages, extracted from https://panlex.org.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset has been extracted from https://panlex.org (the 20240301 database dump) and rearranged on the per-language basis.\nEach language subset consists of expressions (words and phrases). \nEach expression is associated with some meanings (if there is more than one meaning, they are in separate‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/cointegrated/panlex-meanings.","url":"https://huggingface.co/datasets/cointegrated/panlex-meanings","creator_name":"David Dale","creator_url":"https://huggingface.co/cointegrated","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["translation","Afar","Western Abnaki","Abkhazian","Abaza"],"keywords_longer_than_N":true},
	{"name":"Multilingal-sakalt-data","keyword":"romanian","description":"„Éû„É´„ÉÅ„É™„É≥„Ç¨„É´„Éá„Éº„Çø„Çª„ÉÉ„Éà„Åß„Åô„ÄÇmit„É©„Ç§„Çª„É≥„Çπ„Åß„Åô„ÄÇ\n","url":"https://huggingface.co/datasets/Sakalti/Multilingal-sakalt-data","creator_name":"sakasan","creator_url":"https://huggingface.co/Sakalti","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-generation","Abkhaz","Bhojpuri","Chechen","Czech"],"keywords_longer_than_N":true},
	{"name":"mosel","keyword":"romanian","description":"\n\n\n\t\n\t\t\n\t\tDataset Description, Collection, and Source\n\t\n\nThe MOSEL corpus is a multilingual dataset collection including up to 950K hours of open-source speech recordings covering the 24 official languages of the European Union. We collect data by surveying labeled and unlabeled speech corpora under open-source compliant licenses.\nIn particular, MOSEL includes the automatic transcripts of 441k hours of unlabeled speech from VoxPopuli and LibriLight. The data is transcribed using Whisper large‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/FBK-MT/mosel.","url":"https://huggingface.co/datasets/FBK-MT/mosel","creator_name":"FBK-MT","creator_url":"https://huggingface.co/FBK-MT","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","machine-generated","found","multilingual"],"keywords_longer_than_N":true},
	{"name":"RoSchoolToUniQA","keyword":"romanian","description":"\n\t\n\t\t\n\t\tDataset Overview\n\t\n\n\n\t\n\t\t\n\t\tContents:\n\t\n\n\nTotal Questions: 1200\nTwelve Subjects of 100 questions each:\nBiology - Baccalaureate\nChemistry - Baccalaureate\nComputer Science - Baccalaureate\nEconomics - Baccalaureate\nLogic - Baccalaureate\nPhilosophy - Baccalaureate\nPhysics - Baccalaureate\nPsychology - Baccalaureate\nSociology - Baccalaureate\nHistory - University Admission\nMathematics - University Admission\nRomanian - University Admission\n\n\n\n\n\t\n\t\n\t\n\t\tDataset Datasheet\n\t\n\nInspiration:‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/RoLLMHub/RoSchoolToUniQA.","url":"https://huggingface.co/datasets/RoLLMHub/RoSchoolToUniQA","creator_name":"Romanian Hub","creator_url":"https://huggingface.co/RoLLMHub","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["Romanian","cc-by-4.0","üá∫üá∏ Region: US"],"keywords_longer_than_N":false},
	{"name":"ds-tf2-en-ro-15k","keyword":"romanian","description":"\n\t\n\t\t\n\t\tüå± TinyFabulist-TF2-EN-RO-15K\n\t\n\nTinyFabulist-TF2-EN-RO-15K is a parallel English‚ÄìRomanian dataset of 15,000 moral fables for benchmarking and training literary translation models, including parameter-efficient fine-tuning for LLMs. It was curated and released by the TinyFabulist team for open research.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\nTrain: 12,000 EN‚ÄìRO pairs\nValidation: 1,500 pairs\nTest: 1,500 pairs\n\nEach example is a JSON object with the following fields:\n\nlanguage: \"en\" (source) or‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/klusai/ds-tf2-en-ro-15k.","url":"https://huggingface.co/datasets/klusai/ds-tf2-en-ro-15k","creator_name":"KlusAI Labs","creator_url":"https://huggingface.co/klusai","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["translation","text-generation","Romanian","English","mit"],"keywords_longer_than_N":true},
	{"name":"webfaq","keyword":"romanian","description":"WebFAQ Q&A Dataset\n\n   \n       Overview |\n       Details  |\n       Structure  |\n       Examples |\n       Considerations |\n       License |\n       Citation |\n       Contact |\n       Acknowledgement\n   \n\n\n\n\t\n\t\t\n\t\n\t\n\t\tOverview\n\t\n\nThe WebFAQ Q&A Dataset is a broad-coverage corpus of 96 million natural question-answer (QA) pairs in 75 languages, gathered from FAQ pages on the web. It leverages structured schema.org FAQPage annotations, making it a unique resource for large-scale Question Answering‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/PaDaS-Lab/webfaq.","url":"https://huggingface.co/datasets/PaDaS-Lab/webfaq","creator_name":"Chair of Data Science, University of Passau","creator_url":"https://huggingface.co/PaDaS-Lab","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["question-answering","multilingual","Afrikaans","Amharic","Arabic"],"keywords_longer_than_N":true},
	{"name":"floras","keyword":"romanian","description":"\n\t\n\t\t\n\t\tFLORAS\n\t\n\nFLORAS is a 50-language benchmark For LOng-form Recognition And Summarization of spoken language. \nThe goal of FLORAS is to create a more realistic benchmarking environment for speech recognition, translation, and summarization models. \nUnlike typical academic benchmarks like LibriSpeech and FLEURS that uses pre-segmented single-speaker read-speech, FLORAS tests the capabilities of models on raw long-form conversational audio, which can have one or many speakers.\nTo encourage‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/espnet/floras.","url":"https://huggingface.co/datasets/espnet/floras","creator_name":"ESPnet","creator_url":"https://huggingface.co/espnet","license_name":"Creative Commons Attribution 3.0","license_url":"https://scancode-licensedb.aboutcode.org/cc-by-3.0.html","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","translation","summarization","English","Spanish"],"keywords_longer_than_N":true},
	{"name":"MultiEup-v2","keyword":"romanian","description":"\n\t\n\t\t\n\t\tMulti-EuP-v2\n\t\n\nThis dataset card documents Multi-EuP-v2, a multilingual corpus of European Parliament debate speeches enriched with Member of European Parliament (MEP) metadata and multilingual debate titles/IDs. It supports research on political text analysis, speaker-attribute prediction, stance/vote prediction, multilingual NLP, and retrieval.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nMulti-EuP-v2 aggregates 50,337 debate speeches (each a unique did) in 24‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/unimelb-nlp/MultiEup-v2.","url":"https://huggingface.co/datasets/unimelb-nlp/MultiEup-v2","creator_name":"The University of Melbourne","creator_url":"https://huggingface.co/unimelb-nlp","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","text-retrieval","text-generation","multilingual","Bulgarian"],"keywords_longer_than_N":true},
	{"name":"ro-political-socialmedia","keyword":"romanian","description":"\n\t\n\t\t\n\t\tDataset Card for \"RO-Political-Texts\"\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nRoPoli-AI (RO-Political-Texts) is a dataset for RoNLP, focused on detecting the difference between political texts written by humans, during the presidential elections from Romania (2024-2025), and synthetic texts generated with LLM models, as well as on studying linguistic characteristics such as slang, idioms, figurative expressions and \"monkey business\" behaviors in political discourse‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/petrematei/ro-political-socialmedia.","url":"https://huggingface.co/datasets/petrematei/ro-political-socialmedia","creator_name":"Petre Matei","creator_url":"https://huggingface.co/petrematei","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":null,"first_N":5,"first_N_keywords":["text-classification","Romanian","apache-2.0","10K<n<100K","üá∫üá∏ Region: US"],"keywords_longer_than_N":true},
	{"name":"ro-political-socialmedia","keyword":"romanian","description":"\n\t\n\t\t\n\t\tDataset Card for \"RO-Political-Texts\"\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nRoPoli-AI (RO-Political-Texts) is a dataset for RoNLP, focused on detecting the difference between political texts written by humans, during the presidential elections from Romania (2024-2025), and synthetic texts generated with LLM models, as well as on studying linguistic characteristics such as slang, idioms, figurative expressions and \"monkey business\" behaviors in political discourse‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/petrematei/ro-political-socialmedia.","url":"https://huggingface.co/datasets/petrematei/ro-political-socialmedia","creator_name":"Petre Matei","creator_url":"https://huggingface.co/petrematei","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":null,"first_N":5,"first_N_keywords":["text-classification","Romanian","apache-2.0","10K<n<100K","üá∫üá∏ Region: US"],"keywords_longer_than_N":true},
	{"name":"ro-offense-fb","keyword":"romanian","description":"\n\t\n\t\t\n\t\tDataset Card for \"RO-FB-Offense\"\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nFB-RO-Offense corpus, an offensive speech dataset containing 4,455 user-generated comments from Facebook live broadcasts available in Romanian\nThe annotation follows the hierarchical tagset proposed in the Germeval 2018 Dataset. \nThe following Classes are available:\n\nOTHER: Non-Offensive Language\nOFFENSIVE:\nPROFANITY\nINSULT\nABUSE\n\n\n\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nRomanian\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\n\t\n\t\t\n\t\tData Instances\n\t\n\nAn‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/upb-nlp/ro-offense-fb.","url":"https://huggingface.co/datasets/upb-nlp/ro-offense-fb","creator_name":"POLITEHNICA Bucharest NLP Group","creator_url":"https://huggingface.co/upb-nlp","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","hate-speech-detection","expert-generated","found","monolingual"],"keywords_longer_than_N":true},
	{"name":"HPLT2.0_cleaned","keyword":"romanian","description":"This is a large-scale collection of web-crawled documents in 191 world languages, produced by the HPLT project. \nThe source of the data is mostly Internet Archive with some additions from Common Crawl.\nFor a detailed description of the dataset, please refer to https://hplt-project.org/datasets/v2.0\nThe Cleaned variant of HPLT Datasets v2.0\nThis is the cleaned variant of the HPLT Datasets v2.0 converted to the Parquet format semi-automatically when being uploaded here. \nThe original JSONL files‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/jobs-git/HPLT2.0_cleaned.","url":"https://huggingface.co/datasets/jobs-git/HPLT2.0_cleaned","creator_name":"James Guana","creator_url":"https://huggingface.co/jobs-git","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["fill-mask","text-generation","language-modeling","multilingual","Achinese"],"keywords_longer_than_N":true},
	{"name":"GlotCC-V1","keyword":"romanian","description":"\n\t\n\t\t\n\t\tDataset Summary\n\t\n\n \n\nGlotCC-V1.0 is a document-level, general domain dataset derived from CommonCrawl, covering more than 1000 languages.It is built using the GlotLID language identification and Ungoliant pipeline from CommonCrawl.We release our pipeline as open-source at https://github.com/cisnlp/GlotCC.  \nList of Languages: See https://datasets-server.huggingface.co/splits?dataset=cis-lmu/GlotCC-V1 to get the list of splits available.\n\n\t\t\n\t\tUsage (Huggingface Hub -- Recommended)‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/cis-lmu/GlotCC-V1.","url":"https://huggingface.co/datasets/cis-lmu/GlotCC-V1","creator_name":"CIS, LMU Munich","creator_url":"https://huggingface.co/cis-lmu","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["multilingual","Abau","Amarasi","Abkhaz","Abkhazian"],"keywords_longer_than_N":true},
	{"name":"GlotCC-V1","keyword":"romanian","description":"\n\t\n\t\t\n\t\tDataset Summary\n\t\n\n \n\nGlotCC-V1.0 is a document-level, general domain dataset derived from CommonCrawl, covering more than 1000 languages.It is built using the GlotLID language identification and Ungoliant pipeline from CommonCrawl.We release our pipeline as open-source at https://github.com/cisnlp/GlotCC.  \nList of Languages: See https://datasets-server.huggingface.co/splits?dataset=cis-lmu/GlotCC-V1 to get the list of splits available.\n\n\t\t\n\t\tUsage (Huggingface Hub -- Recommended)‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/cis-lmu/GlotCC-V1.","url":"https://huggingface.co/datasets/cis-lmu/GlotCC-V1","creator_name":"CIS, LMU Munich","creator_url":"https://huggingface.co/cis-lmu","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["multilingual","Abau","Amarasi","Abkhaz","Abkhazian"],"keywords_longer_than_N":true},
	{"name":"Romanian_better","keyword":"romanian","description":"Gargaz/Romanian_better dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/Gargaz/Romanian_better","creator_name":"LUCA ","creator_url":"https://huggingface.co/Gargaz","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["Romanian","apache-2.0","10K - 100K","json","Text"],"keywords_longer_than_N":true},
	{"name":"RoMedQA_v2","keyword":"romanian","description":"craciuncg/RoMedQA_v2 dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/craciuncg/RoMedQA_v2","creator_name":"Cristian-George Craciun","creator_url":"https://huggingface.co/craciuncg","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["question-answering","Romanian","apache-2.0","1K - 10K","csv"],"keywords_longer_than_N":true},
	{"name":"CommonVoicesDelta21_ro","keyword":"romanian","description":"\n\t\n\t\t\n\t\tCommon Voices Delta 21.0 (Romanian)\n\t\n\n\nCommon Voices is an open-source dataset of speech recordings created by \nMozilla to improve speech recognition technologies. \nIt consists of crowdsourced voice samples in multiple languages, contributed by volunteers worldwide.\n\n\n\nChallenges: The raw dataset included numerous recordings with incorrect transcriptions \nor those requiring adjustments, such as sampling rate modifications, conversion to .wav format, and other refinements \nessential‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ionut-visan/CommonVoicesDelta21_ro.","url":"https://huggingface.co/datasets/ionut-visan/CommonVoicesDelta21_ro","creator_name":"Ionut Visan","creator_url":"https://huggingface.co/ionut-visan","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","audio-classification","text-to-speech","text-to-audio","Romanian"],"keywords_longer_than_N":true},
	{"name":"CommonVoicesDelta21_ro","keyword":"romanian","description":"\n\t\n\t\t\n\t\tCommon Voices Delta 21.0 (Romanian)\n\t\n\n\nCommon Voices is an open-source dataset of speech recordings created by \nMozilla to improve speech recognition technologies. \nIt consists of crowdsourced voice samples in multiple languages, contributed by volunteers worldwide.\n\n\n\nChallenges: The raw dataset included numerous recordings with incorrect transcriptions \nor those requiring adjustments, such as sampling rate modifications, conversion to .wav format, and other refinements \nessential‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ionut-visan/CommonVoicesDelta21_ro.","url":"https://huggingface.co/datasets/ionut-visan/CommonVoicesDelta21_ro","creator_name":"Ionut Visan","creator_url":"https://huggingface.co/ionut-visan","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","audio-classification","text-to-speech","text-to-audio","Romanian"],"keywords_longer_than_N":true},
	{"name":"reasoning-multilingual-R1-Llama-70B-train","keyword":"romanian","description":"\n\t\n\t\t\n\t\tlightblue/reasoning-multilingual-R1-Llama-70B-train\n\t\n\nThis is a multilingual reasoning dataset covering more than 30 languages.\nThis dataset was made by:\n\nSampling prompts from English datasets and translating them to various languages\nGenerating responses to these prompts 8 times using deepseek-ai/DeepSeek-R1-Distill-Llama-70B\nFiltering out <think> sections with incorrect language, non-fluent language, and incorrect answers\n\nThis dataset was then used to train a multilingual‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/lightblue/reasoning-multilingual-R1-Llama-70B-train.","url":"https://huggingface.co/datasets/lightblue/reasoning-multilingual-R1-Llama-70B-train","creator_name":"Lightblue KK.","creator_url":"https://huggingface.co/lightblue","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["Amharic","Arabic","Bengali","Chinese","Czech"],"keywords_longer_than_N":true},
	{"name":"quran","keyword":"romanian","description":"\n\t\n\t\t\n\t\tDataset Card for the Quran\n\t\n\n\n\t\n\t\t\n\t\tSummary\n\t\n\nThe Quran with metadata, translations, and multiple Arabic text (can use specific types for embeddings, search, classification, and display). There are 126+ columns containing 43+ languages.\n\n\t\n\t\t\n\t\tTODO\n\t\n\n\n Add Tafsirs  \n Add topics/ontology\n\n\n\t\n\t\t\n\t\tUsage\n\t\n\nfrom datasets import load_dataset\n\nds = load_dataset(\"nazimali/quran\", split=\"train\")\nds\n\nOutput:\nDataset({\n    features: ['surah', 'ayah', 'surah-name', 'surah-total-ayas'‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/nazimali/quran.","url":"https://huggingface.co/datasets/nazimali/quran","creator_name":"Nazim Ali","creator_url":"https://huggingface.co/nazimali","license_name":"Creative Commons Attribution 3.0","license_url":"https://scancode-licensedb.aboutcode.org/cc-by-3.0.html","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","translation","feature-extraction","text-generation"],"keywords_longer_than_N":true},
	{"name":"semeval-2025-task11-track-a","keyword":"romanian","description":"\n\t\n\t\t\n\t\tSemEval 2025 Task 11 - Track A Dataset\n\t\n\nThis dataset contains the data for SemEval 2025 Task 11: Bridging the Gap in Text-Based Emotion Detection - Track A, organized as language-specific configurations.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset is a multi-language, multi-label emotion classification dataset with separate configurations for each language.\n\nTotal languages: 26 standard ISO codes\nTotal examples: 115159\nSplits: train, dev, test\n\n\n\t\n\t\t\n\t\tLanguage Configurations\n\t\n\nEach‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/vgaraujov/semeval-2025-task11-track-a.","url":"https://huggingface.co/datasets/vgaraujov/semeval-2025-task11-track-a","creator_name":"Vladimir Araujo","creator_url":"https://huggingface.co/vgaraujov","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["Afrikaans","Amharic","Arabic","German","English"],"keywords_longer_than_N":true},
	{"name":"fleurs_clean","keyword":"romanian","description":"\n\t\n\t\t\n\t\n\t\n\t\tFLEURS\n\t\n\nFleurs is the speech version of the FLoRes machine translation benchmark. \nWe use 2009 n-way parallel sentences from the FLoRes dev and devtest publicly available sets, in 102 languages. \nTraining sets have around 10 hours of supervision. Speakers of the train sets are different than speakers from the dev/test sets. Multilingual fine-tuning is\nused and ‚Äùunit error rate‚Äù (characters, signs) of all languages is averaged. Languages and results are also grouped into seven‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Helloworld668/fleurs_clean.","url":"https://huggingface.co/datasets/Helloworld668/fleurs_clean","creator_name":"zhide Tang","creator_url":"https://huggingface.co/Helloworld668","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","expert-generated","crowdsourced","machine-generated","crowdsourced"],"keywords_longer_than_N":true},
	{"name":"BRIGHTER-emotion-intensities","keyword":"romanian","description":"\n\t\n\t\t\n\t\tBRIGHTER Emotion Intensities Dataset\n\t\n\nThis dataset contains the emotion intensities data from the BRIGHTER paper: BRIdging the Gap in Human-Annotated Textual Emotion Recognition Datasets for 28 Languages.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe BRIGHTER Emotion Intensities dataset is a comprehensive multi-language emotion intensity dataset with separate configurations for each language. It represents one of the largest human-annotated emotion datasets across multiple languages, providing‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/brighter-dataset/BRIGHTER-emotion-intensities.","url":"https://huggingface.co/datasets/brighter-dataset/BRIGHTER-emotion-intensities","creator_name":"BRIGHTER Dataset","creator_url":"https://huggingface.co/brighter-dataset","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["Arabic","German","English","Spanish","Hausa"],"keywords_longer_than_N":true},
	{"name":"multiblimp","keyword":"romanian","description":"\n\t\n\t\t\n\t\tMultiBLiMP\n\t\n\nMultiBLiMP is a massively Multilingual Benchmark for Linguistic Minimal Pairs. The dataset is composed of synthetic pairs generated using Universal Dependencies and UniMorph.\nThe paper can be found here.\nWe split the data set by language: each language consists of a single .tsv file. The rows contain many attributes for a particular pair, most important are the sen and wrong_sen fields, which we use for evaluating the language models.\n\n\t\n\t\t\n\t\n\t\n\t\tUsing MultiBLiMP\n\t\n\nTo‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/jumelet/multiblimp.","url":"https://huggingface.co/datasets/jumelet/multiblimp","creator_name":"Jaap Jumelet","creator_url":"https://huggingface.co/jumelet","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["multilingual","Buriat","Spanish","Sanskrit","Romanian"],"keywords_longer_than_N":true},
	{"name":"Multi-EuP","keyword":"romanian","description":"\n\t\n\t\t\n\t\tNOTES FOR DOWNLOAD!\n\t\n\n\nHighly recommend downloading it via the API:\n\ncurl -X GET \\\n     \"https://datasets-server.huggingface.co/first-rows?dataset=unimelb-nlp%2FMulti-EuP&config=default&split=full\"\n\n\nIf you are using the HuggingFace library, please follow these steps:\n\npip install datasets\n\nfrom datasets import load_dataset\n\ndataset = load_dataset(\"unimelb-nlp/Multi-EuP\", keep_default_na=False)\n\nNote: It's crucial to use keep_default_na=False because some datasets contain 'null'‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/unimelb-nlp/Multi-EuP.","url":"https://huggingface.co/datasets/unimelb-nlp/Multi-EuP","creator_name":"The University of Melbourne","creator_url":"https://huggingface.co/unimelb-nlp","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","English","German","French","Italian"],"keywords_longer_than_N":true},
	{"name":"oscar-mini","keyword":"romanian","description":"The Open Super-large Crawled ALMAnaCH coRpus is a huge multilingual corpus obtained by language classification and filtering of the Common Crawl corpus using the goclassy architecture.\\","url":"https://huggingface.co/datasets/nthngdy/oscar-mini","creator_name":"Nathan Godey","creator_url":"https://huggingface.co/nthngdy","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":null,"first_N":5,"first_N_keywords":["text-generation","language-modeling","no-annotation","found","multilingual"],"keywords_longer_than_N":true},
	{"name":"voxpopuli","keyword":"romanian","description":"A large-scale multilingual speech corpus for representation learning, semi-supervised learning and interpretation.","url":"https://huggingface.co/datasets/facebook/voxpopuli","creator_name":"AI at Meta","creator_url":"https://huggingface.co/facebook","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":null,"first_N":5,"first_N_keywords":["automatic-speech-recognition","multilingual","English","German","French"],"keywords_longer_than_N":true},
	{"name":"para_crawl","keyword":"romanian","description":"\n\t\n\t\t\n\t\tDataset Card for \"para_crawl\"\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nWeb-Scale Parallel Corpora for Official European Languages.\n\n\t\n\t\t\n\t\tSupported Tasks and Leaderboards\n\t\n\nMore Information Needed\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nMore Information Needed\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\n\t\n\t\t\n\t\tData Instances\n\t\n\n\n\t\n\t\t\n\t\tenbg\n\t\n\n\nSize of downloaded dataset files: 103.75 MB\nSize of the generated dataset: 356.54 MB\nTotal amount of disk used: 460.27 MB\n\nAn example of 'train' looks as follows.\nThis example was too‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ParaCrawl/para_crawl.","url":"https://huggingface.co/datasets/ParaCrawl/para_crawl","creator_name":"ParaCrawl","creator_url":"https://huggingface.co/ParaCrawl","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":null,"first_N":5,"first_N_keywords":["translation","no-annotation","found","translation","original"],"keywords_longer_than_N":true},
	{"name":"language_tags","keyword":"romanian","description":"\n\t\n\t\t\n\t\tDescription\n\t\n\nDataset listing 27,328 languages and dialects (also includes macrolanguage names).For each language, either the ISO 639 code, the Glottolog code or both are provided.\n\n\t\n\t\t\n\t\tColumns\n\t\n\n\nEnglish_Name: Language name in English (e.g. \"French\").\nNative_Name: If value is not 0, corresponds to the name of the language by native speakers (e.g. \"Fran√ßais\") which may have been found in Wikipedia's nativename field.\nGlottocode: The language tag in the Glottolog convention (e.g.‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/lbourdois/language_tags.","url":"https://huggingface.co/datasets/lbourdois/language_tags","creator_name":"Lo√Øck BOURDOIS","creator_url":"https://huggingface.co/lbourdois","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["Afade","Par√° Ar√°ra","Afar","Aka-Bea","Abon"],"keywords_longer_than_N":true},
	{"name":"fleurs","keyword":"romanian","description":"\n\t\n\t\t\n\t\tFLEURS\n\t\n\nFleurs is the speech version of the FLoRes machine translation benchmark. \nWe use 2009 n-way parallel sentences from the FLoRes dev and devtest publicly available sets, in 102 languages. \nTraining sets have around 10 hours of supervision. Speakers of the train sets are different than speakers from the dev/test sets. Multilingual fine-tuning is\nused and ‚Äùunit error rate‚Äù (characters, signs) of all languages is averaged. Languages and results are also grouped into seven‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/cahya/fleurs.","url":"https://huggingface.co/datasets/cahya/fleurs","creator_name":"Cahya Wirawan","creator_url":"https://huggingface.co/cahya","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":null,"first_N":5,"first_N_keywords":["automatic-speech-recognition","expert-generated","crowdsourced","machine-generated","crowdsourced"],"keywords_longer_than_N":true},
	{"name":"all-scam-spam","keyword":"romanian","description":"This is a large corpus of 42,619 preprocessed text messages and emails sent by humans in 43 languages. is_spam=1 means spam and is_spam=0 means ham.\n1040 rows of balanced data, consisting of casual conversations and scam emails in ‚âà10 languages, were manually collected and annotated by me, with some help from ChatGPT.\n\n\n\n\t\n\t\t\n\t\tSome preprcoessing algorithms\n\t\n\n\nspam_assassin.js, followed by spam_assassin.py\nenron_spam.py\n\n\n\n\n\t\n\t\t\n\t\tData composition\n\t\n\n\n\n\n\n\t\n\t\t\n\t\tDescription\n\t\n\nTo make the text‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/FredZhang7/all-scam-spam.","url":"https://huggingface.co/datasets/FredZhang7/all-scam-spam","creator_name":"Fred Zhang","creator_url":"https://huggingface.co/FredZhang7","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","zero-shot-classification","Norwegian","Spanish","Somali"],"keywords_longer_than_N":true},
	{"name":"oasst2_top1_chat_format","keyword":"romanian","description":"\n\t\n\t\t\n\t\tOpenAssistant TOP-1 Conversation Threads in huggingface chat format\n\t\n\nExport of oasst2 only top 1 threads in huggingface chat format\n\n\t\n\t\t\n\t\tScript\n\t\n\nThe convert script can be find here\n","url":"https://huggingface.co/datasets/blancsw/oasst2_top1_chat_format","creator_name":"Blanc Swan","creator_url":"https://huggingface.co/blancsw","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["English","Spanish","Russian","German","Polish"],"keywords_longer_than_N":true},
	{"name":"malicious-website-features-2.4M","keyword":"romanian","description":"Important Notice:\n\nA subset of the URL dataset is from Kaggle, and the Kaggle datasets contained 10%-15% mislabelled data. See this dicussion I opened for some false positives. I have contacted Kaggle regarding their erroneous \"Usability\" score calculation for these unreliable datasets.\nThe feature extraction methods shown here are not robust at all in 2023, and there're even silly mistakes in 3 functions: not_indexed_by_google, domain_registration_length, and age_of_domain.\n\n\n\nThe features‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/FredZhang7/malicious-website-features-2.4M.","url":"https://huggingface.co/datasets/FredZhang7/malicious-website-features-2.4M","creator_name":"Fred Zhang","creator_url":"https://huggingface.co/FredZhang7","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","feature-extraction","tabular-classification","Norwegian","Afrikaans"],"keywords_longer_than_N":true},
	{"name":"ronec","keyword":"romanian","description":"\n\t\n\t\t\n\t\tDataset Card for RONEC\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nRONEC, at version 2.0, holds 12330 sentences with over 0.5M tokens, annotated with 15 classes, to a total of 80.283 distinctly annotated entities.\nThe corpus has the following classes and distribution in the train/valid/test splits:\n| Classes      \t| Total  \t    | Train  \t|         \t| Valid  \t|         \t| Test   \t|         \t|\n|-------------\t|:------:\t    |:------:\t|:-------:\t|:------:\t|:-------:\t|:------:\t|:-------:\t|\n|            \t|‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/community-datasets/ronec.","url":"https://huggingface.co/datasets/community-datasets/ronec","creator_name":"Community Datasets","creator_url":"https://huggingface.co/community-datasets","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["token-classification","named-entity-recognition","expert-generated","expert-generated","found"],"keywords_longer_than_N":true},
	{"name":"ro_sts_parallel","keyword":"romanian","description":"The RO-STS-Parallel (a Parallel Romanian English dataset - translation of the Semantic Textual Similarity) contains 17256 sentences in Romanian and English. It is a high-quality translation of the English STS benchmark dataset into Romanian.","url":"https://huggingface.co/datasets/dumitrescustefan/ro_sts_parallel","creator_name":"Dumitrescu Stefan","creator_url":"https://huggingface.co/dumitrescustefan","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":null,"first_N":5,"first_N_keywords":["translation","crowdsourced","crowdsourced","multilingual","extended|other-sts-b"],"keywords_longer_than_N":true},
	{"name":"tatoeba","keyword":"romanian","description":"This is a collection of translated sentences from Tatoeba\n359 languages, 3,403 bitexts\ntotal number of files: 750\ntotal number of tokens: 65.54M\ntotal number of sentence fragments: 8.96M","url":"https://huggingface.co/datasets/Helsinki-NLP/tatoeba","creator_name":"Language Technology Research Group at the University of Helsinki","creator_url":"https://huggingface.co/Helsinki-NLP","license_name":"Creative Commons Attribution 2.0","license_url":"https://scancode-licensedb.aboutcode.org/cc-by-2.0.html","language":null,"first_N":5,"first_N_keywords":["translation","found","found","multilingual","original"],"keywords_longer_than_N":true},
	{"name":"MultiLegalPile_Wikipedia_Filtered","keyword":"romanian","description":"A filtered version of the MultiLegalPile dataset, together with wikipedia articles.","url":"https://huggingface.co/datasets/joelniklaus/MultiLegalPile_Wikipedia_Filtered","creator_name":"Joel Niklaus","creator_url":"https://huggingface.co/joelniklaus","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["fill-mask","other","found","multilingual","original"],"keywords_longer_than_N":true},
	{"name":"ms_terms","keyword":"romanian","description":"The Microsoft Terminology Collection can be used to develop localized versions of applications that integrate with Microsoft products.\nIt can also be used to integrate Microsoft terminology into other terminology collections or serve as a base IT glossary\nfor language development in the nearly 100 languages available. Terminology is provided in .tbx format, an industry standard for terminology exchange.","url":"https://huggingface.co/datasets/microsoft/ms_terms","creator_name":"Microsoft","creator_url":"https://huggingface.co/microsoft","license_name":"Microsoft Public License","license_url":"https://choosealicense.com/licenses/ms-pl/","language":null,"first_N":5,"first_N_keywords":["translation","expert-generated","expert-generated","multilingual","translation"],"keywords_longer_than_N":true},
	{"name":"ro-alpaca-gpt4","keyword":"romanian","description":"This dataset is the translated vicgalle/alpaca-gpt4 instruct dataset using LLMic, a bilingual Romanian-English LLM.\nThe alpaca-gpt4 is an English Instruction-Following generated by GPT-4 using Alpaca prompts for fine-tuning LLMs.\nThe dataset is available under the Creative Commons NonCommercial (CC BY-NC 4.0).\n@article{peng2023instruction,\n  title={Instruction Tuning with GPT-4},\n  author={Peng, Baolin and Li, Chunyuan and He, Pengcheng and Galley, Michel and Gao, Jianfeng},\n  journal={arXiv‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/faur-ai/ro-alpaca-gpt4.","url":"https://huggingface.co/datasets/faur-ai/ro-alpaca-gpt4","creator_name":"faur-ai","creator_url":"https://huggingface.co/faur-ai","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","question-answering","Romanian","cc-by-4.0","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"MultiLegalPileWikipediaFiltered","keyword":"romanian","description":"A filtered version of the MultiLegalPile dataset, together with wikipedia articles.","url":"https://huggingface.co/datasets/joelniklaus/MultiLegalPileWikipediaFiltered","creator_name":"Joel Niklaus","creator_url":"https://huggingface.co/joelniklaus","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["fill-mask","other","found","multilingual","original"],"keywords_longer_than_N":true},
	{"name":"common_voice_17_0","keyword":"romanian","description":"\n\t\n\t\t\n\t\tDataset Card for Common Voice Corpus 17.0\n\t\n\n\n\nThis dataset is an unofficial version of the Mozilla Common Voice Corpus 17. It was downloaded and converted from the project's website https://commonvoice.mozilla.org/.\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nAbkhaz, Albanian, Amharic, Arabic, Armenian, Assamese, Asturian, Azerbaijani, Basaa, Bashkir, Basque, Belarusian, Bengali, Breton, Bulgarian, Cantonese, Catalan, Central Kurdish, Chinese (China), Chinese (Hong Kong), Chinese (Taiwan), Chuvash, Czech‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/fsicoli/common_voice_17_0.","url":"https://huggingface.co/datasets/fsicoli/common_voice_17_0","creator_name":"Fabio Sicoli","creator_url":"https://huggingface.co/fsicoli","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":null,"first_N":5,"first_N_keywords":["automatic-speech-recognition","Abkhaz","Afrikaans","Amharic","Arabic"],"keywords_longer_than_N":true},
	{"name":"entity_cs","keyword":"romanian","description":"\n\t\n\t\t\n\t\tDataset Card for EntityCS\n\t\n\n\nRepository: https://github.com/huawei-noah/noah-research/tree/master/NLP/EntityCS  \nPaper: https://aclanthology.org/2022.findings-emnlp.499.pdf  \nPoint of Contact: Fenia Christopoulou, Chenxi Whitehouse\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Description\n\t\n\nWe use the English Wikipedia and leverage entity information from Wikidata to construct an entity-based Code Switching corpus. \nTo achieve this, we make use of wikilinks in Wikipedia, i.e. links from one page to another.‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/huawei-noah/entity_cs.","url":"https://huggingface.co/datasets/huawei-noah/entity_cs","creator_name":"HUAWEI Noah's Ark Lab","creator_url":"https://huggingface.co/huawei-noah","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["Afrikaans","Amharic","Arabic","Assamese","Azerbaijani"],"keywords_longer_than_N":true},
	{"name":"moroco","keyword":"romanian","description":"The MOROCO (Moldavian and Romanian Dialectal Corpus) dataset contains 33564 samples of text collected from the news domain.\nThe samples belong to one of the following six topics:\n    - culture\n    - finance\n    - politics\n    - science\n    - sports\n    - tech","url":"https://huggingface.co/datasets/universityofbucharest/moroco","creator_name":"University of Bucharest","creator_url":"https://huggingface.co/universityofbucharest","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":null,"first_N":5,"first_N_keywords":["text-classification","topic-classification","found","found","monolingual"],"keywords_longer_than_N":true},
	{"name":"common_language","keyword":"romanian","description":"This dataset is composed of speech recordings from languages that were carefully selected from the CommonVoice database.\nThe total duration of audio recordings is 45.1 hours (i.e., 1 hour of material for each language).\nThe dataset has been extracted from CommonVoice to train language-id systems.","url":"https://huggingface.co/datasets/speechbrain/common_language","creator_name":"SpeechBrain","creator_url":"https://huggingface.co/speechbrain","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":null,"first_N":5,"first_N_keywords":["audio-classification","speaker-identification","crowdsourced","crowdsourced","multilingual"],"keywords_longer_than_N":true},
	{"name":"minigpt4-13b-ggml","keyword":"romanian","description":"These are quantized ggml binary files for minigpt4 13B model.\nThese files can be used in conjunction with vicuna v0 ggml models to get minigpt4 working.\nNot all implementations were tested. If there are any issues, use f16.\n","url":"https://huggingface.co/datasets/maknee/minigpt4-13b-ggml","creator_name":"maknee","creator_url":"https://huggingface.co/maknee","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":null,"first_N":5,"first_N_keywords":["English","Bulgarian","Catalan","Czech","Danish"],"keywords_longer_than_N":true},
	{"name":"openassistant-falcon","keyword":"romanian","description":"\n\t\n\t\t\n\t\tChat Fine-tuning Dataset - OpenAssistant Falcon\n\t\n\nThis dataset allows for fine-tuning chat models using '\\Human:' AND '\\nAssistant:' to wrap user messages.\nIt still uses <|endoftext|> as EOS and BOS token, as per Falcon.\nSample \nPreparation:\n\nThe dataset is cloned from TimDettmers, which itself is a subset of the Open Assistant dataset, which you can find here. This subset of the data only contains the highest-rated paths in the conversation tree, with a total of 9,846 samples.\nThe‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Trelis/openassistant-falcon.","url":"https://huggingface.co/datasets/Trelis/openassistant-falcon","creator_name":"Trelis","creator_url":"https://huggingface.co/Trelis","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["English","Spanish","Russian","German","Polish"],"keywords_longer_than_N":true},
	{"name":"oasst1","keyword":"romanian","description":"\n\t\n\t\t\n\t\tOpenAssistant Conversations Dataset (OASST1)\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nIn an effort to democratize research on large-scale alignment, we release OpenAssistant \nConversations (OASST1), a human-generated, human-annotated assistant-style conversation \ncorpus consisting of 161,443 messages in 35 different languages, annotated with 461,292 \nquality ratings, resulting in over 10,000 fully annotated conversation trees. The corpus \nis a product of a worldwide crowd-sourcing effort‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/OpenAssistant/oasst1.","url":"https://huggingface.co/datasets/OpenAssistant/oasst1","creator_name":"OpenAssistant","creator_url":"https://huggingface.co/OpenAssistant","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["English","Spanish","Russian","German","Polish"],"keywords_longer_than_N":true},
	{"name":"ro-offense-sequences","keyword":"romanian","description":"\n\t\n\t\t\n\t\tDataset Card for \"RO-Offense-Sequences\"\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\n\n\nHomepage: https://github.com/readerbench/ro-offense-sequences\nRepository: https://github.com/readerbench/ro-offense-sequences\nPoint of Contact: Teodora-Andreea Ion\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\na novel Romanian language dataset for offensive sequence detection with manually \nannotated offensive sequences from a local Romanian sports news website (gsp.ro):\nResulting in 4800 annotated messages‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/readerbench/ro-offense-sequences.","url":"https://huggingface.co/datasets/readerbench/ro-offense-sequences","creator_name":"ReaderBench","creator_url":"https://huggingface.co/readerbench","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["token-classification","hate-speech-detection","expert-generated","found","monolingual"],"keywords_longer_than_N":true},
	{"name":"semeval-2025-task11-track-c","keyword":"romanian","description":"\n\t\n\t\t\n\t\tSemEval 2025 Task 11 - Track C Dataset\n\t\n\nThis dataset contains the data for SemEval 2025 Task 11: Bridging the Gap in Text-Based Emotion Detection - Track C, organized as language-specific configurations.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset is a multi-language, multi-label emotion classification dataset with separate configurations for each language.\n\nTotal languages: 30 standard ISO codes\nTotal examples: 57254\nSplits: dev, test (Track C has no train split)\n\n\n\t\n\t\t\n\t\tTrack‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/vgaraujov/semeval-2025-task11-track-c.","url":"https://huggingface.co/datasets/vgaraujov/semeval-2025-task11-track-c","creator_name":"Vladimir Araujo","creator_url":"https://huggingface.co/vgaraujov","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["Afrikaans","Amharic","Arabic","German","English"],"keywords_longer_than_N":true},
	{"name":"HPLT2.0_cleaned","keyword":"romanian","description":"This is a large-scale collection of web-crawled documents in 191 world languages, produced by the HPLT project. \nThe source of the data is mostly Internet Archive with some additions from Common Crawl.\nFor a detailed description of the dataset, please refer to our website and our pre-print.\n\n\t\n\t\t\n\t\n\t\n\t\tThe Cleaned variant of HPLT Datasets v2.0\n\t\n\nThis is the cleaned variant of the HPLT Datasets v2.0 converted to the Parquet format semi-automatically when being uploaded here. \nThe original‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/HPLT/HPLT2.0_cleaned.","url":"https://huggingface.co/datasets/HPLT/HPLT2.0_cleaned","creator_name":"HPLT","creator_url":"https://huggingface.co/HPLT","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["fill-mask","text-generation","language-modeling","multilingual","Achinese"],"keywords_longer_than_N":true},
	{"name":"DATA-AI_Chat","keyword":"romanian","description":"\n\t\n\t\t\n\t\tDATA-AI: Il Modello di IA di M.INC.\n\t\n\n\n\t\n\t\t\n\t\tüìå Introduzione\n\t\n\nDATA-AI √® un avanzato modello di intelligenza artificiale sviluppato da *M.INC., un'azienda italiana fondata da *Mattimax (M. Marzorati).Questo modello √® basato sull'architettura ELNS (Elaborazione del Linguaggio Naturale Semplice), un sistema innovativo progettato per rendere l'IA accessibile su quasi qualsiasi dispositivo, garantendo prestazioni ottimali anche su hardware limitato.  \nDATA-AI √® stato addestrato su un‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Mattimax/DATA-AI_Chat.","url":"https://huggingface.co/datasets/Mattimax/DATA-AI_Chat","creator_name":"M.INC.","creator_url":"https://huggingface.co/Mattimax","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["Italian","English","Spanish","Russian","German"],"keywords_longer_than_N":true},
	{"name":"medical-translation-test-set","keyword":"romanian","description":"ai-amplified/medical-translation-test-set dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/ai-amplified/medical-translation-test-set","creator_name":"admin","creator_url":"https://huggingface.co/ai-amplified","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["English","French","Portuguese","Romanian","German"],"keywords_longer_than_N":true},
	{"name":"RonSTS","keyword":"romanian","description":"\n  RonSTS\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nHigh-quality Romanian translation of STSBenchmark.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2t\n\n\nDomains\nNews, Social, Web, Written\n\n\nReference\nhttps://openreview.net/forum?id=JH61CD7afTv\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask = mteb.get_task(\"RonSTS\")\nevaluator = mteb.MTEB([task])\n\nmodel = mteb.get_model(YOUR_MODEL)\nevaluator.run(model)\n\n\nTo‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/RonSTS.","url":"https://huggingface.co/datasets/mteb/RonSTS","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["sentence-similarity","semantic-similarity-scoring","human-annotated","translated","dumitrescustefan/ro_sts"],"keywords_longer_than_N":true},
	{"name":"reranker_continuous_filt_max7_train","keyword":"romanian","description":"\n\t\n\t\t\n\t\tReranker training data\n\t\n\nThis data was generated using 4 steps:\n\nWe gathered queries and corresponding text data from 35 high quality datasets covering more than 95 languages.\nFor datasets which did not already have negative texts for queries, we mined hard negatives using the BAAI/bge-m3 embedding model.\nFor each query, we selected one positive and one negative text and used Qwen/Qwen2.5-32B-Instruct-GPTQ-Int4 to rate the relatedness of each query-text pair using a token \"1\", \"2\"‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/lightblue/reranker_continuous_filt_max7_train.","url":"https://huggingface.co/datasets/lightblue/reranker_continuous_filt_max7_train","creator_name":"Lightblue KK.","creator_url":"https://huggingface.co/lightblue","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["English","Chinese","Spanish","German","Arabic"],"keywords_longer_than_N":true},
	{"name":"histnero","keyword":"romanian","description":"\n\t\n\t\t\n\t\tHistNERo (CoNLL)\n\t\n\nThis repository contains the Historical Romanian Named Entity Recognition (HistNERo) dataset in a CoNLL-compatible format. \nThe dataset uses the reference dataset from avramandrei/histnero and introduces the following features:\n\nCoNLL-like dataset splits (see train.tsv, dev.tsv and test.tsv), including metadata\nDocument-wise grouping\nFlair Dataset Loader, see the FlairDatasetExample.ipynb example notebook\n\nThe dataset has 10,026 sentences (i.e. 8,020 train, 1,003‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/stefan-it/histnero.","url":"https://huggingface.co/datasets/stefan-it/histnero","creator_name":"Stefan Schweter","creator_url":"https://huggingface.co/stefan-it","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["token-classification","Romanian","mit","100K - 1M","csv"],"keywords_longer_than_N":true},
	{"name":"eng_montok","keyword":"romanian","description":"\n\t\n\t\t\n\t\tMonTok: A Suite of Monolingual Tokenizers\n\t\n\nThis is a set of monolingual tokenizers for 98 languages. For each language, there are Unigram, BPE, and SuperBPE tokenizers, ranging in vocabulary size from around 6k to over 200k.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\n","url":"https://huggingface.co/datasets/catherinearnett/eng_montok","creator_name":"Catherine Arnett","creator_url":"https://huggingface.co/catherinearnett","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["Afrikaans","Tosk Albanian","Amharic","Standard Arabic","Assamese"],"keywords_longer_than_N":true},
	{"name":"ipa-childes-split","keyword":"romanian","description":"\n\t\n\t\t\n\t\tIPA-CHILDES split\n\t\n\nThis dataset is a postprocessed version of the IPA-CHILDES dataset. In particular,\nthe following changes have been implemented:\n\ncolumn processed_gloss dropped as it duplicates information of gloss up to punctuation\ncolumn gloss renamed as sentence, and column ipa_transcription renamed as ipa_g2p_plus (cf. G2P+)\ncolumn lang added to make IETF language tags accessible for training and inference; language tags normalized by the langcodes package\ncolumns ipa_espeak‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/fdemelo/ipa-childes-split.","url":"https://huggingface.co/datasets/fdemelo/ipa-childes-split","creator_name":"Fl√°vio Eler De Melo","creator_url":"https://huggingface.co/fdemelo","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["Catalan","Welsh","Danish","German","English"],"keywords_longer_than_N":true},
	{"name":"finepdfs-summaries","keyword":"romanian","description":"\n\t\n\t\t\n\t\tfinepdfs-summaries\n\t\n\nSummaries generated with Qwen3-Next-80B-A3B-Instruct for documents from finepdfs.\nWork in progress, still generating more data.\nThe following table shows the data available for each language:\n\n\t\n\t\t\nLanguage\nSummaries\nTokens\nDisk size\n\n\n\t\t\nAll\n838,268,819\n247 B\n366 GB\n\n\ndeu_Latn\n363,671,069\n113 B\n149 GB\n\n\neng_Latn\n353,969,370\n89 B\n162 GB\nfra_Latn\n27,308,302\n10 B\n14 GB\n\n\nspa_Latn\n25,624,727\n9 B\n12 GB\n\n\nita_Latn\n17,587,618\n6 B\n8 GB\n\n\npor_Latn\n12,043,607\n4 B\n5 GB‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/MultiSynt/finepdfs-summaries.","url":"https://huggingface.co/datasets/MultiSynt/finepdfs-summaries","creator_name":"MultiSynt","creator_url":"https://huggingface.co/MultiSynt","license_name":"Open Data Commons Attribution License v1.0","license_url":"https://scancode-licensedb.aboutcode.org/odc-by-1.0.html","language":"en","first_N":5,"first_N_keywords":["text-generation","summarization","English","German","French"],"keywords_longer_than_N":true},
	{"name":"X-ALMA-Preference","keyword":"romanian","description":"This is the translation preference dataset used by X-ALMA.\nsource: the source sentence.\nchosen: the preferred translation.\nreject: the dis-preferred translation.\ndirections: the translation direction.\n@misc{xu2024xalmaplugplay,\n      title={X-ALMA: Plug & Play Modules and Adaptive Rejection for Quality Translation at Scale}, \n      author={Haoran Xu and Kenton Murray and Philipp Koehn and Hieu Hoang and Akiko Eriguchi and Huda Khayrallah},\n      year={2024},\n      eprint={2410.03115}‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/haoranxu/X-ALMA-Preference.","url":"https://huggingface.co/datasets/haoranxu/X-ALMA-Preference","creator_name":"Haoran Xu","creator_url":"https://huggingface.co/haoranxu","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["English","Danish","Dutch","German","Icelandic"],"keywords_longer_than_N":true},
	{"name":"Kko","keyword":"romanian","description":"Gargaz/Kko dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/Gargaz/Kko","creator_name":"LUCA ","creator_url":"https://huggingface.co/Gargaz","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["Romanian","apache-2.0","100K - 1M","csv","Text"],"keywords_longer_than_N":true},
	{"name":"ds-tf2-en-ro-3m","keyword":"romanian","description":"\n\t\n\t\t\n\t\tüåç DS-TF2-RO-3M: English‚ÜíRomanian Fable Translations (3M pairs)\n\t\n\nDS-TF2-RO-3M is a large-scale dataset of 3,000,000 English‚ÜíRomanian parallel texts built from moral fables. It targets machine translation, educational NLP, and narrative generation.\nDataset was generated with tf2-12b model\n\n\t\n\t\t\n\t\n\t\n\t\tüîó Resources\n\t\n\n\nSibling dataset (EN originals): klusai/ds-tf1-en-3m\nIntended use: Training/evaluating EN‚ÜíRO MT on narrative prose.\n\n\n\n\t\n\t\n\t\n\t\tüöÄ Quick-start (Python)\n\t\n\nfrom datasets‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/klusai/ds-tf2-en-ro-3m.","url":"https://huggingface.co/datasets/klusai/ds-tf2-en-ro-3m","creator_name":"KlusAI Labs","creator_url":"https://huggingface.co/klusai","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["translation","text-generation","English","Romanian","mit"],"keywords_longer_than_N":true},
	{"name":"ds-tf2-en-ro-3m","keyword":"romanian","description":"\n\t\n\t\t\n\t\tüåç DS-TF2-RO-3M: English‚ÜíRomanian Fable Translations (3M pairs)\n\t\n\nDS-TF2-RO-3M is a large-scale dataset of 3,000,000 English‚ÜíRomanian parallel texts built from moral fables. It targets machine translation, educational NLP, and narrative generation.\nDataset was generated with tf2-12b model\n\n\t\n\t\t\n\t\n\t\n\t\tüîó Resources\n\t\n\n\nSibling dataset (EN originals): klusai/ds-tf1-en-3m\nIntended use: Training/evaluating EN‚ÜíRO MT on narrative prose.\n\n\n\n\t\n\t\n\t\n\t\tüöÄ Quick-start (Python)\n\t\n\nfrom datasets‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/klusai/ds-tf2-en-ro-3m.","url":"https://huggingface.co/datasets/klusai/ds-tf2-en-ro-3m","creator_name":"KlusAI Labs","creator_url":"https://huggingface.co/klusai","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["translation","text-generation","English","Romanian","mit"],"keywords_longer_than_N":true},
	{"name":"multilingual_translation_gpt4o_gen","keyword":"romanian","description":"Youseff1987/multilingual_translation_gpt4o_gen dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/Youseff1987/multilingual_translation_gpt4o_gen","creator_name":"JOON HYOUNG JUN","creator_url":"https://huggingface.co/Youseff1987","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["translation","Korean","English","Chinese","Zulu"],"keywords_longer_than_N":true},
	{"name":"m-ArenaHard","keyword":"romanian","description":"\n\t\n\t\t\n\t\tDataset Card for m-ArenaHard\n\t\n\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\nThe m-ArenaHard dataset is a multilingual LLM evaluation set. This dataset was created by translating the prompts from the originally English-only LMarena (formerly LMSYS) arena-hard-auto-v0.1 test dataset using Google Translate API v3 to 22 languages. The original English-only prompts were created by Li et al. (2024) and consist of 500 challenging user queries sourced from Chatbot Arena. The authors show that these can be used‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/CohereLabs/m-ArenaHard.","url":"https://huggingface.co/datasets/CohereLabs/m-ArenaHard","creator_name":"Cohere Labs","creator_url":"https://huggingface.co/CohereLabs","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["English","French","German","Spanish","Italian"],"keywords_longer_than_N":true},
	{"name":"JQL-LLM-Edu-Annotations","keyword":"romanian","description":"\n\t\n\t\t\n\t\tüìö JQL Educational Quality Annotations from LLMs\n\t\n\nThis dataset provides 17,186,606 documents with high-quality LLM annotations for evaluating the educational value of web documents, and serves as a benchmark for training and evaluating multilingual LLM annotators as described in the JQL paper.\n\n\n\t\n\t\t\n\t\tüìù Dataset Summary\n\t\n\n  Multilingual document-level quality annotations scored on a 0‚Äì5 educational value scale by three state-of-the-art LLMs:\n  Gemma-3-27B-it, Mistral-3.1-24B-it‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/JQL-AI/JQL-LLM-Edu-Annotations.","url":"https://huggingface.co/datasets/JQL-AI/JQL-LLM-Edu-Annotations","creator_name":"JQL-AI","creator_url":"https://huggingface.co/JQL-AI","license_name":"Open Data Commons Attribution License v1.0","license_url":"https://scancode-licensedb.aboutcode.org/odc-by-1.0.html","language":"en","first_N":5,"first_N_keywords":["Bulgarian","Czech","Croatian","Macedonian","Polish"],"keywords_longer_than_N":true},
	{"name":"OGC_Renewable_Regulation","keyword":"romanian","description":"\n\t\n\t\t\n\t\tOGC_Renewable_Regulation - Overview\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nOGC_Renewable_Regulation is a curated multimodal dataset focused on renewable energy technical documents, regulations, and legal frameworks. It combines text and image data extracted from real scientific and regulatory PDFs to support tasks such as RAG DSE, question answering, document search, and vision-language model training.\n\n\t\n\t\t\n\t\tDataset Creation\n\t\n\nThis dataset was created using our open-source tool‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/racineai/OGC_Renewable_Regulation.","url":"https://huggingface.co/datasets/racineai/OGC_Renewable_Regulation","creator_name":"racine.ai","creator_url":"https://huggingface.co/racineai","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["question-answering","visual-question-answering","text-retrieval","English","French"],"keywords_longer_than_N":true},
	{"name":"self-driving","keyword":"romanian","description":"\n\t\n\t\t\n\t\tSelf-driving dataset\n\t\n\nDataset containing model training\n","url":"https://huggingface.co/datasets/teo-m/self-driving","creator_name":"Teodor","creator_url":"https://huggingface.co/teo-m","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["English","Romanian","mit","< 1K","csv"],"keywords_longer_than_N":true},
	{"name":"LivingNER","keyword":"romanian","description":"\n\t\n\t\t\n\t\tLivingNER: Named entity recognition, normalization & classification of species, pathogens and food\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThe LivingNER Gold Standard corpus is a collection of 2000 clinical case reports covering a broad range of medical specialities, i.e. infectious diseases (including Covid-19 cases), cardiology, neurology, oncology, dentistry, pediatrics, endocrinology, primary care, allergology, radiology, psychiatry, ophthalmology, urology, internal medicine, emergency and‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Praise2112/LivingNER.","url":"https://huggingface.co/datasets/Praise2112/LivingNER","creator_name":"Praise","creator_url":"https://huggingface.co/Praise2112","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["token-classification","multilingual","English","French","Galolen"],"keywords_longer_than_N":true},
	{"name":"aya_collection","keyword":"romanian","description":"\nThis dataset is uploaded in two places: here and additionally here as 'Aya Collection Language Split.' These datasets are identical in content but differ in structure of upload. This dataset is structured by folders split according to dataset name. The version here instead divides the Aya collection into folders split by language. We recommend you use the language split version if you are only interested in downloading data for a single or smaller set of languages, and this version if you‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/CohereLabs/aya_collection.","url":"https://huggingface.co/datasets/CohereLabs/aya_collection","creator_name":"Cohere Labs","creator_url":"https://huggingface.co/CohereLabs","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","summarization","translation","Achinese","Afrikaans"],"keywords_longer_than_N":true},
	{"name":"semeval-2025-task11-track-b","keyword":"romanian","description":"\n\t\n\t\t\n\t\tSemEval 2025 Task 11 - Track B Dataset\n\t\n\nThis dataset contains the data for SemEval 2025 Task 11: Bridging the Gap in Text-Based Emotion Detection - Track B, organized as language-specific configurations.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset is a multi-language, multi-label emotion classification dataset with separate configurations for each language.\n\nTotal languages: 11 standard ISO codes\nTotal examples: 47111\nSplits: train, dev, test\n\n\n\t\n\t\t\n\t\tTrack Information\n\t\n\nTrack B has‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/vgaraujov/semeval-2025-task11-track-b.","url":"https://huggingface.co/datasets/vgaraujov/semeval-2025-task11-track-b","creator_name":"Vladimir Araujo","creator_url":"https://huggingface.co/vgaraujov","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["Amharic","Arabic","German","English","Spanish"],"keywords_longer_than_N":true},
	{"name":"IanVOODOO","keyword":"romanian","description":"nekkaz/IanVOODOO dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/nekkaz/IanVOODOO","creator_name":"Andoni Mihai Alexandru","creator_url":"https://huggingface.co/nekkaz","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":null,"first_N":5,"first_N_keywords":["Romanian","apache-2.0","üá∫üá∏ Region: US","music"],"keywords_longer_than_N":false},
	{"name":"mHumanEval-Benchmark","keyword":"romanian","description":"\n\n\n\t\n\t\t\n\t\tüî∑ Accepted in NAACL Proceedings (2025) üî∑\n\t\n\n\n\n\n\n  \n    \n      \n        \n          \n        \n      \n      \n        \n          \n        \n      \n      \n        \n          \n        \n      \n    \n  \n\n\n\n\n\n  \n\n\t\n\t\n\t\n\t\tmHumanEval\n\t\n\nThe mHumanEval benchmark is curated based on prompts from the original HumanEval üìö [Chen et al., 2021]. It includes a total of 33,456 prompts for Python, and 836,400 in total - significantly expanding from the original 164. \n\n\n\t\n\t\t\n\t\tQuick Start\n\t\n\n  Detailed‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/md-nishat-008/mHumanEval-Benchmark.","url":"https://huggingface.co/datasets/md-nishat-008/mHumanEval-Benchmark","creator_name":"Nishat Raihan","creator_url":"https://huggingface.co/md-nishat-008","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["Afar","Abkhaz","Avestan","Afrikaans","Akan"],"keywords_longer_than_N":true},
	{"name":"esol","keyword":"romanian","description":"calofiremil/esol dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/calofiremil/esol","creator_name":"calofir emil","creator_url":"https://huggingface.co/calofiremil","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["Romanian","apache-2.0","< 1K","parquet","Text"],"keywords_longer_than_N":true},
	{"name":"biblenlp-corpus-mmteb","keyword":"romanian","description":"This dataset pre-computes all English-centric directions from bible-nlp/biblenlp-corpus, and as a result loading is significantly faster.\nLoading example:\n>>> from datasets import load_dataset\n>>> dataset = load_dataset(\"davidstap/biblenlp-corpus-mmteb\", \"eng-arb\", trust_remote_code=True)\n>>> dataset\nDatasetDict({\n    train: Dataset({\n        features: ['eng', 'arb'],\n        num_rows: 28723\n    })\n    validation: Dataset({\n        features: ['eng', 'arb'],\n        num_rows: 1578\n    })‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/davidstap/biblenlp-corpus-mmteb.","url":"https://huggingface.co/datasets/davidstap/biblenlp-corpus-mmteb","creator_name":"David Stap","creator_url":"https://huggingface.co/davidstap","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["no-annotation","expert-generated","translation","multilingual","Arifama-Miniafia"],"keywords_longer_than_N":true},
	{"name":"fulg","keyword":"romanian","description":"\n\t\n\t\t\n\t\n\t\n\t\t‚ùÑÔ∏èFuLG\n\t\n\nThe FuLG dataset is a comprehensive Romanian language corpus comprising 150 billion tokens, carefully\nextracted from Common Crawl. This extensive dataset is the result of rigorous filtering and deduplication \nprocesses applied to 95 Common Crawl snapshots. The compressed dataset has 289 GB.\nFor more details, check the arXiv preprint.\n\n\t\n\t\t\n\t\n\t\n\t\tHow do I download this?\n\t\n\n\n\t\n\t\t\n\t\n\t\n\t\tUsing ü§ó Datasets\n\t\n\nfrom datasets import load_dataset\n\n# Full dataset\ndataset =‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/faur-ai/fulg.","url":"https://huggingface.co/datasets/faur-ai/fulg","creator_name":"faur-ai","creator_url":"https://huggingface.co/faur-ai","license_name":"Open Data Commons Attribution License v1.0","license_url":"https://scancode-licensedb.aboutcode.org/odc-by-1.0.html","language":"en","first_N":5,"first_N_keywords":["text-generation","Romanian","odc-by","100B<n<1T","arxiv:2407.13657"],"keywords_longer_than_N":true},
	{"name":"toxi-text-3M","keyword":"romanian","description":"This is a large multilingual toxicity dataset with 3M rows of text data from 55 natural languages, all of which are written/sent by humans, not machine translation models.\nThe preprocessed training data alone consists of 2,880,667 rows of comments, tweets, and messages. Among these rows, 416,529 are classified as toxic, while the remaining 2,463,773 are considered neutral. Below is a table to illustrate the data composition:\n\n\t\n\t\t\n\nToxic\nNeutral\nTotal\n\n\n\t\t\nmultilingual-train-deduplicated.csv‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/FredZhang7/toxi-text-3M.","url":"https://huggingface.co/datasets/FredZhang7/toxi-text-3M","creator_name":"Fred Zhang","creator_url":"https://huggingface.co/FredZhang7","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","zero-shot-classification","Arabic","Spanish","Panjabi"],"keywords_longer_than_N":true},
	{"name":"RoMedQA_v1","keyword":"romanian","description":"\n\t\n\t\t\n\t\tDescription\n\t\n\nThis is RoMedQA, a dataset that amounts to 4,127 single-choice questions regarding the medical field in the Romanian language.\nThe dataset consists of advanced biology questions used in entrance examinations in medical schools in Romania.\nEach question has five possible answer choices, numbered from 1 to 5, with only one correct answer.\n\n\t\n\t\t\n\t\tLoading\n\t\n\nFor loading the dataset, you can simply proceed as follows:\nfrom datasets import load_dataset\n\ndataset =‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/craciuncg/RoMedQA_v1.","url":"https://huggingface.co/datasets/craciuncg/RoMedQA_v1","creator_name":"Cristian-George Craciun","creator_url":"https://huggingface.co/craciuncg","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["question-answering","Romanian","apache-2.0","1K - 10K","csv"],"keywords_longer_than_N":true},
	{"name":"muri-it","keyword":"romanian","description":"\n\t\n\t\t\n\t\tMURI-IT: Multilingual Instruction Tuning Dataset for 200 Languages via Multilingual Reverse Instructions\n\t\n\nMURI-IT is a large-scale multilingual instruction tuning dataset containing 2.2 million instruction-output pairs across 200 languages. It is designed to address the challenges of instruction tuning in low-resource languages with Multilingual Reverse Instructions (MURI), which ensures that the output is human-written, high-quality, and authentic to the cultural and linguistic‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/akoksal/muri-it.","url":"https://huggingface.co/datasets/akoksal/muri-it","creator_name":"Abdullatif Koksal","creator_url":"https://huggingface.co/akoksal","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text2text-generation","text-generation","question-answering","summarization","Achinese"],"keywords_longer_than_N":true},
	{"name":"rssdb","keyword":"romanian","description":"\n***  RSS (Romanian Speech Synthesis) DATABASE v.0.8.1  ***\n\nhttps://romaniantts.com/rssdb/\nThis directory contains recordings of Romanian sentences, recorded by ADR, a native Romanian speaker.\nThe phoneme set used is described in PHONEMES.txt\nThe folder is divided into trainining and testing data. The training data contains two sets of sentences chosen for diphone coverage (diph1 and diph2), three sets of randomly selected newspaper sentences (rnd1, rnd2 and rnd3) and two short stories by Ion‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/devfed/rssdb.","url":"https://huggingface.co/datasets/devfed/rssdb","creator_name":"Fedot Sereoja","creator_url":"https://huggingface.co/devfed","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["Romanian","mit","1K - 10K","soundfolder","Audio"],"keywords_longer_than_N":true},
	{"name":"FineNews-unfiltered","keyword":"romanian","description":"\n\t\n\t\t\n\t\tFineNews\n\t\n\nWIP. Like FineWeb, but built from Common Crawl News instead of main web.\nFor languages not listed as a split, check the data/ directory.\nFor now, it contains the 2024-05 (May),-04 (April),-03 (March) dumps.\nThis is the unfiltered version, with only URL filtering applied.\n\n\t\n\t\t\n\t\tSome initial stats\n\t\n\nTotal number of documents: 35M\n\n\t\n\t\t\nDump\nNumber of docs\nDisk size (compressed)\n\n\n\t\t\nCC-NEWS-2024-05\n11_715_084\n11G\n\n\nCC-NEWS-2024-04\n11_546_298\n11G\n\n\nCC-NEWS-2024-03‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/maxidl/FineNews-unfiltered.","url":"https://huggingface.co/datasets/maxidl/FineNews-unfiltered","creator_name":"Max Idahl","creator_url":"https://huggingface.co/maxidl","license_name":"Open Data Commons Attribution License v1.0","license_url":"https://scancode-licensedb.aboutcode.org/odc-by-1.0.html","language":"en","first_N":5,"first_N_keywords":["text-generation","English","German","French","Polish"],"keywords_longer_than_N":true},
	{"name":"ParaNames","keyword":"romanian","description":"\n\t\n\t\t\n\t\n\t\n\t\tDataset Card for Dataset Name\n\t\n\n\n\nThis dataset card aims to be a base template for new datasets. It has been generated using this raw template.\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Description\n\t\n\n\n\n\n\n\nCurated by: [More Information Needed]\nFunded by [optional]: [More Information Needed]\nShared by [optional]: [More Information Needed]\nLanguage(s) (NLP): [More Information Needed]\nLicense: [More Information Needed]\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Sources [optional]‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/bltlab/ParaNames.","url":"https://huggingface.co/datasets/bltlab/ParaNames","creator_name":"Broadening Linguistic Technologies Lab (BLT Lab)","creator_url":"https://huggingface.co/bltlab","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["token-classification","Nias","Kotava","Banjar","Angika"],"keywords_longer_than_N":true},
	{"name":"xP3x-Kongo","keyword":"romanian","description":"\n\t\n\t\t\n\t\tDataset Card for xP3x Kikongo Focus\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\n\nxP3x (Crosslingual Public Pool of Prompts eXtended) is a collection of prompts & datasets across 277 languages & 16 NLP tasks. It contains all of xP3 + much more! It is used for training future contenders of mT0 & BLOOMZ at project Aya @C4AI üß°\n\n\nCreation: The dataset can be recreated using instructions available here together with the file in this repository named xp3x_create.py. We provide this version to save‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Svngoku/xP3x-Kongo.","url":"https://huggingface.co/datasets/Svngoku/xP3x-Kongo","creator_name":"NIONGOLO Chrys F√©-Marty","creator_url":"https://huggingface.co/Svngoku","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["other","translation","expert-generated","crowdsourced","multilingual"],"keywords_longer_than_N":true},
	{"name":"voices-of-civilizations","keyword":"romanian","description":"\n\t\n\t\t\n\t\tVoices of Civilizations (VoC)\n\t\n\nVoices of Civilizations (VoC) is the first multilingual QA benchmark designed to assess audio LLMs‚Äô cultural comprehension using full-length music recordings. VoC spans:\n\n38 languages üá∏üá¶ Arabic (ar), üáßüá© Bengali (bn), üáßüá¨ Bulgarian (bg), üá®üá≥ Chinese (zh), üá≠üá∑ Croatian (hr), üá®üáø Czech (cs), üá©üá∞ Danish (da), üá≥üá± Dutch (nl), üá¨üáß English (en), üá™üá™ Estonian (et), üá´üáÆ Finnish (fi), üá´üá∑ French (fr), üá©üá™ German (de), üá¨üá∑ Greek (el), üáÆüá± Hebrew‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/sander-wood/voices-of-civilizations.","url":"https://huggingface.co/datasets/sander-wood/voices-of-civilizations","creator_name":"Shangda Wu (Sander Wood)","creator_url":"https://huggingface.co/sander-wood","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["question-answering","Arabic","Bengali","Bulgarian","Chinese"],"keywords_longer_than_N":true},
	{"name":"wikipedia-citation-index","keyword":"romanian","description":"Dataset with citation indexes as of 1 August 2024 for 47 million Wikipedia articles in 55 language versions. Research: ArXiv\n","url":"https://huggingface.co/datasets/lewoniewski/wikipedia-citation-index","creator_name":"W≈Çodzimierz Lewoniewski","creator_url":"https://huggingface.co/lewoniewski","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["Arabic","Azerbaijani","Belarusian","Bulgarian","Catalan"],"keywords_longer_than_N":true},
	{"name":"SmartDataSet","keyword":"romanian","description":"IonGrozea/SmartDataSet dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/IonGrozea/SmartDataSet","creator_name":"Ion Grozea","creator_url":"https://huggingface.co/IonGrozea","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["Romanian","mit","1K - 10K","parquet","Audio"],"keywords_longer_than_N":true},
	{"name":"SmartDataSet","keyword":"romanian","description":"IonGrozea/SmartDataSet dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/IonGrozea/SmartDataSet","creator_name":"Ion Grozea","creator_url":"https://huggingface.co/IonGrozea","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["Romanian","mit","1K - 10K","parquet","Audio"],"keywords_longer_than_N":true},
	{"name":"CommonVoices20_ro","keyword":"romanian","description":"\n\t\n\t\t\n\t\tCommon Voices Corpus 20.0 (Romanian)\n\t\n\n\nCommon Voices is an open-source dataset of speech recordings created by \nMozilla to improve speech recognition technologies. \nIt consists of crowdsourced voice samples in multiple languages, contributed by volunteers worldwide.\n\n\n\nChallenges: The raw dataset included numerous recordings with incorrect transcriptions \nor those requiring adjustments, such as sampling rate modifications, conversion to .wav format, and other refinements \nessential‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/TransferRapid/CommonVoices20_ro.","url":"https://huggingface.co/datasets/TransferRapid/CommonVoices20_ro","creator_name":"Transfer Rapid","creator_url":"https://huggingface.co/TransferRapid","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","audio-classification","text-to-speech","text-to-audio","Romanian"],"keywords_longer_than_N":true},
	{"name":"CommonVoices20_ro","keyword":"romanian","description":"\n\t\n\t\t\n\t\tCommon Voices Corpus 20.0 (Romanian)\n\t\n\n\nCommon Voices is an open-source dataset of speech recordings created by \nMozilla to improve speech recognition technologies. \nIt consists of crowdsourced voice samples in multiple languages, contributed by volunteers worldwide.\n\n\n\nChallenges: The raw dataset included numerous recordings with incorrect transcriptions \nor those requiring adjustments, such as sampling rate modifications, conversion to .wav format, and other refinements \nessential‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/TransferRapid/CommonVoices20_ro.","url":"https://huggingface.co/datasets/TransferRapid/CommonVoices20_ro","creator_name":"Transfer Rapid","creator_url":"https://huggingface.co/TransferRapid","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","audio-classification","text-to-speech","text-to-audio","Romanian"],"keywords_longer_than_N":true},
	{"name":"AyaVisionBench","keyword":"romanian","description":"\n\t\n\t\t\n\t\tDataset Card for Aya Vision Benchmark\n\t\n\n\n\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\nThe Aya Vision Benchmark is designed to evaluate vision-language models in real-world multilingual scenarios. It spans 23 languages and 9 distinct task categories, with 15 samples per category, resulting in 135 image-question pairs per language. \nEach question requires visual context for the answer and covers languages that half of the world's population speaks, making this dataset particularly suited for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/CohereLabs/AyaVisionBench.","url":"https://huggingface.co/datasets/CohereLabs/AyaVisionBench","creator_name":"Cohere Labs","creator_url":"https://huggingface.co/CohereLabs","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["English","French","German","Spanish","Italian"],"keywords_longer_than_N":true},
	{"name":"Pornhub","keyword":"romanian","description":"\n\t\n\t\t\n\t\tPornhub Dataset\n\t\n\nThe Pornhub Dataset provides a comprehensive collection of data sourced from pornhub.com, encompassing various details from MANYYY videos available on the platform.\nThe file consists of 742.133 lines of videos.\n\n\t\n\t\t\n\t\tData Description\n\t\n\n\nDelimiter: ‚ÄΩ\nFile Format: CSV\nContent:\nURL: The URL of the video.\nCategory: The genre or category of the video.\nUser: The username of the uploader.\nVideo_title: The title of the video.\nViews: The number of views the video has‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Nikity/Pornhub.","url":"https://huggingface.co/datasets/Nikity/Pornhub","creator_name":"Nikita","creator_url":"https://huggingface.co/Nikity","license_name":"Open Data Commons Attribution License v1.0","license_url":"https://scancode-licensedb.aboutcode.org/odc-by-1.0.html","language":"en","first_N":5,"first_N_keywords":["Albanian","Arabic","Bengali","Bulgarian","Chinese"],"keywords_longer_than_N":true},
	{"name":"RoSTSC","keyword":"romanian","description":"\n\t\n\t\t\n\t\tRO-STS-Cupidon\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nRoSTSC is a Romanian Semantic Textual Similarity (STS) dataset designed for evaluating and training sentence embedding models. It contains pairs of Romanian sentences along with similarity scores that indicate the degree of semantic equivalence between them.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\nsentence1: The first sentence in the pair.\nsentence2: The second sentence in the pair.\nscore: A numerical value representing the semantic similarity between the‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/BlackKakapo/RoSTSC.","url":"https://huggingface.co/datasets/BlackKakapo/RoSTSC","creator_name":"Alexandru Petrachi","creator_url":"https://huggingface.co/BlackKakapo","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["sentence-similarity","monolingual","Romanian","apache-2.0","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"para_pat","keyword":"romanian","description":"ParaPat: The Multi-Million Sentences Parallel Corpus of Patents Abstracts\n\nThis dataset contains the developed parallel corpus from the open access Google\nPatents dataset in 74 language pairs, comprising more than 68 million sentences\nand 800 million tokens. Sentences were automatically aligned using the Hunalign algorithm\nfor the largest 22 language pairs, while the others were abstract (i.e. paragraph) aligned.","url":"https://huggingface.co/datasets/ParaPat/para_pat","creator_name":"ParaPat","creator_url":"https://huggingface.co/ParaPat","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":null,"first_N":5,"first_N_keywords":["text-generation","fill-mask","translation","language-modeling","masked-language-modeling"],"keywords_longer_than_N":true},
	{"name":"tatoeba_mt","keyword":"romanian","description":"The Tatoeba Translation Challenge is a multilingual data set of\nmachine translation benchmarks derived from user-contributed\ntranslations collected by [Tatoeba.org](https://tatoeba.org/) and\nprovided as parallel corpus from [OPUS](https://opus.nlpl.eu/). This\ndataset includes test and development data sorted by language pair. It\nincludes test sets for hundreds of language pairs and is continuously\nupdated. Please, check the version number tag to refer to the release\nthat your are using.","url":"https://huggingface.co/datasets/Helsinki-NLP/tatoeba_mt","creator_name":"Language Technology Research Group at the University of Helsinki","creator_url":"https://huggingface.co/Helsinki-NLP","license_name":"Creative Commons Attribution 2.0","license_url":"https://scancode-licensedb.aboutcode.org/cc-by-2.0.html","language":null,"first_N":5,"first_N_keywords":["text-generation","translation","no-annotation","crowdsourced","translation"],"keywords_longer_than_N":true},
	{"name":"common_voice_16_0","keyword":"romanian","description":"\n\t\n\t\t\n\t\tDataset Card for Common Voice Corpus 16.0\n\t\n\n\n\nThis dataset is an unofficial version of the Mozilla Common Voice Corpus 16. It was downloaded and converted from the project's website https://commonvoice.mozilla.org/.\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nAbkhaz, Albanian, Amharic, Arabic, Armenian, Assamese, Asturian, Azerbaijani, Basaa, Bashkir, Basque, Belarusian, Bengali, Breton, Bulgarian, Cantonese, Catalan, Central Kurdish, Chinese (China), Chinese (Hong Kong), Chinese (Taiwan), Chuvash, Czech‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/fsicoli/common_voice_16_0.","url":"https://huggingface.co/datasets/fsicoli/common_voice_16_0","creator_name":"Fabio Sicoli","creator_url":"https://huggingface.co/fsicoli","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":null,"first_N":5,"first_N_keywords":["automatic-speech-recognition","Abkhaz","Afrikaans","Amharic","Arabic"],"keywords_longer_than_N":true},
	{"name":"openassistant-deepseek-coder","keyword":"romanian","description":"\n\t\n\t\t\n\t\tChat Fine-tuning Dataset - OpenAssistant DeepSeek Coder\n\t\n\nThis dataset allows for fine-tuning chat models using:\nB_INST = '\\n### Instruction:\\n'\nE_INST = '\\n### Response:\\n'\nBOS = '<ÔΩúbegin‚ñÅof‚ñÅsentenceÔΩú>'\nEOS = '\\n<|EOT|>\\n'\n\nSample Preparation:\n\nThe dataset is cloned from TimDettmers, which itself is a subset of the Open Assistant dataset, which you can find here. This subset of the data only contains the highest-rated paths in the conversation tree, with a total of 9,846 samples.\nThe‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Trelis/openassistant-deepseek-coder.","url":"https://huggingface.co/datasets/Trelis/openassistant-deepseek-coder","creator_name":"Trelis","creator_url":"https://huggingface.co/Trelis","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["English","Spanish","Russian","German","Polish"],"keywords_longer_than_N":true},
	{"name":"xtreme_s","keyword":"romanian","description":"XTREME-S covers four task families: speech recognition, classification, speech-to-text translation and retrieval. Covering 102\nlanguages from 10+ language families, 3 different domains and 4\ntask families, XTREME-S aims to simplify multilingual speech\nrepresentation evaluation, as well as catalyze research in ‚Äúuniversal‚Äù speech representation learning.","url":"https://huggingface.co/datasets/google/xtreme_s","creator_name":"Google","creator_url":"https://huggingface.co/google","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":null,"first_N":5,"first_N_keywords":["automatic-speech-recognition","expert-generated","crowdsourced","machine-generated","crowdsourced"],"keywords_longer_than_N":true},
	{"name":"ro-aya_collection","keyword":"romanian","description":"This dataset is a translation of CohereLabs/aya_collection, an instruction dataset, using LLMic, a bilingual Romanian-English LLM.\nThe Aya Collection is a massive multilingual collection consisting of 513 million instances of prompts and completions covering a wide \nrange of tasks. This collection incorporates instruction-style templates from fluent speakers and applies them to a curated \nlist of datasets, as well as translations of instruction-style datasets into 101 languages.\n\nOnly the‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/faur-ai/ro-aya_collection.","url":"https://huggingface.co/datasets/faur-ai/ro-aya_collection","creator_name":"faur-ai","creator_url":"https://huggingface.co/faur-ai","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","summarization","translation","Romanian","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"super_eurlex","keyword":"romanian","description":"Super-EURLEX dataset containing legal documents from multiple languages.\n                The datasets are build/scrapped from the EURLEX Website [https://eur-lex.europa.eu/homepage.html]\n                With one split per language and sector, because the available features (metadata) differs for each \n                sector. Therefore, each sample contains the content of a full legal document in up to 3 different \n                formats. Those are raw HTML and cleaned HTML (if the HTML format was available on the EURLEX website \n                during the scrapping process) and cleaned text.\n                The cleaned text should be available for each sample and was extracted from HTML or PDF.\n                'Cleaned' HTML stands here for minor cleaning that was done to preserve to a large extent the necessary \n                HTML information like table structures while removing unnecessary complexity which was introduced to the \n                original documents due to actions like writing each sentence into a new object. \n                Additionally, each sample contains metadata which was scrapped on the fly, this implies the following \n                2 things. First, not every sector contains the same metadata. Second, most metadata might be \n                irrelevant for most use cases. \n                In our minds the most interesting metadata is the celex-id which is used to identify the legal \n                document at hand, but also contains a lot of information about the document \n                see [https://eur-lex.europa.eu/content/tools/eur-lex-celex-infographic-A3.pdf] as well as eurovoc-\n                concepts, which are labels that define the content of the documents. \n                Eurovoc-Concepts are, for example, only available for the sectors 1, 2, 3, 4, 5, 6, 9, C, and E.\n                The Naming of most metadata is kept like it was on the eurlex website, except for converting \n                it to lower case and replacing whitespaces with '_'.","url":"https://huggingface.co/datasets/ddrg/super_eurlex","creator_name":"Dresden Database Research Group","creator_url":"https://huggingface.co/ddrg","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":null,"first_N":5,"first_N_keywords":["text-classification","fill-mask","multi-class-classification","multi-label-classification","found"],"keywords_longer_than_N":true},
	{"name":"news-ro-offense","keyword":"romanian","description":"\n\t\n\t\t\n\t\tDataset Card for \"RO-News-Offense\"\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\na novel Romanian language dataset for offensive message detection with manually \nannotated comment from a local Romanian news website (stiri de cluj) into five classes:\n\nnon-offensive\ntargeted insults\nracist\nhomophobic\nsexist\n\nResulting in 4052 annotated messages\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nRomanian\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\n\t\n\t\t\n\t\tData Instances\n\t\n\nAn example of 'train' looks as follows.\n{\n  'comment_id': 5‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/readerbench/news-ro-offense.","url":"https://huggingface.co/datasets/readerbench/news-ro-offense","creator_name":"ReaderBench","creator_url":"https://huggingface.co/readerbench","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","hate-speech-detection","expert-generated","found","monolingual"],"keywords_longer_than_N":true},
	{"name":"oscar-small","keyword":"romanian","description":"The Open Super-large Crawled ALMAnaCH coRpus is a huge multilingual corpus obtained by language classification and filtering of the Common Crawl corpus using the goclassy architecture.\\","url":"https://huggingface.co/datasets/djstrong/oscar-small","creator_name":"Krzysztof Wr√≥bel","creator_url":"https://huggingface.co/djstrong","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","language-modeling","no-annotation","found","multilingual"],"keywords_longer_than_N":true},
	{"name":"oscar-small","keyword":"romanian","description":"The Open Super-large Crawled ALMAnaCH coRpus is a huge multilingual corpus obtained by language classification and filtering of the Common Crawl corpus using the goclassy architecture.\\","url":"https://huggingface.co/datasets/nthngdy/oscar-small","creator_name":"Nathan Godey","creator_url":"https://huggingface.co/nthngdy","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","language-modeling","no-annotation","found","multilingual"],"keywords_longer_than_N":true},
	{"name":"multilingual-pl-bert","keyword":"romanian","description":"Attribution: Wikipedia.org\n","url":"https://huggingface.co/datasets/styletts2-community/multilingual-pl-bert","creator_name":"StyleTTS 2 Community","creator_url":"https://huggingface.co/styletts2-community","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["Afrikaans","Aragonese","Arabic","Azerbaijani","Bashkir"],"keywords_longer_than_N":true},
	{"name":"mapa","keyword":"romanian","description":"\n\t\n\t\t\n\t\tDataset Card for Multilingual European Datasets for Sensitive Entity Detection in the Legal Domain\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThe dataset consists of 12 documents (9 for Spanish due to parsing errors) taken from EUR-Lex, a multilingual corpus of court\ndecisions and legal dispositions in the 24 official languages of the European Union. The documents have been annotated\nfor named entities following the guidelines of the MAPA project which foresees two\nannotation level, a general and a‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/joelniklaus/mapa.","url":"https://huggingface.co/datasets/joelniklaus/mapa","creator_name":"Joel Niklaus","creator_url":"https://huggingface.co/joelniklaus","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["token-classification","named-entity-recognition","other","found","multilingual"],"keywords_longer_than_N":true},
	{"name":"tatoeba-mt-qna-oa","keyword":"romanian","description":"\n\t\n\t\t\n\t\tDataset Card for multilingual tatoeba QnA translation with ~120K entries.\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nContains Parquet of a list of instructions and translation articles on different languages.\nEach row consists of\n\nINSTRUCTION\nRESPONSE\nSOURCE (tatoeba)\nMETADATA (json with language, text length, uuid, langs-pair).\n\n\n\t\n\t\t\n\t\tOriginal Dataset is avalible here:\n\t\n\n\nhttps://huggingface.co/datasets/Helsinki-NLP/tatoeba_mt\n\n","url":"https://huggingface.co/datasets/0x22almostEvil/tatoeba-mt-qna-oa","creator_name":"David Glushkov","creator_url":"https://huggingface.co/0x22almostEvil","license_name":"Creative Commons Attribution 2.0","license_url":"https://scancode-licensedb.aboutcode.org/cc-by-2.0.html","language":"en","first_N":5,"first_N_keywords":["question-answering","translation","English","Russian","German"],"keywords_longer_than_N":true},
	{"name":"docfullstructure_dataset","keyword":"romanian","description":"kopan/docfullstructure_dataset dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/kopan/docfullstructure_dataset","creator_name":"Ilia Kopanichuk","creator_url":"https://huggingface.co/kopan","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":null,"first_N":5,"first_N_keywords":["text-classification","Russian","English","Kazakh","Bulgarian"],"keywords_longer_than_N":true},
	{"name":"openassistant-guanaco-EOS","keyword":"romanian","description":"\n\t\n\t\t\n\t\tChat Fine-tuning Dataset - Guanaco Style\n\t\n\nThis dataset allows for fine-tuning chat models using \"### Human:\" AND \"### Assistant\" as the beginning and end of sequence tokens.\nPreparation:\n\nThe dataset is cloned from TimDettmers, which itself is a subset of the Open Assistant dataset, which you can find here. This subset of the data only contains the highest-rated paths in the conversation tree, with a total of 9,846 samples.\nThe dataset was then slightly adjusted to:\n\n\nif a row of‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Trelis/openassistant-guanaco-EOS.","url":"https://huggingface.co/datasets/Trelis/openassistant-guanaco-EOS","creator_name":"Trelis","creator_url":"https://huggingface.co/Trelis","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["English","Spanish","Russian","German","Polish"],"keywords_longer_than_N":true},
	{"name":"laroseda","keyword":"romanian","description":"        LaRoSeDa (A Large Romanian Sentiment Data Set) contains 15,000 reviews written in Romanian, of which 7,500 are positive and 7,500 negative.\n        Star ratings of 1 and 2 and of 4 and 5 are provided for negative and positive reviews respectively.\n        The current dataset uses star rating as the label for multi-class classification.","url":"https://huggingface.co/datasets/universityofbucharest/laroseda","creator_name":"University of Bucharest","creator_url":"https://huggingface.co/universityofbucharest","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":null,"first_N":5,"first_N_keywords":["text-classification","sentiment-classification","found","found","monolingual"],"keywords_longer_than_N":true},
	{"name":"Wikinews-multilingual","keyword":"romanian","description":"\n\t\n\t\t\n\t\tWikinews - weakly aligned multilingual pararell sentence datasets\n\t\n\nThis dataset contains 15,200 multilingual WikiNews articles in 33 languages.\nOut of 15,200 articles, 9,960 are non-English news and 5240 are English news.  All non-English news are linked to one of 5240 English news. Linked articles show the same event.\nList of non-English languages are: Spanish, French, German, Portuguese, Polish, Italian, Chinese, Russian, Japanese, Dutch, Swedish, Tamil, Serbian, Czech, Catalan‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Fumika/Wikinews-multilingual.","url":"https://huggingface.co/datasets/Fumika/Wikinews-multilingual","creator_name":"Fumika Isono","creator_url":"https://huggingface.co/Fumika","license_name":"Creative Commons Attribution 2.5","license_url":"https://scancode-licensedb.aboutcode.org/cc-by-2.5.html","language":"en","first_N":5,"first_N_keywords":["text-classification","feature-extraction","English","Spanish","French"],"keywords_longer_than_N":true},
	{"name":"mc4-sampling","keyword":"romanian","description":"A sampling-enabled version of mC4, the colossal, cleaned version of Common Crawl's web crawl corpus.\n\nBased on Common Crawl dataset: \"https://commoncrawl.org\".\n\nThis is a version of the processed version of Google's mC4 dataset by AllenAI, in which sampling methods are implemented to perform on the fly.","url":"https://huggingface.co/datasets/bertin-project/mc4-sampling","creator_name":"BERTIN Project","creator_url":"https://huggingface.co/bertin-project","license_name":"Open Data Commons Attribution License v1.0","license_url":"https://scancode-licensedb.aboutcode.org/odc-by-1.0.html","language":null,"first_N":5,"first_N_keywords":["text-generation","fill-mask","language-modeling","no-annotation","found"],"keywords_longer_than_N":true},
	{"name":"audio_vreme","keyword":"romanian","description":"iulik-pisik/audio_vreme dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/iulik-pisik/audio_vreme","creator_name":"Iulia Udrea","creator_url":"https://huggingface.co/iulik-pisik","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":null,"first_N":5,"first_N_keywords":["automatic-speech-recognition","Romanian","apache-2.0","üá∫üá∏ Region: US","climate"],"keywords_longer_than_N":false},
	{"name":"xlel_wd","keyword":"romanian","description":"XLEL-WD is a multilingual event linking dataset. This dataset contains mention references from multilingual Wikipedia/Wikinews articles to event items in Wikidata. The text descriptions for Wikidata events are compiled from Wikipedia articles.","url":"https://huggingface.co/datasets/adithya7/xlel_wd","creator_name":"Adithya Pratapa","creator_url":"https://huggingface.co/adithya7","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["found","found","multilingual","original","Afrikaans"],"keywords_longer_than_N":true},
	{"name":"opus_paracrawl","keyword":"romanian","description":"\n\t\n\t\t\n\t\tDataset Card for OpusParaCrawl\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nParallel corpora from Web Crawls collected in the ParaCrawl project.\nTha dataset contains:\n\n42 languages, 43 bitexts\ntotal number of files: 59,996\ntotal number of tokens: 56.11G\ntotal number of sentence fragments: 3.13G\n\nTo load a language pair which isn't part of the config, all you need to do is specify the language code as pairs,\ne.g.\ndataset = load_dataset(\"opus_paracrawl\", lang1=\"en\", lang2=\"so\")\n\nYou can find the valid‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Helsinki-NLP/opus_paracrawl.","url":"https://huggingface.co/datasets/Helsinki-NLP/opus_paracrawl","creator_name":"Language Technology Research Group at the University of Helsinki","creator_url":"https://huggingface.co/Helsinki-NLP","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["translation","found","found","multilingual","original"],"keywords_longer_than_N":true},
	{"name":"panlex","keyword":"romanian","description":"\n\t\n\t\t\n\t\tPanLex\n\t\n\nJanuary 1, 2024 version of PanLex Language Vocabulary with 24,650,274 rows covering 6,152 languages.\n\n\t\n\t\t\n\t\tColumns\n\t\n\n\nvocab: contains the text entry.  \n639-3: contains the ISO 639-3 languages tags to allow users to filter on the language(s) of their choice.\n639-3_english_name: the English language name associated to the code ISO 639-3. \nvar_code: contains a code to differentiate language variants. In practice, this is the code 639-3 + a number.  If 000, it corresponds to‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/lbourdois/panlex.","url":"https://huggingface.co/datasets/lbourdois/panlex","creator_name":"Lo√Øck BOURDOIS","creator_url":"https://huggingface.co/lbourdois","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["Ghotuo","Alumu-Tesu","Ari","Amal","Arb√´resh√´ Albanian"],"keywords_longer_than_N":true},
	{"name":"tatoeba-mt-all-in-one","keyword":"romanian","description":"\n\t\n\t\t\n\t\tDataset Card for The Tatoeba Translation Challenge | All In One\n\t\n\n~7.3M entries.\nJust more user-friendly version that combines all of the entries of original dataset in a single file:\nhttps://huggingface.co/datasets/Helsinki-NLP/tatoeba_mt\n","url":"https://huggingface.co/datasets/0x22almostEvil/tatoeba-mt-all-in-one","creator_name":"David Glushkov","creator_url":"https://huggingface.co/0x22almostEvil","license_name":"Creative Commons Attribution 2.0","license_url":"https://scancode-licensedb.aboutcode.org/cc-by-2.0.html","language":"en","first_N":5,"first_N_keywords":["Helsinki-NLP","crowdsourced","translation","Helsinki-NLP/tatoeba_mt","Afrikaans"],"keywords_longer_than_N":true},
	{"name":"tatoeba-mt-llama-only","keyword":"romanian","description":"\n\t\n\t\t\n\t\tDataset Card for multilingual tatoeba translations with ~3M entries (llama supported languages only).\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\n~3M entries. Just more user-friendly version that combines all of the entries of original dataset in a single file (llama supported languages only):\nhttps://huggingface.co/datasets/Helsinki-NLP/tatoeba_mt\n","url":"https://huggingface.co/datasets/0x22almostEvil/tatoeba-mt-llama-only","creator_name":"David Glushkov","creator_url":"https://huggingface.co/0x22almostEvil","license_name":"Creative Commons Attribution 2.0","license_url":"https://scancode-licensedb.aboutcode.org/cc-by-2.0.html","language":"en","first_N":5,"first_N_keywords":["translation","English","Russian","German","Ukrainian"],"keywords_longer_than_N":true},
	{"name":"ro-fb-offense","keyword":"romanian","description":"\n\t\n\t\t\n\t\tDataset Card for \"RO-FB-Offense\"\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nFB-RO-Offense corpus, an offensive speech dataset containing 4,455 user-generated comments from Facebook live broadcasts available in Romanian\nThe annotation follows the hierarchical tagset proposed in the Germeval 2018 Dataset. \nThe following Classes are available:\n\nOTHER: Non-Offensive Language\nOFFENSIVE:\nPROFANITY\nINSULT\nABUSE\n\n\n\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nRomanian\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\n\t\n\t\t\n\t\tData Instances\n\t\n\nAn‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/readerbench/ro-fb-offense.","url":"https://huggingface.co/datasets/readerbench/ro-fb-offense","creator_name":"ReaderBench","creator_url":"https://huggingface.co/readerbench","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","hate-speech-detection","expert-generated","found","monolingual"],"keywords_longer_than_N":true},
	{"name":"tokenizer-wiki-bench","keyword":"romanian","description":"\n\t\n\t\t\n\t\tMultilingual Tokenizer Benchmark\n\t\n\nThis dataset includes pre-processed wikipedia data for tokenizer evaluation in 45 languages. We provide more information on the evaluation task in general this blogpost.\n\n\t\n\t\t\n\t\tUsage\n\t\n\nThe dataset allows us to easily calculate tokenizer fertility and the proportion of continued words on any of the supported languages. In the example below we take the Mistral tokenizer and evaluate its performance on Slovak. \nfrom transformers import AutoTokenizer‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/occiglot/tokenizer-wiki-bench.","url":"https://huggingface.co/datasets/occiglot/tokenizer-wiki-bench","creator_name":"Occiglot","creator_url":"https://huggingface.co/occiglot","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["Afrikaans","Arabic","Bulgarian","Catalan","Czech"],"keywords_longer_than_N":true},
	{"name":"ro-stories","keyword":"romanian","description":"The corpus consists of texts written by Romanian authors between 19th century and present, representing stories, short-stories, fairy tales and sketches.\nThe current version contains 19 authors, 1263 full texts and 12516 paragraphs of around 200 words each, preserving paragraphs integrity.\nNote: This is an extended version of ROST corpus (https://www.kaggle.com/datasets/sandamariaavram/rost-romanian-stories-and-other-texts), which only contains 400 texts and 10 authors.\n\n\t\n\t\t\n\t\n\t\n\t\tDataset‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/readerbench/ro-stories.","url":"https://huggingface.co/datasets/readerbench/ro-stories","creator_name":"ReaderBench","creator_url":"https://huggingface.co/readerbench","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["Romanian","apache-2.0","10K - 100K","csv","Text"],"keywords_longer_than_N":true},
	{"name":"ro-stories","keyword":"romanian","description":"The corpus consists of texts written by Romanian authors between 19th century and present, representing stories, short-stories, fairy tales and sketches.\nThe current version contains 19 authors, 1263 full texts and 12516 paragraphs of around 200 words each, preserving paragraphs integrity.\nNote: This is an extended version of ROST corpus (https://www.kaggle.com/datasets/sandamariaavram/rost-romanian-stories-and-other-texts), which only contains 400 texts and 10 authors.\n\n\t\n\t\t\n\t\n\t\n\t\tDataset‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/readerbench/ro-stories.","url":"https://huggingface.co/datasets/readerbench/ro-stories","creator_name":"ReaderBench","creator_url":"https://huggingface.co/readerbench","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["Romanian","apache-2.0","10K - 100K","csv","Text"],"keywords_longer_than_N":true},
	{"name":"voxpopolo_2","keyword":"romanian","description":"A large-scale multilingual speech corpus for representation learning, semi-supervised learning and interpretation.","url":"https://huggingface.co/datasets/mcapozi/voxpopolo_2","creator_name":"Matteo Capozi","creator_url":"https://huggingface.co/mcapozi","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":null,"first_N":5,"first_N_keywords":["automatic-speech-recognition","multilingual","English","German","French"],"keywords_longer_than_N":true},
	{"name":"Synthdog-Multilingual-100","keyword":"romanian","description":"\n\t\n\t\t\n\t\tSynthdog Multilingual\n\t\n\n\n\nThe Synthdog dataset created for training in Centurio: On Drivers of Multilingual Ability of Large Vision-Language Model.\nUsing the official Synthdog code, we created >1 million training samples for improving OCR capabilities in Large Vision-Language Models.\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Details\n\t\n\nWe provide the images for download in two .tar.gz files. Download and extract them in folders of the same name (so cat images.tar.gz.* | tar xvzf -C images; tar xvzf‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/WueNLP/Synthdog-Multilingual-100.","url":"https://huggingface.co/datasets/WueNLP/Synthdog-Multilingual-100","creator_name":"W√ºNLP","creator_url":"https://huggingface.co/WueNLP","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["image-to-text","multilingual","Afrikaans","Amharic","Arabic"],"keywords_longer_than_N":true},
	{"name":"RomanianReviewsSentiment","keyword":"romanian","description":"\n  RomanianReviewsSentiment\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nLaRoSeDa (A Large Romanian Sentiment Data Set) contains 15,000 reviews written in Romanian\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2c\n\n\nDomains\nReviews, Written\n\n\nReferencehttps://arxiv.org/abs/2101.04197\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask = mteb.get_task(\"RomanianReviewsSentiment\")\nevaluator = mteb.MTEB([task])\n\nmodel‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/RomanianReviewsSentiment.","url":"https://huggingface.co/datasets/mteb/RomanianReviewsSentiment","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","sentiment-analysis","sentiment-scoring","sentiment-classification","hate-speech-detection"],"keywords_longer_than_N":true},
	{"name":"MultiQ","keyword":"romanian","description":"\n\t\n\t\t\n\t\tDataset Card for MultiQ\n\t\n\nThis is the dataset corresponding to the paper \"Evaluating the Elementary Multilingual Capabilities of Large Language Models with MultiQ\". \nIt is a silver standard benchmark that can be used to evaluate the basic multilingual capabilities of LLMs. It contains 200 open ended questions automatically \ntranslated into 137 typologically diverse languages. \n\nCurated by: Carolin Holtermann, Paul R√∂ttger, Timm Dill, Anne Lauscher\nLanguage(s) (NLP): 137 diverse‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/caro-holt/MultiQ.","url":"https://huggingface.co/datasets/caro-holt/MultiQ","creator_name":"Holtermann","creator_url":"https://huggingface.co/caro-holt","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["question-answering","Tagalog","Samoan","Macedonian","Gujarati"],"keywords_longer_than_N":true},
	{"name":"JQL-Human-Edu-Annotations","keyword":"romanian","description":"\n\t\n\t\t\n\t\tüìö JQL Multilingual Educational Quality Annotations\n\t\n\nThis dataset provides high-quality human annotations for evaluating the educational value of web documents, and serves as a benchmark for training and evaluating multilingual LLM annotators as described in the JQL paper.\n\n\n\t\n\t\t\n\t\tüìù Dataset Summary\n\t\n\n\nDocuments: 511 English texts  \nAnnotations: 3 human ratings per document (0‚Äì5 scale)  \nTranslations: Into 35 European languages using DeepL and GPT-4o  \nPurpose: For training and‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/JQL-AI/JQL-Human-Edu-Annotations.","url":"https://huggingface.co/datasets/JQL-AI/JQL-Human-Edu-Annotations","creator_name":"JQL-AI","creator_url":"https://huggingface.co/JQL-AI","license_name":"Open Data Commons Attribution License v1.0","license_url":"https://scancode-licensedb.aboutcode.org/odc-by-1.0.html","language":"en","first_N":5,"first_N_keywords":["text-classification","Bulgarian","Czech","Croatian","Macedonian"],"keywords_longer_than_N":true},
	{"name":"language-dataset","keyword":"romanian","description":"\n","url":"https://huggingface.co/datasets/neon-mao/language-dataset","creator_name":"maoqifan","creator_url":"https://huggingface.co/neon-mao","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","English","Chinese","French","Russian"],"keywords_longer_than_N":true},
	{"name":"Romanian","keyword":"romanian","description":"Gargaz/Romanian dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/Gargaz/Romanian","creator_name":"LUCA ","creator_url":"https://huggingface.co/Gargaz","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["Romanian","English","apache-2.0","1K - 10K","json"],"keywords_longer_than_N":true},
	{"name":"multilingual_translation_sft","keyword":"romanian","description":"Youseff1987/multilingual_translation_sft dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/Youseff1987/multilingual_translation_sft","creator_name":"JOON HYOUNG JUN","creator_url":"https://huggingface.co/Youseff1987","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["translation","Korean","English","Chinese","Zulu"],"keywords_longer_than_N":true},
	{"name":"wikipedia_quality_wikirank","keyword":"romanian","description":"Datasets with WikiRank quality score as of 1 August 2024 for 47 million Wikipedia articles in 55 language versions (also simplified version for each language in separate files).\nThe WikiRank quality score is a metric designed to assess the overall quality of a Wikipedia article. Although its specific algorithm can vary depending on the implementation, the score typically combines several key features of the Wikipedia article.\n\n\t\n\t\t\n\t\n\t\n\t\tWhy It‚Äôs Important\n\t\n\n\nEnhances Trust: For readers and‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/lewoniewski/wikipedia_quality_wikirank.","url":"https://huggingface.co/datasets/lewoniewski/wikipedia_quality_wikirank","creator_name":"W≈Çodzimierz Lewoniewski","creator_url":"https://huggingface.co/lewoniewski","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["Arabic","Azerbaijani","Belarusian","Bulgarian","Catalan"],"keywords_longer_than_N":true},
	{"name":"fineweb-2","keyword":"romanian","description":"\n\t\n\t\t\n\t\tü•Ç FineWeb2\n\t\n\n\n    \n\n\n\nA sparkling update with 1000s of languages\n\n\n\t\n\t\t\n\t\tWhat is it?\n\t\n\nThis is the second iteration of the popular üç∑ FineWeb dataset, bringing high quality pretraining data to over 1000 üó£Ô∏è languages.\nThe ü•Ç FineWeb2 dataset is fully reproducible, available under the permissive ODC-By 1.0 license and extensively validated through hundreds of ablation experiments.\nIn particular, on the set of 9 diverse languages we used to guide our processing decisions, ü•Ç FineWeb2‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/HuggingFaceFW/fineweb-2.","url":"https://huggingface.co/datasets/HuggingFaceFW/fineweb-2","creator_name":"FineData","creator_url":"https://huggingface.co/HuggingFaceFW","license_name":"Open Data Commons Attribution License v1.0","license_url":"https://scancode-licensedb.aboutcode.org/odc-by-1.0.html","language":"en","first_N":5,"first_N_keywords":["text-generation","Arifama-Miniafia","Ankave","Abau","Amarasi"],"keywords_longer_than_N":true},
	{"name":"panlex-definitions","keyword":"romanian","description":"\n\t\n\t\t\n\t\tDataset Card for panlex-definitions\n\t\n\nThis is a dataset of word definitions in several hudnred languages, extracted from https://panlex.org.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset has been extracted from https://panlex.org (the 20250201 database dump) and rearranged on the per-language basis (by the language of the definition).\nEach language subset consists of definitions (short phrases).\nEach definition is associated with some meanings (if there is‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/cointegrated/panlex-definitions.","url":"https://huggingface.co/datasets/cointegrated/panlex-definitions","creator_name":"David Dale","creator_url":"https://huggingface.co/cointegrated","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["translation","Abkhazian","Hijazi Arabic","Afrikaans","Ainu (Japan)"],"keywords_longer_than_N":true},
	{"name":"common_voice_21_0","keyword":"romanian","description":"Due to storage limits some files had to be split into multiple parts. They can be merged like this: cat file.* > file.\n","url":"https://huggingface.co/datasets/2Jyq/common_voice_21_0","creator_name":"2Jyq","creator_url":"https://huggingface.co/2Jyq","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["crowdsourced","crowdsourced","multilingual","extended|common_voice","Abkhaz"],"keywords_longer_than_N":true},
	{"name":"ro-offense","keyword":"romanian","description":"\n\t\n\t\t\n\t\tDataset Card for \"RO-Offense-Sequences\"\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\n\n\nHomepage: https://github.com/readerbench/ro-offense-sequences\nRepository: https://github.com/readerbench/ro-offense-sequences\nPoint of Contact: Andrei Paraschiv\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\na novel Romanian language dataset for offensive language detection with manually \nannotated offensive labels from a local Romanian sports news website (gsp.ro):\nResulting in 12,445 annotated messages\n\n\t\n\t\n\t\n\t\tLanguages‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/upb-nlp/ro-offense.","url":"https://huggingface.co/datasets/upb-nlp/ro-offense","creator_name":"POLITEHNICA Bucharest NLP Group","creator_url":"https://huggingface.co/upb-nlp","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","hate-speech-detection","expert-generated","found","monolingual"],"keywords_longer_than_N":true},
	{"name":"ro-offense","keyword":"romanian","description":"\n\t\n\t\t\n\t\tDataset Card for \"RO-Offense-Sequences\"\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\n\n\nHomepage: https://github.com/readerbench/ro-offense-sequences\nRepository: https://github.com/readerbench/ro-offense-sequences\nPoint of Contact: Andrei Paraschiv\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\na novel Romanian language dataset for offensive language detection with manually \nannotated offensive labels from a local Romanian sports news website (gsp.ro):\nResulting in 12,445 annotated messages\n\n\t\n\t\n\t\n\t\tLanguages‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/upb-nlp/ro-offense.","url":"https://huggingface.co/datasets/upb-nlp/ro-offense","creator_name":"POLITEHNICA Bucharest NLP Group","creator_url":"https://huggingface.co/upb-nlp","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","hate-speech-detection","expert-generated","found","monolingual"],"keywords_longer_than_N":true},
	{"name":"GlobalDISCO","keyword":"romanian","description":"\n\t\n\t\t\n\t\tGlobalDISCO\n\t\n\nGlobalDISCO is a large-scale dataset consisting of 73k music tracks generated by state-of-the-art commercial generative music models, along with paired links to 93k reference tracks in LAION-DISCO-12M. The dataset spans 147 languages and includes musical style prompts extracted from MusicBrainz and Wikipedia. The dataset is globally balanced, representing musical styles from artists across 79 countries and five continents. It is aimed to support the research community in‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/disco-eth/GlobalDISCO.","url":"https://huggingface.co/datasets/disco-eth/GlobalDISCO","creator_name":"DISCO","creator_url":"https://huggingface.co/disco-eth","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["audio-classification","English","Spanish","French","German"],"keywords_longer_than_N":true},
	{"name":"open_government","keyword":"romanian","description":"\n\t\n\t\t\n\t\tOpen Government Dataset\n\t\n\nOpen Government is the largest agregation of governement text and data made available as part of open data programs. \nIn total, the dataset contains approximately 380B tokens. While Open Government aims to become a global resource, in its current state it mostly features open datasets from the US, France, European and international organizations.\nThe dataset comprises 16 collections curated through two different initiaties: Finance commons and Legal commons.‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/AgentPublic/open_government.","url":"https://huggingface.co/datasets/AgentPublic/open_government","creator_name":"AgentPublic","creator_url":"https://huggingface.co/AgentPublic","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","English","French","Bulgarian","Croatian"],"keywords_longer_than_N":true},
	{"name":"wildchat-filtered","keyword":"romanian","description":"\n\t\n\t\t\n\t\tWildChat Filtered Dataset\n\t\n\nThis is a filtered version of the WildChat-4.8M dataset.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset contains 3,199,860 conversations between human users and ChatGPT, filtered to keep only the essential conversation structure.\n\n\t\n\t\t\n\t\tData Structure\n\t\n\nEach conversation contains only:\n\nconversations: A list of message objects with:\nrole: Either \"user\" or \"assistant\"\ncontent: The text content of the message\n\n\n\nAll other metadata (timestamps, moderation‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/rayonlabs/wildchat-filtered.","url":"https://huggingface.co/datasets/rayonlabs/wildchat-filtered","creator_name":"Rayon Labs","creator_url":"https://huggingface.co/rayonlabs","license_name":"Open Data Commons Attribution License v1.0","license_url":"https://scancode-licensedb.aboutcode.org/odc-by-1.0.html","language":"en","first_N":5,"first_N_keywords":["text-generation","question-answering","English","Spanish","French"],"keywords_longer_than_N":true},
	{"name":"tatoeba-bitext-mining","keyword":"romanian","description":"\n  Tatoeba\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\n1,000 English-aligned sentence pairs for each language based on the Tatoeba corpus\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2t\n\n\nDomains\nWritten\n\n\nReference\nhttps://github.com/facebookresearch/LASER/tree/main/data/tatoeba/v1\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask = mteb.get_tasks([\"Tatoeba\"])\nevaluator = mteb.MTEB(task)\n\nmodel =‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/tatoeba-bitext-mining.","url":"https://huggingface.co/datasets/mteb/tatoeba-bitext-mining","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"Creative Commons Attribution 2.0","license_url":"https://scancode-licensedb.aboutcode.org/cc-by-2.0.html","language":"en","first_N":5,"first_N_keywords":["translation","human-annotated","multilingual","Afrikaans","Amharic"],"keywords_longer_than_N":true},
	{"name":"ro-offense-news","keyword":"romanian","description":"\n\t\n\t\t\n\t\tDataset Card for \"RO-News-Offense\"\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\na novel Romanian language dataset for offensive message detection with manually \nannotated comment from a local Romanian news website (stiri de cluj) into five classes:\n\nnon-offensive\ntargeted insults\nracist\nhomophobic\nsexist\n\nResulting in 4052 annotated messages\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nRomanian\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\n\t\n\t\t\n\t\tData Instances\n\t\n\nAn example of 'train' looks as follows.\n{\n  'comment_id': 5‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/upb-nlp/ro-offense-news.","url":"https://huggingface.co/datasets/upb-nlp/ro-offense-news","creator_name":"POLITEHNICA Bucharest NLP Group","creator_url":"https://huggingface.co/upb-nlp","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","hate-speech-detection","expert-generated","found","monolingual"],"keywords_longer_than_N":true},
	{"name":"Intermediate-Thinking-130k","keyword":"romanian","description":"\n\t\n\t\t\n\t\tIntermediate-Thinking-130k\n\t\n\nA comprehensive dataset of 135,000 high-quality samples designed to advance language model reasoning capabilities through structured intermediate thinking processes. This dataset enables training and evaluation of models with sophisticated self-correction and iterative reasoning abilities across 42 languages.\nOG Link\n\n\t\n\t\t\n\t\n\t\n\t\tOverview\n\t\n\nIntermediate-Thinking-130k addresses a fundamental limitation in current language models: their inability to pause‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mlx-community/Intermediate-Thinking-130k.","url":"https://huggingface.co/datasets/mlx-community/Intermediate-Thinking-130k","creator_name":"MLX Community","creator_url":"https://huggingface.co/mlx-community","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","Afrikaans","Arabic","Bengali","Bulgarian"],"keywords_longer_than_N":true},
	{"name":"high-quality-multilingual-sentences","keyword":"romanian","description":"\n\t\n\t\t\n\t\tHigh Quality Multilingual Sentences\n\t\n\n\nThis dataset contains multilingual sentences derived from the agentlans/LinguaNova dataset.\nIt includes 1.58 million rows across 51 different languages, each in its own configuration.\n\nExample row (from the all config):\n{\n    \"text\": \"ÿßŸÖÿßŸÖ ÿ¨ŸÖÿπŸá ÿßÿµŸÅŸáÿßŸÜ ⁄ØŸÅÿ™: ŸÖ€åÿ≤ÿßŸÜ ŸÜ€åÿßÿ≤ ÿ¢ÿ® ÿ¥ÿ±ÿ® ÿßÿµŸÅŸáÿßŸÜ €±€±.€µ ŸÖÿ™ÿ± ŸÖ⁄©ÿπÿ® ÿßÿ≥ÿ™ ⁄©Ÿá ÿ™ŸÖÿßŸÖ ÿßÿ≥ÿ™ÿßŸÜ ÿßÿµŸÅŸáÿßŸÜ ÿ±ÿß ŸæŸàÿ¥ÿ¥ ŸÖ€åÿØŸáÿØ Ÿà ŸÜÿ≥ÿ®ÿ™ ÿ®Ÿá ŸÇÿ®ŸÑ ÿßÿ≤ ÿßŸÜŸÇŸÑÿßÿ® €å⁄©€å ÿßÿ≤ Ÿæ€åÿ¥ÿ±ŸÅÿ™Ÿáÿß ÿØÿ± ÿ≠Ÿàÿ≤Ÿá ÿ¢ÿ® ÿ®ŸàÿØŸá ÿßÿ≥ÿ™.\",\n    \"fasttext\": \"fa\",\n    \"gcld3\": \"fa\"\n}\n\nFields:‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/agentlans/high-quality-multilingual-sentences.","url":"https://huggingface.co/datasets/agentlans/high-quality-multilingual-sentences","creator_name":"Alan Tseng","creator_url":"https://huggingface.co/agentlans","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","text-classification","text-retrieval","multilingual","Arabic"],"keywords_longer_than_N":true},
	{"name":"test_4","keyword":"romanian","description":"\n\t\n\t\t\n\t\n\t\n\t\tFLEURS\n\t\n\nFleurs is the speech version of the FLoRes machine translation benchmark. \nWe use 2009 n-way parallel sentences from the FLoRes dev and devtest publicly available sets, in 102 languages. \nTraining sets have around 10 hours of supervision. Speakers of the train sets are different than speakers from the dev/test sets. Multilingual fine-tuning is\nused and ‚Äùunit error rate‚Äù (characters, signs) of all languages is averaged. Languages and results are also grouped into seven‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/tunngo/test_4.","url":"https://huggingface.co/datasets/tunngo/test_4","creator_name":"nguyen tuan","creator_url":"https://huggingface.co/tunngo","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","expert-generated","crowdsourced","machine-generated","crowdsourced"],"keywords_longer_than_N":true},
	{"name":"GlobalNLI","keyword":"romanian","description":"\n\t\n\t\t\n\t\tDataset Card for global_nli\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nGlobal NLI is a new text-based benchmark based on the aggregation of existing NLI datasets that are publicly available.\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nThere are 59 languages available :\n{\n    'amh': 'Amharic',\n    'ara': 'Arabic',\n    'asm': 'Assamese',\n    'aym': 'Aymara',\n    'ben': 'Bengali',\n    'bul': 'Bulgarian',\n    'bzd': 'Bribri',\n    'cat': 'Catalan',\n    'cni': 'Ash√°ninka',\n    'deu': 'German',\n    'ell': 'Greek',\n    'eng':‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/McGill-NLP/GlobalNLI.","url":"https://huggingface.co/datasets/McGill-NLP/GlobalNLI","creator_name":"McGill NLP Group","creator_url":"https://huggingface.co/McGill-NLP","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","natural-language-inference","multilingual","XNLI, AfriXNLI, IndicXNLI, AmericasNLI [30], XNLI-ca, myXNLI, IndoNLI, JNLI , InferBR, sick_pl, JamPatoisNLI, KLUE, RoNLI.","Amharic"],"keywords_longer_than_N":true},
	{"name":"ro-offense-sequences","keyword":"romanian","description":"\n\t\n\t\t\n\t\tDataset Card for \"RO-Offense-Sequences\"\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\n\n\nHomepage: https://github.com/readerbench/ro-offense-sequences\nRepository: https://github.com/readerbench/ro-offense-sequences\nPoint of Contact: Teodora-Andreea Ion\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\na novel Romanian language dataset for offensive sequence detection with manually \nannotated offensive sequences from a local Romanian sports news website (gsp.ro):\nResulting in 4800 annotated messages‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/upb-nlp/ro-offense-sequences.","url":"https://huggingface.co/datasets/upb-nlp/ro-offense-sequences","creator_name":"POLITEHNICA Bucharest NLP Group","creator_url":"https://huggingface.co/upb-nlp","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["token-classification","hate-speech-detection","expert-generated","found","monolingual"],"keywords_longer_than_N":true},
	{"name":"m-WildVision","keyword":"romanian","description":"\n\t\n\t\t\n\t\tDataset Card for m-WildVision\n\t\n\n\n\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\nThe m-WildVision dataset is a multilingual multimodal LLM evaluation set covering 23 languages.  It was created by translating prompts from the original English-only WildVision (vision_bench_0617) test set. \nThe original prompts, developed by Lu et al. (2024) , consist of 500 challenging user queries sourced from the WildVision-Arena platform. \nThe authors demonstrated that these prompts enable automatic LLM judge‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/CohereLabs/m-WildVision.","url":"https://huggingface.co/datasets/CohereLabs/m-WildVision","creator_name":"Cohere Labs","creator_url":"https://huggingface.co/CohereLabs","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["English","French","German","Spanish","Italian"],"keywords_longer_than_N":true},
	{"name":"open-dict-words-ipa","keyword":"romanian","description":"\n\t\n\t\t\n\t\tOpen-dict Words IPA\n\t\n\nThis dataset is a copy of https://github.com/open-dict-data/ipa-dict\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nIPA data is currently available for the following languages:\n\n\t\n\t\t\nLanguage\nCode\n\n\n\t\t\nar\nArabic (Modern Standard)\n\n\nde\nGerman\n\n\nen_UK\nEnglish (Received Pronunciation)\n\n\nen_US\nEnglish (General American)\n\n\neo\nEsperanto\n\n\nes_ES\nSpanish (Spain)\n\n\nes_MX\nSpanish (Mexico)\n\n\nfa\nPersian\n\n\nfi\nFinnish\n\n\nfr_FR\nFrench (France)\n\n\nfr_QC\nFrench (Qu√©bec)\n\n\nis\nIcelandic\n\n\nja\nJapanese\n\n\njam‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/StephanAkkerman/open-dict-words-ipa.","url":"https://huggingface.co/datasets/StephanAkkerman/open-dict-words-ipa","creator_name":"Stephan Akkerman","creator_url":"https://huggingface.co/StephanAkkerman","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["Arabic","German","English","Esperanto","Spanish"],"keywords_longer_than_N":true},
	{"name":"GlobalNLI","keyword":"romanian","description":"\n\t\n\t\t\n\t\tDataset Card for global_nli\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nGlobal NLI is a new text-based benchmark based on the aggregation of existing NLI datasets that are publicly available.\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nThere are 59 languages available :\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\n\t\n\t\t\n\t\tData Instances\n\t\n\nThe examples look like this for English:\nfrom datasets import load_dataset\ndata = load_dataset('vivekvermaiit/globalnli', 'eng') \n# Please, specify the language code\n# A data point example is below:\n{‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/vivekvermaiit/GlobalNLI.","url":"https://huggingface.co/datasets/vivekvermaiit/GlobalNLI","creator_name":"Vivek Verma","creator_url":"https://huggingface.co/vivekvermaiit","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","natural-language-inference","multilingual","XNLI, AfriXNLI, IndicXNLI, AmericasNLI [30], XNLI-ca, myXNLI, IndoNLI, JNLI , InferBR, sick_pl, JamPatoisNLI, KLUE, RoNLI.","Amharic"],"keywords_longer_than_N":true},
	{"name":"PangeaBench-xm100","keyword":"romanian","description":"\n\t\n\t\t\n\t\n\t\n\t\tXM100\n\t\n\n\n\t\n\t\t\n\t\n\t\n\t\tThis is a copy from https://google.github.io/crossmodal-3600/\n\t\n\nIf you use this dataset, please cite the original authors:\n@inproceedings{ThapliyalCrossmodal2022,\n  author = {Ashish Thapliyal and Jordi Pont-Tuset and Xi Chen and Radu Soricut},\n  title = {{Crossmodal-3600: A Massively Multilingual Multimodal Evaluation Dataset}},\n  booktitle = {EMNLP},\n  year = {2022}\n}\n\n","url":"https://huggingface.co/datasets/neulab/PangeaBench-xm100","creator_name":"NeuLab @ LTI/CMU","creator_url":"https://huggingface.co/neulab","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["image-to-text","Arabic","Bengali","Czech","Danish"],"keywords_longer_than_N":true},
	{"name":"Global-MMLU","keyword":"romanian","description":"\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nGlobal-MMLU üåç is a multilingual evaluation set spanning 42 languages, including English. This dataset combines machine translations for MMLU questions along with professional translations and crowd-sourced post-edits.\nIt also includes cultural sensitivity annotations for a subset of the questions (2850 questions per language) and classifies them as Culturally Sensitive (CS) üóΩ or Culturally Agnostic (CA) ‚öñÔ∏è. These annotations were collected as part of an open‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/CohereLabs/Global-MMLU.","url":"https://huggingface.co/datasets/CohereLabs/Global-MMLU","creator_name":"Cohere Labs","creator_url":"https://huggingface.co/CohereLabs","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["English","Arabic","Bengali","Spanish","French"],"keywords_longer_than_N":true},
	{"name":"histnero","keyword":"romanian","description":"\n\t\n\t\t\n\t\tHistNERo\n\t\n\nThis repository contains the Historical Romanian Named Entity Recognition (HistNERo) dataset. The dataset has 10,026 sentences (i.e. 8,020 train, 1,003 valid and 1,003 train) annotated with five named entities: PERSON, ORGANIZATION, LOCATION, PRODUCT and DATE.\nYou can read more about the dataset in the following paper: HistNERo: Historical Named Entity Recognition for the Romanian Language\n\n\t\n\t\t\n\t\n\t\n\t\tLoading\n\t\n\nTo load the dataset, simply run:\nfrom datasets import‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/avramandrei/histnero.","url":"https://huggingface.co/datasets/avramandrei/histnero","creator_name":"Andrei-Marius Avram","creator_url":"https://huggingface.co/avramandrei","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["token-classification","Romanian","mit","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"histnero","keyword":"romanian","description":"\n\t\n\t\t\n\t\tHistNERo\n\t\n\nThis repository contains the Historical Romanian Named Entity Recognition (HistNERo) dataset. The dataset has 10,026 sentences (i.e. 8,020 train, 1,003 valid and 1,003 train) annotated with five named entities: PERSON, ORGANIZATION, LOCATION, PRODUCT and DATE.\nYou can read more about the dataset in the following paper: HistNERo: Historical Named Entity Recognition for the Romanian Language\n\n\t\n\t\t\n\t\n\t\n\t\tLoading\n\t\n\nTo load the dataset, simply run:\nfrom datasets import‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/avramandrei/histnero.","url":"https://huggingface.co/datasets/avramandrei/histnero","creator_name":"Andrei-Marius Avram","creator_url":"https://huggingface.co/avramandrei","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["token-classification","Romanian","mit","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"lexclipr","keyword":"romanian","description":"\n\t\n\t\t\n\t\tDataset Division\n\t\n\n\nUnique_query : contains unique queries that are not present in train, val, test split. Used for testing unseen understandability of models.\nTrain_all : contains the unsplit train, test, val datapoints.\ntrain : train split\nval : val split\ntest : test split\n\nOriginal Paper : LexCLiPR: Cross-Lingual Paragraph Retrieval from Legal Judgments\nBibtext:\n@inproceedings{upadhya-t-y-s-s-2025-lexclipr,\n    title = \"{L}ex{CL}i{PR}: Cross-Lingual Paragraph Retrieval from Legal‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/rohit-upadhya/lexclipr.","url":"https://huggingface.co/datasets/rohit-upadhya/lexclipr","creator_name":"Rohit Upadhya","creator_url":"https://huggingface.co/rohit-upadhya","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["table-question-answering","English","French","Italian","Romanian"],"keywords_longer_than_N":true}
]
;
