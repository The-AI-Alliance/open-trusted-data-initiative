const data_for_language_europe_latin = 
[
	{"name":"panlex","keyword":"latin","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/lbourdois/panlex","creator_name":"LoÃ¯ck BOURDOIS","creator_url":"https://huggingface.co/lbourdois","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tPanLex\\n\\t\\n\\nJanuary 1, 2024 version of PanLex Language Vocabulary with 24,650,274 rows covering 6,152 languages.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tColumns\\n\\t\\n\\n\\nvocab: contains the text entry.  \\n639-3: contains the ISO 639-3 languages tags to allow users to filter on the language(s) of their choice.\\n639-3_english_name: the English language name associated to the code ISO 639-3. \\nvar_code: contains a code to differentiate language variants. In practice, this is the code 639-3 + a number.  If 000, itâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/lbourdois/panlex."},
	{"name":"Basis-Latin-French","keyword":"latin","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/LaMOP/Basis-Latin-French","creator_name":"LaMOP","creator_url":"https://huggingface.co/LaMOP","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Basis-Latin-French\\n\\t\\n\\n\\n\\nThe Basis-Latin-French dataset is an unannotated Latin and old French corpus, compiled from different resources from the web. This resources include the Corpus de la Bourgogne du Moyen Ã‚ge, The e-NDP project, HIMANIS GuÃ©rin and the HOME-Alcar project and the Corpus Cisterciens et Ressources.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLicence\\n\\t\\n\\n[https://creativecommons.org/licenses/by-sa/4.0/deed.en](Creative Commons Attribution-ShareAlike 4.0 International)â€¦ See the full description on the dataset page: https://huggingface.co/datasets/LaMOP/Basis-Latin-French."},
	{"name":"Basis-Latin-French","keyword":"latin","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/LaMOP/Basis-Latin-French","creator_name":"LaMOP","creator_url":"https://huggingface.co/LaMOP","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Basis-Latin-French\\n\\t\\n\\n\\n\\nThe Basis-Latin-French dataset is an unannotated Latin and old French corpus, compiled from different resources from the web. This resources include the Corpus de la Bourgogne du Moyen Ã‚ge, The e-NDP project, HIMANIS GuÃ©rin and the HOME-Alcar project and the Corpus Cisterciens et Ressources.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLicence\\n\\t\\n\\n[https://creativecommons.org/licenses/by-sa/4.0/deed.en](Creative Commons Attribution-ShareAlike 4.0 International)â€¦ See the full description on the dataset page: https://huggingface.co/datasets/LaMOP/Basis-Latin-French."},
	{"name":"LatinYoutube","keyword":"latin","license":"Academic Free License v3.0","license_url":"https://choosealicense.com/licenses/afl-3.0/","language":"en","dataset_url":"https://huggingface.co/datasets/thiagolira/LatinYoutube","creator_name":"Thiago Ildeu Albuquerque Lira","creator_url":"https://huggingface.co/thiagolira","description":"This is a dataset with text/audio pairs of Classical Latin extracted from youtube videos from the channels Scorpio Martianus, LATINITIUS and Musa Pedestris\\n"},
	{"name":"evalatin2024","keyword":"latin","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/adorkin/evalatin2024","creator_name":"Aleksei Dorkin","creator_url":"https://huggingface.co/adorkin","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tTartuNLP at EvaLatin 2024: Emotion Polarity Detection\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tBibTeX entry and citation info\\n\\t\\n\\n@inproceedings{dorkin-sirts-2024-tartunlp-evalatin,\\n    title = \\\"{T}artu{NLP} at {E}va{L}atin 2024: Emotion Polarity Detection\\\",\\n    author = \\\"Dorkin, Aleksei  and\\n      Sirts, Kairit\\\",\\n    editor = \\\"Sprugnoli, Rachele  and\\n      Passarotti, Marco\\\",\\n    booktitle = \\\"Proceedings of the Third Workshop on Language Technologies for Historical and Ancient Languages (LT4HALA) @â€¦ See the full description on the dataset page: https://huggingface.co/datasets/adorkin/evalatin2024."},
	{"name":"MultiQ","keyword":"latin","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/caro-holt/MultiQ","creator_name":"Holtermann","creator_url":"https://huggingface.co/caro-holt","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for MultiQ\\n\\t\\n\\nThis is the dataset corresponding to the paper \\\"Evaluating the Elementary Multilingual Capabilities of Large Language Models with MultiQ\\\". \\nIt is a silver standard benchmark that can be used to evaluate the basic multilingual capabilities of LLMs. It contains 200 open ended questions automatically \\ntranslated into 137 typologically diverse languages. \\n\\nCurated by: Carolin Holtermann, Paul RÃ¶ttger, Timm Dill, Anne Lauscher\\nLanguage(s) (NLP): 137 diverseâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/caro-holt/MultiQ."},
	{"name":"panlex-meanings","keyword":"latin","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/cointegrated/panlex-meanings","creator_name":"David Dale","creator_url":"https://huggingface.co/cointegrated","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for panlex-meanings\\n\\t\\n\\nThis is a dataset of words in several thousand languages, extracted from https://panlex.org.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Details\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThis dataset has been extracted from https://panlex.org (the 20240301 database dump) and rearranged on the per-language basis.\\nEach language subset consists of expressions (words and phrases). \\nEach expression is associated with some meanings (if there is more than one meaning, they are inâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/cointegrated/panlex-meanings."},
	{"name":"biblenlp-corpus-mmteb","keyword":"latin","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/davidstap/biblenlp-corpus-mmteb","creator_name":"David Stap","creator_url":"https://huggingface.co/davidstap","description":"This dataset pre-computes all English-centric directions from bible-nlp/biblenlp-corpus, and as a result loading is significantly faster.\\nLoading example:\\n>>> from datasets import load_dataset\\n>>> dataset = load_dataset(\\\"davidstap/biblenlp-corpus-mmteb\\\", \\\"eng-arb\\\", trust_remote_code=True)\\n>>> dataset\\nDatasetDict({\\n    train: Dataset({\\n        features: ['eng', 'arb'],\\n        num_rows: 28723\\n    })\\n    validation: Dataset({\\n        features: ['eng', 'arb'],\\n        num_rows: 1578\\n    })â€¦ See the full description on the dataset page: https://huggingface.co/datasets/davidstap/biblenlp-corpus-mmteb."},
	{"name":"biblenlp-corpus-mmteb","keyword":"latin","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/davidstap/biblenlp-corpus-mmteb","creator_name":"David Stap","creator_url":"https://huggingface.co/davidstap","description":"This dataset pre-computes all English-centric directions from bible-nlp/biblenlp-corpus, and as a result loading is significantly faster.\\nLoading example:\\n>>> from datasets import load_dataset\\n>>> dataset = load_dataset(\\\"davidstap/biblenlp-corpus-mmteb\\\", \\\"eng-arb\\\", trust_remote_code=True)\\n>>> dataset\\nDatasetDict({\\n    train: Dataset({\\n        features: ['eng', 'arb'],\\n        num_rows: 28723\\n    })\\n    validation: Dataset({\\n        features: ['eng', 'arb'],\\n        num_rows: 1578\\n    })â€¦ See the full description on the dataset page: https://huggingface.co/datasets/davidstap/biblenlp-corpus-mmteb."},
	{"name":"biblenlp-corpus-mmteb","keyword":"latin","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/biblenlp-corpus-mmteb","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"This dataset pre-computes all English-centric directions from bible-nlp/biblenlp-corpus, and as a result loading is significantly faster.\\nLoading example:\\n>>> from datasets import load_dataset\\n>>> dataset = load_dataset(\\\"davidstap/biblenlp-corpus-mmteb\\\", \\\"eng-arb\\\", trust_remote_code=True)\\n>>> dataset\\nDatasetDict({\\n    train: Dataset({\\n        features: ['eng', 'arb'],\\n        num_rows: 28723\\n    })\\n    validation: Dataset({\\n        features: ['eng', 'arb'],\\n        num_rows: 1578\\n    })â€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/biblenlp-corpus-mmteb."},
	{"name":"biblenlp-corpus-mmteb","keyword":"latin","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/biblenlp-corpus-mmteb","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"This dataset pre-computes all English-centric directions from bible-nlp/biblenlp-corpus, and as a result loading is significantly faster.\\nLoading example:\\n>>> from datasets import load_dataset\\n>>> dataset = load_dataset(\\\"davidstap/biblenlp-corpus-mmteb\\\", \\\"eng-arb\\\", trust_remote_code=True)\\n>>> dataset\\nDatasetDict({\\n    train: Dataset({\\n        features: ['eng', 'arb'],\\n        num_rows: 28723\\n    })\\n    validation: Dataset({\\n        features: ['eng', 'arb'],\\n        num_rows: 1578\\n    })â€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/biblenlp-corpus-mmteb."},
	{"name":"ParaNames","keyword":"latin","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/bltlab/ParaNames","creator_name":"Broadening Linguistic Technologies Lab (BLT Lab)","creator_url":"https://huggingface.co/bltlab","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Dataset Name\\n\\t\\n\\n\\n\\nThis dataset card aims to be a base template for new datasets. It has been generated using this raw template.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Details\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\n\\n\\n\\n\\n\\nCurated by: [More Information Needed]\\nFunded by [optional]: [More Information Needed]\\nShared by [optional]: [More Information Needed]\\nLanguage(s) (NLP): [More Information Needed]\\nLicense: [More Information Needed]\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Sources [optional]â€¦ See the full description on the dataset page: https://huggingface.co/datasets/bltlab/ParaNames."},
	{"name":"xP3x-Kongo","keyword":"latin","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Svngoku/xP3x-Kongo","creator_name":"NIONGOLO Chrys FÃ©-Marty","creator_url":"https://huggingface.co/Svngoku","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for xP3x Kikongo Focus\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\n\\nxP3x (Crosslingual Public Pool of Prompts eXtended) is a collection of prompts & datasets across 277 languages & 16 NLP tasks. It contains all of xP3 + much more! It is used for training future contenders of mT0 & BLOOMZ at project Aya @C4AI ðŸ§¡\\n\\n\\nCreation: The dataset can be recreated using instructions available here together with the file in this repository named xp3x_create.py. We provide this version to saveâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Svngoku/xP3x-Kongo."},
	{"name":"modern","keyword":"latin","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/CATMuS/modern","creator_name":"CATMuS: Consistent Approach to Transcribing ManuScripts","creator_url":"https://huggingface.co/CATMuS","description":"\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for CATMuS Modern and Contemporary (McCATMuS)\\n\\t\\n\\nJoin our Discord to ask questions about the dataset: \\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Details\\n\\t\\n\\nHandwritten Text Recognition (HTR) has emerged as a crucial tool for converting manuscripts images into machine-readable formats, enabling researchers and scholars to analyze vast collections efficiently. Despite significant technological progress, establishing consistent ground truth across projects for HTR tasks, particularly forâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/CATMuS/modern."},
	{"name":"librivox-tracks","keyword":"latin","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/xacer/librivox-tracks","creator_name":"xacer","creator_url":"https://huggingface.co/xacer","description":"A dataset of all audio files uploaded to LibriVox before 26th September 2023.\\nForked from https://huggingface.co/datasets/pykeio/librivox-tracks\\nChanges:\\n\\nUsed archive.org metadata API to annotate rows with \\\"duration\\\" column\\n\\n"},
	{"name":"medieval-letters","keyword":"latin","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/medieval-data/medieval-letters","creator_name":"Medieval Data","creator_url":"https://huggingface.co/medieval-data","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tMedieval Letters Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tOverview\\n\\t\\n\\nThis dataset contains a collection of letters from prominent Carolingian scholars and ecclesiastical figures. The letters are sourced from the Patrologia Latina and were downloaded as XML from Corpus Corporum.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Source\\n\\t\\n\\nThe letters in this dataset are derived from the Patrologia Latina, a comprehensive collection of texts from the Church Fathers and other ecclesiastical writers. The XML versions of these textsâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/medieval-data/medieval-letters."},
	{"name":"ARK-Metadata","keyword":"latin","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/SBB/ARK-Metadata","creator_name":"Staatsbibliothek zu Berlin - PreuÃŸischer Kulturbesitz","creator_url":"https://huggingface.co/SBB","description":"\\n\\t\\n\\t\\t\\n\\t\\tMetadata of the \\\"Alter Realkatalog\\\" (ARK) of Berlin State Library (SBB)\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tMotivation\\n\\t\\n\\nThis dataset was created with the intent to provide a single larger set of metadata from Berlin State Library for research purposes and the development of AI applications.\\nThe dataset comprises of descriptive metadata of 2.619.397 titles, which together form the \\\"Alte Realkatalog\\\" of Berlin State Libray, which may be translated to \\\"Old Subject Catalogue\\\". The data are stored in columnarâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/SBB/ARK-Metadata."},
	{"name":"muri-it-language-split","keyword":"latin","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/akoksal/muri-it-language-split","creator_name":"Abdullatif Koksal","creator_url":"https://huggingface.co/akoksal","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tMURI-IT: Multilingual Instruction Tuning Dataset for 200 Languages via Multilingual Reverse Instructions\\n\\t\\n\\nMURI-IT is a large-scale multilingual instruction tuning dataset containing 2.2 million instruction-output pairs across 200 languages. It is designed to address the challenges of instruction tuning in low-resource languages with Multilingual Reverse Instructions (MURI), which ensures that the output is human-written, high-quality, and authentic to the cultural and linguisticâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/akoksal/muri-it-language-split."},
	{"name":"ApolloMoEDataset","keyword":"latin","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/FreedomIntelligence/ApolloMoEDataset","creator_name":"FreedomAI","creator_url":"https://huggingface.co/FreedomIntelligence","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDemocratizing Medical LLMs For Much More Languages\\n\\t\\n\\nCovering 12 Major Languages including English, Chinese, French, Hindi, Spanish, Arabic, Russian, Japanese, Korean, German, Italian, Portuguese and 38 Minor Languages So far.\\n\\n   ðŸ“ƒ Paper â€¢ ðŸŒ Demo â€¢ ðŸ¤— ApolloMoEDataset â€¢ ðŸ¤— ApolloMoEBench  â€¢ ðŸ¤— Models  â€¢ðŸŒ Apollo  â€¢ ðŸŒ ApolloMoE\\n\\n\\n\\n\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tðŸŒˆ Update\\n\\t\\n\\n\\n[2024.10.15] ApolloMoE repo is publishedï¼ðŸŽ‰\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages Coverage\\n\\t\\n\\n12 Major Languages and 38 Minor Languagesâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/FreedomIntelligence/ApolloMoEDataset."},
	{"name":"ApolloMoEBench","keyword":"latin","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/FreedomIntelligence/ApolloMoEBench","creator_name":"FreedomAI","creator_url":"https://huggingface.co/FreedomIntelligence","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDemocratizing Medical LLMs For Much More Languages\\n\\t\\n\\nCovering 12 Major Languages including English, Chinese, French, Hindi, Spanish, Arabic, Russian, Japanese, Korean, German, Italian, Portuguese and 38 Minor Languages So far.\\n\\n   ðŸ“ƒ Paper â€¢ ðŸŒ Demo â€¢ ðŸ¤— ApolloMoEDataset â€¢ ðŸ¤— ApolloMoEBench  â€¢ ðŸ¤— Models  â€¢ðŸŒ Apollo  â€¢ ðŸŒ ApolloMoE\\n\\n\\n\\n\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tðŸŒˆ Update\\n\\t\\n\\n\\n[2024.10.15] ApolloMoE repo is publishedï¼ðŸŽ‰\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages Coverage\\n\\t\\n\\n12 Major Languages and 38 Minor Languagesâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/FreedomIntelligence/ApolloMoEBench."},
	{"name":"vietnamese-nom-latin-translation","keyword":"latin","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/lunovian/vietnamese-nom-latin-translation","creator_name":"Nguyen Xuan An","creator_url":"https://huggingface.co/lunovian","description":"lunovian/vietnamese-nom-latin-translation dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"wiktionary-data","keyword":"latin","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/QubitPi/wiktionary-data","creator_name":"Jiaqi","creator_url":"https://huggingface.co/QubitPi","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tWiktionary Data on Hugging Face Datasets\\n\\t\\n\\n\\n\\n\\n\\n\\nwiktionary-data is a sub-data extraction of the English Wiktionary that currently\\nsupports the following languages:\\n\\nDeutsch - German\\nLatinum - Latin\\ná¼™Î»Î»Î·Î½Î¹ÎºÎ® - Ancient Greek\\ní•œêµ­ì–´ - Korean\\nðŽ ðŽ¼ðŽ¹ - Old Persian\\nð’€ð’…—ð’ºð’Œ‘(ð’Œ) - Akkadian\\nElamite\\nà¤¸à¤‚à¤¸à¥à¤•à¥ƒà¤¤à¤®à¥ - Sanskrit, or Classical Sanskrit\\n\\nwiktionary-data was originally a sub-module of wilhelm-graphdb. While\\nthe dataset it's getting bigger, I noticed a wave of more exciting potentialsâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/QubitPi/wiktionary-data."},
	{"name":"wiktionary-data","keyword":"latin","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/QubitPi/wiktionary-data","creator_name":"Jiaqi","creator_url":"https://huggingface.co/QubitPi","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tWiktionary Data on Hugging Face Datasets\\n\\t\\n\\n\\n\\n\\n\\n\\nwiktionary-data is a sub-data extraction of the English Wiktionary that currently\\nsupports the following languages:\\n\\nDeutsch - German\\nLatinum - Latin\\ná¼™Î»Î»Î·Î½Î¹ÎºÎ® - Ancient Greek\\ní•œêµ­ì–´ - Korean\\nðŽ ðŽ¼ðŽ¹ - Old Persian\\nð’€ð’…—ð’ºð’Œ‘(ð’Œ) - Akkadian\\nElamite\\nà¤¸à¤‚à¤¸à¥à¤•à¥ƒà¤¤à¤®à¥ - Sanskrit, or Classical Sanskrit\\n\\nwiktionary-data was originally a sub-module of wilhelm-graphdb. While\\nthe dataset it's getting bigger, I noticed a wave of more exciting potentialsâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/QubitPi/wiktionary-data."},
	{"name":"Tridis","keyword":"latin","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/magistermilitum/Tridis","creator_name":"Sergio Torres","creator_url":"https://huggingface.co/magistermilitum","description":"This is the first dataset version of the corpora used in TRIDIS (Tria Digita Scribunt) which is a series of Handwriting Text Recognition models trained on semi-diplomatic transcriptions \\nfrom medieval and Early Modern Manuscripts.\\nThe dataset involves 4k pages of manuscripts and is suitable for work on documentary manuscripts, that is, manuscripts arising  from legal, administrative, and memorial practices such as registers, feudal books, charters, proceedings, comptability more commonly fromâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/magistermilitum/Tridis."},
	{"name":"test_modern_dataset","keyword":"latin","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/SerhiiLebediuk/test_modern_dataset","creator_name":"Serhii Lebediuk","creator_url":"https://huggingface.co/SerhiiLebediuk","description":"SerhiiLebediuk/test_modern_dataset dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"georges-1913-normalization","keyword":"latin","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mschonhardt/georges-1913-normalization","creator_name":"Michael Schonhardt","creator_url":"https://huggingface.co/mschonhardt","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tNormalized Georges 1913\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDescription\\n\\t\\n\\nThis dataset was created as part of the Burchard's Dekret Digital project (www.burchards-dekret-digital.de), \\nfunded by the Academy of Sciences and Literature | Mainz.\\nIt is based on 55,000 lemmata from Karl Georges, AusfÃ¼hrliches lateinisch-deutsches HandwÃ¶rterbuch, Hannover 1913 (Georges 1913) \\nand was developed to train models for normalization tasks in the context of medieval Latin.\\nThe dataset consists of approximately 5â€¦ See the full description on the dataset page: https://huggingface.co/datasets/mschonhardt/georges-1913-normalization."},
	{"name":"WillyShakes","keyword":"latin","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/scenecoachai/WillyShakes","creator_name":"Janis Deedy","creator_url":"https://huggingface.co/scenecoachai","description":"cd your-dataset-name\\ncp /path/to/your/data/* .\\ngit add .\\ngit commit -m \\\"Add my dataset\\\"\\ngit push\\n"},
	{"name":"product-database","keyword":"latin","license":"GNU Affero General Public License v3.0","license_url":"https://choosealicense.com/licenses/agpl-3.0/","language":"en","dataset_url":"https://huggingface.co/datasets/openfoodfacts/product-database","creator_name":"Open Food Facts","creator_url":"https://huggingface.co/openfoodfacts","description":"\\n\\t\\n\\t\\t\\n\\t\\tOpen Food Facts Database\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tWhat is ðŸŠ Open Food Facts?\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tA food products database\\n\\t\\n\\nOpen Food Facts is a database of food products with ingredients, allergens, nutrition facts and all the tidbits of information we can find on product labels.\\n\\n\\t\\n\\t\\t\\n\\t\\tMade by everyone\\n\\t\\n\\nOpen Food Facts is a non-profit association of volunteers. 25.000+ contributors like you have added 1.7 million + products from 150 countries using our Android or iPhone app or their camera to scanâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/openfoodfacts/product-database."},
	{"name":"vitruvius_alberti_fludd_corpus","keyword":"latin","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/forcemultiplier/vitruvius_alberti_fludd_corpus","creator_name":"The Force Multiplier","creator_url":"https://huggingface.co/forcemultiplier","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVitruvius Alberti Fludd Architecture Corpus\\n\\t\\n\\nA comprehensive collection of historical architectural texts focusing on works by Vitruvius, Leon Battista Alberti, and Robert Fludd.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Statistics\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tOverview\\n\\t\\n\\n\\nTotal Documents: 16 PDFs\\nTotal Pages: 5,233\\nEmpty Pages: 1,156\\nPages with Errors: 0\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDocument Length Statistics\\n\\t\\n\\n\\nAverage Pages per Document: 327.1\\nMinimum Pages: 10\\nMaximum Pages: 623\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tContent Statistics (words perâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/forcemultiplier/vitruvius_alberti_fludd_corpus."},
	{"name":"CC-100-Latin","keyword":"latin","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Cicciokr/CC-100-Latin","creator_name":"Francesco","creator_url":"https://huggingface.co/Cicciokr","description":"Cicciokr/CC-100-Latin dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"latin_author_dll_id","keyword":"latin","license":"GNU Affero General Public License v3.0","license_url":"https://choosealicense.com/licenses/agpl-3.0/","language":"en","dataset_url":"https://huggingface.co/datasets/sjhuskey/latin_author_dll_id","creator_name":"Samuel J. Huskey","creator_url":"https://huggingface.co/sjhuskey","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLatin Author Name to Digital Latin Library ID Concordance\\n\\t\\n\\nThis dataset contains variant names of authors of works in Latin and their corresponding identifier in the Digital Latin Library's Catalog.\\nThe variant names were gathered from the Virtual International Authority File records for the authors. In instances where an author's name has few or no known variant name forms, pseudo-variant names were generated by \\\"misspelling\\\" the name using the following script:\\nfrom textblobâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/sjhuskey/latin_author_dll_id."},
	{"name":"LatinSummarizerDataset","keyword":"latin","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/LatinNLP/LatinSummarizerDataset","creator_name":"LatinNLP","creator_url":"https://huggingface.co/LatinNLP","description":"\\n\\t\\n\\t\\t\\n\\t\\tLatinSummarizer Dataset\\n\\t\\n\\n    \\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tOverview\\n\\t\\n\\nThe LatinSummarizerDataset is a structured dataset used in the GitHub Repository for Latin summarization and translation tasks. This dataset provides aligned English-Latin texts, extractive summaries, and pre-training prompts for fine-tuning models like mT5 for low-resource NLP applications.\\n\\n\\t\\n\\t\\t\\n\\t\\tStructure\\n\\t\\n\\nThe dataset is divided into two main phases: \\n\\nPre-training Data: Includes aligned bilingual corpora, syntheticâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/LatinNLP/LatinSummarizerDataset."},
	{"name":"LatinSummarizerDataset","keyword":"latin","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/LatinNLP/LatinSummarizerDataset","creator_name":"LatinNLP","creator_url":"https://huggingface.co/LatinNLP","description":"\\n\\t\\n\\t\\t\\n\\t\\tLatinSummarizer Dataset\\n\\t\\n\\n    \\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tOverview\\n\\t\\n\\nThe LatinSummarizerDataset is a structured dataset used in the GitHub Repository for Latin summarization and translation tasks. This dataset provides aligned English-Latin texts, extractive summaries, and pre-training prompts for fine-tuning models like mT5 for low-resource NLP applications.\\n\\n\\t\\n\\t\\t\\n\\t\\tStructure\\n\\t\\n\\nThe dataset is divided into two main phases: \\n\\nPre-training Data: Includes aligned bilingual corpora, syntheticâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/LatinNLP/LatinSummarizerDataset."},
	{"name":"wiktionary-data","keyword":"latin","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/paion-data/wiktionary-data","creator_name":"Paion Data","creator_url":"https://huggingface.co/paion-data","description":"\\n\\t\\n\\t\\t\\n\\t\\tWiktionary Data on Hugging Face Datasets\\n\\t\\n\\n\\n\\n\\n\\nwiktionary-data is a sub-data extraction of the English Wiktionary that currently\\nsupports the following languages:\\n\\nDeutsch - German\\nLatinum - Latin\\ná¼™Î»Î»Î·Î½Î¹ÎºÎ® - Ancient Greek\\ní•œêµ­ì–´ - Korean\\nðŽ ðŽ¼ðŽ¹- Old Persian\\nð’€ð’…—ð’ºð’Œ‘(ð’Œ) - Akkadian\\nElamite\\nà¤¸à¤‚à¤¸à¥à¤•à¥ƒà¤¤à¤®à¥ - Sanskrit, or Classical Sanskrit\\n\\nwiktionary-data was originally a sub-module of wilhelm-graphdb. While\\nthe dataset it's getting bigger, I noticed a wave of more exciting potentials thisâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/paion-data/wiktionary-data."},
	{"name":"wiktionary-data","keyword":"latin","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/paion-data/wiktionary-data","creator_name":"Paion Data","creator_url":"https://huggingface.co/paion-data","description":"\\n\\t\\n\\t\\t\\n\\t\\tWiktionary Data on Hugging Face Datasets\\n\\t\\n\\n\\n\\n\\n\\nwiktionary-data is a sub-data extraction of the English Wiktionary that currently\\nsupports the following languages:\\n\\nDeutsch - German\\nLatinum - Latin\\ná¼™Î»Î»Î·Î½Î¹ÎºÎ® - Ancient Greek\\ní•œêµ­ì–´ - Korean\\nðŽ ðŽ¼ðŽ¹- Old Persian\\nð’€ð’…—ð’ºð’Œ‘(ð’Œ) - Akkadian\\nElamite\\nà¤¸à¤‚à¤¸à¥à¤•à¥ƒà¤¤à¤®à¥ - Sanskrit, or Classical Sanskrit\\n\\nwiktionary-data was originally a sub-module of wilhelm-graphdb. While\\nthe dataset it's getting bigger, I noticed a wave of more exciting potentials thisâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/paion-data/wiktionary-data."},
	{"name":"latin-greek-hebrew-english-dataset","keyword":"latin","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Dddixyy/latin-greek-hebrew-english-dataset","creator_name":"Davide brunori","creator_url":"https://huggingface.co/Dddixyy","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tProverbs: Ancient Languages Set\\n\\t\\n\\nThis repository contains a collection of 2,000 short phrases translated into three ancient languages: Ancient Latin, Ancient Greek, Biblical Hebrew, and English. The phrases cover a wide variety of contexts, providing insight into the linguistic, cultural, and philosophical landscapes of these ancient civilizations.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tOverview\\n\\t\\n\\nThe \\\"Proverbs: Ancient Languages Set\\\" is a resource designed to help individuals explore and understandâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Dddixyy/latin-greek-hebrew-english-dataset."},
	{"name":"wilhelm-vocabulary","keyword":"latin","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/QubitPi/wilhelm-vocabulary","creator_name":"Jiaqi","creator_url":"https://huggingface.co/QubitPi","description":"\\n\\t\\n\\t\\t\\n\\t\\tWilhelm Vocabulary\\n\\t\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nWilhelm Vocabulary\\nDevelopment\\nEnvironment Setup\\nInstalling Dependencies\\nData Format\\nEncoding Table in YAML\\n\\n\\nData Pipeline\\nHow Data (Vocabulary) is Stored in a Graph Database\\nWhy Graph Database\\nBase Schema\\n\\n\\n\\n\\nLanguages\\nGerman\\nPronoun\\nNoun\\nVerb\\n\\n\\nAncient Greek\\nDiacritic Mark Convention\\nPronoun\\nNoun\\nAdjective\\n1. Three-Ending Adjectives: 1st and 2nd Declension (2-1-2)2. Two-Ending 2nd Declension Adjectives (2-2)\\n3. Two-Ending 3rd Declension Adjectivesâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/QubitPi/wilhelm-vocabulary."},
	{"name":"wilhelm-vocabulary","keyword":"latin","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/QubitPi/wilhelm-vocabulary","creator_name":"Jiaqi","creator_url":"https://huggingface.co/QubitPi","description":"\\n\\t\\n\\t\\t\\n\\t\\tWilhelm Vocabulary\\n\\t\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nWilhelm Vocabulary\\nDevelopment\\nEnvironment Setup\\nInstalling Dependencies\\nData Format\\nEncoding Table in YAML\\n\\n\\nData Pipeline\\nHow Data (Vocabulary) is Stored in a Graph Database\\nWhy Graph Database\\nBase Schema\\n\\n\\n\\n\\nLanguages\\nGerman\\nPronoun\\nNoun\\nVerb\\n\\n\\nAncient Greek\\nDiacritic Mark Convention\\nPronoun\\nNoun\\nAdjective\\n1. Three-Ending Adjectives: 1st and 2nd Declension (2-1-2)2. Two-Ending 2nd Declension Adjectives (2-2)\\n3. Two-Ending 3rd Declension Adjectivesâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/QubitPi/wilhelm-vocabulary."},
	{"name":"Everything_Instruct_Multilingual","keyword":"latin","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/rombodawg/Everything_Instruct_Multilingual","creator_name":"rombo dawg","creator_url":"https://huggingface.co/rombodawg","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tEverything Instruct (Multilingual Edition)\\n\\t\\n\\nEverything you need... all in one place ðŸ’˜\\n\\nEverything instruct (Multilingual Edition) is a massive alpaca instruct formatted dataset consisting of a wide variety of topics meant to bring LLM's to the next level in open source AI.\\nNote: This dataset is fully uncensored (No model will refuse any request trained on this dataset unless otherwise aligned)\\nNote2: This version of the dataset supports the following languages:\\n\\nEnglish\\nRussianâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/rombodawg/Everything_Instruct_Multilingual."},
	{"name":"latin_english_translation","keyword":"latin","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/grosenthal/latin_english_translation","creator_name":"Gil Rosenthal","creator_url":"https://huggingface.co/grosenthal","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for \\\"latin_english_parallel\\\"\\n\\t\\n\\n101k translation pairs between Latin and English, split 99/1/1 as train/test/val. These have been collected roughly 66% from the Loeb Classical Library and 34% from the Vulgate translation. \\nFor those that were gathered from the Loeb Classical Library, alignment was performd manually between Source and Target sequences.\\nEach sample is annotated with the index and file (and therefore author/work) that the sample is from. If you findâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/grosenthal/latin_english_translation."},
	{"name":"librivox-tracks","keyword":"latin","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/pykeio/librivox-tracks","creator_name":"pyke.io","creator_url":"https://huggingface.co/pykeio","description":"A dataset of all audio files uploaded to LibriVox before 26th September 2023.\\n"},
	{"name":"multilingual-pl-bert","keyword":"latin","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/styletts2-community/multilingual-pl-bert","creator_name":"StyleTTS 2 Community","creator_url":"https://huggingface.co/styletts2-community","description":"Attribution: Wikipedia.org\\n"},
	{"name":"CulturaY","keyword":"latin","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ontocord/CulturaY","creator_name":"Ontocord.AI","creator_url":"https://huggingface.co/ontocord","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tCulturaY: A Large Cleaned Multilingual Dataset of 75 Languages\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nFrom the team that brought you CulturaX, we present CulturaY, another substantial multilingual dataset of 15TB (uncompressed)/3TB (zstd-compressed) that applies the same dataset cleaning methodology to the HPLT v1.1 dataset. \\nPlease note that HPLT v1.2 has also been released and is an alternative verison with different cleaning methodolgies. \\nThis data was used in part to train our SOTAâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/ontocord/CulturaY."},
	{"name":"GlotCC-V1","keyword":"latin","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/cis-lmu/GlotCC-V1","creator_name":"CIS, LMU Munich","creator_url":"https://huggingface.co/cis-lmu","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\n \\n\\nGlotCC-V1.0 is a document-level, general domain dataset derived from CommonCrawl, covering more than 1000 languages.It is built using the GlotLID language identification and Ungoliant pipeline from CommonCrawl.We release our pipeline as open-source at https://github.com/cisnlp/GlotCC.  \\nList of Languages: See https://datasets-server.huggingface.co/splits?dataset=cis-lmu/GlotCC-V1 to get the list of splits available.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tUsage (Huggingface Hub --â€¦ See the full description on the dataset page: https://huggingface.co/datasets/cis-lmu/GlotCC-V1."},
	{"name":"GlotCC-V1","keyword":"latin","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/cis-lmu/GlotCC-V1","creator_name":"CIS, LMU Munich","creator_url":"https://huggingface.co/cis-lmu","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\n \\n\\nGlotCC-V1.0 is a document-level, general domain dataset derived from CommonCrawl, covering more than 1000 languages.It is built using the GlotLID language identification and Ungoliant pipeline from CommonCrawl.We release our pipeline as open-source at https://github.com/cisnlp/GlotCC.  \\nList of Languages: See https://datasets-server.huggingface.co/splits?dataset=cis-lmu/GlotCC-V1 to get the list of splits available.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tUsage (Huggingface Hub --â€¦ See the full description on the dataset page: https://huggingface.co/datasets/cis-lmu/GlotCC-V1."},
	{"name":"muri-it","keyword":"latin","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/akoksal/muri-it","creator_name":"Abdullatif Koksal","creator_url":"https://huggingface.co/akoksal","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tMURI-IT: Multilingual Instruction Tuning Dataset for 200 Languages via Multilingual Reverse Instructions\\n\\t\\n\\nMURI-IT is a large-scale multilingual instruction tuning dataset containing 2.2 million instruction-output pairs across 200 languages. It is designed to address the challenges of instruction tuning in low-resource languages with Multilingual Reverse Instructions (MURI), which ensures that the output is human-written, high-quality, and authentic to the cultural and linguisticâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/akoksal/muri-it."},
	{"name":"ToxicCommons","keyword":"latin","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/PleIAs/ToxicCommons","creator_name":"PleIAs","creator_url":"https://huggingface.co/PleIAs","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tToxic Commons\\n\\t\\n\\nToxic Commons is a release of 2 million samples of annotated, public domain, multilingual text that was used to train Celadon. \\nIt is being released alongside Celadon, in order to better understand multilingual and multicultural toxicity. \\nEach sample was classified across 5 axes of toxicity:\\n\\nRace and origin-based bias: includes racism as well as bias against someoneâ€™s country or region of origin or immigration status, especially immigrant or refugee status.â€¦ See the full description on the dataset page: https://huggingface.co/datasets/PleIAs/ToxicCommons."},
	{"name":"translation_latin_to_italian","keyword":"latin","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Dddixyy/translation_latin_to_italian","creator_name":"Davide brunori","creator_url":"https://huggingface.co/Dddixyy","description":"Dddixyy/translation_latin_to_italian dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"latin_italian_parallel","keyword":"latin","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Dddixyy/latin_italian_parallel","creator_name":"Davide brunori","creator_url":"https://huggingface.co/Dddixyy","description":"Dddixyy/latin_italian_parallel dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"latin_italian_parallel","keyword":"latin","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Dddixyy/latin_italian_parallel","creator_name":"Davide brunori","creator_url":"https://huggingface.co/Dddixyy","description":"Dddixyy/latin_italian_parallel dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"latino_italiano_traduzioni_DIRETTE","keyword":"latin","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Dddixyy/latino_italiano_traduzioni_DIRETTE","creator_name":"Davide brunori","creator_url":"https://huggingface.co/Dddixyy","description":"Dddixyy/latino_italiano_traduzioni_DIRETTE dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"Diplomatarium-Fennicum","keyword":"latin","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Kansallisarkisto/Diplomatarium-Fennicum","creator_name":"National Archives of Finland","creator_url":"https://huggingface.co/Kansallisarkisto","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDiplomatarium Fennicum-dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset summary\\n\\t\\n\\nDataset consisting of eight data fields taken from the Diplomatarium Fennicum -database. \\nDiplomatarium Fennicum -database contains medieval charters and text excerpts conserning Finland and Finns, \\nand is published and maintained by the National Archives of Finland.\\nThe data fields selected are central to identifying, categorizing and analyzing the texts. \\nThe dataset represents only very minimally the wholeâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Kansallisarkisto/Diplomatarium-Fennicum."},
	{"name":"reranker_continuous_filt_max7_train","keyword":"latin","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/lightblue/reranker_continuous_filt_max7_train","creator_name":"Lightblue KK.","creator_url":"https://huggingface.co/lightblue","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tReranker training data\\n\\t\\n\\nThis data was generated using 4 steps:\\n\\nWe gathered queries and corresponding text data from 35 high quality datasets covering more than 95 languages.\\nFor datasets which did not already have negative texts for queries, we mined hard negatives using the BAAI/bge-m3 embedding model.\\nFor each query, we selected one positive and one negative text and used Qwen/Qwen2.5-32B-Instruct-GPTQ-Int4 to rate the relatedness of each query-text pair using a token \\\"1\\\", \\\"2\\\"â€¦ See the full description on the dataset page: https://huggingface.co/datasets/lightblue/reranker_continuous_filt_max7_train."},
	{"name":"reranking-datasets-light","keyword":"latin","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/abdoelsayed/reranking-datasets-light","creator_name":"unkown","creator_url":"https://huggingface.co/abdoelsayed","description":"\\n\\t\\n\\t\\t\\n\\t\\tðŸ”¥ Rankify: A Comprehensive Python Toolkit for Retrieval, Re-Ranking, and Retrieval-Augmented Generation ðŸ”¥\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tReRanking Datasets : A comprehensive collection of retrieval and reranking datasets with full passage contexts, including titles, text, and metadata for in-depth research.\\n\\t\\n\\n\\n    \\n    \\n    \\n    \\n    \\n    \\n        \\n    \\n    \\n        \\n    \\n    \\n        \\n    \\n    \\n        \\n    \\n    \\n    \\n\\n\\n\\nA curated collection of ready-to-use datasets for retrieval and rerankingâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/abdoelsayed/reranking-datasets-light."},
	{"name":"Synthdog-Multilingual-100","keyword":"latin","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/WueNLP/Synthdog-Multilingual-100","creator_name":"WÃ¼NLP","creator_url":"https://huggingface.co/WueNLP","description":"\\n\\t\\n\\t\\t\\n\\t\\tSynthdog Multilingual\\n\\t\\n\\n\\n\\nThe Synthdog dataset created for training in Centurio: On Drivers of Multilingual Ability of Large Vision-Language Model.\\nUsing the official Synthdog code, we created >1 million training samples for improving OCR capabilities in Large Vision-Language Models.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Details\\n\\t\\n\\nWe provide the images for download in two .tar.gz files. Download and extract them in folders of the same name (so cat images.tar.gz.* | tar xvzf -C images; tar xvzfâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/WueNLP/Synthdog-Multilingual-100."},
	{"name":"wikipedia_quality_wikirank","keyword":"latin","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/lewoniewski/wikipedia_quality_wikirank","creator_name":"WÅ‚odzimierz Lewoniewski","creator_url":"https://huggingface.co/lewoniewski","description":"Datasets with WikiRank quality score as of 1 August 2024 for 47 million Wikipedia articles in 55 language versions (also simplified version for each language in separate files).\\nThe WikiRank quality score is a metric designed to assess the overall quality of a Wikipedia article. Although its specific algorithm can vary depending on the implementation, the score typically combines several key features of the Wikipedia article.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tWhy Itâ€™s Important\\n\\t\\n\\n\\nEnhances Trust: For readers andâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/lewoniewski/wikipedia_quality_wikirank."},
	{"name":"multilingual_translation_sft","keyword":"latin","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Youseff1987/multilingual_translation_sft","creator_name":"JOON HYOUNG JUN","creator_url":"https://huggingface.co/Youseff1987","description":"Youseff1987/multilingual_translation_sft dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"opus_ubuntu","keyword":"latin","license":"BSD 3-Clause \"New\" or \"Revised\" License","license_url":"https://choosealicense.com/licenses/bsd-3-clause/","language":"en","dataset_url":"https://huggingface.co/datasets/Helsinki-NLP/opus_ubuntu","creator_name":"Language Technology Research Group at the University of Helsinki","creator_url":"https://huggingface.co/Helsinki-NLP","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Opus Ubuntu\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThese are translations of the Ubuntu software package messages, donated by the Ubuntu community.\\nTo load a language pair which isn't part of the config, all you need to do is specify the language code as pairs.\\nYou can find the valid pairs in Homepage section of Dataset Description: http://opus.nlpl.eu/Ubuntu.php\\nE.g.\\ndataset = load_dataset(\\\"opus_ubuntu\\\", lang1=\\\"it\\\", lang2=\\\"pl\\\")\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSupported Tasks andâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Helsinki-NLP/opus_ubuntu."},
	{"name":"wit_base","keyword":"latin","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/wikimedia/wit_base","creator_name":"Wikimedia","creator_url":"https://huggingface.co/wikimedia","description":"\\n\\t\\n\\t\\t\\n\\t\\tDataset Card for WIT\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nWikimedia's version of the Wikipedia-based Image Text (WIT) Dataset, a large multimodal multilingual dataset.\\nFrom the official blog post:\\n\\nThe core training data is taken from the Wikipedia Image-Text (WIT) Dataset, a large curated set of more than 37 million image-text associations extracted from Wikipedia articles in 108 languages that was recently released by Google Research.\\nThe WIT dataset offers extremely valuable data about theâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/wikimedia/wit_base."},
	{"name":"bnl_newspapers1841-1879","keyword":"latin","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/biglam/bnl_newspapers1841-1879","creator_name":"BigLAM: BigScience Libraries, Archives and Museums","creator_url":"https://huggingface.co/biglam","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for BnL Newspapers 1841-1881\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\n592.192 articles from historical newspapers (1841-1881) along with metadata and the full text.\\n21 newspaper titles\\n24.415 newspaper issues\\n99.957 scanned pages\\nTranscribed using a variety of OCR engines and corrected using https://github.com/natliblux/nautilusocr (95% threshold)\\nPublic Domain, CC0 (See copyright notice)\\nThe newspapers used are:\\n\\nDer Arbeiter (1878-1881)\\nL'Arlequin (1848-1848)\\nL'Avenirâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/biglam/bnl_newspapers1841-1879."},
	{"name":"latin_english_parallel","keyword":"latin","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/grosenthal/latin_english_parallel","creator_name":"Gil Rosenthal","creator_url":"https://huggingface.co/grosenthal","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for \\\"latin_english_parallel\\\"\\n\\t\\n\\n101k translation pairs between Latin and English, split 99/1/1 as train/test/val. These have been collected roughly 66% from the Loeb Classical Library and 34% from the Vulgate translation. \\nFor those that were gathered from the Loeb Classical Library, alignment was performd manually between Source and Target sequences. Additionally, the English translations were both 1. copyrighted and 2. outdated. As such, we decided to modernize andâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/grosenthal/latin_english_parallel."},
	{"name":"xP3x-sample","keyword":"latin","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Muennighoff/xP3x-sample","creator_name":"Niklas Muennighoff","creator_url":"https://huggingface.co/Muennighoff","description":"A multilingual collection of Winograd Schemas in six languages that can be used for evaluation of cross-lingual commonsense reasoning capabilities."},
	{"name":"wikianc","keyword":"latin","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/cyanic-selkie/wikianc","creator_name":"cyanic-selkie","creator_url":"https://huggingface.co/cyanic-selkie","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for WikiAnc\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThe WikiAnc dataset is an automatically generated dataset from Wikipedia (all languages) and Wikidata dumps (August, 2023). \\nThe code for generating the dataset can be found here.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSupported Tasks\\n\\t\\n\\n\\nwikificiation: The dataset can be used to train a model for Wikification.\\nnamed-entity-linking: The dataset can be used to train a model for Named Entity Linking.\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages\\n\\t\\n\\nThe text in the dataset isâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/cyanic-selkie/wikianc."},
	{"name":"entity_cs","keyword":"latin","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/huawei-noah/entity_cs","creator_name":"HUAWEI Noah's Ark Lab","creator_url":"https://huggingface.co/huawei-noah","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for EntityCS\\n\\t\\n\\n\\nRepository: https://github.com/huawei-noah/noah-research/tree/master/NLP/EntityCS  \\nPaper: https://aclanthology.org/2022.findings-emnlp.499.pdf  \\nPoint of Contact: Fenia Christopoulou, Chenxi Whitehouse\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nWe use the English Wikipedia and leverage entity information from Wikidata to construct an entity-based Code Switching corpus. \\nTo achieve this, we make use of wikilinks in Wikipedia, i.e. links from one page toâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/huawei-noah/entity_cs."},
	{"name":"udhr-lid","keyword":"latin","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/cis-lmu/udhr-lid","creator_name":"CIS, LMU Munich","creator_url":"https://huggingface.co/cis-lmu","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tUDHR-LID\\n\\t\\n\\nWhy UDHR-LID?\\nYou can access UDHR (Universal Declaration of Human Rights) here, but when a verse is missing, they have texts such as \\\"missing\\\" or \\\"?\\\". Also, about 1/3 of the sentences consist only of \\\"articles 1-30\\\" in different languages. We cleaned the entire dataset from XML files and selected only the paragraphs. We cleared any unrelated language texts from the data and also removed the cases that were incorrect.\\nIncorrect? Look at the ckb and kmr files in the UDHR.â€¦ See the full description on the dataset page: https://huggingface.co/datasets/cis-lmu/udhr-lid."},
	{"name":"MonadGPT","keyword":"latin","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Pclanglais/MonadGPT","creator_name":"Pierre-Carl Langlais","creator_url":"https://huggingface.co/Pclanglais","description":"This finetuning dataset has been used to train MonadGPT, a chatGPT-like model for the early modern period. \\nIt contains 10,797 excerpts of texts in English, French and Latin, mostly published in the 17th century, as well as synthetic questions generated by Mistral-Hermes.\\nThe instructions use the chatML format with a unique system prompt (to help with consistency), user questions and assistant answers.\\nAll the excerpts are in the public domain and so are the synthetic instructions (inâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Pclanglais/MonadGPT."},
	{"name":"language_tags","keyword":"latin","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/lbourdois/language_tags","creator_name":"LoÃ¯ck BOURDOIS","creator_url":"https://huggingface.co/lbourdois","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDescription\\n\\t\\n\\nDataset listing 27,328 languages and dialects (also includes macrolanguage names).For each language, either the ISO 639 code, the Glottolog code or both are provided.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tColumns\\n\\t\\n\\n\\nEnglish_Name: Language name in English (e.g. \\\"French\\\").\\nNative_Name: If value is not 0, corresponds to the name of the language by native speakers (e.g. \\\"FranÃ§ais\\\") which may have been found in Wikipedia's nativename field.\\nGlottocode: The language tag in the Glottolog conventionâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/lbourdois/language_tags."},
	{"name":"Himanis-line","keyword":"latin","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Teklia/Himanis-line","creator_name":"Teklia","creator_url":"https://huggingface.co/Teklia","description":"\\n\\t\\n\\t\\t\\n\\t\\tHimanis - line level\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nHimanis (HIstorical MANuscript Indexing for user controlled Search) is a corpus of medieval documents.\\nThe historical corpus is described in the following publication:\\nStutzmann, D., Moufflet, J-F., & Hamel, S. (2017). La recherche en plein texte dans les sources manuscrites mÃ©diÃ©valesâ€¯: enjeux et perspectives du projet HIMANIS pour lâ€™Ã©dition Ã©lectronique. MÃ©diÃ©valesâ€¯: Langue, textes, histoire 73 (2017): 67â€‘96.â€¦ See the full description on the dataset page: https://huggingface.co/datasets/Teklia/Himanis-line."},
	{"name":"HOME-Alcar-line","keyword":"latin","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Teklia/HOME-Alcar-line","creator_name":"Teklia","creator_url":"https://huggingface.co/Teklia","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tHOME-Alcar - line level\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThe HOME-Alcar (Aligned and Annotated Cartularies) dataset is a Medieval corpus. The 17 medieval manuscripts in this corpus are cartularies, i.e. books copying charters and legal acts, produced between the 12th and 14th centuries. \\nThis dataset comes from the following publication:\\nStutzmann, D., Torres Aguilar, S., & Chaffenet, P. (2021). HOME-Alcar: Aligned and Annotated Cartularies [Data set]. Zenodo.â€¦ See the full description on the dataset page: https://huggingface.co/datasets/Teklia/HOME-Alcar-line."},
	{"name":"Deltacorpus_1.1","keyword":"latin","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/FrancophonIA/Deltacorpus_1.1","creator_name":"FrancophonIA","creator_url":"https://huggingface.co/FrancophonIA","description":"\\nDataset origin: https://lindat.cz/repository/xmlui/handle/11234/1-1743\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDescription\\n\\t\\n\\nTexts in 107 languages from the W2C corpus (http://hdl.handle.net/11858/00-097C-0000-0022-6133-9), first 1,000,000 tokens per language, tagged by the delexicalized tagger described in Yu et al. (2016, LREC, PortoroÅ¾, Slovenia).\\nChanges in version 1.1: \\n\\nUniversal Dependencies tagset instead of the older and smaller Google Universal POS tagset. \\n\\nSVM classifier trained on Universal Dependenciesâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/FrancophonIA/Deltacorpus_1.1."},
	{"name":"greek_latin_authors","keyword":"latin","license":"GNU Affero General Public License v3.0","license_url":"https://choosealicense.com/licenses/agpl-3.0/","language":"en","dataset_url":"https://huggingface.co/datasets/sjhuskey/greek_latin_authors","creator_name":"Samuel J. Huskey","creator_url":"https://huggingface.co/sjhuskey","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tGreek and Latin Authors\\n\\t\\n\\nThis dataset contains the names of authors who primarily wrote in Ancient Greek (labeled \\\"Greek\\\") \\nand authors who primarily wrote in Latin (labeled \\\"Latin\\\").\\nThe Greek names were gathered from the Thesaurus Linguae Graecae (TLG) project.\\nSpecifically, the TLG makes lists of authors openly available at https://stephanus.tlg.uci.edu/tlgauthors/post_tlg_e.php\\nand https://stephanus.tlg.uci.edu/tlgauthors/cd.authors.php. These names were supplemented by namesâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/sjhuskey/greek_latin_authors."},
	{"name":"tree_structure","keyword":"latin","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/WaldKI/tree_structure","creator_name":"MeineWaldKI","creator_url":"https://huggingface.co/WaldKI","description":"WaldKI/tree_structure dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"V1Q","keyword":"latin","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/YuRiVeRTi/V1Q","creator_name":"YuRiVeRTical","creator_url":"https://huggingface.co/YuRiVeRTi","description":"from datasets import load_dataset\\nds = load_dataset(\\\"b3x0m/Chinese-H-Novels\\\")\\nimport sagemaker\\nimport boto3\\nfrom sagemaker.huggingface import HuggingFaceModel\\ntry:\\n    role = sagemaker.get_execution_role()\\nexcept ValueError:\\n    iam = boto3.client('iam')\\n    role = iam.get_role(RoleName='sagemaker_execution_role')['Role']['Arn']\\n\\n\\t\\n\\t\\t\\n\\t\\tHub Model configuration. https://huggingface.co/models\\n\\t\\n\\nhub = {\\n    'HF_MODEL_ID':'deepseek-ai/Janus-Pro-7B',\\n    'HF_TASK':'any-to-any'\\n}\\n\\n\\t\\n\\t\\t\\n\\t\\tcreateâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/YuRiVeRTi/V1Q."},
	{"name":"PleIAs-ToxicCommons","keyword":"latin","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/agentlans/PleIAs-ToxicCommons","creator_name":"Alan Tseng","creator_url":"https://huggingface.co/agentlans","description":"\\n\\t\\n\\t\\t\\n\\t\\tPleIAs/ToxicCommons\\n\\t\\n\\nThis dataset is a refined version of the PleIAs/ToxicCommons collection, focusing on historical texts labeled for content that may be considered objectionable by modern standards (what the authors of the dataset deem \\\"toxic\\\"). \\nThe cleaned dataset contains 1â€‰051â€‰027 rows, each representing a text sample with associated toxicity scores across five dimensions:\\n\\nRace and origin-based bias\\nGender and sexuality-based bias\\nReligious bias\\nAbility bias\\nViolence and abuseâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/agentlans/PleIAs-ToxicCommons."},
	{"name":"multilingual_translation_gen_binarized","keyword":"latin","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Youseff1987/multilingual_translation_gen_binarized","creator_name":"JOON HYOUNG JUN","creator_url":"https://huggingface.co/Youseff1987","description":"Youseff1987/multilingual_translation_gen_binarized dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"fishmt5","keyword":"latin","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/MHBS-IHB/fishmt5","creator_name":"Museum of Hydrobiological Sciences, Institute of Hydrobiology, Chinese Academy of Sciences","creator_url":"https://huggingface.co/MHBS-IHB","description":"\\n\\t\\n\\t\\t\\n\\t\\tFish Names Chinese-Latin Parallel Corpora\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Overview\\n\\t\\n\\nWe curated over 60,000 authoritative Chinese-Latin bilingual parallel corpora for fish names by integrating cross-source data, including Eschmeyer's Catalog of Fishes online database. Using a dual translation approach, we applied the Multilingual Text-to-Text Transfer Transformer (mT5) model to generate missing Chinese names.\\nNote: The current release provides 10,000 paired data entries.\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Detailsâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/MHBS-IHB/fishmt5."},
	{"name":"LatinSummarizer","keyword":"latin","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/LatinNLP/LatinSummarizer","creator_name":"LatinNLP","creator_url":"https://huggingface.co/LatinNLP","description":"\\n\\t\\n\\t\\t\\n\\t\\tLatinSummarizer Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tStructure\\n\\t\\n\\n\\naligned_en_la_data_raw.csv\\naligned_en_la_data_cleaned.csv\\naligned_en_la_data_cleaned_with_stanza.csv\\nconcat_aligned_data.csv\\nconcat_cleaned.csv\\nlatin_wikipedia_cleaned.csv\\nlatin_wikipedia_raw.csv\\nlatin-literature-dataset-170M_raw_cleaned.csv\\nlatin-literature-dataset-170M_raw_cleaned_chunked.csv\\nElsa_aligned/\\nREADME.md\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDetails\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\taligned_en_la_data_raw.csv\\n\\t\\n\\nThis dataset contains aligned Latin (la) - English (en)â€¦ See the full description on the dataset page: https://huggingface.co/datasets/LatinNLP/LatinSummarizer."},
	{"name":"LatinSummarizer","keyword":"latin","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/LatinNLP/LatinSummarizer","creator_name":"LatinNLP","creator_url":"https://huggingface.co/LatinNLP","description":"\\n\\t\\n\\t\\t\\n\\t\\tLatinSummarizer Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tStructure\\n\\t\\n\\n\\naligned_en_la_data_raw.csv\\naligned_en_la_data_cleaned.csv\\naligned_en_la_data_cleaned_with_stanza.csv\\nconcat_aligned_data.csv\\nconcat_cleaned.csv\\nlatin_wikipedia_cleaned.csv\\nlatin_wikipedia_raw.csv\\nlatin-literature-dataset-170M_raw_cleaned.csv\\nlatin-literature-dataset-170M_raw_cleaned_chunked.csv\\nElsa_aligned/\\nREADME.md\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDetails\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\taligned_en_la_data_raw.csv\\n\\t\\n\\nThis dataset contains aligned Latin (la) - English (en)â€¦ See the full description on the dataset page: https://huggingface.co/datasets/LatinNLP/LatinSummarizer."}
]
;
