const data_for_language_europe_latin = 
[
	{"name":"Sheetpedia","keyword":"latin","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/tianzl66/Sheetpedia","creator_name":"tianzl","creator_url":"https://huggingface.co/tianzl66","description":"Sheetpedia, a large-scale corpus of over 295,000 diverse spreadsheets (from 324,000+ workbooks) compiled from enterprise email archives and online forums. Sheetpedia provides extensive coverage of real formulas and annotations ‚Äì addressing a gap left by prior table datasets which often lack formula semantics. Sheetpedia fills a crucial need for a large, high-quality spreadsheet benchmark, enabling more effective spreadsheet intelligence and natural language interfaces for spreadsheet tools.\n","first_N":5,"first_N_keywords":["text2text-generation","English","Yoruba","Latin","cc-by-sa-4.0"],"keywords_longer_than_N":true},
	{"name":"LatinSummarizerDataset","keyword":"latin","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/LatinNLP/LatinSummarizerDataset","creator_name":"LatinNLP","creator_url":"https://huggingface.co/LatinNLP","description":"\n\t\n\t\t\n\t\tLatinSummarizer Dataset\n\t\n\n    \n\n\t\n\t\t\n\t\n\t\n\t\tOverview\n\t\n\nThe LatinSummarizerDataset is a structured dataset used in the GitHub Repository for Latin summarization and translation tasks. This dataset provides aligned English-Latin texts, extractive summaries, and pre-training prompts for fine-tuning models like mT5 for low-resource NLP applications.\n\n\t\n\t\t\n\t\tStructure\n\t\n\nThe dataset is divided into two main phases: \n\nPre-training Data: Includes aligned bilingual corpora, synthetic‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/LatinNLP/LatinSummarizerDataset.","first_N":5,"first_N_keywords":["translation","text-generation","summarization","news-articles-summarization","document-retrieval"],"keywords_longer_than_N":true},
	{"name":"LatinSummarizerDataset","keyword":"latin","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/LatinNLP/LatinSummarizerDataset","creator_name":"LatinNLP","creator_url":"https://huggingface.co/LatinNLP","description":"\n\t\n\t\t\n\t\tLatinSummarizer Dataset\n\t\n\n    \n\n\t\n\t\t\n\t\n\t\n\t\tOverview\n\t\n\nThe LatinSummarizerDataset is a structured dataset used in the GitHub Repository for Latin summarization and translation tasks. This dataset provides aligned English-Latin texts, extractive summaries, and pre-training prompts for fine-tuning models like mT5 for low-resource NLP applications.\n\n\t\n\t\t\n\t\tStructure\n\t\n\nThe dataset is divided into two main phases: \n\nPre-training Data: Includes aligned bilingual corpora, synthetic‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/LatinNLP/LatinSummarizerDataset.","first_N":5,"first_N_keywords":["translation","text-generation","summarization","news-articles-summarization","document-retrieval"],"keywords_longer_than_N":true},
	{"name":"kurdish-latin-wikipedia-sentences","keyword":"latin","license":"GNU General Public License v3.0","license_url":"https://choosealicense.com/licenses/gpl-3.0/","language":"en","dataset_url":"https://huggingface.co/datasets/zinaro/kurdish-latin-wikipedia-sentences","creator_name":"Zinar","creator_url":"https://huggingface.co/zinaro","description":"\n\t\n\t\t\n\t\tKurdish Latin Wikipedia Sentences Dataset\n\t\n\nThis dataset consists of 78,004 Kurdish sentences extracted from Wikipedia. All sentences are written in Latin script and consist of 12 to 18 words. The dataset has been carefully cleaned to remove numbers, dates, or non-textual elements.\n\n\t\n\t\t\n\t\tDataset Highlights\n\t\n\n\nSource: Wikipedia (Kurdish content)\nScript: Kurdish Latin\nContent: Pure textual sentences (no numbers, dates, or special characters)\nSentence Length: 12 to 18 words per‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/zinaro/kurdish-latin-wikipedia-sentences.","first_N":5,"first_N_keywords":["Kurdish","gpl-3.0","10K - 100K","text","Text"],"keywords_longer_than_N":true},
	{"name":"LatinSummarizer","keyword":"latin","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/LatinNLP/LatinSummarizer","creator_name":"LatinNLP","creator_url":"https://huggingface.co/LatinNLP","description":"\n\t\n\t\t\n\t\tLatinSummarizer Dataset\n\t\n\n\n\t\n\t\t\n\t\tStructure\n\t\n\n\naligned_en_la_data_raw.csv\naligned_en_la_data_cleaned.csv\naligned_en_la_data_cleaned_with_stanza.csv\nconcat_aligned_data.csv\nconcat_cleaned.csv\nlatin_wikipedia_cleaned.csv\nlatin_wikipedia_raw.csv\nlatin-literature-dataset-170M_raw_cleaned.csv\nlatin-literature-dataset-170M_raw_cleaned_chunked.csv\nElsa_aligned/\nREADME.md\n\n\n\t\n\t\t\n\t\n\t\n\t\tDetails\n\t\n\n\n\t\n\t\t\n\t\n\t\n\t\taligned_en_la_data_raw.csv\n\t\n\nThis dataset contains aligned Latin (la) - English (en)‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/LatinNLP/LatinSummarizer.","first_N":5,"first_N_keywords":["translation","text-generation","summarization","news-articles-summarization","document-retrieval"],"keywords_longer_than_N":true},
	{"name":"LatinSummarizer","keyword":"latin","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/LatinNLP/LatinSummarizer","creator_name":"LatinNLP","creator_url":"https://huggingface.co/LatinNLP","description":"\n\t\n\t\t\n\t\tLatinSummarizer Dataset\n\t\n\n\n\t\n\t\t\n\t\tStructure\n\t\n\n\naligned_en_la_data_raw.csv\naligned_en_la_data_cleaned.csv\naligned_en_la_data_cleaned_with_stanza.csv\nconcat_aligned_data.csv\nconcat_cleaned.csv\nlatin_wikipedia_cleaned.csv\nlatin_wikipedia_raw.csv\nlatin-literature-dataset-170M_raw_cleaned.csv\nlatin-literature-dataset-170M_raw_cleaned_chunked.csv\nElsa_aligned/\nREADME.md\n\n\n\t\n\t\t\n\t\n\t\n\t\tDetails\n\t\n\n\n\t\n\t\t\n\t\n\t\n\t\taligned_en_la_data_raw.csv\n\t\n\nThis dataset contains aligned Latin (la) - English (en)‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/LatinNLP/LatinSummarizer.","first_N":5,"first_N_keywords":["translation","text-generation","summarization","news-articles-summarization","document-retrieval"],"keywords_longer_than_N":true},
	{"name":"wikipedia-citation-index","keyword":"latin","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/lewoniewski/wikipedia-citation-index","creator_name":"W≈Çodzimierz Lewoniewski","creator_url":"https://huggingface.co/lewoniewski","description":"Dataset with citation indexes as of 1 August 2024 for 47 million Wikipedia articles in 55 language versions. Research: ArXiv\n","first_N":5,"first_N_keywords":["Arabic","Azerbaijani","Belarusian","Bulgarian","Catalan"],"keywords_longer_than_N":true},
	{"name":"multiblimp","keyword":"latin","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/jumelet/multiblimp","creator_name":"Jaap Jumelet","creator_url":"https://huggingface.co/jumelet","description":"\n\t\n\t\t\n\t\tMultiBLiMP\n\t\n\nMultiBLiMP is a massively Multilingual Benchmark for Linguistic Minimal Pairs. The dataset is composed of synthetic pairs generated using Universal Dependencies and UniMorph.\nThe paper can be found here.\nWe split the data set by language: each language consists of a single .tsv file. The rows contain many attributes for a particular pair, most important are the sen and wrong_sen fields, which we use for evaluating the language models.\n\n\t\n\t\t\n\t\n\t\n\t\tUsing MultiBLiMP\n\t\n\nTo‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/jumelet/multiblimp.","first_N":5,"first_N_keywords":["multilingual","Buriat","Spanish","Sanskrit","Romanian"],"keywords_longer_than_N":true},
	{"name":"multilingual-pl-bert","keyword":"latin","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/styletts2-community/multilingual-pl-bert","creator_name":"StyleTTS 2 Community","creator_url":"https://huggingface.co/styletts2-community","description":"Attribution: Wikipedia.org\n","first_N":5,"first_N_keywords":["Afrikaans","Aragonese","Arabic","Azerbaijani","Bashkir"],"keywords_longer_than_N":true},
	{"name":"LatinYoutube","keyword":"latin","license":"Academic Free License v3.0","license_url":"https://choosealicense.com/licenses/afl-3.0/","language":"en","dataset_url":"https://huggingface.co/datasets/thiagolira/LatinYoutube","creator_name":"Thiago Ildeu Albuquerque Lira","creator_url":"https://huggingface.co/thiagolira","description":"This is a dataset with text/audio pairs of Classical Latin extracted from youtube videos from the channels Scorpio Martianus, LATINITIUS and Musa Pedestris\n","first_N":5,"first_N_keywords":["Latin","afl-3.0","1K - 10K","parquet","Audio"],"keywords_longer_than_N":true},
	{"name":"udhr-lid","keyword":"latin","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/cis-lmu/udhr-lid","creator_name":"CIS, LMU Munich","creator_url":"https://huggingface.co/cis-lmu","description":"\n\t\n\t\t\n\t\tUDHR-LID\n\t\n\nWhy UDHR-LID?\nYou can access UDHR (Universal Declaration of Human Rights) here, but when a verse is missing, they have texts such as \"missing\" or \"?\". Also, about 1/3 of the sentences consist only of \"articles 1-30\" in different languages. We cleaned the entire dataset from XML files and selected only the paragraphs. We cleared any unrelated language texts from the data and also removed the cases that were incorrect.\nIncorrect? Look at the ckb and kmr files in the UDHR.‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/cis-lmu/udhr-lid.","first_N":5,"first_N_keywords":["multilingual","Tigrinya","Balkan Romani","Standard Arabic","Metlat√≥noc Mixtec"],"keywords_longer_than_N":true},
	{"name":"language_tags","keyword":"latin","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/lbourdois/language_tags","creator_name":"Lo√Øck BOURDOIS","creator_url":"https://huggingface.co/lbourdois","description":"\n\t\n\t\t\n\t\tDescription\n\t\n\nDataset listing 27,328 languages and dialects (also includes macrolanguage names).For each language, either the ISO 639 code, the Glottolog code or both are provided.\n\n\t\n\t\t\n\t\tColumns\n\t\n\n\nEnglish_Name: Language name in English (e.g. \"French\").\nNative_Name: If value is not 0, corresponds to the name of the language by native speakers (e.g. \"Fran√ßais\") which may have been found in Wikipedia's nativename field.\nGlottocode: The language tag in the Glottolog convention (e.g.‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/lbourdois/language_tags.","first_N":5,"first_N_keywords":["Afade","Par√° Ar√°ra","Afar","Aka-Bea","Abon"],"keywords_longer_than_N":true},
	{"name":"wikianc","keyword":"latin","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/cyanic-selkie/wikianc","creator_name":"cyanic-selkie","creator_url":"https://huggingface.co/cyanic-selkie","description":"\n\t\n\t\t\n\t\tDataset Card for WikiAnc\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThe WikiAnc dataset is an automatically generated dataset from Wikipedia (all languages) and Wikidata dumps (August, 2023). \nThe code for generating the dataset can be found here.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\n\nwikificiation: The dataset can be used to train a model for Wikification.\nnamed-entity-linking: The dataset can be used to train a model for Named Entity Linking.\n\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nThe text in the dataset is in all 320‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/cyanic-selkie/wikianc.","first_N":5,"first_N_keywords":["token-classification","machine-generated","crowdsourced","machine-generated","crowdsourced"],"keywords_longer_than_N":true},
	{"name":"entity_cs","keyword":"latin","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/huawei-noah/entity_cs","creator_name":"HUAWEI Noah's Ark Lab","creator_url":"https://huggingface.co/huawei-noah","description":"\n\t\n\t\t\n\t\tDataset Card for EntityCS\n\t\n\n\nRepository: https://github.com/huawei-noah/noah-research/tree/master/NLP/EntityCS  \nPaper: https://aclanthology.org/2022.findings-emnlp.499.pdf  \nPoint of Contact: Fenia Christopoulou, Chenxi Whitehouse\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Description\n\t\n\nWe use the English Wikipedia and leverage entity information from Wikidata to construct an entity-based Code Switching corpus. \nTo achieve this, we make use of wikilinks in Wikipedia, i.e. links from one page to another.‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/huawei-noah/entity_cs.","first_N":5,"first_N_keywords":["Afrikaans","Amharic","Arabic","Assamese","Azerbaijani"],"keywords_longer_than_N":true},
	{"name":"CulturaY","keyword":"latin","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ontocord/CulturaY","creator_name":"Ontocord.AI","creator_url":"https://huggingface.co/ontocord","description":"\n\t\n\t\t\n\t\tCulturaY: A Large Cleaned Multilingual Dataset of 75 Languages\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nFrom the team that brought you CulturaX, we present CulturaY, another substantial multilingual dataset of 15TB (uncompressed)/3TB (zstd-compressed) that applies the same dataset cleaning methodology to the HPLT v1.1 dataset. \nPlease note that HPLT v1.2 has also been released and is an alternative verison with different cleaning methodolgies. \nThis data was used in part to train our SOTA‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ontocord/CulturaY.","first_N":5,"first_N_keywords":["text-generation","fill-mask","language-modeling","masked-language-modeling","no-annotation"],"keywords_longer_than_N":true},
	{"name":"Basis-Latin-French","keyword":"latin","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/LaMOP/Basis-Latin-French","creator_name":"LaMOP","creator_url":"https://huggingface.co/LaMOP","description":"\n\t\n\t\t\n\t\tDataset Card for Basis-Latin-French\n\t\n\n\n\nThe Basis-Latin-French dataset is an unannotated Latin and old French corpus, compiled from different resources from the web. This resources include the Corpus de la Bourgogne du Moyen √Çge, The e-NDP project, HIMANIS Gu√©rin and the HOME-Alcar project and the Corpus Cisterciens et Ressources.\n\n\t\n\t\t\n\t\tLicence\n\t\n\n[https://creativecommons.org/licenses/by-sa/4.0/deed.en](Creative Commons Attribution-ShareAlike 4.0 International)\n\n\t\n\t\t\n\t\tDataset‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/LaMOP/Basis-Latin-French.","first_N":5,"first_N_keywords":["mask-generation","no-annotation","Latin","cc-by-sa-4.0","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"Basis-Latin-French","keyword":"latin","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/LaMOP/Basis-Latin-French","creator_name":"LaMOP","creator_url":"https://huggingface.co/LaMOP","description":"\n\t\n\t\t\n\t\tDataset Card for Basis-Latin-French\n\t\n\n\n\nThe Basis-Latin-French dataset is an unannotated Latin and old French corpus, compiled from different resources from the web. This resources include the Corpus de la Bourgogne du Moyen √Çge, The e-NDP project, HIMANIS Gu√©rin and the HOME-Alcar project and the Corpus Cisterciens et Ressources.\n\n\t\n\t\t\n\t\tLicence\n\t\n\n[https://creativecommons.org/licenses/by-sa/4.0/deed.en](Creative Commons Attribution-ShareAlike 4.0 International)\n\n\t\n\t\t\n\t\tDataset‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/LaMOP/Basis-Latin-French.","first_N":5,"first_N_keywords":["mask-generation","no-annotation","Latin","cc-by-sa-4.0","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"MonadGPT","keyword":"latin","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Pclanglais/MonadGPT","creator_name":"Pierre-Carl Langlais","creator_url":"https://huggingface.co/Pclanglais","description":"This finetuning dataset has been used to train MonadGPT, a chatGPT-like model for the early modern period. \nIt contains 10,797 excerpts of texts in English, French and Latin, mostly published in the 17th century, as well as synthetic questions generated by Mistral-Hermes.\nThe instructions use the chatML format with a unique system prompt (to help with consistency), user questions and assistant answers.\nAll the excerpts are in the public domain and so are the synthetic instructions (in‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Pclanglais/MonadGPT.","first_N":5,"first_N_keywords":["English","French","Latin","cc0-1.0","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"librivox-tracks","keyword":"latin","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/pykeio/librivox-tracks","creator_name":"pyke.io","creator_url":"https://huggingface.co/pykeio","description":"A dataset of all audio files uploaded to LibriVox before 26th September 2023.\n","first_N":5,"first_N_keywords":["text-to-speech","automatic-speech-recognition","Achinese","Afrikaans","Ancient Greek (to 1453)"],"keywords_longer_than_N":true},
	{"name":"TreeOfLife-200M","keyword":"latin","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/imageomics/TreeOfLife-200M","creator_name":"HDR Imageomics Institute","creator_url":"https://huggingface.co/imageomics","description":"\n\t\n\t\t\n\t\tDataset Card for TreeOfLife-200M\n\t\n\nWith nearly 214 million images representing 952,257 taxa across the tree of life, TreeOfLife-200M is the largest and most diverse public ML-ready dataset for computer vision models in biology at release. This dataset combines images and metadata from four core biodiversity data providers: Global Biodiversity Information Facility (GBIF), Encyclopedia of Life (EOL), BIOSCAN-5M, and FathomNet to more than double the number of unique taxa covered by‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/imageomics/TreeOfLife-200M.","first_N":5,"first_N_keywords":["image-classification","zero-shot-classification","English","Latin","cc0-1.0"],"keywords_longer_than_N":true},
	{"name":"wit_base","keyword":"latin","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/wikimedia/wit_base","creator_name":"Wikimedia","creator_url":"https://huggingface.co/wikimedia","description":"\n\t\n\t\t\n\t\tDataset Card for WIT\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nWikimedia's version of the Wikipedia-based Image Text (WIT) Dataset, a large multimodal multilingual dataset.\nFrom the official blog post:\n\nThe core training data is taken from the Wikipedia Image-Text (WIT) Dataset, a large curated set of more than 37 million image-text associations extracted from Wikipedia articles in 108 languages that was recently released by Google Research.\nThe WIT dataset offers extremely valuable data about the‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/wikimedia/wit_base.","first_N":5,"first_N_keywords":["image-to-text","text-retrieval","image-captioning","machine-generated","found"],"keywords_longer_than_N":true},
	{"name":"product-database","keyword":"latin","license":"GNU Affero General Public License v3.0","license_url":"https://choosealicense.com/licenses/agpl-3.0/","language":"en","dataset_url":"https://huggingface.co/datasets/openfoodfacts/product-database","creator_name":"Open Food Facts","creator_url":"https://huggingface.co/openfoodfacts","description":"\n\t\n\t\t\n\t\tOpen Food Facts Database\n\t\n\n\n\t\n\t\t\n\t\tWhat is üçä Open Food Facts?\n\t\n\n\n\t\n\t\t\n\t\tA food products database\n\t\n\nOpen Food Facts is a database of food products with ingredients, allergens, nutrition facts and all the tidbits of information we can find on product labels.\n\n\t\n\t\t\n\t\tMade by everyone\n\t\n\nOpen Food Facts is a non-profit association of volunteers. 25.000+ contributors like you have added 1.7 million + products from 150 countries using our Android or iPhone app or their camera to scan‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/openfoodfacts/product-database.","first_N":5,"first_N_keywords":["English","French","German","Spanish","Italian"],"keywords_longer_than_N":true},
	{"name":"mHumanEval-Benchmark","keyword":"latin","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/md-nishat-008/mHumanEval-Benchmark","creator_name":"Nishat Raihan","creator_url":"https://huggingface.co/md-nishat-008","description":"\n\n\n\t\n\t\t\n\t\tüî∑ Accepted in NAACL Proceedings (2025) üî∑\n\t\n\n\n\n\n\n  \n    \n      \n        \n          \n        \n      \n      \n        \n          \n        \n      \n      \n        \n          \n        \n      \n    \n  \n\n\n\n\n\n  \n\n\t\n\t\n\t\n\t\tmHumanEval\n\t\n\nThe mHumanEval benchmark is curated based on prompts from the original HumanEval üìö [Chen et al., 2021]. It includes a total of 33,456 prompts for Python, and 836,400 in total - significantly expanding from the original 164. \n\n\n\t\n\t\t\n\t\tQuick Start\n\t\n\n  Detailed‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/md-nishat-008/mHumanEval-Benchmark.","first_N":5,"first_N_keywords":["text2text-generation","Afar","Abkhaz","Avestan","Afrikaans"],"keywords_longer_than_N":true},
	{"name":"opus_ubuntu","keyword":"latin","license":"BSD 3-Clause \"New\" or \"Revised\" License","license_url":"https://choosealicense.com/licenses/bsd-3-clause/","language":"en","dataset_url":"https://huggingface.co/datasets/Helsinki-NLP/opus_ubuntu","creator_name":"Language Technology Research Group at the University of Helsinki","creator_url":"https://huggingface.co/Helsinki-NLP","description":"\n\t\n\t\t\n\t\tDataset Card for Opus Ubuntu\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThese are translations of the Ubuntu software package messages, donated by the Ubuntu community.\nTo load a language pair which isn't part of the config, all you need to do is specify the language code as pairs.\nYou can find the valid pairs in Homepage section of Dataset Description: http://opus.nlpl.eu/Ubuntu.php\nE.g.\ndataset = load_dataset(\"opus_ubuntu\", lang1=\"it\", lang2=\"pl\")\n\n\t\n\t\t\n\t\n\t\n\t\tSupported Tasks and Leaderboards‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Helsinki-NLP/opus_ubuntu.","first_N":5,"first_N_keywords":["translation","crowdsourced","expert-generated","found","multilingual"],"keywords_longer_than_N":true},
	{"name":"oscar-small","keyword":"latin","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/nthngdy/oscar-small","creator_name":"Nathan Godey","creator_url":"https://huggingface.co/nthngdy","description":"The Open Super-large Crawled ALMAnaCH coRpus is a huge multilingual corpus obtained by language classification and filtering of the Common Crawl corpus using the goclassy architecture.\\","first_N":5,"first_N_keywords":["text-generation","language-modeling","no-annotation","found","multilingual"],"keywords_longer_than_N":true},
	{"name":"bnl_newspapers1841-1879","keyword":"latin","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/biglam/bnl_newspapers1841-1879","creator_name":"BigLAM: BigScience Libraries, Archives and Museums","creator_url":"https://huggingface.co/biglam","description":"\n\t\n\t\t\n\t\tDataset Card for BnL Newspapers 1841-1881\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\n592.192 articles from historical newspapers (1841-1881) along with metadata and the full text.\n21 newspaper titles\n24.415 newspaper issues\n99.957 scanned pages\nTranscribed using a variety of OCR engines and corrected using https://github.com/natliblux/nautilusocr (95% threshold)\nPublic Domain, CC0 (See copyright notice)\nThe newspapers used are:\n\nDer Arbeiter (1878-1881)\nL'Arlequin (1848-1848)\nL'Avenir (1868-1871)‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/biglam/bnl_newspapers1841-1879.","first_N":5,"first_N_keywords":["text-generation","fill-mask","language-modeling","masked-language-modeling","no-annotation"],"keywords_longer_than_N":true},
	{"name":"latin_english_translation","keyword":"latin","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/grosenthal/latin_english_translation","creator_name":"Gil Rosenthal","creator_url":"https://huggingface.co/grosenthal","description":"\n\t\n\t\t\n\t\tDataset Card for \"latin_english_parallel\"\n\t\n\n101k translation pairs between Latin and English, split 99/1/1 as train/test/val. These have been collected roughly 66% from the Loeb Classical Library and 34% from the Vulgate translation. \nFor those that were gathered from the Loeb Classical Library, alignment was performd manually between Source and Target sequences.\nEach sample is annotated with the index and file (and therefore author/work) that the sample is from. If you find errors‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/grosenthal/latin_english_translation.","first_N":5,"first_N_keywords":["translation","Latin","English","mit","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"oscar-small","keyword":"latin","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/djstrong/oscar-small","creator_name":"Krzysztof Wr√≥bel","creator_url":"https://huggingface.co/djstrong","description":"The Open Super-large Crawled ALMAnaCH coRpus is a huge multilingual corpus obtained by language classification and filtering of the Common Crawl corpus using the goclassy architecture.\\","first_N":5,"first_N_keywords":["text-generation","language-modeling","no-annotation","found","multilingual"],"keywords_longer_than_N":true},
	{"name":"latin_english_parallel","keyword":"latin","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/grosenthal/latin_english_parallel","creator_name":"Gil Rosenthal","creator_url":"https://huggingface.co/grosenthal","description":"\n\t\n\t\t\n\t\tDataset Card for \"latin_english_parallel\"\n\t\n\n101k translation pairs between Latin and English, split 99/1/1 as train/test/val. These have been collected roughly 66% from the Loeb Classical Library and 34% from the Vulgate translation. \nFor those that were gathered from the Loeb Classical Library, alignment was performd manually between Source and Target sequences. Additionally, the English translations were both 1. copyrighted and 2. outdated. As such, we decided to modernize and‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/grosenthal/latin_english_parallel.","first_N":5,"first_N_keywords":["translation","Latin","English","mit","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"xP3x","keyword":"latin","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/CohereLabs/xP3x","creator_name":"Cohere Labs","creator_url":"https://huggingface.co/CohereLabs","description":"\n\t\n\t\t\n\t\tDataset Card for xP3x\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\n\nxP3x (Crosslingual Public Pool of Prompts eXtended) is a collection of prompts & datasets across 277 languages & 16 NLP tasks. It contains all of xP3 + much more! It is used for training future contenders of mT0 & BLOOMZ at project Aya @Cohere Labs üß°\n\n\nCreation: The dataset can be recreated using instructions available here together with the file in this repository named xp3x_create.py. We provide this version to save processing‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/CohereLabs/xP3x.","first_N":5,"first_N_keywords":["other","expert-generated","crowdsourced","multilingual","Afrikaans"],"keywords_longer_than_N":true},
	{"name":"xP3x-sample","keyword":"latin","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Muennighoff/xP3x-sample","creator_name":"Niklas Muennighoff","creator_url":"https://huggingface.co/Muennighoff","description":"A multilingual collection of Winograd Schemas in six languages that can be used for evaluation of cross-lingual commonsense reasoning capabilities.","first_N":5,"first_N_keywords":["other","expert-generated","crowdsourced","multilingual","Afrikaans"],"keywords_longer_than_N":true},
	{"name":"WillyShakes","keyword":"latin","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/scenecoachai/WillyShakes","creator_name":"Janis Deedy","creator_url":"https://huggingface.co/scenecoachai","description":"cd your-dataset-name\ncp /path/to/your/data/* .\ngit add .\ngit commit -m \"Add my dataset\"\ngit push\n","first_N":5,"first_N_keywords":["feature-extraction","Latin","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"georges-1913-normalization","keyword":"latin","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mschonhardt/georges-1913-normalization","creator_name":"Michael Schonhardt","creator_url":"https://huggingface.co/mschonhardt","description":"\n\t\n\t\t\n\t\tNormalized Georges 1913\n\t\n\n\n\t\n\t\t\n\t\tDescription\n\t\n\nThis dataset was created as part of the Burchard's Dekret Digital project (www.burchards-dekret-digital.de), \nfunded by the Academy of Sciences and Literature | Mainz.\nIt is based on 55,000 lemmata from Karl Georges, Ausf√ºhrliches lateinisch-deutsches Handw√∂rterbuch, Hannover 1913 (Georges 1913) \nand was developed to train models for normalization tasks in the context of medieval Latin.\nThe dataset consists of approximately 5 million‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mschonhardt/georges-1913-normalization.","first_N":5,"first_N_keywords":["text2text-generation","Latin","cc-by-4.0","1M - 10M","csv"],"keywords_longer_than_N":true},
	{"name":"wiktionary-data","keyword":"latin","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/paion-data/wiktionary-data","creator_name":"Paion Data","creator_url":"https://huggingface.co/paion-data","description":"\n\t\n\t\t\n\t\tWiktionary Data on Hugging Face Datasets\n\t\n\n\n\n\n\nwiktionary-data is a sub-data extraction of the English Wiktionary that currently\nsupports the following languages:\n\nDeutsch - German\nLatinum - Latin\n·ºôŒªŒªŒ∑ŒΩŒπŒ∫ŒÆ - Ancient Greek\nÌïúÍµ≠Ïñ¥ - Korean\nêé†êéºêéπ- Old Persian\níÄùíÖóíÅ∫íåë(íåù) - Akkadian\nElamite\n‡§∏‡§Ç‡§∏‡•ç‡§ï‡•É‡§§‡§Æ‡•ç - Sanskrit, or Classical Sanskrit\n\nwiktionary-data was originally a sub-module of wilhelm-graphdb. While\nthe dataset it's getting bigger, I noticed a wave of more exciting potentials this‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/paion-data/wiktionary-data.","first_N":5,"first_N_keywords":["English","German","Latin","Ancient Greek (to 1453)","Korean"],"keywords_longer_than_N":true},
	{"name":"wiktionary-data","keyword":"latin","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/paion-data/wiktionary-data","creator_name":"Paion Data","creator_url":"https://huggingface.co/paion-data","description":"\n\t\n\t\t\n\t\tWiktionary Data on Hugging Face Datasets\n\t\n\n\n\n\n\nwiktionary-data is a sub-data extraction of the English Wiktionary that currently\nsupports the following languages:\n\nDeutsch - German\nLatinum - Latin\n·ºôŒªŒªŒ∑ŒΩŒπŒ∫ŒÆ - Ancient Greek\nÌïúÍµ≠Ïñ¥ - Korean\nêé†êéºêéπ- Old Persian\níÄùíÖóíÅ∫íåë(íåù) - Akkadian\nElamite\n‡§∏‡§Ç‡§∏‡•ç‡§ï‡•É‡§§‡§Æ‡•ç - Sanskrit, or Classical Sanskrit\n\nwiktionary-data was originally a sub-module of wilhelm-graphdb. While\nthe dataset it's getting bigger, I noticed a wave of more exciting potentials this‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/paion-data/wiktionary-data.","first_N":5,"first_N_keywords":["English","German","Latin","Ancient Greek (to 1453)","Korean"],"keywords_longer_than_N":true},
	{"name":"muri-it","keyword":"latin","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/akoksal/muri-it","creator_name":"Abdullatif Koksal","creator_url":"https://huggingface.co/akoksal","description":"\n\t\n\t\t\n\t\tMURI-IT: Multilingual Instruction Tuning Dataset for 200 Languages via Multilingual Reverse Instructions\n\t\n\nMURI-IT is a large-scale multilingual instruction tuning dataset containing 2.2 million instruction-output pairs across 200 languages. It is designed to address the challenges of instruction tuning in low-resource languages with Multilingual Reverse Instructions (MURI), which ensures that the output is human-written, high-quality, and authentic to the cultural and linguistic‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/akoksal/muri-it.","first_N":5,"first_N_keywords":["text2text-generation","text-generation","question-answering","summarization","Achinese"],"keywords_longer_than_N":true},
	{"name":"Deltacorpus_1.1","keyword":"latin","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/FrancophonIA/Deltacorpus_1.1","creator_name":"FrancophonIA","creator_url":"https://huggingface.co/FrancophonIA","description":"\n[!NOTE]\nDataset origin: https://lindat.cz/repository/xmlui/handle/11234/1-1743\n\n\n\t\n\t\t\n\t\tDescription\n\t\n\nTexts in 107 languages from the W2C corpus (http://hdl.handle.net/11858/00-097C-0000-0022-6133-9), first 1,000,000 tokens per language, tagged by the delexicalized tagger described in Yu et al. (2016, LREC, Portoro≈æ, Slovenia).\nChanges in version 1.1: \n\nUniversal Dependencies tagset instead of the older and smaller Google Universal POS tagset. \n\nSVM classifier trained on Universal‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/FrancophonIA/Deltacorpus_1.1.","first_N":5,"first_N_keywords":["token-classification","multilingual","Afrikaans","Albanian","Amharic"],"keywords_longer_than_N":true},
	{"name":"ToxicCommons","keyword":"latin","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/PleIAs/ToxicCommons","creator_name":"PleIAs","creator_url":"https://huggingface.co/PleIAs","description":"\n\t\n\t\t\n\t\tToxic Commons\n\t\n\nToxic Commons is a release of 2 million samples of annotated, public domain, multilingual text that was used to train Celadon. \nIt is being released alongside Celadon, in order to better understand multilingual and multicultural toxicity. \nEach sample was classified across 5 axes of toxicity:\n\nRace and origin-based bias: includes racism as well as bias against someone‚Äôs country or region of origin or immigration status, especially immigrant or refugee status. \nGender‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/PleIAs/ToxicCommons.","first_N":5,"first_N_keywords":["text-classification","English","French","Spanish","German"],"keywords_longer_than_N":true},
	{"name":"latin-greek-hebrew-english-dataset","keyword":"latin","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Dddixyy/latin-greek-hebrew-english-dataset","creator_name":"Davide Brunori","creator_url":"https://huggingface.co/Dddixyy","description":"\n\t\n\t\t\n\t\tProverbs: Ancient Languages Set\n\t\n\nThis repository contains a collection of 2,000 short phrases translated into three ancient languages: Ancient Latin, Ancient Greek, Biblical Hebrew, and English. The phrases cover a wide variety of contexts, providing insight into the linguistic, cultural, and philosophical landscapes of these ancient civilizations.\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThe \"Proverbs: Ancient Languages Set\" is a resource designed to help individuals explore and understand ancient‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Dddixyy/latin-greek-hebrew-english-dataset.","first_N":5,"first_N_keywords":["translation","Latin","Hebrew","Greek","English"],"keywords_longer_than_N":true},
	{"name":"Synthdog-Multilingual-100","keyword":"latin","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/WueNLP/Synthdog-Multilingual-100","creator_name":"W√ºNLP","creator_url":"https://huggingface.co/WueNLP","description":"\n\t\n\t\t\n\t\tSynthdog Multilingual\n\t\n\n\n\nThe Synthdog dataset created for training in Centurio: On Drivers of Multilingual Ability of Large Vision-Language Model.\nUsing the official Synthdog code, we created >1 million training samples for improving OCR capabilities in Large Vision-Language Models.\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Details\n\t\n\nWe provide the images for download in two .tar.gz files. Download and extract them in folders of the same name (so cat images.tar.gz.* | tar xvzf -C images; tar xvzf‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/WueNLP/Synthdog-Multilingual-100.","first_N":5,"first_N_keywords":["image-to-text","multilingual","Afrikaans","Amharic","Arabic"],"keywords_longer_than_N":true},
	{"name":"xP3x-Kongo","keyword":"latin","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Svngoku/xP3x-Kongo","creator_name":"NIONGOLO Chrys F√©-Marty","creator_url":"https://huggingface.co/Svngoku","description":"\n\t\n\t\t\n\t\tDataset Card for xP3x Kikongo Focus\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\n\nxP3x (Crosslingual Public Pool of Prompts eXtended) is a collection of prompts & datasets across 277 languages & 16 NLP tasks. It contains all of xP3 + much more! It is used for training future contenders of mT0 & BLOOMZ at project Aya @C4AI üß°\n\n\nCreation: The dataset can be recreated using instructions available here together with the file in this repository named xp3x_create.py. We provide this version to save‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Svngoku/xP3x-Kongo.","first_N":5,"first_N_keywords":["other","translation","expert-generated","crowdsourced","multilingual"],"keywords_longer_than_N":true},
	{"name":"ParaNames","keyword":"latin","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/bltlab/ParaNames","creator_name":"Broadening Linguistic Technologies Lab (BLT Lab)","creator_url":"https://huggingface.co/bltlab","description":"\n\t\n\t\t\n\t\n\t\n\t\tDataset Card for Dataset Name\n\t\n\n\n\nThis dataset card aims to be a base template for new datasets. It has been generated using this raw template.\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Description\n\t\n\n\n\n\n\n\nCurated by: [More Information Needed]\nFunded by [optional]: [More Information Needed]\nShared by [optional]: [More Information Needed]\nLanguage(s) (NLP): [More Information Needed]\nLicense: [More Information Needed]\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Sources [optional]‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/bltlab/ParaNames.","first_N":5,"first_N_keywords":["token-classification","Nias","Kotava","Banjar","Angika"],"keywords_longer_than_N":true},
	{"name":"librivox-tracks","keyword":"latin","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/xacer/librivox-tracks","creator_name":"xacer","creator_url":"https://huggingface.co/xacer","description":"A dataset of all audio files uploaded to LibriVox before 26th September 2023.\nForked from https://huggingface.co/datasets/pykeio/librivox-tracks\nChanges:\n\nUsed archive.org metadata API to annotate rows with \"duration\" column\n\n","first_N":5,"first_N_keywords":["text-to-speech","automatic-speech-recognition","feature-extraction","Achinese","Afrikaans"],"keywords_longer_than_N":true},
	{"name":"ARK-Metadata","keyword":"latin","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/SBB/ARK-Metadata","creator_name":"Staatsbibliothek zu Berlin - Preu√üischer Kulturbesitz","creator_url":"https://huggingface.co/SBB","description":"\n\t\n\t\t\n\t\tMetadata of the \"Alter Realkatalog\" (ARK) of Berlin State Library (SBB)\n\t\n\n\n\t\n\t\t\n\t\tMotivation\n\t\n\nThis dataset was created with the intent to provide a single larger set of metadata from Berlin State Library for research purposes and the development of AI applications.\nThe dataset comprises of descriptive metadata of 2.619.397 titles, which together form the \"Alte Realkatalog\" of Berlin State Libray, which may be translated to \"Old Subject Catalogue\". The data are stored in columnar‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/SBB/ARK-Metadata.","first_N":5,"first_N_keywords":["text-classification","feature-extraction","German","Latin","English"],"keywords_longer_than_N":true},
	{"name":"test_modern_dataset","keyword":"latin","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/SerhiiLebediuk/test_modern_dataset","creator_name":"Serhii Lebediuk","creator_url":"https://huggingface.co/SerhiiLebediuk","description":"SerhiiLebediuk/test_modern_dataset dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["question-answering","Latin","English","Ukrainian","mit"],"keywords_longer_than_N":true},
	{"name":"translation_latin_to_italian","keyword":"latin","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Dddixyy/translation_latin_to_italian","creator_name":"Davide Brunori","creator_url":"https://huggingface.co/Dddixyy","description":"Dddixyy/translation_latin_to_italian dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["translation","Latin","Italian","mit","< 1K"],"keywords_longer_than_N":true},
	{"name":"latino_italiano_traduzioni_DIRETTE","keyword":"latin","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Dddixyy/latino_italiano_traduzioni_DIRETTE","creator_name":"Davide Brunori","creator_url":"https://huggingface.co/Dddixyy","description":"Dddixyy/latino_italiano_traduzioni_DIRETTE dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["translation","Latin","Italian","mit","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"ApolloMoEDataset","keyword":"latin","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/FreedomIntelligence/ApolloMoEDataset","creator_name":"FreedomAI","creator_url":"https://huggingface.co/FreedomIntelligence","description":"\n\t\n\t\t\n\t\tDemocratizing Medical LLMs For Much More Languages\n\t\n\nCovering 12 Major Languages including English, Chinese, French, Hindi, Spanish, Arabic, Russian, Japanese, Korean, German, Italian, Portuguese and 38 Minor Languages So far.\n\n   üìÉ Paper ‚Ä¢ üåê Demo ‚Ä¢ ü§ó ApolloMoEDataset ‚Ä¢ ü§ó ApolloMoEBench  ‚Ä¢ ü§ó Models  ‚Ä¢üåê Apollo  ‚Ä¢ üåê ApolloMoE\n\n\n\n\n\n\n\t\n\t\t\n\t\tüåà Update\n\t\n\n\n[2024.10.15] ApolloMoE repo is publishedÔºÅüéâ\n\n\n\t\n\t\t\n\t\tLanguages Coverage\n\t\n\n12 Major Languages and 38 Minor Languages\n\n  Click to‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/FreedomIntelligence/ApolloMoEDataset.","first_N":5,"first_N_keywords":["question-answering","Arabic","English","Chinese","Korean"],"keywords_longer_than_N":true},
	{"name":"ApolloMoEBench","keyword":"latin","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/FreedomIntelligence/ApolloMoEBench","creator_name":"FreedomAI","creator_url":"https://huggingface.co/FreedomIntelligence","description":"\n\t\n\t\t\n\t\tDemocratizing Medical LLMs For Much More Languages\n\t\n\nCovering 12 Major Languages including English, Chinese, French, Hindi, Spanish, Arabic, Russian, Japanese, Korean, German, Italian, Portuguese and 38 Minor Languages So far.\n\n   üìÉ Paper ‚Ä¢ üåê Demo ‚Ä¢ ü§ó ApolloMoEDataset ‚Ä¢ ü§ó ApolloMoEBench  ‚Ä¢ ü§ó Models  ‚Ä¢üåê Apollo  ‚Ä¢ üåê ApolloMoE\n\n\n\n\n\n\n\t\n\t\t\n\t\tüåà Update\n\t\n\n\n[2024.10.15] ApolloMoE repo is publishedÔºÅüéâ\n\n\n\t\n\t\t\n\t\tLanguages Coverage\n\t\n\n12 Major Languages and 38 Minor Languages\n\n  Click to‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/FreedomIntelligence/ApolloMoEBench.","first_N":5,"first_N_keywords":["question-answering","Arabic","English","Chinese","Korean"],"keywords_longer_than_N":true},
	{"name":"Diplomatarium-Fennicum","keyword":"latin","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Kansallisarkisto/Diplomatarium-Fennicum","creator_name":"National Archives of Finland","creator_url":"https://huggingface.co/Kansallisarkisto","description":"\n\t\n\t\t\n\t\tDiplomatarium Fennicum-dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset summary\n\t\n\nDataset consisting of eight data fields taken from the Diplomatarium Fennicum -database. \nDiplomatarium Fennicum -database contains medieval charters and text excerpts conserning Finland and Finns, \nand is published and maintained by the National Archives of Finland.\nThe data fields selected are central to identifying, categorizing and analyzing the texts. \nThe dataset represents only very minimally the whole database; the‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Kansallisarkisto/Diplomatarium-Fennicum.","first_N":5,"first_N_keywords":["Finnish","Swedish","Latin","German","cc0-1.0"],"keywords_longer_than_N":true},
	{"name":"vietnamese-nom-latin-translation","keyword":"latin","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/lunovian/vietnamese-nom-latin-translation","creator_name":"Nguyen Xuan An","creator_url":"https://huggingface.co/lunovian","description":"lunovian/vietnamese-nom-latin-translation dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["translation","text2text-generation","text-generation","Vietnamese","Latin"],"keywords_longer_than_N":true},
	{"name":"reranker_continuous_filt_max7_train","keyword":"latin","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/lightblue/reranker_continuous_filt_max7_train","creator_name":"Lightblue KK.","creator_url":"https://huggingface.co/lightblue","description":"\n\t\n\t\t\n\t\tReranker training data\n\t\n\nThis data was generated using 4 steps:\n\nWe gathered queries and corresponding text data from 35 high quality datasets covering more than 95 languages.\nFor datasets which did not already have negative texts for queries, we mined hard negatives using the BAAI/bge-m3 embedding model.\nFor each query, we selected one positive and one negative text and used Qwen/Qwen2.5-32B-Instruct-GPTQ-Int4 to rate the relatedness of each query-text pair using a token \"1\", \"2\"‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/lightblue/reranker_continuous_filt_max7_train.","first_N":5,"first_N_keywords":["English","Chinese","Spanish","German","Arabic"],"keywords_longer_than_N":true},
	{"name":"wilhelm-vocabulary","keyword":"latin","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/QubitPi/wilhelm-vocabulary","creator_name":"Jiaqi","creator_url":"https://huggingface.co/QubitPi","description":"\n\t\n\t\t\n\t\tWilhelm Vocabulary\n\t\n\n[![Hugging Face dataset badge]][Hugging Face dataset URL]\n[![Vocabulary count - German]][Docker Hub URL]\n[![Vocabulary count - Latin]][Docker Hub URL]\n[![Vocabulary count - Ancient Greek]][Docker Hub URL]\n[![Docker Hub][Docker Pulls Badge]][Docker Hub URL]\n[![GitHub workflow status badge][GitHub workflow status badge]][GitHub workflow status URL]\n[![Hugging Face sync status badge]][Hugging Face sync status URL]\n[![Apache License Badge]][Apache License, Version‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/QubitPi/wilhelm-vocabulary.","first_N":5,"first_N_keywords":["English","German","Latin","Ancient Greek (to 1453)","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"wilhelm-vocabulary","keyword":"latin","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/QubitPi/wilhelm-vocabulary","creator_name":"Jiaqi","creator_url":"https://huggingface.co/QubitPi","description":"\n\t\n\t\t\n\t\tWilhelm Vocabulary\n\t\n\n[![Hugging Face dataset badge]][Hugging Face dataset URL]\n[![Vocabulary count - German]][Docker Hub URL]\n[![Vocabulary count - Latin]][Docker Hub URL]\n[![Vocabulary count - Ancient Greek]][Docker Hub URL]\n[![Docker Hub][Docker Pulls Badge]][Docker Hub URL]\n[![GitHub workflow status badge][GitHub workflow status badge]][GitHub workflow status URL]\n[![Hugging Face sync status badge]][Hugging Face sync status URL]\n[![Apache License Badge]][Apache License, Version‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/QubitPi/wilhelm-vocabulary.","first_N":5,"first_N_keywords":["English","German","Latin","Ancient Greek (to 1453)","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"vitruvius_alberti_fludd_corpus","keyword":"latin","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/forcemultiplier/vitruvius_alberti_fludd_corpus","creator_name":"The Force Multiplier","creator_url":"https://huggingface.co/forcemultiplier","description":"\n\t\n\t\t\n\t\n\t\n\t\tVitruvius Alberti Fludd Architecture Corpus\n\t\n\nA comprehensive collection of historical architectural texts focusing on works by Vitruvius, Leon Battista Alberti, and Robert Fludd.\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Statistics\n\t\n\n\n\t\n\t\t\n\t\n\t\n\t\tOverview\n\t\n\n\nTotal Documents: 16 PDFs\nTotal Pages: 5,233\nEmpty Pages: 1,156\nPages with Errors: 0\n\n\n\t\n\t\t\n\t\n\t\n\t\tDocument Length Statistics\n\t\n\n\nAverage Pages per Document: 327.1\nMinimum Pages: 10\nMaximum Pages: 623\n\n\n\t\n\t\t\n\t\n\t\n\t\tContent Statistics (words per‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/forcemultiplier/vitruvius_alberti_fludd_corpus.","first_N":5,"first_N_keywords":["text-generation","question-answering","English","Latin","mit"],"keywords_longer_than_N":true},
	{"name":"wiktionary-data","keyword":"latin","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/QubitPi/wiktionary-data","creator_name":"Jiaqi","creator_url":"https://huggingface.co/QubitPi","description":"\n\t\n\t\t\n\t\tWiktionary Data on Hugging Face Datasets\n\t\n\n\n\n\n\nwiktionary-data is a sub-data extraction of the English Wiktionary that currently\nsupports the following languages:\n\nDeutsch - German\nLatinum - Latin\n·ºôŒªŒªŒ∑ŒΩŒπŒ∫ŒÆ - Ancient Greek\nÌïúÍµ≠Ïñ¥ - Korean\nêé†êéºêéπ - Old Persian\níÄùíÖóíÅ∫íåë(íåù) - Akkadian\nElamite\n‡§∏‡§Ç‡§∏‡•ç‡§ï‡•É‡§§‡§Æ‡•ç - Sanskrit, or Classical Sanskrit\n\nwiktionary-data was originally a sub-module of wilhelm-graphdb. While\nthe dataset it's getting bigger, I noticed a wave of more exciting potentials this‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/QubitPi/wiktionary-data.","first_N":5,"first_N_keywords":["English","German","Latin","Ancient Greek (to 1453)","Korean"],"keywords_longer_than_N":true},
	{"name":"wiktionary-data","keyword":"latin","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/QubitPi/wiktionary-data","creator_name":"Jiaqi","creator_url":"https://huggingface.co/QubitPi","description":"\n\t\n\t\t\n\t\tWiktionary Data on Hugging Face Datasets\n\t\n\n\n\n\n\nwiktionary-data is a sub-data extraction of the English Wiktionary that currently\nsupports the following languages:\n\nDeutsch - German\nLatinum - Latin\n·ºôŒªŒªŒ∑ŒΩŒπŒ∫ŒÆ - Ancient Greek\nÌïúÍµ≠Ïñ¥ - Korean\nêé†êéºêéπ - Old Persian\níÄùíÖóíÅ∫íåë(íåù) - Akkadian\nElamite\n‡§∏‡§Ç‡§∏‡•ç‡§ï‡•É‡§§‡§Æ‡•ç - Sanskrit, or Classical Sanskrit\n\nwiktionary-data was originally a sub-module of wilhelm-graphdb. While\nthe dataset it's getting bigger, I noticed a wave of more exciting potentials this‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/QubitPi/wiktionary-data.","first_N":5,"first_N_keywords":["English","German","Latin","Ancient Greek (to 1453)","Korean"],"keywords_longer_than_N":true},
	{"name":"latin_italian_parallel","keyword":"latin","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Dddixyy/latin_italian_parallel","creator_name":"Davide Brunori","creator_url":"https://huggingface.co/Dddixyy","description":"\n\t\n\t\t\n\t\tItalian-Latin Parallel Corpus (30,000 Sentences)\n\t\n\n\nThis dataset provides approximately 30,000 parallel sentences between Italian and Latin. It is designed for tasks such as machine translation and cross-linguistic research.\n üåê The Creative Commons Attribution license allows re-distribution and re-use of a licensed work on the condition that the creator is appropriately credited.\n\n\t\n\t\t\n\t\n\t\n\t\tKey Features\n\t\n\n\nSize: ~30,000 translation pairs.\nLanguages: Italian (it), Latin (la).\nSource‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Dddixyy/latin_italian_parallel.","first_N":5,"first_N_keywords":["translation","Latin","Italian","cc-by-sa-4.0","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"latin_italian_parallel","keyword":"latin","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Dddixyy/latin_italian_parallel","creator_name":"Davide Brunori","creator_url":"https://huggingface.co/Dddixyy","description":"\n\t\n\t\t\n\t\tItalian-Latin Parallel Corpus (30,000 Sentences)\n\t\n\n\nThis dataset provides approximately 30,000 parallel sentences between Italian and Latin. It is designed for tasks such as machine translation and cross-linguistic research.\n üåê The Creative Commons Attribution license allows re-distribution and re-use of a licensed work on the condition that the creator is appropriately credited.\n\n\t\n\t\t\n\t\n\t\n\t\tKey Features\n\t\n\n\nSize: ~30,000 translation pairs.\nLanguages: Italian (it), Latin (la).\nSource‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Dddixyy/latin_italian_parallel.","first_N":5,"first_N_keywords":["translation","Latin","Italian","cc-by-sa-4.0","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"Everything_Instruct_Multilingual","keyword":"latin","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/rombodawg/Everything_Instruct_Multilingual","creator_name":"rombo dawg","creator_url":"https://huggingface.co/rombodawg","description":"\n\t\n\t\t\n\t\tEverything Instruct (Multilingual Edition)\n\t\n\nEverything you need... all in one place üíò\n\nEverything instruct (Multilingual Edition) is a massive alpaca instruct formatted dataset consisting of a wide variety of topics meant to bring LLM's to the next level in open source AI.\nNote: This dataset is fully uncensored (No model will refuse any request trained on this dataset unless otherwise aligned)\nNote2: This version of the dataset supports the following languages:\n\nEnglish\nRussian‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/rombodawg/Everything_Instruct_Multilingual.","first_N":5,"first_N_keywords":["English","Russian","Chinese","Korean","Urdu"],"keywords_longer_than_N":true},
	{"name":"Tridis","keyword":"latin","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/magistermilitum/Tridis","creator_name":"Sergio Torres","creator_url":"https://huggingface.co/magistermilitum","description":"This is the first version of the dataset derived from the corpora used for TRIDIS (Tria Digita Scribunt). \nTRIDIS encompasses a series of Handwriting Text Recognition (HTR) models trained using semi-diplomatic transcriptions of medieval and early modern manuscripts.\nThe semi-diplomatic transcription approach involves resolving abbreviations found in the original manuscripts and normalizing Punctuation and Allographs.\nThe dataset contains approximately 4,000 pages of manuscripts and is‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/magistermilitum/Tridis.","first_N":5,"first_N_keywords":["image-to-text","French","Spanish","Latin","German"],"keywords_longer_than_N":true},
	{"name":"muri-it-language-split","keyword":"latin","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/akoksal/muri-it-language-split","creator_name":"Abdullatif Koksal","creator_url":"https://huggingface.co/akoksal","description":"\n\t\n\t\t\n\t\tMURI-IT: Multilingual Instruction Tuning Dataset for 200 Languages via Multilingual Reverse Instructions\n\t\n\nMURI-IT is a large-scale multilingual instruction tuning dataset containing 2.2 million instruction-output pairs across 200 languages. It is designed to address the challenges of instruction tuning in low-resource languages with Multilingual Reverse Instructions (MURI), which ensures that the output is human-written, high-quality, and authentic to the cultural and linguistic‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/akoksal/muri-it-language-split.","first_N":5,"first_N_keywords":["text2text-generation","text-generation","question-answering","summarization","Achinese"],"keywords_longer_than_N":true},
	{"name":"medieval-letters","keyword":"latin","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/medieval-data/medieval-letters","creator_name":"Medieval Data","creator_url":"https://huggingface.co/medieval-data","description":"\n\t\n\t\t\n\t\tMedieval Letters Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset contains a collection of letters from prominent Carolingian scholars and ecclesiastical figures. The letters are sourced from the Patrologia Latina and were downloaded as XML from Corpus Corporum.\n\n\t\n\t\t\n\t\tData Source\n\t\n\nThe letters in this dataset are derived from the Patrologia Latina, a comprehensive collection of texts from the Church Fathers and other ecclesiastical writers. The XML versions of these texts were obtained‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/medieval-data/medieval-letters.","first_N":5,"first_N_keywords":["Latin","cc-by-sa-4.0","10K - 100K","parquet","Text"],"keywords_longer_than_N":true},
	{"name":"CC-100-Latin","keyword":"latin","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Cicciokr/CC-100-Latin","creator_name":"Francesco","creator_url":"https://huggingface.co/Cicciokr","description":"Cicciokr/CC-100-Latin dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["Latin","cc0-1.0","10M - 100M","text","Text"],"keywords_longer_than_N":true},
	{"name":"reranking-datasets-light","keyword":"latin","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/abdoelsayed/reranking-datasets-light","creator_name":"Abdelrahman Abdallah","creator_url":"https://huggingface.co/abdoelsayed","description":"\n\t\n\t\t\n\t\tüî• Rankify: A Comprehensive Python Toolkit for Retrieval, Re-Ranking, and Retrieval-Augmented Generation üî•\n\t\n\n\n\t\n\t\t\n\t\n\t\n\t\tReRanking Datasets : A comprehensive collection of retrieval and reranking datasets with full passage contexts, including titles, text, and metadata for in-depth research.\n\t\n\n\n    \n    \n    \n    \n    \n    \n        \n    \n    \n        \n    \n    \n        \n    \n    \n        \n    \n    \n    \n\n\n\nA curated collection of ready-to-use datasets for retrieval and reranking‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/abdoelsayed/reranking-datasets-light.","first_N":5,"first_N_keywords":["question-answering","English","Arabic","German","French"],"keywords_longer_than_N":true},
	{"name":"latin_author_dll_id","keyword":"latin","license":"GNU Affero General Public License v3.0","license_url":"https://choosealicense.com/licenses/agpl-3.0/","language":"en","dataset_url":"https://huggingface.co/datasets/sjhuskey/latin_author_dll_id","creator_name":"Samuel J. Huskey","creator_url":"https://huggingface.co/sjhuskey","description":"\n\t\n\t\t\n\t\tLatin Author Name to Digital Latin Library ID Concordance\n\t\n\nThis dataset contains variant names of authors of works in Latin and their corresponding identifier in the Digital Latin Library's Catalog.\nThe variant names were gathered from the Virtual International Authority File records for the authors. In instances where an author's name has few or no known variant name forms, pseudo-variant names were generated by \"misspelling\" the name using the following script:\nfrom textblob import‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/sjhuskey/latin_author_dll_id.","first_N":5,"first_N_keywords":["text-classification","English","Latin","agpl-3.0","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"VD-Metadata","keyword":"latin","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/SBB/VD-Metadata","creator_name":"Staatsbibliothek zu Berlin - Preu√üischer Kulturbesitz","creator_url":"https://huggingface.co/SBB","description":"\n\t\n\t\t\n\t\tMetadata of the \"Verzeichnis der im deutschen Sprachraum erschienen Drucke\"\n\t\n\n\n\t\n\t\t\n\t\tTitle\n\t\n\nMetadata of the \"Verzeichnis der im deutschen Sprachraum erschienen Drucke\"\n\n\t\n\t\t\n\t\tDescription and Motivation\n\t\n\nThis data publication was created with the intent to provide bibliographic and subject indexing metadata for research purposes and the development of AI applications. This data publication can be regarded as the German national bibliography of the period 1500‚Äì1800. It consists of‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/SBB/VD-Metadata.","first_N":5,"first_N_keywords":["text-classification","feature-extraction","German","Latin","Greek"],"keywords_longer_than_N":true},
	{"name":"MultiQ","keyword":"latin","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/caro-holt/MultiQ","creator_name":"Holtermann","creator_url":"https://huggingface.co/caro-holt","description":"\n\t\n\t\t\n\t\tDataset Card for MultiQ\n\t\n\nThis is the dataset corresponding to the paper \"Evaluating the Elementary Multilingual Capabilities of Large Language Models with MultiQ\". \nIt is a silver standard benchmark that can be used to evaluate the basic multilingual capabilities of LLMs. It contains 200 open ended questions automatically \ntranslated into 137 typologically diverse languages. \n\nCurated by: Carolin Holtermann, Paul R√∂ttger, Timm Dill, Anne Lauscher\nLanguage(s) (NLP): 137 diverse‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/caro-holt/MultiQ.","first_N":5,"first_N_keywords":["question-answering","Tagalog","Samoan","Macedonian","Gujarati"],"keywords_longer_than_N":true},
	{"name":"evalatin2024","keyword":"latin","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/adorkin/evalatin2024","creator_name":"Aleksei Dorkin","creator_url":"https://huggingface.co/adorkin","description":"\n\t\n\t\t\n\t\tTartuNLP at EvaLatin 2024: Emotion Polarity Detection\n\t\n\n\n\t\n\t\t\n\t\tBibTeX entry and citation info\n\t\n\n@inproceedings{dorkin-sirts-2024-tartunlp-evalatin,\n    title = \"{T}artu{NLP} at {E}va{L}atin 2024: Emotion Polarity Detection\",\n    author = \"Dorkin, Aleksei  and\n      Sirts, Kairit\",\n    editor = \"Sprugnoli, Rachele  and\n      Passarotti, Marco\",\n    booktitle = \"Proceedings of the Third Workshop on Language Technologies for Historical and Ancient Languages (LT4HALA) @‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/adorkin/evalatin2024.","first_N":5,"first_N_keywords":["text-classification","Latin","mit","10K - 100K","json"],"keywords_longer_than_N":true},
	{"name":"Himanis-line","keyword":"latin","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Teklia/Himanis-line","creator_name":"Teklia","creator_url":"https://huggingface.co/Teklia","description":"\n\t\n\t\t\n\t\tHimanis - line level\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nHimanis (HIstorical MANuscript Indexing for user controlled Search) is a corpus of medieval documents.\nThe historical corpus is described in the following publication:\nStutzmann, D., Moufflet, J-F., & Hamel, S. (2017). La recherche en plein texte dans les sources manuscrites m√©di√©vales‚ÄØ: enjeux et perspectives du projet HIMANIS pour l‚Äô√©dition √©lectronique. M√©di√©vales‚ÄØ: Langue, textes, histoire 73 (2017): 67‚Äë96.‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Teklia/Himanis-line.","first_N":5,"first_N_keywords":["image-to-text","Latin","French","mit","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"HOME-Alcar-line","keyword":"latin","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Teklia/HOME-Alcar-line","creator_name":"Teklia","creator_url":"https://huggingface.co/Teklia","description":"\n\t\n\t\t\n\t\tHOME-Alcar - line level\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThe HOME-Alcar (Aligned and Annotated Cartularies) dataset is a Medieval corpus. The 17 medieval manuscripts in this corpus are cartularies, i.e. books copying charters and legal acts, produced between the 12th and 14th centuries. \nThis dataset comes from the following publication:\nStutzmann, D., Torres Aguilar, S., & Chaffenet, P. (2021). HOME-Alcar: Aligned and Annotated Cartularies [Data set]. Zenodo.‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Teklia/HOME-Alcar-line.","first_N":5,"first_N_keywords":["image-to-text","Latin","mit","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"biblenlp-corpus-mmteb","keyword":"latin","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/davidstap/biblenlp-corpus-mmteb","creator_name":"David Stap","creator_url":"https://huggingface.co/davidstap","description":"This dataset pre-computes all English-centric directions from bible-nlp/biblenlp-corpus, and as a result loading is significantly faster.\nLoading example:\n>>> from datasets import load_dataset\n>>> dataset = load_dataset(\"davidstap/biblenlp-corpus-mmteb\", \"eng-arb\", trust_remote_code=True)\n>>> dataset\nDatasetDict({\n    train: Dataset({\n        features: ['eng', 'arb'],\n        num_rows: 28723\n    })\n    validation: Dataset({\n        features: ['eng', 'arb'],\n        num_rows: 1578\n    })‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/davidstap/biblenlp-corpus-mmteb.","first_N":5,"first_N_keywords":["no-annotation","expert-generated","translation","multilingual","Arifama-Miniafia"],"keywords_longer_than_N":true},
	{"name":"biblenlp-corpus-mmteb","keyword":"latin","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/davidstap/biblenlp-corpus-mmteb","creator_name":"David Stap","creator_url":"https://huggingface.co/davidstap","description":"This dataset pre-computes all English-centric directions from bible-nlp/biblenlp-corpus, and as a result loading is significantly faster.\nLoading example:\n>>> from datasets import load_dataset\n>>> dataset = load_dataset(\"davidstap/biblenlp-corpus-mmteb\", \"eng-arb\", trust_remote_code=True)\n>>> dataset\nDatasetDict({\n    train: Dataset({\n        features: ['eng', 'arb'],\n        num_rows: 28723\n    })\n    validation: Dataset({\n        features: ['eng', 'arb'],\n        num_rows: 1578\n    })‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/davidstap/biblenlp-corpus-mmteb.","first_N":5,"first_N_keywords":["no-annotation","expert-generated","translation","multilingual","Arifama-Miniafia"],"keywords_longer_than_N":true},
	{"name":"panlex","keyword":"latin","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/lbourdois/panlex","creator_name":"Lo√Øck BOURDOIS","creator_url":"https://huggingface.co/lbourdois","description":"\n\t\n\t\t\n\t\tPanLex\n\t\n\nJanuary 1, 2024 version of PanLex Language Vocabulary with 24,650,274 rows covering 6,152 languages.\n\n\t\n\t\t\n\t\tColumns\n\t\n\n\nvocab: contains the text entry.  \n639-3: contains the ISO 639-3 languages tags to allow users to filter on the language(s) of their choice.\n639-3_english_name: the English language name associated to the code ISO 639-3. \nvar_code: contains a code to differentiate language variants. In practice, this is the code 639-3 + a number.  If 000, it corresponds to‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/lbourdois/panlex.","first_N":5,"first_N_keywords":["Ghotuo","Alumu-Tesu","Ari","Amal","Arb√´resh√´ Albanian"],"keywords_longer_than_N":true},
	{"name":"panlex-meanings","keyword":"latin","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/cointegrated/panlex-meanings","creator_name":"David Dale","creator_url":"https://huggingface.co/cointegrated","description":"\n\t\n\t\t\n\t\tDataset Card for panlex-meanings\n\t\n\nThis is a dataset of words in several thousand languages, extracted from https://panlex.org.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset has been extracted from https://panlex.org (the 20240301 database dump) and rearranged on the per-language basis.\nEach language subset consists of expressions (words and phrases). \nEach expression is associated with some meanings (if there is more than one meaning, they are in separate‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/cointegrated/panlex-meanings.","first_N":5,"first_N_keywords":["translation","Afar","Western Abnaki","Abkhazian","Abaza"],"keywords_longer_than_N":true},
	{"name":"biblenlp-corpus-mmteb","keyword":"latin","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/biblenlp-corpus-mmteb","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"This dataset pre-computes all English-centric directions from bible-nlp/biblenlp-corpus, and as a result loading is significantly faster.\nLoading example:\n>>> from datasets import load_dataset\n>>> dataset = load_dataset(\"davidstap/biblenlp-corpus-mmteb\", \"eng-arb\", trust_remote_code=True)\n>>> dataset\nDatasetDict({\n    train: Dataset({\n        features: ['eng', 'arb'],\n        num_rows: 28723\n    })\n    validation: Dataset({\n        features: ['eng', 'arb'],\n        num_rows: 1578\n    })‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/biblenlp-corpus-mmteb.","first_N":5,"first_N_keywords":["no-annotation","expert-generated","translation","multilingual","Arifama-Miniafia"],"keywords_longer_than_N":true},
	{"name":"biblenlp-corpus-mmteb","keyword":"latin","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/biblenlp-corpus-mmteb","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"This dataset pre-computes all English-centric directions from bible-nlp/biblenlp-corpus, and as a result loading is significantly faster.\nLoading example:\n>>> from datasets import load_dataset\n>>> dataset = load_dataset(\"davidstap/biblenlp-corpus-mmteb\", \"eng-arb\", trust_remote_code=True)\n>>> dataset\nDatasetDict({\n    train: Dataset({\n        features: ['eng', 'arb'],\n        num_rows: 28723\n    })\n    validation: Dataset({\n        features: ['eng', 'arb'],\n        num_rows: 1578\n    })‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/biblenlp-corpus-mmteb.","first_N":5,"first_N_keywords":["no-annotation","expert-generated","translation","multilingual","Arifama-Miniafia"],"keywords_longer_than_N":true},
	{"name":"modern","keyword":"latin","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/CATMuS/modern","creator_name":"CATMuS: Consistent Approach to Transcribing ManuScripts","creator_url":"https://huggingface.co/CATMuS","description":"\n\n\t\n\t\t\n\t\tDataset Card for CATMuS Modern and Contemporary (McCATMuS)\n\t\n\nJoin our Discord to ask questions about the dataset: \n\n\t\n\t\t\n\t\tDataset Details\n\t\n\nHandwritten Text Recognition (HTR) has emerged as a crucial tool for converting manuscripts images into machine-readable formats, enabling researchers and scholars to analyze vast collections efficiently. Despite significant technological progress, establishing consistent ground truth across projects for HTR tasks, particularly for complex and‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/CATMuS/modern.","first_N":5,"first_N_keywords":["image-to-text","French","German","English","Italian"],"keywords_longer_than_N":true},
	{"name":"GlotCC-V1","keyword":"latin","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/cis-lmu/GlotCC-V1","creator_name":"CIS, LMU Munich","creator_url":"https://huggingface.co/cis-lmu","description":"\n\t\n\t\t\n\t\tDataset Summary\n\t\n\n \n\nGlotCC-V1.0 is a document-level, general domain dataset derived from CommonCrawl, covering more than 1000 languages.It is built using the GlotLID language identification and Ungoliant pipeline from CommonCrawl.We release our pipeline as open-source at https://github.com/cisnlp/GlotCC.  \nList of Languages: See https://datasets-server.huggingface.co/splits?dataset=cis-lmu/GlotCC-V1 to get the list of splits available.\n\n\t\t\n\t\tUsage (Huggingface Hub -- Recommended)‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/cis-lmu/GlotCC-V1.","first_N":5,"first_N_keywords":["multilingual","Abau","Amarasi","Abkhaz","Abkhazian"],"keywords_longer_than_N":true},
	{"name":"GlotCC-V1","keyword":"latin","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/cis-lmu/GlotCC-V1","creator_name":"CIS, LMU Munich","creator_url":"https://huggingface.co/cis-lmu","description":"\n\t\n\t\t\n\t\tDataset Summary\n\t\n\n \n\nGlotCC-V1.0 is a document-level, general domain dataset derived from CommonCrawl, covering more than 1000 languages.It is built using the GlotLID language identification and Ungoliant pipeline from CommonCrawl.We release our pipeline as open-source at https://github.com/cisnlp/GlotCC.  \nList of Languages: See https://datasets-server.huggingface.co/splits?dataset=cis-lmu/GlotCC-V1 to get the list of splits available.\n\n\t\t\n\t\tUsage (Huggingface Hub -- Recommended)‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/cis-lmu/GlotCC-V1.","first_N":5,"first_N_keywords":["multilingual","Abau","Amarasi","Abkhaz","Abkhazian"],"keywords_longer_than_N":true},
	{"name":"Italian_latin_parallel_animals","keyword":"latin","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Dddixyy/Italian_latin_parallel_animals","creator_name":"Davide Brunori","creator_url":"https://huggingface.co/Dddixyy","description":"\n\t\n\t\t\n\t\tdescrizioni di animali e habitat - Synthetic Dataset\n\t\n\nThis dataset was generated using the Synthetic Dataset Generator powered by Gemini AI.\n\nTopic: descrizioni di animali e habitat\nField 1: italiano\nField 2: latino antico(traduzione)\nRows: 280\n\nGenerated on: 2025-05-27T00:07:49.042Z\n","first_N":5,"first_N_keywords":["text-generation","Italian","Latin","mit","< 1K"],"keywords_longer_than_N":true},
	{"name":"greek_latin_authors","keyword":"latin","license":"GNU Affero General Public License v3.0","license_url":"https://choosealicense.com/licenses/agpl-3.0/","language":"en","dataset_url":"https://huggingface.co/datasets/sjhuskey/greek_latin_authors","creator_name":"Samuel J. Huskey","creator_url":"https://huggingface.co/sjhuskey","description":"\n\t\n\t\t\n\t\tGreek and Latin Authors\n\t\n\nThis dataset contains the names of authors who primarily wrote in Ancient Greek (labeled \"Greek\") \nand authors who primarily wrote in Latin (labeled \"Latin\").\nThe Greek names were gathered from the Thesaurus Linguae Graecae (TLG) project.\nSpecifically, the TLG makes lists of authors openly available at https://stephanus.tlg.uci.edu/tlgauthors/post_tlg_e.php\nand https://stephanus.tlg.uci.edu/tlgauthors/cd.authors.php. These names were supplemented by names‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/sjhuskey/greek_latin_authors.","first_N":5,"first_N_keywords":["text-classification","English","Greek","Latin","agpl-3.0"],"keywords_longer_than_N":true},
	{"name":"V1Q","keyword":"latin","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/YuRiVeRTi/V1Q","creator_name":"YuRiVeRTical","creator_url":"https://huggingface.co/YuRiVeRTi","description":"from datasets import load_dataset\nds = load_dataset(\"b3x0m/Chinese-H-Novels\")\nimport sagemaker\nimport boto3\nfrom sagemaker.huggingface import HuggingFaceModel\ntry:\n    role = sagemaker.get_execution_role()\nexcept ValueError:\n    iam = boto3.client('iam')\n    role = iam.get_role(RoleName='sagemaker_execution_role')['Role']['Arn']\n\n\t\n\t\t\n\t\tHub Model configuration. https://huggingface.co/models\n\t\n\nhub = {\n    'HF_MODEL_ID':'deepseek-ai/Janus-Pro-7B',\n    'HF_TASK':'any-to-any'\n}\n\n\t\n\t\t\n\t\tcreate‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/YuRiVeRTi/V1Q.","first_N":5,"first_N_keywords":["text-classification","token-classification","table-question-answering","question-answering","zero-shot-classification"],"keywords_longer_than_N":true},
	{"name":"PleIAs-ToxicCommons","keyword":"latin","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/agentlans/PleIAs-ToxicCommons","creator_name":"Alan Tseng","creator_url":"https://huggingface.co/agentlans","description":"\n\t\n\t\t\n\t\tPleIAs/ToxicCommons\n\t\n\nThis dataset is a refined version of the PleIAs/ToxicCommons collection, focusing on historical texts labeled for content that may be considered objectionable by modern standards (what the authors of the dataset deem \"toxic\"). \nThe cleaned dataset contains 1‚Äâ051‚Äâ027 rows, each representing a text sample with associated toxicity scores across five dimensions:\n\nRace and origin-based bias\nGender and sexuality-based bias\nReligious bias\nAbility bias\nViolence and abuse‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/agentlans/PleIAs-ToxicCommons.","first_N":5,"first_N_keywords":["text-classification","English","French","Spanish","German"],"keywords_longer_than_N":true},
	{"name":"multilingual_translation_gen_binarized","keyword":"latin","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Youseff1987/multilingual_translation_gen_binarized","creator_name":"JOON HYOUNG JUN","creator_url":"https://huggingface.co/Youseff1987","description":"Youseff1987/multilingual_translation_gen_binarized dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["translation","Korean","English","Chinese","Zulu"],"keywords_longer_than_N":true},
	{"name":"wikipedia_quality_wikirank","keyword":"latin","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/lewoniewski/wikipedia_quality_wikirank","creator_name":"W≈Çodzimierz Lewoniewski","creator_url":"https://huggingface.co/lewoniewski","description":"Datasets with WikiRank quality score as of 1 August 2024 for 47 million Wikipedia articles in 55 language versions (also simplified version for each language in separate files).\nThe WikiRank quality score is a metric designed to assess the overall quality of a Wikipedia article. Although its specific algorithm can vary depending on the implementation, the score typically combines several key features of the Wikipedia article.\n\n\t\n\t\t\n\t\n\t\n\t\tWhy It‚Äôs Important\n\t\n\n\nEnhances Trust: For readers and‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/lewoniewski/wikipedia_quality_wikirank.","first_N":5,"first_N_keywords":["Arabic","Azerbaijani","Belarusian","Bulgarian","Catalan"],"keywords_longer_than_N":true},
	{"name":"multilingual_translation_sft","keyword":"latin","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Youseff1987/multilingual_translation_sft","creator_name":"JOON HYOUNG JUN","creator_url":"https://huggingface.co/Youseff1987","description":"Youseff1987/multilingual_translation_sft dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["translation","Korean","English","Chinese","Zulu"],"keywords_longer_than_N":true},
	{"name":"fishmt5","keyword":"latin","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/MHBS-IHB/fishmt5","creator_name":"Museum of Hydrobiological Sciences, Institute of Hydrobiology, Chinese Academy of Sciences","creator_url":"https://huggingface.co/MHBS-IHB","description":"\n\t\n\t\t\n\t\tFish Names Chinese-Latin Parallel Corpora\n\t\n\n\n\t\n\t\t\n\t\tDataset Overview\n\t\n\nWe curated over 60,000 authoritative Chinese-Latin bilingual parallel corpora for fish names by integrating cross-source data, including Eschmeyer's Catalog of Fishes online database. Using a dual translation approach, we applied the Multilingual Text-to-Text Transfer Transformer (mT5) model to generate missing Chinese names.\nNote: The current release provides 10,000 paired data entries.\n\n\t\n\t\t\n\t\tDataset Details‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/MHBS-IHB/fishmt5.","first_N":5,"first_N_keywords":["translation","Chinese","Latin","apache-2.0","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"panlex-definitions","keyword":"latin","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/cointegrated/panlex-definitions","creator_name":"David Dale","creator_url":"https://huggingface.co/cointegrated","description":"\n\t\n\t\t\n\t\tDataset Card for panlex-definitions\n\t\n\nThis is a dataset of word definitions in several hudnred languages, extracted from https://panlex.org.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset has been extracted from https://panlex.org (the 20250201 database dump) and rearranged on the per-language basis (by the language of the definition).\nEach language subset consists of definitions (short phrases).\nEach definition is associated with some meanings (if there is‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/cointegrated/panlex-definitions.","first_N":5,"first_N_keywords":["translation","Abkhazian","Hijazi Arabic","Afrikaans","Ainu (Japan)"],"keywords_longer_than_N":true}
]
;
