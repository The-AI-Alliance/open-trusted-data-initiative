const data_for_language_europe_bavarian = 
[
	{"name":"wikipedia-monthly","keyword":"bavarian","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/omarkamali/wikipedia-monthly","creator_name":"Omar Kamali","creator_url":"https://huggingface.co/omarkamali","description":"\n\t\n\t\t\n\t\tüöÄ Wikipedia Monthly\n\t\n\nLast updated: July 16, 2025, 22:53 UTC\nThis repository provides monthly, multilingual dumps of Wikipedia, processed and prepared for easy use in NLP projects.\nNOTE: The first run is still in progress and languages are still being processed and uploaded.\n\n\n\t\n\t\t\n\t\tüìä Live Statistics\n\t\n\n\n\t\n\t\t\nMetric\nValue\n\n\n\t\t\nüåç Languages Available\n341\n\n\nüìÑ Total Articles\n64.5M\n\n\nüíæ Total Size\n205.54 GB\n\n\n\t\n\n\n\n\t\n\t\t\n\t\tWhy Use This Dataset?\n\t\n\n\nFreshness: We run our pipeline monthly‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/omarkamali/wikipedia-monthly.","first_N":5,"first_N_keywords":["Abkhaz","Achinese","Adyghe","Afrikaans","Akan"],"keywords_longer_than_N":true},
	{"name":"wit_base","keyword":"bavarian","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/wikimedia/wit_base","creator_name":"Wikimedia","creator_url":"https://huggingface.co/wikimedia","description":"\n\t\n\t\t\n\t\tDataset Card for WIT\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nWikimedia's version of the Wikipedia-based Image Text (WIT) Dataset, a large multimodal multilingual dataset.\nFrom the official blog post:\n\nThe core training data is taken from the Wikipedia Image-Text (WIT) Dataset, a large curated set of more than 37 million image-text associations extracted from Wikipedia articles in 108 languages that was recently released by Google Research.\nThe WIT dataset offers extremely valuable data about the‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/wikimedia/wit_base.","first_N":5,"first_N_keywords":["image-to-text","text-retrieval","image-captioning","machine-generated","found"],"keywords_longer_than_N":true},
	{"name":"wikianc","keyword":"bavarian","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/cyanic-selkie/wikianc","creator_name":"cyanic-selkie","creator_url":"https://huggingface.co/cyanic-selkie","description":"\n\t\n\t\t\n\t\tDataset Card for WikiAnc\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThe WikiAnc dataset is an automatically generated dataset from Wikipedia (all languages) and Wikidata dumps (August, 2023). \nThe code for generating the dataset can be found here.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\n\nwikificiation: The dataset can be used to train a model for Wikification.\nnamed-entity-linking: The dataset can be used to train a model for Named Entity Linking.\n\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nThe text in the dataset is in all 320‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/cyanic-selkie/wikianc.","first_N":5,"first_N_keywords":["token-classification","machine-generated","crowdsourced","machine-generated","crowdsourced"],"keywords_longer_than_N":true},
	{"name":"language_tags","keyword":"bavarian","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/lbourdois/language_tags","creator_name":"Lo√Øck BOURDOIS","creator_url":"https://huggingface.co/lbourdois","description":"\n\t\n\t\t\n\t\tDescription\n\t\n\nDataset listing 27,328 languages and dialects (also includes macrolanguage names).For each language, either the ISO 639 code, the Glottolog code or both are provided.\n\n\t\n\t\t\n\t\tColumns\n\t\n\n\nEnglish_Name: Language name in English (e.g. \"French\").\nNative_Name: If value is not 0, corresponds to the name of the language by native speakers (e.g. \"Fran√ßais\") which may have been found in Wikipedia's nativename field.\nGlottocode: The language tag in the Glottolog convention (e.g.‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/lbourdois/language_tags.","first_N":5,"first_N_keywords":["Afade","Par√° Ar√°ra","Afar","Aka-Bea","Abon"],"keywords_longer_than_N":true},
	{"name":"panlex-meanings","keyword":"bavarian","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/cointegrated/panlex-meanings","creator_name":"David Dale","creator_url":"https://huggingface.co/cointegrated","description":"\n\t\n\t\t\n\t\tDataset Card for panlex-meanings\n\t\n\nThis is a dataset of words in several thousand languages, extracted from https://panlex.org.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset has been extracted from https://panlex.org (the 20240301 database dump) and rearranged on the per-language basis.\nEach language subset consists of expressions (words and phrases). \nEach expression is associated with some meanings (if there is more than one meaning, they are in separate‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/cointegrated/panlex-meanings.","first_N":5,"first_N_keywords":["translation","Afar","Western Abnaki","Abkhazian","Abaza"],"keywords_longer_than_N":true},
	{"name":"panlex","keyword":"bavarian","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/lbourdois/panlex","creator_name":"Lo√Øck BOURDOIS","creator_url":"https://huggingface.co/lbourdois","description":"\n\t\n\t\t\n\t\tPanLex\n\t\n\nJanuary 1, 2024 version of PanLex Language Vocabulary with 24,650,274 rows covering 6,152 languages.\n\n\t\n\t\t\n\t\tColumns\n\t\n\n\nvocab: contains the text entry.  \n639-3: contains the ISO 639-3 languages tags to allow users to filter on the language(s) of their choice.\n639-3_english_name: the English language name associated to the code ISO 639-3. \nvar_code: contains a code to differentiate language variants. In practice, this is the code 639-3 + a number.  If 000, it corresponds to‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/lbourdois/panlex.","first_N":5,"first_N_keywords":["Ghotuo","Alumu-Tesu","Ari","Amal","Arb√´resh√´ Albanian"],"keywords_longer_than_N":true},
	{"name":"GlotCC-V1","keyword":"bavarian","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/cis-lmu/GlotCC-V1","creator_name":"CIS, LMU Munich","creator_url":"https://huggingface.co/cis-lmu","description":"\n\t\n\t\t\n\t\tDataset Summary\n\t\n\n \n\nGlotCC-V1.0 is a document-level, general domain dataset derived from CommonCrawl, covering more than 1000 languages.It is built using the GlotLID language identification and Ungoliant pipeline from CommonCrawl.We release our pipeline as open-source at https://github.com/cisnlp/GlotCC.  \nList of Languages: See https://datasets-server.huggingface.co/splits?dataset=cis-lmu/GlotCC-V1 to get the list of splits available.\n\n\t\t\n\t\tUsage (Huggingface Hub -- Recommended)‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/cis-lmu/GlotCC-V1.","first_N":5,"first_N_keywords":["multilingual","Abau","Amarasi","Abkhaz","Abkhazian"],"keywords_longer_than_N":true},
	{"name":"ParaNames","keyword":"bavarian","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/bltlab/ParaNames","creator_name":"Broadening Linguistic Technologies Lab (BLT Lab)","creator_url":"https://huggingface.co/bltlab","description":"\n\t\n\t\t\n\t\n\t\n\t\tDataset Card for Dataset Name\n\t\n\n\n\nThis dataset card aims to be a base template for new datasets. It has been generated using this raw template.\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Description\n\t\n\n\n\n\n\n\nCurated by: [More Information Needed]\nFunded by [optional]: [More Information Needed]\nShared by [optional]: [More Information Needed]\nLanguage(s) (NLP): [More Information Needed]\nLicense: [More Information Needed]\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Sources [optional]‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/bltlab/ParaNames.","first_N":5,"first_N_keywords":["token-classification","Nias","Kotava","Banjar","Angika"],"keywords_longer_than_N":true},
	{"name":"muri-it-language-split","keyword":"bavarian","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/akoksal/muri-it-language-split","creator_name":"Abdullatif Koksal","creator_url":"https://huggingface.co/akoksal","description":"\n\t\n\t\t\n\t\tMURI-IT: Multilingual Instruction Tuning Dataset for 200 Languages via Multilingual Reverse Instructions\n\t\n\nMURI-IT is a large-scale multilingual instruction tuning dataset containing 2.2 million instruction-output pairs across 200 languages. It is designed to address the challenges of instruction tuning in low-resource languages with Multilingual Reverse Instructions (MURI), which ensures that the output is human-written, high-quality, and authentic to the cultural and linguistic‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/akoksal/muri-it-language-split.","first_N":5,"first_N_keywords":["text-generation","question-answering","summarization","Achinese","Adyghe"],"keywords_longer_than_N":true},
	{"name":"muri-it","keyword":"bavarian","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/akoksal/muri-it","creator_name":"Abdullatif Koksal","creator_url":"https://huggingface.co/akoksal","description":"\n\t\n\t\t\n\t\tMURI-IT: Multilingual Instruction Tuning Dataset for 200 Languages via Multilingual Reverse Instructions\n\t\n\nMURI-IT is a large-scale multilingual instruction tuning dataset containing 2.2 million instruction-output pairs across 200 languages. It is designed to address the challenges of instruction tuning in low-resource languages with Multilingual Reverse Instructions (MURI), which ensures that the output is human-written, high-quality, and authentic to the cultural and linguistic‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/akoksal/muri-it.","first_N":5,"first_N_keywords":["text-generation","question-answering","summarization","Achinese","Adyghe"],"keywords_longer_than_N":true},
	{"name":"barwiki-20250701","keyword":"bavarian","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/bavarian-nlp/barwiki-20250701","creator_name":"Bavarian NLP","creator_url":"https://huggingface.co/bavarian-nlp","description":"\n\t\n\t\t\n\t\tBavarian Wikipedia Dump\n\t\n\nThis datasets hosts a recent Bavarian Wikipedia Dump that is used for various experiments within the Bavarian NLP organization.\n\n\t\n\t\t\n\t\tDataset Creation\n\t\n\nThe latest dump was downloaded with:\nwget https://dumps.wikimedia.org/barwiki/20250701/barwiki-20250701-pages-articles.xml.bz2\n\nThen a patched version of WikiExtractor was used (with Python 3.12.3 - newer versions were not working) to extract all articles into JSONL:\npython3 -m wikiextractor.WikiExtractor‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/bavarian-nlp/barwiki-20250701.","first_N":5,"first_N_keywords":["Bavarian","cc-by-sa-4.0","10K - 100K","json","Text"],"keywords_longer_than_N":true},
	{"name":"gemini-bavarian-tagesschau-v0.1","keyword":"bavarian","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/bavarian-nlp/gemini-bavarian-tagesschau-v0.1","creator_name":"Bavarian NLP","creator_url":"https://huggingface.co/bavarian-nlp","description":"\n\t\n\t\t\n\t\tGemini-powered Bavarian Tagesschau Dataset\n\t\n\n\nThis dataset hosts various 2024 Tagesschau articles from the Awesome Tagesschau dataset that were translated into Bavarian with Gemini 2.5 Flash.\nThe resulting dataset has 12,546 Bavarian articles in total, including metadata information like tags or ressort/topic.\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Format\n\t\n\nHere's an example of the JSON format, that is used for this dataset:\n{\n\"sophoraId\": \"eilmeldung-ampelregierung-scholz-entlaesst-lindner-100\"‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/bavarian-nlp/gemini-bavarian-tagesschau-v0.1.","first_N":5,"first_N_keywords":["summarization","Bavarian","apache-2.0","10K - 100K","json"],"keywords_longer_than_N":true},
	{"name":"barwiki-20250620","keyword":"bavarian","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/bavarian-nlp/barwiki-20250620","creator_name":"Bavarian NLP","creator_url":"https://huggingface.co/bavarian-nlp","description":"\n\t\n\t\t\n\t\tBavarian Wikipedia Dump\n\t\n\nThis datasets hosts a recent Bavarian Wikipedia Dump that is used for various experiments within the Bavarian NLP organization.\n\n\t\n\t\t\n\t\tDataset Creation\n\t\n\nThe latest dump was downloaded with:\nwget https://dumps.wikimedia.org/barwiki/20250620/barwiki-20250620-pages-articles.xml.bz2\n\nThen a patched version of WikiExtractor was used (with Python 3.12.3 - newer versions were not working) to extract all articles into JSONL:\npython3 -m wikiextractor.WikiExtractor‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/bavarian-nlp/barwiki-20250620.","first_N":5,"first_N_keywords":["Bavarian","cc-by-sa-4.0","10K - 100K","json","Text"],"keywords_longer_than_N":true},
	{"name":"gemini-bavarian-ner-v0.1","keyword":"bavarian","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/bavarian-nlp/gemini-bavarian-ner-v0.1","creator_name":"Bavarian NLP","creator_url":"https://huggingface.co/bavarian-nlp","description":"\n\t\n\t\t\n\t\tGemini-powered Bavarian NER Dataset\n\t\n\nInspired by GLiNER models and its used datasets, we present a Gemini-powered NER Dataset for Bavarian.\nThe dataset currently features 116,075 sentences from Bavarian Wikipedia, where named entities are found using Gemini 2.0 Flash.\n\n\t\n\t\t\n\t\tChangelog\n\t\n\n\n03.07.2025: Initial version of the dataset and public release.\n\n\n\t\n\t\t\n\t\tTemplate\n\t\n\nThankfully, the GLiNER-X community shared their prompt for generating datasets that were used for training the‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/bavarian-nlp/gemini-bavarian-ner-v0.1.","first_N":5,"first_N_keywords":["token-classification","Bavarian","cc-by-sa-4.0","100K - 1M","json"],"keywords_longer_than_N":true},
	{"name":"gliner-bavarian-v0.1","keyword":"bavarian","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/bavarian-nlp/gliner-bavarian-v0.1","creator_name":"Bavarian NLP","creator_url":"https://huggingface.co/bavarian-nlp","description":"\n\t\n\t\t\n\t\tGLiNER Dataset for Bavarian\n\t\n\nThis datasets hosts the Gemini-powered Bavarian NER Dataset in a GLiNER-compatible format.\n\n\t\n\t\t\n\t\tChangelog\n\t\n\n\n03.07.2025: Initial version of the dataset and public release.\n\n\n\t\n\t\t\n\t\tDataset Conversion\n\t\n\nWe use this notebook to convert the original dataset into a GLiNER-compatible one.\n\n\t\n\t\t\n\t\tStats\n\t\n\nThe original dataset consists of 116,075 sentences. After the conversion into the GLiNER-compatible format, the dataset consists of 116,073 sentences‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/bavarian-nlp/gliner-bavarian-v0.1.","first_N":5,"first_N_keywords":["token-classification","Bavarian","cc-by-sa-4.0","100K<n<1M","üá∫üá∏ Region: US"],"keywords_longer_than_N":false},
	{"name":"gemini-bavarian-bible","keyword":"bavarian","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/bavarian-nlp/gemini-bavarian-bible","creator_name":"Bavarian NLP","creator_url":"https://huggingface.co/bavarian-nlp","description":"\n\t\n\t\t\n\t\tGemini-powered Bavarian Bible\n\t\n\nThis datasets hosts a translated version of the Public Domain Luther Bible from 1912 from ebible.org. The recently released Gemini 2.5 Pro model was used to translate the German version of the Luther bible into Bavarian.\n\n\t\n\t\t\n\t\tDataset Format\n\t\n\nHere's an example of the JSON format, that is used for this dataset:\n{\n  \"id\": \"deu1912_002_GEN_01\",\n  \"text\": \"As 1. Buach Mose (Genesis).\\n1.\\nAm Ofang hot da Herrgott an Himme und d'Erdn gschaffa...\"\n}\n\nThe‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/bavarian-nlp/gemini-bavarian-bible.","first_N":5,"first_N_keywords":["Bavarian","apache-2.0","1K - 10K","json","Text"],"keywords_longer_than_N":true}
]
;
