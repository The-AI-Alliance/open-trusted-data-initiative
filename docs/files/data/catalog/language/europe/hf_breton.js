const data_for_language_europe_breton = 
[
	{"name":"panlex","keyword":"breton","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/lbourdois/panlex","creator_name":"LoÃ¯ck BOURDOIS","creator_url":"https://huggingface.co/lbourdois","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tPanLex\\n\\t\\n\\nJanuary 1, 2024 version of PanLex Language Vocabulary with 24,650,274 rows covering 6,152 languages.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tColumns\\n\\t\\n\\n\\nvocab: contains the text entry.  \\n639-3: contains the ISO 639-3 languages tags to allow users to filter on the language(s) of their choice.\\n639-3_english_name: the English language name associated to the code ISO 639-3. \\nvar_code: contains a code to differentiate language variants. In practice, this is the code 639-3 + a number.  If 000, itâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/lbourdois/panlex."},
	{"name":"web-sentences-br","keyword":"breton","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/gweltou/web-sentences-br","creator_name":"Gweltaz Duval-Guennoc","creator_url":"https://huggingface.co/gweltou","description":"Breton sentences from the public web. Filtered and deduplicated.\\nMostly KLT orthography.\\nAround 1M words.\\n"},
	{"name":"panlex-meanings","keyword":"breton","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/cointegrated/panlex-meanings","creator_name":"David Dale","creator_url":"https://huggingface.co/cointegrated","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for panlex-meanings\\n\\t\\n\\nThis is a dataset of words in several thousand languages, extracted from https://panlex.org.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Details\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThis dataset has been extracted from https://panlex.org (the 20240301 database dump) and rearranged on the per-language basis.\\nEach language subset consists of expressions (words and phrases). \\nEach expression is associated with some meanings (if there is more than one meaning, they are inâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/cointegrated/panlex-meanings."},
	{"name":"biblenlp-corpus-mmteb","keyword":"breton","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/davidstap/biblenlp-corpus-mmteb","creator_name":"David Stap","creator_url":"https://huggingface.co/davidstap","description":"This dataset pre-computes all English-centric directions from bible-nlp/biblenlp-corpus, and as a result loading is significantly faster.\\nLoading example:\\n>>> from datasets import load_dataset\\n>>> dataset = load_dataset(\\\"davidstap/biblenlp-corpus-mmteb\\\", \\\"eng-arb\\\", trust_remote_code=True)\\n>>> dataset\\nDatasetDict({\\n    train: Dataset({\\n        features: ['eng', 'arb'],\\n        num_rows: 28723\\n    })\\n    validation: Dataset({\\n        features: ['eng', 'arb'],\\n        num_rows: 1578\\n    })â€¦ See the full description on the dataset page: https://huggingface.co/datasets/davidstap/biblenlp-corpus-mmteb."},
	{"name":"biblenlp-corpus-mmteb","keyword":"breton","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/davidstap/biblenlp-corpus-mmteb","creator_name":"David Stap","creator_url":"https://huggingface.co/davidstap","description":"This dataset pre-computes all English-centric directions from bible-nlp/biblenlp-corpus, and as a result loading is significantly faster.\\nLoading example:\\n>>> from datasets import load_dataset\\n>>> dataset = load_dataset(\\\"davidstap/biblenlp-corpus-mmteb\\\", \\\"eng-arb\\\", trust_remote_code=True)\\n>>> dataset\\nDatasetDict({\\n    train: Dataset({\\n        features: ['eng', 'arb'],\\n        num_rows: 28723\\n    })\\n    validation: Dataset({\\n        features: ['eng', 'arb'],\\n        num_rows: 1578\\n    })â€¦ See the full description on the dataset page: https://huggingface.co/datasets/davidstap/biblenlp-corpus-mmteb."},
	{"name":"wikipedia-br-20240325","keyword":"breton","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/gweltou/wikipedia-br-20240325","creator_name":"Gweltaz Duval-Guennoc","creator_url":"https://huggingface.co/gweltou","description":"A corpus of sentences extracted for the Breton Wikipedia (cirrus dump).\\nThe sentences were filtered so that only Breton sentences were kept.\\nPlease note that the sentence splitting algorithm is far from perfect, so many sentences will appear incorrect or incomplete.\\n"},
	{"name":"biblenlp-corpus-mmteb","keyword":"breton","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/biblenlp-corpus-mmteb","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"This dataset pre-computes all English-centric directions from bible-nlp/biblenlp-corpus, and as a result loading is significantly faster.\\nLoading example:\\n>>> from datasets import load_dataset\\n>>> dataset = load_dataset(\\\"davidstap/biblenlp-corpus-mmteb\\\", \\\"eng-arb\\\", trust_remote_code=True)\\n>>> dataset\\nDatasetDict({\\n    train: Dataset({\\n        features: ['eng', 'arb'],\\n        num_rows: 28723\\n    })\\n    validation: Dataset({\\n        features: ['eng', 'arb'],\\n        num_rows: 1578\\n    })â€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/biblenlp-corpus-mmteb."},
	{"name":"biblenlp-corpus-mmteb","keyword":"breton","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/biblenlp-corpus-mmteb","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"This dataset pre-computes all English-centric directions from bible-nlp/biblenlp-corpus, and as a result loading is significantly faster.\\nLoading example:\\n>>> from datasets import load_dataset\\n>>> dataset = load_dataset(\\\"davidstap/biblenlp-corpus-mmteb\\\", \\\"eng-arb\\\", trust_remote_code=True)\\n>>> dataset\\nDatasetDict({\\n    train: Dataset({\\n        features: ['eng', 'arb'],\\n        num_rows: 28723\\n    })\\n    validation: Dataset({\\n        features: ['eng', 'arb'],\\n        num_rows: 1578\\n    })â€¦ See the full description on the dataset page: https://huggingface.co/datasets/mteb/biblenlp-corpus-mmteb."},
	{"name":"ParaNames","keyword":"breton","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/bltlab/ParaNames","creator_name":"Broadening Linguistic Technologies Lab (BLT Lab)","creator_url":"https://huggingface.co/bltlab","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Dataset Name\\n\\t\\n\\n\\n\\nThis dataset card aims to be a base template for new datasets. It has been generated using this raw template.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Details\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\n\\n\\n\\n\\n\\nCurated by: [More Information Needed]\\nFunded by [optional]: [More Information Needed]\\nShared by [optional]: [More Information Needed]\\nLanguage(s) (NLP): [More Information Needed]\\nLicense: [More Information Needed]\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Sources [optional]â€¦ See the full description on the dataset page: https://huggingface.co/datasets/bltlab/ParaNames."},
	{"name":"xP3x-Kongo","keyword":"breton","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Svngoku/xP3x-Kongo","creator_name":"NIONGOLO Chrys FÃ©-Marty","creator_url":"https://huggingface.co/Svngoku","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for xP3x Kikongo Focus\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\n\\nxP3x (Crosslingual Public Pool of Prompts eXtended) is a collection of prompts & datasets across 277 languages & 16 NLP tasks. It contains all of xP3 + much more! It is used for training future contenders of mT0 & BLOOMZ at project Aya @C4AI ðŸ§¡\\n\\n\\nCreation: The dataset can be recreated using instructions available here together with the file in this repository named xp3x_create.py. We provide this version to saveâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Svngoku/xP3x-Kongo."},
	{"name":"muri-it-language-split","keyword":"breton","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/akoksal/muri-it-language-split","creator_name":"Abdullatif Koksal","creator_url":"https://huggingface.co/akoksal","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tMURI-IT: Multilingual Instruction Tuning Dataset for 200 Languages via Multilingual Reverse Instructions\\n\\t\\n\\nMURI-IT is a large-scale multilingual instruction tuning dataset containing 2.2 million instruction-output pairs across 200 languages. It is designed to address the challenges of instruction tuning in low-resource languages with Multilingual Reverse Instructions (MURI), which ensures that the output is human-written, high-quality, and authentic to the cultural and linguisticâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/akoksal/muri-it-language-split."},
	{"name":"Apertium_dictionary_br_fr","keyword":"breton","license":"GNU General Public License v2.0","license_url":"https://choosealicense.com/licenses/gpl-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Bretagne/Apertium_dictionary_br_fr","creator_name":"Bretagne","creator_url":"https://huggingface.co/Bretagne","description":"\\nDataset origin: https://zenodo.org/records/4012218\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDescription\\n\\t\\n\\nDictionnaire breton-franÃ§ais Apertium de Tyers que nous avons nettoyÃ© (suppressions des duplications).\\n\\n\\t\\n\\t\\t\\n\\t\\tCitation\\n\\t\\n\\nCopyright (C) 2008--2011 Francis Tyers Copyright (C) 2009--2011 Fulup Jakez Copyright (C) 2009 Gwenvael Jekel Development supported by: * Prompsit Language Engineering, S. L. * Ofis ar Brezhoneg * Grup Transducens, Universitat d'Alacant\\n\\n"},
	{"name":"Jan_Deloof","keyword":"breton","license":"GNU Affero General Public License v3.0","license_url":"https://choosealicense.com/licenses/agpl-3.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Bretagne/Jan_Deloof","creator_name":"Bretagne","creator_url":"https://huggingface.co/Bretagne","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDescription\\n\\t\\n\\nJan Deloof: Bretons-Nederlands Woordenboek (http://www.brezhoneg.org.uk/deloof)\\nCopyright 2010 Jan Deloof (jan.deloof@pandora.be)\\nWeb conversion: Kevin Donnelly (kevin@dotmon.com)\\nThe accompanying words and phrases files contain part of Jan Deloof's Breton-Dutch dictionary.  See the above website for further details, and a web interface.Note that the conversion is a work in progress, and the files WILL therefore contain some errors.  You are welcome to notify theseâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Bretagne/Jan_Deloof."},
	{"name":"br_fr_en_translation","keyword":"breton","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Bretagne/br_fr_en_translation","creator_name":"Bretagne","creator_url":"https://huggingface.co/Bretagne","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDescription\\n\\t\\n\\nIl s'agit du jeu de donnÃ©es cvqa_br_fr_en oÃ¹ seuls les textes alignÃ©s br/fr/en sont gardÃ©s afin de constituer un jeu de donnÃ©es de traduction automatique qui soit plus lÃ©ger Ã  tÃ©lÃ©charger.405 textes de types \\\"questions\\\" et 405 textes de type \\\"options\\\" sont disponibles.\\n"},
	{"name":"leipzig_corpora_br","keyword":"breton","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Bretagne/leipzig_corpora_br","creator_name":"Bretagne","creator_url":"https://huggingface.co/Bretagne","description":"\\nDataset origin: https://wortschatz.uni-leipzig.de/en/download/Breton\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDescription\\n\\t\\n\\nThe Leipzig Corpora Collection presents corpora in different languages using the same format and comparable sources. All data are available as plain text files and can be imported into a MySQL database by using the provided import script. They are intended both for scientific use by corpus linguists as well as for applications such as knowledge extraction programs.\\nThe corpora are identical inâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Bretagne/leipzig_corpora_br."},
	{"name":"UD_Breton-KEB","keyword":"breton","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Bretagne/UD_Breton-KEB","creator_name":"Bretagne","creator_url":"https://huggingface.co/Bretagne","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDescription\\n\\t\\n\\nVersion parsÃ©e de UD_Breton-KEB afin de rendre son usage plus simple.\\nCe dÃ©pÃ´t ne s'intÃ©resse qu'au POS.\\nPour la partie traduction breton/franÃ§ais, nous vous invitions Ã  consulter Bretagne/UD_Breton-KEB.\\nUD Breton-KEB est une banque d'arbres de textes en breton qui a Ã©tÃ© annotÃ©e manuellement selon les directives d'Universal Dependencies. \\nLa tokenisation et l'annotation morphologique proviennent d'un analyseur morphologique Ã  Ã©tat fini publiÃ© dans le cadre du projetâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Bretagne/UD_Breton-KEB."},
	{"name":"gatitos_br_fr_en","keyword":"breton","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Bretagne/gatitos_br_fr_en","creator_name":"Bretagne","creator_url":"https://huggingface.co/Bretagne","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDescription\\n\\t\\n\\nAlignement des parties en breton, franÃ§ais et anglais du jeu de donnÃ©es Gatitos afin de crÃ©er un jeu de donnÃ©es de traduction.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tCitation\\n\\t\\n\\n@misc{jones2023bilexrxlexicaldata,\\n      title={Bilex Rx: Lexical Data Augmentation for Massively Multilingual Machine Translation}, \\n      author={Alex Jones and Isaac Caswell and Ishank Saxena and Orhan Firat},\\n      year={2023},\\n      eprint={2303.15265},\\n      archivePrefix={arXiv},\\n      primaryClass={cs.CL}â€¦ See the full description on the dataset page: https://huggingface.co/datasets/Bretagne/gatitos_br_fr_en."},
	{"name":"pontoon_br_en","keyword":"breton","license":"Mozilla Public License 2.0","license_url":"https://choosealicense.com/licenses/mpl-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Bretagne/pontoon_br_en","creator_name":"Bretagne","creator_url":"https://huggingface.co/Bretagne","description":"\\n\\t\\n\\t\\t\\n\\t\\tDescription\\n\\t\\n\\nNettoyage de l'Ã©chantillon en-br ayymen/Pontoon-Translations (suppression des duplications, balises html et des emojis).\\n"},
	{"name":"Korpus-divyezhek-brezhoneg-galleg","keyword":"breton","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Bretagne/Korpus-divyezhek-brezhoneg-galleg","creator_name":"Bretagne","creator_url":"https://huggingface.co/Bretagne","description":"\\n\\t\\n\\t\\t\\n\\t\\tKorpus-divyezhek-brezhoneg-galleg\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDescription\\n\\t\\n\\nLe corpus bilingue breton- franÃ§ais de l'Office public de la langue bretonne est un corpus de textes traduits par des traducteurs humains.\\nIl s'agit principalement de documents administratifs, d'articles ou d'expositions.\\nLe jeu de donnÃ©es original provient de ce rÃ©pertoire GitHub.\\nNous l'avons nettoyÃ© (suppression des lignes dupliquÃ©es), passant alors de 62 861 lignes indiquÃ©es par les auteurs Ã  61 503 dans la versionâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Bretagne/Korpus-divyezhek-brezhoneg-galleg."},
	{"name":"GlotCC-V1","keyword":"breton","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/cis-lmu/GlotCC-V1","creator_name":"CIS, LMU Munich","creator_url":"https://huggingface.co/cis-lmu","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\n \\n\\nGlotCC-V1.0 is a document-level, general domain dataset derived from CommonCrawl, covering more than 1000 languages.It is built using the GlotLID language identification and Ungoliant pipeline from CommonCrawl.We release our pipeline as open-source at https://github.com/cisnlp/GlotCC.  \\nList of Languages: See https://datasets-server.huggingface.co/splits?dataset=cis-lmu/GlotCC-V1 to get the list of splits available.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tUsage (Huggingface Hub --â€¦ See the full description on the dataset page: https://huggingface.co/datasets/cis-lmu/GlotCC-V1."},
	{"name":"GlotCC-V1","keyword":"breton","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/cis-lmu/GlotCC-V1","creator_name":"CIS, LMU Munich","creator_url":"https://huggingface.co/cis-lmu","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\n \\n\\nGlotCC-V1.0 is a document-level, general domain dataset derived from CommonCrawl, covering more than 1000 languages.It is built using the GlotLID language identification and Ungoliant pipeline from CommonCrawl.We release our pipeline as open-source at https://github.com/cisnlp/GlotCC.  \\nList of Languages: See https://datasets-server.huggingface.co/splits?dataset=cis-lmu/GlotCC-V1 to get the list of splits available.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tUsage (Huggingface Hub --â€¦ See the full description on the dataset page: https://huggingface.co/datasets/cis-lmu/GlotCC-V1."},
	{"name":"muri-it","keyword":"breton","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/akoksal/muri-it","creator_name":"Abdullatif Koksal","creator_url":"https://huggingface.co/akoksal","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tMURI-IT: Multilingual Instruction Tuning Dataset for 200 Languages via Multilingual Reverse Instructions\\n\\t\\n\\nMURI-IT is a large-scale multilingual instruction tuning dataset containing 2.2 million instruction-output pairs across 200 languages. It is designed to address the challenges of instruction tuning in low-resource languages with Multilingual Reverse Instructions (MURI), which ensures that the output is human-written, high-quality, and authentic to the cultural and linguisticâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/akoksal/muri-it."},
	{"name":"reranking-datasets-light","keyword":"breton","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/abdoelsayed/reranking-datasets-light","creator_name":"unkown","creator_url":"https://huggingface.co/abdoelsayed","description":"\\n\\t\\n\\t\\t\\n\\t\\tðŸ”¥ Rankify: A Comprehensive Python Toolkit for Retrieval, Re-Ranking, and Retrieval-Augmented Generation ðŸ”¥\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tReRanking Datasets : A comprehensive collection of retrieval and reranking datasets with full passage contexts, including titles, text, and metadata for in-depth research.\\n\\t\\n\\n\\n    \\n    \\n    \\n    \\n    \\n    \\n        \\n    \\n    \\n        \\n    \\n    \\n        \\n    \\n    \\n        \\n    \\n    \\n    \\n\\n\\n\\nA curated collection of ready-to-use datasets for retrieval and rerankingâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/abdoelsayed/reranking-datasets-light."},
	{"name":"smol","keyword":"breton","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/google/smol","creator_name":"Google","creator_url":"https://huggingface.co/google","description":"\\n\\t\\n\\t\\t\\n\\t\\tSMOL\\n\\t\\n\\nSMOL (Set for Maximal Overall Leverage) is a collection of professional\\ntranslations into 221 Low-Resource Languages, for the purpose of training\\ntranslation models, and otherwise increasing the representations of said\\nlanguages in NLP and technology.\\nPlease read the SMOL Paper and the\\nGATITOS Paper for a much more\\nthorough description!\\nThere are four resources in this directory:\\n\\nSmolDoc: document-level translations into 100 languages\\nSmolSent: sentence-level translations intoâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/google/smol."},
	{"name":"opus_ubuntu","keyword":"breton","license":"BSD 3-Clause \"New\" or \"Revised\" License","license_url":"https://choosealicense.com/licenses/bsd-3-clause/","language":"en","dataset_url":"https://huggingface.co/datasets/Helsinki-NLP/opus_ubuntu","creator_name":"Language Technology Research Group at the University of Helsinki","creator_url":"https://huggingface.co/Helsinki-NLP","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Opus Ubuntu\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThese are translations of the Ubuntu software package messages, donated by the Ubuntu community.\\nTo load a language pair which isn't part of the config, all you need to do is specify the language code as pairs.\\nYou can find the valid pairs in Homepage section of Dataset Description: http://opus.nlpl.eu/Ubuntu.php\\nE.g.\\ndataset = load_dataset(\\\"opus_ubuntu\\\", lang1=\\\"it\\\", lang2=\\\"pl\\\")\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSupported Tasks andâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Helsinki-NLP/opus_ubuntu."},
	{"name":"wit_base","keyword":"breton","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/wikimedia/wit_base","creator_name":"Wikimedia","creator_url":"https://huggingface.co/wikimedia","description":"\\n\\t\\n\\t\\t\\n\\t\\tDataset Card for WIT\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nWikimedia's version of the Wikipedia-based Image Text (WIT) Dataset, a large multimodal multilingual dataset.\\nFrom the official blog post:\\n\\nThe core training data is taken from the Wikipedia Image-Text (WIT) Dataset, a large curated set of more than 37 million image-text associations extracted from Wikipedia articles in 108 languages that was recently released by Google Research.\\nThe WIT dataset offers extremely valuable data about theâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/wikimedia/wit_base."},
	{"name":"xP3x-sample","keyword":"breton","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Muennighoff/xP3x-sample","creator_name":"Niklas Muennighoff","creator_url":"https://huggingface.co/Muennighoff","description":"A multilingual collection of Winograd Schemas in six languages that can be used for evaluation of cross-lingual commonsense reasoning capabilities."},
	{"name":"wikianc","keyword":"breton","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/cyanic-selkie/wikianc","creator_name":"cyanic-selkie","creator_url":"https://huggingface.co/cyanic-selkie","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for WikiAnc\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThe WikiAnc dataset is an automatically generated dataset from Wikipedia (all languages) and Wikidata dumps (August, 2023). \\nThe code for generating the dataset can be found here.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSupported Tasks\\n\\t\\n\\n\\nwikificiation: The dataset can be used to train a model for Wikification.\\nnamed-entity-linking: The dataset can be used to train a model for Named Entity Linking.\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages\\n\\t\\n\\nThe text in the dataset isâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/cyanic-selkie/wikianc."},
	{"name":"entity_cs","keyword":"breton","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/huawei-noah/entity_cs","creator_name":"HUAWEI Noah's Ark Lab","creator_url":"https://huggingface.co/huawei-noah","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for EntityCS\\n\\t\\n\\n\\nRepository: https://github.com/huawei-noah/noah-research/tree/master/NLP/EntityCS  \\nPaper: https://aclanthology.org/2022.findings-emnlp.499.pdf  \\nPoint of Contact: Fenia Christopoulou, Chenxi Whitehouse\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nWe use the English Wikipedia and leverage entity information from Wikidata to construct an entity-based Code Switching corpus. \\nTo achieve this, we make use of wikilinks in Wikipedia, i.e. links from one page toâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/huawei-noah/entity_cs."},
	{"name":"udhr-lid","keyword":"breton","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/cis-lmu/udhr-lid","creator_name":"CIS, LMU Munich","creator_url":"https://huggingface.co/cis-lmu","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tUDHR-LID\\n\\t\\n\\nWhy UDHR-LID?\\nYou can access UDHR (Universal Declaration of Human Rights) here, but when a verse is missing, they have texts such as \\\"missing\\\" or \\\"?\\\". Also, about 1/3 of the sentences consist only of \\\"articles 1-30\\\" in different languages. We cleaned the entire dataset from XML files and selected only the paragraphs. We cleared any unrelated language texts from the data and also removed the cases that were incorrect.\\nIncorrect? Look at the ckb and kmr files in the UDHR.â€¦ See the full description on the dataset page: https://huggingface.co/datasets/cis-lmu/udhr-lid."},
	{"name":"ARBRES-Kenstur","keyword":"breton","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/lgrobol/ARBRES-Kenstur","creator_name":"LoÃ¯c Grobol","creator_url":"https://huggingface.co/lgrobol","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tARBRES-Kenstur\\n\\t\\n\\nARBRES-Kenstur is a Breton-French parallel corpora generated by extracting the French translations of Breton sentences from the interlinear glosses of the ARBRES wikigrammar.\\nThe extraction is still under developpment in the Autogramm project of the French National Research Agency. More information can be found on their Github repository.\\n"},
	{"name":"Pontoon-Translations","keyword":"breton","license":"Mozilla Public License 2.0","license_url":"https://choosealicense.com/licenses/mpl-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ayymen/Pontoon-Translations","creator_name":"Mohamed Aymane Farhi","creator_url":"https://huggingface.co/ayymen","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Pontoon Translations\\n\\t\\n\\n\\n\\nThis is a dataset containing strings from various Mozilla projects on Mozilla's Pontoon localization platform and their translations into more than 200 languages.\\nSource strings are in English.\\nTo avoid rows with values like \\\"None\\\" and \\\"N/A\\\" being interpreted as missing values, pass the keep_default_na parameter like this:\\nfrom datasets import load_dataset\\n\\ndataset = load_dataset(\\\"ayymen/Pontoon-Translations\\\", keep_default_na=False)â€¦ See the full description on the dataset page: https://huggingface.co/datasets/ayymen/Pontoon-Translations."},
	{"name":"language_tags","keyword":"breton","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/lbourdois/language_tags","creator_name":"LoÃ¯ck BOURDOIS","creator_url":"https://huggingface.co/lbourdois","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDescription\\n\\t\\n\\nDataset listing 27,328 languages and dialects (also includes macrolanguage names).For each language, either the ISO 639 code, the Glottolog code or both are provided.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tColumns\\n\\t\\n\\n\\nEnglish_Name: Language name in English (e.g. \\\"French\\\").\\nNative_Name: If value is not 0, corresponds to the name of the language by native speakers (e.g. \\\"FranÃ§ais\\\") which may have been found in Wikipedia's nativename field.\\nGlottocode: The language tag in the Glottolog conventionâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/lbourdois/language_tags."},
	{"name":"Deltacorpus_1.1","keyword":"breton","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/FrancophonIA/Deltacorpus_1.1","creator_name":"FrancophonIA","creator_url":"https://huggingface.co/FrancophonIA","description":"\\nDataset origin: https://lindat.cz/repository/xmlui/handle/11234/1-1743\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDescription\\n\\t\\n\\nTexts in 107 languages from the W2C corpus (http://hdl.handle.net/11858/00-097C-0000-0022-6133-9), first 1,000,000 tokens per language, tagged by the delexicalized tagger described in Yu et al. (2016, LREC, PortoroÅ¾, Slovenia).\\nChanges in version 1.1: \\n\\nUniversal Dependencies tagset instead of the older and smaller Google Universal POS tagset. \\n\\nSVM classifier trained on Universal Dependenciesâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/FrancophonIA/Deltacorpus_1.1."},
	{"name":"Goulenn-Alpaca-Instruct-110k","keyword":"breton","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/amurienne/Goulenn-Alpaca-Instruct-110k","creator_name":"Albert Murienne","creator_url":"https://huggingface.co/amurienne","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tGoulenn\\n\\t\\n\\n\\nA Breton Instructions Dataset called Goulenn (meaning \\\"Question\\\" in Breton).\\nDirect translation of the jpacifico/French-Alpaca-dataset-Instruct-110K by Jonathan Pacifico.\\nGeneration details available on the GweLLM Github repository.\\n\\nSample test code:\\nfrom datasets import load_dataset\\n\\ndataset = load_dataset( path=\\\"amurienne/Goulenn-Alpaca-Instruct-110k\\\",\\n                        split=\\\"train\\\")\\n\\nprint(f\\\"dataset infos:\\\\n{dataset}\\\")\\nprint(f\\\"dataset firstâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/amurienne/Goulenn-Alpaca-Instruct-110k."},
	{"name":"WikiMatrix_br","keyword":"breton","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Bretagne/WikiMatrix_br","creator_name":"Bretagne","creator_url":"https://huggingface.co/Bretagne","description":"\\nDataset origin: https://opus.nlpl.eu/WikiMatrix/corpus/version/WikiMatrix\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDescription\\n\\t\\n\\nCorpus monolingue en breton de WikiMatrix\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tCitation\\n\\t\\n\\n@misc{schwenk2019wikimatrixmining135mparallel,\\n      title={WikiMatrix: Mining 135M Parallel Sentences in 1620 Language Pairs from Wikipedia}, \\n      author={Holger Schwenk and Vishrav Chaudhary and Shuo Sun and Hongyu Gong and Francisco GuzmÃ¡n},\\n      year={2019},\\n      eprint={1907.05791},\\n      archivePrefix={arXiv}â€¦ See the full description on the dataset page: https://huggingface.co/datasets/Bretagne/WikiMatrix_br."},
	{"name":"UD_Breton-KEB_translation","keyword":"breton","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Bretagne/UD_Breton-KEB_translation","creator_name":"Bretagne","creator_url":"https://huggingface.co/Bretagne","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDescription\\n\\t\\n\\nVersion parsÃ©e de UD_Breton-KEB afin de rendre son usage plus simple.\\nCe dÃ©pÃ´t ne s'intÃ©resse qu'Ã  la traduction breton/franÃ§ais. \\nPour la partie POS, nous vous invitions Ã  consulter Bretagne/UD_Breton-KEB.\\nUD Breton-KEB est une banque d'arbres de textes en breton qui a Ã©tÃ© annotÃ©e manuellement selon les directives d'Universal Dependencies. \\nLa tokenisation et l'annotation morphologique proviennent d'un analyseur morphologique Ã  Ã©tat fini publiÃ© dans le cadre duâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Bretagne/UD_Breton-KEB_translation."},
	{"name":"Goulenn-Alpaca-Instruct-50k","keyword":"breton","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/amurienne/Goulenn-Alpaca-Instruct-50k","creator_name":"Albert Murienne","creator_url":"https://huggingface.co/amurienne","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tGoulenn\\n\\t\\n\\n\\nA Breton Instructions Dataset called Goulenn (meaning \\\"Question\\\" in Breton).\\nDirect translation of the jpacifico/French-Alpaca-dataset-Instruct-110K by Jonathan Pacifico.\\nFor now only 50k samples have been translated, 110k version soo  to come...\\nGeneration details available on the GweLLM Github repository.\\n\\nSample test code:\\nfrom datasets import load_dataset\\n\\ndataset = load_dataset( path=\\\"amurienne/Goulenn-Alpaca-Instruct-50k\\\",\\n                        split=\\\"train\\\")â€¦ See the full description on the dataset page: https://huggingface.co/datasets/amurienne/Goulenn-Alpaca-Instruct-50k."},
	{"name":"V1Q","keyword":"breton","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/YuRiVeRTi/V1Q","creator_name":"YuRiVeRTical","creator_url":"https://huggingface.co/YuRiVeRTi","description":"from datasets import load_dataset\\nds = load_dataset(\\\"b3x0m/Chinese-H-Novels\\\")\\nimport sagemaker\\nimport boto3\\nfrom sagemaker.huggingface import HuggingFaceModel\\ntry:\\n    role = sagemaker.get_execution_role()\\nexcept ValueError:\\n    iam = boto3.client('iam')\\n    role = iam.get_role(RoleName='sagemaker_execution_role')['Role']['Arn']\\n\\n\\t\\n\\t\\t\\n\\t\\tHub Model configuration. https://huggingface.co/models\\n\\t\\n\\nhub = {\\n    'HF_MODEL_ID':'deepseek-ai/Janus-Pro-7B',\\n    'HF_TASK':'any-to-any'\\n}\\n\\n\\t\\n\\t\\t\\n\\t\\tcreateâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/YuRiVeRTi/V1Q."}
]
;
