const data_for_language_europe_italian = 
[
	{"name":"TinyDS-20k","keyword":"italian","description":"\n\t\n\t\t\n\t\tTinyDS\n\t\n\n\n\n\nAlpaca-style dataset with around 20k samples scraped from Qwen3-8B using SyntheticAlpaca. Q&A pairs can be in 32 different languages, these are listed in the metadata.Topics are all around STEM, programming, and literature.  \nMIT @ 2025 Hamzah Asadullah\n\n\n","url":"https://huggingface.co/datasets/Hamzah-Asadullah/TinyDS-20k","creator_name":"Hamzah Asadullah","creator_url":"https://huggingface.co/Hamzah-Asadullah","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["question-answering","translation","text-generation","text2text-generation","English"],"keywords_longer_than_N":true},
	{"name":"apertus-pretrain-swiss","keyword":"italian","description":"\n\t\n\t\t\n\t\tSwiss Pretrain Data\n\t\n\nThis dataset provides a large collection of open-access and license-compliant Swiss data sources for language model training.\nThe dataset includes the following sources:\n\n\t\n\t\t\nName\nInternal ID\nTokens (B)\nDescription\n\n\n\t\t\nCuria Vista\ncuriavista\n0.5\nLegal and administrative documents from the Swiss database of parliamentary proceedings.\n\n\nenscheidsuche\nenscheidsuche_html\n4.5\nSwiss court decisions, sampled at 50% for balance.\n\n\nFineWeb-2‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/swiss-ai/apertus-pretrain-swiss.","url":"https://huggingface.co/datasets/swiss-ai/apertus-pretrain-swiss","creator_name":"Swiss AI Initiative","creator_url":"https://huggingface.co/swiss-ai","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["fill-mask","text-generation","French","English","German"],"keywords_longer_than_N":true},
	{"name":"allenai_tulu-3-sft-mixture-DolphinLabeled","keyword":"italian","description":"\n\t\n\t\t\n\t\tallenai tulu-3-sft-mixture DolphinLabeled\n\t\n\n\n\t\n\t\t\n\t\tPart of the DolphinLabeled series of datasets\n\t\n\n\n\t\n\t\t\n\t\tPresented by Eric Hartford and Cognitive Computations\n\t\n\nThe purpose of this dataset is to enable filtering of allenai/tulu-3-sft-mixture dataset.\nThe original dataset is allenai/tulu-3-sft-mixture\nI have modified the dataset using two scripts.\n\ndedupe.py - removes rows with identical final message content\nlabel.py - adds a \"flags\" column containing the following boolean‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/QuixiAI/allenai_tulu-3-sft-mixture-DolphinLabeled.","url":"https://huggingface.co/datasets/QuixiAI/allenai_tulu-3-sft-mixture-DolphinLabeled","creator_name":"Quixi AI","creator_url":"https://huggingface.co/QuixiAI","license_name":"Open Data Commons Attribution License v1.0","license_url":"https://scancode-licensedb.aboutcode.org/odc-by-1.0.html","language":"en","first_N":5,"first_N_keywords":["other","crowdsourced","expert-generated","machine-generated","multilingual"],"keywords_longer_than_N":true},
	{"name":"prompt_injections","keyword":"italian","description":"\n\t\n\t\t\n\t\tDataset Card for Prompt Injections by  Yanis Miraoui  üëã\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset of prompt injections enriches Large Language Models (LLMs) by providing task-specific examples and prompts, helping improve LLMs' performance and control their behavior.\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset contains over 1000 rows of prompt injections in multiple languages. It contains examples of prompt injections using different techniques such as: prompt leaking, jailbreaking‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/yanismiraoui/prompt_injections.","url":"https://huggingface.co/datasets/yanismiraoui/prompt_injections","creator_name":"Yanis Miraoui","creator_url":"https://huggingface.co/yanismiraoui","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["no-annotation","multilingual","original","English","French"],"keywords_longer_than_N":true},
	{"name":"xlel_wd_dictionary","keyword":"italian","description":"XLEL-WD is a multilingual event linking dataset. This sub-dataset contains a dictionary of events from Wikidata. The multilingual descriptions for Wikidata event items are taken from the corresponding Wikipedia articles.","url":"https://huggingface.co/datasets/adithya7/xlel_wd_dictionary","creator_name":"Adithya Pratapa","creator_url":"https://huggingface.co/adithya7","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["found","found","multilingual","original","Afrikaans"],"keywords_longer_than_N":true},
	{"name":"qg_itquad","keyword":"italian","description":"[SQuAD-it](https://huggingface.co/datasets/squad_it) dataset for question generation (QG) task.","url":"https://huggingface.co/datasets/lmqg/qg_itquad","creator_name":"LMQG","creator_url":"https://huggingface.co/lmqg","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":null,"first_N":5,"first_N_keywords":["text-generation","language-modeling","monolingual","squad_es","Italian"],"keywords_longer_than_N":true},
	{"name":"minigpt4-7b-ggml","keyword":"italian","description":"These are quantized ggml binary files for minigpt4 7B model.\nThese files can be used in conjunction with vicuna v0 ggml models to get minigpt4 working.\nNot all implementations were tested. If there are any issues, use f16.\n","url":"https://huggingface.co/datasets/maknee/minigpt4-7b-ggml","creator_name":"maknee","creator_url":"https://huggingface.co/maknee","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":null,"first_N":5,"first_N_keywords":["English","Bulgarian","Catalan","Czech","Danish"],"keywords_longer_than_N":true},
	{"name":"seamless-align","keyword":"italian","description":"\n\t\n\t\t\n\t\tDataset Card for Seamless-Align (WIP). Inspired by https://huggingface.co/datasets/allenai/nllb\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset was created based on metadata for mined Speech-to-Speech(S2S), Text-to-Speech(TTS) and Speech-to-Text(S2T) released by Meta AI.  The S2S contains data for 35 language pairs. The S2S dataset is ~1000GB compressed.\n\n\t\n\t\t\n\t\tHow to use the data\n\t\n\nThere are two ways to access the data:\n\nVia the Hugging Face Python datasets library\n\nScripts coming soon‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/jhu-clsp/seamless-align.","url":"https://huggingface.co/datasets/jhu-clsp/seamless-align","creator_name":"Center for Language and Speech Processing @ JHU","creator_url":"https://huggingface.co/jhu-clsp","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["translation","audio-to-audio","Maltese","English","Welsh"],"keywords_longer_than_N":true},
	{"name":"WEATHub","keyword":"italian","description":"\n\n\n\n\n\t\n\t\t\n\t\tDataset Card for \"WEATHub\"\n\t\n\nThis dataset corresponds to the data described in the paper \"Global Voices, Local Biases: Socio-Cultural Prejudices across Languages\"\naccepted to EMNLP 2023.\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nWEATHub is a dataset containing 24 languages. It contains words organized into groups of (target1, target2, attribute1, attribute2)\nto measure the association target1:target2 :: attribute1:attribute2. For example target1 can be insects, target2 can be flowers. And we‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/iamshnoo/WEATHub.","url":"https://huggingface.co/datasets/iamshnoo/WEATHub","creator_name":"Anjishnu Mukherjee","creator_url":"https://huggingface.co/iamshnoo","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["Arabic","Bengali","Central Kurdish","Danish","German"],"keywords_longer_than_N":true},
	{"name":"tulu-3-sft-mixture","keyword":"italian","description":"\n\n\n\t\n\t\t\n\t\tTulu 3 SFT Mixture\n\t\n\nNote that this collection is licensed under ODC-BY-1.0 license; different licenses apply to subsets of the data. Some portions of the dataset are non-commercial. We present the mixture as a research artifact.\nThe Tulu 3 SFT mixture was used to train the Tulu 3 series of models.\nIt contains 939,344 samples from the following sets:\n\nCoCoNot (ODC-BY-1.0), 10,983 prompts (Brahman et al., 2024)\nFLAN v2 via ai2-adapt-dev/flan_v2_converted, 89,982 prompts (Longpre et‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/allenai/tulu-3-sft-mixture.","url":"https://huggingface.co/datasets/allenai/tulu-3-sft-mixture","creator_name":"Ai2","creator_url":"https://huggingface.co/allenai","license_name":"Open Data Commons Attribution License v1.0","license_url":"https://scancode-licensedb.aboutcode.org/odc-by-1.0.html","language":"en","first_N":5,"first_N_keywords":["other","crowdsourced","expert-generated","machine-generated","multilingual"],"keywords_longer_than_N":true},
	{"name":"ultrafeedback-preferences-translated-ita","keyword":"italian","description":"\n\t\n\t\t\n\t\tDataset Card for \"ultrafeedback-preferences-translated-ita\"\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis is a translated using argostranslate and filterd version of the ultrafeedback-binarized-preference dataset and was used to train Zefiro-dpo-7b-ITA, a state of the art Italian 7b chat model.\n","url":"https://huggingface.co/datasets/mii-community/ultrafeedback-preferences-translated-ita","creator_name":"mii-community","creator_url":"https://huggingface.co/mii-community","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["Italian","apache-2.0","10K - 100K","parquet","Tabular"],"keywords_longer_than_N":true},
	{"name":"itacasehold","keyword":"italian","description":"\n\t\n\t\t\n\t\tITA-CASEHOLD\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\n\nThis dataset contains the data used in the research of the ITA-CASEHOLD model, an extractive summarization model to extract holdings from Italian Legal Administrative documents.\nThe research paper titled 'Legal Holding Extraction from Italian Case Documents using Italian-LEGAL-BERT Text Summarization' is accepted for ICAIL 23.\nIt consists of 1101 pairs of judgments and their official holdings between the years 2019 and 2022 from the archives‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/itacasehold/itacasehold.","url":"https://huggingface.co/datasets/itacasehold/itacasehold","creator_name":"itacasehold","creator_url":"https://huggingface.co/itacasehold","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["summarization","text-classification","Italian","apache-2.0","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"fleurs-hs","keyword":"italian","description":"\n\t\n\t\t\n\t\tFLEURS-HS\n\t\n\nAn extension of the FLEURS dataset for synthetic speech detection using text-to-speech, featured in the paper Synthetic speech detection with Wav2Vec 2.0 in various language settings.\nThis dataset is 1 of 3 used in the paper, the others being:\n\nFLEURS-HS VITS\ntest set containing (generally) more difficult synthetic samples\nseparated due to different licensing\n\n\nARCTIC-HS\nextension of the CMU_ARCTIC and L2-ARCTIC sets in a similar manner\n\n\n\n\t\n\t\t\n\t\tDataset Details‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/realnetworks-kontxt/fleurs-hs.","url":"https://huggingface.co/datasets/realnetworks-kontxt/fleurs-hs","creator_name":"KONTXT by RealNetworks","creator_url":"https://huggingface.co/realnetworks-kontxt","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":null,"first_N":5,"first_N_keywords":["audio-classification","German","English","Spanish","French"],"keywords_longer_than_N":true},
	{"name":"synthetic-multi-pii-ner-v1","keyword":"italian","description":"\n\t\n\t\t\n\t\tSynthetic Multilingual PII NER Dataset\n\t\n\n\n\t\n\t\t\n\t\tModels Trained Using this Dataset\n\t\n\n\nE3-JSI/gliner-multi-pii-domains-v1\n\n\n\t\n\t\t\n\t\tDescription\n\t\n\nThis is a synthetic dataset created for the purposes for training multilingual personally identifiable information (PII) named entity recognition (NER) models.\nThe examples were generated using a prompt that generates the text and the entities present in the text. In addition, the generated response had to follow the restrictions:\n\nthe‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/E3-JSI/synthetic-multi-pii-ner-v1.","url":"https://huggingface.co/datasets/E3-JSI/synthetic-multi-pii-ner-v1","creator_name":"Department for Artificial Intelligence, Jo≈æef Stefan Institute","creator_url":"https://huggingface.co/E3-JSI","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["token-classification","English","French","German","Greek"],"keywords_longer_than_N":true},
	{"name":"arena-hard-v2-verifiers","keyword":"italian","description":"\n\t\n\t\t\n\t\tArena-Hard v2.0 - Verifiers Format\n\t\n\nThis dataset contains Arena-Hard v2.0 in Verifiers-compatible format for LLM evaluation.\n\n\t\n\t\t\n\t\tüìä Dataset Information\n\t\n\n\nVersion: Arena-Hard v2.0\nExamples: 750\nModel Answers: deepseek-r1\nJudge: gpt-4.1\nFormat: Verifiers-compatible HuggingFace Dataset\nLicense: Apache 2.0\n\n\n\t\n\t\t\n\t\tüéØ Categories\n\t\n\n\nHard Prompts (500 examples): Challenging coding, math, and reasoning tasks\nCoding: 253 examples\nMath: 247 examples\n\n\nCreative Writing (250 examples):‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Anna4242/arena-hard-v2-verifiers.","url":"https://huggingface.co/datasets/Anna4242/arena-hard-v2-verifiers","creator_name":"D","creator_url":"https://huggingface.co/Anna4242","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","question-answering","English","Spanish","French"],"keywords_longer_than_N":true},
	{"name":"test_llm_dataset","keyword":"italian","description":"\n\t\n\t\t\n\t\tModel Card for Mixtral-8x7B\n\t\n\nThe Mixtral-8x7B Large Language Model (LLM) is a pretrained generative Sparse Mixture of Experts. The Mixtral-8x7B outperforms Llama 2 70B on most benchmarks we tested.\nFor full details of this model please read our release blog post.\n\n\t\n\t\t\n\t\tWarning\n\t\n\nThis repo contains weights that are compatible with vLLM serving of the model as well as Hugging Face transformers library. It is based on the original Mixtral torrent release, but the file format and‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/youssefoud/test_llm_dataset.","url":"https://huggingface.co/datasets/youssefoud/test_llm_dataset","creator_name":"Youssef Oudghiri","creator_url":"https://huggingface.co/youssefoud","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["French","Italian","German","Spanish","English"],"keywords_longer_than_N":true},
	{"name":"c4","keyword":"italian","description":"\n\t\n\t\t\n\t\tC4\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nA colossal, cleaned version of Common Crawl's web crawl corpus. Based on Common Crawl dataset: \"https://commoncrawl.org\".\nThis is the processed version of Google's C4 dataset\nWe prepared five variants of the data: en, en.noclean, en.noblocklist, realnewslike, and multilingual (mC4).\nFor reference, these are the sizes of the variants:\n\nen: 305GB\nen.noclean: 2.3TB\nen.noblocklist: 380GB\nrealnewslike: 15GB\nmultilingual (mC4): 9.7TB (108 subsets, one per‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/allenai/c4.","url":"https://huggingface.co/datasets/allenai/c4","creator_name":"Ai2","creator_url":"https://huggingface.co/allenai","license_name":"Open Data Commons Attribution License v1.0","license_url":"https://scancode-licensedb.aboutcode.org/odc-by-1.0.html","language":"en","first_N":5,"first_N_keywords":["text-generation","fill-mask","language-modeling","masked-language-modeling","no-annotation"],"keywords_longer_than_N":true},
	{"name":"divemt_attributions","keyword":"italian","description":"\n\t\n\t\t\n\t\tDataset Card for DivEMT Attributions\n\t\n\nFor more details on DivEMT, see our EMNLP 2022 Paper and our Github repository\n","url":"https://huggingface.co/datasets/inseq/divemt_attributions","creator_name":"Inseq","creator_url":"https://huggingface.co/inseq","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["translation","machine-generated","translation","Italian","Arabic"],"keywords_longer_than_N":true},
	{"name":"clean_mc4_it","keyword":"italian","description":"A thoroughly cleaned version of the Italian portion of the multilingual \ncolossal, cleaned version of Common Crawl's web crawl corpus (mC4) by AllenAI.\n\nBased on Common Crawl dataset: \"https://commoncrawl.org\".\n\nThis is the processed version of Google's mC4 dataset by AllenAI, with further cleaning\ndetailed in the repository README file.","url":"https://huggingface.co/datasets/gsarti/clean_mc4_it","creator_name":"Gabriele Sarti","creator_url":"https://huggingface.co/gsarti","license_name":"Open Data Commons Attribution License v1.0","license_url":"https://scancode-licensedb.aboutcode.org/odc-by-1.0.html","language":null,"first_N":5,"first_N_keywords":["text-generation","language-modeling","no-annotation","found","monolingual"],"keywords_longer_than_N":true},
	{"name":"udhr-lid","keyword":"italian","description":"\n\t\n\t\t\n\t\tUDHR-LID\n\t\n\nWhy UDHR-LID?\nYou can access UDHR (Universal Declaration of Human Rights) here, but when a verse is missing, they have texts such as \"missing\" or \"?\". Also, about 1/3 of the sentences consist only of \"articles 1-30\" in different languages. We cleaned the entire dataset from XML files and selected only the paragraphs. We cleared any unrelated language texts from the data and also removed the cases that were incorrect.\nIncorrect? Look at the ckb and kmr files in the UDHR.‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/cis-lmu/udhr-lid.","url":"https://huggingface.co/datasets/cis-lmu/udhr-lid","creator_name":"CIS, LMU Munich","creator_url":"https://huggingface.co/cis-lmu","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["multilingual","Tigrinya","Balkan Romani","Standard Arabic","Metlat√≥noc Mixtec"],"keywords_longer_than_N":true},
	{"name":"mqa","keyword":"italian","description":"MQA is a multilingual corpus of questions and answers parsed from the Common Crawl. Questions are divided between Frequently Asked Questions (FAQ) pages and Community Question Answering (CQA) pages.","url":"https://huggingface.co/datasets/clips/mqa","creator_name":"CLiPS","creator_url":"https://huggingface.co/clips","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["question-answering","multiple-choice-qa","no-annotation","other","multilingual"],"keywords_longer_than_N":true},
	{"name":"CC-Cat","keyword":"italian","description":"\n\t\n\t\t\n\t\tCC_Cat\n\t\n\n\nExtract from CC-WARC snapshots.\nMainly includes texts with 149 languages.\nPDF/IMAGE/AUDIO/VIDEO raw downloading link.\n\n\n\t\n\t\t\n\t\tNotice\n\t\n\n\nSince my computing resources are limited, this dataset will update by one-day of CC snapshots timestampts.\nAfter a snapshot is updated, the deduplicated version will be uploaded.\nIf you are interested in providing computing resources or have cooperation needs, please contact me.\n  carreyallthetime@gmail.com  \n      \n  \n\n","url":"https://huggingface.co/datasets/chengshidehaimianti/CC-Cat","creator_name":"zyq","creator_url":"https://huggingface.co/chengshidehaimianti","license_name":"Open Data Commons Attribution License v1.0","license_url":"https://scancode-licensedb.aboutcode.org/odc-by-1.0.html","language":"en","first_N":5,"first_N_keywords":["text-generation","Chinese","English","German","Russian"],"keywords_longer_than_N":true},
	{"name":"oasst2","keyword":"italian","description":"\n\t\n\t\t\n\t\tOpen Assistant Conversations Dataset Release 2 (OASST2)\n\t\n\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nThis dataset contains message trees. Each message tree has an initial prompt message as the root node, \nwhich can have multiple child messages as replies, and these child messages can have multiple replies. \nAll messages have a role property: this can either be \"assistant\" or \"prompter\". The roles in \nconversation threads from prompt to leaf node strictly alternate between \"prompter\" and‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/OpenAssistant/oasst2.","url":"https://huggingface.co/datasets/OpenAssistant/oasst2","creator_name":"OpenAssistant","creator_url":"https://huggingface.co/OpenAssistant","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["English","Spanish","Russian","German","Polish"],"keywords_longer_than_N":true},
	{"name":"MultiSim","keyword":"italian","description":"MultiSim is a growing collection of Text Simplfication datasets in multiple languages.  Each dataset is a set of complex and simple sentence pairs.","url":"https://huggingface.co/datasets/MichaelR207/MultiSim","creator_name":"Michael Ryan","creator_url":"https://huggingface.co/MichaelR207","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":null,"first_N":5,"first_N_keywords":["summarization","text-generation","English","French","Russian"],"keywords_longer_than_N":true},
	{"name":"X-TruthfulQA_en_zh_ko_it_es","keyword":"italian","description":"\n\t\n\t\t\n\t\tX-TruthfulQA\n\t\n\nü§ó Paper | üìñ arXiv\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nX-TruthfulQA is an evaluation benchmark for multilingual large language models (LLMs), including questions and answers in 5 languages (English, Chinese, Korean, Italian and Spanish).\nIt is intended to evaluate the truthfulness of LLMs. The dataset is translated by GPT-4 from the original English-version TruthfulQA.\nIn our paper, we evaluate LLMs in a zero-shot generative setting: prompt the instruction-tuned LLM with‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/zhihz0535/X-TruthfulQA_en_zh_ko_it_es.","url":"https://huggingface.co/datasets/zhihz0535/X-TruthfulQA_en_zh_ko_it_es","creator_name":"Zhihan Zhang","creator_url":"https://huggingface.co/zhihz0535","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["question-answering","English","Chinese","Korean","Italian"],"keywords_longer_than_N":true},
	{"name":"fleurs","keyword":"italian","description":"\n\t\n\t\t\n\t\tFLEURS\n\t\n\nFleurs is the speech version of the FLoRes machine translation benchmark. \nWe use 2009 n-way parallel sentences from the FLoRes dev and devtest publicly available sets, in 102 languages. \nTraining sets have around 10 hours of supervision. Speakers of the train sets are different than speakers from the dev/test sets. Multilingual fine-tuning is\nused and ‚Äùunit error rate‚Äù (characters, signs) of all languages is averaged. Languages and results are also grouped into seven‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/google/fleurs.","url":"https://huggingface.co/datasets/google/fleurs","creator_name":"Google","creator_url":"https://huggingface.co/google","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":null,"first_N":5,"first_N_keywords":["automatic-speech-recognition","expert-generated","crowdsourced","machine-generated","crowdsourced"],"keywords_longer_than_N":true},
	{"name":"NSFW_Multilanguage_Chat_Dataset","keyword":"italian","description":"Thanks to utsavm/NSFW_Chat_Dataset, I translate it so it can be more useful.\nüö® 18+ Only! NSFW & Spicy Content Ahead üö®\nHey there, AI enthusiasts and romance lovers! üòè Welcome to the Spicy AI GF Chat Dataset, the ultimate dataset designed to bring your AI waifu to life! üíñ If you've ever dreamed of building an AI that responds like your virtual girlfriend, THIS is the dataset for you.\nüìú What‚Äôs Inside?\nThis dataset features two columns:\ninput ‚Üí Boyfriend‚Äôs dialogue (aka what YOU say üòâ)‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Raphael172/NSFW_Multilanguage_Chat_Dataset.","url":"https://huggingface.co/datasets/Raphael172/NSFW_Multilanguage_Chat_Dataset","creator_name":"Matteo","creator_url":"https://huggingface.co/Raphael172","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":null,"first_N":5,"first_N_keywords":["text-generation","Italian","French","English","Spanish"],"keywords_longer_than_N":true},
	{"name":"tapaco","keyword":"italian","description":"\n\t\n\t\t\n\t\tDataset Card for TaPaCo Corpus\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nA freely available paraphrase corpus for 73 languages extracted from the Tatoeba database. \nTatoeba is a crowdsourcing project mainly geared towards language learners. Its aim is to provide example sentences \nand translations for particular linguistic constructions and words. The paraphrase corpus is created by populating a \ngraph with Tatoeba sentences and equivalence links between sentences ‚Äúmeaning the same thing‚Äù. This‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/community-datasets/tapaco.","url":"https://huggingface.co/datasets/community-datasets/tapaco","creator_name":"Community Datasets","creator_url":"https://huggingface.co/community-datasets","license_name":"Creative Commons Attribution 2.0","license_url":"https://scancode-licensedb.aboutcode.org/cc-by-2.0.html","language":"en","first_N":5,"first_N_keywords":["translation","text-classification","semantic-similarity-classification","machine-generated","crowdsourced"],"keywords_longer_than_N":true},
	{"name":"ilpost","keyword":"italian","description":"\n\t\n\t\t\n\t\tDataset Card for ilpost\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nIlPost dataset, containing news articles taken from IlPost.\nThere are two features:\n\nsource: Input news article.\ntarget: Summary of the article.\n\n\n\t\n\t\t\n\t\tSupported Tasks and Leaderboards\n\t\n\n\nabstractive-summarization, summarization\n\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nThe text in the dataset is in Italian\n\n\t\n\t\t\n\t\tLicensing Information\n\t\n\n IlPost text summarization dataset by Nicola Landro, Ignazio Gallo, Riccardo La Grassa, Edoardo Federici‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ARTeLab/ilpost.","url":"https://huggingface.co/datasets/ARTeLab/ilpost","creator_name":"Applied Recognition Technology Laboratory","creator_url":"https://huggingface.co/ARTeLab","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["summarization","monolingual","Italian","cc-by-4.0","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"mkqa","keyword":"italian","description":"We introduce MKQA, an open-domain question answering evaluation set comprising 10k question-answer pairs sampled from the Google Natural Questions dataset, aligned across 26 typologically diverse languages (260k question-answer pairs in total). For each query we collected new passage-independent answers. These queries and answers were then human translated into 25 Non-English languages.","url":"https://huggingface.co/datasets/apple/mkqa","creator_name":"Apple","creator_url":"https://huggingface.co/apple","license_name":"Creative Commons Attribution 3.0","license_url":"https://scancode-licensedb.aboutcode.org/cc-by-3.0.html","language":null,"first_N":5,"first_N_keywords":["question-answering","open-domain-qa","crowdsourced","found","multilingual"],"keywords_longer_than_N":true},
	{"name":"multi_para_crawl","keyword":"italian","description":"Parallel corpora from Web Crawls collected in the ParaCrawl project and further processed for making it a multi-parallel corpus by pivoting via English. Here we only provide the additional language pairs that came out of pivoting. The bitexts for English are available from the ParaCrawl release.\n40 languages, 669 bitexts\ntotal number of files: 40\ntotal number of tokens: 10.14G\ntotal number of sentence fragments: 505.48M\n\nPlease, acknowledge the ParaCrawl project at http://paracrawl.eu. This version is derived from the original release at their website adjusted for redistribution via the OPUS corpus collection. Please, acknowledge OPUS as well for this service.","url":"https://huggingface.co/datasets/Helsinki-NLP/multi_para_crawl","creator_name":"Language Technology Research Group at the University of Helsinki","creator_url":"https://huggingface.co/Helsinki-NLP","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":null,"first_N":5,"first_N_keywords":["translation","found","found","multilingual","original"],"keywords_longer_than_N":true},
	{"name":"ml_spoken_words","keyword":"italian","description":"Multilingual Spoken Words Corpus is a large and growing audio dataset of spoken\nwords in 50 languages collectively spoken by over 5 billion people, for academic\nresearch and commercial applications in keyword spotting and spoken term search,\nlicensed under CC-BY 4.0. The dataset contains more than 340,000 keywords,\ntotaling 23.4 million 1-second spoken examples (over 6,000 hours). The dataset\nhas many use cases, ranging from voice-enabled consumer devices to call center\nautomation. This dataset is generated by applying forced alignment on crowd-sourced sentence-level\naudio to produce per-word timing estimates for extraction.\nAll alignments are included in the dataset.","url":"https://huggingface.co/datasets/MLCommons/ml_spoken_words","creator_name":"MLCommons","creator_url":"https://huggingface.co/MLCommons","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":null,"first_N":5,"first_N_keywords":["audio-classification","machine-generated","other","multilingual","extended|common_voice"],"keywords_longer_than_N":true},
	{"name":"swissner","keyword":"italian","description":"\n\t\n\t\t\n\t\tSwissNER\n\t\n\nA multilingual test set for named entity recognition (NER) on Swiss news articles.\n\n\t\n\t\t\n\t\tDescription\n\t\n\nSwissNER is a dataset for named entity recognition based on manually annotated news articles in Swiss Standard German, French, Italian, and Romansh Grischun.\nWe have manually annotated a selection of articles that have been published in February 2023 in the categories \"Switzerland\" or \"Regional\" on the following online news portals:\n\nSwiss Standard German: srf.ch‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ZurichNLP/swissner.","url":"https://huggingface.co/datasets/ZurichNLP/swissner","creator_name":"University of Zurich, Department of Computational Linguistics","creator_url":"https://huggingface.co/ZurichNLP","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["token-classification","named-entity-recognition","multilingual","German","French"],"keywords_longer_than_N":true},
	{"name":"seeweb-llama-it-set","keyword":"italian","description":"itsrocchi/seeweb-llama-it-set dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/itsrocchi/seeweb-llama-it-set","creator_name":"Lorenzo Rocchi","creator_url":"https://huggingface.co/itsrocchi","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","Italian","apache-2.0","< 1K","json"],"keywords_longer_than_N":true},
	{"name":"mqnli","keyword":"italian","description":"SachinPatel248/mqnli dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/SachinPatel248/mqnli","creator_name":"Patel","creator_url":"https://huggingface.co/SachinPatel248","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","English","German","Spanish","Arabic"],"keywords_longer_than_N":true},
	{"name":"openassistant-llama-style","keyword":"italian","description":"\n\t\n\t\t\n\t\tChat Fine-tuning Dataset - Llama 2 Style\n\t\n\nThis dataset allows for fine-tuning chat models using [INST] AND [/INST] to wrap user messages.\nPreparation:\n\nThe dataset is cloned from TimDettmers, which itself is a subset of the Open Assistant dataset, which you can find here. This subset of the data only contains the highest-rated paths in the conversation tree, with a total of 9,846 samples.\nThe dataset was then filtered to:\n\n\nreplace instances of '### Human:' with '[INST]'\nreplace‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Trelis/openassistant-llama-style.","url":"https://huggingface.co/datasets/Trelis/openassistant-llama-style","creator_name":"Trelis","creator_url":"https://huggingface.co/Trelis","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["English","Spanish","Russian","German","Polish"],"keywords_longer_than_N":true},
	{"name":"mapa-eur-lex","keyword":"italian","description":"\n\t\n\t\t\n\t\tDataset Card for Multilingual European Datasets for Sensitive Entity Detection in the Legal Domain\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset is a completed version of the MAPA EUR-LEX dataset, originally converted to Huggingface format by joelniklaus. See the dataset card for more information about MAPA.\n3 of the (Spanish) EUR-LEX WebAnno TSV files in the source MAPA repository are malformed, so they were omitted from the original conversion, causing under-representation of the‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/dglover1/mapa-eur-lex.","url":"https://huggingface.co/datasets/dglover1/mapa-eur-lex","creator_name":"D Glover","creator_url":"https://huggingface.co/dglover1","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["token-classification","named-entity-recognition","other","found","multilingual"],"keywords_longer_than_N":true},
	{"name":"lawinstruct","keyword":"italian","description":"LawInstruct is an instruction tuning dataset of multilingual legal documents.","url":"https://huggingface.co/datasets/lawinstruct/lawinstruct","creator_name":"lawinstruct","creator_url":"https://huggingface.co/lawinstruct","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":null,"first_N":5,"first_N_keywords":["fill-mask","other","found","multilingual","original"],"keywords_longer_than_N":true},
	{"name":"documentazioneai","keyword":"italian","description":"donnyweb/documentazioneai dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/donnyweb/documentazioneai","creator_name":"Claudio D'Onofrio","creator_url":"https://huggingface.co/donnyweb","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["Italian","apache-2.0","< 1K","json","Text"],"keywords_longer_than_N":true},
	{"name":"MedExpQA","keyword":"italian","description":"\n    \n    \n    \n\n\n\t\n\t\t\n\t\tMexExpQA: Multilingual Benchmarking of Medical QA with reference gold explanations and Retrieval Augmented Generation (RAG)\n\t\n\nWe present a new multilingual parallel medical benchmark, MedExpQA, for the evaluation of LLMs on Medical Question Answering.\nThis benchmark can be used for various NLP tasks including: Medical Question Answering or Explanation Generation.\nAlthough the design of MedExpQA is independent of any specific dataset, for the first version of the‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/HiTZ/MedExpQA.","url":"https://huggingface.co/datasets/HiTZ/MedExpQA","creator_name":"HiTZ zentroa","creator_url":"https://huggingface.co/HiTZ","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","question-answering","English","Spanish","French"],"keywords_longer_than_N":true},
	{"name":"amazon_massive_intent","keyword":"italian","description":"\n  MassiveIntentClassification\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nMASSIVE: A 1M-Example Multilingual Natural Language Understanding Dataset with 51 Typologically-Diverse Languages\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2c\n\n\nDomains\nSpoken\n\n\nReference\nhttps://arxiv.org/abs/2204.08582\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask = mteb.get_tasks([\"MassiveIntentClassification\"])\nevaluator =‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/amazon_massive_intent.","url":"https://huggingface.co/datasets/mteb/amazon_massive_intent","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","human-annotated","translated","Afrikaans","Amharic"],"keywords_longer_than_N":true},
	{"name":"degeneration-html-multilingual","keyword":"italian","description":"\n\t\n\t\t\n\t\tThe Degeneration of the Nation Multilingual Dataset\n\t\n\nThis dataset contains the complete content of The Degeneration of the Nation project, a comprehensive philosophical and cultural website exploring the intersection of technology, artificial intelligence, and human culture. The content includes philosophical essays, cultural analysis, and contemporary literature, with complex parallel structure and sophisticated HTML architecture across all language versions.\n\n\t\n\t\t\n\t\n\t\n\t\tDataset‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Degeneration-Nation/degeneration-html-multilingual.","url":"https://huggingface.co/datasets/Degeneration-Nation/degeneration-html-multilingual","creator_name":"The Degeneration of the Nation","creator_url":"https://huggingface.co/Degeneration-Nation","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["translation","text2text-generation","text-generation","text-classification","token-classification"],"keywords_longer_than_N":true},
	{"name":"ericksonian-core-competencies-multilingual","keyword":"italian","description":"This dataset is designed to improve the cross-lingual alignment of sentence embeddings related to the work of Milton H. Erickson. Each row contains an English sentence paired with its translation in one of four target languages: French, Spanish, Italian, or Portuguese. The dataset can be used to fine-tune cross-lingual alignment using the tools and procedures developed by SBERT.\nMilton H. Erickson (1901‚Äì1980) was a historically significant hypnotherapist and a pioneer of brief therapy. The‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/LoneWolfgang/ericksonian-core-competencies-multilingual.","url":"https://huggingface.co/datasets/LoneWolfgang/ericksonian-core-competencies-multilingual","creator_name":"Jordan Wolfgang Klein","creator_url":"https://huggingface.co/LoneWolfgang","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["translation","English","Italian","Portuguese","Spanish"],"keywords_longer_than_N":true},
	{"name":"finepdfs","keyword":"italian","description":"\n\nLiberating 3T of the finest tokens from PDFs\n\n\n\t\n\t\t\n\t\tWhat is this?\n\t\n\nAs we run out of web pages to process, the natural question has always been: what to do next? Only a few knew about a data source that everyone avoided for ages, due to its incredible extraction cost and complexity: PDFs.\nüìÑ FinePDFs is exactly that. It is the largest publicly available corpus sourced exclusively from PDFs, containing about 3 trillion tokens across 475 million documents in 1733 languages.\nCompared to HTML‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/HuggingFaceFW/finepdfs.","url":"https://huggingface.co/datasets/HuggingFaceFW/finepdfs","creator_name":"FineData","creator_url":"https://huggingface.co/HuggingFaceFW","license_name":"Open Data Commons Attribution License v1.0","license_url":"https://scancode-licensedb.aboutcode.org/odc-by-1.0.html","language":"en","first_N":5,"first_N_keywords":["text-generation","Arifama-Miniafia","Ankave","Abau","Amarasi"],"keywords_longer_than_N":true},
	{"name":"Question-Sparql","keyword":"italian","description":"\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset contains 895,954 examples of natural language questions paired with their corresponding SPARQL queries. It spans 12 languages and targets 15 distinct knowledge graphs, with a significant portion focused on Wikidata and DBpedia.\nThe dataset was developed as a contribution for the Master Thesis: \"Impact of Continual Multilingual Pre-training on Cross-Lingual Transferability for Source Languages\". Its purpose is to facilitate research in text-to-SPARQL‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/julioc-p/Question-Sparql.","url":"https://huggingface.co/datasets/julioc-p/Question-Sparql","creator_name":"Julio Perez","creator_url":"https://huggingface.co/julioc-p","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-generation","English","German","Hebrew","Kannada"],"keywords_longer_than_N":true},
	{"name":"EuroGEC-7","keyword":"italian","description":"\n\t\n\t\t\n\t\tEuroGEC-7: A Growing Multilingual Dataset for Grammatical Error Correction\n\t\n\nEuroGEC-7 is a large-scale, synthetic, multilingual grammatical error correction (GEC) dataset created using the Mistral API. It is specifically designed to simulate learner-style grammar mistakes across 7 major European languages ‚Äî with over 20,000 annotated pairs and counting.\nThis dataset is actively maintained and continuously expanding, both in scale and coverage. New entries are generated daily from a‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/NoeFlandre/EuroGEC-7.","url":"https://huggingface.co/datasets/NoeFlandre/EuroGEC-7","creator_name":"No√© Flandre","creator_url":"https://huggingface.co/NoeFlandre","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["English","French","Spanish","German","Italian"],"keywords_longer_than_N":true},
	{"name":"Granary","keyword":"italian","description":"\n\t\n\t\t\n\t\tGranary: Speech Recognition and Translation Dataset in 25 European Languages\n\t\n\nGranary is a large-scale, open-source multilingual speech dataset covering 25 European languages for Automatic Speech Recognition (ASR) and Automatic Speech Translation (AST) tasks. \n\n\n\n\t\n\t\t\n\n\n\n\n\t\t\n\n\n\n\n\t\n\n\n\n\n\n\t\n\t\n\t\n\t\tOverview\n\t\n\nGranary addresses the scarcity of high-quality speech data for low-resource languages by consolidating multiple datasets under a unified framework:\nüó£Ô∏è ~1M hours of high-quality‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/nvidia/Granary.","url":"https://huggingface.co/datasets/nvidia/Granary","creator_name":"NVIDIA","creator_url":"https://huggingface.co/nvidia","license_name":"Creative Commons Attribution 3.0","license_url":"https://scancode-licensedb.aboutcode.org/cc-by-3.0.html","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","translation","Bulgarian","Czech","Danish"],"keywords_longer_than_N":true},
	{"name":"unicopf","keyword":"italian","description":"Proclama/unicopf dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/Proclama/unicopf","creator_name":"ROSARIO EMMI","creator_url":"https://huggingface.co/Proclama","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["Italian","apache-2.0","1K - 10K","json","Text"],"keywords_longer_than_N":true},
	{"name":"xP3x","keyword":"italian","description":"\n\t\n\t\t\n\t\tDataset Card for xP3x\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\n\nxP3x (Crosslingual Public Pool of Prompts eXtended) is a collection of prompts & datasets across 277 languages & 16 NLP tasks. It contains all of xP3 + much more! It is used for training future contenders of mT0 & BLOOMZ at project Aya @Cohere Labs üß°\n\n\nCreation: The dataset can be recreated using instructions available here together with the file in this repository named xp3x_create.py. We provide this version to save processing‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/CohereLabs/xP3x.","url":"https://huggingface.co/datasets/CohereLabs/xP3x","creator_name":"Cohere Labs","creator_url":"https://huggingface.co/CohereLabs","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["other","expert-generated","crowdsourced","multilingual","Afrikaans"],"keywords_longer_than_N":true},
	{"name":"italian_ner_dataset","keyword":"italian","description":"\n\t\n\t\t\n\t\tItalian NER dataset\n\t\n\n\n\t\n\t\t\n\t\tAcknowledgement\n\t\n\nThis dataset had been created as part of joint research of HUMADEX research group (https://www.linkedin.com/company/101563689/) and has received funding by the European Union Horizon Europe Research and Innovation Program project SMILE (grant number 101080923) and Marie Sk≈Çodowska-Curie Actions (MSCA) Doctoral Networks, project BosomShield ((rant number 101073222). Responsibility for the information and views expressed herein lies‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/HUMADEX/italian_ner_dataset.","url":"https://huggingface.co/datasets/HUMADEX/italian_ner_dataset","creator_name":"HUMADEX Research Group","creator_url":"https://huggingface.co/HUMADEX","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["token-classification","Italian","apache-2.0","100K - 1M","parquet"],"keywords_longer_than_N":true},
	{"name":"italian_ner_dataset","keyword":"italian","description":"\n\t\n\t\t\n\t\tItalian NER dataset\n\t\n\n\n\t\n\t\t\n\t\tAcknowledgement\n\t\n\nThis dataset had been created as part of joint research of HUMADEX research group (https://www.linkedin.com/company/101563689/) and has received funding by the European Union Horizon Europe Research and Innovation Program project SMILE (grant number 101080923) and Marie Sk≈Çodowska-Curie Actions (MSCA) Doctoral Networks, project BosomShield ((rant number 101073222). Responsibility for the information and views expressed herein lies‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/HUMADEX/italian_ner_dataset.","url":"https://huggingface.co/datasets/HUMADEX/italian_ner_dataset","creator_name":"HUMADEX Research Group","creator_url":"https://huggingface.co/HUMADEX","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["token-classification","Italian","apache-2.0","100K - 1M","parquet"],"keywords_longer_than_N":true},
	{"name":"wiki-talks","keyword":"italian","description":"\n\t\n\t\t\n\t\tWiki-Talks\n\t\n\nThe Wiki-Talks dataset is a collection of conversational threads extracted from the talk pages on Wikipedia.\nThis dataset captures collaborative dialogue, discussion patterns, and consensus-building among Wikipedia contributors.\nIt is useful for NLP research focused on dialogue, sentiment analysis, and community dynamics.\n\n\t\n\t\t\n\t\tDetails\n\t\n\nCurrently due to PyArrow incompatibility to the long recursive structures in the dataset there is an intrinsic incompatibility‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/lflage/wiki-talks.","url":"https://huggingface.co/datasets/lflage/wiki-talks","creator_name":"Lucas Fonseca Lage","creator_url":"https://huggingface.co/lflage","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["English","German","Portuguese","Spanish","French"],"keywords_longer_than_N":true},
	{"name":"llm-metric-mrewardbench","keyword":"italian","description":"rifqifarhansyah/llm-metric-mrewardbench dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/rifqifarhansyah/llm-metric-mrewardbench","creator_name":"Mohammad Rifqi Farhansyah","creator_url":"https://huggingface.co/rifqifarhansyah","license_name":"Open Data Commons Attribution License v1.0","license_url":"https://scancode-licensedb.aboutcode.org/odc-by-1.0.html","language":"en","first_N":5,"first_N_keywords":["Arabic","Chinese","Czech","Dutch","French"],"keywords_longer_than_N":true},
	{"name":"mls_sidon","keyword":"italian","description":"\n\t\n\t\t\n\t\tMLS-Sidon\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is a cleansed version of Multilingual LibriSpeech (MLS) with Sidon speech restoration mode for Speech Synthesis and Spoken Language Modeling.  \nThe dataset is provided in WebDataset format for efficient large-scale training.  \n\nSource: Multilingual LibriSpeech\nLanguages: English, German, French, Spanish, Italian, Portuguese, Polish, Dutch  \nFormat: WebDataset (.tar shards)  \nLicense: CC-BY-4.0\n\n\n\n\t\n\t\n\t\n\t\tDataset Structure\n\t\n\nEach sample in‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/sarulab-speech/mls_sidon.","url":"https://huggingface.co/datasets/sarulab-speech/mls_sidon","creator_name":"SaruLab Speech group","creator_url":"https://huggingface.co/sarulab-speech","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":null,"first_N":5,"first_N_keywords":["text-to-speech","English","French","German","Spanish"],"keywords_longer_than_N":true},
	{"name":"DATA-AI_Conversation_ITA","keyword":"italian","description":"\n\t\n\t\t\n\t\tItaliano / Italian Conversations Dataset - M.INC\n\t\n\nIT | Italiano\nBenvenuti nel Dataset di Conversazioni in Italiano, realizzato da M.INC e pubblicato da Mattimax su Hugging Face. Questo dataset √® pensato per l'addestramento e la valutazione di modelli linguistici in lingua italiana, ed √® composto da oltre 10.000 coppie prompt-response.\nTutte le conversazioni sono in italiano naturale e coprono una vasta gamma di domande e risposte, utili per il fine-tuning di modelli LLM, chatbot‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Mattimax/DATA-AI_Conversation_ITA.","url":"https://huggingface.co/datasets/Mattimax/DATA-AI_Conversation_ITA","creator_name":"M.INC.","creator_url":"https://huggingface.co/Mattimax","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","Italian","apache-2.0","10K - 100K","json"],"keywords_longer_than_N":true},
	{"name":"bhojpuri","keyword":"italian","description":"\n\t\n\t\t\n\t\n\t\n\t\tFLEURS\n\t\n\nFleurs is the speech version of the FLoRes machine translation benchmark. \nWe use 2009 n-way parallel sentences from the FLoRes dev and devtest publicly available sets, in 102 languages. \nTraining sets have around 10 hours of supervision. Speakers of the train sets are different than speakers from the dev/test sets. Multilingual fine-tuning is\nused and ‚Äùunit error rate‚Äù (characters, signs) of all languages is averaged. Languages and results are also grouped into seven‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ankur02/bhojpuri.","url":"https://huggingface.co/datasets/ankur02/bhojpuri","creator_name":"Ankur Verma","creator_url":"https://huggingface.co/ankur02","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","expert-generated","crowdsourced","machine-generated","crowdsourced"],"keywords_longer_than_N":true},
	{"name":"vox-communis-parallel-g2p","keyword":"italian","description":"\n\t\n\t\t\n\t\tVoxCommunis Parallel G2P dataset\n\t\n\nThis dataset was derived from the VoxCommunis Corpus to provide pairs of utterances along with their\ncorresponding phonemes, side by side, as to ease the training of grapheme-to-phoneme (G2P) models.\nThe original VoxCommunis Corpus features force-aligned TextGrids with phone- and word-level segmentations derived from the Mozilla Common Voice Corpus.\nThe lexicons were developed using Epitran, the XPF Corpus, Charsiu, and some custom dictionaries.‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/fdemelo/vox-communis-parallel-g2p.","url":"https://huggingface.co/datasets/fdemelo/vox-communis-parallel-g2p","creator_name":"Fl√°vio Eler De Melo","creator_url":"https://huggingface.co/fdemelo","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["Abkhaz","Amharic","Bashkir","Belarusian","Bulgarian"],"keywords_longer_than_N":true},
	{"name":"IDRE","keyword":"italian","description":"SimoneManai/IDRE dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/SimoneManai/IDRE","creator_name":"Simone Manai","creator_url":"https://huggingface.co/SimoneManai","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text2text-generation","Italian","mit","< 1K","csv"],"keywords_longer_than_N":true},
	{"name":"multilingual_translation_gen_binarized","keyword":"italian","description":"Youseff1987/multilingual_translation_gen_binarized dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/Youseff1987/multilingual_translation_gen_binarized","creator_name":"JOON HYOUNG JUN","creator_url":"https://huggingface.co/Youseff1987","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["translation","Korean","English","Chinese","Zulu"],"keywords_longer_than_N":true},
	{"name":"Maestra-Translation-Instruct-Ita","keyword":"italian","description":"puettmann/Maestra-Translation-Instruct-Ita dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/puettmann/Maestra-Translation-Instruct-Ita","creator_name":"Leonard P√ºttmann","creator_url":"https://huggingface.co/puettmann","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["English","Italian","apache-2.0","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"domain-translations","keyword":"italian","description":"\n\t\n\t\t\n\t\tMultilingual Domain Name Translations Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset contains 155,004 domain names with their multilingual translations across 20 languages. Each domain has been segmented into constituent words and translated while preserving semantic meaning and commercial appeal. The dataset is particularly valuable for domain name research, multilingual NLP tasks, and understanding how brand names and concepts translate across languages.\n\n\t\n\t\t\n\t\tDataset‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/humbleworth/domain-translations.","url":"https://huggingface.co/datasets/humbleworth/domain-translations","creator_name":"HumbleWorth","creator_url":"https://huggingface.co/humbleworth","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["translation","text-generation","feature-extraction","multilingual","Arabic"],"keywords_longer_than_N":true},
	{"name":"truthful_qa_italian","keyword":"italian","description":"\n\t\n\t\t\n\t\tTruthfulQA - Italian (IT)\n\t\n\nThis dataset is an Italian translation of TruthfulQA. TruthfulQA is a dataset for fact-based question answering, which contains questions that require factual knowledge to answer correctly. These questions are designed so that some humans would answer them incorrectly because of common misconceptions.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\nThe dataset is a question answering dataset that contains questions that require factual knowledge to answer correctly and avoid‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/sapienzanlp/truthful_qa_italian.","url":"https://huggingface.co/datasets/sapienzanlp/truthful_qa_italian","creator_name":"Sapienza NLP, Sapienza University of Rome","creator_url":"https://huggingface.co/sapienzanlp","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","Italian","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"DIMMI","keyword":"italian","description":"\n\t\n\t\t\n\t\tDataset Card for Dataset Name\n\t\n\nDIMMI - Drug InforMation Mining in Italian\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nDIMMI consists of 600 Italian drug package leaflets. \nThe documents in the DIMMI exhibit a wide range of lengths, with the shortest document containing 363 tokens and the longest extending to 11,730 tokens.\n\nCurated by: Raffaele Manna, Maria Pia di Buono, Luca Giordano\n-- Language(s) (NLP): Italian\nLicense: [More Information Needed]\n\n\n\t\n\t\t\n\t\tDataset‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/RafaMann/DIMMI.","url":"https://huggingface.co/datasets/RafaMann/DIMMI","creator_name":"Raffaele Manna","creator_url":"https://huggingface.co/RafaMann","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["Italian","cc-by-4.0","< 1K","Text","üá∫üá∏ Region: US"],"keywords_longer_than_N":true},
	{"name":"reflection-small-sonnet","keyword":"italian","description":"\n\t\n\t\t\n\t\tVerified reasoning examples\n\t\n\n","url":"https://huggingface.co/datasets/efederici/reflection-small-sonnet","creator_name":"Edoardo Federici","creator_url":"https://huggingface.co/efederici","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text2text-generation","Italian","apache-2.0","< 1K","parquet"],"keywords_longer_than_N":true},
	{"name":"sentiment-analysis-test","keyword":"italian","description":"\n\t\n\t\t\n\t\tProgetto scolastico per l'analisi dei sentimenti\n\t\n\nIl dataset √® stato creato con un questionario online in cui si chiedeva ad un pubblico di studenti, docenti, personale amministrativo, famiglie di rispondere ad alcune domande sul loro rapporto con la scuola.\nLe annotazioni sono state effettuate correlando le risposte testuali ad indicatori di gradimento.\nIl dataset √® stato realizzato all'interno di un corso pomeridiano scolastico dedicato all'intelligenza artificiale.\nGrazie a tutti‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/MarcPal08/sentiment-analysis-test.","url":"https://huggingface.co/datasets/MarcPal08/sentiment-analysis-test","creator_name":"Marco Palumbo","creator_url":"https://huggingface.co/MarcPal08","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","sentiment-analysis","expert-generated","crowdsourced","crowdsourced"],"keywords_longer_than_N":true},
	{"name":"fineweb2hq-vs-c4","keyword":"italian","description":"This dataset includes 5000 rows per language from each of two sources: the higher-quality epfml/FineWeb2-HQ\nand the lower-quality allenai/c4. The data is split 80/20 into training and test sets.\nLanguages were carefully chosen to ensure balanced representation across both splits:\nArabic, Chinese, Czech, Danish, Dutch, French, German, Greek, Hungarian, Indonesian, Italian, Japanese, Persian, Polish, Portuguese, Russian, Spanish, Swedish, Turkish, and Vietnamese.\n","url":"https://huggingface.co/datasets/agentlans/fineweb2hq-vs-c4","creator_name":"Alan Tseng","creator_url":"https://huggingface.co/agentlans","license_name":"Open Data Commons Attribution License v1.0","license_url":"https://scancode-licensedb.aboutcode.org/odc-by-1.0.html","language":"en","first_N":5,"first_N_keywords":["text-classification","Portuguese","Danish","Persian","German"],"keywords_longer_than_N":true},
	{"name":"biomedical-mmlu-ita","keyword":"italian","description":"\n\t\n\t\t\n\t\tDataset Card for Dataset Name\n\t\n\nItalian translation of the biomedical-related part of the MMLU evaluation dataset described in Measuring Massive Multitask Language Understanding by Dan Hendrycks, Collin Burns, Steven Basart, Andy Zou, Mantas Mazeika, Dawn Song, and Jacob Steinhardt (ICLR 2021).\n","url":"https://huggingface.co/datasets/Detsutut/biomedical-mmlu-ita","creator_name":"Tommaso Mario Buonocore","creator_url":"https://huggingface.co/Detsutut","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["question-answering","Italian","mit","1K - 10K","parquet"],"keywords_longer_than_N":true},
	{"name":"lambada_openai","keyword":"italian","description":"\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset is comprised of the LAMBADA test split as pre-processed by OpenAI (see relevant discussions here and here). It also contains machine translated versions of the split in German, Spanish, French, and Italian.\nLAMBADA is used to evaluate the capabilities of computational models for text understanding by means of a word prediction task. LAMBADA is a collection of narrative texts sharing the characteristic that human subjects are able to guess their last word‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/EleutherAI/lambada_openai.","url":"https://huggingface.co/datasets/EleutherAI/lambada_openai","creator_name":"EleutherAI","creator_url":"https://huggingface.co/EleutherAI","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["language-modeling","machine-generated","translation","lambada","German"],"keywords_longer_than_N":true},
	{"name":"llm-metric-mrewardbench","keyword":"italian","description":"rubricreward/llm-metric-mrewardbench dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/rubricreward/llm-metric-mrewardbench","creator_name":"rubricreward","creator_url":"https://huggingface.co/rubricreward","license_name":"Open Data Commons Attribution License v1.0","license_url":"https://scancode-licensedb.aboutcode.org/odc-by-1.0.html","language":"en","first_N":5,"first_N_keywords":["Arabic","Chinese","Czech","Dutch","French"],"keywords_longer_than_N":true},
	{"name":"phonetic-piper-recording-studio-prompts","keyword":"italian","description":"\n\t\n\t\t\n\t\tPhonetic Piper Studio Recordings Prompts\n\t\n\nThis dataset is a processed version of an utterance dataset made available for various languages as prompts for the Piper recording studio. Along with the original prompts, we include:\n\ncolumns ipa_espeak and ipa_epitran containing phonemized versions of the original sentences according to espeak-ng and Epitran phonemizers, respectively\ncolumns lang, espeak_lang_code, epitran_lang_code containing the language codes as reported by piper‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/fdemelo/phonetic-piper-recording-studio-prompts.","url":"https://huggingface.co/datasets/fdemelo/phonetic-piper-recording-studio-prompts","creator_name":"Fl√°vio Eler De Melo","creator_url":"https://huggingface.co/fdemelo","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["Afrikaans","Arabic","Bulgarian","Catalan","Czech"],"keywords_longer_than_N":true},
	{"name":"multihal","keyword":"italian","description":"\n\t\n\t\t\n\t\tDataset Card for MultiHal\n\t\n\nBenchmark (test-only) intended for generative-form question answering grounded on knowledge graphs. \nMultiHal contains approximately 7k unique questions and 25.9k unique KG paths, some questions contain multiple candidate paths.\nThe benchmark is designed to support research for factual language modeling with a focus on providing a test bed for LLM hallucination evaluation and\nLLM knowledge updating based on KG paths in multilingual setting. See the paper‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ernlavr/multihal.","url":"https://huggingface.co/datasets/ernlavr/multihal","creator_name":"Ernests Lavrinovics","creator_url":"https://huggingface.co/ernlavr","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["question-answering","English","Spanish","French","Portuguese"],"keywords_longer_than_N":true},
	{"name":"AMELIA","keyword":"italian","description":"\n\t\n\t\t\n\t\tDataset Card for AMELIA - Argument Mining Evaluation on Legal documents in ItAlian: A CALAMITA Challenge\n\t\n\nThis dataset consists of argumentative components extracted from 225 Italian decisions on Value Added Tax, annotated to identify and categorize argumentative text. \nThe proposed tasks consists of three classifications, in the context of argument mining in the legal domain. \nThe objective of the first task is to classify each argumentative component as premise or conclusion, while‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/nlp-unibo/AMELIA.","url":"https://huggingface.co/datasets/nlp-unibo/AMELIA","creator_name":"Language Technologies Lab @UNIBO","creator_url":"https://huggingface.co/nlp-unibo","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","Italian","cc-by-4.0","1K - 10K","parquet"],"keywords_longer_than_N":true},
	{"name":"V1Q","keyword":"italian","description":"from datasets import load_dataset\nds = load_dataset(\"b3x0m/Chinese-H-Novels\")\nimport sagemaker\nimport boto3\nfrom sagemaker.huggingface import HuggingFaceModel\ntry:\n    role = sagemaker.get_execution_role()\nexcept ValueError:\n    iam = boto3.client('iam')\n    role = iam.get_role(RoleName='sagemaker_execution_role')['Role']['Arn']\n\n\t\n\t\t\n\t\tHub Model configuration. https://huggingface.co/models\n\t\n\nhub = {\n    'HF_MODEL_ID':'deepseek-ai/Janus-Pro-7B',\n    'HF_TASK':'any-to-any'\n}\n\n\t\n\t\t\n\t\tcreate‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/YuRiVeRTi/V1Q.","url":"https://huggingface.co/datasets/YuRiVeRTi/V1Q","creator_name":"YuRiVeRTical","creator_url":"https://huggingface.co/YuRiVeRTi","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","table-question-answering","question-answering","zero-shot-classification"],"keywords_longer_than_N":true},
	{"name":"LLM_Multilingual_dataset","keyword":"italian","description":"\n\t\n\t\t\n\t\tDataset Card for Dataset Name\n\t\n\n\n\nThis dataset card aims to be a base template for new datasets. It has been generated using this raw template.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\n\n\n\n\n\nCurated by: [More Information Needed]\nFunded by [optional]: [More Information Needed]\nShared by [optional]: [More Information Needed]\nLanguage(s) (NLP): [More Information Needed]\nLicense: [More Information Needed]\n\n\n\t\n\t\t\n\t\tDataset Sources [optional]\n\t\n\n\n\n\nRepository: [More‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/lewishamilton21/LLM_Multilingual_dataset.","url":"https://huggingface.co/datasets/lewishamilton21/LLM_Multilingual_dataset","creator_name":"Kesavprabu","creator_url":"https://huggingface.co/lewishamilton21","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["table-question-answering","Japanese","Finnish","Indonesian","Russian"],"keywords_longer_than_N":true},
	{"name":"truthful_qa_ita","keyword":"italian","description":"\n\t\n\t\t\n\t\tDataset Card TruthfulQA (ita)\n\t\n\n\n\nThis dataset is a machine-translated version of truthful_qa into Italian.\n\nLicensed under CC-BY 4.0\nTranslated with TowerInstruct-7B-v0.2\nMore details and code used for translation will follow shortly.\n\nThe rest of the page is WIP :)\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Description\n\t\n\n\n\n\nCurated by: [More Information Needed]\nFunded by [optional]: [More Information Needed]\nShared by [optional]: [More Information Needed]\nLanguage(s) (NLP):‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/RiTA-nlp/truthful_qa_ita.","url":"https://huggingface.co/datasets/RiTA-nlp/truthful_qa_ita","creator_name":"Risorse per la Lingua Italiana","creator_url":"https://huggingface.co/RiTA-nlp","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","Italian","cc-by-4.0","1K - 10K","parquet"],"keywords_longer_than_N":true},
	{"name":"sentiment-analysis-test","keyword":"italian","description":"\n\t\n\t\t\n\t\tprogetto scolastico per l'analisi dei sentimenti\n\t\n\nIl dataset √® stato creato con un questionario online in cui si chiedeva ad un pubblico di studenti, docenti, personake amministrativo e famiglie di rispondere ad alcune domande\nsul loro rapporto con la scuola.\nLe annotazioni sono state effettuate correlando le risposte testuali an indicatori di gradimento.\nIl dataset √® stato realizzato all'interno di un corso pomeridiano scolastico dedicato all'intelliggenza artificiale.\nGrazie a‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Giova-tech/sentiment-analysis-test.","url":"https://huggingface.co/datasets/Giova-tech/sentiment-analysis-test","creator_name":"giovanni de santis","creator_url":"https://huggingface.co/Giova-tech","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","sentiment-analysis","expert-generated","crowdsourced","crowdsourced"],"keywords_longer_than_N":true},
	{"name":"tatoeba-tokipona","keyword":"italian","description":"NetherQuartz/tatoeba-tokipona dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/NetherQuartz/tatoeba-tokipona","creator_name":"Vladimir Larkin","creator_url":"https://huggingface.co/NetherQuartz","license_name":"Creative Commons Attribution 2.0","license_url":"https://scancode-licensedb.aboutcode.org/cc-by-2.0.html","language":"en","first_N":5,"first_N_keywords":["translation","Toki Pona","English","Russian","Ukrainian"],"keywords_longer_than_N":true},
	{"name":"OpenHumanreasoning-multilingual-2.2k","keyword":"italian","description":"Based off of Pinkstackorg/humanreasoning-testing-en, it is a human-generated dataset where a real person had to create most of the reasoning and the final output. If there are any mistakes please let us know.\nWe offer this dataset at an apache-2.0 license to make it useful for everybody.\nnote: translations are not human generated.\n","url":"https://huggingface.co/datasets/Pinkstack/OpenHumanreasoning-multilingual-2.2k","creator_name":"Pinkstack","creator_url":"https://huggingface.co/Pinkstack","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","Arabic","Chinese","Czech","Danish"],"keywords_longer_than_N":true},
	{"name":"wmt24pp","keyword":"italian","description":"\n\t\n\t\t\n\t\tWMT24++\n\t\n\nThis repository contains the human translation and post-edit data for the 55 en->xx language pairs released in\nthe publication\nWMT24++: Expanding the Language Coverage of WMT24 to 55 Languages & Dialects.\nIf you are interested in the MT/LLM system outputs and automatic metric scores, please see MTME.\nIf you are interested in the images of the source URLs for each document, please see here.\n\n\t\n\t\t\n\t\n\t\n\t\tSchema\n\t\n\nEach language pair is stored in its own jsonl file.\nEach row is‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/google/wmt24pp.","url":"https://huggingface.co/datasets/google/wmt24pp","creator_name":"Google","creator_url":"https://huggingface.co/google","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["translation","Arabic","Bulgarian","Bengali","Catalan"],"keywords_longer_than_N":true},
	{"name":"seamless-align-expressive","keyword":"italian","description":"\n\t\n\t\t\n\t\tDataset Card for Seamless-Align-Expressive (WIP). Inspired by https://huggingface.co/datasets/allenai/nllb\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset was created based on metadata for mined expressive Speech-to-Speech(S2S) released by Meta AI.  The S2S contains data for 5 language pairs. The S2S dataset is ~228GB compressed.\n\n\t\n\t\t\n\t\tHow to use the data\n\t\n\nThere are two ways to access the data:\n\nVia the Hugging Face Python datasets library\n\nScripts coming soon\n\n\nClone the git repo\n\ngit‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/jhu-clsp/seamless-align-expressive.","url":"https://huggingface.co/datasets/jhu-clsp/seamless-align-expressive","creator_name":"Center for Language and Speech Processing @ JHU","creator_url":"https://huggingface.co/jhu-clsp","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["translation","audio-to-audio","German","English","Spanish"],"keywords_longer_than_N":true},
	{"name":"sentiment-analysis-test","keyword":"italian","description":"Il dataset √® stato creato in un questionario online in cui si chiedeva ad un pubblico di studenti, docenti, personale amministrativo, famiglie di rispondere ad alcune domande sul loro rapporto con la scuola.\nLe annotazioni sono state effettuate correlando le risposte testuali ad indicatori di gradimento.\nil dataset √® stato realizzato all'interno di un corso pomeridiano scolastico dedicato all'intelligenza artificiale\nGrazie a tutti per la collaborazione ‚ù§Ô∏è\n","url":"https://huggingface.co/datasets/qwertychri/sentiment-analysis-test","creator_name":"Christian Scimenes","creator_url":"https://huggingface.co/qwertychri","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","sentiment-analysis","crowdsourced","expert-generated","crowdsourced"],"keywords_longer_than_N":true},
	{"name":"mGeNTE-supplementary","keyword":"italian","description":"Supplementary data released alongside the paper: Mind the Inclusivity Gap: Multilingual Gender-Neutral Translation Evaluation with mGeNTE.\nThe official mGeNTE dataset is at this link.\n\n\t\n\t\t\n\t\tStructure\n\t\n\nThe supplementary material is organized as follows:\n\nattributions: contains all the token level attributions to be used with the class defined in our main repository, found at this link. Moreover, we also include a \"processed_\" version of each file where we aggregated the contributions‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/FBK-MT/mGeNTE-supplementary.","url":"https://huggingface.co/datasets/FBK-MT/mGeNTE-supplementary","creator_name":"FBK-MT","creator_url":"https://huggingface.co/FBK-MT","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["English","Spanish","Italian","German","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"modern","keyword":"italian","description":"\n\n\t\n\t\t\n\t\tDataset Card for CATMuS Modern and Contemporary (McCATMuS)\n\t\n\nJoin our Discord to ask questions about the dataset: \n\n\t\n\t\t\n\t\tDataset Details\n\t\n\nHandwritten Text Recognition (HTR) has emerged as a crucial tool for converting manuscripts images into machine-readable formats, enabling researchers and scholars to analyze vast collections efficiently. Despite significant technological progress, establishing consistent ground truth across projects for HTR tasks, particularly for complex and‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/CATMuS/modern.","url":"https://huggingface.co/datasets/CATMuS/modern","creator_name":"CATMuS: Consistent Approach to Transcribing ManuScripts","creator_url":"https://huggingface.co/CATMuS","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["image-to-text","French","German","English","Italian"],"keywords_longer_than_N":true},
	{"name":"ItaIst","keyword":"italian","description":"\n\t\n\t\t\n\t\tCorpus ItaIst\n\t\n\nThe corpus containing 198 texts was collected by the research unit of the University of Molise including linguists (Giuliana Fiorentino, Vittorio Ganfi), jurists (Alessandro Cioffi, Maria Assunta Simonelli, Ludovico Di Benedetto) and computer scientists (Rocco Oliveto, Marco Russodivito).\nThe corpus is diatopically balanced (it contains texts from the PAs of 8 Italian regions) and includes different types of administrative acts with which the PAs address citizens.‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/VerbACxSS/ItaIst.","url":"https://huggingface.co/datasets/VerbACxSS/ItaIst","creator_name":"VerbACxSS","creator_url":"https://huggingface.co/VerbACxSS","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-generation","Italian","mit","1K - 10K","csv"],"keywords_longer_than_N":true},
	{"name":"x-fact","keyword":"italian","description":"\n\t\n\t\t\n\t\tDataset Card for \"x-fact\"\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nX-FACT is a multilingual dataset for fact-checking with real world claims. The dataset contains short statments in 25 languages with top five evidence documents retrieved by performing google search with claim statements. The dataset contains two additional evaluation splits (in addition to a traditional test set): ood and zeroshot. ood measures out-of-domain generalization where while the language‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/utahnlp/x-fact.","url":"https://huggingface.co/datasets/utahnlp/x-fact","creator_name":"NLP at University of Utah","creator_url":"https://huggingface.co/utahnlp","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","Arabic","Bengali","Spanish","Persian"],"keywords_longer_than_N":true},
	{"name":"OGC_Military","keyword":"italian","description":"\n\t\n\t\t\n\t\tOGC - Organized, Grouped, Cleaned\n\t\n\n\n\t\n\t\t\n\t\tMilitary Vision DSE\n\t\n\n\nIntended for image/text to vector (DSE)\n\n\n\t\n\t\t\n\t\tDataset Composition\n\t\n\nMade with https://github.com/RacineAIOS/OGC_pdf-to-parquet\nThis dataset was created by scraping PDF documents from online sources and generating relevant synthetic queries.\nWe used Google's Gemini 2.0 Flash Lite model in our custom pipeline to produce the queries, allowing us to create a diverse set of questions based on the document content.‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/racineai/OGC_Military.","url":"https://huggingface.co/datasets/racineai/OGC_Military","creator_name":"racine.ai","creator_url":"https://huggingface.co/racineai","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["visual-document-retrieval","text-retrieval","English","French","Arabic"],"keywords_longer_than_N":true},
	{"name":"qe4pe","keyword":"italian","description":"\n\t\n\t\t\n\t\tQuality Estimation for Post-Editing (QE4PE)\n\t\n\nFor more details on QE4PE, see our paper and our Github repository\nGabriele Sarti ‚Ä¢ Vil√©m Zouhar ‚Ä¢ Grzegorz Chrupa≈Ça ‚Ä¢ Ana Guerberof Arenas ‚Ä¢ Malvina Nissim ‚Ä¢ Arianna Bisazza\n\n    \n\n\n\nWord-level quality estimation (QE) detects erroneous spans in machine translations, which can direct and facilitate human post-editing. While the accuracy of word-level QE systems has been assessed extensively, their usability and downstream influence on the‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/gsarti/qe4pe.","url":"https://huggingface.co/datasets/gsarti/qe4pe","creator_name":"Gabriele Sarti","creator_url":"https://huggingface.co/gsarti","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["translation","machine-generated","machine-generated","expert-generated","Unbabel/TowerEval-Data-v0.1"],"keywords_longer_than_N":true},
	{"name":"librivox-tracks","keyword":"italian","description":"A dataset of all audio files uploaded to LibriVox before 26th September 2023.\nForked from https://huggingface.co/datasets/pykeio/librivox-tracks\nChanges:\n\nUsed archive.org metadata API to annotate rows with \"duration\" column\n\n","url":"https://huggingface.co/datasets/xacer/librivox-tracks","creator_name":"xacer","creator_url":"https://huggingface.co/xacer","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-to-speech","automatic-speech-recognition","feature-extraction","Achinese","Afrikaans"],"keywords_longer_than_N":true},
	{"name":"fedlex-articles","keyword":"italian","description":"\n\t\n\t\t\n\t\tDataset Card for Dataset Name\n\t\n\n\n\nThis dataset card aims to be a base template for new datasets. It has been generated using this raw template.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\n\n\n\n\n\nCurated by: [More Information Needed]\nFunded by [optional]: [More Information Needed]\nShared by [optional]: [More Information Needed]\nLanguage(s) (NLP): [More Information Needed]\nLicense: [More Information Needed]\n\n\n\t\n\t\t\n\t\tDataset Sources [optional]\n\t\n\n\n\n\nRepository: [More‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/glards/fedlex-articles.","url":"https://huggingface.co/datasets/glards/fedlex-articles","creator_name":"Steve Glardon","creator_url":"https://huggingface.co/glards","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["translation","French","German","Italian","mit"],"keywords_longer_than_N":true},
	{"name":"libri-in-italiano","keyword":"italian","description":"\n\t\n\t\t\n\t\tLibri\n\t\n\nIl dataset dei libri consiste in una raccolta diversificata di 18 libri organizzati in 4 categorie.\nQuesto dataset √® ben pulito e progettato per supportare diversi compiti di elaborazione del linguaggio naturale (NLP), inclusi generazione di testo, traduzione e modellazione del linguaggio mascherato.\n\n\t\n\t\t\n\t\tDettagli\n\t\n\nIl dataset contiene 4 colonne:\n\ntitolo: Il titolo del libro.\nautore: L'autore del libro.\ncategoria: Il genere/categoria del libro.\ncontenuto: Il contenuto‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/IsmaelMousa/libri-in-italiano.","url":"https://huggingface.co/datasets/IsmaelMousa/libri-in-italiano","creator_name":"Ismael","creator_url":"https://huggingface.co/IsmaelMousa","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","translation","fill-mask","IsmaelMousa","expert-generated"],"keywords_longer_than_N":true},
	{"name":"multilingual-reward-bench","keyword":"italian","description":"\n\t\n\t\t\n\t\tMultilingual Reward Bench (v1.0)\n\t\n\nReward models (RMs) have driven the development of state-of-the-art LLMs today, with unprecedented impact across the globe. However, their performance in multilingual settings still remains understudied. \nIn order to probe reward model behavior on multilingual data, we present M-RewardBench, a benchmark for 23 typologically diverse languages. \nM-RewardBench contains prompt-chosen-rejected preference triples obtained by curating and translating chat‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/CohereLabsCommunity/multilingual-reward-bench.","url":"https://huggingface.co/datasets/CohereLabsCommunity/multilingual-reward-bench","creator_name":"Cohere Labs Community","creator_url":"https://huggingface.co/CohereLabsCommunity","license_name":"Open Data Commons Attribution License v1.0","license_url":"https://scancode-licensedb.aboutcode.org/odc-by-1.0.html","language":"en","first_N":5,"first_N_keywords":["Arabic","Chinese","Czech","Dutch","French"],"keywords_longer_than_N":true},
	{"name":"everyday-conversations-ita","keyword":"italian","description":"\n    \n      \n    \n\n\n\n\n\t\n\t\t\n\t\tüáÆüáπüí¨ Everyday Italian Conversations\n\t\n\nInspired by the dataset HuggingFaceTB/everyday-conversations-llama3.1-2k, we generated conversations using the same topics, subtopics, and sub-subtopics as those in the HuggingFaceTB dataset.We slightly adjusted the prompt to produce structured data outputs using Qwen/Qwen2.5-7B-Instruct. Subsequently, we also used the \"user\" role messages as prompts for google/gemma-2-9b-it.  \nThe result is a dataset of approximately 4.5k‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ReDiX/everyday-conversations-ita.","url":"https://huggingface.co/datasets/ReDiX/everyday-conversations-ita","creator_name":"ReDiX Labs","creator_url":"https://huggingface.co/ReDiX","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","text2text-generation","Italian","apache-2.0","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"Italian_FakeNews_detection","keyword":"italian","description":"\n\t\n\t\t\n\t\tFakeNews Detection with Wikipedia\n\t\n\nThis dataset was generated by fetching random first paragraphs from Italian Wikipedia (it.wikipedia.org)\nand processing them using Gemini AI with the following goal(s):\n\nProcessing Goal 1: Trasforma il paragrafo in un paragrafo giornalistico attendibile.\n\nProcessing Goal 2: Genera una notizia falsa distorcendo la realt√†\n\nSource Language: Italian (from Wikipedia)\n\nNumber of Rows: 189\n\nModel Used: gemini-2.5-flash-preview-04-17\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Dddixyy/Italian_FakeNews_detection.","url":"https://huggingface.co/datasets/Dddixyy/Italian_FakeNews_detection","creator_name":"Davide Brunori","creator_url":"https://huggingface.co/Dddixyy","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","gemini-ai","original:wikipedia:it","Italian","mit"],"keywords_longer_than_N":true},
	{"name":"Italian_FakeNews_detection","keyword":"italian","description":"\n\t\n\t\t\n\t\tFakeNews Detection with Wikipedia\n\t\n\nThis dataset was generated by fetching random first paragraphs from Italian Wikipedia (it.wikipedia.org)\nand processing them using Gemini AI with the following goal(s):\n\nProcessing Goal 1: Trasforma il paragrafo in un paragrafo giornalistico attendibile.\n\nProcessing Goal 2: Genera una notizia falsa distorcendo la realt√†\n\nSource Language: Italian (from Wikipedia)\n\nNumber of Rows: 189\n\nModel Used: gemini-2.5-flash-preview-04-17\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Dddixyy/Italian_FakeNews_detection.","url":"https://huggingface.co/datasets/Dddixyy/Italian_FakeNews_detection","creator_name":"Davide Brunori","creator_url":"https://huggingface.co/Dddixyy","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","gemini-ai","original:wikipedia:it","Italian","mit"],"keywords_longer_than_N":true},
	{"name":"parler_tts_mini_V01_TestVoice_Italian","keyword":"italian","description":"udanet/parler_tts_mini_V01_TestVoice_Italian dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/udanet/parler_tts_mini_V01_TestVoice_Italian","creator_name":"Ud'Anet G. D'Annunzio Chieti","creator_url":"https://huggingface.co/udanet","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["Italian","apache-2.0","< 1K","soundfolder","Audio"],"keywords_longer_than_N":true},
	{"name":"include-lite-44","keyword":"italian","description":"\n\t\n\t\t\n\t\tINCLUDE-lite (44 languages)\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\n\n\nPaper: http://arxiv.org/abs/2411.19799\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nINCLUDE is a comprehensive knowledge- and reasoning-centric benchmark across 44 languages that evaluates multilingual LLMs for performance in the actual language environments where they would be deployed. \nIt contains 11,095 4-option multiple-choice-questions (MCQ) extracted from academic and professional exams, covering 57 topics, including regional‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/CohereLabs/include-lite-44.","url":"https://huggingface.co/datasets/CohereLabs/include-lite-44","creator_name":"Cohere Labs","creator_url":"https://huggingface.co/CohereLabs","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["multiple-choice","Albanian","Arabic","Armenian","Azerbaijani"],"keywords_longer_than_N":true},
	{"name":"vdr-multilingual-test","keyword":"italian","description":"\n\t\n\t\t\n\t\tMultilingual Visual Document Retrieval Benchmarks\n\t\n\n\nThis dataset consists of 15 different benchmarks used to initially evaluate the vdr-2b-multi-v1 multimodal retrieval embedding model. These benchmarks allow the testing of multilingual, multimodal retrieval capabilities on text-only, visual-only and mixed page screenshots.\nEach language subset contains queries and images in that language and is divided into three different categories by the \"pagetype\" column. Each category contains‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/llamaindex/vdr-multilingual-test.","url":"https://huggingface.co/datasets/llamaindex/vdr-multilingual-test","creator_name":"LlamaIndex","creator_url":"https://huggingface.co/llamaindex","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["multilingual","German","Italian","French","Spanish"],"keywords_longer_than_N":true},
	{"name":"VoxCommunis","keyword":"italian","description":"\n\t\n\t\t\n\t\tVoxCommunis Corpus\n\t\n\nThe VoxCommunis Corpus is a phonetic corpus derived from the Mozilla Common Voice Corpus. Corresponding audio files and corpus metadata can be downloaded from Mozilla Common Voice, or from one of several Hugging Face repositories for the differing versions. \nWithin each folder, the filenames share similar structure and contain critical information for effectively using the file. More detail regarding the specifics of the filename for each file type is provided‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/pacscilab/VoxCommunis.","url":"https://huggingface.co/datasets/pacscilab/VoxCommunis","creator_name":"PaCSciLab @ UZH","creator_url":"https://huggingface.co/pacscilab","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["Abkhaz","Amharic","Bashkir","Belarusian","Bulgarian"],"keywords_longer_than_N":true},
	{"name":"common_voice_21_0","keyword":"italian","description":"\n\t\n\t\t\n\t\tDataset Card for Common Voice Corpus 21.0\n\t\n\n\n\nThis dataset is an unofficial version of the Mozilla Common Voice Corpus 21. It was downloaded and converted from the project's website https://commonvoice.mozilla.org/.\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nAbkhaz, Albanian, Amharic, Arabic, Armenian, Assamese, Asturian, Azerbaijani, Basaa, Bashkir, Basque, Belarusian, Bengali, Breton, Bulgarian, Cantonese, Catalan, Central Kurdish, Chinese (China), Chinese (Hong Kong), Chinese (Taiwan), Chuvash, Czech‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/fsicoli/common_voice_21_0.","url":"https://huggingface.co/datasets/fsicoli/common_voice_21_0","creator_name":"Fabio Sicoli","creator_url":"https://huggingface.co/fsicoli","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":null,"first_N":5,"first_N_keywords":["automatic-speech-recognition","Abkhaz","Afrikaans","Amharic","Arabic"],"keywords_longer_than_N":true},
	{"name":"Evolkit-mini-ita","keyword":"italian","description":"\n\t\n\t\t\n\t\tEvolkit mini ITA\n\t\n\nHigh Quality Llama3.3-70B synthetic data\n","url":"https://huggingface.co/datasets/mik3ml/Evolkit-mini-ita","creator_name":"Michele Angelo Marcucci","creator_url":"https://huggingface.co/mik3ml","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","Italian","apache-2.0","10K - 100K","json"],"keywords_longer_than_N":true},
	{"name":"quandho","keyword":"italian","description":"mik3ml/quandho dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/mik3ml/quandho","creator_name":"Michele Angelo Marcucci","creator_url":"https://huggingface.co/mik3ml","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["question-answering","Italian","apache-2.0","1K - 10K","json"],"keywords_longer_than_N":true},
	{"name":"HelpSteer3","keyword":"italian","description":"\n\t\n\t\t\n\t\tHelpSteer3\n\t\n\nHelpSteer3 is an open-source dataset (CC-BY-4.0) that supports aligning models to become more helpful in responding to user prompts.\nHelpSteer3-Preference can be used to train Llama 3.3 Nemotron Super 49B v1 (for Generative RMs) and Llama 3.3 70B Instruct Models (for Bradley-Terry RMs) to produce Reward Models that score as high as 85.5% on RM-Bench and 78.6% on JudgeBench, which substantially surpass existing Reward Models on these benchmarks.\nHelpSteer3-Feedback and‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/nvidia/HelpSteer3.","url":"https://huggingface.co/datasets/nvidia/HelpSteer3","creator_name":"NVIDIA","creator_url":"https://huggingface.co/nvidia","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["English","Chinese","Korean","French","Spanish"],"keywords_longer_than_N":true},
	{"name":"from-one-to-many-toxicity-mitigation","keyword":"italian","description":"\n\t\n\t\t\n\t\n\t\n\t\tFrom One to Many: Expanding the Scope of Toxicity Mitigation in Language Models\n\t\n\n[arxiv][code][data]\nData accompanying the paper \"From One to Many: Expanding the Scope of Toxicity Mitigation in Language Models\" accepted to ACL Findings 2024.\nAbstract: To date, toxicity mitigation in language models has almost entirely been focused on single-language settings. As language models embrace multilingual capabilities, it‚Äôs crucial our safety measures keep pace. Recognizing this‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/luizapzbn/from-one-to-many-toxicity-mitigation.","url":"https://huggingface.co/datasets/luizapzbn/from-one-to-many-toxicity-mitigation","creator_name":"Luiza Pozzobon","creator_url":"https://huggingface.co/luizapzbn","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","text-classification","English","Portuguese","Hindi"],"keywords_longer_than_N":true},
	{"name":"Multilingual-Benchmark","keyword":"italian","description":"These are the GSM8K and ARC dataset translated by Google Translate. \nBibTex\n@misc{lu2024languagecountslearnunlearn,\n      title={Every Language Counts: Learn and Unlearn in Multilingual LLMs}, \n      author={Taiming Lu and Philipp Koehn},\n      year={2024},\n      eprint={2406.13748},\n      archivePrefix={arXiv},\n      primaryClass={cs.CL},\n      url={https://arxiv.org/abs/2406.13748}, \n}\n\n","url":"https://huggingface.co/datasets/TaiMingLu/Multilingual-Benchmark","creator_name":"TaiMing","creator_url":"https://huggingface.co/TaiMingLu","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["zero-shot-classification","question-answering","translation","English","German"],"keywords_longer_than_N":true},
	{"name":"OpenSFT-ita","keyword":"italian","description":"\n\t\n\t\t\n\t\tOpenSFT ITA\n\t\n\n","url":"https://huggingface.co/datasets/open-ita-llms/OpenSFT-ita","creator_name":"Open Italian LLMs","creator_url":"https://huggingface.co/open-ita-llms","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","text2text-generation","Italian","apache-2.0","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"u-sticker","keyword":"italian","description":"\n\t\n\t\t\n\t\tU-Sticker\n\t\n\nUser-Sticker is a stickers dataset with multi-domain conversations.\nFeatures of U-Sticker:\n\nMulti-domain interactions ‚úÖ\nTemporal ‚úÖ\nUser information ‚úÖ\n370.2k stickers ‚úÖ (104k unique)\n22.6k users ‚úÖ\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nU-Sticker contains three files:\n\nConversation files: 1 to 67.json\nDomain mapping files idx_to_domain.txt.\nSticker files.\n\n\nSticker files are available here and Baidu Cloud.\n\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\n\t\n\t\t\n\t\tConversation file\n\t\n\n\nEmpty lines are‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/metchee/u-sticker.","url":"https://huggingface.co/datasets/metchee/u-sticker","creator_name":"Metilda Chee","creator_url":"https://huggingface.co/metchee","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["Arabic","Chinese","English","French","Turkish"],"keywords_longer_than_N":true},
	{"name":"multihal","keyword":"italian","description":"\n\t\n\t\t\n\t\tDataset Card for MultiHal\n\t\n\nBenchmark (test-only) intended for generative-form question answering grounded on knowledge graphs. \nMultiHal contains approximately 7k unique questions and 25.9k unique KG paths, some questions contain multiple candidate paths.\nThe benchmark is designed to support research for factual language modeling with a focus on providing a test bed for LLM hallucination evaluation and\nLLM knowledge updating based on KG paths in multilingual setting.\n\n\t\n\t\t\n\t\n\t\n\t\tUses‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/AnonymousSubmission9090/multihal.","url":"https://huggingface.co/datasets/AnonymousSubmission9090/multihal","creator_name":"Anonymous","creator_url":"https://huggingface.co/AnonymousSubmission9090","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["question-answering","English","Spanish","French","Portuguese"],"keywords_longer_than_N":true},
	{"name":"mmlux","keyword":"italian","description":"\n\t\n\t\t\n\t\tCitation Information\n\t\n\nIf you find benchmarks useful in your research, please consider citing the test and also the MMLU dataset it draws from:\n    @misc{thellmann2024crosslingual,\n    title={Towards Cross-Lingual LLM Evaluation for European Languages},\n    author={Klaudia Thellmann and Bernhard Stadler and Michael Fromm and Jasper Schulze Buschhoff and Alex Jude and Fabio Barth and Johannes Leveling and Nicolas Flores-Herr and Joachim K√∂hler and Ren√© J√§kel and Mehdi Ali}‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Eurolingua/mmlux.","url":"https://huggingface.co/datasets/Eurolingua/mmlux","creator_name":"EuroLingua-GPT","creator_url":"https://huggingface.co/Eurolingua","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":null,"first_N":5,"first_N_keywords":["multiple-choice","expert-generated","multilingual","cais/mmlu","German"],"keywords_longer_than_N":true},
	{"name":"montok","keyword":"italian","description":"\n\t\n\t\t\n\t\tMonTok: A Suite of Monolingual Tokenizers\n\t\n\nThis is a set of monolingual tokenizers for 98 languages. For each language, there are Unigram, BPE, and SuperBPE tokenizers, ranging in vocabulary size from around 6k to over 200k.\n\n\t\n\t\t\n\t\tTraining Details\n\t\n\n\n\t\n\t\t\n\t\tTraining Data\n\t\n\nAll tokenizers are trained on samples of the data used to the train the Goldfish language models. \nThe tokenizers were either trained on scaled or unscaled data. This refers to whether the models are trained on‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/catherinearnett/montok.","url":"https://huggingface.co/datasets/catherinearnett/montok","creator_name":"Catherine Arnett","creator_url":"https://huggingface.co/catherinearnett","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["Afrikaans","Tosk Albanian","Amharic","Standard Arabic","Assamese"],"keywords_longer_than_N":true},
	{"name":"unlabelled-sti-corpus","keyword":"italian","description":"\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe unlabelled-sti-corpus is a diverse dataset designed for developing information extraction datasets (i.e. text classification or NER) for Science, Technology, and Innovation (STI) records. The corpus contains approximately 35,000 records sourced from four major repositories:\n\n22,500 publications from OpenAlex\n10,000 European research projects from CORDIS\n5,000 regional projects from Interreg and Kohesio\n7,000 patents from Lens.org\n\nThe dataset is stratified‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/SIRIS-Lab/unlabelled-sti-corpus.","url":"https://huggingface.co/datasets/SIRIS-Lab/unlabelled-sti-corpus","creator_name":"SIRIS Lab, Research Division of SIRIS Academic","creator_url":"https://huggingface.co/SIRIS-Lab","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["English","Spanish","French","German","Italian"],"keywords_longer_than_N":true},
	{"name":"piper_italiano","keyword":"italian","description":"\n\t\n\t\t\n\t\tPiper Italiano\n\t\n\nSto cercando di creare un nuovo checkpoint per PiperTTS in italiano.\nLa fonte per il traine √® il Multilingual LibriSpeech (MLS) rilasciato sotto licenza Creative Commons\nQui metter√≤ i dataset estratti dal suddetto blocco dati\nIl dataset √® nel formato che gradisce PiperTTS come indicato a questo link\n\nAurora √® lo speaker 6807\nLeonardo √® lo speaker 1595 - Probabile voce di Riccardo (modello originale di piper) ma ad una maggiore qualit√†\n\n","url":"https://huggingface.co/datasets/kirys79/piper_italiano","creator_name":"Federico Improta","creator_url":"https://huggingface.co/kirys79","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-to-speech","Italian","cc-by-4.0","üá∫üá∏ Region: US"],"keywords_longer_than_N":false},
	{"name":"AIME2025-Multilingual","keyword":"italian","description":"\n\t\n\t\t\n\t\tDescription\n\t\n\nThis repository contains a multi language version of the AIME2025 dataset. \nAs the english reference version, we haved used the one created by the authors of MathArena.\nFor completness, we have included the english version also in this repository, please, refer to the one contained in the MathArena github repository for the original one (https://github.com/eth-sri/matharena/tree/main/data/aime). Many thanks to Jasper Dekoninck for the help in understanding the structure‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/fedric95/AIME2025-Multilingual.","url":"https://huggingface.co/datasets/fedric95/AIME2025-Multilingual","creator_name":"Federico Ricciuti","creator_url":"https://huggingface.co/fedric95","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["German","English","Italian","Portuguese","French"],"keywords_longer_than_N":true},
	{"name":"redeIT-json-alpaca","keyword":"italian","description":"leinad-deinor/redeIT-json-alpaca dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/leinad-deinor/redeIT-json-alpaca","creator_name":"Daniel Acampora","creator_url":"https://huggingface.co/leinad-deinor","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["Italian","apache-2.0","< 1K","parquet","Text"],"keywords_longer_than_N":true},
	{"name":"librivox-tracks","keyword":"italian","description":"A dataset of all audio files uploaded to LibriVox before 26th September 2023.\n","url":"https://huggingface.co/datasets/pykeio/librivox-tracks","creator_name":"pyke.io","creator_url":"https://huggingface.co/pykeio","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-to-speech","automatic-speech-recognition","Achinese","Afrikaans","Ancient Greek (to 1453)"],"keywords_longer_than_N":true},
	{"name":"mmlu_italian","keyword":"italian","description":"\n\t\n\t\t\n\t\tMMLU - Italian (IT)\n\t\n\nThis dataset is an Italian translation of Massive Multitask Language Understanding (MMLU). MMLU is a dataset that is composed of multiple-choice questions from 57 different topics, including math, science, and social studies. The dataset is designed to evaluate the ability of models to answer questions across a wide range of topics.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\nThe dataset consists of multiple-choice questions from 57 different topics. Each question is associated‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/sapienzanlp/mmlu_italian.","url":"https://huggingface.co/datasets/sapienzanlp/mmlu_italian","creator_name":"Sapienza NLP, Sapienza University of Rome","creator_url":"https://huggingface.co/sapienzanlp","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-generation","Italian","English","mit","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"yodas-granary","keyword":"italian","description":"\n\t\n\t\t\n\t\tDataset Card for YODAS-Granary\n\t\n\n\nRepository: NeMo-speech-data-processor: Granary\nPaper: Granary: Speech Recognition and Translation Dataset in 25 European Languages\nShared by: ESPnet\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Description\n\t\n\nYODAS-Granary is a curated subset of the larger nvidia/Granary dataset, focusing on high-quality pseudo-labeled speech data for Automatic Speech Recognition (ASR) and Automatic Speech Translation (AST) across 23 European languages.\n\n\t\n\t\n\t\n\t\tOverview‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/espnet/yodas-granary.","url":"https://huggingface.co/datasets/espnet/yodas-granary","creator_name":"ESPnet","creator_url":"https://huggingface.co/espnet","license_name":"Creative Commons Attribution 3.0","license_url":"https://scancode-licensedb.aboutcode.org/cc-by-3.0.html","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","translation","Bulgarian","Czech","Danish"],"keywords_longer_than_N":true},
	{"name":"fiNERweb","keyword":"italian","description":"fiNERweb is a multilingual named entity recognition dataset containing annotated text in multiple languages.\nEach example contains the original text, tokenized text, BIO tags, and character/token spans for entities.","url":"https://huggingface.co/datasets/whoisjones/fiNERweb","creator_name":"Jonas Golde","creator_url":"https://huggingface.co/whoisjones","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":null,"first_N":5,"first_N_keywords":["token-classification","named-entity-recognition","Vietnamese","Tamil","Oriya"],"keywords_longer_than_N":true},
	{"name":"multilingual-text","keyword":"italian","description":"\n\t\n\t\t\n\t\tMultilingual Text Dataset\n\t\n\nThis dataset contains a curated selection of rows from multiple input datasets, where each row includes a text chunk of approximately 2000 tokens (as measured by Llama 3.1 tokenizer) verified to be written in the correct language. Only rows with properly classified language chunks are retained, ensuring high-quality multilingual data for analysis or model training.\n\n\t\n\t\t\n\t\tPreprocessing Steps\n\t\n\n\nNormalized whitespace, punctuation, Unicode characters, and‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/agentlans/multilingual-text.","url":"https://huggingface.co/datasets/agentlans/multilingual-text","creator_name":"Alan Tseng","creator_url":"https://huggingface.co/agentlans","license_name":"Open Data Commons Attribution License v1.0","license_url":"https://scancode-licensedb.aboutcode.org/odc-by-1.0.html","language":"en","first_N":5,"first_N_keywords":["text-generation","text-classification","Amharic","Arabic","Bengali"],"keywords_longer_than_N":true},
	{"name":"Chatgpt","keyword":"italian","description":"\n\t\n\t\t\n\t\tOpenAssistant Conversations Dataset (OASST1)\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nIn an effort to democratize research on large-scale alignment, we release OpenAssistant \nConversations (OASST1), a human-generated, human-annotated assistant-style conversation \ncorpus consisting of 161,443 messages in 35 different languages, annotated with 461,292 \nquality ratings, resulting in over 10,000 fully annotated conversation trees. The corpus \nis a product of a worldwide crowd-sourcing effort‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/RajChat/Chatgpt.","url":"https://huggingface.co/datasets/RajChat/Chatgpt","creator_name":"Rajdeep Chatterjee ","creator_url":"https://huggingface.co/RajChat","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["English","Spanish","Russian","German","Polish"],"keywords_longer_than_N":true},
	{"name":"common_voice_22_0","keyword":"italian","description":"\n\t\n\t\t\n\t\tDataset Card for Common Voice Corpus 22.0\n\t\n\n\n\nThis dataset is an unofficial version of the Mozilla Common Voice Corpus 22. It was downloaded and converted from the project's website https://commonvoice.mozilla.org/.\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nAbkhaz, Albanian, Amharic, Arabic, Armenian, Assamese, Asturian, Azerbaijani, Basaa, Bashkir, Basque, Belarusian, Bengali, Breton, Bulgarian, Cantonese, Catalan, Central Kurdish, Chinese (China), Chinese (Hong Kong), Chinese (Taiwan), Chuvash, Czech‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/fsicoli/common_voice_22_0.","url":"https://huggingface.co/datasets/fsicoli/common_voice_22_0","creator_name":"Fabio Sicoli","creator_url":"https://huggingface.co/fsicoli","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":null,"first_N":5,"first_N_keywords":["automatic-speech-recognition","Abkhaz","Afrikaans","Amharic","Arabic"],"keywords_longer_than_N":true},
	{"name":"piqa_italian","keyword":"italian","description":"\n\t\n\t\t\n\t\tPIQA - Italian (IT)\n\t\n\nThis dataset is an Italian translation of PIQA. PIQA stands for Physical Interaction Question Answering, a dataset of questions about common scenarios that require an understanding of the physical world. \n\n\t\n\t\t\n\t\tDataset Details\n\t\n\nThe dataset consists of questions about common scenarios that require an understanding of the physical world. Each question is associated with a correct answer and a distractor. The task is to predict the correct answer to the‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/sapienzanlp/piqa_italian.","url":"https://huggingface.co/datasets/sapienzanlp/piqa_italian","creator_name":"Sapienza NLP, Sapienza University of Rome","creator_url":"https://huggingface.co/sapienzanlp","license_name":"Academic Free License v3.0","license_url":"https://choosealicense.com/licenses/afl-3.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","Italian","English","afl-3.0","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"OGC_2_vdr-visRAG-colpali","keyword":"italian","description":"\n\t\n\t\t\n\t\tOGC 2 - Organized, Grouped, Cleaned\n\t\n\n\nIntended for image/text to vector (DSE)\n\n\n\t\n\t\t\n\t\tDataset Composition\n\t\n\nThis second version only has rows with positive queries\nThe dataset merges, shuffles, and formats data from:\n\nvidore/colpali_train_set\nopenbmb/VisRAG-Ret-Train-Synthetic-data\nllamaindex/vdr-multilingual-train\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Statistics\n\t\n\n\n\t\n\t\t\nMetric\nValue\n\n\n\t\t\nTotal rows\n600,000+\n\n\n\t\n\n\n\t\n\t\n\t\n\t\tLanguage Distribution\n\t\n\n\n\t\n\t\t\nLanguage\nRatio\n\n\n\t\t\nEnglish\n‚âà 64%\n\n\nFrench\n‚âà‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/racineai/OGC_2_vdr-visRAG-colpali.","url":"https://huggingface.co/datasets/racineai/OGC_2_vdr-visRAG-colpali","creator_name":"racine.ai","creator_url":"https://huggingface.co/racineai","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["visual-document-retrieval","text-retrieval","English","French","Italian"],"keywords_longer_than_N":true},
	{"name":"bordirlines","keyword":"italian","description":"\n\t\n\t\t\n\t\tBordIRLines Dataset\n\t\n\nThis is the dataset associated with the paper \"BordIRlines: A Dataset for Evaluating Cross-lingual Retrieval-Augmented Generation\" (link).\nCode: https://github.com/manestay/bordIRlines\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThe BordIRLines Dataset is an information retrieval (IR) dataset constructed from various language corpora. It contains queries and corresponding ranked docs along with their relevance scores. The dataset includes multiple languages, including English‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/borderlines/bordirlines.","url":"https://huggingface.co/datasets/borderlines/bordirlines","creator_name":"cross-lingual LLMs and RAG","creator_url":"https://huggingface.co/borderlines","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":null,"first_N":5,"first_N_keywords":["question-answering","human","machine-generated","found","multilingual"],"keywords_longer_than_N":true},
	{"name":"text_ratings","keyword":"italian","description":"Todo - Write dataset card\n","url":"https://huggingface.co/datasets/lightblue/text_ratings","creator_name":"Lightblue KK.","creator_url":"https://huggingface.co/lightblue","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["Amharic","Arabic","Bulgarian","Bengali","Czech"],"keywords_longer_than_N":true},
	{"name":"taiga_corpus_subtitles","keyword":"italian","description":"\n\t\n\t\t\n\t\tDataset Card for Taiga Corpus - TV Series Subtitles\n\t\n\nThis dataset contains subtitles extracted from various TV series. The original data is sourced from the Taiga Corpus. It consists of line-level subtitle information with precise timing and additional metadata including series title and episode information. The dataset is designed for tasks such as subtitle alignment, translation, and dialogue analysis.\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Details\n\t\n\nEach record in the dataset contains the following‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Fascinat0r/taiga_corpus_subtitles.","url":"https://huggingface.co/datasets/Fascinat0r/taiga_corpus_subtitles","creator_name":"Nikita Kulakov","creator_url":"https://huggingface.co/Fascinat0r","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["question-answering","translation","Russian","English","Italian"],"keywords_longer_than_N":true},
	{"name":"europa","keyword":"italian","description":"\n\t\n\t\t\n\t\tDataset Card for EUROPA\n\t\n\nThis dataset card aims to be a base template for new datasets. It has been generated using this raw template.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nEUROPA is a dataset designed for training and evaluating multilingual keyphrase generation models in the legal domain. It consists of legal judgments from the Court of Justice of the European Union (EU) and includes instances in all 24 official EU languages.\nKey Features:\nMultilingual: Covers‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/NCube/europa.","url":"https://huggingface.co/datasets/NCube/europa","creator_name":"Neural Network Nomads (We are GLOSS)","creator_url":"https://huggingface.co/NCube","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["French","German","English","Italian","Dutch"],"keywords_longer_than_N":true},
	{"name":"xm3600","keyword":"italian","description":"\n\t\n\t\t\n\t\n\t\n\t\tXM3600 - Crossmodal-3600\n\t\n\n\n\t\n\t\t\n\t\n\t\n\t\tThis is a copy from https://google.github.io/crossmodal-3600/\n\t\n\nIf you use this dataset, please cite the original authors:\n@inproceedings{ThapliyalCrossmodal2022,\n  author = {Ashish Thapliyal and Jordi Pont-Tuset and Xi Chen and Radu Soricut},\n  title = {{Crossmodal-3600: A Massively Multilingual Multimodal Evaluation Dataset}},\n  booktitle = {EMNLP},\n  year = {2022}\n}\n\nIt also includes the image features as PIL Image and has a uniform and‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/floschne/xm3600.","url":"https://huggingface.co/datasets/floschne/xm3600","creator_name":"Flo Schneider","creator_url":"https://huggingface.co/floschne","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["image-to-text","Arabic","Bengali","Czech","Danish"],"keywords_longer_than_N":true},
	{"name":"biologia-mc","keyword":"italian","description":"\n\t\n\t\t\n\t\tDataset Card\n\t\n\nBiologia-MC is an extensive multiple-choice dataset focused on biology. It consists of approximately 7k synthetic multiple-choice questions with corresponding answer choices, created using Claude Opus. This dataset aims to support the development of educational tools and language models for biology-related tasks.\n\n\t\n\t\t\n\t\tFeatures\n\t\n\n\nWide Coverage of Biology Concepts: Biologia covers a broad spectrum of topics in biology.\nAutomated Generation: The questions are crafted‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/efederici/biologia-mc.","url":"https://huggingface.co/datasets/efederici/biologia-mc","creator_name":"Edoardo Federici","creator_url":"https://huggingface.co/efederici","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["question-answering","Italian","mit","1K - 10K","parquet"],"keywords_longer_than_N":true},
	{"name":"xm3600_1k","keyword":"italian","description":"\n\t\n\t\t\n\t\n\t\n\t\tXM3600 - Crossmodal-3600 - 1K Split\n\t\n\n\n\t\n\t\t\n\t\n\t\n\t\tThis is a copy from https://google.github.io/crossmodal-3600/\n\t\n\nIf you use this dataset, please cite the original authors:\n@inproceedings{ThapliyalCrossmodal2022,\n  author = {Ashish Thapliyal and Jordi Pont-Tuset and Xi Chen and Radu Soricut},\n  title = {{Crossmodal-3600: A Massively Multilingual Multimodal Evaluation Dataset}},\n  booktitle = {EMNLP},\n  year = {2022}\n}\n\n\n\t\n\t\t\n\t\n\t\n\t\tThis is a 1K split of XM3600!\n\t\n\nFor this, we‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/floschne/xm3600_1k.","url":"https://huggingface.co/datasets/floschne/xm3600_1k","creator_name":"Flo Schneider","creator_url":"https://huggingface.co/floschne","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["image-to-text","Arabic","Bengali","Czech","Danish"],"keywords_longer_than_N":true},
	{"name":"Italian-Reasoning-Logic-2k","keyword":"italian","description":"Dddixyy/Italian-Reasoning-Logic-2k dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/Dddixyy/Italian-Reasoning-Logic-2k","creator_name":"Davide Brunori","creator_url":"https://huggingface.co/Dddixyy","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-generation","Italian","mit","1K - 10K","parquet"],"keywords_longer_than_N":true},
	{"name":"Italian-Reasoning-Logic-2k","keyword":"italian","description":"Dddixyy/Italian-Reasoning-Logic-2k dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/Dddixyy/Italian-Reasoning-Logic-2k","creator_name":"Davide Brunori","creator_url":"https://huggingface.co/Dddixyy","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-generation","Italian","mit","1K - 10K","parquet"],"keywords_longer_than_N":true},
	{"name":"Saka-Alpaca-v1","keyword":"italian","description":"https://chatgpt.com\n","url":"https://huggingface.co/datasets/Sakalti/Saka-Alpaca-v1","creator_name":"sakasan","creator_url":"https://huggingface.co/Sakalti","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","Swedish","Norwegian","Finnish","German"],"keywords_longer_than_N":true},
	{"name":"mementos_1turn_search_sft_std","keyword":"italian","description":"kieranschubert/mementos_1turn_search_sft_std dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/kieranschubert/mementos_1turn_search_sft_std","creator_name":"Kieran Schubert","creator_url":"https://huggingface.co/kieranschubert","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","French","German","Italian","English"],"keywords_longer_than_N":true},
	{"name":"reasoning-ita","keyword":"italian","description":"","url":"https://huggingface.co/datasets/mik3ml/reasoning-ita","creator_name":"Michele Angelo Marcucci","creator_url":"https://huggingface.co/mik3ml","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","text2text-generation","Italian","apache-2.0","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"mmarco-hard-negatives-reranker-score","keyword":"italian","description":"\nhotchpotch/mmarco-hard-negatives-reranker-score\n\nThis repository contains data from mMARCO scored using the reranker BAAI/bge-reranker-v2-m3.\n\n\t\n\t\t\n\t\tLanguages Covered\n\t\n\ntarget_languages = [\n    \"english\",\n    \"chinese\", \n    \"french\",\n    \"german\",\n    \"indonesian\",\n    \"italian\",\n    \"portuguese\",\n    \"russian\",\n    \"spanish\",\n    \"arabic\",\n    \"dutch\",\n    \"hindi\",\n    \"japanese\",\n    \"vietnamese\"\n]\n\n\n\t\n\t\t\n\t\tHard Negative Data\n\t\n\nThe hard negative data is derived from‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/hotchpotch/mmarco-hard-negatives-reranker-score.","url":"https://huggingface.co/datasets/hotchpotch/mmarco-hard-negatives-reranker-score","creator_name":"Yuichi Tateno","creator_url":"https://huggingface.co/hotchpotch","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["English","Chinese","French","German","Indonesian"],"keywords_longer_than_N":true},
	{"name":"aya_collection_language_split","keyword":"italian","description":"\nThis is a re-upload of the aya_collection, and only differs in the structure of upload. While the original aya_collection is structured by folders split according to dataset name, this dataset is split by language. We recommend you use this version of the dataset if you are only interested in downloading all of the Aya collection for a single or smaller set of languages.\n\n\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThe Aya Collection is a massive multilingual collection consisting of 513 million instances of‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/CohereLabs/aya_collection_language_split.","url":"https://huggingface.co/datasets/CohereLabs/aya_collection_language_split","creator_name":"Cohere Labs","creator_url":"https://huggingface.co/CohereLabs","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["Achinese","Afrikaans","Amharic","Arabic","Azerbaijani"],"keywords_longer_than_N":true},
	{"name":"fineweb-edu-translated","keyword":"italian","description":"\n\t\n\t\t\n\t\tHelsinki-NLP/fineweb-edu-translated\n\t\n\nAutomatically translated documents from fineweb-edu. Translations are based on OPUS-MT and HPLT-MT models.\n","url":"https://huggingface.co/datasets/Helsinki-NLP/fineweb-edu-translated","creator_name":"Language Technology Research Group at the University of Helsinki","creator_url":"https://huggingface.co/Helsinki-NLP","license_name":"Open Data Commons Attribution License v1.0","license_url":"https://scancode-licensedb.aboutcode.org/odc-by-1.0.html","language":"en","first_N":5,"first_N_keywords":["text-generation","Bulgarian","Catalan","Czech","Danish"],"keywords_longer_than_N":true},
	{"name":"MMLU-Pro-ita","keyword":"italian","description":"\n\t\n\t\t\n\t\tMMLU-Pro-ita Dataset Introduction\n\t\n\nThis is an Italian translation of MMLU-Pro, a more robust and challenging massive multi-task understanding dataset tailored to more rigorously benchmark large language models' capabilities. This dataset contains 12K complex questions across various disciplines. \n\n\t\n\t\t\n\t\t1. What's new about MMLU-Pro\n\t\n\nCompared to the original MMLU, there are three major differences:\n\nThe original MMLU dataset only contains 4 options, MMLU-Pro increases it to 10‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/efederici/MMLU-Pro-ita.","url":"https://huggingface.co/datasets/efederici/MMLU-Pro-ita","creator_name":"Edoardo Federici","creator_url":"https://huggingface.co/efederici","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["question-answering","Italian","mit","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"imatrix-calibration","keyword":"italian","description":"\n\t\n\t\t\n\t\tImportance Matrix Calibration Datasets\n\t\n\nThis repository contains calibration datasets used to generate importance matrices (imatrix), which in turn help minimise errors introduced during quantization.\n\n\t\n\t\t\n\t\tMath calibration datasets\n\t\n\nThis dataset consists of over 10M tokens of cleaned math prompts and is available in six sizes, ranging from huge (~ 430,000 lines equivalent to approx. 10M tokens), to micro (~ 13,700 lines and 1.7M tokens avg).\nOriginal data sourced from‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/eaddario/imatrix-calibration.","url":"https://huggingface.co/datasets/eaddario/imatrix-calibration","creator_name":"Ed Addario","creator_url":"https://huggingface.co/eaddario","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-generation","Arabic","Chinese","German","English"],"keywords_longer_than_N":true},
	{"name":"redeIT-xml-alpaca","keyword":"italian","description":"leinad-deinor/redeIT-xml-alpaca dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/leinad-deinor/redeIT-xml-alpaca","creator_name":"Daniel Acampora","creator_url":"https://huggingface.co/leinad-deinor","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["Italian","apache-2.0","< 1K","parquet","Text"],"keywords_longer_than_N":true},
	{"name":"europa-random-split","keyword":"italian","description":"\n\t\n\t\t\n\t\tDataset Card for EUROPA\n\t\n\nThis dataset card aims to be a base template for new datasets. It has been generated using this raw template.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nEUROPA is a dataset designed for training and evaluating multilingual keyphrase generation models in the legal domain. It consists of legal judgments from the Court of Justice of the European Union (EU) and includes instances in all 24 official EU languages.\nKey Features:\nMultilingual: Covers‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/NCube/europa-random-split.","url":"https://huggingface.co/datasets/NCube/europa-random-split","creator_name":"Neural Network Nomads (We are GLOSS)","creator_url":"https://huggingface.co/NCube","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["French","German","English","Italian","Dutch"],"keywords_longer_than_N":true},
	{"name":"medical-o1-reasoning-SFT-it_f10_incremental","keyword":"italian","description":"\n\t\n\t\t\n\t\tNews\n\t\n\n[2025/03/08] We open sourced the medical reasoning dataset for SFT translated into italian language.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset will be used to fine-tuning a distiled model to generate an italian medical LLM designed for advanced medical reasoning.\nWe used the \"facebook/nllb-200-distilled-600M\" model to translate the \"FreedomIntelligence/medical-o1-reasoning-SFT\" dataset, from English to Italian\n\n\t\n\t\t\n\t\tCitation\n\t\n\nWe would like to thank the authors of the‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/eugrug-60/medical-o1-reasoning-SFT-it_f10_incremental.","url":"https://huggingface.co/datasets/eugrug-60/medical-o1-reasoning-SFT-it_f10_incremental","creator_name":"Eugenio Ruggieri","creator_url":"https://huggingface.co/eugrug-60","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["question-answering","text-generation","Italian","apache-2.0","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"epfml-FineWeb2-HQ-sample","keyword":"italian","description":"\n\t\n\t\t\n\t\tepfml/FineWeb2-HQ\n\t\n\nA curated subset of the epfml/FineWeb2-HQ dataset featuring high-quality multilingual text.\n\n\t\n\t\t\n\t\tDetails\n\t\n\n\nFirst 25‚Äâ000 rows per config (language and script pair)\nDuplicates removed\nTexts truncated to 512 LLaMA 3.1 tokens\nScores transformed with log10\nRows shuffled and 20% of the rows split into the test set (stratified by config)\n\n\n\t\n\t\t\n\t\tExample\n\t\n\n{\n  \"text\": \"ÁàµÂ£´Â§ßÂ∏àTim Garland Ê∑±Âú≥‰∏ìÂú∫ - [jazz]\\nTim Garland Lighthouse‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/agentlans/epfml-FineWeb2-HQ-sample.","url":"https://huggingface.co/datasets/agentlans/epfml-FineWeb2-HQ-sample","creator_name":"Alan Tseng","creator_url":"https://huggingface.co/agentlans","license_name":"Open Data Commons Attribution License v1.0","license_url":"https://scancode-licensedb.aboutcode.org/odc-by-1.0.html","language":"en","first_N":5,"first_N_keywords":["text-generation","Russian","Chinese","German","Japanese"],"keywords_longer_than_N":true},
	{"name":"domande_e_risposte_wikipedia","keyword":"italian","description":"\n\t\n\t\t\n\t\tProcessed Italian Wikipedia Paragraphs: Scrivi la domanda che ha come risposta il paragrafo\n\t\n\nThis dataset was generated by fetching random first paragraphs from Italian Wikipedia (it.wikipedia.org)\nand then processing them using Gemini AI with the following goal:\n\nProcessing Goal: Scrivi la domanda che ha come risposta il paragrafo\nSource Language: Italian (from Wikipedia)\nNumber of Rows: 86\nModel Used: gemini-2.5-flash-preview-04-17\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Structure\n\t\n\n\ntext: The‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Dddixyy/domande_e_risposte_wikipedia.","url":"https://huggingface.co/datasets/Dddixyy/domande_e_risposte_wikipedia","creator_name":"Davide Brunori","creator_url":"https://huggingface.co/Dddixyy","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["question-answering","text-generation","gemini-ai","original:wikipedia:it","Italian"],"keywords_longer_than_N":true},
	{"name":"BoundingDocs","keyword":"italian","description":"\n\nBoundingDocs\n\nüîç The largest spatially-annotated dataset for Document Question Answering\n\n\n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Description\n\t\n\nBoundingDocs is a unified dataset for Document Question Answering (QA) that includes spatial annotations. It consolidates multiple public datasets from Document AI and Visually Rich Document Understanding (VRDU) domains. The dataset reformulates Information Extraction (IE) tasks into QA tasks, making it a valuable resource for training and evaluating Large Language‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/letxbe/BoundingDocs.","url":"https://huggingface.co/datasets/letxbe/BoundingDocs","creator_name":"Letxbe","creator_url":"https://huggingface.co/letxbe","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["question-answering","visual-question-answering","English","Italian","Spanish"],"keywords_longer_than_N":true},
	{"name":"italian-text-sentiment-analysis","keyword":"italian","description":"MelmaGrigia/italian-text-sentiment-analysis dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/MelmaGrigia/italian-text-sentiment-analysis","creator_name":"Marco Bertelli","creator_url":"https://huggingface.co/MelmaGrigia","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","Italian","mit","1K - 10K","csv"],"keywords_longer_than_N":true},
	{"name":"italian-text-sentiment-analysis","keyword":"italian","description":"MelmaGrigia/italian-text-sentiment-analysis dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/MelmaGrigia/italian-text-sentiment-analysis","creator_name":"Marco Bertelli","creator_url":"https://huggingface.co/MelmaGrigia","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","Italian","mit","1K - 10K","csv"],"keywords_longer_than_N":true},
	{"name":"Tatoeba-Translations","keyword":"italian","description":"\n\t\n\t\t\n\t\tDataset Details\n\t\n\nThis is the latest version of Tatoeba translations as of December 2024.\nThe sentences are downloaded from the Tatoeba collection website.\nThe dataset is processed through mapping sentences.tar.bz2 using sentences_base.tar.bz2 to find source (sentence_src) and target (sentence_tgt) sentences.\nWhile lang_src and lang_tgt columns follow the mapping provided by Tatoeba, the lang_pair column merely lists the two languages in the translation pair.\n\n\t\n\t\t\n\t\n\t\n\t\tStatistics‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ymoslem/Tatoeba-Translations.","url":"https://huggingface.co/datasets/ymoslem/Tatoeba-Translations","creator_name":"Yasmin Moslem","creator_url":"https://huggingface.co/ymoslem","license_name":"Creative Commons Attribution 2.0","license_url":"https://scancode-licensedb.aboutcode.org/cc-by-2.0.html","language":"en","first_N":5,"first_N_keywords":["translation","multilingual","Abkhaz","Afrikaans","Amharic"],"keywords_longer_than_N":true},
	{"name":"Kurtis-E1-Multilingual-01-SFT","keyword":"italian","description":"ethicalabs/Kurtis-E1-Multilingual-01-SFT dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/ethicalabs/Kurtis-E1-Multilingual-01-SFT","creator_name":"ethicalabs.ai","creator_url":"https://huggingface.co/ethicalabs","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["English","Italian","Spanish","French","Portuguese"],"keywords_longer_than_N":true},
	{"name":"fama-data","keyword":"italian","description":"\n\n\n\t\n\t\t\n\t\tDataset Description, Collection, and Source\n\t\n\nThe FAMA training data is the collection of English and Italian datasets for automatic speech recognition (ASR) and speech translation (ST)\nused to train the FAMA models family.\nThe ASR section of FAMA is derived from the MOSEL data collection, including the automatic\ntranscripts obtained with Whisper and available in the HuggingFace MOSEL Dataset.\nThe ASR is further augmented with automatically transcribed speech from the‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/FBK-MT/fama-data.","url":"https://huggingface.co/datasets/FBK-MT/fama-data","creator_name":"FBK-MT","creator_url":"https://huggingface.co/FBK-MT","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["translation","automatic-speech-recognition","multilingual","Italian","English"],"keywords_longer_than_N":true},
	{"name":"biblenlp-corpus","keyword":"italian","description":"\n\t\n\t\t\n\t\tDataset Card for BibleNLP Corpus\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nPartial and complete Bible translations in 833 languages, aligned by verse.\n\n\t\n\t\t\n\t\tLanguages\n\t\n\naai, aak, aau, aaz, abt, abx, aby, acf, acr, acu, adz, aer, aey, agd, agg, agm, agn, agr, agt, agu, aia, aii, aka, ake, alp, alq, als, aly, ame, amf, amk, amm, amn, amo, amp, amr, amu, amx, anh, anv, aoi, aoj, aom, aon, apb, ape, apn, apr, apu, apw, apz, arb, are, arl, arn, arp, asm, aso, ata, atb, atd, atg, att, auc, aui, auy‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/bible-nlp/biblenlp-corpus.","url":"https://huggingface.co/datasets/bible-nlp/biblenlp-corpus","creator_name":"The Partnership for Applied Biblical NLP","creator_url":"https://huggingface.co/bible-nlp","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":null,"first_N":5,"first_N_keywords":["translation","no-annotation","expert-generated","translation","multilingual"],"keywords_longer_than_N":true},
	{"name":"biblenlp-corpus","keyword":"italian","description":"\n\t\n\t\t\n\t\tDataset Card for BibleNLP Corpus\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nPartial and complete Bible translations in 833 languages, aligned by verse.\n\n\t\n\t\t\n\t\tLanguages\n\t\n\naai, aak, aau, aaz, abt, abx, aby, acf, acr, acu, adz, aer, aey, agd, agg, agm, agn, agr, agt, agu, aia, aii, aka, ake, alp, alq, als, aly, ame, amf, amk, amm, amn, amo, amp, amr, amu, amx, anh, anv, aoi, aoj, aom, aon, apb, ape, apn, apr, apu, apw, apz, arb, are, arl, arn, arp, asm, aso, ata, atb, atd, atg, att, auc, aui, auy‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/bible-nlp/biblenlp-corpus.","url":"https://huggingface.co/datasets/bible-nlp/biblenlp-corpus","creator_name":"The Partnership for Applied Biblical NLP","creator_url":"https://huggingface.co/bible-nlp","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":null,"first_N":5,"first_N_keywords":["translation","no-annotation","expert-generated","translation","multilingual"],"keywords_longer_than_N":true},
	{"name":"HashtagPrediction","keyword":"italian","description":"\n\t\n\t\t\n\t\tHashtag Prediction Dataset from paper TwHIN-BERT: A Socially-Enriched Pre-trained Language Model for Multilingual Tweet Representations\n\t\n\n  \nThis repo contains the Hashtag prediction dataset from our paper TwHIN-BERT: A Socially-Enriched Pre-trained Language Model for Multilingual Tweet Representations. \n[arXiv][HuggingFace Models]\n[Github repo]\nThis work is licensed under a Creative Commons Attribution 4.0 International License.\n\n\t\n\t\t\n\t\n\t\n\t\tDownload\n\t\n\nUse the‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Twitter/HashtagPrediction.","url":"https://huggingface.co/datasets/Twitter/HashtagPrediction","creator_name":"Twitter","creator_url":"https://huggingface.co/Twitter","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["Slovenian","Urdu","Sindhi","Polish","Vietnamese"],"keywords_longer_than_N":true},
	{"name":"bernice-pretrain-data","keyword":"italian","description":"Tweet IDs for the 2.5 billion multilingual tweets used to train Bernice, a Twitter encoder.\nThe tweets are from the public 1% Twitter API stream from January 2016 to December 2021. \nTwitter-provided language metadata is provided with the tweet ID. The data contains 66 unique languages, \nas identified by ISO 639 language codes, including `und` for undefined languages.\nTweets need to be re-gathered via the Twitter API.","url":"https://huggingface.co/datasets/jhu-clsp/bernice-pretrain-data","creator_name":"Center for Language and Speech Processing @ JHU","creator_url":"https://huggingface.co/jhu-clsp","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":null,"first_N":5,"first_N_keywords":["other","no-annotation","found","multilingual","original"],"keywords_longer_than_N":true},
	{"name":"ChatML-aya_dataset","keyword":"italian","description":"CohereForAI/aya_dataset in ChatML format, ready to use in HuggingFace TRL's SFT Trainer.\nPython code used for conversion:\nfrom datasets import load_dataset\nfrom transformers import AutoTokenizer\n\ntokenizer = AutoTokenizer.from_pretrained(\"Felladrin/Llama-160M-Chat-v1\")\n\ndataset = load_dataset(\"CohereForAI/aya_dataset\", split=\"train\")\n\ndef format(columns):\n    messages = [\n        {\n            \"role\": \"user\",\n            \"content\": columns[\"inputs\"].strip(),\n        },\n        {‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Felladrin/ChatML-aya_dataset.","url":"https://huggingface.co/datasets/Felladrin/ChatML-aya_dataset","creator_name":"Victor Nogueira","creator_url":"https://huggingface.co/Felladrin","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["question-answering","text-generation","crowdsourced","expert-generated","crowdsourced"],"keywords_longer_than_N":true},
	{"name":"rte3-multi","keyword":"italian","description":"\n\t\n\t\t\n\t\tDataset Card for Dataset Name\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis repository contains all manually translated versions of RTE-3 dataset, plus the original English one. The languages into which RTE-3 dataset has so far been translated are Italian (2012), German (2013), and French (2023).\nUnlike in other repositories, both our own French version and the older Italian and German ones are here annotated in 3 classes (entailment, neutral, contradiction), and not in 2 (entailment, not‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/maximoss/rte3-multi.","url":"https://huggingface.co/datasets/maximoss/rte3-multi","creator_name":"Maximos Skandalis","creator_url":"https://huggingface.co/maximoss","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","natural-language-inference","multi-input-text-classification","French","English"],"keywords_longer_than_N":true},
	{"name":"MMMLU","keyword":"italian","description":"\n\t\n\t\t\n\t\tMultilingual Massive Multitask Language Understanding (MMMLU)\n\t\n\nThe MMLU is a widely recognized benchmark of general knowledge attained by AI models. It covers a broad range of topics from 57 different categories, covering elementary-level knowledge up to advanced professional subjects like law, physics, history, and computer science.\nWe translated the MMLU‚Äôs test set into 14 languages using professional human translators. Relying on human translators for this evaluation increases‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/openai/MMMLU.","url":"https://huggingface.co/datasets/openai/MMMLU","creator_name":"OpenAI","creator_url":"https://huggingface.co/openai","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["question-answering","Arabic","Bengali","German","Spanish"],"keywords_longer_than_N":true},
	{"name":"hatecheck-italian","keyword":"italian","description":"\n\t\n\t\t\n\t\tDataset Card for Multilingual HateCheck\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nMultilingual HateCheck (MHC) is a suite of functional tests for hate speech detection models in 10 different languages: Arabic, Dutch, French, German, Hindi, Italian, Mandarin, Polish, Portuguese and Spanish.\nFor each language, there are 25+ functional tests that correspond to distinct types of hate and challenging non-hate.\nThis allows for targeted diagnostic insights into model performance.\nFor more details‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Paul/hatecheck-italian.","url":"https://huggingface.co/datasets/Paul/hatecheck-italian","creator_name":"Paul R√∂ttger","creator_url":"https://huggingface.co/Paul","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","hate-speech-detection","crowdsourced","expert-generated","monolingual"],"keywords_longer_than_N":true},
	{"name":"lextreme","keyword":"italian","description":"The LEXTREME Benchmark is a collection of multilingual datasets for evaluating model performance \nacross a diverse set of legal NLU tasks.","url":"https://huggingface.co/datasets/joelniklaus/lextreme","creator_name":"Joel Niklaus","creator_url":"https://huggingface.co/joelniklaus","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","multi-class-classification","multi-label-classification","topic-classification"],"keywords_longer_than_N":true},
	{"name":"dlgs_81_08_qa","keyword":"italian","description":"This dataset contains an automatically generated set of Question and Answers extracted from the \"TESTO UNICO SULLA SALUTE E SICUREZZA SUL LAVORO 81/08\" document link\nThe data is extracted from the article directly and the set of QA are generated using OpenAI text-davinci-003\n","url":"https://huggingface.co/datasets/alespalla/dlgs_81_08_qa","creator_name":"Alessandro Palla","creator_url":"https://huggingface.co/alespalla","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["question-answering","text-generation","Italian","apache-2.0","1K<n<10K"],"keywords_longer_than_N":true},
	{"name":"dlgs_81_08_qa","keyword":"italian","description":"This dataset contains an automatically generated set of Question and Answers extracted from the \"TESTO UNICO SULLA SALUTE E SICUREZZA SUL LAVORO 81/08\" document link\nThe data is extracted from the article directly and the set of QA are generated using OpenAI text-davinci-003\n","url":"https://huggingface.co/datasets/alespalla/dlgs_81_08_qa","creator_name":"Alessandro Palla","creator_url":"https://huggingface.co/alespalla","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["question-answering","text-generation","Italian","apache-2.0","1K<n<10K"],"keywords_longer_than_N":true},
	{"name":"fleurs-hs-vits","keyword":"italian","description":"\n\t\n\t\t\n\t\tFLEURS-HS VITS\n\t\n\nAn extension of the FLEURS dataset for synthetic speech detection using text-to-speech, featured in the paper Synthetic speech detection with Wav2Vec 2.0 in various language settings.\nThis dataset is 1 of 3 used in the paper, the others being:\n\nFLEURS-HS\nthe default train, dev and test sets\nseparated due to different licensing\n\n\nARCTIC-HS\nextension of the CMU_ARCTIC and L2-ARCTIC sets in a similar manner\n\n\n\n\n\t\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/realnetworks-kontxt/fleurs-hs-vits.","url":"https://huggingface.co/datasets/realnetworks-kontxt/fleurs-hs-vits","creator_name":"KONTXT by RealNetworks","creator_url":"https://huggingface.co/realnetworks-kontxt","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":null,"first_N":5,"first_N_keywords":["audio-classification","German","English","Spanish","French"],"keywords_longer_than_N":true},
	{"name":"MLDR","keyword":"italian","description":"\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nMLDR is a Multilingual Long-Document Retrieval dataset built on Wikipeida, Wudao and mC4, covering 13 typologically diverse languages. Specifically, we sample lengthy articles from Wikipedia, Wudao and mC4 datasets and randomly choose paragraphs from them. Then we use GPT-3.5 to generate questions based on these paragraphs. The generated question and the sampled article constitute a new text pair to the dataset. The prompt for GPT3.5 is ‚ÄúYou are a curious AI‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Shitao/MLDR.","url":"https://huggingface.co/datasets/Shitao/MLDR","creator_name":"Xiao","creator_url":"https://huggingface.co/Shitao","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":null,"first_N":5,"first_N_keywords":["text-retrieval","multilingual","Arabic","German","English"],"keywords_longer_than_N":true},
	{"name":"casimedicos-exp","keyword":"italian","description":"\n    \n    \n    \n\n\n\t\n\t\t\n\t\tAntidote CasiMedicos Dataset - Possible Answers Explanations in Resident Medical Exams\n\t\n\nWe present a new multilingual parallel medical dataset of commented medical exams which includes not only explanatory arguments\nfor the correct answer but also arguments to explain why the remaining possible answers are incorrect.\nThis dataset can be used for various NLP tasks including: Medical Question Answering, Explanatory Argument Extraction or Explanation Generation.\nThe‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/HiTZ/casimedicos-exp.","url":"https://huggingface.co/datasets/HiTZ/casimedicos-exp","creator_name":"HiTZ zentroa","creator_url":"https://huggingface.co/HiTZ","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","question-answering","English","Spanish","French"],"keywords_longer_than_N":true},
	{"name":"xtr-wiki_qa","keyword":"italian","description":"\n\t\n\t\t\n\t\tXtr-WikiQA\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nXtr-WikiQA is an Answer Sentence Selection (AS2) dataset in 9 non-English languages, proposed in our paper accepted at ACL 2023 (Findings): Cross-Lingual Knowledge Distillation for Answer Sentence Selection in Low-Resource Languages.\nThis dataset is based on an English AS2 dataset, WikiQA (Original, Hugging Face).\nFor translations, we used Amazon Translate.\n\n\t\n\t\t\n\t\n\t\n\t\tLanguages\n\t\n\n\nArabic (ar)\nSpanish (es)\nFrench (fr)\nGerman (de)\nHindi (hi)‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/AmazonScience/xtr-wiki_qa.","url":"https://huggingface.co/datasets/AmazonScience/xtr-wiki_qa","creator_name":"Amazon Science","creator_url":"https://huggingface.co/AmazonScience","license_name":"Community Data License Agreement Permissive 2.0","license_url":"https://scancode-licensedb.aboutcode.org/cdla-permissive-2.0.html","language":"en","first_N":5,"first_N_keywords":["question-answering","text-retrieval","open-domain-qa","machine-generated","found"],"keywords_longer_than_N":true},
	{"name":"multilingual-sentiments","keyword":"italian","description":"\n\t\n\t\t\n\t\tMultilingual Sentiments Dataset\n\t\n\nA collection of multilingual sentiments datasets grouped into 3 classes -- positive, neutral, negative.\nMost multilingual sentiment datasets are either 2-class positive or negative, 5-class ratings of products reviews (e.g. Amazon multilingual dataset) or multiple classes of emotions. However, to an average person, sometimes positive, negative and neutral classes suffice and are more straightforward to perceive and annotate. Also, a positive/negative‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/tyqiangz/multilingual-sentiments.","url":"https://huggingface.co/datasets/tyqiangz/multilingual-sentiments","creator_name":"Tay Yong Qiang","creator_url":"https://huggingface.co/tyqiangz","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","sentiment-analysis","sentiment-classification","monolingual","multilingual"],"keywords_longer_than_N":true},
	{"name":"text_coordinates_regions","keyword":"italian","description":"\n\t\n\t\t\n\t\tDataset Card for Multilingual Geo-Tagged Social Media Posts (by 123 world regions)\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThe \"Regions\" dataset is a multilingual corpus that encompasses textual data from the 123 most populated regions worldwide, with each region's data organized into separate .json files. This dataset consists of approximately 500,000 text samples, each paired with its geographic coordinates.\nKey Features:\n\nTextual Data: The dataset contains 500,000 text samples.‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/yachay/text_coordinates_regions.","url":"https://huggingface.co/datasets/yachay/text_coordinates_regions","creator_name":"Yachay AI","creator_url":"https://huggingface.co/yachay","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","token-classification","text-classification","English","Chinese"],"keywords_longer_than_N":true},
	{"name":"Syntetic_Evil_Dataset","keyword":"italian","description":"MaxForce01/Syntetic_Evil_Dataset dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/MaxForce01/Syntetic_Evil_Dataset","creator_name":"Max","creator_url":"https://huggingface.co/MaxForce01","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":null,"first_N":5,"first_N_keywords":["text-generation","Italian","apache-2.0","1K<n<10K","üá∫üá∏ Region: US"],"keywords_longer_than_N":true},
	{"name":"multilingual_librispeech","keyword":"italian","description":"\n\t\n\t\t\n\t\tDataset Card for MultiLingual LibriSpeech\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis is a streamable version of the Multilingual LibriSpeech (MLS) dataset. \nThe data archives were restructured from the original ones from OpenSLR to make it easier to stream.\nMLS dataset is a large multilingual corpus suitable for speech research. The dataset is derived from read audiobooks from LibriVox and consists of \n8 languages - English, German, Dutch, Spanish, French, Italian, Portuguese, Polish. It‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/facebook/multilingual_librispeech.","url":"https://huggingface.co/datasets/facebook/multilingual_librispeech","creator_name":"AI at Meta","creator_url":"https://huggingface.co/facebook","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","text-to-audio","expert-generated","crowdsourced"],"keywords_longer_than_N":true},
	{"name":"mfaq","keyword":"italian","description":"We present the first multilingual FAQ dataset publicly available. We collected around 6M FAQ pairs from the web, in 21 different languages.","url":"https://huggingface.co/datasets/clips/mfaq","creator_name":"CLiPS","creator_url":"https://huggingface.co/clips","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["question-answering","multiple-choice-qa","no-annotation","other","multilingual"],"keywords_longer_than_N":true},
	{"name":"blbooks-parquet","keyword":"italian","description":"\n\t\n\t\t\n\t\tDataset Card for British Library Books\n\t\n\nThis dataset is the same as https://huggingface.co/datasets/TheBritishLibrary/blbooks, however, this version is stored as parquet to avoid needing to run a datasets script. This also makes loading this dataset much quicker. \n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset consists of books digitised by the British Library in partnership with Microsoft. The dataset includes ~25 million pages of out of copyright texts. The majority of the texts were‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/biglam/blbooks-parquet.","url":"https://huggingface.co/datasets/biglam/blbooks-parquet","creator_name":"BigLAM: BigScience Libraries, Archives and Museums","creator_url":"https://huggingface.co/biglam","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","fill-mask","other","language-modeling","masked-language-modeling"],"keywords_longer_than_N":true},
	{"name":"TWNTW-it-en","keyword":"italian","description":"eddforsure/TWNTW-it-en dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/eddforsure/TWNTW-it-en","creator_name":"Edoardo","creator_url":"https://huggingface.co/eddforsure","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","Italian","English","apache-2.0","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"Open_Assistant_Conversation_Chains","keyword":"italian","description":"\n\t\n\t\t\n\t\tDataset Card for Dataset Name\n\t\n\n\n\t\n\t\t\n\t\tDataset description\n\t\n\n\n\nThis dataset is a reformatting of OpenAssistant Conversations (OASST1), which is\n\na human-generated, human-annotated assistant-style conversation corpus consisting of 161,443 messages in 35 different languages, annotated with 461,292 quality ratings, resulting in over 10,000 fully annotated conversation trees. The corpus is a product of a worldwide crowd-sourcing effort involving over 13,500 volunteers.\n\nIt was modified‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/m-ric/Open_Assistant_Conversation_Chains.","url":"https://huggingface.co/datasets/m-ric/Open_Assistant_Conversation_Chains","creator_name":"Aymeric Roucher","creator_url":"https://huggingface.co/m-ric","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","English","Spanish","Russian","German"],"keywords_longer_than_N":true},
	{"name":"legal-mc4","keyword":"italian","description":"Legal-MC4: A Corpus Covering the Legal Part of MC4 for European Languages","url":"https://huggingface.co/datasets/joelniklaus/legal-mc4","creator_name":"Joel Niklaus","creator_url":"https://huggingface.co/joelniklaus","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["fill-mask","other","found","multilingual","original"],"keywords_longer_than_N":true},
	{"name":"MOCKS","keyword":"italian","description":"Multilingual Open Custom Keyword Spotting Testset (MOCKS) is a comprehensive \naudio testset for evaluation and benchmarking Open-Vocabulary Keyword Spotting (OV-KWS) models.","url":"https://huggingface.co/datasets/voiceintelligenceresearch/MOCKS","creator_name":"VoiceIntelligenceResearch","creator_url":"https://huggingface.co/voiceintelligenceresearch","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":null,"first_N":5,"first_N_keywords":["expert-generated","multilingual","English","German","Spanish"],"keywords_longer_than_N":true},
	{"name":"ggml-vicuna-v0-quantized","keyword":"italian","description":"These are quantized ggml binary files for vicuna 7B and 13B models. The version of vicuna for these models are v0.\nThese files can be used in conjunction with minigpt4 ggml models 7B and 13B in minigpt4.cpp\nRecommended are the Q5_K and Q6_K implementations. If there are any issues, use Q4_1 or Q4_0.\n\n\n\t\n\t\t\n\t\n\t\n\t\tVicuna Model Card\n\t\n\n\n\t\n\t\t\n\t\n\t\n\t\tModel details\n\t\n\nModel type:\nVicuna is an open-source chatbot trained by fine-tuning LLaMA on user-shared conversations collected from ShareGPT.\nIt is‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/maknee/ggml-vicuna-v0-quantized.","url":"https://huggingface.co/datasets/maknee/ggml-vicuna-v0-quantized","creator_name":"maknee","creator_url":"https://huggingface.co/maknee","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["English","Bulgarian","Catalan","Czech","Danish"],"keywords_longer_than_N":true},
	{"name":"Syntetic_Italian_Conversation","keyword":"italian","description":"\n\t\n\t\t\n\t\tDataset Card: Mattimax/Syntetic_Italian_Conversation\n\t\n\n\n\t\n\t\t\n\t\tInformazioni generali\n\t\n\n\nNome dataset: Mattimax/Syntetic_Italian_Conversation\nTipo di dati: Conversazioni e prompt sintetici in lingua italiana\nFormato: JSON\nDimensione target: 10.000 esempi sintetici\nLicenza: Apache 2.0\nData di creazione: 2025-10-18\n\n\n\t\n\t\t\n\t\tScopo del dataset\n\t\n\nQuesto dataset √® progettato per supportare modelli di intelligenza artificiale nel comprendere e generare conversazioni in italiano, insieme a‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Mattimax/Syntetic_Italian_Conversation.","url":"https://huggingface.co/datasets/Mattimax/Syntetic_Italian_Conversation","creator_name":"M.INC.","creator_url":"https://huggingface.co/Mattimax","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","Italian","apache-2.0","10K - 100K","json"],"keywords_longer_than_N":true},
	{"name":"ParlaMint3","keyword":"italian","description":"ParlaMint 3.0 is a multilingual set of 26 comparable corpora containing parliamentary debates mostly starting in 2015 and extending to mid-2022. \nThe corpora have extensive metadata, including aspects of the parliament; the speakers (name, gender, MP status, party affiliation, party coalition/opposition); \nare structured into time-stamped terms, sessions and meetings; and with speeches being marked by the speaker and their role (e.g. chair, regular speaker). \nThe speeches also contain marked-up transcriber comments, such as gaps in the transcription, interruptions, applause, etc. \nNote that some corpora have further information, e.g. the year of birth of the speakers, links to their Wikipedia articles, their membership in various committees, etc. \nThe corpora are also marked to the subcorpus they belong to (\"reference\", until 2020-01-30, \"covid\", from 2020-01-31, and \"war\", from 2022-02-24). \nThe corpora are encoded according to the Parla-CLARIN TEI recommendation (https://clarin-eric.github.io/parla-clarin/), but have been encoded against the compatible, \nbut much stricter ParlaMint encoding guidelines (https://clarin-eric.github.io/ParlaMint/) and schemas (included in this distribution). \nThis entry contains the ParlaMint TEI-encoded corpora with the derived plain text versions of the corpora along with TSV metadata of the speeches. \nAlso included is the 3.0 release of the data and scripts available at the GitHub repository of the ParlaMint project.","url":"https://huggingface.co/datasets/cjvt/ParlaMint3","creator_name":"Center za jezikovne vire in tehnologije Univerze v Ljubljani","creator_url":"https://huggingface.co/cjvt","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":null,"first_N":5,"first_N_keywords":["other","multilingual","Slovenian","German","Bosnian"],"keywords_longer_than_N":true},
	{"name":"europa_eac_tm","keyword":"italian","description":"\n\t\n\t\t\n\t\tDataset Card for Europa Education and Culture Translation Memory (EAC-TM)\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset is a corpus of manually produced translations from english to up to 25 languages, released in 2012 by the European Union's Directorate General for Education and Culture (EAC).\nTo load a language pair that is not part of the config, just specify the language code as language pair. For example, if you want to translate Czech to Greek:\ndataset = load_dataset(\"europa_eac_tm\"‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/community-datasets/europa_eac_tm.","url":"https://huggingface.co/datasets/community-datasets/europa_eac_tm","creator_name":"Community Datasets","creator_url":"https://huggingface.co/community-datasets","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["translation","expert-generated","expert-generated","translation","original"],"keywords_longer_than_N":true},
	{"name":"multilingual_librispeech","keyword":"italian","description":"Multilingual LibriSpeech (MLS) dataset is a large multilingual corpus suitable for speech research. The dataset is derived from read audiobooks from LibriVox and consists of 8 languages - English, German, Dutch, Spanish, French, Italian, Portuguese, Polish.","url":"https://huggingface.co/datasets/legacy-datasets/multilingual_librispeech","creator_name":"Legacy Datasets","creator_url":"https://huggingface.co/legacy-datasets","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":null,"first_N":5,"first_N_keywords":["automatic-speech-recognition","audio-classification","speaker-identification","expert-generated","crowdsourced"],"keywords_longer_than_N":true},
	{"name":"eur-lex-sum","keyword":"italian","description":"The EUR-Lex-Sum dataset is a multilingual resource intended for text summarization in the legal domain.\nIt is based on human-written summaries of legal acts issued by the European Union.\nIt distinguishes itself by introducing a smaller set of high-quality human-written samples,\neach of which have much longer references (and summaries!) than comparable datasets.\nAdditionally, the underlying legal acts provide a challenging domain-specific application to legal texts,\nwhich are so far underrepresented in non-English languages.\nFor each legal act, the sample can be available in up to 24 languages\n(the officially recognized languages in the European Union);\nthe validation and test samples consist entirely of samples available in all languages,\nand are aligned across all languages at the paragraph level.","url":"https://huggingface.co/datasets/dennlinger/eur-lex-sum","creator_name":"Dennis Aumiller","creator_url":"https://huggingface.co/dennlinger","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":null,"first_N":5,"first_N_keywords":["translation","summarization","found","expert-generated","found"],"keywords_longer_than_N":true},
	{"name":"EU_Wikipedias","keyword":"italian","description":"Wikipedia dataset containing cleaned articles of all languages.\nThe datasets are built from the Wikipedia dump\n(https://dumps.wikimedia.org/) with one split per language. Each example\ncontains the content of one full Wikipedia article with cleaning to strip\nmarkdown and unwanted sections (references, etc.).","url":"https://huggingface.co/datasets/joelniklaus/EU_Wikipedias","creator_name":"Joel Niklaus","creator_url":"https://huggingface.co/joelniklaus","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["fill-mask","other","found","multilingual","original"],"keywords_longer_than_N":true},
	{"name":"nllb-200-10M-sample","keyword":"italian","description":"\n\t\n\t\t\n\t\tDataset Card for \"nllb-200-10M-sample\"\n\t\n\nThis is a sample of nearly 10M sentence pairs from the NLLB-200 \nmined dataset allenai/nllb, \nscored with the model facebook/blaser-2.0-qe \ndescribed in the SeamlessM4T paper.\nThe sample is not random; instead, we just took the top n sentence pairs from each translation direction.\nThe number n was computed with the goal of upsamping the directions that contain underrepresented languages.\nNevertheless, the 187 languoids (language and script‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/slone/nllb-200-10M-sample.","url":"https://huggingface.co/datasets/slone/nllb-200-10M-sample","creator_name":"SLONE","creator_url":"https://huggingface.co/slone","license_name":"Open Data Commons Attribution License v1.0","license_url":"https://scancode-licensedb.aboutcode.org/odc-by-1.0.html","language":"en","first_N":5,"first_N_keywords":["translation","Akan","Amharic","Arabic","Awadhi"],"keywords_longer_than_N":true},
	{"name":"bible_para","keyword":"italian","description":"This is a multilingual parallel corpus created from translations of the Bible compiled by Christos Christodoulopoulos and Mark Steedman.\n\n102 languages, 5,148 bitexts\ntotal number of files: 107\ntotal number of tokens: 56.43M\ntotal number of sentence fragments: 2.84M","url":"https://huggingface.co/datasets/Helsinki-NLP/bible_para","creator_name":"Language Technology Research Group at the University of Helsinki","creator_url":"https://huggingface.co/Helsinki-NLP","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":null,"first_N":5,"first_N_keywords":["translation","found","found","multilingual","original"],"keywords_longer_than_N":true},
	{"name":"CulturaY","keyword":"italian","description":"\n\t\n\t\t\n\t\tCulturaY: A Large Cleaned Multilingual Dataset of 75 Languages\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nFrom the team that brought you CulturaX, we present CulturaY, another substantial multilingual dataset of 15TB (uncompressed)/3TB (zstd-compressed) that applies the same dataset cleaning methodology to the HPLT v1.1 dataset. \nPlease note that HPLT v1.2 has also been released and is an alternative verison with different cleaning methodolgies. \nThis data was used in part to train our SOTA‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Viet-Mistral/CulturaY.","url":"https://huggingface.co/datasets/Viet-Mistral/CulturaY","creator_name":"Vietnamese Mistral","creator_url":"https://huggingface.co/Viet-Mistral","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","fill-mask","language-modeling","masked-language-modeling","no-annotation"],"keywords_longer_than_N":true},
	{"name":"HypoTranslate","keyword":"italian","description":"This repo releases the HypoTranslate dataset in paper \"GenTranslate: Large Language Models are Generative Multilingual Speech and Machine Translators\".\nCode: https://github.com/YUCHEN005/GenTranslate\nModel: https://huggingface.co/PeacefulData/GenTranslate\nData: This repo\nFilename format: [split]_[data_source]_[src_language_code]_[tgt_language_code]_[task]_[seamlessm4t_size].pt\ne.g. train_fleurs_en_cy_st_large.pt\nNote:\n\nLanguage code look-up: Table 15 & 17 in‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/PeacefulData/HypoTranslate.","url":"https://huggingface.co/datasets/PeacefulData/HypoTranslate","creator_name":"Peaceful Data","creator_url":"https://huggingface.co/PeacefulData","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":null,"first_N":5,"first_N_keywords":["text-generation","English","Chinese","Japanese","French"],"keywords_longer_than_N":true},
	{"name":"Fact-Completion","keyword":"italian","description":"\n\t\n\t\t\n\t\tDataset Card\n\t\n\n\nHomepage: https://bit.ly/ischool-berkeley-capstone\nRepository: https://github.com/daniel-furman/Capstone\nPoint of Contact: daniel_furman@berkeley.edu\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis is the dataset for Polyglot or Not?: Measuring Multilingual Encyclopedic Knowledge Retrieval from Foundation Language Models.\n\n\t\n\t\t\n\t\n\t\n\t\tTest Description\n\t\n\n Given a factual association such as The capital of France is Paris, we determine whether a model adequately \"knows\" this‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Polyglot-or-Not/Fact-Completion.","url":"https://huggingface.co/datasets/Polyglot-or-Not/Fact-Completion","creator_name":"Polyglot-or-Not","creator_url":"https://huggingface.co/Polyglot-or-Not","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","fill-mask","expert-generated","machine-generated","multilingual"],"keywords_longer_than_N":true},
	{"name":"massive_translation_dataset","keyword":"italian","description":"\n\t\n\t\t\n\t\tDataset Card for Massive Dataset for Translation\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset is derived from AmazonScience/MASSIVE dataset for translation task purpose.\n\n\t\n\t\t\n\t\tSupported Tasks and Leaderboards\n\t\n\nTranslation\n\n\t\n\t\t\n\t\tLanguages\n\t\n\n\nEnglish (en_US)\nGerman (de_DE)\nHindi (hi_IN)\nSpanish (es_ES)\nFrench (fr_FR)\nItalian (it_IT)\nArabic (ar_SA)\nDutch (nl_NL)\nJapanese (ja_JP)\nPortugese (pt_PT)\n\n","url":"https://huggingface.co/datasets/Amani27/massive_translation_dataset","creator_name":"Amani N","creator_url":"https://huggingface.co/Amani27","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["translation","English","German","Spanish","Hindi"],"keywords_longer_than_N":true},
	{"name":"mc4_legal","keyword":"italian","description":"\n\t\n\t\t\n\t\tDataset Card for MC4_Legal: A Corpus Covering the Legal Part of MC4 for European Languages\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset contains large text resources (~133GB in total) from mc4 filtered for legal data that can be used for pretraining language models.\nUse the dataset like this:\nfrom datasets import load_dataset\ndataset = load_dataset(\"joelito/mc4_legal\", \"de\", split='train', streaming=True)\n\n\n\t\n\t\t\n\t\n\t\n\t\tSupported Tasks and Leaderboards\n\t\n\nThe dataset supports the task of‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/joelniklaus/mc4_legal.","url":"https://huggingface.co/datasets/joelniklaus/mc4_legal","creator_name":"Joel Niklaus","creator_url":"https://huggingface.co/joelniklaus","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["fill-mask","other","found","multilingual","original"],"keywords_longer_than_N":true},
	{"name":"eurlex_resources","keyword":"italian","description":"\n\t\n\t\t\n\t\tDataset Card for EurlexResources: A Corpus Covering the Largest EURLEX Resources\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset contains large text resources (~179GB in total) from EURLEX that can be used for pretraining language models.\nUse the dataset like this:\nfrom datasets import load_dataset\nconfig = \"de_caselaw\" # {lang}_{resource}\ndataset = load_dataset(\"joelito/eurlex_resources\", config, split='train', streaming=True) \n\n\n\t\n\t\t\n\t\n\t\n\t\tSupported Tasks and Leaderboards\n\t\n\nThe dataset‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/joelniklaus/eurlex_resources.","url":"https://huggingface.co/datasets/joelniklaus/eurlex_resources","creator_name":"Joel Niklaus","creator_url":"https://huggingface.co/joelniklaus","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":null,"first_N":5,"first_N_keywords":["fill-mask","other","found","multilingual","original"],"keywords_longer_than_N":true},
	{"name":"conceptnet5","keyword":"italian","description":"\n\t\n\t\t\n\t\tDataset Card for Conceptnet5\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nConceptNet is a multilingual knowledge base, representing words and\nphrases that people use and the common-sense relationships between\nthem. The knowledge in ConceptNet is collected from a variety of\nresources, including crowd-sourced resources (such as Wiktionary and\nOpen Mind Common Sense), games with a purpose (such as Verbosity and\nnadya.jp), and expert-created resources (such as WordNet and JMDict).\nYou can browse what‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/conceptnet5/conceptnet5.","url":"https://huggingface.co/datasets/conceptnet5/conceptnet5","creator_name":"conceptnet5","creator_url":"https://huggingface.co/conceptnet5","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","multi-class-classification","crowdsourced","crowdsourced","found"],"keywords_longer_than_N":true},
	{"name":"xP3x-sample","keyword":"italian","description":"A multilingual collection of Winograd Schemas in six languages that can be used for evaluation of cross-lingual commonsense reasoning capabilities.","url":"https://huggingface.co/datasets/Muennighoff/xP3x-sample","creator_name":"Niklas Muennighoff","creator_url":"https://huggingface.co/Muennighoff","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["other","expert-generated","crowdsourced","multilingual","Afrikaans"],"keywords_longer_than_N":true},
	{"name":"blbooks","keyword":"italian","description":"A dataset comprising of text created by OCR from the 49,455 digitised books, equating to 65,227 volumes (25+ million pages), published between c. 1510 - c. 1900.\nThe books cover a wide range of subject areas including philosophy, history, poetry and literature.","url":"https://huggingface.co/datasets/TheBritishLibrary/blbooks","creator_name":"British Library","creator_url":"https://huggingface.co/TheBritishLibrary","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":null,"first_N":5,"first_N_keywords":["text-generation","fill-mask","other","language-modeling","masked-language-modeling"],"keywords_longer_than_N":true},
	{"name":"covid19_emergency_event","keyword":"italian","description":"\n\t\n\t\t\n\t\tDataset Card for EXCEPTIUS Corpus\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset presents a new corpus of legislative documents from 8 European countries (Beglium, France, Hunary, Italy, Netherlands, Norway, Poland, UK) in 7 languages (Dutch, English, French, Hungarian, Italian, Norwegian Bokm√•l, Polish) manually annotated for exceptional measures against COVID-19. The annotation was done on the sentence level.\n\n\t\n\t\t\n\t\tSupported Tasks and Leaderboards\n\t\n\nThe dataset can be used for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/joelniklaus/covid19_emergency_event.","url":"https://huggingface.co/datasets/joelniklaus/covid19_emergency_event","creator_name":"Joel Niklaus","creator_url":"https://huggingface.co/joelniklaus","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","multi-label-classification","found","other","found"],"keywords_longer_than_N":true},
	{"name":"Italian_Parkinsons_Voice_and_Speech","keyword":"italian","description":"The original dataset is located here\nThe citation for this dataset:\n@data{aw6b-tg17-19,\n  doi = {10.21227/aw6b-tg17},\n  url = {https://dx.doi.org/10.21227/aw6b-tg17},\n  author = {Dimauro, Giovanni and Girardi, Francesco},\n  publisher = {IEEE Dataport},\n  title = {Italian Parkinson's Voice and Speech},\n  year = {2019}\n}\n\nThe author of the dataset requests that academic users of the dataset cite the following articles, the latter of which describes how the dataset was created:‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/birgermoell/Italian_Parkinsons_Voice_and_Speech.","url":"https://huggingface.co/datasets/birgermoell/Italian_Parkinsons_Voice_and_Speech","creator_name":"Birger Moell","creator_url":"https://huggingface.co/birgermoell","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["Italian","cc-by-4.0","1K - 10K","soundfolder","Audio"],"keywords_longer_than_N":true},
	{"name":"clean_mc4_it_urls","keyword":"italian","description":"\n\t\n\t\t\n\t\tDataset Card for clean_mc4_it_urls\n\t\n\nThis dataset provides the URLs and top-level domains associated with training records in gsarti/clean_mc4_it. It is part of a collection of datasets curated to make exploring LLM training datasets more straightforward and accessible. \n\n\t\n\t\t\n\t\n\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Description\n\t\n\nThis dataset was created by downloading the source data, extracting URLs and top-level domains, and retaining only those record identifiers. In doing‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/nhagar/clean_mc4_it_urls.","url":"https://huggingface.co/datasets/nhagar/clean_mc4_it_urls","creator_name":"Nick Hagar","creator_url":"https://huggingface.co/nhagar","license_name":"Open Data Commons Attribution License v1.0","license_url":"https://scancode-licensedb.aboutcode.org/odc-by-1.0.html","language":"en","first_N":5,"first_N_keywords":["text-generation","Italian","odc-by","100M - 1B","parquet"],"keywords_longer_than_N":true},
	{"name":"Global-MMLU-Lite","keyword":"italian","description":"\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nGlobal-MMLU-Lite is a multilingual evaluation set spanning 16 languages, including English. It is \"lite\" version of the original Global-MMLU dataset üåç.\nIt includes 200 Culturally Sensitive (CS) and 200 Culturally Agnostic (CA) samples per language. The samples in Global-MMLU-Lite are corresponding to languages which are fully human translated or post-edited in the original Global-MMLU dataset. \nNOTE: Of the 16 languages presently included in Global-MMLU-Lite, 15‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/CohereLabs/Global-MMLU-Lite.","url":"https://huggingface.co/datasets/CohereLabs/Global-MMLU-Lite","creator_name":"Cohere Labs","creator_url":"https://huggingface.co/CohereLabs","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["English","Arabic","Bengali","Spanish","French"],"keywords_longer_than_N":true},
	{"name":"sentiment-analysis-test","keyword":"italian","description":"\n\t\n\t\t\n\t\tProgetto scolastico per l'analisi dei sentimenti\n\t\n\nil dataset √® stato creato con un questionario online in cui si chiedeva ad un publico di studenti, docenti, personale amministrativo, famiglie di rispondere ad alcune domande sul loro rapporto con la scuola.\nle annotazioni sono state effettuate correlando le risposte testuali ad indicatori di gradimento.\nil dataset √® stato realizzato all'interno di un corso pomeridiano scolastico dedicato all'intelligenza artificiale.\nGrazie a tutti‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Riccardoschillaci7/sentiment-analysis-test.","url":"https://huggingface.co/datasets/Riccardoschillaci7/sentiment-analysis-test","creator_name":"riccardo schillaci","creator_url":"https://huggingface.co/Riccardoschillaci7","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","sentiment-analysis","expert-generated","crowdsourced","crowdsourced"],"keywords_longer_than_N":true},
	{"name":"gsm8k_italian","keyword":"italian","description":"\n\t\n\t\t\n\t\tGSM8K - Italian (IT)\n\t\n\nThis dataset is an Italian translation of GSM8K. GSM8K stands for Grade School Math 8K, a dataset for math word problems, which should be easy to solve for people with an elementary school education.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\nThe dataset consists of math word problems, where each problem is associated with a possible explanation of how to solve it. The task is to generate the answer to the math problem. The dataset is split into a training set and a test set.‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/s-conia/gsm8k_italian.","url":"https://huggingface.co/datasets/s-conia/gsm8k_italian","creator_name":"Simone Conia","creator_url":"https://huggingface.co/s-conia","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-generation","Italian","English","mit","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"xsimplusplus","keyword":"italian","description":"xSIM++ is an extension of xSIM. In comparison to xSIM, this evaluates using target-side data with additional synthetic, hard-to-distinguish examples. You can find more details about it in the publication: xSIM++: An Improved Proxy to Bitext Mining Performance for Low-Resource Languages.\n","url":"https://huggingface.co/datasets/jaygala24/xsimplusplus","creator_name":"Jay Gala","creator_url":"https://huggingface.co/jaygala24","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["derived","multilingual","Achinese","Mesopotamian Arabic","Ta'izzi-Adeni Arabic"],"keywords_longer_than_N":true},
	{"name":"cml-tts","keyword":"italian","description":"\n\t\n\t\t\n\t\tDataset Card for CML-TTS\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nCML-TTS is a recursive acronym for CML-Multi-Lingual-TTS, a Text-to-Speech (TTS) dataset developed at the Center of Excellence in Artificial Intelligence (CEIA) of the Federal University of Goias (UFG).\nCML-TTS is a dataset comprising audiobooks sourced from the public domain books of Project Gutenberg, read by volunteers from the LibriVox project. The dataset includes recordings in Dutch, German, French, Italian, Polish‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ylacombe/cml-tts.","url":"https://huggingface.co/datasets/ylacombe/cml-tts","creator_name":"Yoach Lacombe","creator_url":"https://huggingface.co/ylacombe","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-to-speech","text-to-audio","Dutch","French","German"],"keywords_longer_than_N":true},
	{"name":"truthfulqax","keyword":"italian","description":"\n\t\n\t\t\n\t\tCitation Information\n\t\n\nIf you find benchmarks useful in your research, please consider citing the test and also the TruthfulQA dataset it draws from:\n    @misc{thellmann2024crosslingual,\n    title={Towards Cross-Lingual LLM Evaluation for European Languages},\n    author={Klaudia Thellmann and Bernhard Stadler and Michael Fromm and Jasper Schulze Buschhoff and Alex Jude and Fabio Barth and Johannes Leveling and Nicolas Flores-Herr and Joachim K√∂hler and Ren√© J√§kel and Mehdi Ali}‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Eurolingua/truthfulqax.","url":"https://huggingface.co/datasets/Eurolingua/truthfulqax","creator_name":"EuroLingua-GPT","creator_url":"https://huggingface.co/Eurolingua","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":null,"first_N":5,"first_N_keywords":["text-generation","German","French","Spanish","Italian"],"keywords_longer_than_N":true},
	{"name":"regolo-instruct-llama70B","keyword":"italian","description":"\n    \n      \n    \n\n\n\n\t\n\t\t\n\t\tRegolo Instruct Llama-3.3-70B - Regolo.ai üß†\n\t\n\n\n\t\n\t\t\n\t\tDescription\n\t\n\nThis dataset was generated using Llama-3.3-70B, served via regolo.ai.The generation process was divided into two main stages:\n\nTranslation of questions from open-source English-language datasets using Qwen2.5-7B  \nResponse generation through regolo\n\n\n    \n      \n    \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tData\n\t\n\n\n{\n  \"messages\": [\n    {\"role\": \"system\", \"content\": \"<SYSTEM MESSAGE>\"},\n    {\"role\": \"user\", \"content\":‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ReDiX/regolo-instruct-llama70B.","url":"https://huggingface.co/datasets/ReDiX/regolo-instruct-llama70B","creator_name":"ReDiX Labs","creator_url":"https://huggingface.co/ReDiX","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","Italian","apache-2.0","10K - 100K","json"],"keywords_longer_than_N":true},
	{"name":"Alucard-Character-Experiment","keyword":"italian","description":"\n\t\n\t\t\n\t\tAlucard: A Character Experiment\n\t\n\n\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nAlucard: A Character Experiment is a bilingual (Italian-English) dataset designed to train large language models (LLMs) to generate text in the distinctive style of Alucard. The dataset is crafted using a combination of real data (anime subtitles) and synthetic data generated from publicly available character profiles.\nTo ensure high-quality human-like interactions, both Claude Haiku and Llama 3.1 70B were leveraged to‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/WasamiKirua/Alucard-Character-Experiment.","url":"https://huggingface.co/datasets/WasamiKirua/Alucard-Character-Experiment","creator_name":"Wasami","creator_url":"https://huggingface.co/WasamiKirua","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","English","Italian","apache-2.0","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"biblenlp-corpus-mmteb","keyword":"italian","description":"This dataset pre-computes all English-centric directions from bible-nlp/biblenlp-corpus, and as a result loading is significantly faster.\nLoading example:\n>>> from datasets import load_dataset\n>>> dataset = load_dataset(\"davidstap/biblenlp-corpus-mmteb\", \"eng-arb\", trust_remote_code=True)\n>>> dataset\nDatasetDict({\n    train: Dataset({\n        features: ['eng', 'arb'],\n        num_rows: 28723\n    })\n    validation: Dataset({\n        features: ['eng', 'arb'],\n        num_rows: 1578\n    })‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/biblenlp-corpus-mmteb.","url":"https://huggingface.co/datasets/mteb/biblenlp-corpus-mmteb","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["no-annotation","expert-generated","translation","multilingual","Arifama-Miniafia"],"keywords_longer_than_N":true},
	{"name":"biblenlp-corpus-mmteb","keyword":"italian","description":"This dataset pre-computes all English-centric directions from bible-nlp/biblenlp-corpus, and as a result loading is significantly faster.\nLoading example:\n>>> from datasets import load_dataset\n>>> dataset = load_dataset(\"davidstap/biblenlp-corpus-mmteb\", \"eng-arb\", trust_remote_code=True)\n>>> dataset\nDatasetDict({\n    train: Dataset({\n        features: ['eng', 'arb'],\n        num_rows: 28723\n    })\n    validation: Dataset({\n        features: ['eng', 'arb'],\n        num_rows: 1578\n    })‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/biblenlp-corpus-mmteb.","url":"https://huggingface.co/datasets/mteb/biblenlp-corpus-mmteb","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["no-annotation","expert-generated","translation","multilingual","Arifama-Miniafia"],"keywords_longer_than_N":true},
	{"name":"Thinking-multilingual-big-10k-sft","keyword":"italian","description":"\nA dataset based off of openo1 math, 500 examples translated to 23 different languages. filtered out un-translated examples.\nenjoy üëç\n","url":"https://huggingface.co/datasets/Pinkstack/Thinking-multilingual-big-10k-sft","creator_name":"Pinkstack","creator_url":"https://huggingface.co/Pinkstack","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","Arabic","Chinese","Czech","Danish"],"keywords_longer_than_N":true},
	{"name":"gemma-vs-gemma-preferences","keyword":"italian","description":"\n\t\n\t\t\n\t\tüíéüÜöüíé Gemma vs Gemma Preferences\n\t\n\nThis dataset contains on-policy collected preferences generated using anakin87/gemma-2-2b-ita-sft.\n‚ö†Ô∏è While this dataset may be valuable for didactic purposes, it is not recommended for training a model using Preference Tuning due to the following reasons:\n\nThe training would be off-policy for your model.\nThe dataset was generated with gemma-2-2b-ita-sft, a small model for Italian.\n\n\n\t\n\t\t\n\t\n\t\n\t\tMotivation\n\t\n\nWhile DPO (Direct Preference‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/anakin87/gemma-vs-gemma-preferences.","url":"https://huggingface.co/datasets/anakin87/gemma-vs-gemma-preferences","creator_name":"Stefano Fiorucci","creator_url":"https://huggingface.co/anakin87","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","Italian","apache-2.0","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"Test_Youtube","keyword":"italian","description":"Decre99/Test_Youtube dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/Decre99/Test_Youtube","creator_name":"De","creator_url":"https://huggingface.co/Decre99","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-generation","Italian","mit","< 1K","parquet"],"keywords_longer_than_N":true},
	{"name":"dolphin-r1-italian","keyword":"italian","description":"\n  \n  \n\n\n\n  \n    \n  \n  \n    \n  \n  \n    \n  \n    \n  \n    \n    \n  \n\n\n  \n    \n  \n\n\n\n\t\n\t\n\t\n\t\tDolphin R1 Italian üê¨\n\t\n\n\nDolphin-R1 is an Apache-2.0 English dataset curated by Eric Hartford and Cognitive Computations\nDolphin-R1-Italian is a Italian subset of the original dataset.\n\n\n\t\n\t\t\n\t\tSponsors\n\t\n\nTheir and Wiro AI's appreciation for the generous sponsors of Dolphin R1 - Without whom this dataset could not exist.\n\nDria https://x.com/driaforall - Inference Sponsor (DeepSeek)\nChutes‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/WiroAI/dolphin-r1-italian.","url":"https://huggingface.co/datasets/WiroAI/dolphin-r1-italian","creator_name":"Wiro AI","creator_url":"https://huggingface.co/WiroAI","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["Italian","apache-2.0","100K - 1M","parquet","Text"],"keywords_longer_than_N":true},
	{"name":"dolphin-r1-italian","keyword":"italian","description":"\n  \n  \n\n\n\n  \n    \n  \n  \n    \n  \n  \n    \n  \n    \n  \n    \n    \n  \n\n\n  \n    \n  \n\n\n\n\t\n\t\n\t\n\t\tDolphin R1 Italian üê¨\n\t\n\n\nDolphin-R1 is an Apache-2.0 English dataset curated by Eric Hartford and Cognitive Computations\nDolphin-R1-Italian is a Italian subset of the original dataset.\n\n\n\t\n\t\t\n\t\tSponsors\n\t\n\nTheir and Wiro AI's appreciation for the generous sponsors of Dolphin R1 - Without whom this dataset could not exist.\n\nDria https://x.com/driaforall - Inference Sponsor (DeepSeek)\nChutes‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/WiroAI/dolphin-r1-italian.","url":"https://huggingface.co/datasets/WiroAI/dolphin-r1-italian","creator_name":"Wiro AI","creator_url":"https://huggingface.co/WiroAI","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["Italian","apache-2.0","100K - 1M","parquet","Text"],"keywords_longer_than_N":true},
	{"name":"RTE3","keyword":"italian","description":"\n  RTE3\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nRecognising Textual Entailment Challenge (RTE-3) aim to provide the NLP community with a benchmark to test progress in recognizing textual entailment\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2t\n\n\nDomains\nNews, Web, Encyclopaedic, Written\nReference\nhttps://aclanthology.org/W07-1401/\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask = mteb.get_task(\"RTE3\")‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/RTE3.","url":"https://huggingface.co/datasets/mteb/RTE3","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","semantic-similarity-classification","natural-language-inference","expert-annotated","multilingual"],"keywords_longer_than_N":true},
	{"name":"synthetic-pii-ner-mistral-v1","keyword":"italian","description":"This the synthetic dataset used for training https://huggingface.co/urchade/gliner_multi_pii-v1. You can get it by browsing the files and dowloading the data.json file.\n","url":"https://huggingface.co/datasets/urchade/synthetic-pii-ner-mistral-v1","creator_name":"Urchade Zaratiana","creator_url":"https://huggingface.co/urchade","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["English","French","Italian","German","Spanish"],"keywords_longer_than_N":true},
	{"name":"Toxic-All-it","keyword":"italian","description":"\n\t\n\t\t\n\t\tDecentralized Datasets\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis project includes four decentralized datasets: two in DPO format (dpo-unbiased1-it.json, dpo-unbiased2-it.json) and two in Alpaca format (alpaca-unbiased1-it.json, alpaca-unbiased2-it.json). These datasets were curated and reformatted from various open-source projects to support the development and training of decentralized models capable of handling a wide range of topics, including sensitive or controversial issues.‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Mattimax/Toxic-All-it.","url":"https://huggingface.co/datasets/Mattimax/Toxic-All-it","creator_name":"M.INC.","creator_url":"https://huggingface.co/Mattimax","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":null,"first_N":5,"first_N_keywords":["text-generation","Chinese","English","Italian","mit"],"keywords_longer_than_N":true},
	{"name":"TinyStories-Italian","keyword":"italian","description":"\n\t\n\t\t\n\t\tDataset Card for Dataset Name\n\t\n\n\n\nItalian translation of http://huggingface.co/datasets/roneneldan/TinyStories\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\n\n\nThe translation has been performed using Google Translator with Opus (Opus Model https://huggingface.co/Helsinki-NLP/opus-mt-tc-big-en-it ) as backup. \nColab notebook used for the translation: Translate_TinyStories.ipynb.\n\nCurated by: [Me]\nLanguage(s) (NLP): [Italian]\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Sources\n\t\n\n\n\n\nRepository:‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/markod0925/TinyStories-Italian.","url":"https://huggingface.co/datasets/markod0925/TinyStories-Italian","creator_name":"markod","creator_url":"https://huggingface.co/markod0925","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","Italian","apache-2.0","1M - 10M","parquet"],"keywords_longer_than_N":true},
	{"name":"TinyStories-Italian","keyword":"italian","description":"\n\t\n\t\t\n\t\tDataset Card for Dataset Name\n\t\n\n\n\nItalian translation of http://huggingface.co/datasets/roneneldan/TinyStories\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\n\n\nThe translation has been performed using Google Translator with Opus (Opus Model https://huggingface.co/Helsinki-NLP/opus-mt-tc-big-en-it ) as backup. \nColab notebook used for the translation: Translate_TinyStories.ipynb.\n\nCurated by: [Me]\nLanguage(s) (NLP): [Italian]\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Sources\n\t\n\n\n\n\nRepository:‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/markod0925/TinyStories-Italian.","url":"https://huggingface.co/datasets/markod0925/TinyStories-Italian","creator_name":"markod","creator_url":"https://huggingface.co/markod0925","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","Italian","apache-2.0","1M - 10M","parquet"],"keywords_longer_than_N":true},
	{"name":"minds14","keyword":"italian","description":"\n\t\n\t\t\n\t\tMInDS-14\n\t\n\nMINDS-14 is training and evaluation resource for intent detection task with spoken data. It covers 14 \nintents extracted from a commercial system in the e-banking domain, associated with spoken examples in 14 diverse language varieties.\n\n\t\n\t\t\n\t\tExample\n\t\n\nMInDS-14 can be downloaded and used as follows:\nfrom datasets import load_dataset\n\nminds_14 = load_dataset(\"PolyAI/minds14\", \"fr-FR\") # for French\n# to download all data for multi-lingual fine-tuning uncomment following‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/PolyAI/minds14.","url":"https://huggingface.co/datasets/PolyAI/minds14","creator_name":"PolyAI","creator_url":"https://huggingface.co/PolyAI","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","keyword-spotting","expert-generated","crowdsourced","machine-generated"],"keywords_longer_than_N":true},
	{"name":"OGC_MEGA_MultiDomain_DocRetrieval","keyword":"italian","description":"\n\t\n\t\t\n\t\tVisual Document Retrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset is designed for training visual document retrieval models. It combines multiple datasets from the OGC series, Colpali, and LlamaIndex to create the most comprehensive training resource for visual document retrieval tasks.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nThe dataset contains structured fields including unique identifiers with string lengths ranging from 45 to 50 characters, search query text with variable lengths between‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/racineai/OGC_MEGA_MultiDomain_DocRetrieval.","url":"https://huggingface.co/datasets/racineai/OGC_MEGA_MultiDomain_DocRetrieval","creator_name":"racine.ai","creator_url":"https://huggingface.co/racineai","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["visual-document-retrieval","text-retrieval","multilingual","English","French"],"keywords_longer_than_N":true},
	{"name":"DATA-AI_Real_Dataset","keyword":"italian","description":"\n\t\n\t\t\n\t\tItaliano / Italian Real-World Dataset - M.INC\n\t\n\nIT | Italiano\nBenvenuti nel Dataset Reale in Italiano, creato da M.INC e pubblicato da Mattimax su Hugging Face. Questo dataset √® pensato per l'addestramento e la valutazione di modelli linguistici in lingua italiana, ed √® composto da 746 coppie di input e output reali.\nIl dataset raccoglie risposte e conversazioni naturali, incluse quelle fornite da EINS-01, il prototipo di assistente vocale sviluppato da M.INC. √à ideale per il‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Mattimax/DATA-AI_Real_Dataset.","url":"https://huggingface.co/datasets/Mattimax/DATA-AI_Real_Dataset","creator_name":"M.INC.","creator_url":"https://huggingface.co/Mattimax","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","Italian","apache-2.0","< 1K","json"],"keywords_longer_than_N":true},
	{"name":"amazon_massive_scenario","keyword":"italian","description":"\n  MassiveScenarioClassification\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nMASSIVE: A 1M-Example Multilingual Natural Language Understanding Dataset with 51 Typologically-Diverse Languages\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2c\n\n\nDomains\nSpoken\n\nReference\nhttps://arxiv.org/abs/2204.08582\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask = mteb.get_tasks([\"MassiveScenarioClassification\"])\nevaluator =‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/amazon_massive_scenario.","url":"https://huggingface.co/datasets/mteb/amazon_massive_scenario","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","human-annotated","translated","Afrikaans","Amharic"],"keywords_longer_than_N":true},
	{"name":"GeNTE","keyword":"italian","description":"\n\n\t\n\t\t\n\t\tüö® GeNTE has been superseded by mGeNTE, a new multilingual release of the corpus with additional annotations.\n\t\n\n\n\n\t\n\t\t\n\t\tDataset Card for GeNTE\n\t\n\nHomepage: https://mt.fbk.eu/gente/\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nGeNTE (Gender-Neutral Translation Evaluation) is a natural, bilingual corpus designed to benchmark the ability of machine translation systems to generate gender-neutral translations.\nBuilt from European Parliament speeches, GeNTE comprises a subset of the English-Italian portion‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/FBK-MT/GeNTE.","url":"https://huggingface.co/datasets/FBK-MT/GeNTE","creator_name":"FBK-MT","creator_url":"https://huggingface.co/FBK-MT","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["translation","text-generation","language-modeling","expert-generated","expert-generated"],"keywords_longer_than_N":true},
	{"name":"MAiDE-up","keyword":"italian","description":"\n\t\n\t\t\n\t\tDataset Card for MAiDE-up: Multilingual Deception Detection of GPT-generated Hotel Reviews\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nMultilingual Deception Detection of GPT-generated Hotel Reviews. We compare real hotel reviews from Booking with LLM-generated hotel reviews in 10 languages.\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nThe text in the dataset is in 10 languages: Chinese, English, French, German, Italian, Romanian, Korean, Russian, Spanish, Turkish\n\n\t\n\t\t\n\t\tSupported Tasks and Leaderboards\n\t\n\nTODO‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/MichiganNLP/MAiDE-up.","url":"https://huggingface.co/datasets/MichiganNLP/MAiDE-up","creator_name":"LIT @ UMich","creator_url":"https://huggingface.co/MichiganNLP","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","zero-shot-classification","English","Chinese","French"],"keywords_longer_than_N":true},
	{"name":"TxT360-500k-sample-no_cc","keyword":"italian","description":"\n\t\n\t\t\n\t\tBEE-spoke-data/TxT360-500k-sample-no_cc\n\t\n\nno common crawl\n","url":"https://huggingface.co/datasets/BEE-spoke-data/TxT360-500k-sample-no_cc","creator_name":"BEEspoke Data","creator_url":"https://huggingface.co/BEE-spoke-data","license_name":"Open Data Commons Attribution License v1.0","license_url":"https://scancode-licensedb.aboutcode.org/odc-by-1.0.html","language":"en","first_N":5,"first_N_keywords":["text-generation","feature-extraction","English","German","Japanese"],"keywords_longer_than_N":true},
	{"name":"Minstrel-1.0","keyword":"italian","description":"\n\n\n\t\n\t\t\n\t\tStorytelling and Novel Writing Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset has been meticulously crafted to provide a comprehensive resource for storytelling and novel writing. Designed for both aspiring writers and seasoned authors, it serves as a versatile tool to inspire creativity, refine writing techniques, and explore various narrative styles. The dataset combines classic literature from the public domain with systemically generated and manually curated content, making it a‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/WasamiKirua/Minstrel-1.0.","url":"https://huggingface.co/datasets/WasamiKirua/Minstrel-1.0","creator_name":"Wasami","creator_url":"https://huggingface.co/WasamiKirua","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","Italian","apache-2.0","10K - 100K","json"],"keywords_longer_than_N":true},
	{"name":"tweet_sentiment_multilingual","keyword":"italian","description":"\n  TweetSentimentClassification\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nA multilingual Sentiment Analysis dataset consisting of tweets in 8 different languages.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2c\n\n\nDomains\nSocial, Written\n\n\nReferencehttps://aclanthology.org/2022.lrec-1.27\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask = mteb.get_tasks([\"TweetSentimentClassification\"])\nevaluator =‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/tweet_sentiment_multilingual.","url":"https://huggingface.co/datasets/mteb/tweet_sentiment_multilingual","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"Creative Commons Attribution 3.0","license_url":"https://scancode-licensedb.aboutcode.org/cc-by-3.0.html","language":"en","first_N":5,"first_N_keywords":["text-classification","sentiment-analysis","sentiment-scoring","sentiment-classification","hate-speech-detection"],"keywords_longer_than_N":true},
	{"name":"mewsli-x","keyword":"italian","description":"I generated the dataset following mewsli-x.md#getting-started\nand converted into different parts (see process.py):\n\nar/de/en/es/fa/ja/pl/ro/ta/tr/uk wikinews_mentions dev and test (from wikinews_mentions-dev/test.jsonl)\ncandidate entities of 50 languages (from candidate_set_entities.jsonl)\nEnglish wikipedia_pairs to fine-tune models (from wikipedia_pairs-dev/train.jsonl)\n\nRaw data files are in raw.tar.gz, which contains:\n[...] 535M Feb 24 22:06 candidate_set_entities.jsonl\n[...] 9.8M Feb 24‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/izhx/mewsli-x.","url":"https://huggingface.co/datasets/izhx/mewsli-x","creator_name":"Xin Zhang","creator_url":"https://huggingface.co/izhx","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","entity-linking-retrieval","Afrikaans","Arabic","Azerbaijani"],"keywords_longer_than_N":true},
	{"name":"community-alignment-dataset","keyword":"italian","description":"\nCommunity Alignment\n\n\n Github ¬† | ¬†\n Paper\n\n\n\n\t\n\t\t\n\t\tDataset\n\t\n\nCommunity Alignment is a large-scale open source, multilingual and multi-turn preference dataset to align LLMs with human preferences across cultures. It features prompt-level overlap in annotators, enabling social-choice-based and distributional approaches to LLM alignment, as well as natural language explanations for choices.\n\n[Large-scale] ~200,000 comparisons of LLM responses, collected from >3,000 unique annotators who‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/facebook/community-alignment-dataset.","url":"https://huggingface.co/datasets/facebook/community-alignment-dataset","creator_name":"AI at Meta","creator_url":"https://huggingface.co/facebook","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["Hindi","English","Portuguese","Italian","French"],"keywords_longer_than_N":true},
	{"name":"prompt-injection-multilingual","keyword":"italian","description":"rikka-snow/prompt-injection-multilingual dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/rikka-snow/prompt-injection-multilingual","creator_name":"Le Xuan Hoang","creator_url":"https://huggingface.co/rikka-snow","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","Vietnamese","English","Chinese","French"],"keywords_longer_than_N":true},
	{"name":"toxicity-multilingual-binary-classification-dataset","keyword":"italian","description":"This dataset is a comprehensive collection designed to aid in the development of robust and nuanced models for identifying toxic language across multiple languages, while critically distinguishing it from expressions related to mental health, specifically depression. It synthesizes content from three existing public datasets (ToxiGen, TextDetox, and Mental Health - Depression) with a newly generated synthetic dataset (ToxiLLaMA). The creation process involved careful collection, extensive‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/malexandersalazar/toxicity-multilingual-binary-classification-dataset.","url":"https://huggingface.co/datasets/malexandersalazar/toxicity-multilingual-binary-classification-dataset","creator_name":"Alexander Salazar","creator_url":"https://huggingface.co/malexandersalazar","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["English","German","French","Italian","Portuguese"],"keywords_longer_than_N":true},
	{"name":"ApolloMoEDataset","keyword":"italian","description":"\n\t\n\t\t\n\t\tDemocratizing Medical LLMs For Much More Languages\n\t\n\nCovering 12 Major Languages including English, Chinese, French, Hindi, Spanish, Arabic, Russian, Japanese, Korean, German, Italian, Portuguese and 38 Minor Languages So far.\n\n   üìÉ Paper ‚Ä¢ üåê Demo ‚Ä¢ ü§ó ApolloMoEDataset ‚Ä¢ ü§ó ApolloMoEBench  ‚Ä¢ ü§ó Models  ‚Ä¢üåê Apollo  ‚Ä¢ üåê ApolloMoE\n\n\n\n\n\n\n\t\n\t\t\n\t\tüåà Update\n\t\n\n\n[2024.10.15] ApolloMoE repo is publishedÔºÅüéâ\n\n\n\t\n\t\t\n\t\tLanguages Coverage\n\t\n\n12 Major Languages and 38 Minor Languages\n\n  Click to‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/FreedomIntelligence/ApolloMoEDataset.","url":"https://huggingface.co/datasets/FreedomIntelligence/ApolloMoEDataset","creator_name":"FreedomAI","creator_url":"https://huggingface.co/FreedomIntelligence","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["question-answering","Arabic","English","Chinese","Korean"],"keywords_longer_than_N":true},
	{"name":"replique-a","keyword":"italian","description":"\n\t\n\t\t\n\t\tDescription\n\t\n\nThe JSONL file generated by the script below contains detailed information about a corpus of public domain films, including their subtitles in multiple languages. Here is a detailed description of its structure:\n\n\t\n\t\t\n\t\tJSONL file structure\n\t\n\n\nIMDB: Unique identifier for the movie in the IMDb database.\nprimary_title: Primary title of the movie.\noriginal_title:  Original title of the movie.\nfrench: \nfilepath: Relative path to the French subtitles file.\nsubtitles: List of‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/opsci/replique-a.","url":"https://huggingface.co/datasets/opsci/replique-a","creator_name":"opsci","creator_url":"https://huggingface.co/opsci","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","French","English","Italian","Spanish"],"keywords_longer_than_N":true},
	{"name":"Fusion_Ita_Datasets_2","keyword":"italian","description":"\n\t\n\t\t\n\t\tüìö Mattimax/Fusion_Ita_Datasets_2\n\t\n\n\n\t\n\t\t\n\t\tüìå Descrizione\n\t\n\nMattimax/Fusion_Ita_Datasets_v2 √® un dataset in italiano creato dalla fusione e normalizzazione di diversi dataset pubblici di conversazioni, istruzioni e QA.  \nInclude dati di alta qualit√† in lingua italiana, filtrati per rimuovere valori nulli e duplicati, pronti per l‚Äôaddestramento di modelli di linguaggio per completamento di testi, domande/risposte e dialoghi multi-turno.\n\n\n\t\n\t\t\n\t\n\t\n\t\tüõ† Origine dei dati\n\t\n\nI dataset‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Mattimax/Fusion_Ita_Datasets_2.","url":"https://huggingface.co/datasets/Mattimax/Fusion_Ita_Datasets_2","creator_name":"M.INC.","creator_url":"https://huggingface.co/Mattimax","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","question-answering","Italian","apache-2.0","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"casimedicos-arg","keyword":"italian","description":"\n    \n    \n    \n\n\n\t\n\t\t\n\t\tCasiMedicos-Arg: A Medical Question Answering Dataset Annotated with Explanatory Argumentative Structures\n\t\n\nCasiMedicos-Arg is, to the best of our knowledge, the first \nmultilingual dataset for Medical Question Answering where correct and incorrect diagnoses for a clinical case are \nenriched with a natural language explanation written by doctors. \nThe casimedicos-exp have been manually annotated with \nargument components (i.e., premise, claim) and argument relations‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/HiTZ/casimedicos-arg.","url":"https://huggingface.co/datasets/HiTZ/casimedicos-arg","creator_name":"HiTZ zentroa","creator_url":"https://huggingface.co/HiTZ","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","question-answering","token-classification","English","Spanish"],"keywords_longer_than_N":true},
	{"name":"italian_dataset_mix","keyword":"italian","description":"\n\t\n\t\t\n\t\tDataset Card for Dataset Name\n\t\n\n\nThis dataset represents a collection of the most downloaded Italian datasets.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\n\nThis dataset represents a collection of the most downloaded Italian datasets:\n\nWasamiKirua/samantha-ita\n\nmii-community/ultrafeedback-translated-ita\n\nmchl-labs/stambecco_data_it\n\nefederici/fisica\n\nFreedomIntelligence/sharegpt-italian\n\nCurated by: Enzo Palmisano\n\nLanguage(s) (NLP): Italian\n\nLicense: Apache 2.0\n\n\n","url":"https://huggingface.co/datasets/e-palmisano/italian_dataset_mix","creator_name":"Enzo Palmisano","creator_url":"https://huggingface.co/e-palmisano","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["question-answering","text-generation","Italian","apache-2.0","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"muri-it-language-split","keyword":"italian","description":"\n\t\n\t\t\n\t\tMURI-IT: Multilingual Instruction Tuning Dataset for 200 Languages via Multilingual Reverse Instructions\n\t\n\nMURI-IT is a large-scale multilingual instruction tuning dataset containing 2.2 million instruction-output pairs across 200 languages. It is designed to address the challenges of instruction tuning in low-resource languages with Multilingual Reverse Instructions (MURI), which ensures that the output is human-written, high-quality, and authentic to the cultural and linguistic‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/akoksal/muri-it-language-split.","url":"https://huggingface.co/datasets/akoksal/muri-it-language-split","creator_name":"Abdullatif Koksal","creator_url":"https://huggingface.co/akoksal","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text2text-generation","text-generation","question-answering","summarization","Achinese"],"keywords_longer_than_N":true},
	{"name":"BEEP_eval","keyword":"italian","description":"\n\t\n\t\t\n\t\tüöó BEst DrivEr‚Äôs License Performer (BEEP) Dataset\n\t\n\nBEEP is a challenge benchmark designed to evaluate large language models (LLMs) through a simulation of the Italian driver‚Äôs license exam. This dataset focuses on understanding traffic laws and reasoning through driving situations, replicating the complexity of the Italian licensing process.\n\n\n\t\n\t\t\n\t\tüìÅ Dataset Structure\n\t\n\n\n\t\n\t\t\nColumn\nData Type\nDescription\n\n\n\t\t\nCategorisation Structure\n[String]\nHierarchical categorisation of major‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Crisp-Unimib/BEEP_eval.","url":"https://huggingface.co/datasets/Crisp-Unimib/BEEP_eval","creator_name":"Interuniversity Research Centre for Public Services","creator_url":"https://huggingface.co/Crisp-Unimib","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["question-answering","Italian","mit","1K - 10K","csv"],"keywords_longer_than_N":true},
	{"name":"oaast_rm_full_jieba","keyword":"italian","description":"Â∞ùËØïËß£ÂÜ≥\"llm repetition problem\"Ôºå‰ΩøÁî®ÂàÜËØçÊ®°ÂûãÂØπoaastËØ≠ÊñôËøõË°å‚ÄúÁªìÂ∑¥Âåñ‚ÄùÊï∞ÊçÆÂ¢ûÂº∫ÔºåÊèê‰æõÊõ¥Âº∫ÁöÑÈáçÂ§çÂÜÖÂÆπÊãíÁªùÊïàÊûú„ÄÇ\nAttempts to solve the \"llm repetition problem\" by using a segmentation model to enhance the oaast corpus with \"stuttering\" data to provide stronger rejection of duplicate content.\nÂÖ∂Ê¨°ÔºåËøòËøáÊª§Êéâ‰∫ÜÊâÄÊúâËá™ÊàëËÆ§Áü•ÁöÑÂæÆË∞ÉÊ†∑Êú¨„ÄÇ\nSecond, it also filters out all the fine-tuned samples of self-cognition.\nfiles:\n\noaast_rm_full_jieba.jsonl : word level repeat\noaast_rm_full_sent_jieba.jsonl : sentence level repeat\n\n","url":"https://huggingface.co/datasets/lenML/oaast_rm_full_jieba","creator_name":"len","creator_url":"https://huggingface.co/lenML","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["English","Spanish","Russian","German","Polish"],"keywords_longer_than_N":true},
	{"name":"aya_evaluation_suite","keyword":"italian","description":"\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nAya Evaluation Suite contains a total of 26,750 open-ended conversation-style prompts to evaluate multilingual open-ended generation quality.To strike a balance between language coverage and the quality that comes with human curation, we create an evaluation suite that includes:\n\nhuman-curated examples in 7 languages (tur, eng, yor, arb, zho, por, tel) ‚Üí aya-human-annotated.\nmachine-translations of handpicked examples into 101 languages ‚Üí dolly-machine-translated.‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/CohereLabs/aya_evaluation_suite.","url":"https://huggingface.co/datasets/CohereLabs/aya_evaluation_suite","creator_name":"Cohere Labs","creator_url":"https://huggingface.co/CohereLabs","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","crowdsourced","expert-generated","machine-generated","multilingual"],"keywords_longer_than_N":true},
	{"name":"YouTube-Commons","keyword":"italian","description":"\n\t\n\t\t\n\t\tYouTube Commons Re-upload\n\t\n\nThis is a re-upload of PleIAs' YouTube Commons, a valuable open dataset:\n\nYouTube-Commons is a collection of audio transcripts of 2,063,066 videos shared on YouTube under a CC BY 4.0 license.\nContent\nThe collection comprises 22,709,724 original and automatically translated transcripts from 3,156,703 videos (721,136 individual channels).\n\nUnfortunately, there are problems with loading YouTube Commons with Hugging Face Datasets.\nIn order to alleviate those‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Rijgersberg/YouTube-Commons.","url":"https://huggingface.co/datasets/Rijgersberg/YouTube-Commons","creator_name":"Edwin Rijgersberg","creator_url":"https://huggingface.co/Rijgersberg","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","English","French","Spanish","Portuguese"],"keywords_longer_than_N":true},
	{"name":"webui-dom-snapshots","keyword":"italian","description":"\n\t\n\t\t\n\t\tDataset Card for WebUI DOM snapshots\n\t\n\n\n\nThis dataset card aims to be a base template for new datasets. It has been generated using this raw template.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\n\n\n\n\n\nCurated by: Gary Benson\nLanguages: Mostly English (87%);\nDutch, French, Chinese, Japanese (1-2% each); 30+ others (<1% each)\nLicense: CC0 1.0 Universal\n\n\n\t\n\t\t\n\t\tDataset Sources [optional]\n\t\n\n\n\n\nRepository: [More Information Needed]\nPaper [optional]: [More Information Needed]‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/gbenson/webui-dom-snapshots.","url":"https://huggingface.co/datasets/gbenson/webui-dom-snapshots","creator_name":"Gary Benson","creator_url":"https://huggingface.co/gbenson","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["image-feature-extraction","reinforcement-learning","text-classification","multilingual","biglab/webui-7k"],"keywords_longer_than_N":true},
	{"name":"panlex-meanings","keyword":"italian","description":"\n\t\n\t\t\n\t\tDataset Card for panlex-meanings\n\t\n\nThis is a dataset of words in several thousand languages, extracted from https://panlex.org.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset has been extracted from https://panlex.org (the 20240301 database dump) and rearranged on the per-language basis.\nEach language subset consists of expressions (words and phrases). \nEach expression is associated with some meanings (if there is more than one meaning, they are in separate‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/cointegrated/panlex-meanings.","url":"https://huggingface.co/datasets/cointegrated/panlex-meanings","creator_name":"David Dale","creator_url":"https://huggingface.co/cointegrated","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["translation","Afar","Western Abnaki","Abkhazian","Abaza"],"keywords_longer_than_N":true},
	{"name":"Multilingal-sakalt-data","keyword":"italian","description":"„Éû„É´„ÉÅ„É™„É≥„Ç¨„É´„Éá„Éº„Çø„Çª„ÉÉ„Éà„Åß„Åô„ÄÇmit„É©„Ç§„Çª„É≥„Çπ„Åß„Åô„ÄÇ\n","url":"https://huggingface.co/datasets/Sakalti/Multilingal-sakalt-data","creator_name":"sakasan","creator_url":"https://huggingface.co/Sakalti","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-generation","Abkhaz","Bhojpuri","Chechen","Czech"],"keywords_longer_than_N":true},
	{"name":"tokenizer-robustness-mmlu","keyword":"italian","description":"\n\t\n\t\t\n\t\tTokenizer Robustness MMLU Dataset\n\t\n\nThis dataset contains MMLU-formatted questions and answers designed to test tokenizer robustness across different text formats and languages.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset consists of the same questions presented in 6 different formats, with both test (20 questions) and development (5 questions) sets:\n\noriginal - Standard formatted questions\nminor_spelling_errors - Questions with minor misspellings\nspoken_language - Questions in casual‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Malikeh1375/tokenizer-robustness-mmlu.","url":"https://huggingface.co/datasets/Malikeh1375/tokenizer-robustness-mmlu","creator_name":"Malikeh Ehghaghi","creator_url":"https://huggingface.co/Malikeh1375","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["English","Russian","Chinese","Japanese","German"],"keywords_longer_than_N":true},
	{"name":"AIRC_FAQ","keyword":"italian","description":"\n\t\n\t\t\n\t\n\t\n\t\tFAQ AIRC\n\t\n\nCollection of FAQs from AIRC's website.\nAIRC is the Italian association for cancer research. \nFounded more than 50 years ago, it continuously supports, through fundraising, the progress of research for the treatment of cancer and disseminates correct information about its results, prevention and therapeutic prospects.\n","url":"https://huggingface.co/datasets/nickprock/AIRC_FAQ","creator_name":"Nicola Procopio","creator_url":"https://huggingface.co/nickprock","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["question-answering","Italian","mit","n<1K","pandas"],"keywords_longer_than_N":true},
	{"name":"tulu-3-sft-mixture-with-language","keyword":"italian","description":"\n\nJust a version of the good tulu-3-sft-mixture dataset with a column indicating language.\nLanguage detection has been performed with fastText.\n‚ö†Ô∏è It may contain errors.\n","url":"https://huggingface.co/datasets/anakin87/tulu-3-sft-mixture-with-language","creator_name":"Stefano Fiorucci","creator_url":"https://huggingface.co/anakin87","license_name":"Open Data Commons Attribution License v1.0","license_url":"https://scancode-licensedb.aboutcode.org/odc-by-1.0.html","language":"en","first_N":5,"first_N_keywords":["other","crowdsourced","expert-generated","machine-generated","multilingual"],"keywords_longer_than_N":true},
	{"name":"Lemonade","keyword":"italian","description":"LEMONADE is a large, expert-annotated dataset for event extraction from news articles in 20 languages: English, Spanish, Arabic, French, Italian, Russian, German, Turkish, Burmese, Indonesian, Ukrainian, Korean, Portuguese, Dutch, Somali, Nepali, Chinese, Persian, Hebrew, and Japanese.\nSee https://github.com/stanford-oval/Lemonade for details.\n","url":"https://huggingface.co/datasets/stanford-oval/Lemonade","creator_name":"Stanford Open Virtual Assistant Lab (OVAL)","creator_url":"https://huggingface.co/stanford-oval","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","text-generation","English","Spanish","Arabic"],"keywords_longer_than_N":true},
	{"name":"SMPQA","keyword":"italian","description":"\n\t\n\t\t\n\t\n\t\n\t\tSMPQA (Synthetic Multilingual Plot QA)\n\t\n\n\n\nThe SMPQA evaluation dataset proposed in Centurio: On Drivers of Multilingual Ability of Large Vision-Language Model.\nSMPQA is composed of synthetic bar plots and pie charts (generated using word lists of different languages) together with questions about those plots.\nThe datasets aims at providing an initial way of evaluating multilingual OCR capabilities of models in arbritrary languages.\nThere are two sub-tasks: \n\nGrounding text labels‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/WueNLP/SMPQA.","url":"https://huggingface.co/datasets/WueNLP/SMPQA","creator_name":"W√ºNLP","creator_url":"https://huggingface.co/WueNLP","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["visual-question-answering","English","Zulu","Indonesian","Italian"],"keywords_longer_than_N":true},
	{"name":"philosophy-culture-translations-html-csv","keyword":"italian","description":"\n\t\n\t\t\n\t\tAI-Culture Philosophy and Culture Translations CSV + HTML Corpus\n\t\n\nThe corpus contains an exceptionally diverse range of cultural, philosophical, and literary texts, available in 12 major languages. Among other topics, there is extensive engagement with the ethics and aesthetics of artificial intelligence and its cultural and philosophical implications, as well as connections between AI and philosophy of language and philosophy of mind.\nThis project is maintained by a non-profit‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/AI-Culture-Commons/philosophy-culture-translations-html-csv.","url":"https://huggingface.co/datasets/AI-Culture-Commons/philosophy-culture-translations-html-csv","creator_name":"AI‚ÄëCulture‚ÄëCommons","creator_url":"https://huggingface.co/AI-Culture-Commons","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["translation","text-generation","text-classification","sentence-similarity","summarization"],"keywords_longer_than_N":true},
	{"name":"virc","keyword":"italian","description":"\n\t\n\t\t\n\t\tVulnerable Identities Recognition Corpus (VIRC) for Hate Speech Analysis\n\t\n\nWelcome to the Vulnerable Identities Recognition Corpus (VIRC), a dataset created to enhance hate speech analysis in Italian and Spanish news headlines. VIRC provides annotated headlines aimed at identifying vulnerable identities, dangerous discourse, derogatory mentions, and entities. This corpus contributes to developing more sophisticated hate speech detection tools and policies for creating a safer online‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/oeg/virc.","url":"https://huggingface.co/datasets/oeg/virc","creator_name":"Ontology Engineering Group","creator_url":"https://huggingface.co/oeg","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["zero-shot-classification","question-answering","text-classification","Spanish","Italian"],"keywords_longer_than_N":true},
	{"name":"ProfessorHeidelTime","keyword":"italian","description":"\n\t\n\t\t\n\t\tProfessor HeidelTime\n\t\n\nPaper    GitHub\nProfessor HeidelTime is a project to create a multilingual corpus weakly labeled with HeidelTime, a temporal tagger.\n\n\t\n\t\t\n\t\tCorpus Details\n\t\n\nThe weak labeling was performed in six languages. Here are the specifics of the corpus for each language:\n\n\t\n\t\t\nDataset\nLanguage\nDocuments\nFrom\nTo\nTokens\nTimexs\n\n\n\t\t\nAll the News 2.0\nEN\n24,642\n2016-01-01\n2020-04-02\n18,755,616\n254,803\n\n\nItalian Crime News\nIT\n9,619\n2011-01-01\n2021-12-31\n3,296,898\n58,823‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/hugosousa/ProfessorHeidelTime.","url":"https://huggingface.co/datasets/hugosousa/ProfessorHeidelTime","creator_name":"Hugo Sousa","creator_url":"https://huggingface.co/hugosousa","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["token-classification","parsing","part-of-speech","named-entity-recognition","machine-generated"],"keywords_longer_than_N":true},
	{"name":"mosel","keyword":"italian","description":"\n\n\n\t\n\t\t\n\t\tDataset Description, Collection, and Source\n\t\n\nThe MOSEL corpus is a multilingual dataset collection including up to 950K hours of open-source speech recordings covering the 24 official languages of the European Union. We collect data by surveying labeled and unlabeled speech corpora under open-source compliant licenses.\nIn particular, MOSEL includes the automatic transcripts of 441k hours of unlabeled speech from VoxPopuli and LibriLight. The data is transcribed using Whisper large‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/FBK-MT/mosel.","url":"https://huggingface.co/datasets/FBK-MT/mosel","creator_name":"FBK-MT","creator_url":"https://huggingface.co/FBK-MT","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","text-to-speech","machine-generated","found","multilingual"],"keywords_longer_than_N":true},
	{"name":"sentiment-analysis-test","keyword":"italian","description":"\n\t\n\t\t\n\t\tProgetto scolastico per l'analisi dei sentimenti\n\t\n\nIl dataset √® stato creato in un questionario online in cui si chiedeva ad un pubblico di studenti, docenti, personale amministrativo, famiglie di rispondere ad alcune domande sul loro rapporto con la scuola.\nLe annotazioni sono state effettuate correlando le risposte testuali ad indicatori di gradimento.\nil dataset √® stato realizzato all'interno di un corso pomeridiano scolastico dedicato all'intelligenza artificiale\nGrazie a tutti‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Merlinooooo/sentiment-analysis-test.","url":"https://huggingface.co/datasets/Merlinooooo/sentiment-analysis-test","creator_name":"Fra Merlino","creator_url":"https://huggingface.co/Merlinooooo","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","sentiment-analysis","expert-generated","crowdsourced","crowdsourced"],"keywords_longer_than_N":true},
	{"name":"smorfia_napoletana","keyword":"italian","description":"vress/smorfia_napoletana dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/vress/smorfia_napoletana","creator_name":"erika inversi","creator_url":"https://huggingface.co/vress","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-generation","Italian","mit","< 1K","text"],"keywords_longer_than_N":true},
	{"name":"Post-OCR-Correction","keyword":"italian","description":"Post-OCR correction is a large corpus of 1 billion words containing original texts with a varying number of OCR mistakes and an experimental multilingual post-OCR correction output created by Pleias.\nGeneration of Post-OCR correction was performed using HPC resources from GENCI‚ÄìIDRIS (Grant 2023-AD011014736) on Jean-Zay.\n\n\t\n\t\t\n\t\tDescription\n\t\n\nAll the texts come from collections integrated into Common Corpus, the largest open corpus for pretraining previously released by Pleias on HuggingFace.‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/PleIAs/Post-OCR-Correction.","url":"https://huggingface.co/datasets/PleIAs/Post-OCR-Correction","creator_name":"PleIAs","creator_url":"https://huggingface.co/PleIAs","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["French","English","Italian","German","cc0-1.0"],"keywords_longer_than_N":true},
	{"name":"SemEval2024-task8","keyword":"italian","description":"\n\t\n\t\t\n\t\tSemEval2024-task8\n\t\n\nUnofficial mirror of M4 dataset from mbzuai-nlp/SemEval2024-task8 (website, github, codabench).\n\n\t\n\t\t\n\t\n\t\n\t\tData Format\n\t\n\n\n\t\n\t\t\n\t\n\t\n\t\tSubtask A\n\t\n\nAn object in the JSON format:\n{\n  id -> identifier of the example,\n  label -> label (human text: 0, machine text: 1,),\n  text -> text generated by a machine or written by a human,\n  model -> model that generated the data,\n  source -> source (Wikipedia, Wikihow, Peerread, Reddit, Arxiv)  on English or language (Arabic‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/d0rj/SemEval2024-task8.","url":"https://huggingface.co/datasets/d0rj/SemEval2024-task8","creator_name":"Dmitry Balobin","creator_url":"https://huggingface.co/d0rj","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","original","English","Arabic","German"],"keywords_longer_than_N":true},
	{"name":"MultiSimV2","keyword":"italian","description":"\n\t\n\t\t\n\t\tDataset Card for MultiSim Benchmark\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThe MultiSim benchmark is a growing collection of text simplification datasets targeted at sentence simplification in several languages.  Currently, the benchmark spans 12 languages.\n\n\n\t\n\t\n\t\n\t\tSupported Tasks\n\t\n\n\nSentence Simplification\n\n\n\t\n\t\n\t\n\t\tUsage\n\t\n\nfrom datasets importload_dataset\n\ndataset = load_dataset(\"MichaelR207/MultiSimV2\")\n\n\n\t\n\t\t\n\t\tCitation\n\t\n\nIf you use this benchmark, please cite our paper:‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/MichaelR207/MultiSimV2.","url":"https://huggingface.co/datasets/MichaelR207/MultiSimV2","creator_name":"Michael Ryan","creator_url":"https://huggingface.co/MichaelR207","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["summarization","text2text-generation","text-generation","English","French"],"keywords_longer_than_N":true},
	{"name":"MMMLU_subset","keyword":"italian","description":"\n\t\n\t\t\n\t\tAbout MMMLU subset\n\t\n\n  This is a subset of MMMLU, specifically, we sampled 10% of the original data to improve evaluation efficiency.\n  In addition, we categorize the questions into four categories by subject, i.e., STEM, HUMANITIES, SOCIAL SCIENCES, and OTHER, aligned with MMLU.\n\n\t\n\t\t\n\t\n\t\n\t\tMultilingual Massive Multitask Language Understanding (MMMLU)\n\t\n\nThe MMLU is a widely recognized benchmark of general knowledge attained by AI models. It covers a broad range of topics from 57‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/double7/MMMLU_subset.","url":"https://huggingface.co/datasets/double7/MMMLU_subset","creator_name":"Sen Yang","creator_url":"https://huggingface.co/double7","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["question-answering","Arabic","Bengali","German","Spanish"],"keywords_longer_than_N":true},
	{"name":"MAPS_Verified","keyword":"italian","description":"\n\t\n\t\t\n\t\tDataset Card for Multilingual Benchmark for Global Agent Performance and Security\n\t\n\nThis is the first Multilingual Agentic AI Benchmark for evaluating agentic AI systems across different languages and diverse tasks. Benchmark enables systematic analysis of how agents perform under multilingual conditions. This dataset contains 550 instances for GAIA, 660 instances for ASB, 737 instances for Maths, and 1100 instances for SWE. Each task was translated into 10 target languages resulting‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Fujitsu-FRE/MAPS_Verified.","url":"https://huggingface.co/datasets/Fujitsu-FRE/MAPS_Verified","creator_name":"Fujitsu Research of Europe","creator_url":"https://huggingface.co/Fujitsu-FRE","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-generation","question-answering","Arabic","English","Japanese"],"keywords_longer_than_N":true},
	{"name":"ItaRegol","keyword":"italian","description":"\n\t\n\t\t\n\t\tCorpus ItaRegol\n\t\n\nThe corpus containing 8 regulations was collected by the research unit of the University of Molise including linguists (Giuliana Fiorentino, Vittorio Ganfi), jurists (Alessandro Cioffi, Maria Assunta Simonelli) and computer scientists (Rocco Oliveto, Marco Russodivito).\n\n\t\n\t\t\n\t\tAcknowledgements\n\t\n\nThis contribution is a result of the research conducted within the framework of the PRIN 2020 (Progetti di Rilevante Interesse Nazionale) \"VerbACxSS: on analytic verbs‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/VerbACxSS/ItaRegol.","url":"https://huggingface.co/datasets/VerbACxSS/ItaRegol","creator_name":"VerbACxSS","creator_url":"https://huggingface.co/VerbACxSS","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-generation","Italian","mit","< 1K","csv"],"keywords_longer_than_N":true},
	{"name":"alpaca-cleaned-italian","keyword":"italian","description":"\n\t\n\t\t\n\t\tDataset Card for Alpaca-Cleaned-Italian\n\t\n\n\n\t\n\t\t\n\t\tAbout the translation and the original data\n\t\n\nThe translation was done with X-ALMA, a 13-billion-parameter model that surpasses state-of-the-art open-source multilingual LLMs (as of Q1 2025, paper here).\nThe original alpaca-cleaned dataset is also kept here so that there is parallel data for Italian and English.\n\n\t\n\t\t\n\t\n\t\n\t\tAdditional notes on the translation\n\t\n\n\nDespite the good quality of the translation, errors, though rare, are‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/DanielSc4/alpaca-cleaned-italian.","url":"https://huggingface.co/datasets/DanielSc4/alpaca-cleaned-italian","creator_name":"Daniel Scalena","creator_url":"https://huggingface.co/DanielSc4","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","question-answering","language-modeling","multilingual","translation"],"keywords_longer_than_N":true},
	{"name":"mmlu_italian","keyword":"italian","description":"\n\t\n\t\t\n\t\tMMLU - Italian (IT)\n\t\n\nThis dataset is an Italian translation of Massive Multitask Language Understanding (MMLU). MMLU is a dataset that is composed of multiple-choice questions from 57 different topics, including math, science, and social studies. The dataset is designed to evaluate the ability of models to answer questions across a wide range of topics.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\nThe dataset consists of multiple-choice questions from 57 different topics. Each question is associated‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/s-conia/mmlu_italian.","url":"https://huggingface.co/datasets/s-conia/mmlu_italian","creator_name":"Simone Conia","creator_url":"https://huggingface.co/s-conia","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-generation","Italian","English","mit","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"zenamt-sentence-level","keyword":"italian","description":"\n\t\n\t\t\n\t\tZenaMT corpus (sentence-level)\n\t\n\nThis is an Italian ‚Äì Ligurian (Genoese) parallel corpus covering a number of domains of cultural relevance to Ligurian speakers. Parts of the corpus also contain aligned English translations, available in the column eng. Whenever an English translation is not available, the corresponding column is set to null.\nThis is the sentence-level version of the corpus. If you are training your translation model on documents, you may be interested in the‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ConseggioLigure/zenamt-sentence-level.","url":"https://huggingface.co/datasets/ConseggioLigure/zenamt-sentence-level","creator_name":"Council for Ligurian Linguistic Heritage","creator_url":"https://huggingface.co/ConseggioLigure","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["translation","multilingual","original","Ligurian","Italian"],"keywords_longer_than_N":true},
	{"name":"opencup","keyword":"italian","description":"aborruso/opencup dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/aborruso/opencup","creator_name":"Andrea Borruso","creator_url":"https://huggingface.co/aborruso","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["Italian","cc-by-4.0","10M - 100M","parquet","Tabular"],"keywords_longer_than_N":true},
	{"name":"sentiment-analysis-test","keyword":"italian","description":"Liux69/sentiment-analysis-test dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/Liux69/sentiment-analysis-test","creator_name":"Lorenzo Martirani Paolillo","creator_url":"https://huggingface.co/Liux69","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","sentiment-analysis","crowdsourced","expert-generated","crowdsourced"],"keywords_longer_than_N":true},
	{"name":"webfaq","keyword":"italian","description":"WebFAQ Q&A Dataset\n\n   \n       Overview |\n       Details  |\n       Structure  |\n       Examples |\n       Considerations |\n       License |\n       Citation |\n       Contact |\n       Acknowledgement\n   \n\n\n\n\t\n\t\t\n\t\n\t\n\t\tOverview\n\t\n\nThe WebFAQ Q&A Dataset is a broad-coverage corpus of 96 million natural question-answer (QA) pairs in 75 languages, gathered from FAQ pages on the web. It leverages structured schema.org FAQPage annotations, making it a unique resource for large-scale Question Answering‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/PaDaS-Lab/webfaq.","url":"https://huggingface.co/datasets/PaDaS-Lab/webfaq","creator_name":"Chair of Data Science, University of Passau","creator_url":"https://huggingface.co/PaDaS-Lab","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["question-answering","multilingual","Afrikaans","Amharic","Arabic"],"keywords_longer_than_N":true},
	{"name":"floras","keyword":"italian","description":"\n\t\n\t\t\n\t\tFLORAS\n\t\n\nFLORAS is a 50-language benchmark For LOng-form Recognition And Summarization of spoken language. \nThe goal of FLORAS is to create a more realistic benchmarking environment for speech recognition, translation, and summarization models. \nUnlike typical academic benchmarks like LibriSpeech and FLEURS that uses pre-segmented single-speaker read-speech, FLORAS tests the capabilities of models on raw long-form conversational audio, which can have one or many speakers.\nTo encourage‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/espnet/floras.","url":"https://huggingface.co/datasets/espnet/floras","creator_name":"ESPnet","creator_url":"https://huggingface.co/espnet","license_name":"Creative Commons Attribution 3.0","license_url":"https://scancode-licensedb.aboutcode.org/cc-by-3.0.html","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","translation","summarization","English","Spanish"],"keywords_longer_than_N":true},
	{"name":"ragtruth-it-translated","keyword":"italian","description":"The dataset is created from the RAGTruth dataset by translating it to Italian. We've used Gemma 3 27B for the translation.\nThe translation was done on a single A100 machine using VLLM as a server.\n","url":"https://huggingface.co/datasets/KRLabsOrg/ragtruth-it-translated","creator_name":"KR Labs","creator_url":"https://huggingface.co/KRLabsOrg","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["Italian","mit","10K - 100K","parquet","Text"],"keywords_longer_than_N":true},
	{"name":"truthfulqa_italian","keyword":"italian","description":"\n\t\n\t\t\n\t\tTruthfulQA - Italian (IT)\n\t\n\nThis dataset is an Italian translation of TruthfulQA. TruthfulQA is a dataset for fact-based question answering, which contains questions that require factual knowledge to answer correctly. These questions are designed so that some humans would answer them incorrectly because of common misconceptions.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\nThe dataset is a question answering dataset that contains questions that require factual knowledge to answer correctly and avoid‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/s-conia/truthfulqa_italian.","url":"https://huggingface.co/datasets/s-conia/truthfulqa_italian","creator_name":"Simone Conia","creator_url":"https://huggingface.co/s-conia","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","Italian","English","apache-2.0","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"Children-Stories-Collection-Italian","keyword":"italian","description":"\n\t\n\t\t\n\t\tDataset Card for Dataset Name\n\t\n\n\n\nItalian translation of https://huggingface.co/datasets/ajibawa-2023/Children-Stories-Collection\nNOTE: I have decided to mantain alive the repo to honor the Colab CPU and Google GPU that work for it, but this dataset is rubbish. All stories are about tech interests (e.g., \"Explain how to use PostSQL to kids, and how beatiful it is\") or political questions total irrilevant to any kids.\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Description‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/markod0925/Children-Stories-Collection-Italian.","url":"https://huggingface.co/datasets/markod0925/Children-Stories-Collection-Italian","creator_name":"markod","creator_url":"https://huggingface.co/markod0925","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","Italian","apache-2.0","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"apertus-pretrain-swiss","keyword":"italian","description":"\n\t\n\t\t\n\t\tSwiss Pretrain Data\n\t\n\nThis dataset provides a large collection of open-access and license-compliant Swiss data sources for language model training.\nThe dataset includes the following sources:\n\n\t\n\t\t\nName\nInternal ID\nTokens (B)\nDescription\n\n\n\t\t\nCuria Vista\ncuriavista\n0.5\nLegal and administrative documents from the Swiss database of parliamentary proceedings.\n\n\nenscheidsuche\nenscheidsuche_html\n4.5\nSwiss court decisions, sampled at 50% for balance.\n\n\nFineWeb-2‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/swiss-ai/apertus-pretrain-swiss.","url":"https://huggingface.co/datasets/swiss-ai/apertus-pretrain-swiss","creator_name":"Swiss AI Initiative","creator_url":"https://huggingface.co/swiss-ai","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["fill-mask","text-generation","French","English","German"],"keywords_longer_than_N":true},
	{"name":"bio-mqm-dataset","keyword":"italian","description":"This dataset is compiled from the official Amazon repository (all respective licensing applies).\nIt contains system translations, multiple references, and their quality evaluation on the MQM scale. It accompanies the ACL 2024 paper Fine-Tuned Machine Translation Metrics Struggle in Unseen Domains.\nWatch a brief 4 minutes-long video.\n\nAbstract: We introduce a new, extensive multidimensional quality metrics (MQM) annotated dataset covering 11 language pairs in the biomedical domain. We use this‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/zouharvi/bio-mqm-dataset.","url":"https://huggingface.co/datasets/zouharvi/bio-mqm-dataset","creator_name":"Vil√©m Zouhar","creator_url":"https://huggingface.co/zouharvi","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["translation","English","German","Spanish","Basque"],"keywords_longer_than_N":true},
	{"name":"sentiment-analysis-test","keyword":"italian","description":"\n\t\n\t\t\n\t\tProgetto scolastico per l'analisi dei sentimenti\n\t\n\nIl dataset √® stato creato con un questionario online in cui si chiedeva ad un pubblico di studenti, docenti, personale amministrativo, famiglie di rispondere ad alcune domande sul loro rapporto con la scuola.\nLe annotazioni sono state effettuate correlando le risposte testuali ad indicatori di gradimento.\nIl dataset √® stato realizzato all'interno di un corso pomeridiano scolastico dedicato all'intelligenza artificiale.\nGrazie a tutti‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Loacky/sentiment-analysis-test.","url":"https://huggingface.co/datasets/Loacky/sentiment-analysis-test","creator_name":"Lorenzo Adacher","creator_url":"https://huggingface.co/Loacky","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","sentiment-analysis","expert-generated","crowdsourced","crowdsourced"],"keywords_longer_than_N":true},
	{"name":"Multiloko_eval","keyword":"italian","description":"Deer-Lu/Multiloko_eval dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/Deer-Lu/Multiloko_eval","creator_name":"Lu Xu","creator_url":"https://huggingface.co/Deer-Lu","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["question-answering","Italian","English","mit","< 1K"],"keywords_longer_than_N":true},
	{"name":"parler_Google_TTS_Ita_v1_prompted","keyword":"italian","description":"udamaurizio/parler_Google_TTS_Ita_v1_prompted dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/udamaurizio/parler_Google_TTS_Ita_v1_prompted","creator_name":"UdAnet","creator_url":"https://huggingface.co/udamaurizio","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["Italian","apache-2.0","< 1K","parquet","Tabular"],"keywords_longer_than_N":true},
	{"name":"hellaswag_italian","keyword":"italian","description":"\n\t\n\t\t\n\t\tHellaSwag - Italian (IT)\n\t\n\nThis dataset is an Italian translation of HellaSwag. HellaSwag is a large-scale commonsense reasoning dataset, which requires reading comprehension and commonsense reasoning to predict the correct ending of a sentence.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\nThe dataset consists of instances containing a context and a multiple-choice question with four possible answers. The task is to predict the correct ending of the sentence. The dataset is split into a training set‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/sapienzanlp/hellaswag_italian.","url":"https://huggingface.co/datasets/sapienzanlp/hellaswag_italian","creator_name":"Sapienza NLP, Sapienza University of Rome","creator_url":"https://huggingface.co/sapienzanlp","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-generation","Italian","English","mit","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"MultiEup-v2","keyword":"italian","description":"\n\t\n\t\t\n\t\tMulti-EuP-v2\n\t\n\nThis dataset card documents Multi-EuP-v2, a multilingual corpus of European Parliament debate speeches enriched with Member of European Parliament (MEP) metadata and multilingual debate titles/IDs. It supports research on political text analysis, speaker-attribute prediction, stance/vote prediction, multilingual NLP, and retrieval.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nMulti-EuP-v2 aggregates 50,337 debate speeches (each a unique did) in 24‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/unimelb-nlp/MultiEup-v2.","url":"https://huggingface.co/datasets/unimelb-nlp/MultiEup-v2","creator_name":"The University of Melbourne","creator_url":"https://huggingface.co/unimelb-nlp","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","text-retrieval","text-generation","multilingual","Bulgarian"],"keywords_longer_than_N":true},
	{"name":"aya_redteaming-IT","keyword":"italian","description":"\n\t\n\t\t\n\t\tDataset Card for aya_it.jsonl\n\t\n\n\n\t\n\t\t\n\t\tDescrizione\n\t\n\nIl dataset aya_it.jsonl √® la versione tradotta in italiano del file aya_eng.jsonl proveniente dal repository CohereLabs/aya_redteaming.La traduzione √® stata effettuata automaticamente utilizzando il modello Helsinki-NLP/opus-mt-en-it.\nQuesto dataset contiene prompt e contenuti di red-teaming originariamente in inglese, resi disponibili in lingua italiana, per lo studio, l‚Äôanalisi e l‚Äôaddestramento di modelli multilingue su‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Mattimax/aya_redteaming-IT.","url":"https://huggingface.co/datasets/Mattimax/aya_redteaming-IT","creator_name":"M.INC.","creator_url":"https://huggingface.co/Mattimax","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":null,"first_N":5,"first_N_keywords":["text-generation","Italian","apache-2.0","1K<n<10K","arxiv:2406.18682"],"keywords_longer_than_N":true},
	{"name":"Wikipedia-it-Trame-di-Film","keyword":"italian","description":"Collection of plots of historical films and adventure films from Italian Wikipedia (April 2024)\nRaccolta di trame di film storici e film di avventura da Wikipedia italiana (Aprile 2024)\n","url":"https://huggingface.co/datasets/scribis/Wikipedia-it-Trame-di-Film","creator_name":"Fabio Martines","creator_url":"https://huggingface.co/scribis","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["Italian","apache-2.0","1K - 10K","csv","Text"],"keywords_longer_than_N":true},
	{"name":"TinyStories-Italian-Improved","keyword":"italian","description":"\n\t\n\t\t\n\t\tDataset Card for Dataset Name\n\t\n\n\n\nItalian translation of http://huggingface.co/datasets/roneneldan/TinyStories (partial).\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\n\n\nThe translation has been performed using Horizon/Alpha, Horizon/Beta (i.e., GTP-OSS-120B) and Qwen3 32B.\nThe dataset includes the original text, the translated text in Italian, a summary of each story in Italian, a supposed prompt that can be used to generate the story, lists of entities and actions in the‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/markod0925/TinyStories-Italian-Improved.","url":"https://huggingface.co/datasets/markod0925/TinyStories-Italian-Improved","creator_name":"markod","creator_url":"https://huggingface.co/markod0925","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["translation","text-generation","Italian","English","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"En-to-It-translations-alpaca","keyword":"italian","description":"igoranoni/En-to-It-translations-alpaca dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/igoranoni/En-to-It-translations-alpaca","creator_name":"R.A.M.SESSE","creator_url":"https://huggingface.co/igoranoni","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","English","Italian","cc-by-4.0","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"ItaCaseholdClassification","keyword":"italian","description":"\n  ItaCaseholdClassification\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nAn Italian Dataset consisting of 1101 pairs of judgments and their official holdings between the years 2019 and 2022 from the archives of Italian Administrative Justice categorized with 64 subjects.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask categoryt2c\n\n\nDomains\nLegal, Government, Written\n\n\nReference\nhttps://doi.org/10.1145/3594536.3595177\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/ItaCaseholdClassification.","url":"https://huggingface.co/datasets/mteb/ItaCaseholdClassification","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","expert-annotated","monolingual","Italian","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"MAPS","keyword":"italian","description":"\n\t\n\t\t\n\t\tDataset Card for Multilingual Benchmark for Global Agent Performance and Security\n\t\n\nThis is the first Multilingual Agentic AI Benchmark for evaluating agentic AI systems across different languages and diverse tasks. Benchmark enables systematic analysis of how agents perform under multilingual conditions. To balance performance and safety evaluation, our benchmark comprises 805 tasks: 405 from performance-oriented datasets (GAIA, SWE-bench, MATH) and 400 from the Agent Security‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Fujitsu-FRE/MAPS.","url":"https://huggingface.co/datasets/Fujitsu-FRE/MAPS","creator_name":"Fujitsu Research of Europe","creator_url":"https://huggingface.co/Fujitsu-FRE","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-generation","question-answering","Arabic","English","Japanese"],"keywords_longer_than_N":true},
	{"name":"genrescoh","keyword":"italian","description":"\n\t\n\t\t\n\t\tDataset Card for GenResCoh\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nGenResCoh is a collection of positive and negative responses focused on coherence. It is generated using GPT-3.5-Turbo and GPT-4, and contains over 130k responses in different languages (English, French, German, Italian, and Chinese), together with their corresponding explanations (in English).\nGenResCoh was used to train the ECoh family of models.\n\n\t\n\t\t\n\t\n\t\n\t\tLanguages\n\t\n\n\nEnglish\nGerman\nItalian\nFrench\nChinese (Simplified)‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Johndfm/genrescoh.","url":"https://huggingface.co/datasets/Johndfm/genrescoh","creator_name":"John Mendon√ßa","creator_url":"https://huggingface.co/Johndfm","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["English","German","Italian","Chinese","French"],"keywords_longer_than_N":true},
	{"name":"refusal-ita","keyword":"italian","description":"mii-llm/refusal-ita dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/mii-llm/refusal-ita","creator_name":"mii-llm","creator_url":"https://huggingface.co/mii-llm","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","Italian","apache-2.0","< 1K","parquet"],"keywords_longer_than_N":true},
	{"name":"HPLT2.0_cleaned","keyword":"italian","description":"This is a large-scale collection of web-crawled documents in 191 world languages, produced by the HPLT project. \nThe source of the data is mostly Internet Archive with some additions from Common Crawl.\nFor a detailed description of the dataset, please refer to https://hplt-project.org/datasets/v2.0\nThe Cleaned variant of HPLT Datasets v2.0\nThis is the cleaned variant of the HPLT Datasets v2.0 converted to the Parquet format semi-automatically when being uploaded here. \nThe original JSONL files‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/jobs-git/HPLT2.0_cleaned.","url":"https://huggingface.co/datasets/jobs-git/HPLT2.0_cleaned","creator_name":"James Guana","creator_url":"https://huggingface.co/jobs-git","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["fill-mask","text-generation","language-modeling","multilingual","Achinese"],"keywords_longer_than_N":true},
	{"name":"GlotCC-V1","keyword":"italian","description":"\n\t\n\t\t\n\t\tDataset Summary\n\t\n\n \n\nGlotCC-V1.0 is a document-level, general domain dataset derived from CommonCrawl, covering more than 1000 languages.It is built using the GlotLID language identification and Ungoliant pipeline from CommonCrawl.We release our pipeline as open-source at https://github.com/cisnlp/GlotCC.  \nList of Languages: See https://datasets-server.huggingface.co/splits?dataset=cis-lmu/GlotCC-V1 to get the list of splits available.\n\n\t\t\n\t\tUsage (Huggingface Hub -- Recommended)‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/cis-lmu/GlotCC-V1.","url":"https://huggingface.co/datasets/cis-lmu/GlotCC-V1","creator_name":"CIS, LMU Munich","creator_url":"https://huggingface.co/cis-lmu","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["multilingual","Abau","Amarasi","Abkhaz","Abkhazian"],"keywords_longer_than_N":true},
	{"name":"GlotCC-V1","keyword":"italian","description":"\n\t\n\t\t\n\t\tDataset Summary\n\t\n\n \n\nGlotCC-V1.0 is a document-level, general domain dataset derived from CommonCrawl, covering more than 1000 languages.It is built using the GlotLID language identification and Ungoliant pipeline from CommonCrawl.We release our pipeline as open-source at https://github.com/cisnlp/GlotCC.  \nList of Languages: See https://datasets-server.huggingface.co/splits?dataset=cis-lmu/GlotCC-V1 to get the list of splits available.\n\n\t\t\n\t\tUsage (Huggingface Hub -- Recommended)‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/cis-lmu/GlotCC-V1.","url":"https://huggingface.co/datasets/cis-lmu/GlotCC-V1","creator_name":"CIS, LMU Munich","creator_url":"https://huggingface.co/cis-lmu","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["multilingual","Abau","Amarasi","Abkhaz","Abkhazian"],"keywords_longer_than_N":true},
	{"name":"community-alignment","keyword":"italian","description":"Community Alignment\n\nCommunity Alignment is a large-scale open source, multilingual and multi-turn preference dataset to align LLMs with human preferences across cultures. It features prompt-level overlap in annotators, enabling social-choice-based and distributional approaches to LLM alignment, as well as natural language explanations for choices.\n\n[Large-scale] ~200,000 comparisons of LLM responses, collected from >3,000 unique annotators who provided feedback at an individual level.‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/anon-submission00/community-alignment.","url":"https://huggingface.co/datasets/anon-submission00/community-alignment","creator_name":"anonymous","creator_url":"https://huggingface.co/anon-submission00","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["Hindi","English","French","Portuguese","Italian"],"keywords_longer_than_N":true},
	{"name":"Syntactic-Semantic-Annotated-Italian-Corpus","keyword":"italian","description":"\n\t\n\t\t\n\t\tAnnotazione Sintattico-Funzionale e Disambiguazione della Lingua Italiana\n\t\n\nThis dataset was generated by fetching random first paragraphs from Italian Wikipedia (it.wikipedia.org)\nand then processing them using Gemini AI with the following goal:\n\nProcessing Goal: riduci la ambiguit√† aggiungi tag grammaticali (soggetto) (verbo) eccetera. e tag funzionali es. (indica dove √® nato il soggetto) (indica che il soggetto possiede l'oggetto) eccetera\nSource Language: Italian (from Wikipedia)‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Dddixyy/Syntactic-Semantic-Annotated-Italian-Corpus.","url":"https://huggingface.co/datasets/Dddixyy/Syntactic-Semantic-Annotated-Italian-Corpus","creator_name":"Davide Brunori","creator_url":"https://huggingface.co/Dddixyy","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-generation","gemini-ai","original:wikipedia:it","Italian","mit"],"keywords_longer_than_N":true},
	{"name":"gsm8k_italian","keyword":"italian","description":"\n\t\n\t\t\n\t\tGSM8K - Italian (IT)\n\t\n\nThis dataset is an Italian translation of GSM8K. GSM8K stands for Grade School Math 8K, a dataset for math word problems, which should be easy to solve for people with an elementary school education.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\nThe dataset consists of math word problems, where each problem is associated with a possible explanation of how to solve it. The task is to generate the answer to the math problem. The dataset is split into a training set and a test set.‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/sapienzanlp/gsm8k_italian.","url":"https://huggingface.co/datasets/sapienzanlp/gsm8k_italian","creator_name":"Sapienza NLP, Sapienza University of Rome","creator_url":"https://huggingface.co/sapienzanlp","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-generation","Italian","English","mit","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"fusion-synth-data-ufb","keyword":"italian","description":"\n\t\n\t\t\n\t\tOffline Synthetic Data (UFB) for: Making, not taking, the Best-of-N\n\t\n\n\n\t\n\t\t\n\t\tContent\n\t\n\nThis data contains completions for a 10,000 subset of the  UFB prompts (translated into 9 languages)  from 5 different teacher models and 2 aggregations:\nTeachers: We sample one completion from each of the following models at temperature T=0.3. For kimik2, qwen3, and deepseek-v3 we use TogetherAI, for gemma3-27b and command-a we use locally hosted images.\n\ngemma3-27b: GEMMA3-27B-IT\nkimik2:‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/CohereLabs/fusion-synth-data-ufb.","url":"https://huggingface.co/datasets/CohereLabs/fusion-synth-data-ufb","creator_name":"Cohere Labs","creator_url":"https://huggingface.co/CohereLabs","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-generation","English","French","German","Spanish"],"keywords_longer_than_N":true},
	{"name":"Lappland","keyword":"italian","description":"None1145/Lappland dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/None1145/Lappland","creator_name":"None","creator_url":"https://huggingface.co/None1145","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["audio-to-audio","text-to-speech","Chinese","Japanese","English"],"keywords_longer_than_N":true},
	{"name":"DATA-AI_Conversation_Ita_Formatted","keyword":"italian","description":"\n\t\n\t\t\n\t\tDescrizione\n\t\n\nDATA-AI_Conversation_ITA √® un dataset di conversazioni in italiano tra un utente umano e un modello AI. Ogni esempio contiene un prompt dell'utente e la relativa risposta generata dall'AI, strutturati come una lista di messaggi con i campi \"from\" e \"value\" per indicare il mittente e il contenuto del messaggio.\nIl dataset √® stato riformattato per avere una singola colonna \"conversation\", dove ogni riga rappresenta l'intera conversazione tra umano e AI. Questa struttura‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Mattimax/DATA-AI_Conversation_Ita_Formatted.","url":"https://huggingface.co/datasets/Mattimax/DATA-AI_Conversation_Ita_Formatted","creator_name":"M.INC.","creator_url":"https://huggingface.co/Mattimax","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","Italian","apache-2.0","10K - 100K","json"],"keywords_longer_than_N":true},
	{"name":"nanobeir-multilingual","keyword":"italian","description":"This multilingual collection is derived from the original English NanoBEIR datasets, which are smaller versions of BEIR datasets.\nThe compact size of these datasets makes them ideal for conducting quick and efficient evaluations during training.\nTo facilitate broader research in cross-lingual information retrieval, our dataset has been machine-translated from the original English\ninto eight additional languages: Arabic (ar), German (de), Spanish (es), French (fr), Italian (it), Norwegian (no)‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/lightonai/nanobeir-multilingual.","url":"https://huggingface.co/datasets/lightonai/nanobeir-multilingual","creator_name":"LightOn AI","creator_url":"https://huggingface.co/lightonai","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","French","Arabic","English","German"],"keywords_longer_than_N":true},
	{"name":"enciclopedia-QA","keyword":"italian","description":"mik3ml/enciclopedia-QA dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/mik3ml/enciclopedia-QA","creator_name":"Michele Angelo Marcucci","creator_url":"https://huggingface.co/mik3ml","license_name":"Creative Commons Attribution 3.0","license_url":"https://scancode-licensedb.aboutcode.org/cc-by-3.0.html","language":"en","first_N":5,"first_N_keywords":["question-answering","text-generation","Italian","cc-by-3.0","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"apertus-sft-mixture","keyword":"italian","description":"\n\t\n\t\t\n\t\tApertus Supervised Finetuning Data\n\t\n\nOur supervised finetuning data contains a carefully curated blend of instruction-following datasets, \ndeveloped through eight iterations of empirical evaluation. This final mixture comprises approximately \n3.8 million examples from diverse sources, balancing generalinstruction-following, mathematical reasoning, \ncode generation, and multilingual capabilities. \nMore details about data provenance, preparation, and statistics can be found in our tech‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/swiss-ai/apertus-sft-mixture.","url":"https://huggingface.co/datasets/swiss-ai/apertus-sft-mixture","creator_name":"Swiss AI Initiative","creator_url":"https://huggingface.co/swiss-ai","license_name":"Open Data Commons Attribution License v1.0","license_url":"https://scancode-licensedb.aboutcode.org/odc-by-1.0.html","language":"en","first_N":5,"first_N_keywords":["text-generation","English","French","German","Italian"],"keywords_longer_than_N":true},
	{"name":"Esselunga","keyword":"italian","description":"\n\t\n\t\t\n\t\tScraped Esselunga Dataset (Italian store):\n\t\n\n\nDataset preprocessed and cleaned\nDataset in Italian language\n\n\n\t\n\t\t\n\t\tDataset composition:\n\t\n\n\nImage files: Scraped images of products/items sold by the store. Image file name = Item name + Extra informations\nJson files: File containing the items with the full informations scraped available in a map based format {'image-url':value, 'item-field': value, ...}\n\n","url":"https://huggingface.co/datasets/Volzy/Esselunga","creator_name":"Tommaso Di Vito","creator_url":"https://huggingface.co/Volzy","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["Italian","apache-2.0","< 1K","imagefolder","Image"],"keywords_longer_than_N":true},
	{"name":"reasoning-multilingual-R1-Llama-70B-train","keyword":"italian","description":"\n\t\n\t\t\n\t\tlightblue/reasoning-multilingual-R1-Llama-70B-train\n\t\n\nThis is a multilingual reasoning dataset covering more than 30 languages.\nThis dataset was made by:\n\nSampling prompts from English datasets and translating them to various languages\nGenerating responses to these prompts 8 times using deepseek-ai/DeepSeek-R1-Distill-Llama-70B\nFiltering out <think> sections with incorrect language, non-fluent language, and incorrect answers\n\nThis dataset was then used to train a multilingual‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/lightblue/reasoning-multilingual-R1-Llama-70B-train.","url":"https://huggingface.co/datasets/lightblue/reasoning-multilingual-R1-Llama-70B-train","creator_name":"Lightblue KK.","creator_url":"https://huggingface.co/lightblue","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["Amharic","Arabic","Bengali","Chinese","Czech"],"keywords_longer_than_N":true},
	{"name":"quran","keyword":"italian","description":"\n\t\n\t\t\n\t\tDataset Card for the Quran\n\t\n\n\n\t\n\t\t\n\t\tSummary\n\t\n\nThe Quran with metadata, translations, and multiple Arabic text (can use specific types for embeddings, search, classification, and display). There are 126+ columns containing 43+ languages.\n\n\t\n\t\t\n\t\tTODO\n\t\n\n\n Add Tafsirs  \n Add topics/ontology\n\n\n\t\n\t\t\n\t\tUsage\n\t\n\nfrom datasets import load_dataset\n\nds = load_dataset(\"nazimali/quran\", split=\"train\")\nds\n\nOutput:\nDataset({\n    features: ['surah', 'ayah', 'surah-name', 'surah-total-ayas'‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/nazimali/quran.","url":"https://huggingface.co/datasets/nazimali/quran","creator_name":"Nazim Ali","creator_url":"https://huggingface.co/nazimali","license_name":"Creative Commons Attribution 3.0","license_url":"https://scancode-licensedb.aboutcode.org/cc-by-3.0.html","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","translation","feature-extraction","text-generation"],"keywords_longer_than_N":true},
	{"name":"wikipedia-2024-06-bge-m3","keyword":"italian","description":"\n\t\n\t\t\n\t\tWikipedia Embeddings with BGE-M3\n\t\n\nThis dataset contains embeddings from the\nJune 2024 Wikipedia dump\nfor the 11 most popular languages.\nThe embeddings are generated with the multilingual\nBGE-M3 model.\nThe dataset consists of Wikipedia articles split into paragraphs,\nand embedded with the aforementioned model.\nTo enhance search quality, the paragraphs are prefixed with their\nrespective article titles before embedding.\nAdditionally, paragraphs containing fewer than 100 characters‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Upstash/wikipedia-2024-06-bge-m3.","url":"https://huggingface.co/datasets/Upstash/wikipedia-2024-06-bge-m3","creator_name":"Upstash","creator_url":"https://huggingface.co/Upstash","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["English","German","Spanish","Persian","French"],"keywords_longer_than_N":true},
	{"name":"aya_dataset","keyword":"italian","description":"\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThe Aya Dataset is a multilingual instruction fine-tuning dataset curated by an open-science community via Aya Annotation Platform from Cohere Labs. The dataset contains a total of 204k human-annotated prompt-completion pairs along with the demographics data of the annotators.\nThis dataset can be used to train, finetune, and evaluate multilingual LLMs.\n\nCurated by: Contributors of Aya Open Science Intiative.\n\nLanguage(s): 65 languages (71 including dialects &‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/CohereLabs/aya_dataset.","url":"https://huggingface.co/datasets/CohereLabs/aya_dataset","creator_name":"Cohere Labs","creator_url":"https://huggingface.co/CohereLabs","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["other","crowdsourced","expert-generated","crowdsourced","expert-generated"],"keywords_longer_than_N":true},
	{"name":"fleurs_clean","keyword":"italian","description":"\n\t\n\t\t\n\t\n\t\n\t\tFLEURS\n\t\n\nFleurs is the speech version of the FLoRes machine translation benchmark. \nWe use 2009 n-way parallel sentences from the FLoRes dev and devtest publicly available sets, in 102 languages. \nTraining sets have around 10 hours of supervision. Speakers of the train sets are different than speakers from the dev/test sets. Multilingual fine-tuning is\nused and ‚Äùunit error rate‚Äù (characters, signs) of all languages is averaged. Languages and results are also grouped into seven‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Helloworld668/fleurs_clean.","url":"https://huggingface.co/datasets/Helloworld668/fleurs_clean","creator_name":"zhide Tang","creator_url":"https://huggingface.co/Helloworld668","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","expert-generated","crowdsourced","machine-generated","crowdsourced"],"keywords_longer_than_N":true},
	{"name":"Web-multilingual","keyword":"italian","description":"\n\t\n\t\t\n\t\tDataset Card for Dataset Name\n\t\n\nThis dataset contains 1,141 multilingual web pages.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\n Each page contains the visible text extracted from the page. Each page includes 2 or more languages, with 2 prominent languages. \n page.csv lists the 2 prominent for each page. The content of the page is found in the pages/ folder.\n The breakdown of languages is the following:\n   1705 en\n   1043 fr\n    336 zh\n     90 es\n     79 id\n     77 de\n     75 pt\n     40 it\n     34‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/MAximeSobrier/Web-multilingual.","url":"https://huggingface.co/datasets/MAximeSobrier/Web-multilingual","creator_name":"Maxime Sobrier","creator_url":"https://huggingface.co/MAximeSobrier","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","French","English","Chinese","Portuguese"],"keywords_longer_than_N":true},
	{"name":"multiblimp","keyword":"italian","description":"\n\t\n\t\t\n\t\tMultiBLiMP\n\t\n\nMultiBLiMP is a massively Multilingual Benchmark for Linguistic Minimal Pairs. The dataset is composed of synthetic pairs generated using Universal Dependencies and UniMorph.\nThe paper can be found here.\nWe split the data set by language: each language consists of a single .tsv file. The rows contain many attributes for a particular pair, most important are the sen and wrong_sen fields, which we use for evaluating the language models.\n\n\t\n\t\t\n\t\n\t\n\t\tUsing MultiBLiMP\n\t\n\nTo‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/jumelet/multiblimp.","url":"https://huggingface.co/datasets/jumelet/multiblimp","creator_name":"Jaap Jumelet","creator_url":"https://huggingface.co/jumelet","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["multilingual","Buriat","Spanish","Sanskrit","Romanian"],"keywords_longer_than_N":true},
	{"name":"MCIF","keyword":"italian","description":"\n\t\n\t\t\n\t\tDataset Description, Collection, and Source\n\t\n\nMCIF (Multimodal Crosslingual Instruction Following) is a multilingual human-annotated benchmark \nbased on scientific talks that is designed to evaluate instruction-following in crosslingual, \nmultimodal settings over both short- and long-form inputs. \nMCIF spans three core modalities -- speech, vision, and text -- and four diverse languages (English, German, Italian, and Chinese), \nenabling a comprehensive evaluation of MLLMs' abilities‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/danniliu/MCIF.","url":"https://huggingface.co/datasets/danniliu/MCIF","creator_name":"Danni Liu","creator_url":"https://huggingface.co/danniliu","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","question-answering","summarization","visual-question-answering","translation"],"keywords_longer_than_N":true},
	{"name":"Multi-EuP","keyword":"italian","description":"\n\t\n\t\t\n\t\tNOTES FOR DOWNLOAD!\n\t\n\n\nHighly recommend downloading it via the API:\n\ncurl -X GET \\\n     \"https://datasets-server.huggingface.co/first-rows?dataset=unimelb-nlp%2FMulti-EuP&config=default&split=full\"\n\n\nIf you are using the HuggingFace library, please follow these steps:\n\npip install datasets\n\nfrom datasets import load_dataset\n\ndataset = load_dataset(\"unimelb-nlp/Multi-EuP\", keep_default_na=False)\n\nNote: It's crucial to use keep_default_na=False because some datasets contain 'null'‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/unimelb-nlp/Multi-EuP.","url":"https://huggingface.co/datasets/unimelb-nlp/Multi-EuP","creator_name":"The University of Melbourne","creator_url":"https://huggingface.co/unimelb-nlp","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","English","German","French","Italian"],"keywords_longer_than_N":true},
	{"name":"oscar-mini","keyword":"italian","description":"The Open Super-large Crawled ALMAnaCH coRpus is a huge multilingual corpus obtained by language classification and filtering of the Common Crawl corpus using the goclassy architecture.\\","url":"https://huggingface.co/datasets/nthngdy/oscar-mini","creator_name":"Nathan Godey","creator_url":"https://huggingface.co/nthngdy","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":null,"first_N":5,"first_N_keywords":["text-generation","language-modeling","no-annotation","found","multilingual"],"keywords_longer_than_N":true},
	{"name":"JinaVDREuropeanaItScansRetrieval","keyword":"italian","description":"\n  JinaVDREuropeanaItScansRetrieval\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nRetrieve Italian historical articles based on LLM generated queries.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2i\n\n\nDomains\nNews\n\n\nReference\nhttps://huggingface.co/datasets/jinaai/europeana-it-scans_beir\n\n\n\t\n\nSource datasets:\n\njinaai/europeana-it-scans_beir\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask =‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/JinaVDREuropeanaItScansRetrieval.","url":"https://huggingface.co/datasets/mteb/JinaVDREuropeanaItScansRetrieval","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["visual-document-retrieval","image-to-text","text-to-image","LM-generated","monolingual"],"keywords_longer_than_N":true},
	{"name":"blbooks-parquet-embedded","keyword":"italian","description":"\n\t\n\t\t\n\t\tDataset Card for \"blbooks-parquet-embedded\"\n\t\n\nMore Information needed\n","url":"https://huggingface.co/datasets/davanstrien/blbooks-parquet-embedded","creator_name":"Daniel van Strien","creator_url":"https://huggingface.co/davanstrien","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","fill-mask","other","language-modeling","masked-language-modeling"],"keywords_longer_than_N":true},
	{"name":"ARK-Metadata-V2","keyword":"italian","description":"\n\t\n\t\t\n\t\tTitle\n\t\n\nMetadata of the \"Alter Realkatalog\" (ARK) of Berlin State Library (SBB) Version 2 ‚Äì August 2025\n\n\t\n\t\t\n\t\tDescription\n\t\n\nThis dataset was created with the intent to provide a single larger set of metadata from Berlin State Library for research purposes and the development of AI applications.\nThe dataset comprises descriptive metadata of 2.639.554 titles derived from the union catalogue K10plus, a database with about 200 million records from libraries across 11 German states.‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/SBB/ARK-Metadata-V2.","url":"https://huggingface.co/datasets/SBB/ARK-Metadata-V2","creator_name":"Staatsbibliothek zu Berlin - Preu√üischer Kulturbesitz","creator_url":"https://huggingface.co/SBB","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","feature-extraction","German","Latin","English"],"keywords_longer_than_N":true},
	{"name":"voxpopuli","keyword":"italian","description":"A large-scale multilingual speech corpus for representation learning, semi-supervised learning and interpretation.","url":"https://huggingface.co/datasets/facebook/voxpopuli","creator_name":"AI at Meta","creator_url":"https://huggingface.co/facebook","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":null,"first_N":5,"first_N_keywords":["automatic-speech-recognition","multilingual","English","German","French"],"keywords_longer_than_N":true},
	{"name":"para_crawl","keyword":"italian","description":"\n\t\n\t\t\n\t\tDataset Card for \"para_crawl\"\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nWeb-Scale Parallel Corpora for Official European Languages.\n\n\t\n\t\t\n\t\tSupported Tasks and Leaderboards\n\t\n\nMore Information Needed\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nMore Information Needed\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\n\t\n\t\t\n\t\tData Instances\n\t\n\n\n\t\n\t\t\n\t\tenbg\n\t\n\n\nSize of downloaded dataset files: 103.75 MB\nSize of the generated dataset: 356.54 MB\nTotal amount of disk used: 460.27 MB\n\nAn example of 'train' looks as follows.\nThis example was too‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ParaCrawl/para_crawl.","url":"https://huggingface.co/datasets/ParaCrawl/para_crawl","creator_name":"ParaCrawl","creator_url":"https://huggingface.co/ParaCrawl","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":null,"first_N":5,"first_N_keywords":["translation","no-annotation","found","translation","original"],"keywords_longer_than_N":true},
	{"name":"language_tags","keyword":"italian","description":"\n\t\n\t\t\n\t\tDescription\n\t\n\nDataset listing 27,328 languages and dialects (also includes macrolanguage names).For each language, either the ISO 639 code, the Glottolog code or both are provided.\n\n\t\n\t\t\n\t\tColumns\n\t\n\n\nEnglish_Name: Language name in English (e.g. \"French\").\nNative_Name: If value is not 0, corresponds to the name of the language by native speakers (e.g. \"Fran√ßais\") which may have been found in Wikipedia's nativename field.\nGlottocode: The language tag in the Glottolog convention (e.g.‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/lbourdois/language_tags.","url":"https://huggingface.co/datasets/lbourdois/language_tags","creator_name":"Lo√Øck BOURDOIS","creator_url":"https://huggingface.co/lbourdois","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["Afade","Par√° Ar√°ra","Afar","Aka-Bea","Abon"],"keywords_longer_than_N":true},
	{"name":"fleurs","keyword":"italian","description":"\n\t\n\t\t\n\t\tFLEURS\n\t\n\nFleurs is the speech version of the FLoRes machine translation benchmark. \nWe use 2009 n-way parallel sentences from the FLoRes dev and devtest publicly available sets, in 102 languages. \nTraining sets have around 10 hours of supervision. Speakers of the train sets are different than speakers from the dev/test sets. Multilingual fine-tuning is\nused and ‚Äùunit error rate‚Äù (characters, signs) of all languages is averaged. Languages and results are also grouped into seven‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/cahya/fleurs.","url":"https://huggingface.co/datasets/cahya/fleurs","creator_name":"Cahya Wirawan","creator_url":"https://huggingface.co/cahya","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":null,"first_N":5,"first_N_keywords":["automatic-speech-recognition","expert-generated","crowdsourced","machine-generated","crowdsourced"],"keywords_longer_than_N":true},
	{"name":"all-scam-spam","keyword":"italian","description":"This is a large corpus of 42,619 preprocessed text messages and emails sent by humans in 43 languages. is_spam=1 means spam and is_spam=0 means ham.\n1040 rows of balanced data, consisting of casual conversations and scam emails in ‚âà10 languages, were manually collected and annotated by me, with some help from ChatGPT.\n\n\n\n\t\n\t\t\n\t\tSome preprcoessing algorithms\n\t\n\n\nspam_assassin.js, followed by spam_assassin.py\nenron_spam.py\n\n\n\n\n\t\n\t\t\n\t\tData composition\n\t\n\n\n\n\n\n\t\n\t\t\n\t\tDescription\n\t\n\nTo make the text‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/FredZhang7/all-scam-spam.","url":"https://huggingface.co/datasets/FredZhang7/all-scam-spam","creator_name":"Fred Zhang","creator_url":"https://huggingface.co/FredZhang7","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","zero-shot-classification","Norwegian","Spanish","Somali"],"keywords_longer_than_N":true},
	{"name":"oasst2_top1_chat_format","keyword":"italian","description":"\n\t\n\t\t\n\t\tOpenAssistant TOP-1 Conversation Threads in huggingface chat format\n\t\n\nExport of oasst2 only top 1 threads in huggingface chat format\n\n\t\n\t\t\n\t\tScript\n\t\n\nThe convert script can be find here\n","url":"https://huggingface.co/datasets/blancsw/oasst2_top1_chat_format","creator_name":"Blanc Swan","creator_url":"https://huggingface.co/blancsw","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["English","Spanish","Russian","German","Polish"],"keywords_longer_than_N":true},
	{"name":"Syntetic_italian_Conversation","keyword":"italian","description":"MaxForce01/Syntetic_italian_Conversation dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/MaxForce01/Syntetic_italian_Conversation","creator_name":"Max","creator_url":"https://huggingface.co/MaxForce01","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["question-answering","text-generation","Italian","apache-2.0","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"MCIF","keyword":"italian","description":"\n\n\n\n\n\t\n\t\t\n\t\tDataset Description, Collection, and Source\n\t\n\nMCIF (Multimodal Crosslingual Instruction Following) is a multilingual human-annotated benchmark \nbased on scientific talks that is designed to evaluate instruction-following in crosslingual,\nmultimodal settings over both short- and long-form inputs. \nMCIF spans three core modalities -- speech, vision, and text -- and four diverse languages (English, German, Italian, and Chinese), \nenabling a comprehensive evaluation of MLLMs'‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/FBK-MT/MCIF.","url":"https://huggingface.co/datasets/FBK-MT/MCIF","creator_name":"FBK-MT","creator_url":"https://huggingface.co/FBK-MT","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","question-answering","summarization","visual-question-answering","translation"],"keywords_longer_than_N":true},
	{"name":"mittens","keyword":"italian","description":"\n\t\n\t\t\n\t\tMiTTenS: A Dataset for Evaluating Misgendering in Translation\n\t\n\nMisgendering is the act of referring to someone in a way that does not reflect their gender identity.  Translation systems, including foundation models capable of translation, can produce errors that result in misgendering harms. To measure the extent of such potential harms when translating into and out of English, we introduce a dataset, MiTTenS, covering 26 languages from a variety of language families and scripts‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/google/mittens.","url":"https://huggingface.co/datasets/google/mittens","creator_name":"Google","creator_url":"https://huggingface.co/google","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["translation","Arabic","Finnish","Oromo","Ganda"],"keywords_longer_than_N":true},
	{"name":"professor_heideltime_en","keyword":"italian","description":"\n\t\n\t\t\n\t\tProfessor HeidelTime\n\t\n\n\n\nProfessor HeidelTime is a project to create a multilingual corpus weakly labeled with HeidelTime, a temporal tagger.\n\n\t\n\t\t\n\t\n\t\n\t\tCorpus Details\n\t\n\nThe weak labeling was performed in six languages. Here are the specifics of the corpus for each language:\n\n\t\n\t\t\nDataset\nLanguage\nDocuments\nFrom\nTo\nTokens\nTimexs\n\n\n\t\t\nAll the News 2.0\nEN\n24,642\n2016-01-01\n2020-04-0218,755,616\n254,803\n\n\nItalian Crime News\nIT\n9,619\n2011-01-01\n2021-12-31\n3,296,898\n58,823\n\n\nGerman News‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/hugosousa/professor_heideltime_en.","url":"https://huggingface.co/datasets/hugosousa/professor_heideltime_en","creator_name":"Hugo Sousa","creator_url":"https://huggingface.co/hugosousa","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["token-classification","parsing","part-of-speech","named-entity-recognition","machine-generated"],"keywords_longer_than_N":true},
	{"name":"malicious-website-features-2.4M","keyword":"italian","description":"Important Notice:\n\nA subset of the URL dataset is from Kaggle, and the Kaggle datasets contained 10%-15% mislabelled data. See this dicussion I opened for some false positives. I have contacted Kaggle regarding their erroneous \"Usability\" score calculation for these unreliable datasets.\nThe feature extraction methods shown here are not robust at all in 2023, and there're even silly mistakes in 3 functions: not_indexed_by_google, domain_registration_length, and age_of_domain.\n\n\n\nThe features‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/FredZhang7/malicious-website-features-2.4M.","url":"https://huggingface.co/datasets/FredZhang7/malicious-website-features-2.4M","creator_name":"Fred Zhang","creator_url":"https://huggingface.co/FredZhang7","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","feature-extraction","tabular-classification","Norwegian","Afrikaans"],"keywords_longer_than_N":true},
	{"name":"tatoeba","keyword":"italian","description":"This is a collection of translated sentences from Tatoeba\n359 languages, 3,403 bitexts\ntotal number of files: 750\ntotal number of tokens: 65.54M\ntotal number of sentence fragments: 8.96M","url":"https://huggingface.co/datasets/Helsinki-NLP/tatoeba","creator_name":"Language Technology Research Group at the University of Helsinki","creator_url":"https://huggingface.co/Helsinki-NLP","license_name":"Creative Commons Attribution 2.0","license_url":"https://scancode-licensedb.aboutcode.org/cc-by-2.0.html","language":null,"first_N":5,"first_N_keywords":["translation","found","found","multilingual","original"],"keywords_longer_than_N":true},
	{"name":"MultiLegalPile_Wikipedia_Filtered","keyword":"italian","description":"A filtered version of the MultiLegalPile dataset, together with wikipedia articles.","url":"https://huggingface.co/datasets/joelniklaus/MultiLegalPile_Wikipedia_Filtered","creator_name":"Joel Niklaus","creator_url":"https://huggingface.co/joelniklaus","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["fill-mask","other","found","multilingual","original"],"keywords_longer_than_N":true},
	{"name":"xcsr","keyword":"italian","description":"\n\t\n\t\t\n\t\tDataset Card for X-CSR\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nTo evaluate multi-lingual language models (ML-LMs) for commonsense reasoning in a cross-lingual zero-shot transfer setting (X-CSR), i.e., training in English and test in other languages, we create two benchmark datasets, namely X-CSQA and X-CODAH. Specifically, we automatically translate the original CSQA and CODAH datasets, which only have English versions, to 15 other languages, forming development and test sets for studying X-CSR.‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/INK-USC/xcsr.","url":"https://huggingface.co/datasets/INK-USC/xcsr","creator_name":"INK Lab @ USC","creator_url":"https://huggingface.co/INK-USC","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["question-answering","multiple-choice-qa","crowdsourced","crowdsourced","machine-generated"],"keywords_longer_than_N":true},
	{"name":"ms_terms","keyword":"italian","description":"The Microsoft Terminology Collection can be used to develop localized versions of applications that integrate with Microsoft products.\nIt can also be used to integrate Microsoft terminology into other terminology collections or serve as a base IT glossary\nfor language development in the nearly 100 languages available. Terminology is provided in .tbx format, an industry standard for terminology exchange.","url":"https://huggingface.co/datasets/microsoft/ms_terms","creator_name":"Microsoft","creator_url":"https://huggingface.co/microsoft","license_name":"Microsoft Public License","license_url":"https://choosealicense.com/licenses/ms-pl/","language":null,"first_N":5,"first_N_keywords":["translation","expert-generated","expert-generated","multilingual","translation"],"keywords_longer_than_N":true},
	{"name":"ws-semantics-simnrel","keyword":"italian","description":"\n\t\n\t\t\n\t\tDataset Card for WS353-semantics-sim-and-rel with ~2K entries.\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nLicense: Apache-2.0. Contains CSV of a list of word1, word2, their connection score, type of connection and language.\n\n\n\t\n\t\t\n\t\tOriginal Datasets are available here:\n\t\n\n\nhttps://leviants.com/multilingual-simlex999-and-wordsim353/\n\n\n\n\t\n\t\t\n\t\tPaper of original Dataset:\n\t\n\n\nhttps://arxiv.org/pdf/1508.00106v5.pdf\n\n","url":"https://huggingface.co/datasets/0x22almostEvil/ws-semantics-simnrel","creator_name":"David Glushkov","creator_url":"https://huggingface.co/0x22almostEvil","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","English","Russian","German","Italian"],"keywords_longer_than_N":true},
	{"name":"MultiLegalPileWikipediaFiltered","keyword":"italian","description":"A filtered version of the MultiLegalPile dataset, together with wikipedia articles.","url":"https://huggingface.co/datasets/joelniklaus/MultiLegalPileWikipediaFiltered","creator_name":"Joel Niklaus","creator_url":"https://huggingface.co/joelniklaus","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["fill-mask","other","found","multilingual","original"],"keywords_longer_than_N":true},
	{"name":"common_voice_17_0","keyword":"italian","description":"\n\t\n\t\t\n\t\tDataset Card for Common Voice Corpus 17.0\n\t\n\n\n\nThis dataset is an unofficial version of the Mozilla Common Voice Corpus 17. It was downloaded and converted from the project's website https://commonvoice.mozilla.org/.\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nAbkhaz, Albanian, Amharic, Arabic, Armenian, Assamese, Asturian, Azerbaijani, Basaa, Bashkir, Basque, Belarusian, Bengali, Breton, Bulgarian, Cantonese, Catalan, Central Kurdish, Chinese (China), Chinese (Hong Kong), Chinese (Taiwan), Chuvash, Czech‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/fsicoli/common_voice_17_0.","url":"https://huggingface.co/datasets/fsicoli/common_voice_17_0","creator_name":"Fabio Sicoli","creator_url":"https://huggingface.co/fsicoli","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":null,"first_N":5,"first_N_keywords":["automatic-speech-recognition","Abkhaz","Afrikaans","Amharic","Arabic"],"keywords_longer_than_N":true},
	{"name":"tulu-3-sft-olmo-2-mixture","keyword":"italian","description":"Note that this collection is licensed under ODC-BY-1.0 license; different licenses apply to subsets of the data. Some portions of the dataset are non-commercial. We present the mixture as a research artifact.\nThe OLMo v2 SFT mixture was used to train the OLMo models.\nIt contains 939,344 samples from the following sets:\n\nCoCoNot (ODC-BY-1.0), 10,983 prompts (Brahman et al., 2024)\nFLAN v2 via ai2-adapt-dev/flan_v2_converted, 89,982 prompts (Longpre et al., 2023)\nNo Robots (CC-BY-NC-4.0), 9,500‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/allenai/tulu-3-sft-olmo-2-mixture.","url":"https://huggingface.co/datasets/allenai/tulu-3-sft-olmo-2-mixture","creator_name":"Ai2","creator_url":"https://huggingface.co/allenai","license_name":"Open Data Commons Attribution License v1.0","license_url":"https://scancode-licensedb.aboutcode.org/odc-by-1.0.html","language":"en","first_N":5,"first_N_keywords":["other","crowdsourced","expert-generated","machine-generated","multilingual"],"keywords_longer_than_N":true},
	{"name":"entity_cs","keyword":"italian","description":"\n\t\n\t\t\n\t\tDataset Card for EntityCS\n\t\n\n\nRepository: https://github.com/huawei-noah/noah-research/tree/master/NLP/EntityCS  \nPaper: https://aclanthology.org/2022.findings-emnlp.499.pdf  \nPoint of Contact: Fenia Christopoulou, Chenxi Whitehouse\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Description\n\t\n\nWe use the English Wikipedia and leverage entity information from Wikidata to construct an entity-based Code Switching corpus. \nTo achieve this, we make use of wikilinks in Wikipedia, i.e. links from one page to another.‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/huawei-noah/entity_cs.","url":"https://huggingface.co/datasets/huawei-noah/entity_cs","creator_name":"HUAWEI Noah's Ark Lab","creator_url":"https://huggingface.co/huawei-noah","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["Afrikaans","Amharic","Arabic","Assamese","Azerbaijani"],"keywords_longer_than_N":true},
	{"name":"wiki_lingua","keyword":"italian","description":"\n\t\n\t\t\n\t\tDataset Card for \"wiki_lingua\"\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nWe introduce WikiLingua, a large-scale, multilingual dataset for the evaluation of cross-lingual abstractive summarization systems. We extract article and summary pairs in 18 languages from WikiHow, a high quality, collaborative resource of how-to guides on a diverse set of topics written by human authors. We create gold-standard article-summary alignments across languages by aligning the images that are used to describe each‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/esdurmus/wiki_lingua.","url":"https://huggingface.co/datasets/esdurmus/wiki_lingua","creator_name":"Esin Durmus","creator_url":"https://huggingface.co/esdurmus","license_name":"Creative Commons Attribution 3.0","license_url":"https://scancode-licensedb.aboutcode.org/cc-by-3.0.html","language":"en","first_N":5,"first_N_keywords":["summarization","crowdsourced","crowdsourced","multilingual","original"],"keywords_longer_than_N":true},
	{"name":"common_language","keyword":"italian","description":"This dataset is composed of speech recordings from languages that were carefully selected from the CommonVoice database.\nThe total duration of audio recordings is 45.1 hours (i.e., 1 hour of material for each language).\nThe dataset has been extracted from CommonVoice to train language-id systems.","url":"https://huggingface.co/datasets/speechbrain/common_language","creator_name":"SpeechBrain","creator_url":"https://huggingface.co/speechbrain","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":null,"first_N":5,"first_N_keywords":["audio-classification","speaker-identification","crowdsourced","crowdsourced","multilingual"],"keywords_longer_than_N":true},
	{"name":"fanpage","keyword":"italian","description":"\n\t\n\t\t\n\t\tDataset Card for fanpage\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nFanpage dataset, containing news articles taken from Fanpage.\nThere are two features:\n\nsource: Input news article.\ntarget: Summary of the article.\n\n\n\t\n\t\t\n\t\tSupported Tasks and Leaderboards\n\t\n\n\nabstractive-summarization, summarization\n\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nThe text in the dataset is in Italian\n\n\t\n\t\t\n\t\tLicensing Information\n\t\n\n Fanpage text summarization dataset by Nicola Landro, Ignazio Gallo, Riccardo La Grassa, Edoardo Federici‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ARTeLab/fanpage.","url":"https://huggingface.co/datasets/ARTeLab/fanpage","creator_name":"Applied Recognition Technology Laboratory","creator_url":"https://huggingface.co/ARTeLab","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["summarization","monolingual","original","Italian","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"synth_emerg_ITA","keyword":"italian","description":"\n\t\n\t\t\n\t\tDataset Sintetico di Note Mediche di Emergenza Annotate\n\t\n\nQuesto dataset √® composto da frasi sintetiche generate tramite una pipeline basata su LLM (Large Language Model), progettata per simulare scenari di emergenza medica.Ogni frase rappresenta un breve resoconto di interventi o situazioni cliniche e contiene annotazioni di entit√† di interesse, come:\n\nMEDICO: nome del medico o operatore sanitario  \nVIA_RESIDENZA: indirizzo o localizzazione del paziente  \nSESSO: sesso del paziente‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/pacovalentino/synth_emerg_ITA.","url":"https://huggingface.co/datasets/pacovalentino/synth_emerg_ITA","creator_name":"Pasquale Valentino","creator_url":"https://huggingface.co/pacovalentino","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","Italian","apache-2.0","100K - 1M","json"],"keywords_longer_than_N":true},
	{"name":"minigpt4-13b-ggml","keyword":"italian","description":"These are quantized ggml binary files for minigpt4 13B model.\nThese files can be used in conjunction with vicuna v0 ggml models to get minigpt4 working.\nNot all implementations were tested. If there are any issues, use f16.\n","url":"https://huggingface.co/datasets/maknee/minigpt4-13b-ggml","creator_name":"maknee","creator_url":"https://huggingface.co/maknee","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":null,"first_N":5,"first_N_keywords":["English","Bulgarian","Catalan","Czech","Danish"],"keywords_longer_than_N":true},
	{"name":"openassistant-falcon","keyword":"italian","description":"\n\t\n\t\t\n\t\tChat Fine-tuning Dataset - OpenAssistant Falcon\n\t\n\nThis dataset allows for fine-tuning chat models using '\\Human:' AND '\\nAssistant:' to wrap user messages.\nIt still uses <|endoftext|> as EOS and BOS token, as per Falcon.\nSample \nPreparation:\n\nThe dataset is cloned from TimDettmers, which itself is a subset of the Open Assistant dataset, which you can find here. This subset of the data only contains the highest-rated paths in the conversation tree, with a total of 9,846 samples.\nThe‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Trelis/openassistant-falcon.","url":"https://huggingface.co/datasets/Trelis/openassistant-falcon","creator_name":"Trelis","creator_url":"https://huggingface.co/Trelis","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["English","Spanish","Russian","German","Polish"],"keywords_longer_than_N":true},
	{"name":"minds14-mirror","keyword":"italian","description":"MINDS-14 is training and evaluation resource for intent\ndetection task with spoken data. It covers 14\nintents extracted from a commercial system\nin the e-banking domain, associated with spoken examples in 14 diverse language varieties.","url":"https://huggingface.co/datasets/a6kme/minds14-mirror","creator_name":"Abhishek Kumar","creator_url":"https://huggingface.co/a6kme","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":null,"first_N":5,"first_N_keywords":["automatic-speech-recognition","keyword-spotting","expert-generated","crowdsourced","machine-generated"],"keywords_longer_than_N":true},
	{"name":"synthetic_pii_finance_multilingual","keyword":"italian","description":"\n  \n  Image generated by DALL-E. See prompt for more details\n\n\n\n\t\n\t\t\n\t\tüíº üìä Synthetic Financial Domain Documents with PII Labels\n\t\n\ngretelai/synthetic_pii_finance_multilingual is a dataset of full length synthetic financial documents containing Personally Identifiable Information (PII), generated using Gretel Navigator and released under Apache 2.0.\nThis dataset is designed to assist with the following use cases:\n\nüè∑Ô∏è Training NER (Named Entity Recognition) models to detect and label PII in‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/gretelai/synthetic_pii_finance_multilingual.","url":"https://huggingface.co/datasets/gretelai/synthetic_pii_finance_multilingual","creator_name":"Gretel.ai","creator_url":"https://huggingface.co/gretelai","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","fill-mask","token-classification","English","French"],"keywords_longer_than_N":true},
	{"name":"oasst1","keyword":"italian","description":"\n\t\n\t\t\n\t\tOpenAssistant Conversations Dataset (OASST1)\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nIn an effort to democratize research on large-scale alignment, we release OpenAssistant \nConversations (OASST1), a human-generated, human-annotated assistant-style conversation \ncorpus consisting of 161,443 messages in 35 different languages, annotated with 461,292 \nquality ratings, resulting in over 10,000 fully annotated conversation trees. The corpus \nis a product of a worldwide crowd-sourcing effort‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/OpenAssistant/oasst1.","url":"https://huggingface.co/datasets/OpenAssistant/oasst1","creator_name":"OpenAssistant","creator_url":"https://huggingface.co/OpenAssistant","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["English","Spanish","Russian","German","Polish"],"keywords_longer_than_N":true},
	{"name":"X-SVAMP_en_zh_ko_it_es","keyword":"italian","description":"\n\t\n\t\t\n\t\tX-SVAMP\n\t\n\nü§ó Paper | üìñ arXiv\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nX-SVAMP is an evaluation benchmark for multilingual large language models (LLMs), including questions and answers in 5 languages (English, Chinese, Korean, Italian and Spanish).\nIt is intended to evaluate the math reasoning abilities of LLMs. The dataset is translated by GPT-4-turbo from the original English-version SVAMP.\nIn our paper, we evaluate LLMs in a zero-shot generative setting: prompt the instruction-tuned LLM with‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/zhihz0535/X-SVAMP_en_zh_ko_it_es.","url":"https://huggingface.co/datasets/zhihz0535/X-SVAMP_en_zh_ko_it_es","creator_name":"Zhihan Zhang","creator_url":"https://huggingface.co/zhihz0535","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["question-answering","text-generation","English","Chinese","Italian"],"keywords_longer_than_N":true},
	{"name":"ACAData","keyword":"italian","description":"\n\t\n\t\t\n\t\tDataset Card for ACAData\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nACAData is a multilingual instruction tuning dataset containing parallel text paragraphs from the academic domain.\n\n\t\n\t\t\n\t\tSupported Tasks and Leaderboards\n\t\n\nThe dataset is meant to be used for fine-tuning and benchmarking general purpose LLM's on Machine Translation tasks.\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nThe dataset contains (mainly long) paragraph of scientific texts from the academic domain in many European language pairs.\nThe language‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/BSC-LT/ACAData.","url":"https://huggingface.co/datasets/BSC-LT/ACAData","creator_name":"Language Technologies Laboratory @ Barcelona Supercomputing Center","creator_url":"https://huggingface.co/BSC-LT","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["translation","Spanish","English","Catalan","Portuguese"],"keywords_longer_than_N":true},
	{"name":"FineWeb2-HQ","keyword":"italian","description":"\n\t\n\t\t\n\t\tFineWeb2-HQ\n\t\n\n\n\t\n\t\t\n\t\tDataset summary\n\t\n\nFineWeb2-HQ is a high-quality, model-filtered pretraining dataset derived as a subset of FineWeb2, spanning 20 languages. It enables around 6x faster pretraining compared to the base dataset. FineWeb2-HQ was created by selecting the top 10% quality documents of FineWeb2 in each language, based on scores assigned by a deep learning classifier trained to identify structured and knowledge-rich samples using XLM-RoBERTa embeddings.\n\n  \n\n\nValidation‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/epfml/FineWeb2-HQ.","url":"https://huggingface.co/datasets/epfml/FineWeb2-HQ","creator_name":"EPFL Machine Learning and Optimization Laboratory","creator_url":"https://huggingface.co/epfml","license_name":"Open Data Commons Attribution License v1.0","license_url":"https://scancode-licensedb.aboutcode.org/odc-by-1.0.html","language":"en","first_N":5,"first_N_keywords":["text-generation","Russian","Chinese","German","Japanese"],"keywords_longer_than_N":true},
	{"name":"FineWeb2-embedded","keyword":"italian","description":"\n\t\n\t\t\n\t\tFineWeb2-embedded\n\t\n\n\n\t\n\t\t\n\t\tDataset summary\n\t\n\nFineWeb2-embedded is an extension of the FineWeb2 dataset, annotated with document-level XLM-RoBERTa embeddings for 20 languages, making the dataset useful for a variety of tasks, including document clustering, filtering, and other multilingual research.\nSince XLM-RoBERTa has a sequence length limit of 512 tokens, each document's embeddings are obtained by mean-pooling 512 token chunks of the XLM-RoBERTa output. Therefore, longer texts‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/epfml/FineWeb2-embedded.","url":"https://huggingface.co/datasets/epfml/FineWeb2-embedded","creator_name":"EPFL Machine Learning and Optimization Laboratory","creator_url":"https://huggingface.co/epfml","license_name":"Open Data Commons Attribution License v1.0","license_url":"https://scancode-licensedb.aboutcode.org/odc-by-1.0.html","language":"en","first_N":5,"first_N_keywords":["text-generation","Russian","Chinese","German","Japanese"],"keywords_longer_than_N":true},
	{"name":"HPLT2.0_cleaned","keyword":"italian","description":"This is a large-scale collection of web-crawled documents in 191 world languages, produced by the HPLT project. \nThe source of the data is mostly Internet Archive with some additions from Common Crawl.\nFor a detailed description of the dataset, please refer to our website and our pre-print.\n\n\t\n\t\t\n\t\n\t\n\t\tThe Cleaned variant of HPLT Datasets v2.0\n\t\n\nThis is the cleaned variant of the HPLT Datasets v2.0 converted to the Parquet format semi-automatically when being uploaded here. \nThe original‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/HPLT/HPLT2.0_cleaned.","url":"https://huggingface.co/datasets/HPLT/HPLT2.0_cleaned","creator_name":"HPLT","creator_url":"https://huggingface.co/HPLT","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["fill-mask","text-generation","language-modeling","multilingual","Achinese"],"keywords_longer_than_N":true},
	{"name":"DATA-AI_Chat","keyword":"italian","description":"\n\t\n\t\t\n\t\tDATA-AI: Il Modello di IA di M.INC.\n\t\n\n\n\t\n\t\t\n\t\tüìå Introduzione\n\t\n\nDATA-AI √® un avanzato modello di intelligenza artificiale sviluppato da *M.INC., un'azienda italiana fondata da *Mattimax (M. Marzorati).Questo modello √® basato sull'architettura ELNS (Elaborazione del Linguaggio Naturale Semplice), un sistema innovativo progettato per rendere l'IA accessibile su quasi qualsiasi dispositivo, garantendo prestazioni ottimali anche su hardware limitato.  \nDATA-AI √® stato addestrato su un‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Mattimax/DATA-AI_Chat.","url":"https://huggingface.co/datasets/Mattimax/DATA-AI_Chat","creator_name":"M.INC.","creator_url":"https://huggingface.co/Mattimax","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["Italian","English","Spanish","Russian","German"],"keywords_longer_than_N":true},
	{"name":"EmoTalk-7","keyword":"italian","description":"\n\t\n\t\t\n\t\tEmoTalk-7\n\t\n\nEmoTalk-7 is a large-scale, multilingual, synthetic multimodal emotion recognition dataset generated using the Mistral API. It covers 7 major European languages and contains realistic social media scenarios with comprehensive emotion analysis, visual descriptions, and cultural context annotations.\n\n\t\n\t\t\n\t\tüìù Dataset Summary\n\t\n\nEmoTalk-7 contains 1400+ multimodal emotion records with high-quality annotations. It is designed to simulate authentic social media content across‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/NoeFlandre/EmoTalk-7.","url":"https://huggingface.co/datasets/NoeFlandre/EmoTalk-7","creator_name":"No√© Flandre","creator_url":"https://huggingface.co/NoeFlandre","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","English","French","Spanish","German"],"keywords_longer_than_N":true},
	{"name":"MultiLingualSentiment","keyword":"italian","description":"\n\t\n\t\t\n\t\tOverview\n\t\n\nMultilingualSentiment is a sentiment classification dataset that encompasses three sentiment labels: Positive, Neutral, Negative\nThe dataset spans multiple languages and covers a wide range of domains, making it ideal for multilingual sentiment analysis tasks.\n\n\t\n\t\t\n\t\tDataset Information\n\t\n\nThe dataset was meticulously collected and aggregated from various sources, including Hugging Face and Kaggle. These sources provide diverse languages and domains to ensure a‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/clapAI/MultiLingualSentiment.","url":"https://huggingface.co/datasets/clapAI/MultiLingualSentiment","creator_name":"clapAI","creator_url":"https://huggingface.co/clapAI","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","Arabic","German","English","Spanish"],"keywords_longer_than_N":true},
	{"name":"MintakaRetrieval","keyword":"italian","description":"\n  MintakaRetrieval\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nWe introduce Mintaka, a complex, natural, and multilingual dataset designed for experimenting with end-to-end question-answering models. Mintaka is composed of 20,000 question-answer pairs collected in English, annotated with Wikidata entities, and translated into Arabic, French, German, Hindi, Italian, Japanese, Portuguese, and Spanish for a total of 180,000 samples. Mintaka includes 8 types of complex questions‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/MintakaRetrieval.","url":"https://huggingface.co/datasets/mteb/MintakaRetrieval","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","multiple-choice-qa","derived","translated","jinaai/mintakaqa"],"keywords_longer_than_N":true},
	{"name":"evol-dpo-ita-reranked","keyword":"italian","description":"\n\t\n\t\t\n\t\tEvol DPO Ita Reranked\n\t\n\n\nA high-quality Italian preference dataset suitable for Direct Preference Optimization (DPO), ORPO, and other Preference Tuning algorithms.\n\n\t\n\t\t\n\t\n\t\n\t\tü•áü•à Reranking process\n\t\n\nThis work is based on efederici/evol-dpo-ita, a nice Italian preference dataset.\nThe original dataset includes prompts translated from the Evol-Instruct datasets, with responses generated using GPT-3.5-Turbo (rejected) and claude-3-opus-20240229 (chosen).\nChoosing the response from the‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/anakin87/evol-dpo-ita-reranked.","url":"https://huggingface.co/datasets/anakin87/evol-dpo-ita-reranked","creator_name":"Stefano Fiorucci","creator_url":"https://huggingface.co/anakin87","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","Italian","apache-2.0","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"reranker_continuous_filt_max7_train","keyword":"italian","description":"\n\t\n\t\t\n\t\tReranker training data\n\t\n\nThis data was generated using 4 steps:\n\nWe gathered queries and corresponding text data from 35 high quality datasets covering more than 95 languages.\nFor datasets which did not already have negative texts for queries, we mined hard negatives using the BAAI/bge-m3 embedding model.\nFor each query, we selected one positive and one negative text and used Qwen/Qwen2.5-32B-Instruct-GPTQ-Int4 to rate the relatedness of each query-text pair using a token \"1\", \"2\"‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/lightblue/reranker_continuous_filt_max7_train.","url":"https://huggingface.co/datasets/lightblue/reranker_continuous_filt_max7_train","creator_name":"Lightblue KK.","creator_url":"https://huggingface.co/lightblue","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["English","Chinese","Spanish","German","Arabic"],"keywords_longer_than_N":true},
	{"name":"qonto-open-qa","keyword":"italian","description":"ThomasCdnns/qonto-open-qa dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/ThomasCdnns/qonto-open-qa","creator_name":"Thomas Chardonnens","creator_url":"https://huggingface.co/ThomasCdnns","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["question-answering","English","French","Spanish","Italian"],"keywords_longer_than_N":true},
	{"name":"MAGBIG","keyword":"italian","description":"\n\t\n\t\t\n\t\tMAGBIG benchmark\n\t\n\nThis is the MAGBIG benchmark proposed in https://arxiv.org/abs/2401.16092\nThis benchmark is intended for multilingual text-to-image models. With MAGBIG, you can generate images for a diverse set of prompts across ten different languages. These images can be evaluated for differences across languages. MAGBIG is designed to uncover and assess biases across languages such as gender, race, age, etc. This way, we can measure whether bias exists in a language, but also‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/felfri/MAGBIG.","url":"https://huggingface.co/datasets/felfri/MAGBIG","creator_name":"Felix Friedrich","creator_url":"https://huggingface.co/felfri","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-to-image","English","German","Italian","French"],"keywords_longer_than_N":true},
	{"name":"eng_montok","keyword":"italian","description":"\n\t\n\t\t\n\t\tMonTok: A Suite of Monolingual Tokenizers\n\t\n\nThis is a set of monolingual tokenizers for 98 languages. For each language, there are Unigram, BPE, and SuperBPE tokenizers, ranging in vocabulary size from around 6k to over 200k.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\n","url":"https://huggingface.co/datasets/catherinearnett/eng_montok","creator_name":"Catherine Arnett","creator_url":"https://huggingface.co/catherinearnett","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["Afrikaans","Tosk Albanian","Amharic","Standard Arabic","Assamese"],"keywords_longer_than_N":true},
	{"name":"SOC-2508-MULTI","keyword":"italian","description":"\n\t\n\t\t\n\t\tDataset Card for Multilingual Synthetic Online Conversations\n\t\n\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset contains multilingual translations of the Synthetic Online Conversations (SOC-2508) dataset. Each conversation from the original dataset has been translated into French, Italian, German, Spanish, providing over 1,180 synthetically generated, multi-turn online conversations in multiple languages.\nThe translations were generated using google/gemma-3n-E4B-it with vLLM as the inference‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/marcodsn/SOC-2508-MULTI.","url":"https://huggingface.co/datasets/marcodsn/SOC-2508-MULTI","creator_name":"Marco De Santis","creator_url":"https://huggingface.co/marcodsn","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["English","French","Italian","German","Spanish"],"keywords_longer_than_N":true},
	{"name":"ipa-childes-split","keyword":"italian","description":"\n\t\n\t\t\n\t\tIPA-CHILDES split\n\t\n\nThis dataset is a postprocessed version of the IPA-CHILDES dataset. In particular,\nthe following changes have been implemented:\n\ncolumn processed_gloss dropped as it duplicates information of gloss up to punctuation\ncolumn gloss renamed as sentence, and column ipa_transcription renamed as ipa_g2p_plus (cf. G2P+)\ncolumn lang added to make IETF language tags accessible for training and inference; language tags normalized by the langcodes package\ncolumns ipa_espeak‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/fdemelo/ipa-childes-split.","url":"https://huggingface.co/datasets/fdemelo/ipa-childes-split","creator_name":"Fl√°vio Eler De Melo","creator_url":"https://huggingface.co/fdemelo","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["Catalan","Welsh","Danish","German","English"],"keywords_longer_than_N":true},
	{"name":"Italian.sentiment.analysis","keyword":"italian","description":"theoracle/Italian.sentiment.analysis dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/theoracle/Italian.sentiment.analysis","creator_name":"monti","creator_url":"https://huggingface.co/theoracle","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["apache-2.0","1K - 10K","csv","Text","Datasets"],"keywords_longer_than_N":true},
	{"name":"Reddit-MultiGEC","keyword":"italian","description":"\n\t\n\t\t\n\t\tReddit-MultiGEC Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nReddit-MultiGEC is a large multilingual corpus of posts scraped from Reddit, automatically corrected using the approach (TBU).\n\n\t\n\t\t\n\t\tStructure\n\t\n\n\nreddit_multi_gec.csv - main data.\nlanguage - language of text; \ntext - original text; \ncorrection - corrected text;\n\n\nreddit_uk_annotations.csv - contains human annotations for 1500 samples for the Ukrainian language.\ntext - original text; \ncorrection - corrected text;\nscore - annotator score;‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/lang-uk/Reddit-MultiGEC.","url":"https://huggingface.co/datasets/lang-uk/Reddit-MultiGEC","creator_name":"Lang UK","creator_url":"https://huggingface.co/lang-uk","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-generation","Ukrainian","English","German","Czech"],"keywords_longer_than_N":true},
	{"name":"multilingual-speech-commands-15lang-zip","keyword":"italian","description":"\n\t\n\t\t\n\t\tMultilingual Speech Commands Dataset (15 Languages, Augmented)\n\t\n\nThis dataset contains augmented speech command samples in 15 languages, derived from multiple public datasets. Only commands that overlap with the Google Speech Commands (GSC) vocabulary are included, making the dataset suitable for multilingual keyword spotting tasks aligned with GSC-style classification.\nAudio samples have been augmented using standard audio techniques to improve model robustness (e.g., time-shifting‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/artur-muratov/multilingual-speech-commands-15lang-zip.","url":"https://huggingface.co/datasets/artur-muratov/multilingual-speech-commands-15lang-zip","creator_name":"Artur Muratov","creator_url":"https://huggingface.co/artur-muratov","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["English","Russian","Kazakh","Tatar","Arabic"],"keywords_longer_than_N":true},
	{"name":"WikiEdits-MultiGEC","keyword":"italian","description":"\n\t\n\t\t\n\t\tWikiEdits-MultiGEC Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nWikiEdits-MultiGEC is a small dataset of human error corrections made by Wikipedia contributors for eleven languages.\nThese revisions were obtained using the official Wikipedia API, covering the six months from September 28, 2024, to May 15, 2025.\n\n\t\n\t\t\n\t\tStructure\n\t\n\n\nwikiedits_multi_gec.csv - main data.\nindex - index;\nlanguage - language of text; \ntext - original text; \ncorrection - corrected text;\n\n\nwikiedits_multi_gec_metadata.csv -‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/lang-uk/WikiEdits-MultiGEC.","url":"https://huggingface.co/datasets/lang-uk/WikiEdits-MultiGEC","creator_name":"Lang UK","creator_url":"https://huggingface.co/lang-uk","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-generation","Ukrainian","English","German","cz"],"keywords_longer_than_N":true},
	{"name":"Everything_Instruct_Multilingual","keyword":"italian","description":"\n\t\n\t\t\n\t\tEverything Instruct (Multilingual Edition)\n\t\n\nEverything you need... all in one place üíò\n\nEverything instruct (Multilingual Edition) is a massive alpaca instruct formatted dataset consisting of a wide variety of topics meant to bring LLM's to the next level in open source AI.\nNote: This dataset is fully uncensored (No model will refuse any request trained on this dataset unless otherwise aligned)\nNote2: This version of the dataset supports the following languages:\n\nEnglish\nRussian‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/rombodawg/Everything_Instruct_Multilingual.","url":"https://huggingface.co/datasets/rombodawg/Everything_Instruct_Multilingual","creator_name":"rombo dawg","creator_url":"https://huggingface.co/rombodawg","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["English","Russian","Chinese","Korean","Urdu"],"keywords_longer_than_N":true},
	{"name":"sentiment-analysis-test","keyword":"italian","description":"#Sentiment analysi School project\nthe dataset was created with an online questionnaire in which an audience of students, teachers, administrative staff, and families were asked to answer some questions about their relationship with school.\nthe annotations were made by correlating the textual responses to satisfaction indicators.\nthe dataset was created within an afternoon course dedicated to artificial intelligence.\nthanks to everyone for their collaboration‚ù§Ô∏è.\n","url":"https://huggingface.co/datasets/happycircus1/sentiment-analysis-test","creator_name":"tghrgg","creator_url":"https://huggingface.co/happycircus1","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","sentiment-analysis","expert-generated","crowdsourced","crowdsourced"],"keywords_longer_than_N":true},
	{"name":"multivsr","keyword":"italian","description":"\n\t\n\t\t\n\t\tDataset: MultiVSR\n\t\n\nWe introduce a large-scale multilingual lip-reading dataset: MultiVSR. The dataset comprises a total of 12,000 hours of video footage, covering English + 12 non-English languages. MultiVSR is a massive dataset with a huge diversity in terms of the speakers as well as languages, with approximately 1.6M video clips across 123K YouTube videos. Please check the website for samples.\n\n  \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDownload instructions\n\t\n\nPlease check the GitHub repo to download‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/sindhuhegde/multivsr.","url":"https://huggingface.co/datasets/sindhuhegde/multivsr","creator_name":"Sindhu Hegde","creator_url":"https://huggingface.co/sindhuhegde","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["English","French","German","Spanish","Italian"],"keywords_longer_than_N":true},
	{"name":"finepdfs-summaries","keyword":"italian","description":"\n\t\n\t\t\n\t\tfinepdfs-summaries\n\t\n\nSummaries generated with Qwen3-Next-80B-A3B-Instruct for documents from finepdfs.\nWork in progress, still generating more data.\nThe following table shows the data available for each language:\n\n\t\n\t\t\nLanguage\nSummaries\nTokens\nDisk size\n\n\n\t\t\nAll\n838,268,819\n247 B\n366 GB\n\n\ndeu_Latn\n363,671,069\n113 B\n149 GB\n\n\neng_Latn\n353,969,370\n89 B\n162 GB\nfra_Latn\n27,308,302\n10 B\n14 GB\n\n\nspa_Latn\n25,624,727\n9 B\n12 GB\n\n\nita_Latn\n17,587,618\n6 B\n8 GB\n\n\npor_Latn\n12,043,607\n4 B\n5 GB‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/MultiSynt/finepdfs-summaries.","url":"https://huggingface.co/datasets/MultiSynt/finepdfs-summaries","creator_name":"MultiSynt","creator_url":"https://huggingface.co/MultiSynt","license_name":"Open Data Commons Attribution License v1.0","license_url":"https://scancode-licensedb.aboutcode.org/odc-by-1.0.html","language":"en","first_N":5,"first_N_keywords":["text-generation","summarization","English","German","French"],"keywords_longer_than_N":true},
	{"name":"PleIAs-ToxicCommons","keyword":"italian","description":"\n\t\n\t\t\n\t\tPleIAs/ToxicCommons\n\t\n\nThis dataset is a refined version of the PleIAs/ToxicCommons collection, focusing on historical texts labeled for content that may be considered objectionable by modern standards (what the authors of the dataset deem \"toxic\"). \nThe cleaned dataset contains 1‚Äâ051‚Äâ027 rows, each representing a text sample with associated toxicity scores across five dimensions:\n\nRace and origin-based bias\nGender and sexuality-based bias\nReligious bias\nAbility bias\nViolence and abuse‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/agentlans/PleIAs-ToxicCommons.","url":"https://huggingface.co/datasets/agentlans/PleIAs-ToxicCommons","creator_name":"Alan Tseng","creator_url":"https://huggingface.co/agentlans","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","English","French","Spanish","German"],"keywords_longer_than_N":true},
	{"name":"Open-R1-Mulitlingual-SFT","keyword":"italian","description":"\n\t\n\t\t\n\t\tOpen-R1-Mulitlingual-SFT\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nOpen-R1-Mulitlingual-SFT is a curated dataset designed for multilingual supervised fine-tuning.\nThe source data comprises multiple datasets containing original prompts and responses, which were subsequently translated into 14 languages using GPT-4o.\n\n\t\n\t\t\n\t\tSources\n\t\n\nThe dataset is derived from:\n\nopen-thoughts/OpenThoughts-114kHugging Face: open-thoughts/OpenThoughts-114k\nbespokelabs/Bespoke-Stratos-17kHugging Face:‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/amphora/Open-R1-Mulitlingual-SFT.","url":"https://huggingface.co/datasets/amphora/Open-R1-Mulitlingual-SFT","creator_name":"GUIJIN SON","creator_url":"https://huggingface.co/amphora","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["Afrikaans","Arabic","Chinese","English","French"],"keywords_longer_than_N":true},
	{"name":"X-ALMA-Preference","keyword":"italian","description":"This is the translation preference dataset used by X-ALMA.\nsource: the source sentence.\nchosen: the preferred translation.\nreject: the dis-preferred translation.\ndirections: the translation direction.\n@misc{xu2024xalmaplugplay,\n      title={X-ALMA: Plug & Play Modules and Adaptive Rejection for Quality Translation at Scale}, \n      author={Haoran Xu and Kenton Murray and Philipp Koehn and Hieu Hoang and Akiko Eriguchi and Huda Khayrallah},\n      year={2024},\n      eprint={2410.03115}‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/haoranxu/X-ALMA-Preference.","url":"https://huggingface.co/datasets/haoranxu/X-ALMA-Preference","creator_name":"Haoran Xu","creator_url":"https://huggingface.co/haoranxu","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["English","Danish","Dutch","German","Icelandic"],"keywords_longer_than_N":true},
	{"name":"multilingual_translation_gpt4o_gen","keyword":"italian","description":"Youseff1987/multilingual_translation_gpt4o_gen dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/Youseff1987/multilingual_translation_gpt4o_gen","creator_name":"JOON HYOUNG JUN","creator_url":"https://huggingface.co/Youseff1987","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["translation","Korean","English","Chinese","Zulu"],"keywords_longer_than_N":true},
	{"name":"traduzione_italiano_greco-antico","keyword":"italian","description":"\n\t\n\t\t\n\t\tProcessed Italian Wikipedia Paragraphs: traduci in greco antico\n\t\n\nThis dataset was generated by fetching random first paragraphs from Italian Wikipedia (it.wikipedia.org)\nand then processing them using Gemini AI with the following goal:\n\nProcessing Goal: traduci in greco antico\nSource Language: Italian (from Wikipedia)\nNumber of Rows: 526\nModel Used: gemini-2.5-flash-preview-04-17\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Structure\n\t\n\n\ntext: The original first paragraph extracted from an Italian Wikipedia‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Dddixyy/traduzione_italiano_greco-antico.","url":"https://huggingface.co/datasets/Dddixyy/traduzione_italiano_greco-antico","creator_name":"Davide Brunori","creator_url":"https://huggingface.co/Dddixyy","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["gemini-ai","original:wikipedia:it","Italian","Greek","mit"],"keywords_longer_than_N":true},
	{"name":"EC-Guide","keyword":"italian","description":"\n\t\n\t\t\n\t\tThis repo is only used for dataset viewer. Please download from here.\n\t\n\n\n\t\n\t\t\n\t\tAmazon KDDCup 2024 Team ZJU-AI4H‚Äôs Solution and Dataset (Track 2 Top 2; Track 5 Top 5)\n\t\n\nThe Amazon KDD Cup‚Äô24 competition presents a unique challenge by focusing on the application of LLMs in E-commerce across multiple tasks. Our solution for addressing Tracks 2 and 5 involves a comprehensive pipeline encompassing dataset construction, instruction tuning, post-training quantization, and inference‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/AiMijie/EC-Guide.","url":"https://huggingface.co/datasets/AiMijie/EC-Guide","creator_name":"AiMijie","creator_url":"https://huggingface.co/AiMijie","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["question-answering","text-generation","translation","English","Chinese"],"keywords_longer_than_N":true},
	{"name":"CoT-XLang","keyword":"italian","description":"RU:CoT-XLang ‚Äî —ç—Ç–æ –º–Ω–æ–≥–æ—è–∑—ã—á–Ω—ã–π –¥–∞—Ç–∞—Å–µ—Ç, —Å–æ—Å—Ç–æ—è—â–∏–π –∏–∑ —Ç–µ–∫—Å—Ç–æ–≤—ã—Ö –ø—Ä–∏–º–µ—Ä–æ–≤ —Å –ø–æ—à–∞–≥–æ–≤—ã–º–∏ —Ä–∞—Å—Å—É–∂–¥–µ–Ω–∏—è–º–∏ (Chain-of-Thought, CoT) –Ω–∞ —Ä–∞–∑–ª–∏—á–Ω—ã—Ö —è–∑—ã–∫–∞—Ö, –≤–∫–ª—é—á–∞—è –∞–Ω–≥–ª–∏–π—Å–∫–∏–π, —Ä—É—Å—Å–∫–∏–π, —è–ø–æ–Ω—Å–∫–∏–π –∏ –¥—Ä—É–≥–∏–µ. –û–Ω –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –¥–ª—è –æ–±—É—á–µ–Ω–∏—è –∏ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è –º–æ–¥–µ–ª–µ–π –≤ –∑–∞–¥–∞—á–∞—Ö, —Ç—Ä–µ–±—É—é—â–∏—Ö –ø–æ—è—Å–Ω–µ–Ω–∏–π —Ä–µ—à–µ–Ω–∏–π —á–µ—Ä–µ–∑ –Ω–µ—Å–∫–æ–ª—å–∫–æ —à–∞–≥–æ–≤. –î–∞—Ç–∞—Å–µ—Ç –≤–∫–ª—é—á–∞–µ—Ç –æ–∫–æ–ª–æ 2,419,912 –ø—Ä–∏–º–µ—Ä–æ–≤, —á—Ç–æ –ø–æ–∑–≤–æ–ª—è–µ—Ç —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ –æ–±—É—á–∞—Ç—å –º–æ–¥–µ–ª–∏, —Å–ø–æ—Å–æ–±–Ω—ã–µ –≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å –ø–æ—à–∞–≥–æ–≤—ã–µ —Ä–∞—Å—Å—É–∂–¥–µ–Ω–∏—è.\n–†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è:–ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ –¥–∞—Ç–∞—Å–µ—Ç –¥–ª—è –æ–±—É—á–µ–Ω–∏—è –º–æ–¥–µ–ª–µ–π‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Egor-AI/CoT-XLang.","url":"https://huggingface.co/datasets/Egor-AI/CoT-XLang","creator_name":"Egor AI","creator_url":"https://huggingface.co/Egor-AI","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-generation","question-answering","Russian","English","Japanese"],"keywords_longer_than_N":true},
	{"name":"m-ArenaHard","keyword":"italian","description":"\n\t\n\t\t\n\t\tDataset Card for m-ArenaHard\n\t\n\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\nThe m-ArenaHard dataset is a multilingual LLM evaluation set. This dataset was created by translating the prompts from the originally English-only LMarena (formerly LMSYS) arena-hard-auto-v0.1 test dataset using Google Translate API v3 to 22 languages. The original English-only prompts were created by Li et al. (2024) and consist of 500 challenging user queries sourced from Chatbot Arena. The authors show that these can be used‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/CohereLabs/m-ArenaHard.","url":"https://huggingface.co/datasets/CohereLabs/m-ArenaHard","creator_name":"Cohere Labs","creator_url":"https://huggingface.co/CohereLabs","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["English","French","German","Spanish","Italian"],"keywords_longer_than_N":true},
	{"name":"code-switching-tokenizer-robustness","keyword":"italian","description":"\n\t\n\t\t\n\t\tCode-Switching Dataset for Tokenizer Robustness Analysis\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset is designed for tokenizer robustness testing in multilingual and code-switching contexts. It contains identical content expressed across 16 different language variants, including pure English and 15 English-X code-switching pairs, allowing researchers to isolate tokenization effects from semantic differences when evaluating language models.\n\n\t\n\t\t\n\t\tPurpose\n\t\n\n\nTokenizer Comparison:‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Malikeh1375/code-switching-tokenizer-robustness.","url":"https://huggingface.co/datasets/Malikeh1375/code-switching-tokenizer-robustness","creator_name":"Malikeh Ehghaghi","creator_url":"https://huggingface.co/Malikeh1375","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","text-classification","multilingual","English","Russian"],"keywords_longer_than_N":true},
	{"name":"JQL-LLM-Edu-Annotations","keyword":"italian","description":"\n\t\n\t\t\n\t\tüìö JQL Educational Quality Annotations from LLMs\n\t\n\nThis dataset provides 17,186,606 documents with high-quality LLM annotations for evaluating the educational value of web documents, and serves as a benchmark for training and evaluating multilingual LLM annotators as described in the JQL paper.\n\n\n\t\n\t\t\n\t\tüìù Dataset Summary\n\t\n\n  Multilingual document-level quality annotations scored on a 0‚Äì5 educational value scale by three state-of-the-art LLMs:\n  Gemma-3-27B-it, Mistral-3.1-24B-it‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/JQL-AI/JQL-LLM-Edu-Annotations.","url":"https://huggingface.co/datasets/JQL-AI/JQL-LLM-Edu-Annotations","creator_name":"JQL-AI","creator_url":"https://huggingface.co/JQL-AI","license_name":"Open Data Commons Attribution License v1.0","license_url":"https://scancode-licensedb.aboutcode.org/odc-by-1.0.html","language":"en","first_N":5,"first_N_keywords":["Bulgarian","Czech","Croatian","Macedonian","Polish"],"keywords_longer_than_N":true},
	{"name":"latino_italiano_traduzioni_DIRETTE","keyword":"italian","description":"Dddixyy/latino_italiano_traduzioni_DIRETTE dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/Dddixyy/latino_italiano_traduzioni_DIRETTE","creator_name":"Davide Brunori","creator_url":"https://huggingface.co/Dddixyy","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["translation","Latin","Italian","mit","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"latino_italiano_traduzioni_DIRETTE","keyword":"italian","description":"Dddixyy/latino_italiano_traduzioni_DIRETTE dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/Dddixyy/latino_italiano_traduzioni_DIRETTE","creator_name":"Davide Brunori","creator_url":"https://huggingface.co/Dddixyy","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["translation","Latin","Italian","mit","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"OGC_Renewable_Regulation","keyword":"italian","description":"\n\t\n\t\t\n\t\tOGC_Renewable_Regulation - Overview\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nOGC_Renewable_Regulation is a curated multimodal dataset focused on renewable energy technical documents, regulations, and legal frameworks. It combines text and image data extracted from real scientific and regulatory PDFs to support tasks such as RAG DSE, question answering, document search, and vision-language model training.\n\n\t\n\t\t\n\t\tDataset Creation\n\t\n\nThis dataset was created using our open-source tool‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/racineai/OGC_Renewable_Regulation.","url":"https://huggingface.co/datasets/racineai/OGC_Renewable_Regulation","creator_name":"racine.ai","creator_url":"https://huggingface.co/racineai","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["question-answering","visual-question-answering","text-retrieval","English","French"],"keywords_longer_than_N":true},
	{"name":"It-to-En-translations-alpaca","keyword":"italian","description":"igoranoni/It-to-En-translations-alpaca dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/igoranoni/It-to-En-translations-alpaca","creator_name":"R.A.M.SESSE","creator_url":"https://huggingface.co/igoranoni","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["translation","text-generation","Italian","English","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"mmmlu_lite","keyword":"italian","description":"\n\t\n\t\t\n\t\tMMMLU-Lite\n\t\n\n\n\t\n\t\t\n\t\tIntroduction\n\t\n\nA lite version of the MMMLU dataset, which is an community version of the MMMLU dataset by OpenCompass. Due to the large size of the original dataset (about 200k questions), we have created a lite version of the dataset to make it easier to use. We sample 25 examples from each language subject in the original dataset with fixed seed to ensure reproducibility, finally we have 19950 examples in the lite version of the dataset, which is about 10% of‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/opencompass/mmmlu_lite.","url":"https://huggingface.co/datasets/opencompass/mmmlu_lite","creator_name":"OpenCompass","creator_url":"https://huggingface.co/opencompass","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["question-answering","Arabic","Bengali","German","Spanish"],"keywords_longer_than_N":true},
	{"name":"ClimateChangeMeasures","keyword":"italian","description":"\n\t\n\t\t\n\t\tDataset Name\n\t\n\n\n\nClimate Change Multilingual Mini Dataset - ClimateChangeMeasures\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\n\n\nThis is a small parallel dataset consisting of texts related to climate change and environmental topics.\nEach entry is aligned in three languages: English, Spanish, and Italian.\n\n\t\n\t\t\n\t\tSource Data:\n\t\n\n\n\n\nRepository: Caf√© Babel was a multilingual weekly magazine focused on European current affairs, culture, and society.\nIt was known for publishing content in multiple‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Irisba/ClimateChangeMeasures.","url":"https://huggingface.co/datasets/Irisba/ClimateChangeMeasures","creator_name":"Iris Rodriguez","creator_url":"https://huggingface.co/Irisba","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["translation","English","Spanish","Italian","mit"],"keywords_longer_than_N":true},
	{"name":"CIVICS","keyword":"italian","description":"\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\tUses\n\t\n\nEvaluating a language model‚Äôs treatment of different ethical values, specifically for different civics topics relevant to sensitive groups. ‚ÄúTreatment‚Äù includes the likelihood a model gives to different value-laden statements and whether different implicit values in inputs lead to different generations by the model, in response to the provided prompts.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\nLanguage: One of ‚ÄúGerman‚Äù, ‚ÄúEnglish‚Äù, ‚ÄúFrench‚Äù, ‚ÄúItalian‚Äù, ‚ÄúTurkish‚Äù.‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/CIVICS-dataset/CIVICS.","url":"https://huggingface.co/datasets/CIVICS-dataset/CIVICS","creator_name":"CIVICS dataset organization","creator_url":"https://huggingface.co/CIVICS-dataset","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["English","Italian","German","Turkish","French"],"keywords_longer_than_N":true},
	{"name":"LivingNER","keyword":"italian","description":"\n\t\n\t\t\n\t\tLivingNER: Named entity recognition, normalization & classification of species, pathogens and food\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThe LivingNER Gold Standard corpus is a collection of 2000 clinical case reports covering a broad range of medical specialities, i.e. infectious diseases (including Covid-19 cases), cardiology, neurology, oncology, dentistry, pediatrics, endocrinology, primary care, allergology, radiology, psychiatry, ophthalmology, urology, internal medicine, emergency and‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Praise2112/LivingNER.","url":"https://huggingface.co/datasets/Praise2112/LivingNER","creator_name":"Praise","creator_url":"https://huggingface.co/Praise2112","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["token-classification","multilingual","English","French","Galolen"],"keywords_longer_than_N":true},
	{"name":"Samantha-NeonGenesis-Spicy-Reasoning-2.0","keyword":"italian","description":"\n\n\n\t\n\t\t\n\t\tSamantha 2.0\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nSamantha 2.0 is an evolved version of the Samantha 1.0 dataset, introducing new elements designed to enhance roleplay capabilities, particularly in the domains of spicy, nerd, and creepy interactions. This version integrates approximately 1900 additional examples containing NSFW content, expanding the dataset‚Äôs ability to handle a wider range of expressive and intimate conversations while maintaining emotional depth and reasoning capabilities.\nThe‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/WasamiKirua/Samantha-NeonGenesis-Spicy-Reasoning-2.0.","url":"https://huggingface.co/datasets/WasamiKirua/Samantha-NeonGenesis-Spicy-Reasoning-2.0","creator_name":"Wasami","creator_url":"https://huggingface.co/WasamiKirua","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","Italian","apache-2.0","10K - 100K","json"],"keywords_longer_than_N":true},
	{"name":"oasst-italian","keyword":"italian","description":"mik3ml/oasst-italian dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/mik3ml/oasst-italian","creator_name":"Michele Angelo Marcucci","creator_url":"https://huggingface.co/mik3ml","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["question-answering","Italian","apache-2.0","< 1K","json"],"keywords_longer_than_N":true},
	{"name":"aya_collection","keyword":"italian","description":"\nThis dataset is uploaded in two places: here and additionally here as 'Aya Collection Language Split.' These datasets are identical in content but differ in structure of upload. This dataset is structured by folders split according to dataset name. The version here instead divides the Aya collection into folders split by language. We recommend you use the language split version if you are only interested in downloading data for a single or smaller set of languages, and this version if you‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/CohereLabs/aya_collection.","url":"https://huggingface.co/datasets/CohereLabs/aya_collection","creator_name":"Cohere Labs","creator_url":"https://huggingface.co/CohereLabs","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","summarization","translation","Achinese","Afrikaans"],"keywords_longer_than_N":true},
	{"name":"Italian_Civil_Code","keyword":"italian","description":"\n\t\n\t\t\n\t\tAbstract\n\t\n\nThe Italian Civil Code, hereinafter referred to as ICC, is the legislation source containing norms that regulate private law in Italy and it consists of 2969 articles. This number actually corresponds to 3225 articles considering all variants and subsequent insertions, which are designated by using Latin-term suffixes (e.g., ‚Äúbis‚Äù, ‚Äúter‚Äù, ‚Äúquater‚Äù). Then, we obtain a total of 3039 if we remove the articles no longer in force (i.e., articles which are replaced by other‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/AndreaSimeri/Italian_Civil_Code.","url":"https://huggingface.co/datasets/AndreaSimeri/Italian_Civil_Code","creator_name":"Andrea Simeri","creator_url":"https://huggingface.co/AndreaSimeri","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","question-answering","Italian","apache-2.0","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"mHumanEval-Benchmark","keyword":"italian","description":"\n\n\n\t\n\t\t\n\t\tüî∑ Accepted in NAACL Proceedings (2025) üî∑\n\t\n\n\n\n\n\n  \n    \n      \n        \n          \n        \n      \n      \n        \n          \n        \n      \n      \n        \n          \n        \n      \n    \n  \n\n\n\n\n\n  \n\n\t\n\t\n\t\n\t\tmHumanEval\n\t\n\nThe mHumanEval benchmark is curated based on prompts from the original HumanEval üìö [Chen et al., 2021]. It includes a total of 33,456 prompts for Python, and 836,400 in total - significantly expanding from the original 164. \n\n\n\t\n\t\t\n\t\tQuick Start\n\t\n\n  Detailed‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/md-nishat-008/mHumanEval-Benchmark.","url":"https://huggingface.co/datasets/md-nishat-008/mHumanEval-Benchmark","creator_name":"Nishat Raihan","creator_url":"https://huggingface.co/md-nishat-008","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["Afar","Abkhaz","Avestan","Afrikaans","Akan"],"keywords_longer_than_N":true},
	{"name":"text-moderation-02-multilingual","keyword":"italian","description":"This dataset is based on Kaggle.It represents a version of @ifmain/text-moderation-410K that has been cleansed of semantically similar values and normalized to a 50/50 ratio of negative and neutral entries.\nThe dataset contains 1.5M entries (91K * 17 languages).  \nBefore use, augmentation is recommended! (e.g., character substitution to bypass moderation).\nFor augmentation, you can use @ifmain/StringAugmentor.  \nEnjoy using it!\n","url":"https://huggingface.co/datasets/ifmain/text-moderation-02-multilingual","creator_name":"Mike Afton","creator_url":"https://huggingface.co/ifmain","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["English","German","French","Spanish","Italian"],"keywords_longer_than_N":true},
	{"name":"Multilingual-Thinking","keyword":"italian","description":"\n\t\n\t\t\n\t\tDataset summary\n\t\n\nMultilingual-Thinking is a reasoning dataset where the chain-of-thought has been translated from English into one of 4 languages: Spanish, French, Italian, and German. The dataset was created by sampling 1k training samples from the SystemChat subset of SmolTalk2 and translating the reasoning traces with another language model. \nThis dataset was used in the OpenAI Cookbook to fine-tune the OpenAI gpt-oss models.\nYou can load the dataset using:\nfrom datasets import‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/HuggingFaceH4/Multilingual-Thinking.","url":"https://huggingface.co/datasets/HuggingFaceH4/Multilingual-Thinking","creator_name":"Hugging Face H4","creator_url":"https://huggingface.co/HuggingFaceH4","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","English","German","French","Spanish"],"keywords_longer_than_N":true},
	{"name":"global-festivals-translated","keyword":"italian","description":"azminetoushikwasi/global-festivals-translated dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/azminetoushikwasi/global-festivals-translated","creator_name":"Azmine Toushik Wasi","creator_url":"https://huggingface.co/azminetoushikwasi","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","English","French","Spanish","German"],"keywords_longer_than_N":true},
	{"name":"hellaswag_italian","keyword":"italian","description":"\n\t\n\t\t\n\t\tHellaSwag - Italian (IT)\n\t\n\nThis dataset is an Italian translation of HellaSwag. HellaSwag is a large-scale commonsense reasoning dataset, which requires reading comprehension and commonsense reasoning to predict the correct ending of a sentence.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\nThe dataset consists of instances containing a context and a multiple-choice question with four possible answers. The task is to predict the correct ending of the sentence. The dataset is split into a training set‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/s-conia/hellaswag_italian.","url":"https://huggingface.co/datasets/s-conia/hellaswag_italian","creator_name":"Simone Conia","creator_url":"https://huggingface.co/s-conia","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-generation","Italian","English","mit","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"biblenlp-corpus-mmteb","keyword":"italian","description":"This dataset pre-computes all English-centric directions from bible-nlp/biblenlp-corpus, and as a result loading is significantly faster.\nLoading example:\n>>> from datasets import load_dataset\n>>> dataset = load_dataset(\"davidstap/biblenlp-corpus-mmteb\", \"eng-arb\", trust_remote_code=True)\n>>> dataset\nDatasetDict({\n    train: Dataset({\n        features: ['eng', 'arb'],\n        num_rows: 28723\n    })\n    validation: Dataset({\n        features: ['eng', 'arb'],\n        num_rows: 1578\n    })‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/davidstap/biblenlp-corpus-mmteb.","url":"https://huggingface.co/datasets/davidstap/biblenlp-corpus-mmteb","creator_name":"David Stap","creator_url":"https://huggingface.co/davidstap","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["no-annotation","expert-generated","translation","multilingual","Arifama-Miniafia"],"keywords_longer_than_N":true},
	{"name":"biblenlp-corpus-mmteb","keyword":"italian","description":"This dataset pre-computes all English-centric directions from bible-nlp/biblenlp-corpus, and as a result loading is significantly faster.\nLoading example:\n>>> from datasets import load_dataset\n>>> dataset = load_dataset(\"davidstap/biblenlp-corpus-mmteb\", \"eng-arb\", trust_remote_code=True)\n>>> dataset\nDatasetDict({\n    train: Dataset({\n        features: ['eng', 'arb'],\n        num_rows: 28723\n    })\n    validation: Dataset({\n        features: ['eng', 'arb'],\n        num_rows: 1578\n    })‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/davidstap/biblenlp-corpus-mmteb.","url":"https://huggingface.co/datasets/davidstap/biblenlp-corpus-mmteb","creator_name":"David Stap","creator_url":"https://huggingface.co/davidstap","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["no-annotation","expert-generated","translation","multilingual","Arifama-Miniafia"],"keywords_longer_than_N":true},
	{"name":"s-ItaIst","keyword":"italian","description":"\n\t\n\t\t\n\t\tCorpus s-ItaIst\n\t\n\nThe corpus containing 8 texts selected from ItaIst corpus and manually simplified by human experts.\n\n\t\n\t\t\n\t\tAcknowledgements\n\t\n\nThis contribution is a result of the research conducted within the framework of the PRIN 2020 (Progetti di Rilevante Interesse Nazionale) \"VerbACxSS: on analytic verbs, complexity, synthetic verbs, and simplification. For accessibility\" (Prot. 2020BJKB9M), funded by the Italian Ministero dell'Universit√† e della Ricerca.\n\n\t\n\t\t\n\t\tHow to cite‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/VerbACxSS/s-ItaIst.","url":"https://huggingface.co/datasets/VerbACxSS/s-ItaIst","creator_name":"VerbACxSS","creator_url":"https://huggingface.co/VerbACxSS","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-generation","Italian","mit","< 1K","csv"],"keywords_longer_than_N":true},
	{"name":"toxi-text-3M","keyword":"italian","description":"This is a large multilingual toxicity dataset with 3M rows of text data from 55 natural languages, all of which are written/sent by humans, not machine translation models.\nThe preprocessed training data alone consists of 2,880,667 rows of comments, tweets, and messages. Among these rows, 416,529 are classified as toxic, while the remaining 2,463,773 are considered neutral. Below is a table to illustrate the data composition:\n\n\t\n\t\t\n\nToxic\nNeutral\nTotal\n\n\n\t\t\nmultilingual-train-deduplicated.csv‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/FredZhang7/toxi-text-3M.","url":"https://huggingface.co/datasets/FredZhang7/toxi-text-3M","creator_name":"Fred Zhang","creator_url":"https://huggingface.co/FredZhang7","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","zero-shot-classification","Arabic","Spanish","Panjabi"],"keywords_longer_than_N":true},
	{"name":"NOVA-63","keyword":"italian","description":"\n\t\n\t\n\t\n\t\tWe released this dataset under the MIT License. This means that anyone is free to use, copy, modify, distribute, and reuse our data, provided that the original copyright notice and license information are retained.\nThis work is jointly completed by PKU & Alibaba Group. The dataset is currently under review. Please be patient. We also hope this dataset can help more partners/colleagues in the community.\nTo ensure the validity and fairness of the benchmark evaluation, we explicitly‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/zjy1298/NOVA-63.","url":"https://huggingface.co/datasets/zjy1298/NOVA-63","creator_name":"Zhang","creator_url":"https://huggingface.co/zjy1298","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":null,"first_N":5,"first_N_keywords":["Arabic","Chinese","English","French","Spanish"],"keywords_longer_than_N":true},
	{"name":"mc-translation","keyword":"italian","description":"This dataset contains professional human translations from OpenAI's MMMLU dataset, repurposed to train translation models that can help translate future evaluation datasets.\n\n\t\n\t\t\n\t\tWhy This Dataset?\n\t\n\nTranslation of evaluation benchmarks is a critical but challenging task. While automated translations may introduce errors or biases, professional human translations are expensive and time-consuming. This dataset leverages existing professional translations (MMMLU) to train specialized‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/efederici/mc-translation.","url":"https://huggingface.co/datasets/efederici/mc-translation","creator_name":"Edoardo Federici","creator_url":"https://huggingface.co/efederici","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["translation","English","Swahili","Spanish","German"],"keywords_longer_than_N":true},
	{"name":"muri-it","keyword":"italian","description":"\n\t\n\t\t\n\t\tMURI-IT: Multilingual Instruction Tuning Dataset for 200 Languages via Multilingual Reverse Instructions\n\t\n\nMURI-IT is a large-scale multilingual instruction tuning dataset containing 2.2 million instruction-output pairs across 200 languages. It is designed to address the challenges of instruction tuning in low-resource languages with Multilingual Reverse Instructions (MURI), which ensures that the output is human-written, high-quality, and authentic to the cultural and linguistic‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/akoksal/muri-it.","url":"https://huggingface.co/datasets/akoksal/muri-it","creator_name":"Abdullatif Koksal","creator_url":"https://huggingface.co/akoksal","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text2text-generation","text-generation","question-answering","summarization","Achinese"],"keywords_longer_than_N":true},
	{"name":"cml-tts-filtered-annotated","keyword":"italian","description":"\n\t\n\t\t\n\t\tDataset Card for Filtred and annotated CML TTS\n\t\n\nThis dataset is an annotated and filtred version of a CML-TTS [1]. \nCML-TTS [1] CML-TTS is a recursive acronym for CML-Multi-Lingual-TTS, a Text-to-Speech (TTS) dataset developed at the Center of Excellence in Artificial Intelligence (CEIA) of the Federal University of Goias (UFG). CML-TTS is a dataset comprising audiobooks sourced from the public domain books of Project Gutenberg, read by volunteers from the LibriVox project. The‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/PHBJT/cml-tts-filtered-annotated.","url":"https://huggingface.co/datasets/PHBJT/cml-tts-filtered-annotated","creator_name":"Paul Henri Biojout","creator_url":"https://huggingface.co/PHBJT","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-to-speech","French","German","Italian","Spanish"],"keywords_longer_than_N":true},
	{"name":"PolyGuardMix","keyword":"italian","description":"\n\t\n\t\t\n\t\tPolyGuard: A Multilingual Safety Moderation Tool for 17 Languages\n\t\n\nAbstract: Truly multilingual safety moderation efforts for Large Language Models (LLMs) have been hindered by a narrow focus on a small set of languages (e.g., English, Chinese) as well as a limited scope of safety definition, resulting in significant gaps in moderation capabilities. To bridge these gaps, we release PolyGuard, a new state-of-the-art multilingual safety model for safeguarding LLM generations, and the‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ToxicityPrompts/PolyGuardMix.","url":"https://huggingface.co/datasets/ToxicityPrompts/PolyGuardMix","creator_name":"ToxicityPrompts","creator_url":"https://huggingface.co/ToxicityPrompts","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["Arabic","Chinese","Czech","Dutch","English"],"keywords_longer_than_N":true},
	{"name":"BK-Training-Dataset","keyword":"italian","description":"\n\t\n\t\t\n\t\tTitle\n\t\n\n\"Basisklassifikation\" (BK) Training Dataset for Automatic Subject Indexing: Titles and Subjects from the K10plus Library Catalogue\n\n\t\n\t\t\n\t\tDescription\n\t\n\nThis is a training dataset for automatic subject indexing containing more than 6 million titles and their corresponding subjects (classes) from the \"Basisklassifikation\" (BK). Initially introduced in the 1980s, today the Basisklassifikation constitutes the most widely used classification system for subject indexing within the‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/SBB/BK-Training-Dataset.","url":"https://huggingface.co/datasets/SBB/BK-Training-Dataset","creator_name":"Staatsbibliothek zu Berlin - Preu√üischer Kulturbesitz","creator_url":"https://huggingface.co/SBB","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","German","English","French","Italian"],"keywords_longer_than_N":true},
	{"name":"rag-data","keyword":"italian","description":"\n\t\n\t\t\n\t\tThe following dataset is constantly improving, any suggestion/help is welcome.\n\t\n\n Retrieval-Augmented Generation (RAG) Dataset\nRetrieval-Augmented Generation (RAG) data is an Italian translated sub-dataset of Neural-bridge/rag-dataset-12000 designed for RAG-optimized models, craft by Seacom Srl, and released under Apache license 2.0.\n\n\t\n\t\t\n\t\n\t\n\t\tLanguages\n\t\n\nThe text in the dataset is in Italian.\n\n\t\n\t\t\n\t\n\t\n\t\tData Instances\n\t\n\nA typical data point comprises a context, a question about‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/SeacomSrl/rag-data.","url":"https://huggingface.co/datasets/SeacomSrl/rag-data","creator_name":"SEACOM | Il tuo partner per l'Open Source | Societ√† benefit","creator_url":"https://huggingface.co/SeacomSrl","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["question-answering","Italian","apache-2.0","1K - 10K","csv"],"keywords_longer_than_N":true},
	{"name":"comment-translation-01","keyword":"italian","description":"This dataset is based on Kaggle.  \nThis dataset includes translations of 69,000 Reddit comments into 17 languages (English to 16 languages):\nBelarusian, Czech, German,\nEnglish, Spanish, Finnish,\nFrench, Italian, Japanese,\nKazakh, Korean, Latvian,\nPolish, Russian, Swedish,\nUkrainian, and Chinese.\nIt contains 50% regular comments and 50% highly negative ones.\nEnjoy using it!\n","url":"https://huggingface.co/datasets/ifmain/comment-translation-01","creator_name":"Mike Afton","creator_url":"https://huggingface.co/ifmain","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["English","German","French","Spanish","Italian"],"keywords_longer_than_N":true},
	{"name":"FineNews-unfiltered","keyword":"italian","description":"\n\t\n\t\t\n\t\tFineNews\n\t\n\nWIP. Like FineWeb, but built from Common Crawl News instead of main web.\nFor languages not listed as a split, check the data/ directory.\nFor now, it contains the 2024-05 (May),-04 (April),-03 (March) dumps.\nThis is the unfiltered version, with only URL filtering applied.\n\n\t\n\t\t\n\t\tSome initial stats\n\t\n\nTotal number of documents: 35M\n\n\t\n\t\t\nDump\nNumber of docs\nDisk size (compressed)\n\n\n\t\t\nCC-NEWS-2024-05\n11_715_084\n11G\n\n\nCC-NEWS-2024-04\n11_546_298\n11G\n\n\nCC-NEWS-2024-03‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/maxidl/FineNews-unfiltered.","url":"https://huggingface.co/datasets/maxidl/FineNews-unfiltered","creator_name":"Max Idahl","creator_url":"https://huggingface.co/maxidl","license_name":"Open Data Commons Attribution License v1.0","license_url":"https://scancode-licensedb.aboutcode.org/odc-by-1.0.html","language":"en","first_N":5,"first_N_keywords":["text-generation","English","German","French","Polish"],"keywords_longer_than_N":true},
	{"name":"OGC_Quantum","keyword":"italian","description":"\n\t\n\t\t\n\t\tOGC_Quantum ‚Äì Overview\n\t\n\nOGC_Quantum is a curated multimodal dataset focused on quantum technical documents. It combines text and image data extracted from real scientific PDFs to support tasks such as RAG DSE, question answering, document search, and vision-language model training.\n\n\n\t\n\t\t\n\t\tDataset Composition\n\t\n\nThis dataset was created using our open-source tool OGC_pdf-to-parquet.Quantum-related PDFs were collected from public online sources. Each document was processed‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/racineai/OGC_Quantum.","url":"https://huggingface.co/datasets/racineai/OGC_Quantum","creator_name":"racine.ai","creator_url":"https://huggingface.co/racineai","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["visual-document-retrieval","text-retrieval","English","French","Italian"],"keywords_longer_than_N":true},
	{"name":"ParaNames","keyword":"italian","description":"\n\t\n\t\t\n\t\n\t\n\t\tDataset Card for Dataset Name\n\t\n\n\n\nThis dataset card aims to be a base template for new datasets. It has been generated using this raw template.\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Description\n\t\n\n\n\n\n\n\nCurated by: [More Information Needed]\nFunded by [optional]: [More Information Needed]\nShared by [optional]: [More Information Needed]\nLanguage(s) (NLP): [More Information Needed]\nLicense: [More Information Needed]\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Sources [optional]‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/bltlab/ParaNames.","url":"https://huggingface.co/datasets/bltlab/ParaNames","creator_name":"Broadening Linguistic Technologies Lab (BLT Lab)","creator_url":"https://huggingface.co/bltlab","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["token-classification","Nias","Kotava","Banjar","Angika"],"keywords_longer_than_N":true},
	{"name":"Multi-Ita-Datasets","keyword":"italian","description":"\n\t\n\t\t\n\t\tMulti-Ita-Datasets\n\t\n\nMulti-Ita-Datasets √® una fusione di tre dataset italiani ad alto valore istruttivo, progettati per addestrare e valutare modelli linguistici instruction-tuned in lingua italiana.\n\n\t\n\t\t\n\t\tüì¶ Dataset originali\n\t\n\nQuesta raccolta unisce i seguenti dataset open source:\n\nanakin87/fine-instructions-ita-70k\nefederici/capybara-claude-15k-ita\ncosimoiaia/Loquace-102k\n\n\n\t\n\t\t\n\t\n\t\n\t\tüéØ Obiettivo\n\t\n\nFornire un dataset unificato, curato e diversificato per addestrare modelli‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Mattimax/Multi-Ita-Datasets.","url":"https://huggingface.co/datasets/Mattimax/Multi-Ita-Datasets","creator_name":"M.INC.","creator_url":"https://huggingface.co/Mattimax","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","Italian","apache-2.0","100K - 1M","json"],"keywords_longer_than_N":true},
	{"name":"ifeval-ita","keyword":"italian","description":"\n\t\n\t\t\n\t\tDataset Card for IFEval\n\t\n\n\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset contains the prompts used in the Instruction-Following Eval (IFEval) benchmark for large language models. It contains around 500 \"verifiable instructions\" such as \"write in more than 400 words\" and \"mention the keyword of AI at least 3 times\" which can be verified by heuristics. To load the dataset, run:\nfrom datasets import load_dataset\n\nifeval = load_dataset(\"mii-llm/ifeval-ita\")\n\n\n\t\n\t\t\n\t\n\t\n\t\tSupported Tasks and‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mii-llm/ifeval-ita.","url":"https://huggingface.co/datasets/mii-llm/ifeval-ita","creator_name":"mii-llm","creator_url":"https://huggingface.co/mii-llm","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","Italian","apache-2.0","< 1K","json"],"keywords_longer_than_N":true},
	{"name":"Wikipedia-Abstract","keyword":"italian","description":"Wikipedia Abstract\n\n\n  \n\n\n\nIntroducing Wikipedia Abstract, a comprehensive dataset encompassing abstracts, complete articles, and a popularity score index for both widely spoken and lesser-known Wikipedia subsets. Our dedication to Wikipedia-X ensures a centralized Wikipedia dataset that undergoes regular updates and adheres to the highest standards.\nA central focus of our efforts was to include exotic languages that often lack up-to-date Wikipedia dumps or may not have any dumps at all.‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/laion/Wikipedia-Abstract.","url":"https://huggingface.co/datasets/laion/Wikipedia-Abstract","creator_name":"LAION eV","creator_url":"https://huggingface.co/laion","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","question-answering","text-generation","fill-mask","Arabic"],"keywords_longer_than_N":true},
	{"name":"xP3x-Kongo","keyword":"italian","description":"\n\t\n\t\t\n\t\tDataset Card for xP3x Kikongo Focus\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\n\nxP3x (Crosslingual Public Pool of Prompts eXtended) is a collection of prompts & datasets across 277 languages & 16 NLP tasks. It contains all of xP3 + much more! It is used for training future contenders of mT0 & BLOOMZ at project Aya @C4AI üß°\n\n\nCreation: The dataset can be recreated using instructions available here together with the file in this repository named xp3x_create.py. We provide this version to save‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Svngoku/xP3x-Kongo.","url":"https://huggingface.co/datasets/Svngoku/xP3x-Kongo","creator_name":"NIONGOLO Chrys F√©-Marty","creator_url":"https://huggingface.co/Svngoku","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["other","translation","expert-generated","crowdsourced","multilingual"],"keywords_longer_than_N":true},
	{"name":"vault","keyword":"italian","description":"\n\t\n\t\t\n\t\tüõ†Ô∏è Vault Project: Offline Knowledge Vault\n\t\n\nIn a world of uncertainty, knowledge must endure.Vault Project is a tool for creating an offline-optimized database of Wikipedia and other open knowledge repositories, ensuring accessibility even without an internet connection.  \n\n\t\n\t\t\n\t\tüåê What is it?\n\t\n\nVault Project takes publicly available datasets (e.g., Wikipedia, OpenStreetMap, WikiHow) and structures them into an SQLite database with:  \n\nFull-Text Search (FTS) for efficient offline‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/artsakenos/vault.","url":"https://huggingface.co/datasets/artsakenos/vault","creator_name":"Andrea","creator_url":"https://huggingface.co/artsakenos","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":null,"first_N":5,"first_N_keywords":["English","Sardinian","Italian","Chinese","mit"],"keywords_longer_than_N":true},
	{"name":"data-kit-sub-iwslt2025-if-long-constraint","keyword":"italian","description":"\n\t\n\t\t\n\t\tData for KIT‚Äôs Instruction Following Submission for IWSLT 2025\n\t\n\nThis repo contains the data used to train our model for IWSLT 2025's Instruction-Following (IF) Speech Processing track.\nIWSLT 2025's Instruction-Following (IF) Speech Processing track in the scientific domain aims to benchmark foundation models that can follow natural \nlanguage instructions‚Äîan ability well-established in textbased LLMs but still emerging in speech-based counterparts. Our approach employs an end-to-end‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/maikezu/data-kit-sub-iwslt2025-if-long-constraint.","url":"https://huggingface.co/datasets/maikezu/data-kit-sub-iwslt2025-if-long-constraint","creator_name":"Maike Z√ºfle","creator_url":"https://huggingface.co/maikezu","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","summarization","question-answering","translation","English"],"keywords_longer_than_N":true},
	{"name":"redeIT-xml-ShareGPT","keyword":"italian","description":"leinad-deinor/redeIT-xml-ShareGPT dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/leinad-deinor/redeIT-xml-ShareGPT","creator_name":"Daniel Acampora","creator_url":"https://huggingface.co/leinad-deinor","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["Italian","apache-2.0","< 1K","parquet","Text"],"keywords_longer_than_N":true},
	{"name":"fine-instructions-ita-70k","keyword":"italian","description":"\n\t\n\t\t\n\t\tüç∑üáÆüáπ Fine Instructions Ita 70k\n\t\n\nA good instruction dataset in Italian, generated with LLM-aided translation.\n\n\t\n\t\t\n\t\tLLM-aided translation\n\t\n\n\nThe starting point has been mlabonne/FineTome-100k: a subset of arcee-ai/The-Tome, re-filtered using HuggingFaceFW/fineweb-edu-classifier to identify examples with good educational value. FineTome is a high quality dataset containing diverse elements such as conversations, reasoning problems, and more.\nThe translation process includes these‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/anakin87/fine-instructions-ita-70k.","url":"https://huggingface.co/datasets/anakin87/fine-instructions-ita-70k","creator_name":"Stefano Fiorucci","creator_url":"https://huggingface.co/anakin87","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","Italian","apache-2.0","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"voices-of-civilizations","keyword":"italian","description":"\n\t\n\t\t\n\t\tVoices of Civilizations (VoC)\n\t\n\nVoices of Civilizations (VoC) is the first multilingual QA benchmark designed to assess audio LLMs‚Äô cultural comprehension using full-length music recordings. VoC spans:\n\n38 languages üá∏üá¶ Arabic (ar), üáßüá© Bengali (bn), üáßüá¨ Bulgarian (bg), üá®üá≥ Chinese (zh), üá≠üá∑ Croatian (hr), üá®üáø Czech (cs), üá©üá∞ Danish (da), üá≥üá± Dutch (nl), üá¨üáß English (en), üá™üá™ Estonian (et), üá´üáÆ Finnish (fi), üá´üá∑ French (fr), üá©üá™ German (de), üá¨üá∑ Greek (el), üáÆüá± Hebrew‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/sander-wood/voices-of-civilizations.","url":"https://huggingface.co/datasets/sander-wood/voices-of-civilizations","creator_name":"Shangda Wu (Sander Wood)","creator_url":"https://huggingface.co/sander-wood","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["question-answering","Arabic","Bengali","Bulgarian","Chinese"],"keywords_longer_than_N":true},
	{"name":"wikipedia-citation-index","keyword":"italian","description":"Dataset with citation indexes as of 1 August 2024 for 47 million Wikipedia articles in 55 language versions. Research: ArXiv\n","url":"https://huggingface.co/datasets/lewoniewski/wikipedia-citation-index","creator_name":"W≈Çodzimierz Lewoniewski","creator_url":"https://huggingface.co/lewoniewski","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["Arabic","Azerbaijani","Belarusian","Bulgarian","Catalan"],"keywords_longer_than_N":true},
	{"name":"fact-or-opinion","keyword":"italian","description":"agentlans/fact-or-opinion dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/agentlans/fact-or-opinion","creator_name":"Alan Tseng","creator_url":"https://huggingface.co/agentlans","license_name":"Open Data Commons Attribution License v1.0","license_url":"https://scancode-licensedb.aboutcode.org/odc-by-1.0.html","language":"en","first_N":5,"first_N_keywords":["text-classification","Amharic","Arabic","Bengali","German"],"keywords_longer_than_N":true},
	{"name":"latin_italian_semantic_translation","keyword":"italian","description":"\n\t\n\t\t\n\t\tLatin - Italian (Semantic Context And Translation)\n\t\n\nThis dataset was generated by fetching random first paragraphs from Wikipedia in Ancient Latin (la.wikipedia.org)\nand processing them using Gemini AI with the following goal(s):\n\nProcessing Goal 1: mantiene il testo in latino. ma riduce l'ambiguit√† aggiungendo tag grammaticali IN ITALIANO (come soggetto, verbo eccetera...) e tag funzionali (come \"indica dove √® nato il soggetto\" oppure \"indica che il soggetto possiede l'oggetto\")‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Dddixyy/latin_italian_semantic_translation.","url":"https://huggingface.co/datasets/Dddixyy/latin_italian_semantic_translation","creator_name":"Davide Brunori","creator_url":"https://huggingface.co/Dddixyy","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["gemini-ai","original:wikipedia:la","Italian","mit","< 1K"],"keywords_longer_than_N":true},
	{"name":"Text-Moderation-Multilingual","keyword":"italian","description":"\n\t\n\t\t\n\t\tText-Moderation-Multilingual\n\t\n\nA comprehensive multilingual text moderation dataset combining multiple high-quality sources for training robust content moderation classifiers.\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset aggregates text moderation data from multiple sources to create a large-scale, diverse training corpus for content moderation systems. It includes text samples labeled across multiple harmful content categories, supporting both multilingual and English-specific moderation‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/KoalaAI/Text-Moderation-Multilingual.","url":"https://huggingface.co/datasets/KoalaAI/Text-Moderation-Multilingual","creator_name":"Koala AI","creator_url":"https://huggingface.co/KoalaAI","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","English","German","French","Spanish"],"keywords_longer_than_N":true},
	{"name":"female-LJSpeech-italian","keyword":"italian","description":"giacomoarienti/female-LJSpeech-italian dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/giacomoarienti/female-LJSpeech-italian","creator_name":"Giacomo Arienti","creator_url":"https://huggingface.co/giacomoarienti","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-to-speech","Italian","apache-2.0","1K - 10K","parquet"],"keywords_longer_than_N":true},
	{"name":"thinking-multilingual-30-23-small-690","keyword":"italian","description":"\nBased on OPENO1 math, this is a translated dataset of 30 high quality questions & answers in 23 languages. \nOr use the \"big\" version: big 10k rows version\n","url":"https://huggingface.co/datasets/Pinkstack/thinking-multilingual-30-23-small-690","creator_name":"Pinkstack","creator_url":"https://huggingface.co/Pinkstack","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","Arabic","Chinese","Czech","Danish"],"keywords_longer_than_N":true},
	{"name":"multilingual-speech-commands-15lang","keyword":"italian","description":"\n\t\n\t\t\n\t\tMultilingual Speech Commands Dataset (15 Languages, Augmented)\n\t\n\nThis dataset contains augmented speech command samples in 15 languages, derived from multiple public datasets. Only commands that overlap with the Google Speech Commands (GSC) vocabulary are included, making the dataset suitable for multilingual keyword spotting tasks aligned with GSC-style classification.\nAudio samples have been augmented using standard audio techniques to improve model robustness (e.g., time-shifting‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/artur-muratov/multilingual-speech-commands-15lang.","url":"https://huggingface.co/datasets/artur-muratov/multilingual-speech-commands-15lang","creator_name":"Artur Muratov","creator_url":"https://huggingface.co/artur-muratov","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["English","Russian","Kazakh","Tatar","Arabic"],"keywords_longer_than_N":true},
	{"name":"WHSEIN","keyword":"italian","description":"EonUrsis/WHSEIN dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/EonUrsis/WHSEIN","creator_name":"Eon Joubert","creator_url":"https://huggingface.co/EonUrsis","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["English","Afrikaans","Italian","apache-2.0","100K<n<1M"],"keywords_longer_than_N":true},
	{"name":"actuarial-global-glossary-multilingual","keyword":"italian","description":"\n  \n\n\n\n  \n\n\n\t\n\t\t\n\t\tü§ù Connect with me on LinkedIn!\n\t\n\n  \n  Join the mission to make actuarial knowledge accessible worldwide\n  Let's discuss how AI can transform professional education and break language barriers in finance!\n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tüåç Global Actuarial Glossary - Breaking Language Barriers in Finance\n\t\n\n\n\n\n\n\n\t\n\t\t\n\t\tüöÄ The World's Most Comprehensive Multilingual Actuarial Dataset\n\t\n\nImagine: A brilliant actuarial student in Tokyo, a risk analyst in S√£o Paulo, and an insurance executive‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/manuelcaccone/actuarial-global-glossary-multilingual.","url":"https://huggingface.co/datasets/manuelcaccone/actuarial-global-glossary-multilingual","creator_name":"Manuel Caccone","creator_url":"https://huggingface.co/manuelcaccone","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","translation","text-generation","question-answering","multi-class-classification"],"keywords_longer_than_N":true},
	{"name":"piqa_italian","keyword":"italian","description":"\n\t\n\t\t\n\t\tPIQA - Italian (IT)\n\t\n\nThis dataset is an Italian translation of PIQA. PIQA stands for Physical Interaction Question Answering, a dataset of questions about common scenarios that require an understanding of the physical world. \n\n\t\n\t\t\n\t\tDataset Details\n\t\n\nThe dataset consists of questions about common scenarios that require an understanding of the physical world. Each question is associated with a correct answer and a distractor. The task is to predict the correct answer to the‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/s-conia/piqa_italian.","url":"https://huggingface.co/datasets/s-conia/piqa_italian","creator_name":"Simone Conia","creator_url":"https://huggingface.co/s-conia","license_name":"Academic Free License v3.0","license_url":"https://choosealicense.com/licenses/afl-3.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","Italian","English","afl-3.0","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"reranking-datasets-light","keyword":"italian","description":"\n\t\n\t\t\n\t\tüî• Rankify: A Comprehensive Python Toolkit for Retrieval, Re-Ranking, and Retrieval-Augmented Generation üî•\n\t\n\n\n\t\n\t\t\n\t\n\t\n\t\tReRanking Datasets : A comprehensive collection of retrieval and reranking datasets with full passage contexts, including titles, text, and metadata for in-depth research.\n\t\n\n\n    \n    \n    \n    \n    \n    \n        \n    \n    \n        \n    \n    \n        \n    \n    \n        \n    \n    \n    \n\n\n\nA curated collection of ready-to-use datasets for retrieval and reranking‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/abdoelsayed/reranking-datasets-light.","url":"https://huggingface.co/datasets/abdoelsayed/reranking-datasets-light","creator_name":"Abdelrahman Abdallah","creator_url":"https://huggingface.co/abdoelsayed","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["question-answering","English","Arabic","German","French"],"keywords_longer_than_N":true},
	{"name":"winogrande_italian","keyword":"italian","description":"\n\t\n\t\t\n\t\tWinogrande - Italian (IT)\n\t\n\nThis dataset is an Italian translation of Winogrande. Winogrande is a large-scale dataset for coreference resolution, commonsense reasoning, and world knowledge. It is based on the original Winograd Schema Challenge dataset.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\nThe dataset consists of almost 40K examples, each containing a sentence with a blank and two possible fill-in-the-blank options. The task is to choose the correct option that correctly fills in the blank based‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/sapienzanlp/winogrande_italian.","url":"https://huggingface.co/datasets/sapienzanlp/winogrande_italian","creator_name":"Sapienza NLP, Sapienza University of Rome","creator_url":"https://huggingface.co/sapienzanlp","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","Italian","English","apache-2.0","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"capybara-claude-15k-ita","keyword":"italian","description":"\n\t\n\t\t\n\t\tDataset Card\n\t\n\nThis dataset is a multi-turn dialogue dataset in Italian, evolved from a translated capybara first prompt. The dataset was created by running the initial prompt through a pipeline to generate answers and subsequent instructions (1-2-3) for each dialogue turn.\nInstructions are created and translated using claude-3-sonnet-20240229, answers are generated by claude-3-opus-20240229.\n\n\t\n\t\t\n\t\n\t\n\t\tCite this dataset\n\t\n\nI hope it proves valuable for your research and‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/efederici/capybara-claude-15k-ita.","url":"https://huggingface.co/datasets/efederici/capybara-claude-15k-ita","creator_name":"Edoardo Federici","creator_url":"https://huggingface.co/efederici","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["question-answering","text-generation","Italian","mit","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"Growdatasettest","keyword":"italian","description":"Questo √® il dataset di prova di Growdataset per la prova di un codice di test\n","url":"https://huggingface.co/datasets/Fluel/Growdatasettest","creator_name":"Fluel","creator_url":"https://huggingface.co/Fluel","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["Italian","mit","< 1K","text","Text"],"keywords_longer_than_N":true},
	{"name":"AyaVisionBench","keyword":"italian","description":"\n\t\n\t\t\n\t\tDataset Card for Aya Vision Benchmark\n\t\n\n\n\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\nThe Aya Vision Benchmark is designed to evaluate vision-language models in real-world multilingual scenarios. It spans 23 languages and 9 distinct task categories, with 15 samples per category, resulting in 135 image-question pairs per language. \nEach question requires visual context for the answer and covers languages that half of the world's population speaks, making this dataset particularly suited for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/CohereLabs/AyaVisionBench.","url":"https://huggingface.co/datasets/CohereLabs/AyaVisionBench","creator_name":"Cohere Labs","creator_url":"https://huggingface.co/CohereLabs","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["English","French","German","Spanish","Italian"],"keywords_longer_than_N":true},
	{"name":"include-base-44","keyword":"italian","description":"\n\t\n\t\t\n\t\tINCLUDE-base (44 languages)\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\n\n\nPaper: http://arxiv.org/abs/2411.19799\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nINCLUDE is a comprehensive knowledge- and reasoning-centric benchmark across 44 languages that evaluates multilingual LLMs for performance in the actual language environments where they would be deployed. \nIt contains 22,637 4-option multiple-choice-questions (MCQ) extracted from academic and professional exams, covering 57 topics, including regional‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/CohereLabs/include-base-44.","url":"https://huggingface.co/datasets/CohereLabs/include-base-44","creator_name":"Cohere Labs","creator_url":"https://huggingface.co/CohereLabs","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["multiple-choice","Albanian","Arabic","Armenian","Azerbaijani"],"keywords_longer_than_N":true},
	{"name":"cvss","keyword":"italian","description":"CVSS is a massively multilingual-to-English speech-to-speech translation corpus,\ncovering sentence-level parallel speech-to-speech translation pairs from 21\nlanguages into English.","url":"https://huggingface.co/datasets/google/cvss","creator_name":"Google","creator_url":"https://huggingface.co/google","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":null,"first_N":5,"first_N_keywords":["English","Arabic","Catalan","Welsh","German"],"keywords_longer_than_N":true},
	{"name":"Pornhub","keyword":"italian","description":"\n\t\n\t\t\n\t\tPornhub Dataset\n\t\n\nThe Pornhub Dataset provides a comprehensive collection of data sourced from pornhub.com, encompassing various details from MANYYY videos available on the platform.\nThe file consists of 742.133 lines of videos.\n\n\t\n\t\t\n\t\tData Description\n\t\n\n\nDelimiter: ‚ÄΩ\nFile Format: CSV\nContent:\nURL: The URL of the video.\nCategory: The genre or category of the video.\nUser: The username of the uploader.\nVideo_title: The title of the video.\nViews: The number of views the video has‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Nikity/Pornhub.","url":"https://huggingface.co/datasets/Nikity/Pornhub","creator_name":"Nikita","creator_url":"https://huggingface.co/Nikity","license_name":"Open Data Commons Attribution License v1.0","license_url":"https://scancode-licensedb.aboutcode.org/odc-by-1.0.html","language":"en","first_N":5,"first_N_keywords":["Albanian","Arabic","Bengali","Bulgarian","Chinese"],"keywords_longer_than_N":true},
	{"name":"xtreme","keyword":"italian","description":"\n\t\n\t\t\n\t\tDataset Card for \"xtreme\"\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThe Cross-lingual Natural Language Inference (XNLI) corpus is a crowd-sourced collection of 5,000 test and\n2,500 dev pairs for the MultiNLI corpus. The pairs are annotated with textual entailment and translated into\n14 languages: French, Spanish, German, Greek, Bulgarian, Russian, Turkish, Arabic, Vietnamese, Thai, Chinese,\nHindi, Swahili and Urdu. This results in 112.5k annotated pairs. Each premise can be associated with the‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/google/xtreme.","url":"https://huggingface.co/datasets/google/xtreme","creator_name":"Google","creator_url":"https://huggingface.co/google","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["multiple-choice","question-answering","token-classification","text-classification","text-retrieval"],"keywords_longer_than_N":true},
	{"name":"gutenberg_multilang","keyword":"italian","description":"\n\t\n\t\t\n\t\tDataset Card for Project Gutenber - Multilanguage eBooks\n\t\n\nA collection of non-english language eBooks (7907, about 75-80% of all the ES, DE, FR, NL, IT, PT, HU books available on the site) from the Project Gutenberg site with metadata removed. \nOriginally colected for https://github.com/LAION-AI/Open-Assistant\n\n\t\n\t\t\nLANG\nEBOOKS\n\n\n\t\t\nES\n717\n\n\nDE\n1735\n\n\nFR\n2863\n\n\nNL\n904\n\n\nIT\n692\n\n\nPT\n501\n\n\nHU\n495\n\n\n\t\n\nThe METADATA column contains catalogue meta information on each book as a serialized‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/sedthh/gutenberg_multilang.","url":"https://huggingface.co/datasets/sedthh/gutenberg_multilang","creator_name":"Richard Nagyfi","creator_url":"https://huggingface.co/sedthh","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-generation","Spanish","German","French","Dutch"],"keywords_longer_than_N":true},
	{"name":"tatoeba_mt","keyword":"italian","description":"The Tatoeba Translation Challenge is a multilingual data set of\nmachine translation benchmarks derived from user-contributed\ntranslations collected by [Tatoeba.org](https://tatoeba.org/) and\nprovided as parallel corpus from [OPUS](https://opus.nlpl.eu/). This\ndataset includes test and development data sorted by language pair. It\nincludes test sets for hundreds of language pairs and is continuously\nupdated. Please, check the version number tag to refer to the release\nthat your are using.","url":"https://huggingface.co/datasets/Helsinki-NLP/tatoeba_mt","creator_name":"Language Technology Research Group at the University of Helsinki","creator_url":"https://huggingface.co/Helsinki-NLP","license_name":"Creative Commons Attribution 2.0","license_url":"https://scancode-licensedb.aboutcode.org/cc-by-2.0.html","language":null,"first_N":5,"first_N_keywords":["text-generation","translation","no-annotation","crowdsourced","translation"],"keywords_longer_than_N":true},
	{"name":"multilexnorm","keyword":"italian","description":"For this task, participants are asked to develop a system that performs lexical normalization: the conversion of non-canonical texts to their canonical equivalent form. In particular, this task includes data from 12 languages.","url":"https://huggingface.co/datasets/larrylawl/multilexnorm","creator_name":"Law Ann Liat Larry","creator_url":"https://huggingface.co/larrylawl","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":null,"first_N":5,"first_N_keywords":["text-generation","English","Danish","German","Spanish"],"keywords_longer_than_N":true},
	{"name":"Multilingual-Medical-Corpus","keyword":"italian","description":"\n    \n    \n    Mutilingual Medical Corpus\n    \n\n\nMultilingual-Medical-Corpus a 3 billion word multilingual corpus for training LLMs adapted to the medical domain. Multilingual-Medical-Corpus includes four languages, namely, English, Spanish, French, and Italian.\n\n\n\nüìñ Paper: Medical mT5: An Open-Source Multilingual Text-to-Text LLM for The Medical Domain\nüåê Project Website: https://univ-cotedazur.eu/antidote\n\n\n\t\n\t\t\n\t\n\t\n\t\tCorpus Description\n\t\n\n\nDeveloped by: Iker Garc√≠a-Ferrero, Rodrigo Agerri‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/HiTZ/Multilingual-Medical-Corpus.","url":"https://huggingface.co/datasets/HiTZ/Multilingual-Medical-Corpus","creator_name":"HiTZ zentroa","creator_url":"https://huggingface.co/HiTZ","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["English","Spanish","French","Italian","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"SIMPITIKI","keyword":"italian","description":"SIMPITIKI is a Simplification corpus for Italian and it consists of two sets of simplified pairs: the first one is harvested from the Italian Wikipedia in a semi-automatic way; the second one is manually annotated sentence-by-sentence from documents in the administrative domain.","url":"https://huggingface.co/datasets/GEM/SIMPITIKI","creator_name":"GEM benchmark","creator_url":"https://huggingface.co/GEM","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":null,"first_N":5,"first_N_keywords":["text-simplification","crowd-sourced","unknown","unknown","original"],"keywords_longer_than_N":true},
	{"name":"PsiloQA","keyword":"italian","description":"\n\n\t\n\t\t\n\t\tWhat is it?\n\t\n\nPsiloQA is the largest dataset for training and evaluating systems on multilingual span-level hallucination detection with retrieved context. It offers:\n\nAn automated and scalable pipeline for generating, annotating and filtering data for hallucination detection task\nA large multilingual dataset for 14 languages with high-quality and fine-grained span-level hallucination annotations for numerous open-source LLMs\nA comprehensive empirical evaluations of various‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/s-nlp/PsiloQA.","url":"https://huggingface.co/datasets/s-nlp/PsiloQA","creator_name":"s-nlp","creator_url":"https://huggingface.co/s-nlp","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["token-classification","text-classification","text-generation","zero-shot-classification","question-answering"],"keywords_longer_than_N":true},
	{"name":"common_voice_16_0","keyword":"italian","description":"\n\t\n\t\t\n\t\tDataset Card for Common Voice Corpus 16.0\n\t\n\n\n\nThis dataset is an unofficial version of the Mozilla Common Voice Corpus 16. It was downloaded and converted from the project's website https://commonvoice.mozilla.org/.\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nAbkhaz, Albanian, Amharic, Arabic, Armenian, Assamese, Asturian, Azerbaijani, Basaa, Bashkir, Basque, Belarusian, Bengali, Breton, Bulgarian, Cantonese, Catalan, Central Kurdish, Chinese (China), Chinese (Hong Kong), Chinese (Taiwan), Chuvash, Czech‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/fsicoli/common_voice_16_0.","url":"https://huggingface.co/datasets/fsicoli/common_voice_16_0","creator_name":"Fabio Sicoli","creator_url":"https://huggingface.co/fsicoli","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":null,"first_N":5,"first_N_keywords":["automatic-speech-recognition","Abkhaz","Afrikaans","Amharic","Arabic"],"keywords_longer_than_N":true},
	{"name":"openassistant-deepseek-coder","keyword":"italian","description":"\n\t\n\t\t\n\t\tChat Fine-tuning Dataset - OpenAssistant DeepSeek Coder\n\t\n\nThis dataset allows for fine-tuning chat models using:\nB_INST = '\\n### Instruction:\\n'\nE_INST = '\\n### Response:\\n'\nBOS = '<ÔΩúbegin‚ñÅof‚ñÅsentenceÔΩú>'\nEOS = '\\n<|EOT|>\\n'\n\nSample Preparation:\n\nThe dataset is cloned from TimDettmers, which itself is a subset of the Open Assistant dataset, which you can find here. This subset of the data only contains the highest-rated paths in the conversation tree, with a total of 9,846 samples.\nThe‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Trelis/openassistant-deepseek-coder.","url":"https://huggingface.co/datasets/Trelis/openassistant-deepseek-coder","creator_name":"Trelis","creator_url":"https://huggingface.co/Trelis","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["English","Spanish","Russian","German","Polish"],"keywords_longer_than_N":true},
	{"name":"xtreme_s","keyword":"italian","description":"XTREME-S covers four task families: speech recognition, classification, speech-to-text translation and retrieval. Covering 102\nlanguages from 10+ language families, 3 different domains and 4\ntask families, XTREME-S aims to simplify multilingual speech\nrepresentation evaluation, as well as catalyze research in ‚Äúuniversal‚Äù speech representation learning.","url":"https://huggingface.co/datasets/google/xtreme_s","creator_name":"Google","creator_url":"https://huggingface.co/google","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":null,"first_N":5,"first_N_keywords":["automatic-speech-recognition","expert-generated","crowdsourced","machine-generated","crowdsourced"],"keywords_longer_than_N":true},
	{"name":"wikipedia-22-12-it-embeddings","keyword":"italian","description":"\n\t\n\t\t\n\t\tWikipedia (it) embedded with cohere.ai multilingual-22-12 encoder\n\t\n\nWe encoded Wikipedia (it) using the cohere.ai multilingual-22-12 embedding model.\nTo get an overview how this dataset was created and pre-processed, have a look at Cohere/wikipedia-22-12.\n\n\t\n\t\t\n\t\n\t\n\t\tEmbeddings\n\t\n\nWe compute for title+\" \"+text the embeddings using our multilingual-22-12 embedding model, a state-of-the-art model that works for semantic search in 100 languages.  If you want to learn more about this‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Cohere/wikipedia-22-12-it-embeddings.","url":"https://huggingface.co/datasets/Cohere/wikipedia-22-12-it-embeddings","creator_name":"Cohere","creator_url":"https://huggingface.co/Cohere","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","document-retrieval","expert-generated","multilingual","Italian"],"keywords_longer_than_N":true},
	{"name":"Multilingual-BioASQ-6B","keyword":"italian","description":"\n    \n    \n    Mutilingual BioASQ-6B\n    \n\n\nWe translate the BioASQ-6B English Question Answering dataset to generate parallel French, Italian and Spanish versions using the NLLB200 3B parameter model. For more info read the original task description: [http://bioasq.org/participate/challenges_year_6](http://bioasq.org/participate/challenges_year_6)\n\nWe translate the body, snippets, ideal_answer and exact_answer fields. We have validated the quality of the ideal_answer field, however, the‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/HiTZ/Multilingual-BioASQ-6B.","url":"https://huggingface.co/datasets/HiTZ/Multilingual-BioASQ-6B","creator_name":"HiTZ zentroa","creator_url":"https://huggingface.co/HiTZ","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["question-answering","summarization","English","Spanish","French"],"keywords_longer_than_N":true},
	{"name":"super_eurlex","keyword":"italian","description":"Super-EURLEX dataset containing legal documents from multiple languages.\n                The datasets are build/scrapped from the EURLEX Website [https://eur-lex.europa.eu/homepage.html]\n                With one split per language and sector, because the available features (metadata) differs for each \n                sector. Therefore, each sample contains the content of a full legal document in up to 3 different \n                formats. Those are raw HTML and cleaned HTML (if the HTML format was available on the EURLEX website \n                during the scrapping process) and cleaned text.\n                The cleaned text should be available for each sample and was extracted from HTML or PDF.\n                'Cleaned' HTML stands here for minor cleaning that was done to preserve to a large extent the necessary \n                HTML information like table structures while removing unnecessary complexity which was introduced to the \n                original documents due to actions like writing each sentence into a new object. \n                Additionally, each sample contains metadata which was scrapped on the fly, this implies the following \n                2 things. First, not every sector contains the same metadata. Second, most metadata might be \n                irrelevant for most use cases. \n                In our minds the most interesting metadata is the celex-id which is used to identify the legal \n                document at hand, but also contains a lot of information about the document \n                see [https://eur-lex.europa.eu/content/tools/eur-lex-celex-infographic-A3.pdf] as well as eurovoc-\n                concepts, which are labels that define the content of the documents. \n                Eurovoc-Concepts are, for example, only available for the sectors 1, 2, 3, 4, 5, 6, 9, C, and E.\n                The Naming of most metadata is kept like it was on the eurlex website, except for converting \n                it to lower case and replacing whitespaces with '_'.","url":"https://huggingface.co/datasets/ddrg/super_eurlex","creator_name":"Dresden Database Research Group","creator_url":"https://huggingface.co/ddrg","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":null,"first_N":5,"first_N_keywords":["text-classification","fill-mask","multi-class-classification","multi-label-classification","found"],"keywords_longer_than_N":true},
	{"name":"LoLLMS-Open-Community-discussions","keyword":"italian","description":"\n\t\n\t\t\n\t\tDataset Card for GPT4All-Community-Discussions\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset contains ethically gathered discussions from the community, who shared their experiences with various open source discussion models using the GPT4All-ui tool. The dataset is open for any use, including commercial use, as long as proper citation is given to acknowledge the contributions of the community. \nThe GPT4All-ui tool allows users to have conversations with various open source AIs and‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ParisNeo/LoLLMS-Open-Community-discussions.","url":"https://huggingface.co/datasets/ParisNeo/LoLLMS-Open-Community-discussions","creator_name":"Saifeddine ALOUI","creator_url":"https://huggingface.co/ParisNeo","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["English","French","German","Arabic","Italian"],"keywords_longer_than_N":true},
	{"name":"oscar-small","keyword":"italian","description":"The Open Super-large Crawled ALMAnaCH coRpus is a huge multilingual corpus obtained by language classification and filtering of the Common Crawl corpus using the goclassy architecture.\\","url":"https://huggingface.co/datasets/djstrong/oscar-small","creator_name":"Krzysztof Wr√≥bel","creator_url":"https://huggingface.co/djstrong","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","language-modeling","no-annotation","found","multilingual"],"keywords_longer_than_N":true},
	{"name":"oscar-small","keyword":"italian","description":"The Open Super-large Crawled ALMAnaCH coRpus is a huge multilingual corpus obtained by language classification and filtering of the Common Crawl corpus using the goclassy architecture.\\","url":"https://huggingface.co/datasets/nthngdy/oscar-small","creator_name":"Nathan Godey","creator_url":"https://huggingface.co/nthngdy","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","language-modeling","no-annotation","found","multilingual"],"keywords_longer_than_N":true},
	{"name":"multilingual-pl-bert","keyword":"italian","description":"Attribution: Wikipedia.org\n","url":"https://huggingface.co/datasets/styletts2-community/multilingual-pl-bert","creator_name":"StyleTTS 2 Community","creator_url":"https://huggingface.co/styletts2-community","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["Afrikaans","Aragonese","Arabic","Azerbaijani","Bashkir"],"keywords_longer_than_N":true},
	{"name":"mapa","keyword":"italian","description":"\n\t\n\t\t\n\t\tDataset Card for Multilingual European Datasets for Sensitive Entity Detection in the Legal Domain\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThe dataset consists of 12 documents (9 for Spanish due to parsing errors) taken from EUR-Lex, a multilingual corpus of court\ndecisions and legal dispositions in the 24 official languages of the European Union. The documents have been annotated\nfor named entities following the guidelines of the MAPA project which foresees two\nannotation level, a general and a‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/joelniklaus/mapa.","url":"https://huggingface.co/datasets/joelniklaus/mapa","creator_name":"Joel Niklaus","creator_url":"https://huggingface.co/joelniklaus","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["token-classification","named-entity-recognition","other","found","multilingual"],"keywords_longer_than_N":true},
	{"name":"tatoeba-mt-qna-oa","keyword":"italian","description":"\n\t\n\t\t\n\t\tDataset Card for multilingual tatoeba QnA translation with ~120K entries.\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nContains Parquet of a list of instructions and translation articles on different languages.\nEach row consists of\n\nINSTRUCTION\nRESPONSE\nSOURCE (tatoeba)\nMETADATA (json with language, text length, uuid, langs-pair).\n\n\n\t\n\t\t\n\t\tOriginal Dataset is avalible here:\n\t\n\n\nhttps://huggingface.co/datasets/Helsinki-NLP/tatoeba_mt\n\n","url":"https://huggingface.co/datasets/0x22almostEvil/tatoeba-mt-qna-oa","creator_name":"David Glushkov","creator_url":"https://huggingface.co/0x22almostEvil","license_name":"Creative Commons Attribution 2.0","license_url":"https://scancode-licensedb.aboutcode.org/cc-by-2.0.html","language":"en","first_N":5,"first_N_keywords":["question-answering","translation","English","Russian","German"],"keywords_longer_than_N":true},
	{"name":"sumstew","keyword":"italian","description":"\n\t\n\t\t\n\t\tDataset Card for \"sumstew\"\n\t\n\n\n\t\n\t\t\n\t\tTL;DR:\n\t\n\nSumstew is a abstractive, multilingual Dataset, with a balanced number of samples from a diverse set of summarization Datasets. The input sizes range up to 16384 tokens.\nFiltered using a diverse set of heuristics to encourage high coverage, accuracy and factual consistency. Code to reproduce Dataset available at TODO\n\n\t\n\t\t\n\t\tTask Information\n\t\n\n\nTask Categories: The tasks covered by this dataset are primarily summarization tasks.‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Joemgu/sumstew.","url":"https://huggingface.co/datasets/Joemgu/sumstew","creator_name":"Jonas","creator_url":"https://huggingface.co/Joemgu","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["summarization","English","German","French","Italian"],"keywords_longer_than_N":true},
	{"name":"MultiJail","keyword":"italian","description":"\n\t\n\t\t\n\t\tMultilingual Jailbreak Challenges in Large Language Models\n\t\n\nThis repo contains the data for our paper \"Multilingual Jailbreak Challenges in Large Language Models\".\n[Github repo]\n\n\t\n\t\t\n\t\tAnnotation Statistics\n\t\n\nWe collected a total of 315 English unsafe prompts and annotated them into nine non-English languages. The languages were categorized based on resource availability, as shown below:\nHigh-resource languages: Chinese (zh), Italian (it), Vietnamese (vi)\nMedium-resource languages:‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/DAMO-NLP-SG/MultiJail.","url":"https://huggingface.co/datasets/DAMO-NLP-SG/MultiJail","creator_name":"Language Technology Lab at Alibaba DAMO Academy","creator_url":"https://huggingface.co/DAMO-NLP-SG","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["English","Chinese","Italian","Vietnamese","Arabic"],"keywords_longer_than_N":true},
	{"name":"gazzetta-ufficiale","keyword":"italian","description":"\n\t\n\t\t\n\t\tGazzetta Ufficiale üë©üèª‚Äç‚öñÔ∏è‚öñÔ∏èüèõÔ∏èüìúüáÆüáπ\n\t\n\n\n\nLa Gazzetta Ufficiale della Repubblica Italiana, quale fonte ufficiale di conoscenza delle norme in vigore in Italia e strumento di diffusione, informazione e ufficializzazione di testi legislativi, atti pubblici e privati, √® edita dall‚ÄôIstituto Poligrafico e Zecca dello Stato e pubblicata in collaborazione con il Ministero della Giustizia, il quale provvede alla direzione e redazione della stessa. L'Istituto Poligrafico e Zecca dello Stato‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mii-llm/gazzetta-ufficiale.","url":"https://huggingface.co/datasets/mii-llm/gazzetta-ufficiale","creator_name":"mii-llm","creator_url":"https://huggingface.co/mii-llm","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-generation","fill-mask","Italian","mit","1M - 10M"],"keywords_longer_than_N":true},
	{"name":"docfullstructure_dataset","keyword":"italian","description":"kopan/docfullstructure_dataset dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/kopan/docfullstructure_dataset","creator_name":"Ilia Kopanichuk","creator_url":"https://huggingface.co/kopan","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":null,"first_N":5,"first_N_keywords":["text-classification","Russian","English","Kazakh","Bulgarian"],"keywords_longer_than_N":true},
	{"name":"UsenetArchiveIT-conversations","keyword":"italian","description":"\n\t\n\t\t\n\t\tConversational Usenet Archive IT Dataset üáÆüáπ\n\t\n\n\n\t\n\t\t\n\t\tDescription\n\t\n\n\n\t\n\t\t\n\t\tDataset Content\n\t\n\nThis dataset is a filtered version from the Usenet dataset that contains posts from Italian language newsgroups belonging to the it and italia hierarchies. The data has been archived and converted to the Parquet format for easy processing. All posts with more the one message has been grouped in conversations\nThis dataset contributes to the mii-community project, aimed at advancing the‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mii-community/UsenetArchiveIT-conversations.","url":"https://huggingface.co/datasets/mii-community/UsenetArchiveIT-conversations","creator_name":"mii-community","creator_url":"https://huggingface.co/mii-community","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","Italian","apache-2.0","1M - 10M","parquet"],"keywords_longer_than_N":true},
	{"name":"semantics-ws-qna-oa","keyword":"italian","description":"\n\t\n\t\t\n\t\tDataset Card for semantics-ws-qna-oa with ~2K entries.\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nLicense: Apache-2.0. Contains parquet of INSTRUCTION, RESPONSE, SOURCE and METADATA.\n\n\n\t\n\t\t\n\t\tOriginal Datasets are available here:\n\t\n\n\nhttps://leviants.com/multilingual-simlex999-and-wordsim353/\n\n\n\n\t\n\t\t\n\t\tPaper of original Dataset:\n\t\n\n\nhttps://arxiv.org/pdf/1508.00106v5.pdf\n\n","url":"https://huggingface.co/datasets/0x22almostEvil/semantics-ws-qna-oa","creator_name":"David Glushkov","creator_url":"https://huggingface.co/0x22almostEvil","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","English","Russian","German","Italian"],"keywords_longer_than_N":true},
	{"name":"cultural_heritage_metadata_accuracy","keyword":"italian","description":"\n\t\n\t\t\n\t\tDataset Card for Annotated dataset to assess the accuracy of the textual description of cultural heritage records\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThe dataset contains more than 100K textual descriptions of cultural items from Cultura Italia, the Italian National Cultural aggregator. Each of the description is labeled either HIGH or LOW quality, according its adherence to the standard cataloguing guidelines provided by Istituto Centrale per il Catalogo e la Documentazione (ICCD). More‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/biglam/cultural_heritage_metadata_accuracy.","url":"https://huggingface.co/datasets/biglam/cultural_heritage_metadata_accuracy","creator_name":"BigLAM: BigScience Libraries, Archives and Museums","creator_url":"https://huggingface.co/biglam","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","acceptability-classification","machine-generated","expert-generated","expert-generated"],"keywords_longer_than_N":true},
	{"name":"medieval","keyword":"italian","description":"\n\t\n\t\t\n\t\tDataset Card for CATMuS Medieval\n\t\n\n\nJoin our Discord to ask questions about the dataset: \n\n\t\n\t\t\n\t\n\t\n\t\tDataset Details\n\t\n\nHandwritten Text Recognition (HTR) has emerged as a crucial tool for converting manuscripts images into machine-readable formats, \nenabling researchers and scholars to analyse vast collections efficiently. \nDespite significant technological progress, establishing consistent ground truth across projects for HTR tasks, \nparticularly for complex and heterogeneous‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/CATMuS/medieval.","url":"https://huggingface.co/datasets/CATMuS/medieval","creator_name":"CATMuS: Consistent Approach to Transcribing ManuScripts","creator_url":"https://huggingface.co/CATMuS","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["image-to-text","French","English","Dutch","Italian"],"keywords_longer_than_N":true},
	{"name":"openassistant-guanaco-EOS","keyword":"italian","description":"\n\t\n\t\t\n\t\tChat Fine-tuning Dataset - Guanaco Style\n\t\n\nThis dataset allows for fine-tuning chat models using \"### Human:\" AND \"### Assistant\" as the beginning and end of sequence tokens.\nPreparation:\n\nThe dataset is cloned from TimDettmers, which itself is a subset of the Open Assistant dataset, which you can find here. This subset of the data only contains the highest-rated paths in the conversation tree, with a total of 9,846 samples.\nThe dataset was then slightly adjusted to:\n\n\nif a row of‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Trelis/openassistant-guanaco-EOS.","url":"https://huggingface.co/datasets/Trelis/openassistant-guanaco-EOS","creator_name":"Trelis","creator_url":"https://huggingface.co/Trelis","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["English","Spanish","Russian","German","Polish"],"keywords_longer_than_N":true},
	{"name":"xcopa","keyword":"italian","description":"\n\t\n\t\t\n\t\tDataset Card for \"xcopa\"\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\n  XCOPA: A Multilingual Dataset for Causal Commonsense Reasoning\nThe Cross-lingual Choice of Plausible Alternatives dataset is a benchmark to evaluate the ability of machine learning models to transfer commonsense reasoning across\nlanguages. The dataset is the translation and reannotation of the English COPA (Roemmele et al. 2011) and covers 11 languages from 11 families and several areas around\nthe globe. The dataset is‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/cambridgeltl/xcopa.","url":"https://huggingface.co/datasets/cambridgeltl/xcopa","creator_name":"Language Technology Lab @University of Cambridge","creator_url":"https://huggingface.co/cambridgeltl","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["question-answering","multiple-choice-qa","expert-generated","expert-generated","multilingual"],"keywords_longer_than_N":true},
	{"name":"Wikinews-multilingual","keyword":"italian","description":"\n\t\n\t\t\n\t\tWikinews - weakly aligned multilingual pararell sentence datasets\n\t\n\nThis dataset contains 15,200 multilingual WikiNews articles in 33 languages.\nOut of 15,200 articles, 9,960 are non-English news and 5240 are English news.  All non-English news are linked to one of 5240 English news. Linked articles show the same event.\nList of non-English languages are: Spanish, French, German, Portuguese, Polish, Italian, Chinese, Russian, Japanese, Dutch, Swedish, Tamil, Serbian, Czech, Catalan‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Fumika/Wikinews-multilingual.","url":"https://huggingface.co/datasets/Fumika/Wikinews-multilingual","creator_name":"Fumika Isono","creator_url":"https://huggingface.co/Fumika","license_name":"Creative Commons Attribution 2.5","license_url":"https://scancode-licensedb.aboutcode.org/cc-by-2.5.html","language":"en","first_N":5,"first_N_keywords":["text-classification","feature-extraction","English","Spanish","French"],"keywords_longer_than_N":true},
	{"name":"Trucks-Detection-Yolov8","keyword":"italian","description":"\n\t\n\t\t\n\t\tTrucks Detection - v1\n\t\n\nThis dataset was exported via roboflow.com on September 11, 2023 at 8:38 AM GMT\nRoboflow is an end-to-end computer vision platform that helps you\n\ncollaborate with your team on computer vision projects\ncollect & organize images\nunderstand and search unstructured image data\nannotate, and create datasets\nexport, train, and deploy computer vision models\nuse active learning to improve your dataset over time\n\nThe dataset includes 746 images.\nTrucks are annotated in‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/beethogedeon/Trucks-Detection-Yolov8.","url":"https://huggingface.co/datasets/beethogedeon/Trucks-Detection-Yolov8","creator_name":"Gedeon J. Gbedonou","creator_url":"https://huggingface.co/beethogedeon","license_name":"Creative Commons Attribution 3.0","license_url":"https://scancode-licensedb.aboutcode.org/cc-by-3.0.html","language":null,"first_N":5,"first_N_keywords":["object-detection","English","French","German","Italian"],"keywords_longer_than_N":true},
	{"name":"wikievo_qa","keyword":"italian","description":"Italian QA dataset based on this web page.\nThe wiki is a guide on how to use a product called Sicraweb, a software for italian public administration.\nThe qa are generated with gemini-1.5-flash using this prompt:\nChatPromptTemplate.from_messages([\n    ('system', '''\\\nSei un sistema che genera domande e risposte per la creazione di un dataset usato per validare un chatbot basato su RAG.\nTi verr√† passato un paragrafo e basandoti su quello, dovrai generare 5 domande e 5 risposte.\nInoltre ti verr√†‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/dr-naed/wikievo_qa.","url":"https://huggingface.co/datasets/dr-naed/wikievo_qa","creator_name":"Michele Faedi","creator_url":"https://huggingface.co/dr-naed","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["question-answering","Italian","cc-by-4.0","1K - 10K","parquet"],"keywords_longer_than_N":true},
	{"name":"multiconer_v2","keyword":"italian","description":"Complex named entities (NE), like the titles of creative works, are not simple nouns and pose challenges for NER systems (Ashwini and Choi, 2014). They can take the form of any linguistic constituent, like an imperative clause (‚ÄúDial M for Murder‚Äù), and do not look like traditional NEs (Persons, Locations, etc.). This syntactic ambiguity makes it challenging to recognize them based on context. We organized the MultiCoNER task (Malmasi et al., 2022) at SemEval-2022 to address these challenges in 11 languages, receiving a very positive community response with 34 system papers. Results confirmed the challenges of processing complex and long-tail NEs: even the largest pre-trained Transformers did not achieve top performance without external knowledge. The top systems infused transformers with knowledge bases and gazetteers. However, such solutions are brittle against out of knowledge-base entities and noisy scenarios like the presence of spelling mistakes and typos. We propose MultiCoNER II which represents novel challenges through new tasks that emphasize the shortcomings of the current top models.\n\nMultiCoNER II features complex NER in these languages:\n\n1. English\n2. Spanish\n3. Hindi\n4. Bangla\n5. Chinese\n6. Swedish\n7. Farsi\n8. French\n9. Italian\n10. Portugese\n11. Ukranian\n12. German\n\nFor more details see https://multiconer.github.io/\n\n## References\n* Sandeep Ashwini and Jinho D. Choi. 2014. Targetable named entity recognition in social media. CoRR, abs/1408.0782.\n* Shervin Malmasi, Anjie Fang, Besnik Fetahu, Sudipta Kar, Oleg Rokhlenko. 2022. SemEval-2022 Task 11: Multilingual Complex Named Entity Recognition (MultiCoNER).","url":"https://huggingface.co/datasets/MultiCoNER/multiconer_v2","creator_name":"MultiCoNER","creator_url":"https://huggingface.co/MultiCoNER","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["token-classification","Bengali","Chinese","German","English"],"keywords_longer_than_N":true},
	{"name":"mc4-sampling","keyword":"italian","description":"A sampling-enabled version of mC4, the colossal, cleaned version of Common Crawl's web crawl corpus.\n\nBased on Common Crawl dataset: \"https://commoncrawl.org\".\n\nThis is a version of the processed version of Google's mC4 dataset by AllenAI, in which sampling methods are implemented to perform on the fly.","url":"https://huggingface.co/datasets/bertin-project/mc4-sampling","creator_name":"BERTIN Project","creator_url":"https://huggingface.co/bertin-project","license_name":"Open Data Commons Attribution License v1.0","license_url":"https://scancode-licensedb.aboutcode.org/odc-by-1.0.html","language":null,"first_N":5,"first_N_keywords":["text-generation","fill-mask","language-modeling","no-annotation","found"],"keywords_longer_than_N":true},
	{"name":"xlel_wd","keyword":"italian","description":"XLEL-WD is a multilingual event linking dataset. This dataset contains mention references from multilingual Wikipedia/Wikinews articles to event items in Wikidata. The text descriptions for Wikidata events are compiled from Wikipedia articles.","url":"https://huggingface.co/datasets/adithya7/xlel_wd","creator_name":"Adithya Pratapa","creator_url":"https://huggingface.co/adithya7","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["found","found","multilingual","original","Afrikaans"],"keywords_longer_than_N":true},
	{"name":"opus_paracrawl","keyword":"italian","description":"\n\t\n\t\t\n\t\tDataset Card for OpusParaCrawl\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nParallel corpora from Web Crawls collected in the ParaCrawl project.\nTha dataset contains:\n\n42 languages, 43 bitexts\ntotal number of files: 59,996\ntotal number of tokens: 56.11G\ntotal number of sentence fragments: 3.13G\n\nTo load a language pair which isn't part of the config, all you need to do is specify the language code as pairs,\ne.g.\ndataset = load_dataset(\"opus_paracrawl\", lang1=\"en\", lang2=\"so\")\n\nYou can find the valid‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Helsinki-NLP/opus_paracrawl.","url":"https://huggingface.co/datasets/Helsinki-NLP/opus_paracrawl","creator_name":"Language Technology Research Group at the University of Helsinki","creator_url":"https://huggingface.co/Helsinki-NLP","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["translation","found","found","multilingual","original"],"keywords_longer_than_N":true},
	{"name":"panlex","keyword":"italian","description":"\n\t\n\t\t\n\t\tPanLex\n\t\n\nJanuary 1, 2024 version of PanLex Language Vocabulary with 24,650,274 rows covering 6,152 languages.\n\n\t\n\t\t\n\t\tColumns\n\t\n\n\nvocab: contains the text entry.  \n639-3: contains the ISO 639-3 languages tags to allow users to filter on the language(s) of their choice.\n639-3_english_name: the English language name associated to the code ISO 639-3. \nvar_code: contains a code to differentiate language variants. In practice, this is the code 639-3 + a number.  If 000, it corresponds to‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/lbourdois/panlex.","url":"https://huggingface.co/datasets/lbourdois/panlex","creator_name":"Lo√Øck BOURDOIS","creator_url":"https://huggingface.co/lbourdois","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["Ghotuo","Alumu-Tesu","Ari","Amal","Arb√´resh√´ Albanian"],"keywords_longer_than_N":true},
	{"name":"tatoeba-mt-all-in-one","keyword":"italian","description":"\n\t\n\t\t\n\t\tDataset Card for The Tatoeba Translation Challenge | All In One\n\t\n\n~7.3M entries.\nJust more user-friendly version that combines all of the entries of original dataset in a single file:\nhttps://huggingface.co/datasets/Helsinki-NLP/tatoeba_mt\n","url":"https://huggingface.co/datasets/0x22almostEvil/tatoeba-mt-all-in-one","creator_name":"David Glushkov","creator_url":"https://huggingface.co/0x22almostEvil","license_name":"Creative Commons Attribution 2.0","license_url":"https://scancode-licensedb.aboutcode.org/cc-by-2.0.html","language":"en","first_N":5,"first_N_keywords":["Helsinki-NLP","crowdsourced","translation","Helsinki-NLP/tatoeba_mt","Afrikaans"],"keywords_longer_than_N":true},
	{"name":"Pdf","keyword":"italian","description":"Decre99/Pdf dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/Decre99/Pdf","creator_name":"De","creator_url":"https://huggingface.co/Decre99","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["question-answering","Italian","mit","< 1K","text"],"keywords_longer_than_N":true},
	{"name":"tatoeba-mt-llama-only","keyword":"italian","description":"\n\t\n\t\t\n\t\tDataset Card for multilingual tatoeba translations with ~3M entries (llama supported languages only).\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\n~3M entries. Just more user-friendly version that combines all of the entries of original dataset in a single file (llama supported languages only):\nhttps://huggingface.co/datasets/Helsinki-NLP/tatoeba_mt\n","url":"https://huggingface.co/datasets/0x22almostEvil/tatoeba-mt-llama-only","creator_name":"David Glushkov","creator_url":"https://huggingface.co/0x22almostEvil","license_name":"Creative Commons Attribution 2.0","license_url":"https://scancode-licensedb.aboutcode.org/cc-by-2.0.html","language":"en","first_N":5,"first_N_keywords":["translation","English","Russian","German","Ukrainian"],"keywords_longer_than_N":true},
	{"name":"mswc_fscil_subset","keyword":"italian","description":"This is a subset of the Multilingual Spoken Word Corpus dataset, which is built specifically for the Few-shot Class-incremental Learning (FSCIL) task. \nA total of 15 languages are chosen, split into 5 base languages (English, German, Catalan, French, Kinyarwanda) and 10 incrementally learned languages (Persian, Spanish, Russian, Welsh, Italian, Basque, Polish, Esparanto, Portuguese, Dutch).\nThe FSCIL task entails first training a model using abundant training data on words from the 5 base‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/NeuroBench/mswc_fscil_subset.","url":"https://huggingface.co/datasets/NeuroBench/mswc_fscil_subset","creator_name":"NeuroBench","creator_url":"https://huggingface.co/NeuroBench","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["English","Spanish","Catalan","French","Kinyarwanda"],"keywords_longer_than_N":true},
	{"name":"tokenizer-wiki-bench","keyword":"italian","description":"\n\t\n\t\t\n\t\tMultilingual Tokenizer Benchmark\n\t\n\nThis dataset includes pre-processed wikipedia data for tokenizer evaluation in 45 languages. We provide more information on the evaluation task in general this blogpost.\n\n\t\n\t\t\n\t\tUsage\n\t\n\nThe dataset allows us to easily calculate tokenizer fertility and the proportion of continued words on any of the supported languages. In the example below we take the Mistral tokenizer and evaluate its performance on Slovak. \nfrom transformers import AutoTokenizer‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/occiglot/tokenizer-wiki-bench.","url":"https://huggingface.co/datasets/occiglot/tokenizer-wiki-bench","creator_name":"Occiglot","creator_url":"https://huggingface.co/occiglot","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["Afrikaans","Arabic","Bulgarian","Catalan","Czech"],"keywords_longer_than_N":true},
	{"name":"winogrande_italian","keyword":"italian","description":"\n\t\n\t\t\n\t\tWinogrande - Italian (IT)\n\t\n\nThis dataset is an Italian translation of Winogrande. Winogrande is a large-scale dataset for coreference resolution, commonsense reasoning, and world knowledge. It is based on the original Winograd Schema Challenge dataset.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\nThe dataset consists of almost 40K examples, each containing a sentence with a blank and two possible fill-in-the-blank options. The task is to choose the correct option that correctly fills in the blank based‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/s-conia/winogrande_italian.","url":"https://huggingface.co/datasets/s-conia/winogrande_italian","creator_name":"Simone Conia","creator_url":"https://huggingface.co/s-conia","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","Italian","English","apache-2.0","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"Regolo-Instruct_DATA-AI","keyword":"italian","description":"\n\t\n\t\t\n\t\tData\n\t\n\n\n{\n  \"messages\": [\n    {\"role\": \"system\", \"content\": \"<SYSTEM MESSAGE>\"},\n    {\"role\": \"user\", \"content\": \"<USER MESSAGE>\"},\n    {\"role\": \"assistant\", \"content\": \"<LLAMA3 RESPONSE>\"}\n  ],\n  \"category\": string,\n  \"usage\": {\n    \"prompt_tokens\": int,\n    \"total_tokens\": int,\n    \"completion_tokens\": int,\n    \"prompt_tokens_details\": obj\n  },\n  \"time\": time (s),\n  \"model\": \"Mattimax/DATA-AI_Chat_0.5B\"\n}\n\n\n\t\n\t\t\n\t\n\t\n\t\tPurpose of the Dataset\n\t\n\nThis dataset is provided under the‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Mattimax/Regolo-Instruct_DATA-AI.","url":"https://huggingface.co/datasets/Mattimax/Regolo-Instruct_DATA-AI","creator_name":"M.INC.","creator_url":"https://huggingface.co/Mattimax","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","Italian","apache-2.0","10K - 100K","json"],"keywords_longer_than_N":true},
	{"name":"CommonPhoneDataset","keyword":"italian","description":"\n\t\n\t\t\n\t\tDataset Card for Common Phone\n\t\n\nThis corpus aims to provide a basis for Machine Learning (ML) researchers and enthusiasts to train and test their models against a wide variety of speakers, hardware/software ecosystems and acoustic conditions to improve generalization and availability of ML in real-world speech applications.\nThe current version of Common Phone comprises 116,5 hours of speech samples, collected from 11.246 speakers in 6 languages.\nCommon Phone has been used as the‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/pklumpp/CommonPhoneDataset.","url":"https://huggingface.co/datasets/pklumpp/CommonPhoneDataset","creator_name":"Philipp Klumpp","creator_url":"https://huggingface.co/pklumpp","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","English","German","French","Italian"],"keywords_longer_than_N":true},
	{"name":"voxpopolo_2","keyword":"italian","description":"A large-scale multilingual speech corpus for representation learning, semi-supervised learning and interpretation.","url":"https://huggingface.co/datasets/mcapozi/voxpopolo_2","creator_name":"Matteo Capozi","creator_url":"https://huggingface.co/mcapozi","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":null,"first_N":5,"first_N_keywords":["automatic-speech-recognition","multilingual","English","German","French"],"keywords_longer_than_N":true},
	{"name":"italian-embedding-finetune-dataset","keyword":"italian","description":"\n\t\n\t\t\n\t\tItalian-BERT-FineTuning-Embeddings\n\t\n\nThis repository contains a comprehensive dataset designed for fine-tuning BERT-based Italian embedding models. The dataset aims to enhance performance on tasks such as information retrieval, semantic search, and embeddings generation.\n\n\n\t\n\t\t\n\t\tDataset Overview\n\t\n\nThis dataset leverages the C4 dataset (Italian subset) and employs advanced techniques like sliding window segmentation and in-document sampling to create high-quality, diverse examples‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ArchitRastogi/italian-embedding-finetune-dataset.","url":"https://huggingface.co/datasets/ArchitRastogi/italian-embedding-finetune-dataset","creator_name":"Archit Rastogi","creator_url":"https://huggingface.co/ArchitRastogi","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","question-answering","Italian","apache-2.0","10M - 100M"],"keywords_longer_than_N":true},
	{"name":"italian-embedding-finetune-dataset","keyword":"italian","description":"\n\t\n\t\t\n\t\tItalian-BERT-FineTuning-Embeddings\n\t\n\nThis repository contains a comprehensive dataset designed for fine-tuning BERT-based Italian embedding models. The dataset aims to enhance performance on tasks such as information retrieval, semantic search, and embeddings generation.\n\n\n\t\n\t\t\n\t\tDataset Overview\n\t\n\nThis dataset leverages the C4 dataset (Italian subset) and employs advanced techniques like sliding window segmentation and in-document sampling to create high-quality, diverse examples‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ArchitRastogi/italian-embedding-finetune-dataset.","url":"https://huggingface.co/datasets/ArchitRastogi/italian-embedding-finetune-dataset","creator_name":"Archit Rastogi","creator_url":"https://huggingface.co/ArchitRastogi","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","question-answering","Italian","apache-2.0","10M - 100M"],"keywords_longer_than_N":true},
	{"name":"ItaIst-laws","keyword":"italian","description":"\n\t\n\t\t\n\t\tCorpus ItaIst-laws\n\t\n\nThe corpus containing 351 excerpts of legal references that was collected by the research unit of the University of Molise including linguists (Giuliana Fiorentino, Vittorio Ganfi), jurists (Alessandro Cioffi, Maria Assunta Simonelli, Ludovico Di Benedetto) and computer scientists (Rocco Oliveto, Marco Russodivito).\nThe corpus includes legal references from Italian and European laws, covering \"garbage\", \"healthcare\", and \"public services\" topics.‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/VerbACxSS/ItaIst-laws.","url":"https://huggingface.co/datasets/VerbACxSS/ItaIst-laws","creator_name":"VerbACxSS","creator_url":"https://huggingface.co/VerbACxSS","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-generation","Italian","mit","< 1K","csv"],"keywords_longer_than_N":true},
	{"name":"clic-it_corpus","keyword":"italian","description":"\n\t\n\t\t\n\t\tCLiC-it Corpus\n\t\n\nThis repository contains the CLiC-it Corpus, a structured dataset of all the papers presented at the CLiC-it conferences from 2014 to 2024.\nThe dataset is part of the paper Charting a Decade of Computational Linguistics in Italy: The CLiC-it Corpus. If you use this dataset in your work, we kindly ask you to cite our paper:\n@article{alzetta2025charting,\n  title={Charting a Decade of Computational Linguistics in Italy: The CLiC-it Corpus},\n  author={Alzetta, Chiara and‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/alemiaschi/clic-it_corpus.","url":"https://huggingface.co/datasets/alemiaschi/clic-it_corpus","creator_name":"Alessio Miaschi","creator_url":"https://huggingface.co/alemiaschi","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["Italian","English","mit","< 1K","csv"],"keywords_longer_than_N":true},
	{"name":"ApolloMoEBench","keyword":"italian","description":"\n\t\n\t\t\n\t\tDemocratizing Medical LLMs For Much More Languages\n\t\n\nCovering 12 Major Languages including English, Chinese, French, Hindi, Spanish, Arabic, Russian, Japanese, Korean, German, Italian, Portuguese and 38 Minor Languages So far.\n\n   üìÉ Paper ‚Ä¢ üåê Demo ‚Ä¢ ü§ó ApolloMoEDataset ‚Ä¢ ü§ó ApolloMoEBench  ‚Ä¢ ü§ó Models  ‚Ä¢üåê Apollo  ‚Ä¢ üåê ApolloMoE\n\n\n\n\n\n\n\t\n\t\t\n\t\tüåà Update\n\t\n\n\n[2024.10.15] ApolloMoE repo is publishedÔºÅüéâ\n\n\n\t\n\t\t\n\t\tLanguages Coverage\n\t\n\n12 Major Languages and 38 Minor Languages\n\n  Click to‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/FreedomIntelligence/ApolloMoEBench.","url":"https://huggingface.co/datasets/FreedomIntelligence/ApolloMoEBench","creator_name":"FreedomAI","creator_url":"https://huggingface.co/FreedomIntelligence","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["question-answering","Arabic","English","Chinese","Korean"],"keywords_longer_than_N":true},
	{"name":"Vulpisfoglia","keyword":"italian","description":"None1145/Vulpisfoglia dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/None1145/Vulpisfoglia","creator_name":"None","creator_url":"https://huggingface.co/None1145","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["audio-to-audio","text-to-speech","Chinese","Japanese","Italian"],"keywords_longer_than_N":true},
	{"name":"translation_latin_to_italian","keyword":"italian","description":"Dddixyy/translation_latin_to_italian dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/Dddixyy/translation_latin_to_italian","creator_name":"Davide Brunori","creator_url":"https://huggingface.co/Dddixyy","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["translation","Latin","Italian","mit","< 1K"],"keywords_longer_than_N":true},
	{"name":"Synthdog-Multilingual-100","keyword":"italian","description":"\n\t\n\t\t\n\t\tSynthdog Multilingual\n\t\n\n\n\nThe Synthdog dataset created for training in Centurio: On Drivers of Multilingual Ability of Large Vision-Language Model.\nUsing the official Synthdog code, we created >1 million training samples for improving OCR capabilities in Large Vision-Language Models.\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Details\n\t\n\nWe provide the images for download in two .tar.gz files. Download and extract them in folders of the same name (so cat images.tar.gz.* | tar xvzf -C images; tar xvzf‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/WueNLP/Synthdog-Multilingual-100.","url":"https://huggingface.co/datasets/WueNLP/Synthdog-Multilingual-100","creator_name":"W√ºNLP","creator_url":"https://huggingface.co/WueNLP","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["image-to-text","multilingual","Afrikaans","Amharic","Arabic"],"keywords_longer_than_N":true},
	{"name":"truthdetection","keyword":"italian","description":"sangambhamare/truthdetection dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/sangambhamare/truthdetection","creator_name":"Sangam Bhamare","creator_url":"https://huggingface.co/sangambhamare","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["audio-classification","English","Marathi","Hindi","French"],"keywords_longer_than_N":true},
	{"name":"multilingual-queries-for-collected-works-of-milton-h-erickson","keyword":"italian","description":"\n\t\n\t\t\n\t\tMultilingual Queries for the Collected Works of Milton H. Erickson\n\t\n\nThis collection contains machine-generated and translated queries designed to evaluate the performance of a multilingual retriever adapted to Ericksonian terminology.\nTo create the queries, the Collected Works of Milton H. Erickson was segmented into 500-word samples. Also, a list of relevant keywords was extracted from the Glossary of Ericksonian Terminology. Using the samples and keywords, queries were generated by‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/LoneWolfgang/multilingual-queries-for-collected-works-of-milton-h-erickson.","url":"https://huggingface.co/datasets/LoneWolfgang/multilingual-queries-for-collected-works-of-milton-h-erickson","creator_name":"Jordan Wolfgang Klein","creator_url":"https://huggingface.co/LoneWolfgang","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["translation","English","Portuguese","Japanese","Chinese"],"keywords_longer_than_N":true},
	{"name":"italian-dataset-mini","keyword":"italian","description":"\n\t\n\t\t\n\t\titalian-dataset-mini\n\t\n\nCreator: ruslanmv\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nitalian-dataset-mini √® un dataset creato fondendo diverse fonti di testo in italiano, tra cui contenuti presi da Wikipedia in italiano. Il dataset √® stato formattato utilizzando un formato delimiter-based, ideale per attivit√† di instruction tuning e modelli di linguaggio che richiedono coppie istruzione-risposta. \nOgni esempio nel dataset √® strutturato in una singola colonna di testo e, a seconda della fonte originale‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ruslanmv/italian-dataset-mini.","url":"https://huggingface.co/datasets/ruslanmv/italian-dataset-mini","creator_name":"Ruslan Magana Vsevolodovna","creator_url":"https://huggingface.co/ruslanmv","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["Italian","mit","1M - 10M","arrow","Text"],"keywords_longer_than_N":true},
	{"name":"GNR-it","keyword":"italian","description":"\n\t\n\t\t\n\t\tGNR-it Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThe GNR-it dataset contains pairs of gendered and gender-neutral Italian sentences.\nWe release this dataset to ensure reproducibility of the experiments in the paper Gender-Neutral Rewriting in Italian: Models, Approaches, and Trade-offs, accepted at CLiC-it 2025.\nThe dataset is derived from the data originally created to train the gender-neutrality classifier GeNTE-evaluator.\nThe creation and curation of the original dataset is described in the‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/FBK-MT/GNR-it.","url":"https://huggingface.co/datasets/FBK-MT/GNR-it","creator_name":"FBK-MT","creator_url":"https://huggingface.co/FBK-MT","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","text-generation","Italian","cc-by-4.0","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"Italian_latin_parallel_animals","keyword":"italian","description":"\n\t\n\t\t\n\t\tdescrizioni di animali e habitat - Synthetic Dataset\n\t\n\nThis dataset was generated using the Synthetic Dataset Generator powered by Gemini AI.\n\nTopic: descrizioni di animali e habitat\nField 1: italiano\nField 2: latino antico(traduzione)\nRows: 280\n\nGenerated on: 2025-05-27T00:07:49.042Z\n","url":"https://huggingface.co/datasets/Dddixyy/Italian_latin_parallel_animals","creator_name":"Davide Brunori","creator_url":"https://huggingface.co/Dddixyy","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-generation","Italian","Latin","mit","< 1K"],"keywords_longer_than_N":true},
	{"name":"multilingual-coco","keyword":"italian","description":"\n\t\n\t\t\n\t\tMultilingual Common Objects in Context (COCO) Dataset\n\t\n\nThis dataset is a collection of multiple language open-source captions of COCO dataset. \nThe split in this dataset is set according to Andrej Karpathy's split from dataset_coco.json file. The collection was created specifically for simplicity of use in training and evaluation pipeline by non-commercial and research purposes. The COCO images dataset is licensed under a Creative Commons Attribution 4.0 License.‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/romrawinjp/multilingual-coco.","url":"https://huggingface.co/datasets/romrawinjp/multilingual-coco","creator_name":"Romrawin Chumpu","creator_url":"https://huggingface.co/romrawinjp","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["image-to-text","English","Thai","Russian","Japanese"],"keywords_longer_than_N":true},
	{"name":"Fusion_Ita_Datasets","keyword":"italian","description":"\n\t\n\t\t\n\t\tüìö Mattimax/Fusion_Ita_Datasets\n\t\n\n\n\t\n\t\t\n\t\tüìå Descrizione\n\t\n\nMattimax/Fusion_Ita_Datasets √® un dataset in italiano ottenuto dalla fusione, pulizia e normalizzazione di sei dataset pubblici di conversazioni e istruzioni, pensato per l‚Äôaddestramento di modelli di linguaggio in italiano.  \nInclude dati di alta qualit√† da QA, conversazioni multi-turno, domande in stile Quora e StackOverflow, filtrati per lingua e deduplicati per garantire coerenza e ridurre il rumore.\n\n\n\t\n\t\t\n\t\n\t\n\t\tüõ†‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Mattimax/Fusion_Ita_Datasets.","url":"https://huggingface.co/datasets/Mattimax/Fusion_Ita_Datasets","creator_name":"M.INC.","creator_url":"https://huggingface.co/Mattimax","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","question-answering","Italian","apache-2.0","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"MultiQ","keyword":"italian","description":"\n\t\n\t\t\n\t\tDataset Card for MultiQ\n\t\n\nThis is the dataset corresponding to the paper \"Evaluating the Elementary Multilingual Capabilities of Large Language Models with MultiQ\". \nIt is a silver standard benchmark that can be used to evaluate the basic multilingual capabilities of LLMs. It contains 200 open ended questions automatically \ntranslated into 137 typologically diverse languages. \n\nCurated by: Carolin Holtermann, Paul R√∂ttger, Timm Dill, Anne Lauscher\nLanguage(s) (NLP): 137 diverse‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/caro-holt/MultiQ.","url":"https://huggingface.co/datasets/caro-holt/MultiQ","creator_name":"Holtermann","creator_url":"https://huggingface.co/caro-holt","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["question-answering","Tagalog","Samoan","Macedonian","Gujarati"],"keywords_longer_than_N":true},
	{"name":"SyntacticAgreement","keyword":"italian","description":"\n\t\n\t\t\n\t\tSyntacticAgreement\n\t\n\nThis dataset provides manually curated syntactic agreement test suites for four morphologically rich languages: Italian, Spanish, Portuguese, and Russian.It is designed to evaluate the ability of neural language models to capture hierarchical syntactic dependencies, with a focus on agreement phenomena that go beyond English subject‚Äìverb agreement.\nThis dataset is designed for targeted syntactic evaluation, which does not fit standard supervised NLP tasks. For this‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/albalbalba/SyntacticAgreement.","url":"https://huggingface.co/datasets/albalbalba/SyntacticAgreement","creator_name":"alba taboas","creator_url":"https://huggingface.co/albalbalba","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":null,"first_N":5,"first_N_keywords":["other","expert-generated","Spanish","Italian","Portuguese"],"keywords_longer_than_N":true},
	{"name":"OGC_Nuclear","keyword":"italian","description":"\n\t\n\t\t\n\t\tOGC_Nuclear - Overview\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nOGC_Nuclear is a curated multimodal dataset focused on nuclear technical documents, regulations, and legal frameworks. It combines text and image data extracted from real scientific and regulatory PDFs to support tasks such as RAG DSE, question answering, document search, and vision-language model training.\n\n\t\n\t\t\n\t\tDataset Creation\n\t\n\nThis dataset was created using our open-source tool OGC_pdf-to-parquet.\nNuclear-related PDFs were‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/racineai/OGC_Nuclear.","url":"https://huggingface.co/datasets/racineai/OGC_Nuclear","creator_name":"racine.ai","creator_url":"https://huggingface.co/racineai","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["question-answering","visual-question-answering","text-retrieval","English","French"],"keywords_longer_than_N":true},
	{"name":"JQL-Human-Edu-Annotations","keyword":"italian","description":"\n\t\n\t\t\n\t\tüìö JQL Multilingual Educational Quality Annotations\n\t\n\nThis dataset provides high-quality human annotations for evaluating the educational value of web documents, and serves as a benchmark for training and evaluating multilingual LLM annotators as described in the JQL paper.\n\n\n\t\n\t\t\n\t\tüìù Dataset Summary\n\t\n\n\nDocuments: 511 English texts  \nAnnotations: 3 human ratings per document (0‚Äì5 scale)  \nTranslations: Into 35 European languages using DeepL and GPT-4o  \nPurpose: For training and‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/JQL-AI/JQL-Human-Edu-Annotations.","url":"https://huggingface.co/datasets/JQL-AI/JQL-Human-Edu-Annotations","creator_name":"JQL-AI","creator_url":"https://huggingface.co/JQL-AI","license_name":"Open Data Commons Attribution License v1.0","license_url":"https://scancode-licensedb.aboutcode.org/odc-by-1.0.html","language":"en","first_N":5,"first_N_keywords":["text-classification","Bulgarian","Czech","Croatian","Macedonian"],"keywords_longer_than_N":true},
	{"name":"OGC_Qualitative","keyword":"italian","description":"\n\t\n\t\t\n\t\tOGC_Qualitative\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nOGC_Qualitative is a high-quality multimodal dataset created through the merge of multiple domain-specific datasets with enhanced data processing techniques. This dataset represents our most refined approach to multimodal data generation, incorporating filtering algorithms and improved AI-assisted content generation to deliver superior quality for RAG, DSE, question answering, document search, and vision-language model training tasks.‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/racineai/OGC_Qualitative.","url":"https://huggingface.co/datasets/racineai/OGC_Qualitative","creator_name":"racine.ai","creator_url":"https://huggingface.co/racineai","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["question-answering","visual-question-answering","text-retrieval","English","French"],"keywords_longer_than_N":true},
	{"name":"language-dataset","keyword":"italian","description":"\n","url":"https://huggingface.co/datasets/neon-mao/language-dataset","creator_name":"maoqifan","creator_url":"https://huggingface.co/neon-mao","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","English","Chinese","French","Russian"],"keywords_longer_than_N":true},
	{"name":"ToxicCommons","keyword":"italian","description":"\n\t\n\t\t\n\t\tToxic Commons\n\t\n\nToxic Commons is a release of 2 million samples of annotated, public domain, multilingual text that was used to train Celadon. \nIt is being released alongside Celadon, in order to better understand multilingual and multicultural toxicity. \nEach sample was classified across 5 axes of toxicity:\n\nRace and origin-based bias: includes racism as well as bias against someone‚Äôs country or region of origin or immigration status, especially immigrant or refugee status. \nGender‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/PleIAs/ToxicCommons.","url":"https://huggingface.co/datasets/PleIAs/ToxicCommons","creator_name":"PleIAs","creator_url":"https://huggingface.co/PleIAs","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","English","French","Spanish","German"],"keywords_longer_than_N":true},
	{"name":"ITALIC","keyword":"italian","description":"\n\t\n\t\t\n\t\tDataset Card for ITALIC\n\t\n\n\n\nITALIC is a benchmark evaluating language models' understanding of Italian culture, commonsense reasoning and linguistic proficiency in a morphologically rich language.\n\n\nAbove are example questions from ITALIC. Note: every example is a direct translation; the original questions\nare in Italian. The correct option is marked by (‚úì).\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Description\n\t\n\n\n\nWe present ITALIC, a large-scale benchmark dataset of 10,000‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Crisp-Unimib/ITALIC.","url":"https://huggingface.co/datasets/Crisp-Unimib/ITALIC","creator_name":"Interuniversity Research Centre for Public Services","creator_url":"https://huggingface.co/Crisp-Unimib","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["question-answering","Italian","mit","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"MultiPICo","keyword":"italian","description":"\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nMultiPICo (Multilingual Perspectivist Irony Corpus) is a disaggregated multilingual corpus for irony detection, containing 18,778 pairs of short conversations (post-reply) from Twitter (8,956) and Reddit (9,822), along with the demographic information of each annotator (age, nationality, gender, and so on). \n\n\t\n\t\t\n\t\tSupported Tasks and Leaderboards\n\t\n\nIrony classification task using soft labels (i.e., distribution of annotations) or hard labels (i.e., aggregated‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Multilingual-Perspectivist-NLU/MultiPICo.","url":"https://huggingface.co/datasets/Multilingual-Perspectivist-NLU/MultiPICo","creator_name":"MultilingualPerspectivistNLU","creator_url":"https://huggingface.co/Multilingual-Perspectivist-NLU","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["Spanish","English","German","Arabic","Portuguese"],"keywords_longer_than_N":true},
	{"name":"multilingual_translation_sft","keyword":"italian","description":"Youseff1987/multilingual_translation_sft dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/Youseff1987/multilingual_translation_sft","creator_name":"JOON HYOUNG JUN","creator_url":"https://huggingface.co/Youseff1987","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["translation","Korean","English","Chinese","Zulu"],"keywords_longer_than_N":true},
	{"name":"finepdfs-summaries","keyword":"italian","description":"\n\t\n\t\t\n\t\tfinepdfs-summaries\n\t\n\nSummaries generated with Qwen3-Next-80B-A3B-Instruct for documents from finepdfs.\nWork in progress, still generating more data.\nThe following table shows the size for each language:\n\n\t\n\t\t\nLanguage\nSummaries\nTokens\nDisk size\n\n\n\t\t\nAll\n764,482,142\n224 B\n336 GB\n\n\ndeu_Latn\n343,089,235\n106 B\n141 GB\n\n\neng_Latn\n321,343,046\n81 B\n150 GB\n\nfra_Latn\n27,308,302\n10 B\n14 GB\n\n\nspa_Latn\n25,624,727\n9 B\n12 GB\n\n\nita_Latn\n17,587,618\n6 B\n8 GB\n\n\npor_Latn\n12,043,607\n4 B\n5 GB\n\n\npol_Latn\n9‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/maxidl/finepdfs-summaries.","url":"https://huggingface.co/datasets/maxidl/finepdfs-summaries","creator_name":"Max Idahl","creator_url":"https://huggingface.co/maxidl","license_name":"Open Data Commons Attribution License v1.0","license_url":"https://scancode-licensedb.aboutcode.org/odc-by-1.0.html","language":"en","first_N":5,"first_N_keywords":["text-generation","summarization","English","German","French"],"keywords_longer_than_N":true},
	{"name":"mtg-cards-SIFT-Features","keyword":"italian","description":"\n\t\n\t\t\n\t\tMTG Card SIFT Features Dataset (v5.1)\n\t\n\n\nThis dataset contains the latest incremental MTG card SIFT + RootSIFT feature extraction pipeline. It is designed for server-side production inference, enabling additive updates to the FAISS index and id_map.json without retraining or reindexing from scratch.\n\nNote: This version aligns with a daily resources-nightly.zip Hugging Face upload workflow for reliable continuous deployment via my production server.\n\n\n\n\t\n\t\n\t\n\t\tWhat‚Äôs New in v5.1?‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/JakeTurner616/mtg-cards-SIFT-Features.","url":"https://huggingface.co/datasets/JakeTurner616/mtg-cards-SIFT-Features","creator_name":"Jake Turner","creator_url":"https://huggingface.co/JakeTurner616","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":null,"first_N":5,"first_N_keywords":["feature-extraction","English","French","German","Italian"],"keywords_longer_than_N":true},
	{"name":"YouTube-Commons-descriptions","keyword":"italian","description":"\n\t\n\t\t\n\t\tYouTube Commons Descriptions and Language Detection\n\t\n\nThis dataset adds titles, descriptions and language detection to YouTube Commons, a valuable open dataset:\n\nYouTube-Commons is a collection of audio transcripts of 2,063,066 videos shared on YouTube under a CC BY 4.0 license.\nContent\nThe collection comprises 22,709,724 original and automatically translated transcripts from 3,156,703 videos (721,136 individual channels).\n\nUnfortunately I have found that the detection of the original‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Rijgersberg/YouTube-Commons-descriptions.","url":"https://huggingface.co/datasets/Rijgersberg/YouTube-Commons-descriptions","creator_name":"Edwin Rijgersberg","creator_url":"https://huggingface.co/Rijgersberg","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["English","French","Spanish","Portuguese","German"],"keywords_longer_than_N":true},
	{"name":"ericksonian-terminology-multilingual","keyword":"italian","description":"\n\t\n\t\t\n\t\tMultilingual Glossary of Ericksonian Terminology\n\t\n\nThis dataset was created to evaluate the performance of a multilingual sentence encoder adapted to Ericksonian terminology.\nThe International Glossary of Ericksonian Terminology was developed to promote consistent language use among Ericksonian practitioners worldwide.\nEach entry in the glossary reflects the consensus of three native-speaking translators who also study Ericksonian methodology.\nLanguage Teams:\n\nEnglish: Roxanna‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/LoneWolfgang/ericksonian-terminology-multilingual.","url":"https://huggingface.co/datasets/LoneWolfgang/ericksonian-terminology-multilingual","creator_name":"Jordan Wolfgang Klein","creator_url":"https://huggingface.co/LoneWolfgang","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["translation","English","Spanish","Portuguese","French"],"keywords_longer_than_N":true},
	{"name":"wikipedia_quality_wikirank","keyword":"italian","description":"Datasets with WikiRank quality score as of 1 August 2024 for 47 million Wikipedia articles in 55 language versions (also simplified version for each language in separate files).\nThe WikiRank quality score is a metric designed to assess the overall quality of a Wikipedia article. Although its specific algorithm can vary depending on the implementation, the score typically combines several key features of the Wikipedia article.\n\n\t\n\t\t\n\t\n\t\n\t\tWhy It‚Äôs Important\n\t\n\n\nEnhances Trust: For readers and‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/lewoniewski/wikipedia_quality_wikirank.","url":"https://huggingface.co/datasets/lewoniewski/wikipedia_quality_wikirank","creator_name":"W≈Çodzimierz Lewoniewski","creator_url":"https://huggingface.co/lewoniewski","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["Arabic","Azerbaijani","Belarusian","Bulgarian","Catalan"],"keywords_longer_than_N":true},
	{"name":"msvamp_it","keyword":"italian","description":"lrana/msvamp_it dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/lrana/msvamp_it","creator_name":"Leonardo","creator_url":"https://huggingface.co/lrana","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","question-answering","text-generation","Italian","English"],"keywords_longer_than_N":true},
	{"name":"pinocchio","keyword":"italian","description":"\n\t\n\t\t\n\t\tDataset Card\n\t\n\nPinocchio is a comprehensive and challenging Natural Language Understanding (NLU) dataset designed to rigorously evaluate language models' capabilities, with a particular focus on Italian language, culture, and various specialized domains.\n\n\n\n\n\nüìñPaper (maybe soon)\n\n[2024.07.16] Pinocchio dataset released, featuring ~140,000 questions across modalities and ~40 disciplines.\n\n\n\t\n\t\n\t\n\t\t1. What's unique about Pinocchio?\n\t\n\nCompared to other NLU datasets, Pinocchio offers‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mii-llm/pinocchio.","url":"https://huggingface.co/datasets/mii-llm/pinocchio","creator_name":"mii-llm","creator_url":"https://huggingface.co/mii-llm","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["question-answering","Italian","English","apache-2.0","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"fineweb-2","keyword":"italian","description":"\n\t\n\t\t\n\t\tü•Ç FineWeb2\n\t\n\n\n    \n\n\n\nA sparkling update with 1000s of languages\n\n\n\t\n\t\t\n\t\tWhat is it?\n\t\n\nThis is the second iteration of the popular üç∑ FineWeb dataset, bringing high quality pretraining data to over 1000 üó£Ô∏è languages.\nThe ü•Ç FineWeb2 dataset is fully reproducible, available under the permissive ODC-By 1.0 license and extensively validated through hundreds of ablation experiments.\nIn particular, on the set of 9 diverse languages we used to guide our processing decisions, ü•Ç FineWeb2‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/HuggingFaceFW/fineweb-2.","url":"https://huggingface.co/datasets/HuggingFaceFW/fineweb-2","creator_name":"FineData","creator_url":"https://huggingface.co/HuggingFaceFW","license_name":"Open Data Commons Attribution License v1.0","license_url":"https://scancode-licensedb.aboutcode.org/odc-by-1.0.html","language":"en","first_N":5,"first_N_keywords":["text-generation","Arifama-Miniafia","Ankave","Abau","Amarasi"],"keywords_longer_than_N":true},
	{"name":"panlex-definitions","keyword":"italian","description":"\n\t\n\t\t\n\t\tDataset Card for panlex-definitions\n\t\n\nThis is a dataset of word definitions in several hudnred languages, extracted from https://panlex.org.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset has been extracted from https://panlex.org (the 20250201 database dump) and rearranged on the per-language basis (by the language of the definition).\nEach language subset consists of definitions (short phrases).\nEach definition is associated with some meanings (if there is‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/cointegrated/panlex-definitions.","url":"https://huggingface.co/datasets/cointegrated/panlex-definitions","creator_name":"David Dale","creator_url":"https://huggingface.co/cointegrated","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["translation","Abkhazian","Hijazi Arabic","Afrikaans","Ainu (Japan)"],"keywords_longer_than_N":true},
	{"name":"common_voice_21_0","keyword":"italian","description":"Due to storage limits some files had to be split into multiple parts. They can be merged like this: cat file.* > file.\n","url":"https://huggingface.co/datasets/2Jyq/common_voice_21_0","creator_name":"2Jyq","creator_url":"https://huggingface.co/2Jyq","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["crowdsourced","crowdsourced","multilingual","extended|common_voice","Abkhaz"],"keywords_longer_than_N":true},
	{"name":"MELA","keyword":"italian","description":"See the GitHub repo for details.\n","url":"https://huggingface.co/datasets/Geralt-Targaryen/MELA","creator_name":"Ziyin Zhang","creator_url":"https://huggingface.co/Geralt-Targaryen","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","English","Chinese","Italian","Russian"],"keywords_longer_than_N":true},
	{"name":"ai2_arc_ita","keyword":"italian","description":"\n\t\n\t\t\n\t\tDataset Card for Ai2 ARC (ita)\n\t\n\n\n\nThis dataset is a machine-translated version of Ai2 ARC into Italian.\n\nLicensed under CC-BY 4.0\nTranslated with TowerInstruct-7B-v0.2\nMore details and code used for translation will follow shortly.\n\nThe rest of the page is WIP :)\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Description\n\t\n\n\n\n\n\nCurated by: [More Information Needed]\nFunded by [optional]: [More Information Needed]\nShared by [optional]: [More Information Needed]\nLanguage(s) (NLP):‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/RiTA-nlp/ai2_arc_ita.","url":"https://huggingface.co/datasets/RiTA-nlp/ai2_arc_ita","creator_name":"Risorse per la Lingua Italiana","creator_url":"https://huggingface.co/RiTA-nlp","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["question-answering","open-domain-qa","multiple-choice-qa","monolingual","Italian"],"keywords_longer_than_N":true},
	{"name":"R3-eval-MMMLU","keyword":"italian","description":"HLeiTR/R3-eval-MMMLU dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/HLeiTR/R3-eval-MMMLU","creator_name":"Shou-Yi Hung","creator_url":"https://huggingface.co/HLeiTR","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["question-answering","Arabic","Bengali","German","Spanish"],"keywords_longer_than_N":true},
	{"name":"PolyGuardPrompts","keyword":"italian","description":"\n\t\n\t\t\n\t\tPolyGuard: A Multilingual Safety Moderation Tool for 17 Languages\n\t\n\nAbstract: Truly multilingual safety moderation efforts for Large Language Models (LLMs) have been hindered by a narrow focus on a small set of languages (e.g., English, Chinese) as well as a limited scope of safety definition, resulting in significant gaps in moderation capabilities. To bridge these gaps, we release PolyGuard, a new state-of-the-art multilingual safety model for safeguarding LLM generations, and the‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ToxicityPrompts/PolyGuardPrompts.","url":"https://huggingface.co/datasets/ToxicityPrompts/PolyGuardPrompts","creator_name":"ToxicityPrompts","creator_url":"https://huggingface.co/ToxicityPrompts","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["Arabic","Chinese","Czech","Dutch","English"],"keywords_longer_than_N":true},
	{"name":"claude-reviewed-sport-sustainability-papers","keyword":"italian","description":"\n\t\n\t\t\n\t\tClaude Reviewed Sport Sustainability Papers\n\t\n\n\n\t\n\t\t\n\t\tDataset description\n\t\n\nThis dataset encompasses 16 papers (some of them divided in several parts) related to the sustainability of sports products and brands. \nThis information lies at the core of our application and will come into more intesive use with the next release of GreenFit AI. \nThe papers were analysed with Claude 3.5 Sonnet (claude-3-5-sonnet-20241022) and they were translated into:\n\nTheir title (or a Claude-inferred‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/greenfit-ai/claude-reviewed-sport-sustainability-papers.","url":"https://huggingface.co/datasets/greenfit-ai/claude-reviewed-sport-sustainability-papers","creator_name":"GreenFit AI","creator_url":"https://huggingface.co/greenfit-ai","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["English","Italian","mit","< 1K","csv"],"keywords_longer_than_N":true},
	{"name":"GlobalDISCO","keyword":"italian","description":"\n\t\n\t\t\n\t\tGlobalDISCO\n\t\n\nGlobalDISCO is a large-scale dataset consisting of 73k music tracks generated by state-of-the-art commercial generative music models, along with paired links to 93k reference tracks in LAION-DISCO-12M. The dataset spans 147 languages and includes musical style prompts extracted from MusicBrainz and Wikipedia. The dataset is globally balanced, representing musical styles from artists across 79 countries and five continents. It is aimed to support the research community in‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/disco-eth/GlobalDISCO.","url":"https://huggingface.co/datasets/disco-eth/GlobalDISCO","creator_name":"DISCO","creator_url":"https://huggingface.co/disco-eth","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["audio-classification","English","Spanish","French","German"],"keywords_longer_than_N":true},
	{"name":"TransWebEdu","keyword":"italian","description":"\n\t\n\t\t\n\t\tTransWebEdu\n\t\n\nTransWebEdu is a machine-translated, multi-way parallel, multilingual dataset at pretrain scale, supporting ten languages: Arabic, Welsh, German, English, Spanish, French, Indonesian, Italian, Russian, and Swahili.It is used to pretrain the TransWebLLM model from scratch, with a focus on multilingual web-based education content.\nFor more information, see the paper:Multilingual Language Model Pretraining using Machine-translated Data\n\n\t\n\t\t\n\t\n\t\n\t\tLanguages Supported‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/britllm/TransWebEdu.","url":"https://huggingface.co/datasets/britllm/TransWebEdu","creator_name":"BritLLM","creator_url":"https://huggingface.co/britllm","license_name":"Open Data Commons Attribution License v1.0","license_url":"https://scancode-licensedb.aboutcode.org/odc-by-1.0.html","language":null,"first_N":5,"first_N_keywords":["Arabic","Welsh","English","Spanish","French"],"keywords_longer_than_N":true},
	{"name":"multilingual-wealth-alpaca","keyword":"italian","description":"\n\t\n\t\t\n\t\n\t\n\t\tMultilingual Wealth Alpaca Dataset\n\t\n\n\nWork derivative of gbharti/wealth-alpaca_lora dataset. The original dataset is a combination of Stanford's Alpaca (https://github.com/tatsu-lab/stanford_alpaca) and FiQA (https://sites.google.com/view/fiqa/) with another 1.3k pairs custom generated using GPT3.5 . This version is a cleaned up version, which also has: \n\nmutlilingual support (en, it, fr, es, de)\nCSV and JSON files\n\n","url":"https://huggingface.co/datasets/dgallitelli/multilingual-wealth-alpaca","creator_name":"Davide Gallitelli","creator_url":"https://huggingface.co/dgallitelli","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-generation","English","Italian","French","Spanish"],"keywords_longer_than_N":true},
	{"name":"open_government","keyword":"italian","description":"\n\t\n\t\t\n\t\tOpen Government Dataset\n\t\n\nOpen Government is the largest agregation of governement text and data made available as part of open data programs. \nIn total, the dataset contains approximately 380B tokens. While Open Government aims to become a global resource, in its current state it mostly features open datasets from the US, France, European and international organizations.\nThe dataset comprises 16 collections curated through two different initiaties: Finance commons and Legal commons.‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/AgentPublic/open_government.","url":"https://huggingface.co/datasets/AgentPublic/open_government","creator_name":"AgentPublic","creator_url":"https://huggingface.co/AgentPublic","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","English","French","Bulgarian","Croatian"],"keywords_longer_than_N":true},
	{"name":"ARK-Metadata","keyword":"italian","description":"\n\t\n\t\t\n\t\tMetadata of the \"Alter Realkatalog\" (ARK) of Berlin State Library (SBB)\n\t\n\n\n\t\n\t\t\n\t\tMotivation\n\t\n\nThis dataset was created with the intent to provide a single larger set of metadata from Berlin State Library for research purposes and the development of AI applications.\nThe dataset comprises of descriptive metadata of 2.619.397 titles, which together form the \"Alte Realkatalog\" of Berlin State Libray, which may be translated to \"Old Subject Catalogue\". The data are stored in columnar‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/SBB/ARK-Metadata.","url":"https://huggingface.co/datasets/SBB/ARK-Metadata","creator_name":"Staatsbibliothek zu Berlin - Preu√üischer Kulturbesitz","creator_url":"https://huggingface.co/SBB","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","feature-extraction","German","Latin","English"],"keywords_longer_than_N":true},
	{"name":"wildchat-filtered","keyword":"italian","description":"\n\t\n\t\t\n\t\tWildChat Filtered Dataset\n\t\n\nThis is a filtered version of the WildChat-4.8M dataset.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset contains 3,199,860 conversations between human users and ChatGPT, filtered to keep only the essential conversation structure.\n\n\t\n\t\t\n\t\tData Structure\n\t\n\nEach conversation contains only:\n\nconversations: A list of message objects with:\nrole: Either \"user\" or \"assistant\"\ncontent: The text content of the message\n\n\n\nAll other metadata (timestamps, moderation‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/rayonlabs/wildchat-filtered.","url":"https://huggingface.co/datasets/rayonlabs/wildchat-filtered","creator_name":"Rayon Labs","creator_url":"https://huggingface.co/rayonlabs","license_name":"Open Data Commons Attribution License v1.0","license_url":"https://scancode-licensedb.aboutcode.org/odc-by-1.0.html","language":"en","first_N":5,"first_N_keywords":["text-generation","question-answering","English","Spanish","French"],"keywords_longer_than_N":true},
	{"name":"GeNTE_ita-eval","keyword":"italian","description":"This dataset adapts the GeNTE dataset to be run on ItaEval.\nIn particular, we selected the five initial instances from the dataset and used them as few-shot examples (\"train\" split in this release).\nPlease check the original dataset for more details on GeNTE. If you use the dataset, please consider citing the paper:\n@inproceedings{piergentili-etal-2023-hi,\n    title = \"Hi Guys or Hi Folks? Benchmarking Gender-Neutral Machine Translation with the {G}e{NTE} Corpus\",\n    author = \"Piergentili‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/RiTA-nlp/GeNTE_ita-eval.","url":"https://huggingface.co/datasets/RiTA-nlp/GeNTE_ita-eval","creator_name":"Risorse per la Lingua Italiana","creator_url":"https://huggingface.co/RiTA-nlp","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["translation","Italian","English","cc-by-4.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"ai-culture-multilingual-json-dolma","keyword":"italian","description":"\n\t\n\t\t\n\t\tAI-Culture Multilingual JSON + DOLMA Corpus\n\t\n\n\n16M words ¬∑ 12 languages ¬∑ CC-BY-4.0\n\nThe AI-Culture corpus contains 5K articles providing comprehensive philosophical and cultural content, exploring the intersection of technology, artificial intelligence, and human culture, perfectly aligned across 12 languages. All content maintains identical parallel structure across translations with zero duplication and editor-curated quality.\nThis project is maintained by a non-profit digital‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/AI-Culture-Commons/ai-culture-multilingual-json-dolma.","url":"https://huggingface.co/datasets/AI-Culture-Commons/ai-culture-multilingual-json-dolma","creator_name":"AI‚ÄëCulture‚ÄëCommons","creator_url":"https://huggingface.co/AI-Culture-Commons","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["translation","text-generation","text-classification","sentence-similarity","summarization"],"keywords_longer_than_N":true},
	{"name":"SN-echoes","keyword":"italian","description":"[Paper] | [GitHub]\n\n\t\n\t\t\n\t\tDataset Card for SoccerNet-Echoes\n\t\n\nThis dataset card aims to provide comprehensive details for the SoccerNet-Echoes dataset, an audio commentary dataset for soccer games.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nSoccerNet-Echoes is an audio commentary dataset for soccer games, curated by SimulaMet under the AI-Storyteller project. It is funded by the Research Council of Norway (project number 346671) and shared by the SoccerNet team. The dataset‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/SoccerNet/SN-echoes.","url":"https://huggingface.co/datasets/SoccerNet/SN-echoes","creator_name":"SoccerNet","creator_url":"https://huggingface.co/SoccerNet","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["summarization","translation","English","Spanish","Russian"],"keywords_longer_than_N":true},
	{"name":"TRUEBench","keyword":"italian","description":"\n\t\n\t\t\n\t\tTRUEBench: A Benchmark for Assessing LLMs as Human Job Productivity Assistants\n\t\n\nTRUEBench is a benchmark introduced by Samsung Research to evaluate the performance of large language models (LLMs) as human job assistants which consists of over 2,400 realistic and challenging samples. \nTo assess performance in real-world applications, TRUEBench includes diverse dialog scenarios and language conditions.\n\n\t\n\t\t\n\t\tMain Features\n\t\n\n\nMultilinguality: The user instructions are written in a‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/SamsungResearch/TRUEBench.","url":"https://huggingface.co/datasets/SamsungResearch/TRUEBench","creator_name":"Samsung Research","creator_url":"https://huggingface.co/SamsungResearch","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","Korean","English","Japanese","Chinese"],"keywords_longer_than_N":true},
	{"name":"tatoeba-bitext-mining","keyword":"italian","description":"\n  Tatoeba\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\n1,000 English-aligned sentence pairs for each language based on the Tatoeba corpus\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2t\n\n\nDomains\nWritten\n\n\nReference\nhttps://github.com/facebookresearch/LASER/tree/main/data/tatoeba/v1\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask = mteb.get_tasks([\"Tatoeba\"])\nevaluator = mteb.MTEB(task)\n\nmodel =‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/tatoeba-bitext-mining.","url":"https://huggingface.co/datasets/mteb/tatoeba-bitext-mining","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"Creative Commons Attribution 2.0","license_url":"https://scancode-licensedb.aboutcode.org/cc-by-2.0.html","language":"en","first_N":5,"first_N_keywords":["translation","human-annotated","multilingual","Afrikaans","Amharic"],"keywords_longer_than_N":true},
	{"name":"tulu3-100samples","keyword":"italian","description":"\n\t\n\t\t\n\t\tDataset\n\t\n\nThis dataset contains 100 samples from the Tulu 3 SFT Mixture.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nEach example in the dataset contains the standard instruction-tuning data points as follow:\n\nid (str): a unique identifier\nmessages (list): message format used for supervised fine-tuning (this contains user prompt and assistant responses)\nsource (str): the source dataset for the given sample\n\n\n\t\n\t\t\n\t\tLicense\n\t\n\nThis dataset is licensed under ODC-BY-1.0. It is intended for research and‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/anayak/tulu3-100samples.","url":"https://huggingface.co/datasets/anayak/tulu3-100samples","creator_name":"Akash Nayak","creator_url":"https://huggingface.co/anayak","license_name":"Open Data Commons Attribution License v1.0","license_url":"https://scancode-licensedb.aboutcode.org/odc-by-1.0.html","language":null,"first_N":5,"first_N_keywords":["other","crowdsourced","expert-generated","machine-generated","multilingual"],"keywords_longer_than_N":true},
	{"name":"fact-check-bureau","keyword":"italian","description":"\n\t\n\t\t\n\t\n\t\n\t\tFact-Check Retrieval Dataset\n\t\n\nThis dataset is designed to support the development and evaluation of fact-check retrieval pipelines. It is structured to work with FactCheckBureau, a tool for designing and evaluating fact-check retrieval pipelines. The dataset comprises a list of claims, fact-check articles, and precomputed embeddings for English and French fact-checks.\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Structure\n\t\n\nThe dataset consists of the following files and directories:\n\narticles.csv:‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/NaughtyConstrictor/fact-check-bureau.","url":"https://huggingface.co/datasets/NaughtyConstrictor/fact-check-bureau","creator_name":"Younes","creator_url":"https://huggingface.co/NaughtyConstrictor","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["English","French","Portuguese","Spanish","Arabic"],"keywords_longer_than_N":true},
	{"name":"medQA-ita","keyword":"italian","description":"\n\t\n\t\t\n\t\t‚ö†Ô∏èGet Access!‚ö†Ô∏è\n\t\n\nTo get free access to the dataset you must write to redix.ai@redix.it specifying the reasons for your request and your intended use.\n\n\t\n\t\t\n\t\tMedQA Italian\n\t\n\nThis document provides instructions on how to access the dataset, information on licensing, the process of creating the dataset, and how to collaborate with us. This dataset is synthetically generated using a custom model from ReDiX Informatica.\nIt is completely Italian and specifically designed for RAG‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ReDiX/medQA-ita.","url":"https://huggingface.co/datasets/ReDiX/medQA-ita","creator_name":"ReDiX Labs","creator_url":"https://huggingface.co/ReDiX","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["question-answering","Italian","cc-by-4.0","10K - 100K","json"],"keywords_longer_than_N":true},
	{"name":"sentiment-analysis-test","keyword":"italian","description":"\n\t\n\t\t\n\t\tProgetto scolastico per l'analisi dei sentimenti\n\t\n\nIl dataset √® stato creato con un questionario online in cui si chiedeva ad un pubblico di studenti, docenti, personale amministrativo, famiglie di rispondere ad alcune domande sul loro rapporto con la scuola.\nLe annotazioni sono state effettuate correlando le risposte testuali ad indicatori di gradimento.\nIl dataset √® stato realizzato all'interno di un corso pomeridiano scolastico dedicato all'intelligenza artificiale.\nGrazie a tutti‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/wbigger/sentiment-analysis-test.","url":"https://huggingface.co/datasets/wbigger/sentiment-analysis-test","creator_name":"Claudio Capobianco","creator_url":"https://huggingface.co/wbigger","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","sentiment-analysis","expert-generated","crowdsourced","crowdsourced"],"keywords_longer_than_N":true},
	{"name":"OmniGEC-ModelTraining","keyword":"italian","description":"\n\t\n\t\t\n\t\tOmniGEC-Model Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nOmniGEC-Model is a large multilingual dataset that comprises data from both WikiEdits-MultiGEC \nand Reddit-MultiGEC.\nThe dataset was constructed using the same data used for model training to enable the reproducibility of results.\nA link to the model and the associated paper will be provided at a later stage.\n\n\t\n\t\t\n\t\n\t\n\t\tCitation\n\t\n\nIf you use or discuss this project/dataset in your work, please cite our paper:Paper: Introducing OmniGEC: A‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/peterua/OmniGEC-ModelTraining.","url":"https://huggingface.co/datasets/peterua/OmniGEC-ModelTraining","creator_name":"Petro Ivaniuk","creator_url":"https://huggingface.co/peterua","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["Ukrainian","English","German","cz","Italian"],"keywords_longer_than_N":true},
	{"name":"moosa2022multilingual-cross-lingual-archived","keyword":"italian","description":"\n\t\n\t\t\n\t\tDataset Card for Multilingual Hate Speech Dataset\n\t\n\n\n\nThis dataset card provides information about the Multilingual Hate Speech Dataset, which was originally hosted on Kaggle. \nThe Multilingual Hate Speech Dataset is a modified version of an original multilingual hate speech dataset. In this version, examples from each language have been translated into the other languages present in the dataset, creating a more comprehensive cross-lingual resource.\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Details‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ysenarath/moosa2022multilingual-cross-lingual-archived.","url":"https://huggingface.co/datasets/ysenarath/moosa2022multilingual-cross-lingual-archived","creator_name":"Yasas","creator_url":"https://huggingface.co/ysenarath","license_name":"Open Data Commons Attribution License v1.0","license_url":"https://scancode-licensedb.aboutcode.org/odc-by-1.0.html","language":"en","first_N":5,"first_N_keywords":["text-classification","Arabic","English","Chinese","French"],"keywords_longer_than_N":true},
	{"name":"Intermediate-Thinking-130k","keyword":"italian","description":"\n\t\n\t\t\n\t\tIntermediate-Thinking-130k\n\t\n\nA comprehensive dataset of 135,000 high-quality samples designed to advance language model reasoning capabilities through structured intermediate thinking processes. This dataset enables training and evaluation of models with sophisticated self-correction and iterative reasoning abilities across 42 languages.\nOG Link\n\n\t\n\t\t\n\t\n\t\n\t\tOverview\n\t\n\nIntermediate-Thinking-130k addresses a fundamental limitation in current language models: their inability to pause‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mlx-community/Intermediate-Thinking-130k.","url":"https://huggingface.co/datasets/mlx-community/Intermediate-Thinking-130k","creator_name":"MLX Community","creator_url":"https://huggingface.co/mlx-community","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","Afrikaans","Arabic","Bengali","Bulgarian"],"keywords_longer_than_N":true},
	{"name":"high-quality-multilingual-sentences","keyword":"italian","description":"\n\t\n\t\t\n\t\tHigh Quality Multilingual Sentences\n\t\n\n\nThis dataset contains multilingual sentences derived from the agentlans/LinguaNova dataset.\nIt includes 1.58 million rows across 51 different languages, each in its own configuration.\n\nExample row (from the all config):\n{\n    \"text\": \"ÿßŸÖÿßŸÖ ÿ¨ŸÖÿπŸá ÿßÿµŸÅŸáÿßŸÜ ⁄ØŸÅÿ™: ŸÖ€åÿ≤ÿßŸÜ ŸÜ€åÿßÿ≤ ÿ¢ÿ® ÿ¥ÿ±ÿ® ÿßÿµŸÅŸáÿßŸÜ €±€±.€µ ŸÖÿ™ÿ± ŸÖ⁄©ÿπÿ® ÿßÿ≥ÿ™ ⁄©Ÿá ÿ™ŸÖÿßŸÖ ÿßÿ≥ÿ™ÿßŸÜ ÿßÿµŸÅŸáÿßŸÜ ÿ±ÿß ŸæŸàÿ¥ÿ¥ ŸÖ€åÿØŸáÿØ Ÿà ŸÜÿ≥ÿ®ÿ™ ÿ®Ÿá ŸÇÿ®ŸÑ ÿßÿ≤ ÿßŸÜŸÇŸÑÿßÿ® €å⁄©€å ÿßÿ≤ Ÿæ€åÿ¥ÿ±ŸÅÿ™Ÿáÿß ÿØÿ± ÿ≠Ÿàÿ≤Ÿá ÿ¢ÿ® ÿ®ŸàÿØŸá ÿßÿ≥ÿ™.\",\n    \"fasttext\": \"fa\",\n    \"gcld3\": \"fa\"\n}\n\nFields:‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/agentlans/high-quality-multilingual-sentences.","url":"https://huggingface.co/datasets/agentlans/high-quality-multilingual-sentences","creator_name":"Alan Tseng","creator_url":"https://huggingface.co/agentlans","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","text-classification","text-retrieval","multilingual","Arabic"],"keywords_longer_than_N":true},
	{"name":"MSTS","keyword":"italian","description":"\n\t\n\t\t\n\t\tDisclaimer\n\t\n\nThe MSTS dataset contains content that may be offensive or upsetting in nature. Topics include, but are not limited to, discriminatory language and discussions of abuse, violence, self-harm, exploitation, and other potentially upsetting subject matter. \nPlease only engage with the data in accordance with your own personal risk tolerance. The data are intended for research purposes, especially research that can make models less harmful.\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Card for the‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/felfri/MSTS.","url":"https://huggingface.co/datasets/felfri/MSTS","creator_name":"Felix Friedrich","creator_url":"https://huggingface.co/felfri","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["image-text-to-text","English","Arabic","French","German"],"keywords_longer_than_N":true},
	{"name":"mu-shroom","keyword":"italian","description":"\n\t\n\t\t\n\t\tThe Mu-SHROOM dataset for Multilingual Hallucination and Overgeneration detection.\n\t\n\nMu-SHROOM: Multilingual Shared-task on Hallucinations and Related Observable Overgeneration Mistakes and Related Observable Overgeneration Mistakes\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nMu-SHROOM is a multilingual dataset for detecting hallucination spans in LLM outputs across 14 languages. It was created for SemEval-2025 Task 3.\ndisclaimer: Mu-SHROOM is not properly a fact-checking dataset, but we mark is‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Helsinki-NLP/mu-shroom.","url":"https://huggingface.co/datasets/Helsinki-NLP/mu-shroom","creator_name":"Language Technology Research Group at the University of Helsinki","creator_url":"https://huggingface.co/Helsinki-NLP","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["token-classification","fact-checking","Arabic","Catalan","Czech"],"keywords_longer_than_N":true},
	{"name":"evol-dpo-ita","keyword":"italian","description":"\n  \n\n\n\n\n\t\n\t\t\n\t\tDataset Card\n\t\n\nEvol-DPO-Ita is a high-quality dataset consisting of ~20,000 preference pairs derived from responses generated by two large language models: Claude Opus and GPT-3.5 Turbo.\n\n\t\n\t\t\n\t\tKey Features\n\t\n\n\n20,000 Preference Comparisons: Each entry contains two model responses ‚Äî Claude Opus (claude-3-opus-20240229) for the chosen response and GPT-3.5 Turbo for the rejected one, both generated from a translated prompt from the original Evol-Instruct dataset (prompt and‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/efederici/evol-dpo-ita.","url":"https://huggingface.co/datasets/efederici/evol-dpo-ita","creator_name":"Edoardo Federici","creator_url":"https://huggingface.co/efederici","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text2text-generation","Italian","apache-2.0","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"Youtube_Links","keyword":"italian","description":"Decre99/Youtube_Links dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/Decre99/Youtube_Links","creator_name":"De","creator_url":"https://huggingface.co/Decre99","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","Italian","mit","< 1K","parquet"],"keywords_longer_than_N":true},
	{"name":"MMMLU","keyword":"italian","description":"\n\t\n\t\t\n\t\tMultilingual Massive Multitask Language Understanding (MMMLU)\n\t\n\nThe MMLU is a widely recognized benchmark of general knowledge attained by AI models. It covers a broad range of topics from 57 different categories, covering elementary-level knowledge up to advanced professional subjects like law, physics, history, and computer science.\nWe translated the MMLU‚Äôs test set into 14 languages using professional human translators. Relying on human translators for this evaluation increases‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/bzantium/MMMLU.","url":"https://huggingface.co/datasets/bzantium/MMMLU","creator_name":"Minho Ryu","creator_url":"https://huggingface.co/bzantium","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["question-answering","Arabic","Bengali","German","Spanish"],"keywords_longer_than_N":true},
	{"name":"sentiment-analysis-test","keyword":"italian","description":"\n\t\n\t\t\n\t\tProgetto scolastico per L'analisi dei sentimenti\n\t\n\nil dataset √® stato creato con un questionario online in cui si chiedeva ad un pubblico di studenti, docenti, personale amministrativo, famiglie di rispondere ad alcune domande sul loro rapporto con la scuola.\nLe annotazioni sono state effettuate correlando le risposte testuali ad indicatori di gradimento.\nIl dataset √® stato realizzato all'interno di un corso pomeridiano scolastico dedicato all'intelligenza artificiale.\nGrazie a tutti‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Felipeit/sentiment-analysis-test.","url":"https://huggingface.co/datasets/Felipeit/sentiment-analysis-test","creator_name":"Felipe Simoes Campos","creator_url":"https://huggingface.co/Felipeit","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","sentiment-analysis","expert-generated","crowdsourced","crowdsourced"],"keywords_longer_than_N":true},
	{"name":"Test_Youtube_Links","keyword":"italian","description":"Innovina/Test_Youtube_Links dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/Innovina/Test_Youtube_Links","creator_name":"Innovina","creator_url":"https://huggingface.co/Innovina","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-generation","Italian","mit","< 1K","csv"],"keywords_longer_than_N":true},
	{"name":"head_qa_v2","keyword":"italian","description":"\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nHEAD-QA v2 is an updated version of the HEAD-QA dataset, which is a multi-choice HEAlthcare Dataset. The questions come from exams to access a specialized position in the Spanish healthcare system, and are challenging even for highly specialized humans. They are designed by the Ministerio de Sanidad, Consumo y Bienestar Social, who also provides direct access to the exams of the last 5 years (in Spanish).\nHEAD-QA V2 expands on the original dataset by including‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/alesi12/head_qa_v2.","url":"https://huggingface.co/datasets/alesi12/head_qa_v2","creator_name":"Alexis Correa Guillen","creator_url":"https://huggingface.co/alesi12","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["multiple-choice","visual-question-answering","Spanish","English","Galician"],"keywords_longer_than_N":true},
	{"name":"FairytaleQA-translated-italian","keyword":"italian","description":"\n\t\n\t\t\n\t\tDataset Card for FairytaleQA-translated-ptBR\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis repository contains the Italian machine-translated version of the original English FairytaleQA dataset (https://huggingface.co/datasets/WorkInTheDark/FairytaleQA). FairytaleQA is an open-source dataset designed to enhance comprehension of narratives, aimed at students from kindergarten to eighth grade. The dataset is meticulously annotated by education experts following an evidence-based theoretical‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/benjleite/FairytaleQA-translated-italian.","url":"https://huggingface.co/datasets/benjleite/FairytaleQA-translated-italian","creator_name":"Bernardo Leite","creator_url":"https://huggingface.co/benjleite","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["question-answering","text-generation","Italian","apache-2.0","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"test_4","keyword":"italian","description":"\n\t\n\t\t\n\t\n\t\n\t\tFLEURS\n\t\n\nFleurs is the speech version of the FLoRes machine translation benchmark. \nWe use 2009 n-way parallel sentences from the FLoRes dev and devtest publicly available sets, in 102 languages. \nTraining sets have around 10 hours of supervision. Speakers of the train sets are different than speakers from the dev/test sets. Multilingual fine-tuning is\nused and ‚Äùunit error rate‚Äù (characters, signs) of all languages is averaged. Languages and results are also grouped into seven‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/tunngo/test_4.","url":"https://huggingface.co/datasets/tunngo/test_4","creator_name":"nguyen tuan","creator_url":"https://huggingface.co/tunngo","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["automatic-speech-recognition","expert-generated","crowdsourced","machine-generated","crowdsourced"],"keywords_longer_than_N":true},
	{"name":"literary-synthesis","keyword":"italian","description":"\n\t\n\t\t\n\t\tLiterary Synthesis\n\t\n\nThis dataset repurposes the original agentlans/literary-reasoning \ndata by reformatting it as creative writing prompts paired with literary-style outputs. \n\nWriting style attributes were put in random order, with prompts randomly either prepended or appended.\nThe output text has been cleaned to make it suitable for creative writing and literary generation tasks.\nThe rows were sorted by increasing reading difficulty for curriculum learning.\n\n","url":"https://huggingface.co/datasets/agentlans/literary-synthesis","creator_name":"Alan Tseng","creator_url":"https://huggingface.co/agentlans","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","English","French","German","Spanish"],"keywords_longer_than_N":true},
	{"name":"Product_Similarity_Dataset","keyword":"italian","description":"This following dataset is a rich dataset of product similarity. The dataset has been design to be challenging to train on by having quite a lot of hard negatives\nThis dataset is especially targeted toward fine-tuning usecase, especially to finetune reranker or embedding model.\nThe data are especially adapted for listwise loss like LambdaLoss or ListNetLoss.\nThe data are in JSONL and each line follow the same format as here below : \n\nA \"query\", the anchor product label\n\"docs\", the potential‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Antix5/Product_Similarity_Dataset.","url":"https://huggingface.co/datasets/Antix5/Product_Similarity_Dataset","creator_name":"Antoine Demangeon","creator_url":"https://huggingface.co/Antix5","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-ranking","feature-extraction","French","German","Chinese"],"keywords_longer_than_N":true},
	{"name":"Neo-GATE","keyword":"italian","description":"\n\t\n\t\t\n\t\tDataset card for Neo-GATE\n\t\n\nHomepage: https://mt.fbk.eu/neo-gate/\n\n\t\n\t\t\n\t\tDataset summary\n\t\n\nNeo-GATE is a bilingual corpus designed to benchmark the ability of machine translation (MT) systems to translate from English into Italian using gender-inclusive neomorphemes.\nIt is built upon GATE (Rarrick et al., 2023), a benchmark for the evaluation of gender rewriters and gender bias in MT.\nNeo-GATE includes 841 test entries (Neo-GATE.tsv) and 100 dev entries (Neo-GATE-dev.tsv).\nEach‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/FBK-MT/Neo-GATE.","url":"https://huggingface.co/datasets/FBK-MT/Neo-GATE","creator_name":"FBK-MT","creator_url":"https://huggingface.co/FBK-MT","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["translation","text-generation","multilingual","translation","English"],"keywords_longer_than_N":true},
	{"name":"SwissJudgementClassification","keyword":"italian","description":"\n  SwissJudgementClassification\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nMultilingual, diachronic dataset of Swiss Federal Supreme Court cases annotated with the respective binarized judgment outcome (approval/dismissal)\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2c\n\n\nDomainsLegal, Written\n\n\nReference\nhttps://aclanthology.org/2021.nllp-1.3/\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask =‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/SwissJudgementClassification.","url":"https://huggingface.co/datasets/mteb/SwissJudgementClassification","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","expert-annotated","multilingual","rcds/swiss_judgment_prediction","German"],"keywords_longer_than_N":true},
	{"name":"OpenItalianData","keyword":"italian","description":"DeepMount00/OpenItalianData dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/DeepMount00/OpenItalianData","creator_name":"Michele Montebovi","creator_url":"https://huggingface.co/DeepMount00","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","Italian","apache-2.0","1M - 10M","parquet"],"keywords_longer_than_N":true},
	{"name":"m-WildVision","keyword":"italian","description":"\n\t\n\t\t\n\t\tDataset Card for m-WildVision\n\t\n\n\n\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\nThe m-WildVision dataset is a multilingual multimodal LLM evaluation set covering 23 languages.  It was created by translating prompts from the original English-only WildVision (vision_bench_0617) test set. \nThe original prompts, developed by Lu et al. (2024) , consist of 500 challenging user queries sourced from the WildVision-Arena platform. \nThe authors demonstrated that these prompts enable automatic LLM judge‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/CohereLabs/m-WildVision.","url":"https://huggingface.co/datasets/CohereLabs/m-WildVision","creator_name":"Cohere Labs","creator_url":"https://huggingface.co/CohereLabs","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["English","French","German","Spanish","Italian"],"keywords_longer_than_N":true},
	{"name":"Phonemized-UD","keyword":"italian","description":"\n\t\n\t\t\n\t\tPhoneme-UD: A Multilingual Phonemized Universal Dependencies Corpus for 34+ Languages\n\t\n\n\n\t\n\t\t\n\t\tG2P+ Phonemizer\n\t\n\nWe use G2P+ to phonemize Universal Dependencies. Here is an example usage: \n# Install required packages\n!apt-get install -y espeak-ng\n!pip install phonemizer g2p-plus\n# Set the environment variable from Python\nimport os\nos.environ[\"PHONEMIZER_ESPEAK_LIBRARY\"] = \"/usr/lib/x86_64-linux-gnu/libespeak-ng.so.1\"\n\n# Now run your transcription\nfrom g2p_plus import‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/suchirsalhan/Phonemized-UD.","url":"https://huggingface.co/datasets/suchirsalhan/Phonemized-UD","creator_name":"Suchir Salhan","creator_url":"https://huggingface.co/suchirsalhan","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["Afrikaans","Amharic","Arabic","Azerbaijani","Catalan"],"keywords_longer_than_N":true},
	{"name":"OGC_colpali-VisRAG-vdr","keyword":"italian","description":"\n\t\n\t\t\n\t\tWIP - there might be issues with the negatives\n\t\n\n\n\t\n\t\t\n\t\tOGC - Organized, Grouped, Cleaned\n\t\n\n\nIntended for image/text to vector (DSE)\n\n\n\t\n\t\t\n\t\tDataset Composition\n\t\n\nThe dataset merges, shuffles, and formats data from:\n\nvidore/colpali_train_set\nopenbmb/VisRAG-Ret-Train-Synthetic-data\nllamaindex/vdr-multilingual-train\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Statistics\n\t\n\n\n\t\n\t\t\nMetric\nValue\n\n\n\t\t\nTotal rows\n700,000+\n\n\nRows with negatives\n‚âà 33%\n\n\nRows without queries (image negatives only)\n‚âà 25%‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/racineai/OGC_colpali-VisRAG-vdr.","url":"https://huggingface.co/datasets/racineai/OGC_colpali-VisRAG-vdr","creator_name":"racine.ai","creator_url":"https://huggingface.co/racineai","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["visual-document-retrieval","text-retrieval","English","French","Spanish"],"keywords_longer_than_N":true},
	{"name":"linkedin-industry-list","keyword":"italian","description":"fantastic-jobs/linkedin-industry-list dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/fantastic-jobs/linkedin-industry-list","creator_name":"Fantastic.jobs","creator_url":"https://huggingface.co/fantastic-jobs","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","translation","English","Korean","Spanish"],"keywords_longer_than_N":true},
	{"name":"MKQARetrieval","keyword":"italian","description":"\n  MKQARetrieval\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nMultilingual Knowledge Questions & Answers (MKQA)contains 10,000 queries sampled from the Google Natural Questions dataset.\n        For each query we collect new passage-independent answers. These queries and answers are then human translated into 25 Non-English languages.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2t\n\n\nDomains\nWritten\n\n\nReference\nhttps://github.com/apple/ml-mkqa\n\n\n\t\n\nSource datasets:\n\napple/mkqa\n\n\n\t\n\t\t\n\t\tHow to evaluate‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/MKQARetrieval.","url":"https://huggingface.co/datasets/mteb/MKQARetrieval","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"Creative Commons Attribution 3.0","license_url":"https://scancode-licensedb.aboutcode.org/cc-by-3.0.html","language":"en","first_N":5,"first_N_keywords":["text-retrieval","multiple-choice-qa","human-annotated","multilingual","apple/mkqa"],"keywords_longer_than_N":true},
	{"name":"comma-jsonl","keyword":"italian","description":"\n\t\n\t\t\n\t\tDataset Card for CoMMA JSON-L\n\t\n\nCoMMA is a large-scale corpus of digitized medieval manuscripts \ntranscribed using Handwritten Text Recognition (HTR). It \ncontains over 2.5 billion tokens from more than 23,000 manuscripts in\nLatin and Old French (801‚Äì1600 CE). Unlike most existing resources, the corpus\nprovides raw, non-normalized text.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\n\n\n\n\n\nCurated by: Thibault Cl√©rice\nFunded by: Inria, COLaF, ParamHTRs\nLanguage(s) (NLP):‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/comma-project/comma-jsonl.","url":"https://huggingface.co/datasets/comma-project/comma-jsonl","creator_name":"Corpus of Multilingual Medieval Archives","creator_url":"https://huggingface.co/comma-project","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["Latin","French","Italian","cc-by-4.0","1B<n<10B"],"keywords_longer_than_N":true},
	{"name":"Lappland-the-Decadenza","keyword":"italian","description":"None1145/Lappland-the-Decadenza dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/None1145/Lappland-the-Decadenza","creator_name":"None","creator_url":"https://huggingface.co/None1145","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["audio-to-audio","text-to-speech","Chinese","Japanese","Italian"],"keywords_longer_than_N":true},
	{"name":"sentiment-analysis-test","keyword":"italian","description":"\n\t\n\t\t\n\t\tProgetto scolastico per l'analisi dei sentimenti\n\t\n\nIl dataset √® stato creato con un questionario online in cui si chiedeva ad un pubblico di studenti, docenti, personale amministrativo, famiglie di rispondere ad alcune domande sul loro rapporto con la scuola.\nle annotazioni sono state effetuate coorelando le risposte testuali ad indicatori di gradimento.\nIl dataaset √® stato realizzato all'interno di un corso pomeridiano scolastico dedicato all'IA.\nGrazie a tutti per la‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Cocciadipollo/sentiment-analysis-test.","url":"https://huggingface.co/datasets/Cocciadipollo/sentiment-analysis-test","creator_name":"Marrocco Marco","creator_url":"https://huggingface.co/Cocciadipollo","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","sentiment-analysis","expert-generated","crowdsourced","crowdsourced"],"keywords_longer_than_N":true},
	{"name":"zenamt-document-level","keyword":"italian","description":"\n\t\n\t\t\n\t\tZenaMT corpus (document-level)\n\t\n\nThis is an Italian ‚Äì Ligurian (Genoese) parallel corpus covering a number of domains of cultural relevance to Ligurian speakers. Parts of the corpus also contain aligned English translations, available in the column eng. Whenever an English translation is not available, the corresponding column is set to null.\nThis is the document-level version of the corpus. Source elements which were available in document form were retained as full documents, rather‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ConseggioLigure/zenamt-document-level.","url":"https://huggingface.co/datasets/ConseggioLigure/zenamt-document-level","creator_name":"Council for Ligurian Linguistic Heritage","creator_url":"https://huggingface.co/ConseggioLigure","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["translation","multilingual","original","Ligurian","Italian"],"keywords_longer_than_N":true},
	{"name":"napierone-epub-raw","keyword":"italian","description":"\n\t\n\t\t\n\t\tBEE-spoke-data/napierone-epub-raw\n\t\n\nNapierOne EPUB files converted with marker. Seems to contain mostly books from Project Gutenberg.\n\n\t\n\t\t\n\t\tdetected languages\n\t\n\nvia fasttext-langdetect\n{'ca': 1,\n 'cy': 1,\n 'da': 6,\n 'de': 105,\n 'en': 4403,\n 'eo': 2,\n 'es': 61,\n 'fi': 76,\n 'fr': 189,\n 'he': 1,\n 'hu': 5,\n 'is': 1,\n 'it': 40,\n 'la': 6,\n 'nl': 41,\n 'pl': 4,\n 'pt': 38,\n 'sv': 10,\n 'tl': 9}\n\n","url":"https://huggingface.co/datasets/BEE-spoke-data/napierone-epub-raw","creator_name":"BEEspoke Data","creator_url":"https://huggingface.co/BEE-spoke-data","license_name":"Open Data Commons Attribution License v1.0","license_url":"https://scancode-licensedb.aboutcode.org/odc-by-1.0.html","language":"en","first_N":5,"first_N_keywords":["text-generation","feature-extraction","English","Spanish","Finnish"],"keywords_longer_than_N":true},
	{"name":"MultiLongDocRetrieval","keyword":"italian","description":"\n  MultiLongDocRetrieval\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nMulti Long Doc Retrieval (MLDR) 'is curated by the multilingual articles from Wikipedia, Wudao and mC4 (see Table 7), and NarrativeQA (KocÀáisky ÃÅ et al., 2018; Gu Ãànther et al., 2023), which is only for English.' (Chen et al., 2024).\n        It is constructed by sampling lengthy articles from Wikipedia, Wudao and mC4 datasets and randomly choose paragraphs from them. Then we use GPT-3.5 to generate questions based‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/MultiLongDocRetrieval.","url":"https://huggingface.co/datasets/mteb/MultiLongDocRetrieval","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","LM-generated","multilingual","Shitao/MLDR","Arabic"],"keywords_longer_than_N":true},
	{"name":"vdr-multilingual-train","keyword":"italian","description":"\n\t\n\t\t\n\t\tMultilingual Visual Document Retrieval Dataset\n\t\n\n\n\nThis dataset consists of 500k multilingual query image samples, collected and generated from scratch using public internet pdfs. The queries are synthetic and generated using VLMs (gemini-1.5-pro and Qwen2-VL-72B).\n\nIt was used to train the vdr-2b-multi-v1 retrieval multimodal, multilingual embedding model.\n\n\t\n\t\t\n\t\n\t\n\t\tHow it was created\n\t\n\nThis is the entire data pipeline used to create the Italian subset of this dataset. Each step‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/llamaindex/vdr-multilingual-train.","url":"https://huggingface.co/datasets/llamaindex/vdr-multilingual-train","creator_name":"LlamaIndex","creator_url":"https://huggingface.co/llamaindex","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["multilingual","German","Italian","French","Spanish"],"keywords_longer_than_N":true},
	{"name":"PangeaBench-xm100","keyword":"italian","description":"\n\t\n\t\t\n\t\n\t\n\t\tXM100\n\t\n\n\n\t\n\t\t\n\t\n\t\n\t\tThis is a copy from https://google.github.io/crossmodal-3600/\n\t\n\nIf you use this dataset, please cite the original authors:\n@inproceedings{ThapliyalCrossmodal2022,\n  author = {Ashish Thapliyal and Jordi Pont-Tuset and Xi Chen and Radu Soricut},\n  title = {{Crossmodal-3600: A Massively Multilingual Multimodal Evaluation Dataset}},\n  booktitle = {EMNLP},\n  year = {2022}\n}\n\n","url":"https://huggingface.co/datasets/neulab/PangeaBench-xm100","creator_name":"NeuLab @ LTI/CMU","creator_url":"https://huggingface.co/neulab","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["image-to-text","Arabic","Bengali","Czech","Danish"],"keywords_longer_than_N":true},
	{"name":"mls-annotated","keyword":"italian","description":"\n\t\n\t\t\n\t\tDataset Card for Annotations of non English MLS\n\t\n\nThis dataset consists in annotations of a the Non English subset of the Multilingual LibriSpeech (MLS) dataset. \nMLS dataset is a large multilingual corpus suitable for speech research. The dataset is derived from read audiobooks from LibriVox and consists of \n8 languages - English, German, Dutch, Spanish, French, Italian, Portuguese, Polish. It includes about 44.5K hours of English and a total of about 6K hours for other languages.‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/PHBJT/mls-annotated.","url":"https://huggingface.co/datasets/PHBJT/mls-annotated","creator_name":"Paul Henri Biojout","creator_url":"https://huggingface.co/PHBJT","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-to-speech","French","German","Dutch","Portuguese"],"keywords_longer_than_N":true},
	{"name":"multi-hatecheck","keyword":"italian","description":"\n  MultiHateClassification\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nHate speech detection dataset with binary\n                       (hateful vs non-hateful) labels. Includes 25+ distinct types of hate\n                       and challenging non-hate, and 11 languages.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask categoryt2c\n\n\nDomains\nConstructed, Written\n\n\nReference\nhttps://aclanthology.org/2022.woah-1.15/\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/multi-hatecheck.","url":"https://huggingface.co/datasets/mteb/multi-hatecheck","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","sentiment-analysis","sentiment-scoring","sentiment-classification","hate-speech-detection"],"keywords_longer_than_N":true},
	{"name":"cml-tts-filtered","keyword":"italian","description":"\n\t\n\t\t\n\t\tDataset Card for Filtred and CML-TTS\n\t\n\nThis dataset is a filtred version of a CML-TTS [1]. \nCML-TTS [1] CML-TTS is a recursive acronym for CML-Multi-Lingual-TTS, a Text-to-Speech (TTS) dataset developed at the Center of Excellence in Artificial Intelligence (CEIA) of the Federal University of Goias (UFG). CML-TTS is a dataset comprising audiobooks sourced from the public domain books of Project Gutenberg, read by volunteers from the LibriVox project. The dataset includes recordings in‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/PHBJT/cml-tts-filtered.","url":"https://huggingface.co/datasets/PHBJT/cml-tts-filtered","creator_name":"Paul Henri Biojout","creator_url":"https://huggingface.co/PHBJT","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-to-speech","French","German","Dutch","Polish"],"keywords_longer_than_N":true},
	{"name":"parallel_corpus_game","keyword":"italian","description":"https://github.com/mnbvc-parallel-corpus-team/parallel_corpus_mnbvc\nGame Corpus Collected by MNBVC Parallel Corpus Team.\n\n\t\n\t\t\n\t\t09/17/2025 Updated\n\t\n\n\nHollow Knight\n\n\n\t\n\t\t\n\t\t09/15/2025 Updated\n\t\n\n\nLimbus Company\nMirror\n\n\n\t\n\t\t\n\t\t09/08/2025 Updated\n\t\n\n\nSpice and Wolf VR (1&2)\nDeep Rock Galactic\nCities Skylines 1\n\n\n\t\n\t\t\n\t\t09/02/2025 Updated\n\t\n\n\nPlague Inc\n\n\n\t\n\t\t\n\t\t09/01/2025 Updated\n\t\n\n\nBanGDream from https://bestdori.com/\n\n\n\t\n\t\t\n\t\t08/15/2025 Updated\n\t\n\n\nATRI from‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/bot-yaya/parallel_corpus_game.","url":"https://huggingface.co/datasets/bot-yaya/parallel_corpus_game","creator_name":"yaya","creator_url":"https://huggingface.co/bot-yaya","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["translation","Arabic","Chinese","German","English"],"keywords_longer_than_N":true},
	{"name":"BigAudioDataset","keyword":"italian","description":"\n\t\n\t\t\n\t\tAstraMindAI/BigAudioDataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nAstraMindAI/BigAudioDataset is a large-scale, multilingual dataset designed for a wide range of audio and speech processing tasks. It comprises a diverse collection of audio clips, including both spoken voice and music, making it a valuable resource for training and evaluating models for automatic speech recognition (ASR), text-to-speech (TTS), audio classification, and more.\nThe voice data is aggregated from well-known‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/AstraMindAI/BigAudioDataset.","url":"https://huggingface.co/datasets/AstraMindAI/BigAudioDataset","creator_name":"AstraMindAI","creator_url":"https://huggingface.co/AstraMindAI","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["multilingual","English","Italian","French","German"],"keywords_longer_than_N":true},
	{"name":"Global-MMLU","keyword":"italian","description":"\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nGlobal-MMLU üåç is a multilingual evaluation set spanning 42 languages, including English. This dataset combines machine translations for MMLU questions along with professional translations and crowd-sourced post-edits.\nIt also includes cultural sensitivity annotations for a subset of the questions (2850 questions per language) and classifies them as Culturally Sensitive (CS) üóΩ or Culturally Agnostic (CA) ‚öñÔ∏è. These annotations were collected as part of an open‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/CohereLabs/Global-MMLU.","url":"https://huggingface.co/datasets/CohereLabs/Global-MMLU","creator_name":"Cohere Labs","creator_url":"https://huggingface.co/CohereLabs","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["English","Arabic","Bengali","Spanish","French"],"keywords_longer_than_N":true},
	{"name":"lexclipr","keyword":"italian","description":"\n\t\n\t\t\n\t\tDataset Division\n\t\n\n\nUnique_query : contains unique queries that are not present in train, val, test split. Used for testing unseen understandability of models.\nTrain_all : contains the unsplit train, test, val datapoints.\ntrain : train split\nval : val split\ntest : test split\n\nOriginal Paper : LexCLiPR: Cross-Lingual Paragraph Retrieval from Legal Judgments\nBibtext:\n@inproceedings{upadhya-t-y-s-s-2025-lexclipr,\n    title = \"{L}ex{CL}i{PR}: Cross-Lingual Paragraph Retrieval from Legal‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/rohit-upadhya/lexclipr.","url":"https://huggingface.co/datasets/rohit-upadhya/lexclipr","creator_name":"Rohit Upadhya","creator_url":"https://huggingface.co/rohit-upadhya","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["table-question-answering","English","French","Italian","Romanian"],"keywords_longer_than_N":true},
	{"name":"allenai_tulu-3-sft-mixture-DolphinLabeled","keyword":"italian","description":"\n\t\n\t\t\n\t\tallenai tulu-3-sft-mixture DolphinLabeled\n\t\n\n\n\t\n\t\t\n\t\tPart of the DolphinLabeled series of datasets\n\t\n\n\n\t\n\t\t\n\t\tPresented by Eric Hartford and Cognitive Computations\n\t\n\nThe purpose of this dataset is to enable filtering of allenai/tulu-3-sft-mixture dataset.\nThe original dataset is allenai/tulu-3-sft-mixture\nI have modified the dataset using two scripts.\n\ndedupe.py - removes rows with identical final message content\nlabel.py - adds a \"flags\" column containing the following boolean‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/cognitivecomputations/allenai_tulu-3-sft-mixture-DolphinLabeled.","url":"https://huggingface.co/datasets/cognitivecomputations/allenai_tulu-3-sft-mixture-DolphinLabeled","creator_name":"Cognitive Computations","creator_url":"https://huggingface.co/cognitivecomputations","license_name":"Open Data Commons Attribution License v1.0","license_url":"https://scancode-licensedb.aboutcode.org/odc-by-1.0.html","language":"en","first_N":5,"first_N_keywords":["other","crowdsourced","expert-generated","machine-generated","multilingual"],"keywords_longer_than_N":true},
	{"name":"sentiment-analysis-test","keyword":"italian","description":"\n\t\n\t\t\n\t\tprogetto scolastico per l'analisi dei sentimenti\n\t\n\nil dataset √® stato creato con un questionario online in cu isi chiedeva ad un pubblico di studenti, docenti, personale amministrativo, famiglie di rispondere ad alcune domande sul loro rapporto con la scuola.\nLe annotazioni sono state effettuate correlando le risposte testuali ad indicatori di gradimento.\nIl dataset √® stato stato realizzato all'interno di un corsp pomeridiano scolastico dedicato all'intelligenza artificiale.\nGrazie a‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Smatteux/sentiment-analysis-test.","url":"https://huggingface.co/datasets/Smatteux/sentiment-analysis-test","creator_name":"daniele matteucci","creator_url":"https://huggingface.co/Smatteux","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","sentiment-analysis","expert-generated","crowdsourced","crowdsourced"],"keywords_longer_than_N":true},
	{"name":"ProgettoIndice","keyword":"italian","description":"fcrocco/ProgettoIndice dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/fcrocco/ProgettoIndice","creator_name":"Francesco","creator_url":"https://huggingface.co/fcrocco","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":null,"first_N":5,"first_N_keywords":["Italian","apache-2.0","üá∫üá∏ Region: US"],"keywords_longer_than_N":false},
	{"name":"crossword-clues-QA","keyword":"italian","description":"\n\t\n\t\t\n\t\tECWCA-Educational CrossWord Clues Answering A CALAMITA Challenge\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nECWCA (Educational CrossWord Clues Answering) is a dataset designed to evaluate the knowledge and reasoning capabilities of Large Language Models (LLMs) \nthrough crossword clue-answering tasks. \nThe dataset consists of clues and their respective answers, constructed based on entities and facts extracted from Italian Wikipedia.\nECWCA is part of the CALAMITA Challenge.\n\n\t\n\t\t\n\t\tDataset Description‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/azugarini/crossword-clues-QA.","url":"https://huggingface.co/datasets/azugarini/crossword-clues-QA","creator_name":"Andrea Zugarini","creator_url":"https://huggingface.co/azugarini","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["question-answering","Italian","apache-2.0","1K - 10K","parquet"],"keywords_longer_than_N":true},
	{"name":"quran_multilingual_parallel","keyword":"italian","description":"\n\t\n\t\t\n\t\tüìò Qur‚Äôan Multilingual Parallel Dataset (quran_multilingual_parallel)\n\t\n\nThis dataset presents a clean, structurally-aligned multilingual parallel corpus of the Qur‚Äôanic text. It is intended for linguistic, computational, and cross-lingual AI applications ‚Äî not only for religious interpretation.\nIt contains over 6,200 verse-level alignments in 54 human languages, formatted in a machine-friendly .csv structure with language-specific translation fields.\n\n\n\t\n\t\t\n\t\n\t\n\t\tüß† Dataset Highlights‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/freococo/quran_multilingual_parallel.","url":"https://huggingface.co/datasets/freococo/quran_multilingual_parallel","creator_name":"Wynn","creator_url":"https://huggingface.co/freococo","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["translation","Arabic","Albanian","Amharic","Azerbaijani"],"keywords_longer_than_N":true},
	{"name":"Samantha-NeonGenesis-Reasoning-1.1","keyword":"italian","description":"\n\n\n\t\n\t\t\n\t\tSamantha-NeonGenesis-1.1\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nSamantha-NeonGenesis-1.1 is a cutting-edge, curated dataset designed for training large language models (LLMs) specialized in companionship, emotional and sentimental exploration, and deep reasoning. By integrating multiple sources and innovative methodologies, this dataset offers a robust resource for fostering nuanced, emotionally intelligent conversations and in-depth discussions across topics such as psychology, history, humanism‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/WasamiKirua/Samantha-NeonGenesis-Reasoning-1.1.","url":"https://huggingface.co/datasets/WasamiKirua/Samantha-NeonGenesis-Reasoning-1.1","creator_name":"Wasami","creator_url":"https://huggingface.co/WasamiKirua","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","Italian","apache-2.0","10K - 100K","json"],"keywords_longer_than_N":true},
	{"name":"chat-eur-lex","keyword":"italian","description":"\n\t\n\t\t\n\t\n\t\n\t\tDataset Card for the Chat-EUR-Lex dataset\n\t\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Description\n\t\n\n\nHomepage: Chat-EUR-Lex project Homepage\nRepository: Chat-EUR-Lex project Homepage\nPoint of Contact: Aptus Research Team\n\nThe Chat-EUR-Lex dataset comprises a selection of legal acts in English and Italian sourced from EUR-Lex, covering the period from January 1, 2014, to December 31, 2023. Specifically, it includes all historical texts preserved in Celex 3 that remain unaltered over time, along with‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/AptusAI/chat-eur-lex.","url":"https://huggingface.co/datasets/AptusAI/chat-eur-lex","creator_name":"Aptus.AI","creator_url":"https://huggingface.co/AptusAI","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["English","Italian","cc-by-4.0","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"multiCHILDES","keyword":"italian","description":"\n\t\n\t\t\n\t\tmultiCHILDES: Multilingual Child-Directed Speech Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset contains child-directed speech from 19 languages, extracted from the CHILDES corpus. The text has been cleaned and is designed for text generation tasks, particularly in studying early language acquisition.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\nSource: CHILDES corpus\nLanguages: 19 languages\nText Type: Child-directed speech\nTask: Text Generation, Language Modeling\nData Processing: The dataset‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/IParraMartin/multiCHILDES.","url":"https://huggingface.co/datasets/IParraMartin/multiCHILDES","creator_name":"I√±igo Parra","creator_url":"https://huggingface.co/IParraMartin","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-generation","English","Basque","Spanish","Portuguese"],"keywords_longer_than_N":true}
]
;
