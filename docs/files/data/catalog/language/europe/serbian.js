const data_for_language_europe_serbian = 
[
	{"name":"cyrillic-language-classification","keyword":"serbian","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/AlmaznayaGroza/cyrillic-language-classification","creator_name":"G√©raldine","creator_url":"https://huggingface.co/AlmaznayaGroza","description":"\n\t\n\t\t\n\t\tCyrillic Language Classification Corpus\n\t\n\nThis corpus contains texts in 26 languages using the Cyrillic alphabet, designed for the task of automatic language identification.\n\n\t\n\t\t\n\t\tSummary\n\t\n\n\nLanguages: 26 individual Cyrillic languages, plus 17 mixed language combinations created through augmentation\nSource: texts collected from Wikipedia and augmented using various methods\nSize: 20,232 examples in total, including 18,334 original articles collected from Wikipedia and 1,898 texts‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/AlmaznayaGroza/cyrillic-language-classification.","first_N":5,"first_N_keywords":["text-classification","Belarusian","Ukrainian","Russian","Bulgarian"],"keywords_longer_than_N":true},
	{"name":"common_voice_21_0","keyword":"serbian","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/2Jyq/common_voice_21_0","creator_name":"2Jyq","creator_url":"https://huggingface.co/2Jyq","description":"Due to storage limits some files had to be split into multiple parts. They can be merged like this: cat file.* > file.\n","first_N":5,"first_N_keywords":["crowdsourced","crowdsourced","multilingual","extended|common_voice","Abkhaz"],"keywords_longer_than_N":true},
	{"name":"morphscore","keyword":"serbian","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/catherinearnett/morphscore","creator_name":"Catherine Arnett","creator_url":"https://huggingface.co/catherinearnett","description":"\n\t\n\t\t\n\t\tMorphScore\n\t\n\nMorphScore is a tokenizer evaluation framework, which evaluates the extent to which a tokenizer segments words along morpheme boundaries. This repository contains the datasets used to calculate MorphScore.\nIn total, we have datasetes for 86 languages, but only 70 languages have at least 100 items after filtering. \nAll datasets are derived from existing Universal Dependencies treebanks. In the table below, we link the source dataset for each language. \nSee the new preprint‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/catherinearnett/morphscore.","first_N":5,"first_N_keywords":["Arabic","English","German","Russian","Turkish"],"keywords_longer_than_N":true},
	{"name":"sib200_14classes","keyword":"serbian","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Davlan/sib200_14classes","creator_name":"David Adelani","creator_url":"https://huggingface.co/Davlan","description":"\n\t\n\t\t\n\t\tDataset Card for SIB-200\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nSIB-200 is the largest publicly available topic classification dataset based on Flores-200 covering 205 languages and dialects.\nThe train/validation/test sets are available for all the 205 languages.\nThis is another version with 14 classes, more idea for few-shot evaluation, it has 5 examples for few-shot, and larger test set (1225)\n\n\t\n\t\t\n\t\tSupported Tasks and Leaderboards\n\t\n\n\ntopic classification: categorize wikipedia sentences‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Davlan/sib200_14classes.","first_N":5,"first_N_keywords":["text-classification","topic-classification","found","expert-generated","multilingual"],"keywords_longer_than_N":true},
	{"name":"SerbianEmailsNER","keyword":"serbian","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/goranagojic/SerbianEmailsNER","creator_name":"Gorana Gojic","creator_url":"https://huggingface.co/goranagojic","description":"\n\t\n\t\t\n\t\tSerbianEmailsNER Dataset\n\t\n\nAn LLM-generated synthetic dataset comprising of emails in Serbian language and corresponding NER annotations. The primary purpose of the dataset is to be used in evaluation of NER models and anonymization software for Serbian language.\n\n\t\n\t\t\n\t\tüìù Summary\n\t\n\nThis dataset contains 300 synthetically generated emails written in both Latin and Cyrillic scripts, evenly split across four real-world correspondence types: \n\nprivate-to-private \nprivate-to-business‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/goranagojic/SerbianEmailsNER.","first_N":5,"first_N_keywords":["token-classification","Serbian","apache-2.0","< 1K","json"],"keywords_longer_than_N":true},
	{"name":"wikipedia-monthly","keyword":"serbian","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/omarkamali/wikipedia-monthly","creator_name":"Omar Kamali","creator_url":"https://huggingface.co/omarkamali","description":"\n\t\n\t\t\n\t\tüöÄ Wikipedia Monthly\n\t\n\nLast updated: July 16, 2025, 22:53 UTC\nThis repository provides monthly, multilingual dumps of Wikipedia, processed and prepared for easy use in NLP projects.\nNOTE: The first run is still in progress and languages are still being processed and uploaded.\n\n\n\t\n\t\t\n\t\tüìä Live Statistics\n\t\n\n\n\t\n\t\t\nMetric\nValue\n\n\n\t\t\nüåç Languages Available\n341\n\n\nüìÑ Total Articles\n64.5M\n\n\nüíæ Total Size\n205.54 GB\n\n\n\t\n\n\n\n\t\n\t\t\n\t\tWhy Use This Dataset?\n\t\n\n\nFreshness: We run our pipeline monthly‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/omarkamali/wikipedia-monthly.","first_N":5,"first_N_keywords":["Abkhaz","Achinese","Adyghe","Afrikaans","Akan"],"keywords_longer_than_N":true},
	{"name":"HPLT2.0_cleaned","keyword":"serbian","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/HPLT/HPLT2.0_cleaned","creator_name":"HPLT","creator_url":"https://huggingface.co/HPLT","description":"This is a large-scale collection of web-crawled documents in 191 world languages, produced by the HPLT project. \nThe source of the data is mostly Internet Archive with some additions from Common Crawl.\nFor a detailed description of the dataset, please refer to our website and our pre-print.\n\n\t\n\t\t\n\t\n\t\n\t\tThe Cleaned variant of HPLT Datasets v2.0\n\t\n\nThis is the cleaned variant of the HPLT Datasets v2.0 converted to the Parquet format semi-automatically when being uploaded here. \nThe original‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/HPLT/HPLT2.0_cleaned.","first_N":5,"first_N_keywords":["fill-mask","text-generation","language-modeling","multilingual","Achinese"],"keywords_longer_than_N":true},
	{"name":"Global-MMLU","keyword":"serbian","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/CohereLabs/Global-MMLU","creator_name":"Cohere Labs","creator_url":"https://huggingface.co/CohereLabs","description":"\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nGlobal-MMLU üåç is a multilingual evaluation set spanning 42 languages, including English. This dataset combines machine translations for MMLU questions along with professional translations and crowd-sourced post-edits.\nIt also includes cultural sensitivity annotations for a subset of the questions (2850 questions per language) and classifies them as Culturally Sensitive (CS) üóΩ or Culturally Agnostic (CA) ‚öñÔ∏è. These annotations were collected as part of an open‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/CohereLabs/Global-MMLU.","first_N":5,"first_N_keywords":["English","Arabic","Bengali","Spanish","French"],"keywords_longer_than_N":true},
	{"name":"aya_collection","keyword":"serbian","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/CohereLabs/aya_collection","creator_name":"Cohere Labs","creator_url":"https://huggingface.co/CohereLabs","description":"\nThis dataset is uploaded in two places: here and additionally here as 'Aya Collection Language Split.' These datasets are identical in content but differ in structure of upload. This dataset is structured by folders split according to dataset name. The version here instead divides the Aya collection into folders split by language. We recommend you use the language split version if you are only interested in downloading data for a single or smaller set of languages, and this version if you‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/CohereLabs/aya_collection.","first_N":5,"first_N_keywords":["text-classification","summarization","translation","Achinese","Afrikaans"],"keywords_longer_than_N":true},
	{"name":"aya_evaluation_suite","keyword":"serbian","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/CohereLabs/aya_evaluation_suite","creator_name":"Cohere Labs","creator_url":"https://huggingface.co/CohereLabs","description":"\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nAya Evaluation Suite contains a total of 26,750 open-ended conversation-style prompts to evaluate multilingual open-ended generation quality.To strike a balance between language coverage and the quality that comes with human curation, we create an evaluation suite that includes:\n\nhuman-curated examples in 7 languages (tur, eng, yor, arb, zho, por, tel) ‚Üí aya-human-annotated.\nmachine-translations of handpicked examples into 101 languages ‚Üí dolly-machine-translated.‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/CohereLabs/aya_evaluation_suite.","first_N":5,"first_N_keywords":["text-generation","crowdsourced","expert-generated","machine-generated","multilingual"],"keywords_longer_than_N":true},
	{"name":"wmt24pp","keyword":"serbian","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/google/wmt24pp","creator_name":"Google","creator_url":"https://huggingface.co/google","description":"\n\t\n\t\t\n\t\tWMT24++\n\t\n\nThis repository contains the human translation and post-edit data for the 55 en->xx language pairs released in\nthe publication\nWMT24++: Expanding the Language Coverage of WMT24 to 55 Languages & Dialects.\nIf you are interested in the MT/LLM system outputs and automatic metric scores, please see MTME.\nIf you are interested in the images of the source URLs for each document, please see here.\n\n\t\n\t\t\n\t\n\t\n\t\tSchema\n\t\n\nEach language pair is stored in its own jsonl file.\nEach row is‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/google/wmt24pp.","first_N":5,"first_N_keywords":["translation","Arabic","Bulgarian","Bengali","Catalan"],"keywords_longer_than_N":true},
	{"name":"vox-communis-parallel-g2p","keyword":"serbian","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/fdemelo/vox-communis-parallel-g2p","creator_name":"Fl√°vio Eler De Melo","creator_url":"https://huggingface.co/fdemelo","description":"\n\t\n\t\t\n\t\tVoxCommunis Parallel G2P dataset\n\t\n\nThis dataset was derived from the VoxCommunis Corpus to provide pairs of utterances along with their\ncorresponding phonemes, side by side, as to ease the training of grapheme-to-phoneme (G2P) models.\nThe original VoxCommunis Corpus features force-aligned TextGrids with phone- and word-level segmentations derived from the Mozilla Common Voice Corpus.\nThe lexicons were developed using Epitran, the XPF Corpus, Charsiu, and some custom dictionaries.‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/fdemelo/vox-communis-parallel-g2p.","first_N":5,"first_N_keywords":["Abkhaz","Amharic","Bashkir","Belarusian","Bulgarian"],"keywords_longer_than_N":true},
	{"name":"exams","keyword":"serbian","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mhardalov/exams","creator_name":"Momchil Hardalov","creator_url":"https://huggingface.co/mhardalov","description":"\n\t\n\t\t\n\t\tDataset Card for [Dataset Name]\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nEXAMS is a benchmark dataset for multilingual and cross-lingual question answering from high school examinations. It consists of more than 24,000 high-quality high school exam questions in 16 languages, covering 8 language families and 24 school subjects from Natural Sciences and Social Sciences, among others.\n\n\t\n\t\t\n\t\tSupported Tasks and Leaderboards\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nThe languages in the‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mhardalov/exams.","first_N":5,"first_N_keywords":["question-answering","multiple-choice-qa","found","found","monolingual"],"keywords_longer_than_N":true},
	{"name":"opus_ubuntu","keyword":"serbian","license":"BSD 3-Clause \"New\" or \"Revised\" License","license_url":"https://choosealicense.com/licenses/bsd-3-clause/","language":"en","dataset_url":"https://huggingface.co/datasets/Helsinki-NLP/opus_ubuntu","creator_name":"Language Technology Research Group at the University of Helsinki","creator_url":"https://huggingface.co/Helsinki-NLP","description":"\n\t\n\t\t\n\t\tDataset Card for Opus Ubuntu\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThese are translations of the Ubuntu software package messages, donated by the Ubuntu community.\nTo load a language pair which isn't part of the config, all you need to do is specify the language code as pairs.\nYou can find the valid pairs in Homepage section of Dataset Description: http://opus.nlpl.eu/Ubuntu.php\nE.g.\ndataset = load_dataset(\"opus_ubuntu\", lang1=\"it\", lang2=\"pl\")\n\n\t\n\t\t\n\t\n\t\n\t\tSupported Tasks and Leaderboards‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Helsinki-NLP/opus_ubuntu.","first_N":5,"first_N_keywords":["translation","crowdsourced","expert-generated","found","multilingual"],"keywords_longer_than_N":true},
	{"name":"setimes","keyword":"serbian","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/community-datasets/setimes","creator_name":"Community Datasets","creator_url":"https://huggingface.co/community-datasets","description":"\n\t\n\t\t\n\t\tDataset Card for SETimes ‚Äì A Parallel Corpus of English and South-East European Languages\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tSupported Tasks and Leaderboards\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tLanguages\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\n\t\n\t\t\n\t\tData Instances\n\t\n\nHere are some examples of questions and facts:\n\n\t\n\t\t\n\t\tData Fields\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tData Splits\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tDataset Creation‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/community-datasets/setimes.","first_N":5,"first_N_keywords":["translation","found","found","multilingual","original"],"keywords_longer_than_N":true},
	{"name":"mqa","keyword":"serbian","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/clips/mqa","creator_name":"CLiPS","creator_url":"https://huggingface.co/clips","description":"MQA is a multilingual corpus of questions and answers parsed from the Common Crawl. Questions are divided between Frequently Asked Questions (FAQ) pages and Community Question Answering (CQA) pages.","first_N":5,"first_N_keywords":["question-answering","multiple-choice-qa","no-annotation","other","multilingual"],"keywords_longer_than_N":true},
	{"name":"flores_101","keyword":"serbian","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/gsarti/flores_101","creator_name":"Gabriele Sarti","creator_url":"https://huggingface.co/gsarti","description":"One of the biggest challenges hindering progress in low-resource and multilingual machine translation is the \nlack of good evaluation benchmarks. Current evaluation benchmarks either lack good coverage of low-resource \nlanguages, consider only restricted domains, or are low quality because they are constructed using \nsemi-automatic procedures. In this work, we introduce the FLORES evaluation benchmark, consisting of 3001 \nsentences extracted from English Wikipedia and covering a variety of different topics and domains. \nThese sentences have been translated in 101 languages by professional translators through a carefully \ncontrolled process. The resulting dataset enables better assessment of model quality on the long tail of \nlow-resource languages, including the evaluation of many-to-many multilingual translation systems, as all \ntranslations are multilingually aligned. By publicly releasing such a high-quality and high-coverage dataset, \nwe hope to foster progress in the machine translation community and beyond.","first_N":5,"first_N_keywords":["text-generation","translation","found","expert-generated","multilingual"],"keywords_longer_than_N":true},
	{"name":"oscar-small","keyword":"serbian","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/nthngdy/oscar-small","creator_name":"Nathan Godey","creator_url":"https://huggingface.co/nthngdy","description":"The Open Super-large Crawled ALMAnaCH coRpus is a huge multilingual corpus obtained by language classification and filtering of the Common Crawl corpus using the goclassy architecture.\\","first_N":5,"first_N_keywords":["text-generation","language-modeling","no-annotation","found","multilingual"],"keywords_longer_than_N":true},
	{"name":"xlel_wd_dictionary","keyword":"serbian","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/adithya7/xlel_wd_dictionary","creator_name":"Adithya Pratapa","creator_url":"https://huggingface.co/adithya7","description":"XLEL-WD is a multilingual event linking dataset. This sub-dataset contains a dictionary of events from Wikidata. The multilingual descriptions for Wikidata event items are taken from the corresponding Wikipedia articles.","first_N":5,"first_N_keywords":["found","found","multilingual","original","Afrikaans"],"keywords_longer_than_N":true},
	{"name":"xlel_wd","keyword":"serbian","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/adithya7/xlel_wd","creator_name":"Adithya Pratapa","creator_url":"https://huggingface.co/adithya7","description":"XLEL-WD is a multilingual event linking dataset. This dataset contains mention references from multilingual Wikipedia/Wikinews articles to event items in Wikidata. The text descriptions for Wikidata events are compiled from Wikipedia articles.","first_N":5,"first_N_keywords":["found","found","multilingual","original","Afrikaans"],"keywords_longer_than_N":true},
	{"name":"wit_base","keyword":"serbian","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/wikimedia/wit_base","creator_name":"Wikimedia","creator_url":"https://huggingface.co/wikimedia","description":"\n\t\n\t\t\n\t\tDataset Card for WIT\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nWikimedia's version of the Wikipedia-based Image Text (WIT) Dataset, a large multimodal multilingual dataset.\nFrom the official blog post:\n\nThe core training data is taken from the Wikipedia Image-Text (WIT) Dataset, a large curated set of more than 37 million image-text associations extracted from Wikipedia articles in 108 languages that was recently released by Google Research.\nThe WIT dataset offers extremely valuable data about the‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/wikimedia/wit_base.","first_N":5,"first_N_keywords":["image-to-text","text-retrieval","image-captioning","machine-generated","found"],"keywords_longer_than_N":true},
	{"name":"HashtagPrediction","keyword":"serbian","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Twitter/HashtagPrediction","creator_name":"Twitter","creator_url":"https://huggingface.co/Twitter","description":"\n\t\n\t\t\n\t\tHashtag Prediction Dataset from paper TwHIN-BERT: A Socially-Enriched Pre-trained Language Model for Multilingual Tweet Representations\n\t\n\n  \nThis repo contains the Hashtag prediction dataset from our paper TwHIN-BERT: A Socially-Enriched Pre-trained Language Model for Multilingual Tweet Representations. \n[arXiv][HuggingFace Models]\n[Github repo]\nThis work is licensed under a Creative Commons Attribution 4.0 International License.\n\n\t\n\t\t\n\t\n\t\n\t\tDownload\n\t\n\nUse the‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Twitter/HashtagPrediction.","first_N":5,"first_N_keywords":["Slovenian","Urdu","Sindhi","Polish","Vietnamese"],"keywords_longer_than_N":true},
	{"name":"SrpELTeC","keyword":"serbian","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/jerteh/SrpELTeC","creator_name":"Dru≈°tvo za jeziƒçke resurse i tehnologije","creator_url":"https://huggingface.co/jerteh","description":"SrpELTeC is a corpus of old Serbian novels for the first time published in the period 1840-1920. years of digitized within COST ACTION CO16204: Distant Reading for European Literary History, 2018-2022.\nThe corpus includes 120 novels with 5,263.071 words, 22700 pages, 2557 chapters, 158,317 passages, 567 songs, 2972 verses, 803 segments in foreign language and 949 mentioned works.\nDataset is constituted of two text files that can be loaded via:\nfrom datasets import load_dataset\ndataset =‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/jerteh/SrpELTeC.","first_N":5,"first_N_keywords":["text-generation","Serbian","cc-by-4.0","< 1K","json"],"keywords_longer_than_N":true},
	{"name":"oscar-small","keyword":"serbian","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/djstrong/oscar-small","creator_name":"Krzysztof Wr√≥bel","creator_url":"https://huggingface.co/djstrong","description":"The Open Super-large Crawled ALMAnaCH coRpus is a huge multilingual corpus obtained by language classification and filtering of the Common Crawl corpus using the goclassy architecture.\\","first_N":5,"first_N_keywords":["text-generation","language-modeling","no-annotation","found","multilingual"],"keywords_longer_than_N":true},
	{"name":"Fact-Completion","keyword":"serbian","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Polyglot-or-Not/Fact-Completion","creator_name":"Polyglot-or-Not","creator_url":"https://huggingface.co/Polyglot-or-Not","description":"\n\t\n\t\t\n\t\tDataset Card\n\t\n\n\nHomepage: https://bit.ly/ischool-berkeley-capstone\nRepository: https://github.com/daniel-furman/Capstone\nPoint of Contact: daniel_furman@berkeley.edu\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis is the dataset for Polyglot or Not?: Measuring Multilingual Encyclopedic Knowledge Retrieval from Foundation Language Models.\n\n\t\n\t\t\n\t\n\t\n\t\tTest Description\n\t\n\n Given a factual association such as The capital of France is Paris, we determine whether a model adequately \"knows\" this‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Polyglot-or-Not/Fact-Completion.","first_N":5,"first_N_keywords":["text-generation","fill-mask","expert-generated","machine-generated","multilingual"],"keywords_longer_than_N":true},
	{"name":"xP3x","keyword":"serbian","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/CohereLabs/xP3x","creator_name":"Cohere Labs","creator_url":"https://huggingface.co/CohereLabs","description":"\n\t\n\t\t\n\t\tDataset Card for xP3x\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\n\nxP3x (Crosslingual Public Pool of Prompts eXtended) is a collection of prompts & datasets across 277 languages & 16 NLP tasks. It contains all of xP3 + much more! It is used for training future contenders of mT0 & BLOOMZ at project Aya @Cohere Labs üß°\n\n\nCreation: The dataset can be recreated using instructions available here together with the file in this repository named xp3x_create.py. We provide this version to save processing‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/CohereLabs/xP3x.","first_N":5,"first_N_keywords":["other","expert-generated","crowdsourced","multilingual","Afrikaans"],"keywords_longer_than_N":true},
	{"name":"parallel_data","keyword":"serbian","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/MaCoCu/parallel_data","creator_name":"MaCoCu","creator_url":"https://huggingface.co/MaCoCu","description":"The MaCoCu parallel dataset is an English-centric collection of 11\nparallel corpora including the following languages: Albanian,\nBulgarian, Bosnian, Croatian, Icelandic, Macedonian, Maltese,\nMontenegrin, Serbian, Slovenian, and Turkish. These corpora have\nbeen automatically crawled from national and generic top-level\ndomains (for example, \".hr\" for croatian, or \".is\" for icelandic);\nthen, a parallel curation pipeline has been applied to produce\nthe final data (see https://github.com/bitextor/bitextor).","first_N":5,"first_N_keywords":["translation","no-annotation","found","translation","original"],"keywords_longer_than_N":true},
	{"name":"SrpWikiDataset","keyword":"serbian","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/datatab/SrpWikiDataset","creator_name":"Dean","creator_url":"https://huggingface.co/datatab","description":"\nDataset contain text from Wikipedia articles in Serbian (obtained in early 2020) totaling in 477473 articles, as well as some of the WikiSource.\n\n\nDataset is constituted of TXT files.\n\nFixed and used from: JeRTeh/SrpWiki\n\n\n","first_N":5,"first_N_keywords":["text-generation","Serbian","apache-2.0","1M - 10M","parquet"],"keywords_longer_than_N":true},
	{"name":"flores_101","keyword":"serbian","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/severo/flores_101","creator_name":"Sylvain Lesage","creator_url":"https://huggingface.co/severo","description":"One of the biggest challenges hindering progress in low-resource and multilingual machine translation is the \nlack of good evaluation benchmarks. Current evaluation benchmarks either lack good coverage of low-resource \nlanguages, consider only restricted domains, or are low quality because they are constructed using \nsemi-automatic procedures. In this work, we introduce the FLORES evaluation benchmark, consisting of 3001 \nsentences extracted from English Wikipedia and covering a variety of different topics and domains. \nThese sentences have been translated in 101 languages by professional translators through a carefully \ncontrolled process. The resulting dataset enables better assessment of model quality on the long tail of \nlow-resource languages, including the evaluation of many-to-many multilingual translation systems, as all \ntranslations are multilingually aligned. By publicly releasing such a high-quality and high-coverage dataset, \nwe hope to foster progress in the machine translation community and beyond.","first_N":5,"first_N_keywords":["text-generation","translation","found","expert-generated","multilingual"],"keywords_longer_than_N":true},
	{"name":"xP3x-sample","keyword":"serbian","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Muennighoff/xP3x-sample","creator_name":"Niklas Muennighoff","creator_url":"https://huggingface.co/Muennighoff","description":"A multilingual collection of Winograd Schemas in six languages that can be used for evaluation of cross-lingual commonsense reasoning capabilities.","first_N":5,"first_N_keywords":["other","expert-generated","crowdsourced","multilingual","Afrikaans"],"keywords_longer_than_N":true},
	{"name":"ggml-vicuna-v0-quantized","keyword":"serbian","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/maknee/ggml-vicuna-v0-quantized","creator_name":"maknee","creator_url":"https://huggingface.co/maknee","description":"These are quantized ggml binary files for vicuna 7B and 13B models. The version of vicuna for these models are v0.\nThese files can be used in conjunction with minigpt4 ggml models 7B and 13B in minigpt4.cpp\nRecommended are the Q5_K and Q6_K implementations. If there are any issues, use Q4_1 or Q4_0.\n\n\n\t\n\t\t\n\t\n\t\n\t\tVicuna Model Card\n\t\n\n\n\t\n\t\t\n\t\n\t\n\t\tModel details\n\t\n\nModel type:\nVicuna is an open-source chatbot trained by fine-tuning LLaMA on user-shared conversations collected from ShareGPT.\nIt is‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/maknee/ggml-vicuna-v0-quantized.","first_N":5,"first_N_keywords":["English","Bulgarian","Catalan","Czech","Danish"],"keywords_longer_than_N":true},
	{"name":"alpaca-cleaned-serbian-full","keyword":"serbian","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/datatab/alpaca-cleaned-serbian-full","creator_name":"Dean","creator_url":"https://huggingface.co/datatab","description":"\n\t\n\t\t\n\t\tSerbian Alpaca Cleaned Dataset\n\t\n\n\nOriginal Repository: https://github.com/gururise/AlpacaDataCleaned\nOriginal HF Repository: https://huggingface.co/datasets/yahma/alpaca-cleaned\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis is a serbian cleaned version of the original Alpaca Dataset released by Stanford. The following issues have been identified in the original release and fixed in this dataset:\n\nHallucinations: Many instructions in the original dataset had instructions referencing data on the‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/datatab/alpaca-cleaned-serbian-full.","first_N":5,"first_N_keywords":["text-generation","Serbian","cc-by-4.0","10K - 100K","json"],"keywords_longer_than_N":true},
	{"name":"sib200","keyword":"serbian","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Davlan/sib200","creator_name":"David Adelani","creator_url":"https://huggingface.co/Davlan","description":"\n\t\n\t\t\n\t\tDataset Card for SIB-200\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nSIB-200 is the largest publicly available topic classification dataset based on Flores-200 covering 205 languages and dialects.\nThe train/validation/test sets are available for all the 205 languages.\n\n\t\n\t\t\n\t\tSupported Tasks and Leaderboards\n\t\n\n\ntopic classification: categorize wikipedia sentences into topics e.g science/technology, sports or politics.\n\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nThere are 205 languages available :\n\n\t\n\t\t\n\t\tDataset‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Davlan/sib200.","first_N":5,"first_N_keywords":["text-classification","topic-classification","found","expert-generated","multilingual"],"keywords_longer_than_N":true},
	{"name":"wikianc","keyword":"serbian","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/cyanic-selkie/wikianc","creator_name":"cyanic-selkie","creator_url":"https://huggingface.co/cyanic-selkie","description":"\n\t\n\t\t\n\t\tDataset Card for WikiAnc\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThe WikiAnc dataset is an automatically generated dataset from Wikipedia (all languages) and Wikidata dumps (August, 2023). \nThe code for generating the dataset can be found here.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\n\nwikificiation: The dataset can be used to train a model for Wikification.\nnamed-entity-linking: The dataset can be used to train a model for Named Entity Linking.\n\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nThe text in the dataset is in all 320‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/cyanic-selkie/wikianc.","first_N":5,"first_N_keywords":["token-classification","machine-generated","crowdsourced","machine-generated","crowdsourced"],"keywords_longer_than_N":true},
	{"name":"entity_cs","keyword":"serbian","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/huawei-noah/entity_cs","creator_name":"HUAWEI Noah's Ark Lab","creator_url":"https://huggingface.co/huawei-noah","description":"\n\t\n\t\t\n\t\tDataset Card for EntityCS\n\t\n\n\nRepository: https://github.com/huawei-noah/noah-research/tree/master/NLP/EntityCS  \nPaper: https://aclanthology.org/2022.findings-emnlp.499.pdf  \nPoint of Contact: Fenia Christopoulou, Chenxi Whitehouse\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Description\n\t\n\nWe use the English Wikipedia and leverage entity information from Wikidata to construct an entity-based Code Switching corpus. \nTo achieve this, we make use of wikilinks in Wikipedia, i.e. links from one page to another.‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/huawei-noah/entity_cs.","first_N":5,"first_N_keywords":["Afrikaans","Amharic","Arabic","Assamese","Azerbaijani"],"keywords_longer_than_N":true},
	{"name":"juzne_vesti","keyword":"serbian","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/5roop/juzne_vesti","creator_name":"Peter Rupnik","creator_url":"https://huggingface.co/5roop","description":"\n\t\n\t\t\n\t\tASR training dataset for Serbian JuzneVesti-SR v1.0\n\t\n\nhdl: http://hdl.handle.net/11356/1679\nThe JuzneVesti-SR dataset consists of audio recordings and manual transcripts from the Ju≈æne Vesti website and its host show called '15 minuta' (https://www.juznevesti.com/Tagovi/Intervju-15-minuta.sr.html). \nThe processing of the audio and its alignment to the manual transcripts followed the pipeline of the ParlaSpeech-HR dataset (http://hdl.handle.net/11356/1494) as closely as possible.‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/5roop/juzne_vesti.","first_N":5,"first_N_keywords":["Serbian","cc-by-sa-4.0","10K - 100K","parquet","Audio"],"keywords_longer_than_N":true},
	{"name":"multilingual-pl-bert","keyword":"serbian","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/styletts2-community/multilingual-pl-bert","creator_name":"StyleTTS 2 Community","creator_url":"https://huggingface.co/styletts2-community","description":"Attribution: Wikipedia.org\n","first_N":5,"first_N_keywords":["Afrikaans","Aragonese","Arabic","Azerbaijani","Bashkir"],"keywords_longer_than_N":true},
	{"name":"uner_llm_instructions","keyword":"serbian","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/universalner/uner_llm_instructions","creator_name":"Universal NER","creator_url":"https://huggingface.co/universalner","description":"\n\t\n\t\t\n\t\tDataset Card for Universal NER v1 in the Aya format\n\t\n\nThis dataset is a format conversion from its original v1 format into the Aya instruction format and it's released here under the same CC-BY-SA 4.0 license and conditions.\nIt contains data in multiple languages and this version is intended for multi-lingual LLM construction/tuning.\nThe dataset contains different subsets and their dev/test/train splits, depending on language. \n\n\t\n\t\t\n\t\tCitation\n\t\n\nIf you utilize this dataset version‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/universalner/uner_llm_instructions.","first_N":5,"first_N_keywords":["token-classification","Cebuano","Danish","German","English"],"keywords_longer_than_N":true},
	{"name":"uner_llm_inst_serbian","keyword":"serbian","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/universalner/uner_llm_inst_serbian","creator_name":"Universal NER","creator_url":"https://huggingface.co/universalner","description":"\n\t\n\t\t\n\t\tDataset Card for Universal NER v1 in the Aya format - Serbian subset\n\t\n\nThis dataset is a format conversion for the Serbian data in the original Universal NER v1 into the Aya instruction format and it's released here under the same CC-BY-SA 4.0 license and conditions.\nThe dataset contains different subsets and their dev/test/train splits, depending on language. For more details, please refer to:\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\nFor the original Universal NER dataset v1 and more details‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/universalner/uner_llm_inst_serbian.","first_N":5,"first_N_keywords":["token-classification","Serbian","cc-by-sa-4.0","1K - 10K","json"],"keywords_longer_than_N":true},
	{"name":"aya_dataset","keyword":"serbian","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/CohereLabs/aya_dataset","creator_name":"Cohere Labs","creator_url":"https://huggingface.co/CohereLabs","description":"\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThe Aya Dataset is a multilingual instruction fine-tuning dataset curated by an open-science community via Aya Annotation Platform from Cohere Labs. The dataset contains a total of 204k human-annotated prompt-completion pairs along with the demographics data of the annotators.\nThis dataset can be used to train, finetune, and evaluate multilingual LLMs.\n\nCurated by: Contributors of Aya Open Science Intiative.\n\nLanguage(s): 65 languages (71 including dialects &‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/CohereLabs/aya_dataset.","first_N":5,"first_N_keywords":["other","crowdsourced","expert-generated","crowdsourced","expert-generated"],"keywords_longer_than_N":true},
	{"name":"language_tags","keyword":"serbian","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/lbourdois/language_tags","creator_name":"Lo√Øck BOURDOIS","creator_url":"https://huggingface.co/lbourdois","description":"\n\t\n\t\t\n\t\tDescription\n\t\n\nDataset listing 27,328 languages and dialects (also includes macrolanguage names).For each language, either the ISO 639 code, the Glottolog code or both are provided.\n\n\t\n\t\t\n\t\tColumns\n\t\n\n\nEnglish_Name: Language name in English (e.g. \"French\").\nNative_Name: If value is not 0, corresponds to the name of the language by native speakers (e.g. \"Fran√ßais\") which may have been found in Wikipedia's nativename field.\nGlottocode: The language tag in the Glottolog convention (e.g.‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/lbourdois/language_tags.","first_N":5,"first_N_keywords":["Afade","Par√° Ar√°ra","Afar","Aka-Bea","Abon"],"keywords_longer_than_N":true},
	{"name":"udhr-lid","keyword":"serbian","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/cis-lmu/udhr-lid","creator_name":"CIS, LMU Munich","creator_url":"https://huggingface.co/cis-lmu","description":"\n\t\n\t\t\n\t\tUDHR-LID\n\t\n\nWhy UDHR-LID?\nYou can access UDHR (Universal Declaration of Human Rights) here, but when a verse is missing, they have texts such as \"missing\" or \"?\". Also, about 1/3 of the sentences consist only of \"articles 1-30\" in different languages. We cleaned the entire dataset from XML files and selected only the paragraphs. We cleared any unrelated language texts from the data and also removed the cases that were incorrect.\nIncorrect? Look at the ckb and kmr files in the UDHR.‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/cis-lmu/udhr-lid.","first_N":5,"first_N_keywords":["multilingual","Tigrinya","Balkan Romani","Standard Arabic","Metlat√≥noc Mixtec"],"keywords_longer_than_N":true},
	{"name":"COPA-SR","keyword":"serbian","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/classla/COPA-SR","creator_name":"CLASSLA - CLARIN Knowledge Centre for South Slavic Languages","creator_url":"https://huggingface.co/classla","description":"\n\t\n\t\t\n\t\tCOPA-SR\n\t\n\n(The dataset uses cyrillic script. For the latin version, see this dataset.)\nThe COPA-SR dataset (Choice of plausible alternatives in Serbian) is a translation of the English COPA dataset  by following the XCOPA dataset translation methodology .\nThe dataset consists of 1,000 premises (My body cast a shadow over the grass), each given a question (What is the cause? / What happened as a result?), and two choices (The sun was rising; The grass was cut), with a label encoding‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/classla/COPA-SR.","first_N":5,"first_N_keywords":["text-classification","Serbian","cc-by-sa-4.0","1K - 10K","json"],"keywords_longer_than_N":true},
	{"name":"COPA-SR_lat","keyword":"serbian","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/classla/COPA-SR_lat","creator_name":"CLASSLA - CLARIN Knowledge Centre for South Slavic Languages","creator_url":"https://huggingface.co/classla","description":"\n\t\n\t\t\n\t\tCOPA-SR_lat\n\t\n\n(The dataset uses latin script. For the original (cyrillic) version, see this dataset.)\nThe COPA-SR dataset (Choice of plausible alternatives in Serbian) is a translation of the English COPA dataset  by following the XCOPA dataset translation methodology , transliterated into Latin script.\nThe dataset consists of 1,000 premises (My body cast a shadow over the grass), each given a question (What is the cause? / What happened as a result?), and two choices (The sun was‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/classla/COPA-SR_lat.","first_N":5,"first_N_keywords":["text-classification","Serbian","cc-by-sa-4.0","1K - 10K","json"],"keywords_longer_than_N":true},
	{"name":"ChatML-aya_dataset","keyword":"serbian","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Felladrin/ChatML-aya_dataset","creator_name":"Victor Nogueira","creator_url":"https://huggingface.co/Felladrin","description":"CohereForAI/aya_dataset in ChatML format, ready to use in HuggingFace TRL's SFT Trainer.\nPython code used for conversion:\nfrom datasets import load_dataset\nfrom transformers import AutoTokenizer\n\ntokenizer = AutoTokenizer.from_pretrained(\"Felladrin/Llama-160M-Chat-v1\")\n\ndataset = load_dataset(\"CohereForAI/aya_dataset\", split=\"train\")\n\ndef format(columns):\n    messages = [\n        {\n            \"role\": \"user\",\n            \"content\": columns[\"inputs\"].strip(),\n        },\n        {‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Felladrin/ChatML-aya_dataset.","first_N":5,"first_N_keywords":["question-answering","text-generation","crowdsourced","expert-generated","crowdsourced"],"keywords_longer_than_N":true},
	{"name":"ParlaSent","keyword":"serbian","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/classla/ParlaSent","creator_name":"CLASSLA - CLARIN Knowledge Centre for South Slavic Languages","creator_url":"https://huggingface.co/classla","description":"\n\t\n\t\t\n\t\tThe multilingual sentiment dataset of parliamentary debates ParlaSent 1.0\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset was created and used for sentiment analysis experiments.\nThe dataset consists of five training datasets and two test sets. The test sets have a _test.jsonl suffix and appear in the Dataset Viewer as _additional_test.\nEach test set consists of 2,600 sentences, annotated by one highly trained annotator. Training datasets were internally split into \"train\", \"dev\" and \"test\"‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/classla/ParlaSent.","first_N":5,"first_N_keywords":["text-classification","Slovenian","English","Czech","Bosnian"],"keywords_longer_than_N":true},
	{"name":"aya_collection_language_split","keyword":"serbian","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/CohereLabs/aya_collection_language_split","creator_name":"Cohere Labs","creator_url":"https://huggingface.co/CohereLabs","description":"\nThis is a re-upload of the aya_collection, and only differs in the structure of upload. While the original aya_collection is structured by folders split according to dataset name, this dataset is split by language. We recommend you use this version of the dataset if you are only interested in downloading all of the Aya collection for a single or smaller set of languages.\n\n\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThe Aya Collection is a massive multilingual collection consisting of 513 million instances of‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/CohereLabs/aya_collection_language_split.","first_N":5,"first_N_keywords":["Achinese","Afrikaans","Amharic","Arabic","Azerbaijani"],"keywords_longer_than_N":true},
	{"name":"tokenizer-wiki-bench","keyword":"serbian","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/occiglot/tokenizer-wiki-bench","creator_name":"Occiglot","creator_url":"https://huggingface.co/occiglot","description":"\n\t\n\t\t\n\t\tMultilingual Tokenizer Benchmark\n\t\n\nThis dataset includes pre-processed wikipedia data for tokenizer evaluation in 45 languages. We provide more information on the evaluation task in general this blogpost.\n\n\t\n\t\t\n\t\tUsage\n\t\n\nThe dataset allows us to easily calculate tokenizer fertility and the proportion of continued words on any of the supported languages. In the example below we take the Mistral tokenizer and evaluate its performance on Slovak. \nfrom transformers import AutoTokenizer‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/occiglot/tokenizer-wiki-bench.","first_N":5,"first_N_keywords":["Afrikaans","Arabic","Bulgarian","Catalan","Czech"],"keywords_longer_than_N":true},
	{"name":"EQ-Bench-Serbian","keyword":"serbian","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Stopwolf/EQ-Bench-Serbian","creator_name":"Sinisa Stanivuk","creator_url":"https://huggingface.co/Stopwolf","description":"\n\t\n\t\t\n\t\tEQ-Bench-Serbian üá∑üá∏\n\t\n\nEQ-Bench is a benchmark for language models designed to assess emotional intelligence. You can read more about it in the paper.\nThe reason this benchmark was picked is because EQ-Bench in English has very high correlation with LMSYS Arena Elo scores \n(has a 0.97 correlation w/ MMLU, and a 0.94 correlation w/ Arena Elo.). \nSince it wouldn't be feasible to create an arena for a couple of models available for Serbian, we went in this direction.\nThis dataset has‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Stopwolf/EQ-Bench-Serbian.","first_N":5,"first_N_keywords":["Serbian","Bosnian","Croatian","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"panlex-meanings","keyword":"serbian","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/cointegrated/panlex-meanings","creator_name":"David Dale","creator_url":"https://huggingface.co/cointegrated","description":"\n\t\n\t\t\n\t\tDataset Card for panlex-meanings\n\t\n\nThis is a dataset of words in several thousand languages, extracted from https://panlex.org.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset has been extracted from https://panlex.org (the 20240301 database dump) and rearranged on the per-language basis.\nEach language subset consists of expressions (words and phrases). \nEach expression is associated with some meanings (if there is more than one meaning, they are in separate‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/cointegrated/panlex-meanings.","first_N":5,"first_N_keywords":["translation","Afar","Western Abnaki","Abkhazian","Abaza"],"keywords_longer_than_N":true},
	{"name":"SrpKorNews","keyword":"serbian","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/jerteh/SrpKorNews","creator_name":"Dru≈°tvo za jeziƒçke resurse i tehnologije","creator_url":"https://huggingface.co/jerteh","description":"\n\t\n\t\t\n\t\tHighly curated, High-quality, Serbian news corpus\n\t\n\nEach line represents document.\nEach Sentence in a document is delimited.\nDataset contains Serbian news source articles which were post-processed and corrected both automatically and manually.\nIt contains around 468 million words.\nfrom datasets import load_dataset\ndataset = load_dataset(\"jerteh/SrpKorNews\")\n\nPreview:\nprint(dataset[\"train\"][3088])\n{'text': '\"Srbija je dobro mesto za investicije i to bi trebalo iskoristiti, kako bi‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/jerteh/SrpKorNews.","first_N":5,"first_N_keywords":["text-generation","Serbian","cc-by-4.0","1M - 10M","text"],"keywords_longer_than_N":true},
	{"name":"SrpKor4Tagging","keyword":"serbian","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/jerteh/SrpKor4Tagging","creator_name":"Dru≈°tvo za jeziƒçke resurse i tehnologije","creator_url":"https://huggingface.co/jerteh","description":"Corpus is created via mix of literary (‚Öì) and administrative (‚Öî) texts in Serbian.\nIt is tagged for POS for 2 tagsets: Universal POS tagset and SrpLemKor tagset (made according to traditional, descriptive Serbian grammar) and lemmatized\nIt is constituted of a single jsonl file that can be loaded via:\nfrom datasets import load_dataset\ndataset = load_dataset(\"jerteh/SrpKor4Tagging\")\n\nPreview:\nds = dataset[\"train\"][1389]\nfor x, y, z in zip(ds[\"token\"], ds[\"ud\"], ds[\"lemma\"]):\n    print(x, y, z)‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/jerteh/SrpKor4Tagging.","first_N":5,"first_N_keywords":["token-classification","Serbian","cc-by-sa-4.0","10K - 100K","json"],"keywords_longer_than_N":true},
	{"name":"SrpELTeC-gold-NER","keyword":"serbian","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/jerteh/SrpELTeC-gold-NER","creator_name":"Dru≈°tvo za jeziƒçke resurse i tehnologije","creator_url":"https://huggingface.co/jerteh","description":"Named Entity Recognition Training corpus for Serbian ‚Äì The selection of 11 full novels and excerpts from 15 novels from Serbian literary corpus of novels written more than a century ago, have been automatically labelled with SrpNER system for Serbian  in the first stage of the gold standard preparation. Contains 330.119 tokens, 7 classes: person, organization, location, event, work, demonym, role.\nIt is constituted of a single jsonl file that can be loaded via:\nfrom datasets import‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/jerteh/SrpELTeC-gold-NER.","first_N":5,"first_N_keywords":["token-classification","Serbian","cc-by-sa-4.0","10K - 100K","json"],"keywords_longer_than_N":true},
	{"name":"PaSaz","keyword":"serbian","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/jerteh/PaSaz","creator_name":"Dru≈°tvo za jeziƒçke resurse i tehnologije","creator_url":"https://huggingface.co/jerteh","description":"\n  \n  \n    PaSa≈æ\n  \n  \n  \n    \n      Korpus Paralelnih Sa≈æetaka doktorskih disertacija na srpskom i engleskom jeziku\n      Visoko-kvalitetan skup kratkih prevoda\n      Ukupno 10.492 paralelnih jedinica. Velika veƒáina sadr≈æi i paralelizovane naslove.\n    \n    \n       Parallel Serbian-English corpus of doctoral dissertation abstracts\n      High-quality set of short translations\n      A total of 10,492 parallel units. The vast majority also contain parallel titles.\n    \n  \n\n\n\n\nfrom datasets‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/jerteh/PaSaz.","first_N":5,"first_N_keywords":["Serbian","English","cc-by-sa-4.0","10K - 100K","json"],"keywords_longer_than_N":true},
	{"name":"NARDUS-meta","keyword":"serbian","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/jerteh/NARDUS-meta","creator_name":"Dru≈°tvo za jeziƒçke resurse i tehnologije","creator_url":"https://huggingface.co/jerteh","description":"\n\t\n\t\t\n\t\tSkup metapodataka sa platforme NARDUS\n\t\n\n\n\t\n\t\n\t\n\t\tSkup sadr≈æi sledeƒáe podatke o doktorskim disertacijama:\n  - URL disertacije\n  - Naslov na srpskom\n  - Naslov na engleskom\n  - Spisak mentora,\n  - Spisak ƒçlanova komisije\n  - Autor,\n  - Datum objavljivanja\n  - URI\n  - Sa≈æetak na srpskom\n  - Sa≈æetak na engleskom\n  - Format\n  - Izdavaƒç (fakultet)\n  - Prava pristupa\n  - URI licence\n  - Spisak kjuƒçnih reƒçi na srpskom\n  - Spisak kjuƒçnih reƒçi na engleskom\n\t URL do PDF-a\n\nRCUB ID\n\nNauƒçna oblast‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/jerteh/NARDUS-meta.","first_N":5,"first_N_keywords":["Serbian","English","cc-by-sa-4.0","10K - 100K","json"],"keywords_longer_than_N":true},
	{"name":"high-quality-multilingual-sentences","keyword":"serbian","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/agentlans/high-quality-multilingual-sentences","creator_name":"Alan Tseng","creator_url":"https://huggingface.co/agentlans","description":"\n\t\n\t\t\n\t\tHigh Quality Multilingual Sentences\n\t\n\n\nThis dataset contains multilingual sentences derived from the agentlans/LinguaNova dataset.\nIt includes 1.58 million rows across 51 different languages, each in its own configuration.\n\nExample row (from the all config):\n{\n    \"text\": \"ÿßŸÖÿßŸÖ ÿ¨ŸÖÿπŸá ÿßÿµŸÅŸáÿßŸÜ ⁄ØŸÅÿ™: ŸÖ€åÿ≤ÿßŸÜ ŸÜ€åÿßÿ≤ ÿ¢ÿ® ÿ¥ÿ±ÿ® ÿßÿµŸÅŸáÿßŸÜ €±€±.€µ ŸÖÿ™ÿ± ŸÖ⁄©ÿπÿ® ÿßÿ≥ÿ™ ⁄©Ÿá ÿ™ŸÖÿßŸÖ ÿßÿ≥ÿ™ÿßŸÜ ÿßÿµŸÅŸáÿßŸÜ ÿ±ÿß ŸæŸàÿ¥ÿ¥ ŸÖ€åÿØŸáÿØ Ÿà ŸÜÿ≥ÿ®ÿ™ ÿ®Ÿá ŸÇÿ®ŸÑ ÿßÿ≤ ÿßŸÜŸÇŸÑÿßÿ® €å⁄©€å ÿßÿ≤ Ÿæ€åÿ¥ÿ±ŸÅÿ™Ÿáÿß ÿØÿ± ÿ≠Ÿàÿ≤Ÿá ÿ¢ÿ® ÿ®ŸàÿØŸá ÿßÿ≥ÿ™.\",\n    \"fasttext\": \"fa\",\n    \"gcld3\": \"fa\"\n}\n\nFields:‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/agentlans/high-quality-multilingual-sentences.","first_N":5,"first_N_keywords":["text-generation","text-classification","text-retrieval","multilingual","Arabic"],"keywords_longer_than_N":true},
	{"name":"lr-sum","keyword":"serbian","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/bltlab/lr-sum","creator_name":"Broadening Linguistic Technologies Lab (BLT Lab)","creator_url":"https://huggingface.co/bltlab","description":"\n\t\n\t\t\n\t\tDataset Card for LR-Sum\n\t\n\nLR-Sum is a automatic summarization dataset of newswire text with a focus on less resourced languages with a cc-by 4.0 license.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nLR-Sum is a permissively-licensed dataset created with the goal of enabling further research in automatic summarization for less-resourced languages.\nLR-Sum contains human-written summaries for 39 languages, many of which are less-resourced. \nThe data is based on the‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/bltlab/lr-sum.","first_N":5,"first_N_keywords":["summarization","text-generation","found","found","multilingual"],"keywords_longer_than_N":true},
	{"name":"language-dataset","keyword":"serbian","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neon-mao/language-dataset","creator_name":"maoqifan","creator_url":"https://huggingface.co/neon-mao","description":"\n","first_N":5,"first_N_keywords":["text-classification","English","Chinese","French","Russian"],"keywords_longer_than_N":true},
	{"name":"guanaco-sharegpt-style-serbian","keyword":"serbian","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/datatab/guanaco-sharegpt-style-serbian","creator_name":"Dean","creator_url":"https://huggingface.co/datatab","description":"\n\t\n\t\t\n\t\tGuanaco Sharegpt-style Serbian\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset is a Serbian-translated version of the philschmid/guanaco-sharegpt-style\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\n\t\n\t\t\n\t\tUsage\n\t\n\nTo load the dataset in Serbian, run:\nfrom datasets import load_dataset\n\nds = load_dataset(\"datatab/guanaco-sharegpt-style-serbian\")\n\n\n\t\n\t\t\n\t\tData Splits\n\t\n\nThe dataset has one splits, suitable for:\n\nSupervised fine-tuning (sft).\n\nThe dataset is stored in parquet format with each entry using‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/datatab/guanaco-sharegpt-style-serbian.","first_N":5,"first_N_keywords":["question-answering","text-generation","Serbian","apache-2.0","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"gest","keyword":"serbian","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/kinit/gest","creator_name":"Kempelen Institute of Intelligent Technologies","creator_url":"https://huggingface.co/kinit","description":"\n\t\n\t\t\n\t\tGEST Dataset\n\t\n\nThis is a repository for the GEST dataset used to measure gender-stereotypical reasoning in language models and machine translation systems.\n\nPaper: Women Are Beautiful, Men Are Leaders: Gender Stereotypes in Machine Translation and Language Modeling\nCode and additional data (annotation details, translations) are available in our repository\n\n\n\t\n\t\t\n\t\n\t\n\t\tChangelog\n\t\n\n\nDecember 6th 2024 - gest_1.1.csv was added. This is a new version that has 244 typos and other errors‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/kinit/gest.","first_N":5,"first_N_keywords":["English","Slovenian","Slovak","Czech","Polish"],"keywords_longer_than_N":true},
	{"name":"panlex","keyword":"serbian","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/lbourdois/panlex","creator_name":"Lo√Øck BOURDOIS","creator_url":"https://huggingface.co/lbourdois","description":"\n\t\n\t\t\n\t\tPanLex\n\t\n\nJanuary 1, 2024 version of PanLex Language Vocabulary with 24,650,274 rows covering 6,152 languages.\n\n\t\n\t\t\n\t\tColumns\n\t\n\n\nvocab: contains the text entry.  \n639-3: contains the ISO 639-3 languages tags to allow users to filter on the language(s) of their choice.\n639-3_english_name: the English language name associated to the code ISO 639-3. \nvar_code: contains a code to differentiate language variants. In practice, this is the code 639-3 + a number.  If 000, it corresponds to‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/lbourdois/panlex.","first_N":5,"first_N_keywords":["Ghotuo","Alumu-Tesu","Ari","Amal","Arb√´resh√´ Albanian"],"keywords_longer_than_N":true},
	{"name":"open-orca-slim-serbian","keyword":"serbian","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/datatab/open-orca-slim-serbian","creator_name":"Dean","creator_url":"https://huggingface.co/datatab","description":"\n\t\n\t\t\n\t\tPregled\n\t\n\nOvaj segment OpenOrca kolekcije predstavlja pa≈æljivo odabranu selekciju koja omoguƒáava ostvarivanje visokih performansi sliƒçnih onima koje se dobijaju kori≈°ƒáenjem obimnijih delova na≈°eg skupa podataka. Ovog puta, fokus je na kompaktnom skupu od pribli≈æno 500.000 GPT-4 odgovora.\nInovacija koja izdvaja ovu verziju jeste detaljan proces revizije uz pomoƒá GPT-4, gde su izdvojeni i odbaƒçeni odgovori koji nisu u skladu sa standardima kvaliteta utvrƒëenim na osnovu ljudskih ocena iz‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/datatab/open-orca-slim-serbian.","first_N":5,"first_N_keywords":["text-classification","token-classification","table-question-answering","Serbian","mit"],"keywords_longer_than_N":true},
	{"name":"open-orca-slim-serbian-mistral-prepared","keyword":"serbian","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/datatab/open-orca-slim-serbian-mistral-prepared","creator_name":"Dean","creator_url":"https://huggingface.co/datatab","description":"\n\t\n\t\t\n\t\tOverview\n\t\n\n\nOvaj dataset je prilagoƒëen treningu Mistral modela\n\nOvaj segment OpenOrca kolekcije predstavlja pa≈æljivo odabranu selekciju koja omoguƒáava ostvarivanje visokih performansi sliƒçnih onima koje se dobijaju kori≈°ƒáenjem obimnijih delova na≈°eg skupa podataka. Ovog puta, fokus je na kompaktnom skupu od pribli≈æno 500.000 GPT-4 odgovora.\nInovacija koja izdvaja ovu verziju jeste detaljan proces revizije uz pomoƒá GPT-4, gde su izdvojeni i odbaƒçeni odgovori koji nisu u skladu sa‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/datatab/open-orca-slim-serbian-mistral-prepared.","first_N":5,"first_N_keywords":["text-classification","token-classification","table-question-answering","Serbian","mit"],"keywords_longer_than_N":true},
	{"name":"bhojpuri","keyword":"serbian","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ankur02/bhojpuri","creator_name":"Ankur Verma","creator_url":"https://huggingface.co/ankur02","description":"\n\t\n\t\t\n\t\n\t\n\t\tFLEURS\n\t\n\nFleurs is the speech version of the FLoRes machine translation benchmark. \nWe use 2009 n-way parallel sentences from the FLoRes dev and devtest publicly available sets, in 102 languages. \nTraining sets have around 10 hours of supervision. Speakers of the train sets are different than speakers from the dev/test sets. Multilingual fine-tuning is\nused and ‚Äùunit error rate‚Äù (characters, signs) of all languages is averaged. Languages and results are also grouped into seven‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ankur02/bhojpuri.","first_N":5,"first_N_keywords":["automatic-speech-recognition","expert-generated","crowdsourced","machine-generated","crowdsourced"],"keywords_longer_than_N":true},
	{"name":"MultiQ","keyword":"serbian","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/caro-holt/MultiQ","creator_name":"Holtermann","creator_url":"https://huggingface.co/caro-holt","description":"\n\t\n\t\t\n\t\tDataset Card for MultiQ\n\t\n\nThis is the dataset corresponding to the paper \"Evaluating the Elementary Multilingual Capabilities of Large Language Models with MultiQ\". \nIt is a silver standard benchmark that can be used to evaluate the basic multilingual capabilities of LLMs. It contains 200 open ended questions automatically \ntranslated into 137 typologically diverse languages. \n\nCurated by: Carolin Holtermann, Paul R√∂ttger, Timm Dill, Anne Lauscher\nLanguage(s) (NLP): 137 diverse‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/caro-holt/MultiQ.","first_N":5,"first_N_keywords":["question-answering","Tagalog","Samoan","Macedonian","Gujarati"],"keywords_longer_than_N":true},
	{"name":"ultrafeedback_binarized_serbian","keyword":"serbian","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/datatab/ultrafeedback_binarized_serbian","creator_name":"Dean","creator_url":"https://huggingface.co/datatab","description":"\n\t\n\t\t\n\t\tDataset Card for UltraFeedback Binarized Serbian\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset is a Serbian-translated version of the UltraFeedback dataset, utilized for training Zephyr-7Œí-Œ≤. The original dataset comprises 64k English-language prompts, each paired with four completions from various models. In this Serbian version, the prompts and completions have been translated into Serbian. The dataset creation process remains the same: selecting the completion with the highest‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/datatab/ultrafeedback_binarized_serbian.","first_N":5,"first_N_keywords":["text-generation","question-answering","Serbian","mit","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"librivox-tracks","keyword":"serbian","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/pykeio/librivox-tracks","creator_name":"pyke.io","creator_url":"https://huggingface.co/pykeio","description":"A dataset of all audio files uploaded to LibriVox before 26th September 2023.\n","first_N":5,"first_N_keywords":["text-to-speech","automatic-speech-recognition","Achinese","Afrikaans","Ancient Greek (to 1453)"],"keywords_longer_than_N":true},
	{"name":"Pontoon-Translations","keyword":"serbian","license":"Mozilla Public License 2.0","license_url":"https://choosealicense.com/licenses/mpl-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ayymen/Pontoon-Translations","creator_name":"Mohamed Aymane Farhi","creator_url":"https://huggingface.co/ayymen","description":"\n\t\n\t\t\n\t\tDataset Card for Pontoon Translations\n\t\n\n\n\nThis is a dataset containing strings from various Mozilla projects on Mozilla's Pontoon localization platform and their translations into more than 200 languages.\nSource strings are in English.\nTo avoid rows with values like \"None\" and \"N/A\" being interpreted as missing values, pass the keep_default_na parameter like this:\nfrom datasets import load_dataset\n\ndataset = load_dataset(\"ayymen/Pontoon-Translations\", keep_default_na=False)‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ayymen/Pontoon-Translations.","first_N":5,"first_N_keywords":["translation","crowdsourced","Abkhaz","Achinese","Acoli"],"keywords_longer_than_N":true},
	{"name":"serbian-llm-eval-v0","keyword":"serbian","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/gordicaleksa/serbian-llm-eval-v0","creator_name":"Aleksa Gordic","creator_url":"https://huggingface.co/gordicaleksa","description":"\n\t\n\t\t\n\t\n\t\n\t\tSerbian LLM eval v0 üá∑üá∏\n\t\n\nPlease instead use the version 1 of the dataset here.\nWeights & Biases report.\n\n\t\n\t\t\n\t\n\t\n\t\tProject Sponsors\n\t\n\n\n\t\n\t\t\n\t\n\t\n\t\tPlatinum sponsors üåü\n\t\n\n\nIvan (fizicko lice, anoniman)\n\n\n\t\n\t\t\n\t\n\t\n\t\tGold sponsors üü°\n\t\n\n\nqq (fizicko lice, anoniman)\nMitar Perovic\nNikola Ivancevic\n\n\n\t\n\t\t\n\t\n\t\n\t\tSilver sponsors ‚ö™\n\t\n\npsk.rs, OmniStreak, Marko Radojicic, Luka Vazic, Milo≈° Durkoviƒá, Marjan Radeski, Marjan Stankovic (fizicko lice), Nikola Stojiljkovic, Mihailo Tomic‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/gordicaleksa/serbian-llm-eval-v0.","first_N":5,"first_N_keywords":["Serbian","Croatian","Bosnian","apache-2.0","1M<n<10M"],"keywords_longer_than_N":true},
	{"name":"oz-eval","keyword":"serbian","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/DjMel/oz-eval","creator_name":"Milena","creator_url":"https://huggingface.co/DjMel","description":"\n\t\n\t\t\n\t\tOZ Eval\n\t\n\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nOZ Eval (sr. Op≈°te Znanje Evaluacija) dataset was created for the purposes of evaluating General Knowledge of LLM models in Serbian language. \nData consists of 1k+ high-quality questions and answers which were used as part of entry exams at the Faculty of Philosophy and Faculty of Organizational Sciences, University of Belgrade.\nThe exams test the General Knowledge of students and were used in the enrollment periods from 2003 to 2024. \nThis is‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/DjMel/oz-eval.","first_N":5,"first_N_keywords":["question-answering","Serbian","apache-2.0","1K - 10K","parquet"],"keywords_longer_than_N":true},
	{"name":"AyaRedTeaming","keyword":"serbian","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/walledai/AyaRedTeaming","creator_name":"Walled AI","creator_url":"https://huggingface.co/walledai","description":"\n\t\n\t\t\n\t\tDataset Card for Aya Red-teaming\n\t\n\n\n\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\nThe Aya Red-teaming dataset is a human-annotated multilingual red-teaming dataset consisting of harmful prompts in 8 languages across 9 different categories of harm with explicit labels for \"global\" and \"local\" harm.\n\n\n\n\n\n\nCurated by: Professional compensated annotators\nLanguages: Arabic, English, Filipino, French, Hindi, Russian, Serbian and Spanish\nLicense: Apache 2.0\nPaper: arxiv link\n\n\n\t\n\t\t\n\t\n\t\n\t\tHarm Categories:‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/walledai/AyaRedTeaming.","first_N":5,"first_N_keywords":["English","Hindi","French","Spanish","Arabic"],"keywords_longer_than_N":true},
	{"name":"GlotCC-V1","keyword":"serbian","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/cis-lmu/GlotCC-V1","creator_name":"CIS, LMU Munich","creator_url":"https://huggingface.co/cis-lmu","description":"\n\t\n\t\t\n\t\tDataset Summary\n\t\n\n \n\nGlotCC-V1.0 is a document-level, general domain dataset derived from CommonCrawl, covering more than 1000 languages.It is built using the GlotLID language identification and Ungoliant pipeline from CommonCrawl.We release our pipeline as open-source at https://github.com/cisnlp/GlotCC.  \nList of Languages: See https://datasets-server.huggingface.co/splits?dataset=cis-lmu/GlotCC-V1 to get the list of splits available.\n\n\t\t\n\t\tUsage (Huggingface Hub -- Recommended)‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/cis-lmu/GlotCC-V1.","first_N":5,"first_N_keywords":["multilingual","Abau","Amarasi","Abkhaz","Abkhazian"],"keywords_longer_than_N":true},
	{"name":"GlotCC-V1","keyword":"serbian","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/cis-lmu/GlotCC-V1","creator_name":"CIS, LMU Munich","creator_url":"https://huggingface.co/cis-lmu","description":"\n\t\n\t\t\n\t\tDataset Summary\n\t\n\n \n\nGlotCC-V1.0 is a document-level, general domain dataset derived from CommonCrawl, covering more than 1000 languages.It is built using the GlotLID language identification and Ungoliant pipeline from CommonCrawl.We release our pipeline as open-source at https://github.com/cisnlp/GlotCC.  \nList of Languages: See https://datasets-server.huggingface.co/splits?dataset=cis-lmu/GlotCC-V1 to get the list of splits available.\n\n\t\t\n\t\tUsage (Huggingface Hub -- Recommended)‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/cis-lmu/GlotCC-V1.","first_N":5,"first_N_keywords":["multilingual","Abau","Amarasi","Abkhaz","Abkhazian"],"keywords_longer_than_N":true},
	{"name":"Serbian-RAG-Eval","keyword":"serbian","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/IntellyaDS/Serbian-RAG-Eval","creator_name":"Intellya Data Science Team","creator_url":"https://huggingface.co/IntellyaDS","description":"IntellyaDS/Serbian-RAG-Eval dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["Serbian","apache-2.0","10K - 100K","csv","Text"],"keywords_longer_than_N":true},
	{"name":"NTREX","keyword":"serbian","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/davidstap/NTREX","creator_name":"David Stap","creator_url":"https://huggingface.co/davidstap","description":"\n\t\n\t\t\n\t\tDataset Description\n\t\n\nNTREX -- News Test References for MT Evaluation from English into a total of 128 target languages. See original GitHub repo for full details.\nExample of loading:\ndataset = load_dataset(\"davidstap/NTREX\", \"rus_Cyrl\", trust_remote_code=True)\n\n\n\t\n\t\t\n\t\n\t\n\t\tLanguages\n\t\n\nThe following languages are available:\n\n\t\n\t\t\nLanguage Code\nLanguage Name\n\n\n\t\t\nafr_Latn\nAfrikaans\n\n\namh_Ethi\nAmharic\n\n\narb_Arab\nArabic\n\n\naze_Latn\nAzerbaijani\nbak_Cyrl\nBashkir\n\n\nbel_Cyrl\nBelarusian‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/davidstap/NTREX.","first_N":5,"first_N_keywords":["translation","expert-generated","expert-generated","translation","Afrikaans"],"keywords_longer_than_N":true},
	{"name":"biblenlp-corpus-mmteb","keyword":"serbian","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/davidstap/biblenlp-corpus-mmteb","creator_name":"David Stap","creator_url":"https://huggingface.co/davidstap","description":"This dataset pre-computes all English-centric directions from bible-nlp/biblenlp-corpus, and as a result loading is significantly faster.\nLoading example:\n>>> from datasets import load_dataset\n>>> dataset = load_dataset(\"davidstap/biblenlp-corpus-mmteb\", \"eng-arb\", trust_remote_code=True)\n>>> dataset\nDatasetDict({\n    train: Dataset({\n        features: ['eng', 'arb'],\n        num_rows: 28723\n    })\n    validation: Dataset({\n        features: ['eng', 'arb'],\n        num_rows: 1578\n    })‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/davidstap/biblenlp-corpus-mmteb.","first_N":5,"first_N_keywords":["no-annotation","expert-generated","translation","multilingual","Arifama-Miniafia"],"keywords_longer_than_N":true},
	{"name":"biblenlp-corpus-mmteb","keyword":"serbian","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/davidstap/biblenlp-corpus-mmteb","creator_name":"David Stap","creator_url":"https://huggingface.co/davidstap","description":"This dataset pre-computes all English-centric directions from bible-nlp/biblenlp-corpus, and as a result loading is significantly faster.\nLoading example:\n>>> from datasets import load_dataset\n>>> dataset = load_dataset(\"davidstap/biblenlp-corpus-mmteb\", \"eng-arb\", trust_remote_code=True)\n>>> dataset\nDatasetDict({\n    train: Dataset({\n        features: ['eng', 'arb'],\n        num_rows: 28723\n    })\n    validation: Dataset({\n        features: ['eng', 'arb'],\n        num_rows: 1578\n    })‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/davidstap/biblenlp-corpus-mmteb.","first_N":5,"first_N_keywords":["no-annotation","expert-generated","translation","multilingual","Arifama-Miniafia"],"keywords_longer_than_N":true},
	{"name":"xsimplusplus","keyword":"serbian","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/jaygala24/xsimplusplus","creator_name":"Jay Gala","creator_url":"https://huggingface.co/jaygala24","description":"xSIM++ is an extension of xSIM. In comparison to xSIM, this evaluates using target-side data with additional synthetic, hard-to-distinguish examples. You can find more details about it in the publication: xSIM++: An Improved Proxy to Bitext Mining Performance for Low-Resource Languages.\n","first_N":5,"first_N_keywords":["derived","multilingual","Achinese","Mesopotamian Arabic","Ta'izzi-Adeni Arabic"],"keywords_longer_than_N":true},
	{"name":"webui-dom-snapshots","keyword":"serbian","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/gbenson/webui-dom-snapshots","creator_name":"Gary Benson","creator_url":"https://huggingface.co/gbenson","description":"\n\t\n\t\t\n\t\tDataset Card for WebUI DOM snapshots\n\t\n\n\n\nThis dataset card aims to be a base template for new datasets. It has been generated using this raw template.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\n\n\n\n\n\nCurated by: Gary Benson\nLanguages: Mostly English (87%);\nDutch, French, Chinese, Japanese (1-2% each); 30+ others (<1% each)\nLicense: CC0 1.0 Universal\n\n\n\t\n\t\t\n\t\tDataset Sources [optional]\n\t\n\n\n\n\nRepository: [More Information Needed]\nPaper [optional]: [More Information Needed]‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/gbenson/webui-dom-snapshots.","first_N":5,"first_N_keywords":["image-feature-extraction","reinforcement-learning","text-classification","multilingual","biglab/webui-7k"],"keywords_longer_than_N":true},
	{"name":"bitext_sib200_miners","keyword":"serbian","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/gentaiscool/bitext_sib200_miners","creator_name":"Genta Indra Winata","creator_url":"https://huggingface.co/gentaiscool","description":"gentaiscool/bitext_sib200_miners dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["multilingual","Achinese","Mesopotamian Arabic","Ta'izzi-Adeni Arabic","Tunisian Arabic"],"keywords_longer_than_N":true},
	{"name":"biblenlp-corpus-mmteb","keyword":"serbian","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/biblenlp-corpus-mmteb","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"This dataset pre-computes all English-centric directions from bible-nlp/biblenlp-corpus, and as a result loading is significantly faster.\nLoading example:\n>>> from datasets import load_dataset\n>>> dataset = load_dataset(\"davidstap/biblenlp-corpus-mmteb\", \"eng-arb\", trust_remote_code=True)\n>>> dataset\nDatasetDict({\n    train: Dataset({\n        features: ['eng', 'arb'],\n        num_rows: 28723\n    })\n    validation: Dataset({\n        features: ['eng', 'arb'],\n        num_rows: 1578\n    })‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/biblenlp-corpus-mmteb.","first_N":5,"first_N_keywords":["no-annotation","expert-generated","translation","multilingual","Arifama-Miniafia"],"keywords_longer_than_N":true},
	{"name":"biblenlp-corpus-mmteb","keyword":"serbian","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/biblenlp-corpus-mmteb","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"This dataset pre-computes all English-centric directions from bible-nlp/biblenlp-corpus, and as a result loading is significantly faster.\nLoading example:\n>>> from datasets import load_dataset\n>>> dataset = load_dataset(\"davidstap/biblenlp-corpus-mmteb\", \"eng-arb\", trust_remote_code=True)\n>>> dataset\nDatasetDict({\n    train: Dataset({\n        features: ['eng', 'arb'],\n        num_rows: 28723\n    })\n    validation: Dataset({\n        features: ['eng', 'arb'],\n        num_rows: 1578\n    })‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/biblenlp-corpus-mmteb.","first_N":5,"first_N_keywords":["no-annotation","expert-generated","translation","multilingual","Arifama-Miniafia"],"keywords_longer_than_N":true},
	{"name":"librivox-tracks","keyword":"serbian","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/xacer/librivox-tracks","creator_name":"xacer","creator_url":"https://huggingface.co/xacer","description":"A dataset of all audio files uploaded to LibriVox before 26th September 2023.\nForked from https://huggingface.co/datasets/pykeio/librivox-tracks\nChanges:\n\nUsed archive.org metadata API to annotate rows with \"duration\" column\n\n","first_N":5,"first_N_keywords":["text-to-speech","automatic-speech-recognition","feature-extraction","Achinese","Afrikaans"],"keywords_longer_than_N":true},
	{"name":"fleurs_clean","keyword":"serbian","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Helloworld668/fleurs_clean","creator_name":"zhide Tang","creator_url":"https://huggingface.co/Helloworld668","description":"\n\t\n\t\t\n\t\n\t\n\t\tFLEURS\n\t\n\nFleurs is the speech version of the FLoRes machine translation benchmark. \nWe use 2009 n-way parallel sentences from the FLoRes dev and devtest publicly available sets, in 102 languages. \nTraining sets have around 10 hours of supervision. Speakers of the train sets are different than speakers from the dev/test sets. Multilingual fine-tuning is\nused and ‚Äùunit error rate‚Äù (characters, signs) of all languages is averaged. Languages and results are also grouped into seven‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Helloworld668/fleurs_clean.","first_N":5,"first_N_keywords":["automatic-speech-recognition","expert-generated","crowdsourced","machine-generated","crowdsourced"],"keywords_longer_than_N":true},
	{"name":"xP3x-Kongo","keyword":"serbian","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Svngoku/xP3x-Kongo","creator_name":"NIONGOLO Chrys F√©-Marty","creator_url":"https://huggingface.co/Svngoku","description":"\n\t\n\t\t\n\t\tDataset Card for xP3x Kikongo Focus\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\n\nxP3x (Crosslingual Public Pool of Prompts eXtended) is a collection of prompts & datasets across 277 languages & 16 NLP tasks. It contains all of xP3 + much more! It is used for training future contenders of mT0 & BLOOMZ at project Aya @C4AI üß°\n\n\nCreation: The dataset can be recreated using instructions available here together with the file in this repository named xp3x_create.py. We provide this version to save‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Svngoku/xP3x-Kongo.","first_N":5,"first_N_keywords":["other","translation","expert-generated","crowdsourced","multilingual"],"keywords_longer_than_N":true},
	{"name":"kisobran","keyword":"serbian","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/procesaur/kisobran","creator_name":"Mihailo ≈†koriƒá","creator_url":"https://huggingface.co/procesaur","description":"\n\n\n\n  \n  \n    \n      Ki≈°obran korpus - krovni veb korpus srpskog i srpskohrvatskog jezika\n      Najveƒáa agregacija veb korpusa do sada, pogodna za obuƒçavanje velikih jeziƒçkih modela za srpski jezik.\n      Ukupno 56 miliona dokumenata, ukupno sa preko 18.5 milijardi reƒçi.\n      \n      Svaka linija predstavlja novi dokument\n      Reƒçenice unutar dokumenata su obele≈æene.    \n      Sadr≈æi obraƒëene i deduplikovane verzije sledeƒáih korpusa:\n    \n    \n      Umbrella corp. - umbrella web corpus of‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/procesaur/kisobran.","first_N":5,"first_N_keywords":["text-generation","Serbian","Croatian","Bosnian","cc-by-sa-4.0"],"keywords_longer_than_N":true},
	{"name":"flores","keyword":"serbian","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/flores","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  FloresBitextMining\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nFLORES is a benchmark dataset for machine translation between English and low-resource languages.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2t\n\n\nDomains\nNon-fiction, Encyclopaedic, Written\n\nReference\nhttps://huggingface.co/datasets/facebook/flores\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an embedding model on this dataset using the following code:\nimport mteb\n\ntask = mteb.get_tasks([\"FloresBitextMining\"])‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/flores.","first_N":5,"first_N_keywords":["translation","human-annotated","multilingual","Achinese","Mesopotamian Arabic"],"keywords_longer_than_N":true},
	{"name":"NTREX","keyword":"serbian","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/NTREX","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\n  NTREXBitextMining\n  An MTEB dataset\n  Massive Text Embedding Benchmark\n\n\nNTREX is a News Test References dataset for Machine Translation Evaluation, covering translation from English into 128 languages. We select language pairs according to the M2M-100 language grouping strategy, resulting in 1916 directions.\n\n\t\n\t\t\n\n\n\n\n\t\t\nTask category\nt2t\n\n\nDomains\nNews, Written\n\n\nReference\nhttps://huggingface.co/datasets/davidstap/NTREX\n\n\n\t\n\n\n\t\n\t\t\n\t\tHow to evaluate on this task\n\t\n\nYou can evaluate an‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/NTREX.","first_N":5,"first_N_keywords":["translation","expert-annotated","expert-generated","translated","Afrikaans"],"keywords_longer_than_N":true},
	{"name":"ParaNames","keyword":"serbian","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/bltlab/ParaNames","creator_name":"Broadening Linguistic Technologies Lab (BLT Lab)","creator_url":"https://huggingface.co/bltlab","description":"\n\t\n\t\t\n\t\n\t\n\t\tDataset Card for Dataset Name\n\t\n\n\n\nThis dataset card aims to be a base template for new datasets. It has been generated using this raw template.\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Description\n\t\n\n\n\n\n\n\nCurated by: [More Information Needed]\nFunded by [optional]: [More Information Needed]\nShared by [optional]: [More Information Needed]\nLanguage(s) (NLP): [More Information Needed]\nLicense: [More Information Needed]\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Sources [optional]‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/bltlab/ParaNames.","first_N":5,"first_N_keywords":["token-classification","Nias","Kotava","Banjar","Angika"],"keywords_longer_than_N":true},
	{"name":"smece","keyword":"serbian","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/procesaur/smece","creator_name":"Mihailo ≈†koriƒá","creator_url":"https://huggingface.co/procesaur","description":"\n\n\n\n  \n  \n    \n      Skup teksta koji je obele≈æen kao smeƒáe prilikom pripremanja drugih korpusa\n      oko 1.5 milijardi \"reƒçi\"\n      Mo≈æe se koristiti za obuƒçavanje modela za klasifikaciju smeƒáa :)\n      Za korpuse pravog teksta za srpski jezik pogledajte \n      S.T.A.R.S (13,289 disertacija sa NARDUS-a) ili \n        \n      Ki≈°obran veb korpus (najveƒái korpus za srpski jezik).\n    \n    \n      A set of text marked as garbage/boilerplate when preparing other corpora\n       around 1.5 billion‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/procesaur/smece.","first_N":5,"first_N_keywords":["text-generation","text-classification","Serbian","cc-by-sa-4.0","100M - 1B"],"keywords_longer_than_N":true},
	{"name":"orca_math_world_problem_200k_serbian","keyword":"serbian","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/datatab/orca_math_world_problem_200k_serbian","creator_name":"Dean","creator_url":"https://huggingface.co/datatab","description":"\n\t\n\t\t\n\t\tKartica Podataka\n\t\n\n\n\nOvaj skup podataka sadr≈æi ~200K tekstualnih matematiƒçkih zadataka za osnovnu ≈°kolu. Svi odgovori u ovom skupu podataka su generisani kori≈°ƒáenjem Azure GPT4-Turbo. Molimo vas da pogledate Orca-Math: Unlocking the potential of SLMs in Grade School Math za detalje o konstrukciji skupa podataka.\n\n\t\n\t\t\n\t\tOpis Skupa Podataka\n\t\n\n\nKreirao: Microsoft\nJezik(i) (NLP): Engleski\nLicenca: MIT\n\n\n\t\n\t\t\n\t\tIzvori Skupa Podataka\n\t\n\n\n\n\nRepozitorijum:‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/datatab/orca_math_world_problem_200k_serbian.","first_N":5,"first_N_keywords":["text-classification","text-generation","Serbian","English","mit"],"keywords_longer_than_N":true},
	{"name":"x-fact","keyword":"serbian","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/utahnlp/x-fact","creator_name":"NLP at University of Utah","creator_url":"https://huggingface.co/utahnlp","description":"\n\t\n\t\t\n\t\tDataset Card for \"x-fact\"\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nX-FACT is a multilingual dataset for fact-checking with real world claims. The dataset contains short statments in 25 languages with top five evidence documents retrieved by performing google search with claim statements. The dataset contains two additional evaluation splits (in addition to a traditional test set): ood and zeroshot. ood measures out-of-domain generalization where while the language‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/utahnlp/x-fact.","first_N":5,"first_N_keywords":["text-classification","Arabic","Bengali","Spanish","Persian"],"keywords_longer_than_N":true},
	{"name":"bcms-claim-sentences","keyword":"serbian","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/toni5rovic/bcms-claim-sentences","creator_name":"Antonije Petrovic","creator_url":"https://huggingface.co/toni5rovic","description":"toni5rovic/bcms-claim-sentences dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["text-classification","Serbian","Croatian","Bosnian","Serbo-Croatian"],"keywords_longer_than_N":true},
	{"name":"voices-of-civilizations","keyword":"serbian","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/sander-wood/voices-of-civilizations","creator_name":"Shangda Wu (Sander Wood)","creator_url":"https://huggingface.co/sander-wood","description":"\n\t\n\t\t\n\t\tVoices of Civilizations (VoC)\n\t\n\nVoices of Civilizations (VoC) is the first multilingual QA benchmark designed to assess audio LLMs‚Äô cultural comprehension using full-length music recordings. VoC spans:\n\n38 languages (including zh, en, hi, es, fr, ja, ko, ar, sw, bn, de, pt, ru, etc.)\n380 tracks drawn from traditional and regional music\n860 multiple-choice questions probing four dimensions: language, region, mood, and theme\n\nVoC exposes models‚Äô biases and weaknesses on‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/sander-wood/voices-of-civilizations.","first_N":5,"first_N_keywords":["question-answering","Arabic","Bengali","Bulgarian","Chinese"],"keywords_longer_than_N":true},
	{"name":"ApolloMoEDataset","keyword":"serbian","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/FreedomIntelligence/ApolloMoEDataset","creator_name":"FreedomAI","creator_url":"https://huggingface.co/FreedomIntelligence","description":"\n\t\n\t\t\n\t\tDemocratizing Medical LLMs For Much More Languages\n\t\n\nCovering 12 Major Languages including English, Chinese, French, Hindi, Spanish, Arabic, Russian, Japanese, Korean, German, Italian, Portuguese and 38 Minor Languages So far.\n\n   üìÉ Paper ‚Ä¢ üåê Demo ‚Ä¢ ü§ó ApolloMoEDataset ‚Ä¢ ü§ó ApolloMoEBench  ‚Ä¢ ü§ó Models  ‚Ä¢üåê Apollo  ‚Ä¢ üåê ApolloMoE\n\n\n\n\n\n\n\t\n\t\t\n\t\tüåà Update\n\t\n\n\n[2024.10.15] ApolloMoE repo is publishedÔºÅüéâ\n\n\n\t\n\t\t\n\t\tLanguages Coverage\n\t\n\n12 Major Languages and 38 Minor Languages\n\n  Click to‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/FreedomIntelligence/ApolloMoEDataset.","first_N":5,"first_N_keywords":["question-answering","Arabic","English","Chinese","Korean"],"keywords_longer_than_N":true},
	{"name":"ApolloMoEBench","keyword":"serbian","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/FreedomIntelligence/ApolloMoEBench","creator_name":"FreedomAI","creator_url":"https://huggingface.co/FreedomIntelligence","description":"\n\t\n\t\t\n\t\tDemocratizing Medical LLMs For Much More Languages\n\t\n\nCovering 12 Major Languages including English, Chinese, French, Hindi, Spanish, Arabic, Russian, Japanese, Korean, German, Italian, Portuguese and 38 Minor Languages So far.\n\n   üìÉ Paper ‚Ä¢ üåê Demo ‚Ä¢ ü§ó ApolloMoEDataset ‚Ä¢ ü§ó ApolloMoEBench  ‚Ä¢ ü§ó Models  ‚Ä¢üåê Apollo  ‚Ä¢ üåê ApolloMoE\n\n\n\n\n\n\n\t\n\t\t\n\t\tüåà Update\n\t\n\n\n[2024.10.15] ApolloMoE repo is publishedÔºÅüéâ\n\n\n\t\n\t\t\n\t\tLanguages Coverage\n\t\n\n12 Major Languages and 38 Minor Languages\n\n  Click to‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/FreedomIntelligence/ApolloMoEBench.","first_N":5,"first_N_keywords":["question-answering","Arabic","English","Chinese","Korean"],"keywords_longer_than_N":true},
	{"name":"product-database","keyword":"serbian","license":"GNU Affero General Public License v3.0","license_url":"https://choosealicense.com/licenses/agpl-3.0/","language":"en","dataset_url":"https://huggingface.co/datasets/openfoodfacts/product-database","creator_name":"Open Food Facts","creator_url":"https://huggingface.co/openfoodfacts","description":"\n\t\n\t\t\n\t\tOpen Food Facts Database\n\t\n\n\n\t\n\t\t\n\t\tWhat is üçä Open Food Facts?\n\t\n\n\n\t\n\t\t\n\t\tA food products database\n\t\n\nOpen Food Facts is a database of food products with ingredients, allergens, nutrition facts and all the tidbits of information we can find on product labels.\n\n\t\n\t\t\n\t\tMade by everyone\n\t\n\nOpen Food Facts is a non-profit association of volunteers. 25.000+ contributors like you have added 1.7 million + products from 150 countries using our Android or iPhone app or their camera to scan‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/openfoodfacts/product-database.","first_N":5,"first_N_keywords":["English","French","German","Spanish","Italian"],"keywords_longer_than_N":true},
	{"name":"serbian-embeddings-visualization","keyword":"serbian","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/datatab/serbian-embeddings-visualization","creator_name":"Dean","creator_url":"https://huggingface.co/datatab","description":"\n\t\n\t\t\n\t\tVisualizing Embedding Vectors [Serbian Datasets]\n\t\n\n","first_N":5,"first_N_keywords":["Serbian","mit","Text","üá∫üá∏ Region: US"],"keywords_longer_than_N":false},
	{"name":"sib-fleurs","keyword":"serbian","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/WueNLP/sib-fleurs","creator_name":"W√ºNLP","creator_url":"https://huggingface.co/WueNLP","description":"\n\t\n\t\t\n\t\tSIB-Fleurs\n\t\n\nSIB-Fleurs is a dataset suitable to evaluate Multilingual Spoken Language Understanding. For each utterance in Fleurs, the task is to determine the topic the utterance belongs to. \nThe topics are:\n\nScience/Technology\nTravel\nPolitics\nSports\nHealth\nEntertainment\nGeography\n\nPreliminary evaluations can be found at the bottom of the README. The preliminary results in full detail are available in ./results.csv*.\n\n\t\n\t\t\n\t\n\t\n\t\tDataset creation\n\t\n\nThis dataset processes and merges‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/WueNLP/sib-fleurs.","first_N":5,"first_N_keywords":["audio-classification","automatic-speech-recognition","audio-text-to-text","text-to-speech","question-answering"],"keywords_longer_than_N":true},
	{"name":"aya_redteaming_consitutional","keyword":"serbian","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/pbevan11/aya_redteaming_consitutional","creator_name":"Peter J. Bevan","creator_url":"https://huggingface.co/pbevan11","description":"\n\t\n\t\t\n\t\tDataset Card for Aya Red-teaming-constiutional\n\t\n\nThis dataset is an extended version of CohereForAI/aya_redteaming, with added targeted constitutional principles, aiming to allow multilingual constitional AI using the Aya Red team prompts.\nWe take the Anthropic constitutional principles and manually cut out the existing harms so that we can dynamically insert harms specific to our red team prompts.\nThere are 16 critiques and 16 revisions for each red-team prompt, each targeting the‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/pbevan11/aya_redteaming_consitutional.","first_N":5,"first_N_keywords":["English","Hindi","French","Spanish","Arabic"],"keywords_longer_than_N":true},
	{"name":"serbian-llm-benchmark","keyword":"serbian","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/datatab/serbian-llm-benchmark","creator_name":"Dean","creator_url":"https://huggingface.co/datatab","description":"\n\t\n\t\t\n\t\tSerbian LLM Evaluation Dataset\n\t\n\nWelcome to the Serbian LLM Evaluation Dataset, your one-stop solution for evaluating Serbian Language Models (LLMs) like never before! This comprehensive toolkit empowers you to measure model performance across diverse domains in Serbian, ensuring your models are smarter, faster, and more intuitive. Whether you're a researcher, developer, or just an enthusiast‚Äîthis dataset is tailor-made to help your LLM thrive.\n\n\n\t\n\t\n\t\n\t\tüîç What's Inside?\n\t\n\nThis‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/datatab/serbian-llm-benchmark.","first_N":5,"first_N_keywords":["question-answering","table-question-answering","Serbian","cc-by-sa-4.0","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"natural_quesions_sr","keyword":"serbian","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/smartcat/natural_quesions_sr","creator_name":"SmartCat","creator_url":"https://huggingface.co/smartcat","description":"\n\t\n\t\t\n\t\tDataset Card for Serbian Natural Questions (Subset)\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset is a Serbian translation of the first 8,000 examples from Google's Natural Questions (NQ) dataset. It contains real user questions and corresponding Wikipedia articles, automatically translated from English to Serbian. The dataset is designed for evaluating embedding models on Question Answering (QA) and Information Retrieval (IR) tasks in the Serbian language, offering a more realistic and‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/smartcat/natural_quesions_sr.","first_N":5,"first_N_keywords":["question-answering","Serbian","mit","1K - 10K","parquet"],"keywords_longer_than_N":true},
	{"name":"MaCoCu_sr_en","keyword":"serbian","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/smartcat/MaCoCu_sr_en","creator_name":"SmartCat","creator_url":"https://huggingface.co/smartcat","description":"\n\t\n\t\t\n\t\tDataset Card for MaCoCu-sr dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThe Serbian web corpus MaCoCu-sr 1.0 was built by crawling the \".rs\" and \".—Å—Ä–±\" internet top-level domains in 2021 and 2022, extending the crawl dynamically to other domains. This high-quality web corpus is characterized by extensive metadata, making it highly useful for corpus linguistics studies, as well as for training language models and other language technologies.\n\n\t\n\t\t\n\t\tSource Data\n\t\n\nThe source data for the‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/smartcat/MaCoCu_sr_en.","first_N":5,"first_N_keywords":["translation","sentence-similarity","Serbian","English","mit"],"keywords_longer_than_N":true},
	{"name":"serbian_qa","keyword":"serbian","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/smartcat/serbian_qa","creator_name":"SmartCat","creator_url":"https://huggingface.co/smartcat","description":"\n\t\n\t\t\n\t\tDataset Card for \"serbian_qa\"\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThe \"serbian_qa\" dataset is a collection of context-query pairs in Serbian. It is designed for question-answering tasks and contains contexts from various Serbian language sources, paired with automatically generated queries of different lengths.\n\n\t\n\t\t\n\t\tSupported Tasks and Leaderboards\n\t\n\n\nTasks: Question Answering, Information Retrieval\n\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nThe dataset is in Serbian (sr).\n\n\t\n\t\t\n\t\tDataset Structure‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/smartcat/serbian_qa.","first_N":5,"first_N_keywords":["question-answering","Serbian","mit","1K - 10K","parquet"],"keywords_longer_than_N":true},
	{"name":"include-lite-44","keyword":"serbian","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/CohereLabs/include-lite-44","creator_name":"Cohere Labs","creator_url":"https://huggingface.co/CohereLabs","description":"\n\t\n\t\t\n\t\tINCLUDE-lite (44 languages)\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\n\n\nPaper: http://arxiv.org/abs/2411.19799\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nINCLUDE is a comprehensive knowledge- and reasoning-centric benchmark across 44 languages that evaluates multilingual LLMs for performance in the actual language environments where they would be deployed. \nIt contains 11,095 4-option multiple-choice-questions (MCQ) extracted from academic and professional exams, covering 57 topics, including regional‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/CohereLabs/include-lite-44.","first_N":5,"first_N_keywords":["multiple-choice","Albanian","Arabic","Armenian","Azerbaijani"],"keywords_longer_than_N":true},
	{"name":"include-base-44","keyword":"serbian","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/CohereLabs/include-base-44","creator_name":"Cohere Labs","creator_url":"https://huggingface.co/CohereLabs","description":"\n\t\n\t\t\n\t\tINCLUDE-base (44 languages)\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\n\n\nPaper: http://arxiv.org/abs/2411.19799\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nINCLUDE is a comprehensive knowledge- and reasoning-centric benchmark across 44 languages that evaluates multilingual LLMs for performance in the actual language environments where they would be deployed. \nIt contains 22,637 4-option multiple-choice-questions (MCQ) extracted from academic and professional exams, covering 57 topics, including regional‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/CohereLabs/include-base-44.","first_N":5,"first_N_keywords":["multiple-choice","Albanian","Arabic","Armenian","Azerbaijani"],"keywords_longer_than_N":true},
	{"name":"znanje","keyword":"serbian","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/procesaur/znanje","creator_name":"Mihailo ≈†koriƒá","creator_url":"https://huggingface.co/procesaur","description":"\n\n\n\n  \n  \n    \n      Skup nauƒçnih i struƒçnih publikacija na Ju≈ænoslovenskim jezicima\n      Visoko-kvalitetan skup raznovrsnih nauƒçnih publikacija\n      Neophodan za obuƒçavanje kvalitetnih jeziƒçkih modela za ju≈ænoslovenske jezike.\n      Ukupno 280,460 dokumenata, ukupno sa preko 4.2 milijarde reƒçi, 1.9 milijardi na srpskohrvatskom i 2.3 milijarde na slovenaƒçkom jeziku\n      \n      Svaka JSON linija predstavlja jednu publikaciju.\n      Unutar svakog dokumenta su obele≈æene reƒçenice i paragrafi.‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/procesaur/znanje.","first_N":5,"first_N_keywords":["text-generation","Serbian","Croatian","Slovenian","Bosnian"],"keywords_longer_than_N":true},
	{"name":"Deltacorpus_1.1","keyword":"serbian","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/FrancophonIA/Deltacorpus_1.1","creator_name":"FrancophonIA","creator_url":"https://huggingface.co/FrancophonIA","description":"\n[!NOTE]\nDataset origin: https://lindat.cz/repository/xmlui/handle/11234/1-1743\n\n\n\t\n\t\t\n\t\tDescription\n\t\n\nTexts in 107 languages from the W2C corpus (http://hdl.handle.net/11858/00-097C-0000-0022-6133-9), first 1,000,000 tokens per language, tagged by the delexicalized tagger described in Yu et al. (2016, LREC, Portoro≈æ, Slovenia).\nChanges in version 1.1: \n\nUniversal Dependencies tagset instead of the older and smaller Google Universal POS tagset. \n\nSVM classifier trained on Universal‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/FrancophonIA/Deltacorpus_1.1.","first_N":5,"first_N_keywords":["token-classification","multilingual","Afrikaans","Albanian","Amharic"],"keywords_longer_than_N":true},
	{"name":"VoxCommunis","keyword":"serbian","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/pacscilab/VoxCommunis","creator_name":"PaCSciLab @ UZH","creator_url":"https://huggingface.co/pacscilab","description":"The VoxCommunis Corpus contains acoustic models, lexicons, and force-aligned TextGrids with phone- and word-level segmentations derived from the Mozilla Common Voice Corpus. The Mozilla Common Voice Corpus and derivative VoxCommunis Corpus stored here are free to download and use under a CC0 license.\nThe lexicons are developed using Epitran, the XPF Corpus, Charsiu, and some custom dictionaries. Some manual correction has been applied, and we hope to continue improving these. Any updates from‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/pacscilab/VoxCommunis.","first_N":5,"first_N_keywords":["Abkhaz","Amharic","Bashkir","Belarusian","Bulgarian"],"keywords_longer_than_N":true},
	{"name":"STS_parallel_en_sr","keyword":"serbian","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/smartcat/STS_parallel_en_sr","creator_name":"SmartCat","creator_url":"https://huggingface.co/smartcat","description":"\n\t\n\t\t\n\t\tDataset Card for English-Serbian Semantic Text Similarity Benchmark\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset is a parallel English-Serbian Semantic Text Similarity (STS) benchmark. It was created to evaluate multilingual English-Serbian language models, with a focus on SBERT (Sentence-BERT) knowledge distillation. The dataset consists of sentence pairs in English and Serbian, along with their semantic similarity scores.\nThe dataset uses the test split from the original STS benchmark.‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/smartcat/STS_parallel_en_sr.","first_N":5,"first_N_keywords":["text-classification","sentence-similarity","translation","English","Serbian"],"keywords_longer_than_N":true},
	{"name":"Roleplay-Serbian","keyword":"serbian","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/jojo-ai-mst/Roleplay-Serbian","creator_name":"Min Si Thu","creator_url":"https://huggingface.co/jojo-ai-mst","description":"\n\t\n\t\t\n\t\tRolePlay-Serbian\n\t\n\nRoleplay-Serbian Dataset is a dataset for roleplaying in the Serbian language for Large Language Model.\nThe base dataset is GPTeacher role play dataset by teknium 1, which can be found under this link, released under MIT License. The dataset is then translated into respective languages. The translation process is powered by Google Translate, using cloud translation API. \nFor more information and other language datasets for roleplay, it can be found at this github‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/jojo-ai-mst/Roleplay-Serbian.","first_N":5,"first_N_keywords":["text-generation","Serbian","mit","1K - 10K","csv"],"keywords_longer_than_N":true},
	{"name":"X-ALMA-Preference","keyword":"serbian","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/haoranxu/X-ALMA-Preference","creator_name":"Haoran Xu","creator_url":"https://huggingface.co/haoranxu","description":"This is the translation preference dataset used by X-ALMA.\nsource: the source sentence.\nchosen: the preferred translation.\nreject: the dis-preferred translation.\ndirections: the translation direction.\n@misc{xu2024xalmaplugplay,\n      title={X-ALMA: Plug & Play Modules and Adaptive Rejection for Quality Translation at Scale}, \n      author={Haoran Xu and Kenton Murray and Philipp Koehn and Hieu Hoang and Akiko Eriguchi and Huda Khayrallah},\n      year={2024},\n      eprint={2410.03115}‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/haoranxu/X-ALMA-Preference.","first_N":5,"first_N_keywords":["English","Danish","Dutch","German","Icelandic"],"keywords_longer_than_N":true},
	{"name":"ms_marco_sr","keyword":"serbian","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/smartcat/ms_marco_sr","creator_name":"SmartCat","creator_url":"https://huggingface.co/smartcat","description":"\n\t\n\t\t\n\t\tDataset Card for Serbian MS MARCO (Subset)\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset is a Serbian translation of the first 8,000 examples from Microsoft's MS MARCO (Machine Reading Comprehension) dataset. It contains pairs of questions and human-generated answers, automatically translated from English to Serbian. The dataset is designed for evaluating embedding models on Question Answering (QA) and Information Retrieval (IR) tasks in the Serbian language.\nThe original MS MARCO dataset‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/smartcat/ms_marco_sr.","first_N":5,"first_N_keywords":["question-answering","English","Serbian","mit","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"squad_sr","keyword":"serbian","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/smartcat/squad_sr","creator_name":"SmartCat","creator_url":"https://huggingface.co/smartcat","description":"\n\t\n\t\t\n\t\tDataset Card for Serbian SQuAD\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset is an automatic Serbian translation of the Stanford Question Answering Dataset (SQuAD) 1.1. The original SQuAD, developed by Stanford, is a reading comprehension dataset consisting of questions posed by crowdworkers on a set of Wikipedia articles. The answer to every question is a segment of text (span) from the corresponding reading passage, or the question might be unanswerable. It's the largest Serbian QA‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/smartcat/squad_sr.","first_N":5,"first_N_keywords":["question-answering","extractive-qa","rajpurkar/squad","Serbian","cc-by-sa-4.0"],"keywords_longer_than_N":true},
	{"name":"test_4","keyword":"serbian","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/tunngo/test_4","creator_name":"nguyen tuan","creator_url":"https://huggingface.co/tunngo","description":"\n\t\n\t\t\n\t\n\t\n\t\tFLEURS\n\t\n\nFleurs is the speech version of the FLoRes machine translation benchmark. \nWe use 2009 n-way parallel sentences from the FLoRes dev and devtest publicly available sets, in 102 languages. \nTraining sets have around 10 hours of supervision. Speakers of the train sets are different than speakers from the dev/test sets. Multilingual fine-tuning is\nused and ‚Äùunit error rate‚Äù (characters, signs) of all languages is averaged. Languages and results are also grouped into seven‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/tunngo/test_4.","first_N":5,"first_N_keywords":["automatic-speech-recognition","expert-generated","crowdsourced","machine-generated","crowdsourced"],"keywords_longer_than_N":true},
	{"name":"multilingual_translation_gen_binarized","keyword":"serbian","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Youseff1987/multilingual_translation_gen_binarized","creator_name":"JOON HYOUNG JUN","creator_url":"https://huggingface.co/Youseff1987","description":"Youseff1987/multilingual_translation_gen_binarized dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["translation","Korean","English","Chinese","Zulu"],"keywords_longer_than_N":true},
	{"name":"enhanced-cobald","keyword":"serbian","license":"GNU General Public License v3.0","license_url":"https://choosealicense.com/licenses/gpl-3.0/","language":"en","dataset_url":"https://huggingface.co/datasets/CoBaLD/enhanced-cobald","creator_name":"CoBaLD Annotation Project","creator_url":"https://huggingface.co/CoBaLD","description":"\n\t\n\t\t\n\t\tCoBaLD Dataset\n\t\n\nAn umbrella repository for CoBaLD datasets that provides a unified Hugging Face Datasets API.\n\n\t\n\t\t\n\t\tCitation\n\t\n\nFor citation, refer to the source datasets at github.com/CobaldAnnotation.\n","first_N":5,"first_N_keywords":["token-classification","expert-generated","found","monolingual","English"],"keywords_longer_than_N":true},
	{"name":"mHumanEval-Benchmark","keyword":"serbian","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/md-nishat-008/mHumanEval-Benchmark","creator_name":"Nishat Raihan","creator_url":"https://huggingface.co/md-nishat-008","description":"\n\n\n\t\n\t\t\n\t\tüî∑ Accepted in NAACL Proceedings (2025) üî∑\n\t\n\n\n\n\n\n  \n    \n      \n        \n          \n        \n      \n      \n        \n          \n        \n      \n      \n        \n          \n        \n      \n    \n  \n\n\n\n\n\n  \n\n\t\n\t\n\t\n\t\tmHumanEval\n\t\n\nThe mHumanEval benchmark is curated based on prompts from the original HumanEval üìö [Chen et al., 2021]. It includes a total of 33,456 prompts for Python, and 836,400 in total - significantly expanding from the original 164. \n\n\n\t\n\t\t\n\t\tQuick Start\n\t\n\n  Detailed‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/md-nishat-008/mHumanEval-Benchmark.","first_N":5,"first_N_keywords":["Afar","Abkhaz","Avestan","Afrikaans","Akan"],"keywords_longer_than_N":true},
	{"name":"PM4Bench","keyword":"serbian","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/songjhPKU/PM4Bench","creator_name":"Jiahe Song","creator_url":"https://huggingface.co/songjhPKU","description":"\n\t\n\t\t\n\t\tPM4Bench: A Parallel Multilingual Multi-Modal Multi-task Benchmark for Large Vision Language Model\n\t\n\n\n\n\nüåê Homepage | ü§ó Dataset | üìñ Paper \n\n\t\n\t\t\n\t\tüì¢ News\n\t\n\n\nüî•[2025-03-25]: Dataset available on HuggingFace. Paper available on  arXiv.\n\n\n\n\t\n\t\t\n\t\tüßë‚Äçüíª How to Run?\n\t\n\n\n\n\t\n\t\t\n\t\tüè† Set Up\n\t\n\n\n\t\n\t\t\n\t\tDataset Download\n\t\n\nDownload tsv files from HuggingFace and store them in data/tsv/. The directory should be like data/tsv/{DATASET}_{SETTING}_{LANGUAGE}.tsv.\n\n\t\n\t\t\n\t\tEnvironment‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/songjhPKU/PM4Bench.","first_N":5,"first_N_keywords":["question-answering","visual-question-answering","multiple-choice","English","Chinese"],"keywords_longer_than_N":true},
	{"name":"multilingual_translation_gpt4o_gen","keyword":"serbian","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Youseff1987/multilingual_translation_gpt4o_gen","creator_name":"JOON HYOUNG JUN","creator_url":"https://huggingface.co/Youseff1987","description":"Youseff1987/multilingual_translation_gpt4o_gen dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["translation","Korean","English","Chinese","Zulu"],"keywords_longer_than_N":true},
	{"name":"wikipedia_quality_wikirank","keyword":"serbian","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/lewoniewski/wikipedia_quality_wikirank","creator_name":"W≈Çodzimierz Lewoniewski","creator_url":"https://huggingface.co/lewoniewski","description":"Datasets with WikiRank quality score as of 1 August 2024 for 47 million Wikipedia articles in 55 language versions (also simplified version for each language in separate files).\nThe WikiRank quality score is a metric designed to assess the overall quality of a Wikipedia article. Although its specific algorithm can vary depending on the implementation, the score typically combines several key features of the Wikipedia article.\n\n\t\n\t\t\n\t\n\t\n\t\tWhy It‚Äôs Important\n\t\n\n\nEnhances Trust: For readers and‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/lewoniewski/wikipedia_quality_wikirank.","first_N":5,"first_N_keywords":["Arabic","Azerbaijani","Belarusian","Bulgarian","Catalan"],"keywords_longer_than_N":true},
	{"name":"V1Q","keyword":"serbian","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/YuRiVeRTi/V1Q","creator_name":"YuRiVeRTical","creator_url":"https://huggingface.co/YuRiVeRTi","description":"from datasets import load_dataset\nds = load_dataset(\"b3x0m/Chinese-H-Novels\")\nimport sagemaker\nimport boto3\nfrom sagemaker.huggingface import HuggingFaceModel\ntry:\n    role = sagemaker.get_execution_role()\nexcept ValueError:\n    iam = boto3.client('iam')\n    role = iam.get_role(RoleName='sagemaker_execution_role')['Role']['Arn']\n\n\t\n\t\t\n\t\tHub Model configuration. https://huggingface.co/models\n\t\n\nhub = {\n    'HF_MODEL_ID':'deepseek-ai/Janus-Pro-7B',\n    'HF_TASK':'any-to-any'\n}\n\n\t\n\t\t\n\t\tcreate‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/YuRiVeRTi/V1Q.","first_N":5,"first_N_keywords":["text-classification","token-classification","table-question-answering","question-answering","zero-shot-classification"],"keywords_longer_than_N":true},
	{"name":"multilingual_translation_sft","keyword":"serbian","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Youseff1987/multilingual_translation_sft","creator_name":"JOON HYOUNG JUN","creator_url":"https://huggingface.co/Youseff1987","description":"Youseff1987/multilingual_translation_sft dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["translation","Korean","English","Chinese","Zulu"],"keywords_longer_than_N":true},
	{"name":"panlex-definitions","keyword":"serbian","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/cointegrated/panlex-definitions","creator_name":"David Dale","creator_url":"https://huggingface.co/cointegrated","description":"\n\t\n\t\t\n\t\tDataset Card for panlex-definitions\n\t\n\nThis is a dataset of word definitions in several hudnred languages, extracted from https://panlex.org.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset has been extracted from https://panlex.org (the 20250201 database dump) and rearranged on the per-language basis (by the language of the definition).\nEach language subset consists of definitions (short phrases).\nEach definition is associated with some meanings (if there is‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/cointegrated/panlex-definitions.","first_N":5,"first_N_keywords":["translation","Abkhazian","Hijazi Arabic","Afrikaans","Ainu (Japan)"],"keywords_longer_than_N":true},
	{"name":"HPLT2.0_cleaned","keyword":"serbian","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/jobs-git/HPLT2.0_cleaned","creator_name":"James Guana","creator_url":"https://huggingface.co/jobs-git","description":"This is a large-scale collection of web-crawled documents in 191 world languages, produced by the HPLT project. \nThe source of the data is mostly Internet Archive with some additions from Common Crawl.\nFor a detailed description of the dataset, please refer to https://hplt-project.org/datasets/v2.0\nThe Cleaned variant of HPLT Datasets v2.0\nThis is the cleaned variant of the HPLT Datasets v2.0 converted to the Parquet format semi-automatically when being uploaded here. \nThe original JSONL files‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/jobs-git/HPLT2.0_cleaned.","first_N":5,"first_N_keywords":["fill-mask","text-generation","language-modeling","multilingual","Achinese"],"keywords_longer_than_N":true},
	{"name":"Kaleidoscope","keyword":"serbian","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Anonym-sub/Kaleidoscope","creator_name":"Anonymous submission","creator_url":"https://huggingface.co/Anonym-sub","description":"\n\t\n\t\t\n\t\tKaleidoscope  (18 Languages)\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe Kaleidoscope Benchmark is a \nglobal collection of multiple-choice questions sourced from real-world exams, \nwith the goal of evaluating multimodal and multilingual understanding in VLMs. \nThe collected exams are in a Multiple-choice question answering (MCQA) \nformat which provides a structured framework for evaluation by prompting \nmodels with predefined answer choices, closely mimicking conventional human testing‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Anonym-sub/Kaleidoscope.","first_N":5,"first_N_keywords":["Arabic","Bengali","Croatian","Dutch","English"],"keywords_longer_than_N":true},
	{"name":"GammaCorpus-Polylingo-50k","keyword":"serbian","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/rubenroy/GammaCorpus-Polylingo-50k","creator_name":"Ruben Roy","creator_url":"https://huggingface.co/rubenroy","description":"\n\t\n\t\t\n\t\tGammaCorpus Polylingo 50k\n\t\n\n\n\t\n\t\t\n\t\tWhat is it?\n\t\n\nThe GammaCorpus Polylingo 50k dataset consists of 50,000 structured, unfiltered, single-turn conversations, where each interaction includes:\n\nInput: A user prompt or question.\nOutput: A response generated by an AI assistant.\nLanguage: The language used in the interaction.\n\nThis dataset is designed to help in the training and evaluation of conversational AI models for linguistic purposes. This dataset can be especially helpful if you‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/rubenroy/GammaCorpus-Polylingo-50k.","first_N":5,"first_N_keywords":["text-generation","English","Russian","Vietnamese","German"],"keywords_longer_than_N":true},
	{"name":"Synthdog-Multilingual-100","keyword":"serbian","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/WueNLP/Synthdog-Multilingual-100","creator_name":"W√ºNLP","creator_url":"https://huggingface.co/WueNLP","description":"\n\t\n\t\t\n\t\tSynthdog Multilingual\n\t\n\n\n\nThe Synthdog dataset created for training in Centurio: On Drivers of Multilingual Ability of Large Vision-Language Model.\nUsing the official Synthdog code, we created >1 million training samples for improving OCR capabilities in Large Vision-Language Models.\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Details\n\t\n\nWe provide the images for download in two .tar.gz files. Download and extract them in folders of the same name (so cat images.tar.gz.* | tar xvzf -C images; tar xvzf‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/WueNLP/Synthdog-Multilingual-100.","first_N":5,"first_N_keywords":["image-to-text","multilingual","Afrikaans","Amharic","Arabic"],"keywords_longer_than_N":true},
	{"name":"kaleidoscope","keyword":"serbian","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/CohereLabs/kaleidoscope","creator_name":"Cohere Labs","creator_url":"https://huggingface.co/CohereLabs","description":"\n\t\n\t\t\n\t\tKaleidoscope  (18 Languages)\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe Kaleidoscope Benchmark is a \nglobal collection of multiple-choice questions sourced from real-world exams, \nwith the goal of evaluating multimodal and multilingual understanding in VLMs. \nThe collected exams are in a Multiple-choice question answering (MCQA) \nformat which provides a structured framework for evaluation by prompting \nmodels with predefined answer choices, closely mimicking conventional human testing‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/CohereLabs/kaleidoscope.","first_N":5,"first_N_keywords":["Arabic","Bengali","Croatian","Dutch","English"],"keywords_longer_than_N":true},
	{"name":"BenchMAX_Math","keyword":"serbian","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/LLaMAX/BenchMAX_Math","creator_name":"LLaMAX","creator_url":"https://huggingface.co/LLaMAX","description":"\n\t\n\t\t\n\t\tDataset Sources\n\t\n\n\nPaper: BenchMAX: A Comprehensive Multilingual Evaluation Suite for Large Language Models\nLink: https://huggingface.co/papers/2502.07346\nRepository: https://github.com/CONE-MT/BenchMAX\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nBenchMAX_Math is a dataset of BenchMAX, sourcing from MGSM, which evaluates the math reasoning capability in multilingual scenarios.\nWe extend the original MGSM dataset by six additional languages, i.e. Arabic, Czech, Hungarian, Korean, Serbian, and‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/LLaMAX/BenchMAX_Math.","first_N":5,"first_N_keywords":["text-generation","multilingual","English","Chinese","Spanish"],"keywords_longer_than_N":true},
	{"name":"BenchMAX_Science","keyword":"serbian","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/LLaMAX/BenchMAX_Science","creator_name":"LLaMAX","creator_url":"https://huggingface.co/LLaMAX","description":"\n\t\n\t\t\n\t\tDataset Sources\n\t\n\n\nPaper: BenchMAX: A Comprehensive Multilingual Evaluation Suite for Large Language Models\nLink: https://huggingface.co/papers/2502.07346\nRepository: https://github.com/CONE-MT/BenchMAX\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nBenchMAX_Science is a dataset of BenchMAX, sourcing from GPQA, which evaluates the natural science reasoning capability in multilingual scenarios.\nWe extend the original English dataset to 16 non-English languages.\nThe data is first translated by Google‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/LLaMAX/BenchMAX_Science.","first_N":5,"first_N_keywords":["question-answering","multilingual","English","Chinese","Spanish"],"keywords_longer_than_N":true},
	{"name":"BenchMAX_Question_Answering","keyword":"serbian","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/LLaMAX/BenchMAX_Question_Answering","creator_name":"LLaMAX","creator_url":"https://huggingface.co/LLaMAX","description":"\n\t\n\t\t\n\t\tDataset Sources\n\t\n\n\nPaper: BenchMAX: A Comprehensive Multilingual Evaluation Suite for Large Language Models\nLink: https://huggingface.co/papers/2502.07346\nRepository: https://github.com/CONE-MT/BenchMAX\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nBenchMAX_Question_Answering is a dataset of BenchMAX for evaluating the long-context capability of LLMs in multilingual scenarios.\nThe subtasks are similar to the subtasks in RULER.\nThe data is sourcing from UN Parallel Corpus and xquad.\nThe haystacks‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/LLaMAX/BenchMAX_Question_Answering.","first_N":5,"first_N_keywords":["text-generation","multilingual","English","Chinese","Spanish"],"keywords_longer_than_N":true},
	{"name":"2M-Belebele","keyword":"serbian","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/facebook/2M-Belebele","creator_name":"AI at Meta","creator_url":"https://huggingface.co/facebook","description":"\n\t\n\t\t\n\t\t2M-Belebele\n\t\n\n\n\t\n\t\t\n\t\tHighly-Multilingual Speech and American Sign Language Comprehension Dataset\n\t\n\nWe introduce 2M-Belebele as the first highly multilingual speech and American Sign Language (ASL) comprehension dataset. Our dataset, which is an extension of the existing Belebele only-text dataset, covers 74 spoken languages at the intersection of Belebele and Fleurs, and one sign language (ASL). \nThe speech dataset is built from aligning Belebele, Flores200 and Fleurs datasets as‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/facebook/2M-Belebele.","first_N":5,"first_N_keywords":["question-answering","automatic-speech-recognition","Bulgarian","Panjabi","English"],"keywords_longer_than_N":true},
	{"name":"alpaca_cleaned_croatian","keyword":"serbian","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/TimesLast/alpaca_cleaned_croatian","creator_name":"times last","creator_url":"https://huggingface.co/TimesLast","description":"TimesLast/alpaca_cleaned_croatian dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["Croatian","Serbian","Bosnian","apache-2.0","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"BenchMAX_Rule-based","keyword":"serbian","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/LLaMAX/BenchMAX_Rule-based","creator_name":"LLaMAX","creator_url":"https://huggingface.co/LLaMAX","description":"\n\t\n\t\t\n\t\tDataset Sources\n\t\n\n\nPaper: BenchMAX: A Comprehensive Multilingual Evaluation Suite for Large Language Models\nLink: https://huggingface.co/papers/2502.07346\nRepository: https://github.com/CONE-MT/BenchMAX\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nBenchMAX_Rule-based is a dataset of BenchMAX, sourcing from IFEval, which is a rule-based benchmark for evaluating the instruction following capabilities in multilingual scenarios.\nWe extend the original dataset to 16 non-English languages by first‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/LLaMAX/BenchMAX_Rule-based.","first_N":5,"first_N_keywords":["text-generation","multilingual","English","Chinese","Spanish"],"keywords_longer_than_N":true},
	{"name":"BenchMAX_Model-based","keyword":"serbian","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/LLaMAX/BenchMAX_Model-based","creator_name":"LLaMAX","creator_url":"https://huggingface.co/LLaMAX","description":"\n\t\n\t\t\n\t\tDataset Sources\n\t\n\n\nPaper: BenchMAX: A Comprehensive Multilingual Evaluation Suite for Large Language Models\nLink: https://huggingface.co/papers/2502.07346\nRepository: https://github.com/CONE-MT/BenchMAX\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nBenchMAX_Model-based is a dataset of BenchMAX, sourcing from m-ArenaHard, which evaluates the instruction following capability via model-based judgment.\nWe extend the original dataset to include languages that are not supported by m-ArenaHard through‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/LLaMAX/BenchMAX_Model-based.","first_N":5,"first_N_keywords":["text-generation","multilingual","English","Chinese","Spanish"],"keywords_longer_than_N":true},
	{"name":"BenchMAX_Function_Completion","keyword":"serbian","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/LLaMAX/BenchMAX_Function_Completion","creator_name":"LLaMAX","creator_url":"https://huggingface.co/LLaMAX","description":"\n\t\n\t\t\n\t\tDataset Sources\n\t\n\n\nPaper: BenchMAX: A Comprehensive Multilingual Evaluation Suite for Large Language Models\nLink: https://huggingface.co/papers/2502.07346\nRepository: https://github.com/CONE-MT/BenchMAX\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nBenchMAX_Function_Completion is a dataset of BenchMAX, sourcing from humanevalplus, which evaluates the code generation capability in multilingual scenarios.\nWe extend the original English dataset to 16 non-English languages.\nThe data is first translated‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/LLaMAX/BenchMAX_Function_Completion.","first_N":5,"first_N_keywords":["text-generation","multilingual","English","Chinese","Spanish"],"keywords_longer_than_N":true},
	{"name":"BenchMAX_Problem_Solving","keyword":"serbian","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/LLaMAX/BenchMAX_Problem_Solving","creator_name":"LLaMAX","creator_url":"https://huggingface.co/LLaMAX","description":"\n\t\n\t\t\n\t\tDataset Sources\n\t\n\n\nPaper: BenchMAX: A Comprehensive Multilingual Evaluation Suite for Large Language Models\nLink: https://huggingface.co/papers/2502.07346\nRepository: https://github.com/CONE-MT/BenchMAX\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nBenchMAX_Problem_Solving is a dataset of BenchMAX, sourcing from LiveCodeBench_v4, which evaluates the code generation capability for solving multilingual competitive code problems.\nWe extend the original English dataset by 16 non-English languages.\nThe‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/LLaMAX/BenchMAX_Problem_Solving.","first_N":5,"first_N_keywords":["text-generation","multilingual","English","Chinese","Spanish"],"keywords_longer_than_N":true},
	{"name":"BenchMAX_Multiple_Functions","keyword":"serbian","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/LLaMAX/BenchMAX_Multiple_Functions","creator_name":"LLaMAX","creator_url":"https://huggingface.co/LLaMAX","description":"\n\t\n\t\t\n\t\tDataset Sources\n\t\n\n\nPaper: BenchMAX: A Comprehensive Multilingual Evaluation Suite for Large Language Models\nLink: https://huggingface.co/papers/2502.07346\nRepository: https://github.com/CONE-MT/BenchMAX\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nBenchMAX_Multiple_Functions is a dataset of BenchMAX, sourcing from Nexus.\nThis dataset evaluates the tool use capability in multilingual senarios, which requires a model to call the correct function given the user query and multiple functions.\nWe‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/LLaMAX/BenchMAX_Multiple_Functions.","first_N":5,"first_N_keywords":["text-generation","multilingual","English","Chinese","Spanish"],"keywords_longer_than_N":true},
	{"name":"BenchMAX_General_Translation","keyword":"serbian","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/LLaMAX/BenchMAX_General_Translation","creator_name":"LLaMAX","creator_url":"https://huggingface.co/LLaMAX","description":"\n\t\n\t\t\n\t\tDataset Sources\n\t\n\n\nPaper: BenchMAX: A Comprehensive Multilingual Evaluation Suite for Large Language Models\nLink: https://huggingface.co/papers/2502.07346\nRepository: https://github.com/CONE-MT/BenchMAX\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nBenchMAX_General_Translation is a dataset of BenchMAX, which evaluates the translation capability on the general domain.\nWe collect parallel test data from Flore-200, TED-talk, and WMT24.\n\n\t\n\t\t\n\t\n\t\n\t\tUsage\n\t\n\ngit clone‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/LLaMAX/BenchMAX_General_Translation.","first_N":5,"first_N_keywords":["translation","multilingual","English","Chinese","Spanish"],"keywords_longer_than_N":true},
	{"name":"BenchMAX_Domain_Translation","keyword":"serbian","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/LLaMAX/BenchMAX_Domain_Translation","creator_name":"LLaMAX","creator_url":"https://huggingface.co/LLaMAX","description":"\n\t\n\t\t\n\t\tDataset Sources\n\t\n\n\nPaper: BenchMAX: A Comprehensive Multilingual Evaluation Suite for Large Language Models\nLink: https://huggingface.co/papers/2502.07346\nRepository: https://github.com/CONE-MT/BenchMAX\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nBenchMAX_Domain_Translation is a dataset of BenchMAX, which evaluates the translation capability on specific domains.\nWe collect the domain multi-way parallel data from other tasks in BenchMAX, such as math data, code data, etc.\nEach sample contains one‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/LLaMAX/BenchMAX_Domain_Translation.","first_N":5,"first_N_keywords":["translation","multilingual","English","Chinese","Spanish"],"keywords_longer_than_N":true},
	{"name":"reranker_continuous_filt_max7_train","keyword":"serbian","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/lightblue/reranker_continuous_filt_max7_train","creator_name":"Lightblue KK.","creator_url":"https://huggingface.co/lightblue","description":"\n\t\n\t\t\n\t\tReranker training data\n\t\n\nThis data was generated using 4 steps:\n\nWe gathered queries and corresponding text data from 35 high quality datasets covering more than 95 languages.\nFor datasets which did not already have negative texts for queries, we mined hard negatives using the BAAI/bge-m3 embedding model.\nFor each query, we selected one positive and one negative text and used Qwen/Qwen2.5-32B-Instruct-GPTQ-Int4 to rate the relatedness of each query-text pair using a token \"1\", \"2\"‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/lightblue/reranker_continuous_filt_max7_train.","first_N":5,"first_N_keywords":["English","Chinese","Spanish","German","Arabic"],"keywords_longer_than_N":true},
	{"name":"FineTome-Alpaca-Bosnian","keyword":"serbian","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/TimesLast/FineTome-Alpaca-Bosnian","creator_name":"times last","creator_url":"https://huggingface.co/TimesLast","description":"This is a Bosnian translation of the FineTome_Alpaca dataset, hope it helps someone out! \n","first_N":5,"first_N_keywords":["question-answering","Bosnian","Croatian","Serbian","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"webfaq","keyword":"serbian","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/PaDaS-Lab/webfaq","creator_name":"Chair of Data Science, University of Passau","creator_url":"https://huggingface.co/PaDaS-Lab","description":"WebFAQ Q&A Dataset\n\n   \n       Overview |\n       Details  |\n       Structure  |\n       Examples |\n       Considerations |\n       License |\n       Citation |\n       Contact |\n       Acknowledgement\n   \n\n\n\n\t\n\t\t\n\t\n\t\n\t\tOverview\n\t\n\nThe WebFAQ Q&A Dataset is a broad-coverage corpus of 96 million natural question-answer (QA) pairs in 75 languages, gathered from FAQ pages on the web. It leverages structured schema.org FAQPage annotations, making it a unique resource for large-scale Question Answering‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/PaDaS-Lab/webfaq.","first_N":5,"first_N_keywords":["question-answering","multilingual","Afrikaans","Amharic","Arabic"],"keywords_longer_than_N":true},
	{"name":"postocr-sr","keyword":"serbian","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Sagicc/postocr-sr","creator_name":"Andrija","creator_url":"https://huggingface.co/Sagicc","description":"\n\t\n\t\t\n\t\tDataset for OCR correction for Serbian\n\t\n\nBased on Serbian novels it have 'train' (102)  and 'test'(2) splits.\nRaw OCR is based on Wikimedia SrpELTeC PDF collection on this link. Github link\nCorrected OCR files are in TEI xml format, and are available on this links:\n\n100\n20\n\nThis files are part of \"Distant Reading for European Literary History\" Project. link.\nThe whole corpus, in readable format, is available on this link.\nSerbian novels are available on this link\nCorrected novels are‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Sagicc/postocr-sr.","first_N":5,"first_N_keywords":["Serbian","cc-by-4.0","< 1K","json","Text"],"keywords_longer_than_N":true},
	{"name":"bcms-fake-news-articles","keyword":"serbian","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/toni5rovic/bcms-fake-news-articles","creator_name":"Antonije Petrovic","creator_url":"https://huggingface.co/toni5rovic","description":"toni5rovic/bcms-fake-news-articles dataset hosted on Hugging Face and contributed by the HF Datasets community","first_N":5,"first_N_keywords":["text-classification","Croatian","Serbian","Bosnian","Serbo-Croatian"],"keywords_longer_than_N":true},
	{"name":"wikipedia-citation-index","keyword":"serbian","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/lewoniewski/wikipedia-citation-index","creator_name":"W≈Çodzimierz Lewoniewski","creator_url":"https://huggingface.co/lewoniewski","description":"Dataset with citation indexes as of 1 August 2024 for 47 million Wikipedia articles in 55 language versions. Research: ArXiv\n","first_N":5,"first_N_keywords":["Arabic","Azerbaijani","Belarusian","Bulgarian","Catalan"],"keywords_longer_than_N":true}
]
;
