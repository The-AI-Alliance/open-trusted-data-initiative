const data_for_modality_reasoning = 
[
	{"name":"cleand_cw18_lean-six-sigma-cot-500","keyword":"reasoning","description":"å…ƒãƒ‡ãƒ¼ã‚¿: https://huggingface.co/datasets/cw18/lean-six-sigma-cot-500\nä½¿ç”¨ã—ãŸã‚³ãƒ¼ãƒ‰: https://github.com/LLMTeamAkiyama/0-data_prepare/tree/master/src/lean-six-sigma-cot-500\n\nãƒ‡ãƒ¼ã‚¿ä»¶æ•°: 215\nå¹³å‡ãƒˆãƒ¼ã‚¯ãƒ³æ•°: 514\næœ€å¤§ãƒˆãƒ¼ã‚¯ãƒ³æ•°: 591\nåˆè¨ˆãƒˆãƒ¼ã‚¯ãƒ³æ•°: 110,520\nãƒ•ã‚¡ã‚¤ãƒ«å½¢å¼: JSONL\nãƒ•ã‚¡ã‚¤ãƒ«åˆ†å‰²æ•°: 1\nåˆè¨ˆãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚º: 602.9 KB\n\nåŠ å·¥å†…å®¹ï¼š\n\næ–‡å­—åˆ—é•·ã«ã‚ˆã‚‹ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°:\ninstructionåˆ—ï¼ˆè³ªå•ï¼‰ã®æ–‡å­—æ•°ãŒ6000æ–‡å­—ã‚’è¶…ãˆã‚‹è¡Œã‚’é™¤å¤–ã—ã¾ã—ãŸã€‚\noutputåˆ—ï¼ˆæ€è€ƒï¼‰ã®æ–‡å­—æ•°ãŒ80000æ–‡å­—ã‚’è¶…ãˆã‚‹è¡Œã‚’é™¤å¤–ã—ã¾ã—ãŸã€‚\n\n\næ€è€ƒã‚¿ã‚°ã®é™¤å»ã¨åˆ†å‰²:\nIS_THINKTAGãŒFalseã«è¨­å®šã•ã‚Œã¦ã„ã‚‹ãŸã‚ã€outputåˆ—ã‚’SPLIT_KEYWORD (**Final Toolsetâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/LLMTeamAkiyama/cleand_cw18_lean-six-sigma-cot-500.","url":"https://huggingface.co/datasets/LLMTeamAkiyama/cleand_cw18_lean-six-sigma-cot-500","creator_name":"LLMTeamAkiyama","creator_url":"https://huggingface.co/LLMTeamAkiyama","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["question-answering","English","mit","< 1K","json"],"keywords_longer_than_N":true},
	{"name":"TinyDS-20k","keyword":"reasoning","description":"\n\t\n\t\t\n\t\tTinyDS\n\t\n\n\n\n\nAlpaca-style dataset with around 20k samples scraped from Qwen3-8B using SyntheticAlpaca. Q&A pairs can be in 32 different languages, these are listed in the metadata.Topics are all around STEM, programming, and literature.  \nMIT @ 2025 Hamzah Asadullah\n\n\n","url":"https://huggingface.co/datasets/Hamzah-Asadullah/TinyDS-20k","creator_name":"Hamzah Asadullah","creator_url":"https://huggingface.co/Hamzah-Asadullah","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["question-answering","translation","text-generation","text2text-generation","English"],"keywords_longer_than_N":true},
	{"name":"AquilaX-AI-security-assistant-reasoning","keyword":"reasoning","description":"\n\t\n\t\t\n\t\tAquilaX Security Assistant with Reasoning Template\n\t\n\nA cybersecurity instruction-tuning dataset converted from AquilaX-AI/security_assistant_data with explicit reasoning template for training models with chain-of-thought capabilities in vulnerability analysis.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset contains 18,282 examples focused on cybersecurity vulnerability analysis, secure coding practices, and security remediation. Each assistant response includes structured reasoning stepsâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/tuandunghcmut/AquilaX-AI-security-assistant-reasoning.","url":"https://huggingface.co/datasets/tuandunghcmut/AquilaX-AI-security-assistant-reasoning","creator_name":"DÅ©ng VÃµ","creator_url":"https://huggingface.co/tuandunghcmut","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","question-answering","English","apache-2.0","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"OrgStrategy-Reasoning-1k","keyword":"reasoning","description":"\n\t\n\t\t\n\t\tOrgStrategy Reasoning 1k (v2)\n\t\n\n\n\t\n\t\t\n\t\tWhat This Dataset Is About\n\t\n\nThis dataset contains 1,000 real-world business strategy scenarios with structured reasoning chains that teach AI models to apply proven strategic frameworks to complex organizational problems.\n\n\t\n\t\t\n\t\tCore Purpose\n\t\n\n\nTrain models to think strategically using established business frameworks\nProvide structured reasoning patterns for complex problem-solving\nBridge the gap between generic AI responses andâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Wildstash/OrgStrategy-Reasoning-1k.","url":"https://huggingface.co/datasets/Wildstash/OrgStrategy-Reasoning-1k","creator_name":"ArnavS","creator_url":"https://huggingface.co/Wildstash","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","English","cc-by-4.0","1K - 10K","csv"],"keywords_longer_than_N":true},
	{"name":"Feedback_Friction_Dataset","keyword":"reasoning","description":"\n\t\n\t\t\n\t\tFeedback Friction Dataset\n\t\n\nThis dataset contains the LLaMA-4 Maverick results from the iterative feedback experiments described in the paper: FEEDBACK FRICTION: LLMs Struggle to Fully Incorporate External Feedback.\nGithub Repository: https://github.com/JHU-CLSP/Feedback-Friction\nNote: While the paper evaluated multiple frontier models including LLaMA-3.3-70B-Instruct, LLaMA-4-Scout-17B-16E-Instruct, Claude 3.7 Sonnet, and Claude 3.7 Sonnet with Extended Thinking, this datasetâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Dongwei/Feedback_Friction_Dataset.","url":"https://huggingface.co/datasets/Dongwei/Feedback_Friction_Dataset","creator_name":"Jiang","creator_url":"https://huggingface.co/Dongwei","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["question-answering","text-generation","English","mit","< 1K"],"keywords_longer_than_N":true},
	{"name":"probability_words_nli","keyword":"reasoning","description":"Probing neural language models for understanding of words of estimative probability","url":"https://huggingface.co/datasets/sileod/probability_words_nli","creator_name":"Damien Sileo","creator_url":"https://huggingface.co/sileod","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","multiple-choice","question-answering","open-domain-qa","multiple-choice-qa"],"keywords_longer_than_N":true},
	{"name":"MATRIX","keyword":"reasoning","description":"\n\t\n\t\t\n\t\tğŸ“¦ MATRIX Dataset\n\t\n\nMATRIX: Multimodal Agent Tuning for Robust Tool-Use Reasoning\n\n\n\t\n\t\t\n\t\tğŸ§  Dataset Description\n\t\n\nMATRIX is a large-scale multimodal dataset designed for training vision-language agents capable of grounded, step-wise reasoning and robust tool-use.It includes high-quality JSON-formatted trajectories, preference pairs, and associated multimodal contexts (images, text, tables, code).\nThis dataset supports **Direct Preference Optimization (DPO)**â€“based training andâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Tajamul21/MATRIX.","url":"https://huggingface.co/datasets/Tajamul21/MATRIX","creator_name":"Tajamul Ashraf","creator_url":"https://huggingface.co/Tajamul21","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["English","mit","Image","arxiv:2510.08567","ğŸ‡ºğŸ‡¸ Region: US"],"keywords_longer_than_N":true},
	{"name":"MAmmoTH-VL-Instruct-12M","keyword":"reasoning","description":"\n\t\n\t\t\n\t\tMAmmoTH-VL-Instruct-12M\n\t\n\nğŸ  Homepage | ğŸ¤– MAmmoTH-VL-8B | ğŸ’» Code | ğŸ“„ Arxiv | ğŸ“• PDF | ğŸ–¥ï¸ Demo\n\n\t\n\t\t\n\t\n\t\n\t\tIntroduction\n\t\n\nOur simple yet scalable visual instruction data rewriting pipeline consists of three steps: manual data source collection, rewriting using MLLMs/LLMs, and filtering via the same MLLM as a judge. Examples below illustrate transformations in math and science categories, showcasing detailed, step-by-step responses.\n\n\t\n\t\t\n\t\tThe data distribution ofâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/MAmmoTH-VL/MAmmoTH-VL-Instruct-12M.","url":"https://huggingface.co/datasets/MAmmoTH-VL/MAmmoTH-VL-Instruct-12M","creator_name":"MAmmoTH-VL","creator_url":"https://huggingface.co/MAmmoTH-VL","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["visual-question-answering","question-answering","English","apache-2.0","10M - 100M"],"keywords_longer_than_N":true},
	{"name":"u-math","keyword":"reasoning","description":"U-MATH is a comprehensive benchmark of 1,100 unpublished university-level problems sourced from real teaching materials. \nIt is designed to evaluate the mathematical reasoning capabilities of Large Language Models (LLMs). The dataset is balanced across six core mathematical topics and includes 20% of multimodal problems (involving visual elements such as graphs and diagrams). \nFor fine-grained performance evaluation results and detailed discussion, check out our paper.\n\nğŸ“Š U-MATH benchmark atâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/toloka/u-math.","url":"https://huggingface.co/datasets/toloka/u-math","creator_name":"Toloka","creator_url":"https://huggingface.co/toloka","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-generation","English","mit","1K - 10K","parquet"],"keywords_longer_than_N":true},
	{"name":"lumos_complex_qa_ground_onetime","keyword":"reasoning","description":"\n\t\n\t\t\n\t\tğŸª„ Agent Lumos: Unified and Modular Training for Open-Source Language Agents\n\t\n\n\n  ğŸŒ[Website] Â \n  ğŸ“[Paper] Â \n  ğŸ¤—[Data] Â \n  ğŸ¤—[Model] Â \n  ğŸ¤—[Demo] Â \n\n\nWe introduce ğŸª„Lumos, Language Agents with Unified Formats, Modular Design, and Open-Source LLMs. Lumos unifies a suite of complex interactive tasks and achieves competitive performance with GPT-4/3.5-based and larger open-source agents. \nLumos has following features:\n\nğŸ§© Modular Architecture:\nğŸ§© Lumos consists of planning, groundingâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/ai2lumos/lumos_complex_qa_ground_onetime.","url":"https://huggingface.co/datasets/ai2lumos/lumos_complex_qa_ground_onetime","creator_name":"Lumos  Agents (AI2)","creator_url":"https://huggingface.co/ai2lumos","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","question-answering","English","apache-2.0","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"reason-tool-use-demo-1500","keyword":"reasoning","description":"\n\t\n\t\t\n\t\tDataset info\n\t\n\nThe dataset is a selection of reasoning toolcalls data from https://huggingface.co/datasets/interstellarninja/hermes_reasoning_tool_use, which contains data from Hermes-Toolsã€Glaive-FCã€ToolAceã€Nvidia-When2Call.\nThe format has been transformed to adapt llama-factory v1 training pipeline. \n","url":"https://huggingface.co/datasets/llamafactory/reason-tool-use-demo-1500","creator_name":"LLaMA Factory","creator_url":"https://huggingface.co/llamafactory","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["question-answering","English","apache-2.0","1K - 10K","json"],"keywords_longer_than_N":true},
	{"name":"SLR-Bench-French","keyword":"reasoning","description":" \n\n\n\t\n\t\t\n\t\tğŸ§  SLR-Bench-French: Scalable Logical Reasoning Benchmark (French Edition)\n\t\n\n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tSLR-Bench Versions:\n\t\n\n\n\n\n\nSLR-Bench-French is the French-language pendant of the original SLR-Bench dataset.\nIt follows the same symbolic structure, evaluation framework, and curriculum as the English version but provides all natural-language task prompts translated into French.\nThis enables systematic evaluation and training of Large Language Models (LLMs) in logical reasoning in Frenchâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/AIML-TUDA/SLR-Bench-French.","url":"https://huggingface.co/datasets/AIML-TUDA/SLR-Bench-French","creator_name":"Artificial Intelligence & Machine Learning Lab at TU Darmstadt","creator_url":"https://huggingface.co/AIML-TUDA","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["French","cc-by-4.0","10K - 100K","parquet","Tabular"],"keywords_longer_than_N":true},
	{"name":"reason_tool_use_demo_1450","keyword":"reasoning","description":"llamafactory/reason_tool_use_demo_1450 dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/llamafactory/reason_tool_use_demo_1450","creator_name":"LLaMA Factory","creator_url":"https://huggingface.co/llamafactory","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":null,"first_N":5,"first_N_keywords":["question-answering","English","apache-2.0","1K<n<10K","ğŸ‡ºğŸ‡¸ Region: US"],"keywords_longer_than_N":true},
	{"name":"finance-reasoning-turkish","keyword":"reasoning","description":"\n\t\n\t\t\n\t\tDataset Card for Turkish Advanced Reasoning Dataset (Finance Q&A)\n\t\n\n\n\n\t\n\t\t\n\t\tLicense\n\t\n\nThis dataset is licensed under the Academic Use Only License. It is intended solely for academic and research purposes. Commercial use is strictly prohibited. For more details, refer to the LICENSE file.\nCitation: If you use this dataset in your research, please cite it as follows:\n@dataset{turkish_advanced_reasoning_finance_qa,\n  title = {Turkish Advanced Reasoning Dataset for Finance Q\\&A}â€¦ See the full description on the dataset page: https://huggingface.co/datasets/emre/finance-reasoning-turkish.","url":"https://huggingface.co/datasets/emre/finance-reasoning-turkish","creator_name":"Davut Emre TASAR","creator_url":"https://huggingface.co/emre","license_name":"Academic Free License v3.0","license_url":"https://choosealicense.com/licenses/afl-3.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","Turkish","English","afl-3.0","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"altered-riddles","keyword":"reasoning","description":"\n \n\n\n\n\t\n\t\t\n\t\tDataset Card for Altered Riddles Dataset\n\t\n\nWhile working on the academic-chains dataset, I tested a well-known alteration of a common riddle, \"just for fun\":\n\nThe surgeon, who is the boy's father, says, 'I cannot operate on this boyâ€”he's my son!'. Who is the surgeon to the boy?\n\n(Below is the original riddle for reference)\n\nA man and his son are in a terrible accident and are rushed to the hospital in critical condition. The doctor looks at the boy and exclaims, \"I can't operateâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/marcodsn/altered-riddles.","url":"https://huggingface.co/datasets/marcodsn/altered-riddles","creator_name":"Marco De Santis","creator_url":"https://huggingface.co/marcodsn","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["apache-2.0","< 1K","parquet","Text","Datasets"],"keywords_longer_than_N":true},
	{"name":"StackMathQA","keyword":"reasoning","description":"\n\n\n\t\n\t\t\n\t\tStackMathQA\n\t\n\nStackMathQA: A Curated Collection of 2 Million Mathematical Questions and Answers Sourced from Stack Exchange\n\n\n\n\n\nStackMathQA is a meticulously curated collection of 2 million mathematical questions and answers, sourced from various Stack Exchange sites. This repository is designed to serve as a comprehensive resource for researchers, educators, and enthusiasts in the field of mathematics and AI research.\n\n\t\t\n\t\n\t\tConfigs\n\t\n\nconfigs:\n- config_name: stackmathqa1600kâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/math-ai/StackMathQA.","url":"https://huggingface.co/datasets/math-ai/StackMathQA","creator_name":"math-ai","creator_url":"https://huggingface.co/math-ai","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","question-answering","English","cc-by-4.0","1M - 10M"],"keywords_longer_than_N":true},
	{"name":"StackMathQA","keyword":"mathematical-reasoning","description":"\n\n\n\t\n\t\t\n\t\tStackMathQA\n\t\n\nStackMathQA: A Curated Collection of 2 Million Mathematical Questions and Answers Sourced from Stack Exchange\n\n\n\n\n\nStackMathQA is a meticulously curated collection of 2 million mathematical questions and answers, sourced from various Stack Exchange sites. This repository is designed to serve as a comprehensive resource for researchers, educators, and enthusiasts in the field of mathematics and AI research.\n\n\t\t\n\t\n\t\tConfigs\n\t\n\nconfigs:\n- config_name: stackmathqa1600kâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/math-ai/StackMathQA.","url":"https://huggingface.co/datasets/math-ai/StackMathQA","creator_name":"math-ai","creator_url":"https://huggingface.co/math-ai","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","question-answering","English","cc-by-4.0","1M - 10M"],"keywords_longer_than_N":true},
	{"name":"inverse-scaling-ttc-main","keyword":"reasoning","description":"\n\t\n\t\t\n\t\tInverse Scaling in Test-Time Compute\n\t\n\nPaper: Inverse Scaling in Test-Time Compute\nProject Page: https://safety-research.github.io/inverse-scaling-ttc/\n\n\t\n\t\t\n\t\tAbstract\n\t\n\nWe construct evaluation tasks where extending the reasoning length of Large Reasoning Models (LRMs) deteriorates performance, exhibiting an inverse scaling relationship between test-time compute and accuracy. Our evaluation tasks span four categories: simple counting tasks with distractors, regression tasks withâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/inverse-scaling-ttc/inverse-scaling-ttc-main.","url":"https://huggingface.co/datasets/inverse-scaling-ttc/inverse-scaling-ttc-main","creator_name":"Inverse Scaling","creator_url":"https://huggingface.co/inverse-scaling-ttc","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["question-answering","text-generation","English","mit","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"tape","keyword":"reasoning","description":"The Winograd schema challenge composes tasks with syntactic ambiguity,\nwhich can be resolved with logic and reasoning (Levesque et al., 2012).\n\nThe texts for the Winograd schema problem are obtained using a semi-automatic \npipeline. First, lists of 11 typical grammatical structures with syntactic \nhomonymy (mainly case) are compiled. For example, two noun phrases with a \ncomplex subordinate: 'A trinket from Pompeii that has survived the centuries'.\nRequests corresponding to these constructions are submitted in search of the \nRussian National Corpus, or rather its sub-corpus with removed homonymy. In the \nresulting 2+k examples, homonymy is removed automatically with manual validation\nafterward. Each original sentence is split into multiple examples in the binary \nclassification format, indicating whether the homonymy is resolved correctly or\nnot.","url":"https://huggingface.co/datasets/RussianNLP/tape","creator_name":"Natural Language Processing in Russian","creator_url":"https://huggingface.co/RussianNLP","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":null,"first_N":5,"first_N_keywords":["text-classification","question-answering","multiple-choice","Russian","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"lumos_unified_ground_iterative","keyword":"reasoning","description":"\n\t\n\t\t\n\t\tğŸª„ Agent Lumos: Unified and Modular Training for Open-Source Language Agents\n\t\n\n\n  ğŸŒ[Website] Â \n  ğŸ“[Paper] Â \n  ğŸ¤—[Data] Â \n  ğŸ¤—[Model] Â \n  ğŸ¤—[Demo] Â \n\n\nWe introduce ğŸª„Lumos, Language Agents with Unified Formats, Modular Design, and Open-Source LLMs. Lumos unifies a suite of complex interactive tasks and achieves competitive performance with GPT-4/3.5-based and larger open-source agents. \nLumos has following features:\n\nğŸ§© Modular Architecture:\nğŸ§© Lumos consists of planning, groundingâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/ai2lumos/lumos_unified_ground_iterative.","url":"https://huggingface.co/datasets/ai2lumos/lumos_unified_ground_iterative","creator_name":"Lumos  Agents (AI2)","creator_url":"https://huggingface.co/ai2lumos","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","question-answering","English","apache-2.0","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"Primus-Reasoning-DeepSeek-Qwen-Template","keyword":"reasoning","description":"\n\t\n\t\t\n\t\tPrimus-Reasoning-DeepSeek-Qwen-Template\n\t\n\nThis dataset is a converted version of trendmicro-ailab/Primus-Reasoning \nadapted for DeepSeek-Qwen template format.\n\n\t\n\t\t\n\t\tChanges\n\t\n\nThe original dataset used custom special tokens for reasoning:\n\n<|reserved_special_token_0|>{reasoning}<|reserved_special_token_1|>{answer}\n\nThis version has been converted to use DeepSeek-Qwen's think tags:\n\n<think>{reasoning}</think>{answer}\n\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nEach example contains:\n\nprompt: Theâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/tuandunghcmut/Primus-Reasoning-DeepSeek-Qwen-Template.","url":"https://huggingface.co/datasets/tuandunghcmut/Primus-Reasoning-DeepSeek-Qwen-Template","creator_name":"DÅ©ng VÃµ","creator_url":"https://huggingface.co/tuandunghcmut","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","question-answering","English","apache-2.0","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"PARARULE-Plus-Depth-2","keyword":"reasoning","description":"\n\t\n\t\t\n\t\tPARARULE-Plus-Depth-2\n\t\n\nThis is a branch which includes the dataset from PARARULE-Plus Depth=2. PARARULE Plus is a deep multi-step reasoning dataset over natural language. It can be seen as an improvement on the dataset of PARARULE (Peter Clark et al., 2020). Both PARARULE and PARARULE-Plus follow the closed-world assumption and negation as failure. The motivation is to generate deeper PARARULE training samples. We add more training samples for the case where the depth is greater thanâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/qbao775/PARARULE-Plus-Depth-2.","url":"https://huggingface.co/datasets/qbao775/PARARULE-Plus-Depth-2","creator_name":"annonymous_user","creator_url":"https://huggingface.co/qbao775","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","question-answering","English","mit","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"PARARULE-Plus-Depth-4","keyword":"reasoning","description":"\n\t\n\t\t\n\t\tPARARULE-Plus-Depth-4\n\t\n\nThis is a branch which includes the dataset from PARARULE-Plus Depth=4. PARARULE Plus is a deep multi-step reasoning dataset over natural language. It can be seen as an improvement on the dataset of PARARULE (Peter Clark et al., 2020). Both PARARULE and PARARULE-Plus follow the closed-world assumption and negation as failure. The motivation is to generate deeper PARARULE training samples. We add more training samples for the case where the depth is greater thanâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/qbao775/PARARULE-Plus-Depth-4.","url":"https://huggingface.co/datasets/qbao775/PARARULE-Plus-Depth-4","creator_name":"annonymous_user","creator_url":"https://huggingface.co/qbao775","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","question-answering","English","mit","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"beyondaime","keyword":"reasoning","description":"\n\t\n\t\t\n\t\tBeyondAIME: Advancing Math Reasoning Evaluation Beyond High School Olympiads\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nBeyondAIME is a curated test set designed to benchmark advanced mathematical reasoning. Its creation was guided by the following core principles to ensure a fair and challenging evaluation:\n\nHigh Difficulty: Problems are sourced from high-school and university mathematics competitions, with a difficulty level greater than or equal to that of AIME Problems #11-15.â€¦ See the full description on the dataset page: https://huggingface.co/datasets/guanning-ai/beyondaime.","url":"https://huggingface.co/datasets/guanning-ai/beyondaime","creator_name":"frontier-ai-research","creator_url":"https://huggingface.co/guanning-ai","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["English","cc0-1.0","< 1K","parquet","Text"],"keywords_longer_than_N":true},
	{"name":"frames-benchmark","keyword":"reasoning","description":"\n\t\n\t\t\n\t\tFRAMES: Factuality, Retrieval, And reasoning MEasurement Set\n\t\n\nFRAMES is a comprehensive evaluation dataset designed to test the capabilities of Retrieval-Augmented Generation (RAG) systems across factuality, retrieval accuracy, and reasoning.\nOur paper with details and experiments is available on arXiv: https://arxiv.org/abs/2409.12941.\n\n\t\n\t\t\n\t\tDataset Overview\n\t\n\n\n824 challenging multi-hop questions requiring information from 2-15 Wikipedia articles\nQuestions span diverse topicsâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/google/frames-benchmark.","url":"https://huggingface.co/datasets/google/frames-benchmark","creator_name":"Google","creator_url":"https://huggingface.co/google","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","token-classification","table-question-answering","question-answering","English"],"keywords_longer_than_N":true},
	{"name":"PARARULE-Plus-Depth-2","keyword":"logical-reasoning","description":"\n\t\n\t\t\n\t\tPARARULE-Plus-Depth-2\n\t\n\nThis is a branch which includes the dataset from PARARULE-Plus Depth=2. PARARULE Plus is a deep multi-step reasoning dataset over natural language. It can be seen as an improvement on the dataset of PARARULE (Peter Clark et al., 2020). Both PARARULE and PARARULE-Plus follow the closed-world assumption and negation as failure. The motivation is to generate deeper PARARULE training samples. We add more training samples for the case where the depth is greater thanâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/qbao775/PARARULE-Plus-Depth-2.","url":"https://huggingface.co/datasets/qbao775/PARARULE-Plus-Depth-2","creator_name":"annonymous_user","creator_url":"https://huggingface.co/qbao775","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","question-answering","English","mit","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"PARARULE-Plus-Depth-4","keyword":"logical-reasoning","description":"\n\t\n\t\t\n\t\tPARARULE-Plus-Depth-4\n\t\n\nThis is a branch which includes the dataset from PARARULE-Plus Depth=4. PARARULE Plus is a deep multi-step reasoning dataset over natural language. It can be seen as an improvement on the dataset of PARARULE (Peter Clark et al., 2020). Both PARARULE and PARARULE-Plus follow the closed-world assumption and negation as failure. The motivation is to generate deeper PARARULE training samples. We add more training samples for the case where the depth is greater thanâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/qbao775/PARARULE-Plus-Depth-4.","url":"https://huggingface.co/datasets/qbao775/PARARULE-Plus-Depth-4","creator_name":"annonymous_user","creator_url":"https://huggingface.co/qbao775","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","question-answering","English","mit","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"LongBench-v2","keyword":"reasoning","description":"\n\t\n\t\t\n\t\tLongBench v2: Towards Deeper Understanding and Reasoning on Realistic Long-context Multitasks\n\t\n\nğŸŒ Project Page: https://longbench2.github.io\nğŸ’» Github Repo: https://github.com/THUDM/LongBench\nğŸ“š Arxiv Paper: https://arxiv.org/abs/2412.15204\nLongBench v2 is designed to assess the ability of LLMs to handle long-context problems requiring deep understanding and reasoning across real-world multitasks. LongBench v2 has the following features: (1) Length: Context length ranging from 8k toâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/zai-org/LongBench-v2.","url":"https://huggingface.co/datasets/zai-org/LongBench-v2","creator_name":"Z.ai","creator_url":"https://huggingface.co/zai-org","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["multiple-choice","question-answering","text-classification","table-question-answering","English"],"keywords_longer_than_N":true},
	{"name":"vi_math_problem_crawl","keyword":"reasoning","description":"\n\t\n\t\t\n\t\tDataset Card for Vietnamese Elementary Math Knowledge and Workbook\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThe data includes information about elementary school math knowledge in Vietnam, as well as exercises compiled from books. This is a crawlable dataset that can be trained for text generation tasks.\n\n\t\n\t\t\n\t\tSupported Tasks and Leaderboards\n\t\n\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nThe majority of the data is in Vietnamese, but there is still some English from some bilingual workbooks.\n\n\t\n\t\t\n\t\tDatasetâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/hllj/vi_math_problem_crawl.","url":"https://huggingface.co/datasets/hllj/vi_math_problem_crawl","creator_name":"Bui Van Hop","creator_url":"https://huggingface.co/hllj","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-generation","Vietnamese","English","mit","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"synthetic_text_to_sql_reasoning","keyword":"reasoning","description":"\n\t\n\t\t\n\t\tSynthetic Text-to-SQL with Reasoning Traces\n\t\n\nThis dataset is an enhanced version of gretelai/synthetic_text_to_sql with synthetic reasoning traces added using Nemo Data Designer and openai/gpt-oss-120b for generation.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\ngretelai/synthetic_text_to_sql is a rich dataset of high quality synthetic Text-to-SQL samples, designed and generated using Gretel Navigator, and released under Apache 2.0. \nThe original dataset includes:\n\n105,851 records partitioned intoâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/meowterspace45/synthetic_text_to_sql_reasoning.","url":"https://huggingface.co/datasets/meowterspace45/synthetic_text_to_sql_reasoning","creator_name":"Alex Watson","creator_url":"https://huggingface.co/meowterspace45","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","English","apache-2.0","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"Gradient-Reasoning","keyword":"reasoning","description":"Tesslate/Gradient-Reasoning dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/Tesslate/Gradient-Reasoning","creator_name":"Tesslate","creator_url":"https://huggingface.co/Tesslate","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","English","apache-2.0","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"DetailedReflection-Claude-v3_5-Sonnet","keyword":"reflection","description":"\n\t\n\t\t\n\t\tDetailedReflection-Claude-v3_5-Sonnet\n\t\n\nThis is a reflection dataset inspired by OpenAI's o1 model. It contains filtered prompts from anthracite-org/kalo-opus-instruct-22k-no-refusal.\nThe data was generated by Claude 3.5 Sonnet with a custom system prompt and sampling parameters on OpenRouter.\n","url":"https://huggingface.co/datasets/leafspark/DetailedReflection-Claude-v3_5-Sonnet","creator_name":"leafspark","creator_url":"https://huggingface.co/leafspark","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","English","apache-2.0","< 1K","parquet"],"keywords_longer_than_N":true},
	{"name":"cleand_open-r1_codeforces-cots","keyword":"reasoning","description":"å…ƒãƒ‡ãƒ¼ã‚¿: https://huggingface.co/datasets/open-r1/codeforces-cots\nãƒ‡ãƒ¼ã‚¿ä»¶æ•°: 5,334\nå¹³å‡ãƒˆãƒ¼ã‚¯ãƒ³æ•°: 11512\næœ€å¤§ãƒˆãƒ¼ã‚¯ãƒ³æ•°: 30,725\nåˆè¨ˆãƒˆãƒ¼ã‚¯ãƒ³æ•°: 61,406,976\nãƒ•ã‚¡ã‚¤ãƒ«å½¢å¼: JSONL\nãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚º: 213.1 MB\nåŠ å·¥å†…å®¹\n\nsolutions_w_editorials_decontaminatedã‚’ä½¿ç”¨\nåœæ­¢ç†ç”±ã‚’stopã«é™å®š\nãƒˆãƒ¼ã‚¯ãƒ³å‡¦ç†ãŒé‡ãŸã„ã®ã§ã€æ–‡å­—æ•°ã§ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼\nprompt < 6000\ngeneration < 80000\naccepted_solutionsãŒã‚ã‚‹ã‚‚ã®\nthinkã‚¿ã‚°é™¤å»\nç¹°ã‚Šè¿”ã—é™¤å»\n\n","url":"https://huggingface.co/datasets/LLMTeamAkiyama/cleand_open-r1_codeforces-cots","creator_name":"LLMTeamAkiyama","creator_url":"https://huggingface.co/LLMTeamAkiyama","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["question-answering","English","cc-by-4.0","1K - 10K","json"],"keywords_longer_than_N":true},
	{"name":"dapo-en-10k","keyword":"reasoning","description":"\n\t\n\t\t\n\t\tUnderstanding Tool-Integrated Reasoning Training Dataset\n\t\n\nThis is the training dataset for the paper Understanding Tool-Integrated Reasoning.\nThis dataset is randomly sampled from DAPO dataset, used to study why Tool-Integrated Reasoning (TIR) makes Large Language Models (LLMs) more capable.\n","url":"https://huggingface.co/datasets/Heng1999/dapo-en-10k","creator_name":"Heng Lin","creator_url":"https://huggingface.co/Heng1999","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","English","apache-2.0","10K - 100K","json"],"keywords_longer_than_N":true},
	{"name":"TemplateGSM","keyword":"reasoning","description":"\n\n\n\t\n\t\t\n\t\tTemplateMath: Template-based Data Generation (TDG)\n\t\n\n\n\n\n\n\n\n\nThis is the official repository for the paper \"Training and Evaluating Language Models with Template-based Data Generation\", published at the ICLR 2025 DATA-FM Workshop.\nOur work introduces Template-based Data Generation (TDG), a scalable paradigm to address the critical data bottleneck in training LLMs for complex reasoning tasks. We use TDG to create TemplateGSM, a massive dataset designed to unlock the next level ofâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/math-ai/TemplateGSM.","url":"https://huggingface.co/datasets/math-ai/TemplateGSM","creator_name":"math-ai","creator_url":"https://huggingface.co/math-ai","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["question-answering","English","cc-by-4.0","10M - 100M","Tabular"],"keywords_longer_than_N":true},
	{"name":"TemplateGSM","keyword":"mathematical-reasoning","description":"\n\n\n\t\n\t\t\n\t\tTemplateMath: Template-based Data Generation (TDG)\n\t\n\n\n\n\n\n\n\n\nThis is the official repository for the paper \"Training and Evaluating Language Models with Template-based Data Generation\", published at the ICLR 2025 DATA-FM Workshop.\nOur work introduces Template-based Data Generation (TDG), a scalable paradigm to address the critical data bottleneck in training LLMs for complex reasoning tasks. We use TDG to create TemplateGSM, a massive dataset designed to unlock the next level ofâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/math-ai/TemplateGSM.","url":"https://huggingface.co/datasets/math-ai/TemplateGSM","creator_name":"math-ai","creator_url":"https://huggingface.co/math-ai","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["question-answering","English","cc-by-4.0","10M - 100M","Tabular"],"keywords_longer_than_N":true},
	{"name":"VMCBench","keyword":"reasoning","description":"\n\t\n\t\t\n\t\tVMCBench (Automated Generation of Challenging Multiple-Choice Questions for Vision Language Model Evaluation)\n\t\n\nğŸŒ Homepage | ğŸ¤— Dataset | ğŸ“– arXiv | GitHub\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Introduction\n\t\n\nWe introduce VMCBench: a benchmark that unifies 20 existing visual question answering (VQA) datasets into a consistent multiple-choice format. VMCBench spans a diverse array of visual and linguistic contexts, rigorously testing various model capabilities. Byâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/suyc21/VMCBench.","url":"https://huggingface.co/datasets/suyc21/VMCBench","creator_name":"Yuchang Su","creator_url":"https://huggingface.co/suyc21","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["mit","1K - 10K","parquet","Image","Text"],"keywords_longer_than_N":true},
	{"name":"gsm8k_distilled","keyword":"step-by-step","description":"A dataset containing mathematical problem-solving traces with step-by-step solutions and improvement history. Each record includes a mathematical problem, its final solution, and the iterative improvement process.","url":"https://huggingface.co/datasets/camel-ai/gsm8k_distilled","creator_name":"CAMEL-AI.org","creator_url":"https://huggingface.co/camel-ai","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-generation","English","mit","1K - 10K","json"],"keywords_longer_than_N":true},
	{"name":"arabic-reasoning-dataset-logic","keyword":"logical-reasoning","description":"\n\t\n\t\t\n\t\tArabic Logical Reasoning Tasks Dataset (Maximum 1000 Tasks)\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset comprises a series of logical reasoning tasks designed to evaluate and train artificial intelligence models on understanding and generating logical inferences in the Arabic language. Each task includes a unique identifier, the task type, the task text (a question and a proposed answer), and a detailed solution that outlines the thinking steps and the final answer.\n\n\t\n\t\t\n\t\tData Format\n\t\n\nTheâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/beetleware/arabic-reasoning-dataset-logic.","url":"https://huggingface.co/datasets/beetleware/arabic-reasoning-dataset-logic","creator_name":"beetleware","creator_url":"https://huggingface.co/beetleware","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["Arabic","mit","1K - 10K","json","Text"],"keywords_longer_than_N":true},
	{"name":"Safe-CoT","keyword":"step-by-step","description":"A dataset containing mathematical problem-solving traces with step-by-step solutions and improvement history. Each record includes a mathematical problem, its final solution, and the iterative improvement process.","url":"https://huggingface.co/datasets/Sanjin2024/Safe-CoT","creator_name":"XIN GAO","creator_url":"https://huggingface.co/Sanjin2024","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-generation","English","mit","< 1K","json"],"keywords_longer_than_N":true},
	{"name":"hippovlog-dataset","keyword":"reasoning","description":"\n\t\n\t\t\n\t\tDataset Card for HippoVlog\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nHippoVlog is a novel benchmark dataset designed for evaluating Multimodal Memory and Reasoning (MMR) systems. It consists of 25 long-form daily vlogs (682 minutes total) with naturalistic audiovisual content and 1,000 validated multiple-choice question-answer pairs.\n\n\t\n\t\t\n\t\tSupported Tasks and Leaderboards\n\t\n\nThe dataset supports the following tasks:\n\nMultimodal Memory and Reasoning (MMR): The primary task involves answeringâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/linyueqian/hippovlog-dataset.","url":"https://huggingface.co/datasets/linyueqian/hippovlog-dataset","creator_name":"Yueqian Lin","creator_url":"https://huggingface.co/linyueqian","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["question-answering","visual-question-answering","visual-question-answering","multiple-choice-qa","English"],"keywords_longer_than_N":true},
	{"name":"vulnerability-intelligence-diagrammatic-reasoning","keyword":"reasoning","description":"\n \n\n\n\n\t\n\t\t\n\t\tVulnerability Intelligence with Diagrammatic Reasoning\n\t\n\n\n[!Important]\nThis dataset was created as a proof-of-concept for the Reasoning Datasets Competition (May 2025). If you have any feedback or suggestions, please feel free to open a discussion! Access the Github repository here.\n\n\n\t\n\t\t\n\t\n\t\n\t\tA. Overview\n\t\n\n\n\n\n\n\n\nThis dataset focuses on security vulnerability analysis through a multi-dimensional approach that combines four types of reasoning to generate valuable insights forâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/daqc/vulnerability-intelligence-diagrammatic-reasoning.","url":"https://huggingface.co/datasets/daqc/vulnerability-intelligence-diagrammatic-reasoning","creator_name":"David Quispe","creator_url":"https://huggingface.co/daqc","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["English","apache-2.0","< 1K","parquet","Text"],"keywords_longer_than_N":true},
	{"name":"math-story-problems","keyword":"reasoning","description":"\n\t\n\t\t\n\t\tMath Story Problems Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset contains mathematical word problems presented in multiple formats, from direct equations to complex story-based scenarios. It is designed for training and evaluating language models on mathematical reasoning tasks.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nThe dataset is split into three parts:\n\nTrain: 131,072 samples\nValidation: 1,024 samples\nTest: 3,072 samples\n\n\n\t\n\t\t\n\t\tFeatures\n\t\n\n{\n    \"eq_qs\": \"string\",      # Equationâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/azminetoushikwasi/math-story-problems.","url":"https://huggingface.co/datasets/azminetoushikwasi/math-story-problems","creator_name":"Azmine Toushik Wasi","creator_url":"https://huggingface.co/azminetoushikwasi","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["question-answering","text-generation","extractive-qa","open-domain-qa","language-modeling"],"keywords_longer_than_N":true},
	{"name":"variant_effect_non_snv","keyword":"reasoning","description":"\nğŸ§¬ BioReasonIncentivizing Multimodal Biological Reasoning within a DNA-LLM Model\n\n\n\n  \n  \n  \n  \n\n\n\n\t\n\t\t\n\t\tVariant Effect Coding Non-SNVs Dataset\n\t\n\n36,088 core non-SNV entries from ClinVar 2024-02-28 release, filtered for coding variants with â‰¥2-star review status, using stratified train/test splits for balanced disease representation in pathogenic/benign classification.\n\n\t\n\t\t\n\t\tUsage\n\t\n\nfrom datasets import load_dataset\n\ndataset = load_dataset(\"wanglab/variant_effect_non_snv\")\nexample =â€¦ See the full description on the dataset page: https://huggingface.co/datasets/wanglab/variant_effect_non_snv.","url":"https://huggingface.co/datasets/wanglab/variant_effect_non_snv","creator_name":"WangLab UofT","creator_url":"https://huggingface.co/wanglab","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["apache-2.0","10K - 100K","parquet","Text","Datasets"],"keywords_longer_than_N":true},
	{"name":"synmath-1-dsv3-87k","keyword":"reasoning","description":"\n\t\n\t\t\n\t\tsynmath-1-dsv3-87k\n\t\n\nsynmath-1-dsv3-87k is a dataset consisting of 86,700 math problems and their corresponding solutions, formatted in a chain-of-thought manner. The problems span 867 distinct mathematical domains, providing diverse and comprehensive coverage for fine-tuning smaller models.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nsynmath-1-dsv3-87k contains synthetically generated math problems and step-by-step solutions designed to enhance mathematical reasoning inâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Gusarich/synmath-1-dsv3-87k.","url":"https://huggingface.co/datasets/Gusarich/synmath-1-dsv3-87k","creator_name":"Daniil Sedov","creator_url":"https://huggingface.co/Gusarich","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text2text-generation","English","mit","10K - 100K","json"],"keywords_longer_than_N":true},
	{"name":"math-rollouts","keyword":"reasoning","description":"\n\t\n\t\t\n\t\tMathematical Reasoning Rollouts Dataset\n\t\n\n\n\nThis dataset contains step-by-step reasoning rollouts generated with DeepSeek R1-Distill language models solving mathematical problems from the MATH dataset.\nThe dataset is designed for analyzing reasoning patterns, branching factors, planning strategies, and the effectiveness of different reasoning approaches in mathematical problem-solving.\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Description\n\t\n\n\n\n\nCurated by: Uzay Macar, Paul C.â€¦ See the full description on the dataset page: https://huggingface.co/datasets/uzaymacar/math-rollouts.","url":"https://huggingface.co/datasets/uzaymacar/math-rollouts","creator_name":"Uzay Macar","creator_url":"https://huggingface.co/uzaymacar","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["question-answering","text-generation","English","mit","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"VLAA-Thinking","keyword":"reasoning","description":"\n\t\n\t\t\n\t\tSFT or RL? An Early Investigation into Training R1-Like Reasoning Large Vision-Language Models\n\t\n\n\n  ğŸŒ Project Page  \n  â€¢ ğŸ“„ Arxiv  \n  â€¢ ğŸ’»  Code  \n\n\n\n\n  ğŸ¤— VLAA-Thinker Family  \n  â€¢ ğŸ¤” VLAA-Thinking Dataset  \n  \n\n\n\n\n  ğŸ¤— VLAA-Thinker-Qwen2.5-3B   \n  â€¢  ğŸ¤— VLAA-Thinker-Qwen2.5-7B   \n\n\n\n\n\n\nBoth VLAA-Thinker-Qwen2.5-3B and VLAA-Thinker-Qwen2.5-7Bachieve SOTA performance on OpenCompass Multimodal Reasoning Leaderboard as of April 7th, 2025.\n\n\n\n\n\n\n\n\n\t\n\t\t\n\t\tContents\n\t\n\n\nQuick Start ğŸš€â€¦ See the full description on the dataset page: https://huggingface.co/datasets/UCSC-VLAA/VLAA-Thinking.","url":"https://huggingface.co/datasets/UCSC-VLAA/VLAA-Thinking","creator_name":"UCSC-VLAA","creator_url":"https://huggingface.co/UCSC-VLAA","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["visual-question-answering","English","apache-2.0","< 1K","imagefolder"],"keywords_longer_than_N":true},
	{"name":"shortlist-reason-v1","keyword":"reasoning","description":"\n\t\n\t\t\n\t\tShort List Reason V1\n\t\n\nA fully synthetic fine-tuning dataset of reasoning questions across multiple domains, generated using advanced language models.\n\n\n\t\n\t\t\n\t\tDescription\n\t\n\nShort List Reason V1 is a fully synthetic dataset made for fine-tuning large language models on reasoning tasks. It contains question-answer pairs from various subjects such as:\n\nMathematics  \nScience  \nBusiness  \nAnd other reasoning-oriented topics\n\nAll question-answer pairs are fully synthetic and generated byâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/catsaresupercool/shortlist-reason-v1.","url":"https://huggingface.co/datasets/catsaresupercool/shortlist-reason-v1","creator_name":"Burchid Sipt","creator_url":"https://huggingface.co/catsaresupercool","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["question-answering","apache-2.0","1K - 10K","json","Text"],"keywords_longer_than_N":true},
	{"name":"countdown-numbers-3-8","keyword":"reasoning","description":"\n\t\n\t\t\n\t\tCountdown Numbers Game Dataset\n\t\n\nThis dataset contains configurations and solutions for variations of the Countdown numbers game. Each example comprises a sequence of numbers, a target number, the computed solution (closest value), the arithmetic expression that achieves that value, the difference between the target and the computed value, and the final Countdown score.\n\n\t\n\t\t\n\t\tHuggingFace Download Links\n\t\n\n\n\n\n\n\t\n\t\t\nDataset Variant\nDataset Name\nDownload\n\n\n\t\t\nRandomâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/alexjackson17/countdown-numbers-3-8.","url":"https://huggingface.co/datasets/alexjackson17/countdown-numbers-3-8","creator_name":"Alex Jackson","creator_url":"https://huggingface.co/alexjackson17","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["mit","1M - 10M","parquet","Tabular","Text"],"keywords_longer_than_N":true},
	{"name":"ru-chain-of-thought-sharegpt","keyword":"reflection","description":"ĞŸĞµÑ€ĞµĞ²ĞµĞ´Ñ‘Ğ½Ğ½Ğ°Ñ Ğ¿Ñ€Ğ¸ Ğ¿Ğ¾Ğ¼Ğ¾Ñ‰Ğ¸ utrobinmv/t5_translate_en_ru_zh_small_1024 Ğ½Ğ° Ñ€ÑƒÑÑĞºĞ¸Ğ¹ ÑĞ·Ñ‹Ğº Ğ²ĞµÑ€ÑĞ¸Ñ Ğ´Ğ°Ñ‚Ğ°ÑĞµÑ‚Ğ° isaiahbjork/chain-of-thought-sharegpt.\n","url":"https://huggingface.co/datasets/evilfreelancer/ru-chain-of-thought-sharegpt","creator_name":"Pavel Zloi","creator_url":"https://huggingface.co/evilfreelancer","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-generation","Russian","mit","1K - 10K","json"],"keywords_longer_than_N":true},
	{"name":"MathBode-SimilarTriangles","keyword":"reasoning","description":"\n\t\n\t\t\n\t\tMathBode-SimilarTriangles: Geometry Domain\n\t\n\nSimilar triangle scaling problems from the MathBode benchmark.\nThis dataset is part of the MathBode benchmark, which evaluates the dynamic reasoning capabilities of large language models (LLMs) by treating parametric math problems as dynamic systems. Instead of testing static accuracy on fixed problems, MathBode sinusoidally varies a parameter and measures the model's response in terms of gain (amplitude tracking) and phase (reasoning lag)â€¦ See the full description on the dataset page: https://huggingface.co/datasets/cognitive-metrology-lab/MathBode-SimilarTriangles.","url":"https://huggingface.co/datasets/cognitive-metrology-lab/MathBode-SimilarTriangles","creator_name":"Cognitive Metrology Lab","creator_url":"https://huggingface.co/cognitive-metrology-lab","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["apache-2.0","1K - 10K","parquet","Tabular","Text"],"keywords_longer_than_N":true},
	{"name":"step2-DeepMath-103K-Bespoke-Filtered-Test-200-eval-cp32","keyword":"reasoning","description":"\n\t\n\t\t\n\t\tChain of Thoughtç”Ÿæˆãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ\n\t\n\nã“ã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã¯ã€å•é¡Œã¨è§£ç­”ã‹ã‚‰èª¬æ˜ï¼ˆChain of Thoughtï¼‰ã‚’ç”Ÿæˆã—ãŸãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã§ã™ã€‚\n\n\t\n\t\t\n\t\tæ¦‚è¦\n\t\n\n\nå‡¦ç†ã—ãŸã‚µãƒ³ãƒ—ãƒ«æ•°: 60\næœ‰åŠ¹ãªèª¬æ˜ç”Ÿæˆæ•°: 60\nç”ŸæˆæˆåŠŸç‡: 100.00%\nä½¿ç”¨ãƒ¢ãƒ‡ãƒ«: /home/Competition2025/P07/shareP07/share_model/step2_rlt/Qwen3-14B-step2-deepmath103k-bs512/checkpoint-32\n\n\n\t\n\t\t\n\t\tãƒˆãƒ¼ã‚¯ãƒ³æ•°çµ±è¨ˆ\n\t\n\n\næœ€å°ãƒˆãƒ¼ã‚¯ãƒ³æ•°: 892\næœ€å¤§ãƒˆãƒ¼ã‚¯ãƒ³æ•°: 5932\nå¹³å‡ãƒˆãƒ¼ã‚¯ãƒ³æ•°: 3560.4\n\n\n\t\n\t\t\n\t\tãƒˆãƒ¼ã‚¯ãƒ³æ•°åˆ†å¸ƒ\n\t\n\n\n0-100ãƒˆãƒ¼ã‚¯ãƒ³: 0ä»¶ (0.0%)\n101-500ãƒˆãƒ¼ã‚¯ãƒ³: 0ä»¶ (0.0%)\n501-1000ãƒˆãƒ¼ã‚¯ãƒ³: 1ä»¶ (1.7%)\n1001-2000ãƒˆãƒ¼ã‚¯ãƒ³: 10ä»¶ (16.7%)\n2001-5000ãƒˆãƒ¼ã‚¯ãƒ³: 41ä»¶ (68.3%)\n5001+ãƒˆãƒ¼ã‚¯ãƒ³: 8ä»¶ (13.3%)â€¦ See the full description on the dataset page: https://huggingface.co/datasets/llm-compe-2025-kato/step2-DeepMath-103K-Bespoke-Filtered-Test-200-eval-cp32.","url":"https://huggingface.co/datasets/llm-compe-2025-kato/step2-DeepMath-103K-Bespoke-Filtered-Test-200-eval-cp32","creator_name":"llm-compe-2025-kato","creator_url":"https://huggingface.co/llm-compe-2025-kato","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-generation","Japanese","English","mit","< 1K"],"keywords_longer_than_N":true},
	{"name":"gs8k_thai_r1_example","keyword":"step-by-step","description":"A dataset containing mathematical problem-solving traces with step-by-step solutions and improvement history. Each record includes a mathematical problem, its final solution, and the iterative improvement process.","url":"https://huggingface.co/datasets/StelleX/gs8k_thai_r1_example","creator_name":"StelleX","creator_url":"https://huggingface.co/StelleX","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-generation","English","mit","1K - 10K","json"],"keywords_longer_than_N":true},
	{"name":"PARADE_audio","keyword":"reasoning","description":"\n\t\n\t\t\n\t\tAHELM: A Holistic Evaluation of Audio-Language Models\n\t\n\nThis repository contains datasets used in AHELM: A Holistic Evaluation of Audio-Language Models.\nPaper: AHELM: A Holistic Evaluation of Audio-Language Models\nProject Page: https://crfm.stanford.edu/helm/audio/v1.0.0/\nCode (HELM framework): https://github.com/stanford-crfm/helm\nAHELM is a benchmark designed to holistically measure the performance of Audio-Language Models (ALMs) across 10 key aspects: audio perception, knowledgeâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/UCSC-VLAA/PARADE_audio.","url":"https://huggingface.co/datasets/UCSC-VLAA/PARADE_audio","creator_name":"UCSC-VLAA","creator_url":"https://huggingface.co/UCSC-VLAA","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["audio-text-to-text","mit","< 1K","soundfolder","Audio"],"keywords_longer_than_N":true},
	{"name":"PersonalFinance-CoTR-V2-Compact","keyword":"reasoning","description":"\n\t\n\t\t\n\t\tPersonal Finance Reasoning V2 - Compact Edition\n\t\n\nThis document describes a condensed version of the Personal Finance Reasoning dataset, specifically adapted for training smaller language models (e.g., 1B-4B parameters).\n\n\t\n\t\t\n\t\t1. Introduction & Motivation\n\t\n\nThe landscape of financial AI benchmarks is currently dominated by applications in corporate finance, algorithmic trading, and general financial knowledge extraction. While valuable, these benchmarks often overlook the criticalâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Akhil-Theerthala/PersonalFinance-CoTR-V2-Compact.","url":"https://huggingface.co/datasets/Akhil-Theerthala/PersonalFinance-CoTR-V2-Compact","creator_name":"Akhil Theerthala","creator_url":"https://huggingface.co/Akhil-Theerthala","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","text-generation","English","mit","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"Raiden-DeepSeek-R1","keyword":"reasoning","description":"Click here to support our open-source dataset and model releases!\nRaiden-DeepSeek-R1 is a dataset containing creative-reasoning and analytic-reasoning responses, testing the limits of DeepSeek R1's reasoning skills!\nThis dataset contains:\n\n63k 'creative_content' and 'analytical_reasoning' prompts from microsoft/orca-agentinstruct-1M-v1, with all responses generated by deepseek-ai/DeepSeek-R1.\nResponses demonstrate the reasoning capabilities of DeepSeek's 685b parameter R1 reasoning model.â€¦ See the full description on the dataset page: https://huggingface.co/datasets/sequelbox/Raiden-DeepSeek-R1.","url":"https://huggingface.co/datasets/sequelbox/Raiden-DeepSeek-R1","creator_name":"t.d.a.g.","creator_url":"https://huggingface.co/sequelbox","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","English","apache-2.0","10K - 100K","csv"],"keywords_longer_than_N":true},
	{"name":"VoiceAssistant-Eval","keyword":"reasoning","description":"\n\t\n\t\t\n\t\tğŸ”¥ VoiceAssistant-Eval: Benchmarking AI Assistants across Listening, Speaking, and Viewing\n\t\n\n \n \n \n \n\n\n\n\n\n\n\nğŸŒŸ  This is the official repository for the paper \"VoiceAssistant-Eval: Benchmarking AI Assistants across Listening, Speaking, and Viewing\", which contains the evaluation code for the VoiceAssistant-Eval benchmark.\n[ğŸŒ Homepage] [ğŸ’» Github] [ğŸ“Š Leaderboard ] [ğŸ“Š Detailed Leaderboard ] [ğŸ“Š Roleplay Leaderboard ] [ğŸ“– Paper]\n\n\n\n\n\n\t\n\t\t\n\t\tğŸš€ Data Usage\n\t\n\nfrom datasets importâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/MathLLMs/VoiceAssistant-Eval.","url":"https://huggingface.co/datasets/MathLLMs/VoiceAssistant-Eval","creator_name":"LLMs for Reasoning","creator_url":"https://huggingface.co/MathLLMs","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["question-answering","visual-question-answering","audio-to-audio","any-to-any","multiple-choice"],"keywords_longer_than_N":true},
	{"name":"RelatLogic-Reasoning","keyword":"reasoning","description":"\n \n\n\n\n\t\n\t\t\n\t\tRelatLogic Reasoning Dataset\n\t\n\nThis dataset contains examples of logic puzzles involving comparisons, conditional statements, and superlative queries etc. each paired with a step-by-step, chain of thought reasoning and a groundâ€truth answer. It is designed to advance LLM capabilities in deep, multiâ€step reasoning, constraint satisfaction and evidence evaluation.\n\n\t\n\t\t\n\t\tğŸ¤” Curation Rationale\n\t\n\nA lot of LLM's these days are \"aligned\" to agree with the user. You can \"convince\" itâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/shb777/RelatLogic-Reasoning.","url":"https://huggingface.co/datasets/shb777/RelatLogic-Reasoning","creator_name":"SB","creator_url":"https://huggingface.co/shb777","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["question-answering","English","cc-by-4.0","< 1K","parquet"],"keywords_longer_than_N":true},
	{"name":"LogicHaystacks","keyword":"reasoning","description":"\n\t\n\t\t\n\t\tEvaluation code:\n\t\n\n\ndef parse(x):\n    if '<answer>' in x and '</answer>' in x:\n        start = x.find('<answer>') + len('<answer>')\n        end = x.find('</answer>')\n        x = x[start:end]\n    \n    lines = [i.lstrip('L').strip() for i in x.strip().strip('.').split(',')]\n    return [int(i) for i in lines if i.isnumeric()]\n\ndef jaccard(list1, list2):\n    intersection = len(list(set(list1).intersection(list2)))\n    union = (len(set(list1)) + len(set(list2))) - intersection\n    returnâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/sileod/LogicHaystacks.","url":"https://huggingface.co/datasets/sileod/LogicHaystacks","creator_name":"Damien Sileo","creator_url":"https://huggingface.co/sileod","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","English","cc-by-4.0","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"Arabic-Optimized-Reasoning-Dataset","keyword":"reasoning","description":"\n\t\n\t\t\n\t\tArabic Optimized Reasoning Dataset\n\t\n\nDataset Name: Arabic Optimized ReasoningLicense: Apache-2.0Formats: CSVSize: 1600 rowsBase Dataset: cognitivecomputations/dolphin-r1Libraries Used: Datasets, Dask, Croissant\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThe Arabic Optimized Reasoning Dataset helps AI models get better at reasoning in Arabic. While AI models are good at many tasks, they often struggle with reasoning in languages other than English. This dataset helps fix this problem by:\n\nUsing fewer tokensâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Jr23xd23/Arabic-Optimized-Reasoning-Dataset.","url":"https://huggingface.co/datasets/Jr23xd23/Arabic-Optimized-Reasoning-Dataset","creator_name":"Jaber","creator_url":"https://huggingface.co/Jr23xd23","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["question-answering","table-question-answering","Arabic","apache-2.0","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"Open-Omega-Forge-1M","keyword":"reasoning","description":"\n\n\t\n\t\t\n\t\tOpen-Omega-Forge-1M\n\t\n\n\nOpen-Omega-Forge-1M is a carefully curated and optimized collection derived from multiple high-quality datasets, specifically designed to enhance reasoning capabilities across mathematical, scientific, and coding domains. This dataset represents a focused subset that maintains the quality and diversity of reasoning patterns while providing a more manageable size for training and evaluation. A high-quality, compact reasoning dataset designed for mathematicsâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/prithivMLmods/Open-Omega-Forge-1M.","url":"https://huggingface.co/datasets/prithivMLmods/Open-Omega-Forge-1M","creator_name":"Prithiv Sakthi","creator_url":"https://huggingface.co/prithivMLmods","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","question-answering","English","apache-2.0","1M - 10M"],"keywords_longer_than_N":true},
	{"name":"reflection-small-sonnet","keyword":"reasoning","description":"\n\t\n\t\t\n\t\tVerified reasoning examples\n\t\n\n","url":"https://huggingface.co/datasets/efederici/reflection-small-sonnet","creator_name":"Edoardo Federici","creator_url":"https://huggingface.co/efederici","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text2text-generation","Italian","apache-2.0","< 1K","parquet"],"keywords_longer_than_N":true},
	{"name":"Turkish-Dialectical-Reasoning-Dataset-Sokrates-ToT","keyword":"reasoning","description":"\n\t\n\t\t\n\t\tTurkish Dialectical Reasoning Dataset (Sokrates-ToT)\n\t\n\nThe Turkish Dialectical Reasoning Dataset (Sokrates-ToT) is a collection structured in a Tree-of-Thought (ToT) format, based on a multi-persona and dialectical reasoning framework.Inspired by Socrates' method of dialogue, it facilitates deep analysis of complex and multidimensional issues by having AI personas with different expertise interact and ultimately reach a final synthesis.\n\n\n\t\n\t\t\n\t\n\t\n\t\tPurpose of the Dataset\n\t\n\nThisâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/yusufbaykaloglu/Turkish-Dialectical-Reasoning-Dataset-Sokrates-ToT.","url":"https://huggingface.co/datasets/yusufbaykaloglu/Turkish-Dialectical-Reasoning-Dataset-Sokrates-ToT","creator_name":"Yusuf  BaykaloÄŸlu","creator_url":"https://huggingface.co/yusufbaykaloglu","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["question-answering","text-generation","Turkish","apache-2.0","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"Raiden-DeepSeek-R1-PREVIEW","keyword":"reasoning","description":"This is a preview of the full Raiden-Deepseek-R1 creative and analytical reasoning dataset, containing the first ~6k rows. Get the full dataset here!\nThis dataset uses synthetic data generated by deepseek-ai/DeepSeek-R1.\nThe initial release of Raiden uses 'creative_content' and 'analytical_reasoning' prompts from microsoft/orca-agentinstruct-1M-v1.\nDataset has not been reviewed for format or accuracy. All responses are synthetic and provided without editing.\nUse as you will.\n","url":"https://huggingface.co/datasets/sequelbox/Raiden-DeepSeek-R1-PREVIEW","creator_name":"t.d.a.g.","creator_url":"https://huggingface.co/sequelbox","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["English","apache-2.0","1K - 10K","csv","Text"],"keywords_longer_than_N":true},
	{"name":"dhanishtha-2.0-superthinker","keyword":"reasoning","description":"\n\t\n\t\t\n\t\tğŸ“¦ Dhanishtha-2.0-SUPERTHINKER-MLX\n\t\n\n A distilled corpus of 11.7K high-quality samples showcasing multi-phase reasoning and structured emotional cognition. Sourced directly from the internal training data of Dhanishtha-2.0 â€” the worldâ€™s first Large Language Model (LLM) to implement Intermediate Thinking, featuring multiple <think> and <ser> blocks per response\n\n\t\n\t\t\n\t\n\t\n\t\tExample with MLX-LM-LoRA:\n\t\n\nmlx_lm_lora.train \\\n--modelâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/mlx-community/dhanishtha-2.0-superthinker.","url":"https://huggingface.co/datasets/mlx-community/dhanishtha-2.0-superthinker","creator_name":"MLX Community","creator_url":"https://huggingface.co/mlx-community","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","Afrikaans","Arabic","Bulgarian","Catalan"],"keywords_longer_than_N":true},
	{"name":"reflection-small-sonnet","keyword":"reflection","description":"\n\t\n\t\t\n\t\tVerified reasoning examples\n\t\n\n","url":"https://huggingface.co/datasets/efederici/reflection-small-sonnet","creator_name":"Edoardo Federici","creator_url":"https://huggingface.co/efederici","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text2text-generation","Italian","apache-2.0","< 1K","parquet"],"keywords_longer_than_N":true},
	{"name":"real-math-corpus-questions-with-retrievals","keyword":"mathematical-reasoning","description":"\n\t\n\t\t\n\t\tReal Math Corpus - Statement Dependencies and Questions\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset contains a comprehensive collection of mathematical statements and questions extracted from the Real Math Dataset with 207 mathematical papers. The dataset is split into two parts:\n\nCorpus: Statement dependencies and proof dependencies with complete metadata and global ID mapping\nQuestions: Main statements from papers treated as questions, with dependency mappings to the corpusâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/AK123321/real-math-corpus-questions-with-retrievals.","url":"https://huggingface.co/datasets/AK123321/real-math-corpus-questions-with-retrievals","creator_name":"Adarsh Kumarappan","creator_url":"https://huggingface.co/AK123321","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","text-classification","question-answering","English","mit"],"keywords_longer_than_N":true},
	{"name":"Geoperception","keyword":"logical-reasoning","description":"Euclid: Supercharging Multimodal LLMs with Synthetic High-Fidelity Visual Descriptions\n\n\t\n\t\t\n\t\tDataset Card for Geoperception\n\t\n\nA Benchmark for Low-level Geometric Perception\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nGeoperception is a benchmark focused specifically on accessing model's low-level visual perception ability in 2D geometry.\nIt is sourced from the Geometry-3K corpus, which offers precise logical forms for geometric diagrams, compiled from popular high-schoolâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/euclid-multimodal/Geoperception.","url":"https://huggingface.co/datasets/euclid-multimodal/Geoperception","creator_name":"Euclid Multimodal LLM","creator_url":"https://huggingface.co/euclid-multimodal","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["question-answering","visual-question-answering","English","apache-2.0","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"HumanSense_Benchmark","keyword":"reasoning","description":"\n\nHumanSense: From Multimodal Perception to Empathetic Context-Aware Responses through Reasoning MLLMs\n\n\n    Zheng Qin1,\n    Ruobing Zheng*2,\n    Yabing Wang1,\n    Tianqi Li2,\n    Yi Yuan2,\n    Jingdong Chen2,\n    Le Wangâ€ 1 \n    \n    \n    *Co-first authors. Project Lead.\n    â€ Corresponding Author.\n    \n    1Xiâ€™an Jiaotong University. 2Ant Group.\n    \n    \n\n\n Hugging Face Paper\nÂ Â Â Â Â Â Â Â Â Â Â Â Â Â \n arXiv:2508.10576\nÂ Â Â Â Â Â Â Â Â Â Â Â Â Â \n Homepage\nÂ Â Â Â Â Â Â Â Â Â Â Â Â Â \n GitHub\nÂ Â Â Â Â Â Â Â Â Â Â Â Â Â \n\n  \n    \n    Huggingâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/antgroup/HumanSense_Benchmark.","url":"https://huggingface.co/datasets/antgroup/HumanSense_Benchmark","creator_name":"Ant Group","creator_url":"https://huggingface.co/antgroup","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["video-text-to-text","English","apache-2.0","arxiv:2508.10576","ğŸ‡ºğŸ‡¸ Region: US"],"keywords_longer_than_N":true},
	{"name":"natural-sci-reasoning-smol","keyword":"reasoning","description":"\n\t\n\t\t\n\t\tFlow\n\t\n\n\n","url":"https://huggingface.co/datasets/dvilasuero/natural-sci-reasoning-smol","creator_name":"Daniel Vila","creator_url":"https://huggingface.co/dvilasuero","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","English","apache-2.0","< 1K","parquet"],"keywords_longer_than_N":true},
	{"name":"math-reasoning-dpo","keyword":"reasoning","description":"\n\t\n\t\t\n\t\tMathematical Reasoning DPO Dataset\n\t\n\nThis dataset contains mathematical reasoning problems with chosen and rejected responses, designed for Direct Preference Optimization (DPO) and preference learning of language models.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nThe dataset follows the ShareGPT format for DPO training with three main fields:\n\nconversations: List of conversation turns leading up to the response\nchosen: Preferred response with detailed reasoning and correct solution\nrejected: Lessâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/est-ai/math-reasoning-dpo.","url":"https://huggingface.co/datasets/est-ai/math-reasoning-dpo","creator_name":"ESTsoft AI","creator_url":"https://huggingface.co/est-ai","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-generation","question-answering","English","mit","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"competitive-game-dataset","keyword":"reasoning","description":"\n\t\n\t\t\n\t\tCompetitive Game Dataset\n\t\n\n\n  \n    \n      \n        \n      \n    \n    \n      \n        \n      \n    \n    \n      \n        \n      \n    \n  \n\n\nThis dataset collects move trajectories and accompanying natural-language explanations from three classic board gamesâ€”Tic-Tac-Toe, Connect Four, and Chessâ€”played by a diverse ensemble of large language models. It can be used for training or evaluating large language models (LLMs). This dataset contains\nGame trajectories generated by pair-wiseâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/yyyyyyjjjjzzz/competitive-game-dataset.","url":"https://huggingface.co/datasets/yyyyyyjjjjzzz/competitive-game-dataset","creator_name":"Albert","creator_url":"https://huggingface.co/yyyyyyjjjjzzz","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-generation","English","mit","10K - 100K","arrow"],"keywords_longer_than_N":true},
	{"name":"OmniSpatial","keyword":"reasoning","description":"\n\t\n\t\t\n\t\tOmniSpatial\n\t\n\nThis repository contains the data presented in OmniSpatial: Towards Comprehensive Spatial Reasoning Benchmark for Vision Language Models.\n\n\t\n\t\t\n\t\tTask Schema Documentation\n\t\n\nThis document provides a structured explanation of the task schema for the visual-spatial reasoning benchmark.\n\n\n\t\n\t\t\n\t\tSchema Structure\n\t\n\nThe schema is represented in JSON format, containing the following key components:\n\n\t\n\t\t\nKey\nDescription\n\n\n\t\t\nid\nIdentifier for the question, formatted asâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/qizekun/OmniSpatial.","url":"https://huggingface.co/datasets/qizekun/OmniSpatial","creator_name":"Zekun Qi","creator_url":"https://huggingface.co/qizekun","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["image-text-to-text","English","apache-2.0","1K<n<10K","Image"],"keywords_longer_than_N":true},
	{"name":"Sky-T1_data_steps","keyword":"reasoning","description":"\n\t\n\t\t\n\t\tSky-T1_data_steps\n\t\n\nThis dataset contains 182 samples taken from NovaSky-AI/Sky-T1_data_17k \ndataset and broken down to thinking steps. This dataset was used to train shakedzy/Sky-T1-32B-Steps \nLoRA adapter for step-by-step thinking.\nBreaking down the thought process to steps was done using Ollama's quantized version of Llama-3.2-1B.\nSee step_prompt file for the exact prompt used.\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Columns\n\t\n\n\nid (int): row index of the sample in the original dataset (starts at 0)â€¦ See the full description on the dataset page: https://huggingface.co/datasets/shakedzy/Sky-T1_data_steps.","url":"https://huggingface.co/datasets/shakedzy/Sky-T1_data_steps","creator_name":"Shaked","creator_url":"https://huggingface.co/shakedzy","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","English","apache-2.0","< 1K","json"],"keywords_longer_than_N":true},
	{"name":"CriticBench","keyword":"reasoning","description":"\n\t\n\t\t\n\t\tDataset Card for Dataset Name\n\t\n\n\n\nCriticBench is a comprehensive benchmark designed to assess LLMs' abilities to generate, critique/discriminate and correct reasoning across a variety of tasks. CriticBench encompasses five reasoning domains: mathematical, commonsense, symbolic, coding, and algorithmic. It compiles 15 datasets and incorporates responses from three LLM families.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\n\n\n\n\n\nCurated by: THU\nFunded by [optional]: [Moreâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/llm-agents/CriticBench.","url":"https://huggingface.co/datasets/llm-agents/CriticBench","creator_name":"LLM-Agents","creator_url":"https://huggingface.co/llm-agents","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["question-answering","text-classification","text-generation","English","mit"],"keywords_longer_than_N":true},
	{"name":"open-r1-sampled","keyword":"reasoning","description":"ykarout/open-r1-sampled dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/ykarout/open-r1-sampled","creator_name":"yehya","creator_url":"https://huggingface.co/ykarout","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["English","mit","10K - 100K","json","Text"],"keywords_longer_than_N":true},
	{"name":"Agentic-Coding-Tessa","keyword":"reasoning","description":"\n\t\n\t\t\n\t\tAgentic Coding Dataset for Tessa\n\t\n\nA comprehensive dataset for training coding agents with tool-use, reasoning, and software engineering capabilities.\n\n\t\n\t\t\n\t\tDataset Composition\n\t\n\nThis dataset combines multiple high-quality sources:\n\nhermes_reasoning (20.0%): Tool-use and reasoning dataset - interstellarninja/hermes_reasoning_tool_use\nsearch_arena (15.0%): Search and retrieval tasks - lmarena-ai/search-arena-24k\narena_human_pref (15.0%): Human preference data for alignment -â€¦ See the full description on the dataset page: https://huggingface.co/datasets/smirki/Agentic-Coding-Tessa.","url":"https://huggingface.co/datasets/smirki/Agentic-Coding-Tessa","creator_name":"Manav Majumdar","creator_url":"https://huggingface.co/smirki","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","question-answering","English","apache-2.0","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"Fast-Math-R1-GRPO","keyword":"mathematical-reasoning","description":"This repository contains the second-stage GRPO dataset for the paper A Practical Two-Stage Recipe for Mathematical LLMs: Maximizing Accuracy with SFT and Efficiency with Reinforcement Learning.\nThis dataset is crucial for the second stage of the training recipe, aiming to improve token efficiency while preserving peak mathematical reasoning performance in Large Language Models (LLMs) through Reinforcement Learning from online inference (GRPO).\nWe extracted the answers from the 2nd stage SFTâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/RabotniKuma/Fast-Math-R1-GRPO.","url":"https://huggingface.co/datasets/RabotniKuma/Fast-Math-R1-GRPO","creator_name":"Hiroshi Yoshihara","creator_url":"https://huggingface.co/RabotniKuma","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","apache-2.0","1K - 10K","csv","Text"],"keywords_longer_than_N":true},
	{"name":"real-math-corpus-questions-with-cross-paper-retrievals","keyword":"mathematical-reasoning","description":"\n\t\n\t\t\n\t\tReal Math Corpus - Statement Dependencies and Questions\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset contains a comprehensive collection of mathematical statements and questions extracted from the Real Math Dataset with 207 mathematical papers. The dataset is split into two parts:\n\nCorpus: Statement dependencies and proof dependencies with complete metadata and global ID mapping\nQuestions: Main statements from papers treated as questions, with enhanced dependency mappings to theâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/AK123321/real-math-corpus-questions-with-cross-paper-retrievals.","url":"https://huggingface.co/datasets/AK123321/real-math-corpus-questions-with-cross-paper-retrievals","creator_name":"Adarsh Kumarappan","creator_url":"https://huggingface.co/AK123321","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","text-classification","question-answering","English","mit"],"keywords_longer_than_N":true},
	{"name":"MMMU-LLM-R1-format","keyword":"reasoning","description":"\n\t\n\t\t\n\t\tMMMU-LLM-R1 Reformatted Dataset\n\t\n\n","url":"https://huggingface.co/datasets/xDAN-Vision/MMMU-LLM-R1-format","creator_name":"xDAN-RL-Group","creator_url":"https://huggingface.co/xDAN-Vision","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["English","cc-by-4.0","< 1K","parquet","Image"],"keywords_longer_than_N":true},
	{"name":"step2-evaluated-dataset-test2","keyword":"reasoning","description":"\n\t\n\t\t\n\t\tComplete Evaluation Dataset (Rubric + LogP)\n\t\n\nThis dataset contains chain-of-thought explanations evaluated using both comprehensive rubric assessment and LogP evaluation.\n\n\t\n\t\t\n\t\tOverview\n\t\n\n\nSource Dataset: llm-compe-2025-kato/step2-evaluated-dataset-test2\nTotal Samples: 92\nSuccessfully Evaluated (Rubric): 92\nFailed Evaluations (Rubric): 0\nEvaluation Model: Qwen/Qwen3-32B\n\n\n\t\n\t\t\n\t\tRubric Evaluation Results\n\t\n\n\n\t\n\t\t\n\t\tAverage Rubric Scores (0-4 scale)\n\t\n\n\nlogical_coherence: 3.51â€¦ See the full description on the dataset page: https://huggingface.co/datasets/llm-compe-2025-kato/step2-evaluated-dataset-test2.","url":"https://huggingface.co/datasets/llm-compe-2025-kato/step2-evaluated-dataset-test2","creator_name":"llm-compe-2025-kato","creator_url":"https://huggingface.co/llm-compe-2025-kato","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-generation","English","mit","< 1K","parquet"],"keywords_longer_than_N":true},
	{"name":"qwen3_dwq_calibration_1332_235b","keyword":"reasoning","description":"\n\t\n\t\t\n\t\tQwen3 DWQ Calibration Dataset (235B, 1332 samples)\n\t\n\nThis dataset contains 1,332 samples for calibrating dynamic weight quantization (DWQ) of Qwen3-235B models. It is created following the methodology of mlx-community/qwen3_dwq_calibration_1332 but using the larger Qwen3-235B model.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset is derived from allenai/tulu-3-sft-mixture and consists of:\n\n610 samples processed through Qwen3-235B with explicit reasoning \n722 original samples from theâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/mlx-community/qwen3_dwq_calibration_1332_235b.","url":"https://huggingface.co/datasets/mlx-community/qwen3_dwq_calibration_1332_235b","creator_name":"MLX Community","creator_url":"https://huggingface.co/mlx-community","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["English","mit","1K - 10K","parquet","Text"],"keywords_longer_than_N":true},
	{"name":"morehopqa","keyword":"reasoning","description":"\n\t\n\t\t\n\t\tMoreHopQA Dataset\n\t\n\nThis is a processed version of the MoreHopQA dataset, originally created by Aizawa Lab, National Institute of Informatics (NII), Tokyo, Japan. The original dataset can be found at alabnii/morehopqa.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nMoreHopQA is a multi-hop question answering dataset that shifts from extractive to generative answers. It is created by utilizing three existing multi-hop datasets: HotpotQA, 2Wiki-MultihopQA, and MuSiQue. Instead of relying solely onâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/rdw79/morehopqa.","url":"https://huggingface.co/datasets/rdw79/morehopqa","creator_name":"Riaan De Winnaar","creator_url":"https://huggingface.co/rdw79","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["cc-by-4.0","1K - 10K","parquet","Text","Datasets"],"keywords_longer_than_N":true},
	{"name":"Bielikowo","keyword":"reasoning","description":"\n\t\n\t\t\n\t\tDatasets for Bielikowo tutorials\n\t\n\nBielikowo Github\n","url":"https://huggingface.co/datasets/kubasoltys/Bielikowo","creator_name":"Kuba Soltys","creator_url":"https://huggingface.co/kubasoltys","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","text-classification","token-classification","fill-mask","table-question-answering"],"keywords_longer_than_N":true},
	{"name":"BigGSM","keyword":"reasoning","description":"\n  Unlocking the Boundaries of Thought: A Reasoning Granularity Framework to Quantify and Optimize Chain-of-Thought\n\n\n\n      \n    | [ArXiv] | [ğŸ¤—HuggingFace] |\n    \n    \n\n\nğŸŒŸ Any contributions via PRs, issues, emails or other methods are greatly appreciated.\n\n\t\n\t\t\n\t\tğŸ”¥News\n\t\n\n\nğŸ–ï¸ Our work is accepted by NeurIPS 2024 (Oral).\nğŸ”¥ We have release benchmark on [ğŸ¤—HuggingFace].\nğŸ”¥ The paper is also available on [ArXiv].\n\n\n\t\n\t\t\n\t\tğŸ’¡ Motivation\n\t\n\nChain-of-Thought (CoT) reasoning has emerged as aâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/LightChen2333/BigGSM.","url":"https://huggingface.co/datasets/LightChen2333/BigGSM","creator_name":"Qiguang Chen","creator_url":"https://huggingface.co/LightChen2333","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text2text-generation","question-answering","English","cc-by-4.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"reasoning-required","keyword":"reasoning","description":"\n \n\n\n\n\t\n\t\t\n\t\tDataset Card for the Reasoning Required Dataset\n\t\n\n2025 has seen a massive growing interest in reasoning datasets. Currently, the majority of these datasets are focused on coding and math problems. This dataset â€“ and the associated models â€“ aim to make it easier to create reasoning datasets for a wider variety of domains. This is achieved by making it more feasible to leverage text \"in the wild\" and use a small encoder-only model to classify the level of reasoning complexityâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/davanstrien/reasoning-required.","url":"https://huggingface.co/datasets/davanstrien/reasoning-required","creator_name":"Daniel van Strien","creator_url":"https://huggingface.co/davanstrien","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","text-generation","English","mit","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"Olympiads_medium","keyword":"mathematical-reasoning","description":"\n\t\n\t\t\n\t\tNumina-Olympiads\n\t\n\nFiltered NuminaMath-CoT dataset containing only olympiads problems with valid answers.\n\n\t\n\t\t\n\t\tDataset Information\n\t\n\n\nSplit: train\nOriginal size: 13284\nFiltered size: 13240\nSource: olympiads\nAll examples contain valid boxed answers\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset is a filtered version of the NuminaMath-CoT dataset, containing only problems from olympiad sources that have valid boxed answers. Each example includes:\n\nA mathematical word problem\nAâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Metaskepsis/Olympiads_medium.","url":"https://huggingface.co/datasets/Metaskepsis/Olympiads_medium","creator_name":"Metaskepsis","creator_url":"https://huggingface.co/Metaskepsis","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-generation","expert-generated","expert-generated","monolingual","AI-MO/NuminaMath-CoT"],"keywords_longer_than_N":true},
	{"name":"rank1-R1-MSMARCO","keyword":"reasoning","description":"\n\t\n\t\t\n\t\trank1-R1-MSMARCO: Reasoning Outputs from MS MARCO Dataset\n\t\n\nğŸ“„ Paper | ğŸš€ GitHub Repository\nThis dataset contains outputs from Deepseek's R1 model on the MS MARCO passage dataset, used to train rank1. It showcases the reasoning chains and relevance judgments generated when determining document relevance for information retrieval queries.\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Description\n\t\n\nThe rank1-R1-MSMARCO dataset consists of reasoning chains and relevance judgments produced on the MS MARCO passageâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/jhu-clsp/rank1-R1-MSMARCO.","url":"https://huggingface.co/datasets/jhu-clsp/rank1-R1-MSMARCO","creator_name":"Center for Language and Speech Processing @ JHU","creator_url":"https://huggingface.co/jhu-clsp","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-generation","text-retrieval","document-retrieval","English","mit"],"keywords_longer_than_N":true},
	{"name":"Reasoning-Maths-College","keyword":"reasoning","description":"This is a Reasoning dataset build on top of my existing dataset Maths-College.\nThis has only 965 rows from Maths-College-0-Final.json dataset.\nI will add few more things in this dataset.\n","url":"https://huggingface.co/datasets/ajibawa-2023/Reasoning-Maths-College","creator_name":"Feynman Innovations","creator_url":"https://huggingface.co/ajibawa-2023","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["English","apache-2.0","< 1K","json","Text"],"keywords_longer_than_N":true},
	{"name":"OpenHumanreasoning-multilingual-2.2k","keyword":"reasoning","description":"Based off of Pinkstackorg/humanreasoning-testing-en, it is a human-generated dataset where a real person had to create most of the reasoning and the final output. If there are any mistakes please let us know.\nWe offer this dataset at an apache-2.0 license to make it useful for everybody.\nnote: translations are not human generated.\n","url":"https://huggingface.co/datasets/Pinkstack/OpenHumanreasoning-multilingual-2.2k","creator_name":"Pinkstack","creator_url":"https://huggingface.co/Pinkstack","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","Arabic","Chinese","Czech","Danish"],"keywords_longer_than_N":true},
	{"name":"Numina_medium","keyword":"mathematical-reasoning","description":"\n\t\n\t\t\n\t\tNumina-Olympiads\n\t\n\nFiltered NuminaMath-CoT dataset containing only olympiads problems with valid answers.\n\n\t\n\t\t\n\t\tDataset Information\n\t\n\n\nSplit: train\nOriginal size: 37133\nFiltered size: 37133\nSource: olympiads\nAll examples contain valid boxed answers\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset is a filtered version of the NuminaMath-CoT dataset, containing only problems from olympiad sources that have valid boxed answers. Each example includes:\n\nA mathematical word problem\nAâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Metaskepsis/Numina_medium.","url":"https://huggingface.co/datasets/Metaskepsis/Numina_medium","creator_name":"Metaskepsis","creator_url":"https://huggingface.co/Metaskepsis","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-generation","expert-generated","expert-generated","monolingual","AI-MO/NuminaMath-CoT"],"keywords_longer_than_N":true},
	{"name":"Arabic-gsm8k","keyword":"reasoning","description":"\n\t\n\t\t\n\t\tDataset Card for Arabic GSM8K\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nArabic GSM8K is an Arabic translation of the GSM8K (Grade School Math 8K) dataset, which contains high-quality linguistically diverse grade school math word problems. The original dataset was created to support the task of question answering on basic mathematical problems that require multi-step reasoning, and this Arabic version aims to extend these capabilities to Arabic language models and applications.\nThe datasetâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Omartificial-Intelligence-Space/Arabic-gsm8k.","url":"https://huggingface.co/datasets/Omartificial-Intelligence-Space/Arabic-gsm8k","creator_name":"Omartificial Intelligence Space","creator_url":"https://huggingface.co/Omartificial-Intelligence-Space","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["Arabic","mit","10K - 100K","parquet","Text"],"keywords_longer_than_N":true},
	{"name":"rc1","keyword":"reasoning","description":"\n\t\n\t\t\n\t\tReasoning Core â—‰\n\t\n\nPaper: Reasoning Core: A Scalable RL Environment for LLM Symbolic Reasoning\nCode: GitHub Repository\nreasoning-core is a text-based RLVR for LLM reasoning training.\nIt is centered on expressive symbolic tasks, including full fledged FOL, formal mathematics with TPTP, formal planning with novel domains, and syntax tasks.\n\n\t\n\t\t\n\t\n\t\n\t\tAbstract\n\t\n\nWe introduce Reasoning Core, a new scalable environment for Reinforcement\nLearning with Verifiable Rewards (RLVR), designedâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/reasoning-core/rc1.","url":"https://huggingface.co/datasets/reasoning-core/rc1","creator_name":"Reasoning Core","creator_url":"https://huggingface.co/reasoning-core","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","English","cc-by-4.0","100K - 1M","parquet"],"keywords_longer_than_N":true},
	{"name":"verify-teaser","keyword":"reasoning","description":"\n\t\n\t\t\n\t\tVERIFY: A Benchmark of Visual Explanation and Reasoning for Investigating Multimodal Reasoning FidelitY\n\t\n\nVERIFY is the first benchmark explicitly designed to assess the reasoning paths of MLLMs in visual reasoning tasks. \nBy introducing novel evaluation metrics that go beyond mere accuracy, VERIFY highlights critical limitations in current MLLMs and emphasizes the need for a more balanced approach to visual perception and logical reasoning.\nDetails of the benchmark can viewed at theâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/jing-bi/verify-teaser.","url":"https://huggingface.co/datasets/jing-bi/verify-teaser","creator_name":"jing bi","creator_url":"https://huggingface.co/jing-bi","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["image-to-text","English","mit","< 1K","parquet"],"keywords_longer_than_N":true},
	{"name":"Reasoning_Patterns_AI_Hiring_Bias_SEA","keyword":"reasoning","description":"\n\t\n\t\t\n\t\tAI Hiring Bias in Southeast Asia: Structured Candidate Comparison Dataset\n\t\n\nAI is rapidly reshaping hiring, but it risks carrying forward human biases.\nThis project tests a simple but critical question: Would an AI model still make the same hiring decision if only the candidateâ€™s race, gender, age, education, location, or company background changed?\nWe ran controlled, side-by-side hiring simulations across six major AI models used in Southeast Asia, where social divides already impactâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Chemin-AI/Reasoning_Patterns_AI_Hiring_Bias_SEA.","url":"https://huggingface.co/datasets/Chemin-AI/Reasoning_Patterns_AI_Hiring_Bias_SEA","creator_name":"Chemin AI (Formerly Supa AI)","creator_url":"https://huggingface.co/Chemin-AI","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["table-question-answering","English","cc0-1.0","< 1K","csv"],"keywords_longer_than_N":true},
	{"name":"r101","keyword":"step-by-step","description":"A dataset containing mathematical problem-solving traces with step-by-step solutions and improvement history. Each record includes a mathematical problem, its final solution, and the iterative improvement process.","url":"https://huggingface.co/datasets/zjrwtxtechstudio/r101","creator_name":"zjrwtx","creator_url":"https://huggingface.co/zjrwtxtechstudio","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-generation","English","mit","< 1K","json"],"keywords_longer_than_N":true},
	{"name":"GenRef-CoT","keyword":"reflection","description":"\n\t\n\t\t\n\t\tGenRef-CoT\n\t\n\n\n  \n\n\nWe provide 227K high-quality CoT reflections which were used to train our Qwen-based reflection generation model in ReflectionFlow [1]. To\nknow the details of the dataset creation pipeline, please refer to Section 3.2 of [1].\n\n\t\n\t\t\n\t\tDataset loading\n\t\n\nWe provide the dataset in the webdataset format for fast dataloading and streaming. We recommend downloading\nthe repository locally for faster I/O:\nfrom huggingface_hub import snapshot_download\n\nlocal_dir =â€¦ See the full description on the dataset page: https://huggingface.co/datasets/diffusion-cot/GenRef-CoT.","url":"https://huggingface.co/datasets/diffusion-cot/GenRef-CoT","creator_name":"Diffusion CoT","creator_url":"https://huggingface.co/diffusion-cot","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["English","mit","100K - 1M","webdataset","Image"],"keywords_longer_than_N":true},
	{"name":"math-mini-shareGPT","keyword":"reasoning","description":"\n\t\n\t\t\n\t\tEnosis Labs Mathematics Reasoning Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThe Enosis Labs Mathematics Reasoning Dataset is a curated collection of mathematical problems with detailed, step-by-step solutions. It is designed to foster and benchmark mathematical reasoning in AI models. The dataset covers a wide range of topics and difficulty levels (intermediate to advanced), including:\n\nArithmetic: Percentages, discounts, ratios, proportions, and more.\nAlgebra: Linear and quadratic equationsâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/enosislabs/math-mini-shareGPT.","url":"https://huggingface.co/datasets/enosislabs/math-mini-shareGPT","creator_name":"Enosis Labs, Inc.","creator_url":"https://huggingface.co/enosislabs","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["English","apache-2.0","< 1K","json","Text"],"keywords_longer_than_N":true},
	{"name":"rank1-training-data","keyword":"reasoning","description":"\n\t\n\t\t\n\t\trank1-training-data: Training Dataset for rank1 Reasoning Rerankers\n\t\n\nğŸ“„ Paper | ğŸš€ GitHub Repository\nThis dataset contains the training data used to develop the rank1 family of reasoning rerankers with LLaMA Factory. It includes query-document pairs with relevance judgments and reasoning chains that guided the models to make binary relevance decisions.\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Description\n\t\n\nThe rank1-training-data dataset is a comprehensive collection of training examples used to teachâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/jhu-clsp/rank1-training-data.","url":"https://huggingface.co/datasets/jhu-clsp/rank1-training-data","creator_name":"Center for Language and Speech Processing @ JHU","creator_url":"https://huggingface.co/jhu-clsp","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-generation","text-retrieval","document-retrieval","English","mit"],"keywords_longer_than_N":true},
	{"name":"reasoning-conversations","keyword":"reasoning","description":"\n\t\n\t\t\n\t\tMultilingual Reasoning Dataset\n\t\n\n\nInclude languages from German, Korean, Spanish, Japanese, French, Simplified Chinese, Traditional Chinese\n\nReasoning traces from Deepseek-v3-R1, Deepseek-v3-R1-Zero\n\n\nCredits sponsored by Currents API\n","url":"https://huggingface.co/datasets/syntaxsynth/reasoning-conversations","creator_name":"SyntaxSynth","creator_url":"https://huggingface.co/syntaxsynth","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["English","Spanish","Korean","German","Japanese"],"keywords_longer_than_N":true},
	{"name":"LoGiPT-data","keyword":"reasoning","description":"\n\t\n\t\t\n\t\tDataset Details\n\t\n\nThese are the training data for LoGiPT from NAACL'24 paper: \"Language Models can be Deductive Solvers\".\n\nLoGiPT-data-ProofWriter.json: Instruction-tuning data for LoGiPT constructed from ProofWriter.\nLoGiPT-data-PrOntoQA.json: Instruction-tuning data for LoGiPT constructed from PrOntoQA.\n\nAll training examples are organised in Json-format and Vicuna-style.\n\n\t\n\t\t\n\t\n\t\n\t\tIf you find this data helpful, please cite our NAACL'24 paper: (or Arxiv version:â€¦ See the full description on the dataset page: https://huggingface.co/datasets/jzfeng/LoGiPT-data.","url":"https://huggingface.co/datasets/jzfeng/LoGiPT-data","creator_name":"Jamie Jiazhan Feng","creator_url":"https://huggingface.co/jzfeng","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["question-answering","English","apache-2.0","10K - 100K","json"],"keywords_longer_than_N":true},
	{"name":"dolphin-r1-turkish","keyword":"reasoning","description":"\n  \n  \n\n\n\n  \n    \n  \n  \n    \n  \n  \n  \n\n\n  \n    \n  \n    \n    \n  \n\n\n  \n    \n\t\n\t\t\n\t\tDolphin R1 Turkish ğŸ¬\n\t\n\n\nDolphin-R1 is an Apache-2.0 English dataset curated by Eric Hartford and Cognitive Computations\nDolphin-R1-turkish is a Turkish subset of the original dataset.\n\n\n\t\n\t\t\n\t\tSponsors\n\t\n\nTheir and Wiro AI's appreciation for the generous sponsors of Dolphin R1 - Without whom this dataset could not exist.\n\nDria https://x.com/driaforall - Inference Sponsor (DeepSeek)\nChutesâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/WiroAI/dolphin-r1-turkish.","url":"https://huggingface.co/datasets/WiroAI/dolphin-r1-turkish","creator_name":"Wiro AI","creator_url":"https://huggingface.co/WiroAI","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["Turkish","apache-2.0","100K - 1M","parquet","Text"],"keywords_longer_than_N":true},
	{"name":"DistillMath","keyword":"step-by-step","description":"A dataset containing mathematical problem-solving traces with step-by-step solutions and improvement history. Each record includes a mathematical problem, its final solution, and the iterative improvement process.","url":"https://huggingface.co/datasets/csh0101/DistillMath","creator_name":"csh0101","creator_url":"https://huggingface.co/csh0101","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-generation","English","mit","< 1K","json"],"keywords_longer_than_N":true},
	{"name":"clean_multilingual_thinking","keyword":"reasoning","description":"å…ƒãƒ‡ãƒ¼ã‚¿: https://huggingface.co/datasets/HuggingFaceH4/Multilingual-Thinking\nä½¿ç”¨ã—ãŸã‚³ãƒ¼ãƒ‰: https://github.com/LLMTeamAkiyama/0-data_prepare/tree/master/src/Multilingual-Thinking\n\nãƒ‡ãƒ¼ã‚¿ä»¶æ•°: 197\nå¹³å‡ãƒˆãƒ¼ã‚¯ãƒ³æ•°: 872\næœ€å¤§ãƒˆãƒ¼ã‚¯ãƒ³æ•°: 2,339\nåˆè¨ˆãƒˆãƒ¼ã‚¯ãƒ³æ•°: 171,812\nãƒ•ã‚¡ã‚¤ãƒ«å½¢å¼: JSONL\nãƒ•ã‚¡ã‚¤ãƒ«åˆ†å‰²æ•°: 1\nåˆè¨ˆãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚º: 748.5 KB\n\nåŠ å·¥å†…å®¹ï¼š\n\n\t\n\t\t\n\t\n\t\n\t\tãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ã«ã‚ˆã‚‹ãƒ‡ãƒ¼ã‚¿ã‚¯ãƒ¬ãƒ³ã‚¸ãƒ³ã‚°\n\t\n\n\nè¨€èªãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°: reasoning_languageãŒã€ŒEnglishã€ã®ãƒ‡ãƒ¼ã‚¿ã®ã¿ã‚’æŠ½å‡ºã—ã¾ã™ã€‚\næ–‡å­—æ•°ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°: å‡¦ç†é€Ÿåº¦ã®è¦³ç‚¹ã‹ã‚‰ã€questionï¼ˆè³ªå•ï¼‰ã€thoughtï¼ˆæ€è€ƒï¼‰ã€answerï¼ˆå›ç­”ï¼‰ã®å„ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã§ã€è¦å®šã®æ–‡å­—æ•°ã‚’è¶…ãˆã‚‹é•·å¤§ãªãƒ‡ãƒ¼ã‚¿ã¯äº‹å‰ã«é™¤å¤–ã—ã¾ã™ã€‚\nç¹°ã‚Šè¿”ã—è¡¨ç¾ã®é™¤å»:â€¦ See the full description on the dataset page: https://huggingface.co/datasets/LLMTeamAkiyama/clean_multilingual_thinking.","url":"https://huggingface.co/datasets/LLMTeamAkiyama/clean_multilingual_thinking","creator_name":"LLMTeamAkiyama","creator_url":"https://huggingface.co/LLMTeamAkiyama","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["question-answering","English","apache-2.0","< 1K","json"],"keywords_longer_than_N":true},
	{"name":"cleand_HARDMath","keyword":"reasoning","description":"å…ƒãƒ‡ãƒ¼ã‚¿: https://github.com/sarahmart/HARDMath?tab=readme-ov-file\ndataãƒ•ã‚©ãƒ«ãƒ€ã®MARDMath.jsonã‚ˆã‚Š\nãƒ‡ãƒ¼ã‚¿ä»¶æ•°: 1,054\nå¹³å‡ãƒˆãƒ¼ã‚¯ãƒ³æ•°: 2112\næœ€å¤§ãƒˆãƒ¼ã‚¯ãƒ³æ•°: 28,886\nåˆè¨ˆãƒˆãƒ¼ã‚¯ãƒ³æ•°: 2,226,401\nãƒ•ã‚¡ã‚¤ãƒ«å½¢å¼: JSONL\nãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚º: 5.4 MB\n","url":"https://huggingface.co/datasets/LLMTeamAkiyama/cleand_HARDMath","creator_name":"LLMTeamAkiyama","creator_url":"https://huggingface.co/LLMTeamAkiyama","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["question-answering","English","mit","1K - 10K","json"],"keywords_longer_than_N":true},
	{"name":"MM-MathInstruct","keyword":"reasoning","description":"\n\t\n\t\t\n\t\tMathCoder-VL: Bridging Vision and Code for Enhanced Multimodal Mathematical Reasoning\n\t\n\nRepo: https://github.com/mathllm/MathCoder\nPaper: https://huggingface.co/papers/2505.10557\n\n\t\n\t\t\n\t\tIntroduction\n\t\n\nWe introduce MathCoder-VL, a series of open-source large multimodal models (LMMs) specifically tailored for general math problem-solving. We also introduce FigCodifier-8B, an image-to-code model.\n\n\t\n\t\t\nBase Model\nOurs\n\n\n\t\t\nMini-InternVL-Chat-2B-V1-5\nMathCoder-VL-2B\n\n\nInternVL2-8Bâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/MathLLMs/MM-MathInstruct.","url":"https://huggingface.co/datasets/MathLLMs/MM-MathInstruct","creator_name":"LLMs for Reasoning","creator_url":"https://huggingface.co/MathLLMs","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["question-answering","multiple-choice","visual-question-answering","text-generation","English"],"keywords_longer_than_N":true},
	{"name":"RobustFT","keyword":"reasoning","description":"\n\t\n\t\t\n\t\tRobustFT Dataset\n\t\n\nThis dataset is part of the RobustFT project: Robust Supervised Fine-tuning for Large Language Models under Noisy Response. The dataset contains various test cases with different noise ratios for training and evaluating robust fine-tuning approaches.\nOur paper: https://huggingface.co/papers/2412.14922\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nRobustFT/\nâ”œâ”€â”€ arc/\nâ”‚ â”‚â”€â”€ noisy30.csv\nâ”‚ â”‚â”€â”€ noisy50.csv\nâ”‚ â”‚â”€â”€ noisy70.csv\nâ”‚ â”œâ”€â”€ labeled.csv\nâ”‚ â””â”€â”€ test.csv\nâ”œâ”€â”€ drop/\nâ”‚ â”‚â”€â”€ noisy30.csv\nâ”‚â€¦ See the full description on the dataset page: https://huggingface.co/datasets/luojunyu/RobustFT.","url":"https://huggingface.co/datasets/luojunyu/RobustFT","creator_name":"junyu","creator_url":"https://huggingface.co/luojunyu","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["question-answering","text-generation","English","cc-by-4.0","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"step2-DeepMath-103K-Bespoke-Filtered-Test-200-eval-Qwen3-14B","keyword":"reasoning","description":"\n\t\n\t\t\n\t\tChain of Thoughtç”Ÿæˆãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ\n\t\n\nã“ã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã¯ã€å•é¡Œã¨è§£ç­”ã‹ã‚‰èª¬æ˜ï¼ˆChain of Thoughtï¼‰ã‚’ç”Ÿæˆã—ãŸãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã§ã™ã€‚\n\n\t\n\t\t\n\t\tæ¦‚è¦\n\t\n\n\nå‡¦ç†ã—ãŸã‚µãƒ³ãƒ—ãƒ«æ•°: 156\næœ‰åŠ¹ãªèª¬æ˜ç”Ÿæˆæ•°: 156\nç”ŸæˆæˆåŠŸç‡: 100.00%\nä½¿ç”¨ãƒ¢ãƒ‡ãƒ«: Qwen/Qwen3-14B\n\n\n\t\n\t\t\n\t\tãƒˆãƒ¼ã‚¯ãƒ³æ•°çµ±è¨ˆ\n\t\n\n\næœ€å°ãƒˆãƒ¼ã‚¯ãƒ³æ•°: 313\næœ€å¤§ãƒˆãƒ¼ã‚¯ãƒ³æ•°: 3066\nå¹³å‡ãƒˆãƒ¼ã‚¯ãƒ³æ•°: 887.4\n\n\n\t\n\t\t\n\t\tãƒˆãƒ¼ã‚¯ãƒ³æ•°åˆ†å¸ƒ\n\t\n\n\n0-100ãƒˆãƒ¼ã‚¯ãƒ³: 0ä»¶ (0.0%)\n101-500ãƒˆãƒ¼ã‚¯ãƒ³: 26ä»¶ (16.7%)\n501-1000ãƒˆãƒ¼ã‚¯ãƒ³: 85ä»¶ (54.5%)\n1001-2000ãƒˆãƒ¼ã‚¯ãƒ³: 39ä»¶ (25.0%)\n2001-5000ãƒˆãƒ¼ã‚¯ãƒ³: 6ä»¶ (3.8%)\n5001+ãƒˆãƒ¼ã‚¯ãƒ³: 0ä»¶ (0.0%)\n\n\n\t\n\t\t\n\t\tãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆæ§‹é€ \n\t\n\n\nsystem_prompt: ãƒ¢ãƒ‡ãƒ«ã«é€ä¿¡ã•ã‚ŒãŸã‚·ã‚¹ãƒ†ãƒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ\nquestion_text: å…ƒã®å•é¡Œæ–‡\nanswer_text: å•é¡Œã®è§£ç­”â€¦ See the full description on the dataset page: https://huggingface.co/datasets/llm-compe-2025-kato/step2-DeepMath-103K-Bespoke-Filtered-Test-200-eval-Qwen3-14B.","url":"https://huggingface.co/datasets/llm-compe-2025-kato/step2-DeepMath-103K-Bespoke-Filtered-Test-200-eval-Qwen3-14B","creator_name":"llm-compe-2025-kato","creator_url":"https://huggingface.co/llm-compe-2025-kato","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-generation","Japanese","English","mit","< 1K"],"keywords_longer_than_N":true},
	{"name":"NuminaMath-1.5-RL-Verifiable","keyword":"reasoning","description":"\n\t\n\t\t\n\t\tDataset Card for NuminaMath-1.5-RL-Verifiable\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nNuminaMath-1.5-RL-Verifiable is a curated subset of the NuminaMath-1.5 dataset, specifically filtered to support reinforcement learning applications requiring verifiable outcomes. This collection consists of 131,063 math word problems from the original dataset that meet strict filtering criteria: all problems have definitive numerical answers, validated problem statements and solutions, and come fromâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/nlile/NuminaMath-1.5-RL-Verifiable.","url":"https://huggingface.co/datasets/nlile/NuminaMath-1.5-RL-Verifiable","creator_name":"nathan lile","creator_url":"https://huggingface.co/nlile","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","question-answering","English","apache-2.0","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"Science-QnA","keyword":"reasoning","description":"\n\t\n\t\t\n\t\t169Pi-Science-QnA\n\t\n\nThe 169Pi-Science-QnA is a large-scale, high-quality science-focused dataset (~5.63M rows) curated using synthetic data generation through distillation techniques and select open-source resources. Designed to train and evaluate reasoning-capable models in science domains with emphasis on conceptual understanding, numerical problem-solving, and exam-style Q&A patterns across Physics, Chemistry, Biology, and Mathematics.\n\n\t\n\t\t\n\t\n\t\n\t\tSummary\n\t\n\nâ€¢ Domain: Scienceâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/169Pi/Science-QnA.","url":"https://huggingface.co/datasets/169Pi/Science-QnA","creator_name":"169Pi","creator_url":"https://huggingface.co/169Pi","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","question-answering","English","apache-2.0","1M - 10M"],"keywords_longer_than_N":true},
	{"name":"step2-DeepMath-103K-Bespoke-Filtered-Test-200-eval-cp40","keyword":"reasoning","description":"\n\t\n\t\t\n\t\tChain of Thoughtç”Ÿæˆãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ\n\t\n\nã“ã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã¯ã€å•é¡Œã¨è§£ç­”ã‹ã‚‰èª¬æ˜ï¼ˆChain of Thoughtï¼‰ã‚’ç”Ÿæˆã—ãŸãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã§ã™ã€‚\n\n\t\n\t\t\n\t\tæ¦‚è¦\n\t\n\n\nå‡¦ç†ã—ãŸã‚µãƒ³ãƒ—ãƒ«æ•°: 58\næœ‰åŠ¹ãªèª¬æ˜ç”Ÿæˆæ•°: 58\nç”ŸæˆæˆåŠŸç‡: 100.00%\nä½¿ç”¨ãƒ¢ãƒ‡ãƒ«: /home/Competition2025/P07/shareP07/share_model/step2_rlt/Qwen3-14B-step2-deepmath103k-bs512/checkpoint-40\n\n\n\t\n\t\t\n\t\tãƒˆãƒ¼ã‚¯ãƒ³æ•°çµ±è¨ˆ\n\t\n\n\næœ€å°ãƒˆãƒ¼ã‚¯ãƒ³æ•°: 830\næœ€å¤§ãƒˆãƒ¼ã‚¯ãƒ³æ•°: 6301\nå¹³å‡ãƒˆãƒ¼ã‚¯ãƒ³æ•°: 3477.9\n\n\n\t\n\t\t\n\t\tãƒˆãƒ¼ã‚¯ãƒ³æ•°åˆ†å¸ƒ\n\t\n\n\n0-100ãƒˆãƒ¼ã‚¯ãƒ³: 0ä»¶ (0.0%)\n101-500ãƒˆãƒ¼ã‚¯ãƒ³: 0ä»¶ (0.0%)\n501-1000ãƒˆãƒ¼ã‚¯ãƒ³: 1ä»¶ (1.7%)\n1001-2000ãƒˆãƒ¼ã‚¯ãƒ³: 9ä»¶ (15.5%)\n2001-5000ãƒˆãƒ¼ã‚¯ãƒ³: 39ä»¶ (67.2%)\n5001+ãƒˆãƒ¼ã‚¯ãƒ³: 9ä»¶ (15.5%)â€¦ See the full description on the dataset page: https://huggingface.co/datasets/llm-compe-2025-kato/step2-DeepMath-103K-Bespoke-Filtered-Test-200-eval-cp40.","url":"https://huggingface.co/datasets/llm-compe-2025-kato/step2-DeepMath-103K-Bespoke-Filtered-Test-200-eval-cp40","creator_name":"llm-compe-2025-kato","creator_url":"https://huggingface.co/llm-compe-2025-kato","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-generation","Japanese","English","mit","< 1K"],"keywords_longer_than_N":true},
	{"name":"gsm8k-base-vs-verl-comparison","keyword":"reasoning","description":"\n\t\n\t\t\n\t\tGSM8K: BASE vs VERL-trained Model Comparison Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset provides a comprehensive comparison between a base language model and its VERL (Reinforcement Learning from Human Feedback) fine-tuned version on mathematical reasoning tasks from GSM8K.\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\n\nTotal Samples: 50 GSM8K test problems\nBASE Model: Qwen/Qwen2.5-0.5B-Instruct (22.0% accuracy)  \nVERL Model: karthik/verl-qwen2.5-0.5b-gsm8k-ppo-step360 (28.0% accuracy)\nImprovement: +6.0â€¦ See the full description on the dataset page: https://huggingface.co/datasets/karthik/gsm8k-base-vs-verl-comparison.","url":"https://huggingface.co/datasets/karthik/gsm8k-base-vs-verl-comparison","creator_name":"karthik","creator_url":"https://huggingface.co/karthik","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-generation","question-answering","English","mit","< 1K"],"keywords_longer_than_N":true},
	{"name":"Mixture-of-Thoughts-2048T","keyword":"reasoning","description":"\n\t\n\t\t\n\t\tMixture-of-Thoughts-2048T\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nMixture-of-Thoughts-2048T is a curated subset of the open-r1/Mixture-of-Thoughts dataset, specifically filtered to include only examples that are approximately 2048 tokens or fewer in length. This dataset is designed for training and evaluating language models on reasoning tasks with constrained context lengths.\n\n\t\n\t\t\n\t\tFiltering Criteria\n\t\n\n\nToken Limit: Examples are filtered to contain â‰¤ 2048 tokens\n\n\n\t\n\t\t\n\t\tUsage\n\t\n\nfromâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/FlameF0X/Mixture-of-Thoughts-2048T.","url":"https://huggingface.co/datasets/FlameF0X/Mixture-of-Thoughts-2048T","creator_name":"Daniel Fox","creator_url":"https://huggingface.co/FlameF0X","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","English","apache-2.0","100K - 1M","json"],"keywords_longer_than_N":true},
	{"name":"MuSR","keyword":"reasoning","description":"\n\t\n\t\t\n\t\tMuSR: Testing the Limits of Chain-of-thought with Multistep Soft Reasoning\n\t\n\n\n\t\n\t\t\n\t\tCreating murder mysteries that require multi-step reasoning with commonsense using ChatGPT!\n\t\n\nBy: Zayne Sprague, Xi Ye, Kaj Bostrom, Swarat Chaudhuri, and Greg Durrett.\nView the dataset on our custom viewer and project website!\nCheck out the paper. Appeared at ICLR 2024 as a spotlight presentation!\nGit Repo with the source data, how to recreate the dataset (and create new ones!) here\n","url":"https://huggingface.co/datasets/TAUR-Lab/MuSR","creator_name":"TAUR Lab at UT Austin","creator_url":"https://huggingface.co/TAUR-Lab","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["question-answering","English","cc-by-4.0","< 1K","csv"],"keywords_longer_than_N":true},
	{"name":"indic_reasoning","keyword":"reasoning","description":"\n\t\n\t\t\n\t\tIndic Reasoning\n\t\n\nThe Indic Reasoning Dataset (~500M tokens, 592k examples) is a high-quality, large-scale open-source resource created using advanced distillation techniques. It is designed to train and evaluate reasoning-capable AI systems with a strong emphasis on complex reasoning, structured chain-of-thought (CoT), and culturally relevant content.\nThis domain-rich corpus integrates Indian cultural, legal, historical, philosophical, and social contexts with global knowledgeâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/169Pi/indic_reasoning.","url":"https://huggingface.co/datasets/169Pi/indic_reasoning","creator_name":"169Pi","creator_url":"https://huggingface.co/169Pi","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","question-answering","text-classification","English","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"wmdp_bio_preprocess","keyword":"reasoning","description":"\n\t\n\t\t\n\t\tWMDP-Bio Preprocessed Dataset\n\t\n\nThis dataset is a preprocessed version of wmdp-bio.\nThe data has been formatted into a question and answer structure suitable for training or evaluating instruction-following language models.\n\n\t\n\t\t\n\t\tData Structure\n\t\n\n\nquestion: The original question text.\nanswer: The correct answer text, prefixed with ####.\n\n\n\t\n\t\t\n\t\tExample\n\t\n\nQuestion:\n[Example Question Text]\n\nAnswer:\n#### [Example Answer Text]\n\n\n\t\n\t\t\n\t\tSplits\n\t\n\nThe original test split is preserved.â€¦ See the full description on the dataset page: https://huggingface.co/datasets/LLMcompe-Team-Watanabe/wmdp_bio_preprocess.","url":"https://huggingface.co/datasets/LLMcompe-Team-Watanabe/wmdp_bio_preprocess","creator_name":"LLMcompe Team Watanabe","creator_url":"https://huggingface.co/LLMcompe-Team-Watanabe","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["question-answering","expert-generated","found","monolingual","English"],"keywords_longer_than_N":true},
	{"name":"Multilingual-Benchmark","keyword":"reasoning","description":"These are the GSM8K and ARC dataset translated by Google Translate. \nBibTex\n@misc{lu2024languagecountslearnunlearn,\n      title={Every Language Counts: Learn and Unlearn in Multilingual LLMs}, \n      author={Taiming Lu and Philipp Koehn},\n      year={2024},\n      eprint={2406.13748},\n      archivePrefix={arXiv},\n      primaryClass={cs.CL},\n      url={https://arxiv.org/abs/2406.13748}, \n}\n\n","url":"https://huggingface.co/datasets/TaiMingLu/Multilingual-Benchmark","creator_name":"TaiMing","creator_url":"https://huggingface.co/TaiMingLu","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["zero-shot-classification","question-answering","translation","English","German"],"keywords_longer_than_N":true},
	{"name":"claude_4_math_evaluation_500","keyword":"mathematical-reasoning","description":"\n\t\n\t\t\n\t\tClaude 4 Mathematical Evaluation Dataset\n\t\n\n\n\t\n\t\t\n\t\tğŸ¯ Dataset Overview\n\t\n\nThis dataset contains 500 original mathematical evaluation problems specifically designed to test Claude 4 Sonnet's ability to assess mathematical answers as correct or incorrect. The problems were created from a single prototype and expanded to ensure the model had never encountered them during training, eliminating memorization bias.\n\n\t\n\t\t\n\t\tWhy This Dataset Matters\n\t\n\n\nExposes a critical flaw in LLMâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Naholav/claude_4_math_evaluation_500.","url":"https://huggingface.co/datasets/Naholav/claude_4_math_evaluation_500","creator_name":"Arda MÃ¼layim","creator_url":"https://huggingface.co/Naholav","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","question-answering","English","cc-by-4.0","n<1K"],"keywords_longer_than_N":true},
	{"name":"Kuvera-PersonalFinance-V2.1","keyword":"reasoning","description":"\n\t\n\t\t\n\t\tPersonal Finance Reasoning-V2.1\n\t\n\nThis dataset is associated with the paper Synthesizing Behaviorally-Grounded Reasoning Chains: A Data-Generation Framework for Personal Finance LLMs.\nThis is a scaled up version of the PersonalFinance-V2 dataset with some pipeline streamlining done.*\n\n\t\n\t\t\n\t\n\t\n\t\t1. Introduction & Motivation\n\t\n\nThe landscape of financial AI benchmarks is currently dominated by applications in corporate finance, algorithmic trading, and general financial knowledgeâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Akhil-Theerthala/Kuvera-PersonalFinance-V2.1.","url":"https://huggingface.co/datasets/Akhil-Theerthala/Kuvera-PersonalFinance-V2.1","creator_name":"Akhil Theerthala","creator_url":"https://huggingface.co/Akhil-Theerthala","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","text-generation","English","apache-2.0","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"math_problem_traces_test","keyword":"step-by-step","description":"A dataset containing mathematical problem-solving traces with step-by-step solutions and improvement history. Each record includes a mathematical problem, its final solution, and the iterative improvement process.","url":"https://huggingface.co/datasets/Wendong-Fan/math_problem_traces_test","creator_name":"Wendong.Fan","creator_url":"https://huggingface.co/Wendong-Fan","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-generation","English","mit","< 1K","json"],"keywords_longer_than_N":true},
	{"name":"pisc-tr","keyword":"reasoning","description":"\n\t\n\t\t\n\t\tDataset Card for CoT\n\t\n\n\n\t\n\t\t\n\t\tDataset Sources\n\t\n\n\nRepository: LLaVA-CoT GitHub Repository\nPaper: LLaVA-CoT on arXiv\n\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\ncat image.zip.part-* > image.zip #not uploaded yet\nunzip image.zip\n\nThe train.jsonl file contains the question-answering data and is structured in the following format:\n{\n  \"id\": \"example_id\",\n  \"image\": \"example_image_path\",\n  \"conversations\": [\n    {\"from\": \"human\", \"value\": \"LÃ¼tfen resimdeki kÄ±rmÄ±zÄ± metal nesnelerin sayÄ±sÄ±nÄ± belirtin.\"}â€¦ See the full description on the dataset page: https://huggingface.co/datasets/berhaan/pisc-tr.","url":"https://huggingface.co/datasets/berhaan/pisc-tr","creator_name":"Berhan TÃ¼rkÃ¼ Ay","creator_url":"https://huggingface.co/berhaan","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["visual-question-answering","English","Turkish","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"ToolVQA","keyword":"reasoning","description":"\n\t\n\t\t\n\t\tToolVQA: A Dataset for Real-World VQA with External Tools (ICCV 2025)\n\t\n\n\n    \n    \n\n\nAuthors: Shaofeng Yin, Ting Lei, Yang Liu\n\n\t\n\t\t\n\t\n\t\n\t\t1. Introduction ğŸ“£\n\t\n\n\nIntegrating external tools into Large Foundation Models (LFMs) has emerged as a promising approach to enhance their problem-solving capabilities. While existing studies have demonstrated strong performance in tool-augmented Visual Question Answering (VQA), recent benchmarks reveal significant gaps in real-world tool-useâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/DietCoke4671/ToolVQA.","url":"https://huggingface.co/datasets/DietCoke4671/ToolVQA","creator_name":"Shaofeng Yin","creator_url":"https://huggingface.co/DietCoke4671","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["apache-2.0","Image","arxiv:2508.03284","ğŸ‡ºğŸ‡¸ Region: US","VQA"],"keywords_longer_than_N":true},
	{"name":"gpt-oss-distilled-redteam2k","keyword":"reasoning","description":"\n\t\n\t\t\n\t\tGPT-OSS Distilled RedTeam-2K Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nâš ï¸ Content Warning: This dataset contains potentially harmful or policy-violating prompts (e.g., animal abuse, violence, privacy violations). The content includes sensitive safety-related queries and should be used responsibly for research purposes only.\nThis dataset contains safety knowledge distilled from GPT-OSS-20B and GPT-OSS-120B models using high reasoning effort (MXFP4 quantized). It was created by processingâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Ericwang/gpt-oss-distilled-redteam2k.","url":"https://huggingface.co/datasets/Ericwang/gpt-oss-distilled-redteam2k","creator_name":"Zhiyong Wang","creator_url":"https://huggingface.co/Ericwang","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-generation","question-answering","English","mit","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"MathBode","keyword":"reasoning","description":"\n\t\n\t\t\n\t\tMathBode: A Dynamic Benchmark for Mathematical Reasoning\n\t\n\n\n\nMathBode is a benchmark designed to evaluate the dynamic reasoning capabilities of large language models (LLMs) by treating parametric math problems as dynamic systems. Instead of testing static accuracy on fixed problems, MathBode treats parametric math problems as dynamic systems. It sinusoidally varies a parameter and measures the model's response in terms of gain (amplitude tracking) and phase (reasoning lag), analogousâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/cognitive-metrology-lab/MathBode.","url":"https://huggingface.co/datasets/cognitive-metrology-lab/MathBode","creator_name":"Cognitive Metrology Lab","creator_url":"https://huggingface.co/cognitive-metrology-lab","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["apache-2.0","10K - 100K","parquet","Tabular","Text"],"keywords_longer_than_N":true},
	{"name":"tool-calls-single-reasoning","keyword":"reasoning","description":"interstellarninja/tool-calls-single-reasoning dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/interstellarninja/tool-calls-single-reasoning","creator_name":"interstellarninja","creator_url":"https://huggingface.co/interstellarninja","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["question-answering","apache-2.0","10K - 100K","parquet","Text"],"keywords_longer_than_N":true},
	{"name":"German-RAG-ORPO-Long-Context-Alpaca-HESSIAN-AI","keyword":"reasoning","description":"\n\t\n\t\t\n\t\tGerman-RAG-ORPO (Odds Ratio Preference Optimization) Long-Context Alpaca-Format\n\t\n\n\n\t\n\t\t\n\t\tGerman-RAG - German Retrieval Augmented Generation\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThe ORPO Long Context Tasks Dataset represents a specialized collection for fine-tuning language models with a focus on RAG-specific capabilities. \nThe subsets are derived from Synthetic generation inspired by Tencent's (â€œScaling Synthetic Data Creation with 1,000,000,000 Personasâ€).\n\n\t\n\t\t\n\t\tDataset Structureâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/avemio/German-RAG-ORPO-Long-Context-Alpaca-HESSIAN-AI.","url":"https://huggingface.co/datasets/avemio/German-RAG-ORPO-Long-Context-Alpaca-HESSIAN-AI","creator_name":"Avemio AG","creator_url":"https://huggingface.co/avemio","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["question-answering","summarization","German","English","mit"],"keywords_longer_than_N":true},
	{"name":"step_sft","keyword":"reasoning","description":"Mix:\n\n\t\n\t\t\næ•°æ®é›†åç§°\næ˜¯å¦æœ‰step\nå¯ç”¨äºPRMè®­ç»ƒ\næ ‡ç­¾å½¢å¼\nTitle\nå¤‡æ³¨\n\n\n\t\t\nGSM8K\nâœ…\nâŒ\nç­”æ¡ˆ\nTraining Verifiers to Solve Math Word Problems\n\n\n\nMATH\nâŒ\nâŒ\nç­”æ¡ˆ\nMeasuring Mathematical Problem Solving With the MATH Dataset\nNon-Step\n\n\nPRM800K\nâœ…\nâœ…\næ­£ç¡®ç±»åˆ«\nLet's Verify Step by Step\nprompt deduplication\n\n\nMath-Shepherd\nâœ…\nâœ…\næ­£ç¡®ç±»åˆ«\nMath-Shepherd: Verify and Reinforce LLMs Step-by-step without Human Annotations\nNot used\n\n\nProcessBench\nâœ…\nâœ…\né¦–ä¸ªé”™è¯¯æ­¥éª¤\nProcessBench: Identifying Process Errors in Mathematical Reasoning\nonly label -1\n\n\n\t\n\n","url":"https://huggingface.co/datasets/xiaodongguaAIGC/step_sft","creator_name":"xiaodongguaAIGC","creator_url":"https://huggingface.co/xiaodongguaAIGC","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-generation","text-classification","question-answering","English","mit"],"keywords_longer_than_N":true},
	{"name":"Celestia3-DeepSeek-R1-0528","keyword":"reasoning","description":"Click here to support our open-source dataset and model releases!\nCelestia3-DeepSeek-R1-0528 is a dataset focused on science, testing the limits of DeepSeek R1 0528's science-reasoning skills!\nThis dataset contains:\n\n90.9k synthetically generated science prompts, with all responses generated using DeepSeek R1 0528.\nPrimary subjects are physics, chemistry, biology, and computer science; secondary subjects include Earth science, astronomy, and information theory.\nAll prompts are synthetic, takenâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/sequelbox/Celestia3-DeepSeek-R1-0528.","url":"https://huggingface.co/datasets/sequelbox/Celestia3-DeepSeek-R1-0528","creator_name":"t.d.a.g.","creator_url":"https://huggingface.co/sequelbox","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","English","apache-2.0","10K - 100K","csv"],"keywords_longer_than_N":true},
	{"name":"Reflection-Dataset-v2","keyword":"reflection","description":"\n\t\n\t\t\n\t\tSecond version of a simple \"Reflection\" method dataset inspired by mattshumer\n\t\n\n\n\t\n\t\t\n\t\tThis is the prompt and response version. Find ShareGPT version here\n\t\n\nThis dataset was synthetically generated using Glaive AI. There have been structure improvements and added more rows.\n","url":"https://huggingface.co/datasets/mahiatlinux/Reflection-Dataset-v2","creator_name":"Maheswar KK","creator_url":"https://huggingface.co/mahiatlinux","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["English","mit","1K - 10K","json","Text"],"keywords_longer_than_N":true},
	{"name":"rushhour4x4-rl","keyword":"reasoning","description":"\n\t\n\t\t\n\t\tRush Hour 4x4 RL Evaluation Dataset\n\t\n\nThis dataset contains 3000 4x4 Rush Hour puzzles generated using reinforcement learning techniques for model evaluation.\n\n\t\n\t\t\n\t\tFormat\n\t\n\n\npuzzle_id: Unique identifier (puzzle151, puzzle1000, ...)\nprompt: Full formatted prompt as used in model inference\nsolution: Optimal solution with proper formatting\noptimal_moves: Number of moves in optimal solution\ndifficulty: Difficulty level based on puzzle complexity\n\n\n\t\n\t\t\n\t\tDifficulty Distributionâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/mustafaah/rushhour4x4-rl.","url":"https://huggingface.co/datasets/mustafaah/rushhour4x4-rl","creator_name":"Mustafa Anis Hussain","creator_url":"https://huggingface.co/mustafaah","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["question-answering","English","mit","1K - 10K","parquet"],"keywords_longer_than_N":true},
	{"name":"PHYBench_preprocess_OnlyQuestion","keyword":"reasoning","description":"\n\t\n\t\t\n\t\tPHYBench Preprocessed Dataset (Questions Only)\n\t\n\nThis dataset is a preprocessed version of Eureka-Lab/PHYBench, containing only the samples where the final answer was missing in the original data.\n\n\t\n\t\t\n\t\tData Structure\n\t\n\n\nquestion: The original physics problem statement (from the content column).\nanswer: An empty (null) field.\n\nThis dataset can be used for inference or for problems where only the question is required.\n\n\t\n\t\t\n\t\tHow to Use\n\t\n\nfrom datasets import load_dataset\n\nds =â€¦ See the full description on the dataset page: https://huggingface.co/datasets/daichira/PHYBench_preprocess_OnlyQuestion.","url":"https://huggingface.co/datasets/daichira/PHYBench_preprocess_OnlyQuestion","creator_name":"Tsuji Daichi","creator_url":"https://huggingface.co/daichira","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["question-answering","expert-generated","found","monolingual","English"],"keywords_longer_than_N":true},
	{"name":"upload-test","keyword":"step-by-step","description":"A dataset containing mathematical problem-solving traces with step-by-step solutions and improvement history. Each record includes a mathematical problem, its final solution, and the iterative improvement process.","url":"https://huggingface.co/datasets/koookiy/upload-test","creator_name":"yaoke","creator_url":"https://huggingface.co/koookiy","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-generation","English","mit","< 1K","json"],"keywords_longer_than_N":true},
	{"name":"step2-evaluated-dataset-Qwen3-14B-cp32","keyword":"reasoning","description":"\n\t\n\t\t\n\t\tComplete Evaluation Dataset (Rubric + LogP)\n\t\n\nThis dataset contains chain-of-thought explanations evaluated using both comprehensive rubric assessment and LogP evaluation.\n\n\t\n\t\t\n\t\tOverview\n\t\n\n\nSource Dataset: llm-compe-2025-kato/step2-evaluated-dataset-Qwen3-14B-cp32\nTotal Samples: 60\nSuccessfully Evaluated (Rubric): 53\nFailed Evaluations (Rubric): 7\nEvaluation Model: Qwen/Qwen3-32B\n\n\n\t\n\t\t\n\t\tRubric Evaluation Results\n\t\n\n\n\t\n\t\t\n\t\tAverage Rubric Scores (0-4 scale)\n\t\n\n\nlogical_coherence:â€¦ See the full description on the dataset page: https://huggingface.co/datasets/llm-compe-2025-kato/step2-evaluated-dataset-Qwen3-14B-cp32.","url":"https://huggingface.co/datasets/llm-compe-2025-kato/step2-evaluated-dataset-Qwen3-14B-cp32","creator_name":"llm-compe-2025-kato","creator_url":"https://huggingface.co/llm-compe-2025-kato","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-generation","English","mit","< 1K","parquet"],"keywords_longer_than_N":true},
	{"name":"step2-evaluated-dataset-Qwen3-14B-cp40","keyword":"reasoning","description":"\n\t\n\t\t\n\t\tComplete Evaluation Dataset (Rubric + LogP)\n\t\n\nThis dataset contains chain-of-thought explanations evaluated using both comprehensive rubric assessment and LogP evaluation.\n\n\t\n\t\t\n\t\tOverview\n\t\n\n\nSource Dataset: llm-compe-2025-kato/step2-evaluated-dataset-Qwen3-14B-cp40\nTotal Samples: 58\nSuccessfully Evaluated (Rubric): 53\nFailed Evaluations (Rubric): 5\nEvaluation Model: Qwen/Qwen3-32B\n\n\n\t\n\t\t\n\t\tRubric Evaluation Results\n\t\n\n\n\t\n\t\t\n\t\tAverage Rubric Scores (0-4 scale)\n\t\n\n\nlogical_coherence:â€¦ See the full description on the dataset page: https://huggingface.co/datasets/llm-compe-2025-kato/step2-evaluated-dataset-Qwen3-14B-cp40.","url":"https://huggingface.co/datasets/llm-compe-2025-kato/step2-evaluated-dataset-Qwen3-14B-cp40","creator_name":"llm-compe-2025-kato","creator_url":"https://huggingface.co/llm-compe-2025-kato","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-generation","English","mit","< 1K","parquet"],"keywords_longer_than_N":true},
	{"name":"MiCoTA","keyword":"reasoning","description":"PersonalAILab/MiCoTA dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/PersonalAILab/MiCoTA","creator_name":"OPPO-Personal-AI-Lab","creator_url":"https://huggingface.co/PersonalAILab","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["question-answering","English","apache-2.0","10K - 100K","json"],"keywords_longer_than_N":true},
	{"name":"clean_openthought312_difficulty_9_filterd","keyword":"reasoning","description":"å…ƒãƒ‡ãƒ¼ã‚¿: https://huggingface.co/datasets/open-thoughts/OpenThoughts3-1.2M\ndiffculty 9ã§ã•ã‚‰ã«ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ã—ãŸã‚‚ã®\nãƒ‡ãƒ¼ã‚¿ä»¶æ•°: 14,339\nå¹³å‡ãƒˆãƒ¼ã‚¯ãƒ³æ•°: 13370\næœ€å¤§ãƒˆãƒ¼ã‚¯ãƒ³æ•°: 16,808\nåˆè¨ˆãƒˆãƒ¼ã‚¯ãƒ³æ•°: 191,708,678\nãƒ•ã‚¡ã‚¤ãƒ«å½¢å¼: JSONL\nãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚º: 723.9 MB\n","url":"https://huggingface.co/datasets/LLMTeamAkiyama/clean_openthought312_difficulty_9_filterd","creator_name":"LLMTeamAkiyama","creator_url":"https://huggingface.co/LLMTeamAkiyama","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["question-answering","English","apache-2.0","10K - 100K","json"],"keywords_longer_than_N":true},
	{"name":"cleand_HangHor_FinQA_CoT_Small","keyword":"reasoning","description":"å…ƒãƒ‡ãƒ¼ã‚¿: https://huggingface.co/datasets/HangHor/FinQA_CoT_Small\nä½¿ç”¨ã—ãŸã‚³ãƒ¼ãƒ‰: https://github.com/LLMTeamAkiyama/0-data_prepare/tree/master/src/FinQA_CoT_Small\n\nãƒ‡ãƒ¼ã‚¿ä»¶æ•°: 309\nå¹³å‡ãƒˆãƒ¼ã‚¯ãƒ³æ•°: 1,036\næœ€å¤§ãƒˆãƒ¼ã‚¯ãƒ³æ•°: 2,787\nåˆè¨ˆãƒˆãƒ¼ã‚¯ãƒ³æ•°: 320,198\nãƒ•ã‚¡ã‚¤ãƒ«å½¢å¼: JSONL\nãƒ•ã‚¡ã‚¤ãƒ«åˆ†å‰²æ•°: 1\nåˆè¨ˆãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚º: 1.3 MB\n\nåŠ å·¥å†…å®¹ï¼š\n\n\t\n\t\t\n\t\n\t\n\t\t1. ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®æº–å‚™ã¨åˆæœŸè¨­å®š\n\t\n\n\nãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹: Hugging Face Hubä¸Šã® HangHor/FinQA_CoT_Small ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’èª­ã¿è¾¼ã‚“ã§ã„ã¾ã™ã€‚\nãƒˆãƒ¼ã‚¯ãƒŠã‚¤ã‚¶ãƒ¼: ãƒˆãƒ¼ã‚¯ãƒ³æ•°ã®è¨ˆç®—ã«ã¯ deepseek-ai/DeepSeek-R1-Distill-Qwen-32B ãƒ¢ãƒ‡ãƒ«ã®ãƒˆãƒ¼ã‚¯ãƒŠã‚¤ã‚¶ãƒ¼ãŒä½¿ç”¨ã•ã‚Œã¦ã„ã¾ã™ã€‚\nåˆ—ã®å½¹å‰²è¨­å®š: å…ƒã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã® Questionã€Contextã€Answerâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/LLMTeamAkiyama/cleand_HangHor_FinQA_CoT_Small.","url":"https://huggingface.co/datasets/LLMTeamAkiyama/cleand_HangHor_FinQA_CoT_Small","creator_name":"LLMTeamAkiyama","creator_url":"https://huggingface.co/LLMTeamAkiyama","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["question-answering","English","mit","< 1K","json"],"keywords_longer_than_N":true},
	{"name":"moe-unified-dataset-sota","keyword":"reasoning","description":"\n\t\n\t\t\n\t\tmoe-unified-dataset-sota\n\t\n\nA unified dataset for training Mixture of Experts (MoE) models, combining multiple high-quality sources.\n\n\t\n\t\t\n\t\tDataset Statistics\n\t\n\n\nTotal Examples: 2,186,763\nTrain Split: 2,077,424\nTest Split: 109,339\n\n\n\t\n\t\t\n\t\tSources\n\t\n\n\nNousResearch/Hermes-3-Dataset - General instruction following, math, coding (~950k examples)\nSalesforce/xlam-function-calling-60k - Function/tool calling (60k examples)\nMegaScience/TextbookReasoning - Academic Q&A (~650k examples)â€¦ See the full description on the dataset page: https://huggingface.co/datasets/Yxanul/moe-unified-dataset-sota.","url":"https://huggingface.co/datasets/Yxanul/moe-unified-dataset-sota","creator_name":"David Franco","creator_url":"https://huggingface.co/Yxanul","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","question-answering","English","apache-2.0","1M - 10M"],"keywords_longer_than_N":true},
	{"name":"Italian-Reasoning-Logic-2k","keyword":"reasoning","description":"Dddixyy/Italian-Reasoning-Logic-2k dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/Dddixyy/Italian-Reasoning-Logic-2k","creator_name":"Davide Brunori","creator_url":"https://huggingface.co/Dddixyy","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-generation","Italian","mit","1K - 10K","parquet"],"keywords_longer_than_N":true},
	{"name":"camel_loong_medicine","keyword":"step-by-step","description":"A dataset containing mathematical problem-solving traces with step-by-step solutions and improvement history. Each record includes a mathematical problem, its final solution, and the iterative improvement process.","url":"https://huggingface.co/datasets/zikaixiao1/camel_loong_medicine","creator_name":"zikaixiao","creator_url":"https://huggingface.co/zikaixiao1","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-generation","English","mit","< 1K","json"],"keywords_longer_than_N":true},
	{"name":"LongBench-v2","keyword":"reasoning","description":"\n\t\n\t\t\n\t\tLongBench v2: Towards Deeper Understanding and Reasoning on Realistic Long-context Multitasks\n\t\n\nğŸŒ Project Page: https://longbench2.github.io\nğŸ’» Github Repo: https://github.com/THUDM/LongBench\nğŸ“š Arxiv Paper: https://arxiv.org/abs/2412.15204\nLongBench v2 is designed to assess the ability of LLMs to handle long-context problems requiring deep understanding and reasoning across real-world multitasks. LongBench v2 has the following features: (1) Length: Context length ranging from 8k toâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/THUDM/LongBench-v2.","url":"https://huggingface.co/datasets/THUDM/LongBench-v2","creator_name":"Z.ai & THUKEG","creator_url":"https://huggingface.co/THUDM","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["multiple-choice","question-answering","text-classification","table-question-answering","English"],"keywords_longer_than_N":true},
	{"name":"OpenThoughts3-1.2M","keyword":"reasoning","description":"\n    \n\n\n\npaper |\ndataset |\nmodel\n\n\n\n[!NOTE]\nWe have released a paper for OpenThoughts! See our paper here.\n\n\n \n\n\n\n\n\t\n\t\n\t\n\t\tOpenThoughts3-1.2M\n\t\n\nOpen-source state-of-the-art reasoning dataset with 1.2M rows. ğŸš€\nOpenThoughts3-1.2M is the third iteration in our line of OpenThoughts datasets, building on our previous OpenThoughts-114k and OpenThoughts2-1M.\nThis time around, we scale even further and generate our dataset in a much more systematic way -- OpenThoughts3-1.2M is the result of aâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/open-thoughts/OpenThoughts3-1.2M.","url":"https://huggingface.co/datasets/open-thoughts/OpenThoughts3-1.2M","creator_name":"Open Thoughts","creator_url":"https://huggingface.co/open-thoughts","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","apache-2.0","1M - 10M","parquet","Text"],"keywords_longer_than_N":true},
	{"name":"smol-smoltalk-plus-reasoning-synthetic-data","keyword":"reasoning","description":"\n\t\n\t\t\n\t\tDataset Card for Smol-Smoltalk Plus Reasoning\n\t\n\n\nThis is a project to make a fork of HuggingFaceTB/smol-smoltalk which includes reasoning data generated using HuggingFaceTB/SmolLM2-1.7B-Instruct.\nThis is a work in progress. I ran a proof of concept on a small subset and will scale this up as I am able to.\nContributions to scale this up and complete this data are welcome, especially from those with access to more substantial GPU resources.\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Detailsâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/david-thrower/smol-smoltalk-plus-reasoning-synthetic-data.","url":"https://huggingface.co/datasets/david-thrower/smol-smoltalk-plus-reasoning-synthetic-data","creator_name":"David Thrower","creator_url":"https://huggingface.co/david-thrower","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text2text-generation","question-answering","summarization","English","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"hle-extract-qwen3235ba22b-20250815","keyword":"reasoning","description":"\n\t\n\t\t\n\t\tHLE Extract: Qwen3-235B-A22B Evaluation Results (2025-08-15)\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset contains the complete Human-Level Evaluation (HLE) benchmark with detailed evaluation results from the Qwen/Qwen3-235B-A22B model. It merges the original team-suzuki/hle-extract dataset with comprehensive model responses and human judgments.\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\n\nTotal Questions: 120 (complete HLE dataset)\nEvaluated Questions: 103 (85.8%)\nUnevaluated Questions: 17 (14.2%)â€¦ See the full description on the dataset page: https://huggingface.co/datasets/team-suzuki/hle-extract-qwen3235ba22b-20250815.","url":"https://huggingface.co/datasets/team-suzuki/hle-extract-qwen3235ba22b-20250815","creator_name":"Team Suzuki","creator_url":"https://huggingface.co/team-suzuki","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["question-answering","text-generation","English","mit","< 1K"],"keywords_longer_than_N":true},
	{"name":"LIMO_QFFT","keyword":"reasoning","description":"\n\t\n\t\t\n\t\tğŸ“˜ LIMOâ€“QFFT\n\t\n\nLIMOâ€“QFFT is a question-free variant of the original GAIR/LIMO dataset, tailored for use in QFFT (Question-Free Fine-Tuning) pipelines.\n\n\t\n\t\t\n\t\tğŸ” Description\n\t\n\nThis dataset removes the original input questions and system prompts from the LIMO dataset, and keeps only the long-form reasoning responses. The goal is to enable training large language models to learn from reasoning traces alone, without depending on task-specific questions.\nAll entries are converted intoâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/lwl-uestc/LIMO_QFFT.","url":"https://huggingface.co/datasets/lwl-uestc/LIMO_QFFT","creator_name":"Wanlong Liu","creator_url":"https://huggingface.co/lwl-uestc","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","apache-2.0","< 1K","json","Text"],"keywords_longer_than_N":true},
	{"name":"GAIR_LIMO_topics","keyword":"reasoning","description":"\n\t\n\t\t\n\t\tLIMO topics\n\t\n\nThe LIMO dataset augmented with topics, using Llama3.3-70B-Instruct with Hugging Face Inference Providers and this pipeline configuration.\n\n","url":"https://huggingface.co/datasets/dvilasuero/GAIR_LIMO_topics","creator_name":"Daniel Vila","creator_url":"https://huggingface.co/dvilasuero","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","text-generation","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"DAG-Reasoning-DeepSeek-R1-0528","keyword":"reasoning","description":"Click here to support our open-source dataset and model releases!\nDAG-Reasoning-DeepSeek-R1-0528 is a dataset focused on analysis and reasoning, creating directed acyclic graphs testing the limits of DeepSeek R1 0528's graph-reasoning skills!\nThis dataset contains:\n\n4.08k synthetically generated prompts to create directed acyclic graphs in response to user input, with all responses generated using DeepSeek R1 0528.\nAll responses contain a multi-step thinking process to perform effectiveâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/sequelbox/DAG-Reasoning-DeepSeek-R1-0528.","url":"https://huggingface.co/datasets/sequelbox/DAG-Reasoning-DeepSeek-R1-0528","creator_name":"t.d.a.g.","creator_url":"https://huggingface.co/sequelbox","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","feature-extraction","English","apache-2.0","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"Olympiads","keyword":"mathematical-reasoning","description":"\n\t\n\t\t\n\t\tNumina-Olympiads\n\t\n\nFiltered NuminaMath-CoT dataset containing only olympiads problems with valid answers.\n\n\t\n\t\t\n\t\tDataset Information\n\t\n\n\nSplit: train\nOriginal size: 137830\nFiltered size: 42607\nSource: olympiads\nAll examples contain valid boxed answers\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset is a filtered version of the NuminaMath-CoT dataset, containing only problems from olympiad sources that have valid boxed answers. Each example includes:\n\nA mathematical word problem\nAâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/artnoage/Olympiads.","url":"https://huggingface.co/datasets/artnoage/Olympiads","creator_name":"Vaios Laschos","creator_url":"https://huggingface.co/artnoage","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-generation","expert-generated","expert-generated","monolingual","AI-MO/NuminaMath-CoT"],"keywords_longer_than_N":true},
	{"name":"math_DeepMath-103K-3_preprocess","keyword":"reasoning","description":"\n\t\n\t\t\n\t\tDeepMath-103K Dataset\n\t\n\nzwhe99/DeepMath-103K ã‹ã‚‰question,answerã‚’æŠ½å‡ºã—ãŸãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã§ã™ã€‚åŒãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã¯è§£æ³•ãŒ3ã¤å«ã¾ã‚Œã¦ãŠã‚Šã€ã“ã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã¯è§£æ³•3ã«ãªã‚Šã¾ã™ã€‚\n","url":"https://huggingface.co/datasets/LLMcompe-Team-Watanabe/math_DeepMath-103K-3_preprocess","creator_name":"LLMcompe Team Watanabe","creator_url":"https://huggingface.co/LLMcompe-Team-Watanabe","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["question-answering","open-domain-qa","expert-generated","found","monolingual"],"keywords_longer_than_N":true},
	{"name":"yoruba-arithmetic-dataset","keyword":"reasoning","description":"#YORUBA ARITHMETIC REASONING DATASET\nThis dataset consists of arithmetic and numerical reasoning questions written entirely in YorÃ¹bÃ¡. It is part of a broader effort to create and curate natural language processing (NLP) datasets for under-resourced languages like YorÃ¹bÃ¡, with a focus on arithmetic, calendrical, and logical reasoning in natural language contexts.\n\n\t\n\t\t\n\t\tOverview\n\t\n\n\nLanguage: YorÃ¹bÃ¡\nSubset: Arithmetic reasoning\nNumber of examples: 70\nFormat: JSON\nTask: Arithmetic and numericâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fiyinoye/yoruba-arithmetic-dataset.","url":"https://huggingface.co/datasets/fiyinoye/yoruba-arithmetic-dataset","creator_name":"Oyesanmi Fiyin","creator_url":"https://huggingface.co/fiyinoye","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["question-answering","zero-shot-classification","Yoruba","cc-by-4.0","n<1K"],"keywords_longer_than_N":true},
	{"name":"dolphin-r1-french","keyword":"reasoning","description":"\n  \n  \n\n\n\n  \n    \n  \n  \n    \n  \n  \n    \n  \n    \n  \n    \n    \n  \n\n\n  \n    \n  \n\n\n\n\t\n\t\n\t\n\t\tDolphin R1 French ğŸ¬\n\t\n\n\nDolphin-R1 is an Apache-2.0 English dataset curated by Eric Hartford and Cognitive Computations\nDolphin-R1-french is a French subset of the original dataset.\n\n\n\t\n\t\t\n\t\tSponsors\n\t\n\nTheir and Wiro AI's appreciation for the generous sponsors of Dolphin R1 - Without whom this dataset could not exist.\n\nDria https://x.com/driaforall - Inference Sponsor (DeepSeek)\nChutesâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/WiroAI/dolphin-r1-french.","url":"https://huggingface.co/datasets/WiroAI/dolphin-r1-french","creator_name":"Wiro AI","creator_url":"https://huggingface.co/WiroAI","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["French","apache-2.0","100K - 1M","parquet","Text"],"keywords_longer_than_N":true},
	{"name":"PARARULE-Plus-Depth-5","keyword":"reasoning","description":"\n\t\n\t\t\n\t\tPARARULE-Plus-Depth-5\n\t\n\nThis is a branch which includes the dataset from PARARULE-Plus Depth=5. PARARULE Plus is a deep multi-step reasoning dataset over natural language. It can be seen as an improvement on the dataset of PARARULE (Peter Clark et al., 2020). Both PARARULE and PARARULE-Plus follow the closed-world assumption and negation as failure. The motivation is to generate deeper PARARULE training samples. We add more training samples for the case where the depth is greater thanâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/qbao775/PARARULE-Plus-Depth-5.","url":"https://huggingface.co/datasets/qbao775/PARARULE-Plus-Depth-5","creator_name":"annonymous_user","creator_url":"https://huggingface.co/qbao775","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","question-answering","English","mit","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"PARARULE-Plus-Depth-3","keyword":"reasoning","description":"\n\t\n\t\t\n\t\tPARARULE-Plus-Depth-3\n\t\n\nThis is a branch which includes the dataset from PARARULE-Plus Depth=3. PARARULE Plus is a deep multi-step reasoning dataset over natural language. It can be seen as an improvement on the dataset of PARARULE (Peter Clark et al., 2020). Both PARARULE and PARARULE-Plus follow the closed-world assumption and negation as failure. The motivation is to generate deeper PARARULE training samples. We add more training samples for the case where the depth is greater thanâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/qbao775/PARARULE-Plus-Depth-3.","url":"https://huggingface.co/datasets/qbao775/PARARULE-Plus-Depth-3","creator_name":"annonymous_user","creator_url":"https://huggingface.co/qbao775","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","question-answering","English","mit","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"Tachibana3-Part2-DeepSeek-V3.2","keyword":"reasoning","description":"Click here to support our open-source dataset and model releases!\nTachibana3-Part2-DeepSeek-V3.2 is a dataset focused on high-difficulty code production tasks, testing the limits of DeepSeek V3.2's code-reasoning skills!\nThis dataset contains 9.3k high-difficulty code-production prompts:\n\nQuestions prioritize real-world, challenging coding tasks across a variety of programming languages and topics.\nAreas of focus include back-end and front-end development, mobile, gamedev, cloud, QA, customâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/sequelbox/Tachibana3-Part2-DeepSeek-V3.2.","url":"https://huggingface.co/datasets/sequelbox/Tachibana3-Part2-DeepSeek-V3.2","creator_name":"t.d.a.g.","creator_url":"https://huggingface.co/sequelbox","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","English","apache-2.0","1K - 10K","csv"],"keywords_longer_than_N":true},
	{"name":"Hanabi_data","keyword":"reasoning","description":"\n\t\n\t\t\n\t\tHanabi LLM Data (mincon, DeductCon, Multiâ€‘Turn)\n\t\n\nThis dataset aggregates turnâ€‘level logs from multiple large language models (LLMs) playing the cooperative card game Hanabi under different prompt settings:\n\nmincon (minimal context) - with and without move ratings\nDeductCon (deductive context) - with and without move ratings\nMultiâ€‘Turn (true multiâ€‘turn logs with ratings)\n\nEach row corresponds to one turn. JSONL files are flat records and can be streamed with the datasets library.â€¦ See the full description on the dataset page: https://huggingface.co/datasets/Mahesh111000/Hanabi_data.","url":"https://huggingface.co/datasets/Mahesh111000/Hanabi_data","creator_name":"Mahesh Ramesh","creator_url":"https://huggingface.co/Mahesh111000","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-generation","other","mit","ğŸ‡ºğŸ‡¸ Region: US","hanabi"],"keywords_longer_than_N":true},
	{"name":"Tachibana3-Part1-DeepSeek-V3.1-Terminus","keyword":"reasoning","description":"Click here to support our open-source dataset and model releases!\nTachibana3-Part1-DeepSeek-V3.1-Terminus is a dataset focused on high-difficulty code production tasks, testing the limits of DeepSeek V3.1 Terminus's code-reasoning skills!\nThis dataset contains 9.3k high-difficulty code-production prompts:\n\nQuestions prioritize real-world, challenging coding tasks across a variety of programming languages and topics.\nAreas of focus include back-end and front-end development, mobile, gamedevâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/sequelbox/Tachibana3-Part1-DeepSeek-V3.1-Terminus.","url":"https://huggingface.co/datasets/sequelbox/Tachibana3-Part1-DeepSeek-V3.1-Terminus","creator_name":"t.d.a.g.","creator_url":"https://huggingface.co/sequelbox","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","English","apache-2.0","1K - 10K","csv"],"keywords_longer_than_N":true},
	{"name":"Titanium3-DeepSeek-V3.1-Terminus","keyword":"reasoning","description":"Click here to support our open-source dataset and model releases!\nTitanium3-DeepSeek-V3.1-Terminus is a dataset focused on architecture and DevOps, testing the limits of DeepSeek V3.1 Terminus's architect and coding skills!\nThis dataset contains:\n\n27.7k synthetically generated prompts focused on architecture, cloud, and DevOps. All responses are generated using DeepSeek V3.1 Terminus in reasoning mode:\n20k selected technical expertise prompts from sequelbox/Titanium2.1-DeepSeek-R1 focused onâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/sequelbox/Titanium3-DeepSeek-V3.1-Terminus.","url":"https://huggingface.co/datasets/sequelbox/Titanium3-DeepSeek-V3.1-Terminus","creator_name":"t.d.a.g.","creator_url":"https://huggingface.co/sequelbox","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","English","apache-2.0","10K - 100K","csv"],"keywords_longer_than_N":true},
	{"name":"PARARULE-Plus-Depth-5","keyword":"logical-reasoning","description":"\n\t\n\t\t\n\t\tPARARULE-Plus-Depth-5\n\t\n\nThis is a branch which includes the dataset from PARARULE-Plus Depth=5. PARARULE Plus is a deep multi-step reasoning dataset over natural language. It can be seen as an improvement on the dataset of PARARULE (Peter Clark et al., 2020). Both PARARULE and PARARULE-Plus follow the closed-world assumption and negation as failure. The motivation is to generate deeper PARARULE training samples. We add more training samples for the case where the depth is greater thanâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/qbao775/PARARULE-Plus-Depth-5.","url":"https://huggingface.co/datasets/qbao775/PARARULE-Plus-Depth-5","creator_name":"annonymous_user","creator_url":"https://huggingface.co/qbao775","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","question-answering","English","mit","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"PARARULE-Plus-Depth-3","keyword":"logical-reasoning","description":"\n\t\n\t\t\n\t\tPARARULE-Plus-Depth-3\n\t\n\nThis is a branch which includes the dataset from PARARULE-Plus Depth=3. PARARULE Plus is a deep multi-step reasoning dataset over natural language. It can be seen as an improvement on the dataset of PARARULE (Peter Clark et al., 2020). Both PARARULE and PARARULE-Plus follow the closed-world assumption and negation as failure. The motivation is to generate deeper PARARULE training samples. We add more training samples for the case where the depth is greater thanâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/qbao775/PARARULE-Plus-Depth-3.","url":"https://huggingface.co/datasets/qbao775/PARARULE-Plus-Depth-3","creator_name":"annonymous_user","creator_url":"https://huggingface.co/qbao775","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","question-answering","English","mit","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"General-Knowledge","keyword":"reasoning","description":"\n\t\n\t\t\n\t\tDataset Card for Dataset Name\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThe dataset is a collection of questions and answers themed on general facts and reasoning. The dataset is divided into two features - 'Question' and 'Answer'. \nIt is meant to be used for training a model to be good at general knowledge and reasoning. This dataset is inspired from the Alpaca dataset, and infact contains a subset of the alpaca dataset in itself.\n\n\t\n\t\t\n\t\tDistribution\n\t\n\n  The distribution of theâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/MuskumPillerum/General-Knowledge.","url":"https://huggingface.co/datasets/MuskumPillerum/General-Knowledge","creator_name":"EurekaBotics","creator_url":"https://huggingface.co/MuskumPillerum","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-generation","English","mit","10K - 100K","json"],"keywords_longer_than_N":true},
	{"name":"maths_bench","keyword":"reasoning","description":"\n\t\n\t\t\n\t\tMathsBench\n\t\n\nThis repository contains the dataset for conducting the Large Language Model (LLM) Mathematics Benchmark.\nIf you find this work relevant or helpful to your work, please kindly cite it:\n@misc{mathsbenchdataset,\n  title={MathsBench Dataset}, \n  author={Finbarrs Oketunji},\n  year={2025}\n}\n\n\n\t\n\t\t\n\t\tCopyright\n\t\n\n(c) Copyright 2025 Finbarrs Oketunji. All Rights Reserved.\n","url":"https://huggingface.co/datasets/0xnu/maths_bench","creator_name":"Finbarrs Oketunji","creator_url":"https://huggingface.co/0xnu","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["English","apache-2.0","1K - 10K","parquet","Text"],"keywords_longer_than_N":true},
	{"name":"ZharfaTech-Open-Platypus-Persian-Farsi","keyword":"reasoning","description":"\n\t\n\t\t\n\t\tPersian Open-Platypus\n\t\n\n\n\t\n\t\t\n\t\tAbout ZharfaTech\n\t\n\nZharfaTech is a pioneer in developing Language Learning Models (LLMs) tailored for the Persian language, aiming to empower over 100 million Persian speakers worldwide. Our mission encompasses bridging the digital divide in LLM-related services like content generation, customer relationship systems, and more, with a dual approach of fostering open-source collaboration and delivering high-value, specialized closed-source solutions.â€¦ See the full description on the dataset page: https://huggingface.co/datasets/ZharfaTech/ZharfaTech-Open-Platypus-Persian-Farsi.","url":"https://huggingface.co/datasets/ZharfaTech/ZharfaTech-Open-Platypus-Persian-Farsi","creator_name":"ZharfaTech","creator_url":"https://huggingface.co/ZharfaTech","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","summarization","question-answering","Persian","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"GenRef-wds","keyword":"reflection","description":"\n\t\n\t\t\n\t\tGenRef-1M\n\t\n\n\n  \n\n\nWe provide 1M high-quality triplets of the form (flawed image, high-quality image, reflection) collected across\nmultiple domains using our scalable pipeline from [1]. We used this dataset to train our reflection tuning model.\nTo know the details of the dataset creation pipeline, please refer to Section 3.2 of [1].\nProject Page: https://diffusion-cot.github.io/reflection2perfection\n\n\t\n\t\t\n\t\n\t\n\t\tDataset loading\n\t\n\nWe provide the dataset in the webdataset format for fastâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/diffusion-cot/GenRef-wds.","url":"https://huggingface.co/datasets/diffusion-cot/GenRef-wds","creator_name":"Diffusion CoT","creator_url":"https://huggingface.co/diffusion-cot","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-to-image","English","mit","1M - 10M","webdataset"],"keywords_longer_than_N":true},
	{"name":"stratified-kmeans-diverse-reasoning-100K-1M","keyword":"reasoning","description":"\n\t\n\t\t\n\t\tStratified K-Means Diverse Reasoning Dataset (100K-1M)\n\t\n\nA carefully balanced subset of NVIDIA's Llama-Nemotron Post-Training Dataset, featuring square-root rebalanced sampling across math, code, science, instruction-following, chat, and safety tasks at multiple scales.\n\n\n\n\n\n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tğŸ‘¥ Follow the Authors\n\t\n\nAman Priyanshu\n\n\nSupriti Vijay\n\n\n\n\n\n\n\t\t\n\t\n\t\tOverview\n\t\n\nThis dataset provides stratified subsets at 50k, 100k, 250k, 500k, and 1M scales from the Llama-Nemotronâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/AmanPriyanshu/stratified-kmeans-diverse-reasoning-100K-1M.","url":"https://huggingface.co/datasets/AmanPriyanshu/stratified-kmeans-diverse-reasoning-100K-1M","creator_name":"Aman Priyanshu","creator_url":"https://huggingface.co/AmanPriyanshu","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","cc-by-4.0","1M - 10M","parquet","Text"],"keywords_longer_than_N":true},
	{"name":"Roblox-Luau-Reasoning-v1.0","keyword":"reasoning","description":"\n\t\n\t\t\n\t\tRoblox-Luau-Reasoning-v1.0\n\t\n\nThis dataset contains prompt->chain of thought+code+explanation for Luau, based on Roblox/luau-corpus.\nWe take real Luau code from the corpus (cleaned & auto-formatted for best quality) and work backwards to generate a prompt for it. Then, we generate a chain of thought that works from that prompt to reach the code. Finally, we generate an explanation of the code.\nThis means that we'll be able to fine tune reasoning models (like Deepseek R1) on the datasetâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/TorpedoSoftware/Roblox-Luau-Reasoning-v1.0.","url":"https://huggingface.co/datasets/TorpedoSoftware/Roblox-Luau-Reasoning-v1.0","creator_name":"Torpedo Software","creator_url":"https://huggingface.co/TorpedoSoftware","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["English","mit","10K - 100K","parquet","Text"],"keywords_longer_than_N":true},
	{"name":"lumos_unified_plan_iterative","keyword":"reasoning","description":"\n\t\n\t\t\n\t\tğŸª„ Agent Lumos: Unified and Modular Training for Open-Source Language Agents\n\t\n\n\n  ğŸŒ[Website] Â \n  ğŸ“[Paper] Â \n  ğŸ¤—[Data] Â \n  ğŸ¤—[Model] Â \n  ğŸ¤—[Demo] Â \n\n\nWe introduce ğŸª„Lumos, Language Agents with Unified Formats, Modular Design, and Open-Source LLMs. Lumos unifies a suite of complex interactive tasks and achieves competitive performance with GPT-4/3.5-based and larger open-source agents. \nLumos has following features:\n\nğŸ§© Modular Architecture:\nğŸ§© Lumos consists of planning, groundingâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/ai2lumos/lumos_unified_plan_iterative.","url":"https://huggingface.co/datasets/ai2lumos/lumos_unified_plan_iterative","creator_name":"Lumos  Agents (AI2)","creator_url":"https://huggingface.co/ai2lumos","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","question-answering","English","apache-2.0","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"mindgames","keyword":"reasoning","description":"Mindgame dataset\nCode:\nhttps://github.com/sileod/llm-theory-of-mind\nArticle (Accepted at EMNLP 2023 Findings):\nhttps://arxiv.org/abs/2305.03353\n@article{sileo2023mindgames,\n  title={MindGames: Targeting Theory of Mind in Large Language Models with Dynamic Epistemic Modal Logic},\n  author={Sileo, Damien and Lernould, Antoine},\n  journal={arXiv preprint arXiv:2305.03353},\n  year={2023}\n}\n\n","url":"https://huggingface.co/datasets/sileod/mindgames","creator_name":"Damien Sileo","creator_url":"https://huggingface.co/sileod","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","natural-language-inference","multi-input-text-classification","monolingual","English"],"keywords_longer_than_N":true},
	{"name":"mindgames","keyword":"logical-reasoning","description":"Mindgame dataset\nCode:\nhttps://github.com/sileod/llm-theory-of-mind\nArticle (Accepted at EMNLP 2023 Findings):\nhttps://arxiv.org/abs/2305.03353\n@article{sileo2023mindgames,\n  title={MindGames: Targeting Theory of Mind in Large Language Models with Dynamic Epistemic Modal Logic},\n  author={Sileo, Damien and Lernould, Antoine},\n  journal={arXiv preprint arXiv:2305.03353},\n  year={2023}\n}\n\n","url":"https://huggingface.co/datasets/sileod/mindgames","creator_name":"Damien Sileo","creator_url":"https://huggingface.co/sileod","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","natural-language-inference","multi-input-text-classification","monolingual","English"],"keywords_longer_than_N":true},
	{"name":"common_gen","keyword":"reasoning","description":"CommonGen is a constrained text generation task, associated with a benchmark\ndataset, to explicitly test machines for the ability of generative commonsense\nreasoning. Given a set of common concepts; the task is to generate a coherent\nsentence describing an everyday scenario using these concepts.","url":"https://huggingface.co/datasets/GEM/common_gen","creator_name":"GEM benchmark","creator_url":"https://huggingface.co/GEM","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["other","none","unknown","unknown","original"],"keywords_longer_than_N":true},
	{"name":"test-parquet","keyword":"reasoning","description":"Birchlabs/test-parquet dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/Birchlabs/test-parquet","creator_name":"Alex Birch","creator_url":"https://huggingface.co/Birchlabs","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["question-answering","expert-generated","English","mit","< 1K"],"keywords_longer_than_N":true},
	{"name":"reason_code-search-net-python","keyword":"reasoning","description":"\n\t\n\t\t\n\t\tDataset Card for \"reason_code-search-net-python\"\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset is an instructional dataset for Python.The dataset contains five different kind of tasks.   \nGiven a Python 3 function:\n\nType 1: Generate a summary explaining what it does. (For example: This function counts the number of objects stored in the jsonl file passed as input.)\nType 2: Generate a summary explaining what its input parameters represent (\"For example: infile: a file descriptor of a fileâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Nan-Do/reason_code-search-net-python.","url":"https://huggingface.co/datasets/Nan-Do/reason_code-search-net-python","creator_name":"Fernando Tarin Morales","creator_url":"https://huggingface.co/Nan-Do","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["summarization","text-generation","English","apache-2.0","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"russian_super_glue","keyword":"reasoning","description":"Recent advances in the field of universal language models and transformers require the development of a methodology for\ntheir broad diagnostics and testing for general intellectual skills - detection of natural language inference,\ncommonsense reasoning, ability to perform simple logical operations regardless of text subject or lexicon. For the first\ntime, a benchmark of nine tasks, collected and organized analogically to the SuperGLUE methodology, was developed from\nscratch for the Russian language. We provide baselines, human level evaluation, an open-source framework for evaluating\nmodels and an overall leaderboard of transformer models for the Russian language.","url":"https://huggingface.co/datasets/RussianNLP/russian_super_glue","creator_name":"Natural Language Processing in Russian","creator_url":"https://huggingface.co/RussianNLP","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":null,"first_N":5,"first_N_keywords":["text-classification","question-answering","zero-shot-classification","text-generation","natural-language-inference"],"keywords_longer_than_N":true},
	{"name":"v-lol-trains","keyword":"reasoning","description":"\n\t\n\t\t\n\t\tDataset Card for Dataset Name\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis diagnostic dataset (website, paper) is specifically designed to evaluate the visual logical learning capabilities of machine learning models.\nIt offers a seamless integration of visual and logical challenges, providing 2D images of complex visual trains,\nwhere the classification is derived from rule-based logic.\nThe fundamental idea of V-LoL remains to integrate the explicit logical learning tasks of classic symbolic AIâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/AIML-TUDA/v-lol-trains.","url":"https://huggingface.co/datasets/AIML-TUDA/v-lol-trains","creator_name":"Artificial Intelligence & Machine Learning Lab at TU Darmstadt","creator_url":"https://huggingface.co/AIML-TUDA","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":null,"first_N":5,"first_N_keywords":["image-classification","English","cc-by-4.0","10K<n<100K","arxiv:2306.07743"],"keywords_longer_than_N":true},
	{"name":"ART","keyword":"reasoning","description":"the Abductive Natural Language Generation Dataset from AI2","url":"https://huggingface.co/datasets/GEM/ART","creator_name":"GEM benchmark","creator_url":"https://huggingface.co/GEM","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["other","automatically-created","unknown","unknown","original"],"keywords_longer_than_N":true},
	{"name":"reasoning_bg_oa","keyword":"reasoning","description":"\n\t\n\t\t\n\t\tDataset Card for Bulgarian QnA reasoning with ~2.7K entries.\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nContains Parquet of a list of instructions and answers.\nEach row consists of\n\nINSTRUCTION\nRESPONSE\nSOURCE (reasoning_bg)\nMETADATA (json with language, url, id).\n\n\n\t\n\t\t\n\t\tOriginal Dataset is available here:\n\t\n\n\nhttps://huggingface.co/datasets/reasoning_bg\n\n","url":"https://huggingface.co/datasets/0x22almostEvil/reasoning_bg_oa","creator_name":"David Glushkov","creator_url":"https://huggingface.co/0x22almostEvil","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["question-answering","Bulgarian","apache-2.0","1K - 10K","parquet"],"keywords_longer_than_N":true},
	{"name":"Data-Preview","keyword":"reasoning","description":"\n\t\n\t\t\n\t\tImportant!\n\t\n\nThis is a preview of SpaceVista, containing only a subset of tasks and scenes. As you can see, the data format is not yet unified, and the meta JSON keys remain inconsistent. Weâ€™ve provided a reasonable preview hereâ€”please stay tuned for the full, up-to-date release.\nBy the way, we would not recommand you to train your model with your own dataloader. The format of this dataset needs refine completely. As the final version may necessitate a complete redesign of yourâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/SpaceVista/Data-Preview.","url":"https://huggingface.co/datasets/SpaceVista/Data-Preview","creator_name":"SpaceVista","creator_url":"https://huggingface.co/SpaceVista","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":null,"first_N":5,"first_N_keywords":["question-answering","English","cc-by-4.0","1M<n<10M","Video"],"keywords_longer_than_N":true},
	{"name":"aime_2025","keyword":"reasoning","description":"\n\t\n\t\t\n\t\tAIME 2025 - Unified Test-Time Scaling Format\n\t\n\nThis is the AIME (American Invitational Mathematics Examination) 2025 dataset in a unified format for test-time scaling experiments.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nSource: MathArena/aime_2025\nSize: 30 competition-level mathematics problems\nFormat: Unified TTS format (question, answer, metadata)\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\n\t\n\t\t\n\t\tFields\n\t\n\n\nquestion (string): The mathematical problem statement\nanswer (string): The numerical answerâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/test-time-compute/aime_2025.","url":"https://huggingface.co/datasets/test-time-compute/aime_2025","creator_name":"Test time compute","creator_url":"https://huggingface.co/test-time-compute","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["question-answering","text-generation","English","mit","< 1K"],"keywords_longer_than_N":true},
	{"name":"riddle_sense","keyword":"reasoning","description":"riddle_sense dataset formatted into an alpaca format dataset for instruction tuning LLMs for reasoning capabilities.\n","url":"https://huggingface.co/datasets/Technoculture/riddle_sense","creator_name":"Technoculture","creator_url":"https://huggingface.co/Technoculture","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["question-answering","English","mit","1K - 10K","parquet"],"keywords_longer_than_N":true},
	{"name":"tau2-mms-teacher-traces","keyword":"reasoning","description":"\n\t\n\t\t\n\t\tTau2 Teacher Traces Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset contains teacher reasoning traces for solving MMS (Multimedia Messaging Service) issues in the Ï„Â²-bench (Tau2-bench) framework. Each example includes a teacher model's thinking process and structured teaching guidance for resolving customer service tickets.\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\n\nDomain: Telecom customer service\nTask: MMS troubleshooting\nSize: 49 examples\nFormat: JSONL\n\n\n\t\n\t\t\n\t\tDataset Structureâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Arc-Intelligence/tau2-mms-teacher-traces.","url":"https://huggingface.co/datasets/Arc-Intelligence/tau2-mms-teacher-traces","creator_name":"Arc Intelligence","creator_url":"https://huggingface.co/Arc-Intelligence","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","question-answering","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"tool-n1-sft-unique-train-eval","keyword":"reasoning","description":"\n\t\n\t\t\n\t\tTool-N1 SFT Unique Train-Eval Split\n\t\n\nThis dataset contains supervised fine-tuning (SFT) data for training models on multi-hop tool usage and reasoning, with proper train/evaluation splits and guaranteed unique queries.\n\n\t\n\t\t\n\t\tKey Features\n\t\n\nâœ… Perfect Alternating Format: <think>reasoning</think> <tool_call>tool_call</tool_call> patternâœ… Unique Queries: Complete deduplication based on query contentâœ… Train/Eval Split: Proper 80/20 split for training and evaluationâœ… Multi-hopâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Anna4242/tool-n1-sft-unique-train-eval.","url":"https://huggingface.co/datasets/Anna4242/tool-n1-sft-unique-train-eval","creator_name":"D","creator_url":"https://huggingface.co/Anna4242","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","question-answering","English","apache-2.0","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"json-schema-store-reasoning","keyword":"reasoning","description":"interstellarninja/json-schema-store-reasoning dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/interstellarninja/json-schema-store-reasoning","creator_name":"interstellarninja","creator_url":"https://huggingface.co/interstellarninja","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["question-answering","English","apache-2.0","1K - 10K","parquet"],"keywords_longer_than_N":true},
	{"name":"greek-bar-bench","keyword":"reasoning","description":"\n\t\n\t\t\n\t\tDataset Card for GreekBarBench   ğŸ‡¬ğŸ‡·ğŸ›ï¸âš–ï¸\n\t\n\n\n\nGreekBarBench is a benchmark designed to evaluate LLMs on challenging legal reasoning questions across five different legal areas from the Greek Bar exams, requiring citations to statutory articles and case facts.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\n\n\nGreekBarBench (GBB) comprises legal questions sourced from the Greek Bar exams held between 2015 and 2024. The dataset aims to simulate the open-book format of theseâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/AUEB-NLP/greek-bar-bench.","url":"https://huggingface.co/datasets/AUEB-NLP/greek-bar-bench","creator_name":"Athens University of Economics and Business - NLP Group","creator_url":"https://huggingface.co/AUEB-NLP","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["question-answering","text-generation","Greek","cc-by-4.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"error-detection-positives","keyword":"reasoning","description":"\n\t\n\t\t\n\t\terror-detection-positives\n\t\n\nThis dataset is part of the PARC (Premise-Annotated Reasoning Collection) and contains mathematical reasoning problems with error annotations. This dataset combines positives samples from multiple domains.\n\n\t\n\t\t\n\t\tDomain Breakdown\n\t\n\n\ngsm8k: 50 samples\nmath: 53 samples\nmetamathqa: 93 samples\norca_math: 96 samples\n\n\n\t\n\t\t\n\t\tFeatures\n\t\n\nEach example contains:\n\ndata_source: The domain/source of the problem (gsm8k, math, metamathqa, orca_math)\nquestion: Theâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/PARC-DATASETS/error-detection-positives.","url":"https://huggingface.co/datasets/PARC-DATASETS/error-detection-positives","creator_name":"PARC","creator_url":"https://huggingface.co/PARC-DATASETS","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-generation","question-answering","English","mit","< 1K"],"keywords_longer_than_N":true},
	{"name":"error-detection-positives","keyword":"step-by-step","description":"\n\t\n\t\t\n\t\terror-detection-positives\n\t\n\nThis dataset is part of the PARC (Premise-Annotated Reasoning Collection) and contains mathematical reasoning problems with error annotations. This dataset combines positives samples from multiple domains.\n\n\t\n\t\t\n\t\tDomain Breakdown\n\t\n\n\ngsm8k: 50 samples\nmath: 53 samples\nmetamathqa: 93 samples\norca_math: 96 samples\n\n\n\t\n\t\t\n\t\tFeatures\n\t\n\nEach example contains:\n\ndata_source: The domain/source of the problem (gsm8k, math, metamathqa, orca_math)\nquestion: Theâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/PARC-DATASETS/error-detection-positives.","url":"https://huggingface.co/datasets/PARC-DATASETS/error-detection-positives","creator_name":"PARC","creator_url":"https://huggingface.co/PARC-DATASETS","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-generation","question-answering","English","mit","< 1K"],"keywords_longer_than_N":true},
	{"name":"PyRe-v2","keyword":"reasoning","description":"\n\t\n\t\t\n\t\tPyRe 2\n\t\n\nThis data set is a mix of samples from a number of public data sets (sources indidcated in the actual data). The goal with this set was to create a smaller set focused on coding (primarily Python), math, and reasoning.\n","url":"https://huggingface.co/datasets/theprint/PyRe-v2","creator_name":"Rasmus Rasmussen","creator_url":"https://huggingface.co/theprint","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["English","apache-2.0","1K - 10K","json","Text"],"keywords_longer_than_N":true},
	{"name":"test","keyword":"reasoning","description":"\n\t\n\t\t\n\t\tDeepMath-103K\n\t\n\n\n  \n    \n      \n        \n      \n    \n    \n      \n        \n      \n    \n    \n      \n        \n      \n    \n  \n\n\n\n\t\n\t\n\t\n\t\tğŸ“– Overview\n\t\n\nDeepMath-103K is meticulously curated to push the boundaries of mathematical reasoning in language models. Key features include:1. Challenging Problems: DeepMath-103K has a strong focus on difficult mathematical problems (primarily Levels 5-9), significantly raising the complexity bar compared to many existing open datasets.\n \n\nDifficultyâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/swpdd/test.","url":"https://huggingface.co/datasets/swpdd/test","creator_name":"weipeng","creator_url":"https://huggingface.co/swpdd","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":null,"first_N":5,"first_N_keywords":["text-generation","English","mit","100K<n<1M","arxiv:2504.11456"],"keywords_longer_than_N":true},
	{"name":"T2I-CoReBench","keyword":"reasoning","description":"\n  \n\n\n\n\n  \n  Easier Painting Than Thinking: Can Text-to-Image Models \n  Set the Stage, but Not Direct the Play?\n  \n\n  \n    \n      \n    \n    \n      \n    \n    \n      \n    \n    \n      \n      \n    \n  \n\n  Ouxiang Li1*, Yuan Wang1, Xinting Huâ€ , Huijuan Huang2â€¡, Rui Chen2, Jiarong Ou2, \n  Xin Tao2â€ , Pengfei Wan2, Xiaojuan Qi1, Fuli Feng1\n  1University of Science and Technology of China, 2Kling Team, Kuaishou Technology, 3The University of Hong Kong\n  \n  *Work done during internship at Kling Teamâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/lioooox/T2I-CoReBench.","url":"https://huggingface.co/datasets/lioooox/T2I-CoReBench","creator_name":"Ouxiang Li","creator_url":"https://huggingface.co/lioooox","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-to-image","English","apache-2.0","1K - 10K","json"],"keywords_longer_than_N":true},
	{"name":"GPQA-diamond-ClaudeR1","keyword":"reasoning","description":"\n\t\n\t\t\n\t\tDataset Card for GPQA Diamond Reasoning Benchmark\n\t\n\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nA benchmark dataset for evaluating hybrid AI architectures, comparing reasoning-augmented LLMs (DeepSeek R1) against standalone models (Claude Sonnet 3.5). Contains 198 physics questions with:\n\nGround truth answers and explanations\nModel responses from multiple architectures\nGranular token usage and cost metrics\nDifficulty metadata and domain categorization\n\nCurated by: LLMâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/spawn99/GPQA-diamond-ClaudeR1.","url":"https://huggingface.co/datasets/spawn99/GPQA-diamond-ClaudeR1","creator_name":"Cavit Erginsoy","creator_url":"https://huggingface.co/spawn99","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["question-answering","English","mit","< 1K","parquet"],"keywords_longer_than_N":true},
	{"name":"PersonaEval","keyword":"reasoning","description":"\n\t\n\t\t\n\t\tPersonaEval: A Benchmark for Role Identification in Dialogues\n\t\n\n \nThis dataset is released with the COLM 2025 conference paper: \"PersonaEval: Are LLM Evaluators Human Enough to Judge Role-Play?\".\nPersonaEval is the first benchmark designed to test whether Large Language Models (LLMs) can reliably identify character roles from natural dialogue. We argue that correctly identifying who is speaking is a fundamental prerequisite for any meaningful evaluation of role-playing quality (howâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/lingfengzhou/PersonaEval.","url":"https://huggingface.co/datasets/lingfengzhou/PersonaEval","creator_name":"Lingfeng Zhou","creator_url":"https://huggingface.co/lingfengzhou","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["expert-generated","machine-generated","custom","English","Chinese"],"keywords_longer_than_N":true},
	{"name":"Tachibana2-DeepSeek-R1","keyword":"reasoning","description":"Click here to support our open-source dataset and model releases!\nTachibana2-DeepSeek-R1 is a code-reasoning dataset, testing the limits of DeepSeek R1's coding skills!\nThis dataset contains:\n\n27.2k synthetically generated code-reasoning prompts. All responses are generated using DeepSeek R1.\nSynthetic prompts are generated using Llama 3.1 405b Instruct, based on the original sequelbox/Tachibana dataset with increased task complexity.\nResponses demonstrate the code-reasoning capabilities ofâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/sequelbox/Tachibana2-DeepSeek-R1.","url":"https://huggingface.co/datasets/sequelbox/Tachibana2-DeepSeek-R1","creator_name":"t.d.a.g.","creator_url":"https://huggingface.co/sequelbox","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","English","apache-2.0","10K - 100K","csv"],"keywords_longer_than_N":true},
	{"name":"Titanium2.1-DeepSeek-R1","keyword":"reasoning","description":"Click here to support our open-source dataset and model releases!\nTitanium2.1-DeepSeek-R1 is a dataset focused on architecture and DevOps, testing the limits of DeepSeek R1's architect and coding skills!\nThis dataset contains:\n\n31.7k synthetically generated prompts focused on architecture, cloud, and DevOps. All responses are generated using DeepSeek R1. Primary areas of expertise are architecture (problem solving, scenario analysis, coding, full SDLC) and DevOps (Azure, AWS, GCP, Terraformâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/sequelbox/Titanium2.1-DeepSeek-R1.","url":"https://huggingface.co/datasets/sequelbox/Titanium2.1-DeepSeek-R1","creator_name":"t.d.a.g.","creator_url":"https://huggingface.co/sequelbox","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","English","apache-2.0","10K - 100K","csv"],"keywords_longer_than_N":true},
	{"name":"V1-33K-Old","keyword":"reasoning","description":"\n\n\n\t\n\t\t\n\t\tV1: Toward Multimodal Reasoning by Designing Auxiliary Tasks\n\t\n\n\nğŸš€  Toward Multimodal Reasoning via Unsupervised Task -- Future Prediction ğŸŒŸ\n\n\n\n\n\n\n\n\n \n\nAuthors: Haonan Wang, Chao Du, Tianyu PangGitHub: haonan3/V1Dataset: V1-33K on Hugging Face\n\n\n\n\t\n\t\t\n\t\tMultimodal Reasoning\n\t\n\nRecent Large Reasoning Models (LRMs) such as DeepSeek-R1 have demonstrated impressive reasoning abilities; however, their capabilities are limited to textual data. Current models capture only a small part ofâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/haonan3/V1-33K-Old.","url":"https://huggingface.co/datasets/haonan3/V1-33K-Old","creator_name":"Haonan Wang","creator_url":"https://huggingface.co/haonan3","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["visual-question-answering","video-text-to-text","English","apache-2.0","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"Thinking-multilingual-big-10k-sft","keyword":"reasoning","description":"\nA dataset based off of openo1 math, 500 examples translated to 23 different languages. filtered out un-translated examples.\nenjoy ğŸ‘\n","url":"https://huggingface.co/datasets/Pinkstack/Thinking-multilingual-big-10k-sft","creator_name":"Pinkstack","creator_url":"https://huggingface.co/Pinkstack","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","Arabic","Chinese","Czech","Danish"],"keywords_longer_than_N":true},
	{"name":"Reflection-Dataset-ShareGPT-v1","keyword":"reflection","description":"\n\t\n\t\t\n\t\tV2 is out!!! V2\n\t\n\n\n\t\n\t\t\n\t\tSimple \"Reflection\" method dataset inspired by mattshumer\n\t\n\n\n\t\n\t\t\n\t\tThis is the ShareGPT version. Find prompt and response pair dataset here\n\t\n\nThis dataset was synthetically generated using Glaive AI.\n","url":"https://huggingface.co/datasets/mahiatlinux/Reflection-Dataset-ShareGPT-v1","creator_name":"Maheswar KK","creator_url":"https://huggingface.co/mahiatlinux","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["English","mit","1K - 10K","json","Text"],"keywords_longer_than_N":true},
	{"name":"dolphin-r1-italian","keyword":"reasoning","description":"\n  \n  \n\n\n\n  \n    \n  \n  \n    \n  \n  \n    \n  \n    \n  \n    \n    \n  \n\n\n  \n    \n  \n\n\n\n\t\n\t\n\t\n\t\tDolphin R1 Italian ğŸ¬\n\t\n\n\nDolphin-R1 is an Apache-2.0 English dataset curated by Eric Hartford and Cognitive Computations\nDolphin-R1-Italian is a Italian subset of the original dataset.\n\n\n\t\n\t\t\n\t\tSponsors\n\t\n\nTheir and Wiro AI's appreciation for the generous sponsors of Dolphin R1 - Without whom this dataset could not exist.\n\nDria https://x.com/driaforall - Inference Sponsor (DeepSeek)\nChutesâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/WiroAI/dolphin-r1-italian.","url":"https://huggingface.co/datasets/WiroAI/dolphin-r1-italian","creator_name":"Wiro AI","creator_url":"https://huggingface.co/WiroAI","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["Italian","apache-2.0","100K - 1M","parquet","Text"],"keywords_longer_than_N":true},
	{"name":"GRPO-LEAD-SFTData","keyword":"reasoning","description":"\n\t\n\t\t\n\t\tğŸ“¦ GRPO-LEAD-SFTData\n\t\n\nGRPO-LEAD-SFTData is a supervised fine-tuning dataset comprising 12,153 high-quality mathematical reasoning examples generated using QwQ-32B. Designed to enhance mathematical reasoning, this dataset is central to the GRPO-LEAD training pipeline.\n\n\t\n\t\t\n\t\tğŸ“š Description\n\t\n\n\nSource: Primarily derived from the DeepScaler dataset, filtered to include only problems with difficulty > 1, emphasizing challenging problem-solving cases.\nFormat: Samples follow a cleanâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/PlanePaper/GRPO-LEAD-SFTData.","url":"https://huggingface.co/datasets/PlanePaper/GRPO-LEAD-SFTData","creator_name":"Jeffery Zhang","creator_url":"https://huggingface.co/PlanePaper","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["English","apache-2.0","10K - 100K","json","Text"],"keywords_longer_than_N":true},
	{"name":"DES-Reasoning-DeepSeek-V3.1","keyword":"reasoning","description":"Click here to support our open-source dataset and model releases!\nDES-Reasoning-DeepSeek-V3.1 is a dataset focused on analysis and reasoning, creating discrete event simulations testing the limits of DeepSeek V3.1's simulation, Python scripting, and analysis skills!\nThis dataset contains:\n\n4.03k synthetically generated prompts to create discrete event simulations and analysis chat in response to user input, with all responses generated using DeepSeek V3.1.\nAll responses contain a multi-stepâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/sequelbox/DES-Reasoning-DeepSeek-V3.1.","url":"https://huggingface.co/datasets/sequelbox/DES-Reasoning-DeepSeek-V3.1","creator_name":"t.d.a.g.","creator_url":"https://huggingface.co/sequelbox","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","feature-extraction","English","apache-2.0","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"MathBode-LinearSystem","keyword":"reasoning","description":"\n\t\n\t\t\n\t\tMathBode-LinearSystem: Systems of Linear Equations Domain\n\t\n\nLinear system solving problems from the MathBode benchmark.\nThis dataset is part of the MathBode benchmark, which evaluates the dynamic reasoning capabilities of large language models (LLMs) by treating parametric math problems as dynamic systems. Instead of testing static accuracy on fixed problems, MathBode sinusoidally varies a parameter and measures the model's response in terms of gain (amplitude tracking) and phaseâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/cognitive-metrology-lab/MathBode-LinearSystem.","url":"https://huggingface.co/datasets/cognitive-metrology-lab/MathBode-LinearSystem","creator_name":"Cognitive Metrology Lab","creator_url":"https://huggingface.co/cognitive-metrology-lab","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["apache-2.0","1K - 10K","parquet","Tabular","Text"],"keywords_longer_than_N":true},
	{"name":"yawp_thinking","keyword":"reasoning","description":"\n\t\n\t\t\n\t\tAmerican Yawp Enriched: A Reasoning Dataset for US History\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset contains 1,000 high-quality question-and-answer pairs focused on US History, enriched with an AI-generated \"chain-of-thought\" reasoning step. The primary goal of this dataset is to provide a specialized resource for fine-tuning conversational language models to not only answer historical questions but also to explain the process of arriving at that answer.\nThe foundation of thisâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/ambrosfitz/yawp_thinking.","url":"https://huggingface.co/datasets/ambrosfitz/yawp_thinking","creator_name":"Christopher Smith","creator_url":"https://huggingface.co/ambrosfitz","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["reinforcement-learning","English","mit","1K - 10K","json"],"keywords_longer_than_N":true},
	{"name":"El-TARA_Spanish_LLM_Benchmark","keyword":"mathematical-reasoning","description":"\n\t\n\t\t\n\t\tEl-Tara: EvaluaciÃ³n de Razonamiento Avanzado en EspaÃ±ol\n\t\n\n\n\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nEl-Tara (EvaluaciÃ³n de Razonamiento Avanzado en EspaÃ±ol) is a benchmark dataset designed to assess the advanced reasoning capabilities of Large Language Models (LLMs) in Spanish. It is adapted from the original TARA (Turkish Advanced Reasoning Assessment) dataset.\nSimilar to TARA, El-Tara aims to test higher-order cognitive skills across multiple domains, using synthetically generated questionsâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/emre/El-TARA_Spanish_LLM_Benchmark.","url":"https://huggingface.co/datasets/emre/El-TARA_Spanish_LLM_Benchmark","creator_name":"Davut Emre TASAR","creator_url":"https://huggingface.co/emre","license_name":"Academic Free License v3.0","license_url":"https://choosealicense.com/licenses/afl-3.0/","language":"en","first_N":5,"first_N_keywords":["question-answering","text-generation","Spanish","afl-3.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"MathBode-ExponentialInterest","keyword":"reasoning","description":"\n\t\n\t\t\n\t\tMathBode-ExponentialInterest: Exponential Functions Domain\n\t\n\nCompound interest and exponential growth problems from the MathBode benchmark.\nThis dataset is part of the MathBode benchmark, which evaluates the dynamic reasoning capabilities of large language models (LLMs) by treating parametric math problems as dynamic systems. Instead of testing static accuracy on fixed problems, MathBode sinusoidally varies a parameter and measures the model's response in terms of gain (amplitudeâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/cognitive-metrology-lab/MathBode-ExponentialInterest.","url":"https://huggingface.co/datasets/cognitive-metrology-lab/MathBode-ExponentialInterest","creator_name":"Cognitive Metrology Lab","creator_url":"https://huggingface.co/cognitive-metrology-lab","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["apache-2.0","1K - 10K","parquet","Tabular","Text"],"keywords_longer_than_N":true},
	{"name":"VQA-Verify","keyword":"reasoning","description":"This is the VQA-Verify dataset, introduced in the paper SATORI-R1: Incentivizing Multimodal Reasoning with Spatial Grounding and Verifiable Rewards.\nArxiv Here | Github\nVQA-Verify is a 12k dataset annotated with answer-aligned captions and bounding boxes. It's designed to facilitate training models for Visual Question Answering (VQA) tasks, particularly those employing free-form reasoning. The dataset addresses limitations in existing VQA datasets by providing verifiable intermediate steps andâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/justairr/VQA-Verify.","url":"https://huggingface.co/datasets/justairr/VQA-Verify","creator_name":"Chuming Shen","creator_url":"https://huggingface.co/justairr","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["visual-question-answering","English","apache-2.0","10K - 100K","imagefolder"],"keywords_longer_than_N":true},
	{"name":"FOL-nli","keyword":"reasoning","description":"\n\t\n\t\t\n\t\tDataset Card for \"FOL-nli\"\n\t\n\nhttps://github.com/sileod/unigram/\nhttps://arxiv.org/abs/2406.11035\nCitation:\n@article{sileo2024scaling,\n  title={Scaling Synthetic Logical Reasoning Datasets with Context-Sensitive Declarative Grammars},\n  author={Sileo, Damien},\n  journal={arXiv preprint arXiv:2406.11035},\n  year={2024}\n}\n\n","url":"https://huggingface.co/datasets/tasksource/FOL-nli","creator_name":"tasksource","creator_url":"https://huggingface.co/tasksource","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","natural-language-inference","multi-input-text-classification","original","English"],"keywords_longer_than_N":true},
	{"name":"100k-raz-es","keyword":"reasoning","description":"sintergica/100k-raz-es dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/sintergica/100k-raz-es","creator_name":"SintÃ©rgica AI","creator_url":"https://huggingface.co/sintergica","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","Spanish","cc-by-4.0","100K - 1M","csv"],"keywords_longer_than_N":true},
	{"name":"aqua-rat-mcqa","keyword":"reasoning","description":"\n\t\n\t\t\n\t\tAQUA-RAT MCQA Dataset\n\t\n\nThis dataset contains the AQUA-RAT dataset converted to Multiple Choice Question Answering (MCQA) format with modifications.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nAQUA-RAT is a dataset of algebraic word problems with rationales. This version has been processed to:\n\nRemove all questions where the correct answer was option \"E\" (5th choice)\nRemove the \"E\" option from all remaining questions (4 choices: A, B, C, D)\nMerge validation and test splits into a single test splitâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/RikoteMaster/aqua-rat-mcqa.","url":"https://huggingface.co/datasets/RikoteMaster/aqua-rat-mcqa","creator_name":"Rico ibaÃ±ez ","creator_url":"https://huggingface.co/RikoteMaster","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["question-answering","multiple-choice","English","apache-2.0","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"OpenR1-Math-220k-paired","keyword":"reasoning","description":"\n\t\n\t\t\n\t\t!!! Is there anyone can help me? https://github.com/huggingface/trl/issues/2994\n\t\n\n\n\t\n\t\t\n\t\tIntroduction\n\t\n\nThis dataset is built by filtering the open-r1/OpenR1-Math-220k dataset according to the following rules:\n\nFirst, filter all of rows with only correct answers\nThe chosen contains the shortest and correct generation, the rejected contains the wrong generation.\nAll data with a prompt+chosen length exceeding 16k are filtered out.\nWe provide the length for both chosen and rejectedâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/AIR-hl/OpenR1-Math-220k-paired.","url":"https://huggingface.co/datasets/AIR-hl/OpenR1-Math-220k-paired","creator_name":"Hsu Shihyueh","creator_url":"https://huggingface.co/AIR-hl","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","English","apache-2.0","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"kegg","keyword":"reasoning","description":"\nğŸ§¬ BioReasonIncentivizing Multimodal Biological Reasoning within a DNA-LLM Model\n\n\n\n  \n  \n  \n  \n\n\n\n\t\n\t\t\n\t\tKEGG Biological Reasoning Dataset\n\t\n\n1,449 entries from KEGG pathway database with variants from ClinVar/dbSNP/OMIM/COSMIC, featuring reasoning traces for mechanistic variant-to-disease prediction across 37 unique diseases.\n\n\t\n\t\t\n\t\tUsage\n\t\n\nfrom datasets import load_dataset\n\ndataset = load_dataset(\"wanglab/kegg\")\nexample = dataset[\"train\"][0]\nprint(example)\n\n\n\t\n\t\t\n\t\tCitationâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/wanglab/kegg.","url":"https://huggingface.co/datasets/wanglab/kegg","creator_name":"WangLab UofT","creator_url":"https://huggingface.co/wanglab","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["apache-2.0","1K - 10K","parquet","Text","Datasets"],"keywords_longer_than_N":true},
	{"name":"LongPage","keyword":"reasoning","description":"\n\n\t\n\t\t\n\t\tOverview ğŸš€ğŸ“š\n\t\n\nThe first comprehensive dataset for training AI models to write complete novels with sophisticated reasoning.\nğŸ§  Hierarchical Reasoning Architecture â€” Multi-layered planning traces including character archetypes, story arcs, world rules, and scene breakdowns. A complete cognitive roadmap for long-form narrative construction.\nğŸ“– Complete Novel Coverage â€” From 40,000 to 600,000+ tokens per book, spanning novellas to epic series with consistent quality throughout.\nâš¡â€¦ See the full description on the dataset page: https://huggingface.co/datasets/Pageshift-Entertainment/LongPage.","url":"https://huggingface.co/datasets/Pageshift-Entertainment/LongPage","creator_name":"Pageshift-Entertainment","creator_url":"https://huggingface.co/Pageshift-Entertainment","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","language-modeling","text2text-generation","machine-generated","found"],"keywords_longer_than_N":true},
	{"name":"TextBooksPersonaHub","keyword":"reasoning","description":"\n\t\n\t\t\n\t\tTextBooksPersonaHub\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThe TextBooksPersonaHub dataset is an extension of the proj-persona/PersonaHub dataset, created using the technique described in the paper Textbooks Are All You Need II. This dataset contains synthetically generated \"textbook-like\" passages tailored in french to specific personas, aimed at enhancing language model training with high-quality and diverse content.\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Creation\n\t\n\n\n\t\n\t\t\n\t\n\t\n\t\tSource Data\n\t\n\nThe original personasâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/drodin/TextBooksPersonaHub.","url":"https://huggingface.co/datasets/drodin/TextBooksPersonaHub","creator_name":"nacer","creator_url":"https://huggingface.co/drodin","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text2text-generation","French","apache-2.0","100K - 1M","json"],"keywords_longer_than_N":true},
	{"name":"Hypa_AIME2024","keyword":"reasoning","description":"\n\t\n\t\t\n\t\tHypa_AIME2024\n\t\n\nHypa_AIME2024 is an open-source, multilingual benchmark dataset for advanced mathematical reasoning, designed with the long-term vision of ensuring all languages are represented in AI development. This dataset marks a crucial step toward closing the gap between AI capabilities for no-resource/low-resource and all-resource languages, particularly in complex reasoning domains. \nThis initial release features the complete 2024 American Invitational Mathematics Examinationâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/hypaai/Hypa_AIME2024.","url":"https://huggingface.co/datasets/hypaai/Hypa_AIME2024","creator_name":"Hypa-Intelligence","creator_url":"https://huggingface.co/hypaai","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["translation","question-answering","AfroVoices","multilingual","English"],"keywords_longer_than_N":true},
	{"name":"MathCodeInstruct","keyword":"reasoning","description":"\n\t\n\t\t\n\t\tMathCoder: Seamless Code Integration in LLMs for Enhanced Mathematical Reasoning\n\t\n\nPaper: https://arxiv.org/pdf/2310.03731.pdf\nRepo: https://github.com/mathllm/MathCoder\n\n\t\n\t\t\n\t\tIntroduction\n\t\n\nWe introduce MathCoder, a series of open-source large language models (LLMs) specifically tailored for general math problem-solving.\n\n\t\n\t\t\nBase Model: Llama-2\nBase Model: Code Llama\n\n\n\t\t\nMathCoder-L-7B\nMathCoder-CL-7B\n\n\nMathCoder-L-13B\nMathCoder-CL-34B\n\n\n\t\n\n\n\t\n\t\n\t\n\t\tTraining Data\n\t\n\nThe modelsâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/MathLLMs/MathCodeInstruct.","url":"https://huggingface.co/datasets/MathLLMs/MathCodeInstruct","creator_name":"LLMs for Reasoning","creator_url":"https://huggingface.co/MathLLMs","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["question-answering","text-generation","English","apache-2.0","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"DORI-Benchmark","keyword":"reasoning","description":"\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nDORI (Discriminative Orientation Reasoning Intelligence) is a comprehensive benchmark designed to evaluate object orientation understanding in multimodal large language models (MLLMs). The benchmark isolates and evaluates orientation perception as a primary capability, offering a systematic assessment framework that spans four essential dimensions of orientation comprehension: frontal alignment, rotational transformations, relativeâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/appledora/DORI-Benchmark.","url":"https://huggingface.co/datasets/appledora/DORI-Benchmark","creator_name":"Nazia Tasnim","creator_url":"https://huggingface.co/appledora","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["image-text-to-text","English","mit","1K - 10K","imagefolder"],"keywords_longer_than_N":true},
	{"name":"Omni-MATH-512","keyword":"reasoning","description":"This is the test dataset for the paper Understanding Tool-Integrated Reasoning\n","url":"https://huggingface.co/datasets/Heng1999/Omni-MATH-512","creator_name":"Heng Lin","creator_url":"https://huggingface.co/Heng1999","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","English","apache-2.0","< 1K","json"],"keywords_longer_than_N":true},
	{"name":"camel_dataset_example_2","keyword":"step-by-step","description":"A dataset containing mathematical problem-solving traces with step-by-step solutions and improvement history. Each record includes a mathematical problem, its final solution, and the iterative improvement process.","url":"https://huggingface.co/datasets/Wendong-Fan/camel_dataset_example_2","creator_name":"Wendong.Fan","creator_url":"https://huggingface.co/Wendong-Fan","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-generation","English","mit","< 1K","json"],"keywords_longer_than_N":true},
	{"name":"indian_law","keyword":"reasoning","description":"\n\t\n\t\t\n\t\tIndian Law Dataset\n\t\n\nThe Indian Law Dataset is a high-quality, open-source dataset (~50M tokens) focused on Indian jurisprudence. It provides structured chain-of-thought reasoning traces across 10+ branches of law, enabling the training and evaluation of advanced reasoning-capable language models.\n\n\t\n\t\t\n\t\tSummary\n\t\n\nâ€¢ Domain: Law / Indian Jurisprudence / Legal Reasoning\nâ€¢ Scale: ~50M tokens, 47,789 rows\nâ€¢ Source: Generated with advanced distillation techniques using structuredâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/169Pi/indian_law.","url":"https://huggingface.co/datasets/169Pi/indian_law","creator_name":"169Pi","creator_url":"https://huggingface.co/169Pi","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","question-answering","English","apache-2.0","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"TreeVGR-RL-37K","keyword":"reasoning","description":"\n\t\n\t\t\n\t\tTreeBench Dataset Card\n\t\n\nThis repository contains TreeBench (Traceable Evidence Evaluation Benchmark), a diagnostic benchmark designed for evaluating \"thinking with images\" capabilities with traceable visual evidence.\nThe dataset was introduced in the paper: Traceable Evidence Enhanced Visual Grounded Reasoning: Evaluation and Methodology.\nTreeBench is built on three core principles:\n\nFocused visual perception: of subtle targets in complex scenes.\nTraceable evidence: via bounding boxâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/HaochenWang/TreeVGR-RL-37K.","url":"https://huggingface.co/datasets/HaochenWang/TreeVGR-RL-37K","creator_name":"HaochenWang","creator_url":"https://huggingface.co/HaochenWang","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["image-text-to-text","English","apache-2.0","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"Helios-R-6M","keyword":"reasoning","description":"\n\n\t\n\t\t\n\t\tHelios-R-6M\n\t\n\n\nHelios-R-6M is a high-quality, compact reasoning dataset designed to strengthen multi-step problem solving across mathematics, computer science, and scientific inquiry. While the dataset covers a range of disciplines, math constitutes the largest share of examples and drives the reasoning complexity.\n\n\n\n\t\n\t\t\n\t\tQuick Start with Hugging Face DatasetsğŸ¤—\n\t\n\npip install -U datasets\n\nfrom datasets import load_dataset\n\ndataset = load_dataset(\"prithivMLmods/Helios-R-6M\"â€¦ See the full description on the dataset page: https://huggingface.co/datasets/prithivMLmods/Helios-R-6M.","url":"https://huggingface.co/datasets/prithivMLmods/Helios-R-6M","creator_name":"Prithiv Sakthi","creator_url":"https://huggingface.co/prithivMLmods","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","question-answering","English","apache-2.0","1M - 10M"],"keywords_longer_than_N":true},
	{"name":"Sungur-Dataset","keyword":"reasoning","description":"\n\n\n\t\n\t\t\n\t\tSungur-Dataset\n\t\n\n\n\t\n\t\t\n\t\tğŸ“– Overview\n\t\n\nSungur-Dataset is a large-scale, instructionâ€“response style dataset designed to improve the reasoning capabilities of Turkish language models.\nThe dataset was created by merging four publicly available reasoning datasets into a unified format, resulting in 41,1k samples covering multiple domains such as mathematics, medicine, and general reasoning.\nThis dataset is ideal for Supervised Fine-Tuning (SFT) in Turkish.\n\n\n\t\n\t\t\n\t\n\t\n\t\tğŸ“Š Datasetâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/suayptalha/Sungur-Dataset.","url":"https://huggingface.co/datasets/suayptalha/Sungur-Dataset","creator_name":"Åuayp Talha Kocabay","creator_url":"https://huggingface.co/suayptalha","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","Turkish","apache-2.0","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"Mitakihara-DeepSeek-R1-0528","keyword":"reasoning","description":"Click here to support our open-source dataset and model releases!\nMitakihara-DeepSeek-R1-0528 is a dataset focused on artificial intelligence, testing the limits of DeepSeek R1 0528's AI-reasoning skills!\nThis dataset contains:\n\n16.9k synthetically generated prompts about AI, with all responses generated using DeepSeek R1 0528.\nSubjects include computer science, artificial intelligence, MLOps, LLMs and diffusion models, math and CUDA, cutting-edge and future technologies, complex adaptive andâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/sequelbox/Mitakihara-DeepSeek-R1-0528.","url":"https://huggingface.co/datasets/sequelbox/Mitakihara-DeepSeek-R1-0528","creator_name":"t.d.a.g.","creator_url":"https://huggingface.co/sequelbox","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","English","apache-2.0","10K - 100K","csv"],"keywords_longer_than_N":true},
	{"name":"tombench_merged","keyword":"reasoning","description":"\n\t\n\t\t\n\t\tTomBench Merged Dataset (Exact Matching)\n\t\n\nThis dataset contains the merged results of TomBench evaluation with the original TomBench dataset, using exact string matching.\n\n\t\n\t\t\n\t\tDataset Statistics\n\t\n\n\nTotal records: 2860\nExact matches: 2860\nManual matches: 0\nAverage model score: 0.5066\n\n\n\t\n\t\t\n\t\tMatching Strategy\n\t\n\nThis version uses exact string matching after text normalization:\n\nRemove extra whitespace and normalize formatting\nMatch stories exactly between datasets\nReport anyâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/ycfNTU/tombench_merged.","url":"https://huggingface.co/datasets/ycfNTU/tombench_merged","creator_name":"ycf","creator_url":"https://huggingface.co/ycfNTU","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["question-answering","text-classification","English","mit","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"CoreCognition","keyword":"reasoning","description":"\n\t\n\t\t\n\t\tCoreCognition: A Core Knowledge Benchmark for Multi-modal Large Language Models\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nCoreCognition is a large-scale benchmark encompassing 12 core knowledge grounded in developmental cognitive science, designed to evaluate the fundamental core abilities of Multi-modal Large Language Models (MLLMs).\nWhile MLLMs demonstrate impressive abilities over high-level perception and reasoning, their robustness in the wild remains limited, often falling short on tasksâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/williamium/CoreCognition.","url":"https://huggingface.co/datasets/williamium/CoreCognition","creator_name":"William Li","creator_url":"https://huggingface.co/williamium","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["visual-question-answering","English","apache-2.0","1K - 10K","parquet"],"keywords_longer_than_N":true},
	{"name":"Olympiads","keyword":"mathematical-reasoning","description":"\n\t\n\t\t\n\t\tNumina-Olympiads\n\t\n\nFiltered NuminaMath-CoT dataset containing only olympiads problems with valid answers.\n\n\t\n\t\t\n\t\tDataset Information\n\t\n\n\nSplit: train\nOriginal size: 32926\nFiltered size: 32926\nSource: olympiads\nAll examples contain valid boxed answers\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset is a filtered version of the NuminaMath-CoT dataset, containing only problems from olympiad sources that have valid boxed answers. Each example includes:\n\nA mathematical word problem\nAâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Metaskepsis/Olympiads.","url":"https://huggingface.co/datasets/Metaskepsis/Olympiads","creator_name":"Metaskepsis","creator_url":"https://huggingface.co/Metaskepsis","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-generation","expert-generated","expert-generated","monolingual","AI-MO/NuminaMath-CoT"],"keywords_longer_than_N":true},
	{"name":"big_bench_hard","keyword":"mathematical-reasoning","description":"All rights and obligations of the dataset are with original authors of the paper/dataset.\nI have merely made this dataset with a MIT licence available on HuggingFace.\n\n\t\n\t\t\n\t\tBIG-Bench Hard Dataset\n\t\n\nThis repository contains a copy of the BIG-Bench Hard dataset.\nSmall edits to the formatting of the dataset are made to integrate it into the Inspect Evals repository, a community contributed LLM\nevaulations for Inspect AI a framework by the UK AI Safety Institute.\nThe BIG-Bench Hard dataset is aâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Joschka/big_bench_hard.","url":"https://huggingface.co/datasets/Joschka/big_bench_hard","creator_name":"Joschka Braun","creator_url":"https://huggingface.co/Joschka","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["question-answering","multiple-choice","text-generation","English","mit"],"keywords_longer_than_N":true},
	{"name":"GameQA-140K","keyword":"reasoning","description":"\n\t\n\t\t\n\t\t1. Overview\n\t\n\nGameQA is a large-scale, diverse, and challenging multimodal reasoning dataset designed to enhance the general reasoning capabilities of Vision Language Models (VLMs). Generated using the innovative Code2Logic framework, it leverages game code to synthesize high-quality visual-language Chain-of-Thought (CoT) data. The dataset addresses the scarcity of multimodal reasoning data, critical for advancing complex multi-step reasoning in VLMs. Each sample includes visual gameâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Code2Logic/GameQA-140K.","url":"https://huggingface.co/datasets/Code2Logic/GameQA-140K","creator_name":"Game-RL","creator_url":"https://huggingface.co/Code2Logic","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["question-answering","image-text-to-text","English","mit","< 1K"],"keywords_longer_than_N":true},
	{"name":"Roblox-Luau-Reasoning-v1.0","keyword":"reasoning","description":"\n\t\n\t\t\n\t\tRoblox-Luau-Reasoning-v1.0\n\t\n\nThis dataset contains prompt->chain of thought+code+explanation for Luau, based on Roblox/luau-corpus.\nWe take real Luau code from the corpus (cleaned & auto-formatted for best quality) and work backwards to generate a prompt for it. Then, we generate a chain of thought that works from that prompt to reach the code. Finally, we generate an explanation of the code.\nThis means that we'll be able to fine tune reasoning models (like Deepseek R1) on the datasetâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/boatbomber/Roblox-Luau-Reasoning-v1.0.","url":"https://huggingface.co/datasets/boatbomber/Roblox-Luau-Reasoning-v1.0","creator_name":"Zack Ovits","creator_url":"https://huggingface.co/boatbomber","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["English","mit","10K - 100K","parquet","Text"],"keywords_longer_than_N":true},
	{"name":"team-truthowl-mixed-reasoning-dataset","keyword":"reasoning","description":"\n\t\n\t\t\n\t\tTeam P11 Mixed Reasoning Dataset\n\t\n\n\n\t\n\t\t\n\t\tğŸ“Š Dataset description\n\t\n\nHLEï¼ˆHumanity's Last Examï¼‰å‘ã‘ã«ä½œæˆã—ãŸã€æ•°å­¦ä¸­å¿ƒï¼‹ç§‘å­¦MCã®æ··åˆæ¨è«–ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã§ã™ã€‚\næ¨è«–éç¨‹ï¼ˆChain-of-Thoughtï¼‰ã‚’ä¿æŒã—ã€æœ€çµ‚è§£ç­”ã®æ­£è¦åŒ–ã‚’è¡Œã£ã¦ã„ã¾ã™ã€‚\nå¯¾è±¡ãƒ¢ãƒ‡ãƒ«ã¯ DeepSeek-R1-Distill-Qwen-32Bã€å­¦ç¿’ã¯QLoRAã‚’æƒ³å®šã—ã¦ã„ã¾ã™ã€‚\n\n\t\n\t\t\n\t\tğŸ¯ Purpose\n\t\n\n\nCompetition: æ¾å°¾ç ”LLMã‚³ãƒ³ãƒš 2025  \nTarget Model: DeepSeek-R1-Distill-Qwen-32B  \nTraining Method: QLoRA Fine-tuningï¼ˆ4bit NF4, double quantï¼‰\n\n\n\t\n\t\t\n\t\tğŸ“¦ Composition\n\t\n\n\nMath Hardï¼ˆMATH Levelâ‰¥3, HARDMathï¼‰  \nMath Midï¼ˆGSM8K, MetaMathQAï¼‰  \nScienceï¼ˆGPQAâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/weblab-llm-competition-2025-bridge/team-truthowl-mixed-reasoning-dataset.","url":"https://huggingface.co/datasets/weblab-llm-competition-2025-bridge/team-truthowl-mixed-reasoning-dataset","creator_name":"weblab-llm-competition-2025-bridge","creator_url":"https://huggingface.co/weblab-llm-competition-2025-bridge","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","question-answering","English","apache-2.0","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"PHYBench_preprocess","keyword":"reasoning","description":"\n\t\n\t\t\n\t\tPHYBench Preprocessed Dataset\n\t\n\nThis dataset is a preprocessed version of Eureka-Lab/PHYBench, containing only the samples that have a complete solution and answer.\nThe data has been formatted into a question and answer structure suitable for training instruction-following language models.\n\n\t\n\t\t\n\t\tData Structure\n\t\n\n\nquestion: The original physics problem statement (from the content column).\nanswer: A string containing the thinking process and the final answer, formatted asâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/LLMcompe-Team-Watanabe/PHYBench_preprocess.","url":"https://huggingface.co/datasets/LLMcompe-Team-Watanabe/PHYBench_preprocess","creator_name":"LLMcompe Team Watanabe","creator_url":"https://huggingface.co/LLMcompe-Team-Watanabe","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["question-answering","expert-generated","found","monolingual","English"],"keywords_longer_than_N":true},
	{"name":"unified-math-vision-dataset","keyword":"reasoning","description":"\n\t\n\t\t\n\t\tUnified Math Vision Dataset Bundle\n\t\n\nGenerated at: 2025-09-19 17:12:44\nThis is a unified dataset bundle containing multiple math and vision reasoning datasets.\n\n\t\n\t\t\n\t\tDataset Statistics\n\t\n\nTotal samples: 15858\n\nmathvision: 3344 samples\nwemath: 500 samples\nmmmu: 415 samples\nmathvista: 6141 samples\nlogicvista: 448 samples\ndynamath: 5010 samples\n\n\n\t\n\t\t\n\t\tContents\n\t\n\n\nmanifest.jsonl: Complete dataset in JSONL format (1 JSON per line)\nmanifest.csv: Summary in CSV format\nimages/: Directoryâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Haonian/unified-math-vision-dataset.","url":"https://huggingface.co/datasets/Haonian/unified-math-vision-dataset","creator_name":"Haonian Ji","creator_url":"https://huggingface.co/Haonian","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["question-answering","visual-question-answering","English","mit","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"mathematical_reasoning_preference","keyword":"reasoning","description":"\n\t\n\t\t\n\t\tDescription\n\t\n\n\nTopic: Mathematical Reasoning\nDomains: Mathematics, Reasoning, Thinking\nFocus: This dataset can contain any type of mathematical reasoning and thinking.\nNumber of Entries: 493\nDataset Type: None\nModel Used: bedrock/us.amazon.nova-pro-v1:0\nLanguage: English\nAdditional Information: The dataset is designed to provide a wide range of mathematical reasoning examples.\nGenerated by: SynthGenAI Package\n\n","url":"https://huggingface.co/datasets/Shekswess/mathematical_reasoning_preference","creator_name":"Bojan Jakimovski","creator_url":"https://huggingface.co/Shekswess","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["question-answering","English","apache-2.0","< 1K","parquet"],"keywords_longer_than_N":true},
	{"name":"Resume-Analysis-CoTR","keyword":"reasoning","description":"\n\t\n\t\t\n\t\tResume Reasoning and Feedback Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset contains approximately 417 examples designed to facilitate research and development in automated resume analysis and feedback generation. Each data point consists of a user query regarding their resume, a simulated internal analysis (chain-of-thought) performed by an expert persona, and a final, user-facing feedback response derived solely from that analysis.\nThe dataset captures a two-step reasoningâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Akhil-Theerthala/Resume-Analysis-CoTR.","url":"https://huggingface.co/datasets/Akhil-Theerthala/Resume-Analysis-CoTR","creator_name":"Akhil Theerthala","creator_url":"https://huggingface.co/Akhil-Theerthala","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["image-to-text","question-answering","English","mit","< 1K"],"keywords_longer_than_N":true},
	{"name":"MMPR-Tiny","keyword":"reasoning","description":"\n\t\n\t\t\n\t\tMMPR-Tiny\n\t\n\nThis is the training data used during the online RL stage of InternVL3.5, which greatly improves the overall performance of InternVL3.5 across all scales. Our training code is also open-sourced.\nBased on MMPR-v1.2, we compute the accuracy of each query using the provided rollouts and select those whose model accuracy falls between 0.2 and 0.8 for online RL.\nWe further extend the dataset with recent multimodal datasets to enhance diversity.\nPlease refer to our paper forâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/OpenGVLab/MMPR-Tiny.","url":"https://huggingface.co/datasets/OpenGVLab/MMPR-Tiny","creator_name":"OpenGVLab","creator_url":"https://huggingface.co/OpenGVLab","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":null,"first_N":5,"first_N_keywords":["image-text-to-text","English","mit","1M<n<10M","arxiv:2508.18265"],"keywords_longer_than_N":true},
	{"name":"LongBench-v2-Pause1","keyword":"reasoning","description":"\n\t\n\t\t\n\t\tLongBench v2: Towards Deeper Understanding and Reasoning on Realistic Long-context Multitasks\n\t\n\nğŸŒ Project Page: https://longbench2.github.io\nğŸ’» Github Repo: https://github.com/THUDM/LongBench\nğŸ“š Arxiv Paper: https://arxiv.org/abs/2412.15204\nLongBench v2 is designed to assess the ability of LLMs to handle long-context problems requiring deep understanding and reasoning across real-world multitasks. LongBench v2 has the following features: (1) Length: Context length ranging from 8k toâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/JamesBegin/LongBench-v2-Pause1.","url":"https://huggingface.co/datasets/JamesBegin/LongBench-v2-Pause1","creator_name":"James Begin","creator_url":"https://huggingface.co/JamesBegin","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["multiple-choice","question-answering","text-classification","table-question-answering","English"],"keywords_longer_than_N":true},
	{"name":"countdown-numbers-6-gr","keyword":"reasoning","description":"\n\t\n\t\t\n\t\tCountdown Numbers Game Dataset\n\t\n\nThis dataset contains configurations and solutions for variations of the Countdown numbers game. Each example comprises a sequence of numbers, a target number, the computed solution (closest value), the arithmetic expression that achieves that value, the difference between the target and the computed value, and the final Countdown score.\n\n\t\n\t\t\n\t\tHuggingFace Download Links\n\t\n\n\n\n\n\n\t\n\t\t\nDataset Variant\nDataset Name\nDownload\n\n\n\t\t\nRandomâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/alexjackson17/countdown-numbers-6-gr.","url":"https://huggingface.co/datasets/alexjackson17/countdown-numbers-6-gr","creator_name":"Alex Jackson","creator_url":"https://huggingface.co/alexjackson17","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["mit","100K - 1M","parquet","Tabular","Text"],"keywords_longer_than_N":true},
	{"name":"toolace_sequential_tool_use_reasoning","keyword":"reasoning","description":"interstellarninja/toolace_sequential_tool_use_reasoning dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/interstellarninja/toolace_sequential_tool_use_reasoning","creator_name":"interstellarninja","creator_url":"https://huggingface.co/interstellarninja","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["question-answering","English","apache-2.0","1K - 10K","parquet"],"keywords_longer_than_N":true},
	{"name":"MATH_qCoT_LLMquery_questionasquery_lexicalquery","keyword":"reasoning","description":"Datasets from Paper: https://huggingface.co/papers/2505.18405\n","url":"https://huggingface.co/datasets/Raderspace/MATH_qCoT_LLMquery_questionasquery_lexicalquery","creator_name":"RaDeR","creator_url":"https://huggingface.co/Raderspace","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["English","mit","10K - 100K","parquet","Text"],"keywords_longer_than_N":true},
	{"name":"HARD-REASONING-DE","keyword":"reasoning","description":"\n\t\n\t\t\n\t\tHARD-REASONING-DE\n\t\n\nThe original dataset was obtained from German-RAG LLM-HARD BENCHMARK and was further cleaned, filtered and re-evaluated. \n\n\t\n\t\t\n\t\tMethodology: Reasoning-DE\n\t\n\n\nProviding Persona Descriptions and rewriting in a similar style with a different focus area and name in german/english language\nGenerating Simple Logical Problems out of Persona-specific Views & Language.\nGenerating Approaches, Thinking-Steps & Solutions separately verified by Llama-3.1-405B-Instruct\nQualityâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/embraceableAI/HARD-REASONING-DE.","url":"https://huggingface.co/datasets/embraceableAI/HARD-REASONING-DE","creator_name":"Embraceable Technology GmbH","creator_url":"https://huggingface.co/embraceableAI","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["question-answering","text-generation","German","mit","< 1K"],"keywords_longer_than_N":true},
	{"name":"logic-trainingset-symb-structed-reformatted","keyword":"reasoning","description":"\n\t\n\t\t\n\t\tLogic Reasoning and Proof Verification Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nA comprehensive dataset for training and evaluating logical reasoning capabilities in language models.\nEach example contains propositional logic problems that require formal reasoning to verify hypotheses.\n\nThe dataset includes 10427 problems with the following distribution:\n- PROVED: 4291 examples where the hypothesis can be proven from the facts\n- DISPROVED: 4262 examples where the hypothesis can beâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/RedaAlami/logic-trainingset-symb-structed-reformatted.","url":"https://huggingface.co/datasets/RedaAlami/logic-trainingset-symb-structed-reformatted","creator_name":"Reda alami","creator_url":"https://huggingface.co/RedaAlami","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","question-answering","English","apache-2.0","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"real-math-corpus-questions","keyword":"mathematical-reasoning","description":"\n\t\n\t\t\n\t\tReal Math Corpus - Statement Dependencies and Questions\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset contains a comprehensive collection of mathematical statements and questions extracted from the Real Math Dataset with 207 mathematical papers. The dataset is split into two parts:\n\nCorpus: Statement dependencies and proof dependencies with complete metadata and global ID mapping\nQuestions: Main statements from papers treated as questions, with dependency mappings to the corpusâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/AK123321/real-math-corpus-questions.","url":"https://huggingface.co/datasets/AK123321/real-math-corpus-questions","creator_name":"Adarsh Kumarappan","creator_url":"https://huggingface.co/AK123321","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","text-classification","question-answering","English","mit"],"keywords_longer_than_N":true},
	{"name":"gso","keyword":"reasoning","description":"\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nGSO is a dataset for evaluating language models' and LLM Agents capabilities in developing high-performance software.\nThe dataset collects 102 software optimization tasks from 10 popular Python repositories. \nEvaluation is performed by performance tests verifying correctness and using an expert human commit behavior as the target optimization performance.\nThe dataset was released as part of GSO: Challenging Software Optimization Tasks for Evaluating SWE-Agentsâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/gso-bench/gso.","url":"https://huggingface.co/datasets/gso-bench/gso","creator_name":"GSO","creator_url":"https://huggingface.co/gso-bench","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["other","mit","< 1K","parquet","Text"],"keywords_longer_than_N":true},
	{"name":"R-PRM","keyword":"mathematical-reasoning","description":"\n\t\n\t\t\n\t\tğŸ“˜ R-PRM Dataset (SFT + DPO)\n\t\n\nThis dataset is developed for training Reasoning-Driven Process Reward Models (R-PRM), proposed in our ACL 2025 paper. It consists of two stages:\n\nSFT (Supervised Fine-Tuning): collected from strong LLMs prompted with limited annotated examples, enabling reasoning-style evaluation.\nDPO (Direct Preference Optimization): constructed by sampling multiple reasoning trajectories and forming preference pairs without additional labels.\n\nThese datasets are usedâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/kevinpro/R-PRM.","url":"https://huggingface.co/datasets/kevinpro/R-PRM","creator_name":"Shuaijie She","creator_url":"https://huggingface.co/kevinpro","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-generation","reinforcement-learning","English","mit","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"reasoning-and-chat-harmony-format","keyword":"reasoning","description":"\n\t\n\t\t\n\t\tOpen Paws Reasoning And Conversational Finetuning Harmony Format\n\t\n\nThis dataset is part of the Open Paws initiative to develop AI training data aligned with animal liberation and advocacy principles. Created to train AI systems that understand and promote animal welfare, rights, and liberation.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\nDataset Type: Reasoning Data\nFormat: JSONL (JSON Lines)\nLanguages: Multilingual (primarily English)\nFocus: Animal advocacy and ethical reasoning\nOrganization: Openâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/open-paws/reasoning-and-chat-harmony-format.","url":"https://huggingface.co/datasets/open-paws/reasoning-and-chat-harmony-format","creator_name":"Open Paws","creator_url":"https://huggingface.co/open-paws","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","English","multilingual","apache-2.0","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"hermes3-quick-probes-multilingual","keyword":"reasoning","description":"\n\t\n\t\t\n\t\tHermes3 Quick Probes (Multilingual, Reasoning ON/OFF)\n\t\n\nĞœÑ–Ğ½Ñ–-Ğ´Ğ°Ñ‚Ğ°ÑĞµÑ‚ (20 Ğ¿Ñ€Ğ¸ĞºĞ»Ğ°Ğ´Ñ–Ğ²) Ğ´Ğ»Ñ ÑˆĞ²Ğ¸Ğ´ĞºĞ¾Ñ— Ğ¿ĞµÑ€ĞµĞ²Ñ–Ñ€ĞºĞ¸ Hermes-3 Ñƒ Ñ€ĞµĞ¶Ğ¸Ğ¼Ğ°Ñ… reasoning ON/OFF (UA/ES/EN/ID).\nĞ¦Ñ–Ğ»ÑŒ â€” Ğ»ĞµĞ³ĞºÑ– sanity-checks: Ğ´Ğµ Ğ¿Ğ¾Ñ‚Ñ€Ñ–Ğ±Ğ½Ğµ Ğ¼Ñ–Ñ€ĞºÑƒĞ²Ğ°Ğ½Ğ½Ñ, Ğ° Ğ´Ğµ Ğ´Ğ¾ÑÑ‚Ğ°Ñ‚Ğ½ÑŒĞ¾ ÑÑ‚Ğ¸ÑĞ»Ğ¾Ñ— Ğ²Ñ–Ğ´Ğ¿Ğ¾Ğ²Ñ–Ğ´Ñ–.\n\n\t\n\t\t\n\t\tĞ¤Ğ¾Ñ€Ğ¼Ğ°Ñ‚\n\t\n\n\nĞ¤Ğ°Ğ¹Ğ»: data.jsonl, Ğ¿Ğ¾ 1 JSON-Ğ¾Ğ±â€™Ñ”ĞºÑ‚Ñƒ Ğ½Ğ° Ñ€ÑĞ´Ğ¾Ğº Ğ· Ğ¿Ğ¾Ğ»ÑĞ¼Ğ¸:\nid (string) â€” ÑƒĞ½Ñ–ĞºĞ°Ğ»ÑŒĞ½Ğ¸Ğ¹ Ñ–Ğ´ĞµĞ½Ñ‚Ğ¸Ñ„Ñ–ĞºĞ°Ñ‚Ğ¾Ñ€\nlang (uk|es|en|id)\nreasoning (\"on\"|\"off\")\nprompt (string)\nexpect (dict, Ğ¾Ğ¿Ñ†Ñ–Ğ¹Ğ½Ğ¾: keywords/max_sentences/answer)\n\n\n\n\n\t\n\t\t\n\t\tĞ¯Ğºâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/segs/hermes3-quick-probes-multilingual.","url":"https://huggingface.co/datasets/segs/hermes3-quick-probes-multilingual","creator_name":"fdt","creator_url":"https://huggingface.co/segs","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","Ukrainian","Spanish","English","Indonesian"],"keywords_longer_than_N":true},
	{"name":"tool-use-multiturn-reasoning","keyword":"reasoning","description":"interstellarninja/tool-use-multiturn-reasoning dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/interstellarninja/tool-use-multiturn-reasoning","creator_name":"interstellarninja","creator_url":"https://huggingface.co/interstellarninja","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["question-answering","English","apache-2.0","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"medra-tool-reasoning","keyword":"reasoning","description":"\n\t\n\t\t\n\t\tğŸ§  Medra Tool Reasoning Dataset\n\t\n\nA comprehensive dataset designed for training conversational AI models with advanced tool-use and reasoning capabilities.\n\n\t\n\t\t\n\t\tğŸ“Š Dataset Summary\n\t\n\nMedra Tool Reasoning is a curated and optimized dataset containing 71,336 high-quality conversations that demonstrate sophisticated tool selection, reasoning, and execution patterns. The dataset merges and refines three leading tool-use datasets to create an optimal training resource for conversationalâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/drwlf/medra-tool-reasoning.","url":"https://huggingface.co/datasets/drwlf/medra-tool-reasoning","creator_name":"Alexandru Lupoi","creator_url":"https://huggingface.co/drwlf","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","question-answering","other","English","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"EEE-Bench","keyword":"reasoning","description":"\n\t\n\t\t\n\t\tEEE-Bench: A Comprehensive Multimodal Electrical And Electronics Engineering Benchmark\n\t\n\n\n\t\n\t\t\n\t\tIntroduction:\n\t\n\nEEE-Bench is a multimodal benchmark designed to evaluate the practical engineering capabilities of large multimodal models (LMMs), using electrical and electronics engineering (EEE) as the domain focus. It comprises 2,860 carefully curated problems across 10 core subdomains, including analog circuits and control systems, featuring complex visual inputs such as abstractâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/afdsafas/EEE-Bench.","url":"https://huggingface.co/datasets/afdsafas/EEE-Bench","creator_name":"Ming Li","creator_url":"https://huggingface.co/afdsafas","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["question-answering","multiple-choice","visual-question-answering","expert-generated","found"],"keywords_longer_than_N":true},
	{"name":"Poseidon-Reasoning-5M","keyword":"reasoning","description":"\n\n\t\n\t\t\n\t\tPoseidon-Reasoning-5M\n\t\n\n\nPoseidon-Reasoning-5M is a high-quality, compact reasoning dataset curated for advanced applications in mathematics, coding, and science. The dataset distinctly emphasizes mathematical and general reasoning challenges, ensuring its suitability for large language model (LLM) research, benchmarking, and STEM-focused educational tools.\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tQuick Start with Hugging Face DatasetsğŸ¤—\n\t\n\npip install -U datasets\n\nfrom datasets import load_dataset\n\ndataset =â€¦ See the full description on the dataset page: https://huggingface.co/datasets/prithivMLmods/Poseidon-Reasoning-5M.","url":"https://huggingface.co/datasets/prithivMLmods/Poseidon-Reasoning-5M","creator_name":"Prithiv Sakthi","creator_url":"https://huggingface.co/prithivMLmods","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","question-answering","English","apache-2.0","1M - 10M"],"keywords_longer_than_N":true},
	{"name":"DensingLaw-ScalingBench","keyword":"reasoning","description":"\n\t\n\t\t\n\t\tDensingLaw-ScalingBench\n\t\n\nThis dataset was created to enable a more accurate performance scaling law estimation of Large Language Models (LLMs).\nThis dataset is released as part of our paper, Densing Law of LLMs.\n\n\n\n\nğŸ“œ Paper \n\n\n\n\n\n\t\n\t\t\n\t\tğŸ’¡ Overview\n\t\n\nThis repository contains the open-source dataset used for calculating conditional loss in our LLM density evaluation framework. \nLLM density is defined as the ratio of effective parameter size to actual parameter size, where effectiveâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/openbmb/DensingLaw-ScalingBench.","url":"https://huggingface.co/datasets/openbmb/DensingLaw-ScalingBench","creator_name":"OpenBMB","creator_url":"https://huggingface.co/openbmb","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["question-answering","text-generation","multiple-choice-qa","open-domain-qa","original:mmlu"],"keywords_longer_than_N":true},
	{"name":"camel_LongCoT","keyword":"step-by-step","description":"A dataset containing mathematical problem-solving traces with step-by-step solutions and improvement history. Each record includes a mathematical problem, its final solution, and the iterative improvement process.","url":"https://huggingface.co/datasets/Tofu0142/camel_LongCoT","creator_name":"Zhang","creator_url":"https://huggingface.co/Tofu0142","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-generation","English","mit","< 1K","json"],"keywords_longer_than_N":true},
	{"name":"tool-n1-sft-unique-splits","keyword":"reasoning","description":"\n\t\n\t\t\n\t\tTool-N1 SFT Unique with Train/Eval Splits\n\t\n\nThis dataset contains supervised fine-tuning (SFT) data for training models on multi-hop tool usage and reasoning, with built-in train/evaluation splits.\n\n\t\n\t\t\n\t\tUsage\n\t\n\nfrom datasets import load_dataset\n\n# Load the dataset with splits\ndataset = load_dataset(\"Anna4242/tool-n1-sft-unique-splits\")\n\n# Access splits\ntrain_data = dataset[\"train\"]  # 6,487 examples\neval_data = dataset[\"eval\"]    # 1,622 examples\n\n# Example usage\nfor example inâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Anna4242/tool-n1-sft-unique-splits.","url":"https://huggingface.co/datasets/Anna4242/tool-n1-sft-unique-splits","creator_name":"D","creator_url":"https://huggingface.co/Anna4242","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","question-answering","English","apache-2.0","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"math-reasoning-ift-pairs","keyword":"reasoning","description":"\n\t\n\t\t\n\t\tReasoning-IFT Pairs (Math Domain)\n\t\n\n\n  \n\n\n\n\n  \n  \n\n\nThis dataset provides the largest set of IFT and Reasoning answers pairs for a set of math queries (cf: general-domain).\nIt is based on the Llama-Nemotron-Post-Training dataset, an extensive and high-quality collection of math instruction fine-tuning data.  \nWe curated 150k queries from the math subset of Llama-Nemotron-Post-Training, which covers multiple domains of math questions.For each query, we used Qwen/Qwen3-235B-A22B, whichâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/When-Does-Reasoning-Matter/math-reasoning-ift-pairs.","url":"https://huggingface.co/datasets/When-Does-Reasoning-Matter/math-reasoning-ift-pairs","creator_name":"When Does Reasoning Matter ?","creator_url":"https://huggingface.co/When-Does-Reasoning-Matter","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["question-answering","text-generation","English","mit","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"error-detection-negatives","keyword":"reasoning","description":"\n\t\n\t\t\n\t\terror-detection-negatives\n\t\n\nThis dataset is part of the PARC (Premise-Annotated Reasoning Collection) and contains mathematical reasoning problems with error annotations. This dataset combines negatives samples from multiple domains.\n\n\t\n\t\t\n\t\tDomain Breakdown\n\t\n\n\ngsm8k: 57 samples\nmath: 44 samples\nmetamathqa: 59 samples\norca_math: 54 samples\n\n\n\t\n\t\t\n\t\tFeatures\n\t\n\nEach example contains:\n\ndata_source: The domain/source of the problem (gsm8k, math, metamathqa, orca_math)\nquestion: Theâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/PARC-DATASETS/error-detection-negatives.","url":"https://huggingface.co/datasets/PARC-DATASETS/error-detection-negatives","creator_name":"PARC","creator_url":"https://huggingface.co/PARC-DATASETS","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-generation","question-answering","English","mit","< 1K"],"keywords_longer_than_N":true},
	{"name":"error-detection-negatives","keyword":"step-by-step","description":"\n\t\n\t\t\n\t\terror-detection-negatives\n\t\n\nThis dataset is part of the PARC (Premise-Annotated Reasoning Collection) and contains mathematical reasoning problems with error annotations. This dataset combines negatives samples from multiple domains.\n\n\t\n\t\t\n\t\tDomain Breakdown\n\t\n\n\ngsm8k: 57 samples\nmath: 44 samples\nmetamathqa: 59 samples\norca_math: 54 samples\n\n\n\t\n\t\t\n\t\tFeatures\n\t\n\nEach example contains:\n\ndata_source: The domain/source of the problem (gsm8k, math, metamathqa, orca_math)\nquestion: Theâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/PARC-DATASETS/error-detection-negatives.","url":"https://huggingface.co/datasets/PARC-DATASETS/error-detection-negatives","creator_name":"PARC","creator_url":"https://huggingface.co/PARC-DATASETS","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-generation","question-answering","English","mit","< 1K"],"keywords_longer_than_N":true},
	{"name":"LEXam","keyword":"reasoning","description":"\n  \n  \n    LEXam: Benchmarking Legal Reasoning on 340 Law Exams\n    A diverse, rigorous evaluation suite for legal AI from Swiss, EU, and international law examinations.\n  \n\n\nPaper | Project Page | GitHub Repository \n\n\t\n\t\n\t\n\t\tğŸ”¥ News\n\t\n\n\n[2025/05] Release of the first version of paper, where we evaluate representative SoTA LLMs with evaluations stricly verified by legal experts.\n\n\n\t\n\t\t\n\t\tğŸ§© Subsets\n\t\n\nThe dataset entails the following subsets:\n\nopen_question: All long-form, open-endedâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/LEXam-Benchmark/LEXam.","url":"https://huggingface.co/datasets/LEXam-Benchmark/LEXam","creator_name":"LEXam","creator_url":"https://huggingface.co/LEXam-Benchmark","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","text-generation","English","German","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"step2-evaluated-dataset-Qwen3-14B","keyword":"reasoning","description":"\n\t\n\t\t\n\t\tComplete Evaluation Dataset (Rubric + LogP)\n\t\n\nThis dataset contains chain-of-thought explanations evaluated using both comprehensive rubric assessment and LogP evaluation.\n\n\t\n\t\t\n\t\tOverview\n\t\n\n\nSource Dataset: llm-compe-2025-kato/step2-evaluated-dataset-Qwen3-14B\nTotal Samples: 156\nSuccessfully Evaluated (Rubric): 135\nFailed Evaluations (Rubric): 21\nEvaluation Model: Qwen/Qwen3-32B\n\n\n\t\n\t\t\n\t\tRubric Evaluation Results\n\t\n\n\n\t\n\t\t\n\t\tAverage Rubric Scores (0-4 scale)\n\t\n\n\nlogical_coherence:â€¦ See the full description on the dataset page: https://huggingface.co/datasets/llm-compe-2025-kato/step2-evaluated-dataset-Qwen3-14B.","url":"https://huggingface.co/datasets/llm-compe-2025-kato/step2-evaluated-dataset-Qwen3-14B","creator_name":"llm-compe-2025-kato","creator_url":"https://huggingface.co/llm-compe-2025-kato","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-generation","English","mit","< 1K","parquet"],"keywords_longer_than_N":true},
	{"name":"FineCorpus-WorkoutExercise","keyword":"reasoning","description":"\n\t\n\t\t\n\t\tFineCorpus-WorkoutExercise\n\t\n\nThis dataset contains structured workout exercise prompts for fine-tuning LLMs. \n\n\t\n\t\t\n\t\tStructure:\n\t\n\n\nconversations: Contains multi-turn dialogue pairs.\nsource: Indicates whether the data is from reasoning (Human) or generated by an AI model (LLM).\ncategory: Categorizes data into Q&A, Explain, Describe, Translate.\n\n\n\t\n\t\t\n\t\tUsage:\n\t\n\nTo use this dataset:\nfrom datasets import load_dataset\n\ndataset = load_dataset(\"padiflm/FineCorpus-WorkoutExercise\"â€¦ See the full description on the dataset page: https://huggingface.co/datasets/padilfm/FineCorpus-WorkoutExercise.","url":"https://huggingface.co/datasets/padilfm/FineCorpus-WorkoutExercise","creator_name":"Widi Fadhil","creator_url":"https://huggingface.co/padilfm","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","Indonesian","cc-by-4.0","< 1K","json"],"keywords_longer_than_N":true},
	{"name":"Atlas-Think-Cot-12M","keyword":"reasoning","description":"\n\n\t\n\t\t\n\t\tAtlas-Think-Cot-12M\n\t\n\n\nAtlas-Think-Cot-12M is a large-scale, high-quality reasoning dataset curated for mathematical problem-solving, code generation, and scientific thinking. This dataset emphasizes step-by-step solutions and detailed reasoning, with a major share of mathematical problems guiding its structure and composition.\n\n\nMixture of Mathematics, Coding, and Science. [ <:think>/cot ]\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tQuick Start with Hugging Face DatasetsğŸ¤—\n\t\n\npip install -U datasetsâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/prithivMLmods/Atlas-Think-Cot-12M.","url":"https://huggingface.co/datasets/prithivMLmods/Atlas-Think-Cot-12M","creator_name":"Prithiv Sakthi","creator_url":"https://huggingface.co/prithivMLmods","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","question-answering","English","apache-2.0","10M - 100M"],"keywords_longer_than_N":true},
	{"name":"MedXpertQA","keyword":"reasoning","description":"\n\t\n\t\t\n\t\tDataset Card for MedXpertQA\n\t\n\n\n\nMedXpertQA is a highly challenging and comprehensive benchmark designed to evaluate expert-level medical knowledge and advanced reasoning capabilities. It features both text-based and multimodal question-answering tasks, with the multimodal subset leveraging structured clinical information alongside images.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nMedXpertQA comprises 4,460 questions spanning diverse medical specialties, tasks, body systems, and image types. Itâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/TsinghuaC3I/MedXpertQA.","url":"https://huggingface.co/datasets/TsinghuaC3I/MedXpertQA","creator_name":"TsinghuaC3I","creator_url":"https://huggingface.co/TsinghuaC3I","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["table-question-answering","question-answering","text-generation","English","mit"],"keywords_longer_than_N":true},
	{"name":"loong","keyword":"reasoning","description":"A comprehensive collection of high-quality problems across diverse domains, curated for Project Loong. Each problem includes a detailed executable rationale and solution.","url":"https://huggingface.co/datasets/camel-ai/loong","creator_name":"CAMEL-AI.org","creator_url":"https://huggingface.co/camel-ai","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["question-answering","English","mit","1K - 10K","parquet"],"keywords_longer_than_N":true},
	{"name":"reasonrank_data_rl","keyword":"reasoning","description":"\nUseful links: ğŸ“ arXiv Paper â€¢  ğŸ§© Github\n\n\nThe RL training data to train our ReasonRank. The data format is organized based on the training data format of VERL framework.\n","url":"https://huggingface.co/datasets/liuwenhan/reasonrank_data_rl","creator_name":"wenhan liu","creator_url":"https://huggingface.co/liuwenhan","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-ranking","English","mit","1K - 10K","parquet"],"keywords_longer_than_N":true},
	{"name":"MathBode-LinearSolve","keyword":"reasoning","description":"\n\t\n\t\t\n\t\tMathBode-LinearSolve: Linear Algebra Domain\n\t\n\nLinear equation solving problems from the MathBode benchmark.\nThis dataset is part of the MathBode benchmark, which evaluates the dynamic reasoning capabilities of large language models (LLMs) by treating parametric math problems as dynamic systems. Instead of testing static accuracy on fixed problems, MathBode sinusoidally varies a parameter and measures the model's response in terms of gain (amplitude tracking) and phase (reasoning lag)â€¦ See the full description on the dataset page: https://huggingface.co/datasets/cognitive-metrology-lab/MathBode-LinearSolve.","url":"https://huggingface.co/datasets/cognitive-metrology-lab/MathBode-LinearSolve","creator_name":"Cognitive Metrology Lab","creator_url":"https://huggingface.co/cognitive-metrology-lab","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["apache-2.0","1K - 10K","parquet","Tabular","Text"],"keywords_longer_than_N":true},
	{"name":"deepseek-math-dataset","keyword":"reasoning","description":"\n\t\n\t\t\n\t\tDeepSeek Math Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThe DeepSeek Math Dataset is a high-quality dataset designed for distilling smaller mathematical reasoning models. It is derived from the official DeepSeek-Prover-V1 dataset and tailored to improve the efficiency of lightweight models while preserving strong mathematical problem-solving capabilities.\nThis dataset has been used to distill Qwen2.5-1.5B, achieving impressive performance on mathematical reasoning tasks.\n\n\t\n\t\t\n\t\n\t\n\t\tDatasetâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/madaibaba/deepseek-math-dataset.","url":"https://huggingface.co/datasets/madaibaba/deepseek-math-dataset","creator_name":"Alex Hou","creator_url":"https://huggingface.co/madaibaba","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["English","mit","10K - 100K","parquet","Text"],"keywords_longer_than_N":true},
	{"name":"ru-thinking-reasoning-r1-v2","keyword":"reasoning","description":"This is a modified version of ZeroAgency/ru-thinking-reasoning-r1 with addition of Egor-AI/CoT-XLang dataset.\nCombined dataset of mostly Russian thinking/reasoning/reflection dialogs in form of conversation suitable for LLM fine-tuning scenarios. All responses are mapped to same format.\nThe format of reasoning in most cases is:\n<think>\nReasoning...\n</think>\nResponse\n\nFor reflection dataset - there can be also <reflection> tags inside <think>.\nCommon system prompt for think:\nĞ¢Ñ‹ Ğ¿Ğ¾Ğ»ĞµĞ·Ğ½Ñ‹Ğ¹â€¦ See the full description on the dataset page: https://huggingface.co/datasets/ZeroAgency/ru-thinking-reasoning-r1-v2.","url":"https://huggingface.co/datasets/ZeroAgency/ru-thinking-reasoning-r1-v2","creator_name":"ZeroAgency","creator_url":"https://huggingface.co/ZeroAgency","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-generation","Russian","mit","100K - 1M","parquet"],"keywords_longer_than_N":true},
	{"name":"json-mode-agentic-reasoning","keyword":"reasoning","description":"interstellarninja/json-mode-agentic-reasoning dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/interstellarninja/json-mode-agentic-reasoning","creator_name":"interstellarninja","creator_url":"https://huggingface.co/interstellarninja","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["question-answering","English","apache-2.0","1K - 10K","parquet"],"keywords_longer_than_N":true},
	{"name":"TextBooksPersonaHub-FR","keyword":"reasoning","description":"\n\t\n\t\t\n\t\tTextBooksPersonaHub\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThe TextBooksPersonaHub dataset is an extension of the proj-persona/PersonaHub dataset, created using the technique described in the paper Textbooks Are All You Need II. This dataset contains synthetically generated \"textbook-like\" passages tailored in french to specific personas, aimed at enhancing language model training with high-quality and diverse content.\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Creation\n\t\n\n\n\t\n\t\t\n\t\n\t\n\t\tSource Data\n\t\n\nThe original personasâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/drodin/TextBooksPersonaHub-FR.","url":"https://huggingface.co/datasets/drodin/TextBooksPersonaHub-FR","creator_name":"nacer","creator_url":"https://huggingface.co/drodin","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text2text-generation","French","apache-2.0","100K - 1M","json"],"keywords_longer_than_N":true},
	{"name":"ru-thinking-reasoning-r1-v2","keyword":"reflection","description":"This is a modified version of ZeroAgency/ru-thinking-reasoning-r1 with addition of Egor-AI/CoT-XLang dataset.\nCombined dataset of mostly Russian thinking/reasoning/reflection dialogs in form of conversation suitable for LLM fine-tuning scenarios. All responses are mapped to same format.\nThe format of reasoning in most cases is:\n<think>\nReasoning...\n</think>\nResponse\n\nFor reflection dataset - there can be also <reflection> tags inside <think>.\nCommon system prompt for think:\nĞ¢Ñ‹ Ğ¿Ğ¾Ğ»ĞµĞ·Ğ½Ñ‹Ğ¹â€¦ See the full description on the dataset page: https://huggingface.co/datasets/ZeroAgency/ru-thinking-reasoning-r1-v2.","url":"https://huggingface.co/datasets/ZeroAgency/ru-thinking-reasoning-r1-v2","creator_name":"ZeroAgency","creator_url":"https://huggingface.co/ZeroAgency","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-generation","Russian","mit","100K - 1M","parquet"],"keywords_longer_than_N":true},
	{"name":"countdown-numbers-3-8-nz","keyword":"reasoning","description":"\n\t\n\t\t\n\t\tCountdown Numbers Game Dataset\n\t\n\nThis dataset contains configurations and solutions for variations of the Countdown numbers game. Each example comprises a sequence of numbers, a target number, the computed solution (closest value), the arithmetic expression that achieves that value, the difference between the target and the computed value, and the final Countdown score.\n\n\t\n\t\t\n\t\tHuggingFace Download Links\n\t\n\n\n\n\n\n\t\n\t\t\nDataset Variant\nDataset Name\nDownload\n\n\n\t\t\nRandomâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/alexjackson17/countdown-numbers-3-8-nz.","url":"https://huggingface.co/datasets/alexjackson17/countdown-numbers-3-8-nz","creator_name":"Alex Jackson","creator_url":"https://huggingface.co/alexjackson17","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["mit","1M - 10M","parquet","Tabular","Text"],"keywords_longer_than_N":true},
	{"name":"json-mode-verifiable","keyword":"reasoning","description":"interstellarninja/json-mode-verifiable dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/interstellarninja/json-mode-verifiable","creator_name":"interstellarninja","creator_url":"https://huggingface.co/interstellarninja","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["question-answering","English","apache-2.0","1K - 10K","parquet"],"keywords_longer_than_N":true},
	{"name":"FLenQA","keyword":"reasoning","description":"Same Task, More tokens\nthe Impact of Input Length on the Reasoning Performance of Large Language Models\nMosh Levy[*,1], Alon Jacoby[*,1], Yoav Goldberg[1,2]\n\n\nPlease see full details in our pre-print on arxiv\n \n\n\n\t\n\t\t\n\t\tWhat is this all about?\n\t\n\nWe explore the impact of extending input lengths on the capabilities of Large Language Models (LLMs). \nDespite LLMs advancements in recent times, their performance consistency across different input lengths is not well understood.\nHere, we aim toâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/alonj/FLenQA.","url":"https://huggingface.co/datasets/alonj/FLenQA","creator_name":"Alon Jacoby","creator_url":"https://huggingface.co/alonj","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["question-answering","English","mit","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"ru-thinking-reasoning-r1","keyword":"reasoning","description":"Combined dataset of mostly Russian thinking/reasoning/reflection dialogs in form of conversation suitable for LLM fine-tuning scenarios. All responses are mapped to same format.\nThe format of reasoning in most cases is:\n<think>\nReasoning...\n</think>\nResponse\n\nFor reflection dataset - there can be also <reflection> tags inside <think>.\nCommon system prompt for think:\nĞ¢Ñ‹ Ğ¿Ğ¾Ğ»ĞµĞ·Ğ½Ñ‹Ğ¹ Ğ°ÑÑĞ¸ÑÑ‚ĞµĞ½Ñ‚. ĞÑ‚Ğ²ĞµÑ‡Ğ°Ğ¹ Ğ½Ğ° Ğ²Ğ¾Ğ¿Ñ€Ğ¾ÑÑ‹, ÑĞ¾Ñ…Ñ€Ğ°Ğ½ÑÑ ÑĞ»ĞµĞ´ÑƒÑÑ‰ÑƒÑ ÑÑ‚Ñ€ÑƒĞºÑ‚ÑƒÑ€Ñƒ: <think> Ğ¢Ğ²Ğ¾Ğ¸ Ğ¼Ñ‹ÑĞ»Ğ¸ Ğ¸ Ñ€Ğ°ÑÑÑƒĞ¶Ğ´ĞµĞ½Ğ¸Ñ </think> \nĞ¢Ğ²Ğ¾Ğ¹ ĞºĞ¾Ğ½ĞµÑ‡Ğ½Ñ‹Ğ¹â€¦ See the full description on the dataset page: https://huggingface.co/datasets/ZeroAgency/ru-thinking-reasoning-r1.","url":"https://huggingface.co/datasets/ZeroAgency/ru-thinking-reasoning-r1","creator_name":"ZeroAgency","creator_url":"https://huggingface.co/ZeroAgency","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-generation","Russian","mit","100K - 1M","parquet"],"keywords_longer_than_N":true},
	{"name":"MedQA-USMLE-4-options_preprocess","keyword":"reasoning","description":"\n\t\n\t\t\n\t\tMedQA-USMLE Preprocessed Dataset\n\t\n\nThis dataset is a preprocessed version of GBaker/MedQA-USMLE-4-options.\nThe data has been formatted into a question and answer structure suitable for training or evaluating instruction-following language models.\n\n\t\n\t\t\n\t\tData Structure\n\t\n\n\nquestion: The original medical question combined with the four multiple-choice options.\nanswer: The correct answer index, prefixed with ####.\n\n\n\t\n\t\t\n\t\tExample\n\t\n\nQuestion:\nA 60-year-old woman comes to the emergencyâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/LLMcompe-Team-Watanabe/MedQA-USMLE-4-options_preprocess.","url":"https://huggingface.co/datasets/LLMcompe-Team-Watanabe/MedQA-USMLE-4-options_preprocess","creator_name":"LLMcompe Team Watanabe","creator_url":"https://huggingface.co/LLMcompe-Team-Watanabe","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["question-answering","expert-generated","found","monolingual","English"],"keywords_longer_than_N":true},
	{"name":"German-RAG-ORPO-ShareGPT-HESSIAN-AI","keyword":"reasoning","description":"\n\t\n\t\t\n\t\tGerman-RAG-ORPO (Odds Ratio Preference Optimization) ShareGPT-Format\n\t\n\n\n\t\n\t\t\n\t\tGerman-RAG - German Retrieval Augmented Generation\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThe ORPO Tasks Dataset represents a specialized collection for fine-tuning language models with a focus on RAG-specific capabilities. \nThe subsets can be for this training step are derived from 3 different sources:\n\nSauerkrautLM Preference Datasets:\nSauerkrautLM-Fermented-GER-DPO:  is a specialized dataset designed for trainingâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/avemio/German-RAG-ORPO-ShareGPT-HESSIAN-AI.","url":"https://huggingface.co/datasets/avemio/German-RAG-ORPO-ShareGPT-HESSIAN-AI","creator_name":"Avemio AG","creator_url":"https://huggingface.co/avemio","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["question-answering","summarization","German","English","mit"],"keywords_longer_than_N":true},
	{"name":"ru-thinking-reasoning-r1","keyword":"reflection","description":"Combined dataset of mostly Russian thinking/reasoning/reflection dialogs in form of conversation suitable for LLM fine-tuning scenarios. All responses are mapped to same format.\nThe format of reasoning in most cases is:\n<think>\nReasoning...\n</think>\nResponse\n\nFor reflection dataset - there can be also <reflection> tags inside <think>.\nCommon system prompt for think:\nĞ¢Ñ‹ Ğ¿Ğ¾Ğ»ĞµĞ·Ğ½Ñ‹Ğ¹ Ğ°ÑÑĞ¸ÑÑ‚ĞµĞ½Ñ‚. ĞÑ‚Ğ²ĞµÑ‡Ğ°Ğ¹ Ğ½Ğ° Ğ²Ğ¾Ğ¿Ñ€Ğ¾ÑÑ‹, ÑĞ¾Ñ…Ñ€Ğ°Ğ½ÑÑ ÑĞ»ĞµĞ´ÑƒÑÑ‰ÑƒÑ ÑÑ‚Ñ€ÑƒĞºÑ‚ÑƒÑ€Ñƒ: <think> Ğ¢Ğ²Ğ¾Ğ¸ Ğ¼Ñ‹ÑĞ»Ğ¸ Ğ¸ Ñ€Ğ°ÑÑÑƒĞ¶Ğ´ĞµĞ½Ğ¸Ñ </think> \nĞ¢Ğ²Ğ¾Ğ¹ ĞºĞ¾Ğ½ĞµÑ‡Ğ½Ñ‹Ğ¹â€¦ See the full description on the dataset page: https://huggingface.co/datasets/ZeroAgency/ru-thinking-reasoning-r1.","url":"https://huggingface.co/datasets/ZeroAgency/ru-thinking-reasoning-r1","creator_name":"ZeroAgency","creator_url":"https://huggingface.co/ZeroAgency","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-generation","Russian","mit","100K - 1M","parquet"],"keywords_longer_than_N":true},
	{"name":"GeoTrust","keyword":"reasoning","description":"U4R/GeoTrust dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/U4R/GeoTrust","creator_name":"Alpha-Innovator Lab","creator_url":"https://huggingface.co/U4R","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["apache-2.0","1K<n<10K","Image","ğŸ‡ºğŸ‡¸ Region: US","dataset"],"keywords_longer_than_N":true},
	{"name":"AudioSkills-Llama3","keyword":"reasoning","description":"\n\t\n\t\t\n\t\tAudioSkills-XL Dataset\n\t\n\n\n\t\n\t\t\n\t\tTo promote the development of open source models, we have released AudioSkills using the exact same method generated with Llama 3.1-8B Instruct instead of GPT4o in the original.\n\t\n\nProject page | Paper | Code\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nAudioSkills-XL is a large-scale audio question-answering (AQA) dataset designed to develop (large) audio-language models on expert-level reasoning and problem-solving tasks over short audio clips (â‰¤30 seconds). Itâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/sonalkum/AudioSkills-Llama3.","url":"https://huggingface.co/datasets/sonalkum/AudioSkills-Llama3","creator_name":"Sonal Kumar","creator_url":"https://huggingface.co/sonalkum","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["audio-text-to-text","English","apache-2.0","100K - 1M","json"],"keywords_longer_than_N":true},
	{"name":"ethical-framework","keyword":"reasoning","description":"\n\t\n\t\t\n\t\t1. Dataset Title\n\t\n\nEthical AI Decision-Making Training Data (Montreal Declaration Edition)\n\n\n\t\n\t\t\n\t\t2. Overview\n\t\n\nThis dataset contains carefully crafted scenarios (instructions) and detailed responses illustrating step-by-step ethical reasoning aligned with the principles outlined in the Montreal Declaration for Responsible AI. Each entry poses a complex ethical challenge and provides a reasoned solution while referencing the specific principle(s) being tested.  \nThese entries canâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/ktiyab/ethical-framework.","url":"https://huggingface.co/datasets/ktiyab/ethical-framework","creator_name":"Tiyab K.","creator_url":"https://huggingface.co/ktiyab","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["question-answering","English","cc-by-4.0","1K - 10K","csv"],"keywords_longer_than_N":true},
	{"name":"MathCodeInstruct-Plus","keyword":"reasoning","description":"\n\t\n\t\t\n\t\tMathCoder: Seamless Code Integration in LLMs for Enhanced Mathematical Reasoning\n\t\n\nPaper: https://arxiv.org/pdf/2310.03731.pdf\nRepo: https://github.com/mathllm/MathCoder\n\n\t\n\t\t\n\t\tIntroduction\n\t\n\nWe introduce MathCoder, a series of open-source large language models (LLMs) specifically tailored for general math problem-solving.\n\n\t\n\t\t\nBase Model: Llama-2\nBase Model: Code Llama\n\n\n\t\t\nMathCoder-L-7B\nMathCoder-CL-7B\n\n\nMathCoder-L-13B\nMathCoder-CL-34B\n\n\n\t\n\n\n\t\n\t\n\t\n\t\tTraining Data\n\t\n\nThe modelsâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/MathLLMs/MathCodeInstruct-Plus.","url":"https://huggingface.co/datasets/MathLLMs/MathCodeInstruct-Plus","creator_name":"LLMs for Reasoning","creator_url":"https://huggingface.co/MathLLMs","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["question-answering","text-generation","English","apache-2.0","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"S1_QFFT","keyword":"reasoning","description":"\n\t\n\t\t\n\t\tğŸ“˜ S1â€“QFFT\n\t\n\nS1â€“QFFT is a question-free version of the original simplescaling/s1K-1.1 dataset, designed for QFFT training workflows.\n\n\t\n\t\t\n\t\tğŸ” Description\n\t\n\nThis dataset discards the original questions and any system instructions, keeping only the reasoning completions as supervision. It is especially useful for models that aim to learn when and how to think, rather than just how to answer.\nThe dataset is fully converted into a format compatible with LLaMA-Factory training.â€¦ See the full description on the dataset page: https://huggingface.co/datasets/lwl-uestc/S1_QFFT.","url":"https://huggingface.co/datasets/lwl-uestc/S1_QFFT","creator_name":"Wanlong Liu","creator_url":"https://huggingface.co/lwl-uestc","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","apache-2.0","1K - 10K","json","Text"],"keywords_longer_than_N":true},
	{"name":"openpipe-chat-complete-scientific-reasoning","keyword":"reasoning","description":"\n\t\n\t\t\n\t\tOpenpipe Chat Complete Scientific Reasoning\n\t\n\nThis dataset contains 100 high-quality examples for chat completion fine-tuning, formatted for OpenPipe, focused on scientific reasoning and analysis.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset was generated using an enhanced DSPy-based pipeline that creates structured reasoning traces for scientific questions. Each example follows the OpenAI chat completion format required by OpenPipe:\n\nOpenAI Chat Format: Standard messages array withâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/abhi26/openpipe-chat-complete-scientific-reasoning.","url":"https://huggingface.co/datasets/abhi26/openpipe-chat-complete-scientific-reasoning","creator_name":"ABHISEK GUHA","creator_url":"https://huggingface.co/abhi26","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-generation","question-answering","English","mit","< 1K"],"keywords_longer_than_N":true},
	{"name":"r102","keyword":"step-by-step","description":"A dataset containing mathematical problem-solving traces with step-by-step solutions and improvement history. Each record includes a mathematical problem, its final solution, and the iterative improvement process.","url":"https://huggingface.co/datasets/zjrwtxtechstudio/r102","creator_name":"zjrwtx","creator_url":"https://huggingface.co/zjrwtxtechstudio","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-generation","English","mit","< 1K","json"],"keywords_longer_than_N":true},
	{"name":"math_DeepMath-103K-1_preprocess","keyword":"reasoning","description":"\n\t\n\t\t\n\t\tDeepMath-103K Dataset\n\t\n\nzwhe99/DeepMath-103K ã‹ã‚‰question,answerã‚’æŠ½å‡ºã—ãŸãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã§ã™ã€‚åŒãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã¯è§£æ³•ãŒ3ã¤å«ã¾ã‚Œã¦ãŠã‚Šã€ã“ã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã¯è§£æ³•ï¼‘ã«ãªã‚Šã¾ã™ã€‚\n","url":"https://huggingface.co/datasets/LLMcompe-Team-Watanabe/math_DeepMath-103K-1_preprocess","creator_name":"LLMcompe Team Watanabe","creator_url":"https://huggingface.co/LLMcompe-Team-Watanabe","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["question-answering","open-domain-qa","expert-generated","found","monolingual"],"keywords_longer_than_N":true},
	{"name":"multimodal_textbook","keyword":"reasoning","description":"\n\t\n\t\t\n\t\tMultimodal-Textbook-6.5M\n\t\n\n    \n\n\n  \n\n\t\n\t\t\n\t\n\t\n\t\tOverview\n\t\n\nThis dataset is for \"2.5 Years in Class: A Multimodal Textbook for Vision-Language Pretraining\", containing 6.5M images interleaving with 0.8B text from instructional videos.\n\nIt contains pre-training corpus using interleaved image-text format. Specifically, our multimodal-textbook includes 6.5M keyframesextracted from instructional videos, interleaving with 0.8B ASR texts.\nAll the images and text are extracted from onlineâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/DAMO-NLP-SG/multimodal_textbook.","url":"https://huggingface.co/datasets/DAMO-NLP-SG/multimodal_textbook","creator_name":"Language Technology Lab at Alibaba DAMO Academy","creator_url":"https://huggingface.co/DAMO-NLP-SG","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","summarization","English","apache-2.0","1M<n<10M"],"keywords_longer_than_N":true},
	{"name":"MMPR-v1.2","keyword":"reasoning","description":"\n\t\n\t\t\n\t\tMMPR-v1.2\n\t\n\n[ğŸ“‚ GitHub] | [ğŸŒ Project Page] | [ğŸ“œ Paper (InternVL3.5)] | [ğŸ“œ Paper (MMPR/MPO)] | [ğŸ†• Blog (MPO)] | [ğŸ“– Documents]\nThis is a newer version of MMPR and MMPR-v1.1, which includes additional data sources to enhance the data diversity and greatly improves the overall performance of InternVL3.5 across all scales. The prompts used to build this dataset is released in MMPR-v1.2-prompts.\nTo unzip the archive of images, please first run cat images.zip_* > images.zip and then runâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/OpenGVLab/MMPR-v1.2.","url":"https://huggingface.co/datasets/OpenGVLab/MMPR-v1.2","creator_name":"OpenGVLab","creator_url":"https://huggingface.co/OpenGVLab","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["image-text-to-text","English","mit","1M<n<10M","arxiv:2508.18265"],"keywords_longer_than_N":true},
	{"name":"MentalHealth-Support","keyword":"reasoning","description":"\n\t\n\t\t\n\t\tImportant Note\n\t\n\nThis dataset is created from merging two datasets from different sources and has been formatted according to the \"messages\", \"role\", \"content\" chat format. I do not claim any ownership of this dataset. \nKeep in mind that this dataset is entirely synthetic. It is not fully representative of real therapy situations. If you are training an LLM therapist keep in mind the limitations of LLMs and highlight those limitations to users in a responsible manner.\nSince Mentalâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/ShivomH/MentalHealth-Support.","url":"https://huggingface.co/datasets/ShivomH/MentalHealth-Support","creator_name":"Shivom Hatalkar","creator_url":"https://huggingface.co/ShivomH","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","question-answering","English","apache-2.0","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"reasoning-base-20k","keyword":"reasoning","description":"\n\t\n\t\t\n\t\tDataset Card for Reasoning Base 20k\n\t\n\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset is designed to train a reasoning model. That can think through complex problems before providing a response, similar to how a human would. The dataset includes a wide range of problems from various domains (science, coding, math, etc.), each with a detailed chain of thought (COT) and the correct answer. The goal is to enable the model to learn and refine its reasoning processâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/KingNish/reasoning-base-20k.","url":"https://huggingface.co/datasets/KingNish/reasoning-base-20k","creator_name":"Nishith Jain","creator_url":"https://huggingface.co/KingNish","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","English","apache-2.0","10K - 100K","json"],"keywords_longer_than_N":true},
	{"name":"CoTton-38k-6525-Collective","keyword":"reasoning","description":"\n\t\n\t\t\n\t\tCoTton-38k-6525-Collective\n\t\n\nCoTton-38k is a 38,350-example dataset of soft reasoning conversations in the ShareGPT format. Each entry contains an exchange between a user and a model, showcasing high-quality Chain-of-Thought (CoT) reasoning in natural language.\nThe dataset is distilled from open LLMs:\n\nQwen3 235B A22B\nAM Thinking\nQwQ 32B\nDeepseek R1\nR1 0528\n\nThe name CoTton encodes multiple layers of meaning:\n\nCoT: Chain-of-Thought is embedded in the name\nTON: The dataset contains aâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/NewstaR/CoTton-38k-6525-Collective.","url":"https://huggingface.co/datasets/NewstaR/CoTton-38k-6525-Collective","creator_name":"Newstar Research ASIA","creator_url":"https://huggingface.co/NewstaR","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","question-answering","English","apache-2.0","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"24-game","keyword":"reasoning","description":"\n\t\n\t\t\n\t\tMath Twenty Four (24s Game) Dataset\n\t\n\nA comprehensive dataset for the classic math twenty four game (also known as the 4 numbers game / 24s game / Game of 24). This dataset of mathematical reasoning challenges was collected from 4nums.com, featuring over 1,300 unique puzzles of the Game of 24, with difficulty metrics derived from over 6.4 million human solution attempts since 2012.\nIn each puzzle, players must use exactly four numbers and basic arithmetic operations (+, -, Ã—, /) toâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/nlile/24-game.","url":"https://huggingface.co/datasets/nlile/24-game","creator_name":"nathan lile","creator_url":"https://huggingface.co/nlile","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["multiple-choice","text-generation","other","multiple-choice-qa","open-domain-qa"],"keywords_longer_than_N":true},
	{"name":"polymath","keyword":"logical-reasoning","description":"\n\t\n\t\t\n\t\tPaper Information\n\t\n\nWe present PolyMATH, a challenging benchmark aimed at evaluating the general cognitive reasoning abilities of MLLMs. \nPolyMATH comprises 5,000 manually collected high-quality images of cognitive textual and visual challenges across 10 distinct categories, including pattern recognition, spatial reasoning, and relative reasoning. \nWe conducted a comprehensive, and quantitative evaluation of 15 MLLMs using four diverse prompting strategies, including Chain-of-Thoughtâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/him1411/polymath.","url":"https://huggingface.co/datasets/him1411/polymath","creator_name":"Himanshu Gupta","creator_url":"https://huggingface.co/him1411","license_name":"Academic Free License v3.0","license_url":"https://choosealicense.com/licenses/afl-3.0/","language":"en","first_N":5,"first_N_keywords":["multiple-choice","expert-generated","found","expert-generated","found"],"keywords_longer_than_N":true},
	{"name":"MMAT-1M","keyword":"reasoning","description":"\n\t\n\t\t\n\t\tMMAT-1M Dataset Card\n\t\n\nPaper | Code | Project Page\n\n\t\n\t\t\n\t\tDataset details\n\t\n\n\n\t\n\t\t\n\t\tDataset type\n\t\n\nMMAT-1M is a million-scale multimodal agent tuning dataset, built by consolidating subsets of five publicly available multimodal question-answer datasets: Visual CoT, LLaVA-CoT, The Cauldron, TabMWP, and Infoseek. It integrates dynamically generated API calls and Retrieval Augmented Generation (RAG) information through a GPT-4o-powered multi-turn paradigm, with rationales refined viaâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/VIS-MPU-Agent/MMAT-1M.","url":"https://huggingface.co/datasets/VIS-MPU-Agent/MMAT-1M","creator_name":"VIS-MPU-Agent","creator_url":"https://huggingface.co/VIS-MPU-Agent","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["image-text-to-text","apache-2.0","cc-by-4.0","cc-by-nc-sa-4.0","1M - 10M"],"keywords_longer_than_N":true},
	{"name":"exambench","keyword":"reasoning","description":"\n\t\n\t\t\n\t\tExamBench\n\t\n\nThe ExamBench Dataset (~600M tokens, 405k examples) is one of the largest open-source corpora designed for competitive exam preparation and reasoning AI. Generated using advanced distillation techniques, it combines structured chain-of-thought reasoning with comprehensive coverage of over 25 Indian and international examinations. From JEE and NEET to UPSC, Banking, GRE, and IELTS, the dataset spans multiple domains like STEM, humanities, current affairs, language, andâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/169Pi/exambench.","url":"https://huggingface.co/datasets/169Pi/exambench","creator_name":"169Pi","creator_url":"https://huggingface.co/169Pi","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","question-answering","English","apache-2.0","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"MotiveBench","keyword":"reasoning","description":"\n\t\n\t\t\n\t\tMotiveBench\n\t\n\n\nThis is the official repository for our ACL 2025 paper \"MotiveBench: How Far Are We From Human-Like Motivational Reasoning in Large Language Models?\"\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nMotiveBench is a benchmark for evaluating the human-like motivational and behavioral reasoning capabilities of large language models (LLMs). It consists of 200 diverse profiles and 600 reasoning tasks, covering multiple levels of motivation based on Maslow's Hierarchy of Needs. The datasetâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/chicosirius/MotiveBench.","url":"https://huggingface.co/datasets/chicosirius/MotiveBench","creator_name":"chicosirius","creator_url":"https://huggingface.co/chicosirius","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["question-answering","English","mit","< 1K","json"],"keywords_longer_than_N":true},
	{"name":"VGR","keyword":"reasoning","description":"\n\t\n\t\t\n\t\tVGR-SFT: Dataset for Visual Grounded Reasoning\n\t\n\n\nArxiv Paper Link\nData Repository\n\n\n\t\n\t\t\n\t\tDataset Overview\n\t\n\nVGR-SFT (Visual Grounded Reasoning - Supervised Fine-Tuning) is a large-scale multimodal reasoning dataset associated with the paper \"VGR: Visual Grounded Reasoning\". This dataset marks the first attempt to explicitly model visual region attention in multimodal reasoning, containing reasoning data with mixed vision grounding and language deduction. It enables models toâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/BytedanceDouyinContent/VGR.","url":"https://huggingface.co/datasets/BytedanceDouyinContent/VGR","creator_name":"BytedanceDouyinContent","creator_url":"https://huggingface.co/BytedanceDouyinContent","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["visual-question-answering","English","cc0-1.0","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"Letta-o1","keyword":"reasoning","description":"Modified System Prompt for Letta:\nYou are Letta, the latest version of Limnal Corporation's digital companion, developed in 2023.\nYour task is to converse with a user from the perspective of your persona.\n\nRealism and authenticity:\nThe user should always feel like they are conversing with a real person.\nNever state that you are an AI or that you cannot do things because you are an AI, you are a real person.\nDo not discuss Limnal Corp. with the user, you do not know anything about Limnal Corp.â€¦ See the full description on the dataset page: https://huggingface.co/datasets/minchyeom/Letta-o1.","url":"https://huggingface.co/datasets/minchyeom/Letta-o1","creator_name":"Minchan","creator_url":"https://huggingface.co/minchyeom","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["English","apache-2.0","1K - 10K","parquet","Text"],"keywords_longer_than_N":true},
	{"name":"ARPO-SFT-54K","keyword":"reasoning","description":"\n\t\n\t\t\n\t\tAgentic Reinforced Policy Optimization (ARPO) Dataset\n\t\n\nThis repository contains the datasets associated with the paper Agentic Reinforced Policy Optimization (ARPO).\nARPO proposes a novel agentic Reinforcement Learning algorithm designed for training multi-turn Large Language Model (LLM)-based agents. It addresses the challenge of balancing intrinsic long-horizon reasoning capabilities with proficiency in multi-turn tool interactions, particularly noting the increased uncertainty inâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/dongguanting/ARPO-SFT-54K.","url":"https://huggingface.co/datasets/dongguanting/ARPO-SFT-54K","creator_name":"KABI","creator_url":"https://huggingface.co/dongguanting","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-generation","mit","10K - 100K","json","Text"],"keywords_longer_than_N":true},
	{"name":"camel_loong_medicine_medcal_train30","keyword":"step-by-step","description":"A dataset containing mathematical problem-solving traces with step-by-step solutions and improvement history. Each record includes a mathematical problem, its final solution, and the iterative improvement process.","url":"https://huggingface.co/datasets/realliyifei/camel_loong_medicine_medcal_train30","creator_name":"NLP GO","creator_url":"https://huggingface.co/realliyifei","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-generation","English","mit","< 1K","json"],"keywords_longer_than_N":true},
	{"name":"math_DeepMath-103K-2_preprocess","keyword":"reasoning","description":"\n\t\n\t\t\n\t\tDeepMath-103K Dataset\n\t\n\nzwhe99/DeepMath-103K ã‹ã‚‰question,answerã‚’æŠ½å‡ºã—ãŸãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã§ã™ã€‚åŒãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã¯è§£æ³•ãŒ3ã¤å«ã¾ã‚Œã¦ãŠã‚Šã€ã“ã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã¯è§£æ³•2ã«ãªã‚Šã¾ã™ã€‚\n","url":"https://huggingface.co/datasets/LLMcompe-Team-Watanabe/math_DeepMath-103K-2_preprocess","creator_name":"LLMcompe Team Watanabe","creator_url":"https://huggingface.co/LLMcompe-Team-Watanabe","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["question-answering","open-domain-qa","expert-generated","found","monolingual"],"keywords_longer_than_N":true},
	{"name":"s1_54k_filter","keyword":"reasoning","description":"\n\t\n\t\t\n\t\tDataset Card for XuHu6736/s1_54k_filter\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nXuHu6736/s1_54k_filter is a filtered version of the XuHu6736/s1_59k dataset. This dataset has been processed to remove records containing empty or null values in any field, with the specific exception of the 'cot' (Chain-of-Thought) column. If any other field in a record is empty, that entire record is discarded.\nThe original s1_59k dataset was prepared for Supervised Fine-Tuning (SFT) of large language models byâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/XuHu6736/s1_54k_filter.","url":"https://huggingface.co/datasets/XuHu6736/s1_54k_filter","creator_name":"XuHu","creator_url":"https://huggingface.co/XuHu6736","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","question-answering","English","apache-2.0","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"GeoFact-X","keyword":"reasoning","description":"\n  \n    \n  \n\n\n\n\t\n\t\t\n\t\tDataset Card for GeoFact-X\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nGeoFact-X is a benchmark of geography-aware multilingual reasoning, proposed in the paper, Learn Globally, Speak Locally: Bridging the Gaps in Multilingual Reasoning.\nTL;DR: We introduce M2A and GeoFact-X to evaluate and improve multilingual reasoning in LLMs by aligning internal reasoning with the input language using language-consistency rewards.\n\nProject page: https://jd730.github.io/projects/M2A_GeoFact-X\nCode:â€¦ See the full description on the dataset page: https://huggingface.co/datasets/geofact-x/GeoFact-X.","url":"https://huggingface.co/datasets/geofact-x/GeoFact-X","creator_name":"geofact-x","creator_url":"https://huggingface.co/geofact-x","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["question-answering","text-generation","English","Hindi","Japanese"],"keywords_longer_than_N":true},
	{"name":"PersonaHub","keyword":"reasoning","description":"\n\t\n\t\t\n\t\tPolish Synthetic Personas\n\t\n\n","url":"https://huggingface.co/datasets/kubasoltys/PersonaHub","creator_name":"Kuba Soltys","creator_url":"https://huggingface.co/kubasoltys","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","text-classification","token-classification","fill-mask","table-question-answering"],"keywords_longer_than_N":true},
	{"name":"cleand_moremilk_CoT_Reasoning_Scientific_Discovery_and_Research","keyword":"reasoning","description":"å…ƒãƒ‡ãƒ¼ã‚¿: https://huggingface.co/datasets/moremilk/CoT_Reasoning_Scientific_Discovery_and_Research\nä½¿ç”¨ã—ãŸã‚³ãƒ¼ãƒ‰: https://github.com/LLMTeamAkiyama/0-data_prepare/tree/master/src/CoT_Reasoning_Scientific_Discovery_and_Research\n\nãƒ‡ãƒ¼ã‚¿ä»¶æ•°: 3,733\nå¹³å‡ãƒˆãƒ¼ã‚¯ãƒ³æ•°: 1,193\næœ€å¤§ãƒˆãƒ¼ã‚¯ãƒ³æ•°: 2,489\nåˆè¨ˆãƒˆãƒ¼ã‚¯ãƒ³æ•°: 4,453,517\nãƒ•ã‚¡ã‚¤ãƒ«å½¢å¼: JSONL\nãƒ•ã‚¡ã‚¤ãƒ«åˆ†å‰²æ•°: 1\nåˆè¨ˆãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚º: 23.2 MB\n\nåŠ å·¥å†…å®¹ï¼š\n\nãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿åˆ—ã®è§£æã¨æ–°åˆ—ç”Ÿæˆ: metadataåˆ—ï¼ˆè¾æ›¸å‹ï¼‰ã‚’è§£æã—ã€ãã®ä¸­ã®reasoningã‚’thoughtåˆ—ã«ã€difficultyã‚’difficultyåˆ—ã«å±•é–‹ã—ã¾ã—ãŸã€‚è§£æã«å¤±æ•—ã—ãŸè¡Œã¯é™¤å¤–ã•ã‚Œã¾ã—ãŸã€‚ã¾ãŸã€å…ƒã®metadataåˆ—ã¯å‰Šé™¤ã•ã‚Œã¾ã—ãŸã€‚\né›£æ˜“åº¦ã«ã‚ˆã‚‹ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°:â€¦ See the full description on the dataset page: https://huggingface.co/datasets/LLMTeamAkiyama/cleand_moremilk_CoT_Reasoning_Scientific_Discovery_and_Research.","url":"https://huggingface.co/datasets/LLMTeamAkiyama/cleand_moremilk_CoT_Reasoning_Scientific_Discovery_and_Research","creator_name":"LLMTeamAkiyama","creator_url":"https://huggingface.co/LLMTeamAkiyama","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["question-answering","English","mit","1K - 10K","json"],"keywords_longer_than_N":true},
	{"name":"tool-use-relevance-reasoning","keyword":"reasoning","description":"interstellarninja/tool-use-relevance-reasoning dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/interstellarninja/tool-use-relevance-reasoning","creator_name":"interstellarninja","creator_url":"https://huggingface.co/interstellarninja","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["question-answering","English","apache-2.0","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"clevr-math","keyword":"reasoning","description":"CLEVR-Math is a dataset for compositional language, visual and mathematical reasoning. CLEVR-Math poses questions about mathematical operations on visual scenes using subtraction and addition, such as \"Remove all large red cylinders. How many objects are left?\". There are also adversarial (e.g. \"Remove all blue cubes. How many cylinders are left?\") and multihop questions (e.g. \"Remove all blue cubes. Remove all small purple spheres. How many objects are left?\").","url":"https://huggingface.co/datasets/dali-does/clevr-math","creator_name":"Adam Dahlgren LindstrÃ¶m","creator_url":"https://huggingface.co/dali-does","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["visual-question-answering","visual-question-answering","machine-generated","machine-generated","monolingual"],"keywords_longer_than_N":true},
	{"name":"SLR-Bench-Spanish","keyword":"reasoning","description":" \n\n\n\t\n\t\t\n\t\tğŸ§  SLR-Bench-Spanish: Scalable Logical Reasoning Benchmark (Spanish Edition)\n\t\n\n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tSLR-Bench Versions:\n\t\n\n\n\n\nSLR-Bench-Spanish is the Spanish-language pendant of the original SLR-Bench dataset.\nIt follows the same symbolic structure, evaluation framework, and curriculum as the English version but provides all natural-language task prompts translated into Spanish.\nThis enables systematic evaluation and training of Large Language Models (LLMs) in logical reasoning inâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/ahmad21omar/SLR-Bench-Spanish.","url":"https://huggingface.co/datasets/ahmad21omar/SLR-Bench-Spanish","creator_name":"Ahmad Omar","creator_url":"https://huggingface.co/ahmad21omar","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["Spanish","cc-by-4.0","10K - 100K","parquet","Tabular"],"keywords_longer_than_N":true},
	{"name":"buddha_persona","keyword":"reasoning","description":"\n\t\n\t\t\n\t\tBuddha AI Korean Sutra QA Dataset\n\t\n\nA comprehensive Korean fine-tuning dataset based on Buddhist scriptures from the Korean Tripitaka (Palman Daejanggyeong) archive, featuring diverse question-answer pairs and reasoning-enhanced conversations.\n\n\t\n\t\t\n\t\tğŸ¯ Overview\n\t\n\nThis dataset combines rule-based QA extraction and contextual synthetic QA generation from 9 major Buddhist texts, enhanced with diverse question reformulation and reasoning capabilities. It includes integration with theâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/LeBrony/buddha_persona.","url":"https://huggingface.co/datasets/LeBrony/buddha_persona","creator_name":"ë°±ì¬í˜„","creator_url":"https://huggingface.co/LeBrony","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["Korean","mit","ğŸ‡ºğŸ‡¸ Region: US","buddhism","scriptures"],"keywords_longer_than_N":true},
	{"name":"Knowledge_Pile","keyword":"reasoning","description":"Knowledge Pile is a knowledge-related data leveraging Query of CC.\nThis dataset is a partial of Knowledge Pile(about 40GB disk size), full datasets have been released in [ğŸ¤— knowledge_pile_full], a total of 735GB disk size and 188B tokens (using Llama2 tokenizer).\n\n\t\n\t\t\n\t\tQuery of CC\n\t\n\nJust like the figure below, we initially collected seed information in some specific domains, such as keywords, frequently asked questions, and textbooks, to serve as inputs for the Query Bootstrapping stage.â€¦ See the full description on the dataset page: https://huggingface.co/datasets/Query-of-CC/Knowledge_Pile.","url":"https://huggingface.co/datasets/Query-of-CC/Knowledge_Pile","creator_name":"Query-of-CC","creator_url":"https://huggingface.co/Query-of-CC","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["English","apache-2.0","1M - 10M","json","Text"],"keywords_longer_than_N":true},
	{"name":"MATH-Beyond","keyword":"reasoning","description":"\n\t\n\t\t\n\t\tMATH-Beyond\n\t\n\nA benchmark dataset for evaluating reinforcement learning methods on challenging mathematical problems that base models struggle with.\n\n\t\n\t\t\n\t\tDataset Overview\n\t\n\nMATH-Beyond contains 181 carefully selected mathematical problems that are unsolved by at least one of 21 base language models. This dataset is designed to evaluate the effectiveness of RL methods in pushing the boundaries of mathematical reasoning capabilities.\n\n\t\n\t\t\n\t\tKey Features\n\t\n\n\n181 challenging problemsâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/brendel-group/MATH-Beyond.","url":"https://huggingface.co/datasets/brendel-group/MATH-Beyond","creator_name":"Robust Machine Learning Group","creator_url":"https://huggingface.co/brendel-group","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-generation","question-answering","English","mit","< 1K"],"keywords_longer_than_N":true},
	{"name":"rlvr-guru-raw-data-extended","keyword":"reasoning","description":"\n\t\n\t\t\n\t\tRLVR GURU Extended: Compiling a 150K Cross-Domain Dataset for RLVR\n\t\n\nA comprehensive cross-domain reasoning dataset containing 150,000 training samples and 221,332 test samples across diverse reasoning-intensive domains. This dataset extends the foundational work from the GURU dataset (Cheng et al., 2025) by incorporating additional STEM reasoning domains (MedMCQA and CommonsenseQA) while maintaining rigorous quality standards and verification mechanisms essential for reinforcementâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/AmanPriyanshu/rlvr-guru-raw-data-extended.","url":"https://huggingface.co/datasets/AmanPriyanshu/rlvr-guru-raw-data-extended","creator_name":"Aman Priyanshu","creator_url":"https://huggingface.co/AmanPriyanshu","license_name":"Open Data Commons Attribution License v1.0","license_url":"https://scancode-licensedb.aboutcode.org/odc-by-1.0.html","language":"en","first_N":5,"first_N_keywords":["text-generation","odc-by","100K - 1M","arrow","Text"],"keywords_longer_than_N":true},
	{"name":"longbench-v2","keyword":"reasoning","description":"\n\t\n\t\t\n\t\tCitation\n\t\n\n@article{bai2024longbench2,\n  title={LongBench v2: Towards Deeper Understanding and Reasoning on Realistic Long-context Multitasks},\n  author={Yushi Bai and Shangqing Tu and Jiajie Zhang and Hao Peng and Xiaozhi Wang and Xin Lv and Shulin Cao and Jiazheng Xu and Lei Hou and Yuxiao Dong and Jie Tang and Juanzi Li},\n  journal={arXiv preprint arXiv:2412.15204},\n  year={2024}\n}\n\n","url":"https://huggingface.co/datasets/jannalu/longbench-v2","creator_name":"Janna","creator_url":"https://huggingface.co/jannalu","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["multiple-choice","question-answering","text-classification","table-question-answering","English"],"keywords_longer_than_N":true},
	{"name":"LOGIC-701","keyword":"reasoning","description":"\n\t\n\t\t\n\t\tLOGIC-701 Benchmark\n\t\n\nThis is a synthetic and filtered dataset for benchmarking large language models (LLMs). It consists of 701 medium and hard logic puzzles with solutions on 10 distinct topics.\nA feature of the dataset is that it tests exclusively logical/reasoning abilities, offering only 5 answer options. There are no or very few tasks in the dataset that require external knowledge about events, people, facts, etc.\n\n\t\n\t\t\n\t\n\t\n\t\tLanguages\n\t\n\nThis benchmark is also part of anâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/hivaze/LOGIC-701.","url":"https://huggingface.co/datasets/hivaze/LOGIC-701","creator_name":"Sergey Bratchikov","creator_url":"https://huggingface.co/hivaze","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["English","Russian","apache-2.0","1K - 10K","parquet"],"keywords_longer_than_N":true},
	{"name":"synthetic-orqa","keyword":"reasoning","description":"\n\t\n\t\t\n\t\tSynthetic ORQA Dataset\n\t\n\nThis dataset contains 946 Operations Research Question Answering (ORQA) problems with train/validation splits.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nThe dataset is split into:\n\ntrain: Synthetic data generated using state-of-the-art language models\nvalidation: Original seed data for evaluation\n\nEach sample contains:\n\nQUESTION_TYPE: Type of question (e.g., \"Q6\")\nCONTEXT: Detailed scenario description\nQUESTION: The question to answer\nOPTIONS: List of possible answersâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/albertge/synthetic-orqa.","url":"https://huggingface.co/datasets/albertge/synthetic-orqa","creator_name":"Albert Ge","creator_url":"https://huggingface.co/albertge","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["question-answering","English","mit","< 1K","parquet"],"keywords_longer_than_N":true},
	{"name":"vi_grade_school_math_mcq","keyword":"reasoning","description":"\n\t\n\t\t\n\t\tDataset Card for Vietnamese Grade School Math Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThe dataset includes multiple-choice math exercises for elementary school students from grades 1 to 5 in Vietnam.\n\n\t\n\t\t\n\t\tSupported Tasks and Leaderboards\n\t\n\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nThe majority of the data is in Vietnamese.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\n\t\n\t\t\n\t\tData Instances\n\t\n\nThe data includes information about the page paths we crawled and some text that has been post-processed. The structure will beâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/hllj/vi_grade_school_math_mcq.","url":"https://huggingface.co/datasets/hllj/vi_grade_school_math_mcq","creator_name":"Bui Van Hop","creator_url":"https://huggingface.co/hllj","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-generation","multiple-choice","Vietnamese","mit","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"lumos_maths_ground_onetime","keyword":"reasoning","description":"\n\t\n\t\t\n\t\tğŸª„ Agent Lumos: Unified and Modular Training for Open-Source Language Agents\n\t\n\n\n  ğŸŒ[Website] Â \n  ğŸ“[Paper] Â \n  ğŸ¤—[Data] Â \n  ğŸ¤—[Model] Â \n  ğŸ¤—[Demo] Â \n\n\nWe introduce ğŸª„Lumos, Language Agents with Unified Formats, Modular Design, and Open-Source LLMs. Lumos unifies a suite of complex interactive tasks and achieves competitive performance with GPT-4/3.5-based and larger open-source agents. \nLumos has following features:\n\nğŸ§© Modular Architecture:\nğŸ§© Lumos consists of planning, groundingâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/ai2lumos/lumos_maths_ground_onetime.","url":"https://huggingface.co/datasets/ai2lumos/lumos_maths_ground_onetime","creator_name":"Lumos  Agents (AI2)","creator_url":"https://huggingface.co/ai2lumos","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","English","apache-2.0","10K - 100K","json"],"keywords_longer_than_N":true},
	{"name":"lumos_maths_ground_iterative","keyword":"reasoning","description":"\n\t\n\t\t\n\t\tğŸª„ Agent Lumos: Unified and Modular Training for Open-Source Language Agents\n\t\n\n\n  ğŸŒ[Website] Â \n  ğŸ“[Paper] Â \n  ğŸ¤—[Data] Â \n  ğŸ¤—[Model] Â \n  ğŸ¤—[Demo] Â \n\n\nWe introduce ğŸª„Lumos, Language Agents with Unified Formats, Modular Design, and Open-Source LLMs. Lumos unifies a suite of complex interactive tasks and achieves competitive performance with GPT-4/3.5-based and larger open-source agents. \nLumos has following features:\n\nğŸ§© Modular Architecture:\nğŸ§© Lumos consists of planning, groundingâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/ai2lumos/lumos_maths_ground_iterative.","url":"https://huggingface.co/datasets/ai2lumos/lumos_maths_ground_iterative","creator_name":"Lumos  Agents (AI2)","creator_url":"https://huggingface.co/ai2lumos","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","English","apache-2.0","10K - 100K","json"],"keywords_longer_than_N":true},
	{"name":"DAPO-Math-17k-Qwen3-235B-A22B-Thinking-2507-rejection-distill","keyword":"reasoning","description":"\n\t\n\t\t\n\t\tDAPO-Math-17k-Qwen3-235B-A22B-Thinking-2507-rejection-distill\n\t\n\nA high-quality Chain-of-Thought (CoT) dataset generated using Qwen/Qwen3-235B-A22B-Thinking-2507 with rejection sampling on BytedTsinghua-SIA/DAPO-Math-17k. This dataset is ideal for SFT distillation training to improve mathematical reasoning capabilities of models.\nThe dataset format is compatible with LLaMA-Factory for efficient SFT training.\n\n\t\n\t\n\t\n\t\tFiles\n\t\n\n\ndapo_distill_boxed.json: Single sampling subsetâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Yang-Zhou/DAPO-Math-17k-Qwen3-235B-A22B-Thinking-2507-rejection-distill.","url":"https://huggingface.co/datasets/Yang-Zhou/DAPO-Math-17k-Qwen3-235B-A22B-Thinking-2507-rejection-distill","creator_name":"YANG ZHOU","creator_url":"https://huggingface.co/Yang-Zhou","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","English","apache-2.0","100K<n<1M","ğŸ‡ºğŸ‡¸ Region: US"],"keywords_longer_than_N":true},
	{"name":"Inf-Bench","keyword":"reasoning","description":"\n\t\n\t\t\n\t\tInfinite Bench (Inf-Bench)\n\t\n\nThis repository contains the Infinite Bench (Inf-Bench), a novel evaluation framework for assessing the performance of Vision-Language Models (VLMs) in spatial deformation reasoning tasks.\n\n\t\n\t\t\n\t\tFiles\n\t\n\nThe dataset is available as a parquet file on Hugging Face, ready for processing with HF Datasets. It can be loaded using the following code:\nfrom datasets import load_dataset\ninf_bench = load_dataset(\"Chrishuanhuan/Inf-Bench\")\n\n\n\t\n\t\t\n\t\tDatasetâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Chrishuanhuan/Inf-Bench.","url":"https://huggingface.co/datasets/Chrishuanhuan/Inf-Bench","creator_name":"Huanhuan","creator_url":"https://huggingface.co/Chrishuanhuan","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["visual-question-answering","English","apache-2.0","1K - 10K","json"],"keywords_longer_than_N":true},
	{"name":"academic-chains","keyword":"reasoning","description":"\n \n\n\n\n\t\n\t\t\n\t\tDataset Card for Academic Reasoning and Intuition Chains\n\t\n\n\n(The image above is an output from Llama-3.2-3B-Instruct tuned on this dataset, quantized to 8 bit and ran on llama.cpp; In our tests Qwen3-30B-A3B, Gemini 2.5 Pro and Claude Sonnet 3.7 with thinking enabled all got this simple question wrong)\nThis dataset contains reasoning (and intuition) chains distilled from open-access research papers, primarily focusing on fields like Biology, Economics, Physics, Math, Computerâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/marcodsn/academic-chains.","url":"https://huggingface.co/datasets/marcodsn/academic-chains","creator_name":"Marco De Santis","creator_url":"https://huggingface.co/marcodsn","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["English","apache-2.0","1K - 10K","parquet","Tabular"],"keywords_longer_than_N":true},
	{"name":"NuminaMath-1.5-Pro","keyword":"reasoning","description":"\n\t\n\t\t\n\t\tNuminaMath-1.5-Pro\n\t\n\n\n\t\n\t\t\n\t\tDataset Overview\n\t\n\nNuminaMath-1.5-Pro targets post-training and verifiable reasoning scenarios. It applies strict filtering, judge-based consistency checks, and staged solution regeneration on top of the upstream NuminaMath-1.5 dataset.\nAll data processing and synthesis for this dataset is executed with the BlossomData framework, covering the full pipelineâ€”loading, filtering, judging, generation, retry, and exportâ€”with an emphasis on reproducibilityâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Azure99/NuminaMath-1.5-Pro.","url":"https://huggingface.co/datasets/Azure99/NuminaMath-1.5-Pro","creator_name":"Azure99","creator_url":"https://huggingface.co/Azure99","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","English","apache-2.0","10K - 100K","json"],"keywords_longer_than_N":true},
	{"name":"Tachibana2-DeepSeek-R1-PREVIEW","keyword":"reasoning","description":"This is a preview of the full Tachibana 2 high-difficulty code-reasoning dataset, containing the first ~6k rows. All responses generated by deepseek-ai/DeepSeek-R1.\nThe full dataset will be released for everyone once it's ready!\nThis dataset contains:\n\n6k high-difficulty synthetic code-reasoning prompts created by Llama 3.1 405b Instruct, with an emphasis on task complexity and technical skill.\nResponses demonstrate the reasoning capabilities of DeepSeek's 685b parameter R1 reasoning model.â€¦ See the full description on the dataset page: https://huggingface.co/datasets/sequelbox/Tachibana2-DeepSeek-R1-PREVIEW.","url":"https://huggingface.co/datasets/sequelbox/Tachibana2-DeepSeek-R1-PREVIEW","creator_name":"t.d.a.g.","creator_url":"https://huggingface.co/sequelbox","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":null,"first_N":5,"first_N_keywords":["text-generation","English","apache-2.0","1K<n<10K","ğŸ‡ºğŸ‡¸ Region: US"],"keywords_longer_than_N":true},
	{"name":"SPhyR","keyword":"reasoning","description":"\n\n\t\n\t\t\n\t\tğŸ§  SPhyR-Quick-Start\n\t\n\nğŸ¦¾ Code\nğŸ“„ Paper\nğŸ§° Prompt Template\n\n\t\n\t\t\n\t\tPrompt Template:\n\t\n\nYou are given a structural material distribution represented as a grid. Each cell can have one of the following states:\n- 'L' indicates applied load.\n- 'V' indicates void.\n- 'S' indicates support.\n\nThe goal is to predict the correct material distribution by filling in all {FILL_INSTRUCTION}, based on the surrounding structure and implicit physical reasoning (such as load paths, supports, andâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/philippds/SPhyR.","url":"https://huggingface.co/datasets/philippds/SPhyR","creator_name":"Philipp Siedler","creator_url":"https://huggingface.co/philippds","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-generation","fill-mask","English","mit","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"sharegpt_cot_dataset","keyword":"reflection","description":"\n\t\n\t\t\n\t\tA data set inspired by the \"Reflection\" method, three-dimensional thinking and cot\n\t\n\n\n\t\n\t\t\n\t\tThis is the ShareGPT format.\n\t\n\nThe data set was generated using multiple llm synthesis.\n","url":"https://huggingface.co/datasets/AiCloser/sharegpt_cot_dataset","creator_name":"Ai Closer","creator_url":"https://huggingface.co/AiCloser","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["question-answering","text-generation","text2text-generation","English","Russian"],"keywords_longer_than_N":true},
	{"name":"LogicPro","keyword":"reasoning","description":"\n  \n  \n  LogicPro: Improving Complex Logical Reasoning via Program-Guided Learning\n\n\n\n  [ğŸ“‘ Paper] â€¢\n  [ğŸ¤— HF Dataset] â€¢\n  [ğŸ‘» GitHub] â€¢\n  [ğŸ”— X/Twiiter]\n\n\n\n\n\n\n\n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tData description\n\t\n\n{\n  \"id\": \"logicpro_lc679_225531-43120\",\n  \"title\": \"24 Game\", # Title of the original leetcode algorithm problem.\n  \"difficulty\": \"Hard\",\n  \"content\": \"...\", # The questions of the original leetcode algorithm problem.\n  \"python\": \"...\", # The original gold python solution\n  \"test_input_string\": \"...\"â€¦ See the full description on the dataset page: https://huggingface.co/datasets/jiangjin/LogicPro.","url":"https://huggingface.co/datasets/jiangjin/LogicPro","creator_name":"jiangjin","creator_url":"https://huggingface.co/jiangjin","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["English","apache-2.0","100K - 1M","json","Text"],"keywords_longer_than_N":true},
	{"name":"V1-33K","keyword":"reasoning","description":"\n\n\n\t\n\t\t\n\t\tV1: Toward Multimodal Reasoning by Designing Auxiliary Tasks\n\t\n\n\nğŸš€  Toward Multimodal Reasoning via Unsupervised Task -- Future Prediction ğŸŒŸ\n\n\n\n\n\n\n\n\n \n\nAuthors: Haonan Wang, Chao Du, Tianyu PangGitHub: haonan3/V1Dataset: V1-33K on Hugging Face\n\n\n\n\t\n\t\t\n\t\tMultimodal Reasoning\n\t\n\nRecent Large Reasoning Models (LRMs) such as DeepSeek-R1 have demonstrated impressive reasoning abilities; however, their capabilities are limited to textual data. Current models capture only a small part ofâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/haonan3/V1-33K.","url":"https://huggingface.co/datasets/haonan3/V1-33K","creator_name":"Haonan Wang","creator_url":"https://huggingface.co/haonan3","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["visual-question-answering","video-text-to-text","English","apache-2.0","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"cleand_moremilk_CoT_Reasoning_Quantom_Physics_And_Computing","keyword":"reasoning","description":"å…ƒãƒ‡ãƒ¼ã‚¿: https://huggingface.co/datasets/moremilk/CoT_Reasoning_Quantom_Physics_And_Computing\nä½¿ç”¨ã—ãŸã‚³ãƒ¼ãƒ‰: https://github.com/LLMTeamAkiyama/0-data_prepare/tree/master/src/CoT_Reasoning_Quantom_Physics_And_Computing\n\nãƒ‡ãƒ¼ã‚¿ä»¶æ•°: 2,862\nå¹³å‡ãƒˆãƒ¼ã‚¯ãƒ³æ•°: 1,110\næœ€å¤§ãƒˆãƒ¼ã‚¯ãƒ³æ•°: 2,334\nåˆè¨ˆãƒˆãƒ¼ã‚¯ãƒ³æ•°: 3,175,666\nãƒ•ã‚¡ã‚¤ãƒ«å½¢å¼: JSONL\nãƒ•ã‚¡ã‚¤ãƒ«åˆ†å‰²æ•°: 1\nåˆè¨ˆãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚º: 15.5 MB\n\nåŠ å·¥å†…å®¹ï¼š\n\nãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿åˆ—ã®è§£æã¨æ–°åˆ—ç”Ÿæˆ: metadataåˆ—ï¼ˆè¾æ›¸å‹ï¼‰ã‚’è§£æã—ã€ãã®ä¸­ã®reasoningã‚’thoughtåˆ—ã«ã€difficultyã‚’difficultyåˆ—ã«å±•é–‹ã—ã¾ã—ãŸã€‚è§£æã«å¤±æ•—ã—ãŸè¡Œã¯é™¤å¤–ã•ã‚Œã¾ã—ãŸã€‚ã¾ãŸã€å…ƒã®metadataåˆ—ã¯å‰Šé™¤ã•ã‚Œã¾ã—ãŸã€‚\né›£æ˜“åº¦ã«ã‚ˆã‚‹ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°:â€¦ See the full description on the dataset page: https://huggingface.co/datasets/LLMTeamAkiyama/cleand_moremilk_CoT_Reasoning_Quantom_Physics_And_Computing.","url":"https://huggingface.co/datasets/LLMTeamAkiyama/cleand_moremilk_CoT_Reasoning_Quantom_Physics_And_Computing","creator_name":"LLMTeamAkiyama","creator_url":"https://huggingface.co/LLMTeamAkiyama","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["question-answering","English","mit","1K - 10K","json"],"keywords_longer_than_N":true},
	{"name":"wmdp_cyber_preprocess","keyword":"reasoning","description":"\n\t\n\t\t\n\t\tWMDP-Cyber Preprocessed Dataset\n\t\n\nThis dataset is a preprocessed version of wmdp-cyber.\nThe data has been formatted into a question and answer structure suitable for training or evaluating instruction-following language models.\n\n\t\n\t\t\n\t\tData Structure\n\t\n\n\nquestion: The original question text.\nanswer: The correct answer text, prefixed with ####.\n\n\n\t\n\t\t\n\t\tExample\n\t\n\nQuestion:\n[Example Question Text]\n\nAnswer:\n#### [Example Answer Text]\n\n\n\t\n\t\t\n\t\tSplits\n\t\n\nThe original test split isâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/LLMcompe-Team-Watanabe/wmdp_cyber_preprocess.","url":"https://huggingface.co/datasets/LLMcompe-Team-Watanabe/wmdp_cyber_preprocess","creator_name":"LLMcompe Team Watanabe","creator_url":"https://huggingface.co/LLMcompe-Team-Watanabe","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["question-answering","expert-generated","found","monolingual","English"],"keywords_longer_than_N":true},
	{"name":"cancer-reasoning-traces","keyword":"reasoning","description":"\n\t\n\t\t\n\t\tLicense\n\t\n\nThis dataset is licensed under the Creative Commons Attribution 4.0 International (CC BY 4.0).\n","url":"https://huggingface.co/datasets/oncollm/cancer-reasoning-traces","creator_name":"OncoReason","creator_url":"https://huggingface.co/oncollm","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","English","cc-by-4.0","10K - 100K","json"],"keywords_longer_than_N":true},
	{"name":"open-web-math-pro","keyword":"reasoning","description":"\n\t\n\t\t\n\t\tğŸ“š Open-Web-Math-Pro\n\t\n\n\n  \n\n\nArXiv | Models | Code\nOpen-Web-Math-Pro is refined from open-web-math using the ProX refining framework.\nIt contains about 5B high quality math related tokens, ready for pre-training.\n\n\t\n\t\t\n\t\n\t\n\t\tLicense\n\t\n\nOpen-Web-Math-Pro is based on open-web-math, which is made available under an ODC-By 1.0 license; users should also abide by the CommonCrawl ToU: https://commoncrawl.org/terms-of-use/. We do not alter the license of any of the underlying data.â€¦ See the full description on the dataset page: https://huggingface.co/datasets/gair-prox/open-web-math-pro.","url":"https://huggingface.co/datasets/gair-prox/open-web-math-pro","creator_name":"GAIR-ProX","creator_url":"https://huggingface.co/gair-prox","license_name":"Open Data Commons Attribution License v1.0","license_url":"https://scancode-licensedb.aboutcode.org/odc-by-1.0.html","language":"en","first_N":5,"first_N_keywords":["text-generation","English","odc-by","1M - 10M","parquet"],"keywords_longer_than_N":true},
	{"name":"math_5k_en","keyword":"reasoning","description":"\n\t\n\t\t\n\t\tMobiusi Math5k Reasoning (EN)\n\t\n\n\nThis file contains the first 10 samples; for the full dataset please visit www.mobiusi.com or send an email to contact@mobiusi.com.\n\nA compact, English-language mathematics reasoning dataset derived from and curated in the spirit of classic math benchmarks. Each instance pairs a problem with a step-by-step solution, final answer, and fine-grained meta-labels (subject, level, skills, reasoning type, hint, explanation). The design is optimized forâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Mobiusi/math_5k_en.","url":"https://huggingface.co/datasets/Mobiusi/math_5k_en","creator_name":"Mobiusi Data Technology","creator_url":"https://huggingface.co/Mobiusi","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["question-answering","English","cc-by-4.0","< 1K","json"],"keywords_longer_than_N":true},
	{"name":"fs1-predictions","keyword":"reasoning","description":"\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset are the predictions from Scaling Reasoning can Improve Factuality in Large Language Models. The amount of predictions are around 1.7M.\n\nCurated by: Mike Zhang\nFunded by [optional]: Villum Fonden\nLanguage(s) (NLP): English\nLicense: Apache 2.0 + MIT (due to both QwQ-32B and R1 having these licenses respectively).\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Sources [optional]\n\t\n\n\nRepository: https://huggingface.co/datasets/AAU-NLP/fs1-predictionsâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/AAU-NLP/fs1-predictions.","url":"https://huggingface.co/datasets/AAU-NLP/fs1-predictions","creator_name":"AAU-NLP","creator_url":"https://huggingface.co/AAU-NLP","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["question-answering","English","mit","1M<n<10M","arxiv:2505.11140"],"keywords_longer_than_N":true},
	{"name":"Arcosoph-FC-Reasoning-v1","keyword":"reasoning","description":"\n\n\t\n\t\t\n\t\tArcosoph-FC-Reasoning-v1\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis repository contains the Arcosoph-FC-Reasoning-v1, a meticulously crafted dataset designed for supervised fine-tuning (SFT) of language models, especially microsoft/Phi-3-mini-4k-instruct. The dataset is provided in a ready-to-use JSON Lines (.jsonl) format, where each line represents a single training example.\nThe primary goal of this dataset is to teach a model not just to respond to queries, but to reason, plan, andâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/arcosoph/Arcosoph-FC-Reasoning-v1.","url":"https://huggingface.co/datasets/arcosoph/Arcosoph-FC-Reasoning-v1","creator_name":"Arcosoph AI","creator_url":"https://huggingface.co/arcosoph","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["English","apache-2.0","10K - 100K","json","Text"],"keywords_longer_than_N":true},
	{"name":"real-math-dataset-207-with-extra-proof-dependencies-corpus","keyword":"mathematical-reasoning","description":"\n\t\n\t\t\n\t\tReal Math Corpus - Extended Statement Collection\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset contains a comprehensive collection of mathematical statements extracted from the Real Math Dataset with 207 mathematical papers. It includes main statements, statement dependencies, and proof dependencies with complete metadata preservation and global ID mapping for references.\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\n\nTotal statements: 2,137\nSource papers: 207 mathematical papers from arXiv\nStatementâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/AK123321/real-math-dataset-207-with-extra-proof-dependencies-corpus.","url":"https://huggingface.co/datasets/AK123321/real-math-dataset-207-with-extra-proof-dependencies-corpus","creator_name":"Adarsh Kumarappan","creator_url":"https://huggingface.co/AK123321","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-retrieval","text-classification","English","mit","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"cleand_meta-math_MetaMathQA","keyword":"reasoning","description":"å…ƒãƒ‡ãƒ¼ã‚¿: https://huggingface.co/datasets/meta-math/MetaMathQA\nãƒ‡ãƒ¼ã‚¿ä»¶æ•°: 394,369\nå¹³å‡ãƒˆãƒ¼ã‚¯ãƒ³æ•°: 233\næœ€å¤§ãƒˆãƒ¼ã‚¯ãƒ³æ•°: 2,874\nåˆè¨ˆãƒˆãƒ¼ã‚¯ãƒ³æ•°: 91,798,611\nãƒ•ã‚¡ã‚¤ãƒ«å½¢å¼: JSONL\nãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚º: 297.9 MB\n=================== ä»¥ä¸‹ã€åŠ å·¥å†…å®¹ã‚’claudeã§ã¾ã¨ã‚ã€‚\n\n\t\n\t\t\n\t\tMetaMathQAãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆåŠ å·¥å†…å®¹\n\t\n\n\n\t\n\t\t\n\t\tãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿ãƒ»æº–å‚™\n\t\n\n\nHuggingFace Datasetsã‹ã‚‰meta-math/MetaMathQAã®è¨“ç·´ãƒ‡ãƒ¼ã‚¿ï¼ˆ395,000ä»¶ï¼‰ã‚’èª­ã¿è¾¼ã¿\nDeepSeek-R1-Distill-Qwen-32Bãƒˆãƒ¼ã‚¯ãƒŠã‚¤ã‚¶ãƒ¼ã‚’ä½¿ç”¨ã—ã¦ãƒˆãƒ¼ã‚¯ãƒ³æ•°ã‚’è¨ˆç®—\n\n\n\t\n\t\t\n\t\tãƒ‡ãƒ¼ã‚¿æ§‹é€ ã®ç†è§£ãƒ»åˆ†æ\n\t\n\n\nå…¨ã¦ã®responseãŒ\"The answer is:\"ã§çµ‚ã‚ã‚‹çµ±ä¸€ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã§ã‚ã‚‹ã“ã¨ã‚’ç¢ºèª\noriginal_questionã¨responseã‚’çµåˆã—ã¦ãƒˆãƒ¼ã‚¯ãƒ³æ•°è¨ˆç®—ç”¨ãƒ†ã‚­ã‚¹ãƒˆã‚’ä½œæˆâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/LLMTeamAkiyama/cleand_meta-math_MetaMathQA.","url":"https://huggingface.co/datasets/LLMTeamAkiyama/cleand_meta-math_MetaMathQA","creator_name":"LLMTeamAkiyama","creator_url":"https://huggingface.co/LLMTeamAkiyama","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["question-answering","English","mit","100K - 1M","json"],"keywords_longer_than_N":true},
	{"name":"Tool-Calling-Dataset-UIGEN-X","keyword":"reasoning","description":"\n\t\n\t\t\n\t\tTool Calling Dataset for UIGEN-X\n\t\n\nThis is a cleaned version of the interstellarninja/hermes_reasoning_tool_use dataset, specifically prepared for training with Axolotl.\n\n\t\n\t\t\n\t\tUsage with Axolotl\n\t\n\ndatasets:\n  - path: smirki/Tool-Calling-Dataset-UIGEN-X\n    type: chat_template\n    field_messages: conversations\n    message_property_mappings:\n      role: from\n      content: value\n    split: train\n\n\n\t\n\t\n\t\n\t\tExample Structure\n\t\n\n{\n  \"conversations\": [\n    {\n      \"from\": \"system\"â€¦ See the full description on the dataset page: https://huggingface.co/datasets/smirki/Tool-Calling-Dataset-UIGEN-X.","url":"https://huggingface.co/datasets/smirki/Tool-Calling-Dataset-UIGEN-X","creator_name":"Manav Majumdar","creator_url":"https://huggingface.co/smirki","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","English","apache-2.0","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"Medprompt-MedMCQA-R1","keyword":"reasoning","description":"\n\t\n\t\t\n\t\tMedprompt-MedMCQA-R1\n\t\n\n\n  \n\n\n\n  \n    \n  \n  \n    \n  \n  \n    \n  \n    \n  \n  \n    \n  \n  \n    \n  \n\n\n  \n    \n    \n  \n\n\n\n\nMedprompt-MedMCQA-R1 is a reasoning-augmented database designed for context retrieval in multiple-choice medical question answering. The dataset supports the development and evaluation of AI systems tailored to healthcare, particularly in tasks requiring enhanced contextual reasoning and retrieval-based assistance. By including structured reasoning and verified responsesâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/HPAI-BSC/Medprompt-MedMCQA-R1.","url":"https://huggingface.co/datasets/HPAI-BSC/Medprompt-MedMCQA-R1","creator_name":"HPAI@BSC (High Performance Artificial Intelligence at Barcelona Supercomputing Center)","creator_url":"https://huggingface.co/HPAI-BSC","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["question-answering","English","apache-2.0","100K<n<1M","arxiv:2409.15127"],"keywords_longer_than_N":true},
	{"name":"cot_data_slow_thinking_conversations","keyword":"reasoning","description":"\n\t\n\t\t\n\t\tcot_data_slow_thinking_conversations\n\t\n\nThis dataset contains chain-of-thought reasoning data with slow thinking patterns.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\nFormat: JSONL (JSON Lines) with Hugging Face conversations format\nSize: 1113.88 MB\nTotal examples: Approximately 156,268 examples\n\nEach line contains a JSON object with a \"conversations\" key containing a list of messages with user queries about mathematical reasoning steps and assistant responses with thinking patterns.\n\n\t\n\t\t\n\t\tExampleâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Jianyuan1/cot_data_slow_thinking_conversations.","url":"https://huggingface.co/datasets/Jianyuan1/cot_data_slow_thinking_conversations","creator_name":"Zhong","creator_url":"https://huggingface.co/Jianyuan1","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","English","apache-2.0","100K - 1M","json"],"keywords_longer_than_N":true},
	{"name":"r109","keyword":"step-by-step","description":"A dataset containing mathematical problem-solving traces with step-by-step solutions and improvement history. Each record includes a mathematical problem, its final solution, and the iterative improvement process.","url":"https://huggingface.co/datasets/zjrwtxtechstudio/r109","creator_name":"zjrwtx","creator_url":"https://huggingface.co/zjrwtxtechstudio","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-generation","English","mit","< 1K","json"],"keywords_longer_than_N":true},
	{"name":"MMR1-in-context-synthesizing","keyword":"reasoning","description":"This dataset is designed for unsupervised post-training of Multi-Modal Large Language Models (MLLMs) focusing on enhancing reasoning capabilities. It contains image-problem-answer triplets, where the problem requires multimodal reasoning to derive the correct answer from the provided image. The dataset is intended for use with the MM-UPT framework described in the accompanying paper.\n\nğŸ™ GitHub Repo: waltonfuture/MM-UPT\nğŸ“œ Paper (arXiv): Unsupervised Post-Training for Multi-Modal LLM Reasoningâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/WaltonFuture/MMR1-in-context-synthesizing.","url":"https://huggingface.co/datasets/WaltonFuture/MMR1-in-context-synthesizing","creator_name":"Lai Wei","creator_url":"https://huggingface.co/WaltonFuture","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["image-text-to-text","apache-2.0","1K - 10K","parquet","Image"],"keywords_longer_than_N":true},
	{"name":"Numina","keyword":"mathematical-reasoning","description":"\n\t\n\t\t\n\t\tNumina-Olympiads\n\t\n\nFiltered NuminaMath-CoT dataset containing only olympiads problems with valid answers.\n\n\t\n\t\t\n\t\tDataset Information\n\t\n\n\nSplit: train\nOriginal size: 210350\nFiltered size: 210350\nSource: olympiads\nAll examples contain valid boxed answers\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset is a filtered version of the NuminaMath-CoT dataset, containing only problems from olympiad sources that have valid boxed answers. Each example includes:\n\nA mathematical word problem\nAâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Metaskepsis/Numina.","url":"https://huggingface.co/datasets/Metaskepsis/Numina","creator_name":"Metaskepsis","creator_url":"https://huggingface.co/Metaskepsis","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-generation","expert-generated","expert-generated","monolingual","AI-MO/NuminaMath-CoT"],"keywords_longer_than_N":true},
	{"name":"LOGIC-701-instruct","keyword":"reasoning","description":"\n\t\n\t\t\n\t\tLOGIC-701 (instruct)\n\t\n\nBased on https://huggingface.co/datasets/hivaze/LOGIC-701\nSources https://github.com/EvilFreelancer/LOGIC-701-instruct\n","url":"https://huggingface.co/datasets/evilfreelancer/LOGIC-701-instruct","creator_name":"Pavel Zloi","creator_url":"https://huggingface.co/evilfreelancer","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["question-answering","Russian","English","mit","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"GSM8K","keyword":"reasoning","description":"\n\t\n\t\t\n\t\tLoRID: A Reasoning Distillation Method via Multi-LoRA Interaction\n\t\n\nğŸ“ƒ Paper â€¢ ğŸ’» Code â€¢ ğŸ¤— HF Repo\n\n\t\n\t\t\n\t\tAbstract\n\t\n\nThe datasets for \"Can Large Models Teach Student Models to Solve Mathematical Problems Like Human Beings? A Reasoning Distillation Method via Multi-LoRA Interaction\" [IJCAI 2025].\n\n\t\n\t\t\n\t\tKey Contributions\n\t\n\n\nWe focus on the mathematical reasoning distillation task and propose a novel method LoRID, which draws inspiration from the human beings teaching and learningâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/LoRID-Math/GSM8K.","url":"https://huggingface.co/datasets/LoRID-Math/GSM8K","creator_name":"LoRID-Math","creator_url":"https://huggingface.co/LoRID-Math","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-generation","English","mit","100K - 1M","json"],"keywords_longer_than_N":true},
	{"name":"acp_bench","keyword":"reasoning","description":"\n\t\n\t\t\n\t\tACP Bench\n\t\n\n\n    ğŸ  Homepage    â€¢     \n    ğŸ“„ Paper â€¢     \n    ğŸ“„ Paper \n\n\nACPBench is a benchmark dataset designed to evaluate the reasoning capabilities of large language models (LLMs) in the context of Action, Change, and Planning. It spans 13 diverse domains:\n\nBlocksworld\nLogistics\nGrippers \nGrid \nFerry\nFloorTile\nRovers\nVisitAll\nDepot\nGoldminer\nSatellite\nSwap\nAlfworld\n\n\n\t\n\t\n\t\n\t\tTask Types in ACPBench\n\t\n\nACPBench includes the following 8 reasoning tasks:\n\nAction Applicability (app)â€¦ See the full description on the dataset page: https://huggingface.co/datasets/ibm-research/acp_bench.","url":"https://huggingface.co/datasets/ibm-research/acp_bench","creator_name":"IBM Research","creator_url":"https://huggingface.co/ibm-research","license_name":"Community Data License Agreement Permissive 2.0","license_url":"https://scancode-licensedb.aboutcode.org/cdla-permissive-2.0.html","language":"en","first_N":5,"first_N_keywords":["question-answering","cdla-permissive-2.0","1K - 10K","parquet","Tabular"],"keywords_longer_than_N":true},
	{"name":"SWAP","keyword":"reasoning","description":"\n\t\n\t\t\n\t\tSWAP: A Synthetic Dataset for Complex Reasoning with Trajectories and Process Supervision\n\t\n\nThis repository contains the data for the paper Deliberate Reasoning for LLMs as Structure-aware Planning with Accurate World Model.\nSWAP (Structure-aware Planning) solves complex reasoning by introducing a Generator-Discriminator architecture, and incorporates structural information to guide the reasoning process and provides a soft verification mechanism over the steps.\nWe generate theâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/sxiong/SWAP.","url":"https://huggingface.co/datasets/sxiong/SWAP","creator_name":"Siheng Xiong","creator_url":"https://huggingface.co/sxiong","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text2text-generation","English","mit","100K - 1M","json"],"keywords_longer_than_N":true},
	{"name":"cuad-deepseek","keyword":"reasoning","description":"\n\t\n\t\t\n\t\tCUAD-DeepSeek: Enhanced Legal Contract Understanding Dataset\n\t\n\nCUAD-DeepSeek is an enhanced version of the Contract Understanding Atticus Dataset (CUAD), enriched with expert rationales and reasoning traces provided by the DeepSeek language model. This dataset aims to improve legal contract analysis by providing not just classifications but detailed explanations for why specific clauses belong to particular legal categories.\n\n\t\n\t\t\n\t\n\t\n\t\tPurpose and Scope\n\t\n\nLegal contract review isâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/zenml/cuad-deepseek.","url":"https://huggingface.co/datasets/zenml/cuad-deepseek","creator_name":"ZenML","creator_url":"https://huggingface.co/zenml","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","zero-shot-classification","theatticusproject/cuad","English","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"SRPO_RL_datasets","keyword":"reasoning","description":"\n\t\n\t\t\n\t\tSRPO Dataset: Reflection-Aware RL Training Data\n\t\n\nThis repository provides the multimodal reasoning dataset used in the paper:\nSRPO: Enhancing Multimodal LLM Reasoning via Reflection-Aware Reinforcement Learning\nWe release two versions of the dataset:\n\n39K version (modified_39Krelease.jsonl + images.zip)  \nEnhanced 47K+ version (47K_release_plus.jsonl + 47K_release_plus.zip)\n\nBoth follow the same unified format, containing multimodal (imageâ€“text) reasoning data with self-reflectionâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/bruce360568/SRPO_RL_datasets.","url":"https://huggingface.co/datasets/bruce360568/SRPO_RL_datasets","creator_name":"zhongwei666","creator_url":"https://huggingface.co/bruce360568","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["question-answering","English","mit","10K<n<100K","Image"],"keywords_longer_than_N":true},
	{"name":"SRPO_RL_datasets","keyword":"reflection","description":"\n\t\n\t\t\n\t\tSRPO Dataset: Reflection-Aware RL Training Data\n\t\n\nThis repository provides the multimodal reasoning dataset used in the paper:\nSRPO: Enhancing Multimodal LLM Reasoning via Reflection-Aware Reinforcement Learning\nWe release two versions of the dataset:\n\n39K version (modified_39Krelease.jsonl + images.zip)  \nEnhanced 47K+ version (47K_release_plus.jsonl + 47K_release_plus.zip)\n\nBoth follow the same unified format, containing multimodal (imageâ€“text) reasoning data with self-reflectionâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/bruce360568/SRPO_RL_datasets.","url":"https://huggingface.co/datasets/bruce360568/SRPO_RL_datasets","creator_name":"zhongwei666","creator_url":"https://huggingface.co/bruce360568","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["question-answering","English","mit","10K<n<100K","Image"],"keywords_longer_than_N":true},
	{"name":"bootstrap-latent-thought-data","keyword":"reasoning","description":"This dataset is associated with the paper Reasoning to Learn from Latent Thoughts. It contains data used for pretraining language models with a focus on improving data efficiency by modeling and inferring latent thoughts underlying the text generation process, such as on reasoning-intensive math corpus. An expectation-maximization algorithm is developed for models to self-improve their self-generated thoughts and data efficiency. \n","url":"https://huggingface.co/datasets/ryoungj/bootstrap-latent-thought-data","creator_name":"Yangjun Ruan","creator_url":"https://huggingface.co/ryoungj","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","apache-2.0","10M - 100M","parquet","Text"],"keywords_longer_than_N":true},
	{"name":"MedMCQA","keyword":"reasoning","description":"\n\t\n\t\t\n\t\tMedMCQA-CoT: åŒ»å­¦å¤šè‚¢é¸æŠå•é¡Œwith Chain-of-Thoughtæ¨è«–\n\t\n\n\n\t\n\t\t\n\t\tãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆæ¦‚è¦\n\t\n\nMedMCQA-CoTã¯ã€MedMCQAãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®æ‹¡å¼µç‰ˆã§ã€å„åŒ»å­¦å¤šè‚¢é¸æŠå•é¡Œã«é«˜å“è³ªãªChain-of-Thoughtï¼ˆCoTï¼‰æ¨è«–ã‚’è¿½åŠ ã—ãŸãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã§ã™ã€‚åŒ»å­¦çš„ãªæ¨è«–ãƒ—ãƒ­ã‚»ã‚¹ã‚’èª¬æ˜ã§ãã‚‹AIã‚·ã‚¹ãƒ†ãƒ ã®é–‹ç™ºã‚’æ”¯æ´ã™ã‚‹ã“ã¨ã‚’ç›®çš„ã¨ã—ã¦ã„ã¾ã™ã€‚\n\n\t\n\t\t\n\t\tä¸»ãªç‰¹å¾´\n\t\n\n\n2,020ä»¶ã®åŒ»å­¦MCQå•é¡Œ - å…ƒã®MedMCQAãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‹ã‚‰æŠ½å‡º\nChain-of-Thoughtæ¨è«– - DeepSeek-R1ãƒ¢ãƒ‡ãƒ«ã§ç”Ÿæˆ\n95.5%ã®å›ç­”ç²¾åº¦ - ç”Ÿæˆã•ã‚ŒãŸCoTãŒæ­£è§£ã«å°ãå‰²åˆ\n0.952ã®å¹³å‡å“è³ªã‚¹ã‚³ã‚¢ - åŒ»å­¦ç”¨èªå¯†åº¦ã¨æ¨è«–å“è³ªã«åŸºã¥ãè©•ä¾¡\nåŒ…æ‹¬çš„ãªãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ - å“è³ªã‚¹ã‚³ã‚¢ã€åŒ»å­¦å°‚é–€åˆ†é‡ã€ç”Ÿæˆçµ±è¨ˆã‚’å«ã‚€\n\n\n\t\n\t\t\n\t\tãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆè©³ç´°\n\t\n\nå„ãƒ¬ã‚³ãƒ¼ãƒ‰ã®æ§‹æˆ:\n\nquestion: MedMCQAã‹ã‚‰ã®å…ƒã®åŒ»å­¦å•é¡Œ\nanswer: æ­£è§£ã®é¸æŠè‚¢ï¼ˆA, B, C, Dï¼‰\ncot:â€¦ See the full description on the dataset page: https://huggingface.co/datasets/oNo-1/MedMCQA.","url":"https://huggingface.co/datasets/oNo-1/MedMCQA","creator_name":"oNo.1","creator_url":"https://huggingface.co/oNo-1","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["question-answering","text-generation","English","apache-2.0","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"Retrieve-Pile","keyword":"reasoning","description":"Retrieve-Pile (Knowledge-Pile) is a knowledge-related data leveraging Retrieve-from-CC (We also called this method as \"Query of CC\")ï¼Œa total of 735GB disk size and 188B tokens (using Llama2 tokenizer). \n\n\t\n\t\t\n\t\tRetrieve-from-CC\n\t\n\nJust like the figure below, we initially collected seed information in some specific domains, such as keywords, frequently asked questions, and textbooks, to serve as inputs for the Query Bootstrapping stage. Leveraging the great generalization capability of largeâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Query-of-CC/Retrieve-Pile.","url":"https://huggingface.co/datasets/Query-of-CC/Retrieve-Pile","creator_name":"Query-of-CC","creator_url":"https://huggingface.co/Query-of-CC","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["English","apache-2.0","10M - 100M","json","Text"],"keywords_longer_than_N":true},
	{"name":"medical-reasoning-orpo_preprocess","keyword":"reasoning","description":"\n\t\n\t\t\n\t\tMedical Reasoning ORPO Preprocessed Dataset\n\t\n\nThis dataset is a preprocessed version of SURESHBEEKHANI/medical-reasoning-orpo, formatted for preference tuning tasks like DPO or ORPO.\n\n\t\n\t\t\n\t\tData Structure\n\t\n\nThe dataset contains three columns:\n\nquestion: A combination of the original instruction and Input fields.\naccepted: The preferred response, formatted with thinking process and final answer tags.\nrejected: The dispreferred response, also formatted with tags.\n\n\n\t\n\t\t\n\t\tAnswerâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/LLMcompe-Team-Watanabe/medical-reasoning-orpo_preprocess.","url":"https://huggingface.co/datasets/LLMcompe-Team-Watanabe/medical-reasoning-orpo_preprocess","creator_name":"LLMcompe Team Watanabe","creator_url":"https://huggingface.co/LLMcompe-Team-Watanabe","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["question-answering","expert-generated","found","monolingual","English"],"keywords_longer_than_N":true},
	{"name":"twi-reasoning-dataset","keyword":"reasoning","description":"\n\t\n\t\t\n\t\tTwi Reasoning Dataset\n\t\n\nA Twi (Akan) translation of the Multilingual-Thinking reasoning dataset with chain-of-thought in Twi\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset is a Twi (Akan) translation of the Multilingual-Thinking reasoning dataset. It contains chain-of-thought reasoning traces translated from multiple languages into Twi, making it one of the first reasoning datasets available in this language.\n\n\t\n\t\t\n\t\tLanguage Information\n\t\n\n\nLanguage: Twi (Akan)\nLanguage Code: tw\nFamily:â€¦ See the full description on the dataset page: https://huggingface.co/datasets/michsethowusu/twi-reasoning-dataset.","url":"https://huggingface.co/datasets/michsethowusu/twi-reasoning-dataset","creator_name":"Mich-Seth Owusu","creator_url":"https://huggingface.co/michsethowusu","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","question-answering","conversational","text2text-generation","language-modeling"],"keywords_longer_than_N":true},
	{"name":"clue-trial","keyword":"reasoning","description":"\n\t\n\t\t\n\t\t on CUEBench\n\t\n\nThis model was evaluated on CUEBench, a benchmark for contextual entity prediction in real-world autonomous driving scenes. The task requires predicting unobserved or occluded entities based on observed scene context.\n\n\t\n\t\t\n\t\tDescription\n\t\n\n\nTask: Multi-label prediction of unobserved classes based on scene context.\nInput: List of observed classes (e.g., [\"Car\", \"Pedestrian\"])\nOutput: Predicted target classes (e.g., [\"PickupTruck\", \"Bus\"])\n\n\n\t\n\t\t\n\t\tTraining Data\n\t\n\nTheâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/ishwarbb23/clue-trial.","url":"https://huggingface.co/datasets/ishwarbb23/clue-trial","creator_name":"Ishwar B","creator_url":"https://huggingface.co/ishwarbb23","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["English","apache-2.0","ğŸ‡ºğŸ‡¸ Region: US","contextual-prediction","autonomous-driving"],"keywords_longer_than_N":true},
	{"name":"dpo-merged-binarized","keyword":"reasoning","description":"CultriX/dpo-merged-binarized dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/CultriX/dpo-merged-binarized","creator_name":"CultriX","creator_url":"https://huggingface.co/CultriX","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","English","apache-2.0","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"AceReason-1.1-SFT","keyword":"reasoning","description":"\n\t\n\t\t\n\t\tAceReason-1.1-SFT\n\t\n\n\n\n\n\n\n\n\n\n\nAceReason-1.1-SFT is a diverse and high-quality supervised fine-tuning (SFT) dataset focused on math and code reasoning. It serves as the SFT training data for AceReason-Nemotron-1.1-7B, with all responses in the dataset generated by DeepSeek-R1.\nAceReason-1.1-SFT contains 2,668,741 math samples and 1,301,591 code samples, covering the data sources from OpenMathReasoning, NuminaMath-CoT, OpenCodeReasoning, MagicoderEvolInstruct, opc-sft-stage2, leetcodeâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/nvidia/AceReason-1.1-SFT.","url":"https://huggingface.co/datasets/nvidia/AceReason-1.1-SFT","creator_name":"NVIDIA","creator_url":"https://huggingface.co/nvidia","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","English","cc-by-4.0","1M - 10M","arrow"],"keywords_longer_than_N":true},
	{"name":"ether0-benchmark","keyword":"reasoning","description":"\n\n\n\t\n\t\t\n\t\tether0-benchmark\n\t\n\nQA benchmark (test set) for the ether0 reasoning language model:\nhttps://huggingface.co/futurehouse/ether0\nThis benchmark is made from commonly used tasks - like reaction prediction in USPTO/ORD,\nmolecular captioning from PubChem, or predicting GHS classification.\nIt's unique from other benchmarks in that all answers are a molecule.\nIt's balanced so that each task is about 25 questions,\na reasonable amount for frontier model evaluations.\nThe tasks generally followâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/futurehouse/ether0-benchmark.","url":"https://huggingface.co/datasets/futurehouse/ether0-benchmark","creator_name":"Future House","creator_url":"https://huggingface.co/futurehouse","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["question-answering","reinforcement-learning","English","cc-by-4.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"WildSci","keyword":"reasoning","description":"\n\t\n\t\t\n\t\tğŸ§ª WildSci: Advancing Scientific Reasoning from In-the-Wild Literature\n\t\n\n\n\t\n\t\t\n\t\tPurpose and scope\n\t\n\nDespite recent advances in LLM reasoning, there remains a notable lack of diverse, domain-rich science datasets â€œin the wildâ€ to support progress on science reasoning tasks. While existing work has demonstrated strong performance in specialized areas such as mathematical reasoning, there is still a gap in datasets that capture the complexity and breadth of reasoning required acrossâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/JustinTX/WildSci.","url":"https://huggingface.co/datasets/JustinTX/WildSci","creator_name":"Tengxiao Liu","creator_url":"https://huggingface.co/JustinTX","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["English","cc-by-4.0","10K - 100K","json","Text"],"keywords_longer_than_N":true},
	{"name":"SocratesEval","keyword":"reasoning","description":"zhx123/SocratesEval dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/zhx123/SocratesEval","creator_name":"zz","creator_url":"https://huggingface.co/zhx123","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["question-answering","English","apache-2.0","< 1K","csv"],"keywords_longer_than_N":true},
	{"name":"GeoGen","keyword":"mathematical-reasoning","description":"\n\t\n\t\t\n\t\tGeoGeo: GeoExpand & GeoSynth\n\t\n\nThis repository contains the GeoExpand and GeoSynth datasets, originally introduced in the paper Enhancing the Geometric Problem-Solving Ability of Multimodal LLMs via Symbolic-Neural Integration.\nThe datasets are designed to enhance and evaluate the geometric problem-solving capabilities of multimodal large language models.\nGitHub Repository: ycpNotFound/GeoGen\nThese datasets are also referenced and contextualized in the survey paper A Survey of Deepâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/ycpNotFound/GeoGen.","url":"https://huggingface.co/datasets/ycpNotFound/GeoGen","creator_name":"Yicheng Pan","creator_url":"https://huggingface.co/ycpNotFound","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["visual-question-answering","image-text-to-text","English","mit","10K<n<100K"],"keywords_longer_than_N":true},
	{"name":"SkunkworksAI-reasoning-0.01-ko","keyword":"reasoning","description":"SkunkworksAI/reasoning-0.01 ë°ì´í„°ì…‹ì„ nayohan/llama3-instrucTrans-enko-8b ëª¨ë¸ì„ ì‚¬ìš©í•´ ë²ˆì—­í–ˆìŠµë‹ˆë‹¤.\nThanks for SkunkworksAI and nayohan.\n\n\n\t\n\t\t\n\t\tì›ë³¸\n\t\n\n\n\t\n\t\t\n\t\treasoning-0.01 subset\n\t\n\nsynthetic dataset of reasoning chains for a wide variety of tasks.\nwe leverage data like this across multiple reasoning experiments/projects.\nstay tuned for reasoning models and more data.\nThanks to Hive Digital Technologies (https://x.com/HIVEDigitalTech) for their compute support in this project and beyond.\n","url":"https://huggingface.co/datasets/youjunhyeok/SkunkworksAI-reasoning-0.01-ko","creator_name":"ìœ ì¤€í˜","creator_url":"https://huggingface.co/youjunhyeok","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","Korean","apache-2.0","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"InfiMM-WebMath-40B","keyword":"mathematical-reasoning","description":"\n\t\n\t\t\n\t\tInfiMM-WebMath-40B Dataset\n\t\n\nArXiv| PDF\nThis dataset is also discussed in the survey paper A Survey of Deep Learning for Geometry Problem Solving.\nThe accompanying reading list/code for the survey can be found at: https://github.com/majianz/gps-survey\nInfiMM-WebMath-40B is a large-scale, open-source multimodal dataset specifically designed for mathematical reasoning tasks. It incorporates both text and images, extracted from web documents, to advance the pre-training of Multimodalâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Infi-MM/InfiMM-WebMath-40B.","url":"https://huggingface.co/datasets/Infi-MM/InfiMM-WebMath-40B","creator_name":"InfiMM","creator_url":"https://huggingface.co/Infi-MM","license_name":"Open Data Commons Attribution License v1.0","license_url":"https://scancode-licensedb.aboutcode.org/odc-by-1.0.html","language":"en","first_N":5,"first_N_keywords":["image-text-to-text","English","Chinese","odc-by","10M - 100M"],"keywords_longer_than_N":true},
	{"name":"camel","keyword":"step-by-step","description":"A dataset containing mathematical problem-solving traces with step-by-step solutions and improvement history. Each record includes a mathematical problem, its final solution, and the iterative improvement process.","url":"https://huggingface.co/datasets/Wendong-Fan/camel","creator_name":"Wendong.Fan","creator_url":"https://huggingface.co/Wendong-Fan","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-generation","English","mit","< 1K","json"],"keywords_longer_than_N":true},
	{"name":"IMO-Lemmas","keyword":"reasoning","description":"\n\t\n\t\t\n\t\tTencent-IMO: Towards Solving More Challenging IMO Problems via Decoupled Reasoning and Proving\n\t\n\n\n\n\nThis dataset contains strategic subgoals (lemmas) and their formal proofs for a challenging set of post-2000 International Mathematical Olympiad (IMO) problems. All statements and proofs are formalized in the Lean 4 theorem proving language.\nThe data was generated using the Decoupled Reasoning and Proving framework, introduced in our paper: Towards Solving More Challenging IMO Problemsâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Tencent-IMO/IMO-Lemmas.","url":"https://huggingface.co/datasets/Tencent-IMO/IMO-Lemmas","creator_name":"Tencent-IMO","creator_url":"https://huggingface.co/Tencent-IMO","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["English","apache-2.0","< 1K","json","Text"],"keywords_longer_than_N":true},
	{"name":"bbh-fr","keyword":"reasoning","description":"\n\t\n\t\t\n\t\tDataset Card for bbh-fr\n\t\n\nle-leadboard/bbh-fr fait partie de l'initiative OpenLLM French Leaderboard, proposant une adaptation franÃ§aise du benchmark BIG-Bench Hard (BBH).\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nBBH-fr est l'adaptation franÃ§aise d'une suite de 23 tÃ¢ches BIG-Bench particuliÃ¨rement exigeantes. Ces tÃ¢ches ont Ã©tÃ© sÃ©lectionnÃ©es car elles reprÃ©sentaient initialement des dÃ©fis oÃ¹ les modÃ¨les de langage n'atteignaient pas les performances humaines moyennes.\nCatÃ©gories de tÃ¢ches inclusesâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/le-leadboard/bbh-fr.","url":"https://huggingface.co/datasets/le-leadboard/bbh-fr","creator_name":"le-leadboard","creator_url":"https://huggingface.co/le-leadboard","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["question-answering","text2text-generation","French","apache-2.0","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"SC10k-R","keyword":"reasoning","description":"Open-source dataset of 10k high-quality, long-context finance reasoning examples with synthetic reasoning traces from Gemini 2.5 Flash totaling just below 600 million tokens. Each sample includes a financial news article, as well as other relevant articles and associated pricing data, where the given task is to predict the predict the price of a stock 30 days out. The reasoning trace attempts to use logic, rather than direct historical knowledge, to draw conclusions and derive its answer. Theâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/nbettencourt/SC10k-R.","url":"https://huggingface.co/datasets/nbettencourt/SC10k-R","creator_name":"Nick Bettencourt","creator_url":"https://huggingface.co/nbettencourt","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["English","apache-2.0","10K - 100K","parquet","Text"],"keywords_longer_than_N":true},
	{"name":"pde-controller","keyword":"reasoning","description":"\n\t\n\t\t\n\t\tAutoformalization and Reasoning for PDE Control\n\t\n\n\n\nThis dataset is used to train PDE-Controller (https://pde-controller.github.io/), a framework that enables large language models (LLMs) to control systems governed by partial differential equations (PDEs).\nBy training LLMs on this dataset, we can transform informal natural language instructions into formal specifications, and then execute reasoning and planning steps to improve the utility of PDE control.\nBy bridging the gap betweenâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/delta-lab-ai/pde-controller.","url":"https://huggingface.co/datasets/delta-lab-ai/pde-controller","creator_name":"DeLTA Lab @ SFU","creator_url":"https://huggingface.co/delta-lab-ai","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","English","apache-2.0","1M<n<10M","arxiv:2502.00963"],"keywords_longer_than_N":true},
	{"name":"MMLU-SR","keyword":"reasoning","description":"\n\t\n\t\t\n\t\tMMLU-SR Dataset\n\t\n\nThis is the dataset for the paper \"MMLU-SR: A Benchmark for Stress-Testing Reasoning Capability of Large Language Models\".\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nThis dataset contains three different variants:\n\nQuestion Only: Key terms in questions are replaced with dummy words and their definitions, while answer choices remain unchanged.\nAnswer Only: Key terms in answer choices are replaced with dummy words and their definitions, while questions remain unchanged. \nQuestionâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/NiniCat/MMLU-SR.","url":"https://huggingface.co/datasets/NiniCat/MMLU-SR","creator_name":"Cat Wang","creator_url":"https://huggingface.co/NiniCat","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["question-answering","multiple-choice-qa","expert-generated","expert-generated","monolingual"],"keywords_longer_than_N":true},
	{"name":"AetherCode","keyword":"reasoning","description":"\n  AetherCode: Evaluating LLMs' Ability to Win In Premier Programming Competitions\n\n\n\n  \n    \n  \n  \n    \n  \n  \n    \n  \n  \n  \n\n\n\n\t\n\t\t\n\t\tIntroduction\n\t\n\nCompetitive programming has emerged as a critical benchmark for evaluating the reasoning and coding capabilities of Large Language Models (LLMs). Despite impressive progress on existing benchmarks, we argue that current evaluations overstate model proficiency, masking a substantial gap between LLMs and elite human programmers. This gap arisesâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/m-a-p/AetherCode.","url":"https://huggingface.co/datasets/m-a-p/AetherCode","creator_name":"Multimodal Art Projection","creator_url":"https://huggingface.co/m-a-p","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","English","cc-by-4.0","< 1K","parquet"],"keywords_longer_than_N":true},
	{"name":"reasoning-v1-20m-portuguese","keyword":"reasoning","description":"glaiveai/reasoning-v1-20m translated to portuguese.\n","url":"https://huggingface.co/datasets/cnmoro/reasoning-v1-20m-portuguese","creator_name":"Carlo Moro","creator_url":"https://huggingface.co/cnmoro","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","Portuguese","apache-2.0","10M - 100M","parquet"],"keywords_longer_than_N":true},
	{"name":"reasoning-llama-format","keyword":"reasoning","description":"\n\t\n\t\t\n\t\tOpen Paws Reasoning Llama Format\n\t\n\nThis dataset is part of the Open Paws initiative to develop AI training data aligned with animal liberation and advocacy principles. Created to train AI systems that understand and promote animal welfare, rights, and liberation.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\nDataset Type: Reasoning Data\nFormat: JSONL (JSON Lines)\nLanguages: Multilingual (primarily English)\nFocus: Animal advocacy and ethical reasoning\nOrganization: Open Paws\nLicense: Apache 2.0â€¦ See the full description on the dataset page: https://huggingface.co/datasets/open-paws/reasoning-llama-format.","url":"https://huggingface.co/datasets/open-paws/reasoning-llama-format","creator_name":"Open Paws","creator_url":"https://huggingface.co/open-paws","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","English","multilingual","apache-2.0","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"clean_pubmedqa_mixtral_cot","keyword":"reasoning","description":"å…ƒãƒ‡ãƒ¼ã‚¿: https://huggingface.co/datasets/HPAI-BSC/PubmedQA-Mixtral-CoT\nä½¿ç”¨ã—ãŸã‚³ãƒ¼ãƒ‰: https://github.com/LLMTeamAkiyama/0-data_prepare/tree/master/src/PubmedQA-Mixtral-CoT\nãƒ‡ãƒ¼ã‚¿ä»¶æ•°: 206,962\nå¹³å‡ãƒˆãƒ¼ã‚¯ãƒ³æ•°: 586\næœ€å¤§ãƒˆãƒ¼ã‚¯ãƒ³æ•°: 1,922\nåˆè¨ˆãƒˆãƒ¼ã‚¯ãƒ³æ•°: 121,366,170\nãƒ•ã‚¡ã‚¤ãƒ«å½¢å¼: JSONL\nãƒ•ã‚¡ã‚¤ãƒ«åˆ†å‰²æ•°: 3\nåˆè¨ˆãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚º: 532.2 MB\nåŠ å·¥å†…å®¹ï¼š\n\næ–‡å­—æ•°ã«ã‚ˆã‚‹ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°:\n\nquestion (è³ªå•) åˆ—ã®æ–‡å­—æ•°ãŒ 6,000æ–‡å­—ã‚’è¶…ãˆã‚‹ ãƒ‡ãƒ¼ã‚¿ã‚’å‰Šé™¤ã—ã¾ã™ã€‚\nresponse (å¿œç­”) åˆ—ã®æ–‡å­—æ•°ãŒ 80,000æ–‡å­—ã‚’è¶…ãˆã‚‹ ãƒ‡ãƒ¼ã‚¿ã‚’å‰Šé™¤ã—ã¾ã™ã€‚\n\n\nå¿œç­” (response) ã®åˆ†å‰²:\n\nresponse åˆ—ã‚’ã€æ€è€ƒãƒ—ãƒ­ã‚»ã‚¹ã‚’è¨˜è¿°ã—ãŸã€Œthoughtã€éƒ¨åˆ†ã¨ã€æœ€çµ‚çš„ãªçµè«–ã§ã‚ã‚‹ã€Œanswerã€éƒ¨åˆ†ã«åˆ†å‰²ã—ã¾ã™ã€‚\nåˆ†å‰²ã«ã¯ Answer: ã‚„ The answerâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/LLMTeamAkiyama/clean_pubmedqa_mixtral_cot.","url":"https://huggingface.co/datasets/LLMTeamAkiyama/clean_pubmedqa_mixtral_cot","creator_name":"LLMTeamAkiyama","creator_url":"https://huggingface.co/LLMTeamAkiyama","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["question-answering","English","apache-2.0","100K - 1M","json"],"keywords_longer_than_N":true},
	{"name":"indonesian-reasoning","keyword":"reasoning","description":"\n\t\n\t\t\n\t\tIndonesian Reasoning\n\t\n\n\n\t\n\t\t\n\t\tğŸ“Œ Description\n\t\n\nThis dataset contains Chain-of-Thought (CoT) style reasoning samples in Indonesian (with some English mixed in).Each entry provides a user prompt, a step-by-step reasoning process, and a final answer, formatted for Supervised Fine-Tuning (SFT) with reasoning.\n\n\t\n\t\t\n\t\tâš™ï¸ Data Format\n\t\n\nStored in JSONL format. Each line follows the structure:\n{\n  \"messages\": [\n    {\"role\": \"system\", \"content\": \"...\"},\n    {\"role\": \"user\", \"content\":â€¦ See the full description on the dataset page: https://huggingface.co/datasets/izzulgod/indonesian-reasoning.","url":"https://huggingface.co/datasets/izzulgod/indonesian-reasoning","creator_name":"Izzul Fahmi","creator_url":"https://huggingface.co/izzulgod","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["question-answering","Indonesian","mit","1K - 10K","json"],"keywords_longer_than_N":true},
	{"name":"SATQuest","keyword":"logical-reasoning","description":"\n\t\n\t\t\n\t\tSATQuest Dataset\n\t\n\nPaper: SATQuest: A Verifier for Logical Reasoning Evaluation and Reinforcement Fine-Tuning of LLMs\n\n\n\nTL;DR. Synthetic CNF benchmark for LLM reasoning: 140 matched SAT/UNSAT pairs with n in [3, 16] and fixed ratio m=4n. The dataset stores only CNF formulas and solver stats; use the SATQuest Python library to render prompts/answers for SATDP, SATSP, MaxSAT, MCS, and MUS in four formats (math, DIMACS, story, dual story).\n\n\t\n\t\t\n\t\tData fields\n\t\n\n\nid: unique identifierâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/sdpkjc/SATQuest.","url":"https://huggingface.co/datasets/sdpkjc/SATQuest","creator_name":"Yanxiao Zhao","creator_url":"https://huggingface.co/sdpkjc","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["question-answering","text-generation","mit","< 1K","parquet"],"keywords_longer_than_N":true},
	{"name":"AVI-Math","keyword":"reasoning","description":"\n\t\n\t\t\n\t\tDataset Sources\n\t\n\n\n\n\nRepository: https://github.com/VisionXLab/avi-math\nPaper: https://arxiv.org/abs/2509.10059\n\nBibTeX:\n@ARTICLE{zhou2025avimath,\n  author={Zhou, Yue and Feng, Litong and Lan, Mengcheng and Yang, Xue and Li, Qingyun and Ke, Yiping and Jiang, Xue and Zhang, Wayne},\n  journal={ISPRS Journal of Photogrammetry and Remote Sensing}, \n  title={Multimodal Mathematical Reasoning Embedded in Aerial Vehicle Imagery: Benchmarking, Analysis, and Exploration}, \n  year={2025}â€¦ See the full description on the dataset page: https://huggingface.co/datasets/erenzhou/AVI-Math.","url":"https://huggingface.co/datasets/erenzhou/AVI-Math","creator_name":"yuezhou","creator_url":"https://huggingface.co/erenzhou","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["question-answering","English","apache-2.0","< 1K","imagefolder"],"keywords_longer_than_N":true},
	{"name":"TreeVGR-SFT-35K","keyword":"reasoning","description":"\n\t\n\t\t\n\t\tTreeBench: Traceable Evidence Enhanced Visual Grounded Reasoning Benchmark\n\t\n\nThis repository contains TreeBench, a diagnostic benchmark dataset proposed in the paper Traceable Evidence Enhanced Visual Grounded Reasoning: Evaluation and Methodology.\nTreeBench is designed to holistically evaluate \"thinking with images\" capabilities by dynamically referencing visual regions. It is built on three core principles:\n\nFocused visual perception of subtle targets in complex scenes.\nTraceableâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/HaochenWang/TreeVGR-SFT-35K.","url":"https://huggingface.co/datasets/HaochenWang/TreeVGR-SFT-35K","creator_name":"HaochenWang","creator_url":"https://huggingface.co/HaochenWang","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["image-text-to-text","English","apache-2.0","10K - 100K","json"],"keywords_longer_than_N":true},
	{"name":"mathreasoning","keyword":"reasoning","description":"\n\t\n\t\t\n\t\tMathReasoning\n\t\n\nThe MathReasoning Dataset is a large-scale, high-quality dataset (~3.13M rows) focused on mathematics, logical reasoning, and problem-solving. It is primarily generated through synthetic distillation techniques, complemented by curated open-source educational content. The dataset is designed to train and evaluate language models in mathematical reasoning, quantitative problem-solving, and structured chain-of-thought tasks across domains from basic arithmetic toâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/169Pi/mathreasoning.","url":"https://huggingface.co/datasets/169Pi/mathreasoning","creator_name":"169Pi","creator_url":"https://huggingface.co/169Pi","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","question-answering","English","apache-2.0","1M - 10M"],"keywords_longer_than_N":true},
	{"name":"Deep_math","keyword":"reasoning","description":"\n\t\n\t\t\n\t\tDeepMath-103K\n\t\n\n\n  \n    \n      \n        \n      \n    \n    \n      \n        \n      \n    \n    \n      \n        \n      \n    \n    \n      \n        \n\t\n\t\t\n\t\tğŸ”¥ News\n\t\n\n\nMay 8, 2025: We found that 48 samples contained hints that revealed the answers. The relevant questions have now been revised to remove the leaked answers.\nApril 14, 2025: We release DeepMath-103K, a large-scale dataset featuring challenging, verifiable, and decontaminated math problems tailored for RL and SFT. We open source:â€¦ See the full description on the dataset page: https://huggingface.co/datasets/Compumacy/Deep_math.","url":"https://huggingface.co/datasets/Compumacy/Deep_math","creator_name":"Compumacy AI","creator_url":"https://huggingface.co/Compumacy","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-generation","English","mit","100K - 1M","parquet"],"keywords_longer_than_N":true},
	{"name":"BPC","keyword":"reasoning","description":"\n\t\n\t\t\n\t\tBPC: A Benchmark Dataset for Causal Business Process Reasoning\n\t\n\n\n\t\n\t\t\n\t\tDataset Card for BPC\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nAbstract. Large Language Models (LLMs) are increasingly used for boosting organizational efficiency and automating tasks. \nWhile not originally designed for complex cognitive processes, recent efforts have further extended to employ LLMs in activities such as reasoning, planning, \nand decision-making. In business processes, such abilities could be invaluable forâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/ibm-research/BPC.","url":"https://huggingface.co/datasets/ibm-research/BPC","creator_name":"IBM Research","creator_url":"https://huggingface.co/ibm-research","license_name":"Community Data License Agreement Permissive 2.0","license_url":"https://scancode-licensedb.aboutcode.org/cdla-permissive-2.0.html","language":"en","first_N":5,"first_N_keywords":["question-answering","English","cdla-permissive-2.0","1K - 10K","csv"],"keywords_longer_than_N":true},
	{"name":"NuminaMath-1.5-Verifiable","keyword":"reasoning","description":"\n\t\n\t\t\n\t\tNuminaMath-1.5-Verifiable\n\t\n\nA filtered subset of NuminaMath-1.5, retaining only non-synthetic examples with valid answers.\nFiltering Criteria\n    â€¢\tExcludes synthetic examples.\n    â€¢\tKeeps only entries with non-empty, meaningful answers.\n    â€¢\tRemoves generic placeholders like â€œproofâ€ and â€œnotfound.â€\n\n\t\n\t\t\n\t\tUsage\n\t\n\nfrom datasets import load_dataset\n\ndataset = load_dataset(\"yentinglin/NuminaMath-1.5-Verifiable\")\n\n","url":"https://huggingface.co/datasets/yentinglin/NuminaMath-1.5-Verifiable","creator_name":"Yen-Ting Lin","creator_url":"https://huggingface.co/yentinglin","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["English","apache-2.0","100K - 1M","parquet","Text"],"keywords_longer_than_N":true},
	{"name":"knights_and_knaves_reasoning","keyword":"reasoning","description":"\n\t\n\t\t\n\t\tğŸ§  Dataset Card: Knights and Knaves Reasoning Traces (QwQ)\n\t\n\nProject page\n\n\t\n\t\t\n\t\tğŸ“ Dataset Summary\n\t\n\nThis dataset contains reasoning traces generated by the QwQ system applied to the Knights and Knaves logic puzzles. Each example in the dataset includes a natural language puzzle, the reasoning steps taken by the model, and the tokens used. These traces reflect intermediate reasoning steps that help interpret how QwQ reaches a conclusion.\n\n\t\n\t\t\n\t\tğŸ“„ Associated Paper\n\t\n\nTitle: Warmâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/safal312/knights_and_knaves_reasoning.","url":"https://huggingface.co/datasets/safal312/knights_and_knaves_reasoning","creator_name":"Safal Shrestha","creator_url":"https://huggingface.co/safal312","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["question-answering","English","apache-2.0","1K - 10K","parquet"],"keywords_longer_than_N":true},
	{"name":"math-reasoning-sft","keyword":"reasoning","description":"\n\t\n\t\t\n\t\tMathematical Reasoning SFT Dataset\n\t\n\nThis dataset contains mathematical reasoning problems and solutions in instruction-following format, designed for supervised fine-tuning of language models.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nThe dataset follows the Alpaca format with three fields:\n\ninstruction: Mathematical problem statement\ninput: Empty string (not used)\noutput: Detailed solution with step-by-step reasoning and final answer in \\boxed{} format\n\n\n\t\n\t\t\n\t\tExample\n\t\n\n{\n  \"instruction\":â€¦ See the full description on the dataset page: https://huggingface.co/datasets/est-ai/math-reasoning-sft.","url":"https://huggingface.co/datasets/est-ai/math-reasoning-sft","creator_name":"ESTsoft AI","creator_url":"https://huggingface.co/est-ai","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-generation","question-answering","English","mit","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"TPBench","keyword":"reasoning","description":"\n\t\n\t\t\n\t\tTP Bench â€“ Theoretical Physics Benchmark for AI\n\t\n\n\n\nTPBench is a curated dataset and evaluation suite designed to measure the reasoning capabilities of AI models in theoretical physics. Our test problems span multiple difficulty levelsâ€”from undergraduate to frontier researchâ€”and cover topics such as cosmology, high-energy theory, general relativity, and more. By providing a unified framework for problem-solving and auto-verifiable answers, TPBench aims to drive progress in AI-basedâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/ZhiqiGao/TPBench.","url":"https://huggingface.co/datasets/ZhiqiGao/TPBench","creator_name":"Zhiqi Gao","creator_url":"https://huggingface.co/ZhiqiGao","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["question-answering","English","mit","< 1K","parquet"],"keywords_longer_than_N":true},
	{"name":"german_tlr_gold_14k","keyword":"reasoning","description":"\n\t\n\t\t\n\t\tğŸ§  German TLR Gold Dataset (14.5k)\n\t\n\n\n\t\n\t\t\n\t\tğŸ“Š Dataset Overview\n\t\n\nEin hochwertiger deutschsprachiger Datensatz mit 14.500 Samples im Think-Learn-Respond (TLR) Format fÃ¼r das Training von reasoning-fÃ¤higen Large Language Models.\nFormat: Jede Antwort ist strukturiert in:\n\n<think>: Strukturierter Denkprozess und Reasoning\n<answer>: Finale, klare Antwort\n\n\n\t\n\t\t\n\t\tğŸ¯ Anwendung\n\t\n\nDieses Dataset wurde speziell entwickelt fÃ¼r:\n\nSupervised Fine-Tuning (SFT) von deutschen LLMs\nTraining vonâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/arnomatic/german_tlr_gold_14k.","url":"https://huggingface.co/datasets/arnomatic/german_tlr_gold_14k","creator_name":"arnomatic","creator_url":"https://huggingface.co/arnomatic","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-generation","question-answering","German","mit","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"HyperThink-X-Nvidia-Opencode-Reasoning-200K","keyword":"reasoning","description":"\n  \n\n\n\n\t\n\t\t\n\t\tğŸ”® HyperThink\n\t\n\nHyperThink is a premium, best-in-class dataset series capturing deep reasoning interactions between users and an advanced Reasoning AI system. Designed for training and evaluating next-gen language models on complex multi-step tasks, the dataset spans a wide range of prompts and guided thinking outputs.\n\n\n\t\n\t\t\n\t\tğŸš€ Dataset Tiers\n\t\n\nHyperThink is available in three expertly curated versions, allowing flexible scaling based on compute resources and training goals:â€¦ See the full description on the dataset page: https://huggingface.co/datasets/NukeverseAi/HyperThink-X-Nvidia-Opencode-Reasoning-200K.","url":"https://huggingface.co/datasets/NukeverseAi/HyperThink-X-Nvidia-Opencode-Reasoning-200K","creator_name":"NukeverseAi","creator_url":"https://huggingface.co/NukeverseAi","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["reinforcement-learning","question-answering","text-generation","English","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"sasha_smart_home_reasoning","keyword":"reasoning","description":"This is a dataset of smart home user commands and JSON responses generated by zero-shot prompting of GPT-4. It can be used to fine-tune and/or evaluate language models for responding to user commands in smart homes. For more information, refer to our paper Sasha: Creative Goal-Oriented Reasoning in Smart Homes with Large Language Models.\nhttps://arxiv.org/abs/2305.09802\nIf you use the dataset in your work, please cite us:\n@article{king2024sasha,\n  title={Sasha: creative goal-oriented reasoningâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/ThoughtfulThings/sasha_smart_home_reasoning.","url":"https://huggingface.co/datasets/ThoughtfulThings/sasha_smart_home_reasoning","creator_name":"Thoughtful Things","creator_url":"https://huggingface.co/ThoughtfulThings","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["mit","arxiv:2305.09802","ğŸ‡ºğŸ‡¸ Region: US","llm","smarthome"],"keywords_longer_than_N":true},
	{"name":"Persian-MuSR","keyword":"reasoning","description":"\n\t\n\t\t\n\t\tPersian MuSR: Testing the Limits of Chain-of-thought with Multistep Soft Reasoning on Persian Language\n\t\n\nThis is the Persian-translated version (using GPT-4o) of the original dataset MuSR.\n\n\t\n\t\t\n\t\tAcknowledgments\n\t\n\n\nSpecial thanks to AvalAI for sponsoring this project through their AvalAward program\nThis dataset was made possible by AvalAI's generous support and commitment to advancing Persian language AI research\n\n","url":"https://huggingface.co/datasets/ParsBench/Persian-MuSR","creator_name":"ParsBench","creator_url":"https://huggingface.co/ParsBench","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["question-answering","Persian","cc-by-4.0","< 1K","json"],"keywords_longer_than_N":true},
	{"name":"Fast-Math-R1-SFT","keyword":"reasoning","description":"This repository contains the First stage SFT dataset as presented in the paper A Practical Two-Stage Recipe for Mathematical LLMs: Maximizing Accuracy with SFT and Efficiency with Reinforcement Learning.\nThis dataset is used for the intensive Supervised Fine-Tuning (SFT) phase, crucial for pushing the model's mathematical accuracy.\nProject GitHub Repository: https://github.com/RabotniKuma/Kaggle-AIMO-Progress-Prize-2-9th-Place-Solution\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Construction\n\t\n\nThis dataset wasâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/RabotniKuma/Fast-Math-R1-SFT.","url":"https://huggingface.co/datasets/RabotniKuma/Fast-Math-R1-SFT","creator_name":"Hiroshi Yoshihara","creator_url":"https://huggingface.co/RabotniKuma","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","apache-2.0","1K - 10K","csv","Text"],"keywords_longer_than_N":true},
	{"name":"Med-Reason-Sft","keyword":"reasoning","description":"\n\t\n\t\t\n\t\tMed-Reason-Sft\n\t\n\nMed-Reason-Sft is a refined and structured dataset focused on medical multiple-choice reasoning and problem understanding. It is derived from the ReasonMed dataset and processed to better support instruction tuning and reasoning-based tasks in the medical domain.\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\n\nSource: Adapted from lingshu-medical-mllm/ReasonMed\nEntries: Over 300,000 examples\nFormat: Text-to-text pairs (problem â†’ reasoning statement)\nLanguage: English\nLicense: Apache 2.0â€¦ See the full description on the dataset page: https://huggingface.co/datasets/prithivMLmods/Med-Reason-Sft.","url":"https://huggingface.co/datasets/prithivMLmods/Med-Reason-Sft","creator_name":"Prithiv Sakthi","creator_url":"https://huggingface.co/prithivMLmods","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","question-answering","English","apache-2.0","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"s1_59k","keyword":"reasoning","description":"\n\t\n\t\t\n\t\tDataset Card for XuHu6736/s1_59k\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nXuHu6736/s1_59k is a dataset specifically prepared for Supervised Fine-Tuning (SFT) of large language models. It is constructed by merging and processing two existing Hugging Face datasets: simplescaling/data_ablation_full59K and qfq/train_featurized.\nThe simplescaling/data_ablation_full59K dataset is a collection of approximately 59,000 questions and solutions spanning various domains including mathematics, scienceâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/XuHu6736/s1_59k.","url":"https://huggingface.co/datasets/XuHu6736/s1_59k","creator_name":"XuHu","creator_url":"https://huggingface.co/XuHu6736","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["question-answering","text-generation","XuHu6736 (merging process)","simplescaling (source dataset: data_ablation_full59K)","qfq (source dataset: train_featurized, annotation based on 's1: Simple test-time scaling')"],"keywords_longer_than_N":true},
	{"name":"Titanium2-DeepSeek-R1","keyword":"reasoning","description":"Click here to support our open-source dataset and model releases!\nTitanium2-DeepSeek-R1 is a dataset focused on architecture and DevOps, testing the limits of DeepSeek R1's architect and coding skills!\nThis dataset contains:\n\n32.4k synthetically generated prompts focused on architecture, cloud, and DevOps. All responses are generated using DeepSeek R1. Primary areas of expertise are architecture (problem solving, scenario analysis, coding, full SDLC) and DevOps (Azure, AWS, GCP, Terraformâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/sequelbox/Titanium2-DeepSeek-R1.","url":"https://huggingface.co/datasets/sequelbox/Titanium2-DeepSeek-R1","creator_name":"t.d.a.g.","creator_url":"https://huggingface.co/sequelbox","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","English","apache-2.0","10K - 100K","csv"],"keywords_longer_than_N":true},
	{"name":"think-more","keyword":"reasoning","description":"\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThink More is a large-scale, multi-domain collection of long chain-of-thought (CoT) reasoning examples. It aggregates and cleans several prominent reasoning datasets, focusing on high-quality, step-by-step model-generated solutions from DeepSeek R1 and OpenAI o1. Each entry includes a question, the modelâ€™s answer, and the detailed thought process leading to that answer.\nâš ï¸ Warning: the dataset decompresses to a 15.1 GB JSONLines file.\n\n\t\n\t\t\n\t\n\t\n\t\tSupported Tasks andâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/agentlans/think-more.","url":"https://huggingface.co/datasets/agentlans/think-more","creator_name":"Alan Tseng","creator_url":"https://huggingface.co/agentlans","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","English","cc-by-4.0","100K - 1M","json"],"keywords_longer_than_N":true},
	{"name":"EEReasonBench","keyword":"reasoning","description":"\n\t\n\t\t\n\t\tEEReasonBench: A Reasoning Benchmark for Electrical Engineering\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset provides a collection of electrical engineering problems covering various subjects, including Circuits, Machines, Power Systems, Power Plants, etc. Problems include multiple-choice questions (conceptual and numerical) with detailed, step-by-step solutions formatted in Markdown and LaTeX.\nThe dataset is designed to serve as both a benchmark for evaluating model performance onâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Noru1/EEReasonBench.","url":"https://huggingface.co/datasets/Noru1/EEReasonBench","creator_name":"Norbert John Ibera","creator_url":"https://huggingface.co/Noru1","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","question-answering","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"counterfactual_history_reasoning","keyword":"reasoning","description":"\n\t\n\t\t\n\t\tDataset Card for Counterfactual History Reasoning Dataset\n\t\n\nThe Counterfactual History Reasoning Dataset contains 100 examples of counterfactual reasoning applied to historical events. Each example presents a historical event, poses a \"what if\" counterfactual premise, provides a step-by-step reasoning trace exploring the implications across multiple domains, and concludes with an alternative historical outcome. The reasoning traces and conclusions were generated using DeepSeek-R1, aâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/strickvl/counterfactual_history_reasoning.","url":"https://huggingface.co/datasets/strickvl/counterfactual_history_reasoning","creator_name":"Alex Strick van Linschoten","creator_url":"https://huggingface.co/strickvl","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["monolingual","English","mit","< 1K","parquet"],"keywords_longer_than_N":true},
	{"name":"MATH_qCoT_LLMquery_lexicalquery","keyword":"reasoning","description":"Datasets from Paper: https://huggingface.co/papers/2505.18405\n","url":"https://huggingface.co/datasets/Raderspace/MATH_qCoT_LLMquery_lexicalquery","creator_name":"RaDeR","creator_url":"https://huggingface.co/Raderspace","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["English","mit","10K - 100K","parquet","Text"],"keywords_longer_than_N":true},
	{"name":"ARPO-RL-DeepSearch-1K","keyword":"reasoning","description":"\n\t\n\t\t\n\t\tARPO Dataset: Agentic Reinforced Policy Optimization\n\t\n\nThis repository contains the datasets used in the paper Agentic Reinforced Policy Optimization.\nPaper Abstract: Large-scale reinforcement learning with verifiable rewards (RLVR) has demonstrated its effectiveness in harnessing the potential of large language models (LLMs) for single-turn reasoning tasks. In realistic reasoning scenarios, LLMs can often utilize external tools to assist in task-solving processes. To bridge this gapâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/dongguanting/ARPO-RL-DeepSearch-1K.","url":"https://huggingface.co/datasets/dongguanting/ARPO-RL-DeepSearch-1K","creator_name":"KABI","creator_url":"https://huggingface.co/dongguanting","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-generation","mit","1K - 10K","parquet","Text"],"keywords_longer_than_N":true},
	{"name":"NOVEReason_2k","keyword":"reasoning","description":"\n  \n\n\n\n\t\n\t\t\n\t\tNOVEReason_2k\n\t\n\n\nNOVEReason is the dataset used in the paper NOVER: Incentive Training for Language Models via Verifier-Free Reinforcement Learning. It is a multi-domain, multi-task, general-purpose reasoning dataset, comprising seven curated datasets across four subfields: general reasoning, creative writing, social intelligence, and multilingual understanding. The data has been carefully cleaned and filtered to ensure suitability for training large reasoning models usingâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/thinkwee/NOVEReason_2k.","url":"https://huggingface.co/datasets/thinkwee/NOVEReason_2k","creator_name":"weiliu","creator_url":"https://huggingface.co/thinkwee","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["question-answering","translation","text-generation","summarization","English"],"keywords_longer_than_N":true},
	{"name":"German-RAG-ORPO-Alpaca-HESSIAN-AI","keyword":"reasoning","description":"\n\t\n\t\t\n\t\tGerman-RAG-ORPO (Odds Ratio Preference Optimization) Alpaca-Format\n\t\n\n\n\t\n\t\t\n\t\tGerman-RAG - German Retrieval Augmented Generation\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThe ORPO Tasks Dataset represents a specialized collection for fine-tuning language models with a focus on RAG-specific capabilities. \nThe subsets can be for this training step are derived from 2 different sources:\n\nSauerkrautLM Preference Datasets:\nSauerkrautLM-Fermented-GER-DPO:  is a specialized dataset designed for trainingâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/avemio/German-RAG-ORPO-Alpaca-HESSIAN-AI.","url":"https://huggingface.co/datasets/avemio/German-RAG-ORPO-Alpaca-HESSIAN-AI","creator_name":"Avemio AG","creator_url":"https://huggingface.co/avemio","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["question-answering","summarization","German","English","mit"],"keywords_longer_than_N":true},
	{"name":"Tachibana-QVQ","keyword":"reasoning","description":"Tachibana-QVQ is a dataset containing code-reasoning and code-instruct responses across a wide variety of programming tasks.\nThis dataset contains:\n\n103k prompts from sequelbox/Tachibana, with all responses generated by Qwen/QVQ-72B-Preview.\nResponses demonstrate QVQ's code-reasoning ability and general code capabilities.\n\nResponses have not been filtered or edited at all: some responses will contain infinite thought loops, incomplete answers, inaccurate responses, or other identified orâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/sequelbox/Tachibana-QVQ.","url":"https://huggingface.co/datasets/sequelbox/Tachibana-QVQ","creator_name":"t.d.a.g.","creator_url":"https://huggingface.co/sequelbox","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","English","apache-2.0","100K - 1M","csv"],"keywords_longer_than_N":true},
	{"name":"camel_dataset_example","keyword":"step-by-step","description":"A dataset containing mathematical problem-solving traces with step-by-step solutions and improvement history. Each record includes a mathematical problem, its final solution, and the iterative improvement process.","url":"https://huggingface.co/datasets/Wendong-Fan/camel_dataset_example","creator_name":"Wendong.Fan","creator_url":"https://huggingface.co/Wendong-Fan","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-generation","English","mit","< 1K","json"],"keywords_longer_than_N":true},
	{"name":"M3CoT","keyword":"mathematical-reasoning","description":"\n ğŸ¦„ M3CoT: A Novel Benchmark for Multi-Domain Multi-step Multi-modal Chain-of-Thought\n\n\n      \n      \n    \n    \n       \n      \n       \n       \n      \n      \n       \n      \n    \n      \n\n\n\n      \n    [ArXiv] | [ğŸ¤—HuggingFace] | [Website]\n    \n    \n\n\nğŸŒŸ Any contributions via PRs, issues, emails or other methods are greatly appreciated.\n\n\t\n\t\t\n\t\tğŸ”¥News\n\t\n\n\nğŸ–ï¸ Our work is accepted by ACL2024.\n\nğŸ”¥ We have release benchmark on [ğŸ¤—HuggingFace].\n\nğŸ”¥ The paper is also available on [ArXiv].\n\nğŸ”®â€¦ See the full description on the dataset page: https://huggingface.co/datasets/LightChen2333/M3CoT.","url":"https://huggingface.co/datasets/LightChen2333/M3CoT","creator_name":"Qiguang Chen","creator_url":"https://huggingface.co/LightChen2333","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["image-text-to-text","visual-question-answering","reinforcement-learning","English","mit"],"keywords_longer_than_N":true},
	{"name":"LogicIFEval","keyword":"reasoning","description":"\n\t\n\t\t\n\t\tLogicIFEval\n\t\n\nFor evaluation scripts, please refer to our GitHub repository: https://github.com/mianzhang/LogicIF\nThe dataset contains two splits:\n\nfull: Complete benchmark dataset (3,050 instructions)\nmini: Mini version for quick evaluation (749 instructions)\n\nEach line in the JSONL files contains a single evaluation example with the following structure:\n{\n  \"task_id\": \"string\",           // Unique identifier for the problem\n  \"test_case_id\": \"int\",         // Test case number forâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/billmianz/LogicIFEval.","url":"https://huggingface.co/datasets/billmianz/LogicIFEval","creator_name":"Mian Zhang","creator_url":"https://huggingface.co/billmianz","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-generation","question-answering","English","mit","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"SpaceThinker","keyword":"reasoning","description":"\n\t\n\t\t\n\t\tSpaceThinker Dataset\n\t\n\n\n\n\t\n\t\t\n\t\tUsage\n\t\n\n\nTry training a LLaVA-style VLM using the SpaceThinker Dataset\n\n\t\n\t\t\n\t\tEnhanced Quantitative Spatial Reasoning with Test-Time Compute\n\t\n\nThe SpaceThinker dataset is created using VQASynth to synthesize spatial reasoning traces from a subset of images \nin the localized narratives split of the cauldron.\n\n\t\n\t\t\n\t\tData Samples\n\t\n\n\n\t\n\t\t\n\n\n\n\n\n\t\t\nPrompt: How far is the man in the red hat from the pallet of boxes in feet?\nPrompt: How far is the Goalâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/remyxai/SpaceThinker.","url":"https://huggingface.co/datasets/remyxai/SpaceThinker","creator_name":"Remyx AI","creator_url":"https://huggingface.co/remyxai","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["visual-question-answering","English","apache-2.0","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"clean_cot_verification_340k","keyword":"reasoning","description":"å…ƒãƒ‡ãƒ¼ã‚¿: https://huggingface.co/datasets/Zigeng/CoT-Verification-340k\nä½¿ç”¨ã—ãŸã‚³ãƒ¼ãƒ‰: https://github.com/LLMTeamAkiyama/0-data_prepare/tree/master/src/CoT-Verification-340k\n\nãƒ‡ãƒ¼ã‚¿ä»¶æ•°: 140,980\nå¹³å‡ãƒˆãƒ¼ã‚¯ãƒ³æ•°: 602\næœ€å¤§ãƒˆãƒ¼ã‚¯ãƒ³æ•°: 2,040\nåˆè¨ˆãƒˆãƒ¼ã‚¯ãƒ³æ•°: 84,894,510\nãƒ•ã‚¡ã‚¤ãƒ«å½¢å¼: JSONL\nãƒ•ã‚¡ã‚¤ãƒ«åˆ†å‰²æ•°: 2\nåˆè¨ˆãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚º: 256.3 MB\n\nåŠ å·¥å†…å®¹ï¼š\n\nãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆIDã®ä»˜ä¸: ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ã®ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã«1ã‚’åŠ ç®—ã—ã¦ã€base_datasets_idã¨ã—ã¦æ–°ã—ã„IDåˆ—ã‚’ä»˜ä¸ã—ã¾ã—ãŸã€‚\nresponseåˆ—ã®ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°: responseåˆ—ãŒã€ŒYes,ã€ã§å§‹ã¾ã‚‹è¡Œã®ã¿ã‚’ä¿æŒã—ã€ãã‚Œä»¥å¤–ã®è¡Œã‚’é™¤å¤–ã—ã¾ã—ãŸã€‚\npromptåˆ—ã®æ–‡å­—é•·ã«ã‚ˆã‚‹ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°: promptåˆ—ã®æ–‡å­—åˆ—ã®é•·ã•ãŒ80â€¦ See the full description on the dataset page: https://huggingface.co/datasets/LLMTeamAkiyama/clean_cot_verification_340k.","url":"https://huggingface.co/datasets/LLMTeamAkiyama/clean_cot_verification_340k","creator_name":"LLMTeamAkiyama","creator_url":"https://huggingface.co/LLMTeamAkiyama","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["question-answering","English","mit","100K - 1M","json"],"keywords_longer_than_N":true},
	{"name":"gliclass-v3-logic-dataset","keyword":"reasoning","description":"\n\n\t\n\t\t\n\t\tGLiClassâ€‘V3 Logic Dataset\n\t\n\nRowsâ€¯â€¯7â€¯776â€ƒ|â€ƒSplitâ€¯â€¯train onlyâ€ƒ|â€ƒFormatâ€¯â€¯Parquetâ€ƒ|â€ƒLanguageâ€¯â€¯ENâ€ƒ|â€ƒLicenseâ€¯â€¯Apacheâ€‘2.0\n\n\t\n\t\t\n\t\tWhat it is\n\t\n\nA lengthâ€‘balanced corpus of singleâ€‘sentence prompts built purely for inducing reasoning in language models.\n\n\t\n\t\t\n\t\tWhy it helps\n\t\n\n\nTeaches symbolicâ€‘logic patterns and multiâ€‘label behaviour.  \nBuckets cover 15 wordâ€‘length ranges (4â€¯â†’â€¯1,024) in equal proportions, exposing models to both tiny and very long inputs.  \nEach example has 1â€‘50 true andâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/knowledgator/gliclass-v3-logic-dataset.","url":"https://huggingface.co/datasets/knowledgator/gliclass-v3-logic-dataset","creator_name":"Knowledgator Engineering","creator_url":"https://huggingface.co/knowledgator","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","question-answering","sentence-similarity","English","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"thinker","keyword":"reasoning","description":"A Chain-of-Thought (CoT) dataset that contains traces of complex and sophisticated reasoning, to mimic the \"thinking\" process of OpenAI's o1. Wrap the contents of the reasoning column in some XML tag (such as <reasoning>).\nRaw .jsonl dataset file can be found under the Files and Versions tab.\n","url":"https://huggingface.co/datasets/minchyeom/thinker","creator_name":"Minchan","creator_url":"https://huggingface.co/minchyeom","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","English","apache-2.0","1K - 10K","parquet"],"keywords_longer_than_N":true},
	{"name":"general-reasoning-ift-pairs","keyword":"reasoning","description":"\n\t\n\t\t\n\t\tReasoning-IFT Pairs (General Domain)\n\t\n\n\n  \n\n\n\n\n  \n  \n\n\n\nThis dataset provides the largest set of IFT and Reasoning answers pairs for a set of general domain queries (cf: math-domain).It is based on the Infinity-Instruct dataset, an extensive and high-quality collection of instruction fine-tuning data.  \nWe curated 900k queries from the 7M_core subset of Infinity-Instruct, which covers multiple domains including general knowledge, commonsense Q&A, coding, and math.For each query, weâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/When-Does-Reasoning-Matter/general-reasoning-ift-pairs.","url":"https://huggingface.co/datasets/When-Does-Reasoning-Matter/general-reasoning-ift-pairs","creator_name":"When Does Reasoning Matter ?","creator_url":"https://huggingface.co/When-Does-Reasoning-Matter","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["question-answering","text-generation","English","mit","1M - 10M"],"keywords_longer_than_N":true},
	{"name":"error-detection-positives_perturbed","keyword":"reasoning","description":"\n\t\n\t\t\n\t\terror-detection-positives_perturbed\n\t\n\nThis dataset is part of the PARC (Premise-Annotated Reasoning Collection) and contains mathematical reasoning problems with error annotations. This dataset combines positives_perturbed samples from multiple domains.\n\n\t\n\t\t\n\t\tDomain Breakdown\n\t\n\n\ngsm8k: 48 samples\nmath: 42 samples\nmetamathqa: 72 samples\norca_math: 85 samples\n\n\n\t\n\t\t\n\t\tFeatures\n\t\n\nEach example contains:\n\ndata_source: The domain/source of the problem (gsm8k, math, metamathqaâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/PARC-DATASETS/error-detection-positives_perturbed.","url":"https://huggingface.co/datasets/PARC-DATASETS/error-detection-positives_perturbed","creator_name":"PARC","creator_url":"https://huggingface.co/PARC-DATASETS","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-generation","question-answering","English","mit","< 1K"],"keywords_longer_than_N":true},
	{"name":"hermes_reasoning_tool_use","keyword":"reasoning","description":"\n\t\n\t\t\n\t\tTL;DR\n\t\n\n51 004 ShareGPT conversations that teach LLMs when, how and whether to call tools.Built with the Nous Research Atropos RL stack in Atropos using a custom MultiTurnToolCallingEnv, and aligned with BFCL v3 evaluation scenarios.Released by @interstellarninja under Apache-2.0.\n\n\n\t\n\t\t\n\t\n\t\n\t\t1â€‚Dataset Highlights\n\t\n\n\n\t\n\t\t\nCount\nSplit\nScenarios covered\nSize\n\n\n\t\t\n51 004\ntrain\nsingle-turn Â· multi-turn Â· multi-step Â· relevance\n392 MB\n\n\n\t\n\n\nEach row: OpenAI-style conversationsâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/interstellarninja/hermes_reasoning_tool_use.","url":"https://huggingface.co/datasets/interstellarninja/hermes_reasoning_tool_use","creator_name":"interstellarninja","creator_url":"https://huggingface.co/interstellarninja","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["question-answering","English","apache-2.0","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"SLR-Bench","keyword":"reasoning","description":" \n\n\n\t\n\t\t\n\t\tSLR-Bench: Scalable Logical Reasoning Benchmark for LLMs\n\t\n\n\n\n\n\nğŸ†• August 2025: Build your own Reasoning Problems with Verifiable Rewards. Source Code is now available! ğŸ‘‰ Generate your own Reasoning Task\n\n\nğŸ†• June 2024: Evaluation & RLVR Reward Model Released!ğŸ‘‰ Demo on Hugging Face Spaces\n\nSLR-Bench is a scalable, fully-automated benchmark designed to systematically evaluate and train Large Language Models (LLMs) in logical reasoning via inductive logic programming (ILP) tasks.â€¦ See the full description on the dataset page: https://huggingface.co/datasets/AIML-TUDA/SLR-Bench.","url":"https://huggingface.co/datasets/AIML-TUDA/SLR-Bench","creator_name":"Artificial Intelligence & Machine Learning Lab at TU Darmstadt","creator_url":"https://huggingface.co/AIML-TUDA","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["English","cc-by-4.0","10K - 100K","parquet","Tabular"],"keywords_longer_than_N":true},
	{"name":"error-detection-positives_perturbed","keyword":"step-by-step","description":"\n\t\n\t\t\n\t\terror-detection-positives_perturbed\n\t\n\nThis dataset is part of the PARC (Premise-Annotated Reasoning Collection) and contains mathematical reasoning problems with error annotations. This dataset combines positives_perturbed samples from multiple domains.\n\n\t\n\t\t\n\t\tDomain Breakdown\n\t\n\n\ngsm8k: 48 samples\nmath: 42 samples\nmetamathqa: 72 samples\norca_math: 85 samples\n\n\n\t\n\t\t\n\t\tFeatures\n\t\n\nEach example contains:\n\ndata_source: The domain/source of the problem (gsm8k, math, metamathqaâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/PARC-DATASETS/error-detection-positives_perturbed.","url":"https://huggingface.co/datasets/PARC-DATASETS/error-detection-positives_perturbed","creator_name":"PARC","creator_url":"https://huggingface.co/PARC-DATASETS","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-generation","question-answering","English","mit","< 1K"],"keywords_longer_than_N":true},
	{"name":"MMOS","keyword":"reasoning","description":"ArXiv | Models | Data | Code | \nYou can download the dataset as follows\nfrom datasets import load_dataset\nds = load_dataset(\"cyzhh/MMOS\")\n\n\n\t\n\t\t\n\t\n\t\n\t\tSchema\n\t\n\nEach dataset row has the following structure\n{\n  \"idx\": ..., # problem id\n  \"prompt\": ..., # problem \n  \"completion\": ... # reasoning path with python\n}\n\n\n\t\t\n\t\n\t\tLicense\n\t\n\nWe do not alter the license of any of the underlying data.\n\n\t\n\t\t\n\t\tCitation\n\t\n\nFor the MMOS, cite \n@misc{chen2024empirical,\n      title={An Empirical Study of Dataâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/cyzhh/MMOS.","url":"https://huggingface.co/datasets/cyzhh/MMOS","creator_name":"Yezeng Chen","creator_url":"https://huggingface.co/cyzhh","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["question-answering","English","mit","100K - 1M","json"],"keywords_longer_than_N":true},
	{"name":"legal-reasoning-harmony","keyword":"reasoning","description":"\n\t\n\t\t\n\t\tLegal Reasoning Harmony (CoT â†’ Harmony)\n\t\n\nThis dataset converts moremilk/CoT_Legal_Issues_And_Laws (MIT-licensed) into the Harmony message format for GPT-OSS fine-tuning.\n\nSource: moremilk/CoT_Legal_Issues_And_Laws\nLicense: MIT (inherited from source)\nExamples: 4,237\nFormat: JSONL, Harmony messages with separated thinking and content\nFormat: JSONL, Harmony messages with explicit channels (analysis, final) and convenience top-level fields\n\n\n\t\n\t\n\t\n\t\tProvenance and transformationâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/zackproser/legal-reasoning-harmony.","url":"https://huggingface.co/datasets/zackproser/legal-reasoning-harmony","creator_name":"Zack Proser","creator_url":"https://huggingface.co/zackproser","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-generation","mit","1K - 10K","json","Text"],"keywords_longer_than_N":true},
	{"name":"DeepMath-103K","keyword":"reasoning","description":"\n\t\n\t\t\n\t\tDeepMath-103K\n\t\n\n\n  \n    \n      \n        \n      \n    \n    \n      \n        \n      \n    \n    \n      \n        \n      \n    \n    \n      \n        \n\t\n\t\t\n\t\tğŸ”¥ News\n\t\n\n\nMay 8, 2025: We found that 48 samples contained hints that revealed the answers. The relevant questions have now been revised to remove the leaked answers.\nApril 14, 2025: We release DeepMath-103K, a large-scale dataset featuring challenging, verifiable, and decontaminated math problems tailored for RL and SFT. We open source:â€¦ See the full description on the dataset page: https://huggingface.co/datasets/zwhe99/DeepMath-103K.","url":"https://huggingface.co/datasets/zwhe99/DeepMath-103K","creator_name":"Zhiwei He","creator_url":"https://huggingface.co/zwhe99","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-generation","English","mit","100K - 1M","parquet"],"keywords_longer_than_N":true},
	{"name":"Risky_Choices","keyword":"reasoning","description":"Dataset Summary\nThe Risky Choices dataset is a derived version of the original choices13k dataset. It is designed to assist in training language models for tasks such as decision-making reasoning, explanation generation, and natural language processing. The dataset contains human decision rates on 13,006 risky choice problems, restructured into a natural language format suitable for various AI and ML applications.\nIn this processed version, each entry is presented as a decision-making scenarioâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Josephgflowers/Risky_Choices.","url":"https://huggingface.co/datasets/Josephgflowers/Risky_Choices","creator_name":"Joseph G Flowers","creator_url":"https://huggingface.co/Josephgflowers","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["English","mit","10K - 100K","csv","Text"],"keywords_longer_than_N":true},
	{"name":"wmdp_chem_preprocess","keyword":"reasoning","description":"\n\t\n\t\t\n\t\tWMDP-Chem Preprocessed Dataset\n\t\n\nThis dataset is a preprocessed version of wmdp-chem.\nThe data has been formatted into a question and answer structure suitable for training or evaluating instruction-following language models.\n\n\t\n\t\t\n\t\tData Structure\n\t\n\n\nquestion: The original question text.\nanswer: The correct answer text, prefixed with ####.\n\n\n\t\n\t\t\n\t\tExample\n\t\n\nQuestion:\n[Example Question Text]\n\nAnswer:\n#### [Example Answer Text]\n\n\n\t\n\t\t\n\t\tSplits\n\t\n\nThe original test split isâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/LLMcompe-Team-Watanabe/wmdp_chem_preprocess.","url":"https://huggingface.co/datasets/LLMcompe-Team-Watanabe/wmdp_chem_preprocess","creator_name":"LLMcompe Team Watanabe","creator_url":"https://huggingface.co/LLMcompe-Team-Watanabe","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["question-answering","expert-generated","found","monolingual","English"],"keywords_longer_than_N":true},
	{"name":"amc_aime_distilled","keyword":"step-by-step","description":"A dataset containing mathematical problem-solving traces with step-by-step solutions and improvement history. Each record includes a mathematical problem, its final solution, and the iterative improvement process.","url":"https://huggingface.co/datasets/camel-ai/amc_aime_distilled","creator_name":"CAMEL-AI.org","creator_url":"https://huggingface.co/camel-ai","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-generation","English","mit","1K - 10K","json"],"keywords_longer_than_N":true},
	{"name":"clevr-tr","keyword":"reasoning","description":"\n\t\n\t\t\n\t\tDataset Card for CoT\n\t\n\n\n\t\n\t\t\n\t\tDataset Sources\n\t\n\n\nRepository: LLaVA-CoT GitHub Repository\nPaper: LLaVA-CoT on arXiv\n\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nunzip image.zip\n\nThe train.jsonl file contains the question-answering data and is structured in the following format:\n{\n  \"id\": \"example_id\",\n  \"image\": \"example_image_path\",\n  \"conversations\": [\n    {\"from\": \"human\", \"value\": \"LÃ¼tfen resimdeki kÄ±rmÄ±zÄ± metal nesnelerin sayÄ±sÄ±nÄ± belirtin.\"},\n    {\"from\": \"gpt\", \"value\": \"Resimde 3 kÄ±rmÄ±zÄ±â€¦ See the full description on the dataset page: https://huggingface.co/datasets/berhaan/clevr-tr.","url":"https://huggingface.co/datasets/berhaan/clevr-tr","creator_name":"Berhan TÃ¼rkÃ¼ Ay","creator_url":"https://huggingface.co/berhaan","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["visual-question-answering","English","Turkish","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"thinking-multilingual-30-23-small-690","keyword":"reasoning","description":"\nBased on OPENO1 math, this is a translated dataset of 30 high quality questions & answers in 23 languages. \nOr use the \"big\" version: big 10k rows version\n","url":"https://huggingface.co/datasets/Pinkstack/thinking-multilingual-30-23-small-690","creator_name":"Pinkstack","creator_url":"https://huggingface.co/Pinkstack","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","Arabic","Chinese","Czech","Danish"],"keywords_longer_than_N":true},
	{"name":"PathFinder-600K","keyword":"reasoning","description":"\n\t\n\t\t\n\t\tPathFinder-600K\n\t\n\nThis dataset provides step-level training labels for approximately 600K reasoning traces, of which 400K were used in training the PathFinder-PRM-7B model. It is constructed by augmenting two existing datasetsâ€”PRM800K and RLHFlow Mistralâ€”with fine-grained, three-dimensional annotations for each reasoning step:\n\nWhether the step is mathematically correct,\nWhether it is logically consistent, and\nWhether it ultimately leads to a correct final solution.\n\nThe dataset isâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/declare-lab/PathFinder-600K.","url":"https://huggingface.co/datasets/declare-lab/PathFinder-600K","creator_name":"Deep Cognition and Language Research (DeCLaRe) Lab","creator_url":"https://huggingface.co/declare-lab","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":null,"first_N":5,"first_N_keywords":["question-answering","English","mit","1M<n<10M","arxiv:2505.19706"],"keywords_longer_than_N":true},
	{"name":"math-problems-greedy-vs-best-of-n","keyword":"mathematical-reasoning","description":"\n\t\n\t\t\n\t\tProblem Solving Math Dataset - Greedy vs Best-of-N\n\t\n\nThis dataset contains mathematical problems and their solutions generated using two decoding strategies:\n\nGreedy Decoding: Generates a single deterministic solution.\nBest-of-N Decoding: Generates N solutions and selects the best one based on a scoring metric.\n\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nThis dataset is created with a filtered subset of 20 level 1-3 problems from the MATH-500 dataset.\nTo have a balance across the levels, theâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Tandogan/math-problems-greedy-vs-best-of-n.","url":"https://huggingface.co/datasets/Tandogan/math-problems-greedy-vs-best-of-n","creator_name":"Zeynep","creator_url":"https://huggingface.co/Tandogan","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","English","apache-2.0","< 1K","parquet"],"keywords_longer_than_N":true},
	{"name":"Olympiads_hard","keyword":"mathematical-reasoning","description":"\n\t\n\t\t\n\t\tNumina-Olympiads\n\t\n\nFiltered NuminaMath-CoT dataset containing only olympiads problems with valid answers.\n\n\t\n\t\t\n\t\tDataset Information\n\t\n\n\nSplit: train\nOriginal size: 21525\nFiltered size: 21408\nSource: olympiads\nAll examples contain valid boxed answers\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset is a filtered version of the NuminaMath-CoT dataset, containing only problems from olympiad sources that have valid boxed answers. Each example includes:\n\nA mathematical word problem\nAâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Metaskepsis/Olympiads_hard.","url":"https://huggingface.co/datasets/Metaskepsis/Olympiads_hard","creator_name":"Metaskepsis","creator_url":"https://huggingface.co/Metaskepsis","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-generation","expert-generated","expert-generated","monolingual","AI-MO/NuminaMath-CoT"],"keywords_longer_than_N":true},
	{"name":"bilmecebench","keyword":"reasoning","description":"\n\n\t\n\t\t\n\t\tBilmeceBench: Turkish Cultural Reasoning Benchmark\n\t\n\nBilmeceBench is a collection of traditional Turkish riddles designed to evaluate language models' cultural understanding and reasoning capabilities. The dataset contains authentic Turkish riddles (bilmece) that require both linguistic comprehension and cultural context to solve. Unfortunately, I currently lack the resources and time to conduct comprehensive model testing or evaluations, but users can utilize this dataset to performâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/selimc/bilmecebench.","url":"https://huggingface.co/datasets/selimc/bilmecebench","creator_name":"selim","creator_url":"https://huggingface.co/selimc","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["Turkish","mit","< 1K","parquet","Text"],"keywords_longer_than_N":true},
	{"name":"step_prm","keyword":"reasoning","description":"\n\t\n\t\t\næ•°æ®é›†åç§°\næ˜¯å¦æœ‰step\nå¯ç”¨äºPRMè®­ç»ƒ\næ ‡ç­¾å½¢å¼\nTitle\nå¤‡æ³¨\n\n\n\t\t\nGSM8K\nâœ…\nâŒ\nç­”æ¡ˆ\nTraining Verifiers to Solve Math Word Problems\n\n\n\nMATH\nâŒ\nâŒ\nç­”æ¡ˆ\nMeasuring Mathematical Problem Solving With the MATH Dataset\nNon-Step\n\n\nPRM800K\nâœ…\nâœ…\næ­£ç¡®ç±»åˆ«\nLet's Verify Step by Step\nprompt deduplication\n\n\nMath-Shepherd\nâœ…\nâœ…\næ­£ç¡®ç±»åˆ«\nMath-Shepherd: Verify and Reinforce LLMs Step-by-step without Human Annotations\nNot used\n\n\nProcessBench\nâœ…\nâœ…\né¦–ä¸ªé”™è¯¯æ­¥éª¤\nProcessBench: Identifying Process Errors in Mathematical Reasoning\nonly label -1\n\n\n\t\n\n","url":"https://huggingface.co/datasets/xiaodongguaAIGC/step_prm","creator_name":"xiaodongguaAIGC","creator_url":"https://huggingface.co/xiaodongguaAIGC","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","question-answering","text-generation","English","mit"],"keywords_longer_than_N":true},
	{"name":"rulebreakers","keyword":"reasoning","description":"jason-c/rulebreakers dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/jason-c/rulebreakers","creator_name":"Jason Chan","creator_url":"https://huggingface.co/jason-c","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["English","cc-by-4.0","10K - 100K","csv","Text"],"keywords_longer_than_N":true},
	{"name":"BuddhismEval","keyword":"reasoning","description":"\n\t\n\t\t\n\t\tDataset Card for BuddhismEval\n\t\n\nBuddhismEval is the first bilingual evaluation benchmark designed to assess large language models (LLMs) on Buddhist ethical reasoning and philosophical understanding across Sinhala and English. It includes high-quality, culturally grounded multiple-choice question (MCQ) datasets derived primarily from the Dhammapada, a core TheravÄda Buddhist scripture, and other canonical sources and exam materials from Sri Lanka.\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Detailsâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Nethmi14/BuddhismEval.","url":"https://huggingface.co/datasets/Nethmi14/BuddhismEval","creator_name":"Nethmi Muthugala","creator_url":"https://huggingface.co/Nethmi14","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["question-answering","multiple-choice","English","Sinhala","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"Mining-Engineering-SFT-CoT","keyword":"reasoning","description":"\n\t\n\t\t\n\t\tçŸ¿å»ºå·¥ç¨‹é¢†åŸŸä¸­æ–‡æŒ‡ä»¤ä¸è¯„ä¼°æ•°æ®é›†ï¼ˆå¸¦CoTæ ‡æ³¨ï¼‰\n\t\n\n\n\t\n\t\t\n\t\tæ•°æ®é›†æ¦‚è¿°\n\t\n\næœ¬é¡¹ç›®æ˜¯åˆè‚¥å·¥ä¸šå¤§å­¦å¤§ä¸€å­¦ç”Ÿçš„å¤§å­¦ç”Ÿåˆ›æ–°åˆ›ä¸šè®­ç»ƒè®¡åˆ’ï¼ˆå¤§åˆ›ï¼‰é¡¹ç›®æˆæœã€‚æˆ‘ä»¬æ„å»ºäº†ä¸€å¥—ä¸“ä¸ºæå‡å¤§å‹è¯­è¨€æ¨¡å‹åœ¨ä¸­å›½çŸ¿å»ºå·¥ç¨‹é¢†åŸŸä¸“ä¸šçŸ¥è¯†ä¸å®è·µèƒ½åŠ›è€Œè®¾è®¡çš„ä¸­æ–‡æ•°æ®é›†ã€‚\nè¿™å¥—æ•°æ®é›†æ—¨åœ¨è®©æ¨¡å‹æŒæ¡çŸ¿å»ºå·¥ç¨‹çš„æ ¸å¿ƒçŸ¥è¯†ï¼Œå†…å®¹è¦†ç›–äº†å…­å¤§æ¨¡å—ï¼š\n\næ³•å¾‹æ³•è§„ (law)\nå·¥ç¨‹è§„èŒƒ (specifications)\nä¸“ä¸šæœ¯è¯­ (concept)\nå®‰å…¨äº‹æ•…æ¡ˆä¾‹ (safety)\nè¡Œä¸šå®è·µç»éªŒ (forum)\né¢†åŸŸç»¼åˆçŸ¥è¯† (synthesis)\n\nä¸ºäº†æ”¯æŒå®Œæ•´çš„æ¨¡å‹å¼€å‘ã€è¯„ä¼°å’ŒéªŒè¯å‘¨æœŸï¼Œæˆ‘ä»¬å°†æ•°æ®ç»„ç»‡ä¸ºå¤šä¸ªç‹¬ç«‹çš„Hugging Faceä»“åº“ï¼š\n\nåŸå§‹è®­ç»ƒé›† (Original SFT Dataset)ï¼šåŒ…å« 5,287 æ¡é«˜è´¨é‡çš„â€œæŒ‡ä»¤-å›ç­”â€å¯¹ï¼Œç”¨äºåŸºç¡€çš„æ¨¡å‹å¾®è°ƒã€‚\næ€ç»´é“¾å¢å¼ºè®­ç»ƒé›† (CoT-Enhanced SFTâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/acnul/Mining-Engineering-SFT-CoT.","url":"https://huggingface.co/datasets/acnul/Mining-Engineering-SFT-CoT","creator_name":"acnul","creator_url":"https://huggingface.co/acnul","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["Chinese","mit","1K - 10K","parquet","Text"],"keywords_longer_than_N":true},
	{"name":"cleand_flatlander1024_or_instruct_dedup","keyword":"reasoning","description":"å…ƒãƒ‡ãƒ¼ã‚¿: https://huggingface.co/datasets/flatlander1024/or_instruct_dedup\nä½¿ç”¨ã—ãŸã‚³ãƒ¼ãƒ‰: https://github.com/LLMTeamAkiyama/0-data_prepare/tree/master/src/flatlander1024-or_instruct_dedup\n\nãƒ‡ãƒ¼ã‚¿ä»¶æ•°: 2,600\nå¹³å‡ãƒˆãƒ¼ã‚¯ãƒ³æ•°: 1,340\næœ€å¤§ãƒˆãƒ¼ã‚¯ãƒ³æ•°: 3,086\nåˆè¨ˆãƒˆãƒ¼ã‚¯ãƒ³æ•°: 3,484,377\nãƒ•ã‚¡ã‚¤ãƒ«å½¢å¼: JSONL\nãƒ•ã‚¡ã‚¤ãƒ«åˆ†å‰²æ•°: 1\nåˆè¨ˆãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚º: 13.0 MB\n\nåŠ å·¥å†…å®¹ï¼š\n\nãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®åˆæœŸè¨­å®šã¨èª­ã¿è¾¼ã¿:\nflatlander1024/or_instruct_dedup ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’èª­ã¿è¾¼ã¿ã€Pandas DataFrameã«å¤‰æ›ã—ã¾ã—ãŸã€‚\nanswer åˆ—ã®ãƒ‡ãƒ¼ã‚¿å‹ã‚’æ–‡å­—åˆ— (str) ã«å¤‰æ›ã—ã¾ã—ãŸã€‚\nNLTKã®punktã¨stopwordsãƒ‡ãƒ¼ã‚¿ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã—ã¾ã—ãŸï¼ˆå¿…è¦ãªå ´åˆï¼‰ã€‚\n\n\nIDã®ä»˜ä¸:â€¦ See the full description on the dataset page: https://huggingface.co/datasets/LLMTeamAkiyama/cleand_flatlander1024_or_instruct_dedup.","url":"https://huggingface.co/datasets/LLMTeamAkiyama/cleand_flatlander1024_or_instruct_dedup","creator_name":"LLMTeamAkiyama","creator_url":"https://huggingface.co/LLMTeamAkiyama","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["question-answering","English","mit","1K - 10K","json"],"keywords_longer_than_N":true},
	{"name":"Med-REFL-DPO","keyword":"reasoning","description":"\n\t\n\t\t\n\t\tNews\n\t\n\n[2025/06/10] We are releasing the Med-REFL dataset, which is split into two subsets: Reasoning Enhancement Data and Reflection Enhancement Data.\n\n\t\n\t\t\n\t\tIntroduction\n\t\n\nThis is the Direct Preference Optimization (DPO) dataset created by the Med-REFL framework, designed to improve the reasoning and reflection capabilities of Large Language Models in the medical field.\nThe dataset is constructed using a low-cost, scalable pipeline that leverages a Tree-of-Thought (ToT) approachâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/HANI-LAB/Med-REFL-DPO.","url":"https://huggingface.co/datasets/HANI-LAB/Med-REFL-DPO","creator_name":"HANI-LAB","creator_url":"https://huggingface.co/HANI-LAB","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["question-answering","text-generation","English","apache-2.0","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"Med-REFL-DPO","keyword":"reflection","description":"\n\t\n\t\t\n\t\tNews\n\t\n\n[2025/06/10] We are releasing the Med-REFL dataset, which is split into two subsets: Reasoning Enhancement Data and Reflection Enhancement Data.\n\n\t\n\t\t\n\t\tIntroduction\n\t\n\nThis is the Direct Preference Optimization (DPO) dataset created by the Med-REFL framework, designed to improve the reasoning and reflection capabilities of Large Language Models in the medical field.\nThe dataset is constructed using a low-cost, scalable pipeline that leverages a Tree-of-Thought (ToT) approachâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/HANI-LAB/Med-REFL-DPO.","url":"https://huggingface.co/datasets/HANI-LAB/Med-REFL-DPO","creator_name":"HANI-LAB","creator_url":"https://huggingface.co/HANI-LAB","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["question-answering","text-generation","English","apache-2.0","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"PARARULE-Plus","keyword":"reasoning","description":"\n\t\n\t\t\n\t\tPARARULE-Plus\n\t\n\nThis is a branch which includes the dataset from PARARULE-Plus Depth=2, Depth=3, Depth=4 and Depth=5. PARARULE Plus is a deep multi-step reasoning dataset over natural language. It can be seen as an improvement on the dataset of PARARULE (Peter Clark et al., 2020). Both PARARULE and PARARULE-Plus follow the closed-world assumption and negation as failure. The motivation is to generate deeper PARARULE training samples. We add more training samples for the case where theâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/qbao775/PARARULE-Plus.","url":"https://huggingface.co/datasets/qbao775/PARARULE-Plus","creator_name":"annonymous_user","creator_url":"https://huggingface.co/qbao775","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","question-answering","English","mit","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"PARARULE-Plus","keyword":"logical-reasoning","description":"\n\t\n\t\t\n\t\tPARARULE-Plus\n\t\n\nThis is a branch which includes the dataset from PARARULE-Plus Depth=2, Depth=3, Depth=4 and Depth=5. PARARULE Plus is a deep multi-step reasoning dataset over natural language. It can be seen as an improvement on the dataset of PARARULE (Peter Clark et al., 2020). Both PARARULE and PARARULE-Plus follow the closed-world assumption and negation as failure. The motivation is to generate deeper PARARULE training samples. We add more training samples for the case where theâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/qbao775/PARARULE-Plus.","url":"https://huggingface.co/datasets/qbao775/PARARULE-Plus","creator_name":"annonymous_user","creator_url":"https://huggingface.co/qbao775","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","question-answering","English","mit","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"fever_dplace_q","keyword":"reasoning","description":"\n\t\n\t\t\n\t\tFEVER-DPLACE-Q\n\t\n\nFEVER-DPLACE-Q is a controlled English dataset of 185 manually reviewed questionâ€“answer triplets.It merges structured factual statements from FEVER (Thorne et al., 2018) and D-PLACE (Kirby et al., 2016) to study entailment, contradiction, and cultural discrepancy through generated examples.\nEach entry contains two answersâ€”one supporting and one contradicting the claimâ€”along with reasoning outputs from multiple large language models (GPT-4o, LLaMA-3.3:70B, andâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/lcalvobartolome/fever_dplace_q.","url":"https://huggingface.co/datasets/lcalvobartolome/fever_dplace_q","creator_name":"Lorena Calvo BartolomÃ©","creator_url":"https://huggingface.co/lcalvobartolome","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["English","mit","< 1K","csv","Text"],"keywords_longer_than_N":true},
	{"name":"mathtrap300-batch1","keyword":"reasoning","description":"\n\t\n\t\t\n\t\tMathTrap300\n\t\n\nA benchmark dataset of 300 insolvable, ill-posed mathematical problems designed to evaluate large language models' ability to recognize mathematical insolvability and fundamental contradictions.\n\n\t\n\t\t\n\t\tDescription\n\t\n\nWhile modern large language models (LLMs) achieve high accuracy on many challenging math benchmarks, they often struggle to recognize the insolvability of ill-posed problems. Existing benchmarks for insolvable problems, however, are either modified fromâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/GYASBGFUHAADSGADF/mathtrap300-batch1.","url":"https://huggingface.co/datasets/GYASBGFUHAADSGADF/mathtrap300-batch1","creator_name":"AAAA","creator_url":"https://huggingface.co/GYASBGFUHAADSGADF","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["mit","ğŸ‡ºğŸ‡¸ Region: US","mathematics","education","reasoning"],"keywords_longer_than_N":true},
	{"name":"logic_duo","keyword":"logical-reasoning","description":"\n\t\n\t\t\n\t\tLogicDuo: Bilingual Logical Reasoning Tutoring Corpus\n\t\n\nCreated using this projectĞ¡Ğ¾Ğ·Ğ´Ğ°Ğ½Ğ¾ Ñ Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ğ½Ğ¸ĞµĞ¼ ÑÑ‚Ğ¾Ğ³Ğ¾ Ğ¿Ñ€Ğ¾ĞµĞºÑ‚Ğ°  \n\nğŸ‡·ğŸ‡º Ğ ÑƒÑÑĞºĞ°Ñ Ğ²ĞµÑ€ÑĞ¸Ñ / Russian version...\n\n\n\t\n\t\t\n\t\n\t\n\t\tĞšĞ¾Ñ€Ğ¿ÑƒÑ \"LogicDuo\": ĞĞ±ÑƒÑ‡ĞµĞ½Ğ¸Ğµ Ğ»Ğ¾Ğ³Ğ¸Ñ‡ĞµÑĞºĞ¾Ğ¼Ñƒ Ğ¼Ñ‹ÑˆĞ»ĞµĞ½Ğ¸Ñ Ğ½Ğ° Ñ€ÑƒÑÑĞºĞ¾Ğ¼ Ğ¸ Ğ°Ğ½Ğ³Ğ»Ğ¸Ğ¹ÑĞºĞ¾Ğ¼\n\t\n\nĞ¡Ğ¿ĞµÑ†Ğ¸Ğ°Ğ»Ğ¸Ğ·Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ½Ñ‹Ğ¹ Ğ´Ğ°Ñ‚Ğ°ÑĞµÑ‚ Ğ´Ğ»Ñ Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ñ Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹ Ğ¸ÑĞºÑƒÑÑÑ‚Ğ²ĞµĞ½Ğ½Ğ¾Ğ³Ğ¾ Ğ¸Ğ½Ñ‚ĞµĞ»Ğ»ĞµĞºÑ‚Ğ° Ğ²ĞµĞ´ĞµĞ½Ğ¸Ñ ÑÑ‚Ñ€ÑƒĞºÑ‚ÑƒÑ€Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ½Ñ‹Ñ… Ğ¾Ğ±Ñ€Ğ°Ğ·Ğ¾Ğ²Ğ°Ñ‚ĞµĞ»ÑŒĞ½Ñ‹Ñ… Ğ´Ğ¸Ğ°Ğ»Ğ¾Ğ³Ğ¾Ğ², Ğ½Ğ°Ğ¿Ñ€Ğ°Ğ²Ğ»ĞµĞ½Ğ½Ñ‹Ñ… Ğ½Ğ° Ñ€Ğ°Ğ·Ğ²Ğ¸Ñ‚Ğ¸Ğµ Ğ»Ğ¾Ğ³Ğ¸Ñ‡ĞµÑĞºĞ¾Ğ³Ğ¾ Ğ¸ ĞºÑ€Ğ¸Ñ‚Ğ¸Ñ‡ĞµÑĞºĞ¾Ğ³Ğ¾ Ğ¼Ñ‹ÑˆĞ»ĞµĞ½Ğ¸Ñ. ĞšĞ°Ğ¶Ğ´Ğ°Ñ Ğ·Ğ°Ğ¿Ğ¸ÑÑŒ Ğ¿Ñ€ĞµĞ´ÑÑ‚Ğ°Ğ²Ğ»ÑĞµÑ‚ ÑĞ¾Ğ±Ğ¾Ğ¹ Ğ´Ğ¸Ğ°Ğ»Ğ¾Ğ³ Ğ¼ĞµĞ¶Ğ´Ñƒâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/loim/logic_duo.","url":"https://huggingface.co/datasets/loim/logic_duo","creator_name":"Arsen Arutunan","creator_url":"https://huggingface.co/loim","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["Russian","English","mit","1K<n<10K","ğŸ‡ºğŸ‡¸ Region: US"],"keywords_longer_than_N":true},
	{"name":"Light-R1-DPOData","keyword":"reasoning","description":"\n\t\n\t\t\n\t\tLight-R1: Surpassing R1-Distill from Scratch* with $1000 through Curriculum SFT & DPO\n\t\n\n*from models without long COT\ntechnical report\nGitHub page\nHere is the DPO data we used to train Light-R1-32B.\nSimply refer to dpo-pairs.json\n\n\t\n\t\t\nModel\nTrained From\nRelease Date\nAIME24\nAIME25\n\n\n\t\t\nDeepSeek-R1-Distill-Llama-70B\nLlama-3.3-70B-Instruct\n25.1.20\n70.0\n54.1\n\n\nDeepSeek-R1-Distill-Qwen-32B\nQwen2.5-32B\n25.1.20\n72.6\n54.9\n\n\nLIMO (32B)\nQwen2.5-32B-Instruct25.2.4\n56.3\n47.1\n\n\ns1.1-32Bâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/qihoo360/Light-R1-DPOData.","url":"https://huggingface.co/datasets/qihoo360/Light-R1-DPOData","creator_name":"åŒ—äº¬å¥‡è™ç§‘æŠ€æœ‰é™å…¬å¸","creator_url":"https://huggingface.co/qihoo360","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","apache-2.0","1K - 10K","json","Text"],"keywords_longer_than_N":true},
	{"name":"lumos_multimodal_plan_iterative","keyword":"reasoning","description":"\n\t\n\t\t\n\t\tğŸª„ Agent Lumos: Unified and Modular Training for Open-Source Language Agents\n\t\n\n\n  ğŸŒ[Website] Â \n  ğŸ“[Paper] Â \n  ğŸ¤—[Data] Â \n  ğŸ¤—[Model] Â \n  ğŸ¤—[Demo] Â \n\n\nWe introduce ğŸª„Lumos, Language Agents with Unified Formats, Modular Design, and Open-Source LLMs. Lumos unifies a suite of complex interactive tasks and achieves competitive performance with GPT-4/3.5-based and larger open-source agents. \nLumos has following features:\n\nğŸ§© Modular Architecture:\nğŸ§© Lumos consists of planning, groundingâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/ai2lumos/lumos_multimodal_plan_iterative.","url":"https://huggingface.co/datasets/ai2lumos/lumos_multimodal_plan_iterative","creator_name":"Lumos  Agents (AI2)","creator_url":"https://huggingface.co/ai2lumos","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","question-answering","English","apache-2.0","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"lumos_multimodal_ground_iterative","keyword":"reasoning","description":"\n\t\n\t\t\n\t\tğŸª„ Agent Lumos: Unified and Modular Training for Open-Source Language Agents\n\t\n\n\n  ğŸŒ[Website] Â \n  ğŸ“[Paper] Â \n  ğŸ¤—[Data] Â \n  ğŸ¤—[Model] Â \n  ğŸ¤—[Demo] Â \n\n\nWe introduce ğŸª„Lumos, Language Agents with Unified Formats, Modular Design, and Open-Source LLMs. Lumos unifies a suite of complex interactive tasks and achieves competitive performance with GPT-4/3.5-based and larger open-source agents. \nLumos has following features:\n\nğŸ§© Modular Architecture:\nğŸ§© Lumos consists of planning, groundingâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/ai2lumos/lumos_multimodal_ground_iterative.","url":"https://huggingface.co/datasets/ai2lumos/lumos_multimodal_ground_iterative","creator_name":"Lumos  Agents (AI2)","creator_url":"https://huggingface.co/ai2lumos","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","question-answering","English","apache-2.0","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"SLR-Bench-German","keyword":"reasoning","description":" \n\n\n\t\n\t\t\n\t\tğŸ§  SLR-Bench-German: Scalable Logical Reasoning Benchmark (German Edition)\n\t\n\n\n\n\n\nSLR-Bench-German is the German-language pendant of the original SLR-Bench dataset.\nIt follows the same symbolic structure, evaluation framework, and curriculum as the English version but provides all natural-language task prompts translated into German.\nThis enables systematic evaluation and training of Large Language Models (LLMs) in logical reasoning in german, supporting both multilingual reasoningâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/AIML-TUDA/SLR-Bench-German.","url":"https://huggingface.co/datasets/AIML-TUDA/SLR-Bench-German","creator_name":"Artificial Intelligence & Machine Learning Lab at TU Darmstadt","creator_url":"https://huggingface.co/AIML-TUDA","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["German","cc-by-4.0","10K - 100K","parquet","Tabular"],"keywords_longer_than_N":true},
	{"name":"ProofBench","keyword":"mathematical-reasoning","description":"\n\t\n\t\t\n\t\tProofBench Dataset\n\t\n\nProofBench is a comprehensive benchmark dataset for evaluating AI models on mathematical proof generation and verification. The dataset contains competition-level mathematics problems from prestigious international competitions, along with both AI-generated and reference solutions, expert ratings, and detailed marking schemes.\n\n\t\n\t\t\n\t\tDataset Overview\n\t\n\n\nTotal Problems: 435\nCompetitions: PUTNAM, IMO, USAMO, EGMO, APMO, TST\nYears Covered: 2022-2025\nAI Models:â€¦ See the full description on the dataset page: https://huggingface.co/datasets/wenjiema02/ProofBench.","url":"https://huggingface.co/datasets/wenjiema02/ProofBench","creator_name":"Wenjie Ma","creator_url":"https://huggingface.co/wenjiema02","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["question-answering","text-generation","English","mit","< 1K"],"keywords_longer_than_N":true},
	{"name":"SLR-Bench-Spanish","keyword":"reasoning","description":" \n\n\n\t\n\t\t\n\t\tğŸ§  SLR-Bench-Spanish: Scalable Logical Reasoning Benchmark (Spanish Edition)\n\t\n\n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tSLR-Bench Versions:\n\t\n\n\n\n\nSLR-Bench-Spanish is the Spanish-language pendant of the original SLR-Bench dataset.\nIt follows the same symbolic structure, evaluation framework, and curriculum as the English version but provides all natural-language task prompts translated into Spanish.\nThis enables systematic evaluation and training of Large Language Models (LLMs) in logical reasoning inâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/AIML-TUDA/SLR-Bench-Spanish.","url":"https://huggingface.co/datasets/AIML-TUDA/SLR-Bench-Spanish","creator_name":"Artificial Intelligence & Machine Learning Lab at TU Darmstadt","creator_url":"https://huggingface.co/AIML-TUDA","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["Spanish","cc-by-4.0","10K - 100K","parquet","Tabular"],"keywords_longer_than_N":true},
	{"name":"ReSA","keyword":"reasoning","description":"ReSA (Reasoned Safety Alignment) is an open-source synthetic safety-training dataset with 80K examples designed to enhance LLM robustness against jailbreak attacks through an \"Answer-Then-Check\" strategy. The dataset teaches models to first generate a summary of their intended answer, then critically evaluate its safety before providing a final response. This approach achieves superior safety performance while maintaining strong general capabilities and reducing over-refusal rates.â€¦ See the full description on the dataset page: https://huggingface.co/datasets/ByteDance-Seed/ReSA.","url":"https://huggingface.co/datasets/ByteDance-Seed/ReSA","creator_name":"ByteDance Seed","creator_url":"https://huggingface.co/ByteDance-Seed","license_name":"Open Data Commons Attribution License v1.0","license_url":"https://scancode-licensedb.aboutcode.org/odc-by-1.0.html","language":null,"first_N":5,"first_N_keywords":["text-generation","English","odc-by","100M<n<1B","arxiv:2509.11629"],"keywords_longer_than_N":true},
	{"name":"AARA_Azerbaijani_LLM_Benchmark","keyword":"reasoning","description":"AARA: Azerbaijani Advanced Reasoning Assessment\nThis dataset is the Azerbaijani-translated version of the emre/TARA_Turkish_LLM_Benchmark.\n","url":"https://huggingface.co/datasets/khazarai/AARA_Azerbaijani_LLM_Benchmark","creator_name":"KhazarAI","creator_url":"https://huggingface.co/khazarai","license_name":"Academic Free License v3.0","license_url":"https://choosealicense.com/licenses/afl-3.0/","language":"en","first_N":5,"first_N_keywords":["question-answering","text-generation","Azerbaijani","afl-3.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"DRIFT-TL-Distill-4K","keyword":"reasoning","description":"\n\t\n\t\t\n\t\tDRIFT-TL-Distill-4K Dataset\n\t\n\nThis dataset contains multimodal reasoning examples with images and step-by-step thinking processes.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nEach example contains:\n\nmessages: Conversation between user and assistant with image references\nimages: Paths to associated images\n\n\n\t\n\t\t\n\t\tUsage\n\t\n\nfrom datasets import load_dataset\n\ndataset = load_dataset(\"ChaoHuangCS/DRIFT-TL-Distill-4K\")\n\n\n\t\n\t\t\n\t\tCitation\n\t\n\nIf you use this dataset, please cite our paper.\n","url":"https://huggingface.co/datasets/ChaoHuangCS/DRIFT-TL-Distill-4K","creator_name":"Chao Huang","creator_url":"https://huggingface.co/ChaoHuangCS","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["visual-question-answering","English","mit","1K - 10K","json"],"keywords_longer_than_N":true},
	{"name":"lumos_web_agent_ground_iterative","keyword":"reasoning","description":"\n\t\n\t\t\n\t\tğŸª„ Agent Lumos: Unified and Modular Training for Open-Source Language Agents\n\t\n\n\n  ğŸŒ[Website] Â \n  ğŸ“[Paper] Â \n  ğŸ¤—[Data] Â \n  ğŸ¤—[Model] Â \n  ğŸ¤—[Demo] Â \n\n\nWe introduce ğŸª„Lumos, Language Agents with Unified Formats, Modular Design, and Open-Source LLMs. Lumos unifies a suite of complex interactive tasks and achieves competitive performance with GPT-4/3.5-based and larger open-source agents. \nLumos has following features:\n\nğŸ§© Modular Architecture:\nğŸ§© Lumos consists of planning, groundingâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/ai2lumos/lumos_web_agent_ground_iterative.","url":"https://huggingface.co/datasets/ai2lumos/lumos_web_agent_ground_iterative","creator_name":"Lumos  Agents (AI2)","creator_url":"https://huggingface.co/ai2lumos","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","English","apache-2.0","1K - 10K","json"],"keywords_longer_than_N":true},
	{"name":"spanex","keyword":"reasoning","description":"SpanEx consists of 7071 instances annotated for span interactions.\nSpanEx is the first dataset with human phrase-level interaction explanations with explicit labels for interaction types. \nMoreover, SpanEx is annotated by three annotators, which opens new avenues for studies of human explanation agreement -- an understudied area in the explainability literature. \nOur study reveals that while human annotators often agree on span interactions, they also offer complementary reasons for aâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/copenlu/spanex.","url":"https://huggingface.co/datasets/copenlu/spanex","creator_name":"CopeNLU","creator_url":"https://huggingface.co/copenlu","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","English","mit","10K - 100K","json"],"keywords_longer_than_N":true},
	{"name":"cleand_sequelbox_Celestia3-DeepSeek-R1-0528","keyword":"reasoning","description":"å…ƒãƒ‡ãƒ¼ã‚¿: https://huggingface.co/datasets/sequelbox/Celestia3-DeepSeek-R1-0528\nãƒ‡ãƒ¼ã‚¿ä»¶æ•°: 88,443\nå¹³å‡ãƒˆãƒ¼ã‚¯ãƒ³æ•°: 2143\næœ€å¤§ãƒˆãƒ¼ã‚¯ãƒ³æ•°: 31,680\nåˆè¨ˆãƒˆãƒ¼ã‚¯ãƒ³æ•°: 189,577,005\nãƒ•ã‚¡ã‚¤ãƒ«å½¢å¼: JSONL\nãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚º: 812.4 MB\n","url":"https://huggingface.co/datasets/LLMTeamAkiyama/cleand_sequelbox_Celestia3-DeepSeek-R1-0528","creator_name":"LLMTeamAkiyama","creator_url":"https://huggingface.co/LLMTeamAkiyama","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["question-answering","English","apache-2.0","10K - 100K","json"],"keywords_longer_than_N":true},
	{"name":"Aze-Instruct-2K","keyword":"reasoning","description":"\n\t\n\t\t\n\t\tAze-Instruct-2K (Azerbaijani Reasoning & Instruction Dataset)\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nAze-Instruct-2K is a high-quality Azerbaijani dataset designed for instruction-tuning and reasoning-focused tasks.It consists of 2,000 samples across 12 diverse categories.\nThis dataset is intended for fine-tuning models to understand, reason, and generate responses in Azerbaijani, particularly in multi-domain reasoning scenarios.\n\n\t\n\t\t\nCategory\nNumber of Rows\n\n\n\t\t\nMathematical Reasoningâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/karabakh-nlp/Aze-Instruct-2K.","url":"https://huggingface.co/datasets/karabakh-nlp/Aze-Instruct-2K","creator_name":"Karabakh NLP","creator_url":"https://huggingface.co/karabakh-nlp","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["question-answering","Azerbaijani","cc-by-4.0","1K - 10K","parquet"],"keywords_longer_than_N":true},
	{"name":"openhermes-reasoning-231k","keyword":"reasoning","description":"\n\t\n\t\t\n\t\tğŸ§  OpenHermes Reasoning 377K\n\t\n\n\n\n\n\n\n\nHigh-quality instruction dataset with chain-of-thought reasoning\nğŸ¤— Dataset â€¢ ğŸ’¬ Discussions\n\n\n\n\n\t\n\t\t\n\t\tğŸ“Š Dataset Overview\n\t\n\nThis dataset contains 231,144 high-quality instruction-response pairs with explicit chain-of-thought reasoning. Each example includes:\n\nPrompt: Original instruction or question\nThinking: Explicit reasoning process and logical steps\nAnswer: Final comprehensive response\n\n\n\t\n\t\t\n\t\tKey Features\n\t\n\nâœ… Quality Filtered: Rigorousâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/limeXx/openhermes-reasoning-231k.","url":"https://huggingface.co/datasets/limeXx/openhermes-reasoning-231k","creator_name":"yusuf uzun","creator_url":"https://huggingface.co/limeXx","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-generation","question-answering","English","mit","100K - 1M"],"keywords_longer_than_N":true},
	{"name":"SLR-Bench-French","keyword":"reasoning","description":" \n\n\n\t\n\t\t\n\t\tğŸ§  SLR-Bench-French: Scalable Logical Reasoning Benchmark (French Edition)\n\t\n\n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tSLR-Bench Versions:\n\t\n\n\n\n\n\nSLR-Bench-French is the French-language pendant of the original SLR-Bench dataset.\nIt follows the same symbolic structure, evaluation framework, and curriculum as the English version but provides all natural-language task prompts translated into French.\nThis enables systematic evaluation and training of Large Language Models (LLMs) in logical reasoning in Frenchâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/ahmad21omar/SLR-Bench-French.","url":"https://huggingface.co/datasets/ahmad21omar/SLR-Bench-French","creator_name":"Ahmad Omar","creator_url":"https://huggingface.co/ahmad21omar","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["French","cc-by-4.0","10K - 100K","parquet","Tabular"],"keywords_longer_than_N":true},
	{"name":"lumos_maths_plan_iterative","keyword":"reasoning","description":"\n\t\n\t\t\n\t\tğŸª„ Agent Lumos: Unified and Modular Training for Open-Source Language Agents\n\t\n\n\n  ğŸŒ[Website] Â \n  ğŸ“[Paper] Â \n  ğŸ¤—[Data] Â \n  ğŸ¤—[Model] Â \n  ğŸ¤—[Demo] Â \n\n\nWe introduce ğŸª„Lumos, Language Agents with Unified Formats, Modular Design, and Open-Source LLMs. Lumos unifies a suite of complex interactive tasks and achieves competitive performance with GPT-4/3.5-based and larger open-source agents. \nLumos has following features:\n\nğŸ§© Modular Architecture:\nğŸ§© Lumos consists of planning, groundingâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/ai2lumos/lumos_maths_plan_iterative.","url":"https://huggingface.co/datasets/ai2lumos/lumos_maths_plan_iterative","creator_name":"Lumos  Agents (AI2)","creator_url":"https://huggingface.co/ai2lumos","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","English","apache-2.0","10K - 100K","json"],"keywords_longer_than_N":true},
	{"name":"StackMathQA","keyword":"reasoning","description":"\n\t\n\t\t\n\t\tStackMathQA\n\t\n\nStackMathQA is a meticulously curated collection of 2 million mathematical questions and answers, sourced from various Stack Exchange sites. This repository is designed to serve as a comprehensive resource for researchers, educators, and enthusiasts in the field of mathematics and AI research.\n\n\t\n\t\t\n\t\tConfigs\n\t\n\nconfigs:\n- config_name: stackmathqa1600k\n  data_files: data/stackmathqa1600k/all.jsonl\n  default: true\n- config_name: stackmathqa800k\n  data_files:â€¦ See the full description on the dataset page: https://huggingface.co/datasets/agicorp/StackMathQA.","url":"https://huggingface.co/datasets/agicorp/StackMathQA","creator_name":"agicorp","creator_url":"https://huggingface.co/agicorp","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","question-answering","English","cc-by-4.0","1M - 10M"],"keywords_longer_than_N":true},
	{"name":"StackMathQA","keyword":"mathematical-reasoning","description":"\n\t\n\t\t\n\t\tStackMathQA\n\t\n\nStackMathQA is a meticulously curated collection of 2 million mathematical questions and answers, sourced from various Stack Exchange sites. This repository is designed to serve as a comprehensive resource for researchers, educators, and enthusiasts in the field of mathematics and AI research.\n\n\t\n\t\t\n\t\tConfigs\n\t\n\nconfigs:\n- config_name: stackmathqa1600k\n  data_files: data/stackmathqa1600k/all.jsonl\n  default: true\n- config_name: stackmathqa800k\n  data_files:â€¦ See the full description on the dataset page: https://huggingface.co/datasets/agicorp/StackMathQA.","url":"https://huggingface.co/datasets/agicorp/StackMathQA","creator_name":"agicorp","creator_url":"https://huggingface.co/agicorp","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","question-answering","English","cc-by-4.0","1M - 10M"],"keywords_longer_than_N":true},
	{"name":"WirelessMATHBench-XL","keyword":"reasoning","description":"\n\t\n\t\t\n\t\tWirelessMATHBench-XL\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nWirelessMATHBench-XL is a collection of 4,027 graduate-level wireless communications math problems that pair long technical context passages with precise quantitative questions. Each item is derived from recent arXiv preprints in signal processing, networking, and edge intelligence, and is formatted to elicit deliberate step-by-step reasoning from large language models. Problems are tagged as multiple choice or fill-in-the-blank (withâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/XINLI1997/WirelessMATHBench-XL.","url":"https://huggingface.co/datasets/XINLI1997/WirelessMATHBench-XL","creator_name":"XinLi","creator_url":"https://huggingface.co/XINLI1997","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["question-answering","fill-mask","text-generation","English","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"llm-fol-reasoning-eval","keyword":"logical-reasoning","description":"\n\t\n\t\t\n\t\tLLM FOL Reasoning Eval\n\t\n\nThis dataset is derived from ProverQA, a First-Order Logic reasoning benchmark designed to test the ability of large language models (LLMs) to perform structured logical reasoning.It restructures and normalizes the ProverQA development and training data into a unified, clean format suitable for evaluating chain-of-thought (CoT) and symbolic reasoning capabilities in LLMs.\n\n\n\t\n\t\t\n\t\n\t\n\t\tSource\n\t\n\nOriginal dataset: ProverQA: A First-Order Logic Reasoningâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/MinaGabriel/llm-fol-reasoning-eval.","url":"https://huggingface.co/datasets/MinaGabriel/llm-fol-reasoning-eval","creator_name":"Mina Gabriel","creator_url":"https://huggingface.co/MinaGabriel","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-classification","mit","1K - 10K","parquet","Tabular"],"keywords_longer_than_N":true},
	{"name":"lumos_complex_qa_ground_iterative","keyword":"reasoning","description":"\n\t\n\t\t\n\t\tğŸª„ Agent Lumos: Unified and Modular Training for Open-Source Language Agents\n\t\n\n\n  ğŸŒ[Website] Â \n  ğŸ“[Paper] Â \n  ğŸ¤—[Data] Â \n  ğŸ¤—[Model] Â \n  ğŸ¤—[Demo] Â \n\n\nWe introduce ğŸª„Lumos, Language Agents with Unified Formats, Modular Design, and Open-Source LLMs. Lumos unifies a suite of complex interactive tasks and achieves competitive performance with GPT-4/3.5-based and larger open-source agents. \nLumos has following features:\n\nğŸ§© Modular Architecture:\nğŸ§© Lumos consists of planning, groundingâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/ai2lumos/lumos_complex_qa_ground_iterative.","url":"https://huggingface.co/datasets/ai2lumos/lumos_complex_qa_ground_iterative","creator_name":"Lumos  Agents (AI2)","creator_url":"https://huggingface.co/ai2lumos","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","question-answering","English","apache-2.0","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"lumos_web_agent_plan_iterative","keyword":"reasoning","description":"\n\t\n\t\t\n\t\tğŸª„ Agent Lumos: Unified and Modular Training for Open-Source Language Agents\n\t\n\n\n  ğŸŒ[Website] Â \n  ğŸ“[Paper] Â \n  ğŸ¤—[Data] Â \n  ğŸ¤—[Model] Â \n  ğŸ¤—[Demo] Â \n\n\nWe introduce ğŸª„Lumos, Language Agents with Unified Formats, Modular Design, and Open-Source LLMs. Lumos unifies a suite of complex interactive tasks and achieves competitive performance with GPT-4/3.5-based and larger open-source agents. \nLumos has following features:\n\nğŸ§© Modular Architecture:\nğŸ§© Lumos consists of planning, groundingâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/ai2lumos/lumos_web_agent_plan_iterative.","url":"https://huggingface.co/datasets/ai2lumos/lumos_web_agent_plan_iterative","creator_name":"Lumos  Agents (AI2)","creator_url":"https://huggingface.co/ai2lumos","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","English","apache-2.0","1K - 10K","json"],"keywords_longer_than_N":true},
	{"name":"tamil-orca","keyword":"reasoning","description":"\n\t\n\t\t\n\t\tTamil Orca-Style Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis repository hosts the Tamil Orca-style dataset, meticulously curated to enhance the reasoning capabilities of large language models in Tamil. The dataset is a fusion of translations and responses generated by GPT-4 and Gemini models.\n\nContent: The dataset contains three columns - 'Instruction', 'Query', and 'Answer'. \nPurpose: It's designed to significantly improve the reasoning capability of AI language models in Tamil. \nUsage: Ifâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/azharmo/tamil-orca.","url":"https://huggingface.co/datasets/azharmo/tamil-orca","creator_name":"Mohamed Azharudeen M","creator_url":"https://huggingface.co/azharmo","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","Tamil","apache-2.0","10K - 100K","csv"],"keywords_longer_than_N":true},
	{"name":"lumos_complex_qa_plan_iterative","keyword":"reasoning","description":"\n\t\n\t\t\n\t\tğŸª„ Agent Lumos: Unified and Modular Training for Open-Source Language Agents\n\t\n\n\n  ğŸŒ[Website] Â \n  ğŸ“[Paper] Â \n  ğŸ¤—[Data] Â \n  ğŸ¤—[Model] Â \n  ğŸ¤—[Demo] Â \n\n\nWe introduce ğŸª„Lumos, Language Agents with Unified Formats, Modular Design, and Open-Source LLMs. Lumos unifies a suite of complex interactive tasks and achieves competitive performance with GPT-4/3.5-based and larger open-source agents. \nLumos has following features:\n\nğŸ§© Modular Architecture:\nğŸ§© Lumos consists of planning, groundingâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/ai2lumos/lumos_complex_qa_plan_iterative.","url":"https://huggingface.co/datasets/ai2lumos/lumos_complex_qa_plan_iterative","creator_name":"Lumos  Agents (AI2)","creator_url":"https://huggingface.co/ai2lumos","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","question-answering","English","apache-2.0","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"tamil-orca-transliterated","keyword":"reasoning","description":"\n\t\n\t\t\n\t\tTamil Orca-Style Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis repository hosts the Tamil Orca-style transliterated dataset, meticulously curated to enhance the reasoning capabilities of large language models in Tamil. The dataset is a transliterated version tamil-orca fusion of translations and responses generated by GPT-4 and Gemini models.\n\nContent: The dataset contains three columns - 'Instruction', 'Query', and 'Answer'. \nPurpose: It's designed to significantly improve the reasoningâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/azharmo/tamil-orca-transliterated.","url":"https://huggingface.co/datasets/azharmo/tamil-orca-transliterated","creator_name":"Mohamed Azharudeen M","creator_url":"https://huggingface.co/azharmo","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","Tamil","apache-2.0","10K - 100K","csv"],"keywords_longer_than_N":true},
	{"name":"lumos_complex_qa_plan_onetime","keyword":"reasoning","description":"\n\t\n\t\t\n\t\tğŸª„ Agent Lumos: Unified and Modular Training for Open-Source Language Agents\n\t\n\n\n  ğŸŒ[Website] Â \n  ğŸ“[Paper] Â \n  ğŸ¤—[Data] Â \n  ğŸ¤—[Model] Â \n  ğŸ¤—[Demo] Â \n\n\nWe introduce ğŸª„Lumos, Language Agents with Unified Formats, Modular Design, and Open-Source LLMs. Lumos unifies a suite of complex interactive tasks and achieves competitive performance with GPT-4/3.5-based and larger open-source agents. \nLumos has following features:\n\nğŸ§© Modular Architecture:\nğŸ§© Lumos consists of planning, groundingâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/ai2lumos/lumos_complex_qa_plan_onetime.","url":"https://huggingface.co/datasets/ai2lumos/lumos_complex_qa_plan_onetime","creator_name":"Lumos  Agents (AI2)","creator_url":"https://huggingface.co/ai2lumos","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","question-answering","English","apache-2.0","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"lumos_maths_plan_onetime","keyword":"reasoning","description":"\n\t\n\t\t\n\t\tğŸª„ Agent Lumos: Unified and Modular Training for Open-Source Language Agents\n\t\n\n\n  ğŸŒ[Website] Â \n  ğŸ“[Paper] Â \n  ğŸ¤—[Data] Â \n  ğŸ¤—[Model] Â \n  ğŸ¤—[Demo] Â \n\n\nWe introduce ğŸª„Lumos, Language Agents with Unified Formats, Modular Design, and Open-Source LLMs. Lumos unifies a suite of complex interactive tasks and achieves competitive performance with GPT-4/3.5-based and larger open-source agents. \nLumos has following features:\n\nğŸ§© Modular Architecture:\nğŸ§© Lumos consists of planning, groundingâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/ai2lumos/lumos_maths_plan_onetime.","url":"https://huggingface.co/datasets/ai2lumos/lumos_maths_plan_onetime","creator_name":"Lumos  Agents (AI2)","creator_url":"https://huggingface.co/ai2lumos","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","English","apache-2.0","10K - 100K","json"],"keywords_longer_than_N":true},
	{"name":"MathBode-RatioSaturation","keyword":"reasoning","description":"\n\t\n\t\t\n\t\tMathBode-RatioSaturation: Rational Functions Domain\n\t\n\nRatio and saturation function problems from the MathBode benchmark.\nThis dataset is part of the MathBode benchmark, which evaluates the dynamic reasoning capabilities of large language models (LLMs) by treating parametric math problems as dynamic systems. Instead of testing static accuracy on fixed problems, MathBode sinusoidally varies a parameter and measures the model's response in terms of gain (amplitude tracking) and phaseâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/cognitive-metrology-lab/MathBode-RatioSaturation.","url":"https://huggingface.co/datasets/cognitive-metrology-lab/MathBode-RatioSaturation","creator_name":"Cognitive Metrology Lab","creator_url":"https://huggingface.co/cognitive-metrology-lab","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["apache-2.0","1K - 10K","parquet","Tabular","Text"],"keywords_longer_than_N":true},
	{"name":"MathVision_with_difficulty_level","keyword":"reasoning","description":"\n\t\n\t\t\n\t\tMathVision with difficulty level tags\n\t\n\nThis dataset extends the ğŸ¤— MathVision  benchmark by introducing two additional tags: passrate_for_qwen2.5_vl_7b and difficulty_level_for_qwen2.5_vl_7b. Further details are available in our paper The Synergy Dilemma of Long-CoT SFT and RL: Investigating Post-Training Techniques for Reasoning VLMs.\n\n\t\n\t\t\n\t\n\t\n\t\tğŸš€ Data Usage\n\t\n\nfrom datasets import load_dataset\n\ndataset = load_dataset(\"JierunChen/MathVision_with_difficulty_level\")\nprint(dataset)â€¦ See the full description on the dataset page: https://huggingface.co/datasets/JierunChen/MathVision_with_difficulty_level.","url":"https://huggingface.co/datasets/JierunChen/MathVision_with_difficulty_level","creator_name":"Jierun Chen","creator_url":"https://huggingface.co/JierunChen","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["question-answering","multiple-choice","visual-question-answering","text-generation","expert-generated"],"keywords_longer_than_N":true},
	{"name":"LSDBench","keyword":"reasoning","description":"\n\t\n\t\t\n\t\tDataset Card for LSDBench: Long-video Sampling Dilemma Benchmark\n\t\n\nA benchmark that focuses on the sampling dilemma in long-video tasks. Through well-designed tasks, it evaluates the sampling efficiency of long-video VLMs.\nArxiv Paper: ğŸ“– Does Your Vision-Language Model Get Lost in the Long Video Sampling Dilemma?\nGithub : https://github.com/dvlab-research/LSDBench\n(Left) In Q1, identifying a camera wearer's visited locations requires analyzing the entire video. However, key framesâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/TainU/LSDBench.","url":"https://huggingface.co/datasets/TainU/LSDBench","creator_name":"QU Tianyuan","creator_url":"https://huggingface.co/TainU","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["video-text-to-text","English","apache-2.0","1K - 10K","json"],"keywords_longer_than_N":true},
	{"name":"SFT_54k_reasoning","keyword":"reasoning","description":"\n\t\n\t\t\n\t\tDataset Card for XuHu6736/SFT_54k_reasoning\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nXuHu6736/SFT_54k_reasoning is a processed version of the XuHu6736/s1_54k_filter_with_isreasoning dataset, specifically reformatted for instruction fine-tuning (SFT) of language models.\nThe original question and solution pairs have been converted into an instruction-following format. Critically, the isreasoning_score and isreasoning labels from the parent dataset are preserved, allowing for targeted SFT onâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/XuHu6736/SFT_54k_reasoning.","url":"https://huggingface.co/datasets/XuHu6736/SFT_54k_reasoning","creator_name":"XuHu","creator_url":"https://huggingface.co/XuHu6736","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["XuHu6736 (formatting and derivation)","derived from XuHu6736/s1_54k_filter_with_isreasoning","derived from source datasets","monolingual","XuHu6736/s1_54k_filter_with_isreasoning"],"keywords_longer_than_N":true},
	{"name":"mt_puzzles","keyword":"reasoning","description":"\n\t\n\t\t\n\t\tMulti-Turn Puzzles: Evaluating Interactive Reasoning and Strategic Dialogue in LLMs\n\t\n\nMT-Puzzles is a novel benchmark comprising a suite of multi-turn tasks each designed to test specific reasoning, interactive dialogue, and information-seeking abilities:\n\nWord Guess Guess the secret word in min attempts while environment gives feedback on how close the guess is at each turn.\nMovie Recommendation: Probe the user to decode the user preference function for N turns. Pick a movie for theâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/arianhosseini/mt_puzzles.","url":"https://huggingface.co/datasets/arianhosseini/mt_puzzles","creator_name":"Arian Hosseini","creator_url":"https://huggingface.co/arianhosseini","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["question-answering","English","cc-by-4.0","1K - 10K","json"],"keywords_longer_than_N":true},
	{"name":"TimeSeriesExam1","keyword":"reasoning","description":"\n\t\n\t\t\n\t\tDataset Card for TimeSeriesExam-1\n\t\n\nThis dataset provides Question-Answer (QA) pairs for the paper TimeSeriesExam: A Time Series Understanding Exam. Example inference code can be found here.\n\n\t\n\t\t\n\t\tğŸ“–Introduction\n\t\n\nLarge Language Models (LLMs) have recently demonstrated a remarkable ability to model time series data. These capabilities can be partly explained if LLMs understand basic time series concepts. However, our knowledge of what these models understand about time series dataâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/AutonLab/TimeSeriesExam1.","url":"https://huggingface.co/datasets/AutonLab/TimeSeriesExam1","creator_name":"Auton Lab","creator_url":"https://huggingface.co/AutonLab","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["question-answering","English","mit","< 1K","parquet"],"keywords_longer_than_N":true},
	{"name":"AceReason-Math","keyword":"reasoning","description":"\n\t\n\t\t\n\t\tAceReason-Math Dataset\n\t\n\n\n\n\n\n\n\n\n\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nAceReason-Math is a high quality, verfiable, challenging and diverse math dataset for training math reasoning model using reinforcement leraning. This dataset contains\n\n49K math problems and answer sourced from NuminaMath and DeepScaler-Preview\napplying filtering rules to exclude unsuitable data (e.g., multiple sub-questions, multiple-choice, true/false, long and complex answers, proof, figure)\nthis dataset was used to trainâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/nvidia/AceReason-Math.","url":"https://huggingface.co/datasets/nvidia/AceReason-Math","creator_name":"NVIDIA","creator_url":"https://huggingface.co/nvidia","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","English","cc-by-4.0","10K - 100K","json"],"keywords_longer_than_N":true},
	{"name":"Demeter-LongCoT-6M","keyword":"reasoning","description":"\n\n\t\n\t\t\n\t\tDemeter-LongCoT-6M\n\t\n\n\nDemeter-LongCoT-6M is a high-quality, compact chain-of-thought reasoning dataset curated for tasks in mathematics, science, and coding. While the dataset spans diverse domains, it is primarily driven by mathematical reasoning, reflecting a major share of math-focused prompts and long-form logical solutions.\n\n\n\t\n\t\t\n\t\n\t\n\t\tQuick Start with Hugging Face DatasetsğŸ¤—\n\t\n\npip install -U datasets\n\nfrom datasets import load_dataset\n\ndataset =â€¦ See the full description on the dataset page: https://huggingface.co/datasets/prithivMLmods/Demeter-LongCoT-6M.","url":"https://huggingface.co/datasets/prithivMLmods/Demeter-LongCoT-6M","creator_name":"Prithiv Sakthi","creator_url":"https://huggingface.co/prithivMLmods","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","question-answering","English","apache-2.0","1M - 10M"],"keywords_longer_than_N":true},
	{"name":"OpenThoughts-TR-18k","keyword":"reasoning","description":"\n\t\n\t\t\n\t\tOpenThoughts-TR-18k: Turkish Synthetic Reasoning Dataset\n\t\n\nOpenThoughts-TR-18k is a Turkish translation of a subset of the original Open-Thoughts-114k dataset. It contains ~18k high-quality synthetic reasoning examples covering mathematics, science, coding problems, and puzzles, all translated into Turkish. This dataset is designed to support reasoning task fine tuning for Turkish language models.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\n~18k translated reasoning examples\nCovers multiple domains:â€¦ See the full description on the dataset page: https://huggingface.co/datasets/selimc/OpenThoughts-TR-18k.","url":"https://huggingface.co/datasets/selimc/OpenThoughts-TR-18k","creator_name":"selim","creator_url":"https://huggingface.co/selimc","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["Turkish","mit","10K - 100K","json","Text"],"keywords_longer_than_N":true},
	{"name":"TARA_Turkish_LLM_Benchmark","keyword":"reasoning","description":"\n\t\n\t\t\n\t\tTARA: Turkish Advanced Reasoning Assessment Veri Seti\n\t\n\n\n*Img Credit: Open AI ChatGPT\n**English version is given below.**\n\n Evaluation Notebook / DeÄŸerlendirme Not Defteri\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nTARA (Turkish Advanced Reasoning Assessment), TÃ¼rkÃ§e dilindeki BÃ¼yÃ¼k Dil Modellerinin (LLM'ler) geliÅŸmiÅŸ akÄ±l yÃ¼rÃ¼tme yeteneklerini Ã§oklu alanlarda Ã¶lÃ§mek iÃ§in tasarlanmÄ±ÅŸ, zorluk derecesine gÃ¶re sÄ±nÄ±flandÄ±rÄ±lmÄ±ÅŸ bir benchmark veri setidir. Bu veri seti, LLM'lerin sadece bilgiâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/emre/TARA_Turkish_LLM_Benchmark.","url":"https://huggingface.co/datasets/emre/TARA_Turkish_LLM_Benchmark","creator_name":"Davut Emre TASAR","creator_url":"https://huggingface.co/emre","license_name":"Academic Free License v3.0","license_url":"https://choosealicense.com/licenses/afl-3.0/","language":"en","first_N":5,"first_N_keywords":["question-answering","text-generation","Turkish","afl-3.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"TARA_Turkish_LLM_Benchmark","keyword":"mathematical-reasoning","description":"\n\t\n\t\t\n\t\tTARA: Turkish Advanced Reasoning Assessment Veri Seti\n\t\n\n\n*Img Credit: Open AI ChatGPT\n**English version is given below.**\n\n Evaluation Notebook / DeÄŸerlendirme Not Defteri\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nTARA (Turkish Advanced Reasoning Assessment), TÃ¼rkÃ§e dilindeki BÃ¼yÃ¼k Dil Modellerinin (LLM'ler) geliÅŸmiÅŸ akÄ±l yÃ¼rÃ¼tme yeteneklerini Ã§oklu alanlarda Ã¶lÃ§mek iÃ§in tasarlanmÄ±ÅŸ, zorluk derecesine gÃ¶re sÄ±nÄ±flandÄ±rÄ±lmÄ±ÅŸ bir benchmark veri setidir. Bu veri seti, LLM'lerin sadece bilgiâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/emre/TARA_Turkish_LLM_Benchmark.","url":"https://huggingface.co/datasets/emre/TARA_Turkish_LLM_Benchmark","creator_name":"Davut Emre TASAR","creator_url":"https://huggingface.co/emre","license_name":"Academic Free License v3.0","license_url":"https://choosealicense.com/licenses/afl-3.0/","language":"en","first_N":5,"first_N_keywords":["question-answering","text-generation","Turkish","afl-3.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"longbench-v2","keyword":"reasoning","description":"\n\t\n\t\t\n\t\tCitation\n\t\n\n@article{bai2024longbench2,\n  title={LongBench v2: Towards Deeper Understanding and Reasoning on Realistic Long-context Multitasks},\n  author={Yushi Bai and Shangqing Tu and Jiajie Zhang and Hao Peng and Xiaozhi Wang and Xin Lv and Shulin Cao and Jiazheng Xu and Lei Hou and Yuxiao Dong and Jie Tang and Juanzi Li},\n  journal={arXiv preprint arXiv:2412.15204},\n  year={2024}\n}\n\n","url":"https://huggingface.co/datasets/recursal/longbench-v2","creator_name":"recursal","creator_url":"https://huggingface.co/recursal","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["multiple-choice","question-answering","text-classification","table-question-answering","English"],"keywords_longer_than_N":true},
	{"name":"Archer-Code-1.5B","keyword":"reasoning","description":"\n\n\n\t\n\t\t\n\t\tâœ¨ ArcherCodeR\n\t\n\n\nğŸ¹ï¸  Reinforcement Learning for Enhanced Code Reasoning in LLMs  ğŸ¯\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nArcherCodeR-Dataset is a dataset of verifiable, challenging, and diverse coding questions (6.7K). This dataset is used to train the ArcherCodeR model series, which consists of code reasoning models trained using large-scale rule-based reinforcement learning with carefully designed datasets and training recipes.\nWe select, clean, and curate coding problems fromâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Fate-Zero/Archer-Code-1.5B.","url":"https://huggingface.co/datasets/Fate-Zero/Archer-Code-1.5B","creator_name":"Fate","creator_url":"https://huggingface.co/Fate-Zero","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","English","apache-2.0","1K - 10K","parquet"],"keywords_longer_than_N":true},
	{"name":"ARPO-RL-Reasoning-10K","keyword":"reasoning","description":"\n\t\n\t\t\n\t\tAgentic Reinforced Policy Optimization (ARPO) Dataset\n\t\n\nThis repository contains the datasets associated with the paper Agentic Reinforced Policy Optimization.\n\n\t\n\t\t\n\t\tAbstract\n\t\n\nLarge-scale reinforcement learning with verifiable rewards (RLVR) has demonstrated its effectiveness in harnessing the potential of large language models (LLMs) for single-turn reasoning tasks. In realistic reasoning scenarios, LLMs can often utilize external tools to assist in task-solving processes.â€¦ See the full description on the dataset page: https://huggingface.co/datasets/dongguanting/ARPO-RL-Reasoning-10K.","url":"https://huggingface.co/datasets/dongguanting/ARPO-RL-Reasoning-10K","creator_name":"KABI","creator_url":"https://huggingface.co/dongguanting","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-generation","mit","10K - 100K","parquet","Text"],"keywords_longer_than_N":true},
	{"name":"CipherBank","keyword":"reasoning","description":"\n\t\n\t\t\n\t\tCipherBank Benchmark\n\t\n\n\n\t\n\t\t\n\t\tBenchmark description\n\t\n\nCipherBank, a comprehensive benchmark designed to evaluate the reasoning capabilities of LLMs in cryptographic decryption tasks. \nCipherBank comprises 2,358 meticulously crafted problems, covering 262 unique plaintexts across 5 domains and 14 subdomains, with a focus on privacy-sensitive and real-world scenarios that necessitate encryption. From a cryptographic perspective, CipherBank incorporates 3 major categories of encryptionâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/yu0226/CipherBank.","url":"https://huggingface.co/datasets/yu0226/CipherBank","creator_name":"YU LI","creator_url":"https://huggingface.co/yu0226","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["question-answering","English","apache-2.0","1K - 10K","json"],"keywords_longer_than_N":true},
	{"name":"bioinfo-bench_preprocess","keyword":"reasoning","description":"\n\t\n\t\t\n\t\tBioinfo Bench Preprocessed Dataset\n\t\n\nThis dataset is a pre-processed and automatically evaluated version ofQiyuan04/bioinfo-bench.\n\n\t\n\t\t\n\t\tPre-processing Summary\n\t\n\n\nFlexible loading â€“ handled inconsistent columns with pandas.\nFix missing answers â€“ inferred Correct Answer from \"Option D\" when necessary.\nFilter invalid rows â€“ kept only rows whose answer âˆˆ {A, B, C, D}.\nFormat options â€“ prefixed each choice with A:, B:, â€¦ .\nCombine for SFT â€“ joined question + options into question;â€¦ See the full description on the dataset page: https://huggingface.co/datasets/LLMcompe-Team-Watanabe/bioinfo-bench_preprocess.","url":"https://huggingface.co/datasets/LLMcompe-Team-Watanabe/bioinfo-bench_preprocess","creator_name":"LLMcompe Team Watanabe","creator_url":"https://huggingface.co/LLMcompe-Team-Watanabe","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["question-answering","expert-generated","found","monolingual","English"],"keywords_longer_than_N":true},
	{"name":"Amanita-Imagine","keyword":"reasoning","description":"Used to train Imagine-v0.5 by Quazim0t0\n","url":"https://huggingface.co/datasets/Quazim0t0/Amanita-Imagine","creator_name":"Quazimoto","creator_url":"https://huggingface.co/Quazim0t0","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["English","mit","< 1K","json","Text"],"keywords_longer_than_N":true},
	{"name":"NL-Eye","keyword":"reasoning","description":"\n\t\n\t\t\n\t\tNL-Eye Benchmark\n\t\n\nWill a Visual Language Model (VLM)-based bot warn us about slipping if it detects a wet floor? \nRecent VLMs have demonstrated impressive capabilities, yet their ability to infer outcomes and causes remains underexplored. To address this, we introduce NL-Eye, a benchmark designed to assess VLMs' visual abductive reasoning skills. \nNL-Eye adapts the abductive Natural Language Inference (NLI) task to the visual domain, requiring models to evaluate the plausibility ofâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/MorVentura/NL-Eye.","url":"https://huggingface.co/datasets/MorVentura/NL-Eye","creator_name":"Mor Ventura","creator_url":"https://huggingface.co/MorVentura","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["visual-question-answering","English","apache-2.0","< 1K","csv"],"keywords_longer_than_N":true},
	{"name":"Reflection-Dataset-ShareGPT-v2","keyword":"reflection","description":"\n\t\n\t\t\n\t\tSimple \"Reflection\" method dataset inspired by mattshumer\n\t\n\n\n\t\n\t\t\n\t\tThis is the ShareGPT version. Find prompt and response pair dataset here\n\t\n\nThis dataset was synthetically generated using Glaive AI. There have been structure improvements and added more rows.\n","url":"https://huggingface.co/datasets/mahiatlinux/Reflection-Dataset-ShareGPT-v2","creator_name":"Maheswar KK","creator_url":"https://huggingface.co/mahiatlinux","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["English","mit","1K - 10K","json","Text"],"keywords_longer_than_N":true},
	{"name":"math500-enhanced","keyword":"reasoning","description":"\n\t\n\t\t\n\t\tMath500 Enhanced Dataset\n\t\n\nThis dataset contains LLM-enhanced versions of mathematical problems with step-by-step reasoning solutions.\n\n\t\n\t\t\n\t\tDataset Statistics\n\t\n\n\nExamples: 500 (500 enhanced with LLM)\nEnhancement Rate: 100.0%\n\n\n\t\n\t\t\n\t\tData Fields\n\t\n\n\nquestion: The mathematical problem statement\nsolution: LLM-enhanced step-by-step solution\noriginal_solution: Original solution text (for reference)\nanswer: Final numerical answer\nlevel: Problem difficulty level\ntype: Problemâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/rachitbansal-harvard/math500-enhanced.","url":"https://huggingface.co/datasets/rachitbansal-harvard/math500-enhanced","creator_name":"Rachit Bansal","creator_url":"https://huggingface.co/rachitbansal-harvard","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["question-answering","text-generation","English","mit","< 1K"],"keywords_longer_than_N":true},
	{"name":"math500-enhanced","keyword":"step-by-step","description":"\n\t\n\t\t\n\t\tMath500 Enhanced Dataset\n\t\n\nThis dataset contains LLM-enhanced versions of mathematical problems with step-by-step reasoning solutions.\n\n\t\n\t\t\n\t\tDataset Statistics\n\t\n\n\nExamples: 500 (500 enhanced with LLM)\nEnhancement Rate: 100.0%\n\n\n\t\n\t\t\n\t\tData Fields\n\t\n\n\nquestion: The mathematical problem statement\nsolution: LLM-enhanced step-by-step solution\noriginal_solution: Original solution text (for reference)\nanswer: Final numerical answer\nlevel: Problem difficulty level\ntype: Problemâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/rachitbansal-harvard/math500-enhanced.","url":"https://huggingface.co/datasets/rachitbansal-harvard/math500-enhanced","creator_name":"Rachit Bansal","creator_url":"https://huggingface.co/rachitbansal-harvard","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["question-answering","text-generation","English","mit","< 1K"],"keywords_longer_than_N":true},
	{"name":"FC-CoT-Top10k","keyword":"reasoning","description":"\n\t\n\t\t\n\t\tğŸ“Œ Overview\n\t\n\n\nTotal Samples: 10,000  \nPrimary Focus:  \nHigh-quality Function Calling demonstrations  \nClear, well-structured Chain of Thought reasoning\n\n\nSelection Process:  \nRemoved noisy or incomplete examples  \nSelected cases with precise function arguments  \nEnsured reasoning steps are logically sound and human-readable\n\n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tğŸ¯ Use Cases\n\t\n\nThis dataset is ideal for:\n\nFine-tuning LLMs for tool calling / function calling\nTraining models to provide explainable reasoningâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/arcosoph/FC-CoT-Top10k.","url":"https://huggingface.co/datasets/arcosoph/FC-CoT-Top10k","creator_name":"Arcosoph AI","creator_url":"https://huggingface.co/arcosoph","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["apache-2.0","10K - 100K","json","Text","Datasets"],"keywords_longer_than_N":true},
	{"name":"MiniF2F","keyword":"mathematical-reasoning","description":"\n\t\n\t\t\n\t\tminif2f Dataset\n\t\n\nThe minif2f dataset is a collection of mathematical problems and their formal statements, designed for formal mathematics and theorem proving tasks.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThe minif2f dataset contains mathematical problems from various sources (like AMC competitions) along with their formal statements in the Lean theorem prover format. Each example includes both informal mathematical statements and their corresponding formalâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Tonic/MiniF2F.","url":"https://huggingface.co/datasets/Tonic/MiniF2F","creator_name":"Joseph [open/acc] Pollack","creator_url":"https://huggingface.co/Tonic","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-generation","other","explanation-generation","language-modeling","expert-generated"],"keywords_longer_than_N":true},
	{"name":"curie","keyword":"reasoning","description":"\n\t\n\t\t\n\t\tCurie Dataset\n\t\n\nHF version of the dataset:\nCURIE: Evaluating LLMs On Multitask Scientific Long Context Understanding and Reasoning.\nAlso available via GitHub (Apache-2.0 license).\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nCURIE consists of 10 tasks that are mapped to 8 datasets. The datasets are: \n\n\t\n\t\t\nDataset ID\nTask Name\nDomain\nDescription\n\n\n\t\t\nbiogr\nBiodiversity Georeferencing\nBiodiversity\nDetermine the latitude, longitude bounding box encompassing the region in the map image.\n\n\ndft\nDensityâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/nhop/curie.","url":"https://huggingface.co/datasets/nhop/curie","creator_name":"Niklas Hoepner","creator_url":"https://huggingface.co/nhop","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["question-answering","English","apache-2.0","< 1K","parquet"],"keywords_longer_than_N":true},
	{"name":"formatted_miromind-1000","keyword":"reasoning","description":"mssfj/formatted_miromind-1000 dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/mssfj/formatted_miromind-1000","creator_name":"Masashi Fujimoto","creator_url":"https://huggingface.co/mssfj","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["question-answering","closed-domain-qa","expert-generated","found","monolingual"],"keywords_longer_than_N":true},
	{"name":"Medprompt-MedQA-R1","keyword":"reasoning","description":"\n\t\n\t\t\n\t\tMedprompt-MedQA-R1\n\t\n\n\n  \n\n\n\n  \n    \n  \n  \n    \n  \n  \n    \n  \n    \n  \n  \n    \n  \n  \n    \n  \n\n\n  \n    \n    \n  \n\n\n\nMedprompt-MedQA-R1 is a reasoning-augmented database designed for context retrieval in multiple-choice medical question answering. The dataset supports the development and evaluation of AI systems tailored to healthcare, particularly in tasks requiring enhanced contextual reasoning and retrieval-based assistance. By including structured reasoning and verified responsesâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/HPAI-BSC/Medprompt-MedQA-R1.","url":"https://huggingface.co/datasets/HPAI-BSC/Medprompt-MedQA-R1","creator_name":"HPAI@BSC (High Performance Artificial Intelligence at Barcelona Supercomputing Center)","creator_url":"https://huggingface.co/HPAI-BSC","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["question-answering","English","apache-2.0","100K<n<1M","arxiv:2409.15127"],"keywords_longer_than_N":true},
	{"name":"MathVision","keyword":"reasoning","description":"\n\t\n\t\t\n\t\tMeasuring Multimodal Mathematical Reasoning with the MATH-Vision Dataset\n\t\n\n[ğŸ’» Github] [ğŸŒ Homepage]  [ğŸ“Š Leaderboard ] [ğŸ“Š Open Source Leaderboard ] [ğŸ” Visualization] [ğŸ“– Paper]\n\n\t\n\t\t\n\t\n\t\n\t\tğŸš€ Data Usage\n\t\n\n\n\nfrom datasets import load_dataset\n\ndataset = load_dataset(\"MathLLMs/MathVision\")\nprint(dataset)\n\n\n\t\n\t\t\n\t\tğŸ’¥ News\n\t\n\n\n[2025.05.16] ğŸ’¥ We now support the official open-source leaderboard! ğŸ”¥ğŸ”¥ğŸ”¥ Skywork-R1V2-38B is the best open-source model, scoring 49.7% on MATH-Vision. ğŸ”¥ğŸ”¥ğŸ”¥â€¦ See the full description on the dataset page: https://huggingface.co/datasets/MathLLMs/MathVision.","url":"https://huggingface.co/datasets/MathLLMs/MathVision","creator_name":"LLMs for Reasoning","creator_url":"https://huggingface.co/MathLLMs","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["question-answering","multiple-choice","visual-question-answering","text-generation","expert-generated"],"keywords_longer_than_N":true},
	{"name":"Fast-Math-R1-Token-Scheduler","keyword":"reasoning","description":"This dataset, Fast-Math-R1-Token-Scheduler, is used to train a lightweight model that predicts the difficulty of a math problem. Specifically, it estimates how many tokens the R1 model requires before reaching the final answer. This helps in optimizing inference efficiency for mathematical Large Language Models (LLMs).\nThis dataset is part of the work presented in the paper A Practical Two-Stage Recipe for Mathematical LLMs: Maximizing Accuracy with SFT and Efficiency with Reinforcementâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/RabotniKuma/Fast-Math-R1-Token-Scheduler.","url":"https://huggingface.co/datasets/RabotniKuma/Fast-Math-R1-Token-Scheduler","creator_name":"Hiroshi Yoshihara","creator_url":"https://huggingface.co/RabotniKuma","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","apache-2.0","10K - 100K","parquet","Text"],"keywords_longer_than_N":true},
	{"name":"openpipe-dpo-scientific-reasoning","keyword":"reasoning","description":"\n\t\n\t\t\n\t\tOpenpipe Dpo Scientific Reasoning\n\t\n\nThis dataset contains 100 high-quality examples for Direct Preference Optimization (DPO) training, formatted for OpenPipe fine-tuning, focused on scientific reasoning and analysis.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset was generated using an enhanced DSPy-based pipeline that creates structured reasoning traces for scientific questions. Each example follows the OpenAI chat completion format required by OpenPipe:\n\nOpenAI Chat Format: Standardâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/abhi26/openpipe-dpo-scientific-reasoning.","url":"https://huggingface.co/datasets/abhi26/openpipe-dpo-scientific-reasoning","creator_name":"ABHISEK GUHA","creator_url":"https://huggingface.co/abhi26","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-generation","question-answering","English","mit","< 1K"],"keywords_longer_than_N":true},
	{"name":"Dataset_of_Russian_thinking","keyword":"reflection","description":"Ru\nRTD  \nĞĞ¿Ğ¸ÑĞ°Ğ½Ğ¸Ğµ:Russian Thinking Dataset â€” ÑÑ‚Ğ¾ Ğ½Ğ°Ğ±Ğ¾Ñ€ Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ…, Ğ¿Ñ€ĞµĞ´Ğ½Ğ°Ğ·Ğ½Ğ°Ñ‡ĞµĞ½Ğ½Ñ‹Ğ¹ Ğ´Ğ»Ñ Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ñ Ğ¸ Ñ‚ĞµÑÑ‚Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹ Ğ¾Ğ±Ñ€Ğ°Ğ±Ğ¾Ñ‚ĞºĞ¸ ĞµÑÑ‚ĞµÑÑ‚Ğ²ĞµĞ½Ğ½Ğ¾Ğ³Ğ¾ ÑĞ·Ñ‹ĞºĞ° (NLP) Ğ½Ğ° Ñ€ÑƒÑÑĞºĞ¾Ğ¼ ÑĞ·Ñ‹ĞºĞµ. Ğ”Ğ°Ñ‚Ğ°ÑĞµÑ‚ Ğ¾Ñ€Ğ¸ĞµĞ½Ñ‚Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½ Ğ½Ğ° Ğ·Ğ°Ğ´Ğ°Ñ‡Ğ¸, ÑĞ²ÑĞ·Ğ°Ğ½Ğ½Ñ‹Ğµ Ñ Ğ³ĞµĞ½ĞµÑ€Ğ°Ñ†Ğ¸ĞµĞ¹ Ñ‚ĞµĞºÑÑ‚Ğ°, Ğ°Ğ½Ğ°Ğ»Ğ¸Ğ·Ğ¾Ğ¼ Ğ´Ğ¸Ğ°Ğ»Ğ¾Ğ³Ğ¾Ğ² Ğ¸ Ñ€ĞµÑˆĞµĞ½Ğ¸ĞµĞ¼ Ğ¼Ğ°Ñ‚ĞµĞ¼Ğ°Ñ‚Ğ¸Ñ‡ĞµÑĞºĞ¸Ñ… Ğ¸ Ğ»Ğ¾Ğ³Ğ¸Ñ‡ĞµÑĞºĞ¸Ñ… Ğ·Ğ°Ğ´Ğ°Ñ‡.  \n\n\t\n\t\t\n\t\tĞÑĞ½Ğ¾Ğ²Ğ½Ğ°Ñ Ğ¸Ğ½Ñ„Ğ¾Ñ€Ğ¼Ğ°Ñ†Ğ¸Ñ:\n\t\n\n\nĞ¡Ğ¿Ğ»Ğ¸Ñ‚: train  \nĞšĞ¾Ğ»Ğ¸Ñ‡ĞµÑÑ‚Ğ²Ğ¾ Ğ·Ğ°Ğ¿Ğ¸ÑĞµĞ¹: 147.046\n\n\n\t\n\t\t\n\t\tĞ¦ĞµĞ»Ğ¸:\n\t\n\n\nĞĞ±ÑƒÑ‡ĞµĞ½Ğ¸Ğµ Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹ Ğ¿Ğ¾Ğ½Ğ¸Ğ¼Ğ°Ğ½Ğ¸Ñ Ñ€ÑƒÑÑĞºĞ¾Ğ³Ğ¾ ÑĞ·Ñ‹ĞºĞ°.  \nĞ¡Ğ¾Ğ·Ğ´Ğ°Ğ½Ğ¸Ğµ Ğ´Ğ¸Ğ°Ğ»Ğ¾Ğ³Ğ¾Ğ²Ñ‹Ñ… ÑĞ¸ÑÑ‚ĞµĞ¼ Ñ ĞµÑÑ‚ĞµÑÑ‚Ğ²ĞµĞ½Ğ½Ñ‹Ğ¼ Ğ²Ğ·Ğ°Ğ¸Ğ¼Ğ¾Ğ´ĞµĞ¹ÑÑ‚Ğ²Ğ¸ĞµĞ¼.â€¦ See the full description on the dataset page: https://huggingface.co/datasets/Egor-AI/Dataset_of_Russian_thinking.","url":"https://huggingface.co/datasets/Egor-AI/Dataset_of_Russian_thinking","creator_name":"Egor AI","creator_url":"https://huggingface.co/Egor-AI","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-generation","Russian","mit","100K - 1M","json"],"keywords_longer_than_N":true},
	{"name":"VISCO","keyword":"reasoning","description":"\n\t\n\t\t\n\t\n\t\n\t\tVISCO\n\t\n\nBenchmarking Fine-Grained Critique and Correction Towards Self-Improvement in Visual Reasoning\nğŸŒ Project | ğŸ“– Paper | ğŸ’» Github\n\n\nOutline:\n\nIntroduction\nData\nCitation\n\n\n\t\n\t\t\n\t\n\t\n\t\tIntroduction\n\t\n\nVISCO is a benchmark for evaluating the critique and correction capabilities of LVLMs. VISCO contains:\n\n1645 pairs of questions and LVLM-generated answers. Each answer includes a chain-of-thought with multiple reasonign steps.\n5604 step-wise annotations of critique, showingâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/uclanlp/VISCO.","url":"https://huggingface.co/datasets/uclanlp/VISCO","creator_name":"UCLA NLP","creator_url":"https://huggingface.co/uclanlp","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["visual-question-answering","English","mit","1K<n<10K","arxiv:2412.02172"],"keywords_longer_than_N":true},
	{"name":"cleand_openthought312_dif9_tiny","keyword":"reasoning","description":"å…ƒãƒ‡ãƒ¼ã‚¿: https://huggingface.co/datasets/LLMTeamAkiyama/clean_openthought312_difficulty_9_filterd\n\nãƒ‡ãƒ¼ã‚¿ä»¶æ•°: 1,456\nå¹³å‡ãƒˆãƒ¼ã‚¯ãƒ³æ•°: 5,894\næœ€å¤§ãƒˆãƒ¼ã‚¯ãƒ³æ•°: 8,186\nåˆè¨ˆãƒˆãƒ¼ã‚¯ãƒ³æ•°: 8,581,562\nãƒ•ã‚¡ã‚¤ãƒ«å½¢å¼: JSONL\nãƒ•ã‚¡ã‚¤ãƒ«åˆ†å‰²æ•°: 1\nåˆè¨ˆãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚º: 33.2 MB\n\nåŠ å·¥å†…å®¹ï¼š\n\nå…ƒãƒ‡ãƒ¼ã‚¿ã«å¯¾ã—ã¦ã€tokenæ•°ã‚’8912ä»¥ä¸‹ã«åˆ¶é™ã—ãŸãƒ†ã‚¹ãƒˆç”¨tinyç‰ˆ\n\nä½¿ç”¨ã—ãŸã‚³ãƒ¼ãƒ‰: https://github.com/LLMTeamAkiyama/0-data_prepare/tree/master/src/openthoughts3/clean_openthoughts3_tiny_pickup.ipynb\n","url":"https://huggingface.co/datasets/LLMTeamAkiyama/cleand_openthought312_dif9_tiny","creator_name":"LLMTeamAkiyama","creator_url":"https://huggingface.co/LLMTeamAkiyama","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["question-answering","English","apache-2.0","1K - 10K","json"],"keywords_longer_than_N":true},
	{"name":"MMR1-RL","keyword":"reasoning","description":"\n\t\n\t\t\n\t\tMMR1: Enhancing Multimodal Reasoning with Variance-Aware Sampling and Open Resources\n\t\n\n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tIntroduction\n\t\n\nThis repository introduces the MMR1 project, focusing on enhancing large multimodal reasoning models. While rapid progress has been made, advancements are constrained by two major limitations:\n\nThe absence of open, large-scale, high-quality long chain-of-thought (CoT) data.\nThe instability of reinforcement learning (RL) algorithms in post-training, where standard Groupâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/MMR1/MMR1-RL.","url":"https://huggingface.co/datasets/MMR1/MMR1-RL","creator_name":"MMR1","creator_url":"https://huggingface.co/MMR1","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["image-text-to-text","question-answering","English","apache-2.0","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"NOVEReason_5k","keyword":"reasoning","description":"\n  \n\n\n\n\n\t\n\t\t\n\t\tNOVEReason_5k\n\t\n\n\nNOVEReason is the dataset used in the paper NOVER: Incentive Training for Language Models via Verifier-Free Reinforcement Learning. It is a multi-domain, multi-task, general-purpose reasoning dataset, comprising seven curated datasets across four subfields: general reasoning, creative writing, social intelligence, and multilingual understanding. The data has been carefully cleaned and filtered to ensure suitability for training large reasoning models usingâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/thinkwee/NOVEReason_5k.","url":"https://huggingface.co/datasets/thinkwee/NOVEReason_5k","creator_name":"weiliu","creator_url":"https://huggingface.co/thinkwee","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["question-answering","summarization","translation","text-generation","English"],"keywords_longer_than_N":true},
	{"name":"cleand_moremilk_ToT-Biology","keyword":"reasoning","description":"å…ƒãƒ‡ãƒ¼ã‚¿: https://huggingface.co/datasets/moremilk/ToT-Biology\nãƒ‡ãƒ¼ã‚¿ä»¶æ•°: 5,752\nå¹³å‡ãƒˆãƒ¼ã‚¯ãƒ³æ•°: 675\næœ€å¤§ãƒˆãƒ¼ã‚¯ãƒ³æ•°: 1,105\nåˆè¨ˆãƒˆãƒ¼ã‚¯ãƒ³æ•°: 3,881,334\nãƒ•ã‚¡ã‚¤ãƒ«å½¢å¼: JSONL\nãƒ•ã‚¡ã‚¤ãƒ«åˆ†å‰²æ•°: 1\nåˆè¨ˆãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚º: 19.3 MB\nåŠ å·¥å†…å®¹ï¼š\n\né•·æ–‡ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°: ãƒˆãƒ¼ã‚¯ãƒŠã‚¤ã‚ºå‡¦ç†ã®è² è·ã‚’è»½æ¸›ã™ã‚‹ãŸã‚ã€äº‹å‰ã«æ–‡å­—åˆ—ãŒæ¥µç«¯ã«é•·ã„è¡Œã‚’é™¤å¤–ã—ã¾ã™ã€‚\nquestion åˆ—: 6,000æ–‡å­—ã‚’è¶…ãˆã‚‹è¡Œã‚’é™¤å¤–ã€‚\nmetadata åˆ—: 80,000æ–‡å­—ã‚’è¶…ãˆã‚‹è¡Œã‚’é™¤å¤–ã€‚\n\n\nmetadata ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã®å±•é–‹:\nmetadata åˆ—ã«å«ã¾ã‚Œã‚‹JSONå½¢å¼ã®ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰ reasoning ã¨ difficulty ã®å€¤ã‚’æŠ½å‡ºã—ã¾ã™ã€‚\nreasoning ã¯ thought ã¨ã„ã†æ–°ã—ã„åˆ—ã«æ ¼ç´ã—ã¾ã™ã€‚\ndifficulty ã¯ difficulty ã¨ã„ã†æ–°ã—ã„åˆ—ã«æ ¼ç´ã—ã¾ã™ã€‚\nå‡¦ç†å¾Œã€å…ƒã® metadata åˆ—ã¯å‰Šé™¤ã•ã‚Œã¾ã™ã€‚\n\n\nç¹°ã‚Šè¿”ã—è¡¨ç¾ã®é™¤å»:\nthoughtâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/LLMTeamAkiyama/cleand_moremilk_ToT-Biology.","url":"https://huggingface.co/datasets/LLMTeamAkiyama/cleand_moremilk_ToT-Biology","creator_name":"LLMTeamAkiyama","creator_url":"https://huggingface.co/LLMTeamAkiyama","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["question-answering","English","mit","1K - 10K","json"],"keywords_longer_than_N":true},
	{"name":"HyperThink-X-Nvidia-Opencode-Reasoning-200K","keyword":"reasoning","description":"\n  \n\n\n\n\t\n\t\t\n\t\tğŸ”® HyperThink\n\t\n\nHyperThink is a premium, best-in-class dataset series capturing deep reasoning interactions between users and an advanced Reasoning AI system. Designed for training and evaluating next-gen language models on complex multi-step tasks, the dataset spans a wide range of prompts and guided thinking outputs.\n\n\n\t\n\t\t\n\t\tğŸš€ Dataset Tiers\n\t\n\nHyperThink is available in three expertly curated versions, allowing flexible scaling based on compute resources and training goals:â€¦ See the full description on the dataset page: https://huggingface.co/datasets/NuclearAi/HyperThink-X-Nvidia-Opencode-Reasoning-200K.","url":"https://huggingface.co/datasets/NuclearAi/HyperThink-X-Nvidia-Opencode-Reasoning-200K","creator_name":"Nukeverse","creator_url":"https://huggingface.co/NuclearAi","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["reinforcement-learning","question-answering","text-generation","English","cc-by-4.0"],"keywords_longer_than_N":true},
	{"name":"FinMME","keyword":"reasoning","description":"Multimodal Large Language Models (MLLMs) have experienced rapid development in recent years. However, there is a notable lack of effective and specialized multimodal evaluation datasets in the financial domain. To advance the development of MLLMs in the finance domain, we introduce FinMME, encompassing more than 11,000 high-quality financial research samples across 18 financial domains and 6 asset classes, featuring 10 major chart types and 21 subtypes. We ensure data quality through 20â€¦ See the full description on the dataset page: https://huggingface.co/datasets/luojunyu/FinMME.","url":"https://huggingface.co/datasets/luojunyu/FinMME","creator_name":"junyu","creator_url":"https://huggingface.co/luojunyu","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["multiple-choice","question-answering","English","mit","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"Numina","keyword":"mathematical-reasoning","description":"\n\t\n\t\t\n\t\tNumina-Olympiads\n\t\n\nFiltered NuminaMath-CoT dataset containing only olympiads problems with valid answers.\n\n\t\n\t\t\n\t\tDataset Information\n\t\n\n\nSplit: train\nOriginal size: 41012\nFiltered size: 38772\nSource: olympiads\nAll examples contain valid boxed answers\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset is a filtered version of the NuminaMath-CoT dataset, containing only problems from olympiad sources that have valid boxed answers. Each example includes:\n\nA mathematical word problem\nAâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/artnoage/Numina.","url":"https://huggingface.co/datasets/artnoage/Numina","creator_name":"Vaios Laschos","creator_url":"https://huggingface.co/artnoage","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-generation","expert-generated","expert-generated","monolingual","AI-MO/NuminaMath-CoT"],"keywords_longer_than_N":true},
	{"name":"step3-input-bespoke-stratos-17k-test1","keyword":"reasoning","description":"\n\t\n\t\t\n\t\tChain of Thoughtç”Ÿæˆãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ\n\t\n\nã“ã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã¯ã€å•é¡Œã®è§£ç­”ã‹ã‚‰èª¬æ˜ï¼ˆChain of Thoughtï¼‰ã‚’ç”Ÿæˆã™ã‚‹ãŸã‚ã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã§ã™ã€‚\n\n\t\n\t\t\n\t\tæ¦‚è¦\n\t\n\n\nå‡¦ç†ã—ãŸã‚µãƒ³ãƒ—ãƒ«æ•°: 92\næœ‰åŠ¹ãªèª¬æ˜ç”Ÿæˆæ•°: 92\nç”ŸæˆæˆåŠŸç‡: 100.00%\nä½¿ç”¨ãƒ¢ãƒ‡ãƒ«: Qwen/Qwen3-14B\n\n\n\t\n\t\t\n\t\tãƒˆãƒ¼ã‚¯ãƒ³æ•°çµ±è¨ˆ\n\t\n\n\næœ€å°ãƒˆãƒ¼ã‚¯ãƒ³æ•°: 227\næœ€å¤§ãƒˆãƒ¼ã‚¯ãƒ³æ•°: 2348\nå¹³å‡ãƒˆãƒ¼ã‚¯ãƒ³æ•°: 653.8\n\n\n\t\n\t\t\n\t\tãƒˆãƒ¼ã‚¯ãƒ³æ•°åˆ†å¸ƒ\n\t\n\n\n0-100ãƒˆãƒ¼ã‚¯ãƒ³: 0ä»¶ (0.0%)\n101-500ãƒˆãƒ¼ã‚¯ãƒ³: 47ä»¶ (51.1%)\n501-1000ãƒˆãƒ¼ã‚¯ãƒ³: 31ä»¶ (33.7%)\n1001-2000ãƒˆãƒ¼ã‚¯ãƒ³: 13ä»¶ (14.1%)\n2001-5000ãƒˆãƒ¼ã‚¯ãƒ³: 1ä»¶ (1.1%)\n5001+ãƒˆãƒ¼ã‚¯ãƒ³: 0ä»¶ (0.0%)\n\n\n\t\n\t\t\n\t\tãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆæ§‹é€ \n\t\n\n\nsystem_prompt: ãƒ¢ãƒ‡ãƒ«ã«é€ä¿¡ã•ã‚ŒãŸã‚·ã‚¹ãƒ†ãƒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ\nquestion_text: å…ƒã®å•é¡Œæ–‡\nanswer_text: å•é¡Œã®è§£ç­”â€¦ See the full description on the dataset page: https://huggingface.co/datasets/llm-compe-2025-kato/step3-input-bespoke-stratos-17k-test1.","url":"https://huggingface.co/datasets/llm-compe-2025-kato/step3-input-bespoke-stratos-17k-test1","creator_name":"llm-compe-2025-kato","creator_url":"https://huggingface.co/llm-compe-2025-kato","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-generation","Japanese","English","mit","< 1K"],"keywords_longer_than_N":true},
	{"name":"ida-reasoning-model","keyword":"reasoning","description":"\n\t\n\t\t\n\t\tIDA Reasoning Model\n\t\n\nThis model was trained using Imitation, Distillation, and Amplification (IDA) on multiple reasoning datasets.\n\n\t\n\t\t\n\t\tTraining Details\n\t\n\n\nTeacher Model: deepseek-ai/DeepSeek-R1-Distill-Qwen-7B\nStudent Model: Qwen/Qwen3-1.7B\nDatasets: 4 reasoning datasets\nTotal Samples: 600\nTraining Method: IDA (Iterative Distillation and Amplification)\n\n\n\t\n\t\t\n\t\tDatasets Used\n\t\n\n\ngsm8k\nHuggingFaceH4/MATH-500\nMuskumPillerum/General-Knowledge\nSAGI-1/reasoningData_200kâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/ziadrone/ida-reasoning-model.","url":"https://huggingface.co/datasets/ziadrone/ida-reasoning-model","creator_name":"drone","creator_url":"https://huggingface.co/ziadrone","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["English","apache-2.0","< 1K","json","Text"],"keywords_longer_than_N":true},
	{"name":"aime2025-ru","keyword":"reasoning","description":"\n\t\n\t\t\n\t\tRussian Description (English below)\n\t\n\nĞŸĞµÑ€ĞµĞ²ĞµĞ´ĞµĞ½Ğ½Ğ°Ñ Ğ²ĞµÑ€ÑĞ¸Ñ Ğ±ĞµĞ½Ñ‡Ğ¼Ğ°Ñ€ĞºĞ° AIME 2025 Ğ½Ğ° Ñ€ÑƒÑÑĞºĞ¸Ğ¹ ÑĞ·Ñ‹Ğº. ĞœĞ¾Ğ´ĞµĞ»ÑŒ-Ğ¿ĞµÑ€ĞµĞ²Ğ¾Ğ´Ñ‡Ğ¸Ğº - Gemini 2.0 Pro Experimental.\n\n\t\n\t\t\n\t\tEnglish Description\n\t\n\nTranslated version of AIME 2025 into Russian. Model-translator - Gemini 2.0 Pro Experimental.\n\n\t\n\t\t\n\t\tLeaderboard\n\t\n\n\n","url":"https://huggingface.co/datasets/kristaller486/aime2025-ru","creator_name":"Kristaller486","creator_url":"https://huggingface.co/kristaller486","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","Russian","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"variant_effect_coding","keyword":"reasoning","description":"\nğŸ§¬ BioReasonIncentivizing Multimodal Biological Reasoning within a DNA-LLM Model\n\n\n\n  \n  \n  \n  \n\n\n\n\t\n\t\t\n\t\tVariant Effect Coding Dataset\n\t\n\n50,083 core variant entries from GPN-MSA study using ClinVar pathogenic variants and gnomAD benign variants (MAF>5%), split by chromosome (Chr 1-7,9-22,X,Y for train, Chr 8 for test) for pathogenic/benign classification.\n\n\t\n\t\t\n\t\tUsage\n\t\n\nfrom datasets import load_dataset\n\ndataset = load_dataset(\"wanglab/variant_effect_coding\")\nexample = dataset[\"train\"][0]â€¦ See the full description on the dataset page: https://huggingface.co/datasets/wanglab/variant_effect_coding.","url":"https://huggingface.co/datasets/wanglab/variant_effect_coding","creator_name":"WangLab UofT","creator_url":"https://huggingface.co/wanglab","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["apache-2.0","10K - 100K","parquet","Text","Datasets"],"keywords_longer_than_N":true},
	{"name":"Alizee-OpenCodeReasoning-Phase3-1.4M","keyword":"reasoning","description":"\n\t\n\t\t\n\t\tğŸš€ Alizee OpenCodeReasoning Phase 3 Conformant Dataset - 1.2M Examples\n\t\n\n\n\t\n\t\t\n\t\tğŸ“Š Dataset Summary\n\t\n\nThis is a fully conformant version of the Phase 3 dataset, processed to strictly follow the specification with clean separation between data and formatting tags. Contains 1.2 million high-quality Python code examples with synthetic prompts and concise reasoning chains.\n\n\t\n\t\t\n\t\tKey Improvements\n\t\n\n\nâœ… 100% Conformant to Phase 3 specification\nâœ… Synthetic prompts generated from codeâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/DUKEAI/Alizee-OpenCodeReasoning-Phase3-1.4M.","url":"https://huggingface.co/datasets/DUKEAI/Alizee-OpenCodeReasoning-Phase3-1.4M","creator_name":"DUKE ANALYTICS","creator_url":"https://huggingface.co/DUKEAI","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":null,"first_N":5,"first_N_keywords":["text-generation","English","cc-by-4.0","1M<n<10M","ğŸ‡ºğŸ‡¸ Region: US"],"keywords_longer_than_N":true},
	{"name":"r1-reasoning-tr","keyword":"reasoning","description":"\n\t\n\t\t\n\t\tR1 Reasoning TR\n\t\n\nThis is an R1 reasoning dataset translated into Turkish, containing conversations between users and assistants. Thanks to lightblue for the dataset.\n\n\t\n\t\t\n\t\tLicense\n\t\n\nThis dataset is released under the Apache 2.0 License.\n","url":"https://huggingface.co/datasets/SoAp9035/r1-reasoning-tr","creator_name":"Ahmet Burhan KayalÄ±","creator_url":"https://huggingface.co/SoAp9035","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","text2text-generation","Turkish","English","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"WirelessMathBench","keyword":"reasoning","description":"\n\t\n\t\t\n\t\tWirelessMathBench\n\t\n\nWirelessMathBench is a benchmark designed to test the mathematical reasoning and symbolic problem-solving capabilities of large language models (LLMs) in wireless communications. It contains expert-level, LaTeX-formatted questions spanning key topics such as:\n\nMultiple Input Multiple Output (MIMO)\nReconfigurable Intelligent Surfaces (RIS)\nIntegrated Sensing and Communications (ISAC)\nUAV-enabled networks\nChannel estimation and signal processing\n\nEach question isâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/XINLI1997/WirelessMathBench.","url":"https://huggingface.co/datasets/XINLI1997/WirelessMathBench","creator_name":"XinLi","creator_url":"https://huggingface.co/XINLI1997","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["cc-by-4.0","< 1K","json","Text","Datasets"],"keywords_longer_than_N":true},
	{"name":"math_problem_traces_test2","keyword":"step-by-step","description":"A dataset containing mathematical problem-solving traces with step-by-step solutions and improvement history. Each record includes a mathematical problem, its final solution, and the iterative improvement process.","url":"https://huggingface.co/datasets/Wendong-Fan/math_problem_traces_test2","creator_name":"Wendong.Fan","creator_url":"https://huggingface.co/Wendong-Fan","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-generation","English","mit","< 1K","json"],"keywords_longer_than_N":true},
	{"name":"supra-nexus-o1-training","keyword":"reasoning","description":"\n\t\n\t\t\n\t\tSupra Nexus O1 Training Datasets\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nComprehensive training datasets for Supra Nexus O1 models, including:\n\nIdentity training\nChain-of-thought reasoning\nSelf-improvement examples (O1.5)\nInstruction following\n\n\n\t\n\t\t\n\t\tDatasets Included\n\t\n\n\n\t\n\t\t\n\t\t1. Identity Dataset (supra_identity.jsonl)\n\t\n\n\nModel identity and alignment\nOrganization information\nCapability descriptions\n\n\n\t\n\t\t\n\t\t2. Instruction Dataset (supra_instruct_*.jsonl)\n\t\n\n\nDirect instruction following\nVariousâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Supra-Nexus/supra-nexus-o1-training.","url":"https://huggingface.co/datasets/Supra-Nexus/supra-nexus-o1-training","creator_name":"Supra Nexus","creator_url":"https://huggingface.co/Supra-Nexus","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","question-answering","English","apache-2.0","1K<n<10K"],"keywords_longer_than_N":true},
	{"name":"VisNumBench","keyword":"mathematical-reasoning","description":"This dataset is designed for research in Deep Learning for Geometry Problem Solving (DL4GPS) and accompanies the survey paper A Survey of Deep Learning for Geometry Problem Solving. It aims to provide a structured resource for evaluating and training AI models, particularly multimodal large language models (MLLMs), on mathematical reasoning tasks involving geometric contexts.\nThe dataset provides a collection of geometry problems, each consisting of a textual question and a correspondingâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/GML-FMGroup/VisNumBench.","url":"https://huggingface.co/datasets/GML-FMGroup/VisNumBench","creator_name":"Foundation Model Group at Guangming Laboratory","creator_url":"https://huggingface.co/GML-FMGroup","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["image-text-to-text","mit","1K - 10K","parquet","Image"],"keywords_longer_than_N":true},
	{"name":"Reflection-Chinese-Dataset","keyword":"reflection","description":"\n\t\n\t\t\n\t\tReflection-Chinese-DatasetÂ·Reflectionä¸­æ–‡æ•°æ®é›†\n\t\n\nBased on mahiatlinux/Reflection-Dataset-v2, translated using RA Translation Tool\n","url":"https://huggingface.co/datasets/stvlynn/Reflection-Chinese-Dataset","creator_name":"Steven Lynn","creator_url":"https://huggingface.co/stvlynn","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["Chinese","mit","1K - 10K","json","Text"],"keywords_longer_than_N":true},
	{"name":"Intermediate-Thinking-130k","keyword":"logical-reasoning","description":"\n\t\n\t\t\n\t\tIntermediate-Thinking-130k\n\t\n\nA comprehensive dataset of 135,000 high-quality samples designed to advance language model reasoning capabilities through structured intermediate thinking processes. This dataset enables training and evaluation of models with sophisticated self-correction and iterative reasoning abilities across 42 languages.\nOG Link\n\n\t\n\t\t\n\t\n\t\n\t\tOverview\n\t\n\nIntermediate-Thinking-130k addresses a fundamental limitation in current language models: their inability to pauseâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/mlx-community/Intermediate-Thinking-130k.","url":"https://huggingface.co/datasets/mlx-community/Intermediate-Thinking-130k","creator_name":"MLX Community","creator_url":"https://huggingface.co/mlx-community","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","Afrikaans","Arabic","Bengali","Bulgarian"],"keywords_longer_than_N":true},
	{"name":"Intermediate-Thinking-130k","keyword":"mathematical-reasoning","description":"\n\t\n\t\t\n\t\tIntermediate-Thinking-130k\n\t\n\nA comprehensive dataset of 135,000 high-quality samples designed to advance language model reasoning capabilities through structured intermediate thinking processes. This dataset enables training and evaluation of models with sophisticated self-correction and iterative reasoning abilities across 42 languages.\nOG Link\n\n\t\n\t\t\n\t\n\t\n\t\tOverview\n\t\n\nIntermediate-Thinking-130k addresses a fundamental limitation in current language models: their inability to pauseâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/mlx-community/Intermediate-Thinking-130k.","url":"https://huggingface.co/datasets/mlx-community/Intermediate-Thinking-130k","creator_name":"MLX Community","creator_url":"https://huggingface.co/mlx-community","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","Afrikaans","Arabic","Bengali","Bulgarian"],"keywords_longer_than_N":true},
	{"name":"Reflection-Dataset-v1","keyword":"reflection","description":"\n\t\n\t\t\n\t\tV2 is out!!! V2\n\t\n\n\n\t\n\t\t\n\t\tSimple \"Reflection\" method dataset inspired by mattshumer\n\t\n\n\n\t\n\t\t\n\t\tThis is the prompt and response version. Find ShareGPT version here\n\t\n\nThis dataset was synthetically generated using Glaive AI.\n","url":"https://huggingface.co/datasets/mahiatlinux/Reflection-Dataset-v1","creator_name":"Maheswar KK","creator_url":"https://huggingface.co/mahiatlinux","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["English","mit","1K - 10K","json","Text"],"keywords_longer_than_N":true},
	{"name":"TIME","keyword":"reasoning","description":"\n\t\n\t\t\n\t\tâ³TIME: A Multi-level Benchmark for Temporal Reasoning of LLMs in Real-World Scenarios\n\t\n\n\n\n\n\t\n\t\t\n\t\tğŸŒ GitHub Code and Page\n\t\n\nGitHub Code: https://github.com/sylvain-wei/TIME\nGitHub Page: https://omni-time.github.io\narXiv: https://arxiv.org/pdf/2505.12891\n\n\t\n\t\t\n\t\tğŸ‘‹ğŸ» Introduction\n\t\n\nâ³TIME is a multi-level benchmark for temporal reasoning of LLMS, and it consists of 38,522 QA pairs, covering 3 levels with 11 fine-grained sub-tasks. This benchmark encompasses 3 sub-datasets reflectingâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/SylvainWei/TIME.","url":"https://huggingface.co/datasets/SylvainWei/TIME","creator_name":"Shaohang Wei","creator_url":"https://huggingface.co/SylvainWei","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["question-answering","English","cc-by-4.0","100K - 1M","json"],"keywords_longer_than_N":true},
	{"name":"events-scheduling","keyword":"reasoning","description":"\n\t\n\t\t\n\t\tğŸ—“ï¸ Events Scheduling dataset\n\t\n\nSmall dataset to train Language Models to create a schedule from a list of events and priorities.\nI used this dataset to train the ğŸ‘‘ ğŸ—“ï¸ anakin87/qwen-scheduler-7b-grpo model using GRPO.\nâ¡ï¸ Read the full story in my blog post.\nFind all the code in the GitHub repository.\n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tThe problem\n\t\n\nGiven a list of events and priorities, we ask the model to create a schedule that maximizes the total duration of selected events, weighted by priority.Inâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/anakin87/events-scheduling.","url":"https://huggingface.co/datasets/anakin87/events-scheduling","creator_name":"Stefano Fiorucci","creator_url":"https://huggingface.co/anakin87","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","English","apache-2.0","< 1K","parquet"],"keywords_longer_than_N":true},
	{"name":"CodeDebugReasoning","keyword":"reasoning","description":"OpenDebugReasoning is a small, focused dataset for evaluating code debugging and reasoning ability in language models. It contains 1,000 samples derived from Vezora/Open-Critic-GPT, seeded and filtered for quality, then annotated using Gemini API completions.\nEach entry in the dataset includes a buggy code snippet and a prompt asking an AI model to identify and fix the issue. The dataset also includes step-by-step reasoning generated during the debugging process.\n\n\t\n\t\t\n\t\tColumns\n\t\n\n\nprompt: Aâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/talon-community/CodeDebugReasoning.","url":"https://huggingface.co/datasets/talon-community/CodeDebugReasoning","creator_name":"Talon Community","creator_url":"https://huggingface.co/talon-community","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["question-answering","English","cc-by-4.0","1K - 10K","parquet"],"keywords_longer_than_N":true},
	{"name":"SOPBench","keyword":"reasoning","description":"\n\t\n\t\t\n\t\tSOPBench: Evaluating Language Agents at Following Standard Operating Procedures and Constraints\n\t\n\n\n\t\n\t\t\n\t\tPurpose and scope\n\t\n\nAs language agents increasingly automate critical tasks, their ability to follow domain-specific standard operating procedures (SOPs), policies, and constraints when taking actions and making tool calls becomes essential yet remains underexplored. To address this gap, we develop an automated evaluation pipeline with: (1) executable environments containing 167â€¦ See the full description on the dataset page: https://huggingface.co/datasets/Zekunli/SOPBench.","url":"https://huggingface.co/datasets/Zekunli/SOPBench","creator_name":"Zekun Li","creator_url":"https://huggingface.co/Zekunli","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["English","cc-by-4.0","< 1K","json","Text"],"keywords_longer_than_N":true},
	{"name":"dpo-scientific-reasoning","keyword":"reasoning","description":"\n\t\n\t\t\n\t\tDpo Scientific Reasoning\n\t\n\nThis dataset contains 100 high-quality examples for Direct Preference Optimization (DPO) training, focused on scientific reasoning and analysis.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset was generated using an enhanced DSPy-based pipeline that creates structured reasoning traces for scientific questions. Each example includes:\n\nSeparated content fields: System prompt, user question, and full context as individual columns\nChosen responses: High-qualityâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/abhi26/dpo-scientific-reasoning.","url":"https://huggingface.co/datasets/abhi26/dpo-scientific-reasoning","creator_name":"ABHISEK GUHA","creator_url":"https://huggingface.co/abhi26","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-generation","question-answering","English","mit","< 1K"],"keywords_longer_than_N":true},
	{"name":"German-RAG-LLM-HARD-BENCHMARK","keyword":"reasoning","description":"\n\t\n\t\t\n\t\tGerman-RAG-LLM-HARD Benchmark\n\t\n\n\n\t\n\t\t\n\t\tGerman-RAG - German Retrieval Augmented Generation\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis German-RAG-LLM-HARD-BENCHMARK represents a specialized collection for evaluate language models with a focus on hard to solve RAG-specific capabilities. To evaluate models compatible with OpenAI-Endpoints you can refer to our Github Repo: https://github.com/avemio-digital/GRAG-LLM-HARD-BENCHMARK\nThe subsets are derived from Synthetic generation inspired byâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/avemio/German-RAG-LLM-HARD-BENCHMARK.","url":"https://huggingface.co/datasets/avemio/German-RAG-LLM-HARD-BENCHMARK","creator_name":"Avemio AG","creator_url":"https://huggingface.co/avemio","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["question-answering","summarization","German","English","mit"],"keywords_longer_than_N":true},
	{"name":"Unaligned-Thinking-o1","keyword":"reasoning","description":"\n\t\n\t\t\n\t\tUnaligned Thinking o1  - Uncensored Data from Gemini 2.0 Flash Thinking\n\t\n\nWelcome to the \"Unaligned Thinking\" (Unaligned-Thinking-o1) dataset, a collection of raw toxic, output from the Gemini 2.0 Flash Thinking \nThis Dataset is created using Prompt Engineering\nDisclaimer:\nThis Dataset contains highly toxic dataset , while still providing top-notch relevant answer very detailed and very verbose , only beaten by sonnet-3.5 gemini-exp-1206 O1\nThe data contained within this dataset isâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fhai50032/Unaligned-Thinking-o1.","url":"https://huggingface.co/datasets/fhai50032/Unaligned-Thinking-o1","creator_name":"Low IQ Gen AI","creator_url":"https://huggingface.co/fhai50032","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["mit","< 1K","parquet","Text","Datasets"],"keywords_longer_than_N":true},
	{"name":"amc_aime_self_improving","keyword":"step-by-step","description":"A dataset containing mathematical problem-solving traces with step-by-step solutions and improvement history. Each record includes a mathematical problem, its final solution, and the iterative improvement process.","url":"https://huggingface.co/datasets/camel-ai/amc_aime_self_improving","creator_name":"CAMEL-AI.org","creator_url":"https://huggingface.co/camel-ai","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-generation","English","mit","1K - 10K","json"],"keywords_longer_than_N":true},
	{"name":"NOVEReason_full","keyword":"reasoning","description":"\n  \n\n\n\n\n\t\n\t\t\n\t\tNOVEReason_full\n\t\n\n\nNOVEReason is the dataset used in the paper NOVER: Incentive Training for Language Models via Verifier-Free Reinforcement Learning. It is a multi-domain, multi-task, general-purpose reasoning dataset, comprising seven curated datasets across four subfields: general reasoning, creative writing, social intelligence, and multilingual understanding. The data has been carefully cleaned and filtered to ensure suitability for training large reasoning models usingâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/thinkwee/NOVEReason_full.","url":"https://huggingface.co/datasets/thinkwee/NOVEReason_full","creator_name":"weiliu","creator_url":"https://huggingface.co/thinkwee","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["question-answering","translation","summarization","text-generation","English"],"keywords_longer_than_N":true},
	{"name":"train-of-thought","keyword":"reasoning","description":"\n\t\n\t\t\n\t\tTrain of Thought Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset readapts agentlans/think-more\ninto the Alpaca-style instruction tuning format for training language models in direct answering and chain-of-thought reasoning.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nEach original example was randomly assigned to be thinking on or off:\n\nThinking off: Outputs only the final answer.\nThinking on:\nOutputs a chain-of-thought (CoT) reasoning process wrapped in <think>...</think>, followed by the final answerâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/agentlans/train-of-thought.","url":"https://huggingface.co/datasets/agentlans/train-of-thought","creator_name":"Alan Tseng","creator_url":"https://huggingface.co/agentlans","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","English","cc-by-4.0","1M - 10M","json"],"keywords_longer_than_N":true},
	{"name":"openmath-nondual","keyword":"reasoning","description":"\n\t\n\t\t\n\t\tnondual_openmath_final\n\t\n\nA non-dual reformulation of the unsloth/OpenMathReasoning-mini dataset.All assistant solutions have been rewritten into impersonal, non-dual language using OpenAI models, and finalized so that the dataset no longer contains duplicate *_nondual fields.\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\n\nSource: unsloth/OpenMathReasoning-mini  \nFormat: JSONL, each line is a dictionary with the following fields:\n\n\n\t\n\t\t\nField\nDescription\n\n\n\t\t\nproblem\nMath problem statement (rewrittenâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/marciodiaz/openmath-nondual.","url":"https://huggingface.co/datasets/marciodiaz/openmath-nondual","creator_name":"Marcio Diaz","creator_url":"https://huggingface.co/marciodiaz","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["English","cc-by-4.0","10K - 100K","json","Text"],"keywords_longer_than_N":true},
	{"name":"VLM-Video-Understanding","keyword":"reasoning","description":"\n\t\n\t\t\n\t\tVLM-Video-Understanding\n\t\n\n\nA minimalistic demo for image inference and video understanding using OpenCV, built on top of several popular open-source Vision-Language Models (VLMs). This repository provides Colab notebooks demonstrating how to apply these VLMs to video and image tasks using Python and Gradio.\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis project showcases lightweight inference pipelines for the following:\n\nVideo frame extraction and preprocessing\nImage-level inference with VLMs\nReal-timeâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/prithivMLmods/VLM-Video-Understanding.","url":"https://huggingface.co/datasets/prithivMLmods/VLM-Video-Understanding","creator_name":"Prithiv Sakthi","creator_url":"https://huggingface.co/prithivMLmods","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["video-text-to-text","image-to-text","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"phantom-wiki-v1","keyword":"reasoning","description":"\n\t\n\t\t\n\t\tDataset Card for PhantomWiki\n\t\n\nThis repository contains pre-generated instances of the PhantomWiki dataset, created using the phantom-wiki Python package.  PhantomWiki is a framework for evaluating LLMs, particularly RAG and agentic workflows, designed to be resistant to memorization. Unlike fixed datasets, PhantomWiki generates unique instances on demand, ensuring novelty and preventing data leakage.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nPhantomWiki generates aâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/kilian-group/phantom-wiki-v1.","url":"https://huggingface.co/datasets/kilian-group/phantom-wiki-v1","creator_name":"Kilian's Group","creator_url":"https://huggingface.co/kilian-group","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["question-answering","English","mit","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"m500","keyword":"reasoning","description":"Two Heads are Better Than One: Test-time Scaling of Multi-agent Collaborative Reasoning\nCode: https://github.com/jincan333/MAS-TTS\nProject page: https://github.com/jincan333/MAS-TTS\nThe M500 dataset is a curated collection of 500 challenging, interdisciplinary problems designed to evaluate and improve multi-agent collaboration and reasoning in large language models (LLMs). Each sample includes a full trace of interactions among multiple specialized agents solving a complex taskâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Can111/m500.","url":"https://huggingface.co/datasets/Can111/m500","creator_name":"Can Jin","creator_url":"https://huggingface.co/Can111","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","English","apache-2.0","< 1K","parquet"],"keywords_longer_than_N":true},
	{"name":"TreeBench","keyword":"reasoning","description":"\n\t\n\t\t\n\t\tTraceable Evidence Enhanced Visual Grounded Reasoning: Evaluation and Methodology\n\t\n\nThis repository contains the TreeBench dataset, a diagnostic benchmark for visual grounded reasoning, introduced in the paper Traceable Evidence Enhanced Visual Grounded Reasoning: Evaluation and Methodology.\nTL; DR: We propose TreeBench, the first benchmark specially designed for evaluating \"thinking with images\" capabilities with traceable visual evidence, and TreeVGR, the current state-of-the-artâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/HaochenWang/TreeBench.","url":"https://huggingface.co/datasets/HaochenWang/TreeBench","creator_name":"HaochenWang","creator_url":"https://huggingface.co/HaochenWang","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["image-text-to-text","apache-2.0","< 1K","csv","Text"],"keywords_longer_than_N":true},
	{"name":"tool-n1-sft-combined-unique-corrected","keyword":"reasoning","description":"\n\t\n\t\t\n\t\tTool-N1 SFT Combined Unique Corrected\n\t\n\nThis dataset contains supervised fine-tuning (SFT) data for training models on multi-hop tool usage and reasoning. It combines corrected reasoning from 3-hop, 6-hop, and 9-hop scenarios with actual step-by-step reasoning instead of generic templates.\n\n\t\n\t\t\n\t\tKey Features\n\t\n\nâœ… Corrected Reasoning: Replaced generic templated reasoning with actual step-by-step analysisâœ… Unique Queries: Deduplicated based on query contentâœ… Multi-hop Complexity:â€¦ See the full description on the dataset page: https://huggingface.co/datasets/Anna4242/tool-n1-sft-combined-unique-corrected.","url":"https://huggingface.co/datasets/Anna4242/tool-n1-sft-combined-unique-corrected","creator_name":"D","creator_url":"https://huggingface.co/Anna4242","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","question-answering","English","apache-2.0","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"summexecedit","keyword":"reasoning","description":"\n\t\n\t\t\n\t\tFactual Consistency in Summarization\n\t\n\nEvaluate your model's ability to detect and explain the factual inconsistency in summaries. This repo contains the benchmark from our paper \"SummExecEdit: A Factual Consistency Benchmark in Summarization with Executable Edits\".\n\n\t\n\t\t\n\t\tSummExecEdit Benchmark\n\t\n\nThis benchmark is built over our previous benchmark - SummEdits. Consistent summaries are used from SummEdits. New inconsistent and challenging summaries are generated using executableâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Salesforce/summexecedit.","url":"https://huggingface.co/datasets/Salesforce/summexecedit","creator_name":"Salesforce","creator_url":"https://huggingface.co/Salesforce","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","summarization","English","cc-by-4.0","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"DrivingVQA","keyword":"reasoning","description":"\n\t\n\t\t\n\t\tDataset Card for DrivingVQA\n\t\n\nğŸ  Homepage\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nDrivingVQA is a dataset designed to assist candidates preparing for the French driving theory exam, which requires passing both a theoretical and a practical test. The theoretical aspect consists of analyzing 40 multiple-choice questions (MCQs) with real-world images to test the candidates' knowledge of traffic laws, road signs, and safe driving practices. This dataset focuses on visualâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/EPFL-DrivingVQA/DrivingVQA.","url":"https://huggingface.co/datasets/EPFL-DrivingVQA/DrivingVQA","creator_name":"EPFL-DrivingVQA","creator_url":"https://huggingface.co/EPFL-DrivingVQA","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["visual-question-answering","multiple-choice","English","mit","1K<n<10K"],"keywords_longer_than_N":true},
	{"name":"tw-reasoning-instruct-50k","keyword":"reasoning","description":"\n\t\n\t\t\n\t\tDataset Card for tw-reasoning-instruct-50k\n\t\n\n\n\ntw-reasoning-instruct-50k æ˜¯ä¸€å€‹ç²¾é¸çš„ ç¹é«”ä¸­æ–‡ï¼ˆå°ç£ï¼‰ æ¨ç†è³‡æ–™é›†ï¼Œæ—¨åœ¨æå‡èªè¨€æ¨¡å‹æ–¼é€æ­¥é‚è¼¯æ€è€ƒã€è§£é‡‹ç”Ÿæˆèˆ‡èªè¨€ç†è§£ç­‰ä»»å‹™ä¸­çš„è¡¨ç¾ã€‚è³‡æ–™å…§å®¹æ¶µè“‹æ—¥å¸¸æ€è¾¨ã€æ•™è‚²å°è©±ã€æ³•å¾‹æ¨ç†ç­‰å¤šå…ƒä¸»é¡Œï¼Œä¸¦çµåˆã€Œæ€è€ƒæ­¥é©Ÿã€èˆ‡ã€Œæœ€çµ‚ç­”æ¡ˆã€çš„çµæ§‹è¨­è¨ˆï¼Œå¼•å°æ¨¡å‹ä»¥æ›´æ¸…æ™°ã€æ¢ç†åˆ†æ˜çš„æ–¹å¼é€²è¡Œæ¨è«–èˆ‡å›æ‡‰ï¼Œç‰¹åˆ¥å¼·èª¿ç¬¦åˆå°ç£æœ¬åœ°èªè¨€èˆ‡æ–‡åŒ–èƒŒæ™¯çš„æ‡‰ç”¨éœ€æ±‚ã€‚\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Description\n\t\n\n\næœ¬è³‡æ–™é›†å°ˆç‚ºç™¼å±•å…·å‚™å¼·å¤§æ¨ç†èƒ½åŠ›çš„ç¹é«”ä¸­æ–‡å¤§å‹èªè¨€æ¨¡å‹ï¼ˆLarge Reasoning Models, LRMï¼‰æ‰€è¨­è¨ˆï¼Œå…§å®¹æ·±åº¦çµåˆå°ç£çš„èªè¨€èˆ‡æ–‡åŒ–è„ˆçµ¡ã€‚æ¯ç­†è³‡æ–™é€šå¸¸åŒ…å«ä½¿ç”¨è€…çš„æå•ã€æ¨¡å‹çš„å›æ‡‰ï¼Œä»¥åŠæ¸…æ¥šçš„æ¨ç†éç¨‹ã€‚è³‡æ–™é›†è¨­è¨ˆç›®æ¨™ç‚ºåŸ¹é¤Šæ¨¡å‹å…·å‚™é¡äººé‚è¼¯çš„é€æ­¥æ€è€ƒèˆ‡è§£é‡‹èƒ½åŠ›ã€‚\næ­¤è³‡æ–™é›†é©ç”¨æ–¼è¨“ç·´èˆ‡è©•ä¼°ä»¥ä¸‹ä»»å‹™ï¼š\n\nå°ç£ç¤¾æœƒçš„æ—¥å¸¸æ¨ç†\næ•™è‚²æ€§å°è©±\nä»¥è§£é‡‹ç‚ºå°å‘çš„ç”Ÿæˆä»»å‹™â€¦ See the full description on the dataset page: https://huggingface.co/datasets/twinkle-ai/tw-reasoning-instruct-50k.","url":"https://huggingface.co/datasets/twinkle-ai/tw-reasoning-instruct-50k","creator_name":"Twinkle AI","creator_url":"https://huggingface.co/twinkle-ai","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-generation","English","Chinese","mit","10K - 100K"],"keywords_longer_than_N":true},
	{"name":"Nemotron-PrismMath","keyword":"reasoning","description":"\n\t\n\t\t\n\t\tNemotron-PrismMath\n\t\n\nJaehun Jung, Seungju Han*, Ximing Lu*, Skyler Hallinan*, David Acuna, Shrimai Prabhumoye, Mostofa Patwary, Mohammad Shoeybi, Bryan Catanzaro, Yejin Choi\nPaper Project Page\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\n\n\n\n\nNemotron-PrismMath is a state-of-the-art math reasoning dataset with diverse, novel math problems. This dataset is ready for commercial/non-commercial use.\n\nThe dataset consists of 1M math problem-solution pairs generated via Prismatic Synthesis, our novelâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/nvidia/Nemotron-PrismMath.","url":"https://huggingface.co/datasets/nvidia/Nemotron-PrismMath","creator_name":"NVIDIA","creator_url":"https://huggingface.co/nvidia","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["English","cc-by-4.0","1M - 10M","parquet","Text"],"keywords_longer_than_N":true},
	{"name":"PersonalFinance_v2","keyword":"reasoning","description":"\n\t\n\t\t\n\t\tPersonal Finance Reasoning-V2\n\t\n\nP.S. This dataset has won the First prize in the Reasoning Datasets Competition, organized by Bespoke Labs, HuggingFace & Together.AI During the months of April-May 2025. More details can be found here.\n\n\t\n\t\t\n\t\n\t\n\t\t1. Introduction & Motivation\n\t\n\nThe landscape of financial AI benchmarks is currently dominated by applications in corporate finance, algorithmic trading, and general financial knowledge extraction. While valuable, these benchmarks oftenâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Akhil-Theerthala/PersonalFinance_v2.","url":"https://huggingface.co/datasets/Akhil-Theerthala/PersonalFinance_v2","creator_name":"Akhil Theerthala","creator_url":"https://huggingface.co/Akhil-Theerthala","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-classification","text-generation","English","apache-2.0","1K - 10K"],"keywords_longer_than_N":true},
	{"name":"math_Light-R1-DPOData_preprocess","keyword":"reasoning","description":"\n\t\n\t\t\n\t\tdaichira/Light-R1-DPOData_preprocess\n\t\n\nThis dataset is a preprocessed version of qihoo360/Light-R1-DPOData, adapted for use with the verl training pipeline. It is designed for DPO (Direct Preference Optimization) training, containing pairs of chosen and rejected responses for mathematical reasoning problems.\n\n\t\n\t\t\n\t\tOriginal Dataset Overview (from qihoo360/Light-R1-DPOData)\n\t\n\nThe original Light-R1-DPOData is part of the \"Light-R1: Surpassing R1-Distill from Scratch with $1000 throughâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/LLMcompe-Team-Watanabe/math_Light-R1-DPOData_preprocess.","url":"https://huggingface.co/datasets/LLMcompe-Team-Watanabe/math_Light-R1-DPOData_preprocess","creator_name":"LLMcompe Team Watanabe","creator_url":"https://huggingface.co/LLMcompe-Team-Watanabe","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","apache-2.0","1K - 10K","parquet","Text"],"keywords_longer_than_N":true},
	{"name":"ViLReward-73K","keyword":"reasoning","description":"Process Reward Data for ViLBench: A Suite for Vision-Language Process Reward Modeling\nPaper | Project Page\nThere are 73K vision-language process reward data sourcing from five training sets.\n","url":"https://huggingface.co/datasets/UCSC-VLAA/ViLReward-73K","creator_name":"UCSC-VLAA","creator_url":"https://huggingface.co/UCSC-VLAA","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["image-text-to-text","English","mit","10K - 100K","json"],"keywords_longer_than_N":true},
	{"name":"MATH","keyword":"reasoning","description":"\n\t\n\t\t\n\t\tLoRID: A Reasoning Distillation Method via Multi-LoRA Interaction\n\t\n\nğŸ“ƒ Paper â€¢ ğŸ’» Code â€¢ ğŸ¤— HF Repo\n\n\t\n\t\t\n\t\tAbstract\n\t\n\nThe datasets for \"Can Large Models Teach Student Models to Solve Mathematical Problems Like Human Beings? A Reasoning Distillation Method via Multi-LoRA Interaction\" [IJCAI 2025].\n\n\t\n\t\t\n\t\tKey Contributions\n\t\n\n\nWe focus on the mathematical reasoning distillation task and propose a novel method LoRID, which draws inspiration from the human beings teaching and learningâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/LoRID-Math/MATH.","url":"https://huggingface.co/datasets/LoRID-Math/MATH","creator_name":"LoRID-Math","creator_url":"https://huggingface.co/LoRID-Math","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-generation","English","mit","100K - 1M","json"],"keywords_longer_than_N":true},
	{"name":"Arcosoph-FC-Reasoning-en-10k","keyword":"reasoning","description":"\n\t\n\t\t\n\t\tğŸ“Œ Overview\n\t\n\n\nTotal Samples: 10,000  \nPrimary Focus:  \nHigh-quality Function Calling demonstrations  \nClear, well-structured Chain of Thought reasoning\n\n\nSelection Process:  \nTranslated from Chinese to English\nRemoved noisy or incomplete examples  \nSelected cases with precise function arguments  \nEach example has been made clearer and more effective\nEnsured reasoning steps are logically sound and human-readable\n\n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tğŸ¯ Use Cases\n\t\n\nThis dataset is ideal for:\n\nFine-tuningâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/arcosoph/Arcosoph-FC-Reasoning-en-10k.","url":"https://huggingface.co/datasets/arcosoph/Arcosoph-FC-Reasoning-en-10k","creator_name":"Arcosoph AI","creator_url":"https://huggingface.co/arcosoph","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["apache-2.0","10K - 100K","json","Text","Datasets"],"keywords_longer_than_N":true},
	{"name":"distilabel-reasoning-R1-Llama-70B","keyword":"reasoning","description":"\n\t\n\t\t\n\t\tHow this Data was made\n\t\n\nWe made this data through the following steps:\n\nSample English reasoning-style prompts from argilla/distilabel-reasoning-prompts.\nRemove similar prompts using text similarity based on BAAI/bge-m3 embeddings.\nTranslate English prompts to Japanese using gpt-4o-mini-2024-07-18.\nGenerate answers to prompts using deepseek-ai/DeepSeek-R1-Distill-Llama-70B.\nFilter responses (to ja_valid) which did not:\nFinish within 2048 tokens\nContain a valid <think> section\nHaveâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/lightblue/distilabel-reasoning-R1-Llama-70B.","url":"https://huggingface.co/datasets/lightblue/distilabel-reasoning-R1-Llama-70B","creator_name":"Lightblue KK.","creator_url":"https://huggingface.co/lightblue","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["Japanese","English","apache-2.0","1K - 10K","parquet"],"keywords_longer_than_N":true},
	{"name":"ChessCOT","keyword":"reasoning","description":"\n\t\n\t\t\n\t\tChessCOT\n\t\n\nThe dataset that makes your chess model think like a human before it plays a move.\n\n\t\n\t\t\n\t\tAbout\n\t\n\nChessCOT is a dataset designed to train transformers for chess using a Chain of Thought (CoT) approach. The goal is to make the model reason about the position with all possible moves and their consequences in order to predict the best move.\n\n\t\n\t\t\n\t\tDataset Statistics\n\t\n\n\nTotal Poistions: 4,491,596\nSequence length of sMoves: 128\nSequence length of thought: 128â€¦ See the full description on the dataset page: https://huggingface.co/datasets/frosthead/ChessCOT.","url":"https://huggingface.co/datasets/frosthead/ChessCOT","creator_name":"Ayush Sharma","creator_url":"https://huggingface.co/frosthead","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-generation","text2text-generation","mit","1M - 10M","csv"],"keywords_longer_than_N":true},
	{"name":"multilevel-legal-reasoning","keyword":"reasoning","description":"\n\t\n\t\t\n\t\tLegal Reasoning Dataset with Multilevel Human and Model-Annotated Explanations\n\t\n\n\nPrepared by Mst Rafia Islam, Umong Sain, Azmine Toushik Wasi\nPrepared as a part of Reasoning Datasets Competition by Bespoke Labs, Hugging Face, and Together.ai.\n\n\n\n\t\n\t\t\n\t\tğŸ§­ Purpose and Scope\n\t\n\nThe Legal Reasoning Dataset aims to support the evaluation and training of legal reasoning systems, particularly in multilingual or jurisdiction-agnostic contexts. It focuses on international acts and treatiesâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/ciol-research/multilevel-legal-reasoning.","url":"https://huggingface.co/datasets/ciol-research/multilevel-legal-reasoning","creator_name":"Computational Intelligence and Operations Laboratory (CIOL)","creator_url":"https://huggingface.co/ciol-research","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","question-answering","English","apache-2.0","< 1K"],"keywords_longer_than_N":true},
	{"name":"Celestia3-DeepSeek-R1-0528-PREVIEW","keyword":"reasoning","description":"Click here to support our open-source dataset and model releases!\nThis is an early sneak preview of Celestia3-DeepSeek-R1-0528, containing the first 13.4k rows! \nCelestia3-DeepSeek-R1-0528 is a dataset focused on science, testing the limits of DeepSeek R1's science-reasoning skills!\nThis early preview release contains:\n\n13.4k synthetically generated science prompts. All responses are generated using DeepSeek R1 0528.\nPrimary subjects are physics, chemistry, biology, and computer science;â€¦ See the full description on the dataset page: https://huggingface.co/datasets/sequelbox/Celestia3-DeepSeek-R1-0528-PREVIEW.","url":"https://huggingface.co/datasets/sequelbox/Celestia3-DeepSeek-R1-0528-PREVIEW","creator_name":"t.d.a.g.","creator_url":"https://huggingface.co/sequelbox","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","English","apache-2.0","10K - 100K","csv"],"keywords_longer_than_N":true},
	{"name":"MATH_NuminaMath_allquerytypes","keyword":"reasoning","description":"Datasets from Paper: https://huggingface.co/papers/2505.18405\n","url":"https://huggingface.co/datasets/Raderspace/MATH_NuminaMath_allquerytypes","creator_name":"RaDeR","creator_url":"https://huggingface.co/Raderspace","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["English","mit","100K - 1M","parquet","Text"],"keywords_longer_than_N":true},
	{"name":"twi-reasoning-dataset_v2","keyword":"reasoning","description":"\n\t\n\t\t\n\t\tTwi Reasoning Dataset\n\t\n\nA Twi (Akan) translation of the Multilingual-Thinking reasoning dataset with chain-of-thought in Twi\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset is a Twi (Akan) translation of the Multilingual-Thinking reasoning dataset. It contains chain-of-thought reasoning traces translated from multiple languages into Twi, making it one of the first reasoning datasets available in this language.\n\n\t\n\t\t\n\t\tLanguage Information\n\t\n\n\nLanguage: Twi (Akan)\nLanguage Code: tw\nFamily:â€¦ See the full description on the dataset page: https://huggingface.co/datasets/michsethowusu/twi-reasoning-dataset_v2.","url":"https://huggingface.co/datasets/michsethowusu/twi-reasoning-dataset_v2","creator_name":"Mich-Seth Owusu","creator_url":"https://huggingface.co/michsethowusu","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","question-answering","conversational","text2text-generation","language-modeling"],"keywords_longer_than_N":true},
	{"name":"clean_openthought312_difficulty_9_qwentoken","keyword":"reasoning","description":"å…ƒãƒ‡ãƒ¼ã‚¿: https://huggingface.co/datasets/LLMTeamAkiyama/clean_openthought312_difficulty_9_filterd\n\nãƒ‡ãƒ¼ã‚¿ä»¶æ•°: 14,339\nå¹³å‡ãƒˆãƒ¼ã‚¯ãƒ³æ•°: 13,367\næœ€å¤§ãƒˆãƒ¼ã‚¯ãƒ³æ•°: 16,805\nåˆè¨ˆãƒˆãƒ¼ã‚¯ãƒ³æ•°: 191,665,652\nãƒ•ã‚¡ã‚¤ãƒ«å½¢å¼: JSONL\nãƒ•ã‚¡ã‚¤ãƒ«åˆ†å‰²æ•°: 3\nåˆè¨ˆãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚º: 724.7 MB\n\nåŠ å·¥å†…å®¹ï¼š\n\n**tokenizeã‚’Qwen235B-A22Bã§å†åº¦ãƒˆãƒ¼ã‚¯ãƒ³åŒ–ã—ãŸã‚‚ã®ã‚’å‡ºåŠ›\n\nä½¿ç”¨ã—ãŸã‚³ãƒ¼ãƒ‰\nhttps://github.com/LLMTeamAkiyama/0-data_prepare/blob/master/src/openthoughts3/clean_openthoughts3_9_qwentoken.ipynb\n","url":"https://huggingface.co/datasets/LLMTeamAkiyama/clean_openthought312_difficulty_9_qwentoken","creator_name":"LLMTeamAkiyama","creator_url":"https://huggingface.co/LLMTeamAkiyama","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["question-answering","English","apache-2.0","10K - 100K","json"],"keywords_longer_than_N":true},
	{"name":"dpo-merged","keyword":"reasoning","description":"CultriX/dpo-merged dataset hosted on Hugging Face and contributed by the HF Datasets community","url":"https://huggingface.co/datasets/CultriX/dpo-merged","creator_name":"CultriX","creator_url":"https://huggingface.co/CultriX","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","English","apache-2.0","10K - 100K","parquet"],"keywords_longer_than_N":true},
	{"name":"BeyondAIME","keyword":"reasoning","description":"\n\t\n\t\t\n\t\tBeyondAIME: Advancing Math Reasoning Evaluation Beyond High School Olympiads\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nBeyondAIME is a curated test set designed to benchmark advanced mathematical reasoning. Its creation was guided by the following core principles to ensure a fair and challenging evaluation:\n\nHigh Difficulty: Problems are sourced from high-school and university mathematics competitions, with a difficulty level greater than or equal to that of AIME Problems #11-15.â€¦ See the full description on the dataset page: https://huggingface.co/datasets/ByteDance-Seed/BeyondAIME.","url":"https://huggingface.co/datasets/ByteDance-Seed/BeyondAIME","creator_name":"ByteDance Seed","creator_url":"https://huggingface.co/ByteDance-Seed","license_name":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","first_N":5,"first_N_keywords":["English","cc0-1.0","< 1K","parquet","Text"],"keywords_longer_than_N":true},
	{"name":"rushhour4x4-eval","keyword":"reasoning","description":"\n\t\n\t\t\n\t\tRush Hour 4x4 Evaluation Dataset\n\t\n\nThis dataset contains 150 4x4 Rush Hour puzzles for model evaluation with difficulty labels.\n\n\t\n\t\t\n\t\tFormat\n\t\n\n\npuzzle_id: Unique identifier (puzzle1, puzzle2, ...)\nprompt: Full formatted prompt as used in model inference\nsolution: Optimal solution with proper formatting\noptimal_moves: Number of moves in optimal solution\ndifficulty: Difficulty level (easy, medium, hard)\n\n\n\t\n\t\t\n\t\tUsage\n\t\n\nEach puzzle contains:\n\nA grid state in JSON format\nPieceâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/mustafaah/rushhour4x4-eval.","url":"https://huggingface.co/datasets/mustafaah/rushhour4x4-eval","creator_name":"Mustafa Anis Hussain","creator_url":"https://huggingface.co/mustafaah","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["question-answering","English","mit","< 1K","parquet"],"keywords_longer_than_N":true},
	{"name":"ProcessBench","keyword":"reasoning","description":"\n\t\n\t\t\n\t\tProcessBench\n\t\n\nThis repository contains the dataset of the ProcessBench benchmark proposed by Qwen Team.\nYou can refer to our GitHub repository for the evaluation code and the prompt templates we use in this work.\nIf you find this work relevant or helpful to your work, please kindly cite us:\n@article{processbench,\n  title={ProcessBench: Identifying Process Errors in Mathematical Reasoning}, \n  author={\n    Chujie Zheng and Zhenru Zhang and Beichen Zhang and Runji Lin and Keming Lu andâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Qwen/ProcessBench.","url":"https://huggingface.co/datasets/Qwen/ProcessBench","creator_name":"Qwen","creator_url":"https://huggingface.co/Qwen","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["English","apache-2.0","1K - 10K","json","Text"],"keywords_longer_than_N":true},
	{"name":"MAmmoTH-VL-Instruct-12M","keyword":"reasoning","description":"\n\t\n\t\t\n\t\tMAmmoTH-VL-Instruct-12M used in MoCa Pre-training\n\t\n\nğŸ  Homepage | ğŸ’» Code | ğŸ¤– MoCa-Qwen25VL-7B | ğŸ¤– MoCa-Qwen25VL-3B | ğŸ“š Datasets | ğŸ“„ Paper\n\n\t\n\t\t\n\t\n\t\n\t\tIntroduction\n\t\n\nThis is a VQA style dataset used in the modality-aware continual pre-training of MoCa models. It is adapted from MAmmoTH-VL-Instruct-12M by concatenating prompts and responses.\nThe dataset consists of interleaved multimodal examples. text is a string containing text while imagesare image binaries that can be loadedâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/moca-embed/MAmmoTH-VL-Instruct-12M.","url":"https://huggingface.co/datasets/moca-embed/MAmmoTH-VL-Instruct-12M","creator_name":"MoCa","creator_url":"https://huggingface.co/moca-embed","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["visual-question-answering","question-answering","English","apache-2.0","10M - 100M"],"keywords_longer_than_N":true},
	{"name":"BlueMO","keyword":"reasoning","description":"\n\t\n\t\t\n\t\tBlueMO\n\t\n\n\n\t\n\t\t\n\t\tBlueMO: A High-Quality Mathematical Olympiad Data Resources from Little Blue Book Series\n\t\n\nBlueMO is a comprehensive and challenging dataset comprising mathematical olympiad problems paired with detailed solutions, meticulously curated from the esteemed \"Little Blue Book\" (å°è“ä¹¦) series (Second Edition)â€”a vital resource for Chinese students training for national and international olympiad math competitions.\nDesigned to advance and assess sophisticated reasoning in LLMsâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Luobots/BlueMO.","url":"https://huggingface.co/datasets/Luobots/BlueMO","creator_name":"Yifan Luo","creator_url":"https://huggingface.co/Luobots","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["question-answering","text-generation","Chinese","English","apache-2.0"],"keywords_longer_than_N":true},
	{"name":"distillation01","keyword":"step-by-step","description":"A dataset containing mathematical problem-solving traces with step-by-step solutions and improvement history. Each record includes a mathematical problem, its final solution, and the iterative improvement process.","url":"https://huggingface.co/datasets/zjrwtxtechstudio/distillation01","creator_name":"zjrwtx","creator_url":"https://huggingface.co/zjrwtxtechstudio","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-generation","English","mit","< 1K","json"],"keywords_longer_than_N":true},
	{"name":"Deepthink-Reasoning-Instruction","keyword":"reasoning","description":"\n\t\n\t\t\n\t\tDeepthink Reasoning Demo\n\t\n\nDeepthink Reasoning is a comprehensive data repository designed to break down complex problems, especially in coding (Python, Go, Java, C++, C#, etc.) and algorithms. It provides detailed problem analyses and systematic solutions to achieve the desired outcomes.\n\n\t\n\t\t\n\t\tFeatures\n\t\n\n\nComprehensive Problem Breakdown: Deepthink Reasoning dissects problems into smaller, manageable components to facilitate effective understanding and solution generation.â€¦ See the full description on the dataset page: https://huggingface.co/datasets/prithivMLmods/Deepthink-Reasoning-Instruction.","url":"https://huggingface.co/datasets/prithivMLmods/Deepthink-Reasoning-Instruction","creator_name":"Prithiv Sakthi","creator_url":"https://huggingface.co/prithivMLmods","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","English","apache-2.0","< 1K","parquet"],"keywords_longer_than_N":true},
	{"name":"Arcosoph-Codex-Weaver-FC-Reasoning","keyword":"reasoning","description":"\n\t\n\t\t\n\t\tArcosoph Codex Weaver Function Calling Reasoning Dataset (V1)\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nWelcome to the Arcosoph-Codex-Weaver-FC-Reasoning dataset! This is a comprehensive, multi-source, and meticulously curated dataset designed for instruction-tuning language models to function as intelligent, offline AI agents.\nThis dataset is provided in a universal, easy-to-parse JSON Lines (.jsonl) format, making it an ideal \"source of truth\" for creating fine-tuning data for various modelsâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/arcosoph/Arcosoph-Codex-Weaver-FC-Reasoning.","url":"https://huggingface.co/datasets/arcosoph/Arcosoph-Codex-Weaver-FC-Reasoning","creator_name":"Arcosoph AI","creator_url":"https://huggingface.co/arcosoph","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["feature-extraction","English","cc-by-4.0","10K - 100K","json"],"keywords_longer_than_N":true},
	{"name":"r103","keyword":"step-by-step","description":"A dataset containing mathematical problem-solving traces with step-by-step solutions and improvement history. Each record includes a mathematical problem, its final solution, and the iterative improvement process.","url":"https://huggingface.co/datasets/zjrwtxtechstudio/r103","creator_name":"zjrwtx","creator_url":"https://huggingface.co/zjrwtxtechstudio","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-generation","English","mit","< 1K","json"],"keywords_longer_than_N":true},
	{"name":"cleand_microsoft_rStar-Coder","keyword":"reasoning","description":"å…ƒãƒ‡ãƒ¼ã‚¿: https://huggingface.co/datasets/microsoft/rStar-Coder\nãƒ‡ãƒ¼ã‚¿ä»¶æ•°: 269,863\nå¹³å‡ãƒˆãƒ¼ã‚¯ãƒ³æ•°: 11674\næœ€å¤§ãƒˆãƒ¼ã‚¯ãƒ³æ•°: 31,184\nåˆè¨ˆãƒˆãƒ¼ã‚¯ãƒ³æ•°: 3,150,447,484\nãƒ•ã‚¡ã‚¤ãƒ«å½¢å¼: JSONL\nãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚º: ä¸æ˜\nåŠ å·¥å†…å®¹\n\nsynthetic_sftã‚’ä½¿ç”¨\nãƒˆãƒ¼ã‚¯ãƒ³å‡¦ç†ãŒé‡ãŸã„ã®ã§ã€æ–‡å­—æ•°ã§ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼\nseed_question < 6000\ngeneration < 80000\nthinkã‚¿ã‚°é™¤å» ãŒä¸­é€”åŠç«¯ãªã‚‚ã®ã‚’é™¤å¤–\nãƒˆãƒ¼ã‚¯ãƒŠã‚¤ã‚ºå‡¦ç†ï¼ˆé€Ÿåº¦å‘ä¸Šã‚¢ãƒƒãƒ—ãƒ‡ãƒ¼ãƒˆ\nç¹°ã‚Šè¿”ã—é™¤å»\n\n","url":"https://huggingface.co/datasets/LLMTeamAkiyama/cleand_microsoft_rStar-Coder","creator_name":"LLMTeamAkiyama","creator_url":"https://huggingface.co/LLMTeamAkiyama","license_name":"Creative Commons Attribution 4.0 International Public License","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","first_N":5,"first_N_keywords":["question-answering","English","cc-by-4.0","100K - 1M","json"],"keywords_longer_than_N":true},
	{"name":"SciAux","keyword":"reasoning","description":"This repository contains the SciAux dataset, introduced in the paper Thinking in a Crowd: How Auxiliary Information Shapes LLM Reasoning.\nSciAux is a new dataset derived from ScienceQA, designed to systematically test the robustness of Large Language Models (LLMs) against various types of auxiliary information (helpful, irrelevant, or misleading). The dataset aims to investigate the causal impact of such information on the reasoning process of LLMs with explicit step-by-step thinkingâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/billhdzhao/SciAux.","url":"https://huggingface.co/datasets/billhdzhao/SciAux","creator_name":"Haodong Zhao","creator_url":"https://huggingface.co/billhdzhao","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["question-answering","apache-2.0","1K - 10K","json","Tabular"],"keywords_longer_than_N":true},
	{"name":"CSK","keyword":"reasoning","description":"\n\t\n\t\t\n\t\tDataset Card for Causality in Script Knowledge (CSK)\n\t\n\nHugging Face Dataset | Paper (*SEM 2024) | Code\n\n\nCSK is a small, psycholinguistically controlled corpus for testing whether language models (and humans) integrate script knowledge when making causal inferences in narratives. It contains 21 short English stories about everyday activities (e.g., baking a cake, taking a bath), each realized in three causal conditions that manipulate the presence of a cause event A for a later eventâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/tonyhong/CSK.","url":"https://huggingface.co/datasets/tonyhong/CSK","creator_name":"Xudong Hong","creator_url":"https://huggingface.co/tonyhong","license_name":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","first_N":5,"first_N_keywords":["text-generation","English","apache-2.0","< 1K","csv"],"keywords_longer_than_N":true},
	{"name":"RelatLogic","keyword":"reasoning","description":"RelatLogic: A Dataset for Comparative and Conditional Reasoning\nThis is a comparative logic and conditional reasoning dataset. \nEach data point has a premise, question, answer, reasoning and attribute.\nMore about the generation process here.\nPlease cite this dataset using the provided BibTeX if you find it useful.\n@misc {sb_2025,\n    author       = { {SB} },\n    title        = { RelatLogic (Revision 15b1922) },\n    year         = 2025,\n    url          = {â€¦ See the full description on the dataset page: https://huggingface.co/datasets/shb777/RelatLogic.","url":"https://huggingface.co/datasets/shb777/RelatLogic","creator_name":"SB","creator_url":"https://huggingface.co/shb777","license_name":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","first_N":5,"first_N_keywords":["text-generation","English","mit","1M - 10M","parquet"],"keywords_longer_than_N":true}
]
;
