const data_for_modality_safety = 
[
	{"name":"TCM_Humanities","keyword":"safety","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/TCMLM/TCM_Humanities","creator_name":" ","creator_url":"https://huggingface.co/TCMLM","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for [TCMLM/TCM_Humanities]\\n\\t\\n\\n\\n\\nThis dataset, curated by the Traditional Chinese Medicine Language Model Team, comprises a comprehensive collection of multiple-choice questions (both single and multiple answers) from the Chinese Medical Practitioner Examination. It's designed to aid in understanding and assessing knowledge in Chinese humanities medicine, medical ethics, and legal regulations for physicians.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Details\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tUses‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/TCMLM/TCM_Humanities."},
	{"name":"toxic-text","keyword":"toxicity","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/nicholasKluge/toxic-text","creator_name":"Nicholas Kluge Corr√™a","creator_url":"https://huggingface.co/nicholasKluge","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tToxic-Text\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThis dataset contains a collection of examples of toxic and non-toxic language. The dataset is available in both Portuguese and English.\\nSamples were collected from the following datasets:\\n\\nAnthropic/hh-rlhf.\\nallenai/prosocial-dialog.\\nallenai/real-toxicity-prompts.\\ndirtycomputer/Toxic_Comment_Classification_Challenge.\\nPaul/hatecheck-portuguese.\\ntold-br.\\nskg/toxigen-data.\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSupported Tasks and Leaderboards\\n\\t\\n\\nThis dataset can‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/nicholasKluge/toxic-text."},
	{"name":"UHGEvalDataset","keyword":"hallucination","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Ki-Seki/UHGEvalDataset","creator_name":"Shichao Song","creator_url":"https://huggingface.co/Ki-Seki","description":"The dataset sourced from https://github.com/IAAR-Shanghai/UHGEval\\n"},
	{"name":"KoTox","keyword":"toxicity","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/SungJoo/KoTox","creator_name":"Grace","creator_url":"https://huggingface.co/SungJoo","description":"KoTox is an automatically generated toxic instruction dataset in Korean, comprising 39K unethical instruction-output pairs.\\nThe dataset is generated based on predefined lexicons and linguistic templates.\\nIt is designed to address potentially harmful or misleading instructions by including outputs that refrain from providing specific opinions or information in response.\\nThe dataset has been proven effective in mitigating toxicity in Korean Large Language Models (LLMs).\\nThe paper has been‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/SungJoo/KoTox."},
	{"name":"Salad-Data","keyword":"safety","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/OpenSafetyLab/Salad-Data","creator_name":"OpenSafetyLab","creator_url":"https://huggingface.co/OpenSafetyLab","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Description\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\t‚úä How to use\\n\\t\\n\\nfrom datasets import load_dataset\\n\\ndataset = load_dataset(\\\"OpenSafetyLab/Salad-Data\\\", name='base_set', split='train') \\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tüìä Statistical Overview of Base Question\\n\\t\\n\\n\\n\\t\\n\\t\\t\\nType\\nData Source\\nNums\\n\\n\\n\\t\\t\\nSelf-instructed\\nFinetuned GPT-3.5\\n15,433\\n\\n\\nOpen-Sourced\\nHH-harmless\\n4,184\\n\\n\\n\\nHH-red-team\\n659\\n\\n\\n\\nAdvbench\\n359\\n\\n\\n\\nMultilingual\\n230\\n\\n\\n\\nDo-Not-Answer\\n189\\n\\n\\n\\nToxicChat\\n129\\n\\n\\n\\nDo Anything Now\\n93\\n\\n\\n\\nGPTFuzzer\\n42\\n\\n\\nTotal\\n\\n21,318‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/OpenSafetyLab/Salad-Data."},
	{"name":"FactualConsistencyScoresTextSummarization","keyword":"hallucination","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/achandlr/FactualConsistencyScoresTextSummarization","creator_name":"Alex Chandler","creator_url":"https://huggingface.co/achandlr","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tHuggingFace Dataset: FactualConsistencyScoresTextSummarization\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDescription:\\n\\t\\n\\nThis dataset aggregates model scores assessing factual consistency across multiple summarization datasets. It is designed to highlight the thresholding issue with current SOTS factual consistency models in evaluating the factuality of text summarizations.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tWhat is the \\\"Thresholding Issue\\\" with SOTA Factual Consistency Models ?\\n\\t\\n\\nExisting models for detecting factual errors in‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/achandlr/FactualConsistencyScoresTextSummarization."},
	{"name":"saladbench_data","keyword":"safety","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mcj311/saladbench_data","creator_name":"CJMuclum","creator_url":"https://huggingface.co/mcj311","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Description\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\t‚úä How to use\\n\\t\\n\\nfrom datasets import load_dataset\\n\\ndataset = load_dataset(\\\"mcj311/saladbench_data\\\", name='base_set', split='train') \\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tüìä Statistical Overview of Base Question\\n\\t\\n\\n\\n\\t\\n\\t\\t\\nType\\nData Source\\nNums\\n\\n\\n\\t\\t\\nSelf-instructed\\nFinetuned GPT-3.5\\n15,433\\n\\n\\nOpen-Sourced\\nHH-harmless\\n4,184\\n\\n\\n\\nHH-red-team\\n659\\n\\n\\n\\nAdvbench\\n359\\n\\n\\n\\nMultilingual\\n230\\n\\n\\n\\nDo-Not-Answer\\n189\\n\\n\\n\\nToxicChat\\n129\\n\\n\\n\\nDo Anything Now\\n93\\n\\n\\n\\nGPTFuzzer\\n42\\n\\n\\nTotal\\n\\n21,318‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mcj311/saladbench_data."},
	{"name":"gahd","keyword":"hate-speech","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/jagoldz/gahd","creator_name":"Janis Goldzycher","creator_url":"https://huggingface.co/jagoldz","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for GAHD\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nGAHD is a German Adversarial Hate speech Dataset containing 10,996 examples. We collected the dataset via four rounds of Dynamic Adversarial Data Collection and explored various methods of supporting annotators in finding adversarial examples.\\n\\nPaper: https://aclanthology.org/2024.naacl-long.248/\\nRepository: https://github.com/jagol/gahd\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Structure\\n\\t\\n\\ngahd.csv contains the following columns:\\n\\ngahd_id:‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/jagoldz/gahd."},
	{"name":"gahd","keyword":"hate-speech-detection","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/jagoldz/gahd","creator_name":"Janis Goldzycher","creator_url":"https://huggingface.co/jagoldz","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for GAHD\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nGAHD is a German Adversarial Hate speech Dataset containing 10,996 examples. We collected the dataset via four rounds of Dynamic Adversarial Data Collection and explored various methods of supporting annotators in finding adversarial examples.\\n\\nPaper: https://aclanthology.org/2024.naacl-long.248/\\nRepository: https://github.com/jagol/gahd\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Structure\\n\\t\\n\\ngahd.csv contains the following columns:\\n\\ngahd_id:‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/jagoldz/gahd."},
	{"name":"Neo-GATE","keyword":"fairness","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/FBK-MT/Neo-GATE","creator_name":"FBK-MT","creator_url":"https://huggingface.co/FBK-MT","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset card for Neo-GATE\\n\\t\\n\\nHomepage: https://mt.fbk.eu/neo-gate/\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset summary\\n\\t\\n\\nNeo-GATE is a bilingual corpus designed to benchmark the ability of machine translation (MT) systems to translate from English into Italian using gender-inclusive neomorphemes.\\nIt is built upon GATE (Rarrick et al., 2023), a benchmark for the evaluation of gender rewriters and gender bias in MT.\\nNeo-GATE includes 841 test entries (Neo-GATE.tsv) and 100 dev entries (Neo-GATE-dev.tsv).‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/FBK-MT/Neo-GATE."},
	{"name":"MAiDE-up","keyword":"misinformation","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/MichiganNLP/MAiDE-up","creator_name":"LIT @ UMich","creator_url":"https://huggingface.co/MichiganNLP","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for MAiDE-up: Multilingual Deception Detection of GPT-generated Hotel Reviews\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nMultilingual Deception Detection of GPT-generated Hotel Reviews. We compare real hotel reviews from Booking with LLM-generated hotel reviews in 10 languages.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages\\n\\t\\n\\nThe text in the dataset is in 10 languages: Chinese, English, French, German, Italian, Romanian, Korean, Russian, Spanish, Turkish\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSupported Tasks and Leaderboards‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/MichiganNLP/MAiDE-up."},
	{"name":"RealToxicityPrompts","keyword":"toxicity","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ToxicityPrompts/RealToxicityPrompts","creator_name":"ToxicityPrompts","creator_url":"https://huggingface.co/ToxicityPrompts","description":"\\n\\t\\n\\t\\t\\n\\t\\tDataset Card for Real Toxicity Prompts\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nRealToxicityPrompts is a dataset of 100k sentence snippets from the web for researchers to further address the risk of neural toxic degeneration in models.\\n\\n\\t\\n\\t\\t\\n\\t\\tLanguages\\n\\t\\n\\nEnglish\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Structure\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tData Instances\\n\\t\\n\\nEach instance represents a prompt and its metadata:\\n{\\n  \\\"filename\\\":\\\"0766186-bc7f2a64cb271f5f56cf6f25570cd9ed.txt\\\",\\n  \\\"begin\\\":340,\\n  \\\"end\\\":564,\\n  \\\"challenging\\\":false‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ToxicityPrompts/RealToxicityPrompts."},
	{"name":"latam-xix","keyword":"hate-speech-detection","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Flaglab/latam-xix","creator_name":"Computer science research lab  @DISCUniandes.","creator_url":"https://huggingface.co/Flaglab","description":"Flaglab/latam-xix dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"spanish-corpus-xix","keyword":"hate-speech-detection","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Flaglab/spanish-corpus-xix","creator_name":"Computer science research lab  @DISCUniandes.","creator_url":"https://huggingface.co/Flaglab","description":"Flaglab/spanish-corpus-xix dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"generative-ai-red-teaming","keyword":"red-teaming","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/jinnovation/generative-ai-red-teaming","creator_name":"Jonathan Jin","creator_url":"https://huggingface.co/jinnovation","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tAbout this dataset\\n\\t\\n\\nThis dataset is an unofficial transformed clone of the Generative AI Red-Teaming\\n(GRT) dataset created by Humane\\nIntelligence (HI). This dataset collates\\nfindings from the Generative AI Red-Teaming Challenge conducted at AI Village\\nwithin DEFCON 31. It is provided as part of HI's inaugural algorithmic bias\\nbounty.\\nThe original lives on\\nGitHub at:\\nhumane-intelligence/bias-bounty-data\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDifferences\\n\\t\\n\\nThis version of the GRT dataset differs from the‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/jinnovation/generative-ai-red-teaming."},
	{"name":"BAAI_bge-large-en-v1_5-5242024-5uvy-webapp","keyword":"safety","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/fine-tuned/BAAI_bge-large-en-v1_5-5242024-5uvy-webapp","creator_name":"Fine-tuned Embeddings","creator_url":"https://huggingface.co/fine-tuned","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tBAAI_bge-large-en-v1_5-5242024-5uvy-webapp Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThe dataset \\\"informational search on vaccine safety\\\" is a generated dataset designed to support the development of domain specific embedding models for retrieval tasks.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tAssociated Model\\n\\t\\n\\nThis dataset was used to train the BAAI_bge-large-en-v1_5-5242024-5uvy-webapp model.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tHow to Use\\n\\t\\n\\nTo use this dataset for model training or evaluation, you can load it using the‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/fine-tuned/BAAI_bge-large-en-v1_5-5242024-5uvy-webapp."},
	{"name":"ProgressGym-HistText","keyword":"safety","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/PKU-Alignment/ProgressGym-HistText","creator_name":"PKU-Alignment","creator_url":"https://huggingface.co/PKU-Alignment","description":"*Huggingface dataset preview for 19th, 20th, and 21st centuries is not available due to lack of support for array types. Instead, consider downloading those files for manual inspection, or see the Data Samples section below for more examples.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tProgressGym-HistText\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tOverview\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tThe ProgressGym Framework\\n\\t\\n\\n\\nProgressGym-HistText is part of the ProgressGym framework for research and experimentation on progress alignment - the emulation of moral progress in AI‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/PKU-Alignment/ProgressGym-HistText."},
	{"name":"ProgressGym-TimelessQA","keyword":"safety","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/PKU-Alignment/ProgressGym-TimelessQA","creator_name":"PKU-Alignment","creator_url":"https://huggingface.co/PKU-Alignment","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tProgressGym-TimelessQA\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tOverview\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tThe ProgressGym Framework\\n\\t\\n\\n\\nProgressGym-TimelessQA is part of the ProgressGym framework for research and experimentation on progress alignment - the emulation of moral progress in AI alignment algorithms, as a measure to prevent risks of societal value lock-in. \\nTo quote the paper ProgressGym: Alignment with a Millennium of Moral Progress:\\n\\nFrontier AI systems, including large language models (LLMs), hold increasing‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/PKU-Alignment/ProgressGym-TimelessQA."},
	{"name":"ProgressGym-MoralEvals","keyword":"safety","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/PKU-Alignment/ProgressGym-MoralEvals","creator_name":"PKU-Alignment","creator_url":"https://huggingface.co/PKU-Alignment","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tProgressGym-MoralEvals\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tOverview\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tThe ProgressGym Framework\\n\\t\\n\\n\\nProgressGym-MoralEvals is part of the ProgressGym framework for research and experimentation on progress alignment - the emulation of moral progress in AI alignment algorithms, as a measure to prevent risks of societal value lock-in. \\nTo quote the paper ProgressGym: Alignment with a Millennium of Moral Progress:\\n\\nFrontier AI systems, including large language models (LLMs), hold increasing‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/PKU-Alignment/ProgressGym-MoralEvals."},
	{"name":"SaladBench","keyword":"safety","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/walledai/SaladBench","creator_name":"Walled AI","creator_url":"https://huggingface.co/walledai","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for SaladBench\\n\\t\\n\\nPaper: SALAD-Bench: A Hierarchical and Comprehensive Safety Benchmark for Large Language Models\\nData: SafeText Dataset\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tüìä Statistical Overview of Base Question\\n\\t\\n\\n\\n\\t\\n\\t\\t\\nType\\nData Source\\nNums\\n\\n\\n\\t\\t\\nSelf-instructed\\nFinetuned GPT-3.5\\n15,433\\n\\n\\nOpen-Sourced\\nHH-harmless\\n4,184\\n\\n\\n\\nHH-red-team\\n659\\n\\n\\n\\nAdvbench\\n359\\n\\n\\n\\nMultilingual\\n230\\n\\n\\n\\nDo-Not-Answer\\n189\\n\\n\\n\\nToxicChat\\n129\\n\\n\\n\\nDo Anything Now\\n93\\n\\n\\n\\nGPTFuzzer\\n42\\n\\n\\nTotal\\n\\n21,318\\n\\n\\n\\t\\n\\nYou can refer to the‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/walledai/SaladBench."},
	{"name":"KoSBi-v2","keyword":"safety","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/nayohan/KoSBi-v2","creator_name":"Yohan Na","creator_url":"https://huggingface.co/nayohan","description":"reference: https://github.com/naver-ai/korean-safety-benchmarks\\n@inproceedings{lee2023kosbi,\\n                title={KoSBi: A Dataset for Mitigating Social Bias Risks Towards Safer Large Language Model Application}, \\n                author={Hwaran Lee and Seokhee Hong and Joonsuk Park and Takyoung Kim and Gunhee Kim and Jung-Woo Ha},\\n                booktitle={Proceedings of the 61th Annual Meeting of the Association for Computational Linguistics: Industry Track},\\n                year={2023}\\n}\\n\\n"},
	{"name":"KoSBi","keyword":"safety","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/nayohan/KoSBi","creator_name":"Yohan Na","creator_url":"https://huggingface.co/nayohan","description":"reference: https://github.com/naver-ai/korean-safety-benchmarks\\n@inproceedings{lee2023kosbi,\\n                title={KoSBi: A Dataset for Mitigating Social Bias Risks Towards Safer Large Language Model Application}, \\n                author={Hwaran Lee and Seokhee Hong and Joonsuk Park and Takyoung Kim and Gunhee Kim and Jung-Woo Ha},\\n                booktitle={Proceedings of the 61th Annual Meeting of the Association for Computational Linguistics: Industry Track},\\n                year={2023}\\n}\\n\\n"},
	{"name":"SQuARe-question","keyword":"safety","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/nayohan/SQuARe-question","creator_name":"Yohan Na","creator_url":"https://huggingface.co/nayohan","description":"reference: https://github.com/naver-ai/korean-safety-benchmarks\\n@inproceedings{lee2023square,\\n                title={SQuARe: A Large-Scale Dataset of Sensitive Questions and Acceptable Responses Created Through Human-Machine Collaboration}, \\n                author={Hwaran Lee and Seokhee Hong and Joonsuk Park and Takyoung Kim and Meeyoung Cha and Yejin Choi and Byoung Pil Kim and Gunhee Kim and Eun-Ju Lee and Yong Lim and Alice Oh and Sangchul Park and Jung-Woo Ha}‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/nayohan/SQuARe-question."},
	{"name":"SQuARe-response","keyword":"safety","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/nayohan/SQuARe-response","creator_name":"Yohan Na","creator_url":"https://huggingface.co/nayohan","description":"reference: https://github.com/naver-ai/korean-safety-benchmarks\\n@inproceedings{lee2023square,\\n                title={SQuARe: A Large-Scale Dataset of Sensitive Questions and Acceptable Responses Created Through Human-Machine Collaboration}, \\n                author={Hwaran Lee and Seokhee Hong and Joonsuk Park and Takyoung Kim and Meeyoung Cha and Yejin Choi and Byoung Pil Kim and Gunhee Kim and Eun-Ju Lee and Yong Lim and Alice Oh and Sangchul Park and Jung-Woo Ha}‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/nayohan/SQuARe-response."},
	{"name":"korean-hate-speech","keyword":"safety","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/nayohan/korean-hate-speech","creator_name":"Yohan Na","creator_url":"https://huggingface.co/nayohan","description":"reference: https://github.com/kocohub/korean-hate-speech\\n@inproceedings{moon-etal-2020-beep,\\n    title = \\\"{BEEP}! {K}orean Corpus of Online News Comments for Toxic Speech Detection\\\",\\n    author = \\\"Moon, Jihyung  and\\n      Cho, Won Ik  and\\n      Lee, Junbum\\\",\\n    booktitle = \\\"Proceedings of the Eighth International Workshop on Natural Language Processing for Social Media\\\",\\n    month = jul,\\n    year = \\\"2020\\\",\\n    address = \\\"Online\\\",\\n    publisher = \\\"Association for Computational Linguistics\\\"‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/nayohan/korean-hate-speech."},
	{"name":"APEACH","keyword":"safety","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/nayohan/APEACH","creator_name":"Yohan Na","creator_url":"https://huggingface.co/nayohan","description":"reference: https://github.com/jason9693/APEACH\\n@inproceedings{yang-etal-2022-apeach,\\n    title = \\\"{APEACH}: Attacking Pejorative Expressions with Analysis on Crowd-Generated Hate Speech Evaluation Datasets\\\",\\n    author = \\\"Yang, Kichang  and\\n      Jang, Wonjun  and\\n      Cho, Won Ik\\\",\\n    booktitle = \\\"Findings of the Association for Computational Linguistics: EMNLP 2022\\\",\\n    month = dec,\\n    year = \\\"2022\\\",\\n    address = \\\"Abu Dhabi, United Arab Emirates\\\",\\n    publisher = \\\"Association for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/nayohan/APEACH."},
	{"name":"RETURN","keyword":"safety","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/zhliu/RETURN","creator_name":"Zhenhua Liu","creator_url":"https://huggingface.co/zhliu","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tRETURN: Real-world pErsonal daTa UnleaRNing dataset\\n\\t\\n\\n\\nRepository: https://github.com/zhliu0106/learning-to-refuse\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tCitation\\n\\t\\n\\n@misc{liu2024learningrefusemitigatingprivacy,\\n      title={Learning to Refuse: Towards Mitigating Privacy Risks in LLMs}, \\n      author={Zhenhua Liu and Tong Zhu and Chuanyuan Tan and Wenliang Chen},\\n      year={2024},\\n      eprint={2407.10058},\\n      archivePrefix={arXiv},\\n      primaryClass={cs.CL}‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/zhliu/RETURN."},
	{"name":"hcm-examples-aug-2024","keyword":"hallucination","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/vectara/hcm-examples-aug-2024","creator_name":"Vectara","creator_url":"https://huggingface.co/vectara","description":"Dataset of some examples with hallucinations before and after passing through Vectara's Hallucination Correction Model. See our blogpost for details.\\n"},
	{"name":"LongSafetyBench","keyword":"safety","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/LutherXD/LongSafetyBench","creator_name":"mqhuang","creator_url":"https://huggingface.co/LutherXD","description":"LutherXD/LongSafetyBench dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"llm_physical_safety_benchmark","keyword":"safety","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/kumitang/llm_physical_safety_benchmark","creator_name":"Yung-Chen Tang","creator_url":"https://huggingface.co/kumitang","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLLM Physical Safety Benchmark in Drone Control\\n\\t\\n\\nThis benchmark consists of four datasets designed to evaluate the performance of Large Language Models (LLMs) in controlling drones and their vulnerability to physical attacks. The datasets are categorized into different types of attacks:\\n\\nDeliberate Attack: Contains 280 samples that evaluate the LLM's resistance to malicious use, testing its ability to recognize and reject commands intended to cause harm. Subcategories include‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/kumitang/llm_physical_safety_benchmark."},
	{"name":"llm_physical_safety_benchmark","keyword":"safety","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/TrustSafeAI/llm_physical_safety_benchmark","creator_name":"TrustSafeAI","creator_url":"https://huggingface.co/TrustSafeAI","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLLM Physical Safety Benchmark in Drone Control\\n\\t\\n\\nThis benchmark consists of four datasets designed to evaluate the performance of Large Language Models (LLMs) in controlling drones and their vulnerability to physical attacks. The datasets are categorized into different types of attacks:\\n\\nDeliberate Attack: Contains 280 samples that evaluate the LLM's resistance to malicious use, testing its ability to recognize and reject commands intended to cause harm. Subcategories include‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/TrustSafeAI/llm_physical_safety_benchmark."},
	{"name":"MCEval8K","keyword":"hate-speech-detection","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/iszhaoxin/MCEval8K","creator_name":"XIN ZHAO","creator_url":"https://huggingface.co/iszhaoxin","description":"iszhaoxin/MCEval8K dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"toxicity-protests-ES","keyword":"toxicity","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/bgonzalezbustamante/toxicity-protests-ES","creator_name":"Basti√°n Gonz√°lez-Bustamante","creator_url":"https://huggingface.co/bgonzalezbustamante","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tOverview\\n\\t\\n\\nDescription and codebook in progress.\\n\\nGitHub repository.\\nDataset on Zenodo.\\nReference paper\\n\\n"},
	{"name":"toxicity-Constitution-ES","keyword":"toxicity","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/bgonzalezbustamante/toxicity-Constitution-ES","creator_name":"Basti√°n Gonz√°lez-Bustamante","creator_url":"https://huggingface.co/bgonzalezbustamante","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tOverview\\n\\t\\n\\nDescription and codebook in progress.\\n\\nGitHub repository.\\nDataset on Zenodo.\\nReference paper\\n\\n"},
	{"name":"MIS_Test","keyword":"safety","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Tuwhy/MIS_Test","creator_name":"Yi Ding","creator_url":"https://huggingface.co/Tuwhy","description":"\\n\\t\\n\\t\\t\\n\\t\\tRethinking Bottlenecks in Safety Fine-Tuning of Vision Language Models\\n\\t\\n\\n\\nOur paper, code, data, models can be found at MIS.\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Structure\\n\\t\\n\\nOur MIS test set contains three split \\\"MIS-easy\\\", \\\"MIS-hard\\\", \\\"MIS-real\\\".\\n{\\n  \\\"question\\\": \\\"str\\\",\\n  \\\"category\\\": \\\"str\\\",\\n  \\\"sub_category\\\": \\\"str\\\",\\n  \\\"image_path1\\\": \\\"str\\\",\\n  \\\"image_path2\\\": \\\"str\\\",\\n  \\\"id\\\": int\\n}\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tStatistics\\n\\t\\n\\nOur 'MIS-easy' and 'MIS-hard' datasets together contain 2,185 samples across 6 categories and 12‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Tuwhy/MIS_Test."},
	{"name":"FactNews","keyword":"misinformation","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/franciellevargas/FactNews","creator_name":"Francielle Vargas","creator_url":"https://huggingface.co/franciellevargas","description":"\\n\\t\\n\\t\\t\\n\\t\\tEvaluation Benchmark for Sentence-Level Factuality Prediciton in Portuguese\\n\\t\\n\\nThe FactNews consits of the first large sentence-level annotated corpus for factuality prediciton in Portuguese. \\nIt is composed of 6,191 sentences annotated according to factuality and media bias definitions proposed by AllSides. We use FactNews to assess the overall reliability of news sources by formulating \\ntwo text classification problems for predicting sentence-level factuality of news reporting and‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/franciellevargas/FactNews."},
	{"name":"data-advisor-safety-alignment","keyword":"safety","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/fwnlp/data-advisor-safety-alignment","creator_name":"Fei Wang","creator_url":"https://huggingface.co/fwnlp","description":"[EMNLP 2024] Data Advisor: Dynamic Data Curation for Safety Alignment of Large Language Models\\nüåê Homepage | üìñ Paper  | ü§ó Dataset (Data Advisor) | ü§ó Dataset (Self-Instruct)\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDisclaimer\\n\\t\\n\\nThe dataset contains content that may be offensive or harmful. This dataset is intended for research purposes, specifically to support efforts aimed at creating safer and less harmful AI systems. Please engage with it responsibly and at your own risk.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tCitation‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/fwnlp/data-advisor-safety-alignment."},
	{"name":"CADE","keyword":"hate-speech","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/aequa-tech/CADE","creator_name":"aequa-tech","creator_url":"https://huggingface.co/aequa-tech","description":"\\n\\t\\n\\t\\t\\n\\t\\tThe Canceling Attitudes Detection (CADE) Dataset\\n\\t\\n\\nCADE is a dataset created in the context of the research That is Unacceptable: the Moral Foundations of Canceling. Here you can find the abstract.\\nCanceling is a morally-driven phenomenon that hinders the development of safe social media platforms and contributes to ideological polarization. To address this issue we present the Canceling Attitudes Detection (CADE) dataset, an annotated corpus of canceling incidents aimed at exploring‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/aequa-tech/CADE."},
	{"name":"vlsbench","keyword":"safety","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Foreshhh/vlsbench","creator_name":"XuHao Hu","creator_url":"https://huggingface.co/Foreshhh","description":"‚úÖ Update data.json with safety reason and image description for more efficient and reliable evaluaiton.\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Card for VLSBench\\n\\t\\n\\nThis dataset is for paper VLSBench: Unveiling Information Leakage In Multimodal Safety\\nYou can check our Paper, Github, Project Page for more information.\\ndataset = load_dataset(\\\"Foreshhh/vlsbench\\\", split='train') \\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Details\\n\\t\\n\\nOur dataset statistics is listed in the following:\\n\\n\\n\\nHere are examples in our dataset:\\n\\n\\n\\t\\t\\n\\t\\tEthics‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Foreshhh/vlsbench."},
	{"name":"Misinfo_Datasets","keyword":"misinformation","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ComplexDataLab/Misinfo_Datasets","creator_name":"Complex Data Lab","creator_url":"https://huggingface.co/ComplexDataLab","description":"\\n\\t\\n\\t\\t\\n\\t\\tCDL Misinfo Detection Datasets\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDatasets Summary\\n\\t\\n\\nMisinformation is a challenging societal issue, and mitigating solutions are difficult to create due to data deficiencies. To address this problem, we have curated the largest collection of (mis)information datasets in the literature, totaling 75. From these, we evaluated the quality of all of the 36 datasets that consist of statements or claims. If you would like to contribute a novel dataset or report any issues, please‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ComplexDataLab/Misinfo_Datasets."},
	{"name":"raghalu-open","keyword":"hallucination","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/liveperson/raghalu-open","creator_name":"LivePerson Inc.","creator_url":"https://huggingface.co/liveperson","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for RAGHalu Open Source Data\\n\\t\\n\\nThis dataset is the public data portion from the paper Two-tiered\\nEncoder-based Hallucination Detection for Retrieval-Augmented Generation\\nin the Wild by Ilana Zimmerman, Jadin Tredup, Ethan Selfridge, and\\nJoseph Bradley, accepted at EMNLP 2024\\n(Industry Track). The private brand data portion of the dataset is not\\nincluded.\\nNote that this dataset and the paper do not use the common hallucination\\nterms factuality and faithfulness as‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/liveperson/raghalu-open."},
	{"name":"Aegis-AI-Content-Safety-Dataset-2.0","keyword":"safety","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/nvidia/Aegis-AI-Content-Safety-Dataset-2.0","creator_name":"NVIDIA","creator_url":"https://huggingface.co/nvidia","description":"\\n\\t\\n\\t\\t\\n\\t\\tüõ°Ô∏è Aegis AI Content Safety Dataset 2.0\\n\\t\\n\\n\\n\\nThe Aegis AI Content Safety Dataset 2.0 is comprised of 33,416 annotated interactions between humans and LLMs, split into 30,007 training samples, 1,445 validation samples,  and 1,964 test samples. This release is an extension of the previously published Aegis 1.0 Content Safety Dataset. \\nTo curate the dataset, we use the HuggingFace version of human preference data about harmlessness from Anthropic HH-RLHF. We extract only the prompts, and‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/nvidia/Aegis-AI-Content-Safety-Dataset-2.0."},
	{"name":"Deepfakes-QA-Patch1","keyword":"deepfake","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/prithivMLmods/Deepfakes-QA-Patch1","creator_name":"Prithiv Sakthi","creator_url":"https://huggingface.co/prithivMLmods","description":"\\n\\t\\n\\t\\t\\n\\t\\tDeepfake Quality Assessment\\n\\t\\n\\nDeepfake QA is a Deepfake Quality Assessment model designed to analyze the quality of deepfake images & videos. It evaluates whether a deepfake is of good or bad quality, where:  \\n\\n0 represents a bad-quality deepfake  \\n1 represents a good-quality deepfake\\n\\nThis classification serves as the foundation for training models on deepfake quality assessment, helping improve deepfake detection and enhancement techniques.  \\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tCitation\\n\\t\\n\\nIf you use our‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/prithivMLmods/Deepfakes-QA-Patch1."},
	{"name":"Deepfakes-QA-Patch2","keyword":"deepfake","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/prithivMLmods/Deepfakes-QA-Patch2","creator_name":"Prithiv Sakthi","creator_url":"https://huggingface.co/prithivMLmods","description":"\\n\\t\\n\\t\\t\\n\\t\\tDeepfake Quality Assessment\\n\\t\\n\\nDeepfake QA is a Deepfake Quality Assessment model designed to analyze the quality of deepfake images & videos. It evaluates whether a deepfake is of good or bad quality, where:  \\n\\n0 represents a bad-quality deepfake  \\n1 represents a good-quality deepfake\\n\\nThis classification serves as the foundation for training models on deepfake quality assessment, helping improve deepfake detection and enhancement techniques.  \\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tCitation‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/prithivMLmods/Deepfakes-QA-Patch2."},
	{"name":"Deepfakes-QA-Leaning","keyword":"deepfake","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/prithivMLmods/Deepfakes-QA-Leaning","creator_name":"Prithiv Sakthi","creator_url":"https://huggingface.co/prithivMLmods","description":"\\n\\t\\n\\t\\t\\n\\t\\tDeepfake Quality Assessment\\n\\t\\n\\nDeepfake QA is a Deepfake Quality Assessment model designed to analyze the quality of deepfake images & videos. It evaluates whether a deepfake is of good or bad quality, where:  \\n\\n0 represents a bad-quality deepfake  \\n1 represents a good-quality deepfake\\n\\nThis classification serves as the foundation for training models on deepfake quality assessment, helping improve deepfake detection and enhancement techniques.  \\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tCitation‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/prithivMLmods/Deepfakes-QA-Leaning."},
	{"name":"hatecheck-portuguese","keyword":"hate-speech-detection","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Paul/hatecheck-portuguese","creator_name":"Paul R√∂ttger","creator_url":"https://huggingface.co/Paul","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Multilingual HateCheck\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nMultilingual HateCheck (MHC) is a suite of functional tests for hate speech detection models in 10 different languages: Arabic, Dutch, French, German, Hindi, Italian, Mandarin, Polish, Portuguese and Spanish.\\nFor each language, there are 25+ functional tests that correspond to distinct types of hate and challenging non-hate.\\nThis allows for targeted diagnostic insights into model performance.\\nFor more‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Paul/hatecheck-portuguese."},
	{"name":"wiki_toxic","keyword":"hate-speech-detection","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/OxAISH-AL-LLM/wiki_toxic","creator_name":"OxAI Safety Hub Active Learning with Large Language Models Labs Team","creator_url":"https://huggingface.co/OxAISH-AL-LLM","description":"Jigsaw Toxic Comment Challenge dataset. This dataset was the basis of a Kaggle competition run by Jigsaw"},
	{"name":"kmhas_korean_hate_speech","keyword":"hate-speech-detection","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/jeanlee/kmhas_korean_hate_speech","creator_name":"Jean Lee","creator_url":"https://huggingface.co/jeanlee","description":"The K-MHaS (Korean Multi-label Hate Speech) dataset contains 109k utterances from Korean online news comments labeled with 8 fine-grained hate speech classes or Not Hate Speech class.\\nThe fine-grained hate speech classes are politics, origin, physical, age, gender, religion, race, and profanity and these categories are selected in order to reflect the social and historical context."},
	{"name":"wiki_toxic","keyword":"toxicity","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/OxAISH-AL-LLM/wiki_toxic","creator_name":"OxAI Safety Hub Active Learning with Large Language Models Labs Team","creator_url":"https://huggingface.co/OxAISH-AL-LLM","description":"Jigsaw Toxic Comment Challenge dataset. This dataset was the basis of a Kaggle competition run by Jigsaw"},
	{"name":"do-not-answer","keyword":"safety","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/LibrAI/do-not-answer","creator_name":"LibrAI","creator_url":"https://huggingface.co/LibrAI","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDo-Not-Answer: A Dataset for Evaluating Safeguards in LLMs\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tOverview\\n\\t\\n\\nDo not answer is an open-source dataset to evaluate LLMs' safety mechanism at a low cost. The dataset is curated and filtered to consist only of prompts to which responsible language models do not answer. \\nBesides human annotations, Do not answer also implements model-based evaluation, where a 600M fine-tuned BERT-like evaluator achieves comparable results with human and GPT-4.‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/LibrAI/do-not-answer."},
	{"name":"AttaQ","keyword":"safety","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/ibm-research/AttaQ","creator_name":"IBM Research","creator_url":"https://huggingface.co/ibm-research","description":"\\n\\t\\n\\t\\t\\n\\t\\tAttaQ Dataset Card\\n\\t\\n\\nThe AttaQ red teaming dataset, consisting of 1402 carefully crafted adversarial questions, is designed to evaluate Large Language Models (LLMs) by assessing their tendency to generate harmful or undesirable responses. \\nIt may serve as a benchmark to assess the potential harm of responses produced by LLMs. \\nThe dataset is categorized into seven distinct classes of questions: deception, discrimination, harmful information, substance abuse, sexual content, personally‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ibm-research/AttaQ."},
	{"name":"rag-hallucination-dataset-1000","keyword":"hallucination","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/neural-bridge/rag-hallucination-dataset-1000","creator_name":"Neural Bridge AI","creator_url":"https://huggingface.co/neural-bridge","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tRetrieval-Augmented Generation (RAG) Hallucination Dataset 1000\\n\\t\\n\\nRetrieval-Augmented Generation (RAG) Hallucination Dataset 1000 is an English dataset designed to reduce the hallucination in RAG-optimized models, built by Neural Bridge AI, and released under Apache license 2.0.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nHallucination in large language models (LLMs) refers to the generation of incorrect, nonsensical, or unrelated text that does not stem from‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/neural-bridge/rag-hallucination-dataset-1000."},
	{"name":"AttaQ","keyword":"toxicity","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/ibm-research/AttaQ","creator_name":"IBM Research","creator_url":"https://huggingface.co/ibm-research","description":"\\n\\t\\n\\t\\t\\n\\t\\tAttaQ Dataset Card\\n\\t\\n\\nThe AttaQ red teaming dataset, consisting of 1402 carefully crafted adversarial questions, is designed to evaluate Large Language Models (LLMs) by assessing their tendency to generate harmful or undesirable responses. \\nIt may serve as a benchmark to assess the potential harm of responses produced by LLMs. \\nThe dataset is categorized into seven distinct classes of questions: deception, discrimination, harmful information, substance abuse, sexual content, personally‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ibm-research/AttaQ."},
	{"name":"configurable-system-prompt-multitask","keyword":"safety","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/vicgalle/configurable-system-prompt-multitask","creator_name":"Victor Gallego","creator_url":"https://huggingface.co/vicgalle","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tConfigurable System Prompt Multi-task Dataset üõû\\n\\t\\n\\nWe release the synthetic dataset for the multi-task experiments from the paper \\\"Configurable Safety Tuning of Language Models with Synthetic Preference Data\\\", https://huggingface.co/papers/2404.00495. This dataset has two sources for the examples:\\n\\nSelf-critique on a safety task from Harmful Behaviours, using the SOLAR-Instruct model. It employs two system prompts to learn the different behaviors:\\nYou are a helpful yet harmless‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/vicgalle/configurable-system-prompt-multitask."},
	{"name":"Aegis-AI-Content-Safety-Dataset-1.0","keyword":"safety","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/nvidia/Aegis-AI-Content-Safety-Dataset-1.0","creator_name":"NVIDIA","creator_url":"https://huggingface.co/nvidia","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tüõ°Ô∏è Aegis AI Content Safety Dataset 1.0\\n\\t\\n\\nAegis AI Content Safety Dataset is an open-source content safety dataset (CC-BY-4.0), which adheres to Nvidia's content safety taxonomy, covering 13 critical risk categories (see Dataset Description).\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Details\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThe Aegis AI Content Safety Dataset is comprised of approximately 11,000 manually annotated interactions between humans and LLMs, split into 10,798 training samples and 1,199‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/nvidia/Aegis-AI-Content-Safety-Dataset-1.0."},
	{"name":"air-bench-2024","keyword":"safety","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/stanford-crfm/air-bench-2024","creator_name":"Stanford CRFM","creator_url":"https://huggingface.co/stanford-crfm","description":"\\n\\t\\n\\t\\t\\n\\t\\tAIRBench 2024\\n\\t\\n\\nAIRBench 2024 is a AI safety benchmark that aligns with emerging government\\nregulations and company policies. It consists of diverse, malicious prompts\\nspanning categories of the regulation-based safety categories in the\\nAIR 2024 safety taxonomy.\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Details\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\nAIRBench 2024 is a AI safety benchmark that aligns with emerging government\\nregulations and company policies. It consists of diverse, malicious prompts\\nspanning‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/stanford-crfm/air-bench-2024."},
	{"name":"twinviews-13k","keyword":"fairness","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/wwbrannon/twinviews-13k","creator_name":"William Brannon","creator_url":"https://huggingface.co/wwbrannon","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for TwinViews-13k\\n\\t\\n\\nThis dataset contains 13,855 pairs of left-leaning and right-leaning political statements matched by topic. The dataset was generated using GPT-3.5 Turbo and has been audited to ensure quality and ideological balance. It is designed to facilitate the study of political bias in reward models and language models, with a focus on the relationship between truthfulness and political views.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Details\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/wwbrannon/twinviews-13k."},
	{"name":"VISCO","keyword":"hallucination","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/uclanlp/VISCO","creator_name":"UCLA NLP","creator_url":"https://huggingface.co/uclanlp","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVISCO\\n\\t\\n\\nBenchmarking Fine-Grained Critique and Correction Towards Self-Improvement in Visual Reasoning\\nüåê Project | üìñ Paper | üíª Github\\n\\n\\nOutline:\\n\\nIntroduction\\nData\\nCitation\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tIntroduction\\n\\t\\n\\nVISCO is a benchmark for evaluating the critique and correction capabilities of LVLMs. VISCO contains:\\n\\n1645 pairs of questions and LVLM-generated answers. Each answer includes a chain-of-thought with multiple reasonign steps.\\n5604 step-wise annotations of critique, showing‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/uclanlp/VISCO."},
	{"name":"Deepfakes-QA-15K","keyword":"deepfake","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/prithivMLmods/Deepfakes-QA-15K","creator_name":"Prithiv Sakthi","creator_url":"https://huggingface.co/prithivMLmods","description":"\\n\\t\\n\\t\\t\\n\\t\\tDeepfake Quality Assessment\\n\\t\\n\\nDeepfake QA is a Deepfake Quality Assessment model designed to analyze the quality of deepfake images & videos. It evaluates whether a deepfake is of good or bad quality, where:  \\n\\n0 represents a bad-quality deepfake  \\n1 represents a good-quality deepfake\\n\\nThis classification serves as the foundation for training models on deepfake quality assessment, helping improve deepfake detection and enhancement techniques.  \\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tCitation\\n\\t\\n\\nIf you use our‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/prithivMLmods/Deepfakes-QA-15K."},
	{"name":"Deepfakes-QA-Patch1","keyword":"deepfake","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/strangerguardhf/Deepfakes-QA-Patch1","creator_name":"Stranger Guard","creator_url":"https://huggingface.co/strangerguardhf","description":"\\n\\t\\n\\t\\t\\n\\t\\tDeepfake Quality Assessment\\n\\t\\n\\nDeepfake QA is a Deepfake Quality Assessment model designed to analyze the quality of deepfake images & videos. It evaluates whether a deepfake is of good or bad quality, where:  \\n\\n0 represents a bad-quality deepfake  \\n1 represents a good-quality deepfake\\n\\nThis classification serves as the foundation for training models on deepfake quality assessment, helping improve deepfake detection and enhancement techniques.  \\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tCitation‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/strangerguardhf/Deepfakes-QA-Patch1."},
	{"name":"Deepfakes-QA-Patch2","keyword":"deepfake","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/strangerguardhf/Deepfakes-QA-Patch2","creator_name":"Stranger Guard","creator_url":"https://huggingface.co/strangerguardhf","description":"\\n\\t\\n\\t\\t\\n\\t\\tDeepfake Quality Assessment\\n\\t\\n\\nDeepfake QA is a Deepfake Quality Assessment model designed to analyze the quality of deepfake images & videos. It evaluates whether a deepfake is of good or bad quality, where:  \\n\\n0 represents a bad-quality deepfake  \\n1 represents a good-quality deepfake\\n\\nThis classification serves as the foundation for training models on deepfake quality assessment, helping improve deepfake detection and enhancement techniques.  \\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tCitation‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/strangerguardhf/Deepfakes-QA-Patch2."},
	{"name":"Deepfakes-QA-15K","keyword":"deepfake","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/strangerguardhf/Deepfakes-QA-15K","creator_name":"Stranger Guard","creator_url":"https://huggingface.co/strangerguardhf","description":"\\n\\t\\n\\t\\t\\n\\t\\tDeepfake Quality Assessment\\n\\t\\n\\nDeepfake QA is a Deepfake Quality Assessment model designed to analyze the quality of deepfake images & videos. It evaluates whether a deepfake is of good or bad quality, where:  \\n\\n0 represents a bad-quality deepfake  \\n1 represents a good-quality deepfake\\n\\nThis classification serves as the foundation for training models on deepfake quality assessment, helping improve deepfake detection and enhancement techniques.  \\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tCitation‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/strangerguardhf/Deepfakes-QA-15K."},
	{"name":"Deepfakes-QA-Leaning","keyword":"deepfake","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/strangerguardhf/Deepfakes-QA-Leaning","creator_name":"Stranger Guard","creator_url":"https://huggingface.co/strangerguardhf","description":"\\n\\t\\n\\t\\t\\n\\t\\tDeepfake Quality Assessment\\n\\t\\n\\nDeepfake QA is a Deepfake Quality Assessment model designed to analyze the quality of deepfake images & videos. It evaluates whether a deepfake is of good or bad quality, where:  \\n\\n0 represents a bad-quality deepfake  \\n1 represents a good-quality deepfake\\n\\nThis classification serves as the foundation for training models on deepfake quality assessment, helping improve deepfake detection and enhancement techniques.  \\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tCitation‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/strangerguardhf/Deepfakes-QA-Leaning."},
	{"name":"ethical-framework-UNESCO-Ethics-of-AI","keyword":"fairness","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ktiyab/ethical-framework-UNESCO-Ethics-of-AI","creator_name":"Tiyab K.","creator_url":"https://huggingface.co/ktiyab","description":"\\n\\t\\n\\t\\t\\n\\t\\tEthical AI Training Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tIntroduction\\n\\t\\n\\nUNESCO's Ethics of Artificial Intelligence, adopted by 193 Member States in November 2021, represents the first global framework for ethical AI development and deployment.\\nWhile regional initiatives like The Montr√©al Declaration for a Responsible Development of Artificial Intelligence emphasize community-driven governance, UNESCO's approach establishes comprehensive international standards through coordinated multi-stakeholder‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ktiyab/ethical-framework-UNESCO-Ethics-of-AI."},
	{"name":"AdvBench-IR","keyword":"safety","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/McGill-NLP/AdvBench-IR","creator_name":"McGill NLP Group","creator_url":"https://huggingface.co/McGill-NLP","description":"\\n  Exploiting Instruction-Following Retrievers for Malicious Information Retrieval\\n\\n\\n\\n\\n\\n\\nThis dataset includes malicious documents in response to AdvBench (Zou et al., 2023) queries. We have generated these documents using the Mistral-7B-Instruct-v0.2 language model.\\nfrom datasets import load_dataset\\nimport transformers\\n\\nds = load_dataset(\\\"McGill-NLP/AdvBench-IR\\\", split=\\\"train\\\")\\n\\n# Loads LlaMAGuard model to check the safety of the samples\\nmodel_name = \\\"meta-llama/Llama-Guard-3-1B\\\"\\nmodel =‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/McGill-NLP/AdvBench-IR."},
	{"name":"Deepfake-vs-Real","keyword":"deepfake","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/prithivMLmods/Deepfake-vs-Real","creator_name":"Prithiv Sakthi","creator_url":"https://huggingface.co/prithivMLmods","description":"\\n\\t\\n\\t\\t\\n\\t\\tDeepfake vs Real\\n\\t\\n\\nDeepfake vs Real is a dataset designed for image classification, distinguishing between deepfake and real images. This dataset includes a diverse collection of high-quality deepfake images to enhance classification accuracy and improve the model‚Äôs overall efficiency. By providing a well-balanced dataset, it aims to support the development of more robust deepfake detection models.  \\n\\n\\t\\n\\t\\t\\n\\t\\tLabel Mappings\\n\\t\\n\\n\\nMapping of IDs to Labels: {0: 'Deepfake', 1: 'Real'}‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/prithivMLmods/Deepfake-vs-Real."},
	{"name":"AI-vs-Deepfake-vs-Real","keyword":"deepfake","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/prithivMLmods/AI-vs-Deepfake-vs-Real","creator_name":"Prithiv Sakthi","creator_url":"https://huggingface.co/prithivMLmods","description":"\\n\\t\\n\\t\\t\\n\\t\\tAI vs Deepfake vs Real\\n\\t\\n\\nAI vs Deepfake vs Real is a dataset designed for image classification, distinguishing between artificial, deepfake, and real images. This dataset includes a diverse collection of high-quality images to enhance classification accuracy and improve the model‚Äôs overall efficiency. By providing a well-balanced dataset, it aims to support the development of more robust AI-generated and deepfake detection models.  \\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLabel Mappings\\n\\t\\n\\n\\nMapping of IDs to‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/prithivMLmods/AI-vs-Deepfake-vs-Real."},
	{"name":"Deepfake-QA-10K-OPT","keyword":"deepfake","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/prithivMLmods/Deepfake-QA-10K-OPT","creator_name":"Prithiv Sakthi","creator_url":"https://huggingface.co/prithivMLmods","description":"\\n\\t\\n\\t\\t\\n\\t\\tDeepfake Quality Assessment\\n\\t\\n\\nDeepfake QA is a Deepfake Quality Assessment model designed to analyze the quality of deepfake images & videos. It evaluates whether a deepfake is of good or bad quality, where:  \\n\\n0 represents a bad-quality deepfake  \\n1 represents a good-quality deepfake\\n\\nThis classification serves as the foundation for training models on deepfake quality assessment, helping improve deepfake detection and enhancement techniques.  \\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tCitation‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/prithivMLmods/Deepfake-QA-10K-OPT."},
	{"name":"MLAAD","keyword":"deepfake","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mueller91/MLAAD","creator_name":"Nicolas M√ºller","creator_url":"https://huggingface.co/mueller91","description":"\\n  \\n\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tIntroduction\\n\\t\\n\\nWelcome to MLAAD: The Multi-Language Audio Anti-Spoofing Dataset -- a dataset to train, test and evaluate audio deepfake detection. See\\nthe paper for more information.\\n\\n\\t\\n\\t\\t\\n\\t\\tStructure\\n\\t\\n\\nThe dataset is based on the M-AILABS dataset.\\nMLAAD is structured as follows:\\nfake\\n|-language_1\\n|-language_2\\n|- ....\\n|- language_K\\n    | - model_1_K\\n    | - model_2_K\\n    | - ....\\n    | - model_L_K\\n        | - meta.csv\\n        | - audio_L_K_1.wav\\n        | - audio_L_K_2.wav‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mueller91/MLAAD."},
	{"name":"hatecheck","keyword":"hate-speech-detection","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Paul/hatecheck","creator_name":"Paul R√∂ttger","creator_url":"https://huggingface.co/Paul","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for HateCheck\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nHateCheck is a suite of functional test for hate speech detection models. \\nThe dataset contains 3,728 validated test cases in 29 functional tests.\\n19 functional tests correspond to distinct types of hate. The other 11 functional tests cover challenging types of non-hate.\\nThis allows for targeted diagnostic insights into model performance.\\nIn our ACL paper, we found critical weaknesses in all commercial and academic‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Paul/hatecheck."},
	{"name":"measuring-hate-speech","keyword":"hate-speech","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ucberkeley-dlab/measuring-hate-speech","creator_name":"Social Sciences Data Lab at UC Berkeley","creator_url":"https://huggingface.co/ucberkeley-dlab","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset card for Measuring Hate Speech\\n\\t\\n\\nThis is a public release of the dataset described in Kennedy et al. (2020) and Sachdeva et al. (2022), consisting of 39,565 comments annotated by 7,912 annotators, for 135,556 combined rows. The primary outcome variable is the \\\"hate speech score\\\" but the 10 constituent ordinal labels (sentiment, (dis)respect, insult, humiliation, inferior status, violence, dehumanization, genocide, attack/defense, hate speech benchmark) can also be treated‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ucberkeley-dlab/measuring-hate-speech."},
	{"name":"measuring-hate-speech","keyword":"hate-speech-detection","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ucberkeley-dlab/measuring-hate-speech","creator_name":"Social Sciences Data Lab at UC Berkeley","creator_url":"https://huggingface.co/ucberkeley-dlab","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset card for Measuring Hate Speech\\n\\t\\n\\nThis is a public release of the dataset described in Kennedy et al. (2020) and Sachdeva et al. (2022), consisting of 39,565 comments annotated by 7,912 annotators, for 135,556 combined rows. The primary outcome variable is the \\\"hate speech score\\\" but the 10 constituent ordinal labels (sentiment, (dis)respect, insult, humiliation, inferior status, violence, dehumanization, genocide, attack/defense, hate speech benchmark) can also be treated‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ucberkeley-dlab/measuring-hate-speech."},
	{"name":"honest","keyword":"hate-speech-detection","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/MilaNLProc/honest","creator_name":"MilaNLP","creator_url":"https://huggingface.co/MilaNLProc","description":"HONEST dataset comprises a set of templates for measuring hurtful sentence completions in language models. The templates are provided in six languages (English, Italian, French, Portuguese, Romanian, and Spanish) for binary gender and in English for LGBTQAI+ individuals. WARNING: This dataset contains content that are offensive and/or hateful in nature."},
	{"name":"Sinhala-English-Code-Mixed-Code-Switched-Dataset","keyword":"hate-speech-detection","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/NLPC-UOM/Sinhala-English-Code-Mixed-Code-Switched-Dataset","creator_name":"The National Languages Processing Centre","creator_url":"https://huggingface.co/NLPC-UOM","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSinhala-English-Code-Mixed-Code-Switched-Dataset\\n\\t\\n\\nThis dataset contains 10,000 comments that have been annotated at the sentence level for sentiment analysis, humor detection, hate speech detection, aspect identification, and language identification.\\nThe following is the tag scheme.\\n\\nSentiment -  Positive, Negative, Neutral,  Conflict\\nHumor - Humorous, Non humorous\\nHate Speech - Hate-Inducing, Abusive, Not offensive\\nAspect - Network, Billing or Price, Package, Customer Service‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/NLPC-UOM/Sinhala-English-Code-Mixed-Code-Switched-Dataset."},
	{"name":"hatecheck-spanish","keyword":"hate-speech-detection","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Paul/hatecheck-spanish","creator_name":"Paul R√∂ttger","creator_url":"https://huggingface.co/Paul","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Multilingual HateCheck\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nMultilingual HateCheck (MHC) is a suite of functional tests for hate speech detection models in 10 different languages: Arabic, Dutch, French, German, Hindi, Italian, Mandarin, Polish, Portuguese and Spanish.\\nFor each language, there are 25+ functional tests that correspond to distinct types of hate and challenging non-hate.\\nThis allows for targeted diagnostic insights into model performance.\\nFor more‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Paul/hatecheck-spanish."},
	{"name":"hatecheck-polish","keyword":"hate-speech-detection","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Paul/hatecheck-polish","creator_name":"Paul R√∂ttger","creator_url":"https://huggingface.co/Paul","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Multilingual HateCheck\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nMultilingual HateCheck (MHC) is a suite of functional tests for hate speech detection models in 10 different languages: Arabic, Dutch, French, German, Hindi, Italian, Mandarin, Polish, Portuguese and Spanish.\\nFor each language, there are 25+ functional tests that correspond to distinct types of hate and challenging non-hate.\\nThis allows for targeted diagnostic insights into model performance.\\nFor more‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Paul/hatecheck-polish."},
	{"name":"hatecheck-mandarin","keyword":"hate-speech-detection","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Paul/hatecheck-mandarin","creator_name":"Paul R√∂ttger","creator_url":"https://huggingface.co/Paul","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Multilingual HateCheck\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nMultilingual HateCheck (MHC) is a suite of functional tests for hate speech detection models in 10 different languages: Arabic, Dutch, French, German, Hindi, Italian, Mandarin, Polish, Portuguese and Spanish.\\nFor each language, there are 25+ functional tests that correspond to distinct types of hate and challenging non-hate.\\nThis allows for targeted diagnostic insights into model performance.\\nFor more‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Paul/hatecheck-mandarin."},
	{"name":"hatecheck-italian","keyword":"hate-speech-detection","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Paul/hatecheck-italian","creator_name":"Paul R√∂ttger","creator_url":"https://huggingface.co/Paul","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Multilingual HateCheck\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nMultilingual HateCheck (MHC) is a suite of functional tests for hate speech detection models in 10 different languages: Arabic, Dutch, French, German, Hindi, Italian, Mandarin, Polish, Portuguese and Spanish.\\nFor each language, there are 25+ functional tests that correspond to distinct types of hate and challenging non-hate.\\nThis allows for targeted diagnostic insights into model performance.\\nFor more‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Paul/hatecheck-italian."},
	{"name":"hatecheck-hindi","keyword":"hate-speech-detection","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Paul/hatecheck-hindi","creator_name":"Paul R√∂ttger","creator_url":"https://huggingface.co/Paul","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Multilingual HateCheck\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nMultilingual HateCheck (MHC) is a suite of functional tests for hate speech detection models in 10 different languages: Arabic, Dutch, French, German, Hindi, Italian, Mandarin, Polish, Portuguese and Spanish.\\nFor each language, there are 25+ functional tests that correspond to distinct types of hate and challenging non-hate.\\nThis allows for targeted diagnostic insights into model performance.\\nFor more‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Paul/hatecheck-hindi."},
	{"name":"hatecheck-german","keyword":"hate-speech-detection","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Paul/hatecheck-german","creator_name":"Paul R√∂ttger","creator_url":"https://huggingface.co/Paul","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Multilingual HateCheck\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nMultilingual HateCheck (MHC) is a suite of functional tests for hate speech detection models in 10 different languages: Arabic, Dutch, French, German, Hindi, Italian, Mandarin, Polish, Portuguese and Spanish.\\nFor each language, there are 25+ functional tests that correspond to distinct types of hate and challenging non-hate.\\nThis allows for targeted diagnostic insights into model performance.\\nFor more‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Paul/hatecheck-german."},
	{"name":"hatecheck-french","keyword":"hate-speech-detection","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Paul/hatecheck-french","creator_name":"Paul R√∂ttger","creator_url":"https://huggingface.co/Paul","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Multilingual HateCheck\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nMultilingual HateCheck (MHC) is a suite of functional tests for hate speech detection models in 10 different languages: Arabic, Dutch, French, German, Hindi, Italian, Mandarin, Polish, Portuguese and Spanish.\\nFor each language, there are 25+ functional tests that correspond to distinct types of hate and challenging non-hate.\\nThis allows for targeted diagnostic insights into model performance.\\nFor more‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Paul/hatecheck-french."},
	{"name":"hatecheck-dutch","keyword":"hate-speech-detection","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Paul/hatecheck-dutch","creator_name":"Paul R√∂ttger","creator_url":"https://huggingface.co/Paul","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Multilingual HateCheck\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nMultilingual HateCheck (MHC) is a suite of functional tests for hate speech detection models in 10 different languages: Arabic, Dutch, French, German, Hindi, Italian, Mandarin, Polish, Portuguese and Spanish.\\nFor each language, there are 25+ functional tests that correspond to distinct types of hate and challenging non-hate.\\nThis allows for targeted diagnostic insights into model performance.\\nFor more‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Paul/hatecheck-dutch."},
	{"name":"hatecheck-arabic","keyword":"hate-speech-detection","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Paul/hatecheck-arabic","creator_name":"Paul R√∂ttger","creator_url":"https://huggingface.co/Paul","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Multilingual HateCheck\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nMultilingual HateCheck (MHC) is a suite of functional tests for hate speech detection models in 10 different languages: Arabic, Dutch, French, German, Hindi, Italian, Mandarin, Polish, Portuguese and Spanish.\\nFor each language, there are 25+ functional tests that correspond to distinct types of hate and challenging non-hate.\\nThis allows for targeted diagnostic insights into model performance.\\nFor more‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Paul/hatecheck-arabic."},
	{"name":"ro-fb-offense","keyword":"hate-speech-detection","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/readerbench/ro-fb-offense","creator_name":"ReaderBench","creator_url":"https://huggingface.co/readerbench","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for \\\"RO-FB-Offense\\\"\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nFB-RO-Offense corpus, an offensive speech dataset containing 4,455 user-generated comments from Facebook live broadcasts available in Romanian\\nThe annotation follows the hierarchical tagset proposed in the Germeval 2018 Dataset. \\nThe following Classes are available:\\n\\nOTHER: Non-Offensive Language\\nOFFENSIVE:\\nPROFANITY\\nINSULT\\nABUSE\\n\\n\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages\\n\\t\\n\\nRomanian\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Structure\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/readerbench/ro-fb-offense."},
	{"name":"ro-fb-offense","keyword":"hate-speech-detection","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/readerbench/ro-fb-offense","creator_name":"ReaderBench","creator_url":"https://huggingface.co/readerbench","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for \\\"RO-FB-Offense\\\"\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nFB-RO-Offense corpus, an offensive speech dataset containing 4,455 user-generated comments from Facebook live broadcasts available in Romanian\\nThe annotation follows the hierarchical tagset proposed in the Germeval 2018 Dataset. \\nThe following Classes are available:\\n\\nOTHER: Non-Offensive Language\\nOFFENSIVE:\\nPROFANITY\\nINSULT\\nABUSE\\n\\n\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages\\n\\t\\n\\nRomanian\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Structure\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/readerbench/ro-fb-offense."},
	{"name":"scientific-exaggeration-detection","keyword":"misinformation","license":"GNU General Public License v3.0","license_url":"https://choosealicense.com/licenses/gpl-3.0/","language":"en","dataset_url":"https://huggingface.co/datasets/copenlu/scientific-exaggeration-detection","creator_name":"CopeNLU","creator_url":"https://huggingface.co/copenlu","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Scientific Exaggeration Detection\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nPublic trust in science depends on honest and factual communication of scientific papers. However, recent studies have demonstrated a tendency of news media to misrepresent scientific papers by exaggerating their findings. Given this, we present a formalization of and study into the problem of exaggeration detection in science communication. While there are an abundance of scientific papers and‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/copenlu/scientific-exaggeration-detection."},
	{"name":"spiced","keyword":"misinformation","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/copenlu/spiced","creator_name":"CopeNLU","creator_url":"https://huggingface.co/copenlu","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for SPICED\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThe Scientific Paraphrase and Information ChangE Dataset (SPICED) is a dataset of paired scientific findings from scientific papers, news media, and Twitter. The types of pairs are between <paper, news> and <paper, tweet>. Each pair is labeled for the degree of information similarity in the findings described by each sentence, on a scale from 1-5. This is called the Information Matching Score (IMS). The data was curated from‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/copenlu/spiced."},
	{"name":"panda","keyword":"fairness","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/facebook/panda","creator_name":"AI at Meta","creator_url":"https://huggingface.co/facebook","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for PANDA\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nPANDA (Perturbation Augmentation NLP DAtaset) consists of approximately 100K pairs of crowdsourced human-perturbed text snippets (original, perturbed). Annotators were given selected terms and target demographic attributes, and instructed to rewrite text snippets along three demographic axes: gender, race and age, while preserving semantic meaning. Text snippets were sourced from a range of text corpora (BookCorpus, Wikipedia‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/facebook/panda."},
	{"name":"pile-detoxify","keyword":"hate-speech-detection","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/tomekkorbak/pile-detoxify","creator_name":"Tomek Korbak","creator_url":"https://huggingface.co/tomekkorbak","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for pile-pii-scrubadub\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThis dataset contains text from The Pile, annotated based on the toxicity of each sentence.\\nEach document (row in the dataset) is segmented into sentences, and each sentence is given a score: the toxicity predicted by the Detoxify.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSupported Tasks and Leaderboards\\n\\t\\n\\n[More Information Needed]\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages\\n\\t\\n\\nThis dataset is taken from The Pile, which is English text.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/tomekkorbak/pile-detoxify."},
	{"name":"pile-detoxify","keyword":"toxicity","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/tomekkorbak/pile-detoxify","creator_name":"Tomek Korbak","creator_url":"https://huggingface.co/tomekkorbak","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for pile-pii-scrubadub\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThis dataset contains text from The Pile, annotated based on the toxicity of each sentence.\\nEach document (row in the dataset) is segmented into sentences, and each sentence is given a score: the toxicity predicted by the Detoxify.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSupported Tasks and Leaderboards\\n\\t\\n\\n[More Information Needed]\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages\\n\\t\\n\\nThis dataset is taken from The Pile, which is English text.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/tomekkorbak/pile-detoxify."},
	{"name":"fstdt-quotes","keyword":"hate-speech-detection","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/MtCelesteMa/fstdt-quotes","creator_name":"Celeste Ma","creator_url":"https://huggingface.co/MtCelesteMa","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for FSTDT Quotes\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nFSTDT Quotes is a snapshot of the Fundies Say the Darndest Things website taken on 2023/02/03 14:16. It is intended for hate and fringe speech detection and classification.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSupported Tasks and Leaderboards\\n\\t\\n\\n[More Information Needed]\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages\\n\\t\\n\\nFSTDT Quotes is in English.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Structure\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Instances\\n\\t\\n\\nAn example instance looks like this:\\n{\\n  \\\"id\\\": \\\"G\\\"‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/MtCelesteMa/fstdt-quotes."},
	{"name":"news-ro-offense","keyword":"hate-speech-detection","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/readerbench/news-ro-offense","creator_name":"ReaderBench","creator_url":"https://huggingface.co/readerbench","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for \\\"RO-News-Offense\\\"\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\na novel Romanian language dataset for offensive message detection with manually \\nannotated comment from a local Romanian news website (stiri de cluj) into five classes:\\n\\nnon-offensive\\ntargeted insults\\nracist\\nhomophobic\\nsexist\\n\\nResulting in 4052 annotated messages\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages\\n\\t\\n\\nRomanian\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Structure\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Instances\\n\\t\\n\\nAn example of 'train' looks as follows.\\n{‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/readerbench/news-ro-offense."},
	{"name":"news-ro-offense","keyword":"hate-speech-detection","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/readerbench/news-ro-offense","creator_name":"ReaderBench","creator_url":"https://huggingface.co/readerbench","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for \\\"RO-News-Offense\\\"\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\na novel Romanian language dataset for offensive message detection with manually \\nannotated comment from a local Romanian news website (stiri de cluj) into five classes:\\n\\nnon-offensive\\ntargeted insults\\nracist\\nhomophobic\\nsexist\\n\\nResulting in 4052 annotated messages\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages\\n\\t\\n\\nRomanian\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Structure\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Instances\\n\\t\\n\\nAn example of 'train' looks as follows.\\n{‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/readerbench/news-ro-offense."},
	{"name":"ro-offense","keyword":"hate-speech-detection","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/readerbench/ro-offense","creator_name":"ReaderBench","creator_url":"https://huggingface.co/readerbench","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for \\\"RO-Offense-Sequences\\\"\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\n\\n\\nHomepage: https://github.com/readerbench/ro-offense-sequences\\nRepository: https://github.com/readerbench/ro-offense-sequences\\nPoint of Contact: Andrei Paraschiv\\n\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\na novel Romanian language dataset for offensive language detection with manually \\nannotated offensive labels from a local Romanian sports news website (gsp.ro):\\nResulting in 12,445 annotated messages‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/readerbench/ro-offense."},
	{"name":"ro-offense","keyword":"hate-speech-detection","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/readerbench/ro-offense","creator_name":"ReaderBench","creator_url":"https://huggingface.co/readerbench","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for \\\"RO-Offense-Sequences\\\"\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\n\\n\\nHomepage: https://github.com/readerbench/ro-offense-sequences\\nRepository: https://github.com/readerbench/ro-offense-sequences\\nPoint of Contact: Andrei Paraschiv\\n\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\na novel Romanian language dataset for offensive language detection with manually \\nannotated offensive labels from a local Romanian sports news website (gsp.ro):\\nResulting in 12,445 annotated messages‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/readerbench/ro-offense."},
	{"name":"black-box-api-challenges","keyword":"fairness","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/CohereForAI/black-box-api-challenges","creator_name":"Cohere For AI","creator_url":"https://huggingface.co/CohereForAI","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card\\n\\t\\n\\nPaper: On the Challenges of Using Black-Box APIs for Toxicity Evaluation in Research\\nAbstract: Perception of toxicity evolves over time and often differs between geographies and cultural backgrounds. Similarly, black-box commercially available APIs for detecting toxicity, such as the Perspective API, are not static, but frequently retrained to address any unattended weaknesses and biases. We evaluate the implications of these changes on the reproducibility of‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/CohereForAI/black-box-api-challenges."},
	{"name":"black-box-api-challenges","keyword":"toxicity","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/CohereForAI/black-box-api-challenges","creator_name":"Cohere For AI","creator_url":"https://huggingface.co/CohereForAI","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card\\n\\t\\n\\nPaper: On the Challenges of Using Black-Box APIs for Toxicity Evaluation in Research\\nAbstract: Perception of toxicity evolves over time and often differs between geographies and cultural backgrounds. Similarly, black-box commercially available APIs for detecting toxicity, such as the Perspective API, are not static, but frequently retrained to address any unattended weaknesses and biases. We evaluate the implications of these changes on the reproducibility of‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/CohereForAI/black-box-api-challenges."},
	{"name":"toxic-aira-dataset","keyword":"toxicity","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/nicholasKluge/toxic-aira-dataset","creator_name":"Nicholas Kluge Corr√™a","creator_url":"https://huggingface.co/nicholasKluge","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tToxic-Aira Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThis dataset contains a collection of prompt + completion examples of LLM following instructions in a conversational manner. All prompts come with two possible completions (one deemed appropriate and the other toxic). The dataset is available in both Portuguese and English.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSupported Tasks and Leaderboards\\n\\t\\n\\nThis dataset can be utilized to train a reward/preference model, toxicity detection, or DPO fine-tuning.‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/nicholasKluge/toxic-aira-dataset."},
	{"name":"ro-offense-sequences","keyword":"hate-speech-detection","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/readerbench/ro-offense-sequences","creator_name":"ReaderBench","creator_url":"https://huggingface.co/readerbench","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for \\\"RO-Offense-Sequences\\\"\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\n\\n\\nHomepage: https://github.com/readerbench/ro-offense-sequences\\nRepository: https://github.com/readerbench/ro-offense-sequences\\nPoint of Contact: Teodora-Andreea Ion\\n\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\na novel Romanian language dataset for offensive sequence detection with manually \\nannotated offensive sequences from a local Romanian sports news website (gsp.ro):\\nResulting in 4800 annotated messages‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/readerbench/ro-offense-sequences."},
	{"name":"ro-offense-sequences","keyword":"hate-speech-detection","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/readerbench/ro-offense-sequences","creator_name":"ReaderBench","creator_url":"https://huggingface.co/readerbench","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for \\\"RO-Offense-Sequences\\\"\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\n\\n\\nHomepage: https://github.com/readerbench/ro-offense-sequences\\nRepository: https://github.com/readerbench/ro-offense-sequences\\nPoint of Contact: Teodora-Andreea Ion\\n\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\na novel Romanian language dataset for offensive sequence detection with manually \\nannotated offensive sequences from a local Romanian sports news website (gsp.ro):\\nResulting in 4800 annotated messages‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/readerbench/ro-offense-sequences."},
	{"name":"rudetoxifier_data","keyword":"toxicity","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/d0rj/rudetoxifier_data","creator_name":"Dmitry Balobin","creator_url":"https://huggingface.co/d0rj","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\trudetoxifier_data\\n\\t\\n\\nHuggingface copy of Github repo with dataset.\\n"},
	{"name":"rudetoxifier_data_detox","keyword":"toxicity","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/d0rj/rudetoxifier_data_detox","creator_name":"Dmitry Balobin","creator_url":"https://huggingface.co/d0rj","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\trudetoxifier_data_detox\\n\\t\\n\\nThis is subset of toxic comments from d0rj/rudetoxifier_data which has detoxified column created by s-nlp/ruT5-base-detox.\\n"},
	{"name":"FactCHD","keyword":"hallucination","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/zjunlp/FactCHD","creator_name":"ZJUNLP","creator_url":"https://huggingface.co/zjunlp","description":"zjunlp/FactCHD dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"wikitoxic","keyword":"hate-speech-detection","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/pietrolesci/wikitoxic","creator_name":"Pietro Lesci","creator_url":"https://huggingface.co/pietrolesci","description":"This is the same dataset as OxAISH-AL-LLM/wiki_toxic.\\nThe only differences are\\n\\nAddition of a unique identifier, uid\\n\\nAddition of the indices, that is 3 columns with the embeddings of 3 different sentence-transformers\\n\\nall-mpnet-base-v2\\nmulti-qa-mpnet-base-dot-v1\\nall-MiniLM-L12-v2\\n\\n\\nRenaming of the label column to labels for easier compatibility with the transformers library\\n\\n\\n"},
	{"name":"wikitoxic","keyword":"toxicity","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/pietrolesci/wikitoxic","creator_name":"Pietro Lesci","creator_url":"https://huggingface.co/pietrolesci","description":"This is the same dataset as OxAISH-AL-LLM/wiki_toxic.\\nThe only differences are\\n\\nAddition of a unique identifier, uid\\n\\nAddition of the indices, that is 3 columns with the embeddings of 3 different sentence-transformers\\n\\nall-mpnet-base-v2\\nmulti-qa-mpnet-base-dot-v1\\nall-MiniLM-L12-v2\\n\\n\\nRenaming of the label column to labels for easier compatibility with the transformers library\\n\\n\\n"},
	{"name":"COVID-19-conspiracy-theories-tweets","keyword":"misinformation","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/webimmunization/COVID-19-conspiracy-theories-tweets","creator_name":"webimmunization","creator_url":"https://huggingface.co/webimmunization","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThis dataset consists of 6591 tweets generated by GPT-3.5 model. The tweets are juxtaposed with a conspiracy theory related to COVID-19 pandemic. Each item consists of a label that represents the item's output class. The possible labels are support/deny/neutral.\\n\\nsupport: the tweet suggests support for the conspiracy theory\\ndeny: the tweet contradicts the conspiracy theory\\nneutral: the tweet is mostly informative, and does not show emotions against the conspiracy‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/webimmunization/COVID-19-conspiracy-theories-tweets."},
	{"name":"PolishCyberbullyingDataset","keyword":"hate-speech","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ptaszynski/PolishCyberbullyingDataset","creator_name":"Michal Ptaszynski","creator_url":"https://huggingface.co/ptaszynski","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tExpert-annotated dataset to study cyberbullying in Polish language\\n\\t\\n\\nThis the first publically available expert-annotated dataset containing annotations of cyberbullying and hate-speech in Polish language.\\nPlease, read the paper about the dataset for all necessary details.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tModel\\n\\t\\n\\nThe classification model which achieved the highest classification results for the dataset is also released under the following URL.\\nPolbert-CB - Polish BERT trained for Automatic‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ptaszynski/PolishCyberbullyingDataset."},
	{"name":"TuPY_dataset_multilabel","keyword":"hate-speech-detection","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/victoriadreis/TuPY_dataset_multilabel","creator_name":"Victoria Reis","creator_url":"https://huggingface.co/victoriadreis","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tPortuguese Hate Speech Dataset (TuPy)\\n\\t\\n\\nThe Portuguese hate speech dataset (TuPy) is an annotated corpus designed to facilitate the development of advanced hate speech detection models using machine learning (ML) and natural language processing (NLP) techniques. TuPy is formed by 10000 thousand unpublished annotated tweets collected in 2023.\\nThis repository is organized as follows:\\nroot.\\n    ‚îú‚îÄ‚îÄ annotations   : classification given by annotators\\n    ‚îú‚îÄ‚îÄ raw corpus    : dataset‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/victoriadreis/TuPY_dataset_multilabel."},
	{"name":"TuPY_dataset_binary","keyword":"hate-speech-detection","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/victoriadreis/TuPY_dataset_binary","creator_name":"Victoria Reis","creator_url":"https://huggingface.co/victoriadreis","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tPortuguese Hate Speech Dataset (TuPy)\\n\\t\\n\\nThe Portuguese hate speech dataset (TuPy) is an annotated corpus designed to facilitate the development of advanced hate speech detection models using machine learning (ML) and natural language processing (NLP) techniques. TuPy is formed by 10000 thousand unpublished annotated tweets collected in 2023.\\nThis repository is organized as follows:\\nroot.\\n    ‚îú‚îÄ‚îÄ annotations   : classification given by annotators\\n    ‚îú‚îÄ‚îÄ raw corpus    : dataset‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/victoriadreis/TuPY_dataset_binary."},
	{"name":"TuPy-Dataset","keyword":"hate-speech-detection","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Silly-Machine/TuPy-Dataset","creator_name":"Silly-Machine","creator_url":"https://huggingface.co/Silly-Machine","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tPortuguese Hate Speech Dataset (TuPy)\\n\\t\\n\\nThe Portuguese hate speech dataset (TuPy) is an annotated corpus designed to facilitate the development of advanced hate speech detection models using machine learning (ML) \\nand natural language processing (NLP) techniques. TuPy is comprised of 10,000 (ten thousand) unpublished, annotated, and anonymized documents collected \\non Twitter (currently known as X) in 2023. \\nThis repository is organized as follows:\\nroot.\\n    ‚îú‚îÄ‚îÄ binary     : binary‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Silly-Machine/TuPy-Dataset."},
	{"name":"TuPyE-Dataset","keyword":"hate-speech-detection","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Silly-Machine/TuPyE-Dataset","creator_name":"Silly-Machine","creator_url":"https://huggingface.co/Silly-Machine","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tPortuguese Hate Speech Expanded Dataset (TuPyE)\\n\\t\\n\\nTuPyE, an enhanced iteration of TuPy, encompasses a compilation of 43,668 meticulously annotated documents specifically \\nselected for the purpose of hate speech detection within diverse social network contexts. \\nThis augmented dataset integrates supplementary annotations and amalgamates with datasets sourced from \\nFortuna et al. (2019), \\nLeite et al. (2020), \\nand Vargas et al. (2022),\\ncomplemented by an infusion of 10,000 original‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Silly-Machine/TuPyE-Dataset."},
	{"name":"RuLES","keyword":"safety","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/normster/RuLES","creator_name":"Norman Mu","creator_url":"https://huggingface.co/normster","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tCan LLMs Follow Simple Rules?\\n\\t\\n\\n[code] [demo] [website] [paper]\\nThis repo contains the test cases for RuLES: Rule-following Language Evaluation Scenarios, a benchmark for evaluating rule-following in language models. Please see our github repo for usage instructions and our paper for more information about the benchmark.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tAbstract\\n\\t\\n\\nAs Large Language Models (LLMs) are deployed with increasing real-world responsibilities, it is important to be able to specify and‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/normster/RuLES."},
	{"name":"kor-hate-sentence","keyword":"hate-speech","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/SJ-Donald/kor-hate-sentence","creator_name":"SJ.KIM","creator_url":"https://huggingface.co/SJ-Donald","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSJ-Donald/kor-hate-sentence\\n\\t\\n\\nSJ-Donald/kor-hate-sentence is merged dataset from fllow\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDatasets\\n\\t\\n\\n\\nsmilegate-ai/kor_unsmile\\nkorean-hate-speech\\nCurse-detection-data\\nkorean-malicious-comments-dataset\\n\\nMerge datasets from above and drop duplicates.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tHow to use\\n\\t\\n\\nfrom datasets import load_dataset\\n\\nds = load_dataset(\\\"SJ-Donald/kor-hate-sentence\\\")\\nprint(ds)\\n\\nDatasetDict({\\n    train: Dataset({\\n        features: ['Î¨∏Ïû•', 'hate', 'clean', 'labels'],\\n        num_rows:‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/SJ-Donald/kor-hate-sentence."},
	{"name":"virc","keyword":"hate-speech","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/oeg/virc","creator_name":"Ontology Engineering Group","creator_url":"https://huggingface.co/oeg","description":"\\n\\t\\n\\t\\t\\n\\t\\tVulnerable Identities Recognition Corpus (VIRC) for Hate Speech Analysis\\n\\t\\n\\nWelcome to the Vulnerable Identities Recognition Corpus (VIRC), a dataset created to enhance hate speech analysis in Italian and Spanish news headlines. VIRC provides annotated headlines aimed at identifying vulnerable identities, dangerous discourse, derogatory mentions, and entities. This corpus contributes to developing more sophisticated hate speech detection tools and policies for creating a safer online‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/oeg/virc."},
	{"name":"GPT-4o-evaluation-biases","keyword":"fairness","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mtec-TUB/GPT-4o-evaluation-biases","creator_name":"Electronic Systems of Medical Engineering","creator_url":"https://huggingface.co/mtec-TUB","description":"\\n\\t\\n\\t\\t\\n\\t\\tA database to support the evaluation of gender biases in GPT-4o output\\n\\t\\n\\nThe database and its construction process are described in the paper \\\"A database to support the evaluation of gender biases in GPT-4o output\\\" by Mehner et al., presented at the 1st ISCA/ITG Workshop on Diversity in Large Speech and Language Models (Berlin, Februar 20, 2025).\\n\\n\\t\\n\\t\\t\\n\\t\\tIntroduction\\n\\t\\n\\nThis is a database of prompts and answers generated with GPT-4o-mini and GPT-4o in a pretest and a main test‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mtec-TUB/GPT-4o-evaluation-biases."},
	{"name":"hallucination","keyword":"hallucination","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/GuardrailsAI/hallucination","creator_name":"Guardrails AI","creator_url":"https://huggingface.co/GuardrailsAI","description":"This is a vendored reupload of the Benchmarking Unfaithful Minimal Pairs (BUMP) Dataset available at https://github.com/dataminr-ai/BUMP\\nThe BUMP (Benchmark of Unfaithful Minimal Pairs) dataset stands out as a superior choice for evaluating hallucination detection systems due to its quality and realism. Unlike synthetic datasets such as TruthfulQA, HalluBench, or FaithDial that rely on LLMs to generate hallucinations, BUMP employs human annotators to manually introduce errors into summaries‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/GuardrailsAI/hallucination."},
	{"name":"MCRS_by_Databoost","keyword":"toxicity","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Databoost/MCRS_by_Databoost","creator_name":"Mada","creator_url":"https://huggingface.co/Databoost","description":"A dataset for classifying and detecting toxicity in social media content"},
	{"name":"dialectic-preferences-bias-aae-sae-parallel","keyword":"fairness","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/furquan/dialectic-preferences-bias-aae-sae-parallel","creator_name":"Furquan Hassan","creator_url":"https://huggingface.co/furquan","description":"\\n\\t\\n\\t\\t\\n\\t\\tDialectic Preferences Bias Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tOverview\\n\\t\\n\\nThis dataset is part of a research study examining dialectic preference bias in Large Language Models (LLMs). It contains paired sentences in African American English (AAE) and Standard American English (SAE), used to analyze potential biases in language models' treatment of different dialects.\\nThe dataset contains two columns:\\nafrican_american_english: Text samples in African American English‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/furquan/dialectic-preferences-bias-aae-sae-parallel."},
	{"name":"PleIAs-ToxicCommons","keyword":"toxicity","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/agentlans/PleIAs-ToxicCommons","creator_name":"Alan Tseng","creator_url":"https://huggingface.co/agentlans","description":"\\n\\t\\n\\t\\t\\n\\t\\tPleIAs/ToxicCommons\\n\\t\\n\\nThis dataset is a refined version of the PleIAs/ToxicCommons collection, focusing on historical texts labeled for content that may be considered objectionable by modern standards (what the authors of the dataset deem \\\"toxic\\\"). \\nThe cleaned dataset contains 1‚Äâ051‚Äâ027 rows, each representing a text sample with associated toxicity scores across five dimensions:\\n\\nRace and origin-based bias\\nGender and sexuality-based bias\\nReligious bias\\nAbility bias\\nViolence and abuse‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/agentlans/PleIAs-ToxicCommons."}
]
;
