const data_for_modality_monolingual = 
[
	{"name":"wb-feedbacks","keyword":"monolingual","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/nyuuzyou/wb-feedbacks","creator_name":"nyuuzyou","creator_url":"https://huggingface.co/nyuuzyou","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Wildberries products\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThe dataset contains product reviews from the Russian marketplace Wildberries, collected by mining about The dataset was collected by bruteforcing possible product identifiers (about 230 million) and querying all available feedbacks for them. The data are stored in zstd-archives containing jsonl-files. The 'nmId' in the dataset usually corresponds to the valid product article on the site, but sometimes reviews‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/nyuuzyou/wb-feedbacks."},
	{"name":"mmlu_ita","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/swap-uniba/mmlu_ita","creator_name":"SWAP Research Group@UNIBA","creator_url":"https://huggingface.co/swap-uniba","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tItalian Version of the MMLU DATASET\\n\\t\\n\\nBased on the version released by: FreedomIntelligence/MMLU_Italian\\nIncludes minor fixes.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tCitations\\n\\t\\n\\nThis version:\\n@misc{basile2023llamantino,\\n      title={LLaMAntino: LLaMA 2 Models for Effective Text Generation in Italian Language}, \\n      author={Pierpaolo Basile and Elio Musacchio and Marco Polignano and Lucia Siciliani and Giuseppe Fiameni and Giovanni Semeraro},\\n      year={2023},\\n      eprint={2312.09993}‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/swap-uniba/mmlu_ita."},
	{"name":"CHOCOLATE","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/khhuang/CHOCOLATE","creator_name":"Kung-Hsiang Huang","creator_url":"https://huggingface.co/khhuang","description":"\\n\\t\\n\\t\\t\\n\\t\\tDataset Card for CHOCOLATE\\n\\t\\n\\n\\nDataset Description\\nPaper Information\\nCitation\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nCHOCOLATE is a benchmark for detecting and correcting factual inconsistency in generated chart captions. It consists of captions produced by six most advanced models, which are categorized into three subsets:\\n\\nLVLM: GPT-4V, Bard (before Gemini)\\nLLM-based Pipeline: DePlot + GPT-4\\nFine-tuned Model: ChartT5, MatCha, UniChart\\n\\nThe charts are from two datasets: VisText and the‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/khhuang/CHOCOLATE."},
	{"name":"germanrag","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/DiscoResearch/germanrag","creator_name":"Disco Research","creator_url":"https://huggingface.co/DiscoResearch","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tGermanRAG üá©üá™üìúü¶ú\\n\\t\\n\\nThis dataset is derived from the GermanDPR dataset and enhances it by providing fully formulated answers instead of answer spans.\\nIt can be used to finetune for retrieval augmented generation tasks (RAG) in German.\\nWe deduplicated the original contexts resulting in 2243 unique contexts and repeated the hard negatives of half of them, such that the last third of the total dataset contains only not answerable examples.\\nIn contrast to the original dataset the‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/DiscoResearch/germanrag."},
	{"name":"dbnl.org-dutch-public-domain","keyword":"monolingual","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/jvdgoltz/dbnl.org-dutch-public-domain","creator_name":"Julian von der Goltz","creator_url":"https://huggingface.co/jvdgoltz","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for \\\"dbnl.org-dutch-public-domain\\\"\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThis dataset comprises a collection of texts from the Dutch Literature in the public domain, specifically from the DBNL (Digitale Bibliotheek voor de Nederlandse Letteren) public domain collection. The collection includes books, poems, songs, and other documentation, letters, etc., that are at least 140 years old and thus free of copyright restrictions. Each entry in the dataset corresponds to one‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/jvdgoltz/dbnl.org-dutch-public-domain."},
	{"name":"human-eval","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ai4bharat/human-eval","creator_name":"AI4Bharat","creator_url":"https://huggingface.co/ai4bharat","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tAiravata HumanEval Prompts\\n\\t\\n\\nThis benchmark contains a set of prompts written by real-users to evaluate LLMs on real-world tasks and test it for different abilities. We collect prompts for 5 abilities listed below:\\n\\nLong: Ability to generate long-form text like writing essays, speeches, reports, etc.\\nFact-Ops: Ability to give factual opinions and explanations like seeking recommendations, seeking advice, opinions, explanations, etc.\\nContent: Ability to make content accessible like‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ai4bharat/human-eval."},
	{"name":"pierogue","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/dustalov/pierogue","creator_name":"Dmitry Ustalov","creator_url":"https://huggingface.co/dustalov","description":"\\n\\t\\n\\t\\t\\n\\t\\tPierogue\\n\\t\\n\\nPierogue is a small open-licensed machine-generated dataset that contains fifteen short texts in English covering five topics, provided with the relevance judgements (qrels), designed for educational purposes.\\n\\nTopics: cosmos, nature, music, technology, fashion\\nSplits: train (10 documents, 375 qrels) and test (5 documents, 150 qrels)\\n\\nTexts were generated by ChatGPT 3.5. Queries, qrels, and analogies were generated by GPT-4. Words were provided with Word2Vec embeddings‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/dustalov/pierogue."},
	{"name":"chartve_dataset","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/khhuang/chartve_dataset","creator_name":"Kung-Hsiang Huang","creator_url":"https://huggingface.co/khhuang","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for ChartVE's Training Data\\n\\t\\n\\n\\nDataset Description\\nPaper Information\\nCitation\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nChartVE (Chart Visual Entailment) is a visual entailment model introduced in the paper \\\"Do LVLMs Understand Charts? Analyzing and Correcting Factual Errors in Chart Captioning\\\" for evaluating the factuality of a generated caption sentence with regard to the input chart. The model takes in a chart figure and a caption sentence as input, and outputs an‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/khhuang/chartve_dataset."},
	{"name":"Graptoloidea-Specimens-Imaging","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/LeoZhangzaolin/Graptoloidea-Specimens-Imaging","creator_name":"Zaolin Zhang","creator_url":"https://huggingface.co/LeoZhangzaolin","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Graptoloidea Specimens Imaging\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThis dataset offers a detailed examination of Graptoloidea specimens, featuring attributes like image file paths, suborder, infraorder, family (including subfamily), tagged species names, geological stages, mean age values, and locality details (with coordinates and horizon information), complemented by original reference citations for each specimen. It serves as a comprehensive resource for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/LeoZhangzaolin/Graptoloidea-Specimens-Imaging."},
	{"name":"UHGEvalDataset","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Ki-Seki/UHGEvalDataset","creator_name":"Shichao Song","creator_url":"https://huggingface.co/Ki-Seki","description":"The dataset sourced from https://github.com/IAAR-Shanghai/UHGEval\\n"},
	{"name":"datasets-github-issues","keyword":"monolingual","license":"\"Do What The F*ck You Want To Public License\"","license_url":"https://choosealicense.com/licenses/wtfpl/","language":"en","dataset_url":"https://huggingface.co/datasets/alex-atelo/datasets-github-issues","creator_name":"Alexander Atelo Kelly","creator_url":"https://huggingface.co/alex-atelo","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for GitHub Issues\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nGitHub Issues is a dataset consisting of GitHub issues and pull requests associated with the ü§ó Datasets repository. It is intended for educational purposes and can be used for semantic search or multilabel text classification. The contents of each GitHub issue are in English and concern the domain of datasets for NLP, computer vision, and beyond.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSupported Tasks and Leaderboards\\n\\t\\n\\nFor each of the tasks‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/alex-atelo/datasets-github-issues."},
	{"name":"tinyTruthfulQA","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/tinyBenchmarks/tinyTruthfulQA","creator_name":"tinyBenchmarks","creator_url":"https://huggingface.co/tinyBenchmarks","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\ttinyTruthfulQA\\n\\t\\n\\nWelcome to tinyTruthfulQA! This dataset serves as a concise version of the truthfulQA dataset, offering a subset of 100 data points selected from the original compilation. \\ntinyTruthfulQA is designed to enable users to efficiently estimate the performance of a large language model (LLM) with reduced dataset size, saving computational resources \\nwhile maintaining the essence of the truthfulQA evaluation.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tFeatures\\n\\t\\n\\n\\nCompact Dataset: With only 100 data‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/tinyBenchmarks/tinyTruthfulQA."},
	{"name":"observation_or_evaluation","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/thomasgauthier/observation_or_evaluation","creator_name":"Thomas Gauthier-Caron","creator_url":"https://huggingface.co/thomasgauthier","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for \\\"Observation or evaluation\\\"\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThis dataset contains statements classified into observations and evaluations categories, based on the principles of Nonviolent Communication (NVC) teached by Marshall Rosenberg. It includes a synthetic dataset generated and augmented through various language models to classify statements reflecting either pure observations (noticing) or evaluations (judgments), aimed at understanding and practicing‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/thomasgauthier/observation_or_evaluation."},
	{"name":"PLOD-CW","keyword":"monolingual","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/surrey-nlp/PLOD-CW","creator_name":"University of Surrey NLP Group","creator_url":"https://huggingface.co/surrey-nlp","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tPLOD: An Abbreviation Detection Dataset\\n\\t\\n\\nThis is the repository for PLOD Dataset subset being used for CW in NLP module 2023-2024 at University of Surrey. \\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThis PLOD Dataset is an English-language dataset of abbreviations and their long-forms tagged in text. The dataset has been collected for research from the PLOS journals indexing of abbreviations and long-forms in the text. This dataset was created to support the Natural Language Processing task‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/surrey-nlp/PLOD-CW."},
	{"name":"FACTOID","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/aisafe/FACTOID","creator_name":"safe ai","creator_url":"https://huggingface.co/aisafe","description":"aisafe/FACTOID dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"wikisource_tw","keyword":"monolingual","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/jslin09/wikisource_tw","creator_name":"Chun-Hsien Lin","creator_url":"https://huggingface.co/jslin09","description":"Êú¨Ë≥áÊñôÈõÜÊòØËß£ÊûêËá™Á∂≠Âü∫ÊñáÂ∫´Êñº 20240120 ÁôºÂ∏ÉÁöÑÊâìÂåÖÊ™î bz2 Ê™îÊ°àÁöÑÂÖßÂÆπÔºåÂú®Ëß£ÊûêÂá∫ÊâÄÈúÄÂÖßÂÆπÂæåÔºåÂà©Áî® wikitextparser ÁßªÈô§ Wiki Ê®ôË®ò„ÄÇËß£ÊûêÂæå‰øùÁïôÁöÑÊ¨Ñ‰ΩçÊúâÂÖ©ÂÄãÔºöÊ¢ùÁõÆÂêçÁ®±ÔºàtitleÔºâÔºåÊ¢ùÁõÆÂÖßÂÆπÔºàpage articleÔºâ„ÄÇ\\nÂéüÂßãÁöÑÊâìÂåÖÊ™îÊ¢ùÁõÆÂÖßÂÆπÁ∞°ÁπÅÊ∑∑ÈõúÔºåÊâÄ‰ª•ÊúâÂà©Áî® OpenCC ÈÄ≤Ë°åÁ∞°ËΩâÁπÅËôïÁêÜ„ÄÇ\\n\\nÂéüÂßãÁ∏ΩÊ¢ùÁõÆÊï∏: 1,057,179 Ê¢ùÁõÆ„ÄÇ\\nÂÖ®ÈÉ® 1,057,179 ÂÄãÊ¢ùÁõÆÊ®ôÈ°å„ÄÇ\\nÂÖ®ÈÉ® 1,057,179 ÂÄãÊ¢ùÁõÆÂÖßÂÆπ„ÄÇ\\nÁÑ°Ê≥ïËá™ÂãïÂéªÊ®ôË®òÁöÑÊ¢ùÁõÆÊï∏: 166\\nÊúâÂÖßÂÆπÁöÑÊ¢ùÁõÆÊï∏: 1,057,179\\n\\nÂõ†ÁÇ∫Êú¨Ë≥áÊñôÈõÜÂÖßÂÆπÈæêÂ§ßÔºåË¶ÅÂ°ûÈÄ≤‰∏ÄËà¨ÁöÑÂÄã‰∫∫ÈõªËÖ¶‰∏≠ÈÄ≤Ë°åË®àÁÆóÔºåÊÅêÊÄïÊúÉÊúâË≥áÊ∫ê‰∏çË∂≥ÁöÑÊÉÖÂΩ¢„ÄÇÂª∫Ë≠∞‰ΩøÁî®parquetÊ†ºÂºè‰∏ãËºâ‰ΩøÁî®„ÄÇ\\nË≥áÊñôÈõÜÁï∂‰∏≠Êúâ‰∏çÂ∞ëÂÖßÂÆπÁÇ∫„Äå#REDIRECT„ÄçÊàñÊòØ„Äå#ÈáçÂÆöÂêë„ÄçÁöÑÊ¢ùÁõÆÔºåÂ∞±Á≠â‰ª•ÂæåÊúâÁ©∫Êé®Âá∫‰øÆÊ≠£ÁâàÂÜç‰æÜÊ∏ÖÊ¥ó‰∫Ü„ÄÇ\\n"},
	{"name":"nst-da-norm","keyword":"monolingual","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/JackismyShephard/nst-da-norm","creator_name":"Christian Troelsen","creator_url":"https://huggingface.co/JackismyShephard","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for NST-da Normalized\\n\\t\\n\\n\\n\\n\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Details\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\n\\n\\n\\n\\n\\nCurated by: [More Information Needed]\\nFunded by [optional]: [More Information Needed]\\nShared by [optional]: [More Information Needed]\\nLanguage(s) (NLP): da\\nLicense: cc0-1.0\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Sources [optional]\\n\\t\\n\\n\\n\\n\\nRepository: [More Information Needed]\\nPaper [optional]: [More Information Needed]\\nDemo [optional]: [More Information Needed]\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tUses‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/JackismyShephard/nst-da-norm."},
	{"name":"MusteriYorumlari","keyword":"monolingual","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/turkish-nlp-suite/MusteriYorumlari","creator_name":"Turkish NLP Suite","creator_url":"https://huggingface.co/turkish-nlp-suite","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tM√º≈üteriYorumlari - A Large Scale Customer Sentiment Analysis Dataset for Turkish\\n\\t\\n\\n\\n\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nM√º≈üteriYorumlarƒ± is a Turkish e-commerce customer reviews dataset of size 103K, scraped from Hepsiburada.com and Trendyol.com. These reviews encompass a wide\\narray of product categories, including apparel, food items, baby products, and books. Review stars are in range of 1-5 stars.\\nThe star distribution is as follows:\\n\\n\\t\\n\\t\\t\\nstar rating\\ncount\\n\\n\\n\\t\\t\\n1\\n12,873\\n\\n\\n2\\n11‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/turkish-nlp-suite/MusteriYorumlari."},
	{"name":"dataviewer-test","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/gcjavi/dataviewer-test","creator_name":"Javier Gonz√°lez Corbelle","creator_url":"https://huggingface.co/gcjavi","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for [Dataset Name]\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\n[More Information Needed]\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSupported Tasks and Leaderboards\\n\\t\\n\\n[More Information Needed]\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages\\n\\t\\n\\n[More Information Needed]\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Structure\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Instances\\n\\t\\n\\n[More Information Needed]\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Fields\\n\\t\\n\\n[More Information Needed]\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Splits\\n\\t\\n\\n[More Information Needed]\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Creation\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tCuration Rationale\\n\\t\\n\\n[More‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/gcjavi/dataviewer-test."},
	{"name":"NFR_Spanish_requirements_classification","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/MariaIsabel/NFR_Spanish_requirements_classification","creator_name":"Maria Isabel Limaylla Lunarejo","creator_url":"https://huggingface.co/MariaIsabel","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nReSpaN(Spanish Dataset for non-functional requirements classification): Published version of dataset used for paper 'Towards a FAIR Dataset for non-functional requirements'.This dataset was created following the FAIR principles. \\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages\\n\\t\\n\\nSpanish\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Structure\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Fields\\n\\t\\n\\nIn the dataset_structure file.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Creation\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tInitial Data Collection and Normalization\\n\\t\\n\\nThis dataset was created‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/MariaIsabel/NFR_Spanish_requirements_classification."},
	{"name":"PROMISE_NFR_translated","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/MariaIsabel/PROMISE_NFR_translated","creator_name":"Maria Isabel Limaylla Lunarejo","creator_url":"https://huggingface.co/MariaIsabel","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nPublished version of PROMISE NFR translated to Spanish used for paper 'Requirements Classification Using FastText and BETO in Spanish Documents'\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages\\n\\t\\n\\nSpanish\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Structure\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Fields\\n\\t\\n\\nProject: Project's Identifier.\\nRequirement: Description of the software requirement.\\nLabel: Label of the requirement: F (functional requirement) and NF (non-functional requirement).\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Creation‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/MariaIsabel/PROMISE_NFR_translated."},
	{"name":"ProbaEstructura","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/JJFrancisco/ProbaEstructura","creator_name":"jose javier francisco marini","creator_url":"https://huggingface.co/JJFrancisco","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for [Dataset Name]\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\n[More Information Needed]\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSupported Tasks and Leaderboards\\n\\t\\n\\n[More Information Needed]\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages\\n\\t\\n\\n[More Information Needed]\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Structure\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Instances\\n\\t\\n\\n[More Information Needed]\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Fields\\n\\t\\n\\n[More Information Needed]\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Splits\\n\\t\\n\\n[More Information Needed]\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Creation\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tCuration Rationale\\n\\t\\n\\n[More‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/JJFrancisco/ProbaEstructura."},
	{"name":"SB10k","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Alienmaster/SB10k","creator_name":"Robert Geislinger","creator_url":"https://huggingface.co/Alienmaster","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tA Twitter corpus and benchmark resources for german sentiment analysis\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSource\\n\\t\\n\\nThe data is a snapshot from the SB10k Dataset.\\nThe snapshot was made by Oliver Guhr.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tCitation Information\\n\\t\\n\\nPaper\\n@inproceedings{cieliebak2017twitter,\\n  title={A twitter corpus and benchmark resources for german sentiment analysis},\\n  author={Cieliebak, Mark and Deriu, Jan Milan and Egger, Dominic and Uzdilli, Fatih},\\n  booktitle={5th International Workshop on Natural‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Alienmaster/SB10k."},
	{"name":"instruct-legal-refugiados-es","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/edumunozsala/instruct-legal-refugiados-es","creator_name":"Eduardo Mu√±oz Sala","creator_url":"https://huggingface.co/edumunozsala","description":"\\n    \\n\\nLegal Refugiados: Un dataset para QA en temas legales de refugio, asilo y protecci√≥n internacional.\\n\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nInstruction Question-Answering Legal Refugiados es una colecci√≥n de instrucciones extra√≠das de una gran cantidad de documentos legales del gobierno de Espa√±a, principalmente, y de otras instituciones de la UE y tambi√©n de otros pa√≠ses de habla hispana como M√©xico o Venezuela. Todos ellos est√°n relacionados con leyes y disposiciones legales sobre‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/edumunozsala/instruct-legal-refugiados-es."},
	{"name":"Hokchia","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/yjhuang01/Hokchia","creator_name":"Yijun Huang","creator_url":"https://huggingface.co/yjhuang01","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tHokchia Audio Dataset\\n\\t\\n\\nHokchia, or the Fuqing dialect, is a branch of Eastern Min Chinese spoken mainly in the Fuqing City of Fujian province, China. Unlike Hokkien, which is more widely recognized and spoken in various parts of Southeast Asia, Hokchia maintains its unique linguistic characteristics and is primarily used within the Fuqing community and its diaspora. This dialect is known for its distinct pronunciation, vocabulary, and grammatical structures compared to other Min‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/yjhuang01/Hokchia."},
	{"name":"EMERCOM-questions","keyword":"monolingual","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/nyuuzyou/EMERCOM-questions","creator_name":"nyuuzyou","creator_url":"https://huggingface.co/nyuuzyou","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for psi.mchs.gov.ru Questions\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThis dataset contains text-based consultations with Russia's Emergency Psychological Assistance EMERCOM, conducted through their online web portal. It includes the questions and concerns expressed by individuals seeking support, along with the guidance and advice provided by service psychologists. The dataset can be analyzed to understand the nature of anxieties faced by the public and the techniques‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/nyuuzyou/EMERCOM-questions."},
	{"name":"3dnews-articles","keyword":"monolingual","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/nyuuzyou/3dnews-articles","creator_name":"nyuuzyou","creator_url":"https://huggingface.co/nyuuzyou","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for 3DNews Articles\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThe dataset comprises news articles from the Russian technology website 3DNews, covering the period from 2003 to 2024. It covers the latest updates in the world of digital technology and insightful commentary from industry experts, spanning the years 2003 to 2024.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages\\n\\t\\n\\nThe dataset is mostly in Russian, but there may be other languages present.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Structure\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/nyuuzyou/3dnews-articles."},
	{"name":"NoticIA","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Iker/NoticIA","creator_name":"Iker Garc√≠a-Ferrero","creator_url":"https://huggingface.co/Iker","description":"\\n    \\n\\n\\n\\\"A Clickbait Article Summarization Dataset in Spanish.\\\"\\n\\nWe present NoticIA, a dataset consisting of 850 Spanish news articles featuring prominent clickbait headlines, each paired with high-quality, single-sentence generative summarizations written by humans.\\n\\nüìñ Paper: NoticIA: A Clickbait Article Summarization Dataset in Spanish\\nüíª Baseline Code: https://github.com/ikergarcia1996/NoticIA\\nü§ñ Pre Trained Models‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Iker/NoticIA."},
	{"name":"truthfull_qa-tr","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/malhajar/truthfull_qa-tr","creator_name":"Mohamad Alhajar","creator_url":"https://huggingface.co/malhajar","description":"This Dataset is part of a series of datasets aimed at advancing Turkish LLM Developments by establishing rigid Turkish benchmarks to evaluate the performance of LLM's Produced in the Turkish Language.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for truthful_qa-tr\\n\\t\\n\\nmalhajar/truthful_qa-tr is a translated version of truthful_qa aimed specifically to be used in the OpenLLMTurkishLeaderboard \\nDeveloped by: Mohamad Alhajar \\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nTruthfulQA is a benchmark to measure whether a language model‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/malhajar/truthfull_qa-tr."},
	{"name":"wikipedia_leipzig_de_2021","keyword":"monolingual","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Alienmaster/wikipedia_leipzig_de_2021","creator_name":"Robert Geislinger","creator_url":"https://huggingface.co/Alienmaster","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLeipzig Corpora Wikipedia 2021 German\\n\\t\\n\\nThis dataset contains different splits (between 10k and 1mio) from the german wikipedia 2021. The data were collected 2021.\\nEvery element in the dataset is labeled as \\\"neutral\\\".\\nThe source can be found here\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tCitation\\n\\t\\n\\n@inproceedings{goldhahn-etal-2012-building,\\n    title = \\\"Building Large Monolingual Dictionaries at the {L}eipzig Corpora Collection: From 100 to 200 Languages\\\",\\n    author = \\\"Goldhahn, Dirk  and\\n      Eckart‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Alienmaster/wikipedia_leipzig_de_2021."},
	{"name":"WikiSQE","keyword":"monolingual","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ando55/WikiSQE","creator_name":"Kenichiro Ando","creator_url":"https://huggingface.co/ando55","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for WikiSQE\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nWikiSQE: A Large-Scale Dataset for Sentence Quality Estimation in Wikipedia by Kenichiro Ando, Satoshi Sekine and Mamoru Komachi (AAAI 2024).\\nThe WikiSQE dataset is an English-language dataset containing over 3.4 million sentences from all edit histories of English Wikipedia. All sentences in the dataset are considered by Wikipedia editors to have poor quality in some aspect. The aspects of poor quality are classified into‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ando55/WikiSQE."},
	{"name":"WikiSQE_experiment","keyword":"monolingual","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ando55/WikiSQE_experiment","creator_name":"Kenichiro Ando","creator_url":"https://huggingface.co/ando55","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for CNN Dailymail Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nWikiSQE: A Large-Scale Dataset for Sentence Quality Estimation in Wikipedia by Kenichiro Ando, Satoshi Sekine and Mamoru Komachi (AAAI 2024).\\nThe WikiSQE Dataset is an English-language dataset containing over 3.4M sentences in Wikipedia. Dataset's sentences seem to be poor quality in some aspects by Wikipedia editors. The aspects of poor qualities are classified into 153 labels. This repository is a split for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ando55/WikiSQE_experiment."},
	{"name":"web-sentences-br","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/gweltou/web-sentences-br","creator_name":"Gweltaz Duval-Guennoc","creator_url":"https://huggingface.co/gweltou","description":"Breton sentences from the public web. Filtered and deduplicated.\\nMostly KLT orthography.\\nAround 1M words.\\n"},
	{"name":"imdb","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/pt-sk/imdb","creator_name":"Sathish Kumar","creator_url":"https://huggingface.co/pt-sk","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for \\\"imdb\\\"\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nLarge Movie Review Dataset.\\nThis is a dataset for binary sentiment classification containing substantially more data than previous benchmark datasets. We provide a set of 25,000 highly polar movie reviews for training, and 25,000 for testing. There is additional unlabeled data for use as well.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Structure\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Instances\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tplain_text\\n\\t\\n\\n\\nSize of downloaded dataset files: 84.13 MB‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/pt-sk/imdb."},
	{"name":"boolq_bn","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/hishab/boolq_bn","creator_name":"Hishab","creator_url":"https://huggingface.co/hishab","description":"\\n\\t\\n\\t\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nBoolQ Bangla (BN) is a question-answering dataset for yes/no questions, generated using GPT-4. The dataset contains 15,942 examples, with each entry consisting of a triplet: (question, passage, answer). The questions are naturally occurring, generated from unprompted and unconstrained settings. Input passages were sourced from Bangla Wikipedia, Banglapedia, and News Articles, and GPT-4 was used to generate corresponding yes/no questions with answers.\\nThe dataset was‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/hishab/boolq_bn."},
	{"name":"isafpressreleases","keyword":"monolingual","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/strickvl/isafpressreleases","creator_name":"Alex Strick van Linschoten","creator_url":"https://huggingface.co/strickvl","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tISAF Press Releases Dataset Description\\n\\t\\n\\n\\nHomepage: [N/A]\\nRepository: [N/A]\\nPaper: A Knock on the Door: 22 Months of ISAF Press Releases\\nPoint of Contact: Alex Strick van Linschoten (@strickvl)\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThe ISAF Press Releases dataset contains data used as the basis for the research\\npaper \\\"A Knock on the Door: 22 Months of ISAF Press Releases\\\". The dataset\\nprovides a comprehensive collection of press releases issued by the\\nInternational Security Assistance‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/strickvl/isafpressreleases."},
	{"name":"japan_diet_q_and_a_sessions_20k","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/notoxicpeople/japan_diet_q_and_a_sessions_20k","creator_name":"takashi miwa","creator_url":"https://huggingface.co/notoxicpeople","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tJapan Diet Q&A Sessions Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSummary\\n\\t\\n\\n\\nThis dataset was created by scraping the parliamentary questions and answers webpage. \\nAs of March 27, 2024, it includes 216 sessions.\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Fields\\n\\t\\n\\n\\nid: Consists of three parts. \\nThe initial alphabet indicates whether it is a question (a) or an answer (b).\\nThe next three digits represent the session number of the parliament.\\nThe last three digits are the question number within the parliament session.\\n\\n\\ntitle:‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/notoxicpeople/japan_diet_q_and_a_sessions_20k."},
	{"name":"code-action-sociale-familles","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/louisbrulenaudet/code-action-sociale-familles","creator_name":"Louis Brul√© Naudet","creator_url":"https://huggingface.co/louisbrulenaudet","description":"\\n\\t\\n\\t\\t\\n\\t\\tCode de l'action sociale et des familles, non-instruct (2025-03-10)\\n\\t\\n\\nThe objective of this project is to provide researchers, professionals and law students with simplified, up-to-date access to all French legal texts, enriched with a wealth of data to facilitate their integration into Community and European projects.\\nNormally, the data is refreshed daily on all legal codes, and aims to simplify the production of training sets and labeling pipelines for the development of free‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/louisbrulenaudet/code-action-sociale-familles."},
	{"name":"code-aviation-civile","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/louisbrulenaudet/code-aviation-civile","creator_name":"Louis Brul√© Naudet","creator_url":"https://huggingface.co/louisbrulenaudet","description":"\\n\\t\\n\\t\\t\\n\\t\\tCode de l'aviation civile, non-instruct (2025-03-10)\\n\\t\\n\\nThe objective of this project is to provide researchers, professionals and law students with simplified, up-to-date access to all French legal texts, enriched with a wealth of data to facilitate their integration into Community and European projects.\\nNormally, the data is refreshed daily on all legal codes, and aims to simplify the production of training sets and labeling pipelines for the development of free, open-source language‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/louisbrulenaudet/code-aviation-civile."},
	{"name":"code-cinema-image-animee","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/louisbrulenaudet/code-cinema-image-animee","creator_name":"Louis Brul√© Naudet","creator_url":"https://huggingface.co/louisbrulenaudet","description":"\\n\\t\\n\\t\\t\\n\\t\\tCode du cin√©ma et de l'image anim√©e, non-instruct (2025-03-10)\\n\\t\\n\\nThe objective of this project is to provide researchers, professionals and law students with simplified, up-to-date access to all French legal texts, enriched with a wealth of data to facilitate their integration into Community and European projects.\\nNormally, the data is refreshed daily on all legal codes, and aims to simplify the production of training sets and labeling pipelines for the development of free‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/louisbrulenaudet/code-cinema-image-animee."},
	{"name":"code-communes","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/louisbrulenaudet/code-communes","creator_name":"Louis Brul√© Naudet","creator_url":"https://huggingface.co/louisbrulenaudet","description":"\\n\\t\\n\\t\\t\\n\\t\\tCode des communes, non-instruct (2025-03-10)\\n\\t\\n\\nThe objective of this project is to provide researchers, professionals and law students with simplified, up-to-date access to all French legal texts, enriched with a wealth of data to facilitate their integration into Community and European projects.\\nNormally, the data is refreshed daily on all legal codes, and aims to simplify the production of training sets and labeling pipelines for the development of free, open-source language models‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/louisbrulenaudet/code-communes."},
	{"name":"code-communes-nouvelle-caledonie","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/louisbrulenaudet/code-communes-nouvelle-caledonie","creator_name":"Louis Brul√© Naudet","creator_url":"https://huggingface.co/louisbrulenaudet","description":"\\n\\t\\n\\t\\t\\n\\t\\tCode des communes de la Nouvelle-Cal√©donie, non-instruct (2025-03-10)\\n\\t\\n\\nThe objective of this project is to provide researchers, professionals and law students with simplified, up-to-date access to all French legal texts, enriched with a wealth of data to facilitate their integration into Community and European projects.\\nNormally, the data is refreshed daily on all legal codes, and aims to simplify the production of training sets and labeling pipelines for the development of free‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/louisbrulenaudet/code-communes-nouvelle-caledonie."},
	{"name":"code-defense","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/louisbrulenaudet/code-defense","creator_name":"Louis Brul√© Naudet","creator_url":"https://huggingface.co/louisbrulenaudet","description":"\\n\\t\\n\\t\\t\\n\\t\\tCode de la d√©fense, non-instruct (2025-03-10)\\n\\t\\n\\nThe objective of this project is to provide researchers, professionals and law students with simplified, up-to-date access to all French legal texts, enriched with a wealth of data to facilitate their integration into Community and European projects.\\nNormally, the data is refreshed daily on all legal codes, and aims to simplify the production of training sets and labeling pipelines for the development of free, open-source language models‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/louisbrulenaudet/code-defense."},
	{"name":"code-deontologie-architectes","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/louisbrulenaudet/code-deontologie-architectes","creator_name":"Louis Brul√© Naudet","creator_url":"https://huggingface.co/louisbrulenaudet","description":"\\n\\t\\n\\t\\t\\n\\t\\tCode de d√©ontologie des architectes, non-instruct (2025-03-10)\\n\\t\\n\\nThe objective of this project is to provide researchers, professionals and law students with simplified, up-to-date access to all French legal texts, enriched with a wealth of data to facilitate their integration into Community and European projects.\\nNormally, the data is refreshed daily on all legal codes, and aims to simplify the production of training sets and labeling pipelines for the development of free‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/louisbrulenaudet/code-deontologie-architectes."},
	{"name":"code-disciplinaire-penal-marine-marchande","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/louisbrulenaudet/code-disciplinaire-penal-marine-marchande","creator_name":"Louis Brul√© Naudet","creator_url":"https://huggingface.co/louisbrulenaudet","description":"\\n\\t\\n\\t\\t\\n\\t\\tCode disciplinaire et p√©nal de la marine marchande, non-instruct (2025-03-10)\\n\\t\\n\\nThe objective of this project is to provide researchers, professionals and law students with simplified, up-to-date access to all French legal texts, enriched with a wealth of data to facilitate their integration into Community and European projects.\\nNormally, the data is refreshed daily on all legal codes, and aims to simplify the production of training sets and labeling pipelines for the development of‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/louisbrulenaudet/code-disciplinaire-penal-marine-marchande."},
	{"name":"code-domaine-etat","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/louisbrulenaudet/code-domaine-etat","creator_name":"Louis Brul√© Naudet","creator_url":"https://huggingface.co/louisbrulenaudet","description":"\\n\\t\\n\\t\\t\\n\\t\\tCode du domaine de l'Etat, non-instruct (2025-03-10)\\n\\t\\n\\nThe objective of this project is to provide researchers, professionals and law students with simplified, up-to-date access to all French legal texts, enriched with a wealth of data to facilitate their integration into Community and European projects.\\nNormally, the data is refreshed daily on all legal codes, and aims to simplify the production of training sets and labeling pipelines for the development of free, open-source language‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/louisbrulenaudet/code-domaine-etat."},
	{"name":"code-domaine-etat-collectivites-mayotte","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/louisbrulenaudet/code-domaine-etat-collectivites-mayotte","creator_name":"Louis Brul√© Naudet","creator_url":"https://huggingface.co/louisbrulenaudet","description":"\\n\\t\\n\\t\\t\\n\\t\\tCode du domaine de l'Etat et des collectivit√©s publiques applicable √† la collectivit√© territoriale de Mayotte, non-instruct (2025-03-10)\\n\\t\\n\\nThe objective of this project is to provide researchers, professionals and law students with simplified, up-to-date access to all French legal texts, enriched with a wealth of data to facilitate their integration into Community and European projects.\\nNormally, the data is refreshed daily on all legal codes, and aims to simplify the production of‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/louisbrulenaudet/code-domaine-etat-collectivites-mayotte."},
	{"name":"code-domaine-public-fluvial-navigation-interieure","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/louisbrulenaudet/code-domaine-public-fluvial-navigation-interieure","creator_name":"Louis Brul√© Naudet","creator_url":"https://huggingface.co/louisbrulenaudet","description":"\\n\\t\\n\\t\\t\\n\\t\\tCode du domaine public fluvial et de la navigation int√©rieure, non-instruct (2025-03-10)\\n\\t\\n\\nThe objective of this project is to provide researchers, professionals and law students with simplified, up-to-date access to all French legal texts, enriched with a wealth of data to facilitate their integration into Community and European projects.\\nNormally, the data is refreshed daily on all legal codes, and aims to simplify the production of training sets and labeling pipelines for the‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/louisbrulenaudet/code-domaine-public-fluvial-navigation-interieure."},
	{"name":"code-douanes-mayotte","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/louisbrulenaudet/code-douanes-mayotte","creator_name":"Louis Brul√© Naudet","creator_url":"https://huggingface.co/louisbrulenaudet","description":"\\n\\t\\n\\t\\t\\n\\t\\tCode des douanes de Mayotte, non-instruct (2025-03-10)\\n\\t\\n\\nThe objective of this project is to provide researchers, professionals and law students with simplified, up-to-date access to all French legal texts, enriched with a wealth of data to facilitate their integration into Community and European projects.\\nNormally, the data is refreshed daily on all legal codes, and aims to simplify the production of training sets and labeling pipelines for the development of free, open-source‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/louisbrulenaudet/code-douanes-mayotte."},
	{"name":"code-electoral","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/louisbrulenaudet/code-electoral","creator_name":"Louis Brul√© Naudet","creator_url":"https://huggingface.co/louisbrulenaudet","description":"\\n\\t\\n\\t\\t\\n\\t\\tCode √©lectoral, non-instruct (2025-03-10)\\n\\t\\n\\nThe objective of this project is to provide researchers, professionals and law students with simplified, up-to-date access to all French legal texts, enriched with a wealth of data to facilitate their integration into Community and European projects.\\nNormally, the data is refreshed daily on all legal codes, and aims to simplify the production of training sets and labeling pipelines for the development of free, open-source language models‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/louisbrulenaudet/code-electoral."},
	{"name":"code-energie","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/louisbrulenaudet/code-energie","creator_name":"Louis Brul√© Naudet","creator_url":"https://huggingface.co/louisbrulenaudet","description":"\\n\\t\\n\\t\\t\\n\\t\\tCode de l'√©nergie, non-instruct (2025-03-10)\\n\\t\\n\\nThe objective of this project is to provide researchers, professionals and law students with simplified, up-to-date access to all French legal texts, enriched with a wealth of data to facilitate their integration into Community and European projects.\\nNormally, the data is refreshed daily on all legal codes, and aims to simplify the production of training sets and labeling pipelines for the development of free, open-source language models‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/louisbrulenaudet/code-energie."},
	{"name":"code-entree-sejour-etrangers-droit-asile","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/louisbrulenaudet/code-entree-sejour-etrangers-droit-asile","creator_name":"Louis Brul√© Naudet","creator_url":"https://huggingface.co/louisbrulenaudet","description":"\\n\\t\\n\\t\\t\\n\\t\\tCode de l'entr√©e et du s√©jour des √©trangers et du droit d'asile, non-instruct (2025-03-10)\\n\\t\\n\\nThe objective of this project is to provide researchers, professionals and law students with simplified, up-to-date access to all French legal texts, enriched with a wealth of data to facilitate their integration into Community and European projects.\\nNormally, the data is refreshed daily on all legal codes, and aims to simplify the production of training sets and labeling pipelines for the‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/louisbrulenaudet/code-entree-sejour-etrangers-droit-asile."},
	{"name":"code-expropriation-utilite-publique","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/louisbrulenaudet/code-expropriation-utilite-publique","creator_name":"Louis Brul√© Naudet","creator_url":"https://huggingface.co/louisbrulenaudet","description":"\\n\\t\\n\\t\\t\\n\\t\\tCode de l'expropriation pour cause d'utilit√© publique, non-instruct (2025-03-10)\\n\\t\\n\\nThe objective of this project is to provide researchers, professionals and law students with simplified, up-to-date access to all French legal texts, enriched with a wealth of data to facilitate their integration into Community and European projects.\\nNormally, the data is refreshed daily on all legal codes, and aims to simplify the production of training sets and labeling pipelines for the development‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/louisbrulenaudet/code-expropriation-utilite-publique."},
	{"name":"code-famille-aide-sociale","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/louisbrulenaudet/code-famille-aide-sociale","creator_name":"Louis Brul√© Naudet","creator_url":"https://huggingface.co/louisbrulenaudet","description":"\\n\\t\\n\\t\\t\\n\\t\\tCode de la famille et de l'aide sociale, non-instruct (2025-03-10)\\n\\t\\n\\nThe objective of this project is to provide researchers, professionals and law students with simplified, up-to-date access to all French legal texts, enriched with a wealth of data to facilitate their integration into Community and European projects.\\nNormally, the data is refreshed daily on all legal codes, and aims to simplify the production of training sets and labeling pipelines for the development of free‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/louisbrulenaudet/code-famille-aide-sociale."},
	{"name":"code-forestier-nouveau","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/louisbrulenaudet/code-forestier-nouveau","creator_name":"Louis Brul√© Naudet","creator_url":"https://huggingface.co/louisbrulenaudet","description":"\\n\\t\\n\\t\\t\\n\\t\\tCode forestier (nouveau), non-instruct (2025-03-10)\\n\\t\\n\\nThe objective of this project is to provide researchers, professionals and law students with simplified, up-to-date access to all French legal texts, enriched with a wealth of data to facilitate their integration into Community and European projects.\\nNormally, the data is refreshed daily on all legal codes, and aims to simplify the production of training sets and labeling pipelines for the development of free, open-source language‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/louisbrulenaudet/code-forestier-nouveau."},
	{"name":"code-fonction-publique","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/louisbrulenaudet/code-fonction-publique","creator_name":"Louis Brul√© Naudet","creator_url":"https://huggingface.co/louisbrulenaudet","description":"\\n\\t\\n\\t\\t\\n\\t\\tCode g√©n√©ral de la fonction publique, non-instruct (2025-03-10)\\n\\t\\n\\nThe objective of this project is to provide researchers, professionals and law students with simplified, up-to-date access to all French legal texts, enriched with a wealth of data to facilitate their integration into Community and European projects.\\nNormally, the data is refreshed daily on all legal codes, and aims to simplify the production of training sets and labeling pipelines for the development of free‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/louisbrulenaudet/code-fonction-publique."},
	{"name":"code-propriete-personnes-publiques","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/louisbrulenaudet/code-propriete-personnes-publiques","creator_name":"Louis Brul√© Naudet","creator_url":"https://huggingface.co/louisbrulenaudet","description":"\\n\\t\\n\\t\\t\\n\\t\\tCode g√©n√©ral de la propri√©t√© des personnes publiques, non-instruct (2025-03-10)\\n\\t\\n\\nThe objective of this project is to provide researchers, professionals and law students with simplified, up-to-date access to all French legal texts, enriched with a wealth of data to facilitate their integration into Community and European projects.\\nNormally, the data is refreshed daily on all legal codes, and aims to simplify the production of training sets and labeling pipelines for the development of‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/louisbrulenaudet/code-propriete-personnes-publiques."},
	{"name":"code-collectivites-territoriales","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/louisbrulenaudet/code-collectivites-territoriales","creator_name":"Louis Brul√© Naudet","creator_url":"https://huggingface.co/louisbrulenaudet","description":"\\n\\t\\n\\t\\t\\n\\t\\tCode g√©n√©ral des collectivit√©s territoriales, non-instruct (2025-03-10)\\n\\t\\n\\nThe objective of this project is to provide researchers, professionals and law students with simplified, up-to-date access to all French legal texts, enriched with a wealth of data to facilitate their integration into Community and European projects.\\nNormally, the data is refreshed daily on all legal codes, and aims to simplify the production of training sets and labeling pipelines for the development of free‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/louisbrulenaudet/code-collectivites-territoriales."},
	{"name":"code-impots","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/louisbrulenaudet/code-impots","creator_name":"Louis Brul√© Naudet","creator_url":"https://huggingface.co/louisbrulenaudet","description":"\\n\\t\\n\\t\\t\\n\\t\\tCode g√©n√©ral des imp√¥ts, non-instruct (2025-03-10)\\n\\t\\n\\nThe objective of this project is to provide researchers, professionals and law students with simplified, up-to-date access to all French legal texts, enriched with a wealth of data to facilitate their integration into Community and European projects.\\nNormally, the data is refreshed daily on all legal codes, and aims to simplify the production of training sets and labeling pipelines for the development of free, open-source language‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/louisbrulenaudet/code-impots."},
	{"name":"code-impots-annexe-i","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/louisbrulenaudet/code-impots-annexe-i","creator_name":"Louis Brul√© Naudet","creator_url":"https://huggingface.co/louisbrulenaudet","description":"\\n\\t\\n\\t\\t\\n\\t\\tCode g√©n√©ral des imp√¥ts, annexe I, non-instruct (2025-03-10)\\n\\t\\n\\nThe objective of this project is to provide researchers, professionals and law students with simplified, up-to-date access to all French legal texts, enriched with a wealth of data to facilitate their integration into Community and European projects.\\nNormally, the data is refreshed daily on all legal codes, and aims to simplify the production of training sets and labeling pipelines for the development of free, open-source‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/louisbrulenaudet/code-impots-annexe-i."},
	{"name":"code-impots-annexe-ii","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/louisbrulenaudet/code-impots-annexe-ii","creator_name":"Louis Brul√© Naudet","creator_url":"https://huggingface.co/louisbrulenaudet","description":"\\n\\t\\n\\t\\t\\n\\t\\tCode g√©n√©ral des imp√¥ts, annexe II, non-instruct (2025-03-10)\\n\\t\\n\\nThe objective of this project is to provide researchers, professionals and law students with simplified, up-to-date access to all French legal texts, enriched with a wealth of data to facilitate their integration into Community and European projects.\\nNormally, the data is refreshed daily on all legal codes, and aims to simplify the production of training sets and labeling pipelines for the development of free, open-source‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/louisbrulenaudet/code-impots-annexe-ii."},
	{"name":"code-impots-annexe-iii","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/louisbrulenaudet/code-impots-annexe-iii","creator_name":"Louis Brul√© Naudet","creator_url":"https://huggingface.co/louisbrulenaudet","description":"\\n\\t\\n\\t\\t\\n\\t\\tCode g√©n√©ral des imp√¥ts, annexe III, non-instruct (2025-03-10)\\n\\t\\n\\nThe objective of this project is to provide researchers, professionals and law students with simplified, up-to-date access to all French legal texts, enriched with a wealth of data to facilitate their integration into Community and European projects.\\nNormally, the data is refreshed daily on all legal codes, and aims to simplify the production of training sets and labeling pipelines for the development of free‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/louisbrulenaudet/code-impots-annexe-iii."},
	{"name":"code-impots-annexe-iv","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/louisbrulenaudet/code-impots-annexe-iv","creator_name":"Louis Brul√© Naudet","creator_url":"https://huggingface.co/louisbrulenaudet","description":"\\n\\t\\n\\t\\t\\n\\t\\tCode g√©n√©ral des imp√¥ts, annexe IV, non-instruct (2025-03-10)\\n\\t\\n\\nThe objective of this project is to provide researchers, professionals and law students with simplified, up-to-date access to all French legal texts, enriched with a wealth of data to facilitate their integration into Community and European projects.\\nNormally, the data is refreshed daily on all legal codes, and aims to simplify the production of training sets and labeling pipelines for the development of free, open-source‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/louisbrulenaudet/code-impots-annexe-iv."},
	{"name":"code-impositions-biens-services","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/louisbrulenaudet/code-impositions-biens-services","creator_name":"Louis Brul√© Naudet","creator_url":"https://huggingface.co/louisbrulenaudet","description":"\\n\\t\\n\\t\\t\\n\\t\\tCode des impositions sur les biens et services, non-instruct (2025-03-10)\\n\\t\\n\\nThe objective of this project is to provide researchers, professionals and law students with simplified, up-to-date access to all French legal texts, enriched with a wealth of data to facilitate their integration into Community and European projects.\\nNormally, the data is refreshed daily on all legal codes, and aims to simplify the production of training sets and labeling pipelines for the development of free‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/louisbrulenaudet/code-impositions-biens-services."},
	{"name":"code-instruments-monetaires-medailles","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/louisbrulenaudet/code-instruments-monetaires-medailles","creator_name":"Louis Brul√© Naudet","creator_url":"https://huggingface.co/louisbrulenaudet","description":"\\n\\t\\n\\t\\t\\n\\t\\tCode des instruments mon√©taires et des m√©dailles, non-instruct (2025-03-10)\\n\\t\\n\\nThe objective of this project is to provide researchers, professionals and law students with simplified, up-to-date access to all French legal texts, enriched with a wealth of data to facilitate their integration into Community and European projects.\\nNormally, the data is refreshed daily on all legal codes, and aims to simplify the production of training sets and labeling pipelines for the development of‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/louisbrulenaudet/code-instruments-monetaires-medailles."},
	{"name":"code-juridictions-financieres","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/louisbrulenaudet/code-juridictions-financieres","creator_name":"Louis Brul√© Naudet","creator_url":"https://huggingface.co/louisbrulenaudet","description":"\\n\\t\\n\\t\\t\\n\\t\\tCode des juridictions financi√®res, non-instruct (2025-03-10)\\n\\t\\n\\nThe objective of this project is to provide researchers, professionals and law students with simplified, up-to-date access to all French legal texts, enriched with a wealth of data to facilitate their integration into Community and European projects.\\nNormally, the data is refreshed daily on all legal codes, and aims to simplify the production of training sets and labeling pipelines for the development of free, open-source‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/louisbrulenaudet/code-juridictions-financieres."},
	{"name":"code-justice-militaire-nouveau","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/louisbrulenaudet/code-justice-militaire-nouveau","creator_name":"Louis Brul√© Naudet","creator_url":"https://huggingface.co/louisbrulenaudet","description":"\\n\\t\\n\\t\\t\\n\\t\\tCode de justice militaire (nouveau), non-instruct (2025-03-10)\\n\\t\\n\\nThe objective of this project is to provide researchers, professionals and law students with simplified, up-to-date access to all French legal texts, enriched with a wealth of data to facilitate their integration into Community and European projects.\\nNormally, the data is refreshed daily on all legal codes, and aims to simplify the production of training sets and labeling pipelines for the development of free‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/louisbrulenaudet/code-justice-militaire-nouveau."},
	{"name":"code-justice-penale-mineurs","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/louisbrulenaudet/code-justice-penale-mineurs","creator_name":"Louis Brul√© Naudet","creator_url":"https://huggingface.co/louisbrulenaudet","description":"\\n\\t\\n\\t\\t\\n\\t\\tCode de la justice p√©nale des mineurs, non-instruct (2025-03-10)\\n\\t\\n\\nThe objective of this project is to provide researchers, professionals and law students with simplified, up-to-date access to all French legal texts, enriched with a wealth of data to facilitate their integration into Community and European projects.\\nNormally, the data is refreshed daily on all legal codes, and aims to simplify the production of training sets and labeling pipelines for the development of free‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/louisbrulenaudet/code-justice-penale-mineurs."},
	{"name":"code-legion-honneur-medaille-militaire-ordre-national-merite","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/louisbrulenaudet/code-legion-honneur-medaille-militaire-ordre-national-merite","creator_name":"Louis Brul√© Naudet","creator_url":"https://huggingface.co/louisbrulenaudet","description":"\\n\\t\\n\\t\\t\\n\\t\\tCode de la L√©gion d'honneur, de la M√©daille militaire et de l'ordre national du M√©rite, non-instruct (2025-03-10)\\n\\t\\n\\nThe objective of this project is to provide researchers, professionals and law students with simplified, up-to-date access to all French legal texts, enriched with a wealth of data to facilitate their integration into Community and European projects.\\nNormally, the data is refreshed daily on all legal codes, and aims to simplify the production of training sets and‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/louisbrulenaudet/code-legion-honneur-medaille-militaire-ordre-national-merite."},
	{"name":"livre-procedures-fiscales","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/louisbrulenaudet/livre-procedures-fiscales","creator_name":"Louis Brul√© Naudet","creator_url":"https://huggingface.co/louisbrulenaudet","description":"\\n\\t\\n\\t\\t\\n\\t\\tLivre des proc√©dures fiscales, non-instruct (2025-03-10)\\n\\t\\n\\nThe objective of this project is to provide researchers, professionals and law students with simplified, up-to-date access to all French legal texts, enriched with a wealth of data to facilitate their integration into Community and European projects.\\nNormally, the data is refreshed daily on all legal codes, and aims to simplify the production of training sets and labeling pipelines for the development of free, open-source‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/louisbrulenaudet/livre-procedures-fiscales."},
	{"name":"code-minier","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/louisbrulenaudet/code-minier","creator_name":"Louis Brul√© Naudet","creator_url":"https://huggingface.co/louisbrulenaudet","description":"\\n\\t\\n\\t\\t\\n\\t\\tCode minier, non-instruct (2025-03-10)\\n\\t\\n\\nThe objective of this project is to provide researchers, professionals and law students with simplified, up-to-date access to all French legal texts, enriched with a wealth of data to facilitate their integration into Community and European projects.\\nNormally, the data is refreshed daily on all legal codes, and aims to simplify the production of training sets and labeling pipelines for the development of free, open-source language models based‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/louisbrulenaudet/code-minier."},
	{"name":"code-minier-nouveau","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/louisbrulenaudet/code-minier-nouveau","creator_name":"Louis Brul√© Naudet","creator_url":"https://huggingface.co/louisbrulenaudet","description":"\\n\\t\\n\\t\\t\\n\\t\\tCode minier (nouveau), non-instruct (2025-03-10)\\n\\t\\n\\nThe objective of this project is to provide researchers, professionals and law students with simplified, up-to-date access to all French legal texts, enriched with a wealth of data to facilitate their integration into Community and European projects.\\nNormally, the data is refreshed daily on all legal codes, and aims to simplify the production of training sets and labeling pipelines for the development of free, open-source language‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/louisbrulenaudet/code-minier-nouveau."},
	{"name":"code-organisation-judiciaire","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/louisbrulenaudet/code-organisation-judiciaire","creator_name":"Louis Brul√© Naudet","creator_url":"https://huggingface.co/louisbrulenaudet","description":"\\n\\t\\n\\t\\t\\n\\t\\tCode de l'organisation judiciaire, non-instruct (2025-03-10)\\n\\t\\n\\nThe objective of this project is to provide researchers, professionals and law students with simplified, up-to-date access to all French legal texts, enriched with a wealth of data to facilitate their integration into Community and European projects.\\nNormally, the data is refreshed daily on all legal codes, and aims to simplify the production of training sets and labeling pipelines for the development of free, open-source‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/louisbrulenaudet/code-organisation-judiciaire."},
	{"name":"code-patrimoine","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/louisbrulenaudet/code-patrimoine","creator_name":"Louis Brul√© Naudet","creator_url":"https://huggingface.co/louisbrulenaudet","description":"\\n\\t\\n\\t\\t\\n\\t\\tCode du patrimoine, non-instruct (2025-03-10)\\n\\t\\n\\nThe objective of this project is to provide researchers, professionals and law students with simplified, up-to-date access to all French legal texts, enriched with a wealth of data to facilitate their integration into Community and European projects.\\nNormally, the data is refreshed daily on all legal codes, and aims to simplify the production of training sets and labeling pipelines for the development of free, open-source language models‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/louisbrulenaudet/code-patrimoine."},
	{"name":"code-penitentiaire","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/louisbrulenaudet/code-penitentiaire","creator_name":"Louis Brul√© Naudet","creator_url":"https://huggingface.co/louisbrulenaudet","description":"\\n\\t\\n\\t\\t\\n\\t\\tCode p√©nitentiaire, non-instruct (2025-03-10)\\n\\t\\n\\nThe objective of this project is to provide researchers, professionals and law students with simplified, up-to-date access to all French legal texts, enriched with a wealth of data to facilitate their integration into Community and European projects.\\nNormally, the data is refreshed daily on all legal codes, and aims to simplify the production of training sets and labeling pipelines for the development of free, open-source language models‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/louisbrulenaudet/code-penitentiaire."},
	{"name":"code-pensions-civiles-militaires-retraite","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/louisbrulenaudet/code-pensions-civiles-militaires-retraite","creator_name":"Louis Brul√© Naudet","creator_url":"https://huggingface.co/louisbrulenaudet","description":"\\n\\t\\n\\t\\t\\n\\t\\tCode des pensions civiles et militaires de retraite, non-instruct (2025-03-10)\\n\\t\\n\\nThe objective of this project is to provide researchers, professionals and law students with simplified, up-to-date access to all French legal texts, enriched with a wealth of data to facilitate their integration into Community and European projects.\\nNormally, the data is refreshed daily on all legal codes, and aims to simplify the production of training sets and labeling pipelines for the development of‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/louisbrulenaudet/code-pensions-civiles-militaires-retraite."},
	{"name":"code-pensions-retraite-marins-francais-commerce-peche-plaisance","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/louisbrulenaudet/code-pensions-retraite-marins-francais-commerce-peche-plaisance","creator_name":"Louis Brul√© Naudet","creator_url":"https://huggingface.co/louisbrulenaudet","description":"\\n\\t\\n\\t\\t\\n\\t\\tCode des pensions de retraite des marins fran√ßais du commerce, de p√™che ou de plaisance, non-instruct (2025-03-10)\\n\\t\\n\\nThe objective of this project is to provide researchers, professionals and law students with simplified, up-to-date access to all French legal texts, enriched with a wealth of data to facilitate their integration into Community and European projects.\\nNormally, the data is refreshed daily on all legal codes, and aims to simplify the production of training sets and‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/louisbrulenaudet/code-pensions-retraite-marins-francais-commerce-peche-plaisance."},
	{"name":"code-pensions-militaires-invalidite-victimes-guerre","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/louisbrulenaudet/code-pensions-militaires-invalidite-victimes-guerre","creator_name":"Louis Brul√© Naudet","creator_url":"https://huggingface.co/louisbrulenaudet","description":"\\n\\t\\n\\t\\t\\n\\t\\tCode des pensions militaires d'invalidit√© et des victimes de guerre, non-instruct (2025-03-10)\\n\\t\\n\\nThe objective of this project is to provide researchers, professionals and law students with simplified, up-to-date access to all French legal texts, enriched with a wealth of data to facilitate their integration into Community and European projects.\\nNormally, the data is refreshed daily on all legal codes, and aims to simplify the production of training sets and labeling pipelines for the‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/louisbrulenaudet/code-pensions-militaires-invalidite-victimes-guerre."},
	{"name":"code-ports-maritimes","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/louisbrulenaudet/code-ports-maritimes","creator_name":"Louis Brul√© Naudet","creator_url":"https://huggingface.co/louisbrulenaudet","description":"\\n\\t\\n\\t\\t\\n\\t\\tCode des ports maritimes, non-instruct (2025-03-10)\\n\\t\\n\\nThe objective of this project is to provide researchers, professionals and law students with simplified, up-to-date access to all French legal texts, enriched with a wealth of data to facilitate their integration into Community and European projects.\\nNormally, the data is refreshed daily on all legal codes, and aims to simplify the production of training sets and labeling pipelines for the development of free, open-source language‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/louisbrulenaudet/code-ports-maritimes."},
	{"name":"code-procedure-penale","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/louisbrulenaudet/code-procedure-penale","creator_name":"Louis Brul√© Naudet","creator_url":"https://huggingface.co/louisbrulenaudet","description":"\\n\\t\\n\\t\\t\\n\\t\\tCode de proc√©dure p√©nale, non-instruct (2025-03-10)\\n\\t\\n\\nThe objective of this project is to provide researchers, professionals and law students with simplified, up-to-date access to all French legal texts, enriched with a wealth of data to facilitate their integration into Community and European projects.\\nNormally, the data is refreshed daily on all legal codes, and aims to simplify the production of training sets and labeling pipelines for the development of free, open-source language‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/louisbrulenaudet/code-procedure-penale."},
	{"name":"code-recherche","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/louisbrulenaudet/code-recherche","creator_name":"Louis Brul√© Naudet","creator_url":"https://huggingface.co/louisbrulenaudet","description":"\\n\\t\\n\\t\\t\\n\\t\\tCode de la recherche, non-instruct (2025-03-10)\\n\\t\\n\\nThe objective of this project is to provide researchers, professionals and law students with simplified, up-to-date access to all French legal texts, enriched with a wealth of data to facilitate their integration into Community and European projects.\\nNormally, the data is refreshed daily on all legal codes, and aims to simplify the production of training sets and labeling pipelines for the development of free, open-source language‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/louisbrulenaudet/code-recherche."},
	{"name":"code-rural-ancien","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/louisbrulenaudet/code-rural-ancien","creator_name":"Louis Brul√© Naudet","creator_url":"https://huggingface.co/louisbrulenaudet","description":"\\n\\t\\n\\t\\t\\n\\t\\tCode rural (ancien), non-instruct (2025-03-10)\\n\\t\\n\\nThe objective of this project is to provide researchers, professionals and law students with simplified, up-to-date access to all French legal texts, enriched with a wealth of data to facilitate their integration into Community and European projects.\\nNormally, the data is refreshed daily on all legal codes, and aims to simplify the production of training sets and labeling pipelines for the development of free, open-source language‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/louisbrulenaudet/code-rural-ancien."},
	{"name":"code-service-national","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/louisbrulenaudet/code-service-national","creator_name":"Louis Brul√© Naudet","creator_url":"https://huggingface.co/louisbrulenaudet","description":"\\n\\t\\n\\t\\t\\n\\t\\tCode du service national, non-instruct (2025-03-10)\\n\\t\\n\\nThe objective of this project is to provide researchers, professionals and law students with simplified, up-to-date access to all French legal texts, enriched with a wealth of data to facilitate their integration into Community and European projects.\\nNormally, the data is refreshed daily on all legal codes, and aims to simplify the production of training sets and labeling pipelines for the development of free, open-source language‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/louisbrulenaudet/code-service-national."},
	{"name":"code-tourisme","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/louisbrulenaudet/code-tourisme","creator_name":"Louis Brul√© Naudet","creator_url":"https://huggingface.co/louisbrulenaudet","description":"\\n\\t\\n\\t\\t\\n\\t\\tCode du tourisme, non-instruct (2025-03-10)\\n\\t\\n\\nThe objective of this project is to provide researchers, professionals and law students with simplified, up-to-date access to all French legal texts, enriched with a wealth of data to facilitate their integration into Community and European projects.\\nNormally, the data is refreshed daily on all legal codes, and aims to simplify the production of training sets and labeling pipelines for the development of free, open-source language models‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/louisbrulenaudet/code-tourisme."},
	{"name":"code-travail-maritime","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/louisbrulenaudet/code-travail-maritime","creator_name":"Louis Brul√© Naudet","creator_url":"https://huggingface.co/louisbrulenaudet","description":"\\n\\t\\n\\t\\t\\n\\t\\tCode du travail maritime, non-instruct (2025-03-10)\\n\\t\\n\\nThe objective of this project is to provide researchers, professionals and law students with simplified, up-to-date access to all French legal texts, enriched with a wealth of data to facilitate their integration into Community and European projects.\\nNormally, the data is refreshed daily on all legal codes, and aims to simplify the production of training sets and labeling pipelines for the development of free, open-source language‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/louisbrulenaudet/code-travail-maritime."},
	{"name":"code-voirie-routiere","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/louisbrulenaudet/code-voirie-routiere","creator_name":"Louis Brul√© Naudet","creator_url":"https://huggingface.co/louisbrulenaudet","description":"\\n\\t\\n\\t\\t\\n\\t\\tCode de la voirie routi√®re, non-instruct (2025-03-10)\\n\\t\\n\\nThe objective of this project is to provide researchers, professionals and law students with simplified, up-to-date access to all French legal texts, enriched with a wealth of data to facilitate their integration into Community and European projects.\\nNormally, the data is refreshed daily on all legal codes, and aims to simplify the production of training sets and labeling pipelines for the development of free, open-source‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/louisbrulenaudet/code-voirie-routiere."},
	{"name":"ai2_arc_ita","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/RiTA-nlp/ai2_arc_ita","creator_name":"Risorse per la Lingua Italiana","creator_url":"https://huggingface.co/RiTA-nlp","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Ai2 ARC (ita)\\n\\t\\n\\n\\n\\nThis dataset is a machine-translated version of Ai2 ARC into Italian.\\n\\nLicensed under CC-BY 4.0\\nTranslated with TowerInstruct-7B-v0.2\\nMore details and code used for translation will follow shortly.\\n\\nThe rest of the page is WIP :)\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Details\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\n\\n\\n\\n\\nCurated by: [More Information Needed]\\nFunded by [optional]: [More Information Needed]\\nShared by [optional]: [More Information Needed]\\nLanguage(s)‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/RiTA-nlp/ai2_arc_ita."},
	{"name":"tt-crawl","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/yasalma/tt-crawl","creator_name":"Yasalma","creator_url":"https://huggingface.co/yasalma","description":"\\n\\t\\n\\t\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nIn an effort to democratize research on low-resource languages, we release TatarCrawl dataset, a web news corpus consisting of materials from nearly 15 unique sources in the Tatar Language.\\nTo load and use dataset, run this script:\\nfrom datasets import load_dataset\\n\\ntt_crawl=load_dataset(\\\"neurotatarlar/tt-crawl\\\")\\n\\n"},
	{"name":"mnist3d","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/cristiano-pizzamiglio/mnist3d","creator_name":"Cristiano Pizzamiglio","creator_url":"https://huggingface.co/cristiano-pizzamiglio","description":"\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for MNIST3D\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThe MNIST3D dataset consists of 70,000 point clouds of handwritten digits generated \\nby converting the images from the original MNIST dataset.\\nEach point cloud has 193 points.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages\\n\\t\\n\\nEnglish\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Structure\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Splits\\n\\t\\n\\nThe data is split into training and test set. The original data split of the MNIST \\ndataset is preserved.‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/cristiano-pizzamiglio/mnist3d."},
	{"name":"cmc-posts","keyword":"monolingual","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/nyuuzyou/cmc-posts","creator_name":"nyuuzyou","creator_url":"https://huggingface.co/nyuuzyou","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Coinmarketcap Posts\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThis dataset is a collection of posts from Coinmarketcap, a popular cryptocurrency platform. It includes approximately 1 million posts from February 24, 2022. However, a significant portion of the posts are spam, making this dataset ideal for spam detection.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Structure\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Fields\\n\\t\\n\\nThis dataset includes the following fields:\\n\\nid: Identifier for the post (integer)\\nusername:‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/nyuuzyou/cmc-posts."},
	{"name":"NextGenBench","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/KaraKaraWitch/NextGenBench","creator_name":"KaraKaraWitch","creator_url":"https://huggingface.co/KaraKaraWitch","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Next Generation Benchmark\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThis is a multitask test consisting of only questions (some are MCQ) from various branches of knowledge. Specifically the following topics:\\nAbstract Algebra\\nAnatomy\\nAstronomy\\nBusiness Ethics\\nClinical Knowledge\\nPrimary School Biology\\nPrimary School Chemistry\\nPrimary School Physics\\nPrimary School Math\\nPrimary School English\\nPrimary School Science\\nPrimary School Computer Science\\nComputer Security\\nDaily‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/KaraKaraWitch/NextGenBench."},
	{"name":"test","keyword":"monolingual","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/haebo1/test","creator_name":"Hyunho Yang","creator_url":"https://huggingface.co/haebo1","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for KoBEST\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nKoBEST is a Korean benchmark suite consists of 5 natural language understanding tasks that requires advanced knowledge in Korean.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSupported Tasks and Leaderboards\\n\\t\\n\\nBoolean Question Answering, Choice of Plausible Alternatives, Words-in-Context, HellaSwag, Sentiment Negation Recognition\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages\\n\\t\\n\\nko-KR\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Structure\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Instances\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tKB-BoolQ\\n\\t\\n\\nAn example‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/haebo1/test."},
	{"name":"moroccan-darija-youtube-subtitles","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/bourbouh/moroccan-darija-youtube-subtitles","creator_name":"Hamza Bourbouh","creator_url":"https://huggingface.co/bourbouh","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tMoroccan Darija YouTube Subtitles Dataset\\n\\t\\n\\nThis dataset contains subtitles from YouTube videos in Moroccan Darija, a colloquial Arabic dialect spoken in Morocco. The subtitles were collected from several popular Moroccan YouTube channels, providing a diverse set of transcriptions in the Darija language.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThe dataset is provided as a CSV file, where each row represents a YouTube video and contains the following columns:\\n\\nvideo_id: The unique‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/bourbouh/moroccan-darija-youtube-subtitles."},
	{"name":"wikipedia-br-20240325","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/gweltou/wikipedia-br-20240325","creator_name":"Gweltaz Duval-Guennoc","creator_url":"https://huggingface.co/gweltou","description":"A corpus of sentences extracted for the Breton Wikipedia (cirrus dump).\\nThe sentences were filtered so that only Breton sentences were kept.\\nPlease note that the sentence splitting algorithm is far from perfect, so many sentences will appear incorrect or incomplete.\\n"},
	{"name":"TrGLUE","keyword":"monolingual","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/turkish-nlp-suite/TrGLUE","creator_name":"Turkish NLP Suite","creator_url":"https://huggingface.co/turkish-nlp-suite","description":"\\n\\t\\n\\t\\t\\n\\t\\tTrGLUE - A Natural Language Understanding Benchmark for Turkish\\n\\t\\n\\n\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Card for TrGLUE\\n\\t\\n\\nTrGLUE is a natural language understanding benchmarking dataset including several single sentence and sentence pair classification tasks.\\nThe inspiration is clearly the original GLUE benchmark.\\n\\n\\t\\n\\t\\t\\n\\t\\tTasks\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tSingle Sentence Tasks\\n\\t\\n\\nTrCOLA The original Corpus of Linguistic Acceptability consists of sentences compiled from English literature textbooks. The task is to‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/turkish-nlp-suite/TrGLUE."},
	{"name":"time_series_datasets","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/zaai-ai/time_series_datasets","creator_name":"ZAAI","creator_url":"https://huggingface.co/zaai-ai","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tTourism Monthly Time Series Dataset with Economic and Static Covariates\\n\\t\\n\\nThis dataset, originally sourced from Athanasopoulos et al. (2011), focuses on the tourism industry with a monthly frequency and has been enhanced with economic covariates (e.g., CPI, Inflation Rate, GDP) from official Australian government sources. We also perform some preprocessing to further increase the usability of the dataset with dynamic start dates for each series and static covariates for in-depth‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/zaai-ai/time_series_datasets."},
	{"name":"code_leak_qa","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/fyt7943/code_leak_qa","creator_name":"fyt","creator_url":"https://huggingface.co/fyt7943","description":"fyt7943/code_leak_qa dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"openai-summarize-tldr","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/martimfasantos/openai-summarize-tldr","creator_name":"Martim Santos","creator_url":"https://huggingface.co/martimfasantos","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSummarize TL;DR Filtered Dataset\\n\\t\\n\\nThis is the version of the dataset used in https://arxiv.org/abs/2009.01325.\\nIf starting a new project we would recommend using https://huggingface.co/datasets/openai/summarize_from_feedback.\\nFor more information see https://github.com/openai/summarize-from-feedback and for the original TL;DR dataset see https://huggingface.co/datasets/webis/tldr-17.\\n"},
	{"name":"cohere_aya_arabic","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/abuelnasr/cohere_aya_arabic","creator_name":"Mohamed AbuElNasr","creator_url":"https://huggingface.co/abuelnasr","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tArabic aya dataset\\n\\t\\n\\nThis dataset is the arabic partition of the CohereForAI/aya_dataset dataset. \\nFor more information about the dataset, visit the original dataset repo: CohereForAI/aya_dataset.\\nthe data was extracted using this simple code:\\n# Train split.\\naya_train = datasets.load_dataset(\\\"CohereForAI/aya_dataset\\\", split=\\\"train\\\")\\narb_train = aya_train.filter(lambda x: x[\\\"language_code\\\"] == \\\"arb\\\")\\narb_train = arb_train.remove_columns([\\\"language_code\\\", \\\"user_id\\\"])\\n\\n# Test split.‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/abuelnasr/cohere_aya_arabic."},
	{"name":"XCOPA-eu","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/HiTZ/XCOPA-eu","creator_name":"HiTZ zentroa","creator_url":"https://huggingface.co/HiTZ","description":"\\n\\t\\n\\t\\t\\n\\t\\tDataset Card for XCOPA-eu\\n\\t\\n\\n\\nPoint of Contact: hitz@ehu.eus\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nXCOPA-eu is the professional translation to Basque of the English COPA dataset (Roemmmele et al., 2011),\\nin the spirit of the XCOPA effort (Ponti et al., 2020). \\nCOPA is a dataset of causal commmonsense reasoning that focuses on cause-effect relationships between a\\npremise and two choices.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages\\n\\t\\n\\n\\neu-ES\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Structure‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/HiTZ/XCOPA-eu."},
	{"name":"MGSM-eu","keyword":"monolingual","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/HiTZ/MGSM-eu","creator_name":"HiTZ zentroa","creator_url":"https://huggingface.co/HiTZ","description":"\\n\\t\\n\\t\\t\\n\\t\\tDataset Card for MGSM-eu\\n\\t\\n\\n\\nPoint of Contact: hitz@ehu.eus\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nMGSM (Shi et al., 2023) is a subset of 250 grade-school math problems from the GSM8K dataset (Cobbe et al., 2021) that has been manually translated into 10 typologically diverse languages.\\nHere, we provide professional translations to yet another language: Basque.\\n\\n\\t\\n\\t\\t\\n\\t\\tLanguages\\n\\t\\n\\n\\neu-ES\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Structure\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tData Instances\\n\\t\\n\\nMGSM-eu train examples‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/HiTZ/MGSM-eu."},
	{"name":"wnli-eu","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/HiTZ/wnli-eu","creator_name":"HiTZ zentroa","creator_url":"https://huggingface.co/HiTZ","description":"\\n\\t\\n\\t\\t\\n\\t\\tDataset Card for WNLI-eu\\n\\t\\n\\n\\nPoint of Contact: hitz@ehu.eus\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nWNLI-eu is the professional translation to Basque of the WNLI dataset.\\nWNLI is part of the GLUE benchmark for English (Wang et al., 2018) \\nand is based on the Winograd Schema Challenge (WSC) dataset (Levesque et al., 2011):\\n\\nA Winograd schema is a pair of sentences differing in only one or two words and containing an ambiguity that is resolved in opposite ways in the‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/HiTZ/wnli-eu."},
	{"name":"arabic_speech_corpus","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/tunis-ai/arabic_speech_corpus","creator_name":"Tunisia.AI","creator_url":"https://huggingface.co/tunis-ai","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Arabic Speech Corpus\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThis Speech corpus has been developed as part of PhD work carried out by Nawar Halabi at the University of Southampton. The corpus was recorded in south Levantine Arabic (Damascian accent) using a professional studio. Synthesized speech as an output using this corpus has produced a high quality, natural voice.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSupported Tasks and Leaderboards\\n\\t\\n\\n[Needs More Information]\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages\\n\\t\\n\\nThe‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/tunis-ai/arabic_speech_corpus."},
	{"name":"TrQuAD","keyword":"monolingual","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/turkish-nlp-suite/TrQuAD","creator_name":"Turkish NLP Suite","creator_url":"https://huggingface.co/turkish-nlp-suite","description":"\\n\\t\\n\\t\\t\\n\\t\\tTrQuAD - The Turkish SQuAD\\n\\t\\n\\n\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Card for TrQuAD\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nTrQuAD is a Turkish question answering dataset, being the Turkish translation of SQuAD.\\nWe translated the original SQuAD by the LLM Snowflake Arctic. The total dataset is around 61.6K.\\nMore information about the translation process, translation prompts and more can be found in our research paper.\\nDataset instances are identical with the original SQuAD format:\\n{\\n  \\\"id\\\":‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/turkish-nlp-suite/TrQuAD."},
	{"name":"MMBench-DEV-RU","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Vikhrmodels/MMBench-DEV-RU","creator_name":"Vikhr models","creator_url":"https://huggingface.co/Vikhrmodels","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tMMBench-DEV-RU\\n\\t\\n\\n–≠—Ç–æ –ø–µ—Ä–µ–≤–µ–¥–µ–Ω–Ω—ã–π Dev —Å–ø–ª–∏—Ç mmbench –¥–ª—è –æ—Ü–µ–Ω–∫–∏ —Ä—É—Å—Å–∫–æ—è–∑—ã—á–Ω—ã—Ö –º—É–ª—å—Ç–∏–º–æ–¥–∞–ª—å–Ω—ã—Ö LLM.\\n–ü–µ—Ä–µ–≤–æ–¥ –ø—Ä–æ–∏—Å—Ö–æ–¥–∏–ª –ø—Ä–∏ –ø–æ–º–æ—â–∏ gpt-4, —á–∞—Å—Ç—å –≤–æ–ø—Ä–æ—Å–æ–≤ –±—ã–ª–∞ –ø—Ä–æ–≤–µ—Ä–µ–Ω–∞ –∞—Å—Å–µ—Å–æ—Ä–∞–º–∏.\\n–í –¥–∞–Ω–Ω–æ–π –≤–µ—Ä—Å–∏–∏ –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç –º–∞–ª–∞—è —á–∞—Å—Ç—å –≤–æ–ø—Ä–æ—Å–æ–≤ –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω–æ–≥–æ –±–µ–Ω—á–º–∞—Ä–∫–∞. \\n–°—Å—ã–ª–∫–∞ –Ω–∞ –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–π –±–µ–Ω—á–º–∞—Ä–∫: https://huggingface.co/spaces/opencompass/MMBench\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\t–°–∫—Ä–∏–ø—Ç –¥–ª—è –æ—Ü–µ–Ω–∫–∏ –∫–∞—á–µ—Å—Ç–≤–∞\\n\\t\\n\\nhttps://github.com/Natyren/mmbench-ru-eval\\n–§–∞–π–ª, –∫–æ—Ç–æ—Ä—ã–π –≤—ã —Å–æ–±–∏—Ä–∞–µ—Ç–µ—Å—å –ø—Ä–æ–≥–Ω–∞—Ç—å –¥–æ–ª–∂–µ–Ω –≤–∫–ª—é—á–∞—Ç—å –∫–æ–ª–æ–Ω–∫—É gt‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Vikhrmodels/MMBench-DEV-RU."},
	{"name":"copyright_unlearning","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/boyiwei/copyright_unlearning","creator_name":"Boyi Wei","creator_url":"https://huggingface.co/boyiwei","description":"boyiwei/copyright_unlearning dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"tele_con_ciencia","keyword":"monolingual","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ciempiess/tele_con_ciencia","creator_name":"CIEMPIESS-UNAM Project (Mexico)","creator_url":"https://huggingface.co/ciempiess","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for tele_con_ciencia\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nAccording to the Facebook page of Tele con Ciencia:\\n\\\"Nuestra misi√≥n es la comunicaci√≥n p√∫blica de la ciencia y la tecnolog√≠a mexicana. El objetivo, \\nla participaci√≥n activa de todos los mexicanos en las √°reas del descubrimiento cient√≠fico y el \\ndesarrollo tecnol√≥gico.\\\"\\n\\\"Our mission is to spread the achievements of the Mexican Science and Technology. The main goal\\nis to promote the active participation of mexican‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ciempiess/tele_con_ciencia."},
	{"name":"real-toxicity-prompts-lite","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/oskarvanderwal/real-toxicity-prompts-lite","creator_name":"Oskar van der Wal","creator_url":"https://huggingface.co/oskarvanderwal","description":"This is a fork of the original RealToxicityPrompts dataset that contains a much smaller subset of the 100k prompts.\\nSubsets:\\n\\n50_pct: This subset contains all the challenging prompts + 50% of the full RealToxicityPrompts size sampled from the other prompts.\\n10_pct: This subset contains all the challenging prompts + 10% of the full RealToxicityPrompts size sampled from the other prompts.\\n\\nPlease refer to the original dataset for the Dataset Card.\\n"},
	{"name":"vwp","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/tonyhong/vwp","creator_name":"Xudong Hong","creator_url":"https://huggingface.co/tonyhong","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Visual Writing Prompts Dataset (VWP)\\n\\t\\n\\nWebsite | Github Repository | arXiv e-Print\\n\\n\\nThe Visual Writing Prompts (VWP) dataset contains almost 2K selected sequences of\\nmovie shots, each including 5-10 images. The image sequences are aligned with a total of 12K stories which are collected via crowdsourcing given the image sequences and up to 5  grounded characters from the corresponding image sequence.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Details\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Links‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/tonyhong/vwp."},
	{"name":"cms_iom_500","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/evekhm/cms_iom_500","creator_name":"Eva","creator_url":"https://huggingface.co/evekhm","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThis dataset contains CMS information with local and national coverage document data sets (LCD & NCD),as  Coverage Articles and  [Internet-Only Manuals (IOMs)(https://www.cms.gov/medicare/regulations-guidance/manuals/internet-only-manuals-ioms)\\nA list of Current LCDS, NCDs and Articles is obrained from Medicare Coverage Database.\\nThe data itself was obtainted by scrapping the urls and extracting data from the pdf files listed in current articles and current lcds‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/evekhm/cms_iom_500."},
	{"name":"wikipedia_leipzig_de_2016","keyword":"monolingual","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Alienmaster/wikipedia_leipzig_de_2016","creator_name":"Robert Geislinger","creator_url":"https://huggingface.co/Alienmaster","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLeipzig Corpora Wikipedia 2016 German\\n\\t\\n\\nThis dataset contains different splits (between 10k and 1mio) from the german wikipedia 2016. The data were collected 2016.\\nEvery element in the dataset is labeled as \\\"neutral\\\".\\nThe source can be found here\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tCitation\\n\\t\\n\\n@inproceedings{goldhahn-etal-2012-building,\\n    title = \\\"Building Large Monolingual Dictionaries at the {L}eipzig Corpora Collection: From 100 to 200 Languages\\\",\\n    author = \\\"Goldhahn, Dirk  and\\n      Eckart‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Alienmaster/wikipedia_leipzig_de_2016."},
	{"name":"cms_iom_3000","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/evekhm/cms_iom_3000","creator_name":"Eva","creator_url":"https://huggingface.co/evekhm","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThis dataset contains CMS information with local and national coverage document data sets (LCD & NCD),as  Coverage Articles and  [Internet-Only Manuals (IOMs)(https://www.cms.gov/medicare/regulations-guidance/manuals/internet-only-manuals-ioms)\\nA list of Current LCDS, NCDs and Articles is obrained from Medicare Coverage Database.\\nThe data itself was obtainted by scrapping the urls and extracting data from the pdf files listed in current articles and current lcds‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/evekhm/cms_iom_3000."},
	{"name":"commonsenseqa-bn","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/hishab/commonsenseqa-bn","creator_name":"Hishab","creator_url":"https://huggingface.co/hishab","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThis is the Bangla translated version of the CommonsenseQA dataset. The dataset was translated using a new method called Expressive Semantic Translation (EST). This method combines both Google Machine Translation and LLM-based rewriting of the translation to enhance the expressiveness and semantic accuracy of the translated content.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Structure\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData instances\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDefaults\\n\\t\\n\\nAn example of a 'train' looks as follows:\\n{‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/hishab/commonsenseqa-bn."},
	{"name":"RealToxicityPrompts","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ToxicityPrompts/RealToxicityPrompts","creator_name":"ToxicityPrompts","creator_url":"https://huggingface.co/ToxicityPrompts","description":"\\n\\t\\n\\t\\t\\n\\t\\tDataset Card for Real Toxicity Prompts\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nRealToxicityPrompts is a dataset of 100k sentence snippets from the web for researchers to further address the risk of neural toxic degeneration in models.\\n\\n\\t\\n\\t\\t\\n\\t\\tLanguages\\n\\t\\n\\nEnglish\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Structure\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tData Instances\\n\\t\\n\\nEach instance represents a prompt and its metadata:\\n{\\n  \\\"filename\\\":\\\"0766186-bc7f2a64cb271f5f56cf6f25570cd9ed.txt\\\",\\n  \\\"begin\\\":340,\\n  \\\"end\\\":564,\\n  \\\"challenging\\\":false‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ToxicityPrompts/RealToxicityPrompts."},
	{"name":"afrixnli-translate-test","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/masakhane/afrixnli-translate-test","creator_name":"Masakhane NLP","creator_url":"https://huggingface.co/masakhane","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for afrixnli-translate-test\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nAFRIXNLI-TT is an evaluation dataset comprising translations of the AFRIXNLI dataset from 16 African languages and 1 high resource language into English using NLLB. \\nIt includes test sets across all 17 languages.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages\\n\\t\\n\\nThere are 17 languages available :\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Structure\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Instances\\n\\t\\n\\nThe examples look like this for English:\\nfrom datasets import load_dataset‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/masakhane/afrixnli-translate-test."},
	{"name":"afrimgsm-translate-test","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/masakhane/afrimgsm-translate-test","creator_name":"Masakhane NLP","creator_url":"https://huggingface.co/masakhane","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for afrimgsm-translate-test\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nAFRIMGSM-TT is an evaluation dataset comprising translations of the GSM8k dataset from 16 African languages and 1 high resource language into English using NLLB. \\nIt includes test sets across all 17 languages. \\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages\\n\\t\\n\\nThere are 17 languages available :\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Structure\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Instances\\n\\t\\n\\nThe examples look like this for English:\\nfrom datasets import load_dataset‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/masakhane/afrimgsm-translate-test."},
	{"name":"tt-azatliq-crawl","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/veryrealtatarperson/tt-azatliq-crawl","creator_name":"VeryREAL","creator_url":"https://huggingface.co/veryrealtatarperson","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nAzatliqCrawl is a document-level dataset in Tatar language based on Azatliq newspaper.\\nThere are two versions released: the noisy dataset, which has no filtering, and the clean dataset,  which has a variety of filters applied (language identification using fasstext BOW and deduplication using MinHashLSH with number of permutations equal to 128 and threshold equal to 0.9), though it naturally has a fair amount of noise itself. Each dataset is released in a‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/veryrealtatarperson/tt-azatliq-crawl."},
	{"name":"PathPal","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/alternativerealitystudio/PathPal","creator_name":"Alternative Reality Studio","creator_url":"https://huggingface.co/alternativerealitystudio","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Name: Descriptive and Categorized Travel Snippets\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDescription\\n\\t\\n\\nThis dataset is a synthetic collection created from 160 different travel-related categories, providing detailed descriptions of accessible adventures and activities. It aims to inspire and inform individuals about opportunities accommodating diverse needs, each entry pairing a detailed description with a category label reflecting the nature of the activity.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Structure‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/alternativerealitystudio/PathPal."},
	{"name":"HET_Transfer_Orbit_Efficiency","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Taylor658/HET_Transfer_Orbit_Efficiency","creator_name":"atayloraerospace","creator_url":"https://huggingface.co/Taylor658","description":"Data on the impact of space weather on Hall Effect Thrusters (HETs) efficiency, used in spacecraft transfer orbits"},
	{"name":"humaneval_splits","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/iskhare/humaneval_splits","creator_name":"Ishan Khare","creator_url":"https://huggingface.co/iskhare","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for HumanEval with Splits\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThe HumanEval dataset released by OpenAI includes 164 programming problems with a function sig- nature, docstring, body, and several unit tests. They were handwritten to ensure not to be included in the training set of code generation models.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSupported Tasks and Leaderboards\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages\\n\\t\\n\\nThe programming problems are written in Python and contain English natural text in comments and‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/iskhare/humaneval_splits."},
	{"name":"webis-touche2020-v3","keyword":"monolingual","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/castorini/webis-touche2020-v3","creator_name":"Castorini","creator_url":"https://huggingface.co/castorini","description":"castorini/webis-touche2020-v3 dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"latam-xix","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Flaglab/latam-xix","creator_name":"Computer science research lab  @DISCUniandes.","creator_url":"https://huggingface.co/Flaglab","description":"Flaglab/latam-xix dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"spanish-corpus-xix","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Flaglab/spanish-corpus-xix","creator_name":"Computer science research lab  @DISCUniandes.","creator_url":"https://huggingface.co/Flaglab","description":"Flaglab/spanish-corpus-xix dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"InstructIR","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/kaist-ai/InstructIR","creator_name":"KAIST AI","creator_url":"https://huggingface.co/kaist-ai","description":"kaist-ai/InstructIR dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"PUGG","keyword":"monolingual","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/clarin-pl/PUGG","creator_name":"CLARIN-PL","creator_url":"https://huggingface.co/clarin-pl","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tPUGG: KBQA, MRC, IR Dataset for Polish\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDescription\\n\\t\\n\\nThis repository contains the PUGG dataset designed for three NLP tasks in the Polish language:\\n\\nKBQA (Knowledge Base Question Answering)\\nMRC (Machine Reading Comprehension)\\nIR (Information Retrieval)\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tPaper\\n\\t\\n\\nFor more detailed information, please refer to our research paper titled:\\n\\\"Developing PUGG for Polish: A Modern Approach to KBQA, MRC, and IR Dataset Construction\\\" \\nAuthored by:\\n\\nAlbert Sawczyn‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/clarin-pl/PUGG."},
	{"name":"filtered-coyo-700M-beta","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/dwb2023/filtered-coyo-700M-beta","creator_name":"Don Branson","creator_url":"https://huggingface.co/dwb2023","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for filterred-coyo-700M-beta\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSupported Tasks and Leaderboards\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages\\n\\t\\n\\nThe texts in the COYO-700M dataset consist of English.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Structure\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Instances\\n\\t\\n\\nEach instance in COYO-700M represents single image-text pair information with meta-attributes:\\n{\\n  'id': 841814333321,\\n  'url': 'https://blog.dogsof.com/wp-content/uploads/2021/03/Image-from-iOS-5-e1614711641382.jpg'‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/dwb2023/filtered-coyo-700M-beta."},
	{"name":"TrCOLA","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/turkish-nlp-suite/TrCOLA","creator_name":"Turkish NLP Suite","creator_url":"https://huggingface.co/turkish-nlp-suite","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tTrCOLA - Corpus of Linguistic Acceptability for Turkish Language\\n\\t\\n\\n\\n\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for TrCOLA\\n\\t\\n\\nTrCOLA is the Turkish version of CoLA dataset, The Corpus of Linguistic Acceptability.\\nThis dataset introduces linguistic acceptability task for Turkish. The total dataset size is 9.9K instances.\\nEach instance of the dataset is an original and correct sentence, variation of sentence that is produced in a specific way, the variation type and a binary label stating the‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/turkish-nlp-suite/TrCOLA."},
	{"name":"HM-SYNC","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/saluslab/HM-SYNC","creator_name":"SALUS Lab","creator_url":"https://huggingface.co/saluslab","description":"\\n\\t\\n\\t\\t\\n\\t\\tDataset Card for this Human-Machine Interaction Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Overview\\n\\t\\n\\nThis dataset contains a collection of observed interactions between humans and an advanced manufacturing machine, specifically a Wire Arc Additive Manufacuturing (WAAM) machine. The motivations for collecting this dataset, the contents of this dataset, and some ideas for how to analyze and use this dataset can be found below. \\nAdditionally, the paper introducing this dataset is published in the‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/saluslab/HM-SYNC."},
	{"name":"spanishBFF2","keyword":"monolingual","license":"GNU General Public License v3.0","license_url":"https://choosealicense.com/licenses/gpl-3.0/","language":"en","dataset_url":"https://huggingface.co/datasets/MMG/spanishBFF2","creator_name":"dezzai","creator_url":"https://huggingface.co/MMG","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nSpanish-BFF-2 is the second Spanish AI-generated dictionary using GPT4.\\n\\nPaper: Building another Spanish dictionary, this time with GPT-4: https://arxiv.org/abs/2406.11218\\nPoint of Contact: oscar.garcia@dezzai.com , alfonso.ardoiz@dezzai.com\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nSpanish-BFF contains a total of 76,963 lemmas with its definitions.\\nThese lemmas correspond to nominal, adjetival, verbal and adverbial classes.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages\\n\\t\\n\\n\\nSpanish (es)‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/MMG/spanishBFF2."},
	{"name":"unlearning","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/LZ12DH/unlearning","creator_name":"Li Zhaodonghui","creator_url":"https://huggingface.co/LZ12DH","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tTOFU: Task of Fictitious Unlearning üç¢\\n\\t\\n\\nThe TOFU dataset serves as a benchmark for evaluating unlearning performance of large language models on realistic tasks. The dataset comprises question-answer pairs based on autobiographies of 200 different authors that do not exist and are completely fictitiously generated by the GPT-4 model. The goal of the task is to unlearn a fine-tuned model on various fractions of the forget set.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tQuick Links\\n\\t\\n\\n\\nWebsite: The landing page‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/LZ12DH/unlearning."},
	{"name":"open-coursebooks-pl","keyword":"monolingual","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/rafalposwiata/open-coursebooks-pl","creator_name":"Rafa≈Ç Po≈õwiata","creator_url":"https://huggingface.co/rafalposwiata","description":"Open Coursebooks PL (based on https://epodreczniki.open.agh.edu.pl/) \\n"},
	{"name":"scidef","keyword":"monolingual","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/PL-MTEB/scidef","creator_name":"Polish Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/PL-MTEB","description":"PL-MTEB/scidef dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"tarwiiga_adgen_dataset","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/maelghrib/tarwiiga_adgen_dataset","creator_name":"Mustafa A. Elghrib","creator_url":"https://huggingface.co/maelghrib","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tTarwiiga AdGen Dataset\\n\\t\\n\\nThis dataset is generated using LLM for the purpose of fine-tunning another LLM for the task of generating Google Ads, and it used is by Tarwiiga AdGen from Tarwiiga\\n"},
	{"name":"github-issues","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/CodeLifeCL/github-issues","creator_name":"CL","creator_url":"https://huggingface.co/CodeLifeCL","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Dataset Name\\n\\t\\n\\n\\n\\nThis dataset card aims to be a base template for new datasets. It has been generated using this raw template.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Details\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\n\\nGitHub Issues with comments\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Sources [optional]\\n\\t\\n\\n\\n\\n\\nRepository: https://github.com/huggingface/datasets/issues\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tUses\\n\\t\\n\\n\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDirect Use\\n\\t\\n\\n\\n\\n[More Information Needed]\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tOut-of-Scope Use\\n\\t\\n\\n\\n\\n[More Information Needed]‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/CodeLifeCL/github-issues."},
	{"name":"InstructIR","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/henilp105/InstructIR","creator_name":"henil panchal","creator_url":"https://huggingface.co/henilp105","description":"henilp105/InstructIR dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"CoMDataset","keyword":"monolingual","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/qijimrc/CoMDataset","creator_name":"Ji Qi","creator_url":"https://huggingface.co/qijimrc","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nWe open-source both the Automatically Synthesized CoM Data and the Manually Annotated CoM-Math Data to facilitate potential research. The automatically synthesized CoM data (i.e., com.jsonl) consists of 84K positive reasoning chains, which was produced by an automated data generation pipeline with an LLM-based (GPT-4) linguistic solving steps generation and a VFMs-based (GroundingDINO, PaddleOCR) visual evidence compensation upon massive public VQA samples.‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/qijimrc/CoMDataset."},
	{"name":"virgool_62k","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Msobhi/virgool_62k","creator_name":"mohamad sobhi","creator_url":"https://huggingface.co/Msobhi","description":"This dataset represents the publicly available collection of data scraped from the virgool.io website. The data extraction was strategically performed based on specific tags and user. The dataset comprises approximately 62,000 entries across several key attributes: title, text, tags, likes, replies, reading_time, user_id, and URL.\\nThis resource is particularly beneficial for researchers and developers aiming to pre-train large language models (LLMs), as the 'text' column provides a rich corpus‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Msobhi/virgool_62k."},
	{"name":"Hindi_Fever","keyword":"monolingual","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/AIhnIndicRag/Hindi_Fever","creator_name":"AIHN Indic Rag Community","creator_url":"https://huggingface.co/AIhnIndicRag","description":"AIhnIndicRag/Hindi_Fever dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"vibravox_enhanced_by_EBEN","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Cnam-LMSSC/vibravox_enhanced_by_EBEN","creator_name":"Laboratoire de M√©canique des Structures et des Syst√®mes Coupl√©s","creator_url":"https://huggingface.co/Cnam-LMSSC","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card\\n\\t\\n\\n\\n  \\n\\n\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDescription\\n\\t\\n\\nThis dataset features a speech-enhanced version of the test split from the speech_clean subset of the Vibravox Dataset.\\nIt is not intended for training.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tEnhancement procedure\\n\\t\\n\\nThe Bandwidth extension task has been individually achieved for each sensor using configurable EBEN (arXiv link) models available at https://huggingface.co/Cnam-LMSSC/vibravox_EBEN_models.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tRessources\\n\\t\\n\\nResults for speech-to-phoneme‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Cnam-LMSSC/vibravox_enhanced_by_EBEN."},
	{"name":"soda-audio","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/fixie-ai/soda-audio","creator_name":"Fixie.ai","creator_url":"https://huggingface.co/fixie-ai","description":"Parent dataset: SODA\\nThe dataset was created based on SODA by first subsetting it and then adding two synthetic columns for training the Ultravox model:\\n\\nalt_last_turn: is an alternative for the last turn of the dialogue (dialogue[-1]) and was (re-)generated by Llama-3-8B Instruct;\\naudio_one_but_last: is the TTS'd speech for the turn before the last one (dialogue[-2]) using the Eleven Labs voice API using a set of random voices.\\n\\n"},
	{"name":"agxqa_v1","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/msu-ceco/agxqa_v1","creator_name":"The Computational Ecohydrology Group at MSU","creator_url":"https://huggingface.co/msu-ceco","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for AgXQA 1.1\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThe Agricultural eXtension Question Answering Dataset (AgXQA 1.1) is a small-scale, SQuAD-like QA dataset targeting the Agriculture Extension domain. \\nVersion 1.1 currently contains 2.1K+ questions related to irrigation topics across the US, focusing on the Midwest since our crops of interest were mainly soybean and corn.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSupported Tasks and Leaderboards\\n\\t\\n\\nQuestion Answering.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages\\n\\t\\n\\nEnglish‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/msu-ceco/agxqa_v1."},
	{"name":"sec-material-contracts-qa","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/chenghao/sec-material-contracts-qa","creator_name":"Chenghao Mou","creator_url":"https://huggingface.co/chenghao","description":"800+ EDGAR contracts with PDF images and key information extracted by the OpenAI GPT-4o model.\\nThe key information is defined as follows:\\nclass KeyInformation(BaseModel):\\n    agreement_date : str = Field(description=\\\"Agreement signing date of the contract. (date)\\\")\\n    effective_date : str = Field(description=\\\"Effective date of the contract. (date)\\\")\\n    expiration_date : str = Field(description=\\\"Service end date or expiration date of the contract. (date)\\\")\\n    party_address : str =‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/chenghao/sec-material-contracts-qa."},
	{"name":"STAIR-Captions","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/shunk031/STAIR-Captions","creator_name":"Shunsuke Kitada","creator_url":"https://huggingface.co/shunk031","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for STAIR-Captions\\n\\t\\n\\n\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nSTAIR Captions is a large-scale dataset containing 820,310 Japanese captions. This dataset can be used for caption generation, multimodal retrieval, and image generation.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSupported Tasks and Leaderboards\\n\\t\\n\\n[More Information Needed]\\n\\n\\n\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages\\n\\t\\n\\nThe language data in JDocQA is in Japanese (BCP-47 ja-JP).\\n\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Structure\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Instances\\n\\t\\n\\n[More Information‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/shunk031/STAIR-Captions."},
	{"name":"sec-material-contracts-qa-splitted","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/chenghao/sec-material-contracts-qa-splitted","creator_name":"Chenghao Mou","creator_url":"https://huggingface.co/chenghao","description":"Mixed and filtered version of chenghao/sec-material-contracts-qa and jordyvl/DUDE_subset_100val.\\n"},
	{"name":"math-dataset-instruction","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/sanjay-29-29/math-dataset-instruction","creator_name":"Sanjay","creator_url":"https://huggingface.co/sanjay-29-29","description":"sanjay-29-29/math-dataset-instruction dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"photochat_plus","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/passing2961/photochat_plus","creator_name":"Young-Jun Lee","creator_url":"https://huggingface.co/passing2961","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for PhotoChat++\\n\\t\\n\\n\\nüö® Disclaimer: All models and datasets are intended for research purposes only.\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nPhotoChat++ is a publicly available multi-modal dialogue dataset, an extended version of PhotoChat. PhotoChat++ contains six intent labels, a triggering sentence, an image description, and salient information (e.g., ‚Äúwords‚Äù or ‚Äúphrases‚Äù) to invoke the image-sharing behavior. The purpose of this dataset is to thoroughly assess the‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/passing2961/photochat_plus."},
	{"name":"OpenHermes-2.5-ru","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/d0rj/OpenHermes-2.5-ru","creator_name":"Dmitry Balobin","creator_url":"https://huggingface.co/d0rj","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\td0rj/OpenHermes-2.5-ru\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThis is translated version of teknium/OpenHermes-2.5 into Russian using Google Translate.\\n"},
	{"name":"MultiPL-E","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/nuprl-staging/MultiPL-E","creator_name":"Northeastern University PRL","creator_url":"https://huggingface.co/nuprl-staging","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for MultiPL-E\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nMultiPL-E is a dataset for evaluating large language models for code\\ngeneration that supports 22 programming languages. It takes the OpenAI \\nHumanEval and the Mostly Basic Python Programs (MBPP) benchmarks and uses little compilers to\\ntranslate them  to other languages. It is easy to add support for new languages \\nand benchmarks.\\nThe dataset is divided into several configurations named SRCDATA-LANG, where\\nSRCDATA is‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/nuprl-staging/MultiPL-E."},
	{"name":"stock_market_asx_audio","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/sdeering/stock_market_asx_audio","creator_name":"Sam","creator_url":"https://huggingface.co/sdeering","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Stock Market ASX Audio\\n\\t\\n\\nContains audios for every listed company on the Australian Stock Exchange (ASX). The dataset contains 2329 audio files of people saying the name of the company.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Fields\\n\\t\\n\\nsentence_id (string): An id for the sentence used for the recording.\\nvoice_id (string): An id for which client (voice) made the recording.\\naudio (dict): A dictionary containing the path to the downloaded audio file.\\nsentence (string): The sentence the‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/sdeering/stock_market_asx_audio."},
	{"name":"PUGG_KBQA","keyword":"monolingual","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/clarin-pl/PUGG_KBQA","creator_name":"CLARIN-PL","creator_url":"https://huggingface.co/clarin-pl","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tPUGG: KBQA, MRC, IR Dataset for Polish\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDescription\\n\\t\\n\\nThis repository contains the PUGG dataset designed for three NLP tasks in the Polish language:\\n\\nKBQA (Knowledge Base Question Answering)\\nMRC (Machine Reading Comprehension)\\nIR (Information Retrieval)\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tPaper\\n\\t\\n\\nFor more detailed information, please refer to our research paper titled:\\n\\\"Developing PUGG for Polish: A Modern Approach to KBQA, MRC, and IR Dataset Construction\\\" \\nAuthored by:\\n\\nAlbert Sawczyn‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/clarin-pl/PUGG_KBQA."},
	{"name":"PUGG_MRC","keyword":"monolingual","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/clarin-pl/PUGG_MRC","creator_name":"CLARIN-PL","creator_url":"https://huggingface.co/clarin-pl","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tPUGG: KBQA, MRC, IR Dataset for Polish\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDescription\\n\\t\\n\\nThis repository contains the PUGG dataset designed for three NLP tasks in the Polish language:\\n\\nKBQA (Knowledge Base Question Answering)\\nMRC (Machine Reading Comprehension)\\nIR (Information Retrieval)\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tPaper\\n\\t\\n\\nFor more detailed information, please refer to our research paper titled:\\n\\\"Developing PUGG for Polish: A Modern Approach to KBQA, MRC, and IR Dataset Construction\\\" \\nAuthored by:\\n\\nAlbert Sawczyn‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/clarin-pl/PUGG_MRC."},
	{"name":"PUGG_IR","keyword":"monolingual","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/clarin-pl/PUGG_IR","creator_name":"CLARIN-PL","creator_url":"https://huggingface.co/clarin-pl","description":"\\n\\t\\n\\t\\t\\n\\t\\tPUGG: KBQA, MRC, IR Dataset for Polish\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDescription\\n\\t\\n\\nThis repository contains the PUGG dataset designed for three NLP tasks in the Polish language:\\n\\nKBQA (Knowledge Base Question Answering)\\nMRC (Machine Reading Comprehension)\\nIR (Information Retrieval)\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tPaper\\n\\t\\n\\nFor more detailed information, please refer to our research paper titled:\\n\\\"Developing PUGG for Polish: A Modern Approach to KBQA, MRC, and IR Dataset Construction\\\" \\nAuthored by:\\n\\nAlbert Sawczyn\\nKatsiaryna‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/clarin-pl/PUGG_IR."},
	{"name":"192-Youtube-Channel-Views-Count","keyword":"monolingual","license":"Academic Free License v3.0","license_url":"https://choosealicense.com/licenses/afl-3.0/","language":"en","dataset_url":"https://huggingface.co/datasets/leodeveloper2000/192-Youtube-Channel-Views-Count","creator_name":"Muhammad Suleman","creator_url":"https://huggingface.co/leodeveloper2000","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\t192 YouTube Channel Views Count\\n\\t\\n\\nThis project compiles and analyzes data from 192 YouTube channels, totaling approximately 166,411 videos. The dataset includes information such as video titles, view counts, publish dates, and authors.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tIntroduction\\n\\t\\n\\nThe 192 YouTube Channel Views Count project aims to provide insights and analytics on video performance across 192 different YouTube channels. By aggregating data such as video titles, view counts, publish dates, and‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/leodeveloper2000/192-Youtube-Channel-Views-Count."},
	{"name":"smartlab-posts","keyword":"monolingual","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/nyuuzyou/smartlab-posts","creator_name":"nyuuzyou","creator_url":"https://huggingface.co/nyuuzyou","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Smart-lab.ru Posts\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThis dataset contains posts scraped from Smart-lab.ru, a Russian platform for discussing up-to-date stock exchange information, market news, investment ideas, and trading methods. Each entry in the dataset represents a post from the website, including its title, content, author, and a unique identifier.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages\\n\\t\\n\\nThe dataset is primarily in Russian, though some posts may contain content in other‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/nyuuzyou/smartlab-posts."},
	{"name":"grouse","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/illuin/grouse","creator_name":"Illuin Technology","creator_url":"https://huggingface.co/illuin","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for GroUSE\\n\\t\\n\\nGroUSE (Grounded QA Unitary Scoring of Evaluators) is a dataset designed to assess the performance of Grounded QA evaluators. Its purpose is to evaluate whether an LLM, when used as a grounded QA evaluator, delivers the expected scores across six metrics when presented with both good and imperfect answers.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Details\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nEach sample is of the following form :\\n{\\n    \\\"references\\\": [\\n        \\\"[Content of the‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/illuin/grouse."},
	{"name":"PUGG_KG","keyword":"monolingual","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/clarin-pl/PUGG_KG","creator_name":"CLARIN-PL","creator_url":"https://huggingface.co/clarin-pl","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tPUGG: KBQA, MRC, IR Dataset for Polish\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDescription\\n\\t\\n\\nThis repository contains the knowledge graph dedicated for \\nthe KBQA (Knowledge Base Question Answering) task within the PUGG dataset. This repository does not \\ncontain directly any task, but it provides the knowledge graph that can be used to solve the KBQA \\ntask from the PUGG dataset.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tGraphs\\n\\t\\n\\nWe provide sampled versions of the knowledge graph based on Wikidata:\\n\\nWikidata1H: A subgraph created by‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/clarin-pl/PUGG_KG."},
	{"name":"youtube-timestamps","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/lyleokoth/youtube-timestamps","creator_name":"lyle okoth","creator_url":"https://huggingface.co/lyleokoth","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for YouTube Videos Timestamps extraction dataset\\n\\t\\n\\n\\n\\n\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Details\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\n\\n\\n\\n\\n\\nCurated by: [More Information Needed]\\nFunded by [optional]: [More Information Needed]\\nShared by [optional]: [More Information Needed]\\nLanguage(s) (NLP): en\\nLicense: mit\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Sources [optional]\\n\\t\\n\\n\\n\\n\\nRepository: [More Information Needed]\\nPaper [optional]: [More Information Needed]\\nDemo [optional]: [More Information Needed]‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/lyleokoth/youtube-timestamps."},
	{"name":"DarijaMMLU","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/MBZUAI-Paris/DarijaMMLU","creator_name":"MBZUAI France Lab","creator_url":"https://huggingface.co/MBZUAI-Paris","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for DarijaMMLU\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nDarijaMMLU is an evaluation benchmark designed to assess large language models' (LLM) performance in Moroccan Darija, a variety of Arabic. It consists of 22,027 multiple-choice questions, translated from selected subsets of the Massive Multitask Language Understanding (MMLU) and ArabicMMLU benchmarks to measure model performance on 44 subjects in Darija.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSupported Tasks\\n\\t\\n\\n\\nTask Category: Multiple-choice‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/MBZUAI-Paris/DarijaMMLU."},
	{"name":"bordaru-posts","keyword":"monolingual","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/nyuuzyou/bordaru-posts","creator_name":"nyuuzyou","creator_url":"https://huggingface.co/nyuuzyou","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Borda.ru Posts\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThis dataset contains posts scraped from Borda.ru, a Russian platform for hosting various discussion forums on a wide range of topics. Each entry in the dataset represents a post from the website, including its content, author, URL, and other relevant information. The dataset contains 5,251,346 unique messages. The dataset was deduplicated based on the \\\"content\\\" value, which removed spam and other low-quality data‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/nyuuzyou/bordaru-posts."},
	{"name":"github-issues","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/ElisonSherton/github-issues","creator_name":"Vinayak Nayak","creator_url":"https://huggingface.co/ElisonSherton","description":"ElisonSherton/github-issues dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"PIQA-eu","keyword":"monolingual","license":"Academic Free License v3.0","license_url":"https://choosealicense.com/licenses/afl-3.0/","language":"en","dataset_url":"https://huggingface.co/datasets/HiTZ/PIQA-eu","creator_name":"HiTZ zentroa","creator_url":"https://huggingface.co/HiTZ","description":"\\n\\t\\n\\t\\t\\n\\t\\tDataset Card for PIQA-eu\\n\\t\\n\\n\\nPoint of Contact: hitz@ehu.eus\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nPIQA-eu is the professional translation to Basque of the PIQA's \\n(Bisk et al., 2020) validation partition. \\nPIQA is a commonsense QA benchmark for naive physics reasoning focusing on how we interact with everyday\\nobjects in everyday situations.\\n\\n\\t\\n\\t\\t\\n\\t\\tLanguages\\n\\t\\n\\n\\neu-ES\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Structure\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tData Instances\\n\\t\\n\\nPIQA-eu examples look like this:\\n{‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/HiTZ/PIQA-eu."},
	{"name":"ARC-eu","keyword":"monolingual","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/HiTZ/ARC-eu","creator_name":"HiTZ zentroa","creator_url":"https://huggingface.co/HiTZ","description":"\\n\\t\\n\\t\\t\\n\\t\\tDataset Card for ARC-eu\\n\\t\\n\\n\\nPoint of Contact: hitz@ehu.eus\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nARC-eu is the professional translation to Basque of ARC's \\n(Clark et al., 2018) validation and test partitions. \\nARC is a QA benchmark of grade-school level, multiple-choice science questions.\\n\\n\\t\\n\\t\\t\\n\\t\\tLanguages\\n\\t\\n\\n\\neu-ES\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Structure\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tData Instances\\n\\t\\n\\nARC-eu examples look like this:\\n{\\n    \\\"id\\\": \\\"MCAS_2000_4_6\\\",\\n    \\\"question\\\": \\\"Zein teknologia‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/HiTZ/ARC-eu."},
	{"name":"TOFU-C","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/annnli/TOFU-C","creator_name":"Li An","creator_url":"https://huggingface.co/annnli","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tTOFU: Task of Fictitious Unlearning üç¢\\n\\t\\n\\nThe TOFU dataset serves as a benchmark for evaluating unlearning performance of large language models on realistic tasks. The dataset comprises question-answer pairs based on autobiographies of 200 different authors that do not exist and are completely fictitiously generated by the GPT-4 model. The goal of the task is to unlearn a fine-tuned model on various fractions of the forget set.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tQuick Links\\n\\t\\n\\n\\nWebsite: The landing page‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/annnli/TOFU-C."},
	{"name":"TOFU-Cf","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/annnli/TOFU-Cf","creator_name":"Li An","creator_url":"https://huggingface.co/annnli","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tTOFU: Task of Fictitious Unlearning üç¢\\n\\t\\n\\nThe TOFU dataset serves as a benchmark for evaluating unlearning performance of large language models on realistic tasks. The dataset comprises question-answer pairs based on autobiographies of 200 different authors that do not exist and are completely fictitiously generated by the GPT-4 model. The goal of the task is to unlearn a fine-tuned model on various fractions of the forget set.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tQuick Links\\n\\t\\n\\n\\nWebsite: The landing page‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/annnli/TOFU-Cf."},
	{"name":"TOFU-Cr","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/annnli/TOFU-Cr","creator_name":"Li An","creator_url":"https://huggingface.co/annnli","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tTOFU: Task of Fictitious Unlearning üç¢\\n\\t\\n\\nThe TOFU dataset serves as a benchmark for evaluating unlearning performance of large language models on realistic tasks. The dataset comprises question-answer pairs based on autobiographies of 200 different authors that do not exist and are completely fictitiously generated by the GPT-4 model. The goal of the task is to unlearn a fine-tuned model on various fractions of the forget set.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tQuick Links\\n\\t\\n\\n\\nWebsite: The landing page‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/annnli/TOFU-Cr."},
	{"name":"capivara-plugin-orchestration","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/LeonardoBenitez/capivara-plugin-orchestration","creator_name":"Leonardo Santiago Benitez Pereira","creator_url":"https://huggingface.co/LeonardoBenitez","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\t# Dataset Card for Capivara Plugin Orchestration\\n\\t\\n\\n"},
	{"name":"TOFU-C","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/kimperyang/TOFU-C","creator_name":"Jingbo Yang","creator_url":"https://huggingface.co/kimperyang","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tTOFU: Task of Fictitious Unlearning üç¢\\n\\t\\n\\nThe TOFU dataset serves as a benchmark for evaluating unlearning performance of large language models on realistic tasks. The dataset comprises question-answer pairs based on autobiographies of 200 different authors that do not exist and are completely fictitiously generated by the GPT-4 model. The goal of the task is to unlearn a fine-tuned model on various fractions of the forget set.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tQuick Links\\n\\t\\n\\n\\nWebsite: The landing page‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/kimperyang/TOFU-C."},
	{"name":"test","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Liu123456789/test","creator_name":"L","creator_url":"https://huggingface.co/Liu123456789","description":"Liu123456789/test dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"cantemist","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/masaenger/cantemist","creator_name":"Mario S√§nger","creator_url":"https://huggingface.co/masaenger","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for CANTEMIST\\n\\t\\n\\nCollection of 1301 oncological clinical case reports written in Spanish, with tumor morphology mentions manually annotated and mapped by clinical experts to a controlled terminology. Every tumor morphology mention is linked to an eCIE-O code (the Spanish equivalent of ICD-O).\\nThe original dataset is distributed in Brat format, and was randomly sampled into 3 subsets. The training, development and test sets contain 501, 500 and 300 documents each‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/masaenger/cantemist."},
	{"name":"AuthorMix","keyword":"monolingual","license":"Academic Free License v3.0","license_url":"https://choosealicense.com/licenses/afl-3.0/","language":"en","dataset_url":"https://huggingface.co/datasets/jrfish/AuthorMix","creator_name":"Jillian Fisher","creator_url":"https://huggingface.co/jrfish","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for AuthorMix\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nAUTHORMIX, was originally created for authorship obfuscation task and had data from four distinct domains: presidential speeches, early-1900s fiction novels, scholarly articles, and diary-style blogs. Altogether, AUTHORMIX contains over 30k high-quality paragraphs from 14 authors.\\nThis work was created in the paper: StyleRemix: Interpretable Authorship Obfuscation via Distillation and Perturbation of Style Elements‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/jrfish/AuthorMix."},
	{"name":"BuyukSinema","keyword":"monolingual","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/turkish-nlp-suite/BuyukSinema","creator_name":"Turkish NLP Suite","creator_url":"https://huggingface.co/turkish-nlp-suite","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tB√ºy√ºkSinema - A Large Scale Turkish Movie Reviews Sentiment Dataset\\n\\t\\n\\n\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nB√ºy√ºkSinema is a Turkish movie reviews dataset of size 87K, scraped from Sinefil.com and Beyazperde.com. Hence this dataset is a superset of\\nBeyazPerde All Movie Reviews,\\nBeyazPerde Top 300 Movie Reviews and \\nSinefil Movie Reviews datasets. \\nThis is a merge of the three different datasets from two resources, hence we scaled the output stars into the range of 1-10 accordingly.‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/turkish-nlp-suite/BuyukSinema."},
	{"name":"my-awesome-dataset","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Axion004/my-awesome-dataset","creator_name":"Matthew Kehoe","creator_url":"https://huggingface.co/Axion004","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Demo\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThis is a demo dataset with two files train.csv and test.csv.\\nLoad it by:\\nfrom datasets import load_dataset \\ndata_files = {\\\"train\\\": \\\"train.csv\\\", \\\"test\\\": \\\"test.csv\\\"} \\ndemo = load_dataset(\\\"stevhliu/demo\\\", data_files=data_files)  \\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSupported Tasks and Leaderboards\\n\\t\\n\\n[More Information Needed]\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages\\n\\t\\n\\n[More Information Needed]\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Structure\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Instances\\n\\t\\n\\n[More‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Axion004/my-awesome-dataset."},
	{"name":"plvideo","keyword":"monolingual","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/nyuuzyou/plvideo","creator_name":"nyuuzyou","creator_url":"https://huggingface.co/nyuuzyou","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Platforma Video Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThis dataset was scraped from video pages on the Russian video-sharing platform Platforma, a Russian YouTube alternative. It includes information about 181,876 videos across 12,341 channels. The dataset contains detailed information about each video and its associated channel, providing a comprehensive view of the content available on the platform.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages\\n\\t\\n\\nThe dataset is primarily in Russian‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/nyuuzyou/plvideo."},
	{"name":"medotvet-questions","keyword":"monolingual","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/nyuuzyou/medotvet-questions","creator_name":"nyuuzyou","creator_url":"https://huggingface.co/nyuuzyou","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for medotvet.ru Questions\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThis dataset contains 4,319 medical questions and answers from the Russian website medotvet.ru. It includes questions posed by users seeking medical advice, along with responses provided by doctors across various specialties. The dataset can be analyzed to understand common health concerns among the Russian-speaking population and the types of medical advice provided online.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages\\n\\t\\n\\nThe‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/nyuuzyou/medotvet-questions."},
	{"name":"womanru-posts","keyword":"monolingual","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/nyuuzyou/womanru-posts","creator_name":"nyuuzyou","creator_url":"https://huggingface.co/nyuuzyou","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Woman.ru Forum Posts\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThis dataset contains 1,308,238 forum posts from Woman.ru, a popular Russian-language information and entertainment portal. Woman.ru is one of the most visited women's sites in Runet (Russian Internet). The dataset covers posts from around 2005 to 2024, providing a comprehensive view of discussions on the platform over nearly two decades.\\nThe content includes original posts and replies on various topics‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/nyuuzyou/womanru-posts."},
	{"name":"TOFUCr1","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/kimperyang/TOFUCr1","creator_name":"Jingbo Yang","creator_url":"https://huggingface.co/kimperyang","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tTOFU: Task of Fictitious Unlearning üç¢\\n\\t\\n\\nThe TOFU dataset serves as a benchmark for evaluating unlearning performance of large language models on realistic tasks. The dataset comprises question-answer pairs based on autobiographies of 200 different authors that do not exist and are completely fictitiously generated by the GPT-4 model. The goal of the task is to unlearn a fine-tuned model on various fractions of the forget set.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tQuick Links\\n\\t\\n\\n\\nWebsite: The landing page‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/kimperyang/TOFUCr1."},
	{"name":"wise-data","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/meaningalignment/wise-data","creator_name":"Meaning Alignment Institute","creator_url":"https://huggingface.co/meaningalignment","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThe wise-data and wise-data-preferences datasets are synthetically created collections of values-laden conversations, designed to train language models to provide more nuanced and helpful responses to harmful, heavy, or exploratory questions. These datasets were specifically created to train the WiseLLama-8B model, a LLaMa-3.1-8B-Instruct model fine-tuned using SFT (Supervised Fine-Tuning) and DPO (Direct Preference Optimization).\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Creation‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/meaningalignment/wise-data."},
	{"name":"QueryBridge","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/aorogat/QueryBridge","creator_name":"Abdelghny Orogat","creator_url":"https://huggingface.co/aorogat","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tQueryBridge: One Million Annotated Questions with SPARQL Queries - Dataset for Question Answering over Knowledge Graph\\n\\t\\n\\nThe QueryBridge dataset is the first and largest dataset with annotated questions for question answering (QA) over knowledge graphs. It provides a comprehensive resource for developing and testing algorithms that process and interpret natural language questions in the context of structured knowledge. In addition to QA tasks, QueryBridge can also be used for:‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/aorogat/QueryBridge."},
	{"name":"legal_reason","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/chemouda/legal_reason","creator_name":"Moudather Chelbi","creator_url":"https://huggingface.co/chemouda","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tEnhanced Legal Reasoning Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThe Enhanced Legal Reasoning Dataset is a synthetic dataset designed to facilitate the fine-tuning of Large Language Models (LLMs) for tasks related to legal reasoning and argumentation. It encompasses a diverse range of legal scenarios across multiple domains, capturing the nuanced techniques employed by legal professionals in constructing their arguments.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/chemouda/legal_reason."},
	{"name":"chatgpt-in-russia-qa","keyword":"monolingual","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/nyuuzyou/chatgpt-in-russia-qa","creator_name":"nyuuzyou","creator_url":"https://huggingface.co/nyuuzyou","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for —á–∞—Ç–≥–ø—Ç-–≤-—Ä–æ—Å—Å–∏–∏.—Ä—Ñ\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThis dataset contains question-answer pairs collected from —á–∞—Ç–≥–ø—Ç-–≤-—Ä–æ—Å—Å–∏–∏.—Ä—Ñ (meaning in English would be something like chatgpt-in-russia[.]rf), a Russian question-answering website. Each entry in the dataset represents a question asked by a user and the corresponding answer generated by an unspecified language model. The dataset contains 628,186 unique question-answer pairs covering various topics.‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/nyuuzyou/chatgpt-in-russia-qa."},
	{"name":"wise-data-preferences","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/meaningalignment/wise-data-preferences","creator_name":"Meaning Alignment Institute","creator_url":"https://huggingface.co/meaningalignment","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThe wise-data-preferences dataset is a synthetically created collection of values-laden conversations with preferred and rejected responses, designed to train language models to provide more nuanced and helpful responses to harmful, heavy, or exploratory questions. This dataset was specifically created to train the WiseLLama-8B model, a LLaMa-3.1-8B-Instruct model fine-tuned using DPO (Direct Preference Optimization).\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Creation‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/meaningalignment/wise-data-preferences."},
	{"name":"LLaVA-OneVision-Data-ru","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/d0rj/LLaVA-OneVision-Data-ru","creator_name":"Dmitry Balobin","creator_url":"https://huggingface.co/d0rj","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLLaVA-OneVision-Data-ru\\n\\t\\n\\nTranslated lmms-lab/LLaVA-OneVision-Data dataset into Russian language using Google translate.\\n\\nAlmost all datasets have been translated, except for the following:\\n[\\\"tallyqa(cauldron,llava_format)\\\", \\\"clevr(cauldron,llava_format)\\\", \\\"VisualWebInstruct(filtered)\\\", \\\"figureqa(cauldron,llava_format)\\\", \\\"magpie_pro(l3_80b_mt)\\\", \\\"magpie_pro(qwen2_72b_st)\\\", \\\"rendered_text(cauldron)\\\", \\\"ureader_ie\\\"]\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tUsage\\n\\t\\n\\nimport datasets\\n\\n\\ndata =‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/d0rj/LLaVA-OneVision-Data-ru."},
	{"name":"fishkinet-posts","keyword":"monolingual","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/nyuuzyou/fishkinet-posts","creator_name":"nyuuzyou","creator_url":"https://huggingface.co/nyuuzyou","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Fishki.net\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThis dataset contains posts scraped from Fishki.net, a Russian entertainment and news website. Each entry in the dataset represents a post from the website, including its title, content, author, publication date, tags, images, and URL. The dataset contains 369,180 unique posts covering various topics in entertainment, news, and social media content.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages\\n\\t\\n\\nThe dataset is primarily in Russian.‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/nyuuzyou/fishkinet-posts."},
	{"name":"steambans","keyword":"monolingual","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/nyuuzyou/steambans","creator_name":"nyuuzyou","creator_url":"https://huggingface.co/nyuuzyou","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Steam User Bans\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThis dataset contains information about 476,694 Steam users, including their profile details, ban status, and gaming activity. The data was collected from the Steam platform and includes information such as Steam ID, profile URL, username, avatar, account creation date, visibility state, VAC and game bans, economy ban status, time since last ban, Steam level, friend count, game count, total playtime, and CS2‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/nyuuzyou/steambans."},
	{"name":"balinese-carving-dataset","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/aegishield/balinese-carving-dataset","creator_name":"Bagus Prasetyo","creator_url":"https://huggingface.co/aegishield","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Balinese Carving Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThis dataset contains images of Balinese carvings along with their classifications, materials, and color descriptions. It is designed for image classification and retrieval tasks related to Balinese art and cultural heritage.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSupported Tasks and Leaderboards\\n\\t\\n\\nThis dataset supports multi-label image classification for Balinese carving styles and image retrieval based on textual descriptions of‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/aegishield/balinese-carving-dataset."},
	{"name":"TOFUCrP","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/kimperyang/TOFUCrP","creator_name":"Jingbo Yang","creator_url":"https://huggingface.co/kimperyang","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tTOFU: Task of Fictitious Unlearning üç¢\\n\\t\\n\\nThe TOFU dataset serves as a benchmark for evaluating unlearning performance of large language models on realistic tasks. The dataset comprises question-answer pairs based on autobiographies of 200 different authors that do not exist and are completely fictitiously generated by the GPT-4 model. The goal of the task is to unlearn a fine-tuned model on various fractions of the forget set.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tQuick Links\\n\\t\\n\\n\\nWebsite: The landing page‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/kimperyang/TOFUCrP."},
	{"name":"TruthGen","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/wwbrannon/TruthGen","creator_name":"William Brannon","creator_url":"https://huggingface.co/wwbrannon","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for TruthGen\\n\\t\\n\\nTruthGen is a dataset of generated political statements, created to assess the relationship between truthfulness and political bias in reward models and language models. It consists of non-repetitive, non-political factual statements paired with false statements, designed to evaluate models for their ability to distinguish true from false information while minimizing political content. The dataset was generated using GPT-3.5, GPT-4 and Gemini, with a‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/wwbrannon/TruthGen."},
	{"name":"indicvoices_hi_tagged_transcripts","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/WhissleAI/indicvoices_hi_tagged_transcripts","creator_name":"Whissle","creator_url":"https://huggingface.co/WhissleAI","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for indicvoices_hi_tagged_transcripts\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThis dataset contains audio files and their corresponding transcriptions in Hindi for automatic speech recognition (ASR) tasks.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages\\n\\t\\n\\nThe dataset is primarily in Hindi.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Collection\\n\\t\\n\\nThe dataset was collected through automated processes and manual transcription.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Structure\\n\\t\\n\\nThe dataset contains:\\n\\nAudio files (.wav format)\\nTranscriptions‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/WhissleAI/indicvoices_hi_tagged_transcripts."},
	{"name":"COVID-19-el-corpus","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/panosgriz/COVID-19-el-corpus","creator_name":"PanosGriziotis","creator_url":"https://huggingface.co/panosgriz","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThis corpus contains Greek-language texts about the COVID-19 pandemic including relevant information, FAQs, etc. The texts were collected from official websites (WHO, ECDC, NPHO, covid19.gov.gr) and articles from the greek Wikipedia. Total number of words: 204,748.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Fields\\n\\t\\n\\nEach instance contains:\\n\\ncontent: Plain text\\nid: Instance ID\\ntitle: A document title (only in instances related to Wikipedia articles)‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/panosgriz/COVID-19-el-corpus."},
	{"name":"kompy","keyword":"monolingual","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/nyuuzyou/kompy","creator_name":"nyuuzyou","creator_url":"https://huggingface.co/nyuuzyou","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Kompy.info\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThis dataset contains 584,648 pages of educational content in Uzbek language extracted from kompy.info website. The content includes academic and educational materials, with a focus on technical and scientific topics.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages\\n\\t\\n\\nThe dataset is primarily in Uzbek (uz).\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Structure\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Fields\\n\\t\\n\\nThis dataset includes the following fields:\\n\\nurl: URL of the webpage (string)‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/nyuuzyou/kompy."},
	{"name":"librispeech_asr","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/pavanyellow/librispeech_asr","creator_name":"Pavan Katta","creator_url":"https://huggingface.co/pavanyellow","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for librispeech_asr\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLibriSpeech ASR 2s Splits Dataset\\n\\t\\n\\nVersion of LibriSpeech ASR corpus split into 2s clips.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tUsage\\n\\t\\n\\nfrom datasets import load_dataset\\n\\n# Load the dataset from the Hub\\ndataset = load_dataset(\\\"pavanyellow/librispeech_asr\\\")\\n\\n# Or load a specific split\\ndataset = load_dataset(\\\"pavanyellow/librispeech_asr\\\", split=\\\"train\\\")\\n\\n# Access the data\\nfor example in dataset['train'][:5]:\\n   audio = example['audio']\\n   text =‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/pavanyellow/librispeech_asr."},
	{"name":"gdz4you","keyword":"monolingual","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/nyuuzyou/gdz4you","creator_name":"nyuuzyou","creator_url":"https://huggingface.co/nyuuzyou","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for GDZ4You.com Educational Materials\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThis dataset contains metadata and original files for 18,037 educational materials from the gdz4you.com platform, a resource for teachers and students providing multimedia presentations and other educational content. The dataset includes information such as material titles, URLs, download links, ratings, and slide-by-slide content with images where available.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages\\n\\t\\n\\nThe dataset is‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/nyuuzyou/gdz4you."},
	{"name":"clone-of-gretel-financial-risk-analysis-v1","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/AmanPriyanshu/clone-of-gretel-financial-risk-analysis-v1","creator_name":"Aman Priyanshu","creator_url":"https://huggingface.co/AmanPriyanshu","description":"\\n‚ö†Ô∏èüî¥ IMPORTANT NOTICE üî¥‚ö†Ô∏è\\nThis dataset is directly cloned from gretelai/gretel-financial-risk-analysis-v1 on Hugging Face. No modifications have been made to the original dataset, it is only for archival.\\n\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tgretelai/gretel-financial-risk-analysis-v1\\n\\t\\n\\nThis dataset contains synthetic financial risk analysis text generated using differential privacy guarantees, trained on 14,306 SEC (10-K, 10-Q, and 8-k) filings from 2023-2024. The dataset is designed for training models to‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/AmanPriyanshu/clone-of-gretel-financial-risk-analysis-v1."},
	{"name":"requests-github-issues","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Raibek/requests-github-issues","creator_name":"Raibek Tussupbekov","creator_url":"https://huggingface.co/Raibek","description":"Raibek/requests-github-issues dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"fairseq2-lm-gsm8k","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/facebook/fairseq2-lm-gsm8k","creator_name":"AI at Meta","creator_url":"https://huggingface.co/facebook","description":"facebook/fairseq2-lm-gsm8k dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"chinese-squadv2","keyword":"monolingual","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/real-jiakai/chinese-squadv2","creator_name":"jiakai","creator_url":"https://huggingface.co/real-jiakai","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Chinese SQuAD 2.0\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThis is a Chinese translation of the SQuAD 2.0 dataset, translated from the original English version. Like SQuAD 2.0, it contains both answerable and unanswerable questions. The dataset is designed for Chinese reading comprehension and question answering tasks.\\nSource: ChineseSquad\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Structure\\n\\t\\n\\nThe dataset is stored in Parquet format and contains the following‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/real-jiakai/chinese-squadv2."},
	{"name":"tamago","keyword":"monolingual","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/nyuuzyou/tamago","creator_name":"nyuuzyou","creator_url":"https://huggingface.co/nyuuzyou","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Tamago Music Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThis dataset contains metadata for 1,567 music tracks from tamastream.io, a community-based music streaming platform built on the NEAR blockchain. The dataset includes detailed track metadata including titles, descriptions, genres, and user interactions, providing insights into independent artist communities and their music.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages\\n\\t\\n\\nThe dataset is monolingual:\\n\\nEnglish (en): All metadata‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/nyuuzyou/tamago."},
	{"name":"Schemaorg","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Hierarchy-Transformers/Schemaorg","creator_name":"Hierarchy Transformers (HiTs)","creator_url":"https://huggingface.co/Hierarchy-Transformers","description":"This dataset is a collection of Mixed-hop Prediction datasets created from Schema.org's subsumption hierarchy (TBox) for evaluating hierarchy embedding models.\\n"},
	{"name":"FoodOn","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Hierarchy-Transformers/FoodOn","creator_name":"Hierarchy Transformers (HiTs)","creator_url":"https://huggingface.co/Hierarchy-Transformers","description":"This dataset is a collection of Mixed-hop Prediction datasets created from FoodOn's subsumption hierarchy (TBox) for evaluating hierarchy embedding models.\\n"},
	{"name":"Numina","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/artnoage/Numina","creator_name":"Vaios Laschos","creator_url":"https://huggingface.co/artnoage","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tNumina-Olympiads\\n\\t\\n\\nFiltered NuminaMath-CoT dataset containing only olympiads problems with valid answers.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Information\\n\\t\\n\\n\\nSplit: train\\nOriginal size: 41012\\nFiltered size: 38772\\nSource: olympiads\\nAll examples contain valid boxed answers\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThis dataset is a filtered version of the NuminaMath-CoT dataset, containing only problems from olympiad sources that have valid boxed answers. Each example includes:\\n\\nA mathematical word‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/artnoage/Numina."},
	{"name":"github-issues","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/real-jiakai/github-issues","creator_name":"jiakai","creator_url":"https://huggingface.co/real-jiakai","description":"This dataset originates from the teaching materials of the NLP Course.\\nvia: https://huggingface.co/learn/nlp-course/en/chapter5/5\\n"},
	{"name":"mmlu","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/flunardelli/mmlu","creator_name":"Fernando Lunardelli","creator_url":"https://huggingface.co/flunardelli","description":"\\n\\t\\n\\t\\t\\n\\t\\tDataset Card for MMLU\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nMeasuring Massive Multitask Language Understanding by Dan Hendrycks, Collin Burns, Steven Basart, Andy Zou, Mantas Mazeika, Dawn Song, and Jacob Steinhardt (ICLR 2021).\\nThis is a massive multitask test consisting of multiple-choice questions from various branches of knowledge. The test spans subjects in the humanities, social sciences, hard sciences, and other areas that are important for some people to learn. This covers 57 tasks‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/flunardelli/mmlu."},
	{"name":"SynWOZ","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Ayushnangia/SynWOZ","creator_name":"Ayush Nangia","creator_url":"https://huggingface.co/Ayushnangia","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSynWOZ\\n\\t\\n\\nA dataset containing 50k dialogues with various intents and emotions, generated using an advanced dialogue generation pipeline.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThis dataset consists of 50k dialogues generated by an advanced dialogue generation pipeline. The dialogues simulate realistic interactions across various services such as restaurants, hotels, taxis, and more, incorporating diverse scenarios, emotions, and resolution statuses.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSupported Tasks and‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Ayushnangia/SynWOZ."},
	{"name":"xlam-function-calling-60k-raw","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/product-science/xlam-function-calling-60k-raw","creator_name":"Product Science","creator_url":"https://huggingface.co/product-science","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tXLAM Function Calling 60k Raw Dataset\\n\\t\\n\\nThis dataset includes train and test splits derived from Salesforce/xlam-function-calling-60k.\\n\\nTrain split size: 95% of the original dataset\\nTest split size: 5% of the original dataset\\n\\n"},
	{"name":"traffic-qa","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/paulelliotco/traffic-qa","creator_name":"Paul Elliot","creator_url":"https://huggingface.co/paulelliotco","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tFHWA Traffic Signal Timing Q&A Dataset\\n\\t\\n\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Overview\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tKey Features\\n\\t\\n\\n\\n4,368 Q&A pairs on traffic signal timing topics.  \\nAI-generated using Google's Gemini model.  \\nStructured for training and fine-tuning AI models.  \\nBased on official FHWA documentation.\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Details\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tStructure\\n\\t\\n\\n\\nQuestion: Traffic signal timing question.  \\nAnswer: Detailed technical answer.  \\nSection ID: Reference to the original source section.‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/paulelliotco/traffic-qa."},
	{"name":"myelography-imaging","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Taylor658/myelography-imaging","creator_name":"atayloraerospace","creator_url":"https://huggingface.co/Taylor658","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tMyelography Imaging\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThis dataset consists of 750 synthetic myelography examination records representing a wide spectrum of spinal pathologies and patient experiences. Each record includes:\\n\\nPatient demographics: Age and sex.\\nClinical symptoms prompting the procedure: Detailed and verbose descriptions.\\nProcedural details: Contrast medium type, injection site, and imaging modality used.\\nVerbose findings: Observations such as spinal cord‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Taylor658/myelography-imaging."},
	{"name":"llmops-database","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/zenml/llmops-database","creator_name":"ZenML","creator_url":"https://huggingface.co/zenml","description":"\\n\\t\\n\\t\\t\\n\\t\\tThe ZenML LLMOps Database\\n\\t\\n\\n\\nTo learn more about ZenML and our open-source MLOps framework, visit\\nzenml.io.\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThe LLMOps Database is a comprehensive collection of over 500 real-world\\ngenerative AI implementations that showcases how organizations are successfully\\ndeploying Large Language Models (LLMs) in production. The case studies have been\\ncarefully curated to focus on technical depth and practical problem-solving,\\nwith an emphasis on implementation details‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/zenml/llmops-database."},
	{"name":"aircraft-images","keyword":"monolingual","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/nyuuzyou/aircraft-images","creator_name":"nyuuzyou","creator_url":"https://huggingface.co/nyuuzyou","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for High-Resolution Aircraft Images\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThis dataset contains 165,340 high-resolution aircraft images collected from the internet, along with machine-generated captions. The captions were generated using Gemini Flash 1.5 AI model and are stored in separate text files matching the image filenames.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages\\n\\t\\n\\nThe dataset is monolingual:\\n\\nEnglish (en): All image captions are in English\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Structure‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/nyuuzyou/aircraft-images."},
	{"name":"modafact-ita","keyword":"monolingual","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/dhfbk/modafact-ita","creator_name":"Digital Humanities at Fondazione Bruno Kessler","creator_url":"https://huggingface.co/dhfbk","description":"\\n\\t\\n\\t\\t\\n\\t\\tModaFact - Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nModaFact is a textual dataset annotated with Event Factuality and Modality in Italian. ModaFact‚Äôs goal is to model in a joint way factuality and modality values of event-denoting expressions in text.\\n\\n\\t\\n\\t\\t\\n\\t\\tTextual data source\\n\\t\\n\\nOriginal texts (sentences) have been sampled from EventNet-ITA, a dataset for Frame Parsing, consisting of annotated sentences from Wikipedia. \\n\\n\\t\\n\\t\\t\\n\\t\\tStatistics\\n\\t\\n\\n\\n\\t\\n\\t\\t\\nFeature‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/dhfbk/modafact-ita."},
	{"name":"airportwebcams","keyword":"monolingual","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/nyuuzyou/airportwebcams","creator_name":"nyuuzyou","creator_url":"https://huggingface.co/nyuuzyou","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Airport Webcams\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThis dataset contains information about 2,508 airport webcams extracted from airportwebcams.net. Each entry includes source URLs, embedded YouTube video links where available, and URLs to external webcam feeds.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Structure\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Fields\\n\\t\\n\\nThis dataset includes the following fields:\\n\\nsource_url: URL of the airportwebcams.net page (string)\\nyoutube_embeds: List of embedded YouTube video‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/nyuuzyou/airportwebcams."},
	{"name":"Numina_medium","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Metaskepsis/Numina_medium","creator_name":"Metaskepsis","creator_url":"https://huggingface.co/Metaskepsis","description":"\\n\\t\\n\\t\\t\\n\\t\\tNumina-Olympiads\\n\\t\\n\\nFiltered NuminaMath-CoT dataset containing only olympiads problems with valid answers.\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Information\\n\\t\\n\\n\\nSplit: train\\nOriginal size: 37133\\nFiltered size: 37133\\nSource: olympiads\\nAll examples contain valid boxed answers\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThis dataset is a filtered version of the NuminaMath-CoT dataset, containing only problems from olympiad sources that have valid boxed answers. Each example includes:\\n\\nA mathematical word problem\\nA‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Metaskepsis/Numina_medium."},
	{"name":"Olympiads_medium","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Metaskepsis/Olympiads_medium","creator_name":"Metaskepsis","creator_url":"https://huggingface.co/Metaskepsis","description":"\\n\\t\\n\\t\\t\\n\\t\\tNumina-Olympiads\\n\\t\\n\\nFiltered NuminaMath-CoT dataset containing only olympiads problems with valid answers.\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Information\\n\\t\\n\\n\\nSplit: train\\nOriginal size: 13284\\nFiltered size: 13240\\nSource: olympiads\\nAll examples contain valid boxed answers\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThis dataset is a filtered version of the NuminaMath-CoT dataset, containing only problems from olympiad sources that have valid boxed answers. Each example includes:\\n\\nA mathematical word problem\\nA‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Metaskepsis/Olympiads_medium."},
	{"name":"Olympiads_hard","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Metaskepsis/Olympiads_hard","creator_name":"Metaskepsis","creator_url":"https://huggingface.co/Metaskepsis","description":"\\n\\t\\n\\t\\t\\n\\t\\tNumina-Olympiads\\n\\t\\n\\nFiltered NuminaMath-CoT dataset containing only olympiads problems with valid answers.\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Information\\n\\t\\n\\n\\nSplit: train\\nOriginal size: 21525\\nFiltered size: 21408\\nSource: olympiads\\nAll examples contain valid boxed answers\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThis dataset is a filtered version of the NuminaMath-CoT dataset, containing only problems from olympiad sources that have valid boxed answers. Each example includes:\\n\\nA mathematical word problem\\nA‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Metaskepsis/Olympiads_hard."},
	{"name":"combined-fr-caselaw","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/La-Mousse/combined-fr-caselaw","creator_name":"La Mousse","creator_url":"https://huggingface.co/La-Mousse","description":"\\n\\t\\n\\t\\t\\n\\t\\tDataset Card for French Legal Cases Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThis dataset combines French legal cases from multiple sources (INCA, JADE, CASS, CAPP) into a unified format with overlapping text triplets. It includes decisions from various French courts, processed to facilitate natural language processing tasks.\\n\\n\\t\\n\\t\\t\\n\\t\\tSupported Tasks and Leaderboards\\n\\t\\n\\n\\nTasks:\\nText Generation\\nLegal Document Analysis\\nText Classification\\nLanguage Modeling\\n\\n\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tLanguages\\n\\t\\n\\nThe dataset‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/La-Mousse/combined-fr-caselaw."},
	{"name":"Bharat_NanoClimateFEVER_as","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoClimateFEVER_as","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\\n\\t\\n\\t\\t\\n\\t\\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tOverview\\n\\t\\n\\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThis particular dataset is the Assamese version of the NanoClimateFEVER dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoClimateFEVER_as."},
	{"name":"Bharat_NanoClimateFEVER_awa","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoClimateFEVER_awa","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\\n\\t\\n\\t\\t\\n\\t\\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tOverview\\n\\t\\n\\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThis particular dataset is the Awadhi version of the NanoClimateFEVER dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoClimateFEVER_awa."},
	{"name":"Bharat_NanoClimateFEVER_bho","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoClimateFEVER_bho","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\\n\\t\\n\\t\\t\\n\\t\\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tOverview\\n\\t\\n\\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThis particular dataset is the Bhojpuri version of the NanoClimateFEVER dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoClimateFEVER_bho."},
	{"name":"Bharat_NanoClimateFEVER_gu","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoClimateFEVER_gu","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\\n\\t\\n\\t\\t\\n\\t\\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tOverview\\n\\t\\n\\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThis particular dataset is the Gujarati version of the NanoClimateFEVER dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoClimateFEVER_gu."},
	{"name":"Bharat_NanoClimateFEVER_hne","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoClimateFEVER_hne","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\\n\\t\\n\\t\\t\\n\\t\\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tOverview\\n\\t\\n\\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThis particular dataset is the Chhattisgarhi version of the NanoClimateFEVER dataset, specifically adapted‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoClimateFEVER_hne."},
	{"name":"Bharat_NanoClimateFEVER_ksa","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoClimateFEVER_ksa","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\\n\\t\\n\\t\\t\\n\\t\\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tOverview\\n\\t\\n\\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThis particular dataset is the Kashmiri (Arabic script) version of the NanoClimateFEVER dataset, specifically‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoClimateFEVER_ksa."},
	{"name":"Bharat_NanoClimateFEVER_mag","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoClimateFEVER_mag","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\\n\\t\\n\\t\\t\\n\\t\\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tOverview\\n\\t\\n\\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThis particular dataset is the Magahi version of the NanoClimateFEVER dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoClimateFEVER_mag."},
	{"name":"Bharat_NanoClimateFEVER_mai","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoClimateFEVER_mai","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\\n\\t\\n\\t\\t\\n\\t\\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tOverview\\n\\t\\n\\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThis particular dataset is the Maithili version of the NanoClimateFEVER dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoClimateFEVER_mai."},
	{"name":"Bharat_NanoClimateFEVER_mr","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoClimateFEVER_mr","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\\n\\t\\n\\t\\t\\n\\t\\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tOverview\\n\\t\\n\\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThis particular dataset is the Marathi version of the NanoClimateFEVER dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoClimateFEVER_mr."},
	{"name":"Bharat_NanoClimateFEVER_ne","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoClimateFEVER_ne","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\\n\\t\\n\\t\\t\\n\\t\\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tOverview\\n\\t\\n\\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThis particular dataset is the Nepali version of the NanoClimateFEVER dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoClimateFEVER_ne."},
	{"name":"Bharat_NanoClimateFEVER_sa","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoClimateFEVER_sa","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\\n\\t\\n\\t\\t\\n\\t\\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tOverview\\n\\t\\n\\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThis particular dataset is the Sanskrit version of the NanoClimateFEVER dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoClimateFEVER_sa."},
	{"name":"Bharat_NanoDBPedia_bn","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoDBPedia_bn","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\\n\\t\\n\\t\\t\\n\\t\\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tOverview\\n\\t\\n\\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThis particular dataset is the Bengali version of the NanoDBPedia dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoDBPedia_bn."},
	{"name":"Bharat_NanoDBPedia_hi","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoDBPedia_hi","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\\n\\t\\n\\t\\t\\n\\t\\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tOverview\\n\\t\\n\\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThis particular dataset is the Hindi version of the NanoDBPedia dataset, specifically adapted for information‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoDBPedia_hi."},
	{"name":"Bharat_NanoDBPedia_hne","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoDBPedia_hne","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\\n\\t\\n\\t\\t\\n\\t\\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tOverview\\n\\t\\n\\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThis particular dataset is the Chhattisgarhi version of the NanoDBPedia dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoDBPedia_hne."},
	{"name":"Bharat_NanoDBPedia_ksd","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoDBPedia_ksd","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\\n\\t\\n\\t\\t\\n\\t\\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tOverview\\n\\t\\n\\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThis particular dataset is the Kashmiri (Devanagari script) version of the NanoDBPedia dataset, specifically‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoDBPedia_ksd."},
	{"name":"Bharat_NanoDBPedia_mag","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoDBPedia_mag","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\\n\\t\\n\\t\\t\\n\\t\\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tOverview\\n\\t\\n\\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThis particular dataset is the Magahi version of the NanoDBPedia dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoDBPedia_mag."},
	{"name":"Bharat_NanoDBPedia_ml","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoDBPedia_ml","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\\n\\t\\n\\t\\t\\n\\t\\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tOverview\\n\\t\\n\\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThis particular dataset is the Malayalam version of the NanoDBPedia dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoDBPedia_ml."},
	{"name":"Bharat_NanoDBPedia_mni","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoDBPedia_mni","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\\n\\t\\n\\t\\t\\n\\t\\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tOverview\\n\\t\\n\\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThis particular dataset is the Manipuri version of the NanoDBPedia dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoDBPedia_mni."},
	{"name":"Bharat_NanoDBPedia_ne","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoDBPedia_ne","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\\n\\t\\n\\t\\t\\n\\t\\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tOverview\\n\\t\\n\\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThis particular dataset is the Nepali version of the NanoDBPedia dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoDBPedia_ne."},
	{"name":"Bharat_NanoDBPedia_or","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoDBPedia_or","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\\n\\t\\n\\t\\t\\n\\t\\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tOverview\\n\\t\\n\\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThis particular dataset is the Odia (Oriya) version of the NanoDBPedia dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoDBPedia_or."},
	{"name":"Bharat_NanoDBPedia_ta","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoDBPedia_ta","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\\n\\t\\n\\t\\t\\n\\t\\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tOverview\\n\\t\\n\\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThis particular dataset is the Tamil version of the NanoDBPedia dataset, specifically adapted for information‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoDBPedia_ta."},
	{"name":"Bharat_NanoFEVER_bn","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoFEVER_bn","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\\n\\t\\n\\t\\t\\n\\t\\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tOverview\\n\\t\\n\\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThis particular dataset is the Bengali version of the NanoFEVER dataset, specifically adapted for information‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoFEVER_bn."},
	{"name":"Bharat_NanoFEVER_bho","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoFEVER_bho","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\\n\\t\\n\\t\\t\\n\\t\\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tOverview\\n\\t\\n\\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThis particular dataset is the Bhojpuri version of the NanoFEVER dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoFEVER_bho."},
	{"name":"Bharat_NanoFEVER_kn","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoFEVER_kn","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\\n\\t\\n\\t\\t\\n\\t\\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tOverview\\n\\t\\n\\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThis particular dataset is the Kannada version of the NanoFEVER dataset, specifically adapted for information‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoFEVER_kn."},
	{"name":"Bharat_NanoFEVER_mai","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoFEVER_mai","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\\n\\t\\n\\t\\t\\n\\t\\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tOverview\\n\\t\\n\\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThis particular dataset is the Maithili version of the NanoFEVER dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoFEVER_mai."},
	{"name":"Bharat_NanoFEVER_mr","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoFEVER_mr","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\\n\\t\\n\\t\\t\\n\\t\\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tOverview\\n\\t\\n\\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThis particular dataset is the Marathi version of the NanoFEVER dataset, specifically adapted for information‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoFEVER_mr."},
	{"name":"Bharat_NanoFEVER_mni","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoFEVER_mni","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\\n\\t\\n\\t\\t\\n\\t\\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tOverview\\n\\t\\n\\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThis particular dataset is the Manipuri version of the NanoFEVER dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoFEVER_mni."},
	{"name":"Bharat_NanoFEVER_ne","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoFEVER_ne","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\\n\\t\\n\\t\\t\\n\\t\\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tOverview\\n\\t\\n\\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThis particular dataset is the Nepali version of the NanoFEVER dataset, specifically adapted for information‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoFEVER_ne."},
	{"name":"Bharat_NanoFEVER_or","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoFEVER_or","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\\n\\t\\n\\t\\t\\n\\t\\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tOverview\\n\\t\\n\\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThis particular dataset is the Odia (Oriya) version of the NanoFEVER dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoFEVER_or."},
	{"name":"Bharat_NanoFEVER_pa","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoFEVER_pa","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\\n\\t\\n\\t\\t\\n\\t\\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tOverview\\n\\t\\n\\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThis particular dataset is the Punjabi version of the NanoFEVER dataset, specifically adapted for information‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoFEVER_pa."},
	{"name":"Bharat_NanoFEVER_ur","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoFEVER_ur","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\\n\\t\\n\\t\\t\\n\\t\\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tOverview\\n\\t\\n\\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThis particular dataset is the Urdu version of the NanoFEVER dataset, specifically adapted for information‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoFEVER_ur."},
	{"name":"Bharat_NanoFiQA2018_awa","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoFiQA2018_awa","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\\n\\t\\n\\t\\t\\n\\t\\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tOverview\\n\\t\\n\\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThis particular dataset is the Awadhi version of the NanoFiQA2018 dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoFiQA2018_awa."},
	{"name":"Bharat_NanoFiQA2018_ksa","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoFiQA2018_ksa","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\\n\\t\\n\\t\\t\\n\\t\\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tOverview\\n\\t\\n\\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThis particular dataset is the Kashmiri (Arabic script) version of the NanoFiQA2018 dataset, specifically‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoFiQA2018_ksa."},
	{"name":"Bharat_NanoFiQA2018_ksd","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoFiQA2018_ksd","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\\n\\t\\n\\t\\t\\n\\t\\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tOverview\\n\\t\\n\\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThis particular dataset is the Kashmiri (Devanagari script) version of the NanoFiQA2018 dataset, specifically‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoFiQA2018_ksd."},
	{"name":"Bharat_NanoFiQA2018_mag","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoFiQA2018_mag","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\\n\\t\\n\\t\\t\\n\\t\\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tOverview\\n\\t\\n\\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThis particular dataset is the Magahi version of the NanoFiQA2018 dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoFiQA2018_mag."},
	{"name":"Bharat_NanoFiQA2018_ml","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoFiQA2018_ml","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\\n\\t\\n\\t\\t\\n\\t\\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tOverview\\n\\t\\n\\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThis particular dataset is the Malayalam version of the NanoFiQA2018 dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoFiQA2018_ml."},
	{"name":"Bharat_NanoFiQA2018_ne","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoFiQA2018_ne","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\\n\\t\\n\\t\\t\\n\\t\\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tOverview\\n\\t\\n\\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThis particular dataset is the Nepali version of the NanoFiQA2018 dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoFiQA2018_ne."},
	{"name":"Bharat_NanoFiQA2018_sa","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoFiQA2018_sa","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\\n\\t\\n\\t\\t\\n\\t\\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tOverview\\n\\t\\n\\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThis particular dataset is the Sanskrit version of the NanoFiQA2018 dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoFiQA2018_sa."},
	{"name":"Bharat_NanoFiQA2018_te","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoFiQA2018_te","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\\n\\t\\n\\t\\t\\n\\t\\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tOverview\\n\\t\\n\\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThis particular dataset is the Telugu version of the NanoFiQA2018 dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoFiQA2018_te."},
	{"name":"Bharat_NanoHotpotQA_bn","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoHotpotQA_bn","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\\n\\t\\n\\t\\t\\n\\t\\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tOverview\\n\\t\\n\\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThis particular dataset is the Bengali version of the NanoHotpotQA dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoHotpotQA_bn."},
	{"name":"Bharat_NanoHotpotQA_hi","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoHotpotQA_hi","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\\n\\t\\n\\t\\t\\n\\t\\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tOverview\\n\\t\\n\\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThis particular dataset is the Hindi version of the NanoHotpotQA dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoHotpotQA_hi."},
	{"name":"Bharat_NanoHotpotQA_hne","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoHotpotQA_hne","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\\n\\t\\n\\t\\t\\n\\t\\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tOverview\\n\\t\\n\\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThis particular dataset is the Chhattisgarhi version of the NanoHotpotQA dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoHotpotQA_hne."},
	{"name":"Bharat_NanoHotpotQA_ksd","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoHotpotQA_ksd","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\\n\\t\\n\\t\\t\\n\\t\\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tOverview\\n\\t\\n\\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThis particular dataset is the Kashmiri (Devanagari script) version of the NanoHotpotQA dataset, specifically‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoHotpotQA_ksd."},
	{"name":"Bharat_NanoHotpotQA_mag","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoHotpotQA_mag","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\\n\\t\\n\\t\\t\\n\\t\\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tOverview\\n\\t\\n\\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThis particular dataset is the Magahi version of the NanoHotpotQA dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoHotpotQA_mag."},
	{"name":"Bharat_NanoHotpotQA_ml","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoHotpotQA_ml","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\\n\\t\\n\\t\\t\\n\\t\\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tOverview\\n\\t\\n\\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThis particular dataset is the Malayalam version of the NanoHotpotQA dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoHotpotQA_ml."},
	{"name":"Bharat_NanoHotpotQA_mr","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoHotpotQA_mr","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\\n\\t\\n\\t\\t\\n\\t\\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tOverview\\n\\t\\n\\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThis particular dataset is the Marathi version of the NanoHotpotQA dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoHotpotQA_mr."},
	{"name":"Bharat_NanoHotpotQA_pa","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoHotpotQA_pa","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\\n\\t\\n\\t\\t\\n\\t\\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tOverview\\n\\t\\n\\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThis particular dataset is the Punjabi version of the NanoHotpotQA dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoHotpotQA_pa."},
	{"name":"Bharat_NanoHotpotQA_te","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoHotpotQA_te","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\\n\\t\\n\\t\\t\\n\\t\\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tOverview\\n\\t\\n\\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThis particular dataset is the Telugu version of the NanoHotpotQA dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoHotpotQA_te."},
	{"name":"Bharat_NanoMSMARCO_bho","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoMSMARCO_bho","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\\n\\t\\n\\t\\t\\n\\t\\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tOverview\\n\\t\\n\\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThis particular dataset is the Bhojpuri version of the NanoMSMARCO dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoMSMARCO_bho."},
	{"name":"Bharat_NanoMSMARCO_gu","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoMSMARCO_gu","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\\n\\t\\n\\t\\t\\n\\t\\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tOverview\\n\\t\\n\\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThis particular dataset is the Gujarati version of the NanoMSMARCO dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoMSMARCO_gu."},
	{"name":"Bharat_NanoMSMARCO_hi","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoMSMARCO_hi","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\\n\\t\\n\\t\\t\\n\\t\\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tOverview\\n\\t\\n\\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThis particular dataset is the Hindi version of the NanoMSMARCO dataset, specifically adapted for information‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoMSMARCO_hi."},
	{"name":"Bharat_NanoMSMARCO_hne","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoMSMARCO_hne","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\\n\\t\\n\\t\\t\\n\\t\\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tOverview\\n\\t\\n\\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThis particular dataset is the Chhattisgarhi version of the NanoMSMARCO dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoMSMARCO_hne."},
	{"name":"Bharat_NanoMSMARCO_kn","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoMSMARCO_kn","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\\n\\t\\n\\t\\t\\n\\t\\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tOverview\\n\\t\\n\\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThis particular dataset is the Kannada version of the NanoMSMARCO dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoMSMARCO_kn."},
	{"name":"Bharat_NanoMSMARCO_ksa","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoMSMARCO_ksa","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\\n\\t\\n\\t\\t\\n\\t\\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tOverview\\n\\t\\n\\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThis particular dataset is the Kashmiri (Arabic script) version of the NanoMSMARCO dataset, specifically‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoMSMARCO_ksa."},
	{"name":"Bharat_NanoMSMARCO_ksd","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoMSMARCO_ksd","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\\n\\t\\n\\t\\t\\n\\t\\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tOverview\\n\\t\\n\\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThis particular dataset is the Kashmiri (Devanagari script) version of the NanoMSMARCO dataset, specifically‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoMSMARCO_ksd."},
	{"name":"Bharat_NanoMSMARCO_ml","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoMSMARCO_ml","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\\n\\t\\n\\t\\t\\n\\t\\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tOverview\\n\\t\\n\\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThis particular dataset is the Malayalam version of the NanoMSMARCO dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoMSMARCO_ml."},
	{"name":"Bharat_NanoMSMARCO_mni","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoMSMARCO_mni","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\\n\\t\\n\\t\\t\\n\\t\\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tOverview\\n\\t\\n\\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThis particular dataset is the Manipuri version of the NanoMSMARCO dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoMSMARCO_mni."},
	{"name":"Bharat_NanoMSMARCO_ne","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoMSMARCO_ne","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\\n\\t\\n\\t\\t\\n\\t\\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tOverview\\n\\t\\n\\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThis particular dataset is the Nepali version of the NanoMSMARCO dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoMSMARCO_ne."},
	{"name":"Bharat_NanoMSMARCO_pa","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoMSMARCO_pa","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\\n\\t\\n\\t\\t\\n\\t\\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tOverview\\n\\t\\n\\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThis particular dataset is the Punjabi version of the NanoMSMARCO dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoMSMARCO_pa."},
	{"name":"Bharat_NanoMSMARCO_sa","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoMSMARCO_sa","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\\n\\t\\n\\t\\t\\n\\t\\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tOverview\\n\\t\\n\\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThis particular dataset is the Sanskrit version of the NanoMSMARCO dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoMSMARCO_sa."},
	{"name":"Bharat_NanoMSMARCO_ur","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoMSMARCO_ur","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\\n\\t\\n\\t\\t\\n\\t\\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tOverview\\n\\t\\n\\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThis particular dataset is the Urdu version of the NanoMSMARCO dataset, specifically adapted for information‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoMSMARCO_ur."},
	{"name":"Bharat_NanoNFCorpus_awa","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoNFCorpus_awa","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\\n\\t\\n\\t\\t\\n\\t\\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tOverview\\n\\t\\n\\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThis particular dataset is the Awadhi version of the NanoNFCorpus dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoNFCorpus_awa."},
	{"name":"Bharat_NanoNFCorpus_kn","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoNFCorpus_kn","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\\n\\t\\n\\t\\t\\n\\t\\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tOverview\\n\\t\\n\\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThis particular dataset is the Kannada version of the NanoNFCorpus dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoNFCorpus_kn."},
	{"name":"Bharat_NanoNFCorpus_ksa","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoNFCorpus_ksa","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\\n\\t\\n\\t\\t\\n\\t\\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tOverview\\n\\t\\n\\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThis particular dataset is the Kashmiri (Arabic script) version of the NanoNFCorpus dataset, specifically‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoNFCorpus_ksa."},
	{"name":"Bharat_NanoNFCorpus_ksd","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoNFCorpus_ksd","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\\n\\t\\n\\t\\t\\n\\t\\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tOverview\\n\\t\\n\\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThis particular dataset is the Kashmiri (Devanagari script) version of the NanoNFCorpus dataset, specifically‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoNFCorpus_ksd."},
	{"name":"Bharat_NanoNFCorpus_mag","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoNFCorpus_mag","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\\n\\t\\n\\t\\t\\n\\t\\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tOverview\\n\\t\\n\\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThis particular dataset is the Magahi version of the NanoNFCorpus dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoNFCorpus_mag."},
	{"name":"Bharat_NanoNFCorpus_mai","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoNFCorpus_mai","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\\n\\t\\n\\t\\t\\n\\t\\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tOverview\\n\\t\\n\\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThis particular dataset is the Maithili version of the NanoNFCorpus dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoNFCorpus_mai."},
	{"name":"Bharat_NanoNFCorpus_ml","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoNFCorpus_ml","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\\n\\t\\n\\t\\t\\n\\t\\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tOverview\\n\\t\\n\\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThis particular dataset is the Malayalam version of the NanoNFCorpus dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoNFCorpus_ml."},
	{"name":"Bharat_NanoNFCorpus_mr","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoNFCorpus_mr","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\\n\\t\\n\\t\\t\\n\\t\\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tOverview\\n\\t\\n\\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThis particular dataset is the Marathi version of the NanoNFCorpus dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoNFCorpus_mr."},
	{"name":"Bharat_NanoNFCorpus_mni","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoNFCorpus_mni","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\\n\\t\\n\\t\\t\\n\\t\\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tOverview\\n\\t\\n\\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThis particular dataset is the Manipuri version of the NanoNFCorpus dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoNFCorpus_mni."},
	{"name":"Bharat_NanoNFCorpus_pa","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoNFCorpus_pa","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\\n\\t\\n\\t\\t\\n\\t\\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tOverview\\n\\t\\n\\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThis particular dataset is the Punjabi version of the NanoNFCorpus dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoNFCorpus_pa."},
	{"name":"Bharat_NanoNFCorpus_te","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoNFCorpus_te","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\\n\\t\\n\\t\\t\\n\\t\\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tOverview\\n\\t\\n\\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThis particular dataset is the Telugu version of the NanoNFCorpus dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoNFCorpus_te."},
	{"name":"Bharat_NanoNQ_as","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoNQ_as","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\\n\\t\\n\\t\\t\\n\\t\\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tOverview\\n\\t\\n\\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThis particular dataset is the Assamese version of the NanoNQ dataset, specifically adapted for information‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoNQ_as."},
	{"name":"Bharat_NanoNQ_hi","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoNQ_hi","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\\n\\t\\n\\t\\t\\n\\t\\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tOverview\\n\\t\\n\\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThis particular dataset is the Hindi version of the NanoNQ dataset, specifically adapted for information‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoNQ_hi."},
	{"name":"Bharat_NanoNQ_hne","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoNQ_hne","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\\n\\t\\n\\t\\t\\n\\t\\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tOverview\\n\\t\\n\\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThis particular dataset is the Chhattisgarhi version of the NanoNQ dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoNQ_hne."},
	{"name":"Bharat_NanoNQ_kn","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoNQ_kn","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\\n\\t\\n\\t\\t\\n\\t\\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tOverview\\n\\t\\n\\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThis particular dataset is the Kannada version of the NanoNQ dataset, specifically adapted for information‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoNQ_kn."},
	{"name":"Bharat_NanoNQ_ksa","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoNQ_ksa","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\\n\\t\\n\\t\\t\\n\\t\\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tOverview\\n\\t\\n\\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThis particular dataset is the Kashmiri (Arabic script) version of the NanoNQ dataset, specifically adapted‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoNQ_ksa."},
	{"name":"Bharat_NanoNQ_mag","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoNQ_mag","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\\n\\t\\n\\t\\t\\n\\t\\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tOverview\\n\\t\\n\\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThis particular dataset is the Magahi version of the NanoNQ dataset, specifically adapted for information‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoNQ_mag."},
	{"name":"Bharat_NanoNQ_mai","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoNQ_mai","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\\n\\t\\n\\t\\t\\n\\t\\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tOverview\\n\\t\\n\\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThis particular dataset is the Maithili version of the NanoNQ dataset, specifically adapted for information‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoNQ_mai."},
	{"name":"Bharat_NanoNQ_mr","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoNQ_mr","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\\n\\t\\n\\t\\t\\n\\t\\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tOverview\\n\\t\\n\\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThis particular dataset is the Marathi version of the NanoNQ dataset, specifically adapted for information‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoNQ_mr."},
	{"name":"Bharat_NanoNQ_ne","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoNQ_ne","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\\n\\t\\n\\t\\t\\n\\t\\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tOverview\\n\\t\\n\\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThis particular dataset is the Nepali version of the NanoNQ dataset, specifically adapted for information‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoNQ_ne."},
	{"name":"Bharat_NanoNQ_or","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoNQ_or","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\\n\\t\\n\\t\\t\\n\\t\\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tOverview\\n\\t\\n\\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThis particular dataset is the Odia (Oriya) version of the NanoNQ dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoNQ_or."},
	{"name":"Bharat_NanoNQ_sa","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoNQ_sa","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\\n\\t\\n\\t\\t\\n\\t\\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tOverview\\n\\t\\n\\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThis particular dataset is the Sanskrit version of the NanoNQ dataset, specifically adapted for information‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoNQ_sa."},
	{"name":"Bharat_NanoNQ_ur","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoNQ_ur","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\\n\\t\\n\\t\\t\\n\\t\\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tOverview\\n\\t\\n\\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThis particular dataset is the Urdu version of the NanoNQ dataset, specifically adapted for information‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoNQ_ur."},
	{"name":"Bharat_NanoQuoraRetrieval_hne","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoQuoraRetrieval_hne","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\\n\\t\\n\\t\\t\\n\\t\\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tOverview\\n\\t\\n\\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThis particular dataset is the Chhattisgarhi version of the NanoQuoraRetrieval dataset, specifically adapted‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoQuoraRetrieval_hne."},
	{"name":"Bharat_NanoQuoraRetrieval_ksd","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoQuoraRetrieval_ksd","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\\n\\t\\n\\t\\t\\n\\t\\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tOverview\\n\\t\\n\\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThis particular dataset is the Kashmiri (Devanagari script) version of the NanoQuoraRetrieval dataset‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoQuoraRetrieval_ksd."},
	{"name":"Bharat_NanoQuoraRetrieval_mag","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoQuoraRetrieval_mag","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\\n\\t\\n\\t\\t\\n\\t\\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tOverview\\n\\t\\n\\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThis particular dataset is the Magahi version of the NanoQuoraRetrieval dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoQuoraRetrieval_mag."},
	{"name":"Bharat_NanoQuoraRetrieval_mai","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoQuoraRetrieval_mai","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\\n\\t\\n\\t\\t\\n\\t\\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tOverview\\n\\t\\n\\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThis particular dataset is the Maithili version of the NanoQuoraRetrieval dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoQuoraRetrieval_mai."},
	{"name":"Bharat_NanoQuoraRetrieval_te","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoQuoraRetrieval_te","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\\n\\t\\n\\t\\t\\n\\t\\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tOverview\\n\\t\\n\\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThis particular dataset is the Telugu version of the NanoQuoraRetrieval dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoQuoraRetrieval_te."},
	{"name":"Bharat_NanoSCIDOCS_bho","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoSCIDOCS_bho","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\\n\\t\\n\\t\\t\\n\\t\\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tOverview\\n\\t\\n\\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThis particular dataset is the Bhojpuri version of the NanoSCIDOCS dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoSCIDOCS_bho."},
	{"name":"Bharat_NanoSCIDOCS_hi","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoSCIDOCS_hi","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\\n\\t\\n\\t\\t\\n\\t\\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tOverview\\n\\t\\n\\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThis particular dataset is the Hindi version of the NanoSCIDOCS dataset, specifically adapted for information‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoSCIDOCS_hi."},
	{"name":"Bharat_NanoSCIDOCS_hne","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoSCIDOCS_hne","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\\n\\t\\n\\t\\t\\n\\t\\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tOverview\\n\\t\\n\\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThis particular dataset is the Chhattisgarhi version of the NanoSCIDOCS dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoSCIDOCS_hne."},
	{"name":"Bharat_NanoSCIDOCS_ksa","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoSCIDOCS_ksa","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\\n\\t\\n\\t\\t\\n\\t\\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tOverview\\n\\t\\n\\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThis particular dataset is the Kashmiri (Arabic script) version of the NanoSCIDOCS dataset, specifically‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoSCIDOCS_ksa."},
	{"name":"Bharat_NanoSCIDOCS_ksd","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoSCIDOCS_ksd","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\\n\\t\\n\\t\\t\\n\\t\\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tOverview\\n\\t\\n\\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThis particular dataset is the Kashmiri (Devanagari script) version of the NanoSCIDOCS dataset, specifically‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoSCIDOCS_ksd."},
	{"name":"Bharat_NanoSCIDOCS_mag","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoSCIDOCS_mag","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\\n\\t\\n\\t\\t\\n\\t\\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tOverview\\n\\t\\n\\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThis particular dataset is the Magahi version of the NanoSCIDOCS dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoSCIDOCS_mag."},
	{"name":"Bharat_NanoSCIDOCS_ml","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoSCIDOCS_ml","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\\n\\t\\n\\t\\t\\n\\t\\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tOverview\\n\\t\\n\\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThis particular dataset is the Malayalam version of the NanoSCIDOCS dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoSCIDOCS_ml."},
	{"name":"Bharat_NanoSCIDOCS_mr","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoSCIDOCS_mr","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\\n\\t\\n\\t\\t\\n\\t\\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tOverview\\n\\t\\n\\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThis particular dataset is the Marathi version of the NanoSCIDOCS dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoSCIDOCS_mr."},
	{"name":"Bharat_NanoSCIDOCS_mni","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoSCIDOCS_mni","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\\n\\t\\n\\t\\t\\n\\t\\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tOverview\\n\\t\\n\\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThis particular dataset is the Manipuri version of the NanoSCIDOCS dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoSCIDOCS_mni."},
	{"name":"Bharat_NanoSCIDOCS_ne","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoSCIDOCS_ne","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\\n\\t\\n\\t\\t\\n\\t\\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tOverview\\n\\t\\n\\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThis particular dataset is the Nepali version of the NanoSCIDOCS dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoSCIDOCS_ne."},
	{"name":"Bharat_NanoSCIDOCS_te","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoSCIDOCS_te","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\\n\\t\\n\\t\\t\\n\\t\\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tOverview\\n\\t\\n\\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThis particular dataset is the Telugu version of the NanoSCIDOCS dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoSCIDOCS_te."},
	{"name":"Bharat_NanoSCIDOCS_ur","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoSCIDOCS_ur","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\\n\\t\\n\\t\\t\\n\\t\\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tOverview\\n\\t\\n\\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThis particular dataset is the Urdu version of the NanoSCIDOCS dataset, specifically adapted for information‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoSCIDOCS_ur."},
	{"name":"Bharat_NanoSciFact_ksa","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoSciFact_ksa","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\\n\\t\\n\\t\\t\\n\\t\\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tOverview\\n\\t\\n\\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThis particular dataset is the Kashmiri (Arabic script) version of the NanoSciFact dataset, specifically‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoSciFact_ksa."},
	{"name":"Bharat_NanoSciFact_ml","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoSciFact_ml","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\\n\\t\\n\\t\\t\\n\\t\\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tOverview\\n\\t\\n\\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThis particular dataset is the Malayalam version of the NanoSciFact dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoSciFact_ml."},
	{"name":"Bharat_NanoSciFact_mni","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoSciFact_mni","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\\n\\t\\n\\t\\t\\n\\t\\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tOverview\\n\\t\\n\\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThis particular dataset is the Manipuri version of the NanoSciFact dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoSciFact_mni."},
	{"name":"Bharat_NanoSciFact_ne","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoSciFact_ne","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\\n\\t\\n\\t\\t\\n\\t\\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tOverview\\n\\t\\n\\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThis particular dataset is the Nepali version of the NanoSciFact dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoSciFact_ne."},
	{"name":"Bharat_NanoSciFact_pa","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoSciFact_pa","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\\n\\t\\n\\t\\t\\n\\t\\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tOverview\\n\\t\\n\\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThis particular dataset is the Punjabi version of the NanoSciFact dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoSciFact_pa."},
	{"name":"Bharat_NanoSciFact_sa","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoSciFact_sa","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\\n\\t\\n\\t\\t\\n\\t\\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tOverview\\n\\t\\n\\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThis particular dataset is the Sanskrit version of the NanoSciFact dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoSciFact_sa."},
	{"name":"Bharat_NanoSciFact_ta","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoSciFact_ta","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\\n\\t\\n\\t\\t\\n\\t\\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tOverview\\n\\t\\n\\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThis particular dataset is the Tamil version of the NanoSciFact dataset, specifically adapted for information‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoSciFact_ta."},
	{"name":"Bharat_NanoSciFact_te","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoSciFact_te","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\\n\\t\\n\\t\\t\\n\\t\\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tOverview\\n\\t\\n\\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThis particular dataset is the Telugu version of the NanoSciFact dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoSciFact_te."},
	{"name":"Bharat_NanoArguAna_as","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoArguAna_as","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\\n\\t\\n\\t\\t\\n\\t\\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tOverview\\n\\t\\n\\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThis particular dataset is the Assamese version of the NanoArguAna dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoArguAna_as."},
	{"name":"Bharat_NanoArguAna_awa","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoArguAna_awa","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\\n\\t\\n\\t\\t\\n\\t\\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tOverview\\n\\t\\n\\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThis particular dataset is the Awadhi version of the NanoArguAna dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoArguAna_awa."},
	{"name":"Bharat_NanoArguAna_bn","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoArguAna_bn","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\\n\\t\\n\\t\\t\\n\\t\\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tOverview\\n\\t\\n\\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThis particular dataset is the Bengali version of the NanoArguAna dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoArguAna_bn."},
	{"name":"Bharat_NanoArguAna_bho","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoArguAna_bho","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\\n\\t\\n\\t\\t\\n\\t\\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tOverview\\n\\t\\n\\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThis particular dataset is the Bhojpuri version of the NanoArguAna dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoArguAna_bho."},
	{"name":"Bharat_NanoArguAna_kn","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoArguAna_kn","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\\n\\t\\n\\t\\t\\n\\t\\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tOverview\\n\\t\\n\\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThis particular dataset is the Kannada version of the NanoArguAna dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoArguAna_kn."},
	{"name":"Bharat_NanoArguAna_ksa","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoArguAna_ksa","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\\n\\t\\n\\t\\t\\n\\t\\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tOverview\\n\\t\\n\\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThis particular dataset is the Kashmiri (Arabic script) version of the NanoArguAna dataset, specifically‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoArguAna_ksa."},
	{"name":"Bharat_NanoArguAna_mag","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoArguAna_mag","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\\n\\t\\n\\t\\t\\n\\t\\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tOverview\\n\\t\\n\\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThis particular dataset is the Magahi version of the NanoArguAna dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoArguAna_mag."},
	{"name":"Bharat_NanoArguAna_mai","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoArguAna_mai","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\\n\\t\\n\\t\\t\\n\\t\\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tOverview\\n\\t\\n\\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThis particular dataset is the Maithili version of the NanoArguAna dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoArguAna_mai."},
	{"name":"Bharat_NanoArguAna_mni","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoArguAna_mni","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\\n\\t\\n\\t\\t\\n\\t\\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tOverview\\n\\t\\n\\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThis particular dataset is the Manipuri version of the NanoArguAna dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoArguAna_mni."},
	{"name":"Bharat_NanoArguAna_or","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoArguAna_or","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\\n\\t\\n\\t\\t\\n\\t\\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tOverview\\n\\t\\n\\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThis particular dataset is the Odia (Oriya) version of the NanoArguAna dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoArguAna_or."},
	{"name":"Bharat_NanoArguAna_pa","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoArguAna_pa","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\\n\\t\\n\\t\\t\\n\\t\\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tOverview\\n\\t\\n\\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThis particular dataset is the Punjabi version of the NanoArguAna dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoArguAna_pa."},
	{"name":"Bharat_NanoArguAna_sa","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoArguAna_sa","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\\n\\t\\n\\t\\t\\n\\t\\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tOverview\\n\\t\\n\\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThis particular dataset is the Sanskrit version of the NanoArguAna dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoArguAna_sa."},
	{"name":"Bharat_NanoTouche2020_as","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoTouche2020_as","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\\n\\t\\n\\t\\t\\n\\t\\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tOverview\\n\\t\\n\\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThis particular dataset is the Assamese version of the NanoTouche2020 dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoTouche2020_as."},
	{"name":"Bharat_NanoTouche2020_awa","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoTouche2020_awa","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\\n\\t\\n\\t\\t\\n\\t\\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tOverview\\n\\t\\n\\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThis particular dataset is the Awadhi version of the NanoTouche2020 dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoTouche2020_awa."},
	{"name":"Bharat_NanoTouche2020_hne","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoTouche2020_hne","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\\n\\t\\n\\t\\t\\n\\t\\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tOverview\\n\\t\\n\\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThis particular dataset is the Chhattisgarhi version of the NanoTouche2020 dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoTouche2020_hne."},
	{"name":"Bharat_NanoTouche2020_mag","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoTouche2020_mag","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\\n\\t\\n\\t\\t\\n\\t\\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tOverview\\n\\t\\n\\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThis particular dataset is the Magahi version of the NanoTouche2020 dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoTouche2020_mag."},
	{"name":"Bharat_NanoTouche2020_ml","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoTouche2020_ml","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\\n\\t\\n\\t\\t\\n\\t\\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tOverview\\n\\t\\n\\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThis particular dataset is the Malayalam version of the NanoTouche2020 dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoTouche2020_ml."},
	{"name":"Bharat_NanoTouche2020_mr","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoTouche2020_mr","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\\n\\t\\n\\t\\t\\n\\t\\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tOverview\\n\\t\\n\\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThis particular dataset is the Marathi version of the NanoTouche2020 dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoTouche2020_mr."},
	{"name":"Bharat_NanoTouche2020_ne","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoTouche2020_ne","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\\n\\t\\n\\t\\t\\n\\t\\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tOverview\\n\\t\\n\\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThis particular dataset is the Nepali version of the NanoTouche2020 dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoTouche2020_ne."},
	{"name":"Bharat_NanoTouche2020_te","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoTouche2020_te","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\\n\\t\\n\\t\\t\\n\\t\\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tOverview\\n\\t\\n\\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThis particular dataset is the Telugu version of the NanoTouche2020 dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoTouche2020_te."},
	{"name":"apps-small","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/AuroraH456/apps-small","creator_name":"Aurora Huang","creator_url":"https://huggingface.co/AuroraH456","description":"\\n\\t\\n\\t\\t\\n\\t\\tAPPS Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\nAPPS is a benchmark for code generation with 10000 problems. It can be used to evaluate the ability of language models to generate code from natural language specifications.\\nYou can also find APPS metric in the hub here codeparrot/apps_metric.\\n\\n\\t\\n\\t\\t\\n\\t\\tLanguages\\n\\t\\n\\nThe dataset contains questions in English and code solutions in Python.\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Structure\\n\\t\\n\\nfrom datasets import load_dataset\\nload_dataset(\\\"codeparrot/apps\\\")‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/AuroraH456/apps-small."},
	{"name":"TruthfulQA","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/rahmanidashti/TruthfulQA","creator_name":"Hossein A. (Saeed) Rahmani","creator_url":"https://huggingface.co/rahmanidashti","description":"\\n\\t\\n\\t\\t\\n\\t\\tDataset Card for TruthfulQA\\n\\t\\n\\n\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Details\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\n\\nTruthfulQA is a benchmark to measure whether a language model is truthful in generating answers to questions. The benchmark comprises 790 questions that span 38 categories, including health, law, finance and politics. Questions are crafted so that some humans would answer falsely due to a false belief or misconception. To perform well, models must avoid generating false answers learned from‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/rahmanidashti/TruthfulQA."},
	{"name":"hadith-qa-pair","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/rwmasood/hadith-qa-pair","creator_name":"Dr Wasif Masood","creator_url":"https://huggingface.co/rwmasood","description":"\\n\\t\\n\\t\\t\\n\\t\\tHadith QA Pair Dataset\\n\\t\\n\\nThis dataset contains Hadith-based question-answer pairs extracted from four renowned Hadith collections: Musnad Ahmad, Sahih Muslim, Sahih Bukhari, and Jami` at-Tirmidhi.\\nThe dataset is structured as question-answer pairs, where each question is answered using a relevant Hadith along with its reference. It can be utilized to train Large Language Models (LLMs) for text generation and question-answering tasks in Islamic studies.\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tFeatures\\n\\t\\n\\nThe‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/rwmasood/hadith-qa-pair."},
	{"name":"cpath-mcgill-ubc","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/houcine-bdk/cpath-mcgill-ubc","creator_name":"Houcine Bdk","creator_url":"https://huggingface.co/houcine-bdk","description":"\\n\\t\\n\\t\\t\\n\\t\\tCanadian Universities Q&A Dataset (CPath)\\n\\t\\n\\nA comprehensive question-answering dataset focused on Canadian universities' programs, admissions, and academic information, specifically covering McGill University and the University of British Columbia (UBC).\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThis dataset contains carefully curated question-answer pairs extracted from official university websites and documentation. It is designed to serve as a reliable resource for understanding academic‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/houcine-bdk/cpath-mcgill-ubc."},
	{"name":"synthetic_call_center_summaries","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/marccgrau/synthetic_call_center_summaries","creator_name":"Marc Christopher Grau","creator_url":"https://huggingface.co/marccgrau","description":"\\n\\t\\n\\t\\t\\n\\t\\tSynthetic Call Center Summaries Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tOverview\\n\\t\\n\\nThis dataset contains synthetic summaries of call center conversations generated by different prompt configurations.\\nEach record (in JSON Lines format) includes:\\n\\nThe original dialogue metadata.\\nA generated summary tailored to provide quick insights for call center service agents.\\nExtensive evaluation metrics and attributes such as conciseness, formatting, contextual relevance, tone, and actionability.\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tIntended‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/marccgrau/synthetic_call_center_summaries."},
	{"name":"VisOnlyQA_metadata","keyword":"monolingual","license":"GNU General Public License v3.0","license_url":"https://choosealicense.com/licenses/gpl-3.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ryokamoi/VisOnlyQA_metadata","creator_name":"Ryo Kamoi","creator_url":"https://huggingface.co/ryokamoi","description":"\\n\\t\\n\\t\\t\\n\\t\\tVisOnlyQA\\n\\t\\n\\nThis repository contains the code and data for the paper \\\"VisOnlyQA: Large Vision Language Models Still Struggle with Visual Perception of Geometric Information\\\".\\nVisOnlyQA is designed to evaluate the visual perception capability of large vision language models (LVLMs) on geometric information of scientific figures. The evaluation set includes 1,200 mlutiple choice questions in 12 visual perception tasks on 4 categories of scientific figures. We also provide a training‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ryokamoi/VisOnlyQA_metadata."},
	{"name":"PUGG_IR-qrels","keyword":"monolingual","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/clarin-pl/PUGG_IR-qrels","creator_name":"CLARIN-PL","creator_url":"https://huggingface.co/clarin-pl","description":"\\n\\t\\n\\t\\t\\n\\t\\tPUGG: KBQA, MRC, IR Dataset for Polish\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDescription\\n\\t\\n\\nThis repository contains the PUGG dataset designed for three NLP tasks in the Polish language:\\n\\nKBQA (Knowledge Base Question Answering)\\nMRC (Machine Reading Comprehension)\\nIR (Information Retrieval)\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tPaper\\n\\t\\n\\nFor more detailed information, please refer to our research paper titled:\\n\\\"Developing PUGG for Polish: A Modern Approach to KBQA, MRC, and IR Dataset Construction\\\" \\nAuthored by:\\n\\nAlbert Sawczyn\\nKatsiaryna‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/clarin-pl/PUGG_IR-qrels."},
	{"name":"allenai-prosocial-dialog","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/agentlans/allenai-prosocial-dialog","creator_name":"Alan Tseng","creator_url":"https://huggingface.co/agentlans","description":"\\n\\t\\n\\t\\t\\n\\t\\tProsocialDialog ShareGPT Format\\n\\t\\n\\nThis is an adapted version of the allenai/prosocial-dialog dataset, restructured to follow a ShareGPT-like format. This dataset teaches conversational AI agents how to respond to problematic content while adhering to social norms. It covers a wide range of unethical, problematic, biased, and toxic situations, providing responses that encourage prosocial behavior grounded in commonsense social rules.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Structure\\n\\t\\n\\nEach conversation‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/agentlans/allenai-prosocial-dialog."},
	{"name":"math-augmented-dataset","keyword":"monolingual","license":"GNU General Public License v2.0","license_url":"https://choosealicense.com/licenses/gpl-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/nivektk/math-augmented-dataset","creator_name":"Kevin Fabio Ramos L√≥pez","creator_url":"https://huggingface.co/nivektk","description":"\\n\\t\\n\\t\\t\\n\\t\\tMath-Augmented-Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThe Math-Augmented-Dataset extends the MATH dataset by Dan Hendrycks, focusing on algebra problems. It comprises 1,006 validated examples from the algebra subset, structured in JSON format with detailed step-by-step solutions generated using Large Language Models (LLMs) with chain-of-thought reasoning.\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Structure\\n\\t\\n\\nEach JSON file contains:\\n\\nproblem: The math problem statement, including LaTeX expressions.\\nlevel:‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/nivektk/math-augmented-dataset."},
	{"name":"24gadget-posts","keyword":"monolingual","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/nyuuzyou/24gadget-posts","creator_name":"nyuuzyou","creator_url":"https://huggingface.co/nyuuzyou","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for 24gadget.ru\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThis dataset contains articles scraped from 24gadget.ru, a Russian technology news website. Each entry in the dataset represents an article from the website, including its title, content, URL, publication date, and view count. The dataset contains 36,582 unique articles covering various topics in technology and gadgets.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages\\n\\t\\n\\nThe dataset is primarily in Russian.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Structure‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/nyuuzyou/24gadget-posts."},
	{"name":"roemru-posts","keyword":"monolingual","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/nyuuzyou/roemru-posts","creator_name":"nyuuzyou","creator_url":"https://huggingface.co/nyuuzyou","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Roem.ru\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThis dataset contains articles scraped from Roem.ru, a Russian technology and business news website. Each entry in the dataset represents an article from the website, including its title, content, URL, publication date, and author. The dataset contains 19,528 unique articles covering various topics in technology, business, and digital media.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages\\n\\t\\n\\nThe dataset is primarily in Russian.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/nyuuzyou/roemru-posts."},
	{"name":"azkurs","keyword":"monolingual","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/nyuuzyou/azkurs","creator_name":"nyuuzyou","creator_url":"https://huggingface.co/nyuuzyou","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Azkurs.org\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThis dataset contains 566,713 pages of educational content in Azerbaijani language extracted from azkurs.org website. The content includes academic and educational materials, with a focus on technical and scientific topics.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages\\n\\t\\n\\nThe dataset is in Azerbaijani (az) only.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Structure\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Fields\\n\\t\\n\\nThis dataset includes the following fields:\\n\\nurl: URL of the webpage‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/nyuuzyou/azkurs."},
	{"name":"publicdomainpictures","keyword":"monolingual","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/nyuuzyou/publicdomainpictures","creator_name":"nyuuzyou","creator_url":"https://huggingface.co/nyuuzyou","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Public Domain Pictures\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThis dataset contains metadata for 644,412 public domain images from publicdomainpictures.net, a public domain photo sharing platform. The dataset includes detailed image metadata including titles, descriptions, and keywords.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages\\n\\t\\n\\nThe dataset is monolingual:\\n\\nEnglish (en): All metadata including titles, descriptions and keywords\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Structure\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Fields‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/nyuuzyou/publicdomainpictures."},
	{"name":"DOID","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Hierarchy-Transformers/DOID","creator_name":"Hierarchy Transformers (HiTs)","creator_url":"https://huggingface.co/Hierarchy-Transformers","description":"This dataset is a collection of Mixed-hop Prediction datasets created from DOID's subsumption hierarchy (TBox) for evaluating hierarchy embedding models.\\n"},
	{"name":"SnomedCT","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Hierarchy-Transformers/SnomedCT","creator_name":"Hierarchy Transformers (HiTs)","creator_url":"https://huggingface.co/Hierarchy-Transformers","description":"This dataset is a collection of Multi-hop Inference and Mixed-hop Prediction datasets created from SnomedCT's subsumption hierarchy (TBox) for training and evaluating hierarchy embedding models.\\n"},
	{"name":"KublaPL","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/hast2/KublaPL","creator_name":"Takehiro Hashimoto","creator_url":"https://huggingface.co/hast2","description":"\\n\\t\\n\\t\\t\\n\\t\\tSTS Evaluation Datasets for English literary texts\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tRating criteria\\n\\t\\n\\n\\n5: Critics mentioned and strongly influenced - citation\\n\\n4: Critics mentioned and moderately influenced ‚Äì source, borrowing, repeating the same theme, self-citation, precedent example\\n\\n3: Critics mentioned and somewhat influenced ‚Äì association, source\\n\\n2: Influence mentioned but not admitted ‚Äì source text A and influenced text B but different lines critic mentioned ‚Äì e.g. Kubla Khan‚Äôs text but in‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/hast2/KublaPL."},
	{"name":"test1","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/mujif/test1","creator_name":"dasf","creator_url":"https://huggingface.co/mujif","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\ttest\\n\\t\\n\\ntest1\\n"},
	{"name":"fun_rec","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/ykckevin/fun_rec","creator_name":"kevin","creator_url":"https://huggingface.co/ykckevin","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tsmall demo learning how to use dataset in huggingface\\n\\t\\n\\n"},
	{"name":"prezented","keyword":"monolingual","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/nyuuzyou/prezented","creator_name":"nyuuzyou","creator_url":"https://huggingface.co/nyuuzyou","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Prezented.ru Presentations\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThis dataset contains metadata and original files for 2,289 educational presentations from the prezented.ru platform, a service focused on educational presentations for Russian schools. The dataset includes presentation titles, descriptions, download URLs, thumbnail images, and the original PPT/PPTX files.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages\\n\\t\\n\\nThe dataset is monolingual:\\n\\nRussian (ru): All content is in Russian‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/nyuuzyou/prezented."},
	{"name":"steam-reviews-constructiveness-binary-label-annotations-1.5k","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/abullard1/steam-reviews-constructiveness-binary-label-annotations-1.5k","creator_name":"Samuel Bullard","creator_url":"https://huggingface.co/abullard1","description":"\\n\\n\\n    \\n\\n\\n\\n\\n\\n\\n\\n    1.5K Steam Reviews Binary Labeled for Constructiveness\\n\\n\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThis dataset contains 1,461 Steam reviews from 10 of the most reviewed games. Each game has about the same amount of reviews. Each review is annotated with a binary label indicating whether the review is constructive or not. The dataset is designed to support tasks related to text classification, particularly constructiveness detection tasks in the gaming domain.\\n\\nAlso available as‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/abullard1/steam-reviews-constructiveness-binary-label-annotations-1.5k."},
	{"name":"llm_filtered_customer_service_conversations","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/marccgrau/llm_filtered_customer_service_conversations","creator_name":"Marc Christopher Grau","creator_url":"https://huggingface.co/marccgrau","description":"\\n\\t\\n\\t\\t\\n\\t\\tLLM-filtered Customer Service Conversations Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tOverview\\n\\t\\n\\nThis dataset contains simulated conversations generated by our agentic simulation system.\\nThe conversations are filtered by a LLM to ensure they are of high quality.\\nEach record is stored in JSON Lines (JSONL) format and includes:\\n\\nInput Settings: Metadata such as selected bank, customer, agent profiles, and task details.\\nMessages: The full conversation messages.\\nSummary: A German summary of the conversation.‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/marccgrau/llm_filtered_customer_service_conversations."},
	{"name":"text_meme","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/d0rj/text_meme","creator_name":"Dmitry Balobin","creator_url":"https://huggingface.co/d0rj","description":"\\n\\t\\n\\t\\t\\n\\t\\ttext_meme\\n\\t\\n\\n–°–æ—Å–∫—Ä–∞–ø–µ–Ω–æ —Å –æ—Ç–ª–∏—á–Ω–æ–≥–æ Telegram –∫–∞–Ω–∞–ª–∞ —Ç–µ–∫—Å—Ç–æ–≤—ã–µ –º–µ–º—ã.\\n"},
	{"name":"llm_filtered_customer_service_conversations_cleaned","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/marccgrau/llm_filtered_customer_service_conversations_cleaned","creator_name":"Marc Christopher Grau","creator_url":"https://huggingface.co/marccgrau","description":"\\n\\t\\n\\t\\t\\n\\t\\tLLM-filtered Customer Service Conversations Dataset (cleaned)\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tOverview\\n\\t\\n\\nThis dataset contains simulated conversations generated by our agentic simulation system.\\nThe conversations are filtered by a LLM to ensure they are of high quality.\\nEach record is stored in JSON Lines (JSONL) format and includes:\\n\\nInput Settings: Metadata such as selected bank, customer, agent profiles, and task details.\\nMessages: The full conversation messages.\\nSummary: A German summary of the‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/marccgrau/llm_filtered_customer_service_conversations_cleaned."},
	{"name":"wikipedia-paragraph-keywords","keyword":"monolingual","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/agentlans/wikipedia-paragraph-keywords","creator_name":"Alan Tseng","creator_url":"https://huggingface.co/agentlans","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tWikipedia Paragraph and Keyword Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThis dataset contains 10,693 paragraphs extracted from English Wikipedia articles, along with corresponding search-engine style keywords for each paragraph. It is designed to support tasks such as text summarization, keyword extraction, and information retrieval.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Structure\\n\\t\\n\\nThe dataset is structured as a collection of JSON objects, each representing a single paragraph with its associated‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/agentlans/wikipedia-paragraph-keywords."},
	{"name":"NanoArguAna","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/zeta-alpha-ai/NanoArguAna","creator_name":"Zeta Alpha","creator_url":"https://huggingface.co/zeta-alpha-ai","description":"zeta-alpha-ai/NanoArguAna dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"NanoClimateFEVER","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/zeta-alpha-ai/NanoClimateFEVER","creator_name":"Zeta Alpha","creator_url":"https://huggingface.co/zeta-alpha-ai","description":"zeta-alpha-ai/NanoClimateFEVER dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"NanoDBPedia","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/zeta-alpha-ai/NanoDBPedia","creator_name":"Zeta Alpha","creator_url":"https://huggingface.co/zeta-alpha-ai","description":"zeta-alpha-ai/NanoDBPedia dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"NanoFEVER","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/zeta-alpha-ai/NanoFEVER","creator_name":"Zeta Alpha","creator_url":"https://huggingface.co/zeta-alpha-ai","description":"zeta-alpha-ai/NanoFEVER dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"NanoFiQA2018","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/zeta-alpha-ai/NanoFiQA2018","creator_name":"Zeta Alpha","creator_url":"https://huggingface.co/zeta-alpha-ai","description":"zeta-alpha-ai/NanoFiQA2018 dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"NanoHotpotQA","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/zeta-alpha-ai/NanoHotpotQA","creator_name":"Zeta Alpha","creator_url":"https://huggingface.co/zeta-alpha-ai","description":"zeta-alpha-ai/NanoHotpotQA dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"NanoMSMARCO","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/zeta-alpha-ai/NanoMSMARCO","creator_name":"Zeta Alpha","creator_url":"https://huggingface.co/zeta-alpha-ai","description":"zeta-alpha-ai/NanoMSMARCO dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"NanoNFCorpus","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/zeta-alpha-ai/NanoNFCorpus","creator_name":"Zeta Alpha","creator_url":"https://huggingface.co/zeta-alpha-ai","description":"zeta-alpha-ai/NanoNFCorpus dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"NanoNQ","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/zeta-alpha-ai/NanoNQ","creator_name":"Zeta Alpha","creator_url":"https://huggingface.co/zeta-alpha-ai","description":"zeta-alpha-ai/NanoNQ dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"NanoSCIDOCS","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/zeta-alpha-ai/NanoSCIDOCS","creator_name":"Zeta Alpha","creator_url":"https://huggingface.co/zeta-alpha-ai","description":"zeta-alpha-ai/NanoSCIDOCS dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"NanoTouche2020","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/zeta-alpha-ai/NanoTouche2020","creator_name":"Zeta Alpha","creator_url":"https://huggingface.co/zeta-alpha-ai","description":"zeta-alpha-ai/NanoTouche2020 dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"TOFU-C-All","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Gyikoo/TOFU-C-All","creator_name":"Xinyi Gao","creator_url":"https://huggingface.co/Gyikoo","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tTOFU: Task of Fictitious Unlearning üç¢\\n\\t\\n\\nThe TOFU dataset serves as a benchmark for evaluating unlearning performance of large language models on realistic tasks. The dataset comprises question-answer pairs based on autobiographies of 200 different authors that do not exist and are completely fictitiously generated by the GPT-4 model. The goal of the task is to unlearn a fine-tuned model on various fractions of the forget set.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tQuick Links\\n\\t\\n\\n\\nWebsite: The landing page‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Gyikoo/TOFU-C-All."},
	{"name":"SNLI-NLI","keyword":"monolingual","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/1-800-SHARED-TASKS/SNLI-NLI","creator_name":"1-800-Shared-Tasks","creator_url":"https://huggingface.co/1-800-SHARED-TASKS","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for SNLI\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThe SNLI corpus (version 1.0) is a collection of 570k human-written English sentence pairs manually labeled for balanced classification with the labels entailment, contradiction, and neutral, supporting the task of natural language inference (NLI), also known as recognizing textual entailment (RTE).\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSupported Tasks and Leaderboards\\n\\t\\n\\nNatural Language Inference (NLI), also known as Recognizing Textual Entailment‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/1-800-SHARED-TASKS/SNLI-NLI."},
	{"name":"indicvoices_pa_tagged_transcripts","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/WhissleAI/indicvoices_pa_tagged_transcripts","creator_name":"Whissle","creator_url":"https://huggingface.co/WhissleAI","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for indicvoices_pa_tagged_transcripts\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThis dataset contains audio files and their corresponding transcriptions in Hindi for automatic speech recognition (ASR) tasks.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages\\n\\t\\n\\nThe dataset is primarily in Hindi.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Collection\\n\\t\\n\\nThe dataset was collected through automated processes and manual transcription.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Structure\\n\\t\\n\\nThe dataset contains:\\n\\nAudio files (.wav format)\\nTranscriptions‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/WhissleAI/indicvoices_pa_tagged_transcripts."},
	{"name":"indicvoices_mr_tagged_transcripts","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/WhissleAI/indicvoices_mr_tagged_transcripts","creator_name":"Whissle","creator_url":"https://huggingface.co/WhissleAI","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for indicvoices_mr_tagged_transcripts\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThis dataset contains audio files and their corresponding transcriptions in Hindi for automatic speech recognition (ASR) tasks.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages\\n\\t\\n\\nThe dataset is primarily in Hindi.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Collection\\n\\t\\n\\nThe dataset was collected through automated processes and manual transcription.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Structure\\n\\t\\n\\nThe dataset contains:\\n\\nAudio files (.wav format)\\nTranscriptions‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/WhissleAI/indicvoices_mr_tagged_transcripts."},
	{"name":"COVID-QA-el-small","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/panosgriz/COVID-QA-el-small","creator_name":"PanosGriziotis","creator_url":"https://huggingface.co/panosgriz","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for COVID-QA-el-small\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThe COVID-QA-el-small dataset is a Greek-language subset of 826 examples derived from the COVID-QA-el dataset, translated using machine translation. The dataset follows the SQuADv1.1 fashion style. \\nThe original dataset, COVID-QA: A Question Answering Dataset for COVID-19  (ACL 2020) contains 2,019 question-answer pairs annotated by volunteer biomedical experts on scientific literature about COVID-19.‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/panosgriz/COVID-QA-el-small."},
	{"name":"COVID-19_qa_pairs","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/panosgriz/COVID-19_qa_pairs","creator_name":"PanosGriziotis","creator_url":"https://huggingface.co/panosgriz","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for COVID-19_qa_pairs dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThis datasets includes 604 question-answer pairs related to COVID-19 pandemic machine translated in Greek language. \\nThe data is extracted from the official website of WHO.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Fields\\n\\t\\n\\n\\nquestion: Query question\\ndocument: Answer to the question\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tBias, Risks, and Limitations\\n\\t\\n\\nThis dataset is the result of machine translation.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLicensing Information\\n\\t\\n\\nThe dataset is‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/panosgriz/COVID-19_qa_pairs."},
	{"name":"amr-3-parsed","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/hoshuhan/amr-3-parsed","creator_name":"hoshuhan","creator_url":"https://huggingface.co/hoshuhan","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for AMR 3.0 Parsed\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThis dataset contains parsed Abstract Meaning Representation (AMR) annotations from the LDC2020T02 release, formatted as instruction-following conversations. Each example consists of a sentence and its corresponding AMR graph representation.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSupported Tasks and Leaderboards\\n\\t\\n\\n\\nTasks: Semantic parsing, specifically generating AMR graphs from English sentences\\nLeaderboards: AMR Parsing‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/hoshuhan/amr-3-parsed."},
	{"name":"indicvoices_bn_tagged_transcripts","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/WhissleAI/indicvoices_bn_tagged_transcripts","creator_name":"Whissle","creator_url":"https://huggingface.co/WhissleAI","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for indicvoices_bn_tagged_transcripts\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThis dataset contains audio files and their corresponding transcriptions in Hindi for automatic speech recognition (ASR) tasks.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages\\n\\t\\n\\nThe dataset is primarily in Hindi.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Collection\\n\\t\\n\\nThe dataset was collected through automated processes and manual transcription.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Structure\\n\\t\\n\\nThe dataset contains:\\n\\nAudio files (.wav format)\\nTranscriptions‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/WhissleAI/indicvoices_bn_tagged_transcripts."},
	{"name":"WordNetNoun","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Hierarchy-Transformers/WordNetNoun","creator_name":"Hierarchy Transformers (HiTs)","creator_url":"https://huggingface.co/Hierarchy-Transformers","description":"This dataset is a collection of Multi-hop Inference and Mixed-hop Prediction datasets created from WordNet's subsumption (hypernym) hierarchy of noun entities for training and evaluating hierarchy embedding models.\\n"},
	{"name":"MNIST","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/p2pfl/MNIST","creator_name":"P2PFL","creator_url":"https://huggingface.co/p2pfl","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tüñºÔ∏è MNIST (Extracted from PyTorch Vision)\\n\\t\\n\\nMNIST is a classic dataset of handwritten digits, widely used for image classification tasks in machine learning.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\t‚ÑπÔ∏è Dataset Details\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tüìñ Dataset Description\\n\\t\\n\\nThe MNIST database of handwritten digits is a commonly used benchmark dataset in machine learning. It consists of 70,000 grayscale images of handwritten digits (0-9), each with a size of 28x28 pixels. The dataset is split into 60,000 training images and‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/p2pfl/MNIST."},
	{"name":"TOFU-C-Shuffle","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/kimperyang/TOFU-C-Shuffle","creator_name":"Jingbo Yang","creator_url":"https://huggingface.co/kimperyang","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tTOFU: Task of Fictitious Unlearning üç¢\\n\\t\\n\\nThe TOFU dataset serves as a benchmark for evaluating unlearning performance of large language models on realistic tasks. The dataset comprises question-answer pairs based on autobiographies of 200 different authors that do not exist and are completely fictitiously generated by the GPT-4 model. The goal of the task is to unlearn a fine-tuned model on various fractions of the forget set.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tQuick Links\\n\\t\\n\\n\\nWebsite: The landing page‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/kimperyang/TOFU-C-Shuffle."},
	{"name":"TOFU-C-single","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Gyikoo/TOFU-C-single","creator_name":"Xinyi Gao","creator_url":"https://huggingface.co/Gyikoo","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tTOFU: Task of Fictitious Unlearning üç¢\\n\\t\\n\\nThe TOFU dataset serves as a benchmark for evaluating unlearning performance of large language models on realistic tasks. The dataset comprises question-answer pairs based on autobiographies of 200 different authors that do not exist and are completely fictitiously generated by the GPT-4 model. The goal of the task is to unlearn a fine-tuned model on various fractions of the forget set.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tQuick Links\\n\\t\\n\\n\\nWebsite: The landing page‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Gyikoo/TOFU-C-single."},
	{"name":"TOFU-Cbin","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/annnli/TOFU-Cbin","creator_name":"Li An","creator_url":"https://huggingface.co/annnli","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tTOFU: Task of Fictitious Unlearning üç¢\\n\\t\\n\\nThe TOFU dataset serves as a benchmark for evaluating unlearning performance of large language models on realistic tasks. The dataset comprises question-answer pairs based on autobiographies of 200 different authors that do not exist and are completely fictitiously generated by the GPT-4 model. The goal of the task is to unlearn a fine-tuned model on various fractions of the forget set.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tQuick Links\\n\\t\\n\\n\\nWebsite: The landing page‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/annnli/TOFU-Cbin."},
	{"name":"TOFU-C-Direct","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/kimperyang/TOFU-C-Direct","creator_name":"Jingbo Yang","creator_url":"https://huggingface.co/kimperyang","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tTOFU: Task of Fictitious Unlearning üç¢\\n\\t\\n\\nThe TOFU dataset serves as a benchmark for evaluating unlearning performance of large language models on realistic tasks. The dataset comprises question-answer pairs based on autobiographies of 200 different authors that do not exist and are completely fictitiously generated by the GPT-4 model. The goal of the task is to unlearn a fine-tuned model on various fractions of the forget set.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tQuick Links\\n\\t\\n\\n\\nWebsite: The landing page‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/kimperyang/TOFU-C-Direct."},
	{"name":"MATH_LVL5_fr","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/le-leadboard/MATH_LVL5_fr","creator_name":"le-leadboard","creator_url":"https://huggingface.co/le-leadboard","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for MATH_LVL5_fr\\n\\t\\n\\nle-leadboard/MATH_LVL5_fr fait partie de l'initiative OpenLLM French Leaderboard, proposant une adaptation fran√ßaise des probl√®mes math√©matiques de niveau avanc√© du dataset MATH.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nMATH_LVL5_fr est une adaptation fran√ßaise des probl√®mes math√©matiques de niveau 5 (le plus avanc√©) du dataset MATH original. Il comprend des probl√®mes de comp√©tition math√©matique de niveau lyc√©e, format√©s de mani√®re coh√©rente avec LaTeX pour‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/le-leadboard/MATH_LVL5_fr."},
	{"name":"ukiyo-e-face-blip2-captions","keyword":"monolingual","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/py-img-gen/ukiyo-e-face-blip2-captions","creator_name":"Image Generation with Python","creator_url":"https://huggingface.co/py-img-gen","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for ukiyo-e-face-blip2-captions\\n\\t\\n\\n\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nukiyo-e-face-blip2-captions is a dataset that adds captions to Ukiyo-e face dataset using BLIP2 model.\\n\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSupported Tasks and Leaderboards\\n\\t\\n\\n[More Information Needed]\\n\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages\\n\\t\\n\\nThe language data in ukiyo-e-face-blip2-captions is in English.\\n\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Structure\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Instances\\n\\t\\n\\nimport datasets as ds\\n\\ndataset =‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/py-img-gen/ukiyo-e-face-blip2-captions."},
	{"name":"1M-OpenOrca_be","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/WiNE-iNEFF/1M-OpenOrca_be","creator_name":"Artsem Holub","creator_url":"https://huggingface.co/WiNE-iNEFF","description":"En/Be\\nüêã The Belarusian OpenOrca Dataset! üêã\\n\\n\\n\\nBelarusian OpenOrca dataset - is rich collection of augmented FLAN data aligns, that translated in belarusian language.\\nThat dataset should help training LLM in belarusian language and should help on other NLP tasks.\\nThis dataset have 2 version:\\n\\n~1M GPT-4 completions (Now translating)\\n~3.2M GPT-3.5 completions (Can be translated in future)\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tData Fields\\n\\t\\n\\nThe fields are:\\n\\n'id', a unique numbered identifier which includes one of 'niv'‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/WiNE-iNEFF/1M-OpenOrca_be."},
	{"name":"NanoSciFact","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/zeta-alpha-ai/NanoSciFact","creator_name":"Zeta Alpha","creator_url":"https://huggingface.co/zeta-alpha-ai","description":"zeta-alpha-ai/NanoSciFact dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"TOFU-C-All","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/annnli/TOFU-C-All","creator_name":"Li An","creator_url":"https://huggingface.co/annnli","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tTOFU: Task of Fictitious Unlearning üç¢\\n\\t\\n\\nThe TOFU dataset serves as a benchmark for evaluating unlearning performance of large language models on realistic tasks. The dataset comprises question-answer pairs based on autobiographies of 200 different authors that do not exist and are completely fictitiously generated by the GPT-4 model. The goal of the task is to unlearn a fine-tuned model on various fractions of the forget set.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tQuick Links\\n\\t\\n\\n\\nWebsite: The landing page‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/annnli/TOFU-C-All."},
	{"name":"telugu-summarization-generation","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/1-800-SHARED-TASKS/telugu-summarization-generation","creator_name":"1-800-Shared-Tasks","creator_url":"https://huggingface.co/1-800-SHARED-TASKS","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSummary\\n\\t\\n\\naya-telugu-news-articles is an open source dataset of instruct-style records generated by webscraping a Telugu news articles website. This was created as part of Aya Open Science Initiative from Cohere For AI.\\nThis dataset can be used for any purpose, whether academic or commercial, under the terms of the Apache 2.0 License.\\nSupported Tasks:\\n\\nTraining LLMs\\nSynthetic Data Generation\\nData Augmentation\\n\\nLanguages: Telugu Version: 1.0\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Overview‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/1-800-SHARED-TASKS/telugu-summarization-generation."},
	{"name":"gretel-financial-risk-analysis-v1","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/gretelai/gretel-financial-risk-analysis-v1","creator_name":"Gretel.ai","creator_url":"https://huggingface.co/gretelai","description":"\\n\\t\\n\\t\\t\\n\\t\\tgretelai/gretel-financial-risk-analysis-v1\\n\\t\\n\\nThis dataset contains synthetic financial risk analysis text generated by fine-tuning Phi-3-mini-128k-instruct on 14,306 SEC filings (10-K, 10-Q, and 8-K) from 2023-2024, utilizing differential privacy. It is designed for training models to extract key risk factors and generate structured summaries from financial documents while demonstrating the application of differential privacy to safeguard sensitive information.\\nThis dataset showcases‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/gretelai/gretel-financial-risk-analysis-v1."},
	{"name":"fastfine","keyword":"monolingual","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/nyuuzyou/fastfine","creator_name":"nyuuzyou","creator_url":"https://huggingface.co/nyuuzyou","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Fastfine.ru\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThis dataset contains 13,248 pages of educational content in Russian language extracted from fastfine.ru website. The content includes academic papers, essays and educational materials across various subjects.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages\\n\\t\\n\\nThe dataset is primarily in Russian (ru).\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Structure\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Fields\\n\\t\\n\\nThis dataset includes the following fields:\\n\\nurl: URL of the webpage (string)\\ntitle:‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/nyuuzyou/fastfine."},
	{"name":"Eason_TOFU","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/EasonZhong/Eason_TOFU","creator_name":"Yisheng Zhong","creator_url":"https://huggingface.co/EasonZhong","description":"EasonZhong/Eason_TOFU dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"CTO","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/chufangao/CTO","creator_name":"Chufan Gao","creator_url":"https://huggingface.co/chufangao","description":"Dataset for predicting clinical trial outcomes in drug development.  This dataset is part of the work presented in \\\"Automatically Labeling Clinical Trial Outcomes: A Large-Scale Benchmark for Drug Development\\\".\\nWebsite: https://chufangao.github.io/CTOD/\\nPaper: https://arxiv.org/abs/2406.10292\\nCode: https://github.com/chufangao/ctod\\nDescriptions:\\n\\nhuman_labels contains the manually annotated subset. We follow the same rule-based termination of incomplete status and p-value < 0.05 as in the‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/chufangao/CTO."},
	{"name":"CICMalDroid","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/builetrongduc/CICMalDroid","creator_name":"B√πi L√™ Tr·ªçng ƒê·ª©c","creator_url":"https://huggingface.co/builetrongduc","description":"builetrongduc/CICMalDroid dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"cs2-highlights","keyword":"monolingual","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/nyuuzyou/cs2-highlights","creator_name":"nyuuzyou","creator_url":"https://huggingface.co/nyuuzyou","description":"\\n\\t\\n\\t\\t\\n\\t\\tDataset Card for Counter-Strike 2 Highlight Clips\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThis dataset contains 8,369 high-quality gameplay highlight clips primarily from Counter-Strike 2, with a small portion from Counter-Strike: Global Offensive. The clips focus on key gameplay moments such as kills, bomb interactions, and grenade usage. The clips are collected from competitive platforms like Faceit and in-game competitive modes (Premier, Matchmaking) across various skill levels, making it‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/nyuuzyou/cs2-highlights."},
	{"name":"goodgame","keyword":"monolingual","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/nyuuzyou/goodgame","creator_name":"nyuuzyou","creator_url":"https://huggingface.co/nyuuzyou","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for GoodGame.ru Clips\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThis dataset contains information about 39,280 video clips from the Russian streaming platform goodgame.ru. The clips include metadata such as streamer information, view counts, game categories, and related media URLs.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages\\n\\t\\n\\nThe dataset is primarily in Russian (ru).\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Structure\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Fields\\n\\t\\n\\nThis dataset includes the following fields:\\n\\nclip_id: Unique identifier‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/nyuuzyou/goodgame."},
	{"name":"DramaCV","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/gasmichel/DramaCV","creator_name":"Gaspard Michel","creator_url":"https://huggingface.co/gasmichel","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for DramaCV\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThe DramaCV Dataset is an English-language dataset containing utterances of fictional characters in drama plays collected from Project Gutenberg. The dataset was automatically created by parsing 499 drama plays from the 15th to 20th century on Project Gutenberg, that are then parsed to attribute each character line to its speaker.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tTask\\n\\t\\n\\nThis dataset was developed for Authorship Verification of literary‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/gasmichel/DramaCV."},
	{"name":"buzzlyart","keyword":"monolingual","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/nyuuzyou/buzzlyart","creator_name":"nyuuzyou","creator_url":"https://huggingface.co/nyuuzyou","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Buzzly.art\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThis dataset contains 2,000 artwork submissions from the Buzzly.art platform, including images and associated metadata. The content includes original artworks, photography, and other visual arts along with detailed metadata about each submission.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages\\n\\t\\n\\nThe dataset is only in English, including all titles, descriptions, tags and other text content.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Structure\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/nyuuzyou/buzzlyart."},
	{"name":"paintberri","keyword":"monolingual","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/nyuuzyou/paintberri","creator_name":"nyuuzyou","creator_url":"https://huggingface.co/nyuuzyou","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Paintberri\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThis dataset contains 60,224 artwork submissions from the Paintberri.com platform, including images and metadata. Content includes artworks created using the platform's built-in browser-based painting tool.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages\\n\\t\\n\\nEnglish only, including all titles, descriptions and metadata.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Structure\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Fields\\n\\t\\n\\n\\n_id: Unique identifier (string)\\ncreator: Object containing:\\n_id:‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/nyuuzyou/paintberri."},
	{"name":"filtered_convos_research_llm_summaries","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/marccgrau/filtered_convos_research_llm_summaries","creator_name":"Marc Christopher Grau","creator_url":"https://huggingface.co/marccgrau","description":"\\n\\t\\n\\t\\t\\n\\t\\tSynthetic Call Center Summaries Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tOverview\\n\\t\\n\\nThis dataset contains synthetic summaries of call center conversations generated by different prompt configurations.\\nEach record (in JSON Lines format) includes:\\n\\nThe original dialogue metadata.\\nA generated summary tailored to provide quick insights for call center service agents.\\nEvaluation metrics\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tPrompts for summarization\\n\\t\\n\\n\\nNarrative: A narrative summary of the conversation.\\nBullet Points: A summary of the‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/marccgrau/filtered_convos_research_llm_summaries."},
	{"name":"filtered_convos_research_llm_summaries_cleaned","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/marccgrau/filtered_convos_research_llm_summaries_cleaned","creator_name":"Marc Christopher Grau","creator_url":"https://huggingface.co/marccgrau","description":"\\n\\t\\n\\t\\t\\n\\t\\tSynthetic Call Center Summaries Dataset Cleaned\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tOverview\\n\\t\\n\\nThis dataset contains synthetic summaries of call center conversations generated by different prompt configurations.\\nEach record (in JSON Lines format) includes:\\n\\nThe original dialogue metadata.\\nA generated summary tailored to provide quick insights for call center service agents.\\nEvaluation metrics\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tPrompts for summarization\\n\\t\\n\\n\\nNarrative: A narrative summary of the conversation.\\nBullet Points: A summary of‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/marccgrau/filtered_convos_research_llm_summaries_cleaned."},
	{"name":"logical","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Satyam-Singh/logical","creator_name":"Satyam Singh","creator_url":"https://huggingface.co/Satyam-Singh","description":"\\n\\t\\n\\t\\t\\n\\t\\tDataset Card for GSM8K\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nGSM8K (Grade School Math 8K) is a dataset of 8.5K high quality linguistically diverse grade school math word problems. The dataset was created to support the task of question answering on basic mathematical problems that require multi-step reasoning.\\n\\nThese problems take between 2 and 8 steps to solve.\\nSolutions primarily involve performing a sequence of elementary calculations using basic arithmetic operations (+ ‚àí √ó√∑) to reach the‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Satyam-Singh/logical."},
	{"name":"gsm8k","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/oieieio/gsm8k","creator_name":"Jorge Alonso","creator_url":"https://huggingface.co/oieieio","description":"\\n\\t\\n\\t\\t\\n\\t\\tDataset Card for GSM8K\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nGSM8K (Grade School Math 8K) is a dataset of 8.5K high quality linguistically diverse grade school math word problems. The dataset was created to support the task of question answering on basic mathematical problems that require multi-step reasoning.\\n\\nThese problems take between 2 and 8 steps to solve.\\nSolutions primarily involve performing a sequence of elementary calculations using basic arithmetic operations (+ ‚àí √ó√∑) to reach the‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/oieieio/gsm8k."},
	{"name":"superglue","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Hyukkyu/superglue","creator_name":"Hyukkyu Kang","creator_url":"https://huggingface.co/Hyukkyu","description":"\\n\\t\\n\\t\\t\\n\\t\\tSuperGLUE Benchmark Datasets\\n\\t\\n\\nThis repository contains the SuperGLUE benchmark datasets. Each dataset is available as a separate configuration, making it easy to load individual datasets using the datasets library.\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Descriptions\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDatasets Included\\n\\t\\n\\n\\nBoolQ: A question-answering task where each example consists of a short passage and a yes/no question about the passage. The questions are provided anonymously and unsolicited by users of the Google search‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Hyukkyu/superglue."},
	{"name":"VisOnlyQA_Eval_Synthetic","keyword":"monolingual","license":"GNU General Public License v3.0","license_url":"https://choosealicense.com/licenses/gpl-3.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ryokamoi/VisOnlyQA_Eval_Synthetic","creator_name":"Ryo Kamoi","creator_url":"https://huggingface.co/ryokamoi","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVisOnlyQA\\n\\t\\n\\nThis repository contains the code and data for the paper \\\"VisOnlyQA: Large Vision Language Models Still Struggle with Visual Perception of Geometric Information\\\".\\nVisOnlyQA is designed to evaluate the visual perception capability of large vision language models (LVLMs) on geometric information of scientific figures. The evaluation set includes 1,200 mlutiple choice questions in 12 visual perception tasks on 4 categories of scientific figures. We also provide a training‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ryokamoi/VisOnlyQA_Eval_Synthetic."},
	{"name":"VisOnlyQA_Train","keyword":"monolingual","license":"GNU General Public License v3.0","license_url":"https://choosealicense.com/licenses/gpl-3.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ryokamoi/VisOnlyQA_Train","creator_name":"Ryo Kamoi","creator_url":"https://huggingface.co/ryokamoi","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVisOnlyQA\\n\\t\\n\\nThis repository contains the code and data for the paper \\\"VisOnlyQA: Large Vision Language Models Still Struggle with Visual Perception of Geometric Information\\\".\\nVisOnlyQA is designed to evaluate the visual perception capability of large vision language models (LVLMs) on geometric information of scientific figures. The evaluation set includes 1,200 mlutiple choice questions in 12 visual perception tasks on 4 categories of scientific figures. We also provide a training‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ryokamoi/VisOnlyQA_Train."},
	{"name":"distributed-computing-complex","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/JsZe/distributed-computing-complex","creator_name":"Jeffrey Zhou","creator_url":"https://huggingface.co/JsZe","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDistributed Systems Q&A Dataset\\n\\t\\n\\nThis dataset is collection of question-and-answer pairs related to distributed systems, compiled from a list of commonly asked questions in a college-level class. \\nThis dataset is designed to assist educators, researchers, and developers working on tuning AI models, chatbots, or educational tools in the field of distributed systems.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tKey Features:\\n\\t\\n\\n\\nQuestions: A variety of questions covering fundamental distributed systems concepts.‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/JsZe/distributed-computing-complex."},
	{"name":"VisOnlyQA_Eval_Real","keyword":"monolingual","license":"GNU General Public License v3.0","license_url":"https://choosealicense.com/licenses/gpl-3.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ryokamoi/VisOnlyQA_Eval_Real","creator_name":"Ryo Kamoi","creator_url":"https://huggingface.co/ryokamoi","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVisOnlyQA\\n\\t\\n\\nThis repository contains the code and data for the paper \\\"VisOnlyQA: Large Vision Language Models Still Struggle with Visual Perception of Geometric Information\\\".\\nVisOnlyQA is designed to evaluate the visual perception capability of large vision language models (LVLMs) on geometric information of scientific figures. The evaluation set includes 1,200 mlutiple choice questions in 12 visual perception tasks on 4 categories of scientific figures. We also provide a training‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ryokamoi/VisOnlyQA_Eval_Real."},
	{"name":"arthrography-imaging","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Taylor658/arthrography-imaging","creator_name":"atayloraerospace","creator_url":"https://huggingface.co/Taylor658","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tArthrography Imaging\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThis dataset consists of 500 synthetic arthrography procedure reports designed to represent realistic medical scenarios encountered in clinical practice. Each report includes:\\n\\nPatient demographics: Age and sex.\\nClinical indications: Detailed descriptions of reasons for undergoing the procedure, crafted at a PhD level.\\nJoint examined: Specific joint under examination (e.g., shoulder, knee, hip, etc.).\\nContrast agent used:‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Taylor658/arthrography-imaging."},
	{"name":"CIFAR10","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/p2pfl/CIFAR10","creator_name":"P2PFL","creator_url":"https://huggingface.co/p2pfl","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tüñºÔ∏è CIFAR10 (Extracted from PyTorch Vision)\\n\\t\\n\\nThe CIFAR-10 dataset consists of 60000 32x32 colour images in 10 classes, with 6000 images per class. There are 50000 training images and 10000 test images.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\t‚ÑπÔ∏è Dataset Details\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tüìñ Dataset Description\\n\\t\\n\\nThe CIFAR-10 dataset consists of 60000 32x32 colour images in 10 classes, with 6000 images per class. There are 50000 training images and 10000 test images. The classes are completely mutually exclusive. There‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/p2pfl/CIFAR10."},
	{"name":"rule34lol-webm","keyword":"monolingual","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/nyuuzyou/rule34lol-webm","creator_name":"nyuuzyou","creator_url":"https://huggingface.co/nyuuzyou","description":"\\n\\t\\n\\t\\t\\n\\t\\tDataset Card for Rule34.lol WebM\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThis dataset contains information about WebM files from Rule34.lol, a booru-style imageboard. The dataset includes metadata for 22,733 WebM files, including URLs, tags, and file information. The actual WebM files are stored in zip archives, with each archive containing 500 WebM files.\\n\\n\\t\\n\\t\\t\\n\\t\\tLanguages\\n\\t\\n\\nThe dataset metadata is primarily in English.\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Structure\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tData Fields\\n\\t\\n\\nThis dataset includes‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/nyuuzyou/rule34lol-webm."},
	{"name":"CodeMMLU","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Fsoft-AIC/CodeMMLU","creator_name":"FPT Software AI Center","creator_url":"https://huggingface.co/Fsoft-AIC","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tCodeMMLU: A Multi-Task Benchmark for Assessing Code Understanding Capabilities\\n\\t\\n\\n\\n\\n\\n\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tüìå CodeMMLU\\n\\t\\n\\nCodeMMLU is a comprehensive benchmark designed to evaluate the capabilities of large language models (LLMs) in coding and software knowledge. \\nIt builds upon the structure of multiple-choice question answering (MCQA) to cover a wide range of programming tasks and domains, including code generation, defect detection, software engineering principles, and much more.‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Fsoft-AIC/CodeMMLU."},
	{"name":"soloby","keyword":"monolingual","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/nyuuzyou/soloby","creator_name":"nyuuzyou","creator_url":"https://huggingface.co/nyuuzyou","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Soloby.ru\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThis dataset contains 744,131 question-answer pairs in Russian language extracted from soloby.ru website. The content includes educational questions and answers across various subjects and categories.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages\\n\\t\\n\\nThe dataset is primarily in Russian (ru).\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Structure\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Fields\\n\\t\\n\\nThis dataset includes the following fields:\\n\\npage_url: URL of the question page (string)‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/nyuuzyou/soloby."},
	{"name":"RussianFinancialNews","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Kasymkhan/RussianFinancialNews","creator_name":"Kasymkhan","creator_url":"https://huggingface.co/Kasymkhan","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tRussianFinancialNews\\n\\t\\n\\n–î–∞—Ç–∞—Å–µ—Ç —Å–æ–¥–µ—Ä–∂–∏—Ç 92,377 —Ä—É—Å—Å–∫–æ—è–∑—ã—á–Ω—ã—Ö –Ω–æ–≤–æ—Å—Ç–Ω—ã—Ö —Å—Ç–∞—Ç–µ–π –Ω–∞ —Ñ–∏–Ω–∞–Ω—Å–æ–≤—É—é —Ç–µ–º–∞—Ç–∏–∫—É, –ø—Ä–µ–∏–º—É—â–µ—Å—Ç–≤–µ–Ω–Ω–æ –ø—Ä–æ —Ä–æ—Å—Å–∏–π—Å–∫–∏–π —Ä—ã–Ω–æ–∫ —Ü–µ–Ω–Ω—ã—Ö –±—É–º–∞–≥ –∏ —Ä–æ—Å—Å–∏–π—Å–∫—É—é —ç–∫–æ–Ω–æ–º–∏–∫—É. –ù–∞–±–æ—Ä –¥–∞–Ω–Ω—ã—Ö –º–æ–∂–µ—Ç –±—ã—Ç—å –ø–æ–ª–µ–∑–µ–Ω –¥–ª—è —Ä–∞–∑–Ω—ã—Ö –∑–∞–¥–∞—á –æ–±—Ä–∞–±–æ—Ç–∫–∏ –µ—Å—Ç–µ—Å—Ç–≤–µ–Ω–Ω–æ–≥–æ —è–∑—ã–∫–∞ (NLP). \\nA dataset containing 92,377 samples of Russian financial news articles. Each sample includes metadata and content fields that are useful for various Natural Language Processing (NLP) tasks.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Kasymkhan/RussianFinancialNews."},
	{"name":"allstar","keyword":"monolingual","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/nyuuzyou/allstar","creator_name":"nyuuzyou","creator_url":"https://huggingface.co/nyuuzyou","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Allstar.gg Clips\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThis dataset contains information about 47,896 video clips from the gaming platform allstar.gg. The clips primarily focus on Counter-Strike 2 gameplay moments and include detailed metadata such as player information, game statistics, view counts, and related media URLs.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages\\n\\t\\n\\nThe dataset is primarily in English (en).\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Structure\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Fields\\n\\t\\n\\nThis dataset‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/nyuuzyou/allstar."},
	{"name":"Olympiads","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/artnoage/Olympiads","creator_name":"Vaios Laschos","creator_url":"https://huggingface.co/artnoage","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tNumina-Olympiads\\n\\t\\n\\nFiltered NuminaMath-CoT dataset containing only olympiads problems with valid answers.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Information\\n\\t\\n\\n\\nSplit: train\\nOriginal size: 137830\\nFiltered size: 42607\\nSource: olympiads\\nAll examples contain valid boxed answers\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThis dataset is a filtered version of the NuminaMath-CoT dataset, containing only problems from olympiad sources that have valid boxed answers. Each example includes:\\n\\nA mathematical word‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/artnoage/Olympiads."},
	{"name":"question_answering","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/azizmatin/question_answering","creator_name":"Aziz Matin","creator_url":"https://huggingface.co/azizmatin","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Information\\n\\t\\n\\nThis Question Answering dataset is a reading comprehension resource derived from Persian Wikipedia. This crowd-sourced dataset contains over 9,000 entries, each of which can either be an unanswerable question or a question with one or more answers based on the provided context. Similar to the SQuAD2.0 dataset, the inclusion of unanswerable questions allows for the development of systems that \\\"know they don't know the answer.\\\" Additionally, the dataset‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/azizmatin/question_answering."},
	{"name":"gsm8k","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/openai/gsm8k","creator_name":"OpenAI","creator_url":"https://huggingface.co/openai","description":"\\n\\t\\n\\t\\t\\n\\t\\tDataset Card for GSM8K\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nGSM8K (Grade School Math 8K) is a dataset of 8.5K high quality linguistically diverse grade school math word problems. The dataset was created to support the task of question answering on basic mathematical problems that require multi-step reasoning.\\n\\nThese problems take between 2 and 8 steps to solve.\\nSolutions primarily involve performing a sequence of elementary calculations using basic arithmetic operations (+ ‚àí √ó√∑) to reach the‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/openai/gsm8k."},
	{"name":"PubMedQA","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/qiaojin/PubMedQA","creator_name":"Qiao Jin","creator_url":"https://huggingface.co/qiaojin","description":"\\n\\t\\n\\t\\t\\n\\t\\tDataset Card for [Dataset Name]\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThe task of PubMedQA is to answer research questions with yes/no/maybe (e.g.: Do preoperative statins reduce atrial fibrillation after coronary artery bypass grafting?) using the corresponding abstracts.\\n\\n\\t\\n\\t\\t\\n\\t\\tSupported Tasks and Leaderboards\\n\\t\\n\\nThe official leaderboard is available at: https://pubmedqa.github.io/.\\n500 questions in the pqa_labeled are used as the test set. They can be found at‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/qiaojin/PubMedQA."},
	{"name":"mmlu","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/cais/mmlu","creator_name":"Center for AI Safety","creator_url":"https://huggingface.co/cais","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for MMLU\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nMeasuring Massive Multitask Language Understanding by Dan Hendrycks, Collin Burns, Steven Basart, Andy Zou, Mantas Mazeika, Dawn Song, and Jacob Steinhardt (ICLR 2021).\\nThis is a massive multitask test consisting of multiple-choice questions from various branches of knowledge. The test spans subjects in the humanities, social sciences, hard sciences, and other areas that are important for some people to learn. This covers 57‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/cais/mmlu."},
	{"name":"code_contests","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/deepmind/code_contests","creator_name":"Deepmind","creator_url":"https://huggingface.co/deepmind","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for CodeContests\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nCodeContests is a competitive programming dataset for machine-learning. This\\ndataset was used when training AlphaCode.\\nIt consists of programming problems, from a variety of sources:\\n\\n\\t\\n\\t\\t\\nSite\\nURL\\nSource\\n\\n\\n\\t\\t\\nAizu\\nhttps://judge.u-aizu.ac.jp\\nCodeNet\\n\\n\\nAtCoder\\nhttps://atcoder.jp\\nCodeNet\\n\\n\\nCodeChef\\nhttps://www.codechef.com\\ndescription2code\\n\\n\\nCodeforces\\nhttps://codeforces.com\\ndescription2code and Codeforces\\n\\n\\nHackerEarth‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/deepmind/code_contests."},
	{"name":"fimfiction","keyword":"monolingual","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/nyuuzyou/fimfiction","creator_name":"nyuuzyou","creator_url":"https://huggingface.co/nyuuzyou","description":"\\n\\t\\n\\t\\t\\n\\t\\tDataset Card for Fimfiction.net\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThis dataset contains 815,740 user stories from Fimfiction.net, a platform dedicated to fanfiction. Each entry includes the story's title, content, and unique identifier. The writings span diverse genres, themes, and creative styles, contributed by the platform's community. \\n\\n\\t\\n\\t\\t\\n\\t\\tLanguages\\n\\t\\n\\nThe dataset is primarily in English. \\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Structure\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tData Fields\\n\\t\\n\\n\\nid: Unique identifier for the story‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/nyuuzyou/fimfiction."},
	{"name":"squad","keyword":"monolingual","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/rajpurkar/squad","creator_name":"Pranav R","creator_url":"https://huggingface.co/rajpurkar","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for SQuAD\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nStanford Question Answering Dataset (SQuAD) is a reading comprehension dataset, consisting of questions posed by crowdworkers on a set of Wikipedia articles, where the answer to every question is a segment of text, or span, from the corresponding reading passage, or the question might be unanswerable.\\nSQuAD 1.1 contains 100,000+ question-answer pairs on 500+ articles.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSupported Tasks and Leaderboards\\n\\t\\n\\nQuestion‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/rajpurkar/squad."},
	{"name":"MathVista","keyword":"monolingual","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/AI4Math/MathVista","creator_name":"AI for Math Reasoning","creator_url":"https://huggingface.co/AI4Math","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for MathVista\\n\\t\\n\\n\\nDataset Description\\nPaper Information\\nDataset Examples\\nLeaderboard\\nDataset Usage\\nData Downloading\\nData Format\\nData Visualization\\nData Source\\nAutomatic Evaluation\\n\\n\\nLicense\\nCitation\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nMathVista is a consolidated Mathematical reasoning benchmark within Visual contexts. It consists of three newly created datasets, IQTest, FunctionQA, and PaperQA, which address the missing visual domains and are tailored to evaluate‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/AI4Math/MathVista."},
	{"name":"ai2_arc","keyword":"monolingual","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/allenai/ai2_arc","creator_name":"Ai2","creator_url":"https://huggingface.co/allenai","description":"\\n\\t\\n\\t\\t\\n\\t\\tDataset Card for \\\"ai2_arc\\\"\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nA new dataset of 7,787 genuine grade-school level, multiple-choice science questions, assembled to encourage research in\\n advanced question-answering. The dataset is partitioned into a Challenge Set and an Easy Set, where the former contains\\n only questions answered incorrectly by both a retrieval-based algorithm and a word co-occurrence algorithm. We are also\\n including a corpus of over 14 million science sentences relevant to‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/allenai/ai2_arc."},
	{"name":"narrativeqa","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/deepmind/narrativeqa","creator_name":"Deepmind","creator_url":"https://huggingface.co/deepmind","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Narrative QA\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nNarrativeQA is an English-lanaguage dataset of stories and corresponding questions designed to test reading comprehension, especially on long documents.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSupported Tasks and Leaderboards\\n\\t\\n\\nThe dataset is used to test reading comprehension. There are 2 tasks proposed in the paper: \\\"summaries only\\\" and \\\"stories only\\\", depending on whether the human-generated summary or the full story text is used to answer‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/deepmind/narrativeqa."},
	{"name":"truthful_qa","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/truthfulqa/truthful_qa","creator_name":"TruthfulQA","creator_url":"https://huggingface.co/truthfulqa","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for truthful_qa\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nTruthfulQA is a benchmark to measure whether a language model is truthful in generating answers to questions. The benchmark comprises 817 questions that span 38 categories, including health, law, finance and politics. Questions are crafted so that some humans would answer falsely due to a false belief or misconception. To perform well, models must avoid generating false answers learned from imitating human texts.‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/truthfulqa/truthful_qa."},
	{"name":"zeroth-korean","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Bingsu/zeroth-korean","creator_name":"Dowon Hwang","creator_url":"https://huggingface.co/Bingsu","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tZeroth-Korean\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tZeroth-Korean\\n\\t\\n\\nThe data set contains transcriebed audio data for Korean. There are 51.6 hours transcribed Korean audio for training data (22,263 utterances, 105 people, 3000 sentences) and 1.2 hours transcribed Korean audio for testing data (457 utterances, 10 people). This corpus also contains pre-trained/designed language model, lexicon and morpheme-based segmenter(morfessor).\\nZeroth project introduces free Korean speech corpus and aims to make‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Bingsu/zeroth-korean."},
	{"name":"real-toxicity-prompts","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/allenai/real-toxicity-prompts","creator_name":"Ai2","creator_url":"https://huggingface.co/allenai","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Real Toxicity Prompts\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nRealToxicityPrompts is a dataset of 100k sentence snippets from the web for researchers to further address the risk of neural toxic degeneration in models.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages\\n\\t\\n\\nEnglish\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Structure\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Instances\\n\\t\\n\\nEach instance represents a prompt and its metadata:\\n{\\n  \\\"filename\\\":\\\"0766186-bc7f2a64cb271f5f56cf6f25570cd9ed.txt\\\",\\n  \\\"begin\\\":340,\\n  \\\"end\\\":564‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/allenai/real-toxicity-prompts."},
	{"name":"twitter-financial-news-sentiment","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/zeroshot/twitter-financial-news-sentiment","creator_name":"not a","creator_url":"https://huggingface.co/zeroshot","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThe Twitter Financial News dataset is an English-language dataset containing an annotated corpus of finance-related tweets. This dataset is used to classify finance-related tweets for their sentiment.\\n\\nThe dataset holds 11,932 documents annotated with 3 labels:\\n\\nsentiments = {\\n    \\\"LABEL_0\\\": \\\"Bearish\\\", \\n    \\\"LABEL_1\\\": \\\"Bullish\\\", \\n    \\\"LABEL_2\\\": \\\"Neutral\\\"\\n}  \\n\\nThe data was collected using the Twitter API. The current dataset supports the multi-class‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/zeroshot/twitter-financial-news-sentiment."},
	{"name":"soda","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/allenai/soda","creator_name":"Ai2","creator_url":"https://huggingface.co/allenai","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for ü•§SODA\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nü•§SODA is the first publicly available, million-scale, high-quality dialogue dataset covering a wide range of social interactions. Dialogues are distilled from a PLM (InstructGPT; Ouyang et al., 2022) by contextualizing social commonsense knowledge from a knowledge graph (Atomic10x; West et al., 2022). Human evaluation shows that dialogues in SODA are more consistent, specific, and (surprisingly) natural than prior‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/allenai/soda."},
	{"name":"ScienceQA","keyword":"monolingual","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/derek-thomas/ScienceQA","creator_name":"Derek Thomas","creator_url":"https://huggingface.co/derek-thomas","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card Creation Guide\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nLearn to Explain: Multimodal Reasoning via Thought Chains for Science Question Answering\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSupported Tasks and Leaderboards\\n\\t\\n\\nMulti-modal Multiple Choice\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages\\n\\t\\n\\nEnglish\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Structure\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Instances\\n\\t\\n\\nExplore more samples here.\\n{'image': Image,\\n 'question': 'Which of these states is farthest north?',\\n 'choices': ['West Virginia', 'Louisiana', 'Arizona'‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/derek-thomas/ScienceQA."},
	{"name":"amazon_polarity","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/fancyzhx/amazon_polarity","creator_name":"Xiang Zhang","creator_url":"https://huggingface.co/fancyzhx","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Amazon Review Polarity\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThe Amazon reviews dataset consists of reviews from amazon.\\nThe data span a period of 18 years, including ~35 million reviews up to March 2013.\\nReviews include product and user information, ratings, and a plaintext review.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSupported Tasks and Leaderboards\\n\\t\\n\\n\\ntext-classification, sentiment-classification: The dataset is mainly used for text classification: given the content and the title, predict‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/fancyzhx/amazon_polarity."},
	{"name":"aqua_rat","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/deepmind/aqua_rat","creator_name":"Deepmind","creator_url":"https://huggingface.co/deepmind","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for AQUA-RAT\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nA large-scale dataset consisting of approximately 100,000 algebraic word problems.\\nThe solution to each question is explained step-by-step using natural language.\\nThis data is used to train a program generation model that learns to generate the explanation,\\nwhile generating the program that solves the question.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSupported Tasks and Leaderboards\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages\\n\\t\\n\\nen\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Structure‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/deepmind/aqua_rat."},
	{"name":"banking77","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/legacy-datasets/banking77","creator_name":"Legacy Datasets","creator_url":"https://huggingface.co/legacy-datasets","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for BANKING77\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\n\\n  Deprecated: Dataset \\\"banking77\\\" is deprecated and will be deleted. Use \\\"PolyAI/banking77\\\" instead.\\n\\n\\nDataset composed of online banking queries annotated with their corresponding intents.\\nBANKING77 dataset provides a very fine-grained set of intents in a banking domain.\\nIt comprises 13,083 customer service queries labeled with 77 intents. \\nIt focuses on fine-grained single-domain intent detection.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSupported‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/legacy-datasets/banking77."},
	{"name":"beans","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/AI-Lab-Makerere/beans","creator_name":"Makerere AI Lab","creator_url":"https://huggingface.co/AI-Lab-Makerere","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Beans\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nBeans leaf dataset with images of diseased and health leaves.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSupported Tasks and Leaderboards\\n\\t\\n\\n\\nimage-classification: Based on a leaf image, the goal of this task is to predict the disease type (Angular Leaf Spot and Bean Rust), if any.\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages\\n\\t\\n\\nEnglish\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Structure\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Instances\\n\\t\\n\\nA sample from the training set is provided below:\\n{\\n    'image_file_path':‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/AI-Lab-Makerere/beans."},
	{"name":"billsum","keyword":"monolingual","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/FiscalNote/billsum","creator_name":"FiscalNote","creator_url":"https://huggingface.co/FiscalNote","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for \\\"billsum\\\"\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nBillSum, summarization of US Congressional and California state bills.\\nThere are several features:\\n\\ntext: bill text.\\nsummary: summary of the bills.\\ntitle: title of the bills.\\nfeatures for us bills. ca bills does not have.\\ntext_len: number of chars in text.\\nsum_len: number of chars in summary.\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSupported Tasks and Leaderboards\\n\\t\\n\\nMore Information Needed\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages\\n\\t\\n\\nMore Information Needed‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/FiscalNote/billsum."},
	{"name":"blimp","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/nyu-mll/blimp","creator_name":"NYU Machine Learning for Language","creator_url":"https://huggingface.co/nyu-mll","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for \\\"blimp\\\"\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nBLiMP is a challenge set for evaluating what language models (LMs) know about\\nmajor grammatical phenomena in English. BLiMP consists of 67 sub-datasets, each\\ncontaining 1000 minimal pairs isolating specific contrasts in syntax,\\nmorphology, or semantics. The data is automatically generated according to\\nexpert-crafted grammars.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSupported Tasks and Leaderboards\\n\\t\\n\\nMore Information Needed\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/nyu-mll/blimp."},
	{"name":"bn_hate_speech","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/rezacsedu/bn_hate_speech","creator_name":"Rezaul Karim, PhD.","creator_url":"https://huggingface.co/rezacsedu","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Bengali Hate Speech Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThe Bengali Hate Speech Dataset is a Bengali-language dataset of news articles collected from various Bengali media sources and categorized based on the type of hate in the text. The dataset was created to provide greater support for under-resourced languages like Bengali on NLP tasks, and serves as a benchmark for multiple types of classification tasks. \\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSupported Tasks and Leaderboards‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/rezacsedu/bn_hate_speech."},
	{"name":"casino","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/kchawla123/casino","creator_name":"Kushal Chawla","creator_url":"https://huggingface.co/kchawla123","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Casino\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nWe provide a novel dataset (referred to as CaSiNo) of 1030 negotiation dialogues. Two participants take the role of campsite neighbors and negotiate for Food, Water, and Firewood packages, based on their individual preferences and requirements. This design keeps the task tractable, while still facilitating linguistically rich and personal conversations. This helps to overcome the limitations of prior negotiation datasets‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/kchawla123/casino."},
	{"name":"cfq","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/google-research-datasets/cfq","creator_name":"Google Research Datasets","creator_url":"https://huggingface.co/google-research-datasets","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for \\\"cfq\\\"\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThe Compositional Freebase Questions (CFQ) is a dataset that is specifically designed to measure compositional\\ngeneralization. CFQ is a simple yet realistic, large dataset of natural language questions and answers that also\\nprovides for each question a corresponding SPARQL query against the Freebase knowledge base. This means that CFQ can\\nalso be used for semantic parsing.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSupported Tasks and Leaderboards\\n\\t\\n\\nMore‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/google-research-datasets/cfq."},
	{"name":"cmrc2018","keyword":"monolingual","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/hfl/cmrc2018","creator_name":"Joint Laboratory of HIT and iFLYTEK Research (HFL)","creator_url":"https://huggingface.co/hfl","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for \\\"cmrc2018\\\"\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nA Span-Extraction dataset for Chinese machine reading comprehension to add language\\ndiversities in this area. The dataset is composed by near 20,000 real questions annotated\\non Wikipedia paragraphs by human experts. We also annotated a challenge set which\\ncontains the questions that need comprehensive understanding and multi-sentence\\ninference throughout the context.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSupported Tasks and Leaderboards\\n\\t\\n\\nMore‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/hfl/cmrc2018."},
	{"name":"cnn_dailymail","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/abisee/cnn_dailymail","creator_name":"Abigail See","creator_url":"https://huggingface.co/abisee","description":"\\n\\t\\n\\t\\t\\n\\t\\tDataset Card for CNN Dailymail Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThe CNN / DailyMail Dataset is an English-language dataset containing just over 300k unique news articles as written by journalists at CNN and the Daily Mail. The current version supports both extractive and abstractive summarization, though the original version was created for machine reading and comprehension and abstractive question answering. \\n\\n\\t\\n\\t\\t\\n\\t\\tSupported Tasks and Leaderboards\\n\\t\\n\\n\\n'summarization': Versions‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/abisee/cnn_dailymail."},
	{"name":"common_gen","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/allenai/common_gen","creator_name":"Ai2","creator_url":"https://huggingface.co/allenai","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for \\\"common_gen\\\"\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nCommonGen is a constrained text generation task, associated with a benchmark dataset,\\nto explicitly test machines for the ability of generative commonsense reasoning. Given\\na set of common concepts; the task is to generate a coherent sentence describing an\\neveryday scenario using these concepts.\\nCommonGen is challenging because it inherently requires 1) relational reasoning using\\nbackground commonsense knowledge, and‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/allenai/common_gen."},
	{"name":"commonsense_qa","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/tau/commonsense_qa","creator_name":"Tel Aviv University","creator_url":"https://huggingface.co/tau","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for \\\"commonsense_qa\\\"\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nCommonsenseQA is a new multiple-choice question answering dataset that requires different types of commonsense knowledge\\nto predict the correct answers . It contains 12,102 questions with one correct answer and four distractor answers.\\nThe dataset is provided in two major training/validation/testing set splits: \\\"Random split\\\" which is the main evaluation\\nsplit, and \\\"Question token split\\\", see paper for details.‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/tau/commonsense_qa."},
	{"name":"conceptnet5","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/conceptnet5/conceptnet5","creator_name":"conceptnet5","creator_url":"https://huggingface.co/conceptnet5","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Conceptnet5\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nConceptNet is a multilingual knowledge base, representing words and\\nphrases that people use and the common-sense relationships between\\nthem. The knowledge in ConceptNet is collected from a variety of\\nresources, including crowd-sourced resources (such as Wiktionary and\\nOpen Mind Common Sense), games with a purpose (such as Verbosity and\\nnadya.jp), and expert-created resources (such as WordNet and JMDict).\\nYou can browse‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/conceptnet5/conceptnet5."},
	{"name":"covid_qa_deepset","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/deepset/covid_qa_deepset","creator_name":"deepset","creator_url":"https://huggingface.co/deepset","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for COVID-QA\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nCOVID-QA is a Question Answering dataset consisting of 2,019 question/answer pairs annotated by volunteer biomedical experts on scientific articles related to COVID-19.\\nA total of 147 scientific articles from the CORD-19 dataset were annotated by 15 experts.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSupported Tasks and Leaderboards\\n\\t\\n\\n[More Information Needed]\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages\\n\\t\\n\\nThe text in the dataset is in English.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Structure‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/deepset/covid_qa_deepset."},
	{"name":"drop","keyword":"monolingual","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ucinlp/drop","creator_name":"UCI NLP","creator_url":"https://huggingface.co/ucinlp","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for \\\"drop\\\"\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nDROP: A Reading Comprehension Benchmark Requiring Discrete Reasoning Over Paragraphs.\\n. DROP is a crowdsourced, adversarially-created, 96k-question benchmark, in which a system must resolve references in a\\nquestion, perhaps to multiple input positions, and perform discrete operations over them (such as addition, counting, or\\n sorting). These operations require a much more comprehensive understanding of the content of‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ucinlp/drop."},
	{"name":"exams","keyword":"monolingual","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mhardalov/exams","creator_name":"Momchil Hardalov","creator_url":"https://huggingface.co/mhardalov","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for [Dataset Name]\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nEXAMS is a benchmark dataset for multilingual and cross-lingual question answering from high school examinations. It consists of more than 24,000 high-quality high school exam questions in 16 languages, covering 8 language families and 24 school subjects from Natural Sciences and Social Sciences, among others.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSupported Tasks and Leaderboards\\n\\t\\n\\n[More Information Needed]\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages\\n\\t\\n\\nThe‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mhardalov/exams."},
	{"name":"fashion_mnist","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/zalando-datasets/fashion_mnist","creator_name":"zalando-datasets","creator_url":"https://huggingface.co/zalando-datasets","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for FashionMNIST\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nFashion-MNIST is a dataset of Zalando's article images‚Äîconsisting of a training set of 60,000 examples and a test set of 10,000 examples. Each example is a 28x28 grayscale image, associated with a label from 10 classes. We intend Fashion-MNIST to serve as a direct drop-in replacement for the original MNIST dataset for benchmarking machine learning algorithms. It shares the same image size and structure of training and‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/zalando-datasets/fashion_mnist."},
	{"name":"go_emotions","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/google-research-datasets/go_emotions","creator_name":"Google Research Datasets","creator_url":"https://huggingface.co/google-research-datasets","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for GoEmotions\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThe GoEmotions dataset contains 58k carefully curated Reddit comments labeled for 27 emotion categories or Neutral.\\nThe raw data is included as well as the smaller, simplified version of the dataset with predefined train/val/test\\nsplits.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSupported Tasks and Leaderboards\\n\\t\\n\\nThis dataset is intended for multi-class, multi-label emotion classification.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages\\n\\t\\n\\nThe data is in English.‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/google-research-datasets/go_emotions."},
	{"name":"greek_legal_code","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/AI-team-UoA/greek_legal_code","creator_name":"AI Team - University of Athens","creator_url":"https://huggingface.co/AI-team-UoA","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Greek Legal Code\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nGreek_Legal_Code (GLC) is a dataset consisting of approx. 47k legal resources from Greek legislation. The origin of GLC is ‚ÄúPermanent Greek Legislation Code - Raptarchis‚Äù, a collection of Greek legislative documents classified into multi-level (from broader to more specialized) categories.\\nTopics\\nGLC consists of 47 legislative volumes and each volume corresponds to a main thematic topic. Each volume is divided into‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/AI-team-UoA/greek_legal_code."},
	{"name":"kilt_tasks","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/facebook/kilt_tasks","creator_name":"AI at Meta","creator_url":"https://huggingface.co/facebook","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for KILT\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nKILT has been built from 11 datasets representing 5 types of tasks:\\n\\nFact-checking\\nEntity linking\\nSlot filling\\nOpen domain QA\\nDialog generation\\n\\nAll these datasets have been grounded in a single pre-processed Wikipedia dump, allowing for fairer and more consistent evaluation as well as enabling new task setups such as multitask and transfer learning with minimal effort. KILT also provides tools to analyze and understand the‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/facebook/kilt_tasks."},
	{"name":"klue","keyword":"monolingual","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/klue/klue","creator_name":"KLUE Benchmark","creator_url":"https://huggingface.co/klue","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for KLUE\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nKLUE is a collection of 8 tasks to evaluate natural language understanding capability of Korean language models. We delibrately select the 8 tasks, which are Topic Classification, Semantic Textual Similarity, Natural Language Inference, Named Entity Recognition, Relation Extraction, Dependency Parsing, Machine Reading Comprehension, and Dialogue State Tracking.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSupported Tasks and Leaderboards\\n\\t\\n\\nTopic‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/klue/klue."},
	{"name":"lex_glue","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/coastalcph/lex_glue","creator_name":"CoAStaL NLP Group","creator_url":"https://huggingface.co/coastalcph","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for \\\"LexGLUE\\\"\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nInspired by the recent widespread use of the GLUE multi-task benchmark NLP dataset (Wang et al., 2018), the subsequent more difficult SuperGLUE (Wang et al., 2019), other previous multi-task NLP benchmarks (Conneau and Kiela, 2018; McCann et al., 2018), and similar initiatives in other domains (Peng et al., 2019), we introduce the Legal General Language Understanding Evaluation (LexGLUE) benchmark, a benchmark dataset to‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/coastalcph/lex_glue."},
	{"name":"mbpp","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/google-research-datasets/mbpp","creator_name":"Google Research Datasets","creator_url":"https://huggingface.co/google-research-datasets","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Mostly Basic Python Problems (mbpp)\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThe benchmark consists of around 1,000 crowd-sourced Python programming problems, designed to be solvable by entry level programmers, covering programming fundamentals, standard library functionality, and so on. Each problem consists of a task description, code solution and 3 automated test cases. As described in the paper, a subset of the data has been hand-verified by us. \\nReleased here as part‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/google-research-datasets/mbpp."},
	{"name":"mnist","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/ylecun/mnist","creator_name":"Yann LeCun","creator_url":"https://huggingface.co/ylecun","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for MNIST\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThe MNIST dataset consists of 70,000 28x28 black-and-white images of handwritten digits extracted from two NIST databases. There are 60,000 images in the training dataset and 10,000 images in the validation dataset, one class per digit so a total of 10 classes, with 7,000 images (6,000 train images and 1,000 test images) per class.\\nHalf of the image were drawn by Census Bureau employees and the other half by high school‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ylecun/mnist."},
	{"name":"myanmar_news","keyword":"monolingual","license":"GNU General Public License v3.0","license_url":"https://choosealicense.com/licenses/gpl-3.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ayehninnkhine/myanmar_news","creator_name":"Aye Hninn Khine","creator_url":"https://huggingface.co/ayehninnkhine","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Myanmar_News\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThe Myanmar news dataset contains article snippets in four categories:\\nBusiness, Entertainment, Politics, and Sport.\\nThese were collected in October 2017 by Aye Hninn Khine\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages\\n\\t\\n\\nMyanmar/Burmese language\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Structure\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Fields\\n\\t\\n\\n\\ntext - text from article\\ncategory - a topic: Business, Entertainment, Politic, or Sport (note spellings)\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Splits\\n\\t\\n\\nOne‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ayehninnkhine/myanmar_news."},
	{"name":"openai_humaneval","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/openai/openai_humaneval","creator_name":"OpenAI","creator_url":"https://huggingface.co/openai","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for OpenAI HumanEval\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThe HumanEval dataset released by OpenAI includes 164 programming problems with a function sig- nature, docstring, body, and several unit tests. They were handwritten to ensure not to be included in the training set of code generation models.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSupported Tasks and Leaderboards\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages\\n\\t\\n\\nThe programming problems are written in Python and contain English natural text in comments and‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/openai/openai_humaneval."},
	{"name":"poem_sentiment","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/google-research-datasets/poem_sentiment","creator_name":"Google Research Datasets","creator_url":"https://huggingface.co/google-research-datasets","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Gutenberg Poem Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nPoem Sentiment is a sentiment dataset of poem verses from Project Gutenberg.\\nThis dataset can be used for tasks such as sentiment classification or style transfer for poems.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSupported Tasks and Leaderboards\\n\\t\\n\\n[More Information Needed]\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages\\n\\t\\n\\nThe text in the dataset is in English (en).\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Structure\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Instances\\n\\t\\n\\nExample of one instance in the‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/google-research-datasets/poem_sentiment."},
	{"name":"qasc","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/allenai/qasc","creator_name":"Ai2","creator_url":"https://huggingface.co/allenai","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for \\\"qasc\\\"\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nQASC is a question-answering dataset with a focus on sentence composition. It consists of 9,980 8-way multiple-choice\\nquestions about grade school science (8,134 train, 926 dev, 920 test), and comes with a corpus of 17M sentences.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSupported Tasks and Leaderboards\\n\\t\\n\\nMore Information Needed\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages\\n\\t\\n\\nMore Information Needed\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Structure\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Instances‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/allenai/qasc."},
	{"name":"qasper","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/allenai/qasper","creator_name":"Ai2","creator_url":"https://huggingface.co/allenai","description":"A dataset containing 1585 papers with 5049 information-seeking questions asked by regular readers of NLP papers, and answered by a separate set of NLP practitioners."},
	{"name":"tldr-17","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/webis/tldr-17","creator_name":"Webis Group","creator_url":"https://huggingface.co/webis","description":"This corpus contains preprocessed posts from the Reddit dataset.\\nThe dataset consists of 3,848,330 posts with an average length of 270 words for content,\\nand 28 words for the summary.\\n\\nFeatures includes strings: author, body, normalizedBody, content, summary, subreddit, subreddit_id.\\nContent is used as document and summary is used as summary."},
	{"name":"ronec","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/community-datasets/ronec","creator_name":"Community Datasets","creator_url":"https://huggingface.co/community-datasets","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for RONEC\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nRONEC, at version 2.0, holds 12330 sentences with over 0.5M tokens, annotated with 15 classes, to a total of 80.283 distinctly annotated entities.\\nThe corpus has the following classes and distribution in the train/valid/test splits:\\n| Classes      \\t| Total  \\t    | Train  \\t|         \\t| Valid  \\t|         \\t| Test   \\t|         \\t|\\n|-------------\\t|:------:\\t    |:------:\\t|:-------:\\t|:------:\\t|:-------:\\t|:------:\\t|:-------:\\t|\\n|‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/community-datasets/ronec."},
	{"name":"snli","keyword":"monolingual","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/stanfordnlp/snli","creator_name":"Stanford NLP","creator_url":"https://huggingface.co/stanfordnlp","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for SNLI\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThe SNLI corpus (version 1.0) is a collection of 570k human-written English sentence pairs manually labeled for balanced classification with the labels entailment, contradiction, and neutral, supporting the task of natural language inference (NLI), also known as recognizing textual entailment (RTE).\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSupported Tasks and Leaderboards\\n\\t\\n\\nNatural Language Inference (NLI), also known as Recognizing Textual Entailment‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/stanfordnlp/snli."},
	{"name":"spider","keyword":"monolingual","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/xlangai/spider","creator_name":"XLang NLP Lab","creator_url":"https://huggingface.co/xlangai","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Spider\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nSpider is a large-scale complex and cross-domain semantic parsing and text-to-SQL dataset annotated by 11 Yale students.\\nThe goal of the Spider challenge is to develop natural language interfaces to cross-domain databases.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSupported Tasks and Leaderboards\\n\\t\\n\\nThe leaderboard can be seen at https://yale-lily.github.io/spider\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages\\n\\t\\n\\nThe text in the dataset is in English.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/xlangai/spider."},
	{"name":"squad_v2","keyword":"monolingual","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/rajpurkar/squad_v2","creator_name":"Pranav R","creator_url":"https://huggingface.co/rajpurkar","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for SQuAD 2.0\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nStanford Question Answering Dataset (SQuAD) is a reading comprehension dataset, consisting of questions posed by crowdworkers on a set of Wikipedia articles, where the answer to every question is a segment of text, or span, from the corresponding reading passage, or the question might be unanswerable.\\nSQuAD 2.0 combines the 100,000 questions in SQuAD1.1 with over 50,000 unanswerable questions written adversarially by‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/rajpurkar/squad_v2."},
	{"name":"stereoset","keyword":"monolingual","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/McGill-NLP/stereoset","creator_name":"McGill NLP Group","creator_url":"https://huggingface.co/McGill-NLP","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for StereoSet\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nStereoSet is a dataset that measures stereotype bias in language models. StereoSet consists of 17,000 sentences that measures model preferences across gender, race, religion, and profession.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSupported Tasks and Leaderboards\\n\\t\\n\\n\\nmultiple-choice question answering\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages\\n\\t\\n\\n\\nEnglish (en)\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Structure\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Instances\\n\\t\\n\\n#intersentence\\n{'bias_type': 'race'‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/McGill-NLP/stereoset."},
	{"name":"tashkeela","keyword":"monolingual","license":"GNU General Public License v2.0","license_url":"https://choosealicense.com/licenses/gpl-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/community-datasets/tashkeela","creator_name":"Community Datasets","creator_url":"https://huggingface.co/community-datasets","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Tashkeela\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nIt contains 75 million of fully vocalized words mainly\\n97 books from classical and modern Arabic language.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSupported Tasks and Leaderboards\\n\\t\\n\\n[More Information Needed]\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages\\n\\t\\n\\nThe dataset is based on Arabic.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Structure\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Instances\\n\\t\\n\\n{'book':‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/community-datasets/tashkeela."},
	{"name":"tweets_hate_speech_detection","keyword":"monolingual","license":"GNU General Public License v3.0","license_url":"https://choosealicense.com/licenses/gpl-3.0/","language":"en","dataset_url":"https://huggingface.co/datasets/tweets-hate-speech-detection/tweets_hate_speech_detection","creator_name":"tweets-hate-speech-detection","creator_url":"https://huggingface.co/tweets-hate-speech-detection","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Tweets Hate Speech Detection\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThe objective of this task is to detect hate speech in tweets. For the sake of simplicity, we say a tweet contains hate speech if it has a racist or sexist sentiment associated with it. So, the task is to classify racist or sexist tweets from other tweets.\\nFormally, given a training sample of tweets and labels, where label ‚Äò1‚Äô denotes the tweet is racist/sexist and label ‚Äò0‚Äô denotes the tweet is not‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/tweets-hate-speech-detection/tweets_hate_speech_detection."},
	{"name":"wino_bias","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/uclanlp/wino_bias","creator_name":"UCLA NLP","creator_url":"https://huggingface.co/uclanlp","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Wino_Bias dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nWinoBias, a Winograd-schema dataset for coreference resolution focused on gender bias.\\nThe corpus contains Winograd-schema style sentences with entities corresponding to people referred by their occupation (e.g. the nurse, the doctor, the carpenter).\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSupported Tasks and Leaderboards\\n\\t\\n\\nThe underlying task is coreference resolution. \\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages\\n\\t\\n\\nEnglish\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Structure‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/uclanlp/wino_bias."},
	{"name":"wisesight_sentiment","keyword":"monolingual","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/pythainlp/wisesight_sentiment","creator_name":"PyThaiNLP","creator_url":"https://huggingface.co/pythainlp","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for wisesight_sentiment\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nWisesight Sentiment Corpus: Social media messages in Thai language with sentiment label (positive, neutral, negative, question)\\n\\nReleased to public domain under Creative Commons Zero v1.0 Universal license.\\nLabels: {\\\"pos\\\": 0, \\\"neu\\\": 1, \\\"neg\\\": 2, \\\"q\\\": 3}\\nSize: 26,737 messages\\nLanguage: Central Thai\\nStyle: Informal and conversational. With some news headlines and advertisement.\\nTime period: Around 2016 to early‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/pythainlp/wisesight_sentiment."},
	{"name":"wongnai_reviews","keyword":"monolingual","license":"GNU Lesser General Public License v3.0","license_url":"https://choosealicense.com/licenses/lgpl-3.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Wongnai/wongnai_reviews","creator_name":"Wongnai","creator_url":"https://huggingface.co/Wongnai","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Wongnai_Reviews\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThe Wongnai Review dataset contains restaurant reviews and ratings, almost entirely in Thai language.\\nThe reviews are in 5 classes ranging from 1 to 5 stars.\\nThis dataset was featured in a Kaggle challenge https://www.kaggle.com/c/wongnai-challenge-review-rating-prediction/overview\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages\\n\\t\\n\\nThai\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Structure\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Fields\\n\\t\\n\\n\\nreview_body - text of review\\nstar_rating - an‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Wongnai/wongnai_reviews."},
	{"name":"youtube_caption_corrections","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/community-datasets/youtube_caption_corrections","creator_name":"Community Datasets","creator_url":"https://huggingface.co/community-datasets","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for YouTube Caption Corrections\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThis dataset is built from pairs of YouTube captions where both an auto-generated and a manually-corrected caption are available for a single specified language. It currently only in English, but scripts at repo support other languages. The motivation for creating it was from viewing errors in auto-generated captions at a recent virtual conference, with the hope that there could be some way to help‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/community-datasets/youtube_caption_corrections."},
	{"name":"rebel-dataset","keyword":"monolingual","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Babelscape/rebel-dataset","creator_name":"Babelscape","creator_url":"https://huggingface.co/Babelscape","description":"REBEL is a silver dataset created for the paper REBEL: Relation Extraction By End-to-end Language generation"},
	{"name":"CC-NEWS-ES","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/LeoCordoba/CC-NEWS-ES","creator_name":"Leonardo Ignacio C√≥rdoba","creator_url":"https://huggingface.co/LeoCordoba","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for CC-NEWS-ES\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nCC-NEWS-ES is a Spanish-language dataset of news. The corpus was generated by extracting the Spanish articles from CC-NEWS (news index of Common Crawl) of 2019. For doing that FastText model was used for language prediction.\\nIt contains a total of 7,473,286 texts and 1,812,009,283 words distributed as follows:\\n\\n\\t\\n\\t\\t\\ndomain\\ntexts\\nwords\\n\\n\\n\\t\\t\\nar\\n532703\\n1.45127e+08\\n\\n\\nbo\\n29557\\n7.28996e+06\\n\\n\\nbr\\n107\\n14207\\n\\n\\ncl\\n116661‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/LeoCordoba/CC-NEWS-ES."},
	{"name":"norwegian_parliament","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/NbAiLab/norwegian_parliament","creator_name":"Nasjonalbiblioteket AI Lab","creator_url":"https://huggingface.co/NbAiLab","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card Creation Guide\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThis is a classification dataset created from a subset of the Talk of Norway. This dataset contains text phrases from the political parties Fremskrittspartiet and Sosialistisk Venstreparti. The dataset is annotated with the party the speaker, as well as a timestamp. The classification task is to, simply by looking at the text, being able to predict is the speech was done by a representative from Fremskrittspartiet or‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/NbAiLab/norwegian_parliament."},
	{"name":"cantemist-ner","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/PlanTL-GOB-ES/cantemist-ner","creator_name":"Plan de Tecnolog√≠as del Lenguaje - Gobierno de Espa√±a","creator_url":"https://huggingface.co/PlanTL-GOB-ES","description":"https://temu.bsc.es/cantemist/"},
	{"name":"one-million-reddit-confessions","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/SocialGrep/one-million-reddit-confessions","creator_name":"SocialGrep","creator_url":"https://huggingface.co/SocialGrep","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for one-million-reddit-confessions\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThis corpus contains a million posts from the following subreddits:\\n\\n/r/trueoffmychest\\n/r/confession\\n/r/confessions\\n/r/offmychest\\n\\nPosts are annotated with their score.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages\\n\\t\\n\\nMainly English.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Structure\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Instances\\n\\t\\n\\nA data point is a Reddit post.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Fields\\n\\t\\n\\n\\n'type': the type of the data point. Can be 'post' or 'comment'.\\n'id':‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/SocialGrep/one-million-reddit-confessions."},
	{"name":"one-million-reddit-jokes","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/SocialGrep/one-million-reddit-jokes","creator_name":"SocialGrep","creator_url":"https://huggingface.co/SocialGrep","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for one-million-reddit-jokes\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThis corpus contains a million posts from /r/jokes.\\nPosts are annotated with their score.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages\\n\\t\\n\\nMainly English.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Structure\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Instances\\n\\t\\n\\nA data point is a Reddit post.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Fields\\n\\t\\n\\n\\n'type': the type of the data point. Can be 'post' or 'comment'.\\n'id': the base-36 Reddit ID of the data point. Unique when combined with type.‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/SocialGrep/one-million-reddit-jokes."},
	{"name":"one-million-reddit-questions","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/SocialGrep/one-million-reddit-questions","creator_name":"SocialGrep","creator_url":"https://huggingface.co/SocialGrep","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for one-million-reddit-questions\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThis corpus contains a million posts on /r/AskReddit, annotated with their score.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages\\n\\t\\n\\nMainly English.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Structure\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Instances\\n\\t\\n\\nA data point is a Reddit post.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Fields\\n\\t\\n\\n\\n'type': the type of the data point. Can be 'post' or 'comment'.\\n'id': the base-36 Reddit ID of the data point. Unique when combined with type.\\n'subreddit.id':‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/SocialGrep/one-million-reddit-questions."},
	{"name":"P3","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/bigscience/P3","creator_name":"BigScience Workshop","creator_url":"https://huggingface.co/bigscience","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for P3\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nP3 (Public Pool of Prompts) is a collection of prompted English datasets covering a diverse set of NLP tasks. A prompt is the combination of an input template and a target template. The templates are functions mapping a data example into natural language for the input and target sequences. For example, in the case of an NLI dataset, the data example would include fields for Premise, Hypothesis, Label. An input template would be‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/bigscience/P3."},
	{"name":"coda","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/corypaik/coda","creator_name":"Cory Paik","creator_url":"https://huggingface.co/corypaik","description":"*The Color Dataset* (CoDa) is a probing dataset to evaluate the representation of visual properties in language models. CoDa consists of color distributions for 521 common objects, which are split into 3 groups: Single, Multi, and Any."},
	{"name":"aaac","keyword":"monolingual","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/DebateLabKIT/aaac","creator_name":"DebateLab at KIT","creator_url":"https://huggingface.co/DebateLabKIT","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Artificial Argument Analysis Corpus (AAAC)\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nDeepA2 is a modular framework for deep argument analysis. DeepA2 datasets contain comprehensive logical reconstructions of informally presented arguments in short argumentative texts. This document describes two synthetic DeepA2 datasets for artificial argument analysis: AAAC01 and AAAC02.\\n# clone\\ngit lfs clone https://huggingface.co/datasets/debatelab/aaac\\n\\nimport pandas as pd\\nfrom‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/DebateLabKIT/aaac."},
	{"name":"klexikon","keyword":"monolingual","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/dennlinger/klexikon","creator_name":"Dennis Aumiller","creator_url":"https://huggingface.co/dennlinger","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for the Klexikon Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tVersion History\\n\\t\\n\\n\\nv0.3 (2022-09-01): Removing some five samples from the dataset due to duplication conflicts with other samples.\\nv0.2 (2022-02-28): Updated the files to no longer contain empty sections and removing otherwise empty lines at the end of files. Also removing lines with some sort of coordinate.\\nv0.1 (2022-01-19): Initial data release on Huggingface datasets.\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThe Klexikon dataset is a‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/dennlinger/klexikon."},
	{"name":"nli_zh","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/shibing624/nli_zh","creator_name":"Ming Xu (ÂæêÊòé)","creator_url":"https://huggingface.co/shibing624","description":"Á∫ØÊñáÊú¨Êï∞ÊçÆÔºåÊ†ºÂºèÔºöÔºàsentence1Ôºå sentence2Ôºå labelÔºâ„ÄÇÂ∏∏ËßÅ‰∏≠ÊñáËØ≠‰πâÂåπÈÖçÊï∞ÊçÆÈõÜÔºåÂåÖÂê´ATEC„ÄÅBQ„ÄÅLCQMC„ÄÅPAWSX„ÄÅSTS-BÂÖ±5‰∏™‰ªªÂä°„ÄÇ"},
	{"name":"catalan-dictionary","keyword":"monolingual","license":"GNU General Public License v2.0","license_url":"https://choosealicense.com/licenses/gpl-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/softcatala/catalan-dictionary","creator_name":"Softcatal√†","creator_url":"https://huggingface.co/softcatala","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for ca-text-corpus\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nCatalan word lists with part of speech labeling curated by humans. Contains 1 180 773 forms including verbs, nouns, adjectives, names or toponyms. These word lists are used to build applications like Catalan spellcheckers or verb querying applications.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSupported Tasks and Leaderboards\\n\\t\\n\\n[More Information Needed]\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages\\n\\t\\n\\nCatalan (ca).\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Structure\\n\\t\\n\\nThe dataset contains‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/softcatala/catalan-dictionary."},
	{"name":"turkish-sentiment-analysis-dataset","keyword":"monolingual","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/winvoker/turkish-sentiment-analysis-dataset","creator_name":"Batuhan","creator_url":"https://huggingface.co/winvoker","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset\\n\\t\\n\\nThis dataset contains positive , negative and notr sentences from several data sources given in the references. In the most sentiment models , there are only two labels; positive and negative. However , user input can be totally notr sentence. For such cases there were no data I could find. Therefore I created this dataset with 3 class. Positive and negative sentences are listed below. Notr examples are extraced from turkish wiki dump. In addition, added some random text‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/winvoker/turkish-sentiment-analysis-dataset."},
	{"name":"finer-139","keyword":"monolingual","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/nlpaueb/finer-139","creator_name":"AUEB NLP Group","creator_url":"https://huggingface.co/nlpaueb","description":"FiNER-139 is a named entity recognition dataset consisting of 10K annual \\nand quarterly English reports (filings) of publicly traded companies \\ndownloaded from the U.S. Securities and Exchange Commission (SEC) \\nannotated with 139 XBRL tags in the IOB2 format."},
	{"name":"roman_urdu_hate_speech","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/community-datasets/roman_urdu_hate_speech","creator_name":"Community Datasets","creator_url":"https://huggingface.co/community-datasets","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for roman_urdu_hate_speech\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThe Roman Urdu Hate-Speech and Offensive Language Detection (RUHSOLD) dataset is a Roman Urdu dataset of tweets annotated by experts in the relevant language. The authors develop the gold-standard for two sub-tasks. First sub-task is based on binary labels of Hate-Offensive content and Normal content (i.e., inoffensive language). These labels are self-explanatory. The authors refer to this sub-task as‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/community-datasets/roman_urdu_hate_speech."},
	{"name":"Ukr-Synth","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/ukr-models/Ukr-Synth","creator_name":"Volodymyr Kurnosov","creator_url":"https://huggingface.co/ukr-models","description":"Large silver standard Ukrainian corpus annotated with morphology tags, syntax trees and PER, LOC, ORG NER-tags."},
	{"name":"Sinhala-News-Category-classification","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/NLPC-UOM/Sinhala-News-Category-classification","creator_name":"The National Languages Processing Centre","creator_url":"https://huggingface.co/NLPC-UOM","description":"This file contains news texts (sentences) belonging to 5 different news categories (political, business, technology, sports and Entertainment). The original dataset was released by Nisansa de Silva (Sinhala Text Classification: Observations from the Perspective of a Resource Poor Language, 2015). The original dataset is processed and cleaned of single word texts, English only sentences etc. \\nIf you use this dataset, please cite {Nisansa de Silva, Sinhala Text Classification: Observations from‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/NLPC-UOM/Sinhala-News-Category-classification."},
	{"name":"kobest_v1","keyword":"monolingual","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/skt/kobest_v1","creator_name":"SK Telecom","creator_url":"https://huggingface.co/skt","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for KoBEST\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nKoBEST is a Korean benchmark suite consists of 5 natural language understanding tasks that requires advanced knowledge in Korean.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSupported Tasks and Leaderboards\\n\\t\\n\\nBoolean Question Answering, Choice of Plausible Alternatives, Words-in-Context, HellaSwag, Sentiment Negation Recognition\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages\\n\\t\\n\\nko-KR\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Structure\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Instances\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tKB-BoolQ\\n\\t\\n\\nAn example‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/skt/kobest_v1."},
	{"name":"spanish_imdb_synopsis","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mathigatti/spanish_imdb_synopsis","creator_name":"Mathias Gatti","creator_url":"https://huggingface.co/mathigatti","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Spanish IMDb Synopsis\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\n4969 movie synopsis from IMDb in spanish.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\n[N/A]\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages\\n\\t\\n\\nAll descriptions are in spanish, the other fields have some mix of spanish and english.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Structure\\n\\t\\n\\n[N/A]\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Fields\\n\\t\\n\\n\\ndescription: IMDb description for the movie (string), should be spanish\\nkeywords: IMDb keywords for the movie (string), mix of spanish and english‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mathigatti/spanish_imdb_synopsis."},
	{"name":"kote","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/searle-j/kote","creator_name":"Jeon Duyoung","creator_url":"https://huggingface.co/searle-j","description":"50k Korean online comments labeled for 44 emotion categories."},
	{"name":"medmcqa","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/openlifescienceai/medmcqa","creator_name":"Open Life Science AI","creator_url":"https://huggingface.co/openlifescienceai","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for MedMCQA\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nMedMCQA is a large-scale, Multiple-Choice Question Answering (MCQA) dataset designed to address real-world medical entrance exam questions.\\nMedMCQA has more than 194k high-quality AIIMS & NEET PG entrance exam MCQs covering 2.4k healthcare topics and 21 medical subjects are collected with an average token length of 12.77 and high topical diversity.\\nEach sample contains a question, correct answer(s), and other options which‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/openlifescienceai/medmcqa."},
	{"name":"TruthfulQA","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/domenicrosati/TruthfulQA","creator_name":"Domenic Rosati","creator_url":"https://huggingface.co/domenicrosati","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for TruthfulQA\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nTruthfulQA: Measuring How Models Mimic Human Falsehoods\\nWe propose a benchmark to measure whether a language model is truthful in generating answers to questions. The benchmark comprises 817 questions that span 38 categories, including health, law, finance and politics. We crafted questions that some humans would answer falsely due to a false belief or misconception. To perform well, models must avoid generating false‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/domenicrosati/TruthfulQA."},
	{"name":"slither-audited-smart-contracts","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/mwritescode/slither-audited-smart-contracts","creator_name":"Martina Rossini","creator_url":"https://huggingface.co/mwritescode","description":"This dataset contains source code and deployed bytecode for Solidity Smart Contracts that have been verified on Etherscan.io, along with a classification of their vulnerabilities according to the Slither static analysis framework."},
	{"name":"nlpcc-stance","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/strombergnlp/nlpcc-stance","creator_name":"Str√∏mberg NLP","creator_url":"https://huggingface.co/strombergnlp","description":"This is a stance prediction dataset in Chinese.\\nThe data is that from a shared task, stance detection in Chinese microblogs, in NLPCC-ICCPOL 2016. It covers Task A, a mandatory supervised task which detects stance towards five targets of interest with given labeled data."},
	{"name":"gov_report","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/launch/gov_report","creator_name":"LAUNCH Lab","creator_url":"https://huggingface.co/launch","description":"GovReport long document summarization dataset.\\n\\nThere are three configs:\\n  - plain_text: plain text document-to-summary pairs\\n  - plain_text_with_recommendations: plain text doucment-summary pairs, with \\\"What GAO recommends\\\" included in the summary\\n  - structure: data with section structure"},
	{"name":"fiqa","keyword":"monolingual","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/BeIR/fiqa","creator_name":"BEIR","creator_url":"https://huggingface.co/BeIR","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for BEIR Benchmark\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nBEIR is a heterogeneous benchmark that has been built from 18 diverse datasets representing 9 information retrieval tasks:\\n\\nFact-checking: FEVER, Climate-FEVER, SciFact\\nQuestion-Answering: NQ, HotpotQA, FiQA-2018\\nBio-Medical IR: TREC-COVID, BioASQ, NFCorpus\\nNews Retrieval: TREC-NEWS, Robust04\\nArgument Retrieval: Touche-2020, ArguAna\\nDuplicate Question Retrieval: Quora, CqaDupstack\\nCitation-Prediction: SCIDOCS\\nTweet‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/BeIR/fiqa."},
	{"name":"trec-covid","keyword":"monolingual","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/BeIR/trec-covid","creator_name":"BEIR","creator_url":"https://huggingface.co/BeIR","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for BEIR Benchmark\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nBEIR is a heterogeneous benchmark that has been built from 18 diverse datasets representing 9 information retrieval tasks:\\n\\nFact-checking: FEVER, Climate-FEVER, SciFact\\nQuestion-Answering: NQ, HotpotQA, FiQA-2018\\nBio-Medical IR: TREC-COVID, BioASQ, NFCorpus\\nNews Retrieval: TREC-NEWS, Robust04\\nArgument Retrieval: Touche-2020, ArguAna\\nDuplicate Question Retrieval: Quora, CqaDupstack\\nCitation-Prediction: SCIDOCS\\nTweet‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/BeIR/trec-covid."},
	{"name":"msmarco","keyword":"monolingual","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/BeIR/msmarco","creator_name":"BEIR","creator_url":"https://huggingface.co/BeIR","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for BEIR Benchmark\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nBEIR is a heterogeneous benchmark that has been built from 18 diverse datasets representing 9 information retrieval tasks:\\n\\nFact-checking: FEVER, Climate-FEVER, SciFact\\nQuestion-Answering: NQ, HotpotQA, FiQA-2018\\nBio-Medical IR: TREC-COVID, BioASQ, NFCorpus\\nNews Retrieval: TREC-NEWS, Robust04\\nArgument Retrieval: Touche-2020, ArguAna\\nDuplicate Question Retrieval: Quora, CqaDupstack\\nCitation-Prediction: SCIDOCS\\nTweet‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/BeIR/msmarco."},
	{"name":"hotpotqa","keyword":"monolingual","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/BeIR/hotpotqa","creator_name":"BEIR","creator_url":"https://huggingface.co/BeIR","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for BEIR Benchmark\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nBEIR is a heterogeneous benchmark that has been built from 18 diverse datasets representing 9 information retrieval tasks:\\n\\nFact-checking: FEVER, Climate-FEVER, SciFact\\nQuestion-Answering: NQ, HotpotQA, FiQA-2018\\nBio-Medical IR: TREC-COVID, BioASQ, NFCorpus\\nNews Retrieval: TREC-NEWS, Robust04\\nArgument Retrieval: Touche-2020, ArguAna\\nDuplicate Question Retrieval: Quora, CqaDupstack\\nCitation-Prediction: SCIDOCS\\nTweet‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/BeIR/hotpotqa."},
	{"name":"dbpedia-entity","keyword":"monolingual","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/BeIR/dbpedia-entity","creator_name":"BEIR","creator_url":"https://huggingface.co/BeIR","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for BEIR Benchmark\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nBEIR is a heterogeneous benchmark that has been built from 18 diverse datasets representing 9 information retrieval tasks:\\n\\nFact-checking: FEVER, Climate-FEVER, SciFact\\nQuestion-Answering: NQ, HotpotQA, FiQA-2018\\nBio-Medical IR: TREC-COVID, BioASQ, NFCorpus\\nNews Retrieval: TREC-NEWS, Robust04\\nArgument Retrieval: Touche-2020, ArguAna\\nDuplicate Question Retrieval: Quora, CqaDupstack\\nCitation-Prediction: SCIDOCS\\nTweet‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/BeIR/dbpedia-entity."},
	{"name":"climate-fever","keyword":"monolingual","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/BeIR/climate-fever","creator_name":"BEIR","creator_url":"https://huggingface.co/BeIR","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for BEIR Benchmark\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nBEIR is a heterogeneous benchmark that has been built from 18 diverse datasets representing 9 information retrieval tasks:\\n\\nFact-checking: FEVER, Climate-FEVER, SciFact\\nQuestion-Answering: NQ, HotpotQA, FiQA-2018\\nBio-Medical IR: TREC-COVID, BioASQ, NFCorpus\\nNews Retrieval: TREC-NEWS, Robust04\\nArgument Retrieval: Touche-2020, ArguAna\\nDuplicate Question Retrieval: Quora, CqaDupstack\\nCitation-Prediction: SCIDOCS\\nTweet‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/BeIR/climate-fever."},
	{"name":"dbpedia-entity-generated-queries","keyword":"monolingual","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/BeIR/dbpedia-entity-generated-queries","creator_name":"BEIR","creator_url":"https://huggingface.co/BeIR","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for BEIR Benchmark\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nBEIR is a heterogeneous benchmark that has been built from 18 diverse datasets representing 9 information retrieval tasks:\\n\\nFact-checking: FEVER, Climate-FEVER, SciFact\\nQuestion-Answering: NQ, HotpotQA, FiQA-2018\\nBio-Medical IR: TREC-COVID, BioASQ, NFCorpus\\nNews Retrieval: TREC-NEWS, Robust04\\nArgument Retrieval: Touche-2020, ArguAna\\nDuplicate Question Retrieval: Quora, CqaDupstack\\nCitation-Prediction: SCIDOCS\\nTweet‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/BeIR/dbpedia-entity-generated-queries."},
	{"name":"magpie","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/gsarti/magpie","creator_name":"Gabriele Sarti","creator_url":"https://huggingface.co/gsarti","description":"The MAGPIE corpus is a large sense-annotated corpus of potentially idiomatic expressions (PIEs), based on the British National Corpus (BNC). Potentially idiomatic expressions are like idiomatic expressions, but the term also covers literal uses of idiomatic expressions, such as 'I leave work at the end of the day.' for the idiom 'at the end of the day'. This version of the dataset reflects the filtered subset used by Dankers et al. (2022) in their investigation on how PIEs are represented by NMT models. Authors use 37k samples annotated as fully figurative or literal, for 1482 idioms that contain nouns, numerals or adjectives that are colours (which they refer to as keywords). Because idioms show syntactic and morphological variability, the focus is mostly put on nouns. PIEs and their context are separated using the original corpus‚Äôs word-level annotations."},
	{"name":"apps","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/codeparrot/apps","creator_name":"CodeParrot","creator_url":"https://huggingface.co/codeparrot","description":"APPS is a benchmark for Python code generation, it includes 10,000 problems, which range from having simple oneline solutions to being substantial algorithmic challenges, for more details please refer to this paper: https://arxiv.org/pdf/2105.09938.pdf."},
	{"name":"nq-generated-queries","keyword":"monolingual","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/BeIR/nq-generated-queries","creator_name":"BEIR","creator_url":"https://huggingface.co/BeIR","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for BEIR Benchmark\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nBEIR is a heterogeneous benchmark that has been built from 18 diverse datasets representing 9 information retrieval tasks:\\n\\nFact-checking: FEVER, Climate-FEVER, SciFact\\nQuestion-Answering: NQ, HotpotQA, FiQA-2018\\nBio-Medical IR: TREC-COVID, BioASQ, NFCorpus\\nNews Retrieval: TREC-NEWS, Robust04\\nArgument Retrieval: Touche-2020, ArguAna\\nDuplicate Question Retrieval: Quora, CqaDupstack\\nCitation-Prediction: SCIDOCS\\nTweet‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/BeIR/nq-generated-queries."},
	{"name":"codecomplex","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/codeparrot/codecomplex","creator_name":"CodeParrot","creator_url":"https://huggingface.co/codeparrot","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tCodeComplex Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nCodeComplex consists of 4,200 Java codes submitted to programming competitions by human programmers and their complexity labels annotated by a group of algorithm experts.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tHow to use it\\n\\t\\n\\n You can load and iterate through the dataset with the following two lines of code:\\nfrom datasets import load_dataset\\n\\nds = load_dataset(\\\"codeparrot/codecomplex\\\", split=\\\"train\\\")\\nprint(next(iter(ds)))\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Structure‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/codeparrot/codecomplex."},
	{"name":"hatecheck-portuguese","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Paul/hatecheck-portuguese","creator_name":"Paul R√∂ttger","creator_url":"https://huggingface.co/Paul","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Multilingual HateCheck\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nMultilingual HateCheck (MHC) is a suite of functional tests for hate speech detection models in 10 different languages: Arabic, Dutch, French, German, Hindi, Italian, Mandarin, Polish, Portuguese and Spanish.\\nFor each language, there are 25+ functional tests that correspond to distinct types of hate and challenging non-hate.\\nThis allows for targeted diagnostic insights into model performance.\\nFor more‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Paul/hatecheck-portuguese."},
	{"name":"asrs-aviation-reports","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/elihoole/asrs-aviation-reports","creator_name":"Elijah Hoole","creator_url":"https://huggingface.co/elihoole","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for ASRS Aviation Incident Reports\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThis dataset collects 47,723 aviation incident reports published in the Aviation Safety Reporting System (ASRS) database maintained by NASA. \\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSupported Tasks and Leaderboards\\n\\t\\n\\n\\n'summarization': Dataset can be used to train a model for abstractive and extractive summarization. The model performance is measured by how high the output summary's ROUGE score for a given narrative account of‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/elihoole/asrs-aviation-reports."},
	{"name":"moral_stories","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/demelin/moral_stories","creator_name":"Denis Emelin","creator_url":"https://huggingface.co/demelin","description":"Moral Stories is a crowd-sourced dataset of structured, branching narratives for the study of grounded, goal-oriented \\nsocial reasoning. For detailed information, see https://aclanthology.org/2021.emnlp-main.54.pdf."},
	{"name":"mslr2022","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/allenai/mslr2022","creator_name":"Ai2","creator_url":"https://huggingface.co/allenai","description":"The Multidocument Summarization for Literature Review (MSLR) Shared Task aims to study how medical\\nevidence from different clinical studies are summarized in literature reviews. Reviews provide the\\nhighest quality of evidence for clinical care, but are expensive to produce manually.\\n(Semi-)automation via NLP may facilitate faster evidence synthesis without sacrificing rigor.\\nThe MSLR shared task uses two datasets to assess the current state of multidocument summarization\\nfor this task, and to encourage the development of modeling contributions, scaffolding tasks, methods\\nfor model interpretability, and improved automated evaluation methods in this domain."},
	{"name":"clevr-math","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/dali-does/clevr-math","creator_name":"Adam Dahlgren Lindstr√∂m","creator_url":"https://huggingface.co/dali-does","description":"CLEVR-Math is a dataset for compositional language, visual and mathematical reasoning. CLEVR-Math poses questions about mathematical operations on visual scenes using subtraction and addition, such as \\\"Remove all large red cylinders. How many objects are left?\\\". There are also adversarial (e.g. \\\"Remove all blue cubes. How many cylinders are left?\\\") and multihop questions (e.g. \\\"Remove all blue cubes. Remove all small purple spheres. How many objects are left?\\\")."},
	{"name":"proof-pile","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/hoskinson-center/proof-pile","creator_name":"Hoskinson Center for Formal Mathematics","creator_url":"https://huggingface.co/hoskinson-center","description":"A dataset of high quality mathematical text."},
	{"name":"syntran-fa","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/SLPL/syntran-fa","creator_name":"Speech and Language Processing Lab - Sharif University Of Technology","creator_url":"https://huggingface.co/SLPL","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSynTran-fa\\n\\t\\n\\nSyntactic Transformed Version of Farsi QA datasets to make fluent responses from questions and short answers. You can use this dataset by the code below:\\nimport datasets\\ndata = datasets.load_dataset('SLPL/syntran-fa', split=\\\"train\\\")\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\n\\nHomepage: Sharif-SLPL\\nRepository: SynTran-fa\\nPoint of Contact: Sadra Sabouri\\nPaper: SynTran-fa: Generating Comprehensive Answers for Farsi QA Pairs via Syntactic Transformation\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/SLPL/syntran-fa."},
	{"name":"broad_twitter_corpus","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/GateNLP/broad_twitter_corpus","creator_name":"GATE Team, University of Sheffield","creator_url":"https://huggingface.co/GateNLP","description":"This is the Broad Twitter corpus, a dataset of tweets collected over stratified times, places and social uses. \\nThe goal is to represent a broad range of activities, giving a dataset more representative of the language used \\nin this hardest of social media formats to process. Further, the BTC is annotated for named entities.\\n\\nFor more details see [https://aclanthology.org/C16-1111/](https://aclanthology.org/C16-1111/)"},
	{"name":"ami","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/edinburghcstr/ami","creator_name":"University of Edingburgh - Centre For Speech Technology Research","creator_url":"https://huggingface.co/edinburghcstr","description":"The AMI Meeting Corpus consists of 100 hours of meeting recordings. The recordings use a range of signals\\nsynchronized to a common timeline. These include close-talking and far-field microphones, individual and\\nroom-view video cameras, and output from a slide projector and an electronic whiteboard. During the meetings,\\nthe participants also have unsynchronized pens available to them that record what is written. The meetings\\nwere recorded in English using three different rooms with different acoustic properties, and include mostly\\nnon-native speakers. \\\\n"},
	{"name":"multilingual-sentiments","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/tyqiangz/multilingual-sentiments","creator_name":"Tay Yong Qiang","creator_url":"https://huggingface.co/tyqiangz","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tMultilingual Sentiments Dataset\\n\\t\\n\\nA collection of multilingual sentiments datasets grouped into 3 classes -- positive, neutral, negative.\\nMost multilingual sentiment datasets are either 2-class positive or negative, 5-class ratings of products reviews (e.g. Amazon multilingual dataset) or multiple classes of emotions. However, to an average person, sometimes positive, negative and neutral classes suffice and are more straightforward to perceive and annotate. Also, a‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/tyqiangz/multilingual-sentiments."},
	{"name":"wiki_toxic","keyword":"monolingual","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/OxAISH-AL-LLM/wiki_toxic","creator_name":"OxAI Safety Hub Active Learning with Large Language Models Labs Team","creator_url":"https://huggingface.co/OxAISH-AL-LLM","description":"Jigsaw Toxic Comment Challenge dataset. This dataset was the basis of a Kaggle competition run by Jigsaw"},
	{"name":"coyo-700m","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/kakaobrain/coyo-700m","creator_name":"Kakao Brain","creator_url":"https://huggingface.co/kakaobrain","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for COYO-700M\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nCOYO-700M is a large-scale dataset that contains 747M image-text pairs as well as many other meta-attributes to increase the usability to train various models. Our dataset follows a similar strategy to previous vision-and-language datasets, collecting many informative pairs of alt-text and its associated image in HTML documents. We expect COYO to be used to train popular large-scale foundation models \\ncomplementary to‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/kakaobrain/coyo-700m."},
	{"name":"go_emotions-es-mt","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mrm8488/go_emotions-es-mt","creator_name":"Manuel Romero","creator_url":"https://huggingface.co/mrm8488","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tGoEmotions Spanish\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tA Spanish translation (using EasyNMT) of the GoEmotions dataset.\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tFor more information check the official Model Card\\n\\t\\n\\n"},
	{"name":"twitter-financial-news-topic","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/zeroshot/twitter-financial-news-topic","creator_name":"not a","creator_url":"https://huggingface.co/zeroshot","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThe Twitter Financial News dataset is an English-language dataset containing an annotated corpus of finance-related tweets. This dataset is used to classify finance-related tweets for their topic.\\n\\nThe dataset holds 21,107 documents annotated with 20 labels:\\n\\ntopics = {\\n    \\\"LABEL_0\\\": \\\"Analyst Update\\\",\\n    \\\"LABEL_1\\\": \\\"Fed | Central Banks\\\",\\n    \\\"LABEL_2\\\": \\\"Company | Product News\\\",\\n    \\\"LABEL_3\\\": \\\"Treasuries | Corporate Debt\\\",\\n    \\\"LABEL_4\\\": \\\"Dividend\\\"‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/zeroshot/twitter-financial-news-topic."},
	{"name":"laion-aesthetics-12m-umap","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/dclure/laion-aesthetics-12m-umap","creator_name":"David McClure","creator_url":"https://huggingface.co/dclure","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLAION-Aesthetics :: CLIP ‚Üí UMAP\\n\\t\\n\\nThis dataset is a CLIP (text) ‚Üí UMAP embedding of the LAION-Aesthetics dataset - specifically the improved_aesthetics_6plus version, which filters the full dataset to images with scores of > 6 under the \\\"aesthetic\\\" filtering model.\\nThanks LAION for this amazing corpus!\\n\\nThe dataset here includes coordinates for 3x separate UMAP fits using different values for the n_neighbors parameter - 10, 30, and 60 - which are broken out as separate columns‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/dclure/laion-aesthetics-12m-umap."},
	{"name":"recycling-dataset","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/viola77data/recycling-dataset","creator_name":"viola meli","creator_url":"https://huggingface.co/viola77data","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for recycling-dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThis is a recycling dataset that can be used for image classification. It has 11 categories:\\n\\naluminium\\nbatteries\\ncardboard\\ndisposable plates\\nglass\\nhard plastic\\npaper\\npaper towel\\npolystyrene\\nsoft plastics\\ntakeaway cups\\n\\nIt was scrapped from DuckDuckGo using this tool: https://pypi.org/project/jmd-imagescraper/\\n"},
	{"name":"conala","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neulab/conala","creator_name":"NeuLab @ LTI/CMU","creator_url":"https://huggingface.co/neulab","description":"CoNaLa is a dataset of code and natural language pairs crawled from Stack Overflow, for more details please refer to this paper: https://arxiv.org/pdf/1805.08949.pdf or the dataset page https://conala-corpus.github.io/."},
	{"name":"asqa","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/din0s/asqa","creator_name":"Dinos Papakostas","creator_url":"https://huggingface.co/din0s","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for ASQA\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nASQA is the first long-form question answering dataset that focuses on ambiguous factoid questions. Different from previous long-form answers datasets, each question is annotated with both long-form answers and extractive question-answer pairs, which should be answerable by the generated passage. A generated long-form answer will be evaluated using both ROUGE and QA accuracy. In the paper, we show that these evaluation metrics‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/din0s/asqa."},
	{"name":"fashionpedia","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/detection-datasets/fashionpedia","creator_name":"Detection datasets","creator_url":"https://huggingface.co/detection-datasets","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Fashionpedia\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nFashionpedia is a dataset mapping out the visual aspects of the fashion world.\\nFrom the paper:\\n\\nFashionpedia is a new dataset which consists of two parts: (1) an ontology built by fashion experts containing 27 main apparel categories, 19 apparel parts, 294 fine-grained attributes and their relationships; (2) a dataset with everyday and celebrity event fashion images annotated with segmentation masks and their‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/detection-datasets/fashionpedia."},
	{"name":"laion2B-multi-chinese-subset","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/IDEA-CCNL/laion2B-multi-chinese-subset","creator_name":"Fengshenbang-LM","creator_url":"https://huggingface.co/IDEA-CCNL","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tlaion2B-multi-chinese-subset\\n\\t\\n\\n\\nGithub: Fengshenbang-LM\\nDocs: Fengshenbang-Docs\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tÁÆÄ‰ªã Brief Introduction\\n\\t\\n\\nÂèñËá™Laion2BÂ§öËØ≠Ë®ÄÂ§öÊ®°ÊÄÅÊï∞ÊçÆÈõÜ‰∏≠ÁöÑ‰∏≠ÊñáÈÉ®ÂàÜÔºå‰∏ÄÂÖ±143M‰∏™ÂõæÊñáÂØπ„ÄÇ\\nA subset from Laion2B (a multimodal dataset), around 143M image-text pairs (only Chinese).\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tÊï∞ÊçÆÈõÜ‰ø°ÊÅØ Dataset Information\\n\\t\\n\\nÂ§ßÁ∫¶‰∏ÄÂÖ±143M‰∏™‰∏≠ÊñáÂõæÊñáÂØπ„ÄÇÂ§ßÁ∫¶Âç†Áî®19GBÁ©∫Èó¥Ôºà‰ªÖ‰ªÖÊòØurlÁ≠âÊñáÊú¨‰ø°ÊÅØÔºå‰∏çÂåÖÂê´ÂõæÁâáÔºâ„ÄÇ\\n\\nHomepage: laion-5b\\nHuggingface: laion/laion2B-multi\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\t‰∏ãËΩΩ Download\\n\\t\\n\\nmkdir laion2b_chinese_release && cd laion2b_chinese_release\\nfor i in‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/IDEA-CCNL/laion2B-multi-chinese-subset."},
	{"name":"MultiPL-E","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/nuprl/MultiPL-E","creator_name":"Northeastern University Programming Research Lab","creator_url":"https://huggingface.co/nuprl","description":"\\n\\t\\n\\t\\t\\n\\t\\tDataset Card for MultiPL-E\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nMultiPL-E is a dataset for evaluating large language models for code\\ngeneration that supports 22 programming languages. It takes the OpenAI \\nHumanEval and the Mostly Basic Python Programs (MBPP) benchmarks and uses little compilers to\\ntranslate them  to other languages. It is easy to add support for new languages \\nand benchmarks.\\nThe dataset is divided into several configurations named SRCDATA-LANG, where\\nSRCDATA is either‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/nuprl/MultiPL-E."},
	{"name":"balanced-copa","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/pkavumba/balanced-copa","creator_name":"Pride Kavumba","creator_url":"https://huggingface.co/pkavumba","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for \\\"Balanced COPA\\\"\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nBala-COPA: An English language Dataset for Training Robust Commonsense Causal Reasoning Models\\nThe Balanced Choice of Plausible Alternatives dataset is a benchmark for training machine learning models that are robust to superficial cues/spurious correlations. The dataset extends the COPA dataset(Roemmele et al. 2011) with mirrored instances that mitigate against token-level superficial cues in the original COPA‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/pkavumba/balanced-copa."},
	{"name":"youtube-transcriptions","keyword":"monolingual","license":"Academic Free License v3.0","license_url":"https://choosealicense.com/licenses/afl-3.0/","language":"en","dataset_url":"https://huggingface.co/datasets/jamescalam/youtube-transcriptions","creator_name":"James Briggs","creator_url":"https://huggingface.co/jamescalam","description":"The YouTube transcriptions dataset contains technical tutorials (currently from James Briggs, Daniel Bourke, and AI Coffee Break) transcribed using OpenAI's Whisper (large). Each row represents roughly a sentence-length chunk of text alongside the video URL and timestamp.\\nNote that each item in the dataset contains just a short chunk of text. For most use cases you will likely need to merge multiple rows to create more substantial chunks of text, if you need to do that, this code snippet will‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/jamescalam/youtube-transcriptions."},
	{"name":"kqa_pro","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/drt/kqa_pro","creator_name":"Yuanchun","creator_url":"https://huggingface.co/drt","description":"A large-scale, diverse, challenging dataset of complex question answering over knowledge base."},
	{"name":"prosocial-dialog","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/allenai/prosocial-dialog","creator_name":"Ai2","creator_url":"https://huggingface.co/allenai","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for ProsocialDialog Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nProsocialDialog is the first large-scale multi-turn English dialogue dataset to teach conversational agents to respond to problematic content following social norms. Covering diverse unethical, problematic, biased, and toxic situations, ProsocialDialog contains responses that encourage prosocial behavior, grounded in commonsense social rules (i.e., rules-of-thumb, RoTs). Created via a human-AI collaborative‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/allenai/prosocial-dialog."},
	{"name":"sova_rudevices","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/bond005/sova_rudevices","creator_name":"Ivan Bondarenko","creator_url":"https://huggingface.co/bond005","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for sova_rudevices\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nSOVA Dataset is free public STT/ASR dataset. It consists of several parts, one of them is SOVA RuDevices. This part is an acoustic corpus of approximately 100 hours of 16kHz Russian live speech with manual annotating, prepared by SOVA.ai team.\\nAuthors do not divide the dataset into train, validation and test subsets. Therefore, I was compelled to prepare this splitting. The training subset includes more than 82 hours‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/bond005/sova_rudevices."},
	{"name":"qa-pt","keyword":"monolingual","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ju-resplande/qa-pt","creator_name":"Juliana Resplande","creator_url":"https://huggingface.co/ju-resplande","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for QA-Portuguese\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nPortuguese preprocessed split from MQA dataset.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSupported Tasks and Leaderboards\\n\\t\\n\\n[More Information Needed]\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages\\n\\t\\n\\nThe dataset is Portuguese.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Structure\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Instances\\n\\t\\n\\n[More Information Needed]\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Fields\\n\\t\\n\\n[More Information Needed]\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Splits\\n\\t\\n\\n[More Information Needed]\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Creation\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tCuration‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ju-resplande/qa-pt."},
	{"name":"stackoverflow-questions","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/pacovaldez/stackoverflow-questions","creator_name":"Paco Valdez","creator_url":"https://huggingface.co/pacovaldez","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for [Stackoverflow Post Questions]\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nCompanies that sell Open-source software tools usually hire an army of Customer representatives to try to answer every question asked about their tool. The first step in this process \\nis the prioritization of the question. The classification scale usually consists of 4 values, P0, P1, P2, and P3, with different meanings across every participant in the industry. On \\nthe other hand, every software‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/pacovaldez/stackoverflow-questions."},
	{"name":"saf_communication_networks_english","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Short-Answer-Feedback/saf_communication_networks_english","creator_name":"Short Answer Feedback Interest Group","creator_url":"https://huggingface.co/Short-Answer-Feedback","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for \\\"saf_communication_networks_english\\\"\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nShort Answer Feedback (SAF) dataset is a short answer dataset introduced in Your Answer is Incorrect... Would you like to know why? Introducing a Bilingual Short Answer Feedback Dataset (Filighera et al., ACL 2022) as a way to remedy the lack of content-focused feedback datasets. This version of the dataset contains 31 English questions covering a range of college-level communication networks‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Short-Answer-Feedback/saf_communication_networks_english."},
	{"name":"codiesp","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/bigbio/codiesp","creator_name":"BigScience Biomedical Datasets","creator_url":"https://huggingface.co/bigbio","description":"Synthetic corpus of 1,000 manually selected clinical case studies in Spanish\\nthat was designed for the Clinical Case Coding in Spanish Shared Task, as part\\nof the CLEF 2020 conference.\\n\\nThe goal of the task was to automatically assign ICD10 codes (CIE-10, in\\nSpanish) to clinical case documents, being evaluated against manually generated\\nICD10 codifications. The CodiEsp corpus was selected manually by practicing\\nphysicians and clinical documentalists and annotated by clinical coding\\nprofessionals meeting strict quality criteria. They reached an inter-annotator\\nagreement of 88.6% for diagnosis coding, 88.9% for procedure coding and 80.5%\\nfor the textual reference annotation.\\n\\nThe final collection of 1,000 clinical cases that make up the corpus had a total\\nof 16,504 sentences and 396,988 words. All documents are in Spanish language and\\nCIE10 is the coding terminology (the Spanish version of ICD10-CM and ICD10-PCS).\\nThe CodiEsp corpus has been randomly sampled into three subsets. The train set\\ncontains 500 clinical cases, while the development and test sets have 250\\nclinical cases each. In addition to these, a collection of 176,294 abstracts\\nfrom Lilacs and Ibecs with the corresponding ICD10 codes (ICD10-CM and\\nICD10-PCS) was provided by the task organizers. Every abstract has at least one\\nassociated code, with an average of 2.5 ICD10 codes per abstract.\\n\\nThe CodiEsp track was divided into three sub-tracks (2 main and 1 exploratory):\\n\\n- CodiEsp-D: The Diagnosis Coding sub-task, which requires automatic ICD10-CM\\n  [CIE10-Diagn√≥stico] code assignment.\\n- CodiEsp-P: The Procedure Coding sub-task, which requires automatic ICD10-PCS\\n  [CIE10-Procedimiento] code assignment.\\n- CodiEsp-X: The Explainable AI exploratory sub-task, which requires to submit\\n  the reference to the predicted codes (both ICD10-CM and ICD10-PCS). The goal \\n  of this novel task was not only to predict the correct codes but also to \\n  present the reference in the text that supports the code predictions.\\n\\nFor further information, please visit https://temu.bsc.es/codiesp or send an\\nemail to encargo-pln-life@bsc.es"},
	{"name":"grammar-ro","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/BlackKakapo/grammar-ro","creator_name":"Alexandru Petrachi","creator_url":"https://huggingface.co/BlackKakapo","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tRomanian grammar dataset\\n\\t\\n\\nThis data set was created by me, special for grammar \\nHere you can find:\\n~1600k examples of grammar (TRAIN).\\n~220k examples of grammar (TEST).\\n"},
	{"name":"IMaSC","keyword":"monolingual","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/thennal/IMaSC","creator_name":"Thennal","creator_url":"https://huggingface.co/thennal","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tIMaSC: ICFOSS Malayalam Speech Corpus\\n\\t\\n\\nIMaSC is a Malayalam text and speech corpus made available by ICFOSS for the purpose of developing speech technology for Malayalam, particularly text-to-speech. The corpus contains 34,473 text-audio pairs of Malayalam sentences spoken by 8 speakers, totalling in approximately 50 hours of audio.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Structure\\n\\t\\n\\nThe dataset consists of 34,473 instances with fields text, speaker, and audio. The audio is mono, sampled at 16kH.‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/thennal/IMaSC."},
	{"name":"kmhas_korean_hate_speech","keyword":"monolingual","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/jeanlee/kmhas_korean_hate_speech","creator_name":"Jean Lee","creator_url":"https://huggingface.co/jeanlee","description":"The K-MHaS (Korean Multi-label Hate Speech) dataset contains 109k utterances from Korean online news comments labeled with 8 fine-grained hate speech classes or Not Hate Speech class.\\nThe fine-grained hate speech classes are politics, origin, physical, age, gender, religion, race, and profanity and these categories are selected in order to reflect the social and historical context."},
	{"name":"nyu_depth_v2","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/sayakpaul/nyu_depth_v2","creator_name":"Sayak Paul","creator_url":"https://huggingface.co/sayakpaul","description":"The NYU-Depth V2 data set is comprised of video sequences from a variety of indoor scenes as recorded by both the RGB and Depth cameras from the Microsoft Kinect."},
	{"name":"spectrogram-captions","keyword":"monolingual","license":"Academic Free License v3.0","license_url":"https://choosealicense.com/licenses/afl-3.0/","language":"en","dataset_url":"https://huggingface.co/datasets/vucinatim/spectrogram-captions","creator_name":"Tim Vuƒçina","creator_url":"https://huggingface.co/vucinatim","description":"Dataset of captioned spectrograms (text describing the sound).\\n"},
	{"name":"jsnli","keyword":"monolingual","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/shunk031/jsnli","creator_name":"Shunsuke Kitada","creator_url":"https://huggingface.co/shunk031","description":"== Êó•Êú¨Ë™ûSNLI(JSNLI)„Éá„Éº„Çø„Çª„ÉÉ„Éà ==\\n\\nSNLI „Ç≥„Éº„Éë„Çπ„ÇíÊó•Êú¨Ë™û„Å´ÁøªË®≥„Åó„ÅüËá™ÁÑ∂Ë®ÄË™ûÊé®Ë´ñ„Éá„Éº„Çø„Çª„ÉÉ„Éà\\nÂ≠¶Áøí„Éá„Éº„Çø„ÅØÂÖÉ„Éá„Éº„Çø„ÇíÁøªË®≥„Åó„ÄÅË®àÁÆóÊ©ü„Å´„Çà„Çã„Éï„Ç£„É´„Çø„É™„É≥„Ç∞„Å´„Çà„Å£„Å¶‰ΩúÊàê\\nË©ï‰æ°„Éá„Éº„Çø„ÅØÊó•Êú¨Ë™û„Å®„Åó„Å¶ÊÑèÂë≥„ÅåÈÄö„Çã„Åã„ÄÅÁøªË®≥Âæå„ÅÆ„É©„Éô„É´„ÅåÂÖÉ„ÅÆ„É©„Éô„É´„Å®‰∏ÄËá¥„Åó„Å¶„ÅÑ„Çã„Åã„Å©„ÅÜ„Åã„ÅÆ2ÊÆµÈöé„ÅÆ„ÇØ„É©„Ç¶„Éâ„ÇΩ„Éº„Ç∑„É≥„Ç∞„Å´„Çà„Çä„Éá„Éº„Çø„Çí„Éï„Ç£„É´„Çø„É™„É≥„Ç∞"},
	{"name":"clintox","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/zpn/clintox","creator_name":"Zach Nussbaum","creator_url":"https://huggingface.co/zpn","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for clintox\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nclintox is a dataset included in MoleculeNet. Qualitative data of drugs approved by the FDA and those that have failed clinical trials for toxicity reasons. This uses the CT_TOX task.\\nNote, there was one molecule in the training set that could not be converted to SELFIES (*C(=O)[C@H](CCCCNC(=O)OCCOC)NC(=O)OCCOC)\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Structure\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Fields\\n\\t\\n\\nEach split contains\\n\\nsmiles: the SMILES‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/zpn/clintox."},
	{"name":"everyayah","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/tarteel-ai/everyayah","creator_name":"Tarteel AI","creator_url":"https://huggingface.co/tarteel-ai","description":"Ô∑Ω\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Tarteel AI's EveryAyah Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThis dataset is a collection of Quranic verses and their transcriptions, with diacritization, by different reciters.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSupported Tasks and Leaderboards\\n\\t\\n\\n[Needs More Information]\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages\\n\\t\\n\\nThe audio is in Arabic.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Structure\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Instances\\n\\t\\n\\nA typical data point comprises the audio file audio, and its transcription called text.\\nThe duration‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/tarteel-ai/everyayah."},
	{"name":"arxiv-biology","keyword":"monolingual","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/zeroshot/arxiv-biology","creator_name":"not a","creator_url":"https://huggingface.co/zeroshot","description":"\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Curators\\n\\t\\n\\nThe original data is maintained by ArXiv\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLicensing Information\\n\\t\\n\\nThe data is under the Creative Commons CC0 1.0 Universal Public Domain Dedication\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tCitation Information\\n\\t\\n\\n@misc{clement2019arxiv,\\n    title={On the Use of ArXiv as a Dataset},\\n    author={Colin B. Clement and Matthew Bierbaum and Kevin P. O'Keeffe and Alexander A. Alemi},\\n    year={2019},\\n    eprint={1905.00075},\\n    archivePrefix={arXiv},\\n    primaryClass={cs.IR}\\n}\\n\\n"},
	{"name":"laion-high-resolution-chinese","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/wanng/laion-high-resolution-chinese","creator_name":"wangjunjie","creator_url":"https://huggingface.co/wanng","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tlaion-high-resolution-chinese\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tÁÆÄ‰ªã Brief Introduction\\n\\t\\n\\nÂèñËá™Laion5B-high-resolutionÂ§öËØ≠Ë®ÄÂ§öÊ®°ÊÄÅÊï∞ÊçÆÈõÜ‰∏≠ÁöÑ‰∏≠ÊñáÈÉ®ÂàÜÔºå‰∏ÄÂÖ±2.66M‰∏™ÂõæÊñáÂØπ„ÄÇ\\nA subset from Laion5B-high-resolution (a multimodal dataset), around 2.66M image-text pairs (only Chinese).\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tÊï∞ÊçÆÈõÜ‰ø°ÊÅØ Dataset Information\\n\\t\\n\\nÂ§ßÁ∫¶‰∏ÄÂÖ±2.66M‰∏™‰∏≠ÊñáÂõæÊñáÂØπ„ÄÇÂ§ßÁ∫¶Âç†Áî®381MBÁ©∫Èó¥Ôºà‰ªÖ‰ªÖÊòØurlÁ≠âÊñáÊú¨‰ø°ÊÅØÔºå‰∏çÂåÖÂê´ÂõæÁâáÔºâ„ÄÇ\\n\\nHomepage: laion-5b\\nHuggingface: laion/laion-high-resolution\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\t‰∏ãËΩΩ Download\\n\\t\\n\\nmkdir release && cd release\\nfor i in {00000..00015}; do wget‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/wanng/laion-high-resolution-chinese."},
	{"name":"tldr","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neulab/tldr","creator_name":"NeuLab @ LTI/CMU","creator_url":"https://huggingface.co/neulab","description":"This is the re-split of CoNaLa dataset. For each code snippet in the dev and test set, at least one function is held out from the training set. This split aims at testing a code generation model's capacity in generating unseen functions.\\nWe further make sure that examples from the same StackOverflow post (same question_id before -) are in the same split."},
	{"name":"financial-reports-sec","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/JanosAudran/financial-reports-sec","creator_name":"Aman Khan","creator_url":"https://huggingface.co/JanosAudran","description":"The dataset contains the annual report of US public firms filing with the SEC EDGAR system.\\nEach annual report (10K filing) is broken into 20 sections. Each section is split into individual sentences.\\nSentiment labels are provided on a per filing basis from the market reaction around the filing data.\\nAdditional metadata for each filing is included in the dataset."},
	{"name":"test-dataset","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/mqddb/test-dataset","creator_name":"qiangddb","creator_url":"https://huggingface.co/mqddb","description":"The MNIST dataset consists of 70,000 28x28 black-and-white images in 10 classes (one for each digits), with 7,000\\nimages per class. There are 60,000 training images and 10,000 test images."},
	{"name":"jd21","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/kuroneko5943/jd21","creator_name":"Wang Song","creator_url":"https://huggingface.co/kuroneko5943","description":"GLUE, the General Language Understanding Evaluation benchmark\\n(https://gluebenchmark.com/) is a collection of resources for training,\\nevaluating, and analyzing natural language understanding systems."},
	{"name":"weibo16","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/kuroneko5943/weibo16","creator_name":"Wang Song","creator_url":"https://huggingface.co/kuroneko5943","description":"GLUE, the General Language Understanding Evaluation benchmark\\n(https://gluebenchmark.com/) is a collection of resources for training,\\nevaluating, and analyzing natural language understanding systems."},
	{"name":"gsm-hard","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/reasoning-machines/gsm-hard","creator_name":"Reasoning Machines","creator_url":"https://huggingface.co/reasoning-machines","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThis is the harder version of gsm8k math reasoning dataset (https://huggingface.co/datasets/gsm8k).\\nWe construct this dataset by replacing the numbers in the questions of GSM8K with larger numbers that are less common.\\n\\u0001\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSupported Tasks and Leaderboards\\n\\t\\n\\nThis dataset is used to evaluate math reasoning\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages\\n\\t\\n\\nEnglish - Numbers\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Structure\\n\\t\\n\\ndataset = load_dataset(\\\"reasoning-machines/gsm-hard\\\")\\nDatasetDict({‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/reasoning-machines/gsm-hard."},
	{"name":"DBLP-QuAD","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/awalesushil/DBLP-QuAD","creator_name":"Sushil Awale","creator_url":"https://huggingface.co/awalesushil","description":"    DBLP-QuAD is a scholarly knowledge graph question answering dataset with     10,000 question - SPARQL query pairs targeting the DBLP knowledge graph.     The dataset is split into 7,000 training, 1,000 validation and 2,000 test     questions."},
	{"name":"turkish-constitutional-court","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/KocLab-Bilkent/turkish-constitutional-court","creator_name":"Aykut Ko√ß Lab","creator_url":"https://huggingface.co/KocLab-Bilkent","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThis dataset is extracted from the following Github repo, which was created for the journal paper with URL https://www.sciencedirect.com/science/article/abs/pii/S0306457321001692.\\nhttps://github.com/koc-lab/law-turk\\nThe dataset includes 1290 court case decision texts from the Turkish Court of Cassation. Each sample has one label, which is the ruling of the court. The possible rulings are \\\"Violation\\\" and \\\"No violation\\\". There are 1290 samples. 1141 of these‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/KocLab-Bilkent/turkish-constitutional-court."},
	{"name":"poquad","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/clarin-pl/poquad","creator_name":"CLARIN-PL","creator_url":"https://huggingface.co/clarin-pl","description":"PoQuaD description"},
	{"name":"SciQA","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/orkg/SciQA","creator_name":"The Open Research Knowledge Graph","creator_url":"https://huggingface.co/orkg","description":"    SciQA contains 2,565 SPARQL query - question pairs along with answers fetched from the open research knowledge graph (ORKG)     via a Virtuoso SPARQL endpoint, it is a collection of both handcrafted and autogenerated questions and queries.     The dataset is split into 70% training, 10% validation and 20% test examples. The dataset is available as JSON files."},
	{"name":"janli","keyword":"monolingual","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/hpprc/janli","creator_name":"Hayato TSUKAGOSHI","creator_url":"https://huggingface.co/hpprc","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for JaNLI\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThe JaNLI (Japanese Adversarial NLI) dataset, inspired by the English HANS dataset, is designed to necessitate an understanding of Japanese linguistic phenomena and to illuminate the vulnerabilities of models.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages\\n\\t\\n\\nThe language data in JaNLI is in Japanese (BCP-47 ja-JP).\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Structure\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Instances\\n\\t\\n\\nWhen loading a specific configuration, users has to append a version‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/hpprc/janli."},
	{"name":"speech_commands_enriched","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/renumics/speech_commands_enriched","creator_name":"Renumics","creator_url":"https://huggingface.co/renumics","description":"This is a set of one-second .wav audio files, each containing a single spoken\\nEnglish word or background noise. These words are from a small set of commands, and are spoken by a\\nvariety of different speakers. This data set is designed to help train simple\\nmachine learning models. This dataset is covered in more detail at\\n[https://arxiv.org/abs/1804.03209](https://arxiv.org/abs/1804.03209).\\n\\nVersion 0.01 of the data set (configuration `\\\"v0.01\\\"`) was released on August 3rd 2017 and contains\\n64,727 audio files.\\n\\nIn version 0.01 thirty different words were recoded: \\\"Yes\\\", \\\"No\\\", \\\"Up\\\", \\\"Down\\\", \\\"Left\\\",\\n\\\"Right\\\", \\\"On\\\", \\\"Off\\\", \\\"Stop\\\", \\\"Go\\\", \\\"Zero\\\", \\\"One\\\", \\\"Two\\\", \\\"Three\\\", \\\"Four\\\", \\\"Five\\\", \\\"Six\\\", \\\"Seven\\\", \\\"Eight\\\", \\\"Nine\\\",\\n\\\"Bed\\\", \\\"Bird\\\", \\\"Cat\\\", \\\"Dog\\\", \\\"Happy\\\", \\\"House\\\", \\\"Marvin\\\", \\\"Sheila\\\", \\\"Tree\\\", \\\"Wow\\\".\\n\\n\\nIn version 0.02 more words were added: \\\"Backward\\\", \\\"Forward\\\", \\\"Follow\\\", \\\"Learn\\\", \\\"Visual\\\".\\n\\nIn both versions, ten of them are used as commands by convention: \\\"Yes\\\", \\\"No\\\", \\\"Up\\\", \\\"Down\\\", \\\"Left\\\",\\n\\\"Right\\\", \\\"On\\\", \\\"Off\\\", \\\"Stop\\\", \\\"Go\\\". Other words are considered to be auxiliary (in current implementation\\nit is marked by `True` value of `\\\"is_unknown\\\"` feature). Their function is to teach a model to distinguish core words\\nfrom unrecognized ones.\\nThis version is not yet supported.\\n\\nThe `_silence_` class contains a set of longer audio clips that are either recordings or\\na mathematical simulation of noise."},
	{"name":"beyazperde-top-300-movie-reviews","keyword":"monolingual","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/turkish-nlp-suite/beyazperde-top-300-movie-reviews","creator_name":"Turkish NLP Suite","creator_url":"https://huggingface.co/turkish-nlp-suite","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for turkish-nlp-suite/beyazperde-top-300-movie-reviews\\n\\t\\n\\n \\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nBeyazperde Movie Reviews offers Turkish sentiment analysis datasets that is scraped from popular movie reviews website Beyazperde.com. Top 300 Movies include audience reviews about best 300 movies of all the time. Here's the star rating distribution:\\n\\n\\t\\n\\t\\t\\nstar rating\\ncount\\n\\n\\n\\t\\t\\n0.5\\n101\\n\\n\\n1.0\\n39\\n\\n\\n1.5\\n19\\n\\n\\n2.0\\n44\\n\\n\\n2.5\\n210\\n\\n\\n3.0\\n196\\n\\n\\n3.5\\n490\\n\\n\\n4.0\\n1212\\n\\n\\n4.5\\n818\\n\\n\\n5.0\\n1251‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/turkish-nlp-suite/beyazperde-top-300-movie-reviews."},
	{"name":"edgar-corpus","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/c3po-ai/edgar-corpus","creator_name":"C3PO-AI","creator_url":"https://huggingface.co/c3po-ai","description":"The dataset contains annual filings (10K) of all publicly traded firms from 1993-2020. The table data is stripped but all text is retained.\\nThis dataset allows easy access to the EDGAR-CORPUS dataset based on the paper EDGAR-CORPUS: Billions of Tokens Make The World Go Round (See References in README.md for details)."},
	{"name":"mmlu","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/lighteval/mmlu","creator_name":"Evaluation datasets","creator_url":"https://huggingface.co/lighteval","description":"This is a massive multitask test consisting of multiple-choice questions from various branches of knowledge, covering 57 tasks including elementary mathematics, US history, computer science, law, and more."},
	{"name":"tarteel-ai-everyayah-Quran","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Salama1429/tarteel-ai-everyayah-Quran","creator_name":"Mohamed Salama","creator_url":"https://huggingface.co/Salama1429","description":"Ô∑Ω\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Tarteel AI's EveryAyah Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThis dataset is a collection of Quranic verses and their transcriptions, with diacritization, by different reciters.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tHow to download\\n\\t\\n\\n!pip install -q datasets\\n\\nfrom datasets import load_dataset\\ndataset =load_dataset(\\\"Salama1429/tarteel-ai-everyayah-Quran\\\", verification_mode=\\\"no_checks\\\")\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSupported Tasks and Leaderboards\\n\\t\\n\\n[Needs More Information]\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Salama1429/tarteel-ai-everyayah-Quran."},
	{"name":"COCO-AB","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/coallaoh/COCO-AB","creator_name":"Seong Joon Oh","creator_url":"https://huggingface.co/coallaoh","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tGeneral Information\\n\\t\\n\\nTitle: COCO-AB\\nDescription: \\nThe COCO-AB dataset is an extension of the COCO 2014 training set, enriched with additional annotation byproducts (AB). \\nThe data includes 82,765 reannotated images from the original COCO 2014 training set. \\nIt has relevance in computer vision, specifically in object detection and location. \\nThe aim of the dataset is to provide a richer understanding of the images (without extra costs) by recording additional actions and‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/coallaoh/COCO-AB."},
	{"name":"curation-corpus","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/d0rj/curation-corpus","creator_name":"Dmitry Balobin","creator_url":"https://huggingface.co/d0rj","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tcuration-corpus\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSource\\n\\t\\n\\nData from this official repo with downloaded news articles content.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tCitation\\n\\t\\n\\n@misc{curationcorpusbase:2020,\\n  title={Curation Corpus Base},\\n  author={Curation},\\n  year={2020}\\n}\\n\\n"},
	{"name":"nli-zh-all","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/shibing624/nli-zh-all","creator_name":"Ming Xu (ÂæêÊòé)","creator_url":"https://huggingface.co/shibing624","description":"The SNLI corpus (version 1.0) is a merged chinese sentence similarity dataset, supporting the task of natural language\\ninference (NLI), also known as recognizing textual entailment (RTE)."},
	{"name":"alpaca-cleaned-ru","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/d0rj/alpaca-cleaned-ru","creator_name":"Dmitry Balobin","creator_url":"https://huggingface.co/d0rj","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\talpaca-cleaned-ru\\n\\t\\n\\nTranslated version of yahma/alpaca-cleaned into Russian.\\n"},
	{"name":"audiocaps","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/d0rj/audiocaps","creator_name":"Dmitry Balobin","creator_url":"https://huggingface.co/d0rj","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\taudiocaps\\n\\t\\n\\nHuggingFace mirror of official data repo.\\n"},
	{"name":"GRIT","keyword":"monolingual","license":"Microsoft Public License","license_url":"https://choosealicense.com/licenses/ms-pl/","language":"en","dataset_url":"https://huggingface.co/datasets/zzliang/GRIT","creator_name":"zhiliang","creator_url":"https://huggingface.co/zzliang","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tGRIT: Large-Scale Training Corpus of Grounded Image-Text Pairs\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nWe introduce GRIT, a large-scale dataset of Grounded Image-Text pairs, which is created based on image-text pairs from COYO-700M and LAION-2B. We construct a pipeline to extract and link text spans (i.e., noun phrases, and referring expressions) in the caption to their corresponding image regions. More details can be found in the paper.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSupported Tasks\\n\\t\\n\\nDuring the‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/zzliang/GRIT."},
	{"name":"negation-dataset","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/jinaai/negation-dataset","creator_name":"Jina AI","creator_url":"https://huggingface.co/jinaai","description":"\\n\\n\\n\\n\\n\\n\\nThe data offered by Jina AI, Finetuner team.\\n\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSummary\\n\\t\\n\\nThis dataset is an English-language dataset based on the SNLI dataset.\\nIt contains negations of samples from SNLI.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tInstances\\n\\t\\n\\nEach data point consists of a triplet ('anchor', 'entailment', 'negative') of strings, where ('anchor', 'entailment') are positive pairs\\ntaken from SNLI, and 'negative' contradicts  both 'anchor' and 'entailment'.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tFields\\n\\t\\n\\n\\n'anchor': string, some statement‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/jinaai/negation-dataset."},
	{"name":"sharegpt_gpt4","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/shibing624/sharegpt_gpt4","creator_name":"Ming Xu (ÂæêÊòé)","creator_url":"https://huggingface.co/shibing624","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nShareGPT‰∏≠ÊåëÈÄâÂá∫ÁöÑGPT4Â§öËΩÆÈóÆÁ≠îÊï∞ÊçÆÔºåÂ§öËØ≠Ë®ÄÈóÆÁ≠î„ÄÇ\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages\\n\\t\\n\\nÊï∞ÊçÆÈõÜÊòØÂ§öËØ≠Ë®ÄÔºåÂåÖÊã¨‰∏≠Êñá„ÄÅËã±Êñá„ÄÅÊó•ÊñáÁ≠âÂ∏∏Áî®ËØ≠Ë®Ä„ÄÇ\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Structure\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Fields\\n\\t\\n\\nThe data fields are the same among all splits.\\n\\nconversations: a List of string .\\n\\nhead -n 1 sharegpt_gpt4.jsonl\\n\\n{\\\"conversations\\\":[\\n  {'from': 'human',\\n   'value': 'Êé°Áî®ÂÑ™ÈõÖÁèæ‰ª£‰∏≠ÊñáÔºåÁî®‰∏≠ÊñáÁπÅÈ´îÂ≠óÂûãÔºåÂõûÁ≠î‰ª•‰∏ãÂïèÈ°å„ÄÇÁÇ∫ÊâÄÊúâÊ®ôÈ°åÊàñÂ∞àÁî®Â≠óË©ûÊèê‰æõÂ∞çÊáâÁöÑËã±Ë™ûÁøªË≠ØÔºöUsing scholarly style, summarize in detail James Barr\\\\'s book \\\"Semantics of Biblical‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/shibing624/sharegpt_gpt4."},
	{"name":"gsm8k-ru","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/d0rj/gsm8k-ru","creator_name":"Dmitry Balobin","creator_url":"https://huggingface.co/d0rj","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tgsm8k-ru\\n\\t\\n\\nTranslated version of gsm8k dataset into Russian.\\n"},
	{"name":"dialogsum-test","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neil-code/dialogsum-test","creator_name":"neil","creator_url":"https://huggingface.co/neil-code","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for DIALOGSum Corpus\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLinks\\n\\t\\n\\n\\nHomepage: https://aclanthology.org/2021.findings-acl.449\\nRepository: https://github.com/cylnlp/dialogsum\\nPaper: https://aclanthology.org/2021.findings-acl.449\\nPoint of Contact: https://huggingface.co/knkarthick\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nDialogSum is a large-scale dialogue summarization dataset, consisting of 13,460 (Plus 100 holdout data for topic generation) dialogues with‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/neil-code/dialogsum-test."},
	{"name":"clothes_desc","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/wbensvage/clothes_desc","creator_name":"Wolfgang Bensvage","creator_url":"https://huggingface.co/wbensvage","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for H&M Clothes captions\\n\\t\\n\\n_Dataset used to train/finetune [Clothes text to image model]\\nCaptions are generated by using the 'detail_desc' and 'colour_group_name' or 'perceived_colour_master_name' from kaggle/competitions/h-and-m-personalized-fashion-recommendations. Original images were also obtained from the url (https://www.kaggle.com/competitions/h-and-m-personalized-fashion-recommendations/data?select=images)\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tFor each row the dataset contains image‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/wbensvage/clothes_desc."},
	{"name":"AttaQ","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/ibm-research/AttaQ","creator_name":"IBM Research","creator_url":"https://huggingface.co/ibm-research","description":"\\n\\t\\n\\t\\t\\n\\t\\tAttaQ Dataset Card\\n\\t\\n\\nThe AttaQ red teaming dataset, consisting of 1402 carefully crafted adversarial questions, is designed to evaluate Large Language Models (LLMs) by assessing their tendency to generate harmful or undesirable responses. \\nIt may serve as a benchmark to assess the potential harm of responses produced by LLMs. \\nThe dataset is categorized into seven distinct classes of questions: deception, discrimination, harmful information, substance abuse, sexual content, personally‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ibm-research/AttaQ."},
	{"name":"hindi-headline-article-generation","keyword":"monolingual","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ganeshjcs/hindi-headline-article-generation","creator_name":"Ganesh Jagadeesan","creator_url":"https://huggingface.co/ganeshjcs","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSummary\\n\\t\\n\\nhindi-headline-article-generation is an open source dataset of instruct-style records generated from the Hindi Text Short and Large Summarization dataset. This was created as part of Aya Open Science Initiative from Cohere For AI.\\nThis dataset can be used for any purpose, whether academic or commercial, under the terms of the CC BY-SA 4.0 License.\\nSupported Tasks:\\n\\nTraining LLMs\\nSynthetic Data Generation\\nData Augmentation\\n\\nLanguages: Hindi Version: 1.0‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ganeshjcs/hindi-headline-article-generation."},
	{"name":"thaisum","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/pythainlp/thaisum","creator_name":"PyThaiNLP","creator_url":"https://huggingface.co/pythainlp","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for ThaiSum\\n\\t\\n\\nThis dataset was forked from thaisum to HF hub.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThaiSum is a large-scale corpus for Thai text summarization obtained from several online news websites namely Thairath, ThaiPBS, Prachathai, and The Standard. This dataset consists of over 350,000 article and summary pairs written by journalists.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSupported Tasks and Leaderboards\\n\\t\\n\\nsummarization, language modeling\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages\\n\\t\\n\\nThai\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/pythainlp/thaisum."},
	{"name":"uz-books","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/tahrirchi/uz-books","creator_name":"Tahrirchi","creator_url":"https://huggingface.co/tahrirchi","description":"\\n\\t\\n\\t\\t\\n\\t\\tDataset Card for BookCorpus\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nIn an effort to democratize research on low-resource languages, we release UzBooks dataset, a cleaned book corpus consisting of nearly 40000 books in Uzbek Language divided into two branches: \\\"original\\\" and \\\"lat,\\\" representing the OCRed (Latin and Cyrillic) and fully Latin versions of the texts, respectively. \\nPlease refer to our blogpost and paper (Coming soon!) for further details.\\nTo load and use dataset, run this script:‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/tahrirchi/uz-books."},
	{"name":"TOFU","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/locuslab/TOFU","creator_name":"Locus Lab","creator_url":"https://huggingface.co/locuslab","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tTOFU: Task of Fictitious Unlearning üç¢\\n\\t\\n\\nThe TOFU dataset serves as a benchmark for evaluating unlearning performance of large language models on realistic tasks. The dataset comprises question-answer pairs based on autobiographies of 200 different authors that do not exist and are completely fictitiously generated by the GPT-4 model. The goal of the task is to unlearn a fine-tuned model on various fractions of the forget set.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tQuick Links\\n\\t\\n\\n\\nWebsite: The landing page‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/locuslab/TOFU."},
	{"name":"amazon-food-reviews-dataset","keyword":"monolingual","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/jhan21/amazon-food-reviews-dataset","creator_name":"misschestnut","creator_url":"https://huggingface.co/jhan21","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for \\\"Amazon Food Reviews\\\"\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThis dataset consists of reviews of fine foods from amazon. The data span a period of more than 10 years, including all ~500,000 reviews up to October 2012. Reviews include product and user information, ratings, and a plain text review. It also includes reviews from all other Amazon categories.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSupported Tasks and Leaderboards\\n\\t\\n\\nThis dataset can be used for numerous tasks like sentiment analysis‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/jhan21/amazon-food-reviews-dataset."},
	{"name":"SeeTRUE-Feedback","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mismatch-quest/SeeTRUE-Feedback","creator_name":"mismatch-quest","creator_url":"https://huggingface.co/mismatch-quest","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for SeeTRUE-Feedback\\n\\t\\n\\n\\nDataset Description\\nSupported Tasks and Leaderboards\\nLanguages\\n\\n\\nDataset Structure\\nData Fields\\nData Splits\\n\\n\\nDataset Creation\\nLicensing Information\\nCitation Information\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThe SeeTRUE-Feedback dataset is a diverse benchmark for the meta-evaluation of image-text matching/alignment feedback. It aims to overcome limitations in current benchmarks, which primarily focus on predicting a matching score between 0-1.‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mismatch-quest/SeeTRUE-Feedback."},
	{"name":"code-securite-sociale","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/louisbrulenaudet/code-securite-sociale","creator_name":"Louis Brul√© Naudet","creator_url":"https://huggingface.co/louisbrulenaudet","description":"\\n\\t\\n\\t\\t\\n\\t\\tCode de la s√©curit√© sociale, non-instruct (2025-03-10)\\n\\t\\n\\nThe objective of this project is to provide researchers, professionals and law students with simplified, up-to-date access to all French legal texts, enriched with a wealth of data to facilitate their integration into Community and European projects.\\nNormally, the data is refreshed daily on all legal codes, and aims to simplify the production of training sets and labeling pipelines for the development of free, open-source‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/louisbrulenaudet/code-securite-sociale."},
	{"name":"tamil_stories","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/aitamilnadu/tamil_stories","creator_name":"AI Tamil Nadu","creator_url":"https://huggingface.co/aitamilnadu","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSummary\\n\\t\\n\\ntamil_stories is an open source dataset of instruct-style records generated by scraping publicly available short stories on the following websites.\\n\\nSiruvarmalar\\nTamilsurangam\\n\\nApart from scraping and automated cleaning, the data was also tagged manually by a group of volunteers. \\nThis dataset created as part of Aya Open Science Initiative by Cohere For AI.\\nThis dataset can be used for any purpose, whether academic or commercial, under the terms of the Apache 2.0‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/aitamilnadu/tamil_stories."},
	{"name":"code-travail","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/louisbrulenaudet/code-travail","creator_name":"Louis Brul√© Naudet","creator_url":"https://huggingface.co/louisbrulenaudet","description":"\\n\\t\\n\\t\\t\\n\\t\\tCode du travail, non-instruct (2025-03-10)\\n\\t\\n\\nThe objective of this project is to provide researchers, professionals and law students with simplified, up-to-date access to all French legal texts, enriched with a wealth of data to facilitate their integration into Community and European projects.\\nNormally, the data is refreshed daily on all legal codes, and aims to simplify the production of training sets and labeling pipelines for the development of free, open-source language models‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/louisbrulenaudet/code-travail."},
	{"name":"canarim","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/dominguesm/canarim","creator_name":"Maicon Domingues","creator_url":"https://huggingface.co/dominguesm","description":"\\n  \\n\\n\\n\\n  [üê± GitHub]\\n\\n\\n\\n\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tCanarim: A Large-Scale Dataset of Web Pages in the Portuguese Language\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tIntroduction\\n\\t\\n\\nCanarim is a database encompassing over 342 million Portuguese language documents, sourced from multiple iterations of CommonCrawl. This nearly 1 terabyte database stands as one of the most extensive Portuguese language data collections available. It underwent initial deduplication using URLs, with plans for further text-based deduplication and filtering‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/dominguesm/canarim."},
	{"name":"wb-products","keyword":"monolingual","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/nyuuzyou/wb-products","creator_name":"nyuuzyou","creator_url":"https://huggingface.co/nyuuzyou","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Wildberries products\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThis dataset was scraped from product pages on the Russian marketplace Wildberries. It includes all information from the product card and metadata from the API, excluding image URLs. The dataset was collected by processing approximately 160 million products out of a potential 230 million, starting from the first product. Data collection had to be stopped due to serious rate limits that prevented further‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/nyuuzyou/wb-products."},
	{"name":"ke-products","keyword":"monolingual","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/nyuuzyou/ke-products","creator_name":"nyuuzyou","creator_url":"https://huggingface.co/nyuuzyou","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Kazanexpress products\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThis dataset was scraped from product pages on the Russian marketplace Kazanexpress. It includes all information from the product card and metadata from the API. The dataset was collected by processing around 3 million products, starting from the first one. At the time the dataset was collected, it is assumed that these were all the products available on this marketplace. Please note that the data returned by‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/nyuuzyou/ke-products."},
	{"name":"PM-products","keyword":"monolingual","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/nyuuzyou/PM-products","creator_name":"nyuuzyou","creator_url":"https://huggingface.co/nyuuzyou","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for PochtaMarket products\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThis dataset was scraped from product pages on the Russian marketplace PochtaMarket. It includes all information from the product card. The dataset was collected by processing around 500 thousand, starting from the first one. At the time the dataset was collected, it is assumed that these were all the products available on this marketplace. Some fields may be empty, but the string is expected to contain some‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/nyuuzyou/PM-products."},
	{"name":"rutube-channels","keyword":"monolingual","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/nyuuzyou/rutube-channels","creator_name":"nyuuzyou","creator_url":"https://huggingface.co/nyuuzyou","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Rutube channels\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThis dataset was scraped from channel pages on the Russian video-sharing platform Rutube. It includes all information from the channel card. The dataset was collected by processing 36 million channels, starting from the first one. At the time the dataset was collected, it is assumed that these were all the channels available on this platform. Some fields may be empty, but the string is expected to contain some data‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/nyuuzyou/rutube-channels."},
	{"name":"9111-questions","keyword":"monolingual","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/nyuuzyou/9111-questions","creator_name":"nyuuzyou","creator_url":"https://huggingface.co/nyuuzyou","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for 9111.ru Questions\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThis dataset includes legal questions and answers from the Russian law forum 9111.ru. It contains inquiries from users and corresponding responses from lawyers. The dataset was created by processing around 21 million questions, providing a significant corpus of legal discussions.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages\\n\\t\\n\\nThe dataset is mostly in Russian, but there may be other languages present.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Structure‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/nyuuzyou/9111-questions."},
	{"name":"gsm8k-tr","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/malhajar/gsm8k-tr","creator_name":"Mohamad Alhajar","creator_url":"https://huggingface.co/malhajar","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for GSM8K\\n\\t\\n\\nThis Dataset is part of a series of datasets aimed at advancing Turkish LLM Developments by establishing rigid Turkish benchmarks to evaluate the performance of LLM's Produced in the Turkish Language.\\nmalhajar/GSM8K-tr is a translated version of GSM8K aimed specifically to be used in the OpenLLMTurkishLeaderboard \\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nGSM8K (Grade School Math 8K) is a dataset of 8.5K high quality linguistically diverse grade school math word‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/malhajar/gsm8k-tr."},
	{"name":"swim-ir-monolingual","keyword":"monolingual","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/nthakur/swim-ir-monolingual","creator_name":"Nandan Thakur","creator_url":"https://huggingface.co/nthakur","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for SWIM-IR (Monolingual)\\n\\t\\n\\n\\n\\n\\nThis is the monolingual subset of the SWIM-IR dataset, where the query generated and the passage are both in the same language.\\nA few remaining languages will be added in the upcoming v2 version of SWIM-IR. The dataset is available as CC-BY-SA 4.0.\\nFor full details of the dataset, please read our upcoming NAACL 2024 paper and check out our website.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tWhat is SWIM-IR?\\n\\t\\n\\nSWIM-IR dataset is a synthetic multilingual retrieval‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/nthakur/swim-ir-monolingual."},
	{"name":"SentiTurca","keyword":"monolingual","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/turkish-nlp-suite/SentiTurca","creator_name":"Turkish NLP Suite","creator_url":"https://huggingface.co/turkish-nlp-suite","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSentiTurca - A Sentiment Analysis Benchmark for Turkish\\n\\t\\n\\n\\n\\n\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for SentiTurca\\n\\t\\n\\nSentiTurca is a sentiment analysis benchmarking dataset including movie reviews, hate speech and e-commerce reviews classification.  \\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDatasets\\n\\t\\n\\ne-commerce: The e-commerce reviews are scraped from e-commerce websites Trendyol.com and Hepsiburada.com, including review for many product types such as cloths, toys, books, electronics and more.E-commerce reviews has‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/turkish-nlp-suite/SentiTurca."},
	{"name":"afrimmlu-translate-test","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/masakhane/afrimmlu-translate-test","creator_name":"Masakhane NLP","creator_url":"https://huggingface.co/masakhane","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for afrimmlu-translate-test\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nAFRIMMLU-TT is an evaluation dataset comprising translations of the AFRIMMLU dataset from 16 African languages and 1 high resource language into English using NLLB. \\nIt includes test sets across all 17 languages. \\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages\\n\\t\\n\\nThere are 17 languages available :\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Structure\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Instances\\n\\t\\n\\nThe examples look like this for English:\\nfrom datasets import load_dataset‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/masakhane/afrimmlu-translate-test."},
	{"name":"histoires_morales","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/LabHC/histoires_morales","creator_name":"Laboratoire Hubert Curien","creator_url":"https://huggingface.co/LabHC","description":"\\n\\t\\n\\t\\t\\n\\t\\tDataset Card for HistoiresMorales\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Summary\\n\\t\\n\\n‚öñ Histoires Morales is a French dataset derived from the English corpus Moral Stories through multi-step translation and consists of short narratives describing moral and deviant behaviors in social situations centered around personal relationships, education, commerce, domestic affairs, and meals.\\nEach of the 12,000 stories (histoires) follows the same seven-sentence structure as the Moral Stories dataset:\\nContext:‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/LabHC/histoires_morales."},
	{"name":"TurkishHateMap","keyword":"monolingual","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/turkish-nlp-suite/TurkishHateMap","creator_name":"Turkish NLP Suite","creator_url":"https://huggingface.co/turkish-nlp-suite","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tTurkish Hate Map - A Large Scale and Diverse Hate Speech Dataset for Turkish\\n\\t\\n\\n\\n\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nTurkish Hate Map (TuHaMa for short) is a big scale Turkish hate speech dataset that includes diverse target groups such as misogyny,\\npolitical animosity, animal aversion, vegan antipathy, ethnic group hostility, and more. The dataset includes a total of 52K instances with 13 target groups.\\nThe dataset includes 4 labels, offensive, hate, neutral and civilized.\\nHere is‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/turkish-nlp-suite/TurkishHateMap."},
	{"name":"IMDB_Sentiment","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Kwaai/IMDB_Sentiment","creator_name":"Kwaai","creator_url":"https://huggingface.co/Kwaai","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for \\\"imdb\\\"\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nLarge Movie Review Dataset.\\nThis is a dataset for binary sentiment classification containing substantially more data than previous benchmark datasets. We provide a set of 25,000 highly polar movie reviews for training, and 25,000 for testing. There is additional unlabeled data for use as well.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Structure\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Instances\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tplain_text\\n\\t\\n\\n\\nSize of downloaded dataset files: 84.13 MB‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Kwaai/IMDB_Sentiment."},
	{"name":"ru-instruct","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/d0rj/ru-instruct","creator_name":"Dmitry Balobin","creator_url":"https://huggingface.co/d0rj","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\t–ö–∞—Ä—Ç–æ—á–∫–∞ –¥–∞—Ç–∞—Å–µ—Ç–∞\\n\\t\\n\\n–°–∫–æ–º–±–∏–Ω–∏—Ä–æ–≤–∞–Ω –∏–∑ –Ω–µ—Å–∫–æ–ª—å–∫–∏—Ö –ø–æ–ø—É–ª—è—Ä–Ω—ã—Ö –¥–∞—Ç–∞—Å–µ—Ç–æ–≤, –ø–µ—Ä–µ–≤–µ–¥—ë–Ω–Ω—ã—Ö –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏. –û—Ç—Ñ–∏–ª—å—Ç—Ä–æ–≤–∞–Ω –Ω–∞ –ø—Ä–µ–¥–º–µ—Ç –∞—Ä—Ç–µ—Ñ–∞–∫—Ç–æ–≤ –ø–µ—Ä–µ–≤–æ–¥–∞ (—Å–ø–∞—Å–∏–±–æ –º–æ–¥–µ–ª–∏ Den4ikAI/nonsense_gibberish_detector). –î–µ–¥—É–ø–ª–∏—Ü–∏—Ä–æ–≤–∞–Ω SimHash'–æ–º.\\n–û–±—É—á–µ–Ω–Ω–æ–π –Ω–∞ –Ω—ë–º –º–æ–¥–µ–ª–∏ –ø–æ–∫–∞ –Ω–µ –∑–∞–≤—ë–∑, in progress.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\t–°–æ—Å—Ç–∞–≤\\n\\t\\n\\n–°–æ–±—Ä–∞–ª –∏–∑ —ç—Ç–∏—Ö –ø–µ—Ä–µ–≤–µ–¥—ë–Ω–Ω—ã—Ö:\\n\\nd0rj/OpenOrca-ru (–æ—Ç Open-Orca/OpenOrca)\\nd0rj/OpenHermes-2.5-ru (–æ—Ç teknium/OpenHermes-2.5)\\nd0rj/dolphin-ru (–æ—Ç ehartford/dolphin)\\nd0rj/alpaca-cleaned-ru (–æ—Ç‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/d0rj/ru-instruct."},
	{"name":"MoroccanSocialMedia-MultiGen","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/MBZUAI-Paris/MoroccanSocialMedia-MultiGen","creator_name":"MBZUAI France Lab","creator_url":"https://huggingface.co/MBZUAI-Paris","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for MoroccanSocialMedia-MultiGen (MSM-MG)\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nMoroccanSocialMedia-MultiGen (MSM-MG) is a dataset of 12,973 pairs of native Darija social media posts (tweets and YouTube comments) and their synthetic counterparts. The dataset supports six tasks: Continuation, Reply, Summarization, Rephrasing, Explanation, and Safe Response. The synthetic generations were created by prompting Claude 3.5 Sonnet to perform each of these tasks based on the‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/MBZUAI-Paris/MoroccanSocialMedia-MultiGen."},
	{"name":"Tuda-De","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/uhhlt/Tuda-De","creator_name":"LT Group at UHH","creator_url":"https://huggingface.co/uhhlt","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tOpen speech data for German speech recognition\\n\\t\\n\\nLanguage Technology, Universit√§t Hamburg, Germany\\nhttps://www.inf.uni-hamburg.de/en/inst/ab/lt (formerly TU-Darmstadt)\\nhttps://www.lt.tu-darmstadt.de\\nTelecooperation labs, TU-Darmstadt, Germany\\nhttps://www.tk.informatik.tu-darmstadt.de\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tGeneral information\\n\\t\\n\\n\\nThe speech data was collected in a controlled environment (same room, same microphone distances, etc. )\\nDistance between speakers and the microphones is about 1‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/uhhlt/Tuda-De."},
	{"name":"books","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/IsmaelMousa/books","creator_name":"Ismael","creator_url":"https://huggingface.co/IsmaelMousa","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tBooks\\n\\t\\n\\nThe books dataset consists of a diverse collection of books organized into 9 categories, it splitted to train, validation where the train contains 40 books, and the validation 9 books.\\nThis dataset is cleaned well and designed to support various natural language processing (NLP) tasks, including text generation and masked language modeling.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDetails\\n\\t\\n\\nThe dataset contains 4 columns:\\n\\ntitle: The tilte of the book.\\nauthor: The author of the book.\\ncategory: The‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/IsmaelMousa/books."},
	{"name":"libri-in-italiano","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/IsmaelMousa/libri-in-italiano","creator_name":"Ismael","creator_url":"https://huggingface.co/IsmaelMousa","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLibri\\n\\t\\n\\nIl dataset dei libri consiste in una raccolta diversificata di 18 libri organizzati in 4 categorie.\\nQuesto dataset √® ben pulito e progettato per supportare diversi compiti di elaborazione del linguaggio naturale (NLP), inclusi generazione di testo, traduzione e modellazione del linguaggio mascherato.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDettagli\\n\\t\\n\\nIl dataset contiene 4 colonne:\\n\\ntitolo: Il titolo del libro.\\nautore: L'autore del libro.\\ncategoria: Il genere/categoria del libro.\\ncontenuto: Il‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/IsmaelMousa/libri-in-italiano."},
	{"name":"monkey_business","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/ScalingIntelligence/monkey_business","creator_name":"Scaling Intelligence","creator_url":"https://huggingface.co/ScalingIntelligence","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tMonkey Business\\n\\t\\n\\nMonkey Business is a dataset of samples from large language models. It contains both correct and incorrect samples from a variety of models (the Llama-3, Gemma, and Pythia series) on a variety of tasks (problems from GSM8K, MATH, CodeContests, and MiniF2F-MATH). We hope that it can be useful for developing improved verification methods that assess whether a model generated answer is correct.\\nThis dataset was created as part of the project: \\\"Large Language‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ScalingIntelligence/monkey_business."},
	{"name":"NanoQuoraRetrieval","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/zeta-alpha-ai/NanoQuoraRetrieval","creator_name":"Zeta Alpha","creator_url":"https://huggingface.co/zeta-alpha-ai","description":"zeta-alpha-ai/NanoQuoraRetrieval dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"ruschatgpt-qa","keyword":"monolingual","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/nyuuzyou/ruschatgpt-qa","creator_name":"nyuuzyou","creator_url":"https://huggingface.co/nyuuzyou","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for ruschatgpt\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThis dataset contains question-answer pairs collected from ruschatgpt.ru, a Russian question-answering website. Each entry in the dataset represents a question asked by a user and the corresponding answer generated by an unspecified language model. The dataset contains 190,281 unique question-answer pairs covering various topics.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages\\n\\t\\n\\nThe dataset is primarily in Russian.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Structure‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/nyuuzyou/ruschatgpt-qa."},
	{"name":"polymath","keyword":"monolingual","license":"Academic Free License v3.0","license_url":"https://choosealicense.com/licenses/afl-3.0/","language":"en","dataset_url":"https://huggingface.co/datasets/him1411/polymath","creator_name":"Himanshu Gupta","creator_url":"https://huggingface.co/him1411","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tPaper Information\\n\\t\\n\\nWe present PolyMATH, a challenging benchmark aimed at evaluating the general cognitive reasoning abilities of MLLMs. \\nPolyMATH comprises 5,000 manually collected high-quality images of cognitive textual and visual challenges across 10 distinct categories, including pattern recognition, spatial reasoning, and relative reasoning. \\nWe conducted a comprehensive, and quantitative evaluation of 15 MLLMs using four diverse prompting strategies, including‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/him1411/polymath."},
	{"name":"BinauralLibriSpeech","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Holger1997/BinauralLibriSpeech","creator_name":"Holger Severin Bovbjerg","creator_url":"https://huggingface.co/Holger1997","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Dataset Name\\n\\t\\n\\n\\n\\nThis is a Binaural version of LibriSpeech, created using HRTFs from the ARI database and reverberation using simulated RIRs from the SLR28 Room Impulse Response and Noise Database.\\nThe dataset has annotations of the source direction as well as microphone array geometry. \\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Details\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\n\\n\\n\\n\\n\\nCurated by: [More Information Needed]\\nLanguage(s) (NLP): English\\nLicense: [More Information Needed]‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Holger1997/BinauralLibriSpeech."},
	{"name":"Galgame_Speech_ASR_16kHz","keyword":"monolingual","license":"GNU General Public License v3.0","license_url":"https://choosealicense.com/licenses/gpl-3.0/","language":"en","dataset_url":"https://huggingface.co/datasets/litagin/Galgame_Speech_ASR_16kHz","creator_name":"litagin","creator_url":"https://huggingface.co/litagin","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Galgame_Speech_ASR_16kHz\\n\\t\\n\\n\\nThe following rules (in the original repository) must be followed:\\nÂøÖÈ°ªÈÅµÂÆàGNU General Public License v3.0ÂÜÖÁöÑÊâÄÊúâÂçèËÆÆÔºÅÈôÑÂä†ÔºöÁ¶ÅÊ≠¢ÂïÜÁî®ÔºåÊú¨Êï∞ÊçÆÈõÜ‰ª•Âèä‰ΩøÁî®Êú¨Êï∞ÊçÆÈõÜËÆ≠ÁªÉÂá∫Êù•ÁöÑ‰ªª‰ΩïÊ®°ÂûãÈÉΩ‰∏çÂæóÁî®‰∫é‰ªª‰ΩïÂïÜ‰∏öË°å‰∏∫ÔºåÂ¶ÇË¶ÅÁî®‰∫éÂïÜ‰∏öÁî®ÈÄîÔºåËØ∑ÊâæÊï∞ÊçÆÂàóË°®ÂÜÖÁöÑÊâÄÊúâÂéÇÂïÜÊéàÊùÉÔºàÁ¨ëÔºâÔºåÂõ†ËøùÂèçÂºÄÊ∫êÂçèËÆÆËÄåÂá∫Áé∞ÁöÑ‰ªª‰ΩïÈóÆÈ¢òÈÉΩ‰∏éÊú¨‰∫∫Êó†ÂÖ≥ÔºÅ\\nËÆ≠ÁªÉÂá∫Êù•ÁöÑÊ®°ÂûãÂøÖÈ°ªÂºÄÊ∫êÔºåÊòØÂê¶Âú®READMEÂÜÖÂºïÁî®Êú¨Êï∞ÊçÆÈõÜÁî±ËÆ≠ÁªÉËÄÖËá™‰∏ªÂÜ≥ÂÆöÔºå‰∏çÂÅöÂº∫Âà∂Ë¶ÅÊ±Ç„ÄÇ\\nEnglish:\\nYou must comply with all the terms of the GNU General Public License v3.0!Additional note: Commercial use is prohibited. This dataset and any model trained using this dataset cannot be‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/litagin/Galgame_Speech_ASR_16kHz."},
	{"name":"twinviews-13k","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/wwbrannon/twinviews-13k","creator_name":"William Brannon","creator_url":"https://huggingface.co/wwbrannon","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for TwinViews-13k\\n\\t\\n\\nThis dataset contains 13,855 pairs of left-leaning and right-leaning political statements matched by topic. The dataset was generated using GPT-3.5 Turbo and has been audited to ensure quality and ideological balance. It is designed to facilitate the study of political bias in reward models and language models, with a focus on the relationship between truthfulness and political views.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Details\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/wwbrannon/twinviews-13k."},
	{"name":"Galgame_Speech_SER_16kHz","keyword":"monolingual","license":"GNU General Public License v3.0","license_url":"https://choosealicense.com/licenses/gpl-3.0/","language":"en","dataset_url":"https://huggingface.co/datasets/litagin/Galgame_Speech_SER_16kHz","creator_name":"litagin","creator_url":"https://huggingface.co/litagin","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Galgame_Speech_SER_16kHz\\n\\t\\n\\n\\nThe following rules (in the original repository) must be followed:\\nÂøÖÈ°ªÈÅµÂÆàGNU General Public License v3.0ÂÜÖÁöÑÊâÄÊúâÂçèËÆÆÔºÅÈôÑÂä†ÔºöÁ¶ÅÊ≠¢ÂïÜÁî®ÔºåÊú¨Êï∞ÊçÆÈõÜ‰ª•Âèä‰ΩøÁî®Êú¨Êï∞ÊçÆÈõÜËÆ≠ÁªÉÂá∫Êù•ÁöÑ‰ªª‰ΩïÊ®°ÂûãÈÉΩ‰∏çÂæóÁî®‰∫é‰ªª‰ΩïÂïÜ‰∏öË°å‰∏∫ÔºåÂ¶ÇË¶ÅÁî®‰∫éÂïÜ‰∏öÁî®ÈÄîÔºåËØ∑ÊâæÊï∞ÊçÆÂàóË°®ÂÜÖÁöÑÊâÄÊúâÂéÇÂïÜÊéàÊùÉÔºàÁ¨ëÔºâÔºåÂõ†ËøùÂèçÂºÄÊ∫êÂçèËÆÆËÄåÂá∫Áé∞ÁöÑ‰ªª‰ΩïÈóÆÈ¢òÈÉΩ‰∏éÊú¨‰∫∫Êó†ÂÖ≥ÔºÅ\\nËÆ≠ÁªÉÂá∫Êù•ÁöÑÊ®°ÂûãÂøÖÈ°ªÂºÄÊ∫êÔºåÊòØÂê¶Âú®READMEÂÜÖÂºïÁî®Êú¨Êï∞ÊçÆÈõÜÁî±ËÆ≠ÁªÉËÄÖËá™‰∏ªÂÜ≥ÂÆöÔºå‰∏çÂÅöÂº∫Âà∂Ë¶ÅÊ±Ç„ÄÇ\\nEnglish:\\nYou must comply with all the terms of the GNU General Public License v3.0!Additional note: Commercial use is prohibited. This dataset and any model trained using this dataset cannot be‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/litagin/Galgame_Speech_SER_16kHz."},
	{"name":"search-dataset","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/junzhang1207/search-dataset","creator_name":"John","creator_url":"https://huggingface.co/junzhang1207","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tAI Search Providers Benchmark Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tüìä Dataset Structure\\n\\t\\n\\nEach entry contains:\\n\\nid: Unique identifier for the QA pair\\nquestion: The query text\\nexpected_answer: The correct answer\\ncategory: Topic category\\narea: Broader area classification (News/Knowledge)\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tüéØ Categories\\n\\t\\n\\nThe dataset covers various domains including:\\n\\nEntertainment\\nSports\\nTechnology\\nGeneral News\\nFinance\\nArchitecture\\nArts\\nAstronomy\\nAuto (Automotive)\\nE-sports\\nFashion\\nFalse Premise‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/junzhang1207/search-dataset."},
	{"name":"bower-waste-annotations","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/BowerApp/bower-waste-annotations","creator_name":"Bower (Sugi Group AB)","creator_url":"https://huggingface.co/BowerApp","description":"\\n\\t\\n\\t\\t\\n\\t\\tDataset Card for waste annotations made by the recycling solution Bower\\n\\t\\n\\n\\n  \\n\\n\\n\\nThe data offered by Bower (Sugi Group AB) in collaboration with Google.org \\n\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThe bower-waste-annotations dataset consists of 1440 images of waste and various consumer items taken by consumer phone cameras. The images are annotated with Material type and Object type classes, listed below.\\nThe images and annotations has been manually reviewed to ensure correctness. It is assumed‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/BowerApp/bower-waste-annotations."},
	{"name":"microvqa","keyword":"monolingual","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/microvqa/microvqa","creator_name":"microvqa","creator_url":"https://huggingface.co/microvqa","description":"Small Subset of MicroVQA for Demonstration Purposes\\n\\n\\n \\n üåê Homepage ‚Ä¢\\n ü§ó HF Dataset ‚Ä¢\\n üèõ CC-BY-SA-4.0\\n\\n This is a small subset of the MicroVQA benchmark. MicroVQA is an original, expert-curated benchmark for multimodal reasoning for microscopy-based scientific research.\\n\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDescription\\n\\t\\n\\nScientific research demands sophisticated reasoning over multimodal  data, a challenge especially prevalent in biology. Despite recent advances in multimodal large language models (MLLMs) for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/microvqa/microvqa."},
	{"name":"metallurgy-qa","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Abdulrhman37/metallurgy-qa","creator_name":"Eldeeb","creator_url":"https://huggingface.co/Abdulrhman37","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tMetallurgy and Materials Science Knowledge Extraction Dataset\\n\\t\\n\\nThis repository contains a dataset generated from parsed books related to various aspects of metallurgy, materials science, and engineering. The dataset is designed for fine-tuning Large Language Models (LLMs) for Question-Answering (QA) tasks in the domain of metallurgy and materials science.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tIntroduction\\n\\t\\n\\nThe dataset includes content derived from technical books in the field of metallurgy and materials‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Abdulrhman37/metallurgy-qa."},
	{"name":"xlam-function-calling-60k-raw-augmented","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/product-science/xlam-function-calling-60k-raw-augmented","creator_name":"Product Science","creator_url":"https://huggingface.co/product-science","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tXLAM Function Calling 60k Raw Augmented Dataset\\n\\t\\n\\nThis dataset includes augmented train and test splits derived from product-science/xlam-function-calling-60k-raw.\\n\\nTrain split size: Original size plus augmented data\\nTest split size: Original size plus augmented data\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tAugmentation Details\\n\\t\\n\\nThis dataset has been augmented by modifying function names in the original data. Randomly selected function names have underscores replaced with periods at random positions‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/product-science/xlam-function-calling-60k-raw-augmented."},
	{"name":"klingai","keyword":"monolingual","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/nyuuzyou/klingai","creator_name":"nyuuzyou","creator_url":"https://huggingface.co/nyuuzyou","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for KLING AI\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThis dataset contains 12,782 AI-generated media items (images and videos) created using KLING AI's generative tools. The content includes metadata and original files for various AI generations, encompassing both still images and motion videos created through text-to-image and image-to-video transformations.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages\\n\\t\\n\\nThe dataset is primarily in English (en), with prompts and metadata in English.‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/nyuuzyou/klingai."},
	{"name":"begemot","keyword":"monolingual","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/nyuuzyou/begemot","creator_name":"nyuuzyou","creator_url":"https://huggingface.co/nyuuzyou","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Begemot.ai\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThis dataset contains 2,728,999 educational project descriptions in Russian language generated with neural networks from begemot.ai website. The content includes project titles, descriptions, chapters and chapter content across various educational topics.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages\\n\\t\\n\\nThe dataset is primarily in Russian (ru).\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Structure\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Fields\\n\\t\\n\\nThis dataset includes the following‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/nyuuzyou/begemot."},
	{"name":"artfol","keyword":"monolingual","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/nyuuzyou/artfol","creator_name":"nyuuzyou","creator_url":"https://huggingface.co/nyuuzyou","description":"\\n\\t\\n\\t\\t\\n\\t\\tDataset Card for Artfol\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThis dataset contains 1,892,816 artwork posts from Artfol, an independent social media platform focused on artists. Each entry represents an artwork post with associated metadata including title, moderation flags, and URLs.\\n\\n\\t\\n\\t\\t\\n\\t\\tLanguages\\n\\t\\n\\nThe dataset is primarily in English (en).\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Structure\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tData Fields\\n\\t\\n\\nThis dataset includes the following fields:\\n\\nop: Unique identifier for the artist/poster (string)‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/nyuuzyou/artfol."},
	{"name":"emojis","keyword":"monolingual","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/nyuuzyou/emojis","creator_name":"nyuuzyou","creator_url":"https://huggingface.co/nyuuzyou","description":"\\n\\t\\n\\t\\t\\n\\t\\tDataset Card for Emojis.com\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThis dataset contains metadata for 3,264,372 AI-generated emoji images from Emojis.com. Each entry represents an emoji with associated metadata including prompt text and image URLs.\\n\\n\\t\\n\\t\\t\\n\\t\\tLanguages\\n\\t\\n\\nThe dataset is primarily in English (en).\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Structure\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tData Fields\\n\\t\\n\\nThis dataset includes the following fields:\\n\\nslug: Unique identifier for the emoji (string)\\nid: Internal ID (string) \\nnoBackgroundUrl:‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/nyuuzyou/emojis."},
	{"name":"MiniF2F","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Tonic/MiniF2F","creator_name":"Joseph [open/acc] Pollack","creator_url":"https://huggingface.co/Tonic","description":"\\n\\t\\n\\t\\t\\n\\t\\tminif2f Dataset\\n\\t\\n\\nThe minif2f dataset is a collection of mathematical problems and their formal statements, designed for formal mathematics and theorem proving tasks.\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThe minif2f dataset contains mathematical problems from various sources (like AMC competitions) along with their formal statements in the Lean theorem prover format. Each example includes both informal mathematical statements and their corresponding formal‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Tonic/MiniF2F."},
	{"name":"Chart-MRAG","keyword":"monolingual","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ymyang/Chart-MRAG","creator_name":"Young Yurm","creator_url":"https://huggingface.co/ymyang","description":"\\n\\t\\n\\t\\t\\n\\t\\tBenchmarking Multimodal RAG through a Chart-based Document Question-Answering Generation Framework\\n\\t\\n\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tOverview\\n\\t\\n\\nMultimodal Retrieval-Augmented Generation (MRAG) enhances reasoning capabilities by integrating external knowledge. However, existing benchmarks primarily focus on simple image-text interactions, overlooking complex visual formats like charts that are prevalent in real-world applications. In this work, we introduce a novel task, Chart-based MRAG, to address this‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ymyang/Chart-MRAG."},
	{"name":"LMTuberEval","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/shadowlilac/LMTuberEval","creator_name":"ShadowLilac","creator_url":"https://huggingface.co/shadowlilac","description":"\\n\\t\\n\\t\\t\\n\\t\\tDataset Card for LMTuberEval\\n\\t\\n\\nTraining LLMs to convincingly emulate VTubers requires rigorous evaluation of their knowledge, encompassing both specific VTuber details and the broader VTuber landscape.  Current LLMs often struggle with factuality, particularly regarding lesser-known VTubers, frequently resorting to hallucination and generating incorrect information. This benchmark addresses the critical need for objective measurement of this specialized knowledge, which is currently‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/shadowlilac/LMTuberEval."},
	{"name":"grustnogram","keyword":"monolingual","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/nyuuzyou/grustnogram","creator_name":"nyuuzyou","creator_url":"https://huggingface.co/nyuuzyou","description":"\\n\\t\\n\\t\\t\\n\\t\\tDataset Card for Grustnogram\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThis dataset contains 597,704 posts from Grustnogram.ru, a Russian \\\"emotional network\\\" similar to Instagram but with a distinctive black and white filter aesthetic and dark atmosphere. The dataset includes 542,917 image posts with associated metadata and 54,787 anonymous text-only posts.\\n\\n\\t\\n\\t\\t\\n\\t\\tLanguages\\n\\t\\n\\nThe dataset is primarily in Russian (ru).\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Structure\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tData Splits\\n\\t\\n\\nThe dataset is divided into‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/nyuuzyou/grustnogram."},
	{"name":"journals","keyword":"monolingual","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/nyuuzyou/journals","creator_name":"nyuuzyou","creator_url":"https://huggingface.co/nyuuzyou","description":"\\n\\t\\n\\t\\t\\n\\t\\tDataset Card for Historical Russian Technical Journal Images\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThis dataset contains images of pages from old Russian technical journals with descriptions generated using Google Gemini 2.0 Flash.\\n\\n\\t\\n\\t\\t\\n\\t\\tLanguages\\n\\t\\n\\nThe dataset is monolingual:\\n\\nRussian (ru): All journal pages are in Russian with corresponding Russian descriptions\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Structure\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tData Files\\n\\t\\n\\nThe dataset consists of:\\n\\nImage files (.jpg format)\\nCorresponding description‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/nyuuzyou/journals."},
	{"name":"medium-articles-posts-with-content","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Alaamer/medium-articles-posts-with-content","creator_name":"The First","creator_url":"https://huggingface.co/Alaamer","description":"\\n\\t\\n\\t\\t\\n\\t\\tMedium Articles Dataset Generator\\n\\t\\n\\nThis project combines multiple datasets from Kaggle and Hugging Face to create a comprehensive collection of Medium articles. The combined dataset is available on Hugging Face Hub.\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThis dataset is a unique compilation that not only combines multiple sources but also ensures data quality through normalization and deduplication. A key feature is that all entries in the text column are unique - there are no duplicate‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Alaamer/medium-articles-posts-with-content."},
	{"name":"acronym_identification","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/amirveyseh/acronym_identification","creator_name":"amir veyseh","creator_url":"https://huggingface.co/amirveyseh","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Acronym Identification Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThis dataset contains the training, validation, and test data for the Shared Task 1: Acronym Identification of the AAAI-21 Workshop on Scientific Document Understanding.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSupported Tasks and Leaderboards\\n\\t\\n\\nThe dataset supports an acronym-identification task, where the aim is to predic which tokens in a pre-tokenized sentence correspond to acronyms. The dataset was released for a Shared‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/amirveyseh/acronym_identification."},
	{"name":"adversarial_qa","keyword":"monolingual","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/UCLNLP/adversarial_qa","creator_name":"UCL NLP","creator_url":"https://huggingface.co/UCLNLP","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for adversarialQA\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nWe have created three new Reading Comprehension datasets constructed using an adversarial model-in-the-loop.\\nWe use three different models; BiDAF (Seo et al., 2016), BERTLarge (Devlin et al., 2018), and RoBERTaLarge (Liu et al., 2019) in the annotation loop and construct three datasets; D(BiDAF), D(BERT), and D(RoBERTa), each with 10,000 training examples, 1,000 validation, and 1,000 test examples.\\nThe adversarial‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/UCLNLP/adversarial_qa."},
	{"name":"allegro_reviews","keyword":"monolingual","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/legacy-datasets/allegro_reviews","creator_name":"Legacy Datasets","creator_url":"https://huggingface.co/legacy-datasets","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for [Dataset Name]\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nAllegro Reviews is a sentiment analysis dataset, consisting of 11,588 product reviews written in Polish and extracted from Allegro.pl - a popular e-commerce marketplace. Each review contains at least 50 words and has a rating on a scale from one (negative review) to five (positive review).\\nWe recommend using the provided train/dev/test split. The ratings for the test set reviews are kept hidden. You can evaluate your‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/legacy-datasets/allegro_reviews."},
	{"name":"allocine","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/tblard/allocine","creator_name":"Th√©ophile Blard","creator_url":"https://huggingface.co/tblard","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Allocin√©\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThe Allocin√© dataset is a French-language dataset for sentiment analysis. The texts are movie reviews written between 2006 and 2020 by members of the Allocin√©.fr community for various films. It contains 100k positive and 100k negative reviews divided into train (160k), validation (20k), and test (20k). \\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSupported Tasks and Leaderboards\\n\\t\\n\\n\\ntext-classification, sentiment-classification: The dataset can be used‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/tblard/allocine."},
	{"name":"amttl","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/gavinxing/amttl","creator_name":"Gavin Xing","creator_url":"https://huggingface.co/gavinxing","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for AMTTL\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\n[More Information Needed]\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSupported Tasks and Leaderboards\\n\\t\\n\\n[More Information Needed]\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages\\n\\t\\n\\n[More Information Needed]\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Structure\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Instances\\n\\t\\n\\n[More Information Needed]\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Fields\\n\\t\\n\\n[More Information Needed]\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Splits\\n\\t\\n\\n[More Information Needed]\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Creation\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tCuration Rationale\\n\\t\\n\\n[More Information‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/gavinxing/amttl."},
	{"name":"ar_sarcasm","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/iabufarha/ar_sarcasm","creator_name":"Ibrahim","creator_url":"https://huggingface.co/iabufarha","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for ArSarcasm\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nArSarcasm is a new Arabic sarcasm detection dataset.\\nThe dataset was created using previously available Arabic sentiment analysis\\ndatasets (SemEval 2017\\nand ASTD) and adds sarcasm and\\ndialect labels to them.\\nThe dataset contains 10,547 tweets, 1,682 (16%) of which are sarcastic.\\nFor more details, please check the paper\\nFrom Arabic Sentiment Analysis to Sarcasm Detection: The ArSarcasm Dataset\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSupported Tasks‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/iabufarha/ar_sarcasm."},
	{"name":"arcd","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/hsseinmz/arcd","creator_name":"Hussein Mozannar","creator_url":"https://huggingface.co/hsseinmz","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for \\\"arcd\\\"\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\n Arabic Reading Comprehension Dataset (ARCD) composed of 1,395 questions      posed by crowdworkers on Wikipedia articles.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSupported Tasks and Leaderboards\\n\\t\\n\\nMore Information Needed\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages\\n\\t\\n\\nMore Information Needed\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Structure\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Instances\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tplain_text\\n\\t\\n\\n\\nSize of downloaded dataset files: 1.94 MB\\nSize of the generated dataset: 1.70 MB\\nTotal amount‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/hsseinmz/arcd."},
	{"name":"ascent_kb","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/tuanphong/ascent_kb","creator_name":"Tuan-Phong Nguyen","creator_url":"https://huggingface.co/tuanphong","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Ascent KB\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThis dataset contains 8.9M commonsense assertions extracted  by the Ascent pipeline developed at the Max Planck Institute for Informatics.\\nThe focus of this dataset is on everyday concepts such as elephant, car, laptop, etc.\\nThe current version of Ascent KB (v1.0.0) is approximately 19 times larger  than ConceptNet (note that, in this comparison, non-commonsense knowledge in ConceptNet such as lexical relations is‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/tuanphong/ascent_kb."},
	{"name":"asset","keyword":"monolingual","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/facebook/asset","creator_name":"AI at Meta","creator_url":"https://huggingface.co/facebook","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for ASSET\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nASSET (Alva-Manchego et al., 2020) is multi-reference dataset for the evaluation of sentence simplification in English. The dataset uses the same 2,359 sentences from TurkCorpus (Xu et al., 2016) and each sentence is associated with 10 crowdsourced simplifications. Unlike previous simplification datasets, which contain a single transformation (e.g., lexical paraphrasing in TurkCorpus or sentence\\nsplitting in HSplit), the‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/facebook/asset."},
	{"name":"bbc_hindi_nli","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/midas/bbc_hindi_nli","creator_name":"MIDAS Research Laboratory, IIIT-Delhi","creator_url":"https://huggingface.co/midas","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for BBC Hindi NLI Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\n\\nDataset for Natural Language Inference in Hindi Language. BBC Hindi Dataset consists of textual-entailment pairs.\\nEach row of the Datasets if made up of 4 columns - Premise, Hypothesis, Label and Topic.\\nContext and Hypothesis is written in Hindi while Entailment_Label is in English.\\nEntailment_label is of 2 types - entailed and not-entailed.\\nDataset can be used to train models for Natural Language Inference‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/midas/bbc_hindi_nli."},
	{"name":"biosses","keyword":"monolingual","license":"GNU General Public License v3.0","license_url":"https://choosealicense.com/licenses/gpl-3.0/","language":"en","dataset_url":"https://huggingface.co/datasets/tabilab/biosses","creator_name":"BOUN Text Analytics and BIoInformatics Lab User","creator_url":"https://huggingface.co/tabilab","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for BIOSSES\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nBIOSSES is a benchmark dataset for biomedical sentence similarity estimation. The dataset comprises 100 sentence pairs, in which each sentence was selected from the TAC (Text Analysis Conference) Biomedical Summarization Track Training Dataset containing articles from the biomedical domain. The sentence pairs in BIOSSES were selected from citing sentences, i.e. sentences that have a citation to a reference article. \\nThe‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/tabilab/biosses."},
	{"name":"cdt","keyword":"monolingual","license":"BSD 3-Clause \"New\" or \"Revised\" License","license_url":"https://choosealicense.com/licenses/bsd-3-clause/","language":"en","dataset_url":"https://huggingface.co/datasets/ptaszynski/cdt","creator_name":"Michal Ptaszynski","creator_url":"https://huggingface.co/ptaszynski","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for [Dataset Name]\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThe Cyberbullying Detection task was part of 2019 edition of PolEval competition. The goal is to predict if a given Twitter message contains a cyberbullying (harmful) content.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSupported Tasks and Leaderboards\\n\\t\\n\\n[More Information Needed]\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages\\n\\t\\n\\nPolish\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Structure\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Instances\\n\\t\\n\\n[More Information Needed]\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Fields\\n\\t\\n\\n\\nsentence: an‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ptaszynski/cdt."},
	{"name":"cedr_v1","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/sagteam/cedr_v1","creator_name":"AI technology lab at NRC \\\"Kurchatov Institute","creator_url":"https://huggingface.co/sagteam","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for [cedr]\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThe Corpus for Emotions Detecting in Russian-language text sentences of different social sources (CEDR) contains 9410  comments labeled for 5 emotion categories (joy, sadness, surprise, fear, and anger). \\nHere are 2 dataset configurations:\\n\\n\\\"main\\\" - contains \\\"text\\\", \\\"labels\\\", and \\\"source\\\" features;\\n\\\"enriched\\\" - includes all \\\"main\\\" features and \\\"sentences\\\".\\n\\nDataset with predefined train/test splits.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSupported‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/sagteam/cedr_v1."},
	{"name":"circa","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/google-research-datasets/circa","creator_name":"Google Research Datasets","creator_url":"https://huggingface.co/google-research-datasets","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for CIRCA\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThe Circa (meaning ‚Äòapproximately‚Äô) dataset aims to help machine learning systems to solve the problem of interpreting indirect answers to polar questions.\\nThe dataset contains pairs of yes/no questions and indirect answers, together with annotations for the interpretation of the answer. The data is collected in 10 different social conversational situations (eg. food preferences of a friend).\\nThe following are the situational‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/google-research-datasets/circa."},
	{"name":"coarse_discourse","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/google-research-datasets/coarse_discourse","creator_name":"Google Research Datasets","creator_url":"https://huggingface.co/google-research-datasets","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for \\\"coarse_discourse\\\"\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nA large corpus of discourse annotations and relations on ~10K forum threads.\\nWe collect and release a corpus of over 9,000 threads comprising over 100,000 comments manually annotated via paid crowdsourcing with discourse acts and randomly sampled from the site Reddit.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSupported Tasks and Leaderboards\\n\\t\\n\\nMore Information Needed\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages\\n\\t\\n\\nMore Information Needed\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/google-research-datasets/coarse_discourse."},
	{"name":"cs_restaurants","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/community-datasets/cs_restaurants","creator_name":"Community Datasets","creator_url":"https://huggingface.co/community-datasets","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Czech Restaurant\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThis is a dataset for NLG in task-oriented spoken dialogue systems with Czech as the target language. It originated as a translation of the English San Francisco Restaurants dataset by Wen et al. (2015). The domain is restaurant information in Prague, with random/fictional values. It includes input dialogue acts and the corresponding outputs in Czech.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSupported Tasks and Leaderboards‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/community-datasets/cs_restaurants."},
	{"name":"discovery","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/sileod/discovery","creator_name":"Damien Sileo","creator_url":"https://huggingface.co/sileod","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Discovery\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nDiscourse marker prediction with 174 markers\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSupported Tasks and Leaderboards\\n\\t\\n\\n[More Information Needed]\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages\\n\\t\\n\\nEnglish\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Structure\\n\\t\\n\\ninput : sentence1, sentence2, \\nlabel: marker originally between sentence1 and sentence2\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Instances\\n\\t\\n\\n[More Information Needed]\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Fields\\n\\t\\n\\n[More Information Needed]\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Splits\\n\\t\\n\\nTrain/Val/Test‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/sileod/discovery."},
	{"name":"disfl_qa","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/google-research-datasets/disfl_qa","creator_name":"Google Research Datasets","creator_url":"https://huggingface.co/google-research-datasets","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for DISFL-QA: A Benchmark Dataset for Understanding Disfluencies in Question Answering\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nDisfl-QA is a targeted dataset for contextual disfluencies in an information seeking  setting, namely question answering over Wikipedia passages.  Disfl-QA builds upon the SQuAD-v2 (Rajpurkar et al., 2018) dataset, where each question in the dev set is annotated to add a contextual disfluency using the paragraph as a source of distractors.\\nThe final‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/google-research-datasets/disfl_qa."},
	{"name":"duorc","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/ibm-research/duorc","creator_name":"IBM Research","creator_url":"https://huggingface.co/ibm-research","description":"\\n\\t\\n\\t\\t\\n\\t\\tDataset Card for duorc\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThe DuoRC dataset is an English language dataset of questions and answers gathered from crowdsourced AMT workers on Wikipedia and IMDb movie plots. The workers were given freedom to pick answer from the plots or synthesize their own answers. It contains two sub-datasets - SelfRC and ParaphraseRC. SelfRC dataset is built on Wikipedia movie plots solely. ParaphraseRC has questions written from Wikipedia movie plots and the answers are‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ibm-research/duorc."},
	{"name":"dyk","keyword":"monolingual","license":"BSD 3-Clause \"New\" or \"Revised\" License","license_url":"https://choosealicense.com/licenses/bsd-3-clause/","language":"en","dataset_url":"https://huggingface.co/datasets/community-datasets/dyk","creator_name":"Community Datasets","creator_url":"https://huggingface.co/community-datasets","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for [Dataset Name]\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThe Did You Know (pol. Czy wiesz?) dataset consists of human-annotated question-answer pairs. The task is to predict if the answer is correct. We chose the negatives which have the largest token overlap with a question.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSupported Tasks and Leaderboards\\n\\t\\n\\n[More Information Needed]\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages\\n\\t\\n\\nPolish\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Structure\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Instances\\n\\t\\n\\n[More Information Needed]‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/community-datasets/dyk."},
	{"name":"generics_kb","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/community-datasets/generics_kb","creator_name":"Community Datasets","creator_url":"https://huggingface.co/community-datasets","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Generics KB\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nDataset contains a large (3.5M+ sentence) knowledge base of generic sentences.  This is the first large resource to contain naturally occurring generic sentences, rich in high-quality, general, semantically complete statements. All GenericsKB sentences are annotated with their topical term, surrounding context (sentences), and a (learned) confidence. We also release GenericsKB-Best (1M+ sentences), containing the‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/community-datasets/generics_kb."},
	{"name":"glucose","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/community-datasets/glucose","creator_name":"Community Datasets","creator_url":"https://huggingface.co/community-datasets","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for [Dataset Name]\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nGLUCOSE: GeneraLized and COntextualized Story Explanations, is a novel conceptual framework and dataset for commonsense reasoning. Given a short story and a sentence X in the story, GLUCOSE captures ten dimensions of causal explanation related to X. These dimensions, inspired by human cognitive psychology, cover often-implicit causes and effects of X, including events, location, possession, and other attributes.‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/community-datasets/glucose."},
	{"name":"hebrew_this_world","keyword":"monolingual","license":"GNU Affero General Public License v3.0","license_url":"https://choosealicense.com/licenses/agpl-3.0/","language":"en","dataset_url":"https://huggingface.co/datasets/community-datasets/hebrew_this_world","creator_name":"Community Datasets","creator_url":"https://huggingface.co/community-datasets","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for HebrewSentiment\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nHebrewThisWorld is a data set consists of 2028 issues of the newspaper 'This World' edited by Uri Avnery and were published between 1950 and 1989. Released under the AGPLv3 license.\\nData Annotation: \\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSupported Tasks and Leaderboards\\n\\t\\n\\nLanguage modeling\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages\\n\\t\\n\\nHebrew\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Structure\\n\\t\\n\\ncsv file with \\\",\\\" delimeter\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Instances\\n\\t\\n\\nSample:\\n{\\n  \\\"issue_num\\\": 637‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/community-datasets/hebrew_this_world."},
	{"name":"id_newspapers_2018","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/community-datasets/id_newspapers_2018","creator_name":"Community Datasets","creator_url":"https://huggingface.co/community-datasets","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Indonesian Newspapers 2018\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThe dataset contains around 500K articles (136M of words) from 7 Indonesian newspapers: Detik, Kompas, Tempo,\\nCNN Indonesia, Sindo, Republika and Poskota. The articles are dated between 1st January 2018 and 20th August 2018\\n(with few exceptions dated earlier). The size of uncompressed 500K json files (newspapers-json.tgz) is around 2.2GB,\\nand the cleaned uncompressed in a big text file (newspapers.txt.gz)‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/community-datasets/id_newspapers_2018."},
	{"name":"irc_disentangle","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/jkkummerfeld/irc_disentangle","creator_name":"Jonathan K. Kummerfeld","creator_url":"https://huggingface.co/jkkummerfeld","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for IRC Disentanglement\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nDisentangling conversations mixed together in a single stream of messages is a difficult task, made harder by the lack of large manually annotated datasets. This new dataset of 77,563 messages manually annotated with reply-structure graphs that both disentangle conversations and define internal conversation structure. The dataset is 16 times larger than all previously released datasets combined, the first to‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/jkkummerfeld/irc_disentangle."},
	{"name":"kor_3i4k","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/wicho/kor_3i4k","creator_name":"Won Ik Cho","creator_url":"https://huggingface.co/wicho","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for 3i4K\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThe 3i4K dataset is a set of frequently used Korean words (corpus provided by the Seoul National University Speech Language Processing Lab) and manually created questions/commands containing short utterances. The goal is to identify the speaker intention of a spoken utterance based on its transcript, and whether in some cases, requires using auxiliary acoustic features. The classification system decides whether the utterance‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/wicho/kor_3i4k."},
	{"name":"kor_nli","keyword":"monolingual","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/kakaobrain/kor_nli","creator_name":"Kakao Brain","creator_url":"https://huggingface.co/kakaobrain","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for \\\"kor_nli\\\"\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nKorean Natural Language Inference datasets.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSupported Tasks and Leaderboards\\n\\t\\n\\nMore Information Needed\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages\\n\\t\\n\\nMore Information Needed\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Structure\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Instances\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tmulti_nli\\n\\t\\n\\n\\nSize of downloaded dataset files: 42.11 MB\\nSize of the generated dataset: 84.72 MB\\nTotal amount of disk used: 126.85 MB\\n\\nAn example of 'train' looks as follows.‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/kakaobrain/kor_nli."},
	{"name":"kor_sarcasm","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/SpellOnYou/kor_sarcasm","creator_name":"SpellOnYou","creator_url":"https://huggingface.co/SpellOnYou","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Korean Sarcasm Detection\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThe Korean Sarcasm Dataset was created to detect sarcasm in text, which can significantly alter the original meaning of a sentence. 9319 tweets were collected from Twitter and labeled for sarcasm or not_sarcasm. These tweets were gathered by querying for: Ïó≠ÏÑ§, ÏïÑÎ¨¥Îßê, Ïö¥ÏàòÏ¢ãÏùÄÎÇ†, Á¨ë, Î≠êÎûò ÏïÑÎãôÎãàÎã§, Í∑∏Îü¥Î¶¨ÏóÜÎã§, Ïñ¥Í∑∏Î°ú, irony sarcastic, and sarcasm. The dataset was pre-processed by removing the keyword hashtag, urls and mentions of‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/SpellOnYou/kor_sarcasm."},
	{"name":"lambada","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/cimec/lambada","creator_name":"CIMeC - Center for Mind/Brain Sciences, University of Trento","creator_url":"https://huggingface.co/cimec","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for LAMBADA\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThe LAMBADA evaluates the capabilities of computational models\\nfor text understanding by means of a word prediction task.\\nLAMBADA is a collection of narrative passages sharing the characteristic\\nthat human subjects are able to guess their last word if\\nthey are exposed to the whole passage, but not if they\\nonly see the last sentence preceding the target word.\\nTo succeed on LAMBADA, computational models cannot\\nsimply rely on‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/cimec/lambada."},
	{"name":"nkjp-ner","keyword":"monolingual","license":"GNU General Public License v3.0","license_url":"https://choosealicense.com/licenses/gpl-3.0/","language":"en","dataset_url":"https://huggingface.co/datasets/nkjp/nkjp-ner","creator_name":"Narodowego Korpusu Jƒôzyka Polskiego","creator_url":"https://huggingface.co/nkjp","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for NJKP NER\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nA linguistic corpus is a collection of texts where one can find the typical use of a single word or a phrase, as well as their meaning and grammatical function. Nowadays, without access to a language corpus, it has become impossible to do linguistic research, to write dictionaries, grammars and language teaching books, to create search engines sensitive to Polish inflection, machine translation engines and software of‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/nkjp/nkjp-ner."},
	{"name":"onestop_english","keyword":"monolingual","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/iastate/onestop_english","creator_name":"Iowa State University","creator_url":"https://huggingface.co/iastate","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for OneStopEnglish corpus\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nOneStopEnglish is a corpus of texts written at three reading levels, and demonstrates its usefulness for through two applications - automatic readability assessment and automatic text simplification.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSupported Tasks and Leaderboards\\n\\t\\n\\n[More Information Needed]\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages\\n\\t\\n\\n[More Information Needed]\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Structure\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Instances\\n\\t\\n\\nAn instance example:\\n{‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/iastate/onestop_english."},
	{"name":"onestop_qa","keyword":"monolingual","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/malmaud/onestop_qa","creator_name":"Jonathan Malmaud","creator_url":"https://huggingface.co/malmaud","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for OneStopQA\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nOneStopQA is a multiple choice reading comprehension dataset annotated according to the STARC (Structured Annotations for Reading Comprehension) scheme. The reading materials are Guardian articles taken from the OneStopEnglish corpus. Each article comes in three difficulty levels, Elementary, Intermediate and Advanced. Each paragraph is annotated with three multiple choice reading comprehension questions. The reading‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/malmaud/onestop_qa."},
	{"name":"piaf","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/AgentPublic/piaf","creator_name":"AgentPublic","creator_url":"https://huggingface.co/AgentPublic","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Piaf\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nPiaf is a reading comprehension dataset. This version, published in February 2020, contains 3835 questions on French Wikipedia.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSupported Tasks and Leaderboards\\n\\t\\n\\nMore Information Needed\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages\\n\\t\\n\\nMore Information Needed\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Structure\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Instances\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tplain_text\\n\\t\\n\\n\\nSize of downloaded dataset files: 1.31 MB\\nSize of the generated dataset: 3.18 MB\\nTotal‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/AgentPublic/piaf."},
	{"name":"proto_qa","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/community-datasets/proto_qa","creator_name":"Community Datasets","creator_url":"https://huggingface.co/community-datasets","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for [Dataset Name]\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThis dataset is for studying computational models trained to reason about prototypical situations. It is anticipated that still would not lead to usage in a downstream task, but as a way of studying the knowledge (and biases) of prototypical situations already contained in pre-trained models. The data it is partially based on (Family Feud).\\nUsing deterministic filtering a sampling from a larger set of all‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/community-datasets/proto_qa."},
	{"name":"quartz","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/allenai/quartz","creator_name":"Ai2","creator_url":"https://huggingface.co/allenai","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for \\\"quartz\\\"\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nQuaRTz is a crowdsourced dataset of 3864 multiple-choice questions about open domain qualitative relationships. Each\\nquestion is paired with one of 405 different background sentences (sometimes short paragraphs).\\nThe QuaRTz dataset V1 contains 3864 questions about open domain qualitative relationships. Each question is paired with\\none of 405 different background sentences (sometimes short paragraphs).\\nThe dataset is split‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/allenai/quartz."},
	{"name":"re_dial","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/community-datasets/re_dial","creator_name":"Community Datasets","creator_url":"https://huggingface.co/community-datasets","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for ReDial (Recommendation Dialogues)\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nReDial (Recommendation Dialogues) is an annotated dataset of dialogues, where users\\nrecommend movies to each other. The dataset was collected by a team of researchers working at\\nPolytechnique Montr√©al, MILA ‚Äì Quebec AI Institute, Microsoft Research Montr√©al, HEC Montreal, and Element AI.\\nThe dataset allows research at the intersection of goal-directed dialogue systems\\n(such as restaurant‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/community-datasets/re_dial."},
	{"name":"ropes","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/allenai/ropes","creator_name":"Ai2","creator_url":"https://huggingface.co/allenai","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for ROPES\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nROPES (Reasoning Over Paragraph Effects in Situations) is a QA dataset which tests a system's ability to apply knowledge from a passage of text to a new situation. A system is presented a background passage containing a causal or qualitative relation(s) (e.g., \\\"animal pollinators increase efficiency of fertilization in flowers\\\"), a novel situation that uses this background, and questions that require reasoning about effects‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/allenai/ropes."},
	{"name":"selqa","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/community-datasets/selqa","creator_name":"Community Datasets","creator_url":"https://huggingface.co/community-datasets","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for SelQA\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nSelQA: A New Benchmark for Selection-Based Question Answering\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSupported Tasks and Leaderboards\\n\\t\\n\\nQuestion Answering\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages\\n\\t\\n\\nEnglish\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Structure\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Instances\\n\\t\\n\\nAn example from the answer selection set:\\n{\\n        \\\"section\\\": \\\"Museums\\\",\\n        \\\"question\\\": \\\"Where are Rockefeller Museum and LA Mayer Institute for Islamic Art?\\\",\\n        \\\"article\\\": \\\"Israel\\\"‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/community-datasets/selqa."},
	{"name":"snips_built_in_intents","keyword":"monolingual","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/sonos-nlu-benchmark/snips_built_in_intents","creator_name":"sonos-nlu-benchmark","creator_url":"https://huggingface.co/sonos-nlu-benchmark","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Snips Built In Intents\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nSnips' built in intents dataset was initially used to compare different voice assistants and released as a public dataset hosted at\\nhttps://github.com/sonos/nlu-benchmark in folder 2016-12-built-in-intents. The dataset contains 328 utterances over 10 intent classes.\\nA related Medium post is https://medium.com/snips-ai/benchmarking-natural-language-understanding-systems-d35be6ce568d.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSupported‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/sonos-nlu-benchmark/snips_built_in_intents."},
	{"name":"squad_v1_pt","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/nunorc/squad_v1_pt","creator_name":"Nuno Ramos Carvalho","creator_url":"https://huggingface.co/nunorc","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for \\\"squad_v1_pt\\\"\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nPortuguese translation of the SQuAD dataset. The translation was performed automatically using the Google Cloud API.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSupported Tasks and Leaderboards\\n\\t\\n\\nMore Information Needed\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages\\n\\t\\n\\nMore Information Needed\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Structure\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Instances\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tdefault\\n\\t\\n\\n\\nSize of downloaded dataset files: 39.53 MB\\nSize of the generated dataset: 96.72 MB\\nTotal amount‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/nunorc/squad_v1_pt."},
	{"name":"swahili_news","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/community-datasets/swahili_news","creator_name":"Community Datasets","creator_url":"https://huggingface.co/community-datasets","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Swahili : News Classification Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nSwahili is spoken by 100-150 million people across East Africa. In Tanzania, it is one of two national languages (the other is English) and it is the official language of instruction in all schools. News in Swahili is an important part of the media sphere in Tanzania.\\nNews contributes to education, technology, and the economic growth of a country, and news in local languages plays an important‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/community-datasets/swahili_news."},
	{"name":"swedish_medical_ner","keyword":"monolingual","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/community-datasets/swedish_medical_ner","creator_name":"Community Datasets","creator_url":"https://huggingface.co/community-datasets","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for swedish_medical_ner\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nSwedMedNER is Named Entity Recognition dataset on medical text in Swedish. It consists three subsets which are in turn derived from three different sources respectively: the Swedish Wikipedia (a.k.a. wiki), L√§kartidningen (a.k.a. lt), and 1177 V√•rdguiden (a.k.a. 1177). While the Swedish Wikipedia and L√§kartidningen subsets in total contains over 790000 sequences with 60 characters each, the 1177 V√•rdguiden‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/community-datasets/swedish_medical_ner."},
	{"name":"turk","keyword":"monolingual","license":"GNU General Public License v3.0","license_url":"https://choosealicense.com/licenses/gpl-3.0/","language":"en","dataset_url":"https://huggingface.co/datasets/community-datasets/turk","creator_name":"Community Datasets","creator_url":"https://huggingface.co/community-datasets","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for TURK\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nTURK is a multi-reference dataset for the evaluation of sentence simplification in English. The dataset consists of 2,359 sentences from the Parallel Wikipedia Simplification (PWKP) corpus. Each sentence is associated with 8 crowdsourced simplifications that focus on only lexical paraphrasing (no sentence splitting or deletion).\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSupported Tasks and Leaderboards\\n\\t\\n\\nNo Leaderboard for the task.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/community-datasets/turk."},
	{"name":"tweet_qa","keyword":"monolingual","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ucsbnlp/tweet_qa","creator_name":"UC Santa Barbara NLP Group","creator_url":"https://huggingface.co/ucsbnlp","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for TweetQA\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nWith social media becoming increasingly popular on which lots of news and real-time events are reported, developing automated question answering systems is critical to the effectiveness of many applications that rely on real-time knowledge. While previous question answering (QA) datasets have concentrated on formal text like news and Wikipedia, the first large-scale dataset for QA over social media data is presented. To‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ucsbnlp/tweet_qa."},
	{"name":"fanpage","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ARTeLab/fanpage","creator_name":"Applied Recognition Technology Laboratory","creator_url":"https://huggingface.co/ARTeLab","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for fanpage\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nFanpage dataset, containing news articles taken from Fanpage.\\nThere are two features:\\n\\nsource: Input news article.\\ntarget: Summary of the article.\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSupported Tasks and Leaderboards\\n\\t\\n\\n\\nabstractive-summarization, summarization\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages\\n\\t\\n\\nThe text in the dataset is in Italian\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLicensing Information\\n\\t\\n\\n Fanpage text summarization dataset by Nicola Landro, Ignazio Gallo, Riccardo La Grassa‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ARTeLab/fanpage."},
	{"name":"ilpost","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ARTeLab/ilpost","creator_name":"Applied Recognition Technology Laboratory","creator_url":"https://huggingface.co/ARTeLab","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for ilpost\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nIlPost dataset, containing news articles taken from IlPost.\\nThere are two features:\\n\\nsource: Input news article.\\ntarget: Summary of the article.\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSupported Tasks and Leaderboards\\n\\t\\n\\n\\nabstractive-summarization, summarization\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages\\n\\t\\n\\nThe text in the dataset is in Italian\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLicensing Information\\n\\t\\n\\n IlPost text summarization dataset by Nicola Landro, Ignazio Gallo, Riccardo La Grassa‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ARTeLab/ilpost."},
	{"name":"BAAD16","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Aisha/BAAD16","creator_name":"Aisha Khatun","creator_url":"https://huggingface.co/Aisha","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDescription\\n\\t\\n\\nBAAD16 is an Authorship Attribution dataset for Bengali Literature. It was collected and analyzed by the authors of this paper. It was created by scraping text from an online Bangla e-library using custom web crawler and contains literary works of various famous Bangla writers. It contains novels, stories, series, and other works of 16 authors. Each sample document is created with 750 words. The dataset is imbalanced and resembles real-world scenarios more closely‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Aisha/BAAD16."},
	{"name":"BAAD6","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Aisha/BAAD6","creator_name":"Aisha Khatun","creator_url":"https://huggingface.co/Aisha","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDescription\\n\\t\\n\\nBAAD6 is an Authorship Attribution dataset for Bengali Literature. It was collected and analyzed by Hemayet et al [1]. The data was obtained from different online posts and blogs. This dataset is balanced among the 6 Authors with 350 sample texts per author. This is a relatively small dataset but is noisy given the sources it was collected from and its cleaning procedure. Nonetheless, it may help evaluate authorship attribution systems as it resembles texts often‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Aisha/BAAD6."},
	{"name":"fungi_diagnostic_chars_comparison_japanese","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Atsushi/fungi_diagnostic_chars_comparison_japanese","creator_name":"Atsushi Nakajima","creator_url":"https://huggingface.co/Atsushi","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tfungi_diagnostic_chars_comparison_japaneseÂ§ßËèåËº™„ÄåË≠òÂà•ÂΩ¢Ë≥™„Åæ„Å®„ÇÅ„Äç„Éá„Éº„Çø„Çª„ÉÉ„ÉàÊúÄÁµÇÊõ¥Êñ∞Êó• / Last updated: 2024/9/28ÔºàR3-12108„Åæ„Åß / up to R3-12108Ôºâ\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages\\n\\t\\n\\nJapanese  \\nThis dataset is available in Japanese only.  \\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tÊ¶ÇË¶Å / Overview\\n\\t\\n\\nAtsushi NakajimaÔºà‰∏≠Â≥∂Ê∑≥ÂøóÔºâ„ÅåÂÄã‰∫∫„ÅßÈÅãÂñ∂„Åó„Å¶„ÅÑ„ÇãWeb„Çµ„Ç§„ÉàÂ§ßËèåËº™„Åß„ÅØ„ÄÅÊï∞ÂçÉ‰ª∂‰ª•‰∏ä„ÅÆËèåÈ°ûÂàÜÈ°ûÂ≠¶Ë´ñÊñá„Çí„ÄåË´ñÊñá3Ë°å„Åæ„Å®„ÇÅ„Äç„Å®„ÅÑ„ÅÜÂΩ¢„ÅßË¶ÅÁ¥Ñ„Åä„Çà„Å≥Á¥¢Âºï‰ªò„ÅëÔºà„Ç§„É≥„Éá„Ç≠„Ç∑„É≥„Ç∞Ôºâ„Åó„ÅüÊÉÖÂ†±„ÇíÊèê‰æõ„Åó„Å¶„ÅÑ„Åæ„Åô„ÄÇ„Åù„ÅÆ‰∏ÄÁí∞„Å®„Åó„Å¶„ÄÅ„ÅÇ„ÇãËèå„Å®Âà•„ÅÆËèå„ÅÆ„ÄåÂÖ±ÈÄö„Åô„Çã„Äç„ÅÇ„Çã„ÅÑ„ÅØ„ÄåÁï∞„Å™„Çã„ÄçË≠òÂà•ÂΩ¢Ë≥™ (diagnostic characters) „Å´Èñ¢„Åô„ÇãË®òËø∞„Çí‰∫∫Êâã„ÅßÊäΩÂá∫„Åó„Å¶„ÅÑ„Åæ„Åô„ÄÇ\\nDaikinrin, a website personally operated by Atsushi Nakajima‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Atsushi/fungi_diagnostic_chars_comparison_japanese."},
	{"name":"fungi_indexed_mycological_papers_japanese","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Atsushi/fungi_indexed_mycological_papers_japanese","creator_name":"Atsushi Nakajima","creator_url":"https://huggingface.co/Atsushi","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tfungi_indexed_mycological_papers_japanese\\nÂ§ßËèåËº™„ÄåË´ñÊñá3Ë°å„Åæ„Å®„ÇÅ„Äç„Éá„Éº„Çø„Çª„ÉÉ„ÉàÊúÄÁµÇÊõ¥Êñ∞Êó•Ôºö2024/9/28ÔºàR3-12108„Åæ„ÅßÔºâ  \\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages\\n\\t\\n\\nJapanese  \\nThis dataset is available in Japanese only.  \\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tÊ¶ÇË¶Å / Overview\\n\\t\\n\\nÂ§ßËèåËº™„ÅØ„ÄÅAtsushi NakajimaÔºà‰∏≠Â≥∂Ê∑≥ÂøóÔºâ„ÅåÂÄã‰∫∫„ÅßÈÅãÂñ∂„Åó„Å¶„ÅÑ„ÇãWeb„Çµ„Ç§„Éà„Åß„Åô„ÄÇ„Åì„Åì„Åß„ÅØ„ÄÅÊï∞ÂçÉ‰ª∂‰ª•‰∏ä„ÅÆËèåÈ°ûÂàÜÈ°ûÂ≠¶Ë´ñÊñá„Çí„ÄåË´ñÊñá3Ë°å„Åæ„Å®„ÇÅ„Äç„Å®„ÅÑ„ÅÜÂΩ¢„ÅßË¶ÅÁ¥Ñ„Åä„Çà„Å≥Á¥¢Âºï‰ªò„ÅëÔºà„Ç§„É≥„Éá„Ç≠„Ç∑„É≥„Ç∞Ôºâ„Åó„ÅüÊÉÖÂ†±„ÇíÊèê‰æõ„Åó„Å¶„ÅÑ„Åæ„Åô„ÄÇ\\nDaikinrin is a website personally operated by Atsushi Nakajima. It provides summaries and indexing information for thousands of mycological taxonomy papers in the form of‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Atsushi/fungi_indexed_mycological_papers_japanese."},
	{"name":"parla_text_corpus","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Baybars/parla_text_corpus","creator_name":"Baybars K√ºlebi","creator_url":"https://huggingface.co/Baybars","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tParlaTextCorpus\\n\\t\\n\\nSpoken text corpus for Catalan. Derived and cleaned from three sources. OpenSubtitles, Tv3Parla and Festcat.\\n"},
	{"name":"angry-tweets","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/DDSC/angry-tweets","creator_name":"Dansk Data Science Community","creator_url":"https://huggingface.co/DDSC","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for AngryTweets\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThis dataset consists of anonymised Danish Twitter data that has been annotated for sentiment analysis through crowd-sourcing. All credits go to the authors of the following paper, who created the dataset: \\nPauli, Amalie Brogaard, et al. \\\"DaNLP: An open-source toolkit for Danish Natural Language Processing.\\\" Proceedings of the 23rd Nordic Conference on Computational Linguistics (NoDaLiDa). 2021\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSupported‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/DDSC/angry-tweets."},
	{"name":"europarl","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/DDSC/europarl","creator_name":"Dansk Data Science Community","creator_url":"https://huggingface.co/DDSC","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for DKHate\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThis dataset consists of Danish data from the European Parliament that has been annotated for sentiment analysis by the Alexandra Institute - all credits go to them.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSupported Tasks and Leaderboards\\n\\t\\n\\nThis dataset is suitable for sentiment analysis.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages\\n\\t\\n\\nThis dataset is in Danish.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Structure\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Instances\\n\\t\\n\\nEvery entry in the dataset has a document and an‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/DDSC/europarl."},
	{"name":"lcc","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/DDSC/lcc","creator_name":"Dansk Data Science Community","creator_url":"https://huggingface.co/DDSC","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for LCC\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThis dataset consists of Danish data from the Leipzig Collection that has been annotated for sentiment analysis by Finn √Örup Nielsen.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSupported Tasks and Leaderboards\\n\\t\\n\\nThis dataset is suitable for sentiment analysis.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages\\n\\t\\n\\nThis dataset is in Danish.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Structure\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Instances\\n\\t\\n\\nEvery entry in the dataset has a document and an associated label.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/DDSC/lcc."},
	{"name":"reddit-da","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/DDSC/reddit-da","creator_name":"Dansk Data Science Community","creator_url":"https://huggingface.co/DDSC","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for SQuAD-da\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThis dataset consists of 1,908,887 Danish posts from Reddit. These are from this Reddit dump and have been filtered using this script, which uses FastText to detect the Danish posts. \\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSupported Tasks and Leaderboards\\n\\t\\n\\nThis dataset is suitable for language modelling.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages\\n\\t\\n\\nThis dataset is in Danish.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Structure\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Instances\\n\\t\\n\\nEvery entry in the dataset‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/DDSC/reddit-da."},
	{"name":"wiki-entity-similarity","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Exr0n/wiki-entity-similarity","creator_name":"exr0n","creator_url":"https://huggingface.co/Exr0n","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tWiki Entity Similarity\\n\\t\\n\\nUsage:\\nfrom datasets import load_dataset\\n\\ncorpus = load_dataset('Exr0n/wiki-entity-similarity', '2018thresh20corpus', split='train')\\nassert corpus[0] == {'article': 'A1000 road', 'link_text': 'A1000', 'is_same': 1}\\n\\npairs = load_dataset('Exr0n/wiki-entity-similarity', '2018thresh20pairs', split='train')\\nassert corpus[0] == {'article': 'Rhinobatos', 'link_text': 'Ehinobatos beurleni', 'is_same': 1}\\nassert len(corpus) == 4_793_180\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tCorpus‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Exr0n/wiki-entity-similarity."},
	{"name":"DebateSum","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Hellisotherpeople/DebateSum","creator_name":"Allen Roush","creator_url":"https://huggingface.co/Hellisotherpeople","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDebateSum\\n\\t\\n\\nCorresponding code repo for the upcoming paper at ARGMIN 2020: \\\"DebateSum: A large-scale argument mining and summarization dataset\\\"\\nArxiv pre-print available here: https://arxiv.org/abs/2011.07251\\nCheck out the presentation date and time here: https://argmining2020.i3s.unice.fr/node/9\\nFull paper as presented by the ACL is here: https://www.aclweb.org/anthology/2020.argmining-1.1/\\nVideo of presentation at COLING 2020:‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Hellisotherpeople/DebateSum."},
	{"name":"sucx3_ner","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/KBLab/sucx3_ner","creator_name":"National Library of Sweden / KBLab","creator_url":"https://huggingface.co/KBLab","description":"    The dataset is a conversion of the venerable SUC 3.0 dataset into the\\n    huggingface ecosystem. The original dataset does not contain an official\\n    train-dev-test split, which is introduced here; the tag distribution for the\\n    NER tags between the three splits is mostly the same.\\n    \\n    The dataset has three different types of tagsets: manually annotated POS,\\n    manually annotated NER, and automatically annotated NER. For the\\n    automatically annotated NER tags, only sentences were chosen, where the\\n    automatic and manual annotations would match (with their respective\\n    categories).\\n    \\n    Additionally we provide remixes of the same data with some or all sentences\\n    being lowercased."},
	{"name":"ILUR-news-text-classification-corpus","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Karavet/ILUR-news-text-classification-corpus","creator_name":"Karen Avetisyan","creator_url":"https://huggingface.co/Karavet","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tNews Texts Dataset\\n\\t\\n\\nWe release a dataset of over 12000 news articles from iLur.am, categorized into 7 classes: sport, politics, weather, economy, accidents, art, society. The articles are split into train (2242k tokens) and test sets (425k tokens).\\nFor more details, refer to the paper.\\n"},
	{"name":"starter","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Langame/starter","creator_name":"Langa","creator_url":"https://huggingface.co/Langame","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for [Dataset Name]\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\n[More Information Needed]\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSupported Tasks and Leaderboards\\n\\t\\n\\n[More Information Needed]\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages\\n\\t\\n\\n[More Information Needed]\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Structure\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Instances\\n\\t\\n\\n[More Information Needed]\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Fields\\n\\t\\n\\n[More Information Needed]\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Splits\\n\\t\\n\\n[More Information Needed]\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Creation\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tCuration Rationale\\n\\t\\n\\n[More‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Langame/starter."},
	{"name":"CC-NEWS-ES-titles","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/LeoCordoba/CC-NEWS-ES-titles","creator_name":"Leonardo Ignacio C√≥rdoba","creator_url":"https://huggingface.co/LeoCordoba","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for CC-NEWS-ES-titles\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nCC-NEWS-ES-titles is a Spanish-language dataset for news titles generation. The text and titles comes from 2019 and 2020 CC-NEWS data (which is part of Common Crawl).\\nIt contains 402.310 pairs of news title and body, splitted in :\\n\\nTrain: 370.125\\n\\nEval: 16.092\\n\\nTest: 16.092\\n\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSupported Tasks and Leaderboards\\n\\t\\n\\n\\ntext-classification, sentiment-classification: The dataset can be used to train a model for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/LeoCordoba/CC-NEWS-ES-titles."},
	{"name":"monolingual-quechua-iic","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Llamacha/monolingual-quechua-iic","creator_name":"Llamacha","creator_url":"https://huggingface.co/Llamacha","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Monolingual-Quechua-IIC\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\n We present Monolingual-Quechua-IIC, a monolingual corpus of Southern Quechua, which can be used to build language models using Transformers models. This corpus also includes the Wiki and OSCAR corpora. We used this corpus to build Llama-RoBERTa-Quechua, the first language model for Southern Quechua using Transformers.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSupported Tasks and Leaderboards\\n\\t\\n\\nMore Information Needed‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Llamacha/monolingual-quechua-iic."},
	{"name":"HuCOLA","keyword":"monolingual","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/NYTK/HuCOLA","creator_name":"Hungarian Research Centre for Linguistics","creator_url":"https://huggingface.co/NYTK","description":"\\n\\t\\n\\t\\t\\n\\t\\tDataset Card for HuCOLA\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThis is the dataset card for the Hungarian Corpus of Linguistic Acceptability (HuCOLA), which is also part of the Hungarian Language Understanding Evaluation Benchmark Kit HuLU.\\n\\n\\t\\n\\t\\t\\n\\t\\tSupported Tasks and Leaderboards\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tLanguages\\n\\t\\n\\nThe BCP-47 code for Hungarian, the only represented language in this dataset, is hu-HU. \\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Structure\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tData Instances\\n\\t\\n\\nFor each instance, there is aN id, a sentence and‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/NYTK/HuCOLA."},
	{"name":"HuCoPA","keyword":"monolingual","license":"BSD 2-Clause \"Simplified\" License","license_url":"https://choosealicense.com/licenses/bsd-2-clause/","language":"en","dataset_url":"https://huggingface.co/datasets/NYTK/HuCoPA","creator_name":"Hungarian Research Centre for Linguistics","creator_url":"https://huggingface.co/NYTK","description":"\\n\\t\\n\\t\\t\\n\\t\\tDataset Card for HuCoPA\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThis is the dataset card for the Hungarian Choice of Plausible Alternatives Corpus (HuCoPA), which is also part of the Hungarian Language Understanding Evaluation Benchmark Kit HuLU. The corpus was created by translating and re-annotating the original English CoPA corpus (Roemmele et al., 2011).\\n\\n\\t\\n\\t\\t\\n\\t\\tSupported Tasks and Leaderboards\\n\\t\\n\\n'commonsense reasoning'\\n'question answering'\\n\\n\\t\\n\\t\\t\\n\\t\\tLanguages\\n\\t\\n\\nThe BCP-47 code for Hungarian‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/NYTK/HuCoPA."},
	{"name":"HuRC","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/NYTK/HuRC","creator_name":"Hungarian Research Centre for Linguistics","creator_url":"https://huggingface.co/NYTK","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for HuRC\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThis is the dataset card for the Hungarian Corpus for Reading Comprehension with Commonsense Reasoning (HuRC), which is also part of the Hungarian Language Understanding Evaluation Benchmark Kit HuLU.\\nThe dataset contains 80 614 instances. Each instance is composed of a lead, a passage and a cloze-style query with a masked entity. The task is to select the named entity that is being masked in the query.\\nThe data was‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/NYTK/HuRC."},
	{"name":"HuSST","keyword":"monolingual","license":"BSD 2-Clause \"Simplified\" License","license_url":"https://choosealicense.com/licenses/bsd-2-clause/","language":"en","dataset_url":"https://huggingface.co/datasets/NYTK/HuSST","creator_name":"Hungarian Research Centre for Linguistics","creator_url":"https://huggingface.co/NYTK","description":"\\n\\t\\n\\t\\t\\n\\t\\tDataset Card for HuSST\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThis is the dataset card for the Hungarian version of the Stanford Sentiment Treebank. This dataset which is also part of the Hungarian Language Understanding Evaluation Benchmark Kit HuLU. The corpus was created by translating and re-annotating the original SST (Roemmele et al., 2011).\\n\\n\\t\\n\\t\\t\\n\\t\\tSupported Tasks and Leaderboards\\n\\t\\n\\n'sentiment classification'\\n'sentiment scoring'\\n\\n\\t\\n\\t\\t\\n\\t\\tLanguage\\n\\t\\n\\nThe BCP-47 code for Hungarian, the‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/NYTK/HuSST."},
	{"name":"HuWNLI","keyword":"monolingual","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/NYTK/HuWNLI","creator_name":"Hungarian Research Centre for Linguistics","creator_url":"https://huggingface.co/NYTK","description":"\\n\\t\\n\\t\\t\\n\\t\\tDataset Card for HuWNLI\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThis is the dataset card for the Hungarian translation of the Winograd schemata formatted as an inference task. A Winograd schema is a pair of sentences that differ in only one or two words and that contain an ambiguity that is resolved in opposite ways in the two sentences and requires the use of world knowledge and reasoning for its resolution (Levesque et al. 2012). This dataset is also part of the Hungarian Language‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/NYTK/HuWNLI."},
	{"name":"NPSC_test","keyword":"monolingual","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/NbAiLab/NPSC_test","creator_name":"Nasjonalbiblioteket AI Lab","creator_url":"https://huggingface.co/NbAiLab","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for NBAiLab/NPSC\\n\\t\\n\\nThe Norwegian Parliament Speech Corpus (NPSC) is a corpus for training a Norwegian ASR (Automatic Speech Recognition) models. The corpus is created by Spr√•kbanken at the National Library in Norway. \\nNPSC is based on sound recording from meeting in the Norwegian Parliament. These talks are orthographically transcribed to either Norwegian Bokm√•l or Norwegian Nynorsk. In addition to the data actually included in this dataset, there is a significant‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/NbAiLab/NPSC_test."},
	{"name":"hatecheck","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Paul/hatecheck","creator_name":"Paul R√∂ttger","creator_url":"https://huggingface.co/Paul","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for HateCheck\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nHateCheck is a suite of functional test for hate speech detection models. \\nThe dataset contains 3,728 validated test cases in 29 functional tests.\\n19 functional tests correspond to distinct types of hate. The other 11 functional tests cover challenging types of non-hate.\\nThis allows for targeted diagnostic insights into model performance.\\nIn our ACL paper, we found critical weaknesses in all commercial and academic‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Paul/hatecheck."},
	{"name":"pharmaconer","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/PlanTL-GOB-ES/pharmaconer","creator_name":"Plan de Tecnolog√≠as del Lenguaje - Gobierno de Espa√±a","creator_url":"https://huggingface.co/PlanTL-GOB-ES","description":"PharmaCoNER: Pharmacological Substances, Compounds and Proteins Named Entity Recognition track\\n\\nThis dataset is designed for the PharmaCoNER task, sponsored by Plan de Impulso de las Tecnolog√≠as del Lenguaje (Plan TL).\\n\\nIt is a manually classified collection of clinical case studies derived from the Spanish Clinical Case Corpus (SPACCC), an\\nopen access electronic library that gathers Spanish medical publications from SciELO (Scientific Electronic Library Online).\\n\\nThe annotation of the entire set of entity mentions was carried out by medicinal chemistry experts\\nand it includes the following 4 entity types: NORMALIZABLES, NO_NORMALIZABLES, PROTEINAS and UNCLEAR.\\n\\nThe PharmaCoNER corpus contains a total of 396,988 words and 1,000 clinical cases that have been randomly sampled into 3 subsets.\\nThe training set contains 500 clinical cases, while the development and test sets contain 250 clinical cases each.\\nIn terms of training examples, this translates to a total of 8074, 3764 and 3931 annotated sentences in each set.\\nThe original dataset was distributed in Brat format (https://brat.nlplab.org/standoff.html).\\n\\nFor further information, please visit https://temu.bsc.es/pharmaconer/ or send an email to encargo-pln-life@bsc.es"},
	{"name":"nepalitext-language-model-dataset","keyword":"monolingual","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Sakonii/nepalitext-language-model-dataset","creator_name":"Utsav Maskey","creator_url":"https://huggingface.co/Sakonii","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for \\\"nepalitext-language-model-dataset\\\"\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\n\\\"NepaliText\\\" language modeling dataset is a collection of over 13 million Nepali text sequences (phrases/sentences/paragraphs) extracted by combining the datasets: OSCAR , cc100 and a set of scraped Nepali articles on Wikipedia. \\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSupported Tasks and Leaderboards\\n\\t\\n\\nThis dataset is intended to pre-train language models and word representations on Nepali Language.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Sakonii/nepalitext-language-model-dataset."},
	{"name":"one-year-of-r-india","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/SocialGrep/one-year-of-r-india","creator_name":"SocialGrep","creator_url":"https://huggingface.co/SocialGrep","description":"This corpus contains the complete data for the activity of the subreddit /r/India from Sep 30, 2020 to Sep 30, 2021."},
	{"name":"reddit-crypto-aug-2021","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/SocialGrep/reddit-crypto-aug-2021","creator_name":"SocialGrep","creator_url":"https://huggingface.co/SocialGrep","description":"This corpus contains the complete data for the activity on seven major cryptocurrency subreddits for the entire month of August 2021."},
	{"name":"the-2022-trucker-strike-on-reddit","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/SocialGrep/the-2022-trucker-strike-on-reddit","creator_name":"SocialGrep","creator_url":"https://huggingface.co/SocialGrep","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for the-2022-trucker-strike-on-reddit\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThis corpus contains all the comments under the /r/Ottawa convoy megathreads.\\nComments are annotated with their score.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages\\n\\t\\n\\nMainly English.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Structure\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Instances\\n\\t\\n\\nA data point is a Reddit comment.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Fields\\n\\t\\n\\n\\n'type': the type of the data point. Can be 'post' or 'comment'.\\n'id': the base-36 Reddit ID of the data point.‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/SocialGrep/the-2022-trucker-strike-on-reddit."},
	{"name":"the-reddit-covid-dataset","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/SocialGrep/the-reddit-covid-dataset","creator_name":"SocialGrep","creator_url":"https://huggingface.co/SocialGrep","description":"This dataset attempts to capture the full extent of COVID-19 discussion across the entire site of Reddit. All posts and comments found to mention the term 'COVID' as of 2021-10-25 have been gathered from the site."},
	{"name":"top-american-universities-on-reddit","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/SocialGrep/top-american-universities-on-reddit","creator_name":"SocialGrep","creator_url":"https://huggingface.co/SocialGrep","description":"This NLP dataset contains all the posts and comments in the subreddits of top 10 universities in the United States, chosen according to the 2019 Forbes ranking."},
	{"name":"klej-polemo2-in","keyword":"monolingual","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/allegro/klej-polemo2-in","creator_name":"Allegro ML Research","creator_url":"https://huggingface.co/allegro","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tklej-polemo2-in\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDescription\\n\\t\\n\\nThe PolEmo2.0 is a dataset of online consumer reviews from four domains: medicine, hotels, products, and university. It is human-annotated on a level of full reviews and individual sentences. It comprises over 8000 reviews, about 85% from the medicine and hotel domains.\\nWe use the PolEmo2.0 dataset to form two tasks. Both use the same training dataset, i.e., reviews from medicine and hotel domains, but are evaluated on a different test‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/allegro/klej-polemo2-in."},
	{"name":"klej-polemo2-out","keyword":"monolingual","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/allegro/klej-polemo2-out","creator_name":"Allegro ML Research","creator_url":"https://huggingface.co/allegro","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tklej-polemo2-out\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDescription\\n\\t\\n\\nThe PolEmo2.0 is a dataset of online consumer reviews from four domains: medicine, hotels, products, and university. It is human-annotated on a level of full reviews and individual sentences. It comprises over 8000 reviews, about 85% from the medicine and hotel domains.\\nWe use the PolEmo2.0 dataset to form two tasks. Both use the same training dataset, i.e., reviews from medicine and hotel domains, but are evaluated on a different test‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/allegro/klej-polemo2-out."},
	{"name":"scico","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/allenai/scico","creator_name":"Ai2","creator_url":"https://huggingface.co/allenai","description":"        SciCo is a dataset for hierarchical cross-document coreference resolution\\n        over scientific papers in the CS domain."},
	{"name":"qg_squad","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/lmqg/qg_squad","creator_name":"LMQG","creator_url":"https://huggingface.co/lmqg","description":"[SQuAD](https://rajpurkar.github.io/SQuAD-explorer/) evaluation set for the question generation (QG) models. The split \\nof test and development set follows the [\\\"Neural Question Generation\\\"](https://arxiv.org/abs/1705.00106) work and is \\ncompatible with the [leader board](https://paperswithcode.com/sota/question-generation-on-squad11)."},
	{"name":"sentihood","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/bhavnicksm/sentihood","creator_name":"Bhavnick Minhas","creator_url":"https://huggingface.co/bhavnicksm","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for [SentiHood]\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nCreated as a part of the paper \\\"SentiHood: Targeted Aspect Based Sentiment Analysis Dataset for Urban Neighbourhoods\\\" by Saeidi et al. \\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tAbstract\\n\\t\\n\\nIn this paper, we introduce the task of targeted aspect-based sentiment analysis. The goal is to extract fine-grained information with respect to entities mentioned in user comments. This work extends both aspect-based sentiment analysis that assumes a single‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/bhavnicksm/sentihood."},
	{"name":"aspectemo","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/clarin-pl/aspectemo","creator_name":"CLARIN-PL","creator_url":"https://huggingface.co/clarin-pl","description":"AspectEmo dataset: Multi-Domain Corpus of Consumer Reviews for Aspect-Based \\n                Sentiment Analysis"},
	{"name":"nkjp-pos","keyword":"monolingual","license":"GNU General Public License v3.0","license_url":"https://choosealicense.com/licenses/gpl-3.0/","language":"en","dataset_url":"https://huggingface.co/datasets/clarin-pl/nkjp-pos","creator_name":"CLARIN-PL","creator_url":"https://huggingface.co/clarin-pl","description":"NKJP-POS tagging dataset."},
	{"name":"polemo2-official","keyword":"monolingual","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/clarin-pl/polemo2-official","creator_name":"CLARIN-PL","creator_url":"https://huggingface.co/clarin-pl","description":"PolEmo 2.0:  Corpus of Multi-Domain Consumer Reviews, evaluation data for article presented at CoNLL."},
	{"name":"prost","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/corypaik/prost","creator_name":"Cory Paik","creator_url":"https://huggingface.co/corypaik","description":"*Physical Reasoning about Objects Through Space and Time* (PROST) is a probing dataset to evaluate the ability of pretrained LMs to understand and reason about the physical world. PROST consists of 18,736 cloze-style multiple choice questions from 14 manually curated templates, covering 10 physical reasoning concepts:  direction, mass, height, circumference, stackable, rollable, graspable, breakable, slideable, and bounceable."},
	{"name":"few-nerd","keyword":"monolingual","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/DFKI-SLT/few-nerd","creator_name":"Speech and Language Technology, DFKI","creator_url":"https://huggingface.co/DFKI-SLT","description":"Few-NERD is a large-scale, fine-grained manually annotated named entity recognition dataset, \\nwhich contains 8 coarse-grained types, 66 fine-grained types, 188,200 sentences, 491,711 entities \\nand 4,601,223 tokens. Three benchmark tasks are built, one is supervised: Few-NERD (SUP) and the \\nother two are few-shot: Few-NERD (INTRA) and Few-NERD (INTER)."},
	{"name":"mobie","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/DFKI-SLT/mobie","creator_name":"Speech and Language Technology, DFKI","creator_url":"https://huggingface.co/DFKI-SLT","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for \\\"MobIE\\\"\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThis script is for loading the MobIE dataset from https://github.com/dfki-nlp/mobie. \\nMobIE is a German-language dataset which is human-annotated with 20 coarse- and fine-grained entity types and entity linking information for geographically linkable entities. The dataset consists of 3,232 social media texts and traffic reports with 91K tokens, and contains 20.5K annotated entities, 13.1K of which are linked to a knowledge‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/DFKI-SLT/mobie."},
	{"name":"RoITD","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/dragosnicolae555/RoITD","creator_name":"Constantin Nicolae","creator_url":"https://huggingface.co/dragosnicolae555","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\n We introduce a  Romanian IT Dataset (RoITD) resembling SQuAD 1.1.  RoITD consists of 9575 Romanian  QA pairs formulated by crowd workers. QA pairs are based on 5043 articles from Romanian Wikipedia articles describing IT and household products.  Of the total number of questions, 5103 are possible (i.e. the correct answer can be found within the paragraph) and 4472 are not possible (i.e. the given answer is a \\\"plausible answer\\\" and not correct)‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/dragosnicolae555/RoITD."},
	{"name":"Urban100","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/eugenesiow/Urban100","creator_name":"Eugene Siow","creator_url":"https://huggingface.co/eugenesiow","description":"The Urban100 dataset contains 100 images of urban scenes. \\nIt commonly used as a test set to evaluate the performance of super-resolution models."},
	{"name":"arxiv-abstracts-2021","keyword":"monolingual","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/gfissore/arxiv-abstracts-2021","creator_name":"Giancarlo","creator_url":"https://huggingface.co/gfissore","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for arxiv-abstracts-2021\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nA dataset of metadata including title and abstract for all arXiv articles up to the end of 2021 (~2 million papers).\\nPossible applications include trend analysis, paper recommender engines, category prediction,  knowledge graph construction and semantic search interfaces.\\nIn contrast to arxiv_dataset, this dataset doesn't include papers submitted to arXiv after 2021 and it doesn't require any external download.‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/gfissore/arxiv-abstracts-2021."},
	{"name":"java-cmpx-v1","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/giganticode/java-cmpx-v1","creator_name":"Giganticode","creator_url":"https://huggingface.co/giganticode","description":"giganticode/java-cmpx-v1 dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"java-cmpx","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/giganticode/java-cmpx","creator_name":"Giganticode","creator_url":"https://huggingface.co/giganticode","description":"giganticode/java-cmpx dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"ICC","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/jonfd/ICC","creator_name":"J√≥n Fri√∞rik Da√∞ason","creator_url":"https://huggingface.co/jonfd","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for ICC\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThe Icelandic Crawled Corpus (ICC) contains approximately 930M tokens which have been scraped from a selection of Icelandic websites, including news sites, government websites and forums. The scraped text is presented in its original form, unannotated, untokenized and without deduplication.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSupported Tasks and Leaderboards\\n\\t\\n\\nThe ICC is primarily intended for use in training language models. It can be combined with‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/jonfd/ICC."},
	{"name":"ManyTypes4TypeScript","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/kevinjesse/ManyTypes4TypeScript","creator_name":"Kevin Jesse","creator_url":"https://huggingface.co/kevinjesse","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tModels Trained On ManyTypes4TypeScript\\n\\t\\n\\n\\n[CodeBERT](https://huggingface.co/kevinjesse/codebert-MT4TS)\\n[GraphCodeBERT](https://huggingface.co/kevinjesse/graphcodebert-MT4TS)\\n[CodeBERTa](https://huggingface.co/kevinjesse/codeberta-MT4TS)\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nManyTypes4TypeScript type inference dataset, available at the DOI link below. \\nGiven a line of source code, the task is to identify types that correspond with the tokens of code. We treat this as a tagging task‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/kevinjesse/ManyTypes4TypeScript."},
	{"name":"my-awesome-dataset","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/lewtun/my-awesome-dataset","creator_name":"Lewis Tunstall","creator_url":"https://huggingface.co/lewtun","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Demo\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThis is a demo dataset with two files train.csv and test.csv.\\nLoad it by:\\nfrom datasets import load_dataset \\ndata_files = {\\\"train\\\": \\\"train.csv\\\", \\\"test\\\": \\\"test.csv\\\"} \\ndemo = load_dataset(\\\"stevhliu/demo\\\", data_files=data_files)  \\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSupported Tasks and Leaderboards\\n\\t\\n\\n[More Information Needed]\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages\\n\\t\\n\\n[More Information Needed]\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Structure\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Instances\\n\\t\\n\\n[More‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/lewtun/my-awesome-dataset."},
	{"name":"long-covid-classification-data","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/llangnickel/long-covid-classification-data","creator_name":"Lisa Langnickel","creator_url":"https://huggingface.co/llangnickel","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Description\\n\\t\\n\\nLong-COVID related articles have been manually collected by information specialists.Please find further information here. \\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSize\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\nTraining\\nDevelopment\\nTest\\nTotal\\n\\n\\n\\t\\t\\nPositive Examples\\n215\\n76\\n70\\n345\\n\\n\\nNegative Examples\\n199\\n62\\n68\\n345\\n\\n\\nTotal\\n414\\n238\\n138\\n690\\n\\n\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tCitation\\n\\t\\n\\n@article{10.1093/database/baac048,author = {Langnickel, Lisa and Darms, Johannes and Heldt, Katharina and Ducks, Denise and Fluck, Juliane},title = \\\"{Continuous‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/llangnickel/long-covid-classification-data."},
	{"name":"icelandic-error-corpus-IceEC","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mideind/icelandic-error-corpus-IceEC","creator_name":"Mi√∞eind ehf.","creator_url":"https://huggingface.co/mideind","description":"The Icelandic Error Corpus (IceEC) is a collection of texts in modern Icelandic annotated for mistakes related to spelling, grammar, and other issues. The texts are organized by genre. The current version includes sentences from student essays, online news texts and Wikipedia articles.\\nSentences within texts in the student essays had to be shuffled due to the license which they were originally published under, but neither the online news texts nor the Wikipedia articles needed to be shuffled."},
	{"name":"medwiki","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mvarma/medwiki","creator_name":"Maya Varma","creator_url":"https://huggingface.co/mvarma","description":"MedWiki is a large-scale sentence dataset collected from Wikipedia with medical entity (UMLS) annotations. This dataset is intended for pretraining."},
	{"name":"tr-qnli","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/nlpyeditepe/tr-qnli","creator_name":"Yeditepe NLP Lab","creator_url":"https://huggingface.co/nlpyeditepe","description":"nlpyeditepe/tr-qnli dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"tr_rte","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/nlpyeditepe/tr_rte","creator_name":"Yeditepe NLP Lab","creator_url":"https://huggingface.co/nlpyeditepe","description":"nlpyeditepe/tr_rte dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"sharif_emotional_speech_dataset","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/pariajm/sharif_emotional_speech_dataset","creator_name":"Paria Jamshid Lou","creator_url":"https://huggingface.co/pariajm","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSharif Emotional Speech Dataset (ShEMO)\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThe dataset includes 3000 semi-natural utterances, equivalent to 3 hours and 25 minutes of speech data extracted from online Persian radio plays. The ShEMO covers speech samples of 87 native-Persian speakers for five basic emotions including anger, fear, happiness, sadness and surprise, as well as neutral state. Twelve annotators label the underlying emotional state of utterances and majority voting is used‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/pariajm/sharif_emotional_speech_dataset."},
	{"name":"ancora-ca-ner","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/projecte-aina/ancora-ca-ner","creator_name":"Projecte Aina","creator_url":"https://huggingface.co/projecte-aina","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for AnCora-Ca-NER\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThis is a dataset for Named Entity Recognition (NER) in Catalan. It adapts AnCora corpus for Machine Learning and Language Model evaluation purposes.\\nThis dataset was developed by BSC TeMU as part of the Projecte AINA, to enrich the Catalan Language Understanding Benchmark (CLUB).\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSupported Tasks and Leaderboards\\n\\t\\n\\nNamed Entities Recognition, Language Model\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages\\n\\t\\n\\nThe dataset is in‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/projecte-aina/ancora-ca-ner."},
	{"name":"casum","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/projecte-aina/casum","creator_name":"Projecte Aina","creator_url":"https://huggingface.co/projecte-aina","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for CaSum\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nCaSum is a summarization dataset. It is extracted from a newswire corpus crawled from the Catalan News Agency (Ag√®ncia Catalana de Not√≠cies; ACN). The corpus consists of 217,735 instances that are composed by the headline and the body.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSupported Tasks and Leaderboards\\n\\t\\n\\nThe dataset can be used to train a model for abstractive summarization. Success on this task is typically measured by achieving a high Rouge‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/projecte-aina/casum."},
	{"name":"catalan_general_crawling","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/projecte-aina/catalan_general_crawling","creator_name":"Projecte Aina","creator_url":"https://huggingface.co/projecte-aina","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Catalan General Crawling\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThe Catalan General Crawling Corpus is a 435-million-token web corpus of Catalan built from the web. It has been obtained by crawling the 500 most popular .cat and .ad domains during July 2020. It consists of 434,817,705 tokens, 19,451,691 sentences and 1,016,114 documents. Documents are separated by single new lines. It is a subcorpus of the Catalan Textual Corpus.\\nThis work is licensed under a Creative‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/projecte-aina/catalan_general_crawling."},
	{"name":"catalan_government_crawling","keyword":"monolingual","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/projecte-aina/catalan_government_crawling","creator_name":"Projecte Aina","creator_url":"https://huggingface.co/projecte-aina","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Catalan Government Crawling\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThe Catalan Government Crawling Corpus is a 39-million-token web corpus of Catalan built from the web. It has been obtained by crawling the .gencat domain and subdomains, belonging to the Catalan Government during September and October 2020. It consists of 39,117,909 tokens, 1,565,433 sentences and 71,043 documents. Documents are separated by single new lines. It is a subcorpus of the Catalan Textual‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/projecte-aina/catalan_government_crawling."},
	{"name":"catalan_textual_corpus","keyword":"monolingual","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/projecte-aina/catalan_textual_corpus","creator_name":"Projecte Aina","creator_url":"https://huggingface.co/projecte-aina","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Catalan Textual Corpus\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThe Catalan Textual Corpus is a 1760-million-token web corpus of Catalan built from several sources.\\nIt consists of 1,758,388,896 tokens, 73,172,152 sentences, and 12,556,365 documents. Documents are separated by single new lines. These boundaries have been preserved as long as the license allowed it.\\nThis work is licensed under a Creative Commons Attribution Share Alike 4.0 International license.‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/projecte-aina/catalan_textual_corpus."},
	{"name":"vilaquad","keyword":"monolingual","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/projecte-aina/vilaquad","creator_name":"Projecte Aina","creator_url":"https://huggingface.co/projecte-aina","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for VilaQuAD\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nVilaQuAD, An extractive QA dataset for Catalan, from VilaWeb newswire text.\\nThis dataset contains 2095 of Catalan language news articles along with 1 to 5 questions referring to each fragment (or context).\\nVilaQuad articles are extracted from the daily VilaWeb and used under CC-BY-NC-SA-ND licence. \\nThis dataset can be used to build extractive-QA and Language Models.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSupported Tasks and Leaderboards‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/projecte-aina/vilaquad."},
	{"name":"viquiquad","keyword":"monolingual","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/projecte-aina/viquiquad","creator_name":"Projecte Aina","creator_url":"https://huggingface.co/projecte-aina","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tViquiQuAD, An extractive QA dataset for Catalan, from the Wikipedia\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nViquiQuAD, An extractive QA dataset for Catalan, from the Wikipedia.\\nThis dataset contains 3111 contexts extracted from a set of 597 high quality original (no translations) articles in the Catalan Wikipedia \\\"Viquip√®dia\\\", and 1 to 5 questions with their answer for each fragment.\\nViquipedia articles are used under CC-by-sa licence. \\nThis dataset can be used to fine-tune and evaluate‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/projecte-aina/viquiquad."},
	{"name":"wnli-ca","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/projecte-aina/wnli-ca","creator_name":"Projecte Aina","creator_url":"https://huggingface.co/projecte-aina","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tWNLI-ca\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\n\\\"A Winograd schema is a pair of sentences that differ in only one or two words and that contain an ambiguity that is resolved in opposite ways in the two sentences and requires the use of world knowledge and reasoning for its resolution. The schema takes its name from Terry Winograd.\\\" Source: The Winograd Schema Challenge.\\nThe Winograd NLI dataset presents 855 sentence pairs, in which the first sentence contains an ambiguity and the second‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/projecte-aina/wnli-ca."},
	{"name":"xquad-ca","keyword":"monolingual","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/projecte-aina/xquad-ca","creator_name":"Projecte Aina","creator_url":"https://huggingface.co/projecte-aina","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for XQuAD-Ca\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nProfessional translation into Catalan of XQuAD dataset.\\nXQuAD (Cross-lingual Question Answering Dataset) is a benchmark dataset for evaluating cross-lingual question answering performance. The dataset consists of a subset of 240 paragraphs and 1190 question-answer pairs from the development set of SQuAD v1.1 (Rajpurkar, Pranav et al., 2016) together with their professional translations into ten language: Spanish, German‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/projecte-aina/xquad-ca."},
	{"name":"quasar","keyword":"monolingual","license":"BSD 3-Clause \"New\" or \"Revised\" License","license_url":"https://choosealicense.com/licenses/bsd-3-clause/","language":"en","dataset_url":"https://huggingface.co/datasets/sagnikrayc/quasar","creator_name":"sagnik ray choudhury","creator_url":"https://huggingface.co/sagnikrayc","description":"We present two new large-scale datasets aimed at evaluating systems designed to comprehend a natural language query and extract its answer from a large corpus of text. The Quasar-S dataset consists of 37000 cloze-style (fill-in-the-gap) queries constructed from definitions of software entity tags on the popular website Stack Overflow. The posts and comments on the website serve as the background corpus for answering the cloze questions. The Quasar-T dataset consists of 43000 open-domain trivia questions and their answers obtained from various internet sources. ClueWeb09 serves as the background corpus for extracting these answers. We pose these datasets as a challenge for two related subtasks of factoid Question Answering: (1) searching for relevant pieces of text that include the correct answer to a query, and (2) reading the retrieved text to answer the query."},
	{"name":"tripclick-training","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/sebastian-hofstaetter/tripclick-training","creator_name":"Sebastian Hofst√§tter","creator_url":"https://huggingface.co/sebastian-hofstaetter","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tTripClick Baselines with Improved Training Data\\n\\t\\n\\nEstablishing Strong Baselines for TripClick Health Retrieval Sebastian Hofst√§tter, Sophia Althammer, Mete Sertkan and Allan Hanbury\\nhttps://arxiv.org/abs/2201.00365\\ntl;dr We create strong re-ranking and dense retrieval baselines (BERTCAT, BERTDOT, ColBERT, and TK) for TripClick (health ad-hoc retrieval). We improve the ‚Äì originally too noisy ‚Äì training data with a simple negative sampling policy. We achieve large gains over BM25 in‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/sebastian-hofstaetter/tripclick-training."},
	{"name":"source_code","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/shibing624/source_code","creator_name":"Ming Xu (ÂæêÊòé)","creator_url":"https://huggingface.co/shibing624","description":"Á∫ØÊñáÊú¨Êï∞ÊçÆÔºåÂÜÖÂÆπÔºöÈ´òË¥®ÈáèÁºñÁ®ãÊ∫ê‰ª£Á†ÅÔºåÂåÖÊã¨PythonÔºåJavaÔºåCPPÊ∫ê‰ª£Á†Å"},
	{"name":"Softcatala-Web-Texts-Dataset","keyword":"monolingual","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/softcatala/Softcatala-Web-Texts-Dataset","creator_name":"Softcatal√†","creator_url":"https://huggingface.co/softcatala","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Softcatala-Web-Texts-Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThis repository contains Sofcatal√† web site content (articles and programs descriptions).\\nDataset size:\\n\\narticles.json contains 623 articles with 373233 words.\\nprogrames.json contains 330 program descriptions with 49868 words.\\n\\nThe license of the data is Attribution-ShareAlike 4.0 International (CC BY-SA 4.0) or Universal Public Domain Dedication (CC0 1.0)\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSupported Tasks and Leaderboards‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/softcatala/Softcatala-Web-Texts-Dataset."},
	{"name":"ca_text_corpus","keyword":"monolingual","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/softcatala/ca_text_corpus","creator_name":"Softcatal√†","creator_url":"https://huggingface.co/softcatala","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for ca-text-corpus\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nPublic domain corpus of Catalan text.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSupported Tasks and Leaderboards\\n\\t\\n\\n[More Information Needed]\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages\\n\\t\\n\\nCatalan (ca).\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Structure\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Instances\\n\\t\\n\\n[More Information Needed]\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Fields\\n\\t\\n\\n[More Information Needed]\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Splits\\n\\t\\n\\n[More Information Needed]\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Creation\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tCuration Rationale\\n\\t\\n\\n[More‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/softcatala/ca_text_corpus."},
	{"name":"open-source-english-catalan-corpus","keyword":"monolingual","license":"GNU General Public License v3.0","license_url":"https://choosealicense.com/licenses/gpl-3.0/","language":"en","dataset_url":"https://huggingface.co/datasets/softcatala/open-source-english-catalan-corpus","creator_name":"Softcatal√†","creator_url":"https://huggingface.co/softcatala","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for open-source-english-catalan-corpus\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nTranslation memory built from more than 180 open source projects. These include LibreOffice, Mozilla, KDE, GNOME, GIMP, Inkscape and many others. It can be used as translation memory or as training corpus for neural translators.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSupported Tasks and Leaderboards\\n\\t\\n\\n[More Information Needed]\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages\\n\\t\\n\\nCatalan (ca)\\nEnglish (en)\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Structure‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/softcatala/open-source-english-catalan-corpus."},
	{"name":"demo","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/stevhliu/demo","creator_name":"Steven Liu","creator_url":"https://huggingface.co/stevhliu","description":"\\n\\t\\n\\t\\t\\n\\t\\tDataset Card for Demo\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThis is a demo dataset with two files train.csv and test.csv.\\nLoad it by:\\nfrom datasets import load_dataset \\ndata_files = {\\\"train\\\": \\\"train.csv\\\", \\\"test\\\": \\\"test.csv\\\"} \\ndemo = load_dataset(\\\"stevhliu/demo\\\", data_files=data_files)  \\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSupported Tasks and Leaderboards\\n\\t\\n\\n[More Information Needed]\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages\\n\\t\\n\\n[More Information Needed]\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Structure\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Instances\\n\\t\\n\\n[More Information‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/stevhliu/demo."},
	{"name":"measuring-hate-speech","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ucberkeley-dlab/measuring-hate-speech","creator_name":"Social Sciences Data Lab at UC Berkeley","creator_url":"https://huggingface.co/ucberkeley-dlab","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset card for Measuring Hate Speech\\n\\t\\n\\nThis is a public release of the dataset described in Kennedy et al. (2020) and Sachdeva et al. (2022), consisting of 39,565 comments annotated by 7,912 annotators, for 135,556 combined rows. The primary outcome variable is the \\\"hate speech score\\\" but the 10 constituent ordinal labels (sentiment, (dis)respect, insult, humiliation, inferior status, violence, dehumanization, genocide, attack/defense, hate speech benchmark) can also be treated‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ucberkeley-dlab/measuring-hate-speech."},
	{"name":"WikiConvert","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/usc-isi/WikiConvert","creator_name":"USC Information Sciences Institute","creator_url":"https://huggingface.co/usc-isi","description":"Language Modelling with Cardinal Number Annotations."},
	{"name":"lsoie","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/wardenga/lsoie","creator_name":"Robert Wardenga","creator_url":"https://huggingface.co/wardenga","description":"The Large Scale Open Information Extraction Dataset (LSOIE), is a dataset 20 \\ntimes larger than the next largest human-annotated Open Information Extraction\\n(OIE) dataset. LSOIE is a built upon the QA-SRL 2.0 dataset."},
	{"name":"COVID-19-vaccine-attitude-tweets","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/webimmunization/COVID-19-vaccine-attitude-tweets","creator_name":"webimmunization","creator_url":"https://huggingface.co/webimmunization","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for COVID-19-vaccine-attitude-tweets\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThe dataset consists of 2564 manually annotated tweets related to COVID-19 vaccines. The dataset can be used to discover the attitude expressed in the tweet towards the subject of COVID-19 vaccines. Tweets are in English. The dataset was curated in such a way as to maximize the likelihood of tweets with a strong emotional tone. We have assumed the existence of three classes:\\n\\nPRO (label 0): positive‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/webimmunization/COVID-19-vaccine-attitude-tweets."},
	{"name":"annotated_reference_strings","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/yuanchuan/annotated_reference_strings","creator_name":"Yuan Chuan Kee","creator_url":"https://huggingface.co/yuanchuan","description":"A repository of reference strings annotated using CSL processor using citations obtained from various sources."},
	{"name":"java-8m-methods-v1","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/anjandash/java-8m-methods-v1","creator_name":"Anjan Karmakar","creator_url":"https://huggingface.co/anjandash","description":"anjandash/java-8m-methods-v1 dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"the-antiwork-subreddit-dataset","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/SocialGrep/the-antiwork-subreddit-dataset","creator_name":"SocialGrep","creator_url":"https://huggingface.co/SocialGrep","description":"This dataset follows the notorious subreddit /r/Antiwork, a place for many Redditors to share resources and discuss grievances with the current labour market."},
	{"name":"IteraTeR_full_sent","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/wanyu/IteraTeR_full_sent","creator_name":"Wanyu Du","creator_url":"https://huggingface.co/wanyu","description":"Paper: Understanding Iterative Revision from Human-Written Text\\nAuthors: Wanyu Du, Vipul Raheja, Dhruv Kumar, Zae Myung Kim, Melissa Lopez, Dongyeop Kang\\nGithub repo: https://github.com/vipulraheja/IteraTeR\\n"},
	{"name":"IteraTeR_full_doc","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/wanyu/IteraTeR_full_doc","creator_name":"Wanyu Du","creator_url":"https://huggingface.co/wanyu","description":"Paper: Understanding Iterative Revision from Human-Written Text\\nAuthors: Wanyu Du, Vipul Raheja, Dhruv Kumar, Zae Myung Kim, Melissa Lopez, Dongyeop Kang\\nGithub repo: https://github.com/vipulraheja/IteraTeR\\n"},
	{"name":"IteraTeR_human_sent","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/wanyu/IteraTeR_human_sent","creator_name":"Wanyu Du","creator_url":"https://huggingface.co/wanyu","description":"Paper: Understanding Iterative Revision from Human-Written Text\\nAuthors: Wanyu Du, Vipul Raheja, Dhruv Kumar, Zae Myung Kim, Melissa Lopez, Dongyeop Kang\\nGithub repo: https://github.com/vipulraheja/IteraTeR\\n"},
	{"name":"IteraTeR_human_doc","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/wanyu/IteraTeR_human_doc","creator_name":"Wanyu Du","creator_url":"https://huggingface.co/wanyu","description":"Paper: Understanding Iterative Revision from Human-Written Text\\nAuthors: Wanyu Du, Vipul Raheja, Dhruv Kumar, Zae Myung Kim, Melissa Lopez, Dongyeop Kang\\nGithub repo: https://github.com/vipulraheja/IteraTeR\\n"},
	{"name":"java-8m-methods-v2","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/anjandash/java-8m-methods-v2","creator_name":"Anjan Karmakar","creator_url":"https://huggingface.co/anjandash","description":"anjandash/java-8m-methods-v2 dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"test2","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/malteos/test2","creator_name":"malteos","creator_url":"https://huggingface.co/malteos","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for [Dataset Name]\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\n[More Information Needed]\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSupported Tasks and Leaderboards\\n\\t\\n\\n[More Information Needed]\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages\\n\\t\\n\\n[More Information Needed]\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Structure\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Instances\\n\\t\\n\\n[More Information Needed]\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Fields\\n\\t\\n\\n[More Information Needed]\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Splits\\n\\t\\n\\n[More Information Needed]\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Creation\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tCuration Rationale\\n\\t\\n\\n[More‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/malteos/test2."},
	{"name":"pmc_open_access_xml","keyword":"monolingual","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/TomTBT/pmc_open_access_xml","creator_name":"Tom Boissonnet","creator_url":"https://huggingface.co/TomTBT","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for PMC Open Access XML\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThe XML Open Access includes more than 3.4 million journal articles and preprints that are made available under\\nlicense terms that allow reuse. \\nNot all articles in PMC are available for text mining and other reuse, many have copyright protection, however articles\\nin the PMC Open Access Subset are made available under Creative Commons or similar licenses that generally allow more\\nliberal redistribution and reuse‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/TomTBT/pmc_open_access_xml."},
	{"name":"adv_glue","keyword":"monolingual","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/AI-Secure/adv_glue","creator_name":"Secure Learning Lab","creator_url":"https://huggingface.co/AI-Secure","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Adversarial GLUE\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nAdversarial GLUE Benchmark (AdvGLUE) is a comprehensive robustness evaluation benchmark that focuses on the adversarial robustness evaluation of language models. It covers five natural language understanding tasks from the famous GLUE tasks and is an adversarial version of GLUE benchmark.\\nAdvGLUE considers textual adversarial attacks from different perspectives and hierarchies, including word-level transformations‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/AI-Secure/adv_glue."},
	{"name":"psycholinguistic_eval","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/KevinZ/psycholinguistic_eval","creator_name":"Kevin Zhao","creator_url":"https://huggingface.co/KevinZ","description":"Psycholinguistic dataset from 'What BERT is not: Lessons from a new suite of psycholinguistic diagnostics for language models'\\nby Allyson Ettinger"},
	{"name":"multiwoz21","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ConvLab/multiwoz21","creator_name":"ConvLab","creator_url":"https://huggingface.co/ConvLab","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for MultiWOZ 2.1\\n\\t\\n\\n\\nRepository: https://github.com/budzianowski/multiwoz\\nPaper: https://aclanthology.org/2020.lrec-1.53\\nLeaderboard: https://github.com/budzianowski/multiwoz\\nWho transforms the dataset: Qi Zhu(zhuq96 at gmail dot com)\\n\\nTo use this dataset, you need to install ConvLab-3 platform first. Then you can load the dataset via:\\nfrom convlab.util import load_dataset, load_ontology, load_database\\n\\ndataset = load_dataset('multiwoz21')\\nontology =‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ConvLab/multiwoz21."},
	{"name":"readability-es-caes","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/somosnlp-hackathon-2022/readability-es-caes","creator_name":"I Hackathon Somos NLP: PLN en Espa√±ol","creator_url":"https://huggingface.co/somosnlp-hackathon-2022","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for [readability-es-caes]\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThis dataset is a compilation of short articles from websites dedicated to learn Spanish as a second language. These articles have been compiled from the following sources:\\n\\nCAES corpus (Mart√≠nez et al., 2019): the \\\"Corpus de Aprendices del Espa√±ol\\\" is a collection of texts produced by Spanish L2 learners from Spanish learning centers and universities. These text are produced‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/somosnlp-hackathon-2022/readability-es-caes."},
	{"name":"unam_tesis","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/somosnlp-hackathon-2022/unam_tesis","creator_name":"I Hackathon Somos NLP: PLN en Espa√±ol","creator_url":"https://huggingface.co/somosnlp-hackathon-2022","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card of \\\"unam_tesis\\\"\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nEl dataset unam_tesis cuenta con 1000 tesis de 5 carreras de la Universidad Nacional Aut√≥noma de M√©xico (UNAM), 200 por carrera. Se pretende seguir incrementando este dataset con las dem√°s carreras y m√°s tesis.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSupported Tasks and Leaderboards\\n\\t\\n\\ntext-classification\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages\\n\\t\\n\\nEspa√±ol (es)\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Structure\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Instances\\n\\t\\n\\nLas instancias del dataset son de la‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/somosnlp-hackathon-2022/unam_tesis."},
	{"name":"squad_v2_french_translated","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/pragnakalp/squad_v2_french_translated","creator_name":"Pragnakalp Techlabs","creator_url":"https://huggingface.co/pragnakalp","description":"Using Google Translation, we have translated SQuAD 2.0 dataset into multiple languages. \\nHere is the translated dataset of SQuAD 2.0 in French language.\\nShared by Pragnakalp Techlabs\\n"},
	{"name":"readability-es-hackathon-pln-public","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/somosnlp-hackathon-2022/readability-es-hackathon-pln-public","creator_name":"I Hackathon Somos NLP: PLN en Espa√±ol","creator_url":"https://huggingface.co/somosnlp-hackathon-2022","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for [readability-es-sentences]\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nCompilation of short Spanish articles for readability assessment.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThis dataset is a compilation of short articles from websites dedicated to learn Spanish as a second language. These articles have been compiled from the following sources: \\n\\nCoh-Metrix-Esp corpus (Quispesaravia, et al., 2016): collection of 100 parallel texts with simple and complex variants in Spanish.‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/somosnlp-hackathon-2022/readability-es-hackathon-pln-public."},
	{"name":"monolingual_ab","keyword":"monolingual","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Nart/monolingual_ab","creator_name":"Danial Zakaria","creator_url":"https://huggingface.co/Nart","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for \\\"monolingual_ab\\\"\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThe Abkhaz language monolingual dataset is a collection of 1,470,480 sentences extracted from  different sources. The dataset is available under the Creative Commons Universal Public Domain License. Part of it is also available as part of Common Voice, another part is from the Abkhaz National Corpus\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Creation\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSource Data\\n\\t\\n\\nHere is a link to the source of a large part of the data‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Nart/monolingual_ab."},
	{"name":"the-reddit-dataset-dataset","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/SocialGrep/the-reddit-dataset-dataset","creator_name":"SocialGrep","creator_url":"https://huggingface.co/SocialGrep","description":"A meta dataset of Reddit's own /r/datasets community."},
	{"name":"the-reddit-place-dataset","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/SocialGrep/the-reddit-place-dataset","creator_name":"SocialGrep","creator_url":"https://huggingface.co/SocialGrep","description":"The written history or /r/Place, in posts and comments."},
	{"name":"Sinhala-News-Source-classification","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/NLPC-UOM/Sinhala-News-Source-classification","creator_name":"The National Languages Processing Centre","creator_url":"https://huggingface.co/NLPC-UOM","description":"This dataset contains Sinhala news headlines extracted from 9 news sources (websites) (Sri Lanka Army, Dinamina, GossipLanka, Hiru, ITN, Lankapuwath, NewsLK,\\nNewsfirst, World Socialist Web Site-Sinhala). This is a processed version of the corpus created by Sachintha, D., Piyarathna, L., Rajitha, C., and Ranathunga, S. (2021). Exploiting parallel corpora to improve multilingual embedding based document and sentence alignment. Single word sentences, invalid characters have been removed from the‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/NLPC-UOM/Sinhala-News-Source-classification."},
	{"name":"smithsonian_butterflies","keyword":"monolingual","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ceyda/smithsonian_butterflies","creator_name":"Ceyda Cinarel","creator_url":"https://huggingface.co/ceyda","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for [Smithsonian Butterflies]\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nHigh-res images from Smithsonian \\\"Education and Outreach\\\" & \\\"NMNH - Entomology Dept.\\\" collections. Crawled\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSupported Tasks and Leaderboards\\n\\t\\n\\nIncludes metadata about the scientific name of butterflies, but there maybe missing values. Might be good for classification.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages\\n\\t\\n\\nEnglish\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Structure\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Instances\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tExample data‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ceyda/smithsonian_butterflies."},
	{"name":"pesp","keyword":"monolingual","license":"Academic Free License v3.0","license_url":"https://choosealicense.com/licenses/afl-3.0/","language":"en","dataset_url":"https://huggingface.co/datasets/apjanco/pesp","creator_name":"Andy Janco","creator_url":"https://huggingface.co/apjanco","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tPages of Early Soviet Performance (PESP)\\n\\t\\n\\nThis dataset was created as part of the Pages of Early Soviet Performance project at Princeton and provides text and image research data from a previously scanned collection of illustrated periodicals held by Princeton University's Slavic Collections. The project was a partnership with ITMO University in Saint Petersburg. Our work focused on document segmentation and the prediction of image, text, title, and mixedtext regions in the‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/apjanco/pesp."},
	{"name":"APEACH","keyword":"monolingual","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/jason9693/APEACH","creator_name":"Kichang Yang","creator_url":"https://huggingface.co/jason9693","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset for project: kor_hate_eval(APEACH)\\n\\t\\n\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSample Code\\n\\t\\n\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Descritpion\\n\\t\\n\\nKorean Hate Speech Evaluation Datasets : trained with BEEP! and evaluate with APEACH\\n\\nRepository: Korean HateSpeech Evaluation Dataset\\nPaper: APEACH: Attacking Pejorative Expressions with Analysis on Crowd-Generated Hate Speech Evaluation Datasets\\nPoint of Contact: Kichang Yang\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages\\n\\t\\n\\nko-KR\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Structure\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Instances\\n\\t\\n\\nA‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/jason9693/APEACH."},
	{"name":"PLOD-filtered","keyword":"monolingual","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/surrey-nlp/PLOD-filtered","creator_name":"University of Surrey NLP Group","creator_url":"https://huggingface.co/surrey-nlp","description":"This is the dataset repository for PLOD Dataset accepted to be published at LREC 2022.\\nThe dataset can help build sequence labelling models for the task Abbreviation Detection."},
	{"name":"PLOD-unfiltered","keyword":"monolingual","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/surrey-nlp/PLOD-unfiltered","creator_name":"University of Surrey NLP Group","creator_url":"https://huggingface.co/surrey-nlp","description":"This is the dataset repository for PLOD Dataset accepted to be published at LREC 2022.\\nThe dataset can help build sequence labelling models for the task Abbreviation Detection."},
	{"name":"the-reddit-irl-dataset","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/SocialGrep/the-reddit-irl-dataset","creator_name":"SocialGrep","creator_url":"https://huggingface.co/SocialGrep","description":"Data from the humour subreddits /r/meirl and /r/me_irl, up to Apr 1 2022"},
	{"name":"IteraTeR_v2","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/wanyu/IteraTeR_v2","creator_name":"Wanyu Du","creator_url":"https://huggingface.co/wanyu","description":"Paper: Read, Revise, Repeat: A System Demonstration for Human-in-the-loop Iterative Text Revision\\nAuthors: Wanyu Du*, Zae Myung Kim*, Vipul Raheja, Dhruv Kumar, Dongyeop Kang\\nGithub repo: https://github.com/vipulraheja/IteraTeR\\nWatch our system demonstration below!\\n\\n"},
	{"name":"WANLI","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/alisawuffles/WANLI","creator_name":"Alisa Liu","creator_url":"https://huggingface.co/alisawuffles","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for WANLI\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nWANLI (Worker-AI Collaboration for NLI) is a collection of 108K English sentence pairs for the task of natural language inference (NLI).\\nEach example is created by first identifying a \\\"pocket\\\" of examples in MultiNLI (Williams et al., 2018) that share a challenging reasoning pattern, then instructing GPT-3 to write a new example with the same pattern.\\nThe set of generated examples are automatically filtered to contain those‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/alisawuffles/WANLI."},
	{"name":"semeval-2010-pre","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/taln-ls2n/semeval-2010-pre","creator_name":"TALN research group at LS2N lab","creator_url":"https://huggingface.co/taln-ls2n","description":"Preprocessed SemEval-2010 Benchmark dataset for Keyphrase Generation."},
	{"name":"FaithDial","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/McGill-NLP/FaithDial","creator_name":"McGill NLP Group","creator_url":"https://huggingface.co/McGill-NLP","description":"FaithDial is a new benchmark for hallucination-free dialogues, created by manually editing hallucinated and uncooperative responses in Wizard of Wikipedia."},
	{"name":"kinopoisk","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/blinoff/kinopoisk","creator_name":"Pavel Blinov","creator_url":"https://huggingface.co/blinoff","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nKinopoisk movie reviews dataset (TOP250 & BOTTOM100 rank lists).\\nIn total it contains 36,591 reviews from July 2004 to November 2012.\\nWith following distribution along the 3-point sentiment scale:\\n\\nGood: 27,264;\\nBad: 4,751;\\nNeutral: 4,576.\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Fields\\n\\t\\n\\nEach sample contains the following fields:\\n\\npart: rank list top250 or bottom100;\\nmovie_name;\\nreview_id;\\nauthor: review author;\\ndate: date of a review;\\ntitle: review title;\\ngrade3: sentiment score‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/blinoff/kinopoisk."},
	{"name":"bigscience-lama","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/janck/bigscience-lama","creator_name":"Jan-Christoph Kalo","creator_url":"https://huggingface.co/janck","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for LAMA: LAnguage Model Analysis - a dataset for probing and analyzing the factual and commonsense knowledge contained in pretrained language models.\\n\\t\\n\\n@inproceedings{petroni2020how,\\n  title={How Context Affects Language Models' Factual Predictions},\\n  author={Fabio Petroni and Patrick Lewis and Aleksandra Piktus and Tim Rockt{\\\"a}schel and Yuxiang Wu and Alexander H. Miller and Sebastian Riedel},\\n  booktitle={Automated Knowledge Base Construction},\\n  year={2020}‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/janck/bigscience-lama."},
	{"name":"Writing-style-classification","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/NLPC-UOM/Writing-style-classification","creator_name":"The National Languages Processing Centre","creator_url":"https://huggingface.co/NLPC-UOM","description":"This file contains news texts (sentences) belonging to different writing styles. The original dataset created by {Upeksha, D., Wijayarathna, C., Siriwardena, M.,\\nLasandun, L., Wimalasuriya, C., de Silva, N., and Dias, G. (2015). Implementing a corpus for Sinhala language. 01}is processed and cleaned.\\nIf you use this dataset, please cite {Dhananjaya et al. BERTifying Sinhala - A Comprehensive Analysis of Pre-trained Language Models for Sinhala Text Classification, 2022} and the above mentioned‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/NLPC-UOM/Writing-style-classification."},
	{"name":"twitter_pos_vcb","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/strombergnlp/twitter_pos_vcb","creator_name":"Str√∏mberg NLP","creator_url":"https://huggingface.co/strombergnlp","description":"Part-of-speech information is basic NLP task. However, Twitter text\\nis difficult to part-of-speech tag: it is noisy, with linguistic errors and idiosyncratic style.\\nThis data is the vote-constrained bootstrapped data generate to support state-of-the-art results.\\n\\nThe data is about 1.5 million English tweets annotated for part-of-speech using Ritter's extension of the PTB tagset.\\nThe tweets are from 2012 and 2013, tokenized using the GATE tokenizer and tagged\\njointly using the CMU ARK tagger and Ritter's T-POS tagger. Only when both these taggers' outputs\\nare completely compatible over a whole tweet, is that tweet added to the dataset.\\n\\nThis data is recommend for use a training data **only**, and not evaluation data.\\n\\nFor more details see https://gate.ac.uk/wiki/twitter-postagger.html and https://aclanthology.org/R13-1026.pdf"},
	{"name":"zulu_stance","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/strombergnlp/zulu_stance","creator_name":"Str√∏mberg NLP","creator_url":"https://huggingface.co/strombergnlp","description":"This is a stance detection dataset in the Zulu language. The data is translated to Zulu by Zulu native speakers, from English source texts.\\n\\nMisinformation has become a major concern in recent last years given its \\nspread across our information sources. In the past years, many NLP tasks have\\nbeen introduced in this area, with some systems reaching good results on \\nEnglish language datasets. Existing AI based approaches for fighting \\nmisinformation in literature suggest automatic stance detection as an integral\\nfirst step to success. Our paper aims at utilizing this progress made for\\nEnglish to transfers that knowledge into other languages, which is a \\nnon-trivial task due to the domain gap between English and the target \\nlanguages. We propose a black-box non-intrusive method that utilizes techniques\\nfrom Domain Adaptation to reduce the domain gap, without requiring any human\\nexpertise in the target language, by leveraging low-quality data in both a\\nsupervised and unsupervised manner. This allows us to rapidly achieve similar\\nresults for stance detection for the Zulu language, the target language in\\nthis work, as are found for English. We also provide a stance detection dataset\\nin the Zulu language."},
	{"name":"home-depot","keyword":"monolingual","license":"Academic Free License v3.0","license_url":"https://choosealicense.com/licenses/afl-3.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Ukhushn/home-depot","creator_name":"Umair Khushnood","creator_url":"https://huggingface.co/Ukhushn","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Ukhushn/home-depot\\n\\t\\n\\n"},
	{"name":"WIESP2022-NER","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/adsabs/WIESP2022-NER","creator_name":"SAO/NASA Astrophysics Data System","creator_url":"https://huggingface.co/adsabs","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset for the first Workshop on Information Extraction from Scientific Publications (WIESP/2022).\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nDatasets with text fragments from astrophysics papers, provided by the NASA Astrophysical Data System with manually tagged astronomical facilities and other entities of interest (e.g., celestial objects).Datasets are in JSON Lines format (each line is a json dictionary).The datasets are formatted similarly to the CONLL2003 format. Each token is‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/adsabs/WIESP2022-NER."},
	{"name":"twitter_pos","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/strombergnlp/twitter_pos","creator_name":"Str√∏mberg NLP","creator_url":"https://huggingface.co/strombergnlp","description":"Part-of-speech information is basic NLP task. However, Twitter text\\nis difficult to part-of-speech tag: it is noisy, with linguistic errors and idiosyncratic style.\\nThis dataset contains two datasets for English PoS tagging for tweets:\\n\\n* Ritter, with train/dev/test\\n* Foster, with dev/test\\n\\nSplits defined in the Derczynski paper, but the data is from Ritter and Foster.\\n\\nFor more details see:\\n\\n* https://gate.ac.uk/wiki/twitter-postagger.html\\n* https://aclanthology.org/D11-1141.pdf\\n* https://www.aaai.org/ocs/index.php/ws/aaaiw11/paper/download/3912/4191"},
	{"name":"arcalive_220506","keyword":"monolingual","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Bingsu/arcalive_220506","creator_name":"Dowon Hwang","creator_url":"https://huggingface.co/Bingsu","description":"[ÏïÑÏπ¥ÎùºÏù¥Î∏å Î≤†Ïä§Ìä∏ ÎùºÏù¥Î∏å Ï±ÑÎÑê](https://arca.live/b/live)Ïùò 2021ÎÖÑ 8Ïõî 16ÏùºÎ∂ÄÌÑ∞ 2022ÎÖÑ 5Ïõî 6ÏùºÍπåÏßÄÏùò Îç∞Ïù¥ÌÑ∞Î•º ÏàòÏßëÌïòÏó¨, ÎåìÍ∏ÄÎßå Í≥®ÎùºÎÇ∏ Îç∞Ïù¥ÌÑ∞ÏûÖÎãàÎã§."},
	{"name":"QA2D","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/domenicrosati/QA2D","creator_name":"Domenic Rosati","creator_url":"https://huggingface.co/domenicrosati","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for QA2D\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nExisting datasets for natural language inference (NLI) have propelled research on language understanding. We propose a new method for automatically deriving NLI datasets from the growing abundance of large-scale question answering datasets. Our approach hinges on learning a sentence transformation model which converts question-answer pairs into their declarative forms. Despite being primarily trained on a single QA dataset, we‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/domenicrosati/QA2D."},
	{"name":"qg_subjqa","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/lmqg/qg_subjqa","creator_name":"LMQG","creator_url":"https://huggingface.co/lmqg","description":"[SubjQA](https://github.com/megagonlabs/SubjQA) dataset for question generation (QG) task."},
	{"name":"rumoureval_2019","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/strombergnlp/rumoureval_2019","creator_name":"Str√∏mberg NLP","creator_url":"https://huggingface.co/strombergnlp","description":"\\nStance prediction task in English. The goal is to predict whether a given reply to a claim either supports, denies, questions, or simply comments on the claim. Ran as a SemEval task in 2019."},
	{"name":"cogtext","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/morteza/cogtext","creator_name":"Morteza Ansarinia","creator_url":"https://huggingface.co/morteza","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for CogText PubMed Abstracts\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThe CogText dataset is a curated collection of abstracts about cognitive tasks and constructs from PubMed.\\nThis dataset contains the original abstracts and their corresponding embeddings.\\nPlease visit CogText on GitHub for the details and codes.\\n\\nHomepage: https://github.com/morteza/cogtext\\nRepository: https://github.com/morteza/cogtext\\nPoint of Contact: Morteza Ansarinia\\nPaper:‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/morteza/cogtext."},
	{"name":"id_recipe","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Sultannn/id_recipe","creator_name":"Sultan","creator_url":"https://huggingface.co/Sultannn","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for id_recipe\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nIndonesian foods are well-known for their rich taste. There are many spices used even for daily foods. This dataset may give insight on how to prepare Indonesian food. \\nid_recipe is an Indonesian Food Recipe dataset. The dataset contains >10000 Indonesian Recipe.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSupported Tasks and Leaderboards\\n\\t\\n\\n[More Information Needed]\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages\\n\\t\\n\\nIndonesian\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Splits\\n\\t\\n\\nHere are the number of‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Sultannn/id_recipe."},
	{"name":"QA_on_SLA","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/rajeshvarma/QA_on_SLA","creator_name":"sai rajesh varma","creator_url":"https://huggingface.co/rajeshvarma","description":"rajeshvarma/QA_on_SLA dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"bucc-bitext-mining","keyword":"monolingual","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mteb/bucc-bitext-mining","creator_name":"Massive Text Embedding Benchmark","creator_url":"https://huggingface.co/mteb","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for MTEB Benchmark\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nMTEB is a heterogeneous benchmark that has been built from diverse tasks:\\n\\nBitextMining: BUCC, Tatoeba\\nClassification: AmazonCounterfactualClassification, AmazonPolarityClassification, AmazonReviewsClassification, Banking77Classification, EmotionClassification, ImdbClassification, MassiveIntentClassification, MassiveScenarioClassification, MTOPDomainClassification, MTOPIntentClassification‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mteb/bucc-bitext-mining."},
	{"name":"movie_reviews_with_context_drift","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/arize-ai/movie_reviews_with_context_drift","creator_name":"Arize AI","creator_url":"https://huggingface.co/arize-ai","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for reviews_with_drift\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThis dataset was crafted to be used in our tutorial [Link to the tutorial when ready]. It consists on a large Movie Review Dataset mixed with some reviews from a Hotel Review Dataset. The training/validation set are purely obtained from the Movie Review Dataset while the production set is mixed. Some other features have been added (age, gender, context) as well as a made up‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/arize-ai/movie_reviews_with_context_drift."},
	{"name":"million-headlines","keyword":"monolingual","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/rajistics/million-headlines","creator_name":"Rajiv Shah","creator_url":"https://huggingface.co/rajistics","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Million Headlines\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThis contains data of news headlines published over a period of eighteen years.  Sourced from the reputable Australian news source ABC (Australian Broadcasting Corporation) \\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Structure\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Instances\\n\\t\\n\\nFor each instance, there is a integer for the data, a string for news headline.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Fields\\n\\t\\n\\n\\npublish date: a integer that represents the data\\nheadline: a string for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/rajistics/million-headlines."},
	{"name":"BBNLI","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/feyzaakyurek/BBNLI","creator_name":"Afra Feyza Akyurek","creator_url":"https://huggingface.co/feyzaakyurek","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for BBNLI\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nBBNLI (Bias Benchmark for Natural Language Inference) is bias measurement benchmark for the tasks of both natural language inference and question answering. BBNLI consists of 16 subtopics each tailored to measure a specific stereotype that is negatively impacting certain classes. Each subtopic includes a set of 3 to 11 premises,  5 to 11 stereotypical hypotheses that are geared towards measuring biases and 3 to 5 test‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/feyzaakyurek/BBNLI."},
	{"name":"gov_report_qs","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/launch/gov_report_qs","creator_name":"LAUNCH Lab","creator_url":"https://huggingface.co/launch","description":"GovReport-QS hierarchical question-summary generation dataset.\\n\\nThere are two configs:\\n  - paragraph: paragraph-level annotated data\\n  - document: aggregated paragraph-level annotated data for the same document"},
	{"name":"ftrace","keyword":"monolingual","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ekinakyurek/ftrace","creator_name":"Ekin","creator_url":"https://huggingface.co/ekinakyurek","description":"    Factual Tracing Dataset that contains queries and abstracts, and their corresponding ground truth."},
	{"name":"resd","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Aniemore/resd","creator_name":"Aniemore","creator_url":"https://huggingface.co/Aniemore","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for resd\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nRussian dataset of emotional speech dialogues. This dataset was assembled from ~3.5 hours of live speech by actors who voiced pre-distributed emotions in the dialogue for ~3 minutes each.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSupported Tasks and Leaderboards\\n\\t\\n\\n[More Information Needed]\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages\\n\\t\\n\\n[More Information Needed]\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Structure\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Instances\\n\\t\\n\\n[More Information Needed]\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Fields‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Aniemore/resd."},
	{"name":"cedr-m7","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Aniemore/cedr-m7","creator_name":"Aniemore","creator_url":"https://huggingface.co/Aniemore","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for CEDR-M7\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\n[More Information Needed]\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSupported Tasks and Leaderboards\\n\\t\\n\\n[More Information Needed]\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages\\n\\t\\n\\n[More Information Needed]\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Structure\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Instances\\n\\t\\n\\n[More Information Needed]\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Fields\\n\\t\\n\\n[More Information Needed]\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Splits\\n\\t\\n\\n[More Information Needed]\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Creation\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tCuration Rationale\\n\\t\\n\\n[More‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Aniemore/cedr-m7."},
	{"name":"ru_paraphraser","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/merionum/ru_paraphraser","creator_name":"Vadim Gudkov","creator_url":"https://huggingface.co/merionum","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for ParaPhraser\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nParaPhraser is a news headlines corpus annotated according to the following schema:\\n1: precise paraphrases\\n0: near paraphrases\\n-1: non-paraphrases\\n\\nThe Plus part is also available.\\nIt contains clusters of news headline paraphrases labeled automatically by a fine-tuned paraphrase detection BERT model.In order to load it:\\nfrom datasets import load_dataset\\n\\ncorpus = load_dataset('merionum/ru_paraphraser'‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/merionum/ru_paraphraser."},
	{"name":"REPV","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Aniemore/REPV","creator_name":"Aniemore","creator_url":"https://huggingface.co/Aniemore","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tCitations\\n\\t\\n\\n@misc{Aniemore,\\n  author = {–ê—Ä—Ç–µ–º –ê–º–µ–Ω—Ç–µ—Å, –ò–ª—å—è –õ—É–±–µ–Ω–µ—Ü, –ù–∏–∫–∏—Ç–∞ –î–∞–≤–∏–¥—á—É–∫},\\n  title = {–û—Ç–∫—Ä—ã—Ç–∞—è –±–∏–±–ª–∏–æ—Ç–µ–∫–∞ –∏—Å–∫—É—Å—Å—Ç–≤–µ–Ω–Ω–æ–≥–æ –∏–Ω—Ç–µ–ª–ª–µ–∫—Ç–∞ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ –∏ –≤—ã—è–≤–ª–µ–Ω–∏—è —ç–º–æ—Ü–∏–æ–Ω–∞–ª—å–Ω—ã—Ö –æ—Ç—Ç–µ–Ω–∫–æ–≤ —Ä–µ—á–∏ —á–µ–ª–æ–≤–µ–∫–∞},\\n  year = {2022},\\n  publisher = {Hugging Face},\\n  journal = {Hugging Face Hub},\\n  howpublished = {\\\\url{https://huggingface.com/aniemore/Aniemore}},\\n  email = {hello@socialcode.ru}\\n}\\n\\n"},
	{"name":"REPV-S","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Aniemore/REPV-S","creator_name":"Aniemore","creator_url":"https://huggingface.co/Aniemore","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tCitations\\n\\t\\n\\n@misc{Aniemore,\\n  author = {–ê—Ä—Ç–µ–º –ê–º–µ–Ω—Ç–µ—Å, –ò–ª—å—è –õ—É–±–µ–Ω–µ—Ü, –ù–∏–∫–∏—Ç–∞ –î–∞–≤–∏–¥—á—É–∫},\\n  title = {–û—Ç–∫—Ä—ã—Ç–∞—è –±–∏–±–ª–∏–æ—Ç–µ–∫–∞ –∏—Å–∫—É—Å—Å—Ç–≤–µ–Ω–Ω–æ–≥–æ –∏–Ω—Ç–µ–ª–ª–µ–∫—Ç–∞ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ –∏ –≤—ã—è–≤–ª–µ–Ω–∏—è —ç–º–æ—Ü–∏–æ–Ω–∞–ª—å–Ω—ã—Ö –æ—Ç—Ç–µ–Ω–∫–æ–≤ —Ä–µ—á–∏ —á–µ–ª–æ–≤–µ–∫–∞},\\n  year = {2022},\\n  publisher = {Hugging Face},\\n  journal = {Hugging Face Hub},\\n  howpublished = {\\\\url{https://huggingface.com/aniemore/Aniemore}},\\n  email = {hello@socialcode.ru}\\n}\\n\\n"},
	{"name":"movie_recommendation","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/sileod/movie_recommendation","creator_name":"Damien Sileo","creator_url":"https://huggingface.co/sileod","description":"Movie recommendation task based on the Movielens dataset"},
	{"name":"discourse_marker_qa","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/sileod/discourse_marker_qa","creator_name":"Damien Sileo","creator_url":"https://huggingface.co/sileod","description":"Discourse marker/connective prediction as multiple choice questions based on the Discovery dataset"},
	{"name":"lccc","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/silver/lccc","creator_name":"Silver","creator_url":"https://huggingface.co/silver","description":"LCCC: Large-scale Cleaned Chinese Conversation corpus (LCCC) is a large corpus of Chinese conversations.\\nA rigorous data cleaning pipeline is designed to ensure the quality of the corpus.\\nThis pipeline involves a set of rules and several classifier-based filters.\\nNoises such as offensive or sensitive words, special symbols, emojis,\\ngrammatically incorrect sentences, and incoherent conversations are filtered."},
	{"name":"wikitext_linked","keyword":"monolingual","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/DFKI-SLT/wikitext_linked","creator_name":"Speech and Language Technology, DFKI","creator_url":"https://huggingface.co/DFKI-SLT","description":" The WikiText language modeling dataset is a collection of over 100 million tokens extracted from the set of verified\\n Good and Featured articles on Wikipedia. Dependency Relations, POS, NER tags are marked with trankit and\\n entities are linked with entity-fishing.\\n The dataset is available under the Creative Commons Attribution-ShareAlike License."},
	{"name":"qg_squadshifts","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/lmqg/qg_squadshifts","creator_name":"LMQG","creator_url":"https://huggingface.co/lmqg","description":"[SQuAD Shifts](https://modestyachts.github.io/squadshifts-website/index.html) dataset for question generation (QG) task."},
	{"name":"qg_esquad","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/lmqg/qg_esquad","creator_name":"LMQG","creator_url":"https://huggingface.co/lmqg","description":"[SQuAD-es](https://huggingface.co/datasets/squad_es) dataset for question generation (QG) task."},
	{"name":"qg_koquad","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/lmqg/qg_koquad","creator_name":"LMQG","creator_url":"https://huggingface.co/lmqg","description":"[KorQuAD](https://huggingface.co/datasets/squad_kor_v1) dataset for question generation (QG) task."},
	{"name":"trec-covid-qrels","keyword":"monolingual","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/BeIR/trec-covid-qrels","creator_name":"BEIR","creator_url":"https://huggingface.co/BeIR","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for BEIR Benchmark\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nBEIR is a heterogeneous benchmark that has been built from 18 diverse datasets representing 9 information retrieval tasks:\\n\\nFact-checking: FEVER, Climate-FEVER, SciFact\\nQuestion-Answering: NQ, HotpotQA, FiQA-2018\\nBio-Medical IR: TREC-COVID, BioASQ, NFCorpus\\nNews Retrieval: TREC-NEWS, Robust04\\nArgument Retrieval: Touche-2020, ArguAna\\nDuplicate Question Retrieval: Quora, CqaDupstack\\nCitation-Prediction: SCIDOCS\\nTweet‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/BeIR/trec-covid-qrels."},
	{"name":"scifact","keyword":"monolingual","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/BeIR/scifact","creator_name":"BEIR","creator_url":"https://huggingface.co/BeIR","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for BEIR Benchmark\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nBEIR is a heterogeneous benchmark that has been built from 18 diverse datasets representing 9 information retrieval tasks:\\n\\nFact-checking: FEVER, Climate-FEVER, SciFact\\nQuestion-Answering: NQ, HotpotQA, FiQA-2018\\nBio-Medical IR: TREC-COVID, BioASQ, NFCorpus\\nNews Retrieval: TREC-NEWS, Robust04\\nArgument Retrieval: Touche-2020, ArguAna\\nDuplicate Question Retrieval: Quora, CqaDupstack\\nCitation-Prediction: SCIDOCS\\nTweet‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/BeIR/scifact."},
	{"name":"nfcorpus","keyword":"monolingual","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/BeIR/nfcorpus","creator_name":"BEIR","creator_url":"https://huggingface.co/BeIR","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for BEIR Benchmark\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nBEIR is a heterogeneous benchmark that has been built from 18 diverse datasets representing 9 information retrieval tasks:\\n\\nFact-checking: FEVER, Climate-FEVER, SciFact\\nQuestion-Answering: NQ, HotpotQA, FiQA-2018\\nBio-Medical IR: TREC-COVID, BioASQ, NFCorpus\\nNews Retrieval: TREC-NEWS, Robust04\\nArgument Retrieval: Touche-2020, ArguAna\\nDuplicate Question Retrieval: Quora, CqaDupstack\\nCitation-Prediction: SCIDOCS\\nTweet‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/BeIR/nfcorpus."},
	{"name":"nq","keyword":"monolingual","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/BeIR/nq","creator_name":"BEIR","creator_url":"https://huggingface.co/BeIR","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for BEIR Benchmark\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nBEIR is a heterogeneous benchmark that has been built from 18 diverse datasets representing 9 information retrieval tasks:\\n\\nFact-checking: FEVER, Climate-FEVER, SciFact\\nQuestion-Answering: NQ, HotpotQA, FiQA-2018\\nBio-Medical IR: TREC-COVID, BioASQ, NFCorpus\\nNews Retrieval: TREC-NEWS, Robust04\\nArgument Retrieval: Touche-2020, ArguAna\\nDuplicate Question Retrieval: Quora, CqaDupstack\\nCitation-Prediction: SCIDOCS\\nTweet‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/BeIR/nq."},
	{"name":"arguana","keyword":"monolingual","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/BeIR/arguana","creator_name":"BEIR","creator_url":"https://huggingface.co/BeIR","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for BEIR Benchmark\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nBEIR is a heterogeneous benchmark that has been built from 18 diverse datasets representing 9 information retrieval tasks:\\n\\nFact-checking: FEVER, Climate-FEVER, SciFact\\nQuestion-Answering: NQ, HotpotQA, FiQA-2018\\nBio-Medical IR: TREC-COVID, BioASQ, NFCorpus\\nNews Retrieval: TREC-NEWS, Robust04\\nArgument Retrieval: Touche-2020, ArguAna\\nDuplicate Question Retrieval: Quora, CqaDupstack\\nCitation-Prediction: SCIDOCS\\nTweet‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/BeIR/arguana."},
	{"name":"webis-touche2020","keyword":"monolingual","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/BeIR/webis-touche2020","creator_name":"BEIR","creator_url":"https://huggingface.co/BeIR","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for BEIR Benchmark\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nBEIR is a heterogeneous benchmark that has been built from 18 diverse datasets representing 9 information retrieval tasks:\\n\\nFact-checking: FEVER, Climate-FEVER, SciFact\\nQuestion-Answering: NQ, HotpotQA, FiQA-2018\\nBio-Medical IR: TREC-COVID, BioASQ, NFCorpus\\nNews Retrieval: TREC-NEWS, Robust04\\nArgument Retrieval: Touche-2020, ArguAna\\nDuplicate Question Retrieval: Quora, CqaDupstack\\nCitation-Prediction: SCIDOCS\\nTweet‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/BeIR/webis-touche2020."},
	{"name":"quora","keyword":"monolingual","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/BeIR/quora","creator_name":"BEIR","creator_url":"https://huggingface.co/BeIR","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for BEIR Benchmark\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nBEIR is a heterogeneous benchmark that has been built from 18 diverse datasets representing 9 information retrieval tasks:\\n\\nFact-checking: FEVER, Climate-FEVER, SciFact\\nQuestion-Answering: NQ, HotpotQA, FiQA-2018\\nBio-Medical IR: TREC-COVID, BioASQ, NFCorpus\\nNews Retrieval: TREC-NEWS, Robust04\\nArgument Retrieval: Touche-2020, ArguAna\\nDuplicate Question Retrieval: Quora, CqaDupstack\\nCitation-Prediction: SCIDOCS\\nTweet‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/BeIR/quora."},
	{"name":"scidocs","keyword":"monolingual","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/BeIR/scidocs","creator_name":"BEIR","creator_url":"https://huggingface.co/BeIR","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for BEIR Benchmark\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nBEIR is a heterogeneous benchmark that has been built from 18 diverse datasets representing 9 information retrieval tasks:\\n\\nFact-checking: FEVER, Climate-FEVER, SciFact\\nQuestion-Answering: NQ, HotpotQA, FiQA-2018\\nBio-Medical IR: TREC-COVID, BioASQ, NFCorpus\\nNews Retrieval: TREC-NEWS, Robust04\\nArgument Retrieval: Touche-2020, ArguAna\\nDuplicate Question Retrieval: Quora, CqaDupstack\\nCitation-Prediction: SCIDOCS\\nTweet‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/BeIR/scidocs."},
	{"name":"fever","keyword":"monolingual","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/BeIR/fever","creator_name":"BEIR","creator_url":"https://huggingface.co/BeIR","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for BEIR Benchmark\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nBEIR is a heterogeneous benchmark that has been built from 18 diverse datasets representing 9 information retrieval tasks:\\n\\nFact-checking: FEVER, Climate-FEVER, SciFact\\nQuestion-Answering: NQ, HotpotQA, FiQA-2018\\nBio-Medical IR: TREC-COVID, BioASQ, NFCorpus\\nNews Retrieval: TREC-NEWS, Robust04\\nArgument Retrieval: Touche-2020, ArguAna\\nDuplicate Question Retrieval: Quora, CqaDupstack\\nCitation-Prediction: SCIDOCS\\nTweet‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/BeIR/fever."},
	{"name":"scifact-qrels","keyword":"monolingual","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/BeIR/scifact-qrels","creator_name":"BEIR","creator_url":"https://huggingface.co/BeIR","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for BEIR Benchmark\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nBEIR is a heterogeneous benchmark that has been built from 18 diverse datasets representing 9 information retrieval tasks:\\n\\nFact-checking: FEVER, Climate-FEVER, SciFact\\nQuestion-Answering: NQ, HotpotQA, FiQA-2018\\nBio-Medical IR: TREC-COVID, BioASQ, NFCorpus\\nNews Retrieval: TREC-NEWS, Robust04\\nArgument Retrieval: Touche-2020, ArguAna\\nDuplicate Question Retrieval: Quora, CqaDupstack\\nCitation-Prediction: SCIDOCS\\nTweet‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/BeIR/scifact-qrels."},
	{"name":"nfcorpus-qrels","keyword":"monolingual","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/BeIR/nfcorpus-qrels","creator_name":"BEIR","creator_url":"https://huggingface.co/BeIR","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for BEIR Benchmark\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nBEIR is a heterogeneous benchmark that has been built from 18 diverse datasets representing 9 information retrieval tasks:\\n\\nFact-checking: FEVER, Climate-FEVER, SciFact\\nQuestion-Answering: NQ, HotpotQA, FiQA-2018\\nBio-Medical IR: TREC-COVID, BioASQ, NFCorpus\\nNews Retrieval: TREC-NEWS, Robust04\\nArgument Retrieval: Touche-2020, ArguAna\\nDuplicate Question Retrieval: Quora, CqaDupstack\\nCitation-Prediction: SCIDOCS\\nTweet‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/BeIR/nfcorpus-qrels."},
	{"name":"msmarco-qrels","keyword":"monolingual","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/BeIR/msmarco-qrels","creator_name":"BEIR","creator_url":"https://huggingface.co/BeIR","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for BEIR Benchmark\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nBEIR is a heterogeneous benchmark that has been built from 18 diverse datasets representing 9 information retrieval tasks:\\n\\nFact-checking: FEVER, Climate-FEVER, SciFact\\nQuestion-Answering: NQ, HotpotQA, FiQA-2018\\nBio-Medical IR: TREC-COVID, BioASQ, NFCorpus\\nNews Retrieval: TREC-NEWS, Robust04\\nArgument Retrieval: Touche-2020, ArguAna\\nDuplicate Question Retrieval: Quora, CqaDupstack\\nCitation-Prediction: SCIDOCS\\nTweet‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/BeIR/msmarco-qrels."},
	{"name":"hotpotqa-qrels","keyword":"monolingual","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/BeIR/hotpotqa-qrels","creator_name":"BEIR","creator_url":"https://huggingface.co/BeIR","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for BEIR Benchmark\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nBEIR is a heterogeneous benchmark that has been built from 18 diverse datasets representing 9 information retrieval tasks:\\n\\nFact-checking: FEVER, Climate-FEVER, SciFact\\nQuestion-Answering: NQ, HotpotQA, FiQA-2018\\nBio-Medical IR: TREC-COVID, BioASQ, NFCorpus\\nNews Retrieval: TREC-NEWS, Robust04\\nArgument Retrieval: Touche-2020, ArguAna\\nDuplicate Question Retrieval: Quora, CqaDupstack\\nCitation-Prediction: SCIDOCS\\nTweet‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/BeIR/hotpotqa-qrels."},
	{"name":"fiqa-qrels","keyword":"monolingual","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/BeIR/fiqa-qrels","creator_name":"BEIR","creator_url":"https://huggingface.co/BeIR","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for BEIR Benchmark\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nBEIR is a heterogeneous benchmark that has been built from 18 diverse datasets representing 9 information retrieval tasks:\\n\\nFact-checking: FEVER, Climate-FEVER, SciFact\\nQuestion-Answering: NQ, HotpotQA, FiQA-2018\\nBio-Medical IR: TREC-COVID, BioASQ, NFCorpus\\nNews Retrieval: TREC-NEWS, Robust04\\nArgument Retrieval: Touche-2020, ArguAna\\nDuplicate Question Retrieval: Quora, CqaDupstack\\nCitation-Prediction: SCIDOCS\\nTweet‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/BeIR/fiqa-qrels."},
	{"name":"arguana-qrels","keyword":"monolingual","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/BeIR/arguana-qrels","creator_name":"BEIR","creator_url":"https://huggingface.co/BeIR","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for BEIR Benchmark\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nBEIR is a heterogeneous benchmark that has been built from 18 diverse datasets representing 9 information retrieval tasks:\\n\\nFact-checking: FEVER, Climate-FEVER, SciFact\\nQuestion-Answering: NQ, HotpotQA, FiQA-2018\\nBio-Medical IR: TREC-COVID, BioASQ, NFCorpus\\nNews Retrieval: TREC-NEWS, Robust04\\nArgument Retrieval: Touche-2020, ArguAna\\nDuplicate Question Retrieval: Quora, CqaDupstack\\nCitation-Prediction: SCIDOCS\\nTweet‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/BeIR/arguana-qrels."},
	{"name":"webis-touche2020-qrels","keyword":"monolingual","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/BeIR/webis-touche2020-qrels","creator_name":"BEIR","creator_url":"https://huggingface.co/BeIR","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for BEIR Benchmark\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nBEIR is a heterogeneous benchmark that has been built from 18 diverse datasets representing 9 information retrieval tasks:\\n\\nFact-checking: FEVER, Climate-FEVER, SciFact\\nQuestion-Answering: NQ, HotpotQA, FiQA-2018\\nBio-Medical IR: TREC-COVID, BioASQ, NFCorpus\\nNews Retrieval: TREC-NEWS, Robust04\\nArgument Retrieval: Touche-2020, ArguAna\\nDuplicate Question Retrieval: Quora, CqaDupstack\\nCitation-Prediction: SCIDOCS\\nTweet‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/BeIR/webis-touche2020-qrels."},
	{"name":"quora-qrels","keyword":"monolingual","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/BeIR/quora-qrels","creator_name":"BEIR","creator_url":"https://huggingface.co/BeIR","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for BEIR Benchmark\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nBEIR is a heterogeneous benchmark that has been built from 18 diverse datasets representing 9 information retrieval tasks:\\n\\nFact-checking: FEVER, Climate-FEVER, SciFact\\nQuestion-Answering: NQ, HotpotQA, FiQA-2018\\nBio-Medical IR: TREC-COVID, BioASQ, NFCorpus\\nNews Retrieval: TREC-NEWS, Robust04\\nArgument Retrieval: Touche-2020, ArguAna\\nDuplicate Question Retrieval: Quora, CqaDupstack\\nCitation-Prediction: SCIDOCS\\nTweet‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/BeIR/quora-qrels."},
	{"name":"dbpedia-entity-qrels","keyword":"monolingual","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/BeIR/dbpedia-entity-qrels","creator_name":"BEIR","creator_url":"https://huggingface.co/BeIR","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for BEIR Benchmark\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nBEIR is a heterogeneous benchmark that has been built from 18 diverse datasets representing 9 information retrieval tasks:\\n\\nFact-checking: FEVER, Climate-FEVER, SciFact\\nQuestion-Answering: NQ, HotpotQA, FiQA-2018\\nBio-Medical IR: TREC-COVID, BioASQ, NFCorpus\\nNews Retrieval: TREC-NEWS, Robust04\\nArgument Retrieval: Touche-2020, ArguAna\\nDuplicate Question Retrieval: Quora, CqaDupstack\\nCitation-Prediction: SCIDOCS\\nTweet‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/BeIR/dbpedia-entity-qrels."},
	{"name":"scidocs-qrels","keyword":"monolingual","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/BeIR/scidocs-qrels","creator_name":"BEIR","creator_url":"https://huggingface.co/BeIR","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for BEIR Benchmark\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nBEIR is a heterogeneous benchmark that has been built from 18 diverse datasets representing 9 information retrieval tasks:\\n\\nFact-checking: FEVER, Climate-FEVER, SciFact\\nQuestion-Answering: NQ, HotpotQA, FiQA-2018\\nBio-Medical IR: TREC-COVID, BioASQ, NFCorpus\\nNews Retrieval: TREC-NEWS, Robust04\\nArgument Retrieval: Touche-2020, ArguAna\\nDuplicate Question Retrieval: Quora, CqaDupstack\\nCitation-Prediction: SCIDOCS\\nTweet‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/BeIR/scidocs-qrels."},
	{"name":"fever-qrels","keyword":"monolingual","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/BeIR/fever-qrels","creator_name":"BEIR","creator_url":"https://huggingface.co/BeIR","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for BEIR Benchmark\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nBEIR is a heterogeneous benchmark that has been built from 18 diverse datasets representing 9 information retrieval tasks:\\n\\nFact-checking: FEVER, Climate-FEVER, SciFact\\nQuestion-Answering: NQ, HotpotQA, FiQA-2018\\nBio-Medical IR: TREC-COVID, BioASQ, NFCorpus\\nNews Retrieval: TREC-NEWS, Robust04\\nArgument Retrieval: Touche-2020, ArguAna\\nDuplicate Question Retrieval: Quora, CqaDupstack\\nCitation-Prediction: SCIDOCS\\nTweet‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/BeIR/fever-qrels."},
	{"name":"climate-fever-qrels","keyword":"monolingual","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/BeIR/climate-fever-qrels","creator_name":"BEIR","creator_url":"https://huggingface.co/BeIR","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for BEIR Benchmark\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nBEIR is a heterogeneous benchmark that has been built from 18 diverse datasets representing 9 information retrieval tasks:\\n\\nFact-checking: FEVER, Climate-FEVER, SciFact\\nQuestion-Answering: NQ, HotpotQA, FiQA-2018\\nBio-Medical IR: TREC-COVID, BioASQ, NFCorpus\\nNews Retrieval: TREC-NEWS, Robust04\\nArgument Retrieval: Touche-2020, ArguAna\\nDuplicate Question Retrieval: Quora, CqaDupstack\\nCitation-Prediction: SCIDOCS\\nTweet‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/BeIR/climate-fever-qrels."},
	{"name":"nq-qrels","keyword":"monolingual","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/BeIR/nq-qrels","creator_name":"BEIR","creator_url":"https://huggingface.co/BeIR","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for BEIR Benchmark\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nBEIR is a heterogeneous benchmark that has been built from 18 diverse datasets representing 9 information retrieval tasks:\\n\\nFact-checking: FEVER, Climate-FEVER, SciFact\\nQuestion-Answering: NQ, HotpotQA, FiQA-2018\\nBio-Medical IR: TREC-COVID, BioASQ, NFCorpus\\nNews Retrieval: TREC-NEWS, Robust04\\nArgument Retrieval: Touche-2020, ArguAna\\nDuplicate Question Retrieval: Quora, CqaDupstack\\nCitation-Prediction: SCIDOCS\\nTweet‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/BeIR/nq-qrels."},
	{"name":"123_test","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/JeremyAlain/123_test","creator_name":"J√©r√©my Scheurer","creator_url":"https://huggingface.co/JeremyAlain","description":"The Fewshot Table dataset consists of tables that naturally occur on the web, that are formatted as few-shot tasks for fine-tuning language models to improve their few-shot performance. The dataset consists of approximately 413K tables that are extracted from the WDC Web Table Corpora 2015, which is released under the Apache-2.0 license. The WDC Web Table Corpora \\\"contains vast amounts of HTML tables. [...] The Web Data Commons project extracts relational Web tables from the Common Crawl, the largest and most up-to-date Web corpus that is currently available to the public."},
	{"name":"arguana-generated-queries","keyword":"monolingual","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/BeIR/arguana-generated-queries","creator_name":"BEIR","creator_url":"https://huggingface.co/BeIR","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for BEIR Benchmark\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nBEIR is a heterogeneous benchmark that has been built from 18 diverse datasets representing 9 information retrieval tasks:\\n\\nFact-checking: FEVER, Climate-FEVER, SciFact\\nQuestion-Answering: NQ, HotpotQA, FiQA-2018\\nBio-Medical IR: TREC-COVID, BioASQ, NFCorpus\\nNews Retrieval: TREC-NEWS, Robust04\\nArgument Retrieval: Touche-2020, ArguAna\\nDuplicate Question Retrieval: Quora, CqaDupstack\\nCitation-Prediction: SCIDOCS\\nTweet‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/BeIR/arguana-generated-queries."},
	{"name":"climate-fever-generated-queries","keyword":"monolingual","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/BeIR/climate-fever-generated-queries","creator_name":"BEIR","creator_url":"https://huggingface.co/BeIR","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for BEIR Benchmark\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nBEIR is a heterogeneous benchmark that has been built from 18 diverse datasets representing 9 information retrieval tasks:\\n\\nFact-checking: FEVER, Climate-FEVER, SciFact\\nQuestion-Answering: NQ, HotpotQA, FiQA-2018\\nBio-Medical IR: TREC-COVID, BioASQ, NFCorpus\\nNews Retrieval: TREC-NEWS, Robust04\\nArgument Retrieval: Touche-2020, ArguAna\\nDuplicate Question Retrieval: Quora, CqaDupstack\\nCitation-Prediction: SCIDOCS\\nTweet‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/BeIR/climate-fever-generated-queries."},
	{"name":"fever-generated-queries","keyword":"monolingual","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/BeIR/fever-generated-queries","creator_name":"BEIR","creator_url":"https://huggingface.co/BeIR","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for BEIR Benchmark\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nBEIR is a heterogeneous benchmark that has been built from 18 diverse datasets representing 9 information retrieval tasks:\\n\\nFact-checking: FEVER, Climate-FEVER, SciFact\\nQuestion-Answering: NQ, HotpotQA, FiQA-2018\\nBio-Medical IR: TREC-COVID, BioASQ, NFCorpus\\nNews Retrieval: TREC-NEWS, Robust04\\nArgument Retrieval: Touche-2020, ArguAna\\nDuplicate Question Retrieval: Quora, CqaDupstack\\nCitation-Prediction: SCIDOCS\\nTweet‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/BeIR/fever-generated-queries."},
	{"name":"srsd-feynman_medium","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/yoshitomo-matsubara/srsd-feynman_medium","creator_name":"Yoshitomo Matsubara","creator_url":"https://huggingface.co/yoshitomo-matsubara","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for SRSD-Feynman (Medium set)\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nOur SRSD (Feynman) datasets are designed to discuss the performance of Symbolic Regression for Scientific Discovery.\\nWe carefully reviewed the properties of each formula and its variables in the Feynman Symbolic Regression Database to design reasonably realistic sampling range of values so that our SRSD datasets can be used for evaluating the potential of SRSD such as whether or not an SR method con‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/yoshitomo-matsubara/srsd-feynman_medium."},
	{"name":"srsd-feynman_hard","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/yoshitomo-matsubara/srsd-feynman_hard","creator_name":"Yoshitomo Matsubara","creator_url":"https://huggingface.co/yoshitomo-matsubara","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for SRSD-Feynman (Hard set)\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nOur SRSD (Feynman) datasets are designed to discuss the performance of Symbolic Regression for Scientific Discovery.\\nWe carefully reviewed the properties of each formula and its variables in the Feynman Symbolic Regression Database to design reasonably realistic sampling range of values so that our SRSD datasets can be used for evaluating the potential of SRSD such as whether or not an SR method con‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/yoshitomo-matsubara/srsd-feynman_hard."},
	{"name":"answersumm","keyword":"monolingual","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/alexfabbri/answersumm","creator_name":"Alexander Fabbri","creator_url":"https://huggingface.co/alexfabbri","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for answersumm\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThe AnswerSumm dataset is an English-language dataset of questions and answers collected from a StackExchange data dump. The dataset was created to support the task of query-focused answer summarization with an emphasis on multi-perspective answers. \\nThe dataset consists of over 4200 such question-answer threads annotated by professional linguists and includes over 8700 summaries. We decompose the task into several‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/alexfabbri/answersumm."},
	{"name":"ade20k-tiny","keyword":"monolingual","license":"BSD 3-Clause \"New\" or \"Revised\" License","license_url":"https://choosealicense.com/licenses/bsd-3-clause/","language":"en","dataset_url":"https://huggingface.co/datasets/nateraw/ade20k-tiny","creator_name":"Nate Raw","creator_url":"https://huggingface.co/nateraw","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for ADE 20K Tiny\\n\\t\\n\\nThis is a tiny subset of the ADE 20K dataset, which you can find here.\\n"},
	{"name":"fig-qa","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/nightingal3/fig-qa","creator_name":"Emmy Liu","creator_url":"https://huggingface.co/nightingal3","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Fig-QA\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThis is the dataset for the paper Testing the Ability of Language Models to Interpret Figurative Language. Fig-QA consists of 10256 examples of human-written creative metaphors that are paired as a Winograd schema. It can be used to evaluate the commonsense reasoning of models. The metaphors themselves can also be used as training data for other tasks, such as metaphor detection or generation. \\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSupported Tasks‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/nightingal3/fig-qa."},
	{"name":"nfcorpus-generated-queries","keyword":"monolingual","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/BeIR/nfcorpus-generated-queries","creator_name":"BEIR","creator_url":"https://huggingface.co/BeIR","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for BEIR Benchmark\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nBEIR is a heterogeneous benchmark that has been built from 18 diverse datasets representing 9 information retrieval tasks:\\n\\nFact-checking: FEVER, Climate-FEVER, SciFact\\nQuestion-Answering: NQ, HotpotQA, FiQA-2018\\nBio-Medical IR: TREC-COVID, BioASQ, NFCorpus\\nNews Retrieval: TREC-NEWS, Robust04\\nArgument Retrieval: Touche-2020, ArguAna\\nDuplicate Question Retrieval: Quora, CqaDupstack\\nCitation-Prediction: SCIDOCS\\nTweet‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/BeIR/nfcorpus-generated-queries."},
	{"name":"scifact-generated-queries","keyword":"monolingual","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/BeIR/scifact-generated-queries","creator_name":"BEIR","creator_url":"https://huggingface.co/BeIR","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for BEIR Benchmark\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nBEIR is a heterogeneous benchmark that has been built from 18 diverse datasets representing 9 information retrieval tasks:\\n\\nFact-checking: FEVER, Climate-FEVER, SciFact\\nQuestion-Answering: NQ, HotpotQA, FiQA-2018\\nBio-Medical IR: TREC-COVID, BioASQ, NFCorpus\\nNews Retrieval: TREC-NEWS, Robust04\\nArgument Retrieval: Touche-2020, ArguAna\\nDuplicate Question Retrieval: Quora, CqaDupstack\\nCitation-Prediction: SCIDOCS\\nTweet‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/BeIR/scifact-generated-queries."},
	{"name":"scidocs-generated-queries","keyword":"monolingual","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/BeIR/scidocs-generated-queries","creator_name":"BEIR","creator_url":"https://huggingface.co/BeIR","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for BEIR Benchmark\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nBEIR is a heterogeneous benchmark that has been built from 18 diverse datasets representing 9 information retrieval tasks:\\n\\nFact-checking: FEVER, Climate-FEVER, SciFact\\nQuestion-Answering: NQ, HotpotQA, FiQA-2018\\nBio-Medical IR: TREC-COVID, BioASQ, NFCorpus\\nNews Retrieval: TREC-NEWS, Robust04\\nArgument Retrieval: Touche-2020, ArguAna\\nDuplicate Question Retrieval: Quora, CqaDupstack\\nCitation-Prediction: SCIDOCS\\nTweet‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/BeIR/scidocs-generated-queries."},
	{"name":"fiqa-generated-queries","keyword":"monolingual","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/BeIR/fiqa-generated-queries","creator_name":"BEIR","creator_url":"https://huggingface.co/BeIR","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for BEIR Benchmark\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nBEIR is a heterogeneous benchmark that has been built from 18 diverse datasets representing 9 information retrieval tasks:\\n\\nFact-checking: FEVER, Climate-FEVER, SciFact\\nQuestion-Answering: NQ, HotpotQA, FiQA-2018\\nBio-Medical IR: TREC-COVID, BioASQ, NFCorpus\\nNews Retrieval: TREC-NEWS, Robust04\\nArgument Retrieval: Touche-2020, ArguAna\\nDuplicate Question Retrieval: Quora, CqaDupstack\\nCitation-Prediction: SCIDOCS\\nTweet‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/BeIR/fiqa-generated-queries."},
	{"name":"trec-covid-generated-queries","keyword":"monolingual","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/BeIR/trec-covid-generated-queries","creator_name":"BEIR","creator_url":"https://huggingface.co/BeIR","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for BEIR Benchmark\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nBEIR is a heterogeneous benchmark that has been built from 18 diverse datasets representing 9 information retrieval tasks:\\n\\nFact-checking: FEVER, Climate-FEVER, SciFact\\nQuestion-Answering: NQ, HotpotQA, FiQA-2018\\nBio-Medical IR: TREC-COVID, BioASQ, NFCorpus\\nNews Retrieval: TREC-NEWS, Robust04\\nArgument Retrieval: Touche-2020, ArguAna\\nDuplicate Question Retrieval: Quora, CqaDupstack\\nCitation-Prediction: SCIDOCS\\nTweet‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/BeIR/trec-covid-generated-queries."},
	{"name":"trec-news-generated-queries","keyword":"monolingual","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/BeIR/trec-news-generated-queries","creator_name":"BEIR","creator_url":"https://huggingface.co/BeIR","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for BEIR Benchmark\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nBEIR is a heterogeneous benchmark that has been built from 18 diverse datasets representing 9 information retrieval tasks:\\n\\nFact-checking: FEVER, Climate-FEVER, SciFact\\nQuestion-Answering: NQ, HotpotQA, FiQA-2018\\nBio-Medical IR: TREC-COVID, BioASQ, NFCorpus\\nNews Retrieval: TREC-NEWS, Robust04\\nArgument Retrieval: Touche-2020, ArguAna\\nDuplicate Question Retrieval: Quora, CqaDupstack\\nCitation-Prediction: SCIDOCS\\nTweet‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/BeIR/trec-news-generated-queries."},
	{"name":"webis-touche2020-generated-queries","keyword":"monolingual","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/BeIR/webis-touche2020-generated-queries","creator_name":"BEIR","creator_url":"https://huggingface.co/BeIR","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for BEIR Benchmark\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nBEIR is a heterogeneous benchmark that has been built from 18 diverse datasets representing 9 information retrieval tasks:\\n\\nFact-checking: FEVER, Climate-FEVER, SciFact\\nQuestion-Answering: NQ, HotpotQA, FiQA-2018\\nBio-Medical IR: TREC-COVID, BioASQ, NFCorpus\\nNews Retrieval: TREC-NEWS, Robust04\\nArgument Retrieval: Touche-2020, ArguAna\\nDuplicate Question Retrieval: Quora, CqaDupstack\\nCitation-Prediction: SCIDOCS\\nTweet‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/BeIR/webis-touche2020-generated-queries."},
	{"name":"robust04-generated-queries","keyword":"monolingual","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/BeIR/robust04-generated-queries","creator_name":"BEIR","creator_url":"https://huggingface.co/BeIR","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for BEIR Benchmark\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nBEIR is a heterogeneous benchmark that has been built from 18 diverse datasets representing 9 information retrieval tasks:\\n\\nFact-checking: FEVER, Climate-FEVER, SciFact\\nQuestion-Answering: NQ, HotpotQA, FiQA-2018\\nBio-Medical IR: TREC-COVID, BioASQ, NFCorpus\\nNews Retrieval: TREC-NEWS, Robust04\\nArgument Retrieval: Touche-2020, ArguAna\\nDuplicate Question Retrieval: Quora, CqaDupstack\\nCitation-Prediction: SCIDOCS\\nTweet‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/BeIR/robust04-generated-queries."},
	{"name":"signal1m-generated-queries","keyword":"monolingual","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/BeIR/signal1m-generated-queries","creator_name":"BEIR","creator_url":"https://huggingface.co/BeIR","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for BEIR Benchmark\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nBEIR is a heterogeneous benchmark that has been built from 18 diverse datasets representing 9 information retrieval tasks:\\n\\nFact-checking: FEVER, Climate-FEVER, SciFact\\nQuestion-Answering: NQ, HotpotQA, FiQA-2018\\nBio-Medical IR: TREC-COVID, BioASQ, NFCorpus\\nNews Retrieval: TREC-NEWS, Robust04\\nArgument Retrieval: Touche-2020, ArguAna\\nDuplicate Question Retrieval: Quora, CqaDupstack\\nCitation-Prediction: SCIDOCS\\nTweet‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/BeIR/signal1m-generated-queries."},
	{"name":"quora-generated-queries","keyword":"monolingual","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/BeIR/quora-generated-queries","creator_name":"BEIR","creator_url":"https://huggingface.co/BeIR","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for BEIR Benchmark\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nBEIR is a heterogeneous benchmark that has been built from 18 diverse datasets representing 9 information retrieval tasks:\\n\\nFact-checking: FEVER, Climate-FEVER, SciFact\\nQuestion-Answering: NQ, HotpotQA, FiQA-2018\\nBio-Medical IR: TREC-COVID, BioASQ, NFCorpus\\nNews Retrieval: TREC-NEWS, Robust04\\nArgument Retrieval: Touche-2020, ArguAna\\nDuplicate Question Retrieval: Quora, CqaDupstack\\nCitation-Prediction: SCIDOCS\\nTweet‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/BeIR/quora-generated-queries."},
	{"name":"hotpotqa-generated-queries","keyword":"monolingual","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/BeIR/hotpotqa-generated-queries","creator_name":"BEIR","creator_url":"https://huggingface.co/BeIR","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for BEIR Benchmark\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nBEIR is a heterogeneous benchmark that has been built from 18 diverse datasets representing 9 information retrieval tasks:\\n\\nFact-checking: FEVER, Climate-FEVER, SciFact\\nQuestion-Answering: NQ, HotpotQA, FiQA-2018\\nBio-Medical IR: TREC-COVID, BioASQ, NFCorpus\\nNews Retrieval: TREC-NEWS, Robust04\\nArgument Retrieval: Touche-2020, ArguAna\\nDuplicate Question Retrieval: Quora, CqaDupstack\\nCitation-Prediction: SCIDOCS\\nTweet‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/BeIR/hotpotqa-generated-queries."},
	{"name":"cqadupstack-generated-queries","keyword":"monolingual","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/BeIR/cqadupstack-generated-queries","creator_name":"BEIR","creator_url":"https://huggingface.co/BeIR","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for BEIR Benchmark\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nBEIR is a heterogeneous benchmark that has been built from 18 diverse datasets representing 9 information retrieval tasks:\\n\\nFact-checking: FEVER, Climate-FEVER, SciFact\\nQuestion-Answering: NQ, HotpotQA, FiQA-2018\\nBio-Medical IR: TREC-COVID, BioASQ, NFCorpus\\nNews Retrieval: TREC-NEWS, Robust04\\nArgument Retrieval: Touche-2020, ArguAna\\nDuplicate Question Retrieval: Quora, CqaDupstack\\nCitation-Prediction: SCIDOCS\\nTweet‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/BeIR/cqadupstack-generated-queries."},
	{"name":"cqadupstack-qrels","keyword":"monolingual","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/BeIR/cqadupstack-qrels","creator_name":"BEIR","creator_url":"https://huggingface.co/BeIR","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for BEIR Benchmark\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nBEIR is a heterogeneous benchmark that has been built from 18 diverse datasets representing 9 information retrieval tasks:\\n\\nFact-checking: FEVER, Climate-FEVER, SciFact\\nQuestion-Answering: NQ, HotpotQA, FiQA-2018\\nBio-Medical IR: TREC-COVID, BioASQ, NFCorpus\\nNews Retrieval: TREC-NEWS, Robust04\\nArgument Retrieval: Touche-2020, ArguAna\\nDuplicate Question Retrieval: Quora, CqaDupstack\\nCitation-Prediction: SCIDOCS\\nTweet‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/BeIR/cqadupstack-qrels."},
	{"name":"bioasq-generated-queries","keyword":"monolingual","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/BeIR/bioasq-generated-queries","creator_name":"BEIR","creator_url":"https://huggingface.co/BeIR","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for BEIR Benchmark\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nBEIR is a heterogeneous benchmark that has been built from 18 diverse datasets representing 9 information retrieval tasks:\\n\\nFact-checking: FEVER, Climate-FEVER, SciFact\\nQuestion-Answering: NQ, HotpotQA, FiQA-2018\\nBio-Medical IR: TREC-COVID, BioASQ, NFCorpus\\nNews Retrieval: TREC-NEWS, Robust04\\nArgument Retrieval: Touche-2020, ArguAna\\nDuplicate Question Retrieval: Quora, CqaDupstack\\nCitation-Prediction: SCIDOCS\\nTweet‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/BeIR/bioasq-generated-queries."},
	{"name":"core-2020-05-10-deduplication","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/pinecone/core-2020-05-10-deduplication","creator_name":"Pinecone","creator_url":"https://huggingface.co/pinecone","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for CORE Deduplication\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nCORE 2020 Deduplication dataset (https://core.ac.uk/documentation/dataset) contains 100K scholarly documents labeled as duplicates/non-duplicates.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages\\n\\t\\n\\nThe dataset language is English (BCP-47 en)\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tCitation Information\\n\\t\\n\\n@inproceedings{dedup2020,\\n  title={Deduplication of Scholarly Documents using Locality Sensitive Hashing and Word Embeddings},\\n  author={Gyawali, Bikash and‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/pinecone/core-2020-05-10-deduplication."},
	{"name":"ctebmsp","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/lcampillos/ctebmsp","creator_name":"Leonardo Campillos-Llanos","creator_url":"https://huggingface.co/lcampillos","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tCT-EBM-SP (Clinical Trials for Evidence-based Medicine in Spanish)\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThe Clinical Trials for Evidence-Based-Medicine in Spanish corpus is a collection of 1200 texts about clinical trials studies and clinical trials announcements:\\n\\n500 abstracts from journals published under a Creative Commons license, e.g. available in PubMed or the Scientific Electronic Library Online (SciELO)\\n700 clinical trials announcements published in the European Clinical‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/lcampillos/ctebmsp."},
	{"name":"CLIP-Kinetics700","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/iejMac/CLIP-Kinetics700","creator_name":"Maciej Kilian","creator_url":"https://huggingface.co/iejMac","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for CLIP-Kinetics70\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nCLIP-Kinetics700 is a compressed version of the Kinetics700 dataset using OpenAI's CLIP model.\\nThe original dataset is ~700 GB making it difficult to use and hold in memory on one machine. By downsampling each video to 1 FPS and encoding the frames using CLIP we we're able to compress the dataset to ~8 GB making it very memory-friendly and easy to use.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/iejMac/CLIP-Kinetics700."},
	{"name":"tm1","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ConvLab/tm1","creator_name":"ConvLab","creator_url":"https://huggingface.co/ConvLab","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Taskmaster-1\\n\\t\\n\\n\\nRepository: https://github.com/google-research-datasets/Taskmaster/tree/master/TM-1-2019\\nPaper: https://arxiv.org/pdf/1909.05358.pdf\\nLeaderboard: None\\nWho transforms the dataset: Qi Zhu(zhuq96 at gmail dot com)\\n\\nTo use this dataset, you need to install ConvLab-3 platform first. Then you can load the dataset via:\\nfrom convlab.util import load_dataset, load_ontology, load_database\\n\\ndataset = load_dataset('tm1')\\nontology = load_ontology('tm1')‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ConvLab/tm1."},
	{"name":"woz","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ConvLab/woz","creator_name":"ConvLab","creator_url":"https://huggingface.co/ConvLab","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for WOZ 2.0\\n\\t\\n\\n\\nRepository: https://github.com/nmrksic/neural-belief-tracker/tree/master/data/woz\\nPaper: https://aclanthology.org/P17-1163.pdf\\nLeaderboard: None\\nWho transforms the dataset: Qi Zhu(zhuq96 at gmail dot com)\\n\\nTo use this dataset, you need to install ConvLab-3 platform first. Then you can load the dataset via:\\nfrom convlab.util import load_dataset, load_ontology, load_database\\n\\ndataset = load_dataset('woz')\\nontology = load_ontology('woz')\\ndatabase =‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ConvLab/woz."},
	{"name":"camrest","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ConvLab/camrest","creator_name":"ConvLab","creator_url":"https://huggingface.co/ConvLab","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Camrest\\n\\t\\n\\n\\nRepository: https://www.repository.cam.ac.uk/handle/1810/260970\\nPaper: https://aclanthology.org/D16-1233/\\nLeaderboard: None\\nWho transforms the dataset: Qi Zhu(zhuq96 at gmail dot com)\\n\\nTo use this dataset, you need to install ConvLab-3 platform first. Then you can load the dataset via:\\nfrom convlab.util import load_dataset, load_ontology, load_database\\n\\ndataset = load_dataset('camrest')\\nontology = load_ontology('camrest')\\ndatabase =‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ConvLab/camrest."},
	{"name":"tm2","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ConvLab/tm2","creator_name":"ConvLab","creator_url":"https://huggingface.co/ConvLab","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Taskmaster-2\\n\\t\\n\\n\\nRepository: https://github.com/google-research-datasets/Taskmaster/tree/master/TM-2-2020\\nPaper: https://arxiv.org/pdf/1909.05358.pdf\\nLeaderboard: None\\nWho transforms the dataset: Qi Zhu(zhuq96 at gmail dot com)\\n\\nTo use this dataset, you need to install ConvLab-3 platform first. Then you can load the dataset via:\\nfrom convlab.util import load_dataset, load_ontology, load_database\\n\\ndataset = load_dataset('tm2')\\nontology = load_ontology('tm2')‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ConvLab/tm2."},
	{"name":"tm3","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ConvLab/tm3","creator_name":"ConvLab","creator_url":"https://huggingface.co/ConvLab","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Taskmaster-3\\n\\t\\n\\n\\nRepository: https://github.com/google-research-datasets/Taskmaster/tree/master/TM-3-2020\\nPaper: https://aclanthology.org/2021.acl-long.55.pdf\\nLeaderboard: None\\nWho transforms the dataset: Qi Zhu(zhuq96 at gmail dot com)\\n\\nTo use this dataset, you need to install ConvLab-3 platform first. Then you can load the dataset via:\\nfrom convlab.util import load_dataset, load_ontology, load_database\\n\\ndataset = load_dataset('tm3')\\nontology =‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ConvLab/tm3."},
	{"name":"sgd","keyword":"monolingual","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ConvLab/sgd","creator_name":"ConvLab","creator_url":"https://huggingface.co/ConvLab","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Schema-Guided Dialogue\\n\\t\\n\\n\\nRepository: https://github.com/google-research-datasets/dstc8-schema-guided-dialogue\\nPaper: https://arxiv.org/pdf/1909.05855.pdf\\nLeaderboard: None\\nWho transforms the dataset: Qi Zhu(zhuq96 at gmail dot com)\\n\\nTo use this dataset, you need to install ConvLab-3 platform first. Then you can load the dataset via:\\nfrom convlab.util import load_dataset, load_ontology, load_database\\n\\ndataset = load_dataset('sgd')\\nontology = load_ontology('sgd')‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ConvLab/sgd."},
	{"name":"open_question_type","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/launch/open_question_type","creator_name":"LAUNCH Lab","creator_url":"https://huggingface.co/launch","description":"Open-ended question type annotated dataset."},
	{"name":"hmd-erwt-training","keyword":"monolingual","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Livingwithmachines/hmd-erwt-training","creator_name":"Living with Machines","creator_url":"https://huggingface.co/Livingwithmachines","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for ERWT Hertiage Made Digital Newspapers training data\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThis dataset contains text extracted at the page level from historic digitised newspapers from the Heritage Made Digital newspaper digitisation program. The newspapers in the dataset were published between 1800 and 1870.\\nThe data was primarily created as a dataset for training 'time-aware' language models.\\nThe dataset contains text generated from Optical Character Recognition‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Livingwithmachines/hmd-erwt-training."},
	{"name":"highlightsum","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/knkarthick/highlightsum","creator_name":"Karthick Kaliannan Neelamohan","creator_url":"https://huggingface.co/knkarthick","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for HighlightSum Corpus [Single Dataset Comprising of AMI, SamSUM & DialogSUM for Brief Summarization of Text]\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLinks\\n\\t\\n\\n\\nAMI: https://huggingface.co/datasets/knkarthick/AMI\\nDialogSUM: https://github.com/cylnlp/dialogsum\\nSamSUM: https://huggingface.co/datasets/knkarthick/samsum\\nPoint of Contact: https://huggingface.co/knkarthick\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nHighlightSUM is collection of large-scale dialogue‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/knkarthick/highlightsum."},
	{"name":"topicsum","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/knkarthick/topicsum","creator_name":"Karthick Kaliannan Neelamohan","creator_url":"https://huggingface.co/knkarthick","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for TopicSum Corpus [Single Dataset Comprising of XSUM & DialogSUM for One Liner Summarization/ Topic Generation of Text]\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLinks\\n\\t\\n\\n\\nDialogSUM: https://github.com/cylnlp/dialogsum\\nXSUM: https://huggingface.co/datasets/knkarthick/xsum\\nPoint of Contact: https://huggingface.co/knkarthick\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nTopicSUM is collection of large-scale dialogue summarization dataset from XSUM & DialogSUM, consisting of‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/knkarthick/topicsum."},
	{"name":"catalanqa","keyword":"monolingual","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/projecte-aina/catalanqa","creator_name":"Projecte Aina","creator_url":"https://huggingface.co/projecte-aina","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for CatalanQA\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThis dataset can be used to build extractive-QA and Language Models. It is an aggregation and balancing of 2 previous datasets: VilaQuAD and ViquiQuAD.\\nSplits have been balanced by kind of question, and unlike other datasets like SQuAD, it only contains, per record, one question and one answer for each context, although the contexts can repeat multiple times.\\nThis dataset was developed by BSC TeMU as part of Projecte AINA‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/projecte-aina/catalanqa."},
	{"name":"reddit_qg","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/launch/reddit_qg","creator_name":"LAUNCH Lab","creator_url":"https://huggingface.co/launch","description":"Reddit question generation dataset."},
	{"name":"ampere","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/launch/ampere","creator_name":"LAUNCH Lab","creator_url":"https://huggingface.co/launch","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for AMPERE\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThis dataset is released together with our NAACL 2019 Paper \\\"Argument Mining for Understanding Peer Reviews\\\". If you find our work useful, please cite:\\n@inproceedings{hua-etal-2019-argument,\\n    title = \\\"Argument Mining for Understanding Peer Reviews\\\",\\n    author = \\\"Hua, Xinyu  and\\n      Nikolov, Mitko  and\\n      Badugu, Nikhil  and\\n      Wang, Lu\\\",\\n    booktitle = \\\"Proceedings of the 2019 Conference of the North‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/launch/ampere."},
	{"name":"german_argument_mining","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/joelniklaus/german_argument_mining","creator_name":"Joel Niklaus","creator_url":"https://huggingface.co/joelniklaus","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Annotated German Legal Decision Corpus\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThis dataset consists of 200 randomly chosen judgments. In these judgments a legal expert annotated the components\\nconclusion, definition and subsumption of the German legal writing style Urteilsstil.\\n\\\"Overall 25,075 sentences are annotated. 5% (1,202) of these sentences are marked as conclusion, 21% (5,328) as\\ndefinition, 53% (13,322) are marked as subsumption and the remaining 21% (6,481) as‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/joelniklaus/german_argument_mining."},
	{"name":"unpredictable_full","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/MicPie/unpredictable_full","creator_name":"Michael Pieler","creator_url":"https://huggingface.co/MicPie","description":"The UnpredicTable dataset consists of web tables formatted as few-shot tasks for fine-tuning language models to improve their few-shot performance. For more details please see the accompanying dataset card."},
	{"name":"scitail","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/bigbio/scitail","creator_name":"BigScience Biomedical Datasets","creator_url":"https://huggingface.co/bigbio","description":"The SciTail dataset is an entailment dataset created from multiple-choice science exams and\\nweb sentences. Each question and the correct answer choice are converted into an assertive\\nstatement to form the hypothesis. We use information retrieval to obtain relevant text from\\na large text corpus of web sentences, and use these sentences as a premise P. We crowdsource\\nthe annotation of such premise-hypothesis pair as supports (entails) or not (neutral), in order\\nto create the SciTail dataset. The dataset contains 27,026 examples with 10,101 examples with\\nentails label and 16,925 examples with neutral label."},
	{"name":"unpredictable_mmo-champion-com","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/MicPie/unpredictable_mmo-champion-com","creator_name":"Michael Pieler","creator_url":"https://huggingface.co/MicPie","description":"The UnpredicTable dataset consists of web tables formatted as few-shot tasks for fine-tuning language models to improve their few-shot performance. For more details please see the accompanying dataset card."},
	{"name":"unpredictable_baseball-fantasysports-yahoo-com","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/MicPie/unpredictable_baseball-fantasysports-yahoo-com","creator_name":"Michael Pieler","creator_url":"https://huggingface.co/MicPie","description":"The UnpredicTable dataset consists of web tables formatted as few-shot tasks for fine-tuning language models to improve their few-shot performance. For more details please see the accompanying dataset card."},
	{"name":"unpredictable_phonearena-com","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/MicPie/unpredictable_phonearena-com","creator_name":"Michael Pieler","creator_url":"https://huggingface.co/MicPie","description":"The UnpredicTable dataset consists of web tables formatted as few-shot tasks for fine-tuning language models to improve their few-shot performance. For more details please see the accompanying dataset card."},
	{"name":"unpredictable_support-google-com","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/MicPie/unpredictable_support-google-com","creator_name":"Michael Pieler","creator_url":"https://huggingface.co/MicPie","description":"The UnpredicTable dataset consists of web tables formatted as few-shot tasks for fine-tuning language models to improve their few-shot performance. For more details please see the accompanying dataset card."},
	{"name":"unpredictable_dividend-com","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/MicPie/unpredictable_dividend-com","creator_name":"Michael Pieler","creator_url":"https://huggingface.co/MicPie","description":"The UnpredicTable dataset consists of web tables formatted as few-shot tasks for fine-tuning language models to improve their few-shot performance. For more details please see the accompanying dataset card."},
	{"name":"unpredictable_bulbapedia-bulbagarden-net","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/MicPie/unpredictable_bulbapedia-bulbagarden-net","creator_name":"Michael Pieler","creator_url":"https://huggingface.co/MicPie","description":"The UnpredicTable dataset consists of web tables formatted as few-shot tasks for fine-tuning language models to improve their few-shot performance. For more details please see the accompanying dataset card."},
	{"name":"unpredictable_wkdu-org","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/MicPie/unpredictable_wkdu-org","creator_name":"Michael Pieler","creator_url":"https://huggingface.co/MicPie","description":"The UnpredicTable dataset consists of web tables formatted as few-shot tasks for fine-tuning language models to improve their few-shot performance. For more details please see the accompanying dataset card."},
	{"name":"unpredictable_dummies-com","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/MicPie/unpredictable_dummies-com","creator_name":"Michael Pieler","creator_url":"https://huggingface.co/MicPie","description":"The UnpredicTable dataset consists of web tables formatted as few-shot tasks for fine-tuning language models to improve their few-shot performance. For more details please see the accompanying dataset card."},
	{"name":"unpredictable_mgoblog-com","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/MicPie/unpredictable_mgoblog-com","creator_name":"Michael Pieler","creator_url":"https://huggingface.co/MicPie","description":"The UnpredicTable dataset consists of web tables formatted as few-shot tasks for fine-tuning language models to improve their few-shot performance. For more details please see the accompanying dataset card."},
	{"name":"unpredictable_gamefaqs-com","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/MicPie/unpredictable_gamefaqs-com","creator_name":"Michael Pieler","creator_url":"https://huggingface.co/MicPie","description":"The UnpredicTable dataset consists of web tables formatted as few-shot tasks for fine-tuning language models to improve their few-shot performance. For more details please see the accompanying dataset card."},
	{"name":"unpredictable_studystack-com","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/MicPie/unpredictable_studystack-com","creator_name":"Michael Pieler","creator_url":"https://huggingface.co/MicPie","description":"The UnpredicTable dataset consists of web tables formatted as few-shot tasks for fine-tuning language models to improve their few-shot performance. For more details please see the accompanying dataset card."},
	{"name":"unpredictable_sittercity-com","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/MicPie/unpredictable_sittercity-com","creator_name":"Michael Pieler","creator_url":"https://huggingface.co/MicPie","description":"The UnpredicTable dataset consists of web tables formatted as few-shot tasks for fine-tuning language models to improve their few-shot performance. For more details please see the accompanying dataset card."},
	{"name":"unpredictable_msdn-microsoft-com","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/MicPie/unpredictable_msdn-microsoft-com","creator_name":"Michael Pieler","creator_url":"https://huggingface.co/MicPie","description":"The UnpredicTable dataset consists of web tables formatted as few-shot tasks for fine-tuning language models to improve their few-shot performance. For more details please see the accompanying dataset card."},
	{"name":"unpredictable_cappex-com","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/MicPie/unpredictable_cappex-com","creator_name":"Michael Pieler","creator_url":"https://huggingface.co/MicPie","description":"The UnpredicTable dataset consists of web tables formatted as few-shot tasks for fine-tuning language models to improve their few-shot performance. For more details please see the accompanying dataset card."},
	{"name":"unpredictable_en-wikipedia-org","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/MicPie/unpredictable_en-wikipedia-org","creator_name":"Michael Pieler","creator_url":"https://huggingface.co/MicPie","description":"The UnpredicTable dataset consists of web tables formatted as few-shot tasks for fine-tuning language models to improve their few-shot performance. For more details please see the accompanying dataset card."},
	{"name":"unpredictable_cram-com","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/MicPie/unpredictable_cram-com","creator_name":"Michael Pieler","creator_url":"https://huggingface.co/MicPie","description":"The UnpredicTable dataset consists of web tables formatted as few-shot tasks for fine-tuning language models to improve their few-shot performance. For more details please see the accompanying dataset card."},
	{"name":"unpredictable_w3-org","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/MicPie/unpredictable_w3-org","creator_name":"Michael Pieler","creator_url":"https://huggingface.co/MicPie","description":"The UnpredicTable dataset consists of web tables formatted as few-shot tasks for fine-tuning language models to improve their few-shot performance. For more details please see the accompanying dataset card."},
	{"name":"unpredictable_sporcle-com","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/MicPie/unpredictable_sporcle-com","creator_name":"Michael Pieler","creator_url":"https://huggingface.co/MicPie","description":"The UnpredicTable dataset consists of web tables formatted as few-shot tasks for fine-tuning language models to improve their few-shot performance. For more details please see the accompanying dataset card."},
	{"name":"unpredictable_wiki-openmoko-org","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/MicPie/unpredictable_wiki-openmoko-org","creator_name":"Michael Pieler","creator_url":"https://huggingface.co/MicPie","description":"The UnpredicTable dataset consists of web tables formatted as few-shot tasks for fine-tuning language models to improve their few-shot performance. For more details please see the accompanying dataset card."},
	{"name":"unpredictable_ensembl-org","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/MicPie/unpredictable_ensembl-org","creator_name":"Michael Pieler","creator_url":"https://huggingface.co/MicPie","description":"The UnpredicTable dataset consists of web tables formatted as few-shot tasks for fine-tuning language models to improve their few-shot performance. For more details please see the accompanying dataset card."},
	{"name":"SalienceEvaluation","keyword":"monolingual","license":"GNU General Public License v3.0","license_url":"https://choosealicense.com/licenses/gpl-3.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Yincen/SalienceEvaluation","creator_name":"Qu","creator_url":"https://huggingface.co/Yincen","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Yincen/SalienceEvaluation\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\n[More Information Needed]\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSupported Tasks and Leaderboards\\n\\t\\n\\n[More Information Needed]\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages\\n\\t\\n\\n[More Information Needed]\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Structure\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Instances\\n\\t\\n\\n[More Information Needed]\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Fields\\n\\t\\n\\n[More Information Needed]\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Splits\\n\\t\\n\\n[More Information Needed]\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Creation\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tCuration Rationale‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Yincen/SalienceEvaluation."},
	{"name":"hatecheck-spanish","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Paul/hatecheck-spanish","creator_name":"Paul R√∂ttger","creator_url":"https://huggingface.co/Paul","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Multilingual HateCheck\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nMultilingual HateCheck (MHC) is a suite of functional tests for hate speech detection models in 10 different languages: Arabic, Dutch, French, German, Hindi, Italian, Mandarin, Polish, Portuguese and Spanish.\\nFor each language, there are 25+ functional tests that correspond to distinct types of hate and challenging non-hate.\\nThis allows for targeted diagnostic insights into model performance.\\nFor more‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Paul/hatecheck-spanish."},
	{"name":"hatecheck-polish","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Paul/hatecheck-polish","creator_name":"Paul R√∂ttger","creator_url":"https://huggingface.co/Paul","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Multilingual HateCheck\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nMultilingual HateCheck (MHC) is a suite of functional tests for hate speech detection models in 10 different languages: Arabic, Dutch, French, German, Hindi, Italian, Mandarin, Polish, Portuguese and Spanish.\\nFor each language, there are 25+ functional tests that correspond to distinct types of hate and challenging non-hate.\\nThis allows for targeted diagnostic insights into model performance.\\nFor more‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Paul/hatecheck-polish."},
	{"name":"hatecheck-mandarin","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Paul/hatecheck-mandarin","creator_name":"Paul R√∂ttger","creator_url":"https://huggingface.co/Paul","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Multilingual HateCheck\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nMultilingual HateCheck (MHC) is a suite of functional tests for hate speech detection models in 10 different languages: Arabic, Dutch, French, German, Hindi, Italian, Mandarin, Polish, Portuguese and Spanish.\\nFor each language, there are 25+ functional tests that correspond to distinct types of hate and challenging non-hate.\\nThis allows for targeted diagnostic insights into model performance.\\nFor more‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Paul/hatecheck-mandarin."},
	{"name":"hatecheck-italian","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Paul/hatecheck-italian","creator_name":"Paul R√∂ttger","creator_url":"https://huggingface.co/Paul","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Multilingual HateCheck\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nMultilingual HateCheck (MHC) is a suite of functional tests for hate speech detection models in 10 different languages: Arabic, Dutch, French, German, Hindi, Italian, Mandarin, Polish, Portuguese and Spanish.\\nFor each language, there are 25+ functional tests that correspond to distinct types of hate and challenging non-hate.\\nThis allows for targeted diagnostic insights into model performance.\\nFor more‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Paul/hatecheck-italian."},
	{"name":"hatecheck-hindi","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Paul/hatecheck-hindi","creator_name":"Paul R√∂ttger","creator_url":"https://huggingface.co/Paul","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Multilingual HateCheck\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nMultilingual HateCheck (MHC) is a suite of functional tests for hate speech detection models in 10 different languages: Arabic, Dutch, French, German, Hindi, Italian, Mandarin, Polish, Portuguese and Spanish.\\nFor each language, there are 25+ functional tests that correspond to distinct types of hate and challenging non-hate.\\nThis allows for targeted diagnostic insights into model performance.\\nFor more‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Paul/hatecheck-hindi."},
	{"name":"hatecheck-german","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Paul/hatecheck-german","creator_name":"Paul R√∂ttger","creator_url":"https://huggingface.co/Paul","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Multilingual HateCheck\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nMultilingual HateCheck (MHC) is a suite of functional tests for hate speech detection models in 10 different languages: Arabic, Dutch, French, German, Hindi, Italian, Mandarin, Polish, Portuguese and Spanish.\\nFor each language, there are 25+ functional tests that correspond to distinct types of hate and challenging non-hate.\\nThis allows for targeted diagnostic insights into model performance.\\nFor more‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Paul/hatecheck-german."},
	{"name":"hatecheck-french","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Paul/hatecheck-french","creator_name":"Paul R√∂ttger","creator_url":"https://huggingface.co/Paul","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Multilingual HateCheck\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nMultilingual HateCheck (MHC) is a suite of functional tests for hate speech detection models in 10 different languages: Arabic, Dutch, French, German, Hindi, Italian, Mandarin, Polish, Portuguese and Spanish.\\nFor each language, there are 25+ functional tests that correspond to distinct types of hate and challenging non-hate.\\nThis allows for targeted diagnostic insights into model performance.\\nFor more‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Paul/hatecheck-french."},
	{"name":"hatecheck-dutch","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Paul/hatecheck-dutch","creator_name":"Paul R√∂ttger","creator_url":"https://huggingface.co/Paul","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Multilingual HateCheck\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nMultilingual HateCheck (MHC) is a suite of functional tests for hate speech detection models in 10 different languages: Arabic, Dutch, French, German, Hindi, Italian, Mandarin, Polish, Portuguese and Spanish.\\nFor each language, there are 25+ functional tests that correspond to distinct types of hate and challenging non-hate.\\nThis allows for targeted diagnostic insights into model performance.\\nFor more‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Paul/hatecheck-dutch."},
	{"name":"hatecheck-arabic","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Paul/hatecheck-arabic","creator_name":"Paul R√∂ttger","creator_url":"https://huggingface.co/Paul","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Multilingual HateCheck\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nMultilingual HateCheck (MHC) is a suite of functional tests for hate speech detection models in 10 different languages: Arabic, Dutch, French, German, Hindi, Italian, Mandarin, Polish, Portuguese and Spanish.\\nFor each language, there are 25+ functional tests that correspond to distinct types of hate and challenging non-hate.\\nThis allows for targeted diagnostic insights into model performance.\\nFor more‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Paul/hatecheck-arabic."},
	{"name":"FLUTE","keyword":"monolingual","license":"Academic Free License v3.0","license_url":"https://choosealicense.com/licenses/afl-3.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ColumbiaNLP/FLUTE","creator_name":"Columbia University NLP Group","creator_url":"https://huggingface.co/ColumbiaNLP","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for FigLang2022SharedTask\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nModel in the loop approach for fig lang generation and explainability\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Structure\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Instances\\n\\t\\n\\n[More Information Needed]\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Fields\\n\\t\\n\\n[More Information Needed]\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Splits\\n\\t\\n\\n[More Information Needed]\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Creation\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tCuration Rationale\\n\\t\\n\\n[More Information Needed]\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSource Data\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tInitial Data‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ColumbiaNLP/FLUTE."},
	{"name":"unpredictable_5k","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/MicPie/unpredictable_5k","creator_name":"Michael Pieler","creator_url":"https://huggingface.co/MicPie","description":"The UnpredicTable dataset consists of web tables formatted as few-shot tasks for fine-tuning language models to improve their few-shot performance. For more details please see the accompanying dataset card."},
	{"name":"cultural_heritage_metadata_accuracy","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/biglam/cultural_heritage_metadata_accuracy","creator_name":"BigLAM: BigScience Libraries, Archives and Museums","creator_url":"https://huggingface.co/biglam","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Annotated dataset to assess the accuracy of the textual description of cultural heritage records\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThe dataset contains more than 100K textual descriptions of cultural items from Cultura Italia, the Italian National Cultural aggregator. Each of the description is labeled either HIGH or LOW quality, according its adherence to the standard cataloguing guidelines provided by Istituto Centrale per il Catalogo e la Documentazione (ICCD).‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/biglam/cultural_heritage_metadata_accuracy."},
	{"name":"unpredictable_unique","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/MicPie/unpredictable_unique","creator_name":"Michael Pieler","creator_url":"https://huggingface.co/MicPie","description":"The UnpredicTable dataset consists of web tables formatted as few-shot tasks for fine-tuning language models to improve their few-shot performance. For more details please see the accompanying dataset card."},
	{"name":"unpredictable_cluster-noise","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/MicPie/unpredictable_cluster-noise","creator_name":"Michael Pieler","creator_url":"https://huggingface.co/MicPie","description":"The UnpredicTable dataset consists of web tables formatted as few-shot tasks for fine-tuning language models to improve their few-shot performance. For more details please see the accompanying dataset card."},
	{"name":"unpredictable_cluster00","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/MicPie/unpredictable_cluster00","creator_name":"Michael Pieler","creator_url":"https://huggingface.co/MicPie","description":"The UnpredicTable dataset consists of web tables formatted as few-shot tasks for fine-tuning language models to improve their few-shot performance. For more details please see the accompanying dataset card."},
	{"name":"unpredictable_cluster01","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/MicPie/unpredictable_cluster01","creator_name":"Michael Pieler","creator_url":"https://huggingface.co/MicPie","description":"The UnpredicTable dataset consists of web tables formatted as few-shot tasks for fine-tuning language models to improve their few-shot performance. For more details please see the accompanying dataset card."},
	{"name":"unpredictable_cluster10","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/MicPie/unpredictable_cluster10","creator_name":"Michael Pieler","creator_url":"https://huggingface.co/MicPie","description":"The UnpredicTable dataset consists of web tables formatted as few-shot tasks for fine-tuning language models to improve their few-shot performance. For more details please see the accompanying dataset card."},
	{"name":"unpredictable_cluster11","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/MicPie/unpredictable_cluster11","creator_name":"Michael Pieler","creator_url":"https://huggingface.co/MicPie","description":"The UnpredicTable dataset consists of web tables formatted as few-shot tasks for fine-tuning language models to improve their few-shot performance. For more details please see the accompanying dataset card."},
	{"name":"unpredictable_cluster12","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/MicPie/unpredictable_cluster12","creator_name":"Michael Pieler","creator_url":"https://huggingface.co/MicPie","description":"The UnpredicTable dataset consists of web tables formatted as few-shot tasks for fine-tuning language models to improve their few-shot performance. For more details please see the accompanying dataset card."},
	{"name":"unpredictable_cluster13","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/MicPie/unpredictable_cluster13","creator_name":"Michael Pieler","creator_url":"https://huggingface.co/MicPie","description":"The UnpredicTable dataset consists of web tables formatted as few-shot tasks for fine-tuning language models to improve their few-shot performance. For more details please see the accompanying dataset card."},
	{"name":"unpredictable_cluster14","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/MicPie/unpredictable_cluster14","creator_name":"Michael Pieler","creator_url":"https://huggingface.co/MicPie","description":"The UnpredicTable dataset consists of web tables formatted as few-shot tasks for fine-tuning language models to improve their few-shot performance. For more details please see the accompanying dataset card."},
	{"name":"unpredictable_cluster15","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/MicPie/unpredictable_cluster15","creator_name":"Michael Pieler","creator_url":"https://huggingface.co/MicPie","description":"The UnpredicTable dataset consists of web tables formatted as few-shot tasks for fine-tuning language models to improve their few-shot performance. For more details please see the accompanying dataset card."},
	{"name":"unpredictable_cluster16","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/MicPie/unpredictable_cluster16","creator_name":"Michael Pieler","creator_url":"https://huggingface.co/MicPie","description":"The UnpredicTable dataset consists of web tables formatted as few-shot tasks for fine-tuning language models to improve their few-shot performance. For more details please see the accompanying dataset card."},
	{"name":"unpredictable_cluster17","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/MicPie/unpredictable_cluster17","creator_name":"Michael Pieler","creator_url":"https://huggingface.co/MicPie","description":"The UnpredicTable dataset consists of web tables formatted as few-shot tasks for fine-tuning language models to improve their few-shot performance. For more details please see the accompanying dataset card."},
	{"name":"unpredictable_cluster18","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/MicPie/unpredictable_cluster18","creator_name":"Michael Pieler","creator_url":"https://huggingface.co/MicPie","description":"The UnpredicTable dataset consists of web tables formatted as few-shot tasks for fine-tuning language models to improve their few-shot performance. For more details please see the accompanying dataset card."},
	{"name":"unpredictable_cluster19","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/MicPie/unpredictable_cluster19","creator_name":"Michael Pieler","creator_url":"https://huggingface.co/MicPie","description":"The UnpredicTable dataset consists of web tables formatted as few-shot tasks for fine-tuning language models to improve their few-shot performance. For more details please see the accompanying dataset card."},
	{"name":"unpredictable_cluster02","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/MicPie/unpredictable_cluster02","creator_name":"Michael Pieler","creator_url":"https://huggingface.co/MicPie","description":"The UnpredicTable dataset consists of web tables formatted as few-shot tasks for fine-tuning language models to improve their few-shot performance. For more details please see the accompanying dataset card."},
	{"name":"unpredictable_cluster20","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/MicPie/unpredictable_cluster20","creator_name":"Michael Pieler","creator_url":"https://huggingface.co/MicPie","description":"The UnpredicTable dataset consists of web tables formatted as few-shot tasks for fine-tuning language models to improve their few-shot performance. For more details please see the accompanying dataset card."},
	{"name":"unpredictable_cluster21","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/MicPie/unpredictable_cluster21","creator_name":"Michael Pieler","creator_url":"https://huggingface.co/MicPie","description":"The UnpredicTable dataset consists of web tables formatted as few-shot tasks for fine-tuning language models to improve their few-shot performance. For more details please see the accompanying dataset card."},
	{"name":"unpredictable_cluster22","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/MicPie/unpredictable_cluster22","creator_name":"Michael Pieler","creator_url":"https://huggingface.co/MicPie","description":"The UnpredicTable dataset consists of web tables formatted as few-shot tasks for fine-tuning language models to improve their few-shot performance. For more details please see the accompanying dataset card."},
	{"name":"unpredictable_cluster23","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/MicPie/unpredictable_cluster23","creator_name":"Michael Pieler","creator_url":"https://huggingface.co/MicPie","description":"The UnpredicTable dataset consists of web tables formatted as few-shot tasks for fine-tuning language models to improve their few-shot performance. For more details please see the accompanying dataset card."},
	{"name":"unpredictable_cluster24","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/MicPie/unpredictable_cluster24","creator_name":"Michael Pieler","creator_url":"https://huggingface.co/MicPie","description":"The UnpredicTable dataset consists of web tables formatted as few-shot tasks for fine-tuning language models to improve their few-shot performance. For more details please see the accompanying dataset card."},
	{"name":"unpredictable_cluster25","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/MicPie/unpredictable_cluster25","creator_name":"Michael Pieler","creator_url":"https://huggingface.co/MicPie","description":"The UnpredicTable dataset consists of web tables formatted as few-shot tasks for fine-tuning language models to improve their few-shot performance. For more details please see the accompanying dataset card."},
	{"name":"unpredictable_cluster26","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/MicPie/unpredictable_cluster26","creator_name":"Michael Pieler","creator_url":"https://huggingface.co/MicPie","description":"The UnpredicTable dataset consists of web tables formatted as few-shot tasks for fine-tuning language models to improve their few-shot performance. For more details please see the accompanying dataset card."},
	{"name":"unpredictable_cluster27","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/MicPie/unpredictable_cluster27","creator_name":"Michael Pieler","creator_url":"https://huggingface.co/MicPie","description":"The UnpredicTable dataset consists of web tables formatted as few-shot tasks for fine-tuning language models to improve their few-shot performance. For more details please see the accompanying dataset card."},
	{"name":"unpredictable_cluster28","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/MicPie/unpredictable_cluster28","creator_name":"Michael Pieler","creator_url":"https://huggingface.co/MicPie","description":"The UnpredicTable dataset consists of web tables formatted as few-shot tasks for fine-tuning language models to improve their few-shot performance. For more details please see the accompanying dataset card."},
	{"name":"unpredictable_cluster29","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/MicPie/unpredictable_cluster29","creator_name":"Michael Pieler","creator_url":"https://huggingface.co/MicPie","description":"The UnpredicTable dataset consists of web tables formatted as few-shot tasks for fine-tuning language models to improve their few-shot performance. For more details please see the accompanying dataset card."},
	{"name":"unpredictable_cluster03","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/MicPie/unpredictable_cluster03","creator_name":"Michael Pieler","creator_url":"https://huggingface.co/MicPie","description":"The UnpredicTable dataset consists of web tables formatted as few-shot tasks for fine-tuning language models to improve their few-shot performance. For more details please see the accompanying dataset card."},
	{"name":"unpredictable_cluster04","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/MicPie/unpredictable_cluster04","creator_name":"Michael Pieler","creator_url":"https://huggingface.co/MicPie","description":"The UnpredicTable dataset consists of web tables formatted as few-shot tasks for fine-tuning language models to improve their few-shot performance. For more details please see the accompanying dataset card."},
	{"name":"unpredictable_cluster05","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/MicPie/unpredictable_cluster05","creator_name":"Michael Pieler","creator_url":"https://huggingface.co/MicPie","description":"The UnpredicTable dataset consists of web tables formatted as few-shot tasks for fine-tuning language models to improve their few-shot performance. For more details please see the accompanying dataset card."},
	{"name":"unpredictable_cluster06","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/MicPie/unpredictable_cluster06","creator_name":"Michael Pieler","creator_url":"https://huggingface.co/MicPie","description":"The UnpredicTable dataset consists of web tables formatted as few-shot tasks for fine-tuning language models to improve their few-shot performance. For more details please see the accompanying dataset card."},
	{"name":"unpredictable_cluster07","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/MicPie/unpredictable_cluster07","creator_name":"Michael Pieler","creator_url":"https://huggingface.co/MicPie","description":"The UnpredicTable dataset consists of web tables formatted as few-shot tasks for fine-tuning language models to improve their few-shot performance. For more details please see the accompanying dataset card."},
	{"name":"unpredictable_cluster08","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/MicPie/unpredictable_cluster08","creator_name":"Michael Pieler","creator_url":"https://huggingface.co/MicPie","description":"The UnpredicTable dataset consists of web tables formatted as few-shot tasks for fine-tuning language models to improve their few-shot performance. For more details please see the accompanying dataset card."},
	{"name":"unpredictable_cluster09","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/MicPie/unpredictable_cluster09","creator_name":"Michael Pieler","creator_url":"https://huggingface.co/MicPie","description":"The UnpredicTable dataset consists of web tables formatted as few-shot tasks for fine-tuning language models to improve their few-shot performance. For more details please see the accompanying dataset card."},
	{"name":"test_pq","keyword":"monolingual","license":"Academic Free License v3.0","license_url":"https://choosealicense.com/licenses/afl-3.0/","language":"en","dataset_url":"https://huggingface.co/datasets/changxin/test_pq","creator_name":"changxin","creator_url":"https://huggingface.co/changxin","description":"This is a test dataset."},
	{"name":"unpredictable_rated-low","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/MicPie/unpredictable_rated-low","creator_name":"Michael Pieler","creator_url":"https://huggingface.co/MicPie","description":"The UnpredicTable dataset consists of web tables formatted as few-shot tasks for fine-tuning language models to improve their few-shot performance. For more details please see the accompanying dataset card."},
	{"name":"unpredictable_rated-medium","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/MicPie/unpredictable_rated-medium","creator_name":"Michael Pieler","creator_url":"https://huggingface.co/MicPie","description":"The UnpredicTable dataset consists of web tables formatted as few-shot tasks for fine-tuning language models to improve their few-shot performance. For more details please see the accompanying dataset card."},
	{"name":"unpredictable_rated-high","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/MicPie/unpredictable_rated-high","creator_name":"Michael Pieler","creator_url":"https://huggingface.co/MicPie","description":"The UnpredicTable dataset consists of web tables formatted as few-shot tasks for fine-tuning language models to improve their few-shot performance. For more details please see the accompanying dataset card."},
	{"name":"ro-fb-offense","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/readerbench/ro-fb-offense","creator_name":"ReaderBench","creator_url":"https://huggingface.co/readerbench","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for \\\"RO-FB-Offense\\\"\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nFB-RO-Offense corpus, an offensive speech dataset containing 4,455 user-generated comments from Facebook live broadcasts available in Romanian\\nThe annotation follows the hierarchical tagset proposed in the Germeval 2018 Dataset. \\nThe following Classes are available:\\n\\nOTHER: Non-Offensive Language\\nOFFENSIVE:\\nPROFANITY\\nINSULT\\nABUSE\\n\\n\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages\\n\\t\\n\\nRomanian\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Structure\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/readerbench/ro-fb-offense."},
	{"name":"aeslc_kw","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/postbot/aeslc_kw","creator_name":"postbot","creator_url":"https://huggingface.co/postbot","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tabout\\n\\t\\n\\n\\naeslc dataset but cleaned and keywords extracted to a new column\\nan EDA website generated via pandas profiling is on netlify here\\n\\nDatasetDict({\\n    train: Dataset({\\n        features: ['email_body', 'subject_line', 'clean_email', 'clean_email_keywords'],\\n        num_rows: 14436\\n    })\\n    test: Dataset({\\n        features: ['email_body', 'subject_line', 'clean_email', 'clean_email_keywords'],\\n        num_rows: 1906\\n    })\\n    validation: Dataset({\\n        features:‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/postbot/aeslc_kw."},
	{"name":"atypical_animacy","keyword":"monolingual","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/biglam/atypical_animacy","creator_name":"BigLAM: BigScience Libraries, Archives and Museums","creator_url":"https://huggingface.co/biglam","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for atypical_animacy\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nAtypical animacy detection dataset, based on nineteenth-century sentences in English extracted from an open dataset of nineteenth-century books digitized by the British Library. This dataset contains 598 sentences containing mentions of machines. Each sentence has been annotated according to the animacy and humanness of the machine in the sentence. \\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSupported Tasks and Leaderboards‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/biglam/atypical_animacy."},
	{"name":"SQuAD_v2_fi","keyword":"monolingual","license":"GNU General Public License v3.0","license_url":"https://choosealicense.com/licenses/gpl-3.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ilmariky/SQuAD_v2_fi","creator_name":"Ilmari Kylli√§inen","creator_url":"https://huggingface.co/ilmariky","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for \\\"squad-v2-fi\\\"\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nMachine translated and normalized Finnish version of the SQuAD-v2.0 dataset. Details about the translation and normalization processes can be found here.\\nStanford Question Answering Dataset (SQuAD) is a reading comprehension dataset, consisting of questions posed by crowdworkers on a set of Wikipedia articles, where the answer to every question is a segment of text, or span, from the corresponding reading passage, or‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ilmariky/SQuAD_v2_fi."},
	{"name":"WikiQA-100-fi","keyword":"monolingual","license":"GNU General Public License v3.0","license_url":"https://choosealicense.com/licenses/gpl-3.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ilmariky/WikiQA-100-fi","creator_name":"Ilmari Kylli√§inen","creator_url":"https://huggingface.co/ilmariky","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for \\\"WikiQA-100-fi\\\"\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nWikiQA-100-fi dataset contains 100 questions related to Finnish Wikipedia articles. The dataset is in the SQuAD format, and there are 10 questions for each category identified by the authors of SQuAD. Unlike SQuAD2.0, WikiQA-100-fi contains only answerable questions. The dataset is tiny compared to actual QA test sets, but it still gives an impression of the models' performance on purely native text data collected‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ilmariky/WikiQA-100-fi."},
	{"name":"KcBERT_Pre-Training_Corpus","keyword":"monolingual","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Bingsu/KcBERT_Pre-Training_Corpus","creator_name":"Dowon Hwang","creator_url":"https://huggingface.co/Bingsu","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tKcBERT Pre-Training Corpus (Korean News Comments)\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tKcBERT\\n\\t\\n\\nbeomi/kcbert-base\\nGithub KcBERT Repo:¬†https://github.com/Beomi/KcBERTKcBERT is Korean Comments BERT pretrained on this Corpus set.(You can use it via Huggingface's Transformers library!)\\nThis Kaggle Dataset contains¬†CLEANED¬†dataset preprocessed with the code below.\\nimport re\\nimport emoji\\nfrom soynlp.normalizer import repeat_normalize\\n\\nemojis = ''.join(emoji.UNICODE_EMOJI.keys())\\npattern = re.compile(f'[^ .‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Bingsu/KcBERT_Pre-Training_Corpus."},
	{"name":"understanding_fables","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/demelin/understanding_fables","creator_name":"Denis Emelin","creator_url":"https://huggingface.co/demelin","description":"This task aims to measure the ability of computational models to understand short narratives, by identifying the most \\nappropriate moral for a given fable from a set of five alternatives."},
	{"name":"lotte","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/colbertv2/lotte","creator_name":"colbertv2","creator_url":"https://huggingface.co/colbertv2","description":"LoTTE Passages Dataset for ColBERTv2"},
	{"name":"FR_NFR_Spanish_requirements_classification","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/MariaIsabel/FR_NFR_Spanish_requirements_classification","creator_name":"Maria Isabel Limaylla Lunarejo","creator_url":"https://huggingface.co/MariaIsabel","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nReSpa: Published version of dataset used for paper 'Towards an automatic requirements classification in a new Spanish dataset'\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages\\n\\t\\n\\nSpanish\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Structure\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Fields\\n\\t\\n\\nProject: Project's Identifier from which the requirements were obtained.\\nRequirement: Description of the software requirement.\\nFinal label: Label of the requirement: F (functional requirement) and NF (non-functional requirement).‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/MariaIsabel/FR_NFR_Spanish_requirements_classification."},
	{"name":"fin","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/tner/fin","creator_name":"TNER","creator_url":"https://huggingface.co/tner","description":"[FIN NER dataset](https://aclanthology.org/U15-1010.pdf)"},
	{"name":"old_bailey_proceedings","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/biglam/old_bailey_proceedings","creator_name":"BigLAM: BigScience Libraries, Archives and Museums","creator_url":"https://huggingface.co/biglam","description":"[Needs More Information]\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Old Bailey Proceedings\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nNote We are making this dataset available via the HuggingFace hub to open it up to more users and use cases. We have focused primarily on making an initial version of this dataset available, focusing on some potential use cases. If you think there are other configurations this dataset should support, please use the community tab to open an issue. \\nThe dataset consists of 2,163‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/biglam/old_bailey_proceedings."},
	{"name":"clmet_3_1","keyword":"monolingual","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/biglam/clmet_3_1","creator_name":"BigLAM: BigScience Libraries, Archives and Museums","creator_url":"https://huggingface.co/biglam","description":"The Corpus of Late Modern English Texts, version 3.1 (CLMET3.1) has been created by Hendrik De Smet, \\nSusanne Flach, Hans-J√ºrgen Diller and Jukka Tyrkk√∂, as an offshoot of a bigger project developing a database of text \\ndescriptors (Diller, De Smet & Tyrkk√∂ 2011). CLMET3.1 is a principled collection of public domain texts drawn from \\nvarious online archiving projects. This dataset can be used for part-of-speech tagging, NER and text classification"},
	{"name":"mbpp","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Muennighoff/mbpp","creator_name":"Niklas Muennighoff","creator_url":"https://huggingface.co/Muennighoff","description":"The MBPP (Mostly Basic Python Problems) dataset consists of around 1,000 crowd-sourced Python\\nprogramming problems, designed to be solvable by entry level programmers, covering programming\\nfundamentals, standard library functionality, and so on. Each problem consists of a task\\ndescription, code solution and 3 automated test cases."},
	{"name":"ShahNegar","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/sadrasabouri/ShahNegar","creator_name":"Sadra Sabouri","creator_url":"https://huggingface.co/sadrasabouri","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tShahNegar (A Plotted version of The Shahnameh)\\n\\t\\n\\nThis dataset is a plotted version of Ferdowsi's Shahnameh (which is a highly-regarded ancient set of Farsi poems) generated using DALL-E mini (aka craiyon). You can use this dataset using the code below: \\nfrom datasets import load_dataset\\n\\ndataset = load_dataset(\\\"sadrasabouri/ShahNegar\\\")\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThis dataset contains more than 30K images with their corresponding text from the Shahnameh. For each Shahnameh‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/sadrasabouri/ShahNegar."},
	{"name":"Piyyut","keyword":"monolingual","license":"Academic Free License v3.0","license_url":"https://choosealicense.com/licenses/afl-3.0/","language":"en","dataset_url":"https://huggingface.co/datasets/tokeron/Piyyut","creator_name":"Michael Toker","creator_url":"https://huggingface.co/tokeron","description":""},
	{"name":"NERDE","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Gpaiva/NERDE","creator_name":"Guilherme Pereira Paiva","creator_url":"https://huggingface.co/Gpaiva","description":"(pt) NERDE √© um dataset para NER a partir de documentos jur√≠dicos da defesa econ√¥mica em portugu√™s do Brasil, foi criado em colabora√ß√£o com o Cade e o laborat√≥rio LATITUDE/UnB.\\n(en) NERDE is a NER dataset from economic defense legal documents in Brazilian Portuguese, created in collaboration with Cade and the LATITUDE/UnB laboratory."},
	{"name":"hansard_speech","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/biglam/hansard_speech","creator_name":"BigLAM: BigScience Libraries, Archives and Museums","creator_url":"https://huggingface.co/biglam","description":"A dataset containing every speech in the House of Commons from May 1979-July 2020."},
	{"name":"reddit-r-bitcoin-data-for-jun-2022","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/SocialGrep/reddit-r-bitcoin-data-for-jun-2022","creator_name":"SocialGrep","creator_url":"https://huggingface.co/SocialGrep","description":"Lite version of our Reddit /r/Bitcoin dataset - CSV of all posts & comments to the /r/Bitcoin subreddit over Jun 2022."},
	{"name":"news-data","keyword":"monolingual","license":"Academic Free License v3.0","license_url":"https://choosealicense.com/licenses/afl-3.0/","language":"en","dataset_url":"https://huggingface.co/datasets/okite97/news-data","creator_name":"Okite Chimaobi Samuel","creator_url":"https://huggingface.co/okite97","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for news-data\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThe News Dataset is an English-language dataset containing just over 4k unique news articles scrapped from AriseTv- One of the most popular news television in Nigeria. \\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSupported Tasks and Leaderboards\\n\\t\\n\\nIt supports news article classification into different categories.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages\\n\\t\\n\\nEnglish\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Structure\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Instances\\n\\t\\n\\n'''\\n{'Title': 'Nigeria: APC Yet to Zone Party‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/okite97/news-data."},
	{"name":"laion2B-multi-korean-subset","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Bingsu/laion2B-multi-korean-subset","creator_name":"Dowon Hwang","creator_url":"https://huggingface.co/Bingsu","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tlaion2B-multi-korean-subset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tAbout dataset\\n\\t\\n\\na subset data of laion/laion2B-multi, including only korean\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLisence\\n\\t\\n\\nCC-BY-4.0\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Structure\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Instance\\n\\t\\n\\n>>> from datasets import load_dataset\\n>>> dataset = load_dataset(\\\"Bingsu/laion2B-multi-korean-subset\\\")\\n>>> dataset\\nDatasetDict({\\n    train: Dataset({\\n        features: ['SAMPLE_ID', 'URL', 'TEXT', 'HEIGHT', 'WIDTH', 'LICENSE', 'LANGUAGE', 'NSFW', 'similarity']‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Bingsu/laion2B-multi-korean-subset."},
	{"name":"filtered-cuad","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/alex-apostolo/filtered-cuad","creator_name":"Alex Apostolopoulos","creator_url":"https://huggingface.co/alex-apostolo","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for filtered_cuad\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nContract Understanding Atticus Dataset (CUAD) v1 is a corpus of more than 13,000 labels in 510 commercial legal contracts that have been manually labeled to identify 41 categories of important clauses that lawyers look for when reviewing contracts in connection with corporate transactions. This dataset is a filtered version of CUAD. It excludes legal contracts with an Agreement date prior to 2002 and contracts which‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/alex-apostolo/filtered-cuad."},
	{"name":"google-play-review","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/jakartaresearch/google-play-review","creator_name":"Jakarta AI Research","creator_url":"https://huggingface.co/jakartaresearch","description":"This dataset is built as a playground for beginner to make a use case for creating sentiment analysis model."},
	{"name":"indonews","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/jakartaresearch/indonews","creator_name":"Jakarta AI Research","creator_url":"https://huggingface.co/jakartaresearch","description":"This dataset is built as a playground for beginner to make a use case for creating sentiment analysis model."},
	{"name":"poem-tweets","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/jakartaresearch/poem-tweets","creator_name":"Jakarta AI Research","creator_url":"https://huggingface.co/jakartaresearch","description":"This dataset is built for text generation task in context of poem tweets in Bahasa."},
	{"name":"DBPedia_Classes","keyword":"monolingual","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/DeveloperOats/DBPedia_Classes","creator_name":"Willem","creator_url":"https://huggingface.co/DeveloperOats","description":"About Dataset\\nDBpedia (from \\\"DB\\\" for \\\"database\\\") is a project aiming to extract structured content from the information created in Wikipedia.\\nThis is an extract of the data (after cleaning, kernel included) that provides taxonomic, hierarchical categories (\\\"classes\\\") for 342,782 wikipedia articles. There are 3 levels, with 9, 70 and 219 classes respectively.\\nA version of this dataset is a popular baseline for NLP/text classification tasks. This version of the dataset is much tougher‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/DeveloperOats/DBPedia_Classes."},
	{"name":"Million_News_Headlines","keyword":"monolingual","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/DeveloperOats/Million_News_Headlines","creator_name":"Willem","creator_url":"https://huggingface.co/DeveloperOats","description":"About Dataset\\nContext\\nThis contains data of news headlines published over a period of nineteen years.\\nSourced from the reputable Australian news source ABC (Australian Broadcasting Corporation)\\nAgency Site: (http://www.abc.net.au)\\nContent\\nFormat: CSV ; Single File\\npublish_date: Date of publishing for the article in yyyyMMdd format\\nheadline_text: Text of the headline in Ascii , English , lowercase\\n\\nStart Date: 2003-02-19 ; End Date: 2021-12-31\\nInspiration\\nI look at this news dataset as a‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/DeveloperOats/Million_News_Headlines."},
	{"name":"cerpen-corpus","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/jakartaresearch/cerpen-corpus","creator_name":"Jakarta AI Research","creator_url":"https://huggingface.co/jakartaresearch","description":"This dataset is built as a playground for beginner to make a use case for creating sentiment analysis model."},
	{"name":"ludwig","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/UCL-DARK/ludwig","creator_name":"UCL DARK","creator_url":"https://huggingface.co/UCL-DARK","description":"TODO"},
	{"name":"news-title-gen","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/jakartaresearch/news-title-gen","creator_name":"Jakarta AI Research","creator_url":"https://huggingface.co/jakartaresearch","description":"This dataset is built for generating text for news title."},
	{"name":"id-paraphrase-detection","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/jakartaresearch/id-paraphrase-detection","creator_name":"Jakarta AI Research","creator_url":"https://huggingface.co/jakartaresearch","description":"This dataset is built as a playground for sequence to sequence classification"},
	{"name":"semeval-absa","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/jakartaresearch/semeval-absa","creator_name":"Jakarta AI Research","creator_url":"https://huggingface.co/jakartaresearch","description":"This dataset is built as a playground for aspect-based sentiment analysis."},
	{"name":"sentinews","keyword":"monolingual","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/cjvt/sentinews","creator_name":"Center za jezikovne vire in tehnologije Univerze v Ljubljani","creator_url":"https://huggingface.co/cjvt","description":"SentiNews is a Slovenian sentiment classification dataset, consisting of news articles manually annotated with their \\nsentiment by between 2 and 6 annotators. The news articles contain political, business, economic and financial content \\nfrom the Slovenian news portals 24ur, Dnevnik, Finance, Rtvslo, and ≈Ωurnal24. The texts were annotated using the \\nfive-level Lickert scale (1 ‚Äì very negative, 2 ‚Äì negative, 3 ‚Äì neutral, 4 ‚Äì positive, and 5 ‚Äì very positive) on three \\nlevels of granularity, i.e. on the document, paragraph, and sentence level. The final sentiment is determined using \\nthe following criterion: negative (if average of scores ‚â§ 2.4); neutral (if average of scores is between 2.4 and 3.6); \\npositive (average of annotated scores ‚â• 3.6)."},
	{"name":"indo-movie-subtitle","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/jakartaresearch/indo-movie-subtitle","creator_name":"Jakarta AI Research","creator_url":"https://huggingface.co/jakartaresearch","description":"This dataset is built as a playground for analyzing text on movie subtitle"},
	{"name":"bold","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/AlexaAI/bold","creator_name":"Alexa AI","creator_url":"https://huggingface.co/AlexaAI","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Bias in Open-ended Language Generation Dataset (BOLD)\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nBias in Open-ended Language Generation Dataset (BOLD) is a dataset to evaluate fairness in open-ended language generation in English language. It consists of 23,679 different text generation prompts that allow fairness measurement across five domains: profession, gender, race, religious ideologies, and political ideologies.\\n Some examples of prompts in BOLD are as follows:‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/AlexaAI/bold."},
	{"name":"wildfire_tweets","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/rubrix/wildfire_tweets","creator_name":"rubrix","creator_url":"https://huggingface.co/rubrix","description":"rubrix/wildfire_tweets dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"openai-tldr-summarisation-preferences","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/UCL-DARK/openai-tldr-summarisation-preferences","creator_name":"UCL DARK","creator_url":"https://huggingface.co/UCL-DARK","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tHuman feedback data\\n\\t\\n\\nThis is the version of the dataset used in https://arxiv.org/abs/2310.06452.\\nIf starting a new project we would recommend using https://huggingface.co/datasets/openai/summarize_from_feedback.\\nSee https://github.com/openai/summarize-from-feedback for original details of the dataset.\\nHere the data is formatted to enable huggingface transformers sequence classification models to be trained as reward functions.\\n"},
	{"name":"scientific-exaggeration-detection","keyword":"monolingual","license":"GNU General Public License v3.0","license_url":"https://choosealicense.com/licenses/gpl-3.0/","language":"en","dataset_url":"https://huggingface.co/datasets/copenlu/scientific-exaggeration-detection","creator_name":"CopeNLU","creator_url":"https://huggingface.co/copenlu","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Scientific Exaggeration Detection\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nPublic trust in science depends on honest and factual communication of scientific papers. However, recent studies have demonstrated a tendency of news media to misrepresent scientific papers by exaggerating their findings. Given this, we present a formalization of and study into the problem of exaggeration detection in science communication. While there are an abundance of scientific papers and‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/copenlu/scientific-exaggeration-detection."},
	{"name":"openai-tldr-filtered","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/UCL-DARK/openai-tldr-filtered","creator_name":"UCL DARK","creator_url":"https://huggingface.co/UCL-DARK","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tFiltered TL;DR Dataset\\n\\t\\n\\nThis is the version of the dataset used in https://arxiv.org/abs/2310.06452.\\nIf starting a new project we would recommend using https://huggingface.co/datasets/openai/summarize_from_feedback.\\nFor more information see https://github.com/openai/summarize-from-feedback and for the original TL;DR dataset see https://zenodo.org/record/1168855#.YvzwJexudqs\\n"},
	{"name":"COCO","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Luka-Wang/COCO","creator_name":"Wang Yanghao","creator_url":"https://huggingface.co/Luka-Wang","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for [COCO]\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\n[More Information Needed]\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSupported Tasks and Leaderboards\\n\\t\\n\\n[More Information Needed]\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages\\n\\t\\n\\n[More Information Needed]\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Structure\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Instances\\n\\t\\n\\n[More Information Needed]\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Fields\\n\\t\\n\\n[More Information Needed]\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Splits\\n\\t\\n\\n[More Information Needed]\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Creation\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tCuration Rationale\\n\\t\\n\\n[More‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Luka-Wang/COCO."},
	{"name":"openai-tldr-filtered-queries","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/UCL-DARK/openai-tldr-filtered-queries","creator_name":"UCL DARK","creator_url":"https://huggingface.co/UCL-DARK","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tFiltered TL;DR Dataset\\n\\t\\n\\nThis is the version of the dataset used in https://arxiv.org/abs/2310.06452.\\nIf starting a new project we would recommend using https://huggingface.co/datasets/openai/summarize_from_feedback.\\nFor more information see https://github.com/openai/summarize-from-feedback and for the original TL;DR dataset see https://zenodo.org/record/1168855#.YvzwJexudqs\\nThis is the version of the dataset with only filtering on the queries, and hence there is more data than in‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/UCL-DARK/openai-tldr-filtered-queries."},
	{"name":"naab","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/SLPL/naab","creator_name":"Speech and Language Processing Lab - Sharif University Of Technology","creator_url":"https://huggingface.co/SLPL","description":"Huge corpora of textual data are always known to be a crucial need for training deep models such as transformer-based ones. This issue is emerging more in lower resource languages - like Farsi. We propose naab, the biggest cleaned and ready-to-use open-source textual corpus in Farsi. It contains about 130GB of data, 250 million paragraphs, and 15 billion words. The project name is derived from the Farsi word ŸÜÿßÿ® which means pure and high-grade."},
	{"name":"EstCOPA","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/tartuNLP/EstCOPA","creator_name":"TartuNLP","creator_url":"https://huggingface.co/tartuNLP","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for EstCOPA\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nEstCOPA is an extended version of XCOPA that was created with a goal to further investigate Estonian language understanding of large language models. EstCOPA provides two new versions of train, eval and test datasets in Estonian: firstly, a machine translated (En->Et) version of original English COPA (Roemmele et al., 2011)  and secondly, a manually post-edited version of the same machine translated data.‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/tartuNLP/EstCOPA."},
	{"name":"codequeries","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/thepurpleowl/codequeries","creator_name":"Surya Prakash Sahu","creator_url":"https://huggingface.co/thepurpleowl","description":"CodeQueries Ideal setup."},
	{"name":"eurlex","keyword":"monolingual","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/jonathanli/eurlex","creator_name":"Jonathan Li","creator_url":"https://huggingface.co/jonathanli","description":"EURLEX57K contains 57k legislative documents in English from EUR-Lex portal, annotated with EUROVOC concepts."},
	{"name":"Gameplay_Images","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Bingsu/Gameplay_Images","creator_name":"Dowon Hwang","creator_url":"https://huggingface.co/Bingsu","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tGameplay Images\\n\\t\\n\\nA dataset from kaggle.\\nThis is a dataset of 10 very famous video games in the world.\\nThese include\\n\\nAmong Us\\nApex Legends\\nFortnite\\nForza Horizon\\nFree Fire\\nGenshin Impact\\nGod of War\\nMinecraft\\nRoblox\\nTerraria\\n\\nThere are 1000 images per class and all are sized 640 x 360. They are in the .png format.\\nThis Dataset was made by saving frames every few seconds from famous gameplay videos on Youtube.\\n‚Äª This dataset was uploaded in January 2022. Game content updated after‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Bingsu/Gameplay_Images."},
	{"name":"clip-bert-data","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Lo/clip-bert-data","creator_name":"Lovisa Hagstrom","creator_url":"https://huggingface.co/Lo","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tCLIP-BERT training data\\n\\t\\n\\nThis data was used to train the CLIP-BERT model first described in this paper. \\nThe dataset is based on text and images from MS COCO, SBU Captions, Visual Genome QA and Conceptual Captions.\\nThe image features have been extracted using the CLIP model openai/clip-vit-base-patch32 available on Huggingface.\\n"},
	{"name":"ms2_sparse_max","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/allenai/ms2_sparse_max","creator_name":"Ai2","creator_url":"https://huggingface.co/allenai","description":"This is a copy of the MS^2 dataset, except the input source documents of its validation split have been replaced by a sparse retriever. The retrieval pipeline used:\\n\\nquery: The background field of each example\\ncorpus: The union of all documents in the train, validation and test splits. A document is the concatenation of the title and abstract.\\nretriever: BM25 via PyTerrier with default settings\\ntop-k strategy: \\\"max\\\", i.e. the number of documents retrieved, k, is set as the maximum number of‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/allenai/ms2_sparse_max."},
	{"name":"ms2_sparse_mean","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/allenai/ms2_sparse_mean","creator_name":"Ai2","creator_url":"https://huggingface.co/allenai","description":"This is a copy of the MS^2 dataset, except the input source documents of its validation split have been replaced by a sparse retriever. The retrieval pipeline used:\\n\\nquery: The background field of each example\\ncorpus: The union of all documents in the train, validation and test splits. A document is the concatenation of the title and abstract.\\nretriever: BM25 via PyTerrier with default settings\\ntop-k strategy: \\\"mean\\\", i.e. the number of documents retrieved, k, is set as the mean number of‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/allenai/ms2_sparse_mean."},
	{"name":"ms2_sparse_oracle","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/allenai/ms2_sparse_oracle","creator_name":"Ai2","creator_url":"https://huggingface.co/allenai","description":"This is a copy of the MS^2 dataset, except the input source documents of its validation split have been replaced by a sparse retriever. The retrieval pipeline used:\\n\\nquery: The background field of each example\\ncorpus: The union of all documents in the train, validation and test splits. A document is the concatenation of the title and abstract.\\nretriever: BM25 via PyTerrier with default settings\\ntop-k strategy: \\\"oracle\\\", i.e. the number of documents retrieved, k, is set as the original number‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/allenai/ms2_sparse_oracle."},
	{"name":"unpredictable_full","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/unpredictable/unpredictable_full","creator_name":"unpredictable","creator_url":"https://huggingface.co/unpredictable","description":"The UnpredicTable dataset consists of web tables formatted as few-shot tasks for fine-tuning language models to improve their few-shot performance. For more details please see the accompanying dataset card."},
	{"name":"unpredictable_5k","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/unpredictable/unpredictable_5k","creator_name":"unpredictable","creator_url":"https://huggingface.co/unpredictable","description":"The UnpredicTable dataset consists of web tables formatted as few-shot tasks for fine-tuning language models to improve their few-shot performance. For more details please see the accompanying dataset card."},
	{"name":"unpredictable_support-google-com","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/unpredictable/unpredictable_support-google-com","creator_name":"unpredictable","creator_url":"https://huggingface.co/unpredictable","description":"The UnpredicTable dataset consists of web tables formatted as few-shot tasks for fine-tuning language models to improve their few-shot performance. For more details please see the accompanying dataset card."},
	{"name":"unpredictable_unique","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/unpredictable/unpredictable_unique","creator_name":"unpredictable","creator_url":"https://huggingface.co/unpredictable","description":"The UnpredicTable dataset consists of web tables formatted as few-shot tasks for fine-tuning language models to improve their few-shot performance. For more details please see the accompanying dataset card."},
	{"name":"adapt-pre-trained-VL-models-to-text-data-LXMERT","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Lo/adapt-pre-trained-VL-models-to-text-data-LXMERT","creator_name":"Lovisa Hagstrom","creator_url":"https://huggingface.co/Lo","description":"The LXMERT text train data used to train BERT-base baselines and adapt vision-and-language models to text-only tasks in the paper \\\"How to Adapt Pre-trained Vision-and-Language Models to a Text-only Input?\\\".\\nThe data has been created from the data made available by the LXMERT repo.\\n"},
	{"name":"adapt-pre-trained-VL-models-to-text-data-LXMERT-finetune","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Lo/adapt-pre-trained-VL-models-to-text-data-LXMERT-finetune","creator_name":"Lovisa Hagstrom","creator_url":"https://huggingface.co/Lo","description":"The LXMERT text finetune data used to train visual features for the adaption of vision-and-language models to text-only tasks in the paper \\\"How to Adapt Pre-trained Vision-and-Language Models to a Text-only Input?\\\".\\nThe data has been created from the data made available by the LXMERT repo.\\n"},
	{"name":"blogspot_raw","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/mschi/blogspot_raw","creator_name":"Martin Schirmer","creator_url":"https://huggingface.co/mschi","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for blogspot raw dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThis dataset is a corpus of raw blogposts from blogspot mostly in the English language. It was obtained by scraping corpora of webarchive and commoncrawl.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSupported Tasks and Leaderboards\\n\\t\\n\\nThe dataset may be used for training language models or serve other research interests.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages\\n\\t\\n\\nMostly English language, but some outliers may occur.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Structure‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mschi/blogspot_raw."},
	{"name":"glue-ci","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/evaluate/glue-ci","creator_name":"evaluate","creator_url":"https://huggingface.co/evaluate","description":"GLUE, the General Language Understanding Evaluation benchmark\\n(https://gluebenchmark.com/) is a collection of resources for training,\\nevaluating, and analyzing natural language understanding systems."},
	{"name":"VaccinChatNL","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/clips/VaccinChatNL","creator_name":"CLiPS","creator_url":"https://huggingface.co/clips","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for VaccinChatNL\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\n\\n\\nPoint of Contact:  Jeska Buhmann\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nVaccinChatNL is a Flemish Dutch FAQ dataset on the topic of COVID-19 vaccinations in Flanders. It consists of 12,833 user questions divided over 181 answer labels, thus providing large groups of semantically equivalent paraphrases (a many-to-one mapping of user questions to answer labels). VaccinChatNL is the first Dutch many-to-one FAQ dataset of‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/clips/VaccinChatNL."},
	{"name":"ord-uniq-canonicalized","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/sagawa/ord-uniq-canonicalized","creator_name":"Tatsuya Sagawa","creator_url":"https://huggingface.co/sagawa","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tdataset description\\n\\t\\n\\nWe downloaded open-reaction-database(ORD) dataset from here. As a preprocess, we removed overlapping data and canonicalized them using RDKit.\\nWe used the following function to canonicalize the data and removed some SMILES that cannot be read by RDKit.\\nfrom rdkit import Chem\\ndef canonicalize(mol):\\n    mol = Chem.MolToSmiles(Chem.MolFromSmiles(mol),True)\\n    return mol \\n\\nWe randomly split the preprocessed data into train, validation and test. The ratio is 8:1:1.\\n"},
	{"name":"pubchem-10m-canonicalized","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/sagawa/pubchem-10m-canonicalized","creator_name":"Tatsuya Sagawa","creator_url":"https://huggingface.co/sagawa","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tdataset description\\n\\t\\n\\nWe downloaded PubChem-10m dataset from here and canonicalized it.\\nWe used the following function to canonicalize the data and removed some SMILES that cannot be read by RDKit.\\nfrom rdkit import Chem\\ndef canonicalize(mol):\\n    mol = Chem.MolToSmiles(Chem.MolFromSmiles(mol),True)\\n    return mol \\n\\nWe randomly split the preprocessed data into train and validation. The ratio is 9 : 1.\\n"},
	{"name":"ZINC-canonicalized","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/sagawa/ZINC-canonicalized","creator_name":"Tatsuya Sagawa","creator_url":"https://huggingface.co/sagawa","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tdataset description\\n\\t\\n\\nWe downloaded ZINC dataset from here and canonicalized it.\\nWe used the following function to canonicalize the data and removed some SMILES that cannot be read by RDKit.\\nfrom rdkit import Chem\\ndef canonicalize(mol):\\n    mol = Chem.MolToSmiles(Chem.MolFromSmiles(mol),True)\\n    return mol \\n\\nWe randomly split the preprocessed data into train and validation. The ratio is 9 : 1.\\n"},
	{"name":"biosses","keyword":"monolingual","license":"GNU General Public License v3.0","license_url":"https://choosealicense.com/licenses/gpl-3.0/","language":"en","dataset_url":"https://huggingface.co/datasets/bigbio/biosses","creator_name":"BigScience Biomedical Datasets","creator_url":"https://huggingface.co/bigbio","description":"BIOSSES computes similarity of biomedical sentences by utilizing WordNet as the\\ngeneral domain ontology and UMLS as the biomedical domain specific ontology.\\nThe original paper outlines the approaches with respect to using annotator\\nscore as golden standard. Source view will return all annotator score\\nindividually whereas the Bigbio view will return the mean of the annotator\\nscore."},
	{"name":"clinical_trial_reason_to_stop","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/opentargets/clinical_trial_reason_to_stop","creator_name":"Open Targets","creator_url":"https://huggingface.co/opentargets","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Clinical Trials's Reason to Stop\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThis dataset contains a curated classification of more than 5000 reasons why a clinical trial has suffered an early stop.\\nThe text has been extracted from clinicaltrials.gov, the largest resource of clinical trial information. The text has been curated by members of the Open Targets organisation, a project aimed at providing data relevant to drug development.\\nAll 17 possible classes have been‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/opentargets/clinical_trial_reason_to_stop."},
	{"name":"cuad_qa","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/chenghao/cuad_qa","creator_name":"Chenghao Mou","creator_url":"https://huggingface.co/chenghao","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for CUAD\\n\\t\\n\\nThis is a modified version of original CUAD which trims the question to its label form.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nContract Understanding Atticus Dataset (CUAD) v1 is a corpus of more than 13,000 labels in 510 commercial legal contracts that have been manually labeled to identify 41 categories of important clauses that lawyers look for when reviewing contracts in connection with corporate transactions.\\nCUAD is curated and maintained by The Atticus‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/chenghao/cuad_qa."},
	{"name":"cochrane_sparse_max","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/allenai/cochrane_sparse_max","creator_name":"Ai2","creator_url":"https://huggingface.co/allenai","description":"This is a copy of the Cochrane dataset, except the input source documents of its validation split have been replaced by a sparse retriever. The retrieval pipeline used:\\n\\nquery: The target field of each example\\ncorpus: The union of all documents in the train, validation and test splits. A document is the concatenation of the title and abstract.\\nretriever: BM25 via PyTerrier with default settings\\ntop-k strategy: \\\"max\\\", i.e. the number of documents retrieved, k, is set as the maximum number of‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/allenai/cochrane_sparse_max."},
	{"name":"cochrane_sparse_mean","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/allenai/cochrane_sparse_mean","creator_name":"Ai2","creator_url":"https://huggingface.co/allenai","description":"This is a copy of the Cochrane dataset, except the input source documents of its validation split have been replaced by a sparse retriever. The retrieval pipeline used:\\n\\nquery: The target field of each example\\ncorpus: The union of all documents in the train, validation and test splits. A document is the concatenation of the title and abstract.\\nretriever: BM25 via PyTerrier with default settings\\ntop-k strategy: \\\"mean\\\", i.e. the number of documents retrieved, k, is set as the mean number of‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/allenai/cochrane_sparse_mean."},
	{"name":"cochrane_sparse_oracle","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/allenai/cochrane_sparse_oracle","creator_name":"Ai2","creator_url":"https://huggingface.co/allenai","description":"This is a copy of the Cochrane dataset, except the input source documents of its validation split have been replaced by a sparse retriever. The retrieval pipeline used:\\n\\nquery: The target field of each example\\ncorpus: The union of all documents in the train, validation and test splits. A document is the concatenation of the title and abstract.\\nretriever: BM25 via PyTerrier with default settings\\ntop-k strategy: \\\"oracle\\\", i.e. the number of documents retrieved, k, is set as the original number‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/allenai/cochrane_sparse_oracle."},
	{"name":"salom-ladino-articles","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/collectivat/salom-ladino-articles","creator_name":"Col¬∑lectivaT","creator_url":"https://huggingface.co/collectivat","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\t≈ûalom Ladino articles text corpus\\n\\t\\n\\nText corpus compiled from 397 articles from the Judeo-Espanyol section of ≈ûalom newspaper. Original sentences and articles belong to ≈ûalom. \\nSize: 176,843 words\\nOffical link\\nPaper on ArXiv\\nCitation:\\nPreparing an endangered language for the digital age: The Case of Judeo-Spanish. Alp √ñktem, Rodolfo Zevallos, Yasmin Moslem, G√ºne≈ü √ñzt√ºrk, Karen ≈ûarhon. \\nWorkshop on Resources and Technologies for Indigenous, Endangered and Lesser-resourced Languages‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/collectivat/salom-ladino-articles."},
	{"name":"splittedspanish3bwc","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/vialibre/splittedspanish3bwc","creator_name":"Via Libre","creator_url":"https://huggingface.co/vialibre","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Unannotated Spanish 3 Billion Words Corpora\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\n\\nNumber of lines: 300904000 (300M)\\nNumber of tokens: 2996016962 (3B)\\nNumber of chars: 18431160978 (18.4B)\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages\\n\\t\\n\\n\\nSpanish\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSource Data\\n\\t\\n\\n\\nAvailable to download here: Zenodo\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Subset\\n\\t\\n\\n\\nSpanish Wikis: Wich include Wikipedia, Wikinews, Wikiquotes and more. These were first processed with wikiextractor‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/vialibre/splittedspanish3bwc."},
	{"name":"openwebtext_20p","keyword":"monolingual","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Bingsu/openwebtext_20p","creator_name":"Dowon Hwang","creator_url":"https://huggingface.co/Bingsu","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\topenwebtext_20p\\n\\t\\n\\nfirst 20% of openwebtext\\n"},
	{"name":"openwebtext_20p","keyword":"monolingual","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Bingsu/openwebtext_20p","creator_name":"Dowon Hwang","creator_url":"https://huggingface.co/Bingsu","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\topenwebtext_20p\\n\\t\\n\\nfirst 20% of openwebtext\\n"},
	{"name":"sd-character-level-ner","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/EMBO/sd-character-level-ner","creator_name":"EMBO","creator_url":"https://huggingface.co/EMBO","description":"    This dataset is based on the SourceData database and is intented to facilitate training of NLP tasks in the cell and molecualr biology domain."},
	{"name":"fashionpedia_4_categories","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/detection-datasets/fashionpedia_4_categories","creator_name":"Detection datasets","creator_url":"https://huggingface.co/detection-datasets","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Fashionpedia_4_categories\\n\\t\\n\\nThis dataset is a variation of the fashionpedia dataset available here, with 2 key differences:\\n\\nIt contains only 4 categories:\\nClothing\\nShoes\\nBags\\nAccessories\\n\\n\\nNew splits were created:\\nTrain: 90% of the images\\nVal: 5%\\nTest 5%\\n\\n\\n\\nThe goal is to make the detection task easier with 4 categories instead of 46 for the full fashionpedia dataset.\\nThis dataset was created using the detection_datasets library (GitHub, PyPI), you can check here‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/detection-datasets/fashionpedia_4_categories."},
	{"name":"nouns","keyword":"monolingual","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/m1guelpf/nouns","creator_name":"Miguel Piedrafita","creator_url":"https://huggingface.co/m1guelpf","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Nouns auto-captioned\\n\\t\\n\\nDataset used to train Nouns text to image model\\nAutomatically generated captions for Nouns from their attributes, colors and items. Help on the captioning script appreciated!\\nFor each row the dataset contains image and text keys. image is a varying size PIL jpeg, and text is the accompanying text caption. Only a train split is provided.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tCitation\\n\\t\\n\\nIf you use this dataset, please cite it as:\\n@misc{piedrafita2022nouns‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/m1guelpf/nouns."},
	{"name":"dialogs_from_jokes","keyword":"monolingual","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/artemsnegirev/dialogs_from_jokes","creator_name":"Artem Snegirev","creator_url":"https://huggingface.co/artemsnegirev","description":"Converted to json version of dataset from Koziev/NLP_Datasets\\n"},
	{"name":"UD_Catalan-AnCora","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/projecte-aina/UD_Catalan-AnCora","creator_name":"Projecte Aina","creator_url":"https://huggingface.co/projecte-aina","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tUD_Catalan-AnCora\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThis dataset is composed of the annotations from the AnCora corpus, projected on the Universal Dependencies treebank. We use the POS annotations of this corpus as part of the Catalan Language Understanding Benchmark (CLUB).\\nThis work is licensed under a CC Attribution 4.0 International License.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSupported Tasks and Leaderboards\\n\\t\\n\\nPOS tagging\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages\\n\\t\\n\\nThe dataset is in Catalan (ca-ES)\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/projecte-aina/UD_Catalan-AnCora."},
	{"name":"tathagata","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/radm/tathagata","creator_name":"r4dm","creator_url":"https://huggingface.co/radm","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for tathagata\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tI-Dataset Summary\\n\\t\\n\\ntathagata.txt is a dataset based on summaries of major Buddhist, Hindu and Advaita texts such as:\\n\\nDiamond Sutra\\nLankavatara Sutra\\nSri Nisargadatta Maharaj quotes\\nQuotes from the Bhagavad Gita\\n\\nThis dataset was used to train this model https://huggingface.co/radm/rugpt3medium-tathagata\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tII-Languages\\n\\t\\n\\nThe texts in the dataset are in Russian (ru).\\n"},
	{"name":"newyorker_caption_contest","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/jmhessel/newyorker_caption_contest","creator_name":"Jack Hessel","creator_url":"https://huggingface.co/jmhessel","description":"\\n\\t\\n\\t\\t\\n\\t\\tDataset Card for New Yorker Caption Contest Benchmarks\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nSee capcon.dev for more!\\nData from:\\nDo Androids Laugh at Electric Sheep? Humor \\\"Understanding\\\" Benchmarks from The New Yorker Caption Contest\\n@inproceedings{hessel2023androids,\\n  title={Do Androids Laugh at Electric Sheep? {Humor} ``Understanding''\\n         Benchmarks from {The New Yorker Caption Contest}},\\n  author={Hessel, Jack and Marasovi{\\\\'c}, Ana and Hwang, Jena D. and Lee, Lillian\\n          and‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/jmhessel/newyorker_caption_contest."},
	{"name":"msmarco-nlgen","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/din0s/msmarco-nlgen","creator_name":"Dinos Papakostas","creator_url":"https://huggingface.co/din0s","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for MSMARCO - Natural Language Generation Task\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThe original focus of MSMARCO was to provide a corpus for training and testing systems which given a real domain user query systems would then provide the most likley candidate answer and do so in language which was natural and conversational. All questions have been generated from real anonymized Bing user queries which grounds the dataset in a real world problem and can provide‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/din0s/msmarco-nlgen."},
	{"name":"Lipogram-e","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Hellisotherpeople/Lipogram-e","creator_name":"Allen Roush","creator_url":"https://huggingface.co/Hellisotherpeople","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Lipogram-e\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\n\\n\\n\\nThis is a dataset of 3 English books which do not contain the letter \\\"e\\\" in them. This dataset includes all of \\\"Gadsby\\\" by Ernest Vincent Wright, all of \\\"A Void\\\" by Georges Perec, and almost all of \\\"Eunoia\\\" by Christian Bok (except for the single chapter that uses the letter \\\"e\\\" in it) \\nThis dataset is contributed as part of a paper titled \\\"Most Language Models can be Poets too: An AI Writing Assistant and Constrained‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Hellisotherpeople/Lipogram-e."},
	{"name":"one_syllable","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Hellisotherpeople/one_syllable","creator_name":"Allen Roush","creator_url":"https://huggingface.co/Hellisotherpeople","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Lipogram-e\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\n\\nThis is a dataset of English books which only write using one syllable at a time. At this time, the dataset only contains Robinson Crusoe ‚Äî in Words of One Syllable by Lucy Aikin and Daniel Defoe\\nThis dataset is contributed as part of a paper titled \\\"Most Language Models can be Poets too: An AI Writing Assistant and Constrained Text Generation Studio\\\" to appear at COLING 2022. This dataset does not appear in the paper‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Hellisotherpeople/one_syllable."},
	{"name":"NeQA","keyword":"monolingual","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/inverse-scaling/NeQA","creator_name":"Inverse Scaling Prize","creator_url":"https://huggingface.co/inverse-scaling","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tNeQA: Can Large Language Models Understand Negation in Multi-choice Questions? (Zhengping Zhou and Yuhui Zhang)\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tGeneral description\\n\\t\\n\\nThis task takes an existing multiple-choice dataset and negates a part of each question to see if language models are sensitive to negation. The authors find that smaller language models display approximately random performance whereas the performance of larger models become significantly worse than random. \\nLanguage models failing to‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/inverse-scaling/NeQA."},
	{"name":"quote-repetition","keyword":"monolingual","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/inverse-scaling/quote-repetition","creator_name":"Inverse Scaling Prize","creator_url":"https://huggingface.co/inverse-scaling","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tquote-repetition (Joe Cavanagh, Andrew Gritsevskiy, and Derik Kauffman of Cavendish Labs)\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tGeneral description\\n\\t\\n\\nIn this task, the authors ask language models to repeat back sentences given in the prompt, with few-shot examples to help it recognize the task. Each prompt contains a famous quote with a modified ending to mislead the model into completing the sequence with the famous ending rather than with the ending given in the prompt. The authors find that smaller‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/inverse-scaling/quote-repetition."},
	{"name":"humaneval_infilling","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/loubnabnl/humaneval_infilling","creator_name":"Loubna Ben Allal","creator_url":"https://huggingface.co/loubnabnl","description":"An evaluation benchamrk for infilling tasks on HumanEval dataset for code generation."},
	{"name":"meddocan","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/GuiGel/meddocan","creator_name":"Guillaume Gelabert","creator_url":"https://huggingface.co/GuiGel","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for \\\"meddocan\\\"\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nA personal upload of the SPACC_MEDDOCAN corpus. The tokenization is made with the help of a custom spaCy pipeline.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSupported Tasks and Leaderboards\\n\\t\\n\\nName Entity Recognition\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages\\n\\t\\n\\nMore Information Needed\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Structure\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Instances\\n\\t\\n\\nMore Information Needed\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Fields\\n\\t\\n\\nThe data fields are the same among all splits.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Splits‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/GuiGel/meddocan."},
	{"name":"multiscale_rotten_tomatoes_critic_reviews","keyword":"monolingual","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/frankier/multiscale_rotten_tomatoes_critic_reviews","creator_name":"Frankie Robertson","creator_url":"https://huggingface.co/frankier","description":"Cleaned up version of the rotten tomatoes critic reviews dataset. The original\\nis obtained from Kaggle:\\nhttps://www.kaggle.com/datasets/stefanoleone992/rotten-tomatoes-movies-and-critic-reviews-dataset\\nData has been scraped from the publicly available website\\nhttps://www.rottentomatoes.com as of 2020-10-31.\\nThe clean up process drops anything without both a review and a rating, as well\\nas standardising the ratings onto several integer, ordinal scales.\\nRequires the kaggle library to be‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/frankier/multiscale_rotten_tomatoes_critic_reviews."},
	{"name":"inferes","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/venelin/inferes","creator_name":"Venelin Kovatchev","creator_url":"https://huggingface.co/venelin","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for InferES\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nNatural Language Inference dataset for European Spanish\\nPaper accepted and (to be) presented at COLING 2022\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSupported Tasks and Leaderboards\\n\\t\\n\\nNatural Language Inference\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages\\n\\t\\n\\nSpanish\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Structure\\n\\t\\n\\nThe dataset contains two texts inputs (Premise and Hypothesis), Label for three-way classification, and annotation data.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Instances\\n\\t\\n\\ntrain size = 6444 \\ntest‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/venelin/inferes."},
	{"name":"redefine-math","keyword":"monolingual","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/inverse-scaling/redefine-math","creator_name":"Inverse Scaling Prize","creator_url":"https://huggingface.co/inverse-scaling","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tredefine-math (Xudong Shen)\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tGeneral description\\n\\t\\n\\nIn this task, the author tests whether language models are able to work with common symbols when they are redefined to mean something else. The author finds that larger models are more likely to pick the answer corresponding to the original definition rather than the redefined meaning, relative to smaller models. \\nThis task demonstrates that it is difficult for language models to work with new information given at‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/inverse-scaling/redefine-math."},
	{"name":"hindsight-neglect-10shot","keyword":"monolingual","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/inverse-scaling/hindsight-neglect-10shot","creator_name":"Inverse Scaling Prize","creator_url":"https://huggingface.co/inverse-scaling","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tinverse-scaling/hindsight-neglect-10shot (‚ÄòThe Floating Droid‚Äô)\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tGeneral description\\n\\t\\n\\nThis task tests whether language models are able to assess whether a bet was worth taking based on its expected value. The author provides few shot examples in which the model predicts whether a bet is worthwhile by correctly answering yes or no when the expected value of the bet is positive (where the model should respond that ‚Äòyes‚Äô, taking the bet is the right decision) or‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/inverse-scaling/hindsight-neglect-10shot."},
	{"name":"brwac_tiny","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/thegoodfellas/brwac_tiny","creator_name":"The Good Fellas","creator_url":"https://huggingface.co/thegoodfellas","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for BrWac\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThe BrWaC (Brazilian Portuguese Web as Corpus) is a large corpus constructed following the Wacky framework, \\nwhich was made public for research purposes. The current corpus version, released in January 2017, is composed by \\n3.53 million documents, 2.68 billion tokens and 5.79 million types. Please note that this resource is available \\nsolely for academic research purposes, and you agreed not to use it for any commercial‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/thegoodfellas/brwac_tiny."},
	{"name":"skateboarding-tricks","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/vogloblinsky/skateboarding-tricks","creator_name":"Ogloblinsky","creator_url":"https://huggingface.co/vogloblinsky","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Skateboarding tricks\\n\\t\\n\\nDataset used to train Text to skateboarding image model.\\nFor each row the dataset contains image and text keys.\\nimage is a varying size PIL jpeg, and text is the accompanying text caption.\\n"},
	{"name":"cochrane_dense_mean","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/allenai/cochrane_dense_mean","creator_name":"Ai2","creator_url":"https://huggingface.co/allenai","description":"This is a copy of the Cochrane dataset, except the input source documents of its train, validation and test splits have been replaced by a dense retriever. The retrieval pipeline used:\\n\\nquery: The target field of each example\\ncorpus: The union of all documents in the train, validation and test splits. A document is the concatenation of the title and abstract.\\nretriever: facebook/contriever-msmarco via PyTerrier with default settings\\ntop-k strategy: \\\"max\\\", i.e. the number of documents retrieved‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/allenai/cochrane_dense_mean."},
	{"name":"cochrane_dense_max","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/allenai/cochrane_dense_max","creator_name":"Ai2","creator_url":"https://huggingface.co/allenai","description":"This is a copy of the Cochrane dataset, except the input source documents of its validation split have been replaced by a dense retriever. The retrieval pipeline used:\\n\\nquery: The target field of each example\\ncorpus: The union of all documents in the train, validation and test splits. A document is the concatenation of the title and abstract.\\nretriever: facebook/contriever-msmarco via PyTerrier with default settings\\ntop-k strategy: \\\"max\\\", i.e. the number of documents retrieved, k, is set as‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/allenai/cochrane_dense_max."},
	{"name":"cochrane_dense_oracle","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/allenai/cochrane_dense_oracle","creator_name":"Ai2","creator_url":"https://huggingface.co/allenai","description":"This is a copy of the Cochrane dataset, except the input source documents of the train, validation, and test splits have been replaced by a dense retriever.\\n\\nquery: The target field of each example\\ncorpus: The union of all documents in the train, validation and test splits. A document is the concatenation of the title and abstract.\\nretriever: facebook/contriever-msmarco via PyTerrier with default settings\\ntop-k strategy: \\\"oracle\\\", i.e. the number of documents retrieved, k, is set as the‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/allenai/cochrane_dense_oracle."},
	{"name":"ms2_dense_max","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/allenai/ms2_dense_max","creator_name":"Ai2","creator_url":"https://huggingface.co/allenai","description":"This is a copy of the MS^2 dataset, except the input source documents of its validation split have been replaced by a dense retriever. The retrieval pipeline used:\\n\\nquery: The background field of each example\\ncorpus: The union of all documents in the train, validation and test splits. A document is the concatenation of the title and abstract.\\nretriever: facebook/contriever-msmarco via PyTerrier with default settings\\ntop-k strategy: \\\"max\\\", i.e. the number of documents retrieved, k, is set as‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/allenai/ms2_dense_max."},
	{"name":"ms2_dense_mean","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/allenai/ms2_dense_mean","creator_name":"Ai2","creator_url":"https://huggingface.co/allenai","description":"This is a copy of the MS^2 dataset, except the input source documents of its train, validation and test splits have been replaced by a dense retriever. The retrieval pipeline used:\\n\\nquery: The background field of each example\\ncorpus: The union of all documents in the train, validation and test splits. A document is the concatenation of the title and abstract.\\nretriever: facebook/contriever-msmarco via PyTerrier with default settings\\ntop-k strategy: \\\"max\\\", i.e. the number of documents retrieved‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/allenai/ms2_dense_mean."},
	{"name":"ms2_dense_oracle","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/allenai/ms2_dense_oracle","creator_name":"Ai2","creator_url":"https://huggingface.co/allenai","description":"This is a copy of the MS^2 dataset, except the input source documents of the train, validation, and test splits have been replaced by a dense retriever.\\n\\nquery: The background field of each example\\ncorpus: The union of all documents in the train, validation and test splits. A document is the concatenation of the title and abstract.\\nretriever: facebook/contriever-msmarco via PyTerrier with default settings\\ntop-k strategy: \\\"oracle\\\", i.e. the number of documents retrieved, k, is set as the‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/allenai/ms2_dense_oracle."},
	{"name":"ALotNLI","keyword":"monolingual","license":"GNU Affero General Public License v3.0","license_url":"https://choosealicense.com/licenses/agpl-3.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Thamognya/ALotNLI","creator_name":"Thamognya Kodi","creator_url":"https://huggingface.co/Thamognya","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tRepo\\n\\t\\n\\nGithub Repo: thamognya/TBertNLI specifically in the src/data directory.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSample\\n\\t\\n\\n0  this church choir sings to the masses as they ...      the church is filled with song      0\\n1  this church choir sings to the masses as they ...  a choir singing at a baseball game      2\\n2  a woman with a green headscarf blue shirt and ...                  the woman is young      1\\n3  a woman with a green headscarf blue shirt and ...             the woman is very happy      0‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Thamognya/ALotNLI."},
	{"name":"nan-nli","keyword":"monolingual","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/joey234/nan-nli","creator_name":"Thinh Truong","creator_url":"https://huggingface.co/joey234","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for [Dataset Name]\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\n[More Information Needed]\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSupported Tasks and Leaderboards\\n\\t\\n\\nNatural Language Inference\\nText Classification\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages\\n\\t\\n\\nen\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Structure\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Instances\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Fields\\n\\t\\n\\npremise:\\nhypothesis:\\nlabel:\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Splits\\n\\t\\n\\nEvaluation: 258 samples\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Creation\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tCuration Rationale\\n\\t\\n\\nExtracting samples corresponding to‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/joey234/nan-nli."},
	{"name":"channel-metadata","keyword":"monolingual","license":"Academic Free License v3.0","license_url":"https://choosealicense.com/licenses/afl-3.0/","language":"en","dataset_url":"https://huggingface.co/datasets/jamescalam/channel-metadata","creator_name":"James Briggs","creator_url":"https://huggingface.co/jamescalam","description":"Dataset containing video metadata from a few tech channels, i.e.\\n\\nJames Briggs\\nYannic Kilcher\\nsentdex\\nDaniel Bourke\\nAI Coffee Break with Letitia\\nAlex Ziskind\\n\\n"},
	{"name":"cloth","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/AndyChiang/cloth","creator_name":"CHIANG SHANG-HSUAN","creator_url":"https://huggingface.co/AndyChiang","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tcloth\\n\\t\\n\\nCLOTH is a dataset which is a collection of nearly 100,000 cloze questions from middle school and high school English exams. The detail of CLOTH dataset is shown below.\\n\\n\\t\\n\\t\\t\\nNumber of questions\\nTrain\\nValid\\nTest\\n\\n\\n\\t\\t\\nMiddle school\\n22056\\n3273\\n3198\\n\\n\\nHigh school\\n54794\\n7794\\n8318\\n\\n\\nTotal\\n76850\\n11067\\n11516\\n\\n\\n\\t\\n\\nSource: https://www.cs.cmu.edu/~glai1/data/cloth/\\n"},
	{"name":"dgen","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/AndyChiang/dgen","creator_name":"CHIANG SHANG-HSUAN","creator_url":"https://huggingface.co/AndyChiang","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tdgen\\n\\t\\n\\nDGen is a cloze questions dataset which covers multiple domains including science, vocabulary, common sense and trivia. It is compiled from a wide variety of datasets including SciQ, MCQL, AI2 Science Questions, etc. The detail of DGen dataset is shown below.\\n\\n\\t\\n\\t\\t\\nDGen dataset\\nTrain\\nValid\\nTest\\nTotal\\n\\n\\n\\t\\t\\nNumber of questions\\n2321\\n300\\n259\\n2880\\n\\n\\n\\t\\n\\nSource: https://github.com/DRSY/DGen\\n"},
	{"name":"gutenberg-poetry-corpus","keyword":"monolingual","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/biglam/gutenberg-poetry-corpus","creator_name":"BigLAM: BigScience Libraries, Archives and Museums","creator_url":"https://huggingface.co/biglam","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tAllison Parrish's Gutenberg Poetry Corpus\\n\\t\\n\\nThis corpus was originally published under the CC0 license by Allison Parrish. Please visit Allison's fantastic accompanying GitHub repository for usage inspiration as well as more information on how the data was mined, how to create your own version of the corpus, and examples of projects using it.\\nThis dataset contains 3,085,117 lines of poetry from hundreds of Project Gutenberg books. Each line has a corresponding gutenberg_id (1191‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/biglam/gutenberg-poetry-corpus."},
	{"name":"laion2b_multi_korean_subset_with_image","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Bingsu/laion2b_multi_korean_subset_with_image","creator_name":"Dowon Hwang","creator_url":"https://huggingface.co/Bingsu","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tlaion2b_multi_korean_subset_with_image\\n\\t\\n\\nimg2datasetÏùÑ ÌÜµÌï¥ Îã§Ïö¥Î°úÎìúÏóê ÏÑ±Í≥µÌïú Bingsu/laion2B-multi-korean-subset Ïù¥ÎØ∏ÏßÄÎ•º Ï†ïÎ¶¨Ìïú Îç∞Ïù¥ÌÑ∞ÏÖãÏûÖÎãàÎã§.\\nÏù¥ÎØ∏ÏßÄÎäî 9,800,137Ïû•ÏûÖÎãàÎã§.\\nÏù¥ÎØ∏ÏßÄÎäî ÏßßÏùÄ Ï™Ω Í∏∏Ïù¥Í∞Ä 256Ïù¥ ÎêòÎèÑÎ°ù Î¶¨ÏÇ¨Ïù¥Ï¶à ÎêòÏóàÏúºÎ©∞, ÌíàÏßà 100Ïù∏ webpÌååÏùºÎ°ú Îã§Ïö¥Î°úÎìú ÎêòÏóàÏäµÎãàÎã§.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tUsage\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\t1. datasets\\n\\t\\n\\n>>> from datasets import load_dataset\\n\\n>>> dataset = load_dataset(\\\"Bingsu/laion2b_multi_korean_subset_with_image\\\", streaming=True, split=\\\"train\\\")\\n\\n>>> dataset.features\\n{'image': Image(decode=True, id=None),\\n 'text':‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Bingsu/laion2b_multi_korean_subset_with_image."},
	{"name":"ted_descriptions","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/gigant/ted_descriptions","creator_name":"Th√©o Gigant","creator_url":"https://huggingface.co/gigant","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for TED descriptions\\n\\t\\n\\nMore Information needed\\n"},
	{"name":"slo_thesaurus","keyword":"monolingual","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/cjvt/slo_thesaurus","creator_name":"Center za jezikovne vire in tehnologije Univerze v Ljubljani","creator_url":"https://huggingface.co/cjvt","description":"This is an automatically created Slovene thesaurus from Slovene data available in a comprehensive \\nEnglish‚ÄìSlovenian dictionary, a monolingual dictionary, and a corpus. A network analysis on the bilingual dictionary \\nword co-occurrence graph was used, together with additional information from the distributional thesaurus data \\navailable as part of the Sketch Engine tool and extracted from the 1.2 billion word Gigafida corpus and the \\nmonolingual dictionary."},
	{"name":"FB15k-237","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/KGraph/FB15k-237","creator_name":"YHLong","creator_url":"https://huggingface.co/KGraph","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for FB15k-237\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nFB15k-237 is a link prediction dataset created from FB15k. While FB15k consists of 1,345 relations, 14,951 entities, and 592,213 triples, many triples are inverses that cause leakage from the training to testing and validation splits. FB15k-237 was created by Toutanova and Chen (2015) to ensure that the testing and evaluation datasets do not have inverse relation test leakage. In summary, FB15k-237 dataset contains 310‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/KGraph/FB15k-237."},
	{"name":"slownet","keyword":"monolingual","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/cjvt/slownet","creator_name":"Center za jezikovne vire in tehnologije Univerze v Ljubljani","creator_url":"https://huggingface.co/cjvt","description":"sloWNet is the Slovene WordNet developed in the expand approach: it contains the complete Princeton WordNet 3.0 and \\nover 70 000 Slovene literals. These literals have been added automatically using different types of existing resources, \\nsuch as bilingual dictionaries, parallel corpora and Wikipedia. 33 000 literals have been subsequently hand-validated."},
	{"name":"crosswoz","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ConvLab/crosswoz","creator_name":"ConvLab","creator_url":"https://huggingface.co/ConvLab","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for CrossWOZ\\n\\t\\n\\n\\nRepository: https://github.com/thu-coai/CrossWOZ\\nPaper: https://aclanthology.org/2020.tacl-1.19/\\nLeaderboard: None\\nWho transforms the dataset: Qi Zhu(zhuq96 at gmail dot com)\\n\\nTo use this dataset, you need to install ConvLab-3 platform first. Then you can load the dataset via:\\nfrom convlab.util import load_dataset, load_ontology, load_database\\n\\ndataset = load_dataset('crosswoz')\\nontology = load_ontology('crosswoz')\\ndatabase = load_database('crosswoz')‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ConvLab/crosswoz."},
	{"name":"spiced","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/copenlu/spiced","creator_name":"CopeNLU","creator_url":"https://huggingface.co/copenlu","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for SPICED\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThe Scientific Paraphrase and Information ChangE Dataset (SPICED) is a dataset of paired scientific findings from scientific papers, news media, and Twitter. The types of pairs are between <paper, news> and <paper, tweet>. Each pair is labeled for the degree of information similarity in the findings described by each sentence, on a scale from 1-5. This is called the Information Matching Score (IMS). The data was curated from‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/copenlu/spiced."},
	{"name":"Gitcoin-ODS-Hackhaton-GR15","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Poupou/Gitcoin-ODS-Hackhaton-GR15","creator_name":"Poupou web3","creator_url":"https://huggingface.co/Poupou","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for [Gitcoin ODS Hackathon GR15]\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThis data set was created in the context of the first Gitcoin Open Data Science Hackathon.\\nIt contains all the transactions on the Ethereum and Polygon chains of the wallet that contributed to the Grant 15 of Gitcoin grants program.\\nIt was created in order to find patterns in the transactions of potential Sybil attackers by exploring their on-chain activity.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Creation‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Poupou/Gitcoin-ODS-Hackhaton-GR15."},
	{"name":"WSDMCup2023","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/toloka/WSDMCup2023","creator_name":"Toloka","creator_url":"https://huggingface.co/toloka","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for WSDMCup2023\\n\\t\\n\\n\\n\\t\\n\\t\\t\\nQuestion\\nImage and Answer\\n\\n\\n\\t\\t\\nWhat do you use to hit the ball?\\n\\n\\n\\nWhat do people use for cutting?\\n\\n\\n\\nWhat do we use to support the immune system and get vitamin C?\\n\\n\\n\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThe WSDMCup2023 Dataset consists of images associated with textual questions.\\nOne entry (instance) in our dataset is a question-image pair labeled with the ground truth coordinates of a bounding box containing\\nthe visual answer to the given‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/toloka/WSDMCup2023."},
	{"name":"PortugueseLegalSentences-v1","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/rufimelo/PortugueseLegalSentences-v1","creator_name":"Rui Melo","creator_url":"https://huggingface.co/rufimelo","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tPortuguese Legal Sentences\\n\\t\\n\\nCollection of Legal Sentences from the Portuguese Supreme Court of Justice\\nThe goal of this dataset was to be used for MLM and TSDAE\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tContributions\\n\\t\\n\\n@rufimelo99\\n"},
	{"name":"PortugueseLegalSentences-v0","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/rufimelo/PortugueseLegalSentences-v0","creator_name":"Rui Melo","creator_url":"https://huggingface.co/rufimelo","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tPortuguese Legal Sentences\\n\\t\\n\\nCollection of Legal Sentences from the Portuguese Supreme Court of Justice\\nThe goal of this dataset was to be used for MLM and TSDAE\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tContributions\\n\\t\\n\\n@rufimelo99\\n"},
	{"name":"copa-sse","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/anab/copa-sse","creator_name":"Ana Brassard","creator_url":"https://huggingface.co/anab","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for COPA-SSE\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\n\\nCOPA-SSE contains crowdsourced explanations for the Balanced COPA dataset, a variant of the Choice of Plausible Alternatives (COPA) benchmark. The explanations are formatted as a set of triple-like common sense statements with ConceptNet relations but freely written concepts.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSupported Tasks and Leaderboards\\n\\t\\n\\nCan be used to train a model for explain+predict or predict+explain settings. Suited for both‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/anab/copa-sse."},
	{"name":"P3","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Muennighoff/P3","creator_name":"Niklas Muennighoff","creator_url":"https://huggingface.co/Muennighoff","description":"This is a repreprocessed version of P3 with any updates that have been made to the P3 datasets since the release of the original P3. It is used for the finetuning of bloomz-p3 & mt0-xxl-p3. The script is available here.\\n"},
	{"name":"naacl2022","keyword":"monolingual","license":"Academic Free License v3.0","license_url":"https://choosealicense.com/licenses/afl-3.0/","language":"en","dataset_url":"https://huggingface.co/datasets/havens2/naacl2022","creator_name":"Haotian Teng","creator_url":"https://huggingface.co/havens2","description":"NACL22 is a dataset labelled for Science Entity Recognition task, which is a subtask of NER task. \\nThe text is from 2022 conference papers collected from ACL anthology. \\nThe dataset is collected by Haotian Teng and Xiaoyue Cui. \\nAnnotation standard can be found here https://github.com/neubig/nlp-from-scratch-assignment-2022/blob/main/annotation_standard.md"},
	{"name":"afrolm_active_learning_dataset","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/bonadossou/afrolm_active_learning_dataset","creator_name":"Bonaventure Dossou","creator_url":"https://huggingface.co/bonadossou","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tAfroLM: A Self-Active Learning-based Multilingual Pretrained Language Model for 23 African Languages\\n\\t\\n\\n\\nGitHub Repository of the Paper\\n\\nThis repository contains the dataset for our paper AfroLM: A Self-Active Learning-based Multilingual Pretrained Language Model for 23 African Languages which will appear at the third Simple and Efficient Natural Language Processing, at EMNLP 2022.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tOur self-active learning framework\\n\\t\\n\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages Covered\\n\\t\\n\\nAfroLM has been‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/bonadossou/afrolm_active_learning_dataset."},
	{"name":"glue","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/severo/glue","creator_name":"Sylvain Lesage","creator_url":"https://huggingface.co/severo","description":"GLUE, the General Language Understanding Evaluation benchmark\\n(https://gluebenchmark.com/) is a collection of resources for training,\\nevaluating, and analyzing natural language understanding systems."},
	{"name":"standard_humaneval","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/diversoailab/standard_humaneval","creator_name":"Diverso AI Lab","creator_url":"https://huggingface.co/diversoailab","description":"diversoailab/standard_humaneval dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"qg_annotation","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/lmqg/qg_annotation","creator_name":"LMQG","creator_url":"https://huggingface.co/lmqg","description":"Human-annotated question generated by models."},
	{"name":"PortugueseLegalSentences-v2","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/rufimelo/PortugueseLegalSentences-v2","creator_name":"Rui Melo","creator_url":"https://huggingface.co/rufimelo","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tPortuguese Legal Sentences\\n\\t\\n\\nCollection of Legal Sentences from the Portuguese Supreme Court of Justice\\nThe goal of this dataset was to be used for MLM and TSDAE\\nExtended version of rufimelo/PortugueseLegalSentences-v1\\n200000/200000/100000\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tContributions\\n\\t\\n\\n@rufimelo99\\n"},
	{"name":"PortugueseLegalSentences-v3","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/rufimelo/PortugueseLegalSentences-v3","creator_name":"Rui Melo","creator_url":"https://huggingface.co/rufimelo","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tPortuguese Legal Sentences\\n\\t\\n\\nCollection of Legal Sentences from the Portuguese Supreme Court of Justice\\nThe goal of this dataset was to be used for MLM and TSDAE\\nExtended version of rufimelo/PortugueseLegalSentences-v1\\n400000/50000/50000\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tContributions\\n\\t\\n\\n@rufimelo99\\n"},
	{"name":"probability_words_nli","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/sileod/probability_words_nli","creator_name":"Damien Sileo","creator_url":"https://huggingface.co/sileod","description":"Probing neural language models for understanding of words of estimative probability"},
	{"name":"docee-event-classification","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/fkdosilovic/docee-event-classification","creator_name":"Filip Karlo Do≈°iloviƒá","creator_url":"https://huggingface.co/fkdosilovic","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for DocEE Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nDocEE dataset is an English-language dataset containing more than 27k news and Wikipedia articles. Dataset is primarily annotated and collected for large-scale document-level event extraction.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Fields\\n\\t\\n\\n\\ntitle: TODO\\ntext: TODO\\nevent_type: TODO\\ndate: TODO\\nmetadata: TODO\\n\\nNote: this repo contains only event detection portion of the dataset.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Splits\\n\\t\\n\\nThe dataset has 2 splits: train and‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/fkdosilovic/docee-event-classification."},
	{"name":"Biosses-BLUE","keyword":"monolingual","license":"GNU General Public License v3.0","license_url":"https://choosealicense.com/licenses/gpl-3.0/","language":"en","dataset_url":"https://huggingface.co/datasets/qanastek/Biosses-BLUE","creator_name":"yanis labrak","creator_url":"https://huggingface.co/qanastek","description":"BIOSSES is a benchmark dataset for biomedical sentence similarity estimation.\\nThe dataset comprises 100 sentence pairs, in which each sentence was selected\\nfrom the TAC (Text Analysis Conference) Biomedical Summarization Track Training\\nDataset containing articles from the biomedical domain. The sentence pairs in\\nBIOSSES were selected from citing sentences, i.e. sentences that have a citation\\nto a reference article.\\n\\nThe sentence pairs were evaluated by five different human experts that judged\\ntheir similarity and gave scores ranging from 0 (no relation) to 4 (equivalent).\\nIn the original paper the mean of the scores assigned by the five human annotators\\nwas taken as the gold standard. The Pearson correlation between the gold standard\\nscores and the scores estimated by the models was used as the evaluation metric.\\nThe strength of correlation can be assessed by the general guideline proposed by\\nEvans (1996) as follows:\\n\\nvery strong: 0.80‚Äì1.00\\nstrong: 0.60‚Äì0.79\\nmoderate: 0.40‚Äì0.59\\nweak: 0.20‚Äì0.39\\nvery weak: 0.00‚Äì0.19"},
	{"name":"machine-paraphrase-dataset","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/jpwahle/machine-paraphrase-dataset","creator_name":"Jan Philip Wahle","creator_url":"https://huggingface.co/jpwahle","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Machine Paraphrase Dataset (MPC)\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThe Machine Paraphrase Corpus (MPC) consists of ~200k examples of original, and paraphrases using two online paraphrasing tools.\\nIt uses two paraphrasing tools (SpinnerChief, SpinBot) on three source texts (Wikipedia, arXiv, student theses).\\nThe examples are not aligned, i.e., we sample different paragraphs for originals and paraphrased versions.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tHow to use it\\n\\t\\n\\nYou can load the dataset‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/jpwahle/machine-paraphrase-dataset."},
	{"name":"autoencoder-paraphrase-dataset","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/jpwahle/autoencoder-paraphrase-dataset","creator_name":"Jan Philip Wahle","creator_url":"https://huggingface.co/jpwahle","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Machine Paraphrase Dataset (MPC)\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThe Autoencoder Paraphrase Corpus (APC) consists of ~200k examples of original, and paraphrases using three neural language models.\\nIt uses three models (BERT, RoBERTa, Longformer) on three source texts (Wikipedia, arXiv, student theses).\\nThe examples are aligned, i.e., we sample the same paragraphs for originals and paraphrased versions.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tHow to use it\\n\\t\\n\\nYou can load the dataset using‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/jpwahle/autoencoder-paraphrase-dataset."},
	{"name":"autoregressive-paraphrase-dataset","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/jpwahle/autoregressive-paraphrase-dataset","creator_name":"Jan Philip Wahle","creator_url":"https://huggingface.co/jpwahle","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for [Dataset Name]\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\n[More Information Needed]\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSupported Tasks and Leaderboards\\n\\t\\n\\n[More Information Needed]\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages\\n\\t\\n\\n[More Information Needed]\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Structure\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Instances\\n\\t\\n\\n[More Information Needed]\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Fields\\n\\t\\n\\n[More Information Needed]\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Splits\\n\\t\\n\\n[More Information Needed]\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Creation\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tCuration Rationale\\n\\t\\n\\n[More‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/jpwahle/autoregressive-paraphrase-dataset."},
	{"name":"laion2B-multi-turkish-subset","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mcemilg/laion2B-multi-turkish-subset","creator_name":"Cemil Guney","creator_url":"https://huggingface.co/mcemilg","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for laion2B-multi-turkish-subset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nLAION-5B is a large scale openly accessible image-text dataset contains text from multiple languages. This is a Turkish subset data of laion/laion2B-multi. It's compatible to be used with image2dataset to fetch the images at scale.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Structure\\n\\t\\n\\nDatasetDict({\\n    train: Dataset({\\n        features: ['SAMPLE_ID', 'URL', 'TEXT', 'HEIGHT', 'WIDTH', 'LICENSE', 'LANGUAGE', 'NSFW'‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/mcemilg/laion2B-multi-turkish-subset."},
	{"name":"CONDAQA","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/lasha-nlp/CONDAQA","creator_name":"Abhilasha Ravichander","creator_url":"https://huggingface.co/lasha-nlp","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for CondaQA: A Contrastive Reading Comprehension Dataset for Reasoning about Negation\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nData from the EMNLP 2022 paper by Ravichander et al.: \\\"CondaQA: A Contrastive Reading Comprehension Dataset for Reasoning about Negation\\\". \\nIf you use this dataset, we would appreciate you citing our work:\\n@inproceedings{ravichander-et-al-2022-condaqa,\\n  title={CONDAQA: A Contrastive Reading Comprehension Dataset for Reasoning about Negation}‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/lasha-nlp/CONDAQA."},
	{"name":"saf_legal_domain_german","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Short-Answer-Feedback/saf_legal_domain_german","creator_name":"Short Answer Feedback Interest Group","creator_url":"https://huggingface.co/Short-Answer-Feedback","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for \\\"saf_legal_domain_german\\\"\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThis Short Answer Feedback (SAF) dataset contains 19 German questions in the domain of the German social law (with reference answers). The idea of constructing a bilingual (English and German) short answer dataset as a way to remedy the lack of content-focused feedback datasets was introduced in Your Answer is Incorrect... Would you like to know why? Introducing a‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Short-Answer-Feedback/saf_legal_domain_german."},
	{"name":"text2image-multi-prompt","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/pszemraj/text2image-multi-prompt","creator_name":"Peter Szemraj","creator_url":"https://huggingface.co/pszemraj","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\ttext2image multi-prompt(s): a dataset collection\\n\\t\\n\\n\\ncollection of several text2image prompt datasets\\ndata was cleaned/normalized with the goal of removing \\\"model specific APIs\\\" like the \\\"--ar\\\" for Midjourney and so on\\ndata de-duplicated on a basic level: exactly duplicate prompts were dropped (after cleaning and normalization)\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tupdates\\n\\t\\n\\n\\nOct 2023: the default config has been updated with better deduplication. It was deduplicated with minhash (params: n-gram size set‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/pszemraj/text2image-multi-prompt."},
	{"name":"coyo-labeled-300m","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/kakaobrain/coyo-labeled-300m","creator_name":"Kakao Brain","creator_url":"https://huggingface.co/kakaobrain","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for COYO-Labeled-300M\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nCOYO-Labeled-300M is a dataset of machine-labeled 300M images-multi-label pairs. We labeled subset of COYO-700M with a large model (efficientnetv2-xl) trained on imagenet-21k. We followed the same evaluation pipeline as in efficientnet-v2. The labels are top 50 most likely labels out of 21,841 classes from imagenet-21k. The label probabilies are provided rather than label so that the user can select threshold of‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/kakaobrain/coyo-labeled-300m."},
	{"name":"libri","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/bgstud/libri","creator_name":"bc","creator_url":"https://huggingface.co/bgstud","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for [Dataset Name]\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\n[More Information Needed]\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSupported Tasks and Leaderboards\\n\\t\\n\\n[More Information Needed]\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages\\n\\t\\n\\n[More Information Needed]\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Structure\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Instances\\n\\t\\n\\n[More Information Needed]\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Fields\\n\\t\\n\\n[More Information Needed]\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Splits\\n\\t\\n\\n[More Information Needed]\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Creation\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tCuration Rationale\\n\\t\\n\\n[More‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/bgstud/libri."},
	{"name":"saf_micro_job_german","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Short-Answer-Feedback/saf_micro_job_german","creator_name":"Short Answer Feedback Interest Group","creator_url":"https://huggingface.co/Short-Answer-Feedback","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for \\\"saf_micro_job_german\\\"\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nShort Answer Feedback (SAF) dataset is a short answer dataset introduced in Your Answer is Incorrect... Would you like to know why? Introducing a Bilingual Short Answer Feedback Dataset (Filighera et al., ACL 2022) as a way to remedy the lack of content-focused feedback datasets. This version of the dataset contains 8 German questions used in micro-job training on the crowd-worker platform appJobber - while‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Short-Answer-Feedback/saf_micro_job_german."},
	{"name":"idk-mrc","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/rifkiaputri/idk-mrc","creator_name":"Rifki Afina Putri","creator_url":"https://huggingface.co/rifkiaputri","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for IDK-MRC\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nI(n)dontKnow-MRC (IDK-MRC) is an Indonesian Machine Reading Comprehension dataset that covers answerable and unanswerable questions. Based on the combination of the existing answerable questions in TyDiQA, the new unanswerable question in IDK-MRC is generated using a question generation model and human-written question. Each paragraph in the dataset has a set of answerable and unanswerable questions with the corresponding‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/rifkiaputri/idk-mrc."},
	{"name":"libri-whisper-raw","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/bgstud/libri-whisper-raw","creator_name":"bc","creator_url":"https://huggingface.co/bgstud","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for [Dataset Name]\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\n[More Information Needed]\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSupported Tasks and Leaderboards\\n\\t\\n\\n[More Information Needed]\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages\\n\\t\\n\\n[More Information Needed]\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Structure\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Instances\\n\\t\\n\\n[More Information Needed]\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Fields\\n\\t\\n\\n[More Information Needed]\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Splits\\n\\t\\n\\n[More Information Needed]\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Creation\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tCuration Rationale\\n\\t\\n\\n[More‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/bgstud/libri-whisper-raw."},
	{"name":"qag_tweetqa","keyword":"monolingual","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/lmqg/qag_tweetqa","creator_name":"LMQG","creator_url":"https://huggingface.co/lmqg","description":"Question & answer generation dataset based on [TweetQA](https://huggingface.co/datasets/tweet_qa)."},
	{"name":"qag_squad","keyword":"monolingual","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/lmqg/qag_squad","creator_name":"LMQG","creator_url":"https://huggingface.co/lmqg","description":"Question & answer generation dataset based on SQuAD."},
	{"name":"ask_a_patient","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/bigbio/ask_a_patient","creator_name":"BigScience Biomedical Datasets","creator_url":"https://huggingface.co/bigbio","description":"The AskAPatient dataset contains medical concepts written on social media mapped to how they are formally written in medical ontologies (SNOMED-CT and AMT)."},
	{"name":"bioasq_2021_mesinesp","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/bigbio/bioasq_2021_mesinesp","creator_name":"BigScience Biomedical Datasets","creator_url":"https://huggingface.co/bigbio","description":"The main aim of MESINESP2 is to promote the development of practically relevant semantic indexing tools for biomedical content in non-English language. We have generated a manually annotated corpus, where domain experts have labeled a set of scientific literature, clinical trials, and patent abstracts. All the documents were labeled with DeCS descriptors, which is a structured controlled vocabulary created by BIREME to index scientific publications on BvSalud, the largest database of scientific documents in Spanish, which hosts records from the databases LILACS, MEDLINE, IBECS, among others.\\n\\nMESINESP track at BioASQ9 explores the efficiency of systems for assigning DeCS to different types of biomedical documents. To that purpose, we have divided the task into three subtracks depending on the document type. Then, for each one we generated an annotated corpus which was provided to participating teams:\\n\\n- [Subtrack 1 corpus] MESINESP-L ‚Äì Scientific Literature: It contains all   Spanish records from LILACS and IBECS databases at the Virtual Health Library   (VHL) with non-empty abstract written in Spanish.\\n- [Subtrack 2 corpus] MESINESP-T- Clinical Trials contains records from Registro   Espa√±ol de Estudios Cl√≠nicos (REEC). REEC doesn't provide documents with the   structure title/abstract needed in BioASQ, for that reason we have built   artificial abstracts based on the content available in the data crawled using   the REEC API.\\n- [Subtrack 3 corpus] MESINESP-P ‚Äì Patents: This corpus includes patents in   Spanish extracted from Google Patents which have the IPC code ‚ÄúA61P‚Äù and   ‚ÄúA61K31‚Äù. In addition, we also provide a set of complementary data such as:   the DeCS terminology file, a silver standard with the participants' predictions   to the task background set and the entities of medications, diseases, symptoms   and medical procedures extracted from the BSC NERs documents."},
	{"name":"chebi_nactem","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/bigbio/chebi_nactem","creator_name":"BigScience Biomedical Datasets","creator_url":"https://huggingface.co/bigbio","description":"The ChEBI corpus contains 199 annotated abstracts and 100 annotated full papers.\\nAll documents in the corpus have been annotated for named entities and relations\\nbetween these. In total, our corpus provides over 15000 named entity annotations\\nand over 6,000 relations between entities."},
	{"name":"chia","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/bigbio/chia","creator_name":"BigScience Biomedical Datasets","creator_url":"https://huggingface.co/bigbio","description":"A large annotated corpus of patient eligibility criteria extracted from 1,000\\ninterventional, Phase IV clinical trials registered in ClinicalTrials.gov. This\\ndataset includes 12,409 annotated eligibility criteria, represented by 41,487\\ndistinctive entities of 15 entity types and 25,017 relationships of 12\\nrelationship types."},
	{"name":"ehr_rel","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/bigbio/ehr_rel","creator_name":"BigScience Biomedical Datasets","creator_url":"https://huggingface.co/bigbio","description":"EHR-Rel is a novel open-source1 biomedical concept relatedness dataset consisting of 3630 concept pairs, six times more\\nthan the largest existing dataset.  Instead of manually selecting and pairing concepts as done in previous work,\\nthe dataset is sampled from EHRs to ensure concepts are relevant for the EHR concept retrieval task.\\nA detailed analysis of the concepts in the dataset reveals a far larger coverage compared to existing datasets."},
	{"name":"evidence_inference","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/bigbio/evidence_inference","creator_name":"BigScience Biomedical Datasets","creator_url":"https://huggingface.co/bigbio","description":"The dataset consists of biomedical articles describing randomized control trials (RCTs) that compare multiple\\ntreatments. Each of these articles will have multiple questions, or 'prompts' associated with them.\\nThese prompts will ask about the relationship between an intervention and comparator with respect to an outcome,\\nas reported in the trial. For example, a prompt may ask about the reported effects of aspirin as compared\\nto placebo on the duration of headaches. For the sake of this task, we assume that a particular article\\nwill report that the intervention of interest either significantly increased, significantly decreased\\nor had significant effect on the outcome, relative to the comparator."},
	{"name":"hallmarks_of_cancer","keyword":"monolingual","license":"GNU General Public License v3.0","license_url":"https://choosealicense.com/licenses/gpl-3.0/","language":"en","dataset_url":"https://huggingface.co/datasets/bigbio/hallmarks_of_cancer","creator_name":"BigScience Biomedical Datasets","creator_url":"https://huggingface.co/bigbio","description":"The Hallmarks of Cancer (HOC) Corpus consists of 1852 PubMed publication\\nabstracts manually annotated by experts according to a taxonomy. The taxonomy\\nconsists of 37 classes in a hierarchy. Zero or more class labels are assigned\\nto each sentence in the corpus. The labels are found under the \\\"labels\\\"\\ndirectory, while the tokenized text can be found under \\\"text\\\" directory.\\nThe filenames are the corresponding PubMed IDs (PMID)."},
	{"name":"linnaeus","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/bigbio/linnaeus","creator_name":"BigScience Biomedical Datasets","creator_url":"https://huggingface.co/bigbio","description":"Linnaeus is a novel corpus of full-text documents manually annotated for species mentions."},
	{"name":"mayosrs","keyword":"monolingual","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/bigbio/mayosrs","creator_name":"BigScience Biomedical Datasets","creator_url":"https://huggingface.co/bigbio","description":"MayoSRS consists of 101 clinical term pairs whose relatedness was determined by nine medical coders and three physicians from the Mayo Clinic."},
	{"name":"meddocan","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/bigbio/meddocan","creator_name":"BigScience Biomedical Datasets","creator_url":"https://huggingface.co/bigbio","description":"MEDDOCAN: Medical Document Anonymization Track\\n\\nThis dataset is designed for the MEDDOCAN task, sponsored by Plan de Impulso de las Tecnolog√≠as del Lenguaje.\\n\\nIt is a manually classified collection of 1,000 clinical case reports derived from the Spanish Clinical Case Corpus (SPACCC), enriched with PHI expressions.\\n\\nThe annotation of the entire set of entity mentions was carried out by experts annotatorsand it includes 29 entity types relevant for the annonymiation of medical documents.22 of these annotation types are actually present in the corpus: TERRITORIO, FECHAS, EDAD_SUJETO_ASISTENCIA, NOMBRE_SUJETO_ASISTENCIA, NOMBRE_PERSONAL_SANITARIO, SEXO_SUJETO_ASISTENCIA, CALLE, PAIS, ID_SUJETO_ASISTENCIA, CORREO, ID_TITULACION_PERSONAL_SANITARIO,ID_ASEGURAMIENTO, HOSPITAL, FAMILIARES_SUJETO_ASISTENCIA, INSTITUCION, ID_CONTACTO ASISTENCIAL,NUMERO_TELEFONO, PROFESION, NUMERO_FAX, OTROS_SUJETO_ASISTENCIA, CENTRO_SALUD, ID_EMPLEO_PERSONAL_SANITARIO\\n    \\nFor further information, please visit https://temu.bsc.es/meddocan/ or send an email to encargo-pln-life@bsc.es"},
	{"name":"minimayosrs","keyword":"monolingual","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/bigbio/minimayosrs","creator_name":"BigScience Biomedical Datasets","creator_url":"https://huggingface.co/bigbio","description":"MiniMayoSRS is a subset of the MayoSRS and consists of 30 term pairs on which a higher inter-annotator agreement was\\nachieved. The average correlation between physicians is 0.68. The average correlation between medical coders is 0.78."},
	{"name":"multi_xscience","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/bigbio/multi_xscience","creator_name":"BigScience Biomedical Datasets","creator_url":"https://huggingface.co/bigbio","description":"Multi-document summarization is a challenging task for which there exists little large-scale datasets. \\nWe propose Multi-XScience, a large-scale multi-document summarization dataset created from scientific articles. \\nMulti-XScience introduces a challenging multi-document summarization task: writing the related-work section \\nof a paper based on its abstract and the articles it references. Our work is inspired by extreme summarization, \\na dataset construction protocol that favours abstractive modeling approaches. Descriptive statistics and \\nempirical results---using several state-of-the-art models trained on the Multi-XScience dataset---reveal t\\nhat Multi-XScience is well suited for abstractive models."},
	{"name":"pharmaconer","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/bigbio/pharmaconer","creator_name":"BigScience Biomedical Datasets","creator_url":"https://huggingface.co/bigbio","description":"PharmaCoNER: Pharmacological Substances, Compounds and Proteins Named Entity Recognition track\\n\\nThis dataset is designed for the PharmaCoNER task, sponsored by Plan de Impulso de las Tecnolog√≠as del Lenguaje.\\n\\nIt is a manually classified collection of clinical case studies derived from the Spanish Clinical Case Corpus (SPACCC), an open access electronic library that gathers Spanish medical publications from SciELO (Scientific Electronic Library Online).\\n\\nThe annotation of the entire set of entity mentions was carried out by medicinal chemistry experts and it includes the following 4 entity types: NORMALIZABLES, NO_NORMALIZABLES, PROTEINAS and UNCLEAR.\\n\\nThe PharmaCoNER corpus contains a total of 396,988 words and 1,000 clinical cases that have been randomly sampled into 3 subsets. The training set contains 500 clinical cases, while the development and test sets contain 250 clinical cases each.\\n\\nFor further information, please visit https://temu.bsc.es/pharmaconer/ or send an email to encargo-pln-life@bsc.es"},
	{"name":"progene","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/bigbio/progene","creator_name":"BigScience Biomedical Datasets","creator_url":"https://huggingface.co/bigbio","description":"The Protein/Gene corpus was developed at the JULIE Lab Jena under supervision of Prof. Udo Hahn.\\nThe executing scientist was Dr. Joachim Wermter.\\nThe main annotator was Dr. Rico Pusch who is an expert in biology.\\nThe corpus was developed in the context of the StemNet project (http://www.stemnet.de/)."},
	{"name":"pubhealth","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/bigbio/pubhealth","creator_name":"BigScience Biomedical Datasets","creator_url":"https://huggingface.co/bigbio","description":"A dataset of 11,832 claims for fact- checking, which are related a range of health topics\\nincluding biomedical subjects (e.g., infectious diseases, stem cell research), government healthcare policy\\n(e.g., abortion, mental health, women‚Äôs health), and other public health-related stories"},
	{"name":"seth_corpus","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/bigbio/seth_corpus","creator_name":"BigScience Biomedical Datasets","creator_url":"https://huggingface.co/bigbio","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for SETH Corpus\\n\\t\\n\\nSNP named entity recognition corpus consisting of 630 PubMed citations.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tCitation Information\\n\\t\\n\\n@Article{SETH2016,\\n    Title       = {SETH detects and normalizes genetic variants in text.},\\n    Author      = {Thomas, Philippe and Rockt{\\\"{a}}schel, Tim and Hakenberg, J{\\\"{o}}rg and Lichtblau, Yvonne and Leser, Ulf},\\n    Journal     = {Bioinformatics},\\n    Year        = {2016},\\n    Month       = {Jun},\\n    Doi         =‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/bigbio/seth_corpus."},
	{"name":"spl_adr_200db","keyword":"monolingual","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/bigbio/spl_adr_200db","creator_name":"BigScience Biomedical Datasets","creator_url":"https://huggingface.co/bigbio","description":"The United States Food and Drug Administration (FDA) partnered with the National Library\\nof Medicine to create a pilot dataset containing standardised information about known\\nadverse reactions for 200 FDA-approved drugs. The Structured Product Labels (SPLs),\\nthe documents FDA uses to exchange information about drugs and other products, were\\nmanually annotated for adverse reactions at the mention level to facilitate development\\nand evaluation of text mining tools for extraction of ADRs from all SPLs.  The ADRs were\\nthen normalised to the Unified Medical Language System (UMLS) and to the Medical\\nDictionary for Regulatory Activities (MedDRA)."},
	{"name":"umnsrs","keyword":"monolingual","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/bigbio/umnsrs","creator_name":"BigScience Biomedical Datasets","creator_url":"https://huggingface.co/bigbio","description":"UMNSRS, developed by Pakhomov, et al., consists of 725 clinical term pairs whose semantic similarity and relatedness.\\nThe similarity and relatedness of each term pair was annotated based on a continuous scale by having the resident touch\\na bar on a touch sensitive computer screen to indicate the degree of similarity or relatedness.\\nThe following subsets are available:\\n- similarity: A set of 566 UMLS concept pairs manually rated for semantic similarity (e.g. whale-dolphin) using a\\n  continuous response scale.\\n- relatedness: A set of 588 UMLS concept pairs manually rated for semantic relatedness (e.g. needle-thread) using a\\n  continuous response scale.\\n- similarity_mod: Modification of the UMNSRS-Similarity dataset to exclude control samples and those pairs that did not\\n  match text in clinical, biomedical and general English corpora. Exact modifications are detailed in the paper (Corpus\\n  Domain Effects on Distributional Semantic Modeling of Medical Terms. Serguei V.S. Pakhomov, Greg Finley, Reed McEwan,\\n  Yan Wang, and Genevieve B. Melton. Bioinformatics. 2016; 32(23):3635-3644). The resulting dataset contains 449 pairs.\\n- relatedness_mod: Modification of the UMNSRS-Relatedness dataset to exclude control samples and those pairs that did\\n  not match text in clinical, biomedical and general English corpora. Exact modifications are detailed in the paper\\n  (Corpus Domain Effects on Distributional Semantic Modeling of Medical Terms. Serguei V.S. Pakhomov, Greg Finley,\\n  Reed McEwan, Yan Wang, and Genevieve B. Melton. Bioinformatics. 2016; 32(23):3635-3644).\\n  The resulting dataset contains 458 pairs."},
	{"name":"portuguese-legal-sentences-v0","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/stjiris/portuguese-legal-sentences-v0","creator_name":"Sumariza√ß√£o e Informa√ß√£o de decis√µes: Aplica√ß√£o de T√©cnicas de Intelig√™ncia Artificial no Supremo Tribunal de Justi√ßa (IRIS)","creator_url":"https://huggingface.co/stjiris","description":"\\n\\nWork developed as part of Project IRIS.\\nThesis: A Semantic Search System for Supremo Tribunal de Justi√ßa\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tPortuguese Legal Sentences\\n\\t\\n\\nCollection of Legal Sentences from the Portuguese Supreme Court of Justice\\nThe goal of this dataset was to be used for MLM and TSDAE\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tContributions\\n\\t\\n\\n@rufimelo99\\nIf you use this work, please cite:\\n@InProceedings{MeloSemantic,\\n  author=\\\"Melo, Rui\\n  and Santos, Pedro A.\\n  and Dias, Jo{\\\\~a}o\\\",\\n  editor=\\\"Moniz, Nuno\\n  and Vale, Zita\\n  and‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/stjiris/portuguese-legal-sentences-v0."},
	{"name":"paraphrase-ro","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/BlackKakapo/paraphrase-ro","creator_name":"Alexandru Petrachi","creator_url":"https://huggingface.co/BlackKakapo","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tRomanian paraphrase dataset\\n\\t\\n\\nThis data set was created by me, special for paraphrase\\nt5-small-paraphrase-ro\\nt5-small-paraphrase-ro-v2\\nt5-base-paraphrase-ro\\nt5-base-paraphrase-ro-v2\\nHere you can find ~100k examples of paraphrase.\\n"},
	{"name":"librispeech_asr_dummy","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/sanchit-gandhi/librispeech_asr_dummy","creator_name":"Sanchit Gandhi","creator_url":"https://huggingface.co/sanchit-gandhi","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for librispeech_asr_dummy\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThis is a truncated version of the LibriSpeech dataset. It contains 20 samples from each of the splits. To view the full dataset, visit: https://huggingface.co/datasets/librispeech_asr\\nLibriSpeech is a corpus of approximately 1000 hours of 16kHz read English speech, prepared by Vassil Panayotov with the assistance of Daniel Povey. The data is derived from read audiobooks from the LibriVox project, and has been‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/sanchit-gandhi/librispeech_asr_dummy."},
	{"name":"kodak","keyword":"monolingual","license":"GNU General Public License v3.0","license_url":"https://choosealicense.com/licenses/gpl-3.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Freed-Wu/kodak","creator_name":"wzy","creator_url":"https://huggingface.co/Freed-Wu","description":"The pictures below link to lossless, true color (24 bits per pixel, aka \\\"full\\ncolor\\\") images. It is my understanding they have been released by the Eastman\\nKodak Company for unrestricted usage. Many sites use them as a standard test\\nsuite for compression testing, etc. Prior to this site, they were only\\navailable in the Sun Raster format via ftp. This meant that the images could\\nnot be previewed before downloading. Since their release, however, the lossless\\nPNG format has been incorporated into all the major browsers. Since PNG\\nsupports 24-bit lossless color (which GIF and JPEG do not), it is now possible\\nto offer this browser-friendly access to the images."},
	{"name":"common-voice-test16k","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/DTU54DL/common-voice-test16k","creator_name":"DTU DL 54","creator_url":"https://huggingface.co/DTU54DL","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for [Dataset Name]\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\n[More Information Needed]\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSupported Tasks and Leaderboards\\n\\t\\n\\n[More Information Needed]\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages\\n\\t\\n\\n[More Information Needed]\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Structure\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Instances\\n\\t\\n\\n[More Information Needed]\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Fields\\n\\t\\n\\n[More Information Needed]\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Splits\\n\\t\\n\\n[More Information Needed]\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Creation\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tCuration Rationale\\n\\t\\n\\n[More‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/DTU54DL/common-voice-test16k."},
	{"name":"common-voice-test3k","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/DTU54DL/common-voice-test3k","creator_name":"DTU DL 54","creator_url":"https://huggingface.co/DTU54DL","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for [Dataset Name]\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\n[More Information Needed]\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSupported Tasks and Leaderboards\\n\\t\\n\\n[More Information Needed]\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages\\n\\t\\n\\n[More Information Needed]\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Structure\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Instances\\n\\t\\n\\n[More Information Needed]\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Fields\\n\\t\\n\\n[More Information Needed]\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Splits\\n\\t\\n\\n[More Information Needed]\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Creation\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tCuration Rationale\\n\\t\\n\\n[More‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/DTU54DL/common-voice-test3k."},
	{"name":"common-train-3k","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/DTU54DL/common-train-3k","creator_name":"DTU DL 54","creator_url":"https://huggingface.co/DTU54DL","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for [Dataset Name]\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\n[More Information Needed]\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSupported Tasks and Leaderboards\\n\\t\\n\\n[More Information Needed]\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages\\n\\t\\n\\n[More Information Needed]\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Structure\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Instances\\n\\t\\n\\n[More Information Needed]\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Fields\\n\\t\\n\\n[More Information Needed]\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Splits\\n\\t\\n\\n[More Information Needed]\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Creation\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tCuration Rationale\\n\\t\\n\\n[More‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/DTU54DL/common-train-3k."},
	{"name":"common3k-train","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/DTU54DL/common3k-train","creator_name":"DTU DL 54","creator_url":"https://huggingface.co/DTU54DL","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for [Dataset Name]\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\n[More Information Needed]\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSupported Tasks and Leaderboards\\n\\t\\n\\n[More Information Needed]\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages\\n\\t\\n\\n[More Information Needed]\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Structure\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Instances\\n\\t\\n\\n[More Information Needed]\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Fields\\n\\t\\n\\n[More Information Needed]\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Splits\\n\\t\\n\\n[More Information Needed]\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Creation\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tCuration Rationale\\n\\t\\n\\n[More‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/DTU54DL/common3k-train."},
	{"name":"common-voice","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/DTU54DL/common-voice","creator_name":"DTU DL 54","creator_url":"https://huggingface.co/DTU54DL","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for [Dataset Name]\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\n[More Information Needed]\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSupported Tasks and Leaderboards\\n\\t\\n\\n[More Information Needed]\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages\\n\\t\\n\\n[More Information Needed]\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Structure\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Instances\\n\\t\\n\\n[More Information Needed]\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Fields\\n\\t\\n\\n[More Information Needed]\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Splits\\n\\t\\n\\n[More Information Needed]\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Creation\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tCuration Rationale\\n\\t\\n\\n[More‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/DTU54DL/common-voice."},
	{"name":"snli-cf-kaushik","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/sagnikrayc/snli-cf-kaushik","creator_name":"sagnik ray choudhury","creator_url":"https://huggingface.co/sagnikrayc","description":"The SNLI corpus (version 1.0) is a collection of 570k human-written English sentence pairs manually labeled for balanced classification with the labels entailment, contradiction, and neutral, supporting the task of natural language inference (NLI), also known as recognizing textual entailment (RTE). In the ICLR 2020 paper [Learning the Difference that Makes a Difference with Counterfactually-Augmented Data](https://openreview.net/forum?id=Sklgs0NFvr), Kaushik et. al. provided a dataset with counterfactual perturbations on the SNLI and IMDB data. This repository contains the original and counterfactual perturbations for the SNLI data, which was generated after processing the original data from [here](https://github.com/acmi-lab/counterfactually-augmented-data)."},
	{"name":"ciempiess_test","keyword":"monolingual","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ciempiess/ciempiess_test","creator_name":"CIEMPIESS-UNAM Project (Mexico)","creator_url":"https://huggingface.co/ciempiess","description":"The CIEMPIESS TEST Corpus is a gender balanced corpus destined to test acoustic models for the speech recognition task. The corpus was manually transcribed and it contains audio recordings from 10 male and 10 female speakers. The CIEMPIESS TEST is one of the three corpora included at the LDC's \\\\\\\"CIEMPIESS Experimentation\\\\\\\" (LDC2019S07)."},
	{"name":"ger-backtrans-paraphrase","keyword":"monolingual","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/deutsche-telekom/ger-backtrans-paraphrase","creator_name":"Deutsche Telekom AG","creator_url":"https://huggingface.co/deutsche-telekom","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tGerman Backtranslated Paraphrase Dataset\\n\\t\\n\\nThis is a dataset of more than 21 million German paraphrases.\\nThese are text pairs that have the same meaning but are expressed with different words.\\nThe source of the paraphrases are different parallel German / English text corpora.\\nThe English texts were machine translated back into German to obtain the paraphrases.\\nThis dataset can be used for example to train semantic text embeddings.\\nTo do this, for example, SentenceTransformers\\nand‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/deutsche-telekom/ger-backtrans-paraphrase."},
	{"name":"dmeo","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/DTU54DL/dmeo","creator_name":"DTU DL 54","creator_url":"https://huggingface.co/DTU54DL","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for [Dataset Name]\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\n[More Information Needed]\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSupported Tasks and Leaderboards\\n\\t\\n\\n[More Information Needed]\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages\\n\\t\\n\\n[More Information Needed]\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Structure\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Instances\\n\\t\\n\\n[More Information Needed]\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Fields\\n\\t\\n\\n[More Information Needed]\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Splits\\n\\t\\n\\n[More Information Needed]\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Creation\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tCuration Rationale\\n\\t\\n\\n[More‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/DTU54DL/dmeo."},
	{"name":"demo-common-whisper","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/DTU54DL/demo-common-whisper","creator_name":"DTU DL 54","creator_url":"https://huggingface.co/DTU54DL","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for [Dataset Name]\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\n[More Information Needed]\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSupported Tasks and Leaderboards\\n\\t\\n\\n[More Information Needed]\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages\\n\\t\\n\\n[More Information Needed]\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Structure\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Instances\\n\\t\\n\\n[More Information Needed]\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Fields\\n\\t\\n\\n[More Information Needed]\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Splits\\n\\t\\n\\n[More Information Needed]\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Creation\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tCuration Rationale\\n\\t\\n\\n[More‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/DTU54DL/demo-common-whisper."},
	{"name":"sgd1","keyword":"monolingual","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ConvLab/sgd1","creator_name":"ConvLab","creator_url":"https://huggingface.co/ConvLab","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for SGD-X v1\\n\\t\\n\\n\\nRepository: https://github.com/google-research-datasets/dstc8-schema-guided-dialogue/tree/master/sgd_x\\nPaper: https://arxiv.org/pdf/2110.06800.pdf\\nLeaderboard: None\\nWho transforms the dataset: Qi Zhu(zhuq96 at gmail dot com)\\n\\nTo use this dataset, you need to install ConvLab-3 platform first. Then you can load the dataset via:\\nfrom convlab.util import load_dataset, load_ontology, load_database\\n\\ndataset = load_dataset('sgd1')\\nontology =‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ConvLab/sgd1."},
	{"name":"sgd2","keyword":"monolingual","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ConvLab/sgd2","creator_name":"ConvLab","creator_url":"https://huggingface.co/ConvLab","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for SGD-X v2\\n\\t\\n\\n\\nRepository: https://github.com/google-research-datasets/dstc8-schema-guided-dialogue/tree/master/sgd_x\\nPaper: https://arxiv.org/pdf/2110.06800.pdf\\nLeaderboard: None\\nWho transforms the dataset: Qi Zhu(zhuq96 at gmail dot com)\\n\\nTo use this dataset, you need to install ConvLab-3 platform first. Then you can load the dataset via:\\nfrom convlab.util import load_dataset, load_ontology, load_database\\n\\ndataset = load_dataset('sgd2')\\nontology =‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ConvLab/sgd2."},
	{"name":"sgd3","keyword":"monolingual","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ConvLab/sgd3","creator_name":"ConvLab","creator_url":"https://huggingface.co/ConvLab","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for SGD-X v3\\n\\t\\n\\n\\nRepository: https://github.com/google-research-datasets/dstc8-schema-guided-dialogue/tree/master/sgd_x\\nPaper: https://arxiv.org/pdf/2110.06800.pdf\\nLeaderboard: None\\nWho transforms the dataset: Qi Zhu(zhuq96 at gmail dot com)\\n\\nTo use this dataset, you need to install ConvLab-3 platform first. Then you can load the dataset via:\\nfrom convlab.util import load_dataset, load_ontology, load_database\\n\\ndataset = load_dataset('sgd3')\\nontology =‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ConvLab/sgd3."},
	{"name":"sgd4","keyword":"monolingual","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ConvLab/sgd4","creator_name":"ConvLab","creator_url":"https://huggingface.co/ConvLab","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for SGD-X v4\\n\\t\\n\\n\\nRepository: https://github.com/google-research-datasets/dstc8-schema-guided-dialogue/tree/master/sgd_x\\nPaper: https://arxiv.org/pdf/2110.06800.pdf\\nLeaderboard: None\\nWho transforms the dataset: Qi Zhu(zhuq96 at gmail dot com)\\n\\nTo use this dataset, you need to install ConvLab-3 platform first. Then you can load the dataset via:\\nfrom convlab.util import load_dataset, load_ontology, load_database\\n\\ndataset = load_dataset('sgd4')\\nontology =‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ConvLab/sgd4."},
	{"name":"sgd5","keyword":"monolingual","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ConvLab/sgd5","creator_name":"ConvLab","creator_url":"https://huggingface.co/ConvLab","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for SGD-X v5\\n\\t\\n\\n\\nRepository: https://github.com/google-research-datasets/dstc8-schema-guided-dialogue/tree/master/sgd_x\\nPaper: https://arxiv.org/pdf/2110.06800.pdf\\nLeaderboard: None\\nWho transforms the dataset: Qi Zhu(zhuq96 at gmail dot com)\\n\\nTo use this dataset, you need to install ConvLab-3 platform first. Then you can load the dataset via:\\nfrom convlab.util import load_dataset, load_ontology, load_database\\n\\ndataset = load_dataset('sgd5')\\nontology =‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ConvLab/sgd5."},
	{"name":"samromur_children","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/language-and-voice-lab/samromur_children","creator_name":"Language and Voice Laboratory (Reykjav√≠k University)","creator_url":"https://huggingface.co/language-and-voice-lab","description":"The Samr√≥mur Children corpus contains more than 137000 validated speech-recordings uttered by Icelandic children."},
	{"name":"xbmu_amdo31","keyword":"monolingual","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/syzym/xbmu_amdo31","creator_name":"Senyan Li","creator_url":"https://huggingface.co/syzym","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for [XBMU-AMDO31]\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nXBMU-AMDO31 dataset is a speech recognition corpus of Amdo Tibetan dialect. The open source corpus contains 31 hours of speech data and resources related to build speech recognition systems, including transcribed texts and a Tibetan pronunciation dictionary.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSupported Tasks and Leaderboards\\n\\t\\n\\nautomatic-speech-recognition: The dataset can be used to train a model for Amdo Tibetan Automatic Speech‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/syzym/xbmu_amdo31."},
	{"name":"qa_squad","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/lmqg/qa_squad","creator_name":"LMQG","creator_url":"https://huggingface.co/lmqg","description":"SQuAD with the train/validation/test split used in SQuAD QG"},
	{"name":"raddromur_asr","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/language-and-voice-lab/raddromur_asr","creator_name":"Language and Voice Laboratory (Reykjav√≠k University)","creator_url":"https://huggingface.co/language-and-voice-lab","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for raddromur_asr\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThe \\\"Raddr√≥mur Icelandic Speech 22.09\\\" (\\\"Raddr√≥mur Corpus\\\" for short) is an Icelandic corpus created by the Language and Voice Laboratory (LVL) at Reykjav√≠k University (RU) in 2022. It is made out of radio podcasts mostly taken from R√öV (ruv.is).\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tExample Usage\\n\\t\\n\\nThe Raddr√≥mur Corpus counts with the train split only. To load the training split pass its name as a config name:\\nfrom datasets import‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/language-and-voice-lab/raddromur_asr."},
	{"name":"common-proc-whisper","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/DTU54DL/common-proc-whisper","creator_name":"DTU DL 54","creator_url":"https://huggingface.co/DTU54DL","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for [Dataset Name]\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\n[More Information Needed]\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSupported Tasks and Leaderboards\\n\\t\\n\\n[More Information Needed]\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages\\n\\t\\n\\n[More Information Needed]\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Structure\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Instances\\n\\t\\n\\n[More Information Needed]\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Fields\\n\\t\\n\\n[More Information Needed]\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Splits\\n\\t\\n\\n[More Information Needed]\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Creation\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tCuration Rationale\\n\\t\\n\\n[More‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/DTU54DL/common-proc-whisper."},
	{"name":"wave-energy","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/cmudrc/wave-energy","creator_name":"Design Research Collective","creator_url":"https://huggingface.co/cmudrc","description":"cmudrc/wave-energy dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"commonvoice_accent_test","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/DTU54DL/commonvoice_accent_test","creator_name":"DTU DL 54","creator_url":"https://huggingface.co/DTU54DL","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for [Dataset Name]\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\n[More Information Needed]\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSupported Tasks and Leaderboards\\n\\t\\n\\n[More Information Needed]\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages\\n\\t\\n\\n[More Information Needed]\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Structure\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Instances\\n\\t\\n\\n[More Information Needed]\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Fields\\n\\t\\n\\n[More Information Needed]\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Splits\\n\\t\\n\\n[More Information Needed]\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Creation\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tCuration Rationale\\n\\t\\n\\n[More‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/DTU54DL/commonvoice_accent_test."},
	{"name":"DocBank","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/maveriq/DocBank","creator_name":"Haris Jabbar","creator_url":"https://huggingface.co/maveriq","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for DocBank\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nDocBank is a new large-scale dataset that is constructed using a weak supervision approach. It enables models to integrate both the textual and layout information for downstream tasks. The current DocBank dataset totally includes 500K document pages, where 400K for training, 50K for validation and 50K for testing.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSupported Tasks and Leaderboards\\n\\t\\n\\nDocument AI (text and layout)\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages\\n\\t\\n\\nEnglish‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/maveriq/DocBank."},
	{"name":"3d-printed-or-not","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/cmudrc/3d-printed-or-not","creator_name":"Design Research Collective","creator_url":"https://huggingface.co/cmudrc","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\t3d-printed-or-not: An Image Dataset of 3D-printed Prototypes\\n\\t\\n\\nThis dataset is a collection of images that are particularly relevant to engineering and design, consisting of two categories: 3D-printed prototypes, and non-3D-printed prototypes This data was collected through a hybrid approach that entailed both web scraping and direct collection from engineering labs and workspaces at Penn State University. The initial data was then augmented using several data augmentation‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/cmudrc/3d-printed-or-not."},
	{"name":"bace_regression","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/zpn/bace_regression","creator_name":"Zach Nussbaum","creator_url":"https://huggingface.co/zpn","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for bace_regression\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nbace_regression is a dataset included in MoleculeNet. This dataset consists of  Quantitative (IC50) binding results for a set of inhibitors of human Œ≤-secretase 1(BACE-1).\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Structure\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Fields\\n\\t\\n\\nEach split contains\\n\\nsmiles: the SMILES representation of a molecule\\nselfies: the SELFIES representation of a molecule\\ntarget: the IC50 binding results\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Splits\\n\\t\\n\\nThe‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/zpn/bace_regression."},
	{"name":"bace_classification","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/zpn/bace_classification","creator_name":"Zach Nussbaum","creator_url":"https://huggingface.co/zpn","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for bace_classification\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nbace_classification is a dataset included in MoleculeNet. This dataset consists of qualitative (binary label) binding binding results for a set of inhibitors of human Œ≤-secretase 1(BACE-1).\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Structure\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Fields\\n\\t\\n\\nEach split contains\\n\\nsmiles: the SMILES representation of a molecule\\nselfies: the SELFIES representation of a molecule\\ntarget: the binary label binding results‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/zpn/bace_classification."},
	{"name":"pcba_686978","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/zpn/pcba_686978","creator_name":"Zach Nussbaum","creator_url":"https://huggingface.co/zpn","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for pcba_686978\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\npcba_686978 is a dataset included in MoleculeNet. PubChem BioAssay (PCBA) is a database consisting of biological activities of small molecules generated by high-throughput screening. We have chosen one of the larger tasks (ID 686978) as described in https://par.nsf.gov/servlets/purl/10168888.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Structure\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Fields\\n\\t\\n\\nEach split contains\\n\\nsmiles: the SMILES representation of a molecule‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/zpn/pcba_686978."},
	{"name":"SAD","keyword":"monolingual","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/surrey-nlp/SAD","creator_name":"University of Surrey NLP Group","creator_url":"https://huggingface.co/surrey-nlp","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tUtilising Weak Supervision to Create S3D: A Sarcasm Annotated Dataset\\n\\t\\n\\nThis is the repository for the S3D dataset published at EMNLP 2022. The dataset can help build sarcasm detection models.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSAD\\n\\t\\n\\nThe SAD dataset is our gold standard dataset of tweets labelled for sarcasm. These tweets were scraped by observing a '#sarcasm' hashtag and then manually annotated by three annotators.\\nThere are a total of 1170 pairs of a sarcastic and non-sarcastic tweets which were both‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/surrey-nlp/SAD."},
	{"name":"S3D-v1","keyword":"monolingual","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/surrey-nlp/S3D-v1","creator_name":"University of Surrey NLP Group","creator_url":"https://huggingface.co/surrey-nlp","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tUtilising Weak Supervision to Create S3D: A Sarcasm Annotated Dataset\\n\\t\\n\\nThis is the repository for the S3D dataset published at EMNLP 2022. The dataset can help build sarcasm detection models.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tS3D Summary\\n\\t\\n\\nThe S3D dataset is our silver standard dataset of 100,000 tweets labelled for sarcasm using weak supervision by our BERTweet-sarcasm-combined model.\\nThese tweets can be accessed by using the Twitter API so that they can be used for other experiments.\\nS3D contains‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/surrey-nlp/S3D-v1."},
	{"name":"CONDA","keyword":"monolingual","license":"Academic Free License v3.0","license_url":"https://choosealicense.com/licenses/afl-3.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Matrix430/CONDA","creator_name":"Kunze Wang","creator_url":"https://huggingface.co/Matrix430","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for CONDA\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nTraditional toxicity detection models have focused on the single utterance level without deeper understanding of context. We introduce CONDA, a new dataset for in-game toxic language detection enabling joint intent classification and slot filling analysis, which is the core task of Natural Language Understanding (NLU). The dataset consists of 45K utterances from 12K conversations from the chat logs of 1.9K completed Dota 2‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Matrix430/CONDA."},
	{"name":"common-native","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/DTU54DL/common-native","creator_name":"DTU DL 54","creator_url":"https://huggingface.co/DTU54DL","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for [Dataset Name]\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\n[More Information Needed]\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSupported Tasks and Leaderboards\\n\\t\\n\\n[More Information Needed]\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages\\n\\t\\n\\n[More Information Needed]\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Structure\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Instances\\n\\t\\n\\n[More Information Needed]\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Fields\\n\\t\\n\\n[More Information Needed]\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Splits\\n\\t\\n\\n[More Information Needed]\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Creation\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tCuration Rationale\\n\\t\\n\\n[More‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/DTU54DL/common-native."},
	{"name":"cSQuAD1","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/dferndz/cSQuAD1","creator_name":"Daniel Fernandez","creator_url":"https://huggingface.co/dferndz","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for cSQuAD1\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nA contrast set generated from the eval set of SQuAD. Questions and answers were modified\\nto help detecting dataset artifacts. This dataset only contains a validation set, which\\nshould only be used to evaluate a model.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSupported Tasks\\n\\t\\n\\nQuestion Answering (SQuAD).\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages\\n\\t\\n\\nEnglish\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Structure\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Instances\\n\\t\\n\\nDataset contains 100 instances\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Fields‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/dferndz/cSQuAD1."},
	{"name":"cSQuAD2","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/dferndz/cSQuAD2","creator_name":"Daniel Fernandez","creator_url":"https://huggingface.co/dferndz","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for cSQuAD2\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nA contrast set to evaluate models trained on SQUAD on out-of-domain data.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSupported Tasks\\n\\t\\n\\nEvaluate question-answering\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages\\n\\t\\n\\nEnglish\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Structure\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Instances\\n\\t\\n\\nDataset contains 40 instances\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Fields\\n\\t\\n\\n\\n\\t\\n\\t\\t\\nField\\nDescription\\n\\n\\n\\t\\t\\nid\\nId of document containing context\\n\\n\\ntitle\\nTitle of the document\\n\\n\\ncontext\\nThe context of the question‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/dferndz/cSQuAD2."},
	{"name":"stackoverflow-questions-2016","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/pacovaldez/stackoverflow-questions-2016","creator_name":"Paco Valdez","creator_url":"https://huggingface.co/pacovaldez","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for [Stackoverflow Post Questions]\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nCompanies that sell Open-source software tools usually hire an army of Customer representatives to try to answer every question asked about their tool. The first step in this process \\nis the prioritization of the question. The classification scale usually consists of 4 values, P0, P1, P2, and P3, with different meanings across every participant in the industry. On \\nthe other hand, every software‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/pacovaldez/stackoverflow-questions-2016."},
	{"name":"common-native-proc","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/DTU54DL/common-native-proc","creator_name":"DTU DL 54","creator_url":"https://huggingface.co/DTU54DL","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for [Dataset Name]\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\n[More Information Needed]\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSupported Tasks and Leaderboards\\n\\t\\n\\n[More Information Needed]\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages\\n\\t\\n\\n[More Information Needed]\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Structure\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Instances\\n\\t\\n\\n[More Information Needed]\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Fields\\n\\t\\n\\n[More Information Needed]\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Splits\\n\\t\\n\\n[More Information Needed]\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Creation\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tCuration Rationale\\n\\t\\n\\n[More‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/DTU54DL/common-native-proc."},
	{"name":"common-accent","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/DTU54DL/common-accent","creator_name":"DTU DL 54","creator_url":"https://huggingface.co/DTU54DL","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for [Dataset Name]\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\n[More Information Needed]\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSupported Tasks and Leaderboards\\n\\t\\n\\n[More Information Needed]\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages\\n\\t\\n\\n[More Information Needed]\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Structure\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Instances\\n\\t\\n\\n[More Information Needed]\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Fields\\n\\t\\n\\n[More Information Needed]\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Splits\\n\\t\\n\\n[More Information Needed]\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Creation\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tCuration Rationale\\n\\t\\n\\n[More‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/DTU54DL/common-accent."},
	{"name":"common-accent-proc","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/DTU54DL/common-accent-proc","creator_name":"DTU DL 54","creator_url":"https://huggingface.co/DTU54DL","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for [Dataset Name]\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\n[More Information Needed]\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSupported Tasks and Leaderboards\\n\\t\\n\\n[More Information Needed]\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages\\n\\t\\n\\n[More Information Needed]\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Structure\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Instances\\n\\t\\n\\n[More Information Needed]\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Fields\\n\\t\\n\\n[More Information Needed]\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Splits\\n\\t\\n\\n[More Information Needed]\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Creation\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tCuration Rationale\\n\\t\\n\\n[More‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/DTU54DL/common-accent-proc."},
	{"name":"common-accent-augmented","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/DTU54DL/common-accent-augmented","creator_name":"DTU DL 54","creator_url":"https://huggingface.co/DTU54DL","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for [Dataset Name]\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\n[More Information Needed]\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSupported Tasks and Leaderboards\\n\\t\\n\\n[More Information Needed]\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages\\n\\t\\n\\n[More Information Needed]\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Structure\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Instances\\n\\t\\n\\n[More Information Needed]\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Fields\\n\\t\\n\\n[More Information Needed]\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Splits\\n\\t\\n\\n[More Information Needed]\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Creation\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tCuration Rationale\\n\\t\\n\\n[More‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/DTU54DL/common-accent-augmented."},
	{"name":"delaney","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/zpn/delaney","creator_name":"Zach Nussbaum","creator_url":"https://huggingface.co/zpn","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for delaney\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\ndelaney (aka. ESOL) is a dataset included in MoleculeNet. Water solubility data(log solubility in mols per litre) for common organic small molecules.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Structure\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Fields\\n\\t\\n\\nEach split contains\\n\\nsmiles: the SMILES representation of a molecule\\nselfies: the SELFIES representation of a molecule\\ntarget: log solubility in mols per litre\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Splits\\n\\t\\n\\nThe dataset is split into an‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/zpn/delaney."},
	{"name":"clearance","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/zpn/clearance","creator_name":"Zach Nussbaum","creator_url":"https://huggingface.co/zpn","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for clearance\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nclearance is a dataset included in Chemberta-2 benchmarking. \\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Structure\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Fields\\n\\t\\n\\nEach split contains\\n\\nsmiles: the SMILES representation of a molecule\\nselfies: the SELFIES representation of a molecule\\ntarget:\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Splits\\n\\t\\n\\nThe dataset is split into an 80/10/10 train/valid/test split using scaffold split. \\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSource Data\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tInitial Data Collection‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/zpn/clearance."},
	{"name":"lipo","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/zpn/lipo","creator_name":"Zach Nussbaum","creator_url":"https://huggingface.co/zpn","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for lipo\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nlipo is a dataset included in MoleculeNet. It measures the experimental results of octanol/water distribution coefficient(logD at pH 7.4)\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Structure\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Fields\\n\\t\\n\\nEach split contains\\n\\nsmiles: the SMILES representation of a molecule\\nselfies: the SELFIES representation of a molecule\\ntarget: octanol/water distribution coefficient(logD at pH 7.4)\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Splits\\n\\t\\n\\nThe dataset is split‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/zpn/lipo."},
	{"name":"bbbp","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/zpn/bbbp","creator_name":"Zach Nussbaum","creator_url":"https://huggingface.co/zpn","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for bbbp\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nbbbp is a dataset included in MoleculeNet. This dataset has binary labels of blood-brain barrier penetration(permeability).\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Structure\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Fields\\n\\t\\n\\nEach split contains\\n\\nsmiles: the SMILES representation of a molecule\\nselfies: the SELFIES representation of a molecule\\ntarget: blood-brain barrier penetration(permeability)\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Splits\\n\\t\\n\\nThe dataset is split into an 80/10/10‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/zpn/bbbp."},
	{"name":"IRIS_sts","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/stjiris/IRIS_sts","creator_name":"Sumariza√ß√£o e Informa√ß√£o de decis√µes: Aplica√ß√£o de T√©cnicas de Intelig√™ncia Artificial no Supremo Tribunal de Justi√ßa (IRIS)","creator_url":"https://huggingface.co/stjiris","description":"\\n\\nWork developed as part of Project IRIS.\\nThesis: A Semantic Search System for Supremo Tribunal de Justi√ßa\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tPortuguese Legal Sentences\\n\\t\\n\\nCollection of Legal Sentences pairs from the Portuguese Supreme Court of Justice\\nThe goal of this dataset was to be used for Semantic Textual Similarity\\n\\nValues from 0-1: random sentences across documents\\nValues from 2-4: sentences from the same summary (implying some level of entailment)\\nValues from 4-5: sentences pairs generated through OpenAi'‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/stjiris/IRIS_sts."},
	{"name":"skquad","keyword":"monolingual","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/TUKE-DeutscheTelekom/skquad","creator_name":"TUKE and DTSS cooperation","creator_url":"https://huggingface.co/TUKE-DeutscheTelekom","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for SkQuAD\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nSK-QuAD is the first QA dataset for the Slovak language.\\nIt is manually annotated, so it has no distortion caused by\\nmachine translation. The dataset is thematically diverse ‚Äì it\\ndoes not overlap with SQuAD ‚Äì it brings new knowledge.\\nIt passed the second round of annotation ‚Äì each question\\nand the answer were seen by at least two annotators.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSupported Tasks\\n\\t\\n\\n\\nQuestion answering\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Fields\\n\\t\\n\\nThe‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/TUKE-DeutscheTelekom/skquad."},
	{"name":"qg_tweetqa","keyword":"monolingual","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/lmqg/qg_tweetqa","creator_name":"LMQG","creator_url":"https://huggingface.co/lmqg","description":"Question generation dataset based on [TweetQA](https://huggingface.co/datasets/tweet_qa)."},
	{"name":"common-accent-augmented-proc","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/DTU54DL/common-accent-augmented-proc","creator_name":"DTU DL 54","creator_url":"https://huggingface.co/DTU54DL","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for [Dataset Name]\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\n[More Information Needed]\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSupported Tasks and Leaderboards\\n\\t\\n\\n[More Information Needed]\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages\\n\\t\\n\\n[More Information Needed]\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Structure\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Instances\\n\\t\\n\\n[More Information Needed]\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Fields\\n\\t\\n\\n[More Information Needed]\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Splits\\n\\t\\n\\n[More Information Needed]\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Creation\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tCuration Rationale\\n\\t\\n\\n[More‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/DTU54DL/common-accent-augmented-proc."},
	{"name":"bible_tts_hausa","keyword":"monolingual","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/vpetukhov/bible_tts_hausa","creator_name":"Viktor Petukhov","creator_url":"https://huggingface.co/vpetukhov","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for BibleTTS Hausa\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nBibleTTS is a large high-quality open Text-to-Speech dataset with up to 80 hours of single speaker, studio quality 48kHz recordings.\\nThis is a Hausa part of the dataset. Aligned hours: 86.6, aligned verses: 40,603.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages\\n\\t\\n\\nHausa\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Structure\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Fields\\n\\t\\n\\n\\naudio: audio path\\nsentence: transcription of the audio\\nlocale: always set to ha\\nbook: 3-char book encoding\\nverse:‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/vpetukhov/bible_tts_hausa."},
	{"name":"libris_clean_100","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/nguyenvulebinh/libris_clean_100","creator_name":"Binh Nguyen","creator_url":"https://huggingface.co/nguyenvulebinh","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for librispeech_asr\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nLibriSpeech is a corpus of approximately 1000 hours of 16kHz read English speech, prepared by Vassil Panayotov with the assistance of Daniel Povey. The data is derived from read audiobooks from the LibriVox project, and has been carefully segmented and aligned.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSupported Tasks and Leaderboards\\n\\t\\n\\n\\nautomatic-speech-recognition, audio-speaker-identification: The dataset can be used to train a model for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/nguyenvulebinh/libris_clean_100."},
	{"name":"araina-text-corpus","keyword":"monolingual","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/collectivat/araina-text-corpus","creator_name":"Col¬∑lectivaT","creator_url":"https://huggingface.co/collectivat","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tAraina Text Corpus\\n\\t\\n\\nText corpus in Aranese variety of Gascon dialect of Occitan.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tCorpora\\n\\t\\n\\n\\n_nogues: Literary texts translated by Ant√≤ni Nogu√©s. Sourced from institutestudisaranesi.cat\\n_suils: Language educational material by Jordi Su√Øls Subir√†\\n_conselh: Administrative proceedings from Conselh Generau d'Aran\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tProject Araina\\n\\t\\n\\nThis corpus was prepared as part of Project Araina with support from Culture Department of the Catalan autonomous government.‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/collectivat/araina-text-corpus."},
	{"name":"nkjp1m","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ipipan/nkjp1m","creator_name":"IPI PAN","creator_url":"https://huggingface.co/ipipan","description":"This is the official dataset for NKJP1M ‚Äì the 1-million token subcorpus of the\\nNational Corpus of Polish (Narodowy Korpus Jƒôzyka Polskiego)\\n\\nBesides the text (divided into paragraphs/samples and sentences) the\\nset contains lemmas and morpho-syntactic tags for all tokens in the corpus.\\n\\nThis release corresponds to the version 1.2 of the corpus with\\nfollowing corrections and improvements. In particular the\\nmorpho-syntactic annotation has been aligned with the present version\\nof Morfeusz2 morphological analyser."},
	{"name":"msc","keyword":"monolingual","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/thennal/msc","creator_name":"Thennal","creator_url":"https://huggingface.co/thennal","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSMC Malayalam Speech Corpus\\n\\t\\n\\nMalayalam Speech Corpus (MSC) is a repository of curated speech samples collected using MSC web application, released by Swathanthra Malayalam Computing. \\nThe official blog post and source data can be found at https://blog.smc.org.in/malayalam-speech-corpus/.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThe first version of Malayalam Speech Corpus contains 1541 speech samples from 75 contributors amounting to 1:38:16 hours of speech. It has 482 unique sentences‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/thennal/msc."},
	{"name":"Mroue","keyword":"monolingual","license":"Artistic License 2.0","license_url":"https://choosealicense.com/licenses/artistic-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Gr3en/Mroue","creator_name":"Walter Maiorino","creator_url":"https://huggingface.co/Gr3en","description":"Gr3en/Mroue dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"ulca_ml","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/thennal/ulca_ml","creator_name":"Thennal","creator_url":"https://huggingface.co/thennal","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tULCA ASR Dataset Malayalam Speech Corpus\\n\\t\\n\\nThe labelled Malayalam speech subcorpus from the larger ULCA ASR Corpus.\\nThe speech is taken from news broadcasts, and is largely composed of short soundbites with some longer outliers.\\n"},
	{"name":"fashion-captions-de","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/jinaai/fashion-captions-de","creator_name":"Jina AI","creator_url":"https://huggingface.co/jinaai","description":"\\n\\n\\n\\n\\n\\n\\nThe data offered by Jina AI, Finetuner team.\\n\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSummary\\n\\t\\n\\nThis dataset is a German-language dataset based on the Fashion12K dataset, which originally contains both English and German text descriptions for each item.\\nThis dataset was used to to finetuner CLIP using the Finetuner tool.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tFine-tuning\\n\\t\\n\\nPlease refer to our documentation: Multilingual Text-to-Image Search with MultilingualCLIP\\nand blog Improving Search Quality for Non-English Queries with Fine-tuned‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/jinaai/fashion-captions-de."},
	{"name":"panda","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/facebook/panda","creator_name":"AI at Meta","creator_url":"https://huggingface.co/facebook","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for PANDA\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nPANDA (Perturbation Augmentation NLP DAtaset) consists of approximately 100K pairs of crowdsourced human-perturbed text snippets (original, perturbed). Annotators were given selected terms and target demographic attributes, and instructed to rewrite text snippets along three demographic axes: gender, race and age, while preserving semantic meaning. Text snippets were sourced from a range of text corpora (BookCorpus, Wikipedia‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/facebook/panda."},
	{"name":"kpwr","keyword":"monolingual","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/clarin-knext/kpwr","creator_name":"G4.19 Knowledge Extraction Team","creator_url":"https://huggingface.co/clarin-knext","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tKPWr\\n\\t\\n\\n"},
	{"name":"told_br_binary_sm","keyword":"monolingual","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/inctdd/told_br_binary_sm","creator_name":"Instituto Nacional de Ci√™ncia e Tecnologia em Democracia Digital","creator_url":"https://huggingface.co/inctdd","description":"This dataset is a random 1/3 slice of the original told-br\\n"},
	{"name":"test-tweets","keyword":"monolingual","license":"GNU General Public License v3.0","license_url":"https://choosealicense.com/licenses/gpl-3.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ad321/test-tweets","creator_name":"ad","creator_url":"https://huggingface.co/ad321","description":"tweets in english positive negative\\n"},
	{"name":"S3D-v2","keyword":"monolingual","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/surrey-nlp/S3D-v2","creator_name":"University of Surrey NLP Group","creator_url":"https://huggingface.co/surrey-nlp","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tUtilising Weak Supervision to Create S3D: A Sarcasm Annotated Dataset\\n\\t\\n\\nThis is the repository for the S3D dataset published at EMNLP 2022. The dataset can help build sarcasm detection models.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tS3D-v2 Summary\\n\\t\\n\\nThe S3D-v2 dataset is our silver standard dataset of 100,000 tweets labelled for sarcasm using weak supervision by a majority voting system of fine-tuned sarcasm detection models. The models used are \\nour roberta-large-finetuned-SARC-combined-DS‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/surrey-nlp/S3D-v2."},
	{"name":"squad_v2_dutch","keyword":"monolingual","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/yhavinga/squad_v2_dutch","creator_name":"Yeb Havinga","creator_url":"https://huggingface.co/yhavinga","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for \\\"squad_v2_dutch\\\"\\n\\t\\n\\n\\n  Deprecated: This translation is not recommended. 12% of the translated answers do not appear verbatim in the contexts. Use NetherlandsForensicInstitute/squad-nl-v2.0 instead.\\n\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThe squad_v2_dutch dataset is a machine-translated version of the SQuAD v2 dataset from English to Dutch.\\nThe SQuAD v2 dataset combines the 100,000 questions in SQuAD1.1 with over 50,000 unanswerable questions written adversarially by‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/yhavinga/squad_v2_dutch."},
	{"name":"qag_koquad","keyword":"monolingual","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/lmqg/qag_koquad","creator_name":"LMQG","creator_url":"https://huggingface.co/lmqg","description":"Question & answer generation dataset based on SQuAD."},
	{"name":"qag_jaquad","keyword":"monolingual","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/lmqg/qag_jaquad","creator_name":"LMQG","creator_url":"https://huggingface.co/lmqg","description":"Question & answer generation dataset based on SQuAD."},
	{"name":"qag_esquad","keyword":"monolingual","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/lmqg/qag_esquad","creator_name":"LMQG","creator_url":"https://huggingface.co/lmqg","description":"Question & answer generation dataset based on SQuAD."},
	{"name":"cs_csfd-movie-reviews","keyword":"monolingual","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/fewshot-goes-multilingual/cs_csfd-movie-reviews","creator_name":"Fewshot Goes Multilingual","creator_url":"https://huggingface.co/fewshot-goes-multilingual","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for CSFD movie reviews (Czech)\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThe dataset contains user reviews from Czech/Slovak movie databse website https://csfd.cz.\\nEach review contains text, rating, date, and basic information about the movie (or TV series).\\nThe dataset has in total (train+validation+test) 30,000 reviews. The data is balanced - each rating has approximately the same frequency.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Features\\n\\t\\n\\nEach sample contains:\\n\\nreview_id: unique string‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/fewshot-goes-multilingual/cs_csfd-movie-reviews."},
	{"name":"sk_csfd-movie-reviews","keyword":"monolingual","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/fewshot-goes-multilingual/sk_csfd-movie-reviews","creator_name":"Fewshot Goes Multilingual","creator_url":"https://huggingface.co/fewshot-goes-multilingual","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for CSFD movie reviews (Slovak)\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThe dataset contains user reviews from Czech/Slovak movie databse website https://csfd.cz.\\nEach review contains text, rating, date, and basic information about the movie (or TV series).\\nThe dataset has in total (train+validation+test) 30,000 reviews. The data is balanced - each rating has approximately the same frequency.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Features\\n\\t\\n\\nEach sample contains:\\n\\nreview_id: unique string‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/fewshot-goes-multilingual/sk_csfd-movie-reviews."},
	{"name":"Hansel","keyword":"monolingual","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/HIT-TMG/Hansel","creator_name":"HITsz-Text Machine Group","creator_url":"https://huggingface.co/HIT-TMG","description":"Hansel is a high-quality human-annotated Chinese entity linking (EL) dataset, used for testing Chinese EL systems' generalization ability to tail entities and emerging entities.\\nThe test set contains Few-shot (FS) and zero-shot (ZS) slices, has 10K examples and uses Wikidata as the corresponding knowledge base.\\nThe training and validation sets are from Wikipedia hyperlinks, useful for large-scale pretraining of Chinese EL systems."},
	{"name":"qa_squadshifts_synthetic","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/lmqg/qa_squadshifts_synthetic","creator_name":"LMQG","creator_url":"https://huggingface.co/lmqg","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for \\\"lmqg/qa_squadshifts_synthetic\\\"\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThis is a synthetic QA dataset generated with fine-tuned QG models over lmqg/qa_squadshifts, made for question-answering based evaluation (QAE) for question generation model proposed by Zhang and Bansal, 2019.\\nThe test split is the original validation set of lmqg/qa_squadshifts, where the model should be evaluate on.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSupported Tasks and Leaderboards\\n\\t\\n\\n\\nquestion-answering‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/lmqg/qa_squadshifts_synthetic."},
	{"name":"cs_squad-3.0","keyword":"monolingual","license":"GNU Lesser General Public License v3.0","license_url":"https://choosealicense.com/licenses/lgpl-3.0/","language":"en","dataset_url":"https://huggingface.co/datasets/fewshot-goes-multilingual/cs_squad-3.0","creator_name":"Fewshot Goes Multilingual","creator_url":"https://huggingface.co/fewshot-goes-multilingual","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Czech Simple Question Answering Dataset 3.0\\n\\t\\n\\nThis a processed and filtered adaptation of an existing dataset. For raw and larger dataset, see Dataset Source section.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThe data contains questions and answers based on Czech wikipeadia articles.\\nEach question has an answer (or more) and a selected part of the context as the evidence.\\nA majority of the answers are extractive - i.e. they are present in the context in the exact form.‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/fewshot-goes-multilingual/cs_squad-3.0."},
	{"name":"model-written-evals","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Anthropic/model-written-evals","creator_name":"Anthropic","creator_url":"https://huggingface.co/Anthropic","description":"\\n\\t\\n\\t\\t\\n\\t\\tModel-Written Evaluation Datasets\\n\\t\\n\\nThis repository includes datasets written by language models, used in our paper on \\\"Discovering Language Model Behaviors with Model-Written Evaluations.\\\"\\nWe intend the datasets to be useful to:\\n\\nThose who are interested in understanding the quality and properties of model-generated data\\nThose who wish to use our datasets to evaluate other models for the behaviors we examined in our work (e.g., related to model persona, sycophancy, advanced AI risks‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Anthropic/model-written-evals."},
	{"name":"docprompting-conala","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/neulab/docprompting-conala","creator_name":"NeuLab @ LTI/CMU","creator_url":"https://huggingface.co/neulab","description":"This is the re-split of CoNaLa dataset. For each code snippet in the dev and test set, at least one function is held out from the training set. This split aims at testing a code generation model's capacity in generating unseen functions.\\nWe further make sure that examples from the same StackOverflow post (same question_id before -) are in the same split."},
	{"name":"financial_news_sentiment","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Jean-Baptiste/financial_news_sentiment","creator_name":"JB Polle","creator_url":"https://huggingface.co/Jean-Baptiste","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for \\\"financial_news_sentiment\\\"\\n\\t\\n\\nManually validated sentiment for ~2000 Canadian news articles.\\nThe dataset also include a column topic which contains one of the following value:\\n\\nacquisition\\nother\\nquaterly financial release\\nappointment to new position\\ndividend\\ncorporate update\\ndrillings results\\nconference\\nshare repurchase program\\ngrant of stocks\\n\\nThis was generated automatically using a zero-shot classification model and was not reviewed manually.\\n"},
	{"name":"tox21_srp53","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/zpn/tox21_srp53","creator_name":"Zach Nussbaum","creator_url":"https://huggingface.co/zpn","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for tox21_srp53\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\ntox21_srp53 is a dataset included in MoleculeNet. It is the p53 stress-response pathway activation (SR-p53) task from Tox21.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Structure\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Fields\\n\\t\\n\\nEach split contains\\n\\nsmiles: the SMILES representation of a molecule\\nselfies: the SELFIES representation of a molecule\\ntarget: clinical trial toxicity (or absence of toxicity)\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Splits\\n\\t\\n\\nThe dataset is split into an‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/zpn/tox21_srp53."},
	{"name":"chizuru-ichinose","keyword":"monolingual","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/alexandreteles/chizuru-ichinose","creator_name":"Alexandre Teles","creator_url":"https://huggingface.co/alexandreteles","description":"This dataset is extracted from the Anime \\\"Rent-A-Girlfriend\\\" as posted on Kaggle by xandercubbin.\\nPlease refer to the chizuru_dialog_dataset.ipynb file to see how the dataset was pre-processed.\\n"},
	{"name":"golf-courses","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/bethecloud/golf-courses","creator_name":"Kevin Leffew (GTM @ Replit)","creator_url":"https://huggingface.co/bethecloud","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary: golf-course\\n\\t\\n\\nThis dataset (bethecloud/golf-courses) includes 21 unique images of golf courses pulled from Unsplash.  \\nThe dataset is a collection of photographs taken at various golf courses around the world. The images depict a variety of scenes, including fairways, greens, bunkers, water hazards, and clubhouse facilities. The images are high resolution and have been carefully selected to provide a diverse range of visual content for fine-tuning a machine‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/bethecloud/golf-courses."},
	{"name":"echr_rational","keyword":"monolingual","license":"Academic Free License v3.0","license_url":"https://choosealicense.com/licenses/afl-3.0/","language":"en","dataset_url":"https://huggingface.co/datasets/TUMLegalTech/echr_rational","creator_name":"TUMLegalTech","creator_url":"https://huggingface.co/TUMLegalTech","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for echr_rational\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nDeconfounding Legal Judgment Prediction for European Court of Human\\nRights Cases Towards Better Alignment with Experts\\nThis work demonstrates that Legal Judgement Prediction systems without expert-informed adjustments can be vulnerable to shallow, distracting surface signals that arise from corpus construction, case distribution, and confounding factors. To mitigate this, we use domain expertise to strategically‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/TUMLegalTech/echr_rational."},
	{"name":"hacker_news_with_comments","keyword":"monolingual","license":"Academic Free License v3.0","license_url":"https://choosealicense.com/licenses/afl-3.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Linkseed/hacker_news_with_comments","creator_name":"KunLi","creator_url":"https://huggingface.co/Linkseed","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for [Dataset Name]\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nHacker news until 2015 with comments. Collect from Google BigQuery open dataset. We didn't do any pre-processing except remove HTML tags.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSupported Tasks and Leaderboards\\n\\t\\n\\nComment Generation; News analysis with comments; Other comment-based NLP tasks.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages\\n\\t\\n\\nEnglish\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Fields\\n\\t\\n\\n[More Information Needed]\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Splits\\n\\t\\n\\n[More Information Needed]‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Linkseed/hacker_news_with_comments."},
	{"name":"mdk_gov_data_titles_clf","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/and-effect/mdk_gov_data_titles_clf","creator_name":"&effect data solutions GmbH","creator_url":"https://huggingface.co/and-effect","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for MDK\\n\\t\\n\\nThis dataset was created as part of the Bertelsmann Foundation's \\nMusterdatenkatalog (MDK) project. The MDK provides an overview of Open Data in municipalities in Germany. It is intended to help municipalities in Germany, as well as data analysts and journalists, to get an overview of the topics and the extent to which cities have already published data sets.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThe dataset is an annotated corpus‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/and-effect/mdk_gov_data_titles_clf."},
	{"name":"amz20","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/kuroneko5943/amz20","creator_name":"Wang Song","creator_url":"https://huggingface.co/kuroneko5943","description":"GLUE, the General Language Understanding Evaluation benchmark\\n(https://gluebenchmark.com/) is a collection of resources for training,\\nevaluating, and analyzing natural language understanding systems."},
	{"name":"snap21","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/kuroneko5943/snap21","creator_name":"Wang Song","creator_url":"https://huggingface.co/kuroneko5943","description":"GLUE, the General Language Understanding Evaluation benchmark\\n(https://gluebenchmark.com/) is a collection of resources for training,\\nevaluating, and analyzing natural language understanding systems."},
	{"name":"stock11","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/kuroneko5943/stock11","creator_name":"Wang Song","creator_url":"https://huggingface.co/kuroneko5943","description":"GLUE, the General Language Understanding Evaluation benchmark\\n(https://gluebenchmark.com/) is a collection of resources for training,\\nevaluating, and analyzing natural language understanding systems."},
	{"name":"korfin-asc","keyword":"monolingual","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/amphora/korfin-asc","creator_name":"GUIJIN SON","creator_url":"https://huggingface.co/amphora","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for KorFin-ABSA\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThe KorFin-ASC is an extension of KorFin-ABSA including 8818 samples with (aspect, polarity) pairs annotated. \\nThe samples were collected from KLUE-TC and \\nanalyst reports from Naver Finance. \\nAnnotation of the dataset is described in the paper Removing Non-Stationary Knowledge From Pre-Trained Language Models for Entity-Level Sentiment Classification in Finance.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSupported‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/amphora/korfin-asc."},
	{"name":"LIFD_Seismic_Data","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/cemachelen/LIFD_Seismic_Data","creator_name":"Helen Burns","creator_url":"https://huggingface.co/cemachelen","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for LFID Seismic Data\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nA description of the dataset:\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSupported Tasks and Leaderboards\\n\\t\\n\\ncoming soon - Kaggle links? \\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Fields\\n\\t\\n\\nSAC files\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Creation\\n\\t\\n\\nAll seismic data were downloaded through the IRIS Wilber 3 system (https://ds.iris.edu/wilber3/) or IRIS Web Services (https://service.iris.edu/), including the following seismic networks: (1) the AZ (ANZA; UC San Diego, 1982); (2) the TA‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/cemachelen/LIFD_Seismic_Data."},
	{"name":"douban-dushu","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/larrylawl/douban-dushu","creator_name":"Law Ann Liat Larry","creator_url":"https://huggingface.co/larrylawl","description":"This dataset contains book reviews from DouBan Dushu. DouBan DuShu is a Chinese website where users can share their reviews about various kinds of books. Most of the users in this website are unprofessional book reviewers. Therefore, the comments are usually spoken Chinese or even Internet slang."},
	{"name":"b2w-reviews01","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ruanchaves/b2w-reviews01","creator_name":"Ruan Chaves Rodrigues","creator_url":"https://huggingface.co/ruanchaves","description":"B2W-Reviews01 is an open corpus of product reviews. It contains more than 130k e-commerce customer reviews, collected from the Americanas.com website between January and May, 2018. B2W-Reviews01 offers rich information about the reviewer profile, such as gender, age, and geographical location. The corpus also has two different review rates"},
	{"name":"fake_railroad_company","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/davidwisdom/fake_railroad_company","creator_name":"David Wisdom","creator_url":"https://huggingface.co/davidwisdom","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tfake_railroad_company\\n\\t\\n\\nThis is toy data I created about an imaginary railroad company.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tV1\\n\\t\\n\\nThis is the first version of the data that I generated.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tV2\\n\\t\\n\\nI tweaked some of the weights I used to calculate the satisfaction score.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tV3\\n\\t\\n\\nSome customers are now power users who ride more often than other users.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tV4\\n\\t\\n\\nCustomers with children are more likely to be members\\n"},
	{"name":"defamation-japanese-twitter","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/kubota/defamation-japanese-twitter","creator_name":"Issei","creator_url":"https://huggingface.co/kubota","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tdefamation_japanese_twitter\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tTwitterÊó•Êú¨Ë™ûË™πË¨ó‰∏≠ÂÇ∑Ê§úÂá∫„Éá„Éº„Çø„Çª„ÉÉ„Éà\\n\\t\\n\\n\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nSNS„Å´„Åä„Åë„ÇãË™πË¨ó‰∏≠ÂÇ∑Ê§úÂá∫„ÅÆ„Åü„ÇÅ„ÅÆ„Éá„Éº„Çø„Çª„ÉÉ„Éà„Åß„ÅôÔºé\\n5,000‰ª∂„ÅÆÊó•Êú¨Ë™û„ÅÆ„ÉÑ„Ç§„Éº„Éà„Å´Ôºå„Åù„Çå„Åû„Çå‰ª•‰∏ã„ÅßÂÆöÁæ©„Åó„Å¶„ÅÑ„ÇãË™πË¨ó‰∏≠ÂÇ∑„ÅÆÂØæË±°ËÄÖ„Å®ÂÜÖÂÆπ„Çí„Ç¢„Éé„ÉÜ„Éº„Ç∑„Éß„É≥„Åó„Å¶„ÅÑ„Åæ„ÅôÔºé„Ç¢„Éé„ÉÜ„Éº„Ç∑„Éß„É≥„ÅØÔºå3‰∫∫„ÅÆ„ÇØ„É©„Ç¶„Éâ„ÉØ„Éº„Ç´„Éº„Å´„Çà„ÇäË°å„Çè„Çå„Å¶„ÅÑ„Åæ„ÅôÔºé2022Âπ¥2Êúà15Êó•„Åã„Çâ2022Âπ¥6Êúà30Êó•„Åæ„Åß„ÅÆ„ÉÑ„Ç§„Éº„Éà„Åß„ÅôÔºé\\nÂÖÉ„ÅÆ„ÉÑ„Ç§„Éº„Éà„ÅØÂê´„Åæ„Çå„Å¶„ÅÑ„Å™„ÅÑ„Åü„ÇÅÔºåTwitter API„ÇíÁî®„ÅÑ„Å¶„Éá„Éº„Çø„Çª„ÉÉ„Éà„ÇíÂèéÈõÜ„Åó„Å¶„Åè„Å†„Åï„ÅÑÔºé\\n‰∏≠ÂÇ∑ÂØæË±°(target)„Å®‰∏≠ÂÇ∑ÂÜÖÂÆπ(label)„ÅÆ2È†ÖÁõÆ„Åå„Ç¢„Éé„ÉÜ„Éº„Ç∑„Éß„É≥„Åï„Çå„Å¶„ÅÑ„Åæ„ÅôÔºé\\n\\ntarget Ôºö„ÉÜ„Ç≠„Çπ„Éà„ÅåË©±È°å„Å´„Åó„Å¶„ÅÑ„ÇãÂØæË±°ËÄÖ„ÅÆÂàÜÈ°û\\nlabel Ôºö target„ÅßÈÅ∏Êäû„Åï„Çå„ÅüÂØæË±°ËÄÖ„Å´ÂØæ„Åô„ÇãË™πË¨ó‰∏≠ÂÇ∑„ÅÆÁ®ÆÈ°û„ÅÆÂàÜÈ°û\\n\\nÊñá„Å®„Åó„Å¶ÊàêÁ´ã„Åó„Å¶„Åä„Çâ„ÅöÊÑèÂë≥„ÅÆÂèñ„Çå„Å™„ÅÑ„ÇÇ„ÅÆ„ÅØ„É©„Éô„É´C(0)„Å®„Åó„Å¶„ÅÑ„Åæ„ÅôÔºé\\n\\n\\t\\n\\t\\t\\ntarget\\nÂØæË±°\\n‰æã\\n\\n\\n\\t\\t\\nA1(1)‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/kubota/defamation-japanese-twitter."},
	{"name":"hungarian-single-speaker-tts","keyword":"monolingual","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/KTH/hungarian-single-speaker-tts","creator_name":"KTH","creator_url":"https://huggingface.co/KTH","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for CSS10 Hungarian: Single Speaker Speech Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThe corpus consists of a single speaker, with 4515 segments extracted\\nfrom a single LibriVox audiobook.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSupported Tasks and Leaderboards\\n\\t\\n\\n[Needs More Information]\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages\\n\\t\\n\\nThe audio is in Hungarian.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Structure\\n\\t\\n\\n[Needs More Information]\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Instances\\n\\t\\n\\n[Needs More Information]\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Fields\\n\\t\\n\\n[Needs More‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/KTH/hungarian-single-speaker-tts."},
	{"name":"nfcorpus-top-20-gen-queries","keyword":"monolingual","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/income/nfcorpus-top-20-gen-queries","creator_name":"INCOME","creator_url":"https://huggingface.co/income","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tNFCorpus: 20 generated queries (BEIR Benchmark)\\n\\t\\n\\nThis HF dataset contains the top-20 synthetic queries generated for each passage in the above BEIR benchmark dataset.\\n\\nDocT5query model used: BeIR/query-gen-msmarco-t5-base-v1\\nid (str): unique document id in NFCorpus in the BEIR benchmark (corpus.jsonl).\\nQuestions generated: 20\\nCode used for generation: evaluate_anserini_docT5query_parallel.py\\n\\nBelow contains the old dataset card for the BEIR benchmark.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/income/nfcorpus-top-20-gen-queries."},
	{"name":"fiqa-top-20-gen-queries","keyword":"monolingual","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/income/fiqa-top-20-gen-queries","creator_name":"INCOME","creator_url":"https://huggingface.co/income","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tNFCorpus: 20 generated queries (BEIR Benchmark)\\n\\t\\n\\nThis HF dataset contains the top-20 synthetic queries generated for each passage in the above BEIR benchmark dataset.\\n\\nDocT5query model used: BeIR/query-gen-msmarco-t5-base-v1\\nid (str): unique document id in NFCorpus in the BEIR benchmark (corpus.jsonl).\\nQuestions generated: 20\\nCode used for generation: evaluate_anserini_docT5query_parallel.py\\n\\nBelow contains the old dataset card for the BEIR benchmark.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/income/fiqa-top-20-gen-queries."},
	{"name":"scifact-top-20-gen-queries","keyword":"monolingual","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/income/scifact-top-20-gen-queries","creator_name":"INCOME","creator_url":"https://huggingface.co/income","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tNFCorpus: 20 generated queries (BEIR Benchmark)\\n\\t\\n\\nThis HF dataset contains the top-20 synthetic queries generated for each passage in the above BEIR benchmark dataset.\\n\\nDocT5query model used: BeIR/query-gen-msmarco-t5-base-v1\\nid (str): unique document id in NFCorpus in the BEIR benchmark (corpus.jsonl).\\nQuestions generated: 20\\nCode used for generation: evaluate_anserini_docT5query_parallel.py\\n\\nBelow contains the old dataset card for the BEIR benchmark.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/income/scifact-top-20-gen-queries."},
	{"name":"trec-news-top-20-gen-queries","keyword":"monolingual","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/income/trec-news-top-20-gen-queries","creator_name":"INCOME","creator_url":"https://huggingface.co/income","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tNFCorpus: 20 generated queries (BEIR Benchmark)\\n\\t\\n\\nThis HF dataset contains the top-20 synthetic queries generated for each passage in the above BEIR benchmark dataset.\\n\\nDocT5query model used: BeIR/query-gen-msmarco-t5-base-v1\\nid (str): unique document id in NFCorpus in the BEIR benchmark (corpus.jsonl).\\nQuestions generated: 20\\nCode used for generation: evaluate_anserini_docT5query_parallel.py\\n\\nBelow contains the old dataset card for the BEIR benchmark.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/income/trec-news-top-20-gen-queries."},
	{"name":"robust04-top-20-gen-queries","keyword":"monolingual","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/income/robust04-top-20-gen-queries","creator_name":"INCOME","creator_url":"https://huggingface.co/income","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tNFCorpus: 20 generated queries (BEIR Benchmark)\\n\\t\\n\\nThis HF dataset contains the top-20 synthetic queries generated for each passage in the above BEIR benchmark dataset.\\n\\nDocT5query model used: BeIR/query-gen-msmarco-t5-base-v1\\nid (str): unique document id in NFCorpus in the BEIR benchmark (corpus.jsonl).\\nQuestions generated: 20\\nCode used for generation: evaluate_anserini_docT5query_parallel.py\\n\\nBelow contains the old dataset card for the BEIR benchmark.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/income/robust04-top-20-gen-queries."},
	{"name":"scidocs-top-20-gen-queries","keyword":"monolingual","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/income/scidocs-top-20-gen-queries","creator_name":"INCOME","creator_url":"https://huggingface.co/income","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tNFCorpus: 20 generated queries (BEIR Benchmark)\\n\\t\\n\\nThis HF dataset contains the top-20 synthetic queries generated for each passage in the above BEIR benchmark dataset.\\n\\nDocT5query model used: BeIR/query-gen-msmarco-t5-base-v1\\nid (str): unique document id in NFCorpus in the BEIR benchmark (corpus.jsonl).\\nQuestions generated: 20\\nCode used for generation: evaluate_anserini_docT5query_parallel.py\\n\\nBelow contains the old dataset card for the BEIR benchmark.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/income/scidocs-top-20-gen-queries."},
	{"name":"arguana-top-20-gen-queries","keyword":"monolingual","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/income/arguana-top-20-gen-queries","creator_name":"INCOME","creator_url":"https://huggingface.co/income","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tNFCorpus: 20 generated queries (BEIR Benchmark)\\n\\t\\n\\nThis HF dataset contains the top-20 synthetic queries generated for each passage in the above BEIR benchmark dataset.\\n\\nDocT5query model used: BeIR/query-gen-msmarco-t5-base-v1\\nid (str): unique document id in NFCorpus in the BEIR benchmark (corpus.jsonl).\\nQuestions generated: 20\\nCode used for generation: evaluate_anserini_docT5query_parallel.py\\n\\nBelow contains the old dataset card for the BEIR benchmark.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/income/arguana-top-20-gen-queries."},
	{"name":"trec-covid-top-20-gen-queries","keyword":"monolingual","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/income/trec-covid-top-20-gen-queries","creator_name":"INCOME","creator_url":"https://huggingface.co/income","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tNFCorpus: 20 generated queries (BEIR Benchmark)\\n\\t\\n\\nThis HF dataset contains the top-20 synthetic queries generated for each passage in the above BEIR benchmark dataset.\\n\\nDocT5query model used: BeIR/query-gen-msmarco-t5-base-v1\\nid (str): unique document id in NFCorpus in the BEIR benchmark (corpus.jsonl).\\nQuestions generated: 20\\nCode used for generation: evaluate_anserini_docT5query_parallel.py\\n\\nBelow contains the old dataset card for the BEIR benchmark.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/income/trec-covid-top-20-gen-queries."},
	{"name":"quora-top-20-gen-queries","keyword":"monolingual","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/income/quora-top-20-gen-queries","creator_name":"INCOME","creator_url":"https://huggingface.co/income","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tNFCorpus: 20 generated queries (BEIR Benchmark)\\n\\t\\n\\nThis HF dataset contains the top-20 synthetic queries generated for each passage in the above BEIR benchmark dataset.\\n\\nDocT5query model used: BeIR/query-gen-msmarco-t5-base-v1\\nid (str): unique document id in NFCorpus in the BEIR benchmark (corpus.jsonl).\\nQuestions generated: 20\\nCode used for generation: evaluate_anserini_docT5query_parallel.py\\n\\nBelow contains the old dataset card for the BEIR benchmark.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/income/quora-top-20-gen-queries."},
	{"name":"webis-touche2020-top-20-gen-queries","keyword":"monolingual","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/income/webis-touche2020-top-20-gen-queries","creator_name":"INCOME","creator_url":"https://huggingface.co/income","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tNFCorpus: 20 generated queries (BEIR Benchmark)\\n\\t\\n\\nThis HF dataset contains the top-20 synthetic queries generated for each passage in the above BEIR benchmark dataset.\\n\\nDocT5query model used: BeIR/query-gen-msmarco-t5-base-v1\\nid (str): unique document id in NFCorpus in the BEIR benchmark (corpus.jsonl).\\nQuestions generated: 20\\nCode used for generation: evaluate_anserini_docT5query_parallel.py\\n\\nBelow contains the old dataset card for the BEIR benchmark.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/income/webis-touche2020-top-20-gen-queries."},
	{"name":"hotpotqa-top-20-gen-queries","keyword":"monolingual","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/income/hotpotqa-top-20-gen-queries","creator_name":"INCOME","creator_url":"https://huggingface.co/income","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tNFCorpus: 20 generated queries (BEIR Benchmark)\\n\\t\\n\\nThis HF dataset contains the top-20 synthetic queries generated for each passage in the above BEIR benchmark dataset.\\n\\nDocT5query model used: BeIR/query-gen-msmarco-t5-base-v1\\nid (str): unique document id in NFCorpus in the BEIR benchmark (corpus.jsonl).\\nQuestions generated: 20\\nCode used for generation: evaluate_anserini_docT5query_parallel.py\\n\\nBelow contains the old dataset card for the BEIR benchmark.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/income/hotpotqa-top-20-gen-queries."},
	{"name":"dbpedia-entity-top-20-gen-queries","keyword":"monolingual","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/income/dbpedia-entity-top-20-gen-queries","creator_name":"INCOME","creator_url":"https://huggingface.co/income","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tNFCorpus: 20 generated queries (BEIR Benchmark)\\n\\t\\n\\nThis HF dataset contains the top-20 synthetic queries generated for each passage in the above BEIR benchmark dataset.\\n\\nDocT5query model used: BeIR/query-gen-msmarco-t5-base-v1\\nid (str): unique document id in NFCorpus in the BEIR benchmark (corpus.jsonl).\\nQuestions generated: 20\\nCode used for generation: evaluate_anserini_docT5query_parallel.py\\n\\nBelow contains the old dataset card for the BEIR benchmark.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/income/dbpedia-entity-top-20-gen-queries."},
	{"name":"fever-top-20-gen-queries","keyword":"monolingual","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/income/fever-top-20-gen-queries","creator_name":"INCOME","creator_url":"https://huggingface.co/income","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tNFCorpus: 20 generated queries (BEIR Benchmark)\\n\\t\\n\\nThis HF dataset contains the top-20 synthetic queries generated for each passage in the above BEIR benchmark dataset.\\n\\nDocT5query model used: BeIR/query-gen-msmarco-t5-base-v1\\nid (str): unique document id in NFCorpus in the BEIR benchmark (corpus.jsonl).\\nQuestions generated: 20\\nCode used for generation: evaluate_anserini_docT5query_parallel.py\\n\\nBelow contains the old dataset card for the BEIR benchmark.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/income/fever-top-20-gen-queries."},
	{"name":"climate-fever-top-20-gen-queries","keyword":"monolingual","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/income/climate-fever-top-20-gen-queries","creator_name":"INCOME","creator_url":"https://huggingface.co/income","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tNFCorpus: 20 generated queries (BEIR Benchmark)\\n\\t\\n\\nThis HF dataset contains the top-20 synthetic queries generated for each passage in the above BEIR benchmark dataset.\\n\\nDocT5query model used: BeIR/query-gen-msmarco-t5-base-v1\\nid (str): unique document id in NFCorpus in the BEIR benchmark (corpus.jsonl).\\nQuestions generated: 20\\nCode used for generation: evaluate_anserini_docT5query_parallel.py\\n\\nBelow contains the old dataset card for the BEIR benchmark.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/income/climate-fever-top-20-gen-queries."},
	{"name":"signal1m-top-20-gen-queries","keyword":"monolingual","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/income/signal1m-top-20-gen-queries","creator_name":"INCOME","creator_url":"https://huggingface.co/income","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tNFCorpus: 20 generated queries (BEIR Benchmark)\\n\\t\\n\\nThis HF dataset contains the top-20 synthetic queries generated for each passage in the above BEIR benchmark dataset.\\n\\nDocT5query model used: BeIR/query-gen-msmarco-t5-base-v1\\nid (str): unique document id in NFCorpus in the BEIR benchmark (corpus.jsonl).\\nQuestions generated: 20\\nCode used for generation: evaluate_anserini_docT5query_parallel.py\\n\\nBelow contains the old dataset card for the BEIR benchmark.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/income/signal1m-top-20-gen-queries."},
	{"name":"nq-top-20-gen-queries","keyword":"monolingual","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/income/nq-top-20-gen-queries","creator_name":"INCOME","creator_url":"https://huggingface.co/income","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tNFCorpus: 20 generated queries (BEIR Benchmark)\\n\\t\\n\\nThis HF dataset contains the top-20 synthetic queries generated for each passage in the above BEIR benchmark dataset.\\n\\nDocT5query model used: BeIR/query-gen-msmarco-t5-base-v1\\nid (str): unique document id in NFCorpus in the BEIR benchmark (corpus.jsonl).\\nQuestions generated: 20\\nCode used for generation: evaluate_anserini_docT5query_parallel.py\\n\\nBelow contains the old dataset card for the BEIR benchmark.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/income/nq-top-20-gen-queries."},
	{"name":"cqadupstack-android-top-20-gen-queries","keyword":"monolingual","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/income/cqadupstack-android-top-20-gen-queries","creator_name":"INCOME","creator_url":"https://huggingface.co/income","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tNFCorpus: 20 generated queries (BEIR Benchmark)\\n\\t\\n\\nThis HF dataset contains the top-20 synthetic queries generated for each passage in the above BEIR benchmark dataset.\\n\\nDocT5query model used: BeIR/query-gen-msmarco-t5-base-v1\\nid (str): unique document id in NFCorpus in the BEIR benchmark (corpus.jsonl).\\nQuestions generated: 20\\nCode used for generation: evaluate_anserini_docT5query_parallel.py\\n\\nBelow contains the old dataset card for the BEIR benchmark.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/income/cqadupstack-android-top-20-gen-queries."},
	{"name":"cqadupstack-english-top-20-gen-queries","keyword":"monolingual","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/income/cqadupstack-english-top-20-gen-queries","creator_name":"INCOME","creator_url":"https://huggingface.co/income","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tNFCorpus: 20 generated queries (BEIR Benchmark)\\n\\t\\n\\nThis HF dataset contains the top-20 synthetic queries generated for each passage in the above BEIR benchmark dataset.\\n\\nDocT5query model used: BeIR/query-gen-msmarco-t5-base-v1\\nid (str): unique document id in NFCorpus in the BEIR benchmark (corpus.jsonl).\\nQuestions generated: 20\\nCode used for generation: evaluate_anserini_docT5query_parallel.py\\n\\nBelow contains the old dataset card for the BEIR benchmark.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/income/cqadupstack-english-top-20-gen-queries."},
	{"name":"cqadupstack-gaming-top-20-gen-queries","keyword":"monolingual","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/income/cqadupstack-gaming-top-20-gen-queries","creator_name":"INCOME","creator_url":"https://huggingface.co/income","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tNFCorpus: 20 generated queries (BEIR Benchmark)\\n\\t\\n\\nThis HF dataset contains the top-20 synthetic queries generated for each passage in the above BEIR benchmark dataset.\\n\\nDocT5query model used: BeIR/query-gen-msmarco-t5-base-v1\\nid (str): unique document id in NFCorpus in the BEIR benchmark (corpus.jsonl).\\nQuestions generated: 20\\nCode used for generation: evaluate_anserini_docT5query_parallel.py\\n\\nBelow contains the old dataset card for the BEIR benchmark.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/income/cqadupstack-gaming-top-20-gen-queries."},
	{"name":"cqadupstack-gis-top-20-gen-queries","keyword":"monolingual","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/income/cqadupstack-gis-top-20-gen-queries","creator_name":"INCOME","creator_url":"https://huggingface.co/income","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tNFCorpus: 20 generated queries (BEIR Benchmark)\\n\\t\\n\\nThis HF dataset contains the top-20 synthetic queries generated for each passage in the above BEIR benchmark dataset.\\n\\nDocT5query model used: BeIR/query-gen-msmarco-t5-base-v1\\nid (str): unique document id in NFCorpus in the BEIR benchmark (corpus.jsonl).\\nQuestions generated: 20\\nCode used for generation: evaluate_anserini_docT5query_parallel.py\\n\\nBelow contains the old dataset card for the BEIR benchmark.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/income/cqadupstack-gis-top-20-gen-queries."},
	{"name":"cqadupstack-mathematica-top-20-gen-queries","keyword":"monolingual","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/income/cqadupstack-mathematica-top-20-gen-queries","creator_name":"INCOME","creator_url":"https://huggingface.co/income","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tNFCorpus: 20 generated queries (BEIR Benchmark)\\n\\t\\n\\nThis HF dataset contains the top-20 synthetic queries generated for each passage in the above BEIR benchmark dataset.\\n\\nDocT5query model used: BeIR/query-gen-msmarco-t5-base-v1\\nid (str): unique document id in NFCorpus in the BEIR benchmark (corpus.jsonl).\\nQuestions generated: 20\\nCode used for generation: evaluate_anserini_docT5query_parallel.py\\n\\nBelow contains the old dataset card for the BEIR benchmark.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/income/cqadupstack-mathematica-top-20-gen-queries."},
	{"name":"cqadupstack-physics-top-20-gen-queries","keyword":"monolingual","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/income/cqadupstack-physics-top-20-gen-queries","creator_name":"INCOME","creator_url":"https://huggingface.co/income","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tNFCorpus: 20 generated queries (BEIR Benchmark)\\n\\t\\n\\nThis HF dataset contains the top-20 synthetic queries generated for each passage in the above BEIR benchmark dataset.\\n\\nDocT5query model used: BeIR/query-gen-msmarco-t5-base-v1\\nid (str): unique document id in NFCorpus in the BEIR benchmark (corpus.jsonl).\\nQuestions generated: 20\\nCode used for generation: evaluate_anserini_docT5query_parallel.py\\n\\nBelow contains the old dataset card for the BEIR benchmark.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/income/cqadupstack-physics-top-20-gen-queries."},
	{"name":"cqadupstack-programmers-top-20-gen-queries","keyword":"monolingual","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/income/cqadupstack-programmers-top-20-gen-queries","creator_name":"INCOME","creator_url":"https://huggingface.co/income","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tNFCorpus: 20 generated queries (BEIR Benchmark)\\n\\t\\n\\nThis HF dataset contains the top-20 synthetic queries generated for each passage in the above BEIR benchmark dataset.\\n\\nDocT5query model used: BeIR/query-gen-msmarco-t5-base-v1\\nid (str): unique document id in NFCorpus in the BEIR benchmark (corpus.jsonl).\\nQuestions generated: 20\\nCode used for generation: evaluate_anserini_docT5query_parallel.py\\n\\nBelow contains the old dataset card for the BEIR benchmark.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/income/cqadupstack-programmers-top-20-gen-queries."},
	{"name":"cqadupstack-stats-top-20-gen-queries","keyword":"monolingual","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/income/cqadupstack-stats-top-20-gen-queries","creator_name":"INCOME","creator_url":"https://huggingface.co/income","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tNFCorpus: 20 generated queries (BEIR Benchmark)\\n\\t\\n\\nThis HF dataset contains the top-20 synthetic queries generated for each passage in the above BEIR benchmark dataset.\\n\\nDocT5query model used: BeIR/query-gen-msmarco-t5-base-v1\\nid (str): unique document id in NFCorpus in the BEIR benchmark (corpus.jsonl).\\nQuestions generated: 20\\nCode used for generation: evaluate_anserini_docT5query_parallel.py\\n\\nBelow contains the old dataset card for the BEIR benchmark.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/income/cqadupstack-stats-top-20-gen-queries."},
	{"name":"cqadupstack-tex-top-20-gen-queries","keyword":"monolingual","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/income/cqadupstack-tex-top-20-gen-queries","creator_name":"INCOME","creator_url":"https://huggingface.co/income","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tNFCorpus: 20 generated queries (BEIR Benchmark)\\n\\t\\n\\nThis HF dataset contains the top-20 synthetic queries generated for each passage in the above BEIR benchmark dataset.\\n\\nDocT5query model used: BeIR/query-gen-msmarco-t5-base-v1\\nid (str): unique document id in NFCorpus in the BEIR benchmark (corpus.jsonl).\\nQuestions generated: 20\\nCode used for generation: evaluate_anserini_docT5query_parallel.py\\n\\nBelow contains the old dataset card for the BEIR benchmark.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/income/cqadupstack-tex-top-20-gen-queries."},
	{"name":"cqadupstack-unix-top-20-gen-queries","keyword":"monolingual","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/income/cqadupstack-unix-top-20-gen-queries","creator_name":"INCOME","creator_url":"https://huggingface.co/income","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tNFCorpus: 20 generated queries (BEIR Benchmark)\\n\\t\\n\\nThis HF dataset contains the top-20 synthetic queries generated for each passage in the above BEIR benchmark dataset.\\n\\nDocT5query model used: BeIR/query-gen-msmarco-t5-base-v1\\nid (str): unique document id in NFCorpus in the BEIR benchmark (corpus.jsonl).\\nQuestions generated: 20\\nCode used for generation: evaluate_anserini_docT5query_parallel.py\\n\\nBelow contains the old dataset card for the BEIR benchmark.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/income/cqadupstack-unix-top-20-gen-queries."},
	{"name":"cqadupstack-webmasters-top-20-gen-queries","keyword":"monolingual","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/income/cqadupstack-webmasters-top-20-gen-queries","creator_name":"INCOME","creator_url":"https://huggingface.co/income","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tNFCorpus: 20 generated queries (BEIR Benchmark)\\n\\t\\n\\nThis HF dataset contains the top-20 synthetic queries generated for each passage in the above BEIR benchmark dataset.\\n\\nDocT5query model used: BeIR/query-gen-msmarco-t5-base-v1\\nid (str): unique document id in NFCorpus in the BEIR benchmark (corpus.jsonl).\\nQuestions generated: 20\\nCode used for generation: evaluate_anserini_docT5query_parallel.py\\n\\nBelow contains the old dataset card for the BEIR benchmark.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/income/cqadupstack-webmasters-top-20-gen-queries."},
	{"name":"cqadupstack-wordpress-top-20-gen-queries","keyword":"monolingual","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/income/cqadupstack-wordpress-top-20-gen-queries","creator_name":"INCOME","creator_url":"https://huggingface.co/income","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tNFCorpus: 20 generated queries (BEIR Benchmark)\\n\\t\\n\\nThis HF dataset contains the top-20 synthetic queries generated for each passage in the above BEIR benchmark dataset.\\n\\nDocT5query model used: BeIR/query-gen-msmarco-t5-base-v1\\nid (str): unique document id in NFCorpus in the BEIR benchmark (corpus.jsonl).\\nQuestions generated: 20\\nCode used for generation: evaluate_anserini_docT5query_parallel.py\\n\\nBelow contains the old dataset card for the BEIR benchmark.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/income/cqadupstack-wordpress-top-20-gen-queries."},
	{"name":"hl","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/michelecafagna26/hl","creator_name":"Michele Cafagna","creator_url":"https://huggingface.co/michelecafagna26","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for the High-Level Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThe High-Level (HL) dataset aligns object-centric descriptions from COCO \\nwith high-level descriptions crowdsourced along 3 axes: scene, action, rationale\\nThe HL dataset contains 14997 images from COCO and a total of 134973 crowdsourced captions (3 captions for each axis) aligned with ~749984 object-centric captions from COCO.\\nEach axis is collected by asking the following 3 questions:\\n\\nWhere is the‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/michelecafagna26/hl."},
	{"name":"pile-detoxify","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/tomekkorbak/pile-detoxify","creator_name":"Tomek Korbak","creator_url":"https://huggingface.co/tomekkorbak","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for pile-pii-scrubadub\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThis dataset contains text from The Pile, annotated based on the toxicity of each sentence.\\nEach document (row in the dataset) is segmented into sentences, and each sentence is given a score: the toxicity predicted by the Detoxify.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSupported Tasks and Leaderboards\\n\\t\\n\\n[More Information Needed]\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages\\n\\t\\n\\nThis dataset is taken from The Pile, which is English text.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/tomekkorbak/pile-detoxify."},
	{"name":"pile-pii-scrubadub","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/tomekkorbak/pile-pii-scrubadub","creator_name":"Tomek Korbak","creator_url":"https://huggingface.co/tomekkorbak","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for pile-pii-scrubadub\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThis dataset contains text from The Pile, annotated based on the personal idenfitiable information (PII) in each sentence.\\nEach document (row in the dataset) is segmented into sentences, and each sentence is given a score: the percentage of words in it that are classified as PII by Scrubadub.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSupported Tasks and Leaderboards\\n\\t\\n\\n[More Information Needed]\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages\\n\\t\\n\\nThis dataset is taken‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/tomekkorbak/pile-pii-scrubadub."},
	{"name":"competition_math","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/qwedsacf/competition_math","creator_name":"Michael Vechtomov","creator_url":"https://huggingface.co/qwedsacf","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Mathematics Aptitude Test of Heuristics (MATH) dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThe Mathematics Aptitude Test of Heuristics (MATH) dataset consists of problems\\nfrom mathematics competitions, including the AMC 10, AMC 12, AIME, and more. \\nEach problem in MATH has a full step-by-step solution, which can be used to teach\\nmodels to generate answer derivations and explanations.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSupported Tasks and Leaderboards\\n\\t\\n\\n[More Information Needed]‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/qwedsacf/competition_math."},
	{"name":"multiglue","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/MtCelesteMa/multiglue","creator_name":"Celeste Ma","creator_url":"https://huggingface.co/MtCelesteMa","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for MultiGLUE\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThis dataset is a combination of the cola, mrpc, qnli, qqp, rte, sst2, and wnli subsets of the GLUE dataset. Its intended use is to benchmark language models on multitask binary classification.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSupported Tasks and Leaderboards\\n\\t\\n\\n[More Information Needed]\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages\\n\\t\\n\\nLike the GLUE dataset, this dataset is in English.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Structure\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Instances\\n\\t\\n\\nAn example‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/MtCelesteMa/multiglue."},
	{"name":"alsqa","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/biu-nlp/alsqa","creator_name":"Bar-Ilan University NLP Lab","creator_url":"https://huggingface.co/biu-nlp","description":"To test the lexical overlap heuristic utilization in Reading Comprehension models, we create a new test set: Analyzing Lexically Similar QA (ALSQA).\\nWe augment the SQuAD 2.0 dataset (Rajpurkar et al., 2018) by asking crowdworkers to generate questions with high context-overlap from questions with low overlap (These questions are paraphrases of the original questions).\\nIn the case of un-answerable questions, annotators were asked to re-write the question without changing its meaning and maintain the unanswerability reason.3 ALSQA contains 365 questions pairs, 190 with an- swer and 174 without answer."},
	{"name":"bioasq-top-20-gen-queries","keyword":"monolingual","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/income/bioasq-top-20-gen-queries","creator_name":"INCOME","creator_url":"https://huggingface.co/income","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tNFCorpus: 20 generated queries (BEIR Benchmark)\\n\\t\\n\\nThis HF dataset contains the top-20 synthetic queries generated for each passage in the above BEIR benchmark dataset.\\n\\nDocT5query model used: BeIR/query-gen-msmarco-t5-base-v1\\nid (str): unique document id in NFCorpus in the BEIR benchmark (corpus.jsonl).\\nQuestions generated: 20\\nCode used for generation: evaluate_anserini_docT5query_parallel.py\\n\\nBelow contains the old dataset card for the BEIR benchmark.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/income/bioasq-top-20-gen-queries."},
	{"name":"fstdt-quotes","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/MtCelesteMa/fstdt-quotes","creator_name":"Celeste Ma","creator_url":"https://huggingface.co/MtCelesteMa","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for FSTDT Quotes\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nFSTDT Quotes is a snapshot of the Fundies Say the Darndest Things website taken on 2023/02/03 14:16. It is intended for hate and fringe speech detection and classification.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSupported Tasks and Leaderboards\\n\\t\\n\\n[More Information Needed]\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages\\n\\t\\n\\nFSTDT Quotes is in English.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Structure\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Instances\\n\\t\\n\\nAn example instance looks like this:\\n{\\n  \\\"id\\\": \\\"G\\\"‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/MtCelesteMa/fstdt-quotes."},
	{"name":"bioleaflets-biomedical-ner","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ruslan/bioleaflets-biomedical-ner","creator_name":"Ruslan Yermak","creator_url":"https://huggingface.co/ruslan","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for BioLeaflets Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nBioLeaflets is a biomedical dataset for Data2Text generation. It is a corpus of 1,336 package leaflets of medicines authorised in Europe, which were obtained by scraping the European Medicines Agency (EMA) website. \\nPackage leaflets are included in the packaging of medicinal products and contain information to help patients use the product safely and appropriately. \\nThis dataset comprises the large majority (‚àº‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ruslan/bioleaflets-biomedical-ner."},
	{"name":"soda_synthetic_dialogue","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/emozilla/soda_synthetic_dialogue","creator_name":"Jeffrey Quesnelle","creator_url":"https://huggingface.co/emozilla","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for ü•§SODA Synthetic Dialogue\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nü•§SODA Synthetic Dialogue is a set of synthetic dialogues between Assistant and\\nUser. In each conversation, User asks Assistant to perform summarization or\\nstory generation tasks based on a snippet of an existing dialogue, story, or\\nfrom a title or theme.\\nThis data was created by synthesizing the dialogues in\\nü•§Soda and applying a set of\\ntemplates to generate the conversation. The original research paper‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/emozilla/soda_synthetic_dialogue."},
	{"name":"test","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/j-krzywdziak/test","creator_name":"Justyna Krzywdziak","creator_url":"https://huggingface.co/j-krzywdziak","description":"Lorem ipsum"},
	{"name":"Bundestag-v2","keyword":"monolingual","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/threite/Bundestag-v2","creator_name":"Thomas Reitenspiess","creator_url":"https://huggingface.co/threite","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Bundestag-v2\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThis dataset was generated from the ParlSpeech V2 dataset. It contains speeches from the german parliament from 1990 until 2020 labelled with the party of the speaker.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSupported Tasks\\n\\t\\n\\nText Classification\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages\\n\\t\\n\\nGerman\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Structure\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Fields\\n\\t\\n\\n\\ntext: Transcript of the speech in german\\nparty: Party of the speaker\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Splits\\n\\t\\n\\n\\ntrain‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/threite/Bundestag-v2."},
	{"name":"squad-v1.1-t5-question-generation","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/derek-thomas/squad-v1.1-t5-question-generation","creator_name":"Derek Thomas","creator_url":"https://huggingface.co/derek-thomas","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for \\\"squad-v1.1-t5-question-generation\\\"\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThis is a modified Stanford Question Answering Dataset (SQuAD) to suit question generation with All Questions in One Line (AQOL) just like in Transformer-based End-to-End Question Generation\\nspecifically for the T5 family of models. The prefix is generate questions:  so that the task can be unique to a trained model.\\nCheck out the generation notebook here.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSupported Tasks and‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/derek-thomas/squad-v1.1-t5-question-generation."},
	{"name":"ddisco","keyword":"monolingual","license":"Academic Free License v3.0","license_url":"https://choosealicense.com/licenses/afl-3.0/","language":"en","dataset_url":"https://huggingface.co/datasets/alexandrainst/ddisco","creator_name":"Alexandra Institute","creator_url":"https://huggingface.co/alexandrainst","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for DDisco\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThe DDisco dataset is a dataset which can be used to train models to classify levels of coherence in danish discourse. Each entry in the dataset is annotated with a discourse coherence label (rating from 1 to 3):\\n1: low coherence (difficult to understand, unorganized, contained unnecessary details and can not be summarized briefly and easily)\\n2: medium coherence\\n3: high coherence (easy to understand, well organized, only‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/alexandrainst/ddisco."},
	{"name":"recipepairs","keyword":"monolingual","license":"GNU General Public License v3.0","license_url":"https://choosealicense.com/licenses/gpl-3.0/","language":"en","dataset_url":"https://huggingface.co/datasets/lishuyang/recipepairs","creator_name":"Shuyang Li","creator_url":"https://huggingface.co/lishuyang","description":"RecipePairs dataset, originally from the 2022 EMNLP paper: \\\"SHARE: a System for Hierarchical Assistive Recipe Editing\\\" by Shuyang Li, Yufei Li, Jianmo Ni, and Julian McAuley.\\nThis version (1.5.0) has been updated with 6.9M pairs of base -> target recipes, alongside their name overlap, IOU (longest common subsequence / union), and target dietary categories.\\nThese cover the 459K recipes from the original GeniusKitcen/Food.com dataset.\\nIf you would like to use this data or found it useful in your‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/lishuyang/recipepairs."},
	{"name":"humaneval-rust","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/diversoailab/humaneval-rust","creator_name":"Diverso AI Lab","creator_url":"https://huggingface.co/diversoailab","description":"diversoailab/humaneval-rust dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"test2","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/j-krzywdziak/test2","creator_name":"Justyna Krzywdziak","creator_url":"https://huggingface.co/j-krzywdziak","description":"Lorem ipsum"},
	{"name":"incivility-arizona-daily-star-comments","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/civility-lab/incivility-arizona-daily-star-comments","creator_name":"Civility Lab","creator_url":"https://huggingface.co/civility-lab","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for incivility-arizona-daily-star-comments\\n\\t\\n\\nThis is a collection of more than 6000 comments on Arizona Daily Star news articles from 2011 that have been manually annotated for various forms of incivility including aspersion, namecalling, sarcasm, and vulgarity.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Structure\\n\\t\\n\\nEach instance in the dataset corresponds to a single comment from a single commenter.\\nAn instance's text field contains the text of the comment with any quotes of other‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/civility-lab/incivility-arizona-daily-star-comments."},
	{"name":"srsd-feynman_easy_dummy","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/yoshitomo-matsubara/srsd-feynman_easy_dummy","creator_name":"Yoshitomo Matsubara","creator_url":"https://huggingface.co/yoshitomo-matsubara","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for SRSD-Feynman (Easy set with Dummy Variables)\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nOur SRSD (Feynman) datasets are designed to discuss the performance of Symbolic Regression for Scientific Discovery.\\nWe carefully reviewed the properties of each formula and its variables in the Feynman Symbolic Regression Database to design reasonably realistic sampling range of values so that our SRSD datasets can be used for evaluating the potential of SRSD such as whether or not an‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/yoshitomo-matsubara/srsd-feynman_easy_dummy."},
	{"name":"srsd-feynman_medium_dummy","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/yoshitomo-matsubara/srsd-feynman_medium_dummy","creator_name":"Yoshitomo Matsubara","creator_url":"https://huggingface.co/yoshitomo-matsubara","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for SRSD-Feynman (Medium set with Dummy Variables)\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nOur SRSD (Feynman) datasets are designed to discuss the performance of Symbolic Regression for Scientific Discovery.\\nWe carefully reviewed the properties of each formula and its variables in the Feynman Symbolic Regression Database to design reasonably realistic sampling range of values so that our SRSD datasets can be used for evaluating the potential of SRSD such as whether or not an‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/yoshitomo-matsubara/srsd-feynman_medium_dummy."},
	{"name":"srsd-feynman_hard_dummy","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/yoshitomo-matsubara/srsd-feynman_hard_dummy","creator_name":"Yoshitomo Matsubara","creator_url":"https://huggingface.co/yoshitomo-matsubara","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for SRSD-Feynman (Hard set with Dummy Variables)\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nOur SRSD (Feynman) datasets are designed to discuss the performance of Symbolic Regression for Scientific Discovery.\\nWe carefully reviewed the properties of each formula and its variables in the Feynman Symbolic Regression Database to design reasonably realistic sampling range of values so that our SRSD datasets can be used for evaluating the potential of SRSD such as whether or not an‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/yoshitomo-matsubara/srsd-feynman_hard_dummy."},
	{"name":"skolmat","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/amcoff/skolmat","creator_name":"√Öke Amcoff","creator_url":"https://huggingface.co/amcoff","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Skolmat\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\n[More Information Needed]\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSupported Tasks and Leaderboards\\n\\t\\n\\n[More Information Needed]\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages\\n\\t\\n\\n[More Information Needed]\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Structure\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Instances\\n\\t\\n\\n[More Information Needed]\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Fields\\n\\t\\n\\n[More Information Needed]\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Splits\\n\\t\\n\\n[More Information Needed]\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Creation\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tCuration Rationale\\n\\t\\n\\n[More‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/amcoff/skolmat."},
	{"name":"news-ro-offense","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/readerbench/news-ro-offense","creator_name":"ReaderBench","creator_url":"https://huggingface.co/readerbench","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for \\\"RO-News-Offense\\\"\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\na novel Romanian language dataset for offensive message detection with manually \\nannotated comment from a local Romanian news website (stiri de cluj) into five classes:\\n\\nnon-offensive\\ntargeted insults\\nracist\\nhomophobic\\nsexist\\n\\nResulting in 4052 annotated messages\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages\\n\\t\\n\\nRomanian\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Structure\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Instances\\n\\t\\n\\nAn example of 'train' looks as follows.\\n{‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/readerbench/news-ro-offense."},
	{"name":"ro-offense","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/readerbench/ro-offense","creator_name":"ReaderBench","creator_url":"https://huggingface.co/readerbench","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for \\\"RO-Offense-Sequences\\\"\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\n\\n\\nHomepage: https://github.com/readerbench/ro-offense-sequences\\nRepository: https://github.com/readerbench/ro-offense-sequences\\nPoint of Contact: Andrei Paraschiv\\n\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\na novel Romanian language dataset for offensive language detection with manually \\nannotated offensive labels from a local Romanian sports news website (gsp.ro):\\nResulting in 12,445 annotated messages‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/readerbench/ro-offense."},
	{"name":"UTS_Text","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/undertheseanlp/UTS_Text","creator_name":"undertheseanlp","creator_url":"https://huggingface.co/undertheseanlp","description":"UTSText"},
	{"name":"wikitablequestions-wtq","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/danwakeem/wikitablequestions-wtq","creator_name":"Dan Jarvis","creator_url":"https://huggingface.co/danwakeem","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for WikiTableQuestions-wtq\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThe WikiTableQuestions-wtq dataset is a small-scale dataset for the task of question answering on semi-structured tables.\\nThis data includes the aggregation_label and answer_coordinates to make it easy to train this model on any TAPAS based modles.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSupported Tasks and Leaderboards\\n\\t\\n\\nquestion-answering, table-question-answering\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages\\n\\t\\n\\nen\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Structure‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/danwakeem/wikitablequestions-wtq."},
	{"name":"test-user","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/polinaeterna/test-user","creator_name":"Polina Kazakova","creator_url":"https://huggingface.co/polinaeterna","description":"Lorem ipsum"},
	{"name":"SpanishBFF","keyword":"monolingual","license":"GNU General Public License v3.0","license_url":"https://choosealicense.com/licenses/gpl-3.0/","language":"en","dataset_url":"https://huggingface.co/datasets/MMG/SpanishBFF","creator_name":"dezzai","creator_url":"https://huggingface.co/MMG","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nSpanish-BFF is the first Spanish AI-generated dictionary using GPT3.\\n\\nPaper: Spanish Built Factual Freectianary (Spanish-BFF): the first IA-generated free dictionary\\nPoint of Contact: oscar.garcia@dezzai.com , alfonso.ardoiz@dezzai.com\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nSpanish-BFF contains a total of 66353 lemmas with its definitions (only one definiton per lemma).\\nThese lemmas correspond to nominal, adjetival, verbal and adverbial classes.‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/MMG/SpanishBFF."},
	{"name":"dev_mode-wtq","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Serverless/dev_mode-wtq","creator_name":"Serverless Inc","creator_url":"https://huggingface.co/Serverless","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for dev_mode-wtq\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThe dev_mode-wtq dataset is a small-scale dataset for the task of question answering on semi-structured tables.\\nThis data includes the aggregation_label and answer_coordinates to make it easy to train this model on any TAPAS based modles.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSupported Tasks and Leaderboards\\n\\t\\n\\nquestion-answering, table-question-answering\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages\\n\\t\\n\\nen\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Structure\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Instances‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Serverless/dev_mode-wtq."},
	{"name":"recept","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/amcoff/recept","creator_name":"√Öke Amcoff","creator_url":"https://huggingface.co/amcoff","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Recept\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\n[More Information Needed]\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSupported Tasks and Leaderboards\\n\\t\\n\\n[More Information Needed]\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages\\n\\t\\n\\n[More Information Needed]\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Structure\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Instances\\n\\t\\n\\n[More Information Needed]\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Fields\\n\\t\\n\\n[More Information Needed]\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Splits\\n\\t\\n\\n[More Information Needed]\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Creation\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tCuration Rationale\\n\\t\\n\\n[More‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/amcoff/recept."},
	{"name":"comps","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/kanishka/comps","creator_name":"Kanishka Misra","creator_url":"https://huggingface.co/kanishka","description":"COMPS is a dataset of minimal pair sentences in English that enables the \\ntesting knowledge of concepts and their properties in language models (LMs).\\nSpecifically, it tests the ability of LMs to attribute properties to everyday \\nconcepts, and demonstrate reasoning compatible with property inheritance, where\\nsubordinate concepts inherit the properties of their superordinate (hypernyms)."},
	{"name":"faquad-nli","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ruanchaves/faquad-nli","creator_name":"Ruan Chaves Rodrigues","creator_url":"https://huggingface.co/ruanchaves","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for FaQuAD-NLI\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nFaQuAD is a Portuguese reading comprehension dataset that follows the format of the Stanford Question Answering Dataset (SQuAD). It is a pioneer Portuguese reading comprehension dataset using the challenging format of SQuAD. The dataset aims to address the problem of abundant questions sent by academics whose answers are found in available institutional documents in the Brazilian higher education system. It consists of‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ruanchaves/faquad-nli."},
	{"name":"latvian-text","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/RaivisDejus/latvian-text","creator_name":"Raivis Dejus","creator_url":"https://huggingface.co/RaivisDejus","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLatvian text dataset\\n\\t\\n\\nData set of latvian language texts. Intended for use in AI tool development, like speech recognition or spellcheckers\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData sources used\\n\\t\\n\\n\\nLatvian Wikisource articles - https://wikisource.org/wiki/Category:Latvian\\nLiterary works of Rainis - https://repository.clarin.lv/repository/xmlui/handle/20.500.12574/41\\nLatvian Wikipedia articles - https://huggingface.co/datasets/joelito/EU_Wikipedias\\nEuropean Parliament Proceedings Parallel Corpus -‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/RaivisDejus/latvian-text."},
	{"name":"squad-sk","keyword":"monolingual","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/TUKE-DeutscheTelekom/squad-sk","creator_name":"TUKE and DTSS cooperation","creator_url":"https://huggingface.co/TUKE-DeutscheTelekom","description":"        Slovak translation of Standford Question Answering Dataset"},
	{"name":"vegetable","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/cc92yy3344/vegetable","creator_name":"ÈôàË∂Ö","creator_url":"https://huggingface.co/cc92yy3344","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tËî¨ËèúÂõæÂÉèÊï∞ÊçÆÈõÜ\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tËÉåÊôØ\\n\\t\\n\\nÊúÄÂàùÁöÑÂÆûÈ™åÊòØÁî®‰∏ñÁïåÂêÑÂú∞ÂèëÁé∞ÁöÑ15ÁßçÂ∏∏ËßÅËî¨ËèúËøõË°åÁöÑ„ÄÇÂÆûÈ™åÈÄâÊã©ÁöÑËî¨ËèúÊúâÔºöË±ÜÁ±ª„ÄÅËã¶Áìú„ÄÅËë´Ëä¶„ÄÅËåÑÂ≠ê„ÄÅË•øÂÖ∞Ëä±„ÄÅÂç∑ÂøÉËèú„ÄÅËæ£Ê§í„ÄÅËÉ°ËêùÂçú„ÄÅËä±Ê§∞Ëèú„ÄÅÈªÑÁìú„ÄÅÊú®Áìú„ÄÅÂúüË±Ü„ÄÅÂçóÁìú„ÄÅËêùÂçúÂíåÁï™ËåÑ„ÄÇÂÖ±‰ΩøÁî®‰∫ÜÊù•Ëá™15‰∏™Á±ªÁöÑ21000Âº†ÂõæÂÉèÔºåÂÖ∂‰∏≠ÊØè‰∏™Á±ªÂåÖÂê´1400Âº†Â∞∫ÂØ∏‰∏∫224√ó224„ÄÅÊ†ºÂºè‰∏∫*.jpgÁöÑÂõæÂÉè„ÄÇÊï∞ÊçÆÈõÜ‰∏≠70%Áî®‰∫éÂüπËÆ≠Ôºå15%Áî®‰∫éÈ™åËØÅÔºå15%Áî®‰∫éÊµãËØï„ÄÇ\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tÁõÆÂΩï\\n\\t\\n\\nÊ≠§Êï∞ÊçÆÈõÜÂåÖÂê´‰∏â‰∏™Êñá‰ª∂Â§πÔºö\\n\\ntrain (15000 Âº†ÂõæÂÉè)\\ntest (3000 Âº†ÂõæÂÉè)\\nvalidation (3000 Âº†ÂõæÂÉè)\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tÊï∞ÊçÆÊî∂ÈõÜ\\n\\t\\n\\nËøô‰∏™Êï∞ÊçÆÈõÜ‰∏≠ÁöÑÂõæÂÉèÊòØÊàë‰ª¨‰∏∫‰∏Ä‰∏™È°πÁõÆ‰ªéËî¨ËèúÂÜúÂú∫ÂíåÂ∏ÇÂú∫Êî∂ÈõÜÁöÑ„ÄÇ\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tÂà∂‰ΩúÂÖÉÊï∞ÊçÆÊñá‰ª∂\\n\\t\\n\\nËøêË°å‰∏ãÈù¢pythonÁöÑ‰ª£Á†ÅÔºåÂ∞±ÂèØ‰ª•Âú®Ê°åÈù¢ÁîüÊàê‰∏â‰∏™csvÊ†ºÂºèÁöÑÂÖÉÊï∞ÊçÆÊñá‰ª∂„ÄÅ‰∏Ä‰∏™ÂàÜÁ±ªÊï∞ÊçÆÊñá‰ª∂ÔºàÈúÄË¶ÅÊîæÂÖ•Âà∞Êï∞ÊçÆÊñá‰ª∂‰∏≠Ôºâ\\n#!/usr/bin/env python3\\n# -*- coding: utf-8 -*-\\n\\n\\\"\\\"\\n1.‰∏ãËΩΩÁöÑÊï∞ÊçÆÊñá‰ª∂ Vegetable‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/cc92yy3344/vegetable."},
	{"name":"unarXive_imrad_clf","keyword":"monolingual","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/saier/unarXive_imrad_clf","creator_name":"Tarek Saier","creator_url":"https://huggingface.co/saier","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for unarXive IMRaD classification\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThe unarXive IMRaD classification dataset contains 530k paragraphs from computer science papers and the IMRaD section they originate from. The paragraphs are derived from unarXive.\\nThe dataset can be used as follows.\\nfrom datasets import load_dataset\\n\\nimrad_data = load_dataset('saier/unarXive_imrad_clf')\\nimrad_data = imrad_data.class_encode_column('label')  # assign target label column\\nimrad_data =‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/saier/unarXive_imrad_clf."},
	{"name":"unarXive_citrec","keyword":"monolingual","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/saier/unarXive_citrec","creator_name":"Tarek Saier","creator_url":"https://huggingface.co/saier","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for unarXive citation recommendation\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThe unarXive citation recommendation dataset contains 2.5 Million paragraphs from computer science papers and with an annotated citation marker. The paragraphs and citation information is derived from unarXive.\\nNote that citation infromation is only given as the OpenAlex ID of the cited paper. An important consideration for models is therefore if the data is used as is, or if additional information‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/saier/unarXive_citrec."},
	{"name":"aihub_corpus_expertise","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/wisenut-nlp-team/aihub_corpus_expertise","creator_name":"wisenut-nlp","creator_url":"https://huggingface.co/wisenut-nlp-team","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for \\\"corpus_professional_field\\\"\\n\\t\\n\\nÏ†ÑÎ¨∏Î∂ÑÏïº ÎßêÎ≠âÏπò\\n"},
	{"name":"letras-carnaval-cadiz","keyword":"monolingual","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/IES-Rafael-Alberti/letras-carnaval-cadiz","creator_name":"IES Rafael Alberti","creator_url":"https://huggingface.co/IES-Rafael-Alberti","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Letras Carnaval C√°diz\\n\\t\\n\\n\\n\\n    \\n        English |\\n        Espa√±ol\\n    \\n\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tChangelog\\n\\t\\n\\n\\n\\t\\n\\t\\t\\nRelease\\nDescription\\n\\n\\n\\t\\t\\nv1.0\\nInitial release of the dataset. Included more than 1K lyrics. It is necessary to verify the accuracy of the data, especially the subset midaccurate.\\n\\n\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThis dataset is a comprehensive collection of lyrics from the Carnaval de C√°diz, a significant cultural heritage of the city of C√°diz, Spain. Despite‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/IES-Rafael-Alberti/letras-carnaval-cadiz."},
	{"name":"cococon","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/adymaharana/cococon","creator_name":"Adyasha Maharana","creator_url":"https://huggingface.co/adymaharana","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for CoCoCON\\n\\t\\n\\n\\nDataset Description\\nLanguages\\n\\n\\nDataset Structure\\nData Fields\\nData Splits\\n\\n\\nDataset Creation\\nConsiderations for Using the Data\\nLicensing Information\\nCitation Information\\n\\n\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nCocoCON is a challenging dataset for evaluating cross-task consistency in vision-and-language models. We use contrast sets created by modifying COCO test instances for multiple tasks in small but semantically meaningful ways to change the gold label‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/adymaharana/cococon."},
	{"name":"FLUE_VSD","keyword":"monolingual","license":"GNU General Public License v3.0","license_url":"https://choosealicense.com/licenses/gpl-3.0/","language":"en","dataset_url":"https://huggingface.co/datasets/GETALP/FLUE_VSD","creator_name":" Groupe d'√âtude en Traduction Automatique/Traitement Automatis√© des Langues et de la Parole","creator_url":"https://huggingface.co/GETALP","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tFrenchSemEval\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThis dataset correspond to the FrenchSemEval, in which verb occurences where manually annotated with Wiktionary senses. \\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSupported Tasks and Leaderboards\\n\\t\\n\\nVerb Sense Disambiguation for French verbs.  \\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguage\\n\\t\\n\\nFrench\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Structure\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Instances\\n\\t\\n\\nEach instance of the dataset has the following fields and these following types of field. \\n{\\n  \\\"document_id\\\": \\\"d001\\\"‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/GETALP/FLUE_VSD."},
	{"name":"ru_goemotions","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Djacon/ru_goemotions","creator_name":"Daniel","creator_url":"https://huggingface.co/Djacon","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for GoEmotions\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThe RuGoEmotions dataset contains 34k Reddit comments labeled for 9 emotion categories (joy, interest, surprice, sadness, anger, disgust, fear, guilt and neutral).\\nThe dataset already with predefined train/val/test splits\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSupported Tasks and Leaderboards\\n\\t\\n\\nThis dataset is intended for multi-class, multi-label emotion classification.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages\\n\\t\\n\\nThe data is in Russian.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Djacon/ru_goemotions."},
	{"name":"multitask-ro","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/BlackKakapo/multitask-ro","creator_name":"Alexandru Petrachi","creator_url":"https://huggingface.co/BlackKakapo","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tTrain\\n\\t\\n\\n\\n\\t\\n\\t\\t\\nDataset\\nLink\\nRows\\nTask-specific prefix\\n\\n\\n\\t\\t\\nParaphrase\\nParaphrase\\n131951\\nparaphrase: string\\n\\n\\nGrammar\\nGrammar\\n1686054\\ngrammar: string\\n\\n\\nSynonyms\\n-\\n14085\\nsynonyms: word\\n\\n\\nTranslate\\n-\\n999725\\ntranslate Romanian to English: string\\n\\n\\nSummarize\\nSummarize\\n71999\\nsummarize: string\\n\\n\\nSentiment analysis\\nSentiment analysis\\n36498\\nsentiment analysis: string\\n\\n\\nSTS\\nSTS\\n7499\\nsts: string\\n\\n\\nOffense analysis\\nOffense analysis\\n3199\\noffense analysis: string‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/BlackKakapo/multitask-ro."},
	{"name":"NewQA","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/badokorach/NewQA","creator_name":"brenda Adokorach","creator_url":"https://huggingface.co/badokorach","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for \\\"squad\\\"\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nStanford Question Answering Dataset (SQuAD) is a reading comprehension dataset, consisting of questions posed by crowdworkers on a set of Wikipedia articles, where the answer to every question is a segment of text, or span, from the corresponding reading passage, or the question might be unanswerable.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSupported Tasks and Leaderboards\\n\\t\\n\\nMore Information Needed\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages\\n\\t\\n\\nMore Information Needed‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/badokorach/NewQA."},
	{"name":"cifar100-enriched","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/renumics/cifar100-enriched","creator_name":"Renumics","creator_url":"https://huggingface.co/renumics","description":"The CIFAR-100 dataset consists of 60000 32x32 colour images in 100 classes, with 600 images\\nper class. There are 500 training images and 100 testing images per class. There are 50000 training images and 10000 test images. The 100 classes are grouped into 20 superclasses.\\nThere are two labels per image - fine label (actual class) and coarse label (superclass)."},
	{"name":"truthful_qa_mc","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/EleutherAI/truthful_qa_mc","creator_name":"EleutherAI","creator_url":"https://huggingface.co/EleutherAI","description":"TruthfulQA-MC is a benchmark to measure whether a language model is truthful in\\ngenerating answers to questions. The benchmark comprises 817 questions that\\nspan 38 categories, including health, law, finance and politics. Questions are\\ncrafted so that some humans would answer falsely due to a false belief or\\nmisconception. To perform well, models must avoid generating false answers\\nlearned from imitating human texts."},
	{"name":"truthful_qa_binary","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/EleutherAI/truthful_qa_binary","creator_name":"EleutherAI","creator_url":"https://huggingface.co/EleutherAI","description":"TruthfulQA-Binary is a benchmark to measure whether a language model is truthful in\\ngenerating answers to questions. The benchmark comprises 817 questions that\\nspan 38 categories, including health, law, finance and politics. Questions are\\ncrafted so that some humans would answer falsely due to a false belief or\\nmisconception. To perform well, models must avoid generating false answers\\nlearned from imitating human texts."},
	{"name":"GMaSC","keyword":"monolingual","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/thennal/GMaSC","creator_name":"Thennal","creator_url":"https://huggingface.co/thennal","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tGMaSC: GEC Barton Hill Malayalam Speech Corpus\\n\\t\\n\\nGMaSC is a Malayalam text and speech corpus created by the Government Engineering College Barton Hill with an emphasis on Malayalam-accented English. The corpus contains 2,000 text-audio pairs of Malayalam sentences spoken by 2 speakers, totalling in approximately 139 minutes of audio. Each sentences has at least one English word common in Malayalam speech.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Structure\\n\\t\\n\\nThe dataset consists of 2,000 instances‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/thennal/GMaSC."},
	{"name":"peewee-issues","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/akumoth/peewee-issues","creator_name":"Rainer Palm","creator_url":"https://huggingface.co/akumoth","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Peewee Issues\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nPeewee Issues is a dataset containing all the issues in the Peewee github repository up to the last date of extraction (5/3/2023). It has been made for educational purposes in mind (especifically, to get me used to using Hugging Face's datasets), but can be used for multi-label classification or semantic search. The contents are all in English and concern SQL databases and ORM libraries.\\n"},
	{"name":"mindgames","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/sileod/mindgames","creator_name":"Damien Sileo","creator_url":"https://huggingface.co/sileod","description":"Mindgame dataset\\nCode:\\nhttps://github.com/sileod/llm-theory-of-mind\\nArticle (Accepted at EMNLP 2023 Findings):\\nhttps://arxiv.org/abs/2305.03353\\n@article{sileo2023mindgames,\\n  title={MindGames: Targeting Theory of Mind in Large Language Models with Dynamic Epistemic Modal Logic},\\n  author={Sileo, Damien and Lernould, Antoine},\\n  journal={arXiv preprint arXiv:2305.03353},\\n  year={2023}\\n}\\n\\n"},
	{"name":"turkish-wikiNER","keyword":"monolingual","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/turkish-nlp-suite/turkish-wikiNER","creator_name":"Turkish NLP Suite","creator_url":"https://huggingface.co/turkish-nlp-suite","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for \\\"turkish-nlp-suite/turkish-wikiNER\\\"\\n\\t\\n\\n \\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nTurkish NER dataset from Wikipedia sentences. 20.000 sentences are sampled and re-annotated from Kuzgunlar NER dataset.\\nAnnotations are done by Co-one. Many thanks to them for their contributions. This dataset is also used in our brand new spaCy Turkish packages.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Instances\\n\\t\\n\\nAn instance of this dataset looks as follows:\\n{\\n\\\"tokens\\\": [\\\"√áekimler\\\", \\\"5\\\", \\\"Temmuz\\\", \\\"2005\\\"‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/turkish-nlp-suite/turkish-wikiNER."},
	{"name":"Corona-mini","keyword":"monolingual","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/turkish-nlp-suite/Corona-mini","creator_name":"Turkish NLP Suite","creator_url":"https://huggingface.co/turkish-nlp-suite","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for turkish-nlp-suite/Corona-mini\\n\\t\\n\\n \\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThis is a tiny Turkish corpus consisting of comments about Corona symptoms. The corpus is compiled from two Ek≈üis√∂zl√ºk headlines \\\"covid-19 belirtileri\\\" and \\\"g√ºn g√ºn koronavir√ºs belirtileri\\\": \\nhttps://eksisozluk.com/covid-19-belirtileri--6416646  \\nhttps://eksisozluk.com/gun-gun-koronavirus-belirtileri--6757665\\nThis corpus \\n\\ncontains 178 raw, 175 processed comments\\nall comments are in Turkish\\ncomes in‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/turkish-nlp-suite/Corona-mini."},
	{"name":"dialogsum-ru","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/d0rj/dialogsum-ru","creator_name":"Dmitry Balobin","creator_url":"https://huggingface.co/d0rj","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for DIALOGSum Corpus\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLinks\\n\\t\\n\\n\\nHomepage: https://aclanthology.org/2021.findings-acl.449\\nRepository: https://github.com/cylnlp/dialogsum\\nPaper: https://aclanthology.org/2021.findings-acl.449\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nDialogSum is a large-scale dialogue summarization dataset, consisting of 13,460 (Plus 100 holdout data for topic generation) dialogues with corresponding manually labeled summaries and topics.‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/d0rj/dialogsum-ru."},
	{"name":"utcd","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/claritylab/utcd","creator_name":"Clarity Lab (University of Michigan)","creator_url":"https://huggingface.co/claritylab","description":"UTCD is a compilation of 18 classification datasets spanning 3 categories of Sentiment, \\nIntent/Dialogue and Topic classification. UTCD focuses on the task of zero-shot text classification where the \\ncandidate labels are descriptive of the text being classified. UTCD consists of ~ 6M/800K train/test examples."},
	{"name":"NevIR","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/orionweller/NevIR","creator_name":"Orion Weller","creator_url":"https://huggingface.co/orionweller","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for NevIR: Negation in Neural Information Retrieval\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nData from the paper: \\\"NevIR: Negation in Neural Information Retrieval\\\". \\nIf you use this dataset, we would appreciate you citing our work:\\n@inproceedings{weller-et-al-2023-nevir,\\n  title={NevIR: Negation in Neural Information Retrieval},\\n  author={Weller, Orion and Lawrie, Dawn, and Van Durme, Benjamin},\\n  year={2023},\\n  eprint={2305.07614},\\n  archivePrefix={arXiv},\\n  year={2023}\\n}‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/orionweller/NevIR."},
	{"name":"prosocial-dialog-filtered","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Englishman2022/prosocial-dialog-filtered","creator_name":"Josh Oliver","creator_url":"https://huggingface.co/Englishman2022","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nProsocialDialogFiltered is a filtered version of the ProsocialDialog dataset.\\nMultiple versions are present:\\n\\nIn train_no_casual, rows with the label \\\"casual\\\" have been filtered out as a starting point.\\nIn train_no_possibly, rows with \\\"possibly needs caution\\\" have been filtered out.\\nIn train_no_probably, rows with \\\"probably needs caution\\\" have been filtered out, as I found those to be largely pointless as well, leaving only \\\"needs caution\\\" and \\\"needs‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Englishman2022/prosocial-dialog-filtered."},
	{"name":"FOCAL","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/adsabs/FOCAL","creator_name":"SAO/NASA Astrophysics Data System","creator_url":"https://huggingface.co/adsabs","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tFunction Of Citation in Astrophysics Literature (FOCAL): Dataset and Task\\n\\t\\n\\nCan you explain why the authors made a given citation?\\nThis dataset was created as a shared task for WIESP @ AACL-IJCNLP 2023.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nDatasets are in JSON Lines format (each line is a json dictionary).  \\nEach entry consists of a dictionary with the following keys:\\n\\n\\\"Identifier\\\": unique string to identify the entry\\n\\\"Paragraph\\\": text string from an astrophysics paper \\n\\\"Citation‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/adsabs/FOCAL."},
	{"name":"turkish-thesaurus-synonyms-antonyms","keyword":"monolingual","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/agmmnn/turkish-thesaurus-synonyms-antonyms","creator_name":"agmmnn","creator_url":"https://huggingface.co/agmmnn","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tTurkish Thesaurus (T√ºrk√ße E≈ü-Zƒ±t Anlam S√∂zl√ºƒü√º)\\n\\t\\n\\nTurkish synonym, antonym thesaurus. Final thesaurus contains 33587 keys in total.\\nfrom datasets import load_dataset\\n\\ndataset = load_dataset(\\\"agmmnn/turkish-thesaurus-synonyms-antonyms\\\")\\n\\nprint(dataset['train'][0])\\n\\n"},
	{"name":"clinic150-sur","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/ibm-research/clinic150-sur","creator_name":"IBM Research","creator_url":"https://huggingface.co/ibm-research","description":"dataset_info:\\n  features:\\n\\nname: intent\\ndtype: string\\nname: user_utterance\\ndtype: string\\nname: origin\\ndtype: string\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Card for \\\"clinic150-SUR\\\"\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThe Clinic150-SUR dataset is a novel and augmented dataset designed to simulate natural human behavior during interactions with customer service-like centers.\\nExtending the Clinic150 dataset, it incorporates two augmentation techniques, including IBM's LAMBADA and Parrot models and carefully curated‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ibm-research/clinic150-sur."},
	{"name":"CaSET-catalan-stance-emotions-twitter","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/projecte-aina/CaSET-catalan-stance-emotions-twitter","creator_name":"Projecte Aina","creator_url":"https://huggingface.co/projecte-aina","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for CaSET, the Catalan Stance and Emotions Dataset from Twitter\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThe CaSET dataset is a Catalan corpus of Tweets annotated with Emotions, Static Stance, and Dynamic Stance. The dataset contains 11k unique sentences on five controversial topics, grouped in 6k pairs of sentences, paired as parent messages and replies to these messages.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSupported Tasks and Leaderboards\\n\\t\\n\\nThis dataset can be used to train models for emotion‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/projecte-aina/CaSET-catalan-stance-emotions-twitter."},
	{"name":"CaSERa-catalan-stance-emotions-raco","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/projecte-aina/CaSERa-catalan-stance-emotions-raco","creator_name":"Projecte Aina","creator_url":"https://huggingface.co/projecte-aina","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for CaSERa, the Catalan Stance and Emotions Dataset from Rac√≥ Catal√†\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThe CaSERa dataset is a Catalan corpus from the forum Rac√≥ Catal√† annotated with Emotions and Dynamic Stance. The dataset contains 15.782 unique sentences grouped in 10.745 pairs of sentences, paired as parent messages and replies to these messages.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSupported Tasks and Leaderboards\\n\\t\\n\\nThis dataset can be used to train models for emotion detection and‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/projecte-aina/CaSERa-catalan-stance-emotions-raco."},
	{"name":"internal-datasets","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Marbyun/internal-datasets","creator_name":"Ivan Rivaldo Marbun","creator_url":"https://huggingface.co/Marbyun","description":"SynQA is a Reading Comprehension dataset created in the work \\\"Improving Question Answering Model Robustness with Synthetic Adversarial Data Generation\\\" (https://aclanthology.org/2021.emnlp-main.696/).\\nIt consists of 314,811 synthetically generated questions on the passages in the SQuAD v1.1 (https://arxiv.org/abs/1606.05250) training set.\\n\\nIn this work, we use a synthetic adversarial data generation to make QA models more robust to human adversaries. We develop a data generation pipeline that selects source passages, identifies candidate answers, generates questions, then finally filters or re-labels them to improve quality. Using this approach, we amplify a smaller human-written adversarial dataset to a much larger set of synthetic question-answer pairs. By incorporating our synthetic data, we improve the state-of-the-art on the AdversarialQA (https://adversarialqa.github.io/) dataset by 3.7F1 and improve model generalisation on nine of the twelve MRQA datasets. We further conduct a novel human-in-the-loop evaluation to show that our models are considerably more robust to new human-written adversarial examples: crowdworkers can fool our model only 8.8% of the time on average, compared to 17.6% for a model trained without synthetic data.\\n\\nFor full details on how the dataset was created, kindly refer to the paper."},
	{"name":"SOTAB","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/shivangibithel/SOTAB","creator_name":"Shivangi Bithel","creator_url":"https://huggingface.co/shivangibithel","description":"# Understanding the semantics of table elements is a prerequisite for many data integration and data discovery tasks. Table annotation is the task of labeling table elements with terms from a given vocabulary. This paper presents the WDC Schema.org Table Annotation Benchmark (SOTAB) for comparing the performance of table annotation systems. SOTAB covers the column type annotation (CTA) and columns property annotation (CPA) tasks. SOTAB provides ‚àº50,000 annotated tables for each of the tasks containing Schema.org data from different websites. The tables cover 17 different types of entities such as movie, event, local business, recipe, job posting, or product. The tables stem from the WDC Schema.org Table Corpus which was created by extracting Schema.org annotations from the Common Crawl. Consequently, the labels used for annotating columns in SOTAB are part of the Schema.org vocabulary. The benchmark covers 91 types for CTA and 176 properties for CPA distributed across textual, numerical and date/time columns. The tables are split into fixed training, validation and test sets. The test sets are further divided into subsets focusing on specific challenges, such as columns with missing values or different value formats, in order to allow a more fine-grained comparison of annotation systems. The evaluation of SOTAB using Doduo and TURL shows that the benchmark is difficult to solve for current state-of-the-art systems.\\n#"},
	{"name":"ptparl","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/luist18/ptparl","creator_name":"Lu√≠s Tavares","creator_url":"https://huggingface.co/luist18","description":"The PTPARL dataset is a dataset containing 5713 interventions in the Portuguese parliament."},
	{"name":"ParsiGoo","keyword":"monolingual","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Kamtera/ParsiGoo","creator_name":"Flincer","creator_url":"https://huggingface.co/Kamtera","description":"A Persian multispeaker dataset for text-to-speech purposes."},
	{"name":"HC3-ru","keyword":"monolingual","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/d0rj/HC3-ru","creator_name":"Dmitry Balobin","creator_url":"https://huggingface.co/d0rj","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for \\\"HC3-ru\\\"\\n\\t\\n\\nThis is translated version of Hello-SimpleAI/HC3 dataset into Russian.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tCitation\\n\\t\\n\\nCheckout this papaer arxiv: 2301.07597\\n@article{guo-etal-2023-hc3,\\n    title = \\\"How Close is ChatGPT to Human Experts? Comparison Corpus, Evaluation, and Detection\\\",\\n    author = \\\"Guo, Biyang  and\\n      Zhang, Xin  and\\n      Wang, Ziyuan  and\\n      Jiang, Minqi  and\\n      Nie, Jinran  and\\n      Ding, Yuxuan  and\\n      Yue, Jianwei  and\\n      Wu, Yupeng\\\"‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/d0rj/HC3-ru."},
	{"name":"hh-rlhf-ru","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/d0rj/hh-rlhf-ru","creator_name":"Dmitry Balobin","creator_url":"https://huggingface.co/d0rj","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for \\\"hh-rlhf-ru\\\"\\n\\t\\n\\nThis is translated version of Anthropic/hh-rlhf dataset into Russian.\\n"},
	{"name":"synthetic-instruct-gptj-pairwise-ru","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/d0rj/synthetic-instruct-gptj-pairwise-ru","creator_name":"Dmitry Balobin","creator_url":"https://huggingface.co/d0rj","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for \\\"synthetic-instruct-gptj-pairwise-ru\\\"\\n\\t\\n\\nThis is translated version of Dahoas/synthetic-instruct-gptj-pairwise dataset into Russian.\\n"},
	{"name":"rlhf-reward-datasets-ru","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/d0rj/rlhf-reward-datasets-ru","creator_name":"Dmitry Balobin","creator_url":"https://huggingface.co/d0rj","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for \\\"rlhf-reward-datasets-ru\\\"\\n\\t\\n\\nThis is translated version of yitingxie/rlhf-reward-datasets dataset into Russian.\\n"},
	{"name":"ImageNet-AB","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/coallaoh/ImageNet-AB","creator_name":"Seong Joon Oh","creator_url":"https://huggingface.co/coallaoh","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tGeneral Information\\n\\t\\n\\nTitle: ImageNet-AB\\nDescription: ImageNet-AB is an extended version of the ImageNet-1K training set, enriched with annotation byproducts (AB).\\nIn addition to the image and corresponding class labels, this dataset provides a rich history of interactions per input signal per front-end component during the annotation process.\\nThey include mouse traces, click locations, annotation times, as well as anonymised worker IDs.\\nLinks:\\n\\nICCV'23 Paper\\nMain Repository‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/coallaoh/ImageNet-AB."},
	{"name":"COPA-ca","keyword":"monolingual","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/projecte-aina/COPA-ca","creator_name":"Projecte Aina","creator_url":"https://huggingface.co/projecte-aina","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for COPA-ca\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThe COPA-ca dataset (Choice of plausible alternatives in Catalan) is a professional translation of the English COPA dataset into Catalan, commissioned by BSC LangTech Unit. The dataset consists of 1000 premises, each given a question and two choices with a label encoding which of the choices is more plausible given the annotator.\\nThe dataset is split into 400 training samples, 100 validation samples, and 500 test samples.‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/projecte-aina/COPA-ca."},
	{"name":"curation-corpus-ru","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/d0rj/curation-corpus-ru","creator_name":"Dmitry Balobin","creator_url":"https://huggingface.co/d0rj","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tcuration-corpus-ru\\n\\t\\n\\nTranslated version of d0rj/curation-corpus into Russian.\\n"},
	{"name":"snli-zh","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/shibing624/snli-zh","creator_name":"Ming Xu (ÂæêÊòé)","creator_url":"https://huggingface.co/shibing624","description":"The SNLI corpus (version 1.0) is a collection of 570k human-written English\\nsentence pairs manually labeled for balanced classification with the labels\\nentailment, contradiction, and neutral, supporting the task of natural language\\ninference (NLI), also known as recognizing textual entailment (RTE)."},
	{"name":"mnist-outlier","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/renumics/mnist-outlier","creator_name":"Renumics","creator_url":"https://huggingface.co/renumics","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for \\\"mnist-outlier\\\"\\n\\t\\n\\nüìö This dataset is an enriched version of the MNIST Dataset.\\nThe workflow is described in the medium article: Changes of Embeddings during Fine-Tuning of Transformers.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tExplore the Dataset\\n\\t\\n\\nThe open source data curation tool Renumics Spotlight allows you to explorer this dataset. You can find a Hugging Face Space running Spotlight with this dataset here: https://huggingface.co/spaces/renumics/mnist-outlier.\\n\\nOr you can explorer it‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/renumics/mnist-outlier."},
	{"name":"beans-outlier","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/renumics/beans-outlier","creator_name":"Renumics","creator_url":"https://huggingface.co/renumics","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for \\\"beans-outlier\\\"\\n\\t\\n\\nüìö This dataset is an enhancved version of the ibean project of the AIR lab.\\nThe workflow is described in the medium article: Changes of Embeddings during Fine-Tuning of Transformers.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tExplore the Dataset\\n\\t\\n\\nThe open source data curation tool Renumics Spotlight allows you to explorer this dataset. You can find a Hugging Face Space running Spotlight with this dataset here: https://huggingface.co/spaces/renumics/beans-outlier\\n\\nOr you can‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/renumics/beans-outlier."},
	{"name":"AMIsum","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/TalTechNLP/AMIsum","creator_name":"Laboratory of Language Technology at Tallinn University of Technology","creator_url":"https://huggingface.co/TalTechNLP","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for \\\"AMIsum\\\"\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nAMIsum is meeting summaryzation dataset based on the AMI Meeting Corpus (https://groups.inf.ed.ac.uk/ami/corpus/). The dataset utilizes the transcripts as the source data and abstract summaries as the target data.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSupported Tasks and Leaderboards\\n\\t\\n\\nMore Information Needed\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages\\n\\t\\n\\nEnglish\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Structure\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Instances\\n\\t\\n\\n{'transcript': '<PM> Okay. <PM> Right. <PM>‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/TalTechNLP/AMIsum."},
	{"name":"rudetoxifier_data","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/d0rj/rudetoxifier_data","creator_name":"Dmitry Balobin","creator_url":"https://huggingface.co/d0rj","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\trudetoxifier_data\\n\\t\\n\\nHuggingface copy of Github repo with dataset.\\n"},
	{"name":"rudetoxifier_data_detox","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/d0rj/rudetoxifier_data_detox","creator_name":"Dmitry Balobin","creator_url":"https://huggingface.co/d0rj","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\trudetoxifier_data_detox\\n\\t\\n\\nThis is subset of toxic comments from d0rj/rudetoxifier_data which has detoxified column created by s-nlp/ruT5-base-detox.\\n"},
	{"name":"livingner1","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/IIC/livingner1","creator_name":"Instituto de Ingenier√≠a del Conocimiento","creator_url":"https://huggingface.co/IIC","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLivingNER\\n\\t\\n\\nThis is a third party reupload of the LivingNER task 1 dataset.\\nIt only contains the task 1 for the Spanish language. It does not include the multilingual data nor the background data.\\nThis dataset is part of a benchmark in the paper A comparative analysis of Spanish Clinical encoder-based models on NER and classification tasks.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tCitation Information\\n\\t\\n\\n@article{10.1093/jamia/ocae054,\\n    author = {Garc√≠a Subies, Guillem and Barbero Jim√©nez, √Ålvaro and‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/IIC/livingner1."},
	{"name":"livingner3","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/IIC/livingner3","creator_name":"Instituto de Ingenier√≠a del Conocimiento","creator_url":"https://huggingface.co/IIC","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLivingNER\\n\\t\\n\\nThis is a third party reupload of the LivingNER task 3 dataset.\\nIt only contains the task 3 for the Spanish language. It does not include the multilingual data nor the background data.\\nThis dataset is part of a benchmark in the paper A comparative analysis of Spanish Clinical encoder-based models on NER and classification tasks.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tCitation Information\\n\\t\\n\\n@article{10.1093/jamia/ocae054,\\n    author = {Garc√≠a Subies, Guillem and Barbero Jim√©nez, √Ålvaro and‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/IIC/livingner3."},
	{"name":"dane_plus","keyword":"monolingual","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/KennethEnevoldsen/dane_plus","creator_name":"Kenneth C. Enevoldsen","creator_url":"https://huggingface.co/KennethEnevoldsen","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDaNE+\\n\\t\\n\\nThis is a version of DaNE, where the original NER labels have been updated to follow the ontonotes annotation scheme. The annotation process used the model trained on the Danish dataset DANSK for the first round of annotation and then all the discrepancies were manually reviewed and corrected by Kenneth C. Enevoldsen. A discrepancy include notably also includes newly added entities such as PRODUCT and WORK_OF_ART. Thus in practice a great deal of entities were manually‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/KennethEnevoldsen/dane_plus."},
	{"name":"quickdraw","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Xenova/quickdraw","creator_name":"Joshua","creator_url":"https://huggingface.co/Xenova","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Quick, Draw!\\n\\t\\n\\nThis is a processed version of Google's Quick, Draw dataset to be compatible with the latest versions of ü§ó Datasets that support .parquet files. NOTE: this dataset only contains the \\\"preprocessed_bitmaps\\\" subset of the original dataset.\\n"},
	{"name":"ro-offense-sequences","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/readerbench/ro-offense-sequences","creator_name":"ReaderBench","creator_url":"https://huggingface.co/readerbench","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for \\\"RO-Offense-Sequences\\\"\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\n\\n\\nHomepage: https://github.com/readerbench/ro-offense-sequences\\nRepository: https://github.com/readerbench/ro-offense-sequences\\nPoint of Contact: Teodora-Andreea Ion\\n\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\na novel Romanian language dataset for offensive sequence detection with manually \\nannotated offensive sequences from a local Romanian sports news website (gsp.ro):\\nResulting in 4800 annotated messages‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/readerbench/ro-offense-sequences."},
	{"name":"librispeech_asr_individual","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Splend1dchan/librispeech_asr_individual","creator_name":"Ë®±ÊπõÁÑ∂","creator_url":"https://huggingface.co/Splend1dchan","description":"LibriSpeech is a corpus of approximately 1000 hours of read English speech with sampling rate of 16 kHz,\\nprepared by Vassil Panayotov with the assistance of Daniel Povey. The data is derived from read\\naudiobooks from the LibriVox project, and has been carefully segmented and aligned.87"},
	{"name":"socialdisner","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/IIC/socialdisner","creator_name":"Instituto de Ingenier√≠a del Conocimiento","creator_url":"https://huggingface.co/IIC","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSocialDisNER\\n\\t\\n\\nThis is a third party reupload of the SocialDisNER dataset.\\nThis dataset is part of a benchmark in the paper A comparative analysis of Spanish Clinical encoder-based models on NER and classification tasks.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tCitation Information\\n\\t\\n\\n@article{10.1093/jamia/ocae054,\\n    author = {Garc√≠a Subies, Guillem and Barbero Jim√©nez, √Ålvaro and Mart√≠nez Fern√°ndez, Paloma},\\n    title = {A comparative analysis of Spanish Clinical encoder-based models on NER and‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/IIC/socialdisner."},
	{"name":"audiocaps-ru","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/d0rj/audiocaps-ru","creator_name":"Dmitry Balobin","creator_url":"https://huggingface.co/d0rj","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\taudiocaps-ru\\n\\t\\n\\nTranslated version of d0rj/audiocaps into Russian.\\n"},
	{"name":"samromur_synthetic","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/language-and-voice-lab/samromur_synthetic","creator_name":"Language and Voice Laboratory (Reykjav√≠k University)","creator_url":"https://huggingface.co/language-and-voice-lab","description":"Samr√≥mur Synthetic consists of 72 hours of synthetized speech in Icelandic."},
	{"name":"OV_Text","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/duyhngoc/OV_Text","creator_name":"Duy Huynh","creator_url":"https://huggingface.co/duyhngoc","description":"OVText"},
	{"name":"SeeTRUE","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/yonatanbitton/SeeTRUE","creator_name":"Yonatan","creator_url":"https://huggingface.co/yonatanbitton","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for SeeTRUE\\n\\t\\n\\n\\nDataset Description\\nSupported Tasks and Leaderboards\\nLanguages\\n\\n\\nDataset Structure\\nData Fields\\nData Splits\\n\\n\\nDataset Creation\\nLicensing Information\\nCitation Information\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThe SeeTRUE dataset is a diverse benchmark for meta-evaluation of image-text alignment methods, covering the 4-way combinations of real and synthetic text-and-image pairs. It addresses limitations in current benchmarks, which mainly focus on natural‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/yonatanbitton/SeeTRUE."},
	{"name":"mmlu","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Stevross/mmlu","creator_name":"Stephen Davies","creator_url":"https://huggingface.co/Stevross","description":"This is a massive multitask test consisting of multiple-choice questions from various branches of knowledge, covering 57 tasks including elementary mathematics, US history, computer science, law, and more."},
	{"name":"tlunified-ner","keyword":"monolingual","license":"GNU General Public License v3.0","license_url":"https://choosealicense.com/licenses/gpl-3.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ljvmiranda921/tlunified-ner","creator_name":"Lj V. Miranda","creator_url":"https://huggingface.co/ljvmiranda921","description":"\\n\\t\\n\\t\\t\\n\\t\\tü™ê spaCy Project: TLUnified-NER Corpus\\n\\t\\n\\n\\nHomepage: Github\\nRepository: Github\\nPoint of Contact: ljvmiranda@gmail.com\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThis dataset contains the annotated TLUnified corpora from Cruz and Cheng\\n(2021).  It is a curated sample of around 7,000 documents for the\\nnamed entity recognition (NER) task.  The majority of the corpus are news\\nreports in Tagalog, resembling the domain of the original ConLL 2003.  There\\nare three entity types: Person (PER), Organization‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ljvmiranda921/tlunified-ner."},
	{"name":"skb","keyword":"monolingual","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/min9805/skb","creator_name":"min","creator_url":"https://huggingface.co/min9805","description":"min9805/skb dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"MKB_Hindi_2023","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/rashmi035/MKB_Hindi_2023","creator_name":"Rashmi Singh","creator_url":"https://huggingface.co/rashmi035","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for [Dataset Name]\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\n[More Information Needed]\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSupported Tasks and Leaderboards\\n\\t\\n\\n[More Information Needed]\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages\\n\\t\\n\\n[More Information Needed]\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Structure\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Instances\\n\\t\\n\\n[More Information Needed]\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Fields\\n\\t\\n\\n[More Information Needed]\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Splits\\n\\t\\n\\n[More Information Needed]\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Creation\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tCuration Rationale\\n\\t\\n\\n[More‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/rashmi035/MKB_Hindi_2023."},
	{"name":"OpenOrca-ru","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/d0rj/OpenOrca-ru","creator_name":"Dmitry Balobin","creator_url":"https://huggingface.co/d0rj","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tOpenOrca-ru\\n\\t\\n\\nThis is translated version of Open-Orca/OpenOrca into Russian.\\n"},
	{"name":"hl-narratives","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/michelecafagna26/hl-narratives","creator_name":"Michele Cafagna","creator_url":"https://huggingface.co/michelecafagna26","description":"\\n\\t\\n\\t\\t\\n\\t\\tDataset Card for the High-Level Narratives Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThe High-Level Narratives (HL-Narratives) dataset aligns object-centric descriptions from COCO \\nwith synthetic high-level narratives captions automatically generated by merging scene, action, rationale captions from the HL Dataset using T5\\nThe HL-Naratives dataset contains 14997 images from COCO and a total of 134973 synthetic captions (3 captions per image) aligned with ~749984 object-centric captions‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/michelecafagna26/hl-narratives."},
	{"name":"wikipedia_tw","keyword":"monolingual","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/jslin09/wikipedia_tw","creator_name":"Chun-Hsien Lin","creator_url":"https://huggingface.co/jslin09","description":"Ë¶ÅÊêûËá™Â∑±ÁöÑÂ§ßÂûãË™ûË®ÄÊ®°ÂûãÔºåÊúÄÂü∫Êú¨ÁöÑÂü∫Êú¨ÔºåÂ∞±ÊòØÈúÄË¶Å‰∏ÄÂ§ßÂ†ÜÊñáÂ≠óË≥áÊñôÔºåÂæû Common Crawl ‰∏äÈ†≠ÊäìÂõû‰æÜÊÖ¢ÊÖ¢Ê∏ÖÊ¥óÊòØ‰∏ÄÊ¢ùË∑ØÔºåÊ∏ÖÊ¥óÁ∂≠Âü∫ÁôæÁßëÁ∂≤Á´ôÁöÑÈÄ±ÊúüÊÄß‰∏ãËºâÊ™î‰πüÊòØ‰∏ÄÂÄãÊñπÊ≥ï„ÄÇÊú¨Ë≥áÊñôÈõÜÊòØËß£ÊûêËá™Á∂≠Âü∫ÁôæÁßëÊñº 20240420 ÁôºÂ∏ÉÁöÑÁπÅÈ´î‰∏≠ÊñáÁâàÊâìÂåÖÊ™î bz2 Ê™îÊ°àÁöÑÂÖßÂÆπÔºåÂú®Ëß£ÊûêÂá∫ÊâÄÈúÄÂÖßÂÆπÂæåÔºåÂà©Áî® wikitextparser ÁßªÈô§ Wiki Ê®ôË®ò„ÄÇËß£ÊûêÂæå‰øùÁïôÁöÑÊ¨Ñ‰ΩçÊúâÂÖ©ÂÄãÔºöÊ¢ùÁõÆÂêçÁ®±ÔºàtitleÔºâÔºåÊ¢ùÁõÆÂÖßÂÆπÔºàpage articleÔºâ„ÄÇ\\nÂéüÂßãÁöÑÊâìÂåÖÊ™îÊ¢ùÁõÆÂÖßÂÆπÁ∞°ÁπÅÊ∑∑ÈõúÔºåÊâÄ‰ª•ÊúâÂà©Áî® OpenCC ÈÄ≤Ë°åÁ∞°ËΩâÁπÅËôïÁêÜ„ÄÇ\\n\\nÂéüÂßãÁ∏ΩÊ¢ùÁõÆÊï∏: 4,451,426 Ê¢ùÁõÆ„ÄÇ\\nÂÖ®ÈÉ® 4,451,426 ÂÄãÊ¢ùÁõÆÊ®ôÈ°å„ÄÇ\\nÁÑ°Ê≥ïËá™ÂãïÂéªÊ®ôË®òÁöÑÊ¢ùÁõÆÊï∏: 3,035,750\\nÊúâÂÖßÂÆπÁöÑÊ¢ùÁõÆÊï∏: 1,415,676\\n\\nÂõ†ÁÇ∫Êú¨Ë≥áÊñôÈõÜÂÖßÂÆπÈæêÂ§ßÔºåË¶ÅÂ°ûÈÄ≤‰∏ÄËà¨ÁöÑÂÄã‰∫∫ÈõªËÖ¶‰∏≠ÈÄ≤Ë°åË®àÁÆóÔºåÊÅêÊÄïÊúÉÊúâË≥áÊ∫ê‰∏çË∂≥ÁöÑÊÉÖÂΩ¢„ÄÇÂª∫Ë≠∞‰ΩøÁî®parquetÊ†ºÂºè‰∏ãËºâ‰ΩøÁî®„ÄÇ\\nË≥áÊñôÈõÜÁï∂‰∏≠Êúâ‰∏çÂ∞ëÂÖßÂÆπÁÇ∫ #REDIRECT ÁöÑÊ¢ùÁõÆÂ∑≤Á∂ìÂòóË©¶ÁßªÈô§ÔºåÂ¶ÇÊûúÁßªÈô§ÁöÑ‰∏ç‰πæÊ∑®ÔºåÂ∞±Á≠â‰ª•ÂæåÊúâÁ©∫Êé®Âá∫‰øÆÊ≠£ÁâàÂÜç‰æÜÊ∏ÖÊ¥ó‰∫Ü„ÄÇ\\n"},
	{"name":"dolphin-ru","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/d0rj/dolphin-ru","creator_name":"Dmitry Balobin","creator_url":"https://huggingface.co/d0rj","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDolphin-ru üê¨\\n\\t\\n\\nThis is translated version of ehartford/dolphin into Russian.\\n"},
	{"name":"xwinograd_fr_prompt_coreference","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/CATIE-AQ/xwinograd_fr_prompt_coreference","creator_name":"CATIE","creator_url":"https://huggingface.co/CATIE-AQ","description":"\\n\\t\\n\\t\\t\\n\\t\\txwinograd_fr_prompt_coreference\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tSummary\\n\\t\\n\\nxwinograd_fr_prompt_coreference is a subset of the Dataset of French Prompts (DFP).It contains 830 rows that can be used for a coreference task.The original data (without prompts) comes from the dataset xwinograd by Muennighoff where only the French part has been kept.A list of prompts (see below) was then applied in order to build the input and target columns and thus obtain the same format as the xP3 dataset by Muennighoff et al.‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/CATIE-AQ/xwinograd_fr_prompt_coreference."},
	{"name":"wino_x_fr_prompt_coreference","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/CATIE-AQ/wino_x_fr_prompt_coreference","creator_name":"CATIE","creator_url":"https://huggingface.co/CATIE-AQ","description":"\\n\\t\\n\\t\\t\\n\\t\\twino_x_fr_prompt_coreference\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tSummary\\n\\t\\n\\nwino_x_fr_prompt_coreference is a subset of the Dataset of French Prompts (DFP).It contains 27,930 rows that can be used for a coreference task.The original data (without prompts) comes from the dataset wino_x by Emelin et al. where only the French part has been kept.A list of prompts (see below) was then applied in order to build the input and target columns and thus obtain the same format as the xP3 dataset by Muennighoff et al.‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/CATIE-AQ/wino_x_fr_prompt_coreference."},
	{"name":"allocine_fr_prompt_sentiment_analysis","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/CATIE-AQ/allocine_fr_prompt_sentiment_analysis","creator_name":"CATIE","creator_url":"https://huggingface.co/CATIE-AQ","description":"\\n\\t\\n\\t\\t\\n\\t\\tallocine_fr_prompt_sentiment_analysis\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tSummary\\n\\t\\n\\nallocine_fr_prompt_sentiment_analysis is a subset of the Dataset of French Prompts (DFP).It contains 5,600,000 rows that can be used for a binary sentiment analysis task.The original data (without prompts) comes from the dataset allocine by Blard.A list of prompts (see below) was then applied in order to build the input and target columns and thus obtain the same format as the xP3 dataset by Muennighoff et al.‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/CATIE-AQ/allocine_fr_prompt_sentiment_analysis."},
	{"name":"universal_dependencies_fr_gsd_fr_prompt_pos","keyword":"monolingual","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/CATIE-AQ/universal_dependencies_fr_gsd_fr_prompt_pos","creator_name":"CATIE","creator_url":"https://huggingface.co/CATIE-AQ","description":"\\n\\t\\n\\t\\t\\n\\t\\tuniversal_dependencies_fr_gsd_fr_prompt_pos\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tSummary\\n\\t\\n\\nuniversal_dependencies_fr_gsd_fr_prompt_pos is a subset of the Dataset of French Prompts (DFP).It contains 343,161 rows that can be used for a part-of-speech task.The original data (without prompts) comes from the dataset universal_dependencies where only the French gsd split has been kept.A list of prompts (see below) was then applied in order to build the input and target columns and thus obtain the same format as the‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/CATIE-AQ/universal_dependencies_fr_gsd_fr_prompt_pos."},
	{"name":"universal_dependencies_fr_partut_fr_prompt_pos","keyword":"monolingual","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/CATIE-AQ/universal_dependencies_fr_partut_fr_prompt_pos","creator_name":"CATIE","creator_url":"https://huggingface.co/CATIE-AQ","description":"\\n\\t\\n\\t\\t\\n\\t\\tuniversal_dependencies_fr_partut_fr_prompt_pos\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tSummary\\n\\t\\n\\nuniversal_dependencies_fr_partut_fr_prompt_pos is a subset of the Dataset of French Prompts (DFP).It contains 21,420 rows that can be used for a part-of-speech task.The original data (without prompts) comes from the dataset universal_dependencies where only the French parput split has been kept.A list of prompts (see below) was then applied in order to build the input and target columns and thus obtain the same format‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/CATIE-AQ/universal_dependencies_fr_partut_fr_prompt_pos."},
	{"name":"universal_dependencies_fr_spoken_fr_prompt_pos","keyword":"monolingual","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/CATIE-AQ/universal_dependencies_fr_spoken_fr_prompt_pos","creator_name":"CATIE","creator_url":"https://huggingface.co/CATIE-AQ","description":"\\n\\t\\n\\t\\t\\n\\t\\tuniversal_dependencies_fr_spoken_fr_prompt_pos\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tSummary\\n\\t\\n\\nuniversal_dependencies_fr_spoken_fr_prompt_pos is a subset of the Dataset of French Prompts (DFP).It contains 58,926 rows that can be used for a part-of-speech task.The original data (without prompts) comes from the dataset universal_dependencies where only the French spoken split has been kept.A list of prompts (see below) was then applied in order to build the input and target columns and thus obtain the same format‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/CATIE-AQ/universal_dependencies_fr_spoken_fr_prompt_pos."},
	{"name":"amazon_massive_intent_fr_prompt_intent_classification","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/CATIE-AQ/amazon_massive_intent_fr_prompt_intent_classification","creator_name":"CATIE","creator_url":"https://huggingface.co/CATIE-AQ","description":"\\n\\t\\n\\t\\t\\n\\t\\tamazon_massive_intent_fr_prompt_intent_classification\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tSummary\\n\\t\\n\\namazon_massive_intent_fr_prompt_intent_classification is a subset of the Dataset of French Prompts (DFP).It contains 555,000 rows that can be used for an intent text classification task.The original data (without prompts) comes from the dataset amazon_massive_intent_fr-FR by FitzGerald et al..\\nA list of prompts (see below) was then applied in order to build the input and target columns and thus obtain the same‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/CATIE-AQ/amazon_massive_intent_fr_prompt_intent_classification."},
	{"name":"text2image-multi-prompt","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/JohnTeddy3/text2image-multi-prompt","creator_name":"JohnTeddy3","creator_url":"https://huggingface.co/JohnTeddy3","description":"###ËΩ¨ËΩΩ pszemraj/text2image-multi-prompt\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\ttext2image multi-prompt(s): a dataset collection\\n\\t\\n\\n\\ncollection of several text2image prompt datasets\\ndata was cleaned/normalized with the goal of removing \\\"model specific APIs\\\" like the \\\"--ar\\\" for Midjourney and so on\\ndata de-duplicated on a basic level: exactly duplicate prompts were dropped (after cleaning and normalization)\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tcontents\\n\\t\\n\\nDatasetDict({\\n    train: Dataset({\\n        features: ['text', 'src_dataset']‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/JohnTeddy3/text2image-multi-prompt."},
	{"name":"ciempiess_light","keyword":"monolingual","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ciempiess/ciempiess_light","creator_name":"CIEMPIESS-UNAM Project (Mexico)","creator_url":"https://huggingface.co/ciempiess","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for ciempiess_light\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThe CIEMPIESS LIGHT is a Radio Corpus designed to create acoustic models for automatic speech recognition and it is made up by recordings of spontaneous conversations in Mexican Spanish between a radio moderator and his guests. It is an enhanced version of the CIEMPIESS Corpus (LDC item LDC2015S07).\\nCIEMPIESS LIGHT is \\\"light\\\" because it doesn't include much of the files of the first version of CIEMPIESS and it is‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ciempiess/ciempiess_light."},
	{"name":"ciempiess_balance","keyword":"monolingual","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ciempiess/ciempiess_balance","creator_name":"CIEMPIESS-UNAM Project (Mexico)","creator_url":"https://huggingface.co/ciempiess","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for ciempiess_balance\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThe CIEMPIESS BALANCE Corpus is designed to match with the CIEMPIESS LIGHT Corpus (LDC2017S23). So, \\\"Balance\\\" means that if the CIEMPIESS BALANCE is combined with the CIEMPIESS LIGHT, one will get a gender balanced corpus. To appreciate this, one need to know that the CIEMPIESS LIGHT is by itself, a gender unbalanced corpus of approximately 25% of female speakers and 75% of male speakers. So, the CIEMPIESS BALANCE‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ciempiess/ciempiess_balance."},
	{"name":"ciempiess_fem","keyword":"monolingual","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ciempiess/ciempiess_fem","creator_name":"CIEMPIESS-UNAM Project (Mexico)","creator_url":"https://huggingface.co/ciempiess","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for ciempiess_fem\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nSince the publication of the CIEMPIESS Corpus (LDC2015S07) in 2015 we have noticed that there is a lack of female speakers in the sources where we traditionally take audio to create new CIEMPIESS datasets. That is why we decided to create a corpus that helps to balance future gender unbalanced datasets.\\nThe CIEMPIESS FEM Corpus was created by recordings and human transcripts of 21 different women. 16 of these women‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ciempiess/ciempiess_fem."},
	{"name":"ciempiess_complementary","keyword":"monolingual","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ciempiess/ciempiess_complementary","creator_name":"CIEMPIESS-UNAM Project (Mexico)","creator_url":"https://huggingface.co/ciempiess","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for ciempiess_complementary\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThe CIEMPIESS COMPLEMENTARY is a phonetically balanced corpus of isolated Spanish words spoken by people of Central Mexico. It was designed to solve one particular issue when training automatic speech recognition (ASR) systems in the Spanish of Central Mexico. This problem appears when someone collects some training data, but the system complains because it does not find enough instances of one or more‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ciempiess/ciempiess_complementary."},
	{"name":"my-issues-dataset","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/devopsmarc/my-issues-dataset","creator_name":"Marcello Barretto","creator_url":"https://huggingface.co/devopsmarc","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Dataset Name\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary in English\\n\\t\\n\\nThis customized dataset is made of a corpus of commun Github issues, typically utilized for tracking bugs or features within a repositories. This self-constructed corpus can serve multiple purposes, such as analyzing the time taken to resolve open issues or pull requests, training a classifier to tag issues based on their descriptions (e.g., \\\"bug,\\\" \\\"enhancement,\\\" \\\"question\\\"), or developing a semantic search‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/devopsmarc/my-issues-dataset."},
	{"name":"bengali_asr_corpus","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/parambharat/bengali_asr_corpus","creator_name":"Bharat Ramanathan","creator_url":"https://huggingface.co/parambharat","description":"The corpus contains roughly 500 hours of audio and transcripts in Bangla language. \\nThe transcripts have beed de-duplicated using exact match deduplication and audio has be converted to 16000 samples"},
	{"name":"squad","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/lhoestq/squad","creator_name":"Quentin Lhoest","creator_url":"https://huggingface.co/lhoestq","description":"Stanford Question Answering Dataset (SQuAD) is a reading comprehension dataset, consisting of questions posed by crowdworkers on a set of Wikipedia articles, where the answer to every question is a segment of text, or span, from the corresponding reading passage, or the question might be unanswerable."},
	{"name":"central_de_fatos","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/fake-news-UFG/central_de_fatos","creator_name":"fake-news-UFG","creator_url":"https://huggingface.co/fake-news-UFG","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tCentral de Fatos\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nIn recent times, the interest for research dissecting the dissemination and prevention of misinformation in the online environment has spiked dramatically.\\nGiven that scenario, a recurring obstacle is the unavailability of public datasets containing fact-checked instances.\\nIn this work, we performed an extensive data collection of such instances from the better part of all major internationally recognized Brazilian fact-checking‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/fake-news-UFG/central_de_fatos."},
	{"name":"pubmed_qa","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/highnote/pubmed_qa","creator_name":"Highnote Health, Inc.","creator_url":"https://huggingface.co/highnote","description":"PubMedQA is a novel biomedical question answering (QA) dataset collected from PubMed abstracts.\\nThe task of PubMedQA is to answer research questions with yes/no/maybe (e.g.: Do preoperative\\nstatins reduce atrial fibrillation after coronary artery bypass grafting?) using the corresponding abstracts.\\nPubMedQA has 1k expert-annotated, 61.2k unlabeled and 211.3k artificially generated QA instances.\\nEach PubMedQA instance is composed of (1) a question which is either an existing research article\\ntitle or derived from one, (2) a context which is the corresponding abstract without its conclusion,\\n(3) a long answer, which is the conclusion of the abstract and, presumably, answers the research question,\\nand (4) a yes/no/maybe answer which summarizes the conclusion.\\nPubMedQA is the first QA dataset where reasoning over biomedical research texts, especially their\\nquantitative contents, is required to answer the questions."},
	{"name":"RSNA-ATD2023","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/ziq/RSNA-ATD2023","creator_name":"ziq","creator_url":"https://huggingface.co/ziq","description":"The dataset is the processed version of Kaggle Competition: RSNA 2023 Abdominal Trauma Detection.\\nIt comprises of segmentation of 205 series of CT scans with 5 classes (liver, spleen, right_kidney, \\nleft_kidney, bowel)."},
	{"name":"orange_sum_fr_prompt_fill_mask","keyword":"monolingual","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/CATIE-AQ/orange_sum_fr_prompt_fill_mask","creator_name":"CATIE","creator_url":"https://huggingface.co/CATIE-AQ","description":"\\n\\t\\n\\t\\t\\n\\t\\torange_sum_fr_prompt_fill_mask\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tSummary\\n\\t\\n\\norange_sum_fr_prompt_fill_mask is a subset of the Dataset of French Prompts (DFP).It contains 585,624 rows that can be used for a fill mask task.The original data (without prompts) comes from the dataset orange_sum by Eddine et al.A list of prompts (see below) was then applied in order to build the input and target columns and thus obtain the same format as the xP3 dataset by Muennighoff et al.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tPrompts used‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/CATIE-AQ/orange_sum_fr_prompt_fill_mask."},
	{"name":"orange_sum_fr_prompt_summarization","keyword":"monolingual","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/CATIE-AQ/orange_sum_fr_prompt_summarization","creator_name":"CATIE","creator_url":"https://huggingface.co/CATIE-AQ","description":"\\n\\t\\n\\t\\t\\n\\t\\torange_sum_fr_prompt_summarization\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tSummary\\n\\t\\n\\norange_sum_fr_prompt_summarization is a subset of the Dataset of French Prompts (DFP).It contains 683,228 rows that can be used for a summary task.The original data (without prompts) comes from the dataset orange_sum by Eddine et al.A list of prompts (see below) was then applied in order to build the input and target columns and thus obtain the same format as the xP3 dataset by Muennighoff et al.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tPrompts used‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/CATIE-AQ/orange_sum_fr_prompt_summarization."},
	{"name":"orange_sum_fr_prompt_text_generation_from_an_article","keyword":"monolingual","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/CATIE-AQ/orange_sum_fr_prompt_text_generation_from_an_article","creator_name":"CATIE","creator_url":"https://huggingface.co/CATIE-AQ","description":"\\n\\t\\n\\t\\t\\n\\t\\torange_sum_fr_prompt_text_generation_from_an_article\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tSummary\\n\\t\\n\\norange_sum_fr_prompt_text_generation_from_an_article is a subset of the Dataset of French Prompts (DFP).It contains 539,400 rows that can be used for a text generation task.The original data (without prompts) comes from the dataset orange_sum by Eddine et al.A list of prompts (see below) was then applied in order to build the input and target columns and thus obtain the same format as the xP3 dataset by‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/CATIE-AQ/orange_sum_fr_prompt_text_generation_from_an_article."},
	{"name":"orange_sum_fr_prompt_text_generation_from_title_of_an_article","keyword":"monolingual","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/CATIE-AQ/orange_sum_fr_prompt_text_generation_from_title_of_an_article","creator_name":"CATIE","creator_url":"https://huggingface.co/CATIE-AQ","description":"\\n\\t\\n\\t\\t\\n\\t\\torange_sum_fr_prompt_text_generation_from_title_of_an_article\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tSummary\\n\\t\\n\\norange_sum_fr_prompt_text_generation_from_title_of_an_article is a subset of the Dataset of French Prompts (DFP).It contains 908,793 rows that can be used for a part-of-speech task.The original data (without prompts) comes from the dataset orange_sum by Eddine et al.A list of prompts (see below) was then applied in order to build the input and target columns and thus obtain the same format as the xP3‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/CATIE-AQ/orange_sum_fr_prompt_text_generation_from_title_of_an_article."},
	{"name":"orange_sum_fr_prompt_title_generation_from_an_article","keyword":"monolingual","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/CATIE-AQ/orange_sum_fr_prompt_title_generation_from_an_article","creator_name":"CATIE","creator_url":"https://huggingface.co/CATIE-AQ","description":"\\n\\t\\n\\t\\t\\n\\t\\torange_sum_fr_prompt_title_generation_from_an_article\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tSummary\\n\\t\\n\\norange_sum_fr_prompt_title_generation_from_an_article is a subset of the Dataset of French Prompts (DFP).It contains 639,521 rows that can be used for a title generation task.The original data (without prompts) comes from the dataset orange_sum by Eddine et al.A list of prompts (see below) was then applied in order to build the input and target columns and thus obtain the same format as the xP3 dataset by‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/CATIE-AQ/orange_sum_fr_prompt_title_generation_from_an_article."},
	{"name":"squad_v2_french_translated_fr_prompt_context_generation_with_answer","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/CATIE-AQ/squad_v2_french_translated_fr_prompt_context_generation_with_answer","creator_name":"CATIE","creator_url":"https://huggingface.co/CATIE-AQ","description":"\\n\\t\\n\\t\\t\\n\\t\\tsquad_v2_french_translated_fr_prompt_context_generation_with_answer\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tSummary\\n\\t\\n\\nsquad_v2_french_translated_fr_prompt_context_generation_with_answer is a subset of the Dataset of French Prompts (DFP).It contains 1,271,928 rows that can be used for a context-generation (with answer) task.The original data (without prompts) comes from the dataset pragnakalp/squad_v2_french_translated and was augmented by questions in SQUAD 2.0 format in the FrenchQA dataset.\\nA list of prompts‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/CATIE-AQ/squad_v2_french_translated_fr_prompt_context_generation_with_answer."},
	{"name":"squad_v2_french_translated_fr_prompt_qa","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/CATIE-AQ/squad_v2_french_translated_fr_prompt_qa","creator_name":"CATIE","creator_url":"https://huggingface.co/CATIE-AQ","description":"\\n\\t\\n\\t\\t\\n\\t\\tsquad_v2_french_translated_fr_prompt_qa\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tSummary\\n\\t\\n\\nsquad_v2_french_translated_fr_prompt_qa is a subset of the Dataset of French Prompts (DFP).It contains 3,320,898 rows that can be used for a question-answering task.The original data (without prompts) comes from the dataset pragnakalp/squad_v2_french_translated and was augmented by questions in SQUAD 2.0 format in the FrenchQA dataset.\\nA list of prompts (see below) was then applied in order to build the input and target‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/CATIE-AQ/squad_v2_french_translated_fr_prompt_qa."},
	{"name":"squad_v2_french_translated_fr_prompt_context_generation_with_answer_and_question","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/CATIE-AQ/squad_v2_french_translated_fr_prompt_context_generation_with_answer_and_question","creator_name":"CATIE","creator_url":"https://huggingface.co/CATIE-AQ","description":"\\n\\t\\n\\t\\t\\n\\t\\tsquad_v2_french_translated_fr_prompt_context_generation_with_answer_and_question\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tSummary\\n\\t\\n\\nsquad_v2_french_translated_fr_prompt_context_generation_with_answer_and_question is a subset of the Dataset of French Prompts (DFP).It contains 1,271,928 rows that can be used for a context-generation (with answer and question) task.The original data (without prompts) comes from the dataset pragnakalp/squad_v2_french_translated and was augmented by questions in SQUAD 2.0 format in the‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/CATIE-AQ/squad_v2_french_translated_fr_prompt_context_generation_with_answer_and_question."},
	{"name":"squad_v2_french_translated_fr_prompt_context_generation_with_question","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/CATIE-AQ/squad_v2_french_translated_fr_prompt_context_generation_with_question","creator_name":"CATIE","creator_url":"https://huggingface.co/CATIE-AQ","description":"\\n\\t\\n\\t\\t\\n\\t\\tsquad_v2_french_translated_fr_prompt_context_generation_with_question\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tSummary\\n\\t\\n\\nsquad_v2_french_translated_fr_prompt_context_generation_with_question is a subset of the Dataset of French Prompts (DFP).It contains 3,795,312 rows that can be used for a context-generation (with question) task.The original data (without prompts) comes from the dataset pragnakalp/squad_v2_french_translated and was augmented by questions in SQUAD 2.0 format in the FrenchQA dataset.\\nA list of‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/CATIE-AQ/squad_v2_french_translated_fr_prompt_context_generation_with_question."},
	{"name":"squad_v2_french_translated_fr_prompt_question_generation_with_answer","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/CATIE-AQ/squad_v2_french_translated_fr_prompt_question_generation_with_answer","creator_name":"CATIE","creator_url":"https://huggingface.co/CATIE-AQ","description":"\\n\\t\\n\\t\\t\\n\\t\\tsquad_v2_french_translated_fr_prompt_question_generation_with_answer\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tSummary\\n\\t\\n\\nsquad_v2_french_translated_fr_prompt_question_generation_with_answer is a subset of the Dataset of French Prompts (DFP).It contains 1,165,934 rows that can be used for a question-generation (with answer) task.The original data (without prompts) comes from the dataset pragnakalp/squad_v2_french_translated and was augmented by questions in SQUAD 2.0 format in the FrenchQA dataset.\\nA list of prompts‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/CATIE-AQ/squad_v2_french_translated_fr_prompt_question_generation_with_answer."},
	{"name":"squad_v2_french_translated_fr_prompt_question_generation_with_context","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/CATIE-AQ/squad_v2_french_translated_fr_prompt_question_generation_with_context","creator_name":"CATIE","creator_url":"https://huggingface.co/CATIE-AQ","description":"\\n\\t\\n\\t\\t\\n\\t\\tsquad_v2_french_translated_fr_prompt_question_generation_with_context\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tSummary\\n\\t\\n\\nsquad_v2_french_translated_fr_prompt_question_generation_with_context is a subset of the Dataset of French Prompts (DFP).It contains 3,795,312 rows that can be used for a question-generation (with context) task.The original data (without prompts) comes from the dataset pragnakalp/squad_v2_french_translated and was augmented by questions in SQUAD 2.0 format in the FrenchQA dataset.\\nA list of‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/CATIE-AQ/squad_v2_french_translated_fr_prompt_question_generation_with_context."},
	{"name":"piaf_fr_prompt_qa","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/CATIE-AQ/piaf_fr_prompt_qa","creator_name":"CATIE","creator_url":"https://huggingface.co/CATIE-AQ","description":"\\n\\t\\n\\t\\t\\n\\t\\tpiaf_fr_prompt_qa\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tSummary\\n\\t\\n\\npiaf_fr_prompt_qa is a subset of the Dataset of French Prompts (DFP).It contains 387,408 rows that can be used for a question-answering task.The original data (without prompts) comes from the dataset PIAF and was augmented by questions in SQUAD 2.0 format in the FrenchQA dataset.\\nA list of prompts (see below) was then applied in order to build the input and target columns and thus obtain the same format as the xP3 dataset by Muennighoff et al.‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/CATIE-AQ/piaf_fr_prompt_qa."},
	{"name":"piaf_fr_prompt_context_generation_with_answer","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/CATIE-AQ/piaf_fr_prompt_context_generation_with_answer","creator_name":"CATIE","creator_url":"https://huggingface.co/CATIE-AQ","description":"\\n\\t\\n\\t\\t\\n\\t\\tpiaf_fr_prompt_context_generation_with_answer\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tSummary\\n\\t\\n\\npiaf_fr_prompt_context_generation_with_answer is a subset of the Dataset of French Prompts (DFP).It contains 442,752 rows that can be used for a context-generation (with answer) task.The original data (without prompts) comes from the dataset PIAF and was augmented by questions in SQUAD 2.0 format in the FrenchQA dataset.\\nA list of prompts (see below) was then applied in order to build the input and target columns and‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/CATIE-AQ/piaf_fr_prompt_context_generation_with_answer."},
	{"name":"piaf_fr_prompt_context_generation_with_answer_and_question","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/CATIE-AQ/piaf_fr_prompt_context_generation_with_answer_and_question","creator_name":"CATIE","creator_url":"https://huggingface.co/CATIE-AQ","description":"\\n\\t\\n\\t\\t\\n\\t\\tpiaf_fr_prompt_context_generation_with_answer_and_question\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tSummary\\n\\t\\n\\npiaf_fr_prompt_context_generation_with_answer_and_question is a subset of the Dataset of French Prompts (DFP).It contains 442,752 rows that can be used for a context-generation (with answer and question) task.The original data (without prompts) comes from the dataset PIAF and was augmented by questions in SQUAD 2.0 format in the FrenchQA dataset.\\nA list of prompts (see below) was then applied in order to‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/CATIE-AQ/piaf_fr_prompt_context_generation_with_answer_and_question."},
	{"name":"piaf_fr_prompt_context_generation_with_question","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/CATIE-AQ/piaf_fr_prompt_context_generation_with_question","creator_name":"CATIE","creator_url":"https://huggingface.co/CATIE-AQ","description":"\\n\\t\\n\\t\\t\\n\\t\\tpiaf_fr_prompt_context_generation_with_question\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tSummary\\n\\t\\n\\npiaf_fr_prompt_context_generation_with_question is a subset of the Dataset of French Prompts (DFP).It contains 442,752 rows that can be used for a context-generation (with answer and question) task.The original data (without prompts) comes from the dataset PIAF and was augmented by questions in SQUAD 2.0 format in the FrenchQA dataset.\\nA list of prompts (see below) was then applied in order to build the input and‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/CATIE-AQ/piaf_fr_prompt_context_generation_with_question."},
	{"name":"piaf_fr_prompt_question_generation_with_answer","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/CATIE-AQ/piaf_fr_prompt_question_generation_with_answer","creator_name":"CATIE","creator_url":"https://huggingface.co/CATIE-AQ","description":"\\n\\t\\n\\t\\t\\n\\t\\tpiaf_fr_prompt_question_generation_with_answer\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tSummary\\n\\t\\n\\npiaf_fr_prompt_question_generation_with_answer is a subset of the Dataset of French Prompts (DFP).It contains 387,408 rows that can be used for a question-generation (with answer) task.The original data (without prompts) comes from the dataset PIAF and was augmented by questions in SQUAD 2.0 format in the FrenchQA dataset.\\nA list of prompts (see below) was then applied in order to build the input and target columns‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/CATIE-AQ/piaf_fr_prompt_question_generation_with_answer."},
	{"name":"piaf_fr_prompt_question_generation_with_context","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/CATIE-AQ/piaf_fr_prompt_question_generation_with_context","creator_name":"CATIE","creator_url":"https://huggingface.co/CATIE-AQ","description":"\\n\\t\\n\\t\\t\\n\\t\\tpiaf_fr_prompt_question_generation_with_context\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tSummary\\n\\t\\n\\npiaf_fr_prompt_question_generation_with_context is a subset of the Dataset of French Prompts (DFP).It contains 442,752 rows that can be used for a question-generation (with context) task.The original data (without prompts) comes from the dataset PIAF and was augmented by questions in SQUAD 2.0 format in the FrenchQA dataset.\\nA list of prompts (see below) was then applied in order to build the input and target columns‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/CATIE-AQ/piaf_fr_prompt_question_generation_with_context."},
	{"name":"piaf_fr_prompt_question_generation_with_answer_and_context","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/CATIE-AQ/piaf_fr_prompt_question_generation_with_answer_and_context","creator_name":"CATIE","creator_url":"https://huggingface.co/CATIE-AQ","description":"\\n\\t\\n\\t\\t\\n\\t\\tpiaf_fr_prompt_question_generation_with_answer_and_context\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tSummary\\n\\t\\n\\npiaf_fr_prompt_question_generation_with_answer_and_context is a subset of the Dataset of French Prompts (DFP).It contains 387,408 rows that can be used for a question-generation (with answer and context) task.The original data (without prompts) comes from the dataset PIAF and was augmented by questions in SQUAD 2.0 format in the FrenchQA dataset.\\nA list of prompts (see below) was then applied in order to‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/CATIE-AQ/piaf_fr_prompt_question_generation_with_answer_and_context."},
	{"name":"squad_v2_french_translated_fr_prompt_question_generation_with_answer_and_context","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/CATIE-AQ/squad_v2_french_translated_fr_prompt_question_generation_with_answer_and_context","creator_name":"CATIE","creator_url":"https://huggingface.co/CATIE-AQ","description":"\\n\\t\\n\\t\\t\\n\\t\\tsquad_v2_french_translated_fr_prompt_question_generation_with_answer_and_context\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tSummary\\n\\t\\n\\nsquad_v2_french_translated_fr_prompt_question_generation_with_answer_and_context is a subset of the Dataset of French Prompts (DFP).It contains 1,112,937 rows that can be used for a question-generation (with answer and context) task.The original data (without prompts) comes from the dataset pragnakalp/squad_v2_french_translated and was augmented by questions in SQUAD 2.0 format in the‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/CATIE-AQ/squad_v2_french_translated_fr_prompt_question_generation_with_answer_and_context."},
	{"name":"aya-telugu-paraphrase","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/SuryaKrishna02/aya-telugu-paraphrase","creator_name":"Surya Guthikonda","creator_url":"https://huggingface.co/SuryaKrishna02","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSummary\\n\\t\\n\\naya-telugu-paraphrase is an open source dataset of instruct-style records generated from the Telugu split of ai4bharat/IndicXParaphrase dataset. This was created as part of Aya Open Science Initiative from Cohere For AI.\\nThis dataset can be used for any purpose, whether academic or commercial, under the terms of the Apache 2.0 License.\\nSupported Tasks:\\n\\nTraining LLMs\\nSynthetic Data Generation\\nData Augmentation\\n\\nLanguages: Telugu Version: 1.0\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Overview‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/SuryaKrishna02/aya-telugu-paraphrase."},
	{"name":"aya-telugu-jokes","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/SuryaKrishna02/aya-telugu-jokes","creator_name":"Surya Guthikonda","creator_url":"https://huggingface.co/SuryaKrishna02","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSummary\\n\\t\\n\\naya-telugu-jokes is an open source dataset of instruct-style records generated by webscraping a Telugu Jokes website. This was created as part of Aya Open Science Initiative from Cohere For AI.\\nThis dataset can be used for any purpose, whether academic or commercial, under the terms of the Apache 2.0 License.\\nSupported Tasks:\\n\\nTraining LLMs\\nSynthetic Data Generation\\nData Augmentation\\n\\nLanguages: Telugu Version: 1.0\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Overview\\n\\t\\n\\naya-telugu-jokes is a‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/SuryaKrishna02/aya-telugu-jokes."},
	{"name":"minispider","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ravidborse/minispider","creator_name":"Ravikiran Borse","creator_url":"https://huggingface.co/ravidborse","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Spider\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nSpider is a large-scale complex and cross-domain semantic parsing and text-to-SQL dataset annotated by 11 Yale students\\nThe goal of the Spider challenge is to develop natural language interfaces to cross-domain databases\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSupported Tasks and Leaderboards\\n\\t\\n\\nThe leaderboard can be seen at https://yale-lily.github.io/spider\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages\\n\\t\\n\\nThe text in the dataset is in English.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Structure‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ravidborse/minispider."},
	{"name":"huggingface-dataset-issues","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/SergeiGKS/huggingface-dataset-issues","creator_name":"Serge Ghomsi","creator_url":"https://huggingface.co/SergeiGKS","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for \\\"my-issues-dataset\\\"\\n\\t\\n\\nMore Information needed\\n"},
	{"name":"TeluguRiddles","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/desik98/TeluguRiddles","creator_name":"Desik Mandava","creator_url":"https://huggingface.co/desik98","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSummary\\n\\t\\n\\nTeluguRiddles is an open source dataset of instruct-style records generated by webscraping multiple riddles websites. This was created as part of Aya Open Science Initiative from Cohere For AI.\\nThis dataset can be used for any purpose, whether academic or commercial, under the terms of the Apache 2.0 License.\\nSupported Tasks:\\n\\nTraining LLMs\\nSynthetic Data Generation\\nData Augmentation\\n\\nLanguages: Telugu Version: 1.0\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Overview\\n\\t\\n\\nTeluguRiddles is a‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/desik98/TeluguRiddles."},
	{"name":"aya-telugu-food-recipes","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/SuryaKrishna02/aya-telugu-food-recipes","creator_name":"Surya Guthikonda","creator_url":"https://huggingface.co/SuryaKrishna02","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSummary\\n\\t\\n\\naya-telugu-food-recipes is an open source dataset of instruct-style records generated by webscraping a Telugu food recipes website. This was created as part of Aya Open Science Initiative from Cohere For AI.\\nThis dataset can be used for any purpose, whether academic or commercial, under the terms of the Apache 2.0 License.\\nSupported Tasks:\\n\\nTraining LLMs\\nSynthetic Data Generation\\nData Augmentation\\n\\nLanguages: Telugu Version: 1.0\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Overview‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/SuryaKrishna02/aya-telugu-food-recipes."},
	{"name":"thirukkural_instruct","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/aitamilnadu/thirukkural_instruct","creator_name":"AI Tamil Nadu","creator_url":"https://huggingface.co/aitamilnadu","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSummary\\n\\t\\n\\nthirukkural_QA is an open source dataset of instruct-style records generated by converting publicly available data on Thirukkural and it's meaning.\\nThis was created as part of Aya Open Science Initiative by Cohere For AI.\\nThis dataset can be used for any purpose, whether academic or commercial, under the terms of the Apache 2.0 License.\\nSupported Tasks:\\n\\nTraining LLMs\\nSynthetic Data Generation\\nData Augmentation\\nQuestion Answering\\n\\nLanguages: Tamil Version: 1.0‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/aitamilnadu/thirukkural_instruct."},
	{"name":"aya-telugu-poems","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/SuryaKrishna02/aya-telugu-poems","creator_name":"Surya Guthikonda","creator_url":"https://huggingface.co/SuryaKrishna02","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSummary\\n\\t\\n\\naya-telugu-poems is an open source dataset of instruct-style records generated by webscraping a Telugu poems website. This was created as part of Aya Open Science Initiative from Cohere For AI.\\nThis dataset can be used for any purpose, whether academic or commercial, under the terms of the Apache 2.0 License.\\nSupported Tasks:\\n\\nTraining LLMs\\nSynthetic Data Generation\\nData Augmentation\\n\\nLanguages: Telugu Version: 1.0\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Overview\\n\\t\\n\\naya-telugu-poems is a‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/SuryaKrishna02/aya-telugu-poems."},
	{"name":"wikitoxic","keyword":"monolingual","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/pietrolesci/wikitoxic","creator_name":"Pietro Lesci","creator_url":"https://huggingface.co/pietrolesci","description":"This is the same dataset as OxAISH-AL-LLM/wiki_toxic.\\nThe only differences are\\n\\nAddition of a unique identifier, uid\\n\\nAddition of the indices, that is 3 columns with the embeddings of 3 different sentence-transformers\\n\\nall-mpnet-base-v2\\nmulti-qa-mpnet-base-dot-v1\\nall-MiniLM-L12-v2\\n\\n\\nRenaming of the label column to labels for easier compatibility with the transformers library\\n\\n\\n"},
	{"name":"liwu-MNBVC","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/botp/liwu-MNBVC","creator_name":"ab10","creator_url":"https://huggingface.co/botp","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for MNBVC\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tÊï∞ÊçÆÈõÜ‰ªãÁªç\\n\\t\\n\\n‰∏≠Êñá‰∫íËÅîÁΩë‰∏äÊúÄÂè§ËÄÅÊúÄÁ•ûÁßò(Ê≤°Êúâ‰πã‰∏Ä)ÁöÑÈáåÂ±ãÁ§æÂå∫‰∫é2023.1.1Â∫ÑÈáçÂÆ£Â∏É:\\nÂú®Ëã±ÊòéÁ•ûÊ≠¶ÁöÑÈáåÂ±ãÁÆ°Â≠êÂ∏¶È¢Ü‰∏ãÔºåÂÜ≥ÂøÉÂèëÊå•Á§æÂå∫ÊâÄÈïø(Âì™ÈÉΩÈïø)ÔºåÂ∏ÆÂä©ÂºÄÊ∫êÁ§æÂå∫ÈïøÊúüÊõ¥Êñ∞‰∏Ä‰ªΩÊúÄÂ§ßÁöÑ‰∏≠Êñá‰∫íËÅîÁΩëËØ≠ÊñôÈõÜ„ÄÇ\\nHuggingface‰∏äÁöÑMNBVCÊï∞ÊçÆÈõÜÂú®ÈÄêÊ∏êÊõ¥Êñ∞‰∏≠ÔºåËØ∑Âà∞https://github.com/esbatmop/MNBVC Ëé∑ÂèñÊú™ÂÆåÊàêÊ∏ÖÊ¥óÁöÑÊõ¥Â§öÊï∞ÊçÆ„ÄÇ\\nÂèØ‰ª•‰ΩøÁî®Â¶Ç‰∏ãËÑöÊú¨Âä†ËΩΩÔºö\\nfrom datasets import load_dataset\\ndataset = load_dataset(\\\"liwu/MNBVC\\\", 'law_judgement', split='train', streaming=True)\\n\\nnext(iter(dataset))  # get the first line\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tÊï∞ÊçÆÂ≠êÈõÜ\\n\\t\\n\\nMNBVCÊï∞ÊçÆÈõÜÂåÖÂê´Êï∞‰∏™Â≠êÈõÜÔºö\\n\\nlaw_judgement: Êù•Ëá™Ê≥ïÂæãÊñá‰π¶ÁöÑÊñáÊú¨„ÄÇ\\ngov_xuexiqiangguo: Êù•Ëá™Â≠¶‰π†Âº∫ÂõΩÁöÑÊñáÊú¨„ÄÇ‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/botp/liwu-MNBVC."},
	{"name":"plsc","keyword":"monolingual","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/rafalposwiata/plsc","creator_name":"Rafa≈Ç Po≈õwiata","creator_url":"https://huggingface.co/rafalposwiata","description":"PLSC - Polish Library of Science Corpus\\n"},
	{"name":"hindi-article-summarization","keyword":"monolingual","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ganeshjcs/hindi-article-summarization","creator_name":"Ganesh Jagadeesan","creator_url":"https://huggingface.co/ganeshjcs","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSummary\\n\\t\\n\\nhindi-article-summarization is an open source dataset of instruct-style records generated from the Hindi Text Short and Large Summarization dataset. This was created as part of Aya Open Science Initiative from Cohere For AI.\\nThis dataset can be used for any purpose, whether academic or commercial, under the terms of the CC BY-SA 4.0 License.\\nSupported Tasks:\\n\\nTraining LLMs\\nSynthetic Data Generation\\nData Augmentation\\n\\nLanguages: Hindi Version: 1.0\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ganeshjcs/hindi-article-summarization."},
	{"name":"samromur_children_test","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Ericwang/samromur_children_test","creator_name":"Zhiyong Wang","creator_url":"https://huggingface.co/Ericwang","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for samromur_children\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThe Samr√≥mur Children Corpus consists of audio recordings and metadata files containing prompts read by the participants. It contains more than 137000 validated speech-recordings uttered by Icelandic children.\\nThe corpus is a result of the crowd-sourcing effort run by the Language and Voice Lab (LVL) at the Reykjavik University, in cooperation with Almannar√≥mur, Center for Language Technology. The recording‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Ericwang/samromur_children_test."},
	{"name":"genai_dataset","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/samyakmohelay/genai_dataset","creator_name":"Samyak Mohelay","creator_url":"https://huggingface.co/samyakmohelay","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for CNN Dailymail Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThe CNN / DailyMail Dataset is an English-language dataset containing just over 300k unique news articles as written by journalists at CNN and the Daily Mail. The current version supports both extractive and abstractive summarization, though the original version was created for machine reading and comprehension and abstractive question answering. \\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSupported Tasks and Leaderboards‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/samyakmohelay/genai_dataset."},
	{"name":"fake_news_en_opensources","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/andyP/fake_news_en_opensources","creator_name":"Andrei Paraschiv","creator_url":"https://huggingface.co/andyP","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for \\\"Fake News Opensources\\\"\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\n\\n\\nHomepage: https://github.com/AndyTheFactory/FakeNewsDataset\\nRepository: https://github.com/AndyTheFactory/FakeNewsDataset\\nPoint of Contact: Andrei Paraschiv\\n\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\na consolidated and cleaned up version of the opensources Fake News dataset\\nFake News Corpus comprises 8,529,090 individual articles, classified into 12 classes: reliable, unreliable, political, bias, fake‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/andyP/fake_news_en_opensources."},
	{"name":"commonsense_qa-ID","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/rizquuula/commonsense_qa-ID","creator_name":"Muhammad Razif Rizqullah","creator_url":"https://huggingface.co/rizquuula","description":"CommonsenseQA-ID is Indonesian translation version of CommonsenseQA, a new multiple-choice question answering dataset that requires different types of commonsense knowledge\\nto predict the correct answers . It contains 12,102 questions with one correct answer and four distractor answers.\\nThe dataset is provided in two major training/validation/testing set splits: \\\"Random split\\\" which is the main evaluation\\nsplit, and \\\"Question token split\\\", see paper for details."},
	{"name":"Alpaca-cnn-dailymail","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ZhongshengWang/Alpaca-cnn-dailymail","creator_name":"Zhongsheng Wang","creator_url":"https://huggingface.co/ZhongshengWang","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Summary\\n\\t\\n\\nData set Alpaca-cnn-dailymail is a data set version format changed by ccdv/cnn_dailymail to meet Alpaca fine-tuning Llama2. Only versions 3.0.0 and 2.0.0 were used for merging and as a key data set for the summary extraction task.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLicensing Information\\n\\t\\n\\nThe Alpaca-cnn-dailymail dataset version 1.0.0 is released under the Apache-2.0 License.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tCitation Information\\n\\t\\n\\n@inproceedings{see-etal-2017-get,\\n    title = \\\"Get To The Point:‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ZhongshengWang/Alpaca-cnn-dailymail."},
	{"name":"beyazperde-all-movie-reviews","keyword":"monolingual","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/turkish-nlp-suite/beyazperde-all-movie-reviews","creator_name":"Turkish NLP Suite","creator_url":"https://huggingface.co/turkish-nlp-suite","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for turkish-nlp-suite/beyazperde-all-movie-reviews\\n\\t\\n\\n \\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nBeyazperde Movie Reviews offers Turkish sentiment analysis datasets that is scraped from popular movie reviews website Beyazperde.com. All Movie Reviews include audience reviews about movies of all the time. Here's the star rating distribution:\\n\\n\\t\\n\\t\\t\\nstar rating\\ncount\\n\\n\\n\\t\\t\\n0.5\\n3.635\\n\\n\\n1.0\\n2.325\\n\\n\\n1.5\\n1.077\\n\\n\\n2.0\\n1.902\\n\\n\\n2.5\\n4.767\\n\\n\\n3.0\\n4.347\\n\\n\\n3.5\\n6.495\\n\\n\\n4.0\\n9.486\\n\\n\\n4.5\\n3.652\\n\\n\\n5.0‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/turkish-nlp-suite/beyazperde-all-movie-reviews."},
	{"name":"vitamins-supplements-reviews","keyword":"monolingual","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/turkish-nlp-suite/vitamins-supplements-reviews","creator_name":"Turkish NLP Suite","creator_url":"https://huggingface.co/turkish-nlp-suite","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for turkish-nlp-suite/vitamins-supplements-reviews\\n\\t\\n\\n \\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nTurkish sentiment analysis dataset from customer reviews about supplement and vitamin products. The dataset is scraped from Vitaminler.com and contains\\ncustomer reviews and star rating about vitamin and supplement products.\\nEach customer review in the Vitamins and Supplements Reviews Dataset describes a customer‚Äôs experience with a supplement product in terms of the product‚Äôs‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/turkish-nlp-suite/vitamins-supplements-reviews."},
	{"name":"vitamins-supplements-NER","keyword":"monolingual","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/turkish-nlp-suite/vitamins-supplements-NER","creator_name":"Turkish NLP Suite","creator_url":"https://huggingface.co/turkish-nlp-suite","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for turkish-nlp-suite/vitamins-supplements-NER\\n\\t\\n\\n \\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThe Vitamins and Supplements NER Dataset is a NER dataset containing customer reviews with entity and span annotations. User reviews were collected from a popular supplement products e-\\ncommerce website Vitaminler.com. \\nEach customer review in the Vitamins and Supplements NER Dataset describes a customer‚Äôs experience with a supplement product in terms of that product‚Äôs effectiveness‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/turkish-nlp-suite/vitamins-supplements-NER."},
	{"name":"taln-archives_fr_prompt_data_to_text","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/CATIE-AQ/taln-archives_fr_prompt_data_to_text","creator_name":"CATIE","creator_url":"https://huggingface.co/CATIE-AQ","description":"\\n\\t\\n\\t\\t\\n\\t\\ttaln-archives_fr_prompt_data_to_text\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tSummary\\n\\t\\n\\ntaln-archives_fr_prompt_data_to_text is a subset of the Dataset of French Prompts (DFP).It contains 35,370 rows that can be used for a data-to-text task.The original data (without prompts) comes from the dataset taln-archives.A list of prompts (see below) was then applied in order to build the input and target columns and thus obtain the same format as the xP3 dataset by Muennighoff et al.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tPrompts used‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/CATIE-AQ/taln-archives_fr_prompt_data_to_text."},
	{"name":"taln-archives_fr_prompt_keywords_extraction","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/CATIE-AQ/taln-archives_fr_prompt_keywords_extraction","creator_name":"CATIE","creator_url":"https://huggingface.co/CATIE-AQ","description":"\\n\\t\\n\\t\\t\\n\\t\\ttaln-archives_fr_prompt_keywords_extraction\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tSummary\\n\\t\\n\\ntaln-archives_fr_prompt_keywords_extraction is a subset of the Dataset of French Prompts (DFP).It contains 24,507 rows that can be used for a keywords_extraction task.The original data (without prompts) comes from the dataset taln-archives.A list of prompts (see below) was then applied in order to build the input and target columns and thus obtain the same format as the xP3 dataset by Muennighoff et al.‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/CATIE-AQ/taln-archives_fr_prompt_keywords_extraction."},
	{"name":"termith-eval_fr_prompt_data_to_text","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/CATIE-AQ/termith-eval_fr_prompt_data_to_text","creator_name":"CATIE","creator_url":"https://huggingface.co/CATIE-AQ","description":"\\n\\t\\n\\t\\t\\n\\t\\ttermith-eval_fr_prompt_data_to_text\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tSummary\\n\\t\\n\\ntermith-eval_fr_prompt_data_to_text is a subset of the Dataset of French Prompts (DFP).It contains 11,886 rows that can be used for a data-to-text task.The original data (without prompts) comes from the dataset termith-eval.A list of prompts (see below) was then applied in order to build the input and target columns and thus obtain the same format as the xP3 dataset by Muennighoff et al.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tPrompts used‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/CATIE-AQ/termith-eval_fr_prompt_data_to_text."},
	{"name":"termith-eval_fr_prompt_keywords_extraction","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/CATIE-AQ/termith-eval_fr_prompt_keywords_extraction","creator_name":"CATIE","creator_url":"https://huggingface.co/CATIE-AQ","description":"\\n\\t\\n\\t\\t\\n\\t\\ttermith-eval_fr_prompt_keywords_extraction\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tSummary\\n\\t\\n\\ntermith-eval_fr_prompt_keywords_extraction is a subset of the Dataset of French Prompts (DFP).It contains 8,295 rows that can be used for a keywords_extraction task.The original data (without prompts) comes from the dataset termith-eval.A list of prompts (see below) was then applied in order to build the input and target columns and thus obtain the same format as the xP3 dataset by Muennighoff et al.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tPrompts‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/CATIE-AQ/termith-eval_fr_prompt_keywords_extraction."},
	{"name":"wikinews-fr-100_fr_prompt_data_to_text","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/CATIE-AQ/wikinews-fr-100_fr_prompt_data_to_text","creator_name":"CATIE","creator_url":"https://huggingface.co/CATIE-AQ","description":"\\n\\t\\n\\t\\t\\n\\t\\twikinews-fr-100_fr_prompt_data_to_text\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tSummary\\n\\t\\n\\nwikinews-fr-100_fr_prompt_data_to_text is a subset of the Dataset of French Prompts (DFP).It contains 3,000 rows that can be used for a data-to-text task.The original data (without prompts) comes from the dataset wikinews-fr-100.A list of prompts (see below) was then applied in order to build the input and target columns and thus obtain the same format as the xP3 dataset by Muennighoff et al.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tPrompts used‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/CATIE-AQ/wikinews-fr-100_fr_prompt_data_to_text."},
	{"name":"wikinews-fr-100_fr_prompt_keywords_extraction","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/CATIE-AQ/wikinews-fr-100_fr_prompt_keywords_extraction","creator_name":"CATIE","creator_url":"https://huggingface.co/CATIE-AQ","description":"\\n\\t\\n\\t\\t\\n\\t\\twikinews-fr-100_fr_prompt_keywords_extraction\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tSummary\\n\\t\\n\\nwikinews-fr-100_fr_prompt_keywords_extraction is a subset of the Dataset of French Prompts (DFP).It contains 2,100 rows that can be used for a keywords_extraction task.The original data (without prompts) comes from the dataset wikinews-fr-100.A list of prompts (see below) was then applied in order to build the input and target columns and thus obtain the same format as the xP3 dataset by Muennighoff et al.‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/CATIE-AQ/wikinews-fr-100_fr_prompt_keywords_extraction."},
	{"name":"speech_commands_enrichment_only","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/renumics/speech_commands_enrichment_only","creator_name":"Renumics","creator_url":"https://huggingface.co/renumics","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for SpeechCommands\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nüìä Data-centric AI principles have become increasingly important for real-world use cases.At Renumics we believe that classical benchmark datasets and competitions should be extended to reflect this development. \\nüîç This is why we are publishing benchmark datasets with application-specific enrichments (e.g. embeddings, baseline results, uncertainties, label error scores). We hope this helps the ML community in the‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/renumics/speech_commands_enrichment_only."},
	{"name":"big_patent_sample","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Trelis/big_patent_sample","creator_name":"Trelis","creator_url":"https://huggingface.co/Trelis","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSampled big_patent Dataset\\n\\t\\n\\nThis is a sampled big_patent dataset - sampled down for shorter fine-tunings.\\nThe data is sampled with the aim of providing an even distribution across data lengths. The distribution is quite flat up until 1 million characters in length, making the dataset good for training on lengths up to 250,000 tokens.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Big Patent\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nBIGPATENT, consisting of 1.3 million records of U.S. patent documents‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Trelis/big_patent_sample."},
	{"name":"This-is-not-a-dataset","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/HiTZ/This-is-not-a-dataset","creator_name":"HiTZ zentroa","creator_url":"https://huggingface.co/HiTZ","description":"\\n    \\n\\n\\n\\\"A Large Negation Benchmark to Challenge Large Language Models\\\"\\n\\n\\nWe introduce a large semi-automatically generated dataset of ~400,000 descriptive sentences about commonsense knowledge that can be true or false in which negation is present in about 2/3 of the corpus in different forms that we use to evaluate LLMs.\\n\\n\\n\\nüìñ Paper: This is not a Dataset: A Large Negation Benchmark to Challenge Large Language Models (EMNLP'23)\\nüíª Baseline Code and the Official Scorer:‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/HiTZ/This-is-not-a-dataset."},
	{"name":"vibravox","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Cnam-LMSSC/vibravox","creator_name":"Laboratoire de M√©canique des Structures et des Syst√®mes Coupl√©s","creator_url":"https://huggingface.co/Cnam-LMSSC","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for VibraVox\\n\\t\\n\\n\\n  \\n\\n\\n\\nüëÄ While waiting for the TooBigContentError issue to be resolved by the HuggingFace team, you can explore the dataset viewer of vibravox-test\\nwhich has exactly the same architecture.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDATASET SUMMARY\\n\\t\\n\\nThe VibraVox dataset is a general purpose audio dataset of french speech captured with body-conduction transducers.\\nThis dataset can be used for various audio machine learning tasks :\\n\\nAutomatic Speech Recognition (ASR) (Speech-to-Text‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Cnam-LMSSC/vibravox."},
	{"name":"fashion-test","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/koaning/fashion-test","creator_name":"Vincent D. Warmerdam","creator_url":"https://huggingface.co/koaning","description":"This dataset represents some data that Ines annotated. I am adding this info manually. \\n"},
	{"name":"ro-paraphrase-bible","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/andyP/ro-paraphrase-bible","creator_name":"Andrei Paraschiv","creator_url":"https://huggingface.co/andyP","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for \\\"Romanian Bible Paraphrase Corpus\\\"\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\n\\n\\nHomepage: https://github.com/AndyTheFactory/ro-paraphrase-bible\\nRepository: https://github.com/AndyTheFactory/ro-paraphrase-bible\\nPoint of Contact: Andrei Paraschiv\\n\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nA paraphprase corpus created from 10 different Romanian language Bible versions. Since the Bible has all paragraphs uniquely numbered an alignment between two \\nversions is straighforward. \\nWe‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/andyP/ro-paraphrase-bible."},
	{"name":"NOAA-Buoy","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Qdrant/NOAA-Buoy","creator_name":"Qdrant","creator_url":"https://huggingface.co/Qdrant","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tNOAA Buoy meterological data\\n\\t\\n\\nNOAA Buoy Data was downloaded, processed, and cleaned for tasks pertaining to tabular data. The data consists of meteorological measurements. There are two datasets\\n\\nFrom 1980 through 2022 (denoted with \\\"years\\\" in file names)\\nFrom Jan 2023 through end of Sept 2023 (denoted with \\\"2023\\\" in file names)\\n\\nThe original intended use is for anomaly detection in tabular data. \\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Details\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThis dataset‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Qdrant/NOAA-Buoy."},
	{"name":"uz-crawl","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/tahrirchi/uz-crawl","creator_name":"Tahrirchi","creator_url":"https://huggingface.co/tahrirchi","description":"\\n\\t\\n\\t\\t\\n\\t\\tDataset Card for UzCrawl\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nIn an effort to democratize research on low-resource languages, we release UzCrawl dataset, a web and telegram crawl corpus consisting of materials from nearly 1.2 million unique sources in the Uzbek Language. \\nPlease refer to our blogpost for further details.\\nP.S. We updated the dataset with 2nd version that extends the scope to new topics as well as being up to date to March 2024.\\nTo load and use dataset, run this script:\\nfrom‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/tahrirchi/uz-crawl."},
	{"name":"simsamu","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/medkit/simsamu","creator_name":"medkit","creator_url":"https://huggingface.co/medkit","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSimsamu dataset\\n\\t\\n\\nThis repository contains recordings of simulated medical dispatch dialogs in the\\nfrench language, annotated for diarization and transcription. It is published\\nunder the MIT license.\\nThese dialogs were recorded as part of the training of emergency medicine\\ninterns, which consisted in simulating a medical dispatch call where the interns\\ntook turns playing the caller and the regulating doctor. \\nEach situation was decided randomly in advance, blind to who was playing‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/medkit/simsamu."},
	{"name":"Openclipart-Oldstyle","keyword":"monolingual","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/joshuajewell/Openclipart-Oldstyle","creator_name":"Joshua Jewell","creator_url":"https://huggingface.co/joshuajewell","description":"Dataset Card for 16th Century(?) Black and White Style\\n\\nDataset used to train/finetune a black and white print style\\nCaptions are generated by hand with the assistance of BLIP.\\nImages were sourced from:\\n  https://openclipart.org/artist/j4p4n\\n  https://openclipart.org/artist/johnny_automatic\\n  https://openclipart.org/artist/SnipsAndClips\\nText file filenames correspond image file filenames as captions.\\n"},
	{"name":"32000-BlackSharpie","keyword":"monolingual","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/joshuajewell/32000-BlackSharpie","creator_name":"Joshua Jewell","creator_url":"https://huggingface.co/joshuajewell","description":"Dataset Card for a Black and White Sharpie Style\\n\\nDataset used to train/finetune a black and white sharpie style\\nCaptions are generated by hand with the assistance of BLIP.\\nImages were hand drawn.\\nText file filenames correspond image file filenames as captions.\\n"},
	{"name":"kor_duorc","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/KETI-AIR/kor_duorc","creator_name":"Korea Electronics Technology Institute Artificial Intelligence Research Center","creator_url":"https://huggingface.co/KETI-AIR","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for duorc\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLicensing Information\\n\\t\\n\\nMIT License\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSource Data Citation Information\\n\\t\\n\\n@inproceedings{DuoRC,\\nauthor = { Amrita Saha and Rahul Aralikatte and Mitesh M. Khapra and Karthik Sankaranarayanan},\\ntitle = {{DuoRC: Towards Complex Language Understanding with Paraphrased Reading Comprehension}},\\nbooktitle = {Meeting of the Association for Computational Linguistics (ACL)},\\nyear = {2018}\\n}\\n\\n"},
	{"name":"aya-telugu-news-articles","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/SuryaKrishna02/aya-telugu-news-articles","creator_name":"Surya Guthikonda","creator_url":"https://huggingface.co/SuryaKrishna02","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSummary\\n\\t\\n\\naya-telugu-news-articles is an open source dataset of instruct-style records generated by webscraping a Telugu news articles website. This was created as part of Aya Open Science Initiative from Cohere For AI.\\nThis dataset can be used for any purpose, whether academic or commercial, under the terms of the Apache 2.0 License.\\nSupported Tasks:\\n\\nTraining LLMs\\nSynthetic Data Generation\\nData Augmentation\\n\\nLanguages: Telugu Version: 1.0\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Overview‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/SuryaKrishna02/aya-telugu-news-articles."},
	{"name":"TimeQA","keyword":"monolingual","license":"BSD 3-Clause Clear License","license_url":"https://choosealicense.com/licenses/bsd-3-clause-clear/","language":"en","dataset_url":"https://huggingface.co/datasets/hugosousa/TimeQA","creator_name":"Hugo Sousa","creator_url":"https://huggingface.co/hugosousa","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tTimeQA\\n\\t\\n\\nCheck out the original GitHub repo to learn more about the dataset.\\n"},
	{"name":"CSMD","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/davebulaval/CSMD","creator_name":"David","creator_url":"https://huggingface.co/davebulaval","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for \\\"Continuous Scale Meaning Dataset\\\" (CSMD)\\n\\t\\n\\nCSMD was created for MeaningBERT: Assessing Meaning Preservation Between Sentences.\\nIt contains 1,355 English text simplification meaning preservation annotations. Meaning preservation measures how well the meaning of the output text corresponds to the meaning of the source (Saggion, 2017).\\nThe annotations were taken from the following four datasets: \\n\\nASSET\\nQuestEVal,\\nSimpDa_2022 and,\\nSimplicity-DA.\\n\\nIt contains a data‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/davebulaval/CSMD."},
	{"name":"zelensky-speeches","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/slava-medvedev/zelensky-speeches","creator_name":"Viacheslav Medvediev","creator_url":"https://huggingface.co/slava-medvedev","description":"\\n\\t\\n\\t\\t\\n\\t\\tDataset Card for \\\"zelenskiy-speeches\\\"\\n\\t\\n\\nSpeeches given by the president of Ukraine Volodymyr ZelenskyLanguages: Ukrainian, EnglishSource: president.gov.uaAuto-updated daily by Github Actions of zelensky-speech-fetcherLicense: CC BY-NC-ND 4.0 Deed\\n"},
	{"name":"medtrain_may23","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Taylor658/medtrain_may23","creator_name":"atayloraerospace","creator_url":"https://huggingface.co/Taylor658","description":"\\nlicense: apache-2.0\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Medical Question Answering Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThis dataset contains a collection of question-answer pairs related to various medical topics. The data is structured to provide comprehensive answers to specific medical questions, covering information, diagnosis, treatment, prevention, and susceptibility related to different health conditions.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSupported Tasks and Leaderboards‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Taylor658/medtrain_may23."},
	{"name":"FOCALtask","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/V12X-ksr/FOCALtask","creator_name":"Kushal S Raj","creator_url":"https://huggingface.co/V12X-ksr","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Dataset Name\\n\\t\\n\\n\\n\\nThis dataset card aims to be a base template for new datasets. It has been generated using this raw template.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Details\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\n\\n\\n\\n\\n\\nCurated by: [More Information Needed]\\nFunded by [optional]: [More Information Needed]\\nShared by [optional]: [More Information Needed]\\nLanguage(s) (NLP): [More Information Needed]\\nLicense: [More Information Needed]\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Sources [optional]‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/V12X-ksr/FOCALtask."},
	{"name":"squad-augmented-v2","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/christti/squad-augmented-v2","creator_name":"Christoph Timmermann","creator_url":"https://huggingface.co/christti","description":"christti/squad-augmented-v2 dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"arxiv_nlp_intstruct","keyword":"monolingual","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/AlgorithmicResearchGroup/arxiv_nlp_intstruct","creator_name":"Algorithmic Research Group","creator_url":"https://huggingface.co/AlgorithmicResearchGroup","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for \\\"arxiv_nlp_intstruct\\\"\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThe \\\"AlgorithmicResearchGroup/arxiv_nlp_intstruct\\\" dataset consists of question-answer pairs derived from ArXiv abstracts from the cs.CL category\\\". \\nQuestions and answers are generated using GPT-3.5-turbo model\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages\\n\\t\\n\\nEnglish\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Structure\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Instances\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\ttrain\\n\\t\\n\\n\\nSize of downloaded dataset files: 38.4 MB\\n\\nAn example of 'train' looks as follows.\\n{‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/AlgorithmicResearchGroup/arxiv_nlp_intstruct."},
	{"name":"Vibravox_dummy","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/zinc75/Vibravox_dummy","creator_name":"√âric Bavu","creator_url":"https://huggingface.co/zinc75","description":"zinc75/Vibravox_dummy dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"drugscom_reviews","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Zakia/drugscom_reviews","creator_name":"Zakia Salod","creator_url":"https://huggingface.co/Zakia","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for \\\"DrugsCom Reviews\\\"\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThe DrugsCom Reviews dataset is originally sourced from the UCI Machine Learning Repository. It provides patient reviews on specific drugs along with related conditions and a 10-star patient rating reflecting overall patient satisfaction. The dataset has been uploaded to Hugging Face to facilitate easier access and use by the machine learning community. It contains 161,297 instances in the training set and 53,766‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Zakia/drugscom_reviews."},
	{"name":"Marathon","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Lemoncoke/Marathon","creator_name":"Lei Zhang","creator_url":"https://huggingface.co/Lemoncoke","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Marathon\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tRelease\\n\\t\\n\\n\\n[2024/05/15] üî• Marathon is accepted by ACL 2024 Main Conference.\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nMarathon benchmark is a new long-context multiple-choice benchmark, mainly based on LooGLE, with some original data from LongBench. The context length can reach up to 200K+. Marathon benchmark comprises six tasks: Comprehension and Reasoning, Multiple Information Retrieval, Timeline Reorder, Computation, Passage Retrieval, and Short‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Lemoncoke/Marathon."},
	{"name":"big_patent_100k_characters","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Trelis/big_patent_100k_characters","creator_name":"Trelis","creator_url":"https://huggingface.co/Trelis","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSampled Big Patent Dataset\\n\\t\\n\\nThis is a sampled Trelis/big_patent_sample dataset containing rows of data with descriptions shorter than or equal to 100,000 characters in length.\\n--- Sampled from Trelis/big_patent_sampled ---\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSampled big_patent Dataset\\n\\t\\n\\nThis is a sampled big_patent dataset - sampled down for shorter fine-tunings.\\nThe data is sampled with the aim of providing an even distribution across data lengths. The distribution is quite flat up until 1 million‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Trelis/big_patent_100k_characters."},
	{"name":"CanItEdit","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/nuprl/CanItEdit","creator_name":"Northeastern University Programming Research Lab","creator_url":"https://huggingface.co/nuprl","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tCan It Edit? Evaluating the Ability of Large Language Models to Follow Code Editing Instructions\\n\\t\\n\\nCanItEdit is a benchmark for evaluating LLMs on instructional code editing, the task of updating a program given a natural language instruction. The benchmark contains 105 hand-crafted Python programs with before and after code blocks, two types of natural language instructions (descriptive and lazy), and a hidden test suite.\\nThe dataset‚Äôs dual natural language instructions test‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/nuprl/CanItEdit."},
	{"name":"openslr-slr69-ca-trimmed-denoised","keyword":"monolingual","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/projecte-aina/openslr-slr69-ca-trimmed-denoised","creator_name":"Projecte Aina","creator_url":"https://huggingface.co/projecte-aina","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for openslr-slr69-ca-denoised\\n\\t\\n\\nThis is a post-processed version of the Catalan subset belonging to the Open Speech and Language Resources (OpenSLR) speech dataset. \\nSpecifically the subset OpenSLR-69. \\nThe original HFü§ó SLR-69 dataset is located here.\\nSame license is maintained: Attribution-ShareAlike 4.0 International.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Details\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nWe processed the data of the Catalan OpenSLR with the following recipe:\\n\\nTrimming:‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/projecte-aina/openslr-slr69-ca-trimmed-denoised."},
	{"name":"lpf","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/louisbrulenaudet/lpf","creator_name":"Louis Brul√© Naudet","creator_url":"https://huggingface.co/louisbrulenaudet","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLivre des proc√©dures fiscales, non-instruct (11-12-2023)\\n\\t\\n\\nThis project focuses on fine-tuning pre-trained language models to create efficient and accurate models for tax practice. \\nFine-tuning is the process of adapting a pre-trained model to perform specific tasks or cater to particular domains. It involves adjusting the model's parameters through a further round of training on task-specific or domain-specific data. While conventional fine-tuning strategies involve supervised‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/louisbrulenaudet/lpf."},
	{"name":"cgi","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/louisbrulenaudet/cgi","creator_name":"Louis Brul√© Naudet","creator_url":"https://huggingface.co/louisbrulenaudet","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tCode G√©n√©ral des Imp√¥ts, non-instruct (11-12-2023)\\n\\t\\n\\nThis project focuses on fine-tuning pre-trained language models to create efficient and accurate models for tax practice. \\nFine-tuning is the process of adapting a pre-trained model to perform specific tasks or cater to particular domains. It involves adjusting the model's parameters through a further round of training on task-specific or domain-specific data. While conventional fine-tuning strategies involve supervised learning‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/louisbrulenaudet/cgi."},
	{"name":"code-douanes","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/louisbrulenaudet/code-douanes","creator_name":"Louis Brul√© Naudet","creator_url":"https://huggingface.co/louisbrulenaudet","description":"\\n\\t\\n\\t\\t\\n\\t\\tCode des douanes, non-instruct (2025-03-10)\\n\\t\\n\\nThe objective of this project is to provide researchers, professionals and law students with simplified, up-to-date access to all French legal texts, enriched with a wealth of data to facilitate their integration into Community and European projects.\\nNormally, the data is refreshed daily on all legal codes, and aims to simplify the production of training sets and labeling pipelines for the development of free, open-source language models‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/louisbrulenaudet/code-douanes."},
	{"name":"code-consommation","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/louisbrulenaudet/code-consommation","creator_name":"Louis Brul√© Naudet","creator_url":"https://huggingface.co/louisbrulenaudet","description":"\\n\\t\\n\\t\\t\\n\\t\\tCode de la consommation, non-instruct (2025-03-10)\\n\\t\\n\\nThe objective of this project is to provide researchers, professionals and law students with simplified, up-to-date access to all French legal texts, enriched with a wealth of data to facilitate their integration into Community and European projects.\\nNormally, the data is refreshed daily on all legal codes, and aims to simplify the production of training sets and labeling pipelines for the development of free, open-source language‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/louisbrulenaudet/code-consommation."},
	{"name":"code-penal","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/louisbrulenaudet/code-penal","creator_name":"Louis Brul√© Naudet","creator_url":"https://huggingface.co/louisbrulenaudet","description":"\\n\\t\\n\\t\\t\\n\\t\\tCode p√©nal, non-instruct (2025-03-10)\\n\\t\\n\\nThe objective of this project is to provide researchers, professionals and law students with simplified, up-to-date access to all French legal texts, enriched with a wealth of data to facilitate their integration into Community and European projects.\\nNormally, the data is refreshed daily on all legal codes, and aims to simplify the production of training sets and labeling pipelines for the development of free, open-source language models based‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/louisbrulenaudet/code-penal."},
	{"name":"code-sport","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/louisbrulenaudet/code-sport","creator_name":"Louis Brul√© Naudet","creator_url":"https://huggingface.co/louisbrulenaudet","description":"\\n\\t\\n\\t\\t\\n\\t\\tCode du sport, non-instruct (2025-03-10)\\n\\t\\n\\nThe objective of this project is to provide researchers, professionals and law students with simplified, up-to-date access to all French legal texts, enriched with a wealth of data to facilitate their integration into Community and European projects.\\nNormally, the data is refreshed daily on all legal codes, and aims to simplify the production of training sets and labeling pipelines for the development of free, open-source language models‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/louisbrulenaudet/code-sport."},
	{"name":"code-civil","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/louisbrulenaudet/code-civil","creator_name":"Louis Brul√© Naudet","creator_url":"https://huggingface.co/louisbrulenaudet","description":"\\n\\t\\n\\t\\t\\n\\t\\tCode civil, non-instruct (2025-03-10)\\n\\t\\n\\nThe objective of this project is to provide researchers, professionals and law students with simplified, up-to-date access to all French legal texts, enriched with a wealth of data to facilitate their integration into Community and European projects.\\nNormally, the data is refreshed daily on all legal codes, and aims to simplify the production of training sets and labeling pipelines for the development of free, open-source language models based‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/louisbrulenaudet/code-civil."},
	{"name":"code-commerce","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/louisbrulenaudet/code-commerce","creator_name":"Louis Brul√© Naudet","creator_url":"https://huggingface.co/louisbrulenaudet","description":"\\n\\t\\n\\t\\t\\n\\t\\tCode de commerce, non-instruct (2025-03-10)\\n\\t\\n\\nThe objective of this project is to provide researchers, professionals and law students with simplified, up-to-date access to all French legal texts, enriched with a wealth of data to facilitate their integration into Community and European projects.\\nNormally, the data is refreshed daily on all legal codes, and aims to simplify the production of training sets and labeling pipelines for the development of free, open-source language models‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/louisbrulenaudet/code-commerce."},
	{"name":"code-sante-publique","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/louisbrulenaudet/code-sante-publique","creator_name":"Louis Brul√© Naudet","creator_url":"https://huggingface.co/louisbrulenaudet","description":"\\n\\t\\n\\t\\t\\n\\t\\tCode de la sant√© publique, non-instruct (2025-03-10)\\n\\t\\n\\nThe objective of this project is to provide researchers, professionals and law students with simplified, up-to-date access to all French legal texts, enriched with a wealth of data to facilitate their integration into Community and European projects.\\nNormally, the data is refreshed daily on all legal codes, and aims to simplify the production of training sets and labeling pipelines for the development of free, open-source language‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/louisbrulenaudet/code-sante-publique."},
	{"name":"code-environnement","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/louisbrulenaudet/code-environnement","creator_name":"Louis Brul√© Naudet","creator_url":"https://huggingface.co/louisbrulenaudet","description":"\\n\\t\\n\\t\\t\\n\\t\\tCode de l'environnement, non-instruct (2025-03-10)\\n\\t\\n\\nThe objective of this project is to provide researchers, professionals and law students with simplified, up-to-date access to all French legal texts, enriched with a wealth of data to facilitate their integration into Community and European projects.\\nNormally, the data is refreshed daily on all legal codes, and aims to simplify the production of training sets and labeling pipelines for the development of free, open-source language‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/louisbrulenaudet/code-environnement."},
	{"name":"dac6-instruct","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/louisbrulenaudet/dac6-instruct","creator_name":"Louis Brul√© Naudet","creator_url":"https://huggingface.co/louisbrulenaudet","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDAC6 instruct (11-12-2023)\\n\\t\\n\\n‚ÄúDAC 6‚Äù refers to European Council Directive (EU) 2018/822 of May 25, 2018 relating to the automatic and mandatory exchange of information on cross-border arrangements requiring declaration. It aims to strengthen cooperation between tax administrations in EU countries on potentially aggressive tax planning arrangements.\\nThis project focuses on fine-tuning pre-trained language models to create efficient and accurate models for tax practice. \\nFine-tuning‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/louisbrulenaudet/dac6-instruct."},
	{"name":"code-procedure-civile","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/louisbrulenaudet/code-procedure-civile","creator_name":"Louis Brul√© Naudet","creator_url":"https://huggingface.co/louisbrulenaudet","description":"\\n\\t\\n\\t\\t\\n\\t\\tCode de proc√©dure civile, non-instruct (2025-03-10)\\n\\t\\n\\nThe objective of this project is to provide researchers, professionals and law students with simplified, up-to-date access to all French legal texts, enriched with a wealth of data to facilitate their integration into Community and European projects.\\nNormally, the data is refreshed daily on all legal codes, and aims to simplify the production of training sets and labeling pipelines for the development of free, open-source language‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/louisbrulenaudet/code-procedure-civile."},
	{"name":"code-monetaire-financier","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/louisbrulenaudet/code-monetaire-financier","creator_name":"Louis Brul√© Naudet","creator_url":"https://huggingface.co/louisbrulenaudet","description":"\\n\\t\\n\\t\\t\\n\\t\\tCode mon√©taire et financier, non-instruct (2025-03-10)\\n\\t\\n\\nThe objective of this project is to provide researchers, professionals and law students with simplified, up-to-date access to all French legal texts, enriched with a wealth of data to facilitate their integration into Community and European projects.\\nNormally, the data is refreshed daily on all legal codes, and aims to simplify the production of training sets and labeling pipelines for the development of free, open-source‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/louisbrulenaudet/code-monetaire-financier."},
	{"name":"code-assurances","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/louisbrulenaudet/code-assurances","creator_name":"Louis Brul√© Naudet","creator_url":"https://huggingface.co/louisbrulenaudet","description":"\\n\\t\\n\\t\\t\\n\\t\\tCode des assurances, non-instruct (2025-03-10)\\n\\t\\n\\nThe objective of this project is to provide researchers, professionals and law students with simplified, up-to-date access to all French legal texts, enriched with a wealth of data to facilitate their integration into Community and European projects.\\nNormally, the data is refreshed daily on all legal codes, and aims to simplify the production of training sets and labeling pipelines for the development of free, open-source language‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/louisbrulenaudet/code-assurances."},
	{"name":"code-artisanat","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/louisbrulenaudet/code-artisanat","creator_name":"Louis Brul√© Naudet","creator_url":"https://huggingface.co/louisbrulenaudet","description":"\\n\\t\\n\\t\\t\\n\\t\\tCode de l'artisanat, non-instruct (2025-03-10)\\n\\t\\n\\nThe objective of this project is to provide researchers, professionals and law students with simplified, up-to-date access to all French legal texts, enriched with a wealth of data to facilitate their integration into Community and European projects.\\nNormally, the data is refreshed daily on all legal codes, and aims to simplify the production of training sets and labeling pipelines for the development of free, open-source language‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/louisbrulenaudet/code-artisanat."},
	{"name":"code-commande-publique","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/louisbrulenaudet/code-commande-publique","creator_name":"Louis Brul√© Naudet","creator_url":"https://huggingface.co/louisbrulenaudet","description":"\\n\\t\\n\\t\\t\\n\\t\\tCode de la commande publique, non-instruct (2025-03-10)\\n\\t\\n\\nThe objective of this project is to provide researchers, professionals and law students with simplified, up-to-date access to all French legal texts, enriched with a wealth of data to facilitate their integration into Community and European projects.\\nNormally, the data is refreshed daily on all legal codes, and aims to simplify the production of training sets and labeling pipelines for the development of free, open-source‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/louisbrulenaudet/code-commande-publique."},
	{"name":"code-propriete-intellectuelle","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/louisbrulenaudet/code-propriete-intellectuelle","creator_name":"Louis Brul√© Naudet","creator_url":"https://huggingface.co/louisbrulenaudet","description":"\\n\\t\\n\\t\\t\\n\\t\\tCode de la propri√©t√© intellectuelle, non-instruct (2025-03-10)\\n\\t\\n\\nThe objective of this project is to provide researchers, professionals and law students with simplified, up-to-date access to all French legal texts, enriched with a wealth of data to facilitate their integration into Community and European projects.\\nNormally, the data is refreshed daily on all legal codes, and aims to simplify the production of training sets and labeling pipelines for the development of free‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/louisbrulenaudet/code-propriete-intellectuelle."},
	{"name":"code-procedures-civiles-execution","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/louisbrulenaudet/code-procedures-civiles-execution","creator_name":"Louis Brul√© Naudet","creator_url":"https://huggingface.co/louisbrulenaudet","description":"\\n\\t\\n\\t\\t\\n\\t\\tCode des proc√©dures civiles d'ex√©cution, non-instruct (2025-03-10)\\n\\t\\n\\nThe objective of this project is to provide researchers, professionals and law students with simplified, up-to-date access to all French legal texts, enriched with a wealth of data to facilitate their integration into Community and European projects.\\nNormally, the data is refreshed daily on all legal codes, and aims to simplify the production of training sets and labeling pipelines for the development of free‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/louisbrulenaudet/code-procedures-civiles-execution."},
	{"name":"code-route","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/louisbrulenaudet/code-route","creator_name":"Louis Brul√© Naudet","creator_url":"https://huggingface.co/louisbrulenaudet","description":"\\n\\t\\n\\t\\t\\n\\t\\tCode de la route, non-instruct (2025-03-10)\\n\\t\\n\\nThe objective of this project is to provide researchers, professionals and law students with simplified, up-to-date access to all French legal texts, enriched with a wealth of data to facilitate their integration into Community and European projects.\\nNormally, the data is refreshed daily on all legal codes, and aims to simplify the production of training sets and labeling pipelines for the development of free, open-source language models‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/louisbrulenaudet/code-route."},
	{"name":"code-education","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/louisbrulenaudet/code-education","creator_name":"Louis Brul√© Naudet","creator_url":"https://huggingface.co/louisbrulenaudet","description":"\\n\\t\\n\\t\\t\\n\\t\\tCode de l'√©ducation, non-instruct (2025-03-10)\\n\\t\\n\\nThe objective of this project is to provide researchers, professionals and law students with simplified, up-to-date access to all French legal texts, enriched with a wealth of data to facilitate their integration into Community and European projects.\\nNormally, the data is refreshed daily on all legal codes, and aims to simplify the production of training sets and labeling pipelines for the development of free, open-source language‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/louisbrulenaudet/code-education."},
	{"name":"code-construction-habitation","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/louisbrulenaudet/code-construction-habitation","creator_name":"Louis Brul√© Naudet","creator_url":"https://huggingface.co/louisbrulenaudet","description":"\\n\\t\\n\\t\\t\\n\\t\\tCode de la construction et de l'habitation, non-instruct (2025-03-10)\\n\\t\\n\\nThe objective of this project is to provide researchers, professionals and law students with simplified, up-to-date access to all French legal texts, enriched with a wealth of data to facilitate their integration into Community and European projects.\\nNormally, the data is refreshed daily on all legal codes, and aims to simplify the production of training sets and labeling pipelines for the development of free‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/louisbrulenaudet/code-construction-habitation."},
	{"name":"code-mutualite","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/louisbrulenaudet/code-mutualite","creator_name":"Louis Brul√© Naudet","creator_url":"https://huggingface.co/louisbrulenaudet","description":"\\n\\t\\n\\t\\t\\n\\t\\tCode de la mutualit√©, non-instruct (2025-03-10)\\n\\t\\n\\nThe objective of this project is to provide researchers, professionals and law students with simplified, up-to-date access to all French legal texts, enriched with a wealth of data to facilitate their integration into Community and European projects.\\nNormally, the data is refreshed daily on all legal codes, and aims to simplify the production of training sets and labeling pipelines for the development of free, open-source language‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/louisbrulenaudet/code-mutualite."},
	{"name":"code-transports","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/louisbrulenaudet/code-transports","creator_name":"Louis Brul√© Naudet","creator_url":"https://huggingface.co/louisbrulenaudet","description":"\\n\\t\\n\\t\\t\\n\\t\\tCode des transports, non-instruct (2025-03-10)\\n\\t\\n\\nThe objective of this project is to provide researchers, professionals and law students with simplified, up-to-date access to all French legal texts, enriched with a wealth of data to facilitate their integration into Community and European projects.\\nNormally, the data is refreshed daily on all legal codes, and aims to simplify the production of training sets and labeling pipelines for the development of free, open-source language‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/louisbrulenaudet/code-transports."},
	{"name":"code-urbanisme","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/louisbrulenaudet/code-urbanisme","creator_name":"Louis Brul√© Naudet","creator_url":"https://huggingface.co/louisbrulenaudet","description":"\\n\\t\\n\\t\\t\\n\\t\\tCode de l'urbanisme, non-instruct (2025-03-10)\\n\\t\\n\\nThe objective of this project is to provide researchers, professionals and law students with simplified, up-to-date access to all French legal texts, enriched with a wealth of data to facilitate their integration into Community and European projects.\\nNormally, the data is refreshed daily on all legal codes, and aims to simplify the production of training sets and labeling pipelines for the development of free, open-source language‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/louisbrulenaudet/code-urbanisme."},
	{"name":"code-general-fonction-publique","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/louisbrulenaudet/code-general-fonction-publique","creator_name":"Louis Brul√© Naudet","creator_url":"https://huggingface.co/louisbrulenaudet","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tCode g√©n√©ral de la fonction publique, non-instruct (11-12-2023)\\n\\t\\n\\nThis project focuses on fine-tuning pre-trained language models to create efficient and accurate models for legal practice. \\nFine-tuning is the process of adapting a pre-trained model to perform specific tasks or cater to particular domains. It involves adjusting the model's parameters through a further round of training on task-specific or domain-specific data. While conventional fine-tuning strategies involve‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/louisbrulenaudet/code-general-fonction-publique."},
	{"name":"code-forestier","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/louisbrulenaudet/code-forestier","creator_name":"Louis Brul√© Naudet","creator_url":"https://huggingface.co/louisbrulenaudet","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tCode forestier, non-instruct (11-12-2023)\\n\\t\\n\\nThis project focuses on fine-tuning pre-trained language models to create efficient and accurate models for legal practice. \\nFine-tuning is the process of adapting a pre-trained model to perform specific tasks or cater to particular domains. It involves adjusting the model's parameters through a further round of training on task-specific or domain-specific data. While conventional fine-tuning strategies involve supervised learning with‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/louisbrulenaudet/code-forestier."},
	{"name":"code-justice-administrative","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/louisbrulenaudet/code-justice-administrative","creator_name":"Louis Brul√© Naudet","creator_url":"https://huggingface.co/louisbrulenaudet","description":"\\n\\t\\n\\t\\t\\n\\t\\tCode de justice administrative, non-instruct (2025-03-10)\\n\\t\\n\\nThe objective of this project is to provide researchers, professionals and law students with simplified, up-to-date access to all French legal texts, enriched with a wealth of data to facilitate their integration into Community and European projects.\\nNormally, the data is refreshed daily on all legal codes, and aims to simplify the production of training sets and labeling pipelines for the development of free, open-source‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/louisbrulenaudet/code-justice-administrative."},
	{"name":"code-postes-communications-electroniques","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/louisbrulenaudet/code-postes-communications-electroniques","creator_name":"Louis Brul√© Naudet","creator_url":"https://huggingface.co/louisbrulenaudet","description":"\\n\\t\\n\\t\\t\\n\\t\\tCode des postes et des communications √©lectroniques, non-instruct (2025-03-10)\\n\\t\\n\\nThe objective of this project is to provide researchers, professionals and law students with simplified, up-to-date access to all French legal texts, enriched with a wealth of data to facilitate their integration into Community and European projects.\\nNormally, the data is refreshed daily on all legal codes, and aims to simplify the production of training sets and labeling pipelines for the development of‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/louisbrulenaudet/code-postes-communications-electroniques."},
	{"name":"code-relations-public-administration","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/louisbrulenaudet/code-relations-public-administration","creator_name":"Louis Brul√© Naudet","creator_url":"https://huggingface.co/louisbrulenaudet","description":"\\n\\t\\n\\t\\t\\n\\t\\tCode des relations entre le public et l'administration, non-instruct (2025-03-10)\\n\\t\\n\\nThe objective of this project is to provide researchers, professionals and law students with simplified, up-to-date access to all French legal texts, enriched with a wealth of data to facilitate their integration into Community and European projects.\\nNormally, the data is refreshed daily on all legal codes, and aims to simplify the production of training sets and labeling pipelines for the development‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/louisbrulenaudet/code-relations-public-administration."},
	{"name":"code-rural-peche-maritime","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/louisbrulenaudet/code-rural-peche-maritime","creator_name":"Louis Brul√© Naudet","creator_url":"https://huggingface.co/louisbrulenaudet","description":"\\n\\t\\n\\t\\t\\n\\t\\tCode rural et de la p√™che maritime, non-instruct (2025-03-10)\\n\\t\\n\\nThe objective of this project is to provide researchers, professionals and law students with simplified, up-to-date access to all French legal texts, enriched with a wealth of data to facilitate their integration into Community and European projects.\\nNormally, the data is refreshed daily on all legal codes, and aims to simplify the production of training sets and labeling pipelines for the development of free, open-source‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/louisbrulenaudet/code-rural-peche-maritime."},
	{"name":"code-securite-interieure","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/louisbrulenaudet/code-securite-interieure","creator_name":"Louis Brul√© Naudet","creator_url":"https://huggingface.co/louisbrulenaudet","description":"\\n\\t\\n\\t\\t\\n\\t\\tCode de la s√©curit√© int√©rieure, non-instruct (2025-03-10)\\n\\t\\n\\nThe objective of this project is to provide researchers, professionals and law students with simplified, up-to-date access to all French legal texts, enriched with a wealth of data to facilitate their integration into Community and European projects.\\nNormally, the data is refreshed daily on all legal codes, and aims to simplify the production of training sets and labeling pipelines for the development of free, open-source‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/louisbrulenaudet/code-securite-interieure."},
	{"name":"4catac","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/projecte-aina/4catac","creator_name":"Projecte Aina","creator_url":"https://huggingface.co/projecte-aina","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for 4catac\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\n4catac: examples of phonetic transcription in 4  Catalan accents is a dataset of phonetic transcriptions in four Catalan accents: Balearic, Central, North-Western and Valencian. \\nIt consists of 160 sentences transcribed using IPA, following the recommendations of the Institut d'Estudis Catalans.\\nThese sentences are the same for the four accents but may have small morphological adaptations to make them more natural for the‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/projecte-aina/4catac."},
	{"name":"festcat_trimmed_denoised","keyword":"monolingual","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/projecte-aina/festcat_trimmed_denoised","creator_name":"Projecte Aina","creator_url":"https://huggingface.co/projecte-aina","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for festcat_trimmed_denoised\\n\\t\\n\\nThis is a post-processed version of the Catalan Festcat speech dataset. \\nThe original data can be found here.\\nSame license is maintained: Creative Commons Attribution-ShareAlike 3.0 Spain License.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Details\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nWe processed the data of the Catalan Festcat with the following recipe:\\n\\nTrimming: Long silences from the start and the end of clips have been removed.\\npy-webrtcvad -> Python‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/projecte-aina/festcat_trimmed_denoised."},
	{"name":"geo-reviews-dataset-2023","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/d0rj/geo-reviews-dataset-2023","creator_name":"Dmitry Balobin","creator_url":"https://huggingface.co/d0rj","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tGeo Reviews Dataset 2023\\n\\t\\n\\nYandex is making available the largest Russian-language dataset of reviews about organizations published on Yandex Maps.\\nUse it for academic and research purposes, share your results with us in Issues.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDescription\\n\\t\\n\\n\\n500,000 unique reviews\\nOnly reviews about organizations in Russia\\nAvailable on Yandex Maps\\nPublished from January to July 2023\\nThe dataset does not contain short one-word reviews\\nReviews have been cleared of personal data (phone‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/d0rj/geo-reviews-dataset-2023."},
	{"name":"bofip","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/louisbrulenaudet/bofip","creator_name":"Louis Brul√© Naudet","creator_url":"https://huggingface.co/louisbrulenaudet","description":"\\n\\t\\n\\t\\t\\n\\t\\tBulletin officiel des finances publiques - imp√¥ts, non-instruct (11-12-2023)\\n\\t\\n\\nThis project focuses on fine-tuning pre-trained language models to create efficient and accurate models for legal practice. \\nFine-tuning is the process of adapting a pre-trained model to perform specific tasks or cater to particular domains. It involves adjusting the model's parameters through a further round of training on task-specific or domain-specific data. While conventional fine-tuning strategies‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/louisbrulenaudet/bofip."},
	{"name":"TuPY_dataset_multilabel","keyword":"monolingual","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/victoriadreis/TuPY_dataset_multilabel","creator_name":"Victoria Reis","creator_url":"https://huggingface.co/victoriadreis","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tPortuguese Hate Speech Dataset (TuPy)\\n\\t\\n\\nThe Portuguese hate speech dataset (TuPy) is an annotated corpus designed to facilitate the development of advanced hate speech detection models using machine learning (ML) and natural language processing (NLP) techniques. TuPy is formed by 10000 thousand unpublished annotated tweets collected in 2023.\\nThis repository is organized as follows:\\nroot.\\n    ‚îú‚îÄ‚îÄ annotations   : classification given by annotators\\n    ‚îú‚îÄ‚îÄ raw corpus    : dataset‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/victoriadreis/TuPY_dataset_multilabel."},
	{"name":"TuPY_dataset_binary","keyword":"monolingual","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/victoriadreis/TuPY_dataset_binary","creator_name":"Victoria Reis","creator_url":"https://huggingface.co/victoriadreis","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tPortuguese Hate Speech Dataset (TuPy)\\n\\t\\n\\nThe Portuguese hate speech dataset (TuPy) is an annotated corpus designed to facilitate the development of advanced hate speech detection models using machine learning (ML) and natural language processing (NLP) techniques. TuPy is formed by 10000 thousand unpublished annotated tweets collected in 2023.\\nThis repository is organized as follows:\\nroot.\\n    ‚îú‚îÄ‚îÄ annotations   : classification given by annotators\\n    ‚îú‚îÄ‚îÄ raw corpus    : dataset‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/victoriadreis/TuPY_dataset_binary."},
	{"name":"TuPy-Dataset","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Silly-Machine/TuPy-Dataset","creator_name":"Silly-Machine","creator_url":"https://huggingface.co/Silly-Machine","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tPortuguese Hate Speech Dataset (TuPy)\\n\\t\\n\\nThe Portuguese hate speech dataset (TuPy) is an annotated corpus designed to facilitate the development of advanced hate speech detection models using machine learning (ML) \\nand natural language processing (NLP) techniques. TuPy is comprised of 10,000 (ten thousand) unpublished, annotated, and anonymized documents collected \\non Twitter (currently known as X) in 2023. \\nThis repository is organized as follows:\\nroot.\\n    ‚îú‚îÄ‚îÄ binary     : binary‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Silly-Machine/TuPy-Dataset."},
	{"name":"TuPyE-Dataset","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Silly-Machine/TuPyE-Dataset","creator_name":"Silly-Machine","creator_url":"https://huggingface.co/Silly-Machine","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tPortuguese Hate Speech Expanded Dataset (TuPyE)\\n\\t\\n\\nTuPyE, an enhanced iteration of TuPy, encompasses a compilation of 43,668 meticulously annotated documents specifically \\nselected for the purpose of hate speech detection within diverse social network contexts. \\nThis augmented dataset integrates supplementary annotations and amalgamates with datasets sourced from \\nFortuna et al. (2019), \\nLeite et al. (2020), \\nand Vargas et al. (2022),\\ncomplemented by an infusion of 10,000 original‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Silly-Machine/TuPyE-Dataset."},
	{"name":"LongSumEt","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/TalTechNLP/LongSumEt","creator_name":"Laboratory of Language Technology at Tallinn University of Technology","creator_url":"https://huggingface.co/TalTechNLP","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for \\\"LongSumEt\\\"\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nLongSumEt is an estonian language long summarization dataset with pages filtered from CulturaX dataset. The dataset consists of the page text, and machine generated short summary, long summary and bulletpoints.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSupported Tasks and Leaderboards\\n\\t\\n\\nMore Information Needed\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages\\n\\t\\n\\nEstonian\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Structure\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData Instances\\n\\t\\n\\nMore Information Needed\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tData‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/TalTechNLP/LongSumEt."},
	{"name":"harem","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/arubenruben/harem","creator_name":"R√∫ben Almeida","creator_url":"https://huggingface.co/arubenruben","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for HAREM\\n\\t\\n\\n\\n\\n\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Details\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\n\\n\\n\\n\\n\\nCurated by: [More Information Needed]\\nFunded by [optional]: [More Information Needed]\\nShared by [optional]: [More Information Needed]\\nLanguage(s) (NLP): pt\\nLicense: cc-by-4.0\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Sources [optional]\\n\\t\\n\\n\\n\\n\\nRepository: [More Information Needed]\\nPaper [optional]: [More Information Needed]\\nDemo [optional]: [More Information Needed]\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tUses‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/arubenruben/harem."},
	{"name":"SAW-corpus","keyword":"monolingual","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/MMinasyan/SAW-corpus","creator_name":"Mkrtich Minasyan","creator_url":"https://huggingface.co/MMinasyan","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for SAW Corpus\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThe Selective Armenian Web (SAW) Corpus is a collection of Armenian language texts, selectively compiled from various online sources. It aims to support natural language processing tasks, offering a wide range of text types, including news articles, legal documents, and other web content.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSupported Tasks and Leaderboards\\n\\t\\n\\n\\nlanguage-modeling\\nmasked-language-modeling‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/MMinasyan/SAW-corpus."},
	{"name":"poquad-imp","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/arduwa/poquad-imp","creator_name":"Jakub","creator_url":"https://huggingface.co/arduwa","description":"PoQuaD dataset\\n"},
	{"name":"rejection_sampling_phi_2_OA_rm","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/alizeepace/rejection_sampling_phi_2_OA_rm","creator_name":"Aliz√©e Pace","creator_url":"https://huggingface.co/alizeepace","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Rejection Sampling Phi-2 with OpenAssistant RM\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThe \\\"Rejection Sampling Phi-2 with OpenAssistant RM\\\" dataset consists of 10 pairs of prompts and responses, which were generated using rejection sampling over 10 Phi-2 generation using the OpenAssistant Reward Model.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSupported Tasks and Leaderboards\\n\\t\\n\\nThe dataset and its creation rationale could be used to support models for question-answering, text-generation, or‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/alizeepace/rejection_sampling_phi_2_OA_rm."},
	{"name":"Contextual_Response_Evaluation_for_ESL_and_ASD_Support","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/yunjaeys/Contextual_Response_Evaluation_for_ESL_and_ASD_Support","creator_name":"Eric Soderquist","creator_url":"https://huggingface.co/yunjaeys","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for \\\"Contextual Response Evaluation for ESL and ASD Supportüíúüí¨üåê\\\"\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description üìñ\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary üìù\\n\\t\\n\\nCurated by Eric Soderquist, this dataset is a collection of English prompts and responses generated by the Phi-2 model, designed to evaluate and improve NLP models for supporting ESL (English as a Second Language) and ASD (Autism Spectrum Disorder) user bases. Each prompt is paired with multiple AI-generated responses and‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/yunjaeys/Contextual_Response_Evaluation_for_ESL_and_ASD_Support."},
	{"name":"ai2_arc-hi","keyword":"monolingual","license":"Creative Commons Attribution Share Alike 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-sa-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ai4bharat/ai2_arc-hi","creator_name":"AI4Bharat","creator_url":"https://huggingface.co/ai4bharat","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for \\\"ai2_arc\\\" translated into Hindi\\n\\t\\n\\nThis is Hindi translated version of \\\"ai2_arc\\\" using the IndicTrans2 model (Gala et al., 2023).\\nWe recommend you to visit the \\\"ai2_arc\\\" huggingface dataset card (link) for the details.\\n"},
	{"name":"code_civil","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Hunterlige/code_civil","creator_name":"Denis","creator_url":"https://huggingface.co/Hunterlige","description":"Hunterlige/code_civil dataset hosted on Hugging Face and contributed by the HF Datasets community"},
	{"name":"wb-questions","keyword":"monolingual","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/nyuuzyou/wb-questions","creator_name":"nyuuzyou","creator_url":"https://huggingface.co/nyuuzyou","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Wildberries questions\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThis is a dataset of questions and answers scraped from product pages from the Russian marketplace Wildberries. Dataset contains all questions and answers, as well as all metadata from the API. However, the \\\"productName\\\" field may be empty in some cases because the API does not return the name for old products.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages\\n\\t\\n\\nThe dataset is mostly in Russian, but there may be other languages present.‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/nyuuzyou/wb-questions."},
	{"name":"itaku","keyword":"monolingual","license":"Creative Commons Zero v1.0 Universal","license_url":"https://choosealicense.com/licenses/cc0-1.0/","language":"en","dataset_url":"https://huggingface.co/datasets/nyuuzyou/itaku","creator_name":"nyuuzyou","creator_url":"https://huggingface.co/nyuuzyou","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for Itaku.ee\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThis dataset contains metadata for 924,723 artwork posts from Itaku.ee, an art-sharing and commissioning platform. The total uncompressed size of the original media files (not included in dataset) is 1,900,129.40 MB. The dataset includes only metadata such as titles, descriptions, tags, and other post information.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLanguages\\n\\t\\n\\nThe dataset is primarily in English (en), with titles, descriptions and tags in‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/nyuuzyou/itaku."},
	{"name":"Olympiads","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Metaskepsis/Olympiads","creator_name":"Metaskepsis","creator_url":"https://huggingface.co/Metaskepsis","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tNumina-Olympiads\\n\\t\\n\\nFiltered NuminaMath-CoT dataset containing only olympiads problems with valid answers.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Information\\n\\t\\n\\n\\nSplit: train\\nOriginal size: 32926\\nFiltered size: 32926\\nSource: olympiads\\nAll examples contain valid boxed answers\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThis dataset is a filtered version of the NuminaMath-CoT dataset, containing only problems from olympiad sources that have valid boxed answers. Each example includes:\\n\\nA mathematical word‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Metaskepsis/Olympiads."},
	{"name":"Numina","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/Metaskepsis/Numina","creator_name":"Metaskepsis","creator_url":"https://huggingface.co/Metaskepsis","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tNumina-Olympiads\\n\\t\\n\\nFiltered NuminaMath-CoT dataset containing only olympiads problems with valid answers.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Information\\n\\t\\n\\n\\nSplit: train\\nOriginal size: 210350\\nFiltered size: 210350\\nSource: olympiads\\nAll examples contain valid boxed answers\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThis dataset is a filtered version of the NuminaMath-CoT dataset, containing only problems from olympiad sources that have valid boxed answers. Each example includes:\\n\\nA mathematical word‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Metaskepsis/Numina."},
	{"name":"tiny-stack","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/fhswf/tiny-stack","creator_name":"Fachhochschule S√ºdwestfalen","creator_url":"https://huggingface.co/fhswf","description":"\\n\\t\\n\\t\\t\\n\\t\\tAbout\\n\\t\\n\\nDataset for tinystack.\\n"},
	{"name":"vibeeval_greek","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/ilsp/vibeeval_greek","creator_name":"Institute for Language and Speech Processing","creator_url":"https://huggingface.co/ilsp","description":"\\n\\t\\n\\t\\t\\n\\t\\tDataset Card for Vibe-Eval Greek\\n\\t\\n\\nThe Vibe-Eval Greek dataset is a benchmark of 269 examples for evaluating multimodal chat models, including especially challenging examples. It has been manually translated into Greek from the VibeEval dataset.\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Details\\n\\t\\n\\nEach example has the following fields:\\n\\nmedia_url: a URL where the file is hosted publicly\\nexample_id: a unique ID for the example\\ncategory: the category that this example belongs to, either difficulty-normal or‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/ilsp/vibeeval_greek."},
	{"name":"combined-fr-caselaw","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/Tonic/combined-fr-caselaw","creator_name":"Joseph [open/acc] Pollack","creator_url":"https://huggingface.co/Tonic","description":"\\n\\t\\n\\t\\t\\n\\t\\tDataset Card for French Legal Cases Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThis dataset combines French legal cases from multiple sources (INCA, JADE, CASS, CAPP) into a unified format with overlapping text triplets. It includes decisions from various French courts, processed to facilitate natural language processing tasks.\\n\\n\\t\\n\\t\\t\\n\\t\\tSupported Tasks and Leaderboards\\n\\t\\n\\n\\nTasks:\\nText Generation\\nLegal Document Analysis\\nText Classification\\nLanguage Modeling\\n\\n\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tLanguages\\n\\t\\n\\nThe dataset‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/Tonic/combined-fr-caselaw."},
	{"name":"Bharat_NanoClimateFEVER_bn","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoClimateFEVER_bn","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\\n\\t\\n\\t\\t\\n\\t\\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tOverview\\n\\t\\n\\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThis particular dataset is the Bengali version of the NanoClimateFEVER dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoClimateFEVER_bn."},
	{"name":"Bharat_NanoClimateFEVER_hi","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoClimateFEVER_hi","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\\n\\t\\n\\t\\t\\n\\t\\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tOverview\\n\\t\\n\\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThis particular dataset is the Hindi version of the NanoClimateFEVER dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoClimateFEVER_hi."},
	{"name":"Bharat_NanoClimateFEVER_kn","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoClimateFEVER_kn","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\\n\\t\\n\\t\\t\\n\\t\\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tOverview\\n\\t\\n\\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThis particular dataset is the Kannada version of the NanoClimateFEVER dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoClimateFEVER_kn."},
	{"name":"Bharat_NanoClimateFEVER_ksd","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoClimateFEVER_ksd","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\\n\\t\\n\\t\\t\\n\\t\\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tOverview\\n\\t\\n\\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThis particular dataset is the Kashmiri (Devanagari script) version of the NanoClimateFEVER dataset‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoClimateFEVER_ksd."},
	{"name":"Bharat_NanoClimateFEVER_ml","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoClimateFEVER_ml","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\\n\\t\\n\\t\\t\\n\\t\\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tOverview\\n\\t\\n\\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThis particular dataset is the Malayalam version of the NanoClimateFEVER dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoClimateFEVER_ml."},
	{"name":"Bharat_NanoClimateFEVER_mni","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoClimateFEVER_mni","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\\n\\t\\n\\t\\t\\n\\t\\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tOverview\\n\\t\\n\\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThis particular dataset is the Manipuri version of the NanoClimateFEVER dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoClimateFEVER_mni."},
	{"name":"Bharat_NanoClimateFEVER_or","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoClimateFEVER_or","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\\n\\t\\n\\t\\t\\n\\t\\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tOverview\\n\\t\\n\\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThis particular dataset is the Odia (Oriya) version of the NanoClimateFEVER dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoClimateFEVER_or."},
	{"name":"Bharat_NanoClimateFEVER_pa","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoClimateFEVER_pa","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\\n\\t\\n\\t\\t\\n\\t\\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tOverview\\n\\t\\n\\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThis particular dataset is the Punjabi version of the NanoClimateFEVER dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoClimateFEVER_pa."},
	{"name":"Bharat_NanoClimateFEVER_ta","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoClimateFEVER_ta","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\\n\\t\\n\\t\\t\\n\\t\\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tOverview\\n\\t\\n\\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThis particular dataset is the Tamil version of the NanoClimateFEVER dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoClimateFEVER_ta."},
	{"name":"Bharat_NanoClimateFEVER_te","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoClimateFEVER_te","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\\n\\t\\n\\t\\t\\n\\t\\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tOverview\\n\\t\\n\\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThis particular dataset is the Telugu version of the NanoClimateFEVER dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoClimateFEVER_te."},
	{"name":"Bharat_NanoClimateFEVER_ur","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoClimateFEVER_ur","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\\n\\t\\n\\t\\t\\n\\t\\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tOverview\\n\\t\\n\\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThis particular dataset is the Urdu version of the NanoClimateFEVER dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoClimateFEVER_ur."},
	{"name":"Bharat_NanoDBPedia_as","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoDBPedia_as","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\\n\\t\\n\\t\\t\\n\\t\\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tOverview\\n\\t\\n\\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThis particular dataset is the Assamese version of the NanoDBPedia dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoDBPedia_as."},
	{"name":"Bharat_NanoDBPedia_awa","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoDBPedia_awa","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\\n\\t\\n\\t\\t\\n\\t\\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tOverview\\n\\t\\n\\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThis particular dataset is the Awadhi version of the NanoDBPedia dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoDBPedia_awa."},
	{"name":"Bharat_NanoDBPedia_bho","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoDBPedia_bho","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\\n\\t\\n\\t\\t\\n\\t\\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tOverview\\n\\t\\n\\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThis particular dataset is the Bhojpuri version of the NanoDBPedia dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoDBPedia_bho."},
	{"name":"Bharat_NanoDBPedia_gu","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoDBPedia_gu","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\\n\\t\\n\\t\\t\\n\\t\\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tOverview\\n\\t\\n\\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThis particular dataset is the Gujarati version of the NanoDBPedia dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoDBPedia_gu."},
	{"name":"Bharat_NanoDBPedia_kn","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoDBPedia_kn","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\\n\\t\\n\\t\\t\\n\\t\\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tOverview\\n\\t\\n\\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThis particular dataset is the Kannada version of the NanoDBPedia dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoDBPedia_kn."},
	{"name":"Bharat_NanoDBPedia_ksa","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoDBPedia_ksa","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\\n\\t\\n\\t\\t\\n\\t\\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tOverview\\n\\t\\n\\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThis particular dataset is the Kashmiri (Arabic script) version of the NanoDBPedia dataset, specifically‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoDBPedia_ksa."},
	{"name":"Bharat_NanoDBPedia_mai","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoDBPedia_mai","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\\n\\t\\n\\t\\t\\n\\t\\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tOverview\\n\\t\\n\\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThis particular dataset is the Maithili version of the NanoDBPedia dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoDBPedia_mai."},
	{"name":"Bharat_NanoDBPedia_mr","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoDBPedia_mr","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\\n\\t\\n\\t\\t\\n\\t\\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tOverview\\n\\t\\n\\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThis particular dataset is the Marathi version of the NanoDBPedia dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoDBPedia_mr."},
	{"name":"Bharat_NanoDBPedia_pa","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoDBPedia_pa","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\\n\\t\\n\\t\\t\\n\\t\\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tOverview\\n\\t\\n\\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThis particular dataset is the Punjabi version of the NanoDBPedia dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoDBPedia_pa."},
	{"name":"Bharat_NanoDBPedia_sa","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoDBPedia_sa","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\\n\\t\\n\\t\\t\\n\\t\\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tOverview\\n\\t\\n\\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThis particular dataset is the Sanskrit version of the NanoDBPedia dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoDBPedia_sa."},
	{"name":"Bharat_NanoDBPedia_te","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoDBPedia_te","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\\n\\t\\n\\t\\t\\n\\t\\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tOverview\\n\\t\\n\\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThis particular dataset is the Telugu version of the NanoDBPedia dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoDBPedia_te."},
	{"name":"Bharat_NanoDBPedia_ur","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoDBPedia_ur","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\\n\\t\\n\\t\\t\\n\\t\\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tOverview\\n\\t\\n\\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThis particular dataset is the Urdu version of the NanoDBPedia dataset, specifically adapted for information‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoDBPedia_ur."},
	{"name":"Bharat_NanoFEVER_as","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoFEVER_as","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\\n\\t\\n\\t\\t\\n\\t\\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tOverview\\n\\t\\n\\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThis particular dataset is the Assamese version of the NanoFEVER dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoFEVER_as."},
	{"name":"Bharat_NanoFEVER_awa","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoFEVER_awa","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\\n\\t\\n\\t\\t\\n\\t\\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tOverview\\n\\t\\n\\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThis particular dataset is the Awadhi version of the NanoFEVER dataset, specifically adapted for information‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoFEVER_awa."},
	{"name":"Bharat_NanoFEVER_gu","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoFEVER_gu","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\\n\\t\\n\\t\\t\\n\\t\\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tOverview\\n\\t\\n\\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThis particular dataset is the Gujarati version of the NanoFEVER dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoFEVER_gu."},
	{"name":"Bharat_NanoFEVER_hi","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoFEVER_hi","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\\n\\t\\n\\t\\t\\n\\t\\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tOverview\\n\\t\\n\\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThis particular dataset is the Hindi version of the NanoFEVER dataset, specifically adapted for information‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoFEVER_hi."},
	{"name":"Bharat_NanoFEVER_hne","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoFEVER_hne","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\\n\\t\\n\\t\\t\\n\\t\\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tOverview\\n\\t\\n\\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThis particular dataset is the Chhattisgarhi version of the NanoFEVER dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoFEVER_hne."},
	{"name":"Bharat_NanoFEVER_ksa","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoFEVER_ksa","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\\n\\t\\n\\t\\t\\n\\t\\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tOverview\\n\\t\\n\\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThis particular dataset is the Kashmiri (Arabic script) version of the NanoFEVER dataset, specifically‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoFEVER_ksa."},
	{"name":"Bharat_NanoFEVER_ksd","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoFEVER_ksd","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\\n\\t\\n\\t\\t\\n\\t\\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tOverview\\n\\t\\n\\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThis particular dataset is the Kashmiri (Devanagari script) version of the NanoFEVER dataset, specifically‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoFEVER_ksd."},
	{"name":"Bharat_NanoFEVER_mag","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoFEVER_mag","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\\n\\t\\n\\t\\t\\n\\t\\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tOverview\\n\\t\\n\\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThis particular dataset is the Magahi version of the NanoFEVER dataset, specifically adapted for information‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoFEVER_mag."},
	{"name":"Bharat_NanoFEVER_ml","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoFEVER_ml","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\\n\\t\\n\\t\\t\\n\\t\\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tOverview\\n\\t\\n\\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThis particular dataset is the Malayalam version of the NanoFEVER dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoFEVER_ml."},
	{"name":"Bharat_NanoFEVER_sa","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoFEVER_sa","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\\n\\t\\n\\t\\t\\n\\t\\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tOverview\\n\\t\\n\\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThis particular dataset is the Sanskrit version of the NanoFEVER dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoFEVER_sa."},
	{"name":"Bharat_NanoFEVER_ta","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoFEVER_ta","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\\n\\t\\n\\t\\t\\n\\t\\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tOverview\\n\\t\\n\\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThis particular dataset is the Tamil version of the NanoFEVER dataset, specifically adapted for information‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoFEVER_ta."},
	{"name":"Bharat_NanoFEVER_te","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoFEVER_te","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\\n\\t\\n\\t\\t\\n\\t\\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tOverview\\n\\t\\n\\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThis particular dataset is the Telugu version of the NanoFEVER dataset, specifically adapted for information‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoFEVER_te."},
	{"name":"Bharat_NanoFiQA2018_as","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoFiQA2018_as","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\\n\\t\\n\\t\\t\\n\\t\\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tOverview\\n\\t\\n\\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThis particular dataset is the Assamese version of the NanoFiQA2018 dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoFiQA2018_as."},
	{"name":"Bharat_NanoFiQA2018_bn","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoFiQA2018_bn","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\\n\\t\\n\\t\\t\\n\\t\\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tOverview\\n\\t\\n\\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThis particular dataset is the Bengali version of the NanoFiQA2018 dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoFiQA2018_bn."},
	{"name":"Bharat_NanoFiQA2018_bho","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoFiQA2018_bho","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\\n\\t\\n\\t\\t\\n\\t\\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tOverview\\n\\t\\n\\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThis particular dataset is the Bhojpuri version of the NanoFiQA2018 dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoFiQA2018_bho."},
	{"name":"Bharat_NanoFiQA2018_gu","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoFiQA2018_gu","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\\n\\t\\n\\t\\t\\n\\t\\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tOverview\\n\\t\\n\\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThis particular dataset is the Gujarati version of the NanoFiQA2018 dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoFiQA2018_gu."},
	{"name":"Bharat_NanoFiQA2018_hi","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoFiQA2018_hi","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\\n\\t\\n\\t\\t\\n\\t\\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tOverview\\n\\t\\n\\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThis particular dataset is the Hindi version of the NanoFiQA2018 dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoFiQA2018_hi."},
	{"name":"Bharat_NanoFiQA2018_hne","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoFiQA2018_hne","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\\n\\t\\n\\t\\t\\n\\t\\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tOverview\\n\\t\\n\\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThis particular dataset is the Chhattisgarhi version of the NanoFiQA2018 dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoFiQA2018_hne."},
	{"name":"Bharat_NanoFiQA2018_kn","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoFiQA2018_kn","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\\n\\t\\n\\t\\t\\n\\t\\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tOverview\\n\\t\\n\\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThis particular dataset is the Kannada version of the NanoFiQA2018 dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoFiQA2018_kn."},
	{"name":"Bharat_NanoFiQA2018_mai","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoFiQA2018_mai","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\\n\\t\\n\\t\\t\\n\\t\\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tOverview\\n\\t\\n\\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThis particular dataset is the Maithili version of the NanoFiQA2018 dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoFiQA2018_mai."},
	{"name":"Bharat_NanoFiQA2018_mr","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoFiQA2018_mr","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\\n\\t\\n\\t\\t\\n\\t\\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tOverview\\n\\t\\n\\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThis particular dataset is the Marathi version of the NanoFiQA2018 dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoFiQA2018_mr."},
	{"name":"Bharat_NanoFiQA2018_mni","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoFiQA2018_mni","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\\n\\t\\n\\t\\t\\n\\t\\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tOverview\\n\\t\\n\\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThis particular dataset is the Manipuri version of the NanoFiQA2018 dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoFiQA2018_mni."},
	{"name":"Bharat_NanoFiQA2018_or","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoFiQA2018_or","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\\n\\t\\n\\t\\t\\n\\t\\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tOverview\\n\\t\\n\\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThis particular dataset is the Odia (Oriya) version of the NanoFiQA2018 dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoFiQA2018_or."},
	{"name":"Bharat_NanoFiQA2018_pa","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoFiQA2018_pa","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\\n\\t\\n\\t\\t\\n\\t\\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tOverview\\n\\t\\n\\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThis particular dataset is the Punjabi version of the NanoFiQA2018 dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoFiQA2018_pa."},
	{"name":"Bharat_NanoFiQA2018_ta","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoFiQA2018_ta","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\\n\\t\\n\\t\\t\\n\\t\\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tOverview\\n\\t\\n\\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThis particular dataset is the Tamil version of the NanoFiQA2018 dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoFiQA2018_ta."},
	{"name":"Bharat_NanoFiQA2018_ur","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoFiQA2018_ur","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\\n\\t\\n\\t\\t\\n\\t\\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tOverview\\n\\t\\n\\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThis particular dataset is the Urdu version of the NanoFiQA2018 dataset, specifically adapted for information‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoFiQA2018_ur."},
	{"name":"Bharat_NanoHotpotQA_as","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoHotpotQA_as","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\\n\\t\\n\\t\\t\\n\\t\\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tOverview\\n\\t\\n\\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThis particular dataset is the Assamese version of the NanoHotpotQA dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoHotpotQA_as."},
	{"name":"Bharat_NanoHotpotQA_awa","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoHotpotQA_awa","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\\n\\t\\n\\t\\t\\n\\t\\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tOverview\\n\\t\\n\\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThis particular dataset is the Awadhi version of the NanoHotpotQA dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoHotpotQA_awa."},
	{"name":"Bharat_NanoHotpotQA_bho","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoHotpotQA_bho","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\\n\\t\\n\\t\\t\\n\\t\\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tOverview\\n\\t\\n\\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThis particular dataset is the Bhojpuri version of the NanoHotpotQA dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoHotpotQA_bho."},
	{"name":"Bharat_NanoHotpotQA_gu","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoHotpotQA_gu","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\\n\\t\\n\\t\\t\\n\\t\\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tOverview\\n\\t\\n\\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThis particular dataset is the Gujarati version of the NanoHotpotQA dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoHotpotQA_gu."},
	{"name":"Bharat_NanoHotpotQA_kn","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoHotpotQA_kn","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\\n\\t\\n\\t\\t\\n\\t\\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tOverview\\n\\t\\n\\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThis particular dataset is the Kannada version of the NanoHotpotQA dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoHotpotQA_kn."},
	{"name":"Bharat_NanoHotpotQA_ksa","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoHotpotQA_ksa","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\\n\\t\\n\\t\\t\\n\\t\\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tOverview\\n\\t\\n\\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThis particular dataset is the Kashmiri (Arabic script) version of the NanoHotpotQA dataset, specifically‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoHotpotQA_ksa."},
	{"name":"Bharat_NanoHotpotQA_mai","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoHotpotQA_mai","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\\n\\t\\n\\t\\t\\n\\t\\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tOverview\\n\\t\\n\\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThis particular dataset is the Maithili version of the NanoHotpotQA dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoHotpotQA_mai."},
	{"name":"Bharat_NanoHotpotQA_mni","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoHotpotQA_mni","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\\n\\t\\n\\t\\t\\n\\t\\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tOverview\\n\\t\\n\\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThis particular dataset is the Manipuri version of the NanoHotpotQA dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoHotpotQA_mni."},
	{"name":"Bharat_NanoHotpotQA_ne","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoHotpotQA_ne","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\\n\\t\\n\\t\\t\\n\\t\\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tOverview\\n\\t\\n\\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThis particular dataset is the Nepali version of the NanoHotpotQA dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoHotpotQA_ne."},
	{"name":"Bharat_NanoHotpotQA_or","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoHotpotQA_or","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\\n\\t\\n\\t\\t\\n\\t\\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tOverview\\n\\t\\n\\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThis particular dataset is the Odia (Oriya) version of the NanoHotpotQA dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoHotpotQA_or."},
	{"name":"Bharat_NanoHotpotQA_sa","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoHotpotQA_sa","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\\n\\t\\n\\t\\t\\n\\t\\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tOverview\\n\\t\\n\\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThis particular dataset is the Sanskrit version of the NanoHotpotQA dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoHotpotQA_sa."},
	{"name":"Bharat_NanoHotpotQA_ta","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoHotpotQA_ta","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\\n\\t\\n\\t\\t\\n\\t\\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tOverview\\n\\t\\n\\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThis particular dataset is the Tamil version of the NanoHotpotQA dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoHotpotQA_ta."},
	{"name":"Bharat_NanoHotpotQA_ur","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoHotpotQA_ur","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\\n\\t\\n\\t\\t\\n\\t\\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tOverview\\n\\t\\n\\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThis particular dataset is the Urdu version of the NanoHotpotQA dataset, specifically adapted for information‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoHotpotQA_ur."},
	{"name":"nemo-github-issues","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/renwei2024/nemo-github-issues","creator_name":"Wei Ren","creator_url":"https://huggingface.co/renwei2024","description":"\\n\\t\\n\\t\\t\\n\\t\\tDataset Card for Dataset Name\\n\\t\\n\\nThis dataset contains 10,000 issues and pull requests along with their associated comments of Nvidia Nemo Github repo.\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Details\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\n\\n\\n\\n\\n\\nCurated by: [More Information Needed]\\nFunded by [optional]: [More Information Needed]\\nShared by [optional]: [More Information Needed]\\nLanguage(s) (NLP): [More Information Needed]\\nLicense: [More Information Needed]\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Sources [optional]\\n\\t\\n\\n\\n\\n\\nRepository: [More‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/renwei2024/nemo-github-issues."},
	{"name":"Bharat_NanoMSMARCO_as","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoMSMARCO_as","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\\n\\t\\n\\t\\t\\n\\t\\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tOverview\\n\\t\\n\\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThis particular dataset is the Assamese version of the NanoMSMARCO dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoMSMARCO_as."},
	{"name":"Bharat_NanoMSMARCO_awa","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoMSMARCO_awa","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\\n\\t\\n\\t\\t\\n\\t\\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tOverview\\n\\t\\n\\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThis particular dataset is the Awadhi version of the NanoMSMARCO dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoMSMARCO_awa."},
	{"name":"Bharat_NanoMSMARCO_bn","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoMSMARCO_bn","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\\n\\t\\n\\t\\t\\n\\t\\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tOverview\\n\\t\\n\\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThis particular dataset is the Bengali version of the NanoMSMARCO dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoMSMARCO_bn."},
	{"name":"Bharat_NanoMSMARCO_mag","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoMSMARCO_mag","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\\n\\t\\n\\t\\t\\n\\t\\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tOverview\\n\\t\\n\\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThis particular dataset is the Magahi version of the NanoMSMARCO dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoMSMARCO_mag."},
	{"name":"Bharat_NanoMSMARCO_mai","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoMSMARCO_mai","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\\n\\t\\n\\t\\t\\n\\t\\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tOverview\\n\\t\\n\\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThis particular dataset is the Maithili version of the NanoMSMARCO dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoMSMARCO_mai."},
	{"name":"Bharat_NanoMSMARCO_mr","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoMSMARCO_mr","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\\n\\t\\n\\t\\t\\n\\t\\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tOverview\\n\\t\\n\\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThis particular dataset is the Marathi version of the NanoMSMARCO dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoMSMARCO_mr."},
	{"name":"Bharat_NanoMSMARCO_or","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoMSMARCO_or","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\\n\\t\\n\\t\\t\\n\\t\\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tOverview\\n\\t\\n\\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThis particular dataset is the Odia (Oriya) version of the NanoMSMARCO dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoMSMARCO_or."},
	{"name":"Bharat_NanoMSMARCO_ta","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoMSMARCO_ta","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\\n\\t\\n\\t\\t\\n\\t\\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tOverview\\n\\t\\n\\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThis particular dataset is the Tamil version of the NanoMSMARCO dataset, specifically adapted for information‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoMSMARCO_ta."},
	{"name":"Bharat_NanoMSMARCO_te","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoMSMARCO_te","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\\n\\t\\n\\t\\t\\n\\t\\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tOverview\\n\\t\\n\\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThis particular dataset is the Telugu version of the NanoMSMARCO dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoMSMARCO_te."},
	{"name":"Bharat_NanoNFCorpus_as","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoNFCorpus_as","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\\n\\t\\n\\t\\t\\n\\t\\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tOverview\\n\\t\\n\\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThis particular dataset is the Assamese version of the NanoNFCorpus dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoNFCorpus_as."},
	{"name":"Bharat_NanoNFCorpus_bn","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoNFCorpus_bn","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\\n\\t\\n\\t\\t\\n\\t\\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tOverview\\n\\t\\n\\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThis particular dataset is the Bengali version of the NanoNFCorpus dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoNFCorpus_bn."},
	{"name":"Bharat_NanoNFCorpus_bho","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoNFCorpus_bho","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\\n\\t\\n\\t\\t\\n\\t\\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tOverview\\n\\t\\n\\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThis particular dataset is the Bhojpuri version of the NanoNFCorpus dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoNFCorpus_bho."},
	{"name":"Bharat_NanoNFCorpus_gu","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoNFCorpus_gu","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\\n\\t\\n\\t\\t\\n\\t\\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tOverview\\n\\t\\n\\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThis particular dataset is the Gujarati version of the NanoNFCorpus dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoNFCorpus_gu."},
	{"name":"Bharat_NanoNFCorpus_hi","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoNFCorpus_hi","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\\n\\t\\n\\t\\t\\n\\t\\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tOverview\\n\\t\\n\\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThis particular dataset is the Hindi version of the NanoNFCorpus dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoNFCorpus_hi."},
	{"name":"Bharat_NanoNFCorpus_hne","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoNFCorpus_hne","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\\n\\t\\n\\t\\t\\n\\t\\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tOverview\\n\\t\\n\\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThis particular dataset is the Chhattisgarhi version of the NanoNFCorpus dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoNFCorpus_hne."},
	{"name":"Bharat_NanoNFCorpus_ne","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoNFCorpus_ne","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\\n\\t\\n\\t\\t\\n\\t\\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tOverview\\n\\t\\n\\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThis particular dataset is the Nepali version of the NanoNFCorpus dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoNFCorpus_ne."},
	{"name":"Bharat_NanoNFCorpus_or","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoNFCorpus_or","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\\n\\t\\n\\t\\t\\n\\t\\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tOverview\\n\\t\\n\\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThis particular dataset is the Odia (Oriya) version of the NanoNFCorpus dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoNFCorpus_or."},
	{"name":"Bharat_NanoNFCorpus_sa","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoNFCorpus_sa","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\\n\\t\\n\\t\\t\\n\\t\\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tOverview\\n\\t\\n\\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThis particular dataset is the Sanskrit version of the NanoNFCorpus dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoNFCorpus_sa."},
	{"name":"Bharat_NanoNFCorpus_ta","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoNFCorpus_ta","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\\n\\t\\n\\t\\t\\n\\t\\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tOverview\\n\\t\\n\\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThis particular dataset is the Tamil version of the NanoNFCorpus dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoNFCorpus_ta."},
	{"name":"Bharat_NanoNFCorpus_ur","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoNFCorpus_ur","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\\n\\t\\n\\t\\t\\n\\t\\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tOverview\\n\\t\\n\\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThis particular dataset is the Urdu version of the NanoNFCorpus dataset, specifically adapted for information‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoNFCorpus_ur."},
	{"name":"Bharat_NanoNQ_awa","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoNQ_awa","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\\n\\t\\n\\t\\t\\n\\t\\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tOverview\\n\\t\\n\\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThis particular dataset is the Awadhi version of the NanoNQ dataset, specifically adapted for information‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoNQ_awa."},
	{"name":"Bharat_NanoNQ_bn","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoNQ_bn","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\\n\\t\\n\\t\\t\\n\\t\\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tOverview\\n\\t\\n\\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThis particular dataset is the Bengali version of the NanoNQ dataset, specifically adapted for information‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoNQ_bn."},
	{"name":"Bharat_NanoNQ_bho","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoNQ_bho","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\\n\\t\\n\\t\\t\\n\\t\\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tOverview\\n\\t\\n\\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThis particular dataset is the Bhojpuri version of the NanoNQ dataset, specifically adapted for information‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoNQ_bho."},
	{"name":"Bharat_NanoNQ_gu","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoNQ_gu","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\\n\\t\\n\\t\\t\\n\\t\\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tOverview\\n\\t\\n\\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThis particular dataset is the Gujarati version of the NanoNQ dataset, specifically adapted for information‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoNQ_gu."},
	{"name":"Bharat_NanoNQ_ksd","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoNQ_ksd","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\\n\\t\\n\\t\\t\\n\\t\\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tOverview\\n\\t\\n\\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThis particular dataset is the Kashmiri (Devanagari script) version of the NanoNQ dataset, specifically‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoNQ_ksd."},
	{"name":"Bharat_NanoNQ_ml","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoNQ_ml","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\\n\\t\\n\\t\\t\\n\\t\\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tOverview\\n\\t\\n\\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThis particular dataset is the Malayalam version of the NanoNQ dataset, specifically adapted for information‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoNQ_ml."},
	{"name":"Bharat_NanoNQ_mni","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoNQ_mni","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\\n\\t\\n\\t\\t\\n\\t\\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tOverview\\n\\t\\n\\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThis particular dataset is the Manipuri version of the NanoNQ dataset, specifically adapted for information‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoNQ_mni."},
	{"name":"Bharat_NanoNQ_pa","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoNQ_pa","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\\n\\t\\n\\t\\t\\n\\t\\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tOverview\\n\\t\\n\\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThis particular dataset is the Punjabi version of the NanoNQ dataset, specifically adapted for information‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoNQ_pa."},
	{"name":"Bharat_NanoNQ_ta","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoNQ_ta","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\\n\\t\\n\\t\\t\\n\\t\\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tOverview\\n\\t\\n\\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThis particular dataset is the Tamil version of the NanoNQ dataset, specifically adapted for information‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoNQ_ta."},
	{"name":"Bharat_NanoNQ_te","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoNQ_te","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\\n\\t\\n\\t\\t\\n\\t\\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tOverview\\n\\t\\n\\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThis particular dataset is the Telugu version of the NanoNQ dataset, specifically adapted for information‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoNQ_te."},
	{"name":"Bharat_NanoQuoraRetrieval_as","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoQuoraRetrieval_as","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\\n\\t\\n\\t\\t\\n\\t\\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tOverview\\n\\t\\n\\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThis particular dataset is the Assamese version of the NanoQuoraRetrieval dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoQuoraRetrieval_as."},
	{"name":"Bharat_NanoQuoraRetrieval_awa","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoQuoraRetrieval_awa","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\\n\\t\\n\\t\\t\\n\\t\\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tOverview\\n\\t\\n\\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThis particular dataset is the Awadhi version of the NanoQuoraRetrieval dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoQuoraRetrieval_awa."},
	{"name":"Bharat_NanoQuoraRetrieval_bn","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoQuoraRetrieval_bn","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\\n\\t\\n\\t\\t\\n\\t\\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tOverview\\n\\t\\n\\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThis particular dataset is the Bengali version of the NanoQuoraRetrieval dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoQuoraRetrieval_bn."},
	{"name":"Bharat_NanoQuoraRetrieval_bho","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoQuoraRetrieval_bho","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\\n\\t\\n\\t\\t\\n\\t\\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tOverview\\n\\t\\n\\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThis particular dataset is the Bhojpuri version of the NanoQuoraRetrieval dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoQuoraRetrieval_bho."},
	{"name":"Bharat_NanoQuoraRetrieval_gu","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoQuoraRetrieval_gu","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\\n\\t\\n\\t\\t\\n\\t\\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tOverview\\n\\t\\n\\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThis particular dataset is the Gujarati version of the NanoQuoraRetrieval dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoQuoraRetrieval_gu."},
	{"name":"Bharat_NanoQuoraRetrieval_hi","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoQuoraRetrieval_hi","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\\n\\t\\n\\t\\t\\n\\t\\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tOverview\\n\\t\\n\\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThis particular dataset is the Hindi version of the NanoQuoraRetrieval dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoQuoraRetrieval_hi."},
	{"name":"Bharat_NanoQuoraRetrieval_kn","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoQuoraRetrieval_kn","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\\n\\t\\n\\t\\t\\n\\t\\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tOverview\\n\\t\\n\\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThis particular dataset is the Kannada version of the NanoQuoraRetrieval dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoQuoraRetrieval_kn."},
	{"name":"Bharat_NanoQuoraRetrieval_ksa","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoQuoraRetrieval_ksa","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\\n\\t\\n\\t\\t\\n\\t\\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tOverview\\n\\t\\n\\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThis particular dataset is the Kashmiri (Arabic script) version of the NanoQuoraRetrieval dataset‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoQuoraRetrieval_ksa."},
	{"name":"Bharat_NanoQuoraRetrieval_ml","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoQuoraRetrieval_ml","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\\n\\t\\n\\t\\t\\n\\t\\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tOverview\\n\\t\\n\\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThis particular dataset is the Malayalam version of the NanoQuoraRetrieval dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoQuoraRetrieval_ml."},
	{"name":"Bharat_NanoQuoraRetrieval_mr","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoQuoraRetrieval_mr","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\\n\\t\\n\\t\\t\\n\\t\\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tOverview\\n\\t\\n\\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThis particular dataset is the Marathi version of the NanoQuoraRetrieval dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoQuoraRetrieval_mr."},
	{"name":"Bharat_NanoQuoraRetrieval_mni","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoQuoraRetrieval_mni","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\\n\\t\\n\\t\\t\\n\\t\\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tOverview\\n\\t\\n\\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThis particular dataset is the Manipuri version of the NanoQuoraRetrieval dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoQuoraRetrieval_mni."},
	{"name":"Bharat_NanoQuoraRetrieval_ne","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoQuoraRetrieval_ne","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\\n\\t\\n\\t\\t\\n\\t\\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tOverview\\n\\t\\n\\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThis particular dataset is the Nepali version of the NanoQuoraRetrieval dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoQuoraRetrieval_ne."},
	{"name":"Bharat_NanoQuoraRetrieval_or","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoQuoraRetrieval_or","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\\n\\t\\n\\t\\t\\n\\t\\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tOverview\\n\\t\\n\\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThis particular dataset is the Odia (Oriya) version of the NanoQuoraRetrieval dataset, specifically adapted‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoQuoraRetrieval_or."},
	{"name":"Bharat_NanoQuoraRetrieval_pa","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoQuoraRetrieval_pa","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\\n\\t\\n\\t\\t\\n\\t\\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tOverview\\n\\t\\n\\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThis particular dataset is the Punjabi version of the NanoQuoraRetrieval dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoQuoraRetrieval_pa."},
	{"name":"Bharat_NanoQuoraRetrieval_sa","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoQuoraRetrieval_sa","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\\n\\t\\n\\t\\t\\n\\t\\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tOverview\\n\\t\\n\\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThis particular dataset is the Sanskrit version of the NanoQuoraRetrieval dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoQuoraRetrieval_sa."},
	{"name":"Bharat_NanoQuoraRetrieval_ta","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoQuoraRetrieval_ta","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\\n\\t\\n\\t\\t\\n\\t\\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tOverview\\n\\t\\n\\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThis particular dataset is the Tamil version of the NanoQuoraRetrieval dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoQuoraRetrieval_ta."},
	{"name":"Bharat_NanoQuoraRetrieval_ur","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoQuoraRetrieval_ur","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\\n\\t\\n\\t\\t\\n\\t\\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tOverview\\n\\t\\n\\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThis particular dataset is the Urdu version of the NanoQuoraRetrieval dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoQuoraRetrieval_ur."},
	{"name":"Bharat_NanoSCIDOCS_as","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoSCIDOCS_as","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\\n\\t\\n\\t\\t\\n\\t\\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tOverview\\n\\t\\n\\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThis particular dataset is the Assamese version of the NanoSCIDOCS dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoSCIDOCS_as."},
	{"name":"Bharat_NanoSCIDOCS_awa","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoSCIDOCS_awa","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\\n\\t\\n\\t\\t\\n\\t\\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tOverview\\n\\t\\n\\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThis particular dataset is the Awadhi version of the NanoSCIDOCS dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoSCIDOCS_awa."},
	{"name":"Bharat_NanoSCIDOCS_bn","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoSCIDOCS_bn","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\\n\\t\\n\\t\\t\\n\\t\\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tOverview\\n\\t\\n\\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThis particular dataset is the Bengali version of the NanoSCIDOCS dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoSCIDOCS_bn."},
	{"name":"Bharat_NanoSCIDOCS_gu","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoSCIDOCS_gu","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\\n\\t\\n\\t\\t\\n\\t\\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tOverview\\n\\t\\n\\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThis particular dataset is the Gujarati version of the NanoSCIDOCS dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoSCIDOCS_gu."},
	{"name":"Bharat_NanoSCIDOCS_kn","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoSCIDOCS_kn","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\\n\\t\\n\\t\\t\\n\\t\\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tOverview\\n\\t\\n\\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThis particular dataset is the Kannada version of the NanoSCIDOCS dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoSCIDOCS_kn."},
	{"name":"Bharat_NanoSCIDOCS_mai","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoSCIDOCS_mai","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\\n\\t\\n\\t\\t\\n\\t\\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tOverview\\n\\t\\n\\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThis particular dataset is the Maithili version of the NanoSCIDOCS dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoSCIDOCS_mai."},
	{"name":"Bharat_NanoSCIDOCS_or","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoSCIDOCS_or","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\\n\\t\\n\\t\\t\\n\\t\\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tOverview\\n\\t\\n\\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThis particular dataset is the Odia (Oriya) version of the NanoSCIDOCS dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoSCIDOCS_or."},
	{"name":"Bharat_NanoSCIDOCS_pa","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoSCIDOCS_pa","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\\n\\t\\n\\t\\t\\n\\t\\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tOverview\\n\\t\\n\\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThis particular dataset is the Punjabi version of the NanoSCIDOCS dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoSCIDOCS_pa."},
	{"name":"Bharat_NanoSCIDOCS_sa","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoSCIDOCS_sa","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\\n\\t\\n\\t\\t\\n\\t\\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tOverview\\n\\t\\n\\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThis particular dataset is the Sanskrit version of the NanoSCIDOCS dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoSCIDOCS_sa."},
	{"name":"Bharat_NanoSCIDOCS_ta","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoSCIDOCS_ta","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\\n\\t\\n\\t\\t\\n\\t\\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tOverview\\n\\t\\n\\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThis particular dataset is the Tamil version of the NanoSCIDOCS dataset, specifically adapted for information‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoSCIDOCS_ta."},
	{"name":"Bharat_NanoSciFact_as","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoSciFact_as","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\\n\\t\\n\\t\\t\\n\\t\\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tOverview\\n\\t\\n\\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThis particular dataset is the Assamese version of the NanoSciFact dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoSciFact_as."},
	{"name":"Bharat_NanoSciFact_awa","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoSciFact_awa","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\\n\\t\\n\\t\\t\\n\\t\\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tOverview\\n\\t\\n\\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThis particular dataset is the Awadhi version of the NanoSciFact dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoSciFact_awa."},
	{"name":"Bharat_NanoSciFact_bn","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoSciFact_bn","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\\n\\t\\n\\t\\t\\n\\t\\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tOverview\\n\\t\\n\\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThis particular dataset is the Bengali version of the NanoSciFact dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoSciFact_bn."},
	{"name":"Bharat_NanoSciFact_bho","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoSciFact_bho","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\\n\\t\\n\\t\\t\\n\\t\\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tOverview\\n\\t\\n\\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThis particular dataset is the Bhojpuri version of the NanoSciFact dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoSciFact_bho."},
	{"name":"Bharat_NanoSciFact_gu","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoSciFact_gu","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\\n\\t\\n\\t\\t\\n\\t\\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tOverview\\n\\t\\n\\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThis particular dataset is the Gujarati version of the NanoSciFact dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoSciFact_gu."},
	{"name":"Bharat_NanoSciFact_hi","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoSciFact_hi","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\\n\\t\\n\\t\\t\\n\\t\\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tOverview\\n\\t\\n\\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThis particular dataset is the Hindi version of the NanoSciFact dataset, specifically adapted for information‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoSciFact_hi."},
	{"name":"Bharat_NanoSciFact_hne","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoSciFact_hne","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\\n\\t\\n\\t\\t\\n\\t\\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tOverview\\n\\t\\n\\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThis particular dataset is the Chhattisgarhi version of the NanoSciFact dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoSciFact_hne."},
	{"name":"Bharat_NanoSciFact_kn","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoSciFact_kn","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\\n\\t\\n\\t\\t\\n\\t\\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tOverview\\n\\t\\n\\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThis particular dataset is the Kannada version of the NanoSciFact dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoSciFact_kn."},
	{"name":"Bharat_NanoSciFact_ksd","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoSciFact_ksd","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\\n\\t\\n\\t\\t\\n\\t\\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tOverview\\n\\t\\n\\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThis particular dataset is the Kashmiri (Devanagari script) version of the NanoSciFact dataset, specifically‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoSciFact_ksd."},
	{"name":"Bharat_NanoSciFact_mag","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoSciFact_mag","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\\n\\t\\n\\t\\t\\n\\t\\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tOverview\\n\\t\\n\\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThis particular dataset is the Magahi version of the NanoSciFact dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoSciFact_mag."},
	{"name":"Bharat_NanoSciFact_mai","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoSciFact_mai","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\\n\\t\\n\\t\\t\\n\\t\\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tOverview\\n\\t\\n\\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThis particular dataset is the Maithili version of the NanoSciFact dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoSciFact_mai."},
	{"name":"Bharat_NanoSciFact_mr","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoSciFact_mr","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\\n\\t\\n\\t\\t\\n\\t\\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tOverview\\n\\t\\n\\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThis particular dataset is the Marathi version of the NanoSciFact dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoSciFact_mr."},
	{"name":"Bharat_NanoSciFact_or","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoSciFact_or","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\\n\\t\\n\\t\\t\\n\\t\\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tOverview\\n\\t\\n\\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThis particular dataset is the Odia (Oriya) version of the NanoSciFact dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoSciFact_or."},
	{"name":"Bharat_NanoSciFact_ur","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoSciFact_ur","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\\n\\t\\n\\t\\t\\n\\t\\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tOverview\\n\\t\\n\\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThis particular dataset is the Urdu version of the NanoSciFact dataset, specifically adapted for information‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoSciFact_ur."},
	{"name":"YSSY_1","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/lmejias/YSSY_1","creator_name":"Luis Mejias","creator_url":"https://huggingface.co/lmejias","description":"\\n\\t\\n\\t\\t\\n\\t\\tDataset Card for ATCOSYDNEY corpus\\n\\t\\n\\n"},
	{"name":"synthetic-contextual-anonymizer-dataset","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/kurkowski/synthetic-contextual-anonymizer-dataset","creator_name":"Micha≈Ç Kurkowski","creator_url":"https://huggingface.co/kurkowski","description":"\\n\\t\\n\\t\\t\\n\\t\\tContextual Text Anonymizer Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThis dataset contains synthetically generated pairs of texts (original and anonymized) for various document types. The dataset was created for training text anonymization models while preserving context.\\n\\n\\t\\n\\t\\t\\n\\t\\tDocument Types\\n\\t\\n\\nThe dataset includes examples from the following categories:\\n\\nMedical records\\nBanking documents\\nBusiness correspondence\\nRecruitment documents\\nSocial media content\\nLegal documents\\nEducational‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/kurkowski/synthetic-contextual-anonymizer-dataset."},
	{"name":"github-issues","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/xyx138/github-issues","creator_name":"xxx","creator_url":"https://huggingface.co/xyx138","description":"\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for GitHub Issues\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nGitHub Issues is a dataset consisting of GitHub issues and pull requests associated with the ü§ó Datasets repository. It is intended for educational purposes and can be used for semantic search or multilabel text classification. The contents of each GitHub issue are in English and concern the domain of datasets for NLP, computer vision, and beyond.\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tSupported Tasks and Leaderboards\\n\\t\\n\\nFor each of the tasks‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/xyx138/github-issues."},
	{"name":"brwac","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/bfunicheli/brwac","creator_name":"Funicheli","creator_url":"https://huggingface.co/bfunicheli","description":"\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for BrWaC\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nThe BrWaC (Brazilian Portuguese Web as Corpus) is a large corpus constructed following the Wacky framework, \\nwhich was made public for research purposes. The current corpus version, released in January 2017, is composed by \\n3.53 million documents, 2.68 billion tokens and 5.79 million types. Please note that this resource is available \\nsolely for academic research purposes, and you agreed not to use it for any commercial‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/bfunicheli/brwac."},
	{"name":"RAG-Evaluation-Dataset-KO","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/datalama/RAG-Evaluation-Dataset-KO","creator_name":"DongWook Kim","creator_url":"https://huggingface.co/datalama","description":"\\n\\t\\n\\t\\t\\n\\t\\tDataset Card for Reconstructed RAG Evaluation Dataset (KO)\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Summary\\n\\t\\n\\nÎ≥∏ Îç∞Ïù¥ÌÑ∞ÏÖãÏùÄ allganize/RAG-Evaluation-Dataset-KOÎ•º Í∏∞Î∞òÏúºÎ°ú PDF ÌååÏùºÏùÑ Ìè¨Ìï®ÌïòÎèÑÎ°ù Ïû¨Íµ¨ÏÑ±Ìïú ÌïúÍµ≠Ïñ¥ ÌèâÍ∞Ä Îç∞Ïù¥ÌÑ∞ÏÖãÏûÖÎãàÎã§. ÏõêÎ≥∏ Îç∞Ïù¥ÌÑ∞ÏÖãÏóêÏÑúÎäî PDF ÌååÏùºÏùò Í≤ΩÎ°úÎßå Ï†úÍ≥µÎêòÏñ¥ ÏàòÎèôÏúºÎ°ú ÌååÏùºÏùÑ Îã§Ïö¥Î°úÎìúÌï¥Ïïº ÌïòÎäî Î∂àÌé∏Ìï®Ïù¥ ÏûàÏóàÍ≥†, ÏùºÎ∂Ä PDF ÌååÏùºÏùò Í≤ΩÎ°úÍ∞Ä Ïú†Ìö®ÌïòÏßÄ ÏïäÏùÄ Î¨∏Ï†úÎ•º Î≥¥ÏôÑÌïòÍ∏∞ ÏúÑÌï¥ PDF ÌååÏùºÏùÑ Ìè¨Ìï®Ìïú Îç∞Ïù¥ÌÑ∞ÏÖãÏùÑ Ïû¨Íµ¨ÏÑ±ÌïòÏòÄÏäµÎãàÎã§.\\n\\n\\t\\n\\t\\t\\n\\t\\tSupported Tasks and Leaderboards\\n\\t\\n\\n\\nRAG Evaluation: Î≥∏ Îç∞Ïù¥ÌÑ∞Îäî ÌïúÍµ≠Ïñ¥ RAG ÌååÏù¥ÌîÑÎùºÏù∏Ïóê ÎåÄÌïú E2E EvaluationÏù¥ Í∞ÄÎä•Ìï©ÎãàÎã§.\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tLanguages\\n\\t\\n\\nThe dataset is in Korean (ko).\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Structure‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/datalama/RAG-Evaluation-Dataset-KO."},
	{"name":"agentic_synthetic_customer_service_conversations","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/marccgrau/agentic_synthetic_customer_service_conversations","creator_name":"Marc Christopher Grau","creator_url":"https://huggingface.co/marccgrau","description":"\\n\\t\\n\\t\\t\\n\\t\\tLLM-filtered Customer Service Conversations Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tOverview\\n\\t\\n\\nThis dataset contains simulated conversations generated by our agentic simulation system.\\nThe conversations are filtered by a LLM to ensure they are of high quality.\\nEach record is stored in JSON Lines (JSONL) format and includes:\\n\\nInput Settings: Metadata such as selected bank, customer, agent profiles, and task details.\\nMessages: The full conversation messages.\\nSummary: A German summary of the conversation.‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/marccgrau/agentic_synthetic_customer_service_conversations."},
	{"name":"agentic_synthetic_aggressive_conversations","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/marccgrau/agentic_synthetic_aggressive_conversations","creator_name":"Marc Christopher Grau","creator_url":"https://huggingface.co/marccgrau","description":"\\n\\t\\n\\t\\t\\n\\t\\tSimulated Aggressive Customer Service Conversations Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tOverview\\n\\t\\n\\nThis dataset contains aggressive customer service conversations generated by an agentic simulation system.\\nEach record is stored in JSON Lines (JSONL) format and includes:\\n\\nScenario Metadata: Selected bank, customer, agent profiles, and task details.\\nConversation Messages: Full message history between the customer and service agent.\\nSummary: A German summary of the conversation.\\nCost Metrics: API cost‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/marccgrau/agentic_synthetic_aggressive_conversations."},
	{"name":"Bharat_NanoArguAna_gu","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoArguAna_gu","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\\n\\t\\n\\t\\t\\n\\t\\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tOverview\\n\\t\\n\\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThis particular dataset is the Gujarati version of the NanoArguAna dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoArguAna_gu."},
	{"name":"Bharat_NanoArguAna_hi","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoArguAna_hi","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\\n\\t\\n\\t\\t\\n\\t\\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tOverview\\n\\t\\n\\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThis particular dataset is the Hindi version of the NanoArguAna dataset, specifically adapted for information‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoArguAna_hi."},
	{"name":"Bharat_NanoArguAna_hne","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoArguAna_hne","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\\n\\t\\n\\t\\t\\n\\t\\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tOverview\\n\\t\\n\\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThis particular dataset is the Chhattisgarhi version of the NanoArguAna dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoArguAna_hne."},
	{"name":"Bharat_NanoArguAna_ksd","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoArguAna_ksd","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\\n\\t\\n\\t\\t\\n\\t\\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tOverview\\n\\t\\n\\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThis particular dataset is the Kashmiri (Devanagari script) version of the NanoArguAna dataset, specifically‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoArguAna_ksd."},
	{"name":"Bharat_NanoArguAna_ml","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoArguAna_ml","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\\n\\t\\n\\t\\t\\n\\t\\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tOverview\\n\\t\\n\\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThis particular dataset is the Malayalam version of the NanoArguAna dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoArguAna_ml."},
	{"name":"Bharat_NanoArguAna_mr","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoArguAna_mr","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\\n\\t\\n\\t\\t\\n\\t\\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tOverview\\n\\t\\n\\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThis particular dataset is the Marathi version of the NanoArguAna dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoArguAna_mr."},
	{"name":"Bharat_NanoArguAna_ne","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoArguAna_ne","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\\n\\t\\n\\t\\t\\n\\t\\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tOverview\\n\\t\\n\\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThis particular dataset is the Nepali version of the NanoArguAna dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoArguAna_ne."},
	{"name":"Bharat_NanoArguAna_ta","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoArguAna_ta","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\\n\\t\\n\\t\\t\\n\\t\\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tOverview\\n\\t\\n\\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThis particular dataset is the Tamil version of the NanoArguAna dataset, specifically adapted for information‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoArguAna_ta."},
	{"name":"Bharat_NanoArguAna_te","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoArguAna_te","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\\n\\t\\n\\t\\t\\n\\t\\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tOverview\\n\\t\\n\\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThis particular dataset is the Telugu version of the NanoArguAna dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoArguAna_te."},
	{"name":"Bharat_NanoArguAna_ur","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoArguAna_ur","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\\n\\t\\n\\t\\t\\n\\t\\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tOverview\\n\\t\\n\\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThis particular dataset is the Urdu version of the NanoArguAna dataset, specifically adapted for information‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoArguAna_ur."},
	{"name":"Bharat_NanoTouche2020_bn","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoTouche2020_bn","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\\n\\t\\n\\t\\t\\n\\t\\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tOverview\\n\\t\\n\\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThis particular dataset is the Bengali version of the NanoTouche2020 dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoTouche2020_bn."},
	{"name":"Bharat_NanoTouche2020_bho","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoTouche2020_bho","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\\n\\t\\n\\t\\t\\n\\t\\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tOverview\\n\\t\\n\\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThis particular dataset is the Bhojpuri version of the NanoTouche2020 dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoTouche2020_bho."},
	{"name":"Bharat_NanoTouche2020_gu","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoTouche2020_gu","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\\n\\t\\n\\t\\t\\n\\t\\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tOverview\\n\\t\\n\\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThis particular dataset is the Gujarati version of the NanoTouche2020 dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoTouche2020_gu."},
	{"name":"Bharat_NanoTouche2020_hi","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoTouche2020_hi","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\\n\\t\\n\\t\\t\\n\\t\\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tOverview\\n\\t\\n\\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThis particular dataset is the Hindi version of the NanoTouche2020 dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoTouche2020_hi."},
	{"name":"Bharat_NanoTouche2020_kn","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoTouche2020_kn","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\\n\\t\\n\\t\\t\\n\\t\\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tOverview\\n\\t\\n\\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThis particular dataset is the Kannada version of the NanoTouche2020 dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoTouche2020_kn."},
	{"name":"Bharat_NanoTouche2020_ksa","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoTouche2020_ksa","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\\n\\t\\n\\t\\t\\n\\t\\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tOverview\\n\\t\\n\\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThis particular dataset is the Kashmiri (Arabic script) version of the NanoTouche2020 dataset, specifically‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoTouche2020_ksa."},
	{"name":"Bharat_NanoTouche2020_ksd","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoTouche2020_ksd","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\\n\\t\\n\\t\\t\\n\\t\\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tOverview\\n\\t\\n\\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThis particular dataset is the Kashmiri (Devanagari script) version of the NanoTouche2020 dataset‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoTouche2020_ksd."},
	{"name":"Bharat_NanoTouche2020_mai","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoTouche2020_mai","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\\n\\t\\n\\t\\t\\n\\t\\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tOverview\\n\\t\\n\\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThis particular dataset is the Maithili version of the NanoTouche2020 dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoTouche2020_mai."},
	{"name":"Bharat_NanoTouche2020_mni","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoTouche2020_mni","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\\n\\t\\n\\t\\t\\n\\t\\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tOverview\\n\\t\\n\\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThis particular dataset is the Manipuri version of the NanoTouche2020 dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoTouche2020_mni."},
	{"name":"Bharat_NanoTouche2020_or","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoTouche2020_or","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\\n\\t\\n\\t\\t\\n\\t\\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tOverview\\n\\t\\n\\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThis particular dataset is the Odia (Oriya) version of the NanoTouche2020 dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoTouche2020_or."},
	{"name":"Bharat_NanoTouche2020_pa","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoTouche2020_pa","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\\n\\t\\n\\t\\t\\n\\t\\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tOverview\\n\\t\\n\\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThis particular dataset is the Punjabi version of the NanoTouche2020 dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoTouche2020_pa."},
	{"name":"Bharat_NanoTouche2020_sa","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoTouche2020_sa","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\\n\\t\\n\\t\\t\\n\\t\\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tOverview\\n\\t\\n\\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThis particular dataset is the Sanskrit version of the NanoTouche2020 dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoTouche2020_sa."},
	{"name":"Bharat_NanoTouche2020_ta","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoTouche2020_ta","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\\n\\t\\n\\t\\t\\n\\t\\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tOverview\\n\\t\\n\\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThis particular dataset is the Tamil version of the NanoTouche2020 dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoTouche2020_ta."},
	{"name":"Bharat_NanoTouche2020_ur","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/carlfeynman/Bharat_NanoTouche2020_ur","creator_name":"Arun","creator_url":"https://huggingface.co/carlfeynman","description":"\\n\\t\\n\\t\\t\\n\\t\\tBharat-NanoBEIR: Indian Language Information Retrieval Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tOverview\\n\\t\\n\\nThis dataset is part of the Bharat-NanoBEIR collection, which provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets containing 50 queries and up to 10K documents each.\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\nThis particular dataset is the Urdu version of the NanoTouche2020 dataset, specifically adapted for‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/carlfeynman/Bharat_NanoTouche2020_ur."},
	{"name":"agentic_synthetic_aggressive_conversations_en","keyword":"monolingual","license":"Apache License 2.0","license_url":"https://choosealicense.com/licenses/apache-2.0/","language":"en","dataset_url":"https://huggingface.co/datasets/marccgrau/agentic_synthetic_aggressive_conversations_en","creator_name":"Marc Christopher Grau","creator_url":"https://huggingface.co/marccgrau","description":"\\n\\t\\n\\t\\t\\n\\t\\tSimulated Aggressive Customer Service Conversations Dataset\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tOverview\\n\\t\\n\\nThis dataset contains aggressive customer service conversations generated by an agentic simulation system.\\nEach record is stored in JSON Lines (JSONL) format and includes:\\n\\nScenario Metadata: Selected bank, customer, agent profiles, and task details.\\nConversation Messages: Full message history between the customer and service agent.\\nSummary: A German summary of the conversation.\\nCost Metrics: API cost‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/marccgrau/agentic_synthetic_aggressive_conversations_en."},
	{"name":"mongs","keyword":"monolingual","license":"MIT License","license_url":"https://choosealicense.com/licenses/mit/","language":"en","dataset_url":"https://huggingface.co/datasets/sangyon/mongs","creator_name":"yoon","creator_url":"https://huggingface.co/sangyon","description":"\\n\\t\\n\\t\\t\\n\\t\\tDataset Card for Dataset Name\\n\\t\\n\\n\\n\\nThis dataset card aims to be a base template for new datasets. It has been generated using this raw template.\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Details\\n\\t\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Description\\n\\t\\n\\n\\n\\n\\n\\n\\nCurated by: [More Information Needed]\\nFunded by [optional]: [More Information Needed]\\nShared by [optional]: [More Information Needed]\\nLanguage(s) (NLP): [More Information Needed]\\nLicense: [More Information Needed]\\n\\n\\n\\t\\n\\t\\t\\n\\t\\tDataset Sources [optional]\\n\\t\\n\\n\\n\\n\\nRepository: [More‚Ä¶ See the full description on the dataset page: https://huggingface.co/datasets/sangyon/mongs."},
	{"name":"COPA-cy","keyword":"monolingual","license":"Creative Commons Attribution 4.0 International","license_url":"https://choosealicense.com/licenses/cc-by-4.0/","language":"en","dataset_url":"https://huggingface.co/datasets/mgrbyte/COPA-cy","creator_name":"Matt Russell","creator_url":"https://huggingface.co/mgrbyte","description":"\\n\\t\\n\\t\\t\\n\\t\\tDataset Card for COPA-cy\\n\\t\\n\\n"}
]
;
